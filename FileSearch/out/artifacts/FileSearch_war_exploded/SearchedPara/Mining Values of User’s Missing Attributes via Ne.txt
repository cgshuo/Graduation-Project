 Now online soc ial network (e.g., twitter, Weibo, QQ , Facebook) have become a neces-sity in people X  X  daily life. Thus, people produce large amount of online information, such as online account, social links and behavioral records. Meanwhile, that infor-mation is public and easy to crawl. A concern that is raised about social networks is how to using that information to mining more latent information, for example, infer -ring missing attributes, such as gender, status and so on, about online user. Some com-panies using that in formation to analysis user behavior, which could improve the accu-racy of recommendation and provide targeted advertisement and services to their users. Besides, many researches also using some data mining approaches to infer user -missing attributes. Most o f them achieve excellent performance. However, attributes inferring suffers from two important limitations. 2
First, we perfect assume this problem as a classif ication problem and a large num ber of researchers take the classify methods to add ress this probl em. Most of algo rithms, such as, Bayes classifier and SVM, have good pe rformance when infer di chotomous variable, for example, gender or sexual orientation. However, when infer other attrib-utes, especially major, status; the accuracy is not as good as dich otomous variable. The reason lead to this result is that those algorithms is design to address binary classifica-tion problem. Even if some method, such as, label propagation, infer -ring user X  X  miss-(e.g. social links, users X  attribution, and behavior records) and the missing attribution. 
Second, another importation limitation is that the great majority of these ap proaches assumption used by researchers for te sting algorithms using pubic da tasets. However, in real -life, especially the number of online social network user are increased rapidly, a method that can analyze a large number of data is necessary. Moreover, even if some method can process large number of data, the accuracy and time efficiency is unac-ceptable. Researches attempt various approach es, such as, machine learning, for link -ever  X  those machine learning algorithms do not perform well in time efficiency. On one hand, several algorithms need large time to compute the training weight matrix neighbor no des X  information and structure of target user, and this would use large time (e.g. majority voting). 
In this work , we aim to address the above two challenges and develop automatic techniques to infer target user X  X  target attributes. Our contributions are as follows: 
First, we proposed a neural network model to address the first challenges. NN has a good performance when solved multi -classification problem. Through this model, we could catch the nonlinear relation between the known and unknown information.
Second, in order to cope the second problem, we exploit parallelism to process the data more effectively. This is the second difference between NN and others machine learning approaches. More details, we crawl 3.2m users of Zhihu social network and perfo rm our experiment model in such a parallel manner.

Third, we report results from an extensive empirical evaluation against four state -of -achieve the stat -of -the -art performan ce, we conside r both user X  X  publicly available so-cial friends and behavioral records. Results show that the pro -posed algorithm can pro-vide a considerably higher accuracy and less time -consuming. Moreover, an interesting result is that profile attributes s uch as status can be predicted with more than 75% ac-curacy using our algorithms.
 pre sents related work, problem definition, proposed model, experiment evaluation and conclus ion. A wide range of attribute and link prediction methods have been developed and re-ceived excellent performance in the social network. Most of them leverage user infor-mation that is publicly in online social networks to infer profile. Such a s: methods of infer missing attributes and the links. As we aim to profile a user X  X  attributes accurately attributes information, social links and behaviors records and a bove all .
 Using attributes information is first used by researcher to predict missing attribute. Most of studies focus on linear classifier, for example: Lindamood et al. [9 ] present a modification of Na X ve Bayes classification that is suitable for classi fying large amount of social network data to prediction the political attitudes. They evaluated their method on Facebook dataset and using user X  X  social links and other attributes. However, their approach is not applicable to user that share no attributes.

Kosinski et al. [2 ] using the data about Facebook, detailed demographic profiles and the result of several psychometric tests to predict sensitive personal attributes, such as: sexual orientation, ethnicity, religious and so on. They predict different at tribute using gender by binary classifier. However, the result of linear regression method depends on the model. Therefore, some time they may not perform very well.
 Us ing attributes information and social links caused widespread attention after the bad performance by only use attribute in formation. A large related work has been done by research and the representative work are as follow: global and local ways that are centered on users with a common attribute is a natural works well in their dataset.

Dougnon et al. [3 ] note that most of approaches assumes the unrealistic assumption that full social graph is available for training and several algorithms do not consider th e rich information that is available on social networks, such as, group memberships, likes and so on. The authors proposed a new lazy algorithm named PGPI that can infer user successful, it requires large time to compute the scores in iteration.

Li et al. [1 ] using a label propagation method to infer users X  profile. They present a hidden factor in social connections  X  relationship type. Based on this development, they Through iteratively profiles attributes by propagation via certain types of connections, and profiles types of connections based on attributes and the network structure, their al gorithm profiles various attributes accurately. However, the weight matrix used large time to compute and need compute it again when add a new node in his social network. users X  attributes. In addition, they design different strategies for computing the rela-tional weights between users X  attribute s and social links. Mo et al. [11 ] also do some 4 experiment about this approach, they proposed a co -training method, which has two classifiers to process the links and attributes respectively. Using attributes information, social links and behavior records:
Yin et al. [14, 15 ] proposed a social -attribute network (SAN) to gracefully integrate social link and attribute information in a scalable way. They focused on a Random Walk with Restart (RWwR) algorithm to the SAN model to predict links as well as infer mutex attributes. They generalize several le ading supervised and unsupervised link and attribute -prediction algorithms in this improved model. Moreover, they make a novel make full use of this conclusion in their e xperimental section.

Finally, we emphasize that most of existing methods profile user attribute used large However, our work take neural network to address these two chall enges. To the best of our knowledge, this is the first study that explores neural network. network and ego networks and propose a novel model of inferrin g user X  X  attributes and behaviors to suit the neural network. In this section, we will formally introduce some definition of the problem of inferring user profiles.
 is the set of nodes in the social graph, and we assume the number of full social graph  X   X   X   X  Example 1. Let be a social graph with five nodes  X  = {  X  X  X   X   X  ,  X  X  X  X  X  X  X  ,  X  X  X  X  ,  X  X  X  X  X  ,  X  X  X  X  X  X  } . Consider three attributes name , gender and status, and two behaviors review John X  X  moments and take part in a basketball discussion. Therefore, the relation {  X  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  } ,  X  3 = {  X  X  X  X  ,  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  X  X  X  } ,  X  4 = {  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  } and  X  5 = {  X  X  X  X  X  X  ,  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  } . Thus the relation between the behavior X  X  {  X  X  X  X  ,  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  } ,  X  4 = {  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X   X  X  X   X   X  X  X   X  X  X  X  X  X  X  X  X  } {  X  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X   X  X  X   X   X   X  X  X  X  X  X  X  X  X  } ,  X  3 = {  X  X  X  X  ,  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  X  X  X  ,  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  } ,  X  4 = {  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  ,  X  X  X   X   X  X  X   X  X  X  X  X  X  X  X  X  X  } and  X  5 = {  X  X  X  X  X  X  ,  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  ,  X  X  X  X  X  X   X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  } .
 Definition 2 (User profiling in a social graph by using attributes and behavior X  X  infor-mation, called UPS). The problem of inferring the user profile of a node n in a social graph G is to correctly guess the missing attributes X  value using other X  X  attributes and behavior X  X  information provided in the social graph. We address this problem using a CNN architecture and we will discuss the detail in next sectio n.
 Definition 3(ego network) . A user X  X  ego network can be represented as a graph  X   X  = node X  X  (e.g. v0) social friends. In addition, we define  X   X  contains both the connections between the ego and his friends and the con nections among their friends.  X  is a relation L  X   X   X   X   X  (  X  is the sum of kinds of attributes and behavior records), which include the ego node and his friends X  both attributes and behaviors records. Besides, a matrix L includes all information about an ego network.
 Example 2. Let John, as an ego node, and his friends are Alice and Tom. T he  X   X  and  X   X  X  X  X  X  X  X  ) } . The all information of this e go netw ork can be represent as the matrix  X  = (  X  X  X  X  ,  X  X  X  X  X  X  ,  X  X  X  X  X  X  X  X  X  X  X  X  X  ,  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  ) } , which z ero represents the corresponding attribute or behavior value is not observed in his profile. Definition 4 (User profiling in ego network, named UPE). The problem of inferring the user profile of an ego node  X   X  V in an ego network  X   X  is to correctly gu ess the attrib-utes value of n using the information in his ego network. In this section, we present our neu ral network model and explain the architecture and social network and using only attributes and behaviors. Then, we present another ver-sion UPE that designed for predicting user profiles in the ego network using attributes, behaviors and links. UPE has two key differences from the UPS. First, it f ocuses on ego -network, while the UPS focus on either a  X  X ull X  social network, which ignore useful 6 connections between the ego and his friends. Second, we capture a relationship between these connections and missing attributes, for example, the status and m ajor attributes, the ego nodes more likely shares these two attributes value with his friends than others. [ 1 ] 4.1 U ser Profiling in social network Our proposed algorithm UPS for inferring profiles in social network by using attributes and behaviors informatio n. This algorithm is inspired by the good performance of NN model in Natural Language Processing [ 12 ]. In the NLP, NN model changes each sen-tence as a feature vector. Similarly, we defined the set F, which includes the attributes and behaviors information of each user, as the feature vector. Then we will try to pro -process our features as numeric feature vectors and then fed to a multilayer convolution tributes Infer approa ch, neural network (NN) architecture could achieve better perfor-mance when we fed it a larger dataset. o ur model is summarized in Fig. 2 . The first layer extracts feature for each user. The second layer translates those features into the numeric feature vectors. In addition, the following layers are standard NN layers. neural network with P layers can be seen as a com position of functions f, corresponding to each layer p. layer we used in our architecture shown in Fig.2 .
 T ransforming user X  X  F into Feature Vectors (Lookup Table layer)
One of the essential key points of our model is its ability to perform well with the user X  X  attributes (almost Chinese characters). Our model could not cat ch the relation-ships between Chinese characters and we also could not train our architecture through those words. Because neural network is a math model in essentially.

In NLP, researcher use word representing to transform each input word into a vector nodes in our attribute classification (we prefer consider our profile inferring problem as classification problem); we should first concentrate on learning discriminative wo rd embedding, which carry less syntactic and semantic information. And, it usually takes a long time to train the word embedding. In addition, there are many trained word em-bedding that are freely available, for example, google word2vec. Our experiments fi rstly utilize the trained embedding provided by Google. However, some attributes are construct by serval words and we trained a small lookup table to represent those attrib-utes perfectly.

More formally, for any node  X   X  s word vector  X   X  , a numeric v ector representation  X  X   X  is given by the Lookup table layer LTF (  X  ) : H idden layer
These two hidden layers are fully connected layers. The first hidden layer has n*n neuro n, and dropout half of these neuron in the second hidden layer. We used ReLU as active function, which is represent by the following equation:
Besides, in order to compute th e parameters quickly , we used SGD in our training steps. S oftmax Classifier (Output layer)
To compute the finally value of the target user X  X  missing attributes, we used a soft-possible attribute value if we give the final weight matrix  X  and bias  X  .

Formally, the final output of each input vector  X   X  can be interpreted as follow: 4.2 U ser Profiling in Ego -network UPE use the CNN model to catch latent relations of users X  attributes and social links and predict user attribute value using this relationship. This algorithm is inspired by the good performance of CNN in image Identification. In the process of image recognition, researchers catch the feature of the image through the CNN, and the input of CNN is an array of pixel values of the image. Similarly, when we add social links in our neural network, the input become a matrix L, as the feature matrix in image classification. The 8 pre -process is the same as UPS algorithm, but we construct a more fixed network to trained our dataset and predict the missing attribute (or classify the target user into the missing attribute possible values). 
Our model is summarized i n fig.3 . The first layer is th e same as the UPS layer. Th e second layer contains serval convolution operation, and we take multiple convolution kernels of different sizes to extract feature of input data. We would introduce our model layer by layer in the following parts.
 C onvoluti on layer
The first two layer are same as UPS. That is to say, each word in  X  is first passed as  X   X  . This f eature can be viewed as the initial input of the standard convolution neural written as:
Convolution can be seen as a linear operation between weight vector W and a nu-meric represented by elements in a matrix  X  X   X  (in our lookup table (5)). Then the vec-tor  X  X   X  can be fed to one standard neural network layer which perform affine tra nsfor-mations over their inputs:
W here  X  is the weight matrix and  X  is the bias in this layer. We use ReLU as the active function. As for standard affine layers, convol ution layers often stacked to extract higher level features.
 M ax Pooling layer
The size of the output (6) depend on the number of ego nodes social friends in the ego -network fed to the network. Local feature vectors extracted by the convolutional pendent of the Li, in order to apply subsequent standard affine layers. Traditional con-volutional network often apply an average or a max operation over the convolution layer. The a verage operation does not make much sense in our case; as in general most prediction. Instead, we used a max approach, which forces the network to capture the most useful local features produced by the convolutional layers. Given a matrix  X   X   X  1 output by a convolution layer p -1 , the Max layer l output a vector  X 
W here t is the number of layer p -1 output. The fixed size global size fe ature vector can be then fed to the standard affine network layers (4). As in the UPS approach, we then finally produce one score per possible attribute values for the given. We performed several experiments to access the accuracy of the propose d UPE and computer with a fourth generation 64 -bit Core i5 processor running Ubuntu 14.5 and 16GB of RAM. Our UPS and UPE algorithms were run on GPU to complete parallel model.

We compared the performance of the proposed algorithm with four state -of -the -art algorithms: Linear Regression, Na X ve Bayes classifiers [ 9 ], Graph Semi -Supervised Learn ing and Majority Voting. Thes e four algorithms predict the value of target user X  X  gender, status and major respectively. 
Linear Regression (LR): we construct a linear function by using our training dataset, and predict the missing values using this functi on. Na X ve Bayes (NB) classifiers: NB well as our UPS model. 
Both the Linear Regression and Na X ve Bayes classifiers have the state -of -art perfor-mance on binary classifi cation. However, inferring user X  X  missing profiles is a problem of multi -classification. Therefore, we extend those two algorithms to solve this problem by using One vs. Rest ways.

Graph Semi -Supervised Learning (GSSL) [ 11 ] and Majority Voting (MV) [ 6 ] inf er user X  X  profiles by using the social structures which is the same as our UPE model. For algorithms which need specific parameters, the best values have been empirically found to provide the best results. 5.1 D ataset Experiments were carried on datasets are c rawled from the real online social network websites: Zhihu. Table 1 gives detail statistics of this dataset.

A series of data processing such as target attribute selection and data cleaning are conducted before running algorithms.
 them are needed. In fact, some features such as username provide little information for 10 our classification problem. Besides, most people fill only a few of these features. Thus, we select 13 featu res for our algorithms. After excluding useless attributes, we finally choose gender, status and major as basic profile information of each target user.
Data cleaning: although we select 13 attributes which are most useful information for our problem, the number of missing value is still very large and noise information, like status values are love money, exist widespread in our datasets. For gender, 0.5 is used to represent missing value (1 represents male and 0 represents female). For status and major, 20 is represent the noise information and 0 is represent the missing value (we assume the possible value of status and major are 15 and 19 and represent by 1 -15 and 1 -19 respectively). And we also take the same method to clean other 10 attributes. 5.2 E xperiment Result Table 1 and Table 2 give the results of experiments, from which various algorithms X  performance can be evaluated. Fig 4 describe s the accuracy of predict target users gen-der and status attributes via public information respectively.

Gender , the first version of Figure 3 illustrates various algorithms X  performance on gender prediction. It is clear to see in most cases the result of all methods are similarly. specific, UPS and UPE methods perform better than other methods, and MV achieve the worst performance. This is because that the attribute of ge nder did not depend on the target user social friends.

Status , another version gives another experiment result. That is, UPE outperform other methods. In detail, the accuracy most of methods is between 30% and 40%. How-ever, UPE algorithms obtain a rate of 76.28% of correctly predicting status, in which the accuracy is improved almost 40%. This result demonstrates that UPE have the great advantages when deal with multi classification problem. algo rithms UPS UPE NB LR GSSL MV
Ana lysis Table 2 , we can see two phenomena. The first one is UPE have same ex-periment result used NN and CNN architecture. So, we choice NN architecture in our achiev e the same accuracy. Second, the accuracy of UPECNN is improved when used CNN architecture both in gender and status prediction. Compared UPE and UPS, the result improved significantly when we add the social links in the neural network, that friends. And, this hidden relation, in our definition, is the nonlinear relation exist in our ego -network.
In contrast to machine learning algorithms, UPE predicts multi candi date attributes such as status in online social network more accurately. From our result, we find it is possible to learn hidden users X  attributes based on relational information and profile similarity among users. However , we did not demonstrate the less time neural network used in our experiment. Thus, there is a need of big data in real online social network to test distinction between our algorithms and other methods. In addition, some attrib-utes are mutex, such as gender. But we did not consider this r elation in our algorithms. As our future work, we would like to add this mutex relation in our algorithms. Further, networks.
 References 12
