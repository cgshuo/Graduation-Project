 We propose and analyze two algorithms for maintaining ap-proximate Personalized PageRank (PPR) vectors on a dy-namic graph, where edges are added or deleted. Our algo-rithms are natural dynamic versions of two known local vari-ations of power iteration. One, Forward Push, propagates probability mass forwards along edges from a source node, while the other, Reverse Push, propagates local changes backwards along edges from a target. In both variations, we maintain an invariant between two vectors, and when an edge is updated, our algorithm first modifies the vectors to restore the invariant, then performs any needed local push operations to restore accuracy.

For Reverse Push, we prove that for an arbitrary directed graph in a random edge model, or for an arbitrary undi-rected graph, given a uniformly random target node t , the cost to maintain a PPR vector to t of additive error  X  as k edges are updated is O ( k + d/ X  ), where d is the average degree of the graph. This is O (1) work per update, plus the cost of computing a reverse vector once on a static graph. For Forward Push, we show that on an arbitrary undirected graph, given a uniformly random start node s , the cost to maintain a PPR vector from s of degree-normalized error  X  as k edges are updated is O ( k + 1 / X  ), which is again O (1) per update plus the cost of computing a PPR vector once on a static graph.

Personalized PageRank (PPR) models the relevance of nodes in a network from the point of view of a given node. It has applications in search [13, 12], friend recommendations [4, 11], community detection [22, 2], video recommendations [6], and other applications. Because PPR is expensive to compute at query time, several authors have proposed pre-computing it for each user and storing it [13, 7, 8]. However, in practice graphs are dynamic, for example on a social net-work users are constantly adding new edges to the network, so we need a method of updating pre-computed PPR values. In this work, we propose two new algorithms for updating pre-computed PPR vectors and give the first rigorous anal-ysis of their running time.

There are four main algorithms for computing PPR [15], of which only one has an analysis for dynamic graphs prior to our work. The first is power iteration [21], but it is very slow, requiring  X ( m ) time per user (where m is the number of edges), so it can X  X  be used efficiently for PPR even on static graphs. The second, Forward Push [7, 2], is a local variation of power iteration which starts from the source user (the node whose point of view we take) and pushes proba-bility mass forwards along edges. Berkin [7] proposed pre-computing Forward Push vectors from many source nodes, and Ohsaka et al. [20] proposed an algorithm for updating it on dynamic graphs, however no past work has analyzed the running time for maintaining Forward Push. The third, Reverse Push [13, 2], is an alternative variation of power iteration which starts at each target node and pushes val-ues backwards along edges to improve estimates. Jeh and Widom [13] and Lofgren et al. [17] propose pre-computing Reverse Push vectors (or a variation on them), to enable ef-ficient search, but no past work has proposed an algorithm for updating Reverse Push vectors on dynamic graphs. Fi-nally, a fourth method of computing PPR is Monte-Carlo [3, 9], and for that algorithm Bahmani et al. [5] give an ef-ficient algorithm for updating it on dynamic graphs, with running time analysis in a random edge arrival order model. In experiments, Ohsaka et al. [20] find that when maintain-ing very accurate PPR vectors, Monte-Carlo is slower than Forward-Push, motivating the analysis of updating Forward Push.

Our contribution is the first running time guarantees for updating Forward Push on undirected graphs and for updat-ing Reverse Push on directed as well as undireted graphs. The analysis is challenging because a new edge at one node can cause that node to push, which can cause a cascade of other nodes to push. Understanding and bounding the size of this cascade required a novel amortized analysis. We al-low for a worst case graph, but we assume that edge updates arrive in a random order to better capture performance in practice. The same assumption was used in the analysis of Monte Carlo [5] where the bounds it leads to were found to model the running time in practice on Twitter. Alter-natively, for undirected graphs we prove a worst-case amor-tized running time. In addition, for undirected graphs, we strengthen the analysis of Monte-Carlo on dynamic graphs [5] to a worst-case edge arrival order.

Our algorithms are simple to implement, and we present two experiments for forward push. One insight from our theoretical analysis is a different way of updating Forward Push values than the previously proposed method [20], and we find that our variation is 1.5-3.5 times faster than that method without sacrificing accuracy. In the second exper-iment, we evaluate forward push for the problem of find-ing the top K highest personalized PageRank from a source node. We compare to the Monte-Carlo method of Bahmani et al. [5] and found that the forward push is 4.5-12 times more efficient in storage compared to Monte-Carlo, and is able to do edge update 1.5 -2.5 times faster.
 The main idea of our algorithms is that both Forward Push and Reverse Push maintain an invariant between a pair of vectors, and when an edge is added or deleted, we first restore the invariant with an efficient change to the vectors, then perform local push operations as needed to control the error. One limitation of our analysis is that it applies to the pure versions of Forward Push and Reverse Push, while some prior work [13, 7] proposes combining Forward or Reverse push vectors together, but we believe our analysis would extend to that case. It would also be interesting to extend our analysis adapt the Personalized PageRank search index of [17] to dynamic graphs.

For the Reverse Push algorithm, we show that on a worst-case graph, for a uniform random target, the expected time required to maintain PPR estimates at accuracy  X  to that target as k edge updates arrive in a random order is O ( k + k/ ( n X  ) + d/ X  ). Here  X  is the desired additive error of the estimates, and d is the average degree of nodes in the graph. Since a random PPR value is 1 /n , values smaller than 1 /n are not very meaningful. Hence typically  X  =  X (1 /n ) and our running time is O ( k + d/ X  ). Since d/ X  is the expected time required to compute Reverse Push from scratch [1, 15], we see that our incremental algorithm can maintain esti-mates after every edge update using O (1) time per update and the time required to compute a single Reverse Push vector.

For the Forward Push algorithm, we show that on an arbitrary undirected graph and arbitrary edge arrival or-der, for a uniform random source node s , the worst-case running time to maintain a PPR vector from that source node is O ( k + k/ ( n X  ) + 1 / X  ). Here  X  is a bound on the degree-normalized error (which we define later). Typically  X  =  X (1 /n ), so this is O ( k + 1 / X  ). The cost of computing such a PPR vector from scratch is O (1 / X  ) [2] so we again see that the cost to maintain the PPR vector over k updates is O (1) per update plus the cost of computing it once from scratch.
 One observation that follows from our work is that for Monte-Carlo, for an arbitrary undirected graph and arbi-trary edge arrival order, the time required to maintain r ran-dom walks from every source node over k arrivals is O ( rk ). This contrasts with a worst-case example constructed on di-rected graphs where the total running time to maintain these walks grows super-linear in k [14]. Our observation suggests a weaker yet still meaningful bound without the random edge assumption made in Bahmani et al. [5] for Monte-Carlo methods on undirected graphs.
Let G = ( V,E ) be an unweighted directed graph. Let A denote the adjacency matrix of G and let D denote the di-agonal matrix representing the outdegrees of all vertices in G . For a vertex v , let N out ( v ) denote the set of out neigh-bors of v and let N in ( v ) denote the set of in neighbors of v . The personalized PageRank vector ~ X  s for a source node s is defined as the unique solution of the following linear system ([21]): where  X  (a.k.a. the teleport probability) is a constant be-tween 0 and 1, and ~e s is the indicator vector with a single nonzero entry of 1 at s . For a pair of vertices s and t on G , we will use  X  ( s,t ) to denote the personalized PageRank from s to t . This linear algebraic definition of personalized PageR-ank is equivalent to simulating a random walk. Start from the source node s , with probability (1  X   X  ), go to a uniformly chosen neighbor of the current node, or with probability  X  stop at the current node:  X  ( s,t ) is the probability that a random walk from s stops at t [21]. In the above definitions, we assumed that the outdegree of every vertex is at least one for simplicity. If a vertex has no out neighbors, then the random walk transitions to s with probability (1  X   X  ) (cf. Gleich [10] for other ways to handle dangling nodes).
In the dynamic edge arrival model, we start with an initial graph and there is a sequence of edge updates one by one. Let G 0 = ( V 0 ,E 0 ) denote the initial graph. Let k denote the number of edge updates. When the i -th edge e i = ( u i ,v arrives, if e i is already in G i  X  1 , then it will be deleted; else it will be added to G i  X  1 . Let G i = ( V i ,E i updated graph. Note that V i can differ from V i  X  1 by at most two vertices. Let d out i ( u ) denote the outdegree of u  X  V on G i and d in i ( u ) denote its indegree. Also let D i diagonal matrix of the outdegrees of V i . Let  X  i ( s,t ) denote the personalized PageRank from s to t on G i . Let n = | V | denote the number of vertices and m = | E 0 | denote the number of edges in the initial graph G 0 . We will analyze the following two edge arrival models:
To introduce this graph model in our notation, consider a uniformly random edge permutation of E k . Then G 0 is the subgraph consisting of the first m edges in the permutation. And e i is defined as the ( m + i )-th edge in this permuta-tion, for i = 1 ,...,k . In a uniformly random edge stream, the personalized PageRank vector does not change by  X  X oo much X  after an edge update [5]. This intuition is not true in the worst case  X  there exists a sequence of edge insertions such that for a single source node, the aggregate l 1 difference between the personalized PageRank vector before and after every edge insertion grows superlinear in the number of of nodes [14].

For undirected graph, we observe a few interesting prop-erties for personalized PageRank, which will be used later. The first one exploits the fact that on an undirected graph, a random walk can be in either direction.
 Proposition 1 (cf. Lemma 1 in Lofgren et al. [16]). Let G be an undirected graph. Let s and t be two vertices of G . Then  X  ( s,t )  X  d ( s ) =  X  ( t,s )  X  d ( t ) . Here we dropped the superscript on d since there is no di-rection for undireced edges.

Proposition 2. Let G = ( V,E ) be an undirected graph and let t be a vertex of V , then P x  X  V  X  ( x,t ) /d ( t )  X  1 . Proof. Note that, where we used Proposition 1.
The random walk interpretation of personalized PageR-ank leads to the following general class of local computa-tion algorithms: start with all the probability mass on the source node of the graph, and iteratively push this mass out to neighboring nodes, getting progressively better ap-proximations. In these  X  X ocal push X  algorithms, we typically maintain a  X  X esidual X  at every node, which is mass that has been received but not yet been pushed out from that node, as well as an  X  X stimate X , which is mass that has been both received and pushed out (after accounting for the teleport probability and the outdegrees), we will now precisely de-scribe how this local approach can be used in the forward and reverse direction.
Given a source node s , the forward push algorithm main-tains an estimate ~ P ( s,t ) of  X  ( s,t ) for each target t  X  V . It also maintains a residual ~ R ( s,t ) for t . Let ~ residuals. The estimates and residuals satisfy the following invariant property (cf. Section 3 in Lofgren [2]): Algorithm 1 described below is a variant of the classic for-ward local push algorithm [2], the difference being that we added negative residuals. As we will see later on, an edge arrival can result in negative residuals  X  the edge update affects the amount of residuals a vertex have pushed out. During a forward push iteration for vertex u (Step 6 in Al-gorithm 1), an  X  fraction of u  X  X  residual will be added to u  X  X  estimate. For the rest of (1  X   X  ) fraction, each out neighbor of u receives an equal proportion of (1  X   X  ) /d out ( u ). Al-gorithm 1 repeatedly perform forward push iterations, first for vertices with positive residuals and then for vertices with negative residuals, until for every vertex, its residual divided by the outdegree is within  X   X  and  X  . It X  X  clear that while we work on vertices with negative residuals, no vertices whose residual is positive and below  X  will increase above  X  .
Given a target node t , the reverse push algorithm main-tains an estimate It also maitains a residual Algorithm 1 ForwardLocalPush denote the vector of estimates and vector of residuals. Similar to forward push, estimates and residuals satisfy an invariant property [1, 18]: In Algorithm 2 below, we X  X e also added negative residuals. A reverse push iteration on vertex u works backward (step 6): an  X  fraction of u  X  X  residuals goes to u  X  X  estimate; to push back the other 1  X   X  fraction to an in neighbor v of u , it takes into account the outdegree of v , hence the amount is the residual amount times (1  X   X  ) /d out ( v ). Algorithm 2 keeps pushing residuals back from each vertex, until the residual of every vertex is within  X   X  and  X  . When this happens, it is guaranteed that |  X  ( s,t )  X  P ( s,t ) |  X   X  (cf. Theorem 1 in Anderson et al. [1]).
 Algorithm 2 ReverseLocalPush
Given a node, we can run push algorithms to initialize its data structures that include the estimates and residuals. If an edge is inserted/deleted, we can obtain a new pair of estimates and residuals, by adjusting them locally at the updated edge using the invariant equations. Since this ad-justment can create residuals that gets above  X  or below  X   X  , we then invoke Algorithm 1 (or Algorithm 2) to push residu-als from such nodes. While the idea is simple, the analysis of the number of push iterations is quite intricate. For the rest of this section, we describe an approach to obtain dynamic local push algorithms and show how to analyze their running time. We will introduce a dynamic reverse push algorithm in the first part. Then we will introduce a dynamic forward push algorithm in the second part. Finally we will consider how to extend the algorithms to handle node arrivals and other issues.
Let t be a (target) vertex of G . Let  X  be a parameter between 0 and 1. Our goal is to maintain a pair of esti-mates and residuals, denoted by k
R ( t ) k  X   X   X  . As mentioned in Section 2.2.2, this will ensure that | with an equivalent formulation of Equation 3.

Lemma 3. Equation (3) implies and vice versa.

Proof. Let ~ X  t =  X  (  X  ,t ) denote the vector with person-alized PageRank from every node of G to t . Let  X  = ( I  X  (1  X   X  ) D  X  1 A ) / X  . It follows from the work of Haveli-that the ( s,t )-th entry of  X   X  1 is equal to  X  ( s,t ), since the s -th entry of ~ X  t is  X  ( s,t ), Now, we can write Equation (3) in vector form:
Hence it follows if one can maintain the equivalent invari-ant in Lemma 3, then one obtains a feasible pair of estimates and residuals for the updated graph. And the question be-comes how to maintain the invariant between the estimate and the residual vectors. We will only do it for edge in-sertions, and it X  X  not hard to work out the details for edge deletions using the same approach. Suppose that an edge u  X  v is inserted into G . Then the only vertex that doesn X  X  satisfy the invariant in Lemma 3 is u . In this case, it suf-fices to update b ecause the only variable that has been changed is u  X  X  out-degree. The precise formula is obtained by calculating u  X  X  correct new residual minus its old residual amount. To sim-plify the expression below, we take out a common factor of 1 / X  , which comes from dividing the  X  multiplier of as in Lemma 3: Hence the insertion procedure in Algorithm 3 described be-low correctly generates a pair of estimates and residuals for the updated graph. Similarly for deletions. It is worth men-tioning that we haven X  X  described how to handle nodes whose indegree is zero (also known as dangling nodes): since they do not have in neighbors, their residuals cannot be pushed out. We put off this issue until Section 3.3. Another issue is, if one works with undirected graphs, one needs to apply the insert/delete procedure for both direction of an edge. A lgorithm 3 UpdateReversePush
F or the rest of this section, our goal is presenting an anal-ysis of Algorithm 3. Based on previous work of Bahmani et al. [5], it is not difficult to observe that the updated amount of residuals from step 4 and 6) should be small in expec-tation in a random edge permutation model. However, one can observe that there are already a lot of nonzero residuals in
R ( t ). While these residuals have all been reduced below  X  , it gets unclear if they couple with the updated amount of residuals. Our intuition is to solve this problem with amor-tized analysis.

Theorem 4. Let  X  G i = ( V i ,E i )  X  be a sequence of k + 1 graphs such that each graph is obtained from the previous graph with one edge update. Let  X  d denote the average de-gree of G 0 . Let t be a random vertex of G 0 . Then the total running time of maintaining a reverse push solution ~ P ( t ) f or each graph G i such that | any s  X  V i , using Algorithm 2 and 3, is at most O ( k/ X  + k/ ( n X  X  2 )+  X  d/ (  X  X  )) for the following two dynamic graph mod-els:
Remark: the assumptions under the case of directed graphs is because our proof does not deal with issues of bounding the running time of handling dangling nodes, and this can happen a node of G 0 has no in neighbors, or when a new node arrives, thus creating a node without in neighbors.
We prove this theorem in three steps. First of all, we de-rive a bound on the running time of Algorithm 2. Secondly, we present a bound on the running time of Algorithm 3 and derive the total running time. Finally, we bound the total running time using properties of the graph model. Due to space limit, we only include the proofs for the case of undi-rected graphs, and refer the reader to the full version for proofs of the other case.

We start with the running time of Algorithm 2. Lemma 5 below is a Corollary of Theorem 2 in the work of Lofgren et al. [18], the difference being that we subtracted a part that corresponds to the total cost of pushing all the remaining residuals, since these residuals have not yet been pushed dynamic settings. Let and
Lemma 5. The running time of Algorithm 2 is at most:
Proof. To see this, note that every time a node pushes, its estimate increases by  X  X  , hence the total cost of Algo-rithm 2 is bounded by:
Now consider the i -th edge update, for i = 1 ,...,k . That is, we have had the updated graph G i , after updating G i  X  1 with e i = u i  X  v i . Then we run Algorithm 3 to update ~ P For simplicity, let  X  i ( t ) denote the updated amount of resid-uals for this edge update. That is, if we are inserting e from step 4 of Algorithm 3,  X  i ( u i ,v i ,t ) is defined to be 1 / X  times: and it could be similarly defined for deletion.

Lemma 6 is the heart of our amortized analysis. The key observation is that one can take care of the cost of an edge update, by comparing the amount of residuals that we pushed out, to the amount of new residuals that get cre-ated. Note that the difference between these two masses is precisely the amount of mass that has been received into the estimates. Another useful property of push algorithms is monotonicity: this property has played a crucial role in all the running time analysis of push algorithms. As long as we only push positive residuals or only negative residuals, then the estimates will only change in one way but not the other. This ensures that we could use estimates as a po-tential function to bound the number of push operations a vertex does.

Lemma 6. The running time of Algorithm 3 for updating ~ P
P roof. Let of that when we invoke Algorithm 2 to reduce the maximum residual of work on negative residuals. We bound the cost of the two phases separately.

We first bound the cost of pushing out positive residuals (step 1 and 2 in Algorithm 2). Let the estimate and residual vector after step 2. Since only positive residuals are pushed out, any s  X  V i . Hence the cost of this reverse local push is at most:
By Equation (3),
Similarly, Hence the difference is: Apply the above expression into Equation (7), we get: H ere we used ~  X  i ( x ) to simplify the above expression. Now we show that the above expression is at most: T o check this, we compare each vertex x  X  V i and their corresponding entries in the above expression. Since ~  X  is positive for every x  X  V i , if If
R 00 ( x, t ) &lt; 0, then we infer that x has not performed any push operation: otherwise Note that x only received positive residual updates during this phase of forward push. This shows 0. Therefore:
We then bound the cost of pushing out negative residuals (step 3 and 4 in Algorithm 2). Since only negative residuals are pushed out, same argument we used to derive Equation (7), the total cost of this reverse local push is at most: We claim that: To see this, we compare each vertex x  X  V i and their corre-sponding entries between Equation (8) and (9). If 0, then clearly: If
R i ( x, t ) &gt; 0, then we infer that x does not push out any negative residuals, otherwise This further implies that x may only receive negative residual updates during this phase. Therefore,
Finally, we obtain a bound on the total running time of invoking Algorithm 2 to reduce the maximum residual: We work on the above equation to finish the proof. First, since tex u i , we can separate out  X  i ( u i ,v i ,t ) from
A pplying the above equation into Equation (10), we found that
Then, since k A pplying the above equation into equation (11) gives us the desired conclusion.

Lemma 6 naturally suggests that there is a way to amor-tize per edge update costs, by cancelling out the weighted residual terms. Hence, by summing up the initialization cost in Lemma 5, and the edge update cost in Lemma 6, for i = 1 ,...,k , we obtained the total cost of maintaining the estimates and residuals for every graph G i , from i = 0 ,...,k :
Now we are ready to present an average case analysis, by summing up  X  ( t ) over all the target vertices. First, we know from the work of Lofgren et al. (Theorem 1, [18]) that: Therefore, the total running time of maintaining a pair of estimates and residuals with threshold  X  for every node t  X  V , starting from G 0 with m edges, during k edge updates, is at most: where we have changed the order of summation for the sec-ond and third term.
 Lemma 7. Let t be any vertex of V i . Then for any i = 1 ,...,k .

Proof. We deal with the sum of numerators of  X  i ( u i ,v first, since the denominator of  X  i ( u i ,v i ,t ) does not depend on t . We first take out each term from the absolute value to obtain an upper bound of  X  i ( u i ,v i ,t ): We used the fact that for v i ) and pression over t  X  V i , and take the denominator back to the expression, it leads to the following much simplified conclu-sion: Proof of Theorem 4, Part 1 : Note that Lemma 5 (initial-ization cost) holds for undirected graphs as well. When we update an edge, We need to take into account that we ap-plied insertion/deletion twice (step 4 and 6 in Algorithm 3), for each direction of the edge. This makes a difference when we separate out the difference between H ence, it suffices to add into the bound of Lemma 6: the rest of the proof holds for undirected graphs. In conclusion, we found that the total running time of maintaining
N ow we claim that with ~  X  i ( x ) = d i ( x ), for any x  X  V i = 0 ,...,k . By Proposition 1, Combined with Lemma 7, the second term of  X  is at most
It also follows that ~  X  i is equal to the degree vector of G only the degrees of u i and v i changed by one.
 To sum up,
Now we apply a similar approach to derive a dynamic forward push algorithm. Let s be a source vertex of G . Let  X  be a threshold parameter between 0 and 1. Our goal is to maintain a pair of estimates ~ P ( s ) and residuals su ch that ~ R ( s,t ) /d out ( t )  X   X  , for any t  X  V . We begin by describing an equivalent invariant property to Equation 2.
Lemma 8. Equation 2 implies ~
P ( s,t ) +  X   X  ~ R ( s,t ) = X and vice versa.

Proof. Let ~ X  s =  X  ( s,  X  ) denote a vector with person-alized PageRank from s to every node of G . Let  X  = Definition 1, and ~ X  s is equal to  X   X  ~e s . Therefore equation 2 in vector form is equivalent to: Now we use Lemma 8 to derive the update procedure. Consider when an edge u  X  v is inserted to G . Since the outdegree of u increases by 1, the invariant does not hold for the out neighbors of u any more: the reason being that every out neighbor receives an equal proportion of mass from u which is (1  X   X  ) divided by the outdegree of u times the amount of mass that u pushed. To solve this imbalance, out neighbor of u , except v . This is because we need to take into account the amount of residuals v should have received previously, had the edge u  X  v existed. Finally, since we have increased ~ P ( s,u ), this will break the invariant for u . Hence we will reduce ~ R ( s,u ) by the increased amount on ~ P ( s,u ), divided by  X  . See Algorithm 4 below for details. To work with an undirected graph, we will apply insert/delete twice, for both direction between u and v . It X  X  not hard to see this, following our discussion above.

Next we prove a theorem on the update cost of Algo-rithm 4. We will prove it on undirected graphs. It X  X  not clear to us how to analyze directed graphs with forward push: the difficulty being that there is no clean bound on the error of Algorithm 1, between the estimates and the true personal-ized PageRank value.
 Algorithm 4 UpdateForwardPush
Theorem 9. Let  X  G i = ( V i ,E i )  X  be a sequence of k + 1 undirected graphs, such that each graph is obtained from the previous graph by one edge update. Let s be a random vertex of V 0 . And let  X  be a parameter between 0 and 1 . Then the total running time of maintaining a forward local push solution ~ P i ( s ) for each graph G i such that | ~  X  ( s,t ) | /d i ( t )  X   X  , for any t  X  V i , using Algorithms 4 is at most O ( k/ (  X  2 ) + k/ ( n X  2  X  ) + 1 / (  X  X  )) .
As long as | ~ R i ( s,t ) | /d i ( t )  X   X  , for any t  X  V guarantee follows from the work of Anderson et al. and Lof-gren et al. [2, 15]. Hence, we will focus on analyzing running time. To derive this theorem, we divide the arguments into three parts: first, we present a bound on the initiation cost as well as the update cost per edge; secondly, we amortize the costs together, cancelling out the residual terms; finally, we use properties from undirected graphs to bound the to-tal cost. The proof can be found in the full version of this paper.
The algorithms presented in the previous sections do not handle dangling nodes. We consider how to take care of this situation. We also extend the algorithms to handle newly arrived nodes.
 There are two possible ways to handle dangling nodes. The first way is to create a separate sink node. Consider the case of doing reverse push (similarly for forward push). If a node u does not have any in neighbors and need to perform a push operation, then the amount of mass will be pushed to the sink node. These mass will stay at the sink node. Another way is to insert an edge from t to u , if t is the target node for maintaining reverse push solutions. Later on if an edge is added from v to u , so that u is not a dangling node anymore, then we first delete the edge from t to u and then insert an edge from v to u .

When a new node arrives, one can insert the edges one by one using the procedures in Algorithm 3 (line 3) and Algo-rithm 4 (line 3), and then invoke the local push algorithms to reduce the maximum absolute values of residuals. Similarly for node deletions. In this section, we evaluate our approach in experiments. We first compare our dynamic forward local push algorithm (Algorithm 4) to the previous work of Ohsaka et al. [20]. Our dynamic Forward Push algorithm differs from Ohsaka et. al. X  X  in an important way. When an edge ( u,v ) arrives, they propose to push the change in residual immediately to all of u  X  X  neighbors, requiring  X ( d ( u )) time, in addition to any pushes needed to restore the invariant. In contrast, we modify the estimate and residual values only at u and v , tak-ing only O (1) time, before performing any pushes needed to restore the invariant. We found that this simple optimiza-tion decreased the number of residual values updated and led to a 1.5 -3.5 times improvement in running time, with-out sacrificing accuracy.

We then make a comparison to the random walk approach of Bahmani et al. [5]. We consider the problem of identify-ing the top-K vertices that have the highest personalized PageRank from a source node, with random walks being commonly used to solve it on social networks [11, 19]. We found that the random walk algorithm uses 4.5 to 12 times as much storage compared to forward local push algorithm, and requires 1.5 to 2.5 times as much time to update as well, to achieve the same level of precision.
 Finally, we evaluate our dynamic reverse push algorithm. We compare against the baseline where we recompute the reverse push from scratch after every edge update. We found that our approach is 100x faster than this baseline.
We implement the experiments in Scala. We use an Ama-zon EC2 Ubuntu machine with 64GB of RAM and 16 pro-cessors of Intel(R) Xeon(R) CPU E5-2676 v3 @ 2.40GHz. We tested with three undirected social networks graphs, all downloaded from https://snap.stanford.edu/data/. The statistics are listed in Table 1 below. For each social net-work, we generate a uniformly random edge stream of the graph. Given a test vertex, we initialize its data struc-tures using the subgraph that consists of the first half of the edges in the random edge stream. After that, for each new edge arrival, we update its data structure depending the approach we are using. The teleport probability  X  is set to 0 . 2 in all the experiments. For ease of comparison, we use LazyFwdUpdate to refer to Algorithm 4 (because it  X  X azily X  avoids pushing from vertices that receive new edges), Ohsaka et al. X  X  Algorithm TrackingPPR and the random walk update Algorithm by RandomWalk . Table 1: Basic statistics of graphs that we experi-mented with.
We compare LazyFwdUpdate and TrackingPPR over 100 uniformly sampled source vertices from each graph. In our implementation, we first update the previous estimate vectors and residual vectors based on LazyFwdUpdate and TrackingPPR , respectively. We then invoke the same for-ward local push routine (Algorithm 1) to reduce any residual that is outside the desired threshold. At the end of the edge stream, we compare the performance of each algorithm, us-ing measurements described below:
For residual update, push iteraions and running time, we computed the average value over the 100 samples. For l error, we compute the median error over the 100 samples. The test results is shown in Table 2. We found that Track-ingPPR does more residual updates than LazyFwdUp-date , for all three graphs, and the improvement is more significant for denser graphs. While Algorithm 4 does more push operations than TrackingPPR , since the latter al-ready does a push operation before invoking Algorithm 1, the compound effect is that we achieved 1.5 to 5 times speed up, without sacrificing accuracy.
We compare LazyFwdUpdate and RandomWalk for the problem of finding top-K vertices ranked by their per-sonalized Pagerank from a source vertex. We sample 100 test vertices uniformly at random. For each test vertex, the correct top-K solution is the set of K vertices with highest personalized Pagerank from that vertex. The performance of each algorithm is measured by:
To allow for efficient update, it X  X  necessary to build an in-verted index for each vertex that quickly finds to the set of random walks crossing it. In our implementation we built a hashmap for this purpose, resulting in an additional fac-Table 2: Test results between LazyFwdUpdate with  X  = 7  X  10 graph, we sampled 100 vertices uniformly at random. 4 3 . 2  X  10 5 6 . 3  X  10 4 3 . 2  X  10 5 median accuracy of both algorithms are around 0.9 on LiveJournal. 5 5 . 0  X  10 5 1 . 5  X  10 5 5 . 0  X  10 5 median accuracy of both algorithms are around 0.9 on LiveJournal. nodes and compute the average running time for each algorithm. Table 3 and 4 below describe the results with K being 50 and 100, respectively. We take the average of running time and storage, and median of accuracy over the 100 sampled ver-tices. For the problem of identifying top-50 nodes, we found tor of 2 in the amount of storage used. Since there might be more efficient implementation, we do not take this additional factor into account in our comparison. that RandomWalk uses 4.5 to 12 times as much storage compared to LazyFwdUpdate , and uses 1.6 to 2.7 as much running time. On Orkut graph, when accuracy is controlled to be at the same level as RandomWalk for LazyFwdUp-date (with  X  = 4  X  10  X  5 ), the average amount of storage becomes 7 . 0  X  10 4 and the average running time becomes 33 . 3 s . When K is 100, the test results are qualitatively con-sistent with the above conclusion.
In this section we evaluate the performance of our dy-namic reverse push algorithm. We compare our proposed solution (Algorithm 3) to the baseline, where we recompute reverse push from scratch after every edge insertion using Al-gorithm 2. We sample 100 target vertices uniformly at ran-dom and take the average of the running time over these 100 samples. We have chosen the maximum residual parameter  X  = 10  X  4 so that at the end of the edge stream, the median l error over the 100 samples between the maintained reverse push estimates and the true values is less than 0 . 1. Because it takes too long to compute reverse push from scratch af-ter every edge insertion for 100 sampled vertices, we only computed reverse push from scratch for the first 1000 edge insertions. We take the average running time for performing reverse push during 1000 edge updates, and use this average value times the number of inserted edges as an approxima-tion to the true running time, if we have computed reverse push from scratch for every edge insertion. Figure 1 shows the experiment result on the LiveJournal graph. We found that our approach is 100x faster than the baseline. The ag-gregate running time for updating reverse push has a linear correlation with the number of edges added. This is consis-tent with the theoretical bound from Theorem 4.

Research supported by the DARPA GRAPHS program via grant FA9550-12-1-0411, and by NSF grant 1447697. [1] Reid Andersen, Christian Borgs, Jennifer Chayes, [2] Reid Andersen, Fan Chung, and Kevin Lang. Local [3] Konstantin Avrachenkov, Nelly Litvak, Danil [4] Lars Backstrom and Jure Leskovec. Supervised [5] Bahman Bahmani, Abdur Chowdhury, and Ashish [6] Shumeet Baluja, Rohan Seth, D Sivakumar, Yushi [7] Pavel Berkhin. Bookmark-coloring algorithm for [8] Soumen Chakrabarti. Dynamic personalized pagerank [9] D  X aniel Fogaras, Bal  X azs R  X acz, K  X aroly Csalog  X any, and [10] David F Gleich. Pagerank beyond the web. SIAM [11] Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh [12] Taher H Haveliwala. Topic-sensitive pagerank: A [13] Glen Jeh and Jennifer Widom. Scaling personalized [14] Peter Lofgren. On the complexity of the monte carlo [15] Peter Lofgren. Efficient algorithms for personalized [16] Peter Lofgren, Siddhartha Banerjee, and Ashish Goel. [17] Peter Lofgren, Siddhartha Banerjee, and Ashish Goel. [18] Peter A Lofgren, Siddhartha Banerjee, Ashish Goel, [19] Ioannis Mitliagkas, Michael Borokhovich, [20] Naoto Ohsaka, Takanori Maehara, and Ken-ichi [21] Lawrence Page, Sergey Brin, Rajeev Motwani, and [22] Jaewon Yang and Jure Leskovec. Defining and
