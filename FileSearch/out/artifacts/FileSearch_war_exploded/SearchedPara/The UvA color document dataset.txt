 Leon Todoran, Marcel Worring, Arnold W.M. Smeulders Abstract. Publications on color document image anal-ysis present results on small, nonpublicly available datasets. In this paper we propose a well-defined and groundtruthed color dataset consisting of over 1000 pages, with associated tools for evaluation. As we fo-cus on aspects specific to color documents, we leave out the document textual content in the ground truth. The color data groundtruthing and evaluation tools are based on a well-defined document model, complexity measures to assess the inherent difficulty of analyzing a page, and well-founded evaluation measures. Together they form a suitable basis for evaluating diverse applications in color document analysis. Both the dataset and the tools are available through our Web site. 1 1 Introduction Color now plays an important role in publishing every-thing from scientific journals, newspapers, and maga-zines to advertisements. The nature of documents in cur-rent document scanning applications is therefore rapidly shifting from simple black-and-white documents to com-plex color documents. Possible commercial applications of color document analysis are: analysis of advertise-ments, information retrieval from Internet pictures, color document compression, and reuse of information from color magazines.
 [4, 19, 24], color document compression [2], and color string localization [3, 5, 7, 15] have been developed. How-ever, whereas document analysis for black-and-white documents is mature, color document analysis is still in its infancy.
 field of black-and-white document analysis. Firstly, the existence of public domain datasets like the UW [11] and MTDB [17] has freed researchers from the labor-intensive task of creating datasets to work on. Secondly, the availability of standard evaluation tools for OCR and page segmentation [12, 18, 25] has allowed for knowledge exchange between different researchers.
 standardization has taken place. The MDTB dataset does contain some color pages. Their layout is, however, so simple that their structure is not essentially differ-ent from black-and-white documents. Also the ground truth does not include any color information. As a conse-quence, each developer now uses its own color dataset for evaluating tools. Typically the datasets used are small, as providing a ground truth for color documents is a time-consuming task. In this paper we report on the cre-ation of a large dataset with ground truth that could be a first step in standardizing the evaluation of color doc-ument analysis.
 truth describing the document components, their lay-out, and their logical structure. As we focus on aspects specific to color documents, we leave out the document textual content in the ground truth. In fact, we make the assumption that whenever a system can reliably decom-pose a document into its constituent components and their structure, existing OCR methods can extract the content from a text zone. Hence methods for this task are not essentially different from black-and-white methods. complexity, ranging from simple one-column pages with one picture to pages with several layers of document ob-jects with multiple overlapping pictures. It is important to be able to quantify the complexity of a document in the collection prior to evaluation. If the complexity of documents in a dataset is known and well defined, the complexity measures can be used to weight the evalu-ation results leading to evaluation independent of page difficulty [6].
 plexity. For instance, in [26] Zhong et al. define a com-plex document image as  X  X n image where the charac-ters cannot be segmented by simple thresholding, and the color, size, font, and orientation of the text are un-known. X  Chen defines complex images as  X  X hose in which text blocks are overlaid on images or graphics X  [3]. dent. A document can be simple for one task while being very difficult for another. Therefore, there is a need for a set of measures that collectively cover the whole docu-ment analysis process. Such a set of complexity measures would rank the data, but evaluation measures are needed to assess the algorithm X  X  performance on those data. The existing evaluation methods for layout analysis can be grouped into two main categories: text-based and region-based evaluation. Text-based evaluation [9] uses textual ground truth and the edit distance to measure the er-rors in layout detection. Region-based evaluation meth-ods [10 X 12,25] compare the outline of the detected zones with the zone description in the ground truth. As noted, we do not consider textual content. Thus, the region-based methods are best suited for evaluating document analysis algorithms. Furthermore, they can easily be ap-plied to text, pictures, and graphics. We do, however, need to extend these measures to color document anal-ysis.
 scribe the dataset and a model for its content. Section 3.4 makes precise the complexity of the documents with re-spect to the different tasks in color document analy-sis. For each of these tasks an appropriate evaluation measure is derived in Sect. 4. Finally, Sect. 5 discusses how the ground truth is generated and which tools have been implemented to support ground truth definition and evaluation. 2 Document dataset In this section we describe the documents that comprise the document dataset. We then define models to describe the content of each document. 2.1 Dataset content A dataset for the evaluation of color document analy-sis must cover different applications consisting of doc-ument pages of varying style and complexity. Further-more, in the documents considered color must be an es-sential component of the message the author wants to convey. Otherwise, the document is probably equivalent to a black-and-white document. We found that commer-cial color magazines form the most representative cate-gory of color documents. Even inside a single issue the document pages show a great variety in style, ranging from simple pages containing text only to highly com-plex color advertisements. Especially in the latter cat-egory of pages, the color is chosen carefully to attract the readers X  attention. A system tested well on such a dataset will perform well on most other applications. we have scanned full issues of internationally avail-able magazines: Cosmopolitan, Time, Newsweek, Na-tional Geographic, IEEE Spectrum, The New Yorker, and IEEE Computer. They are representatives of scien-tific magazines, informative magazines, lifestyle maga-zines, and weekly news magazines. The issues together form a dataset of more than 1000 scanned pages. Packard ScanJet Scanner. In order to reduce trans-parency noise, a black sheet of paper was placed on the back of the scanned page. The scanning resolution was 300 dpi with 24 bits of color information per pixel. In uncompressed TIFF format this requires a total space of 23.3 GB. We have also created a JPEG compressed version of the dataset. To that end we used a JPEG compression quality factor of 75%, which is the recom-mended ratio [22] for preserving image quality while pro-viding fair compression. In this format the dataset totals 1.1 GB.
 Web site. Access to this site is restricted to registered re-searchers. To use the images in publications, each author should individually seek permission from the magazines X  publication office. 2.2 The document model For defining the ground truth, which provides the basis for evaluation, a document model is needed that captures all essential information in the document.
 of the document: the layout information  X  encoding the presentation of the document  X  and the logical informa-tion  X  encoding the meaning of the document.
 objects in the document object set O : which hold the content of the document. Each docu-ment object is an entity in which the content has a uni-form style expressing some intention of the author. So, an element in O can, for example, be a single picture used as illustration, a text line in bold acting as a header, or a line in red used as a separator.
 object use different attributes to describe the content. As indicated earlier, the attributes should describe the con-tent appearance and meaning, but not the actual content like ASCII codes for a text. Therefore, layout attributes are restricted to the geometric and color properties of the document objects. Logical attributes are functional labels expressing the function of the document object in the document. The object sets O g and O l denote the set O with geometric and logical attributes added, respec-tively.
 an author adds structure to the set O . At creation time the author first defines the logical structure L of the document. In what order are the document entities to be read? Which figure and caption belong together? Only when this has been established the author starts placing the document objects on the page yielding the layout structure G . is often of a rather simple nature and document objects do not overlap. Tree-based representations have been in common use. For color documents the author can use lay-ers to organize content, where document objects within a layer do not overlap, but between layers they do. The layer assignment is not unique, and, furthermore, the au-thor can also move document objects forward or back-ward at will. Therefore, for analysis purposes, not the layers themselves should be encoded but the spatial re-lations between the document objects. Tree-based rep-resentations are too limited to describe such complex relations, hence a graph-based representation must be used.
 relations among document objects. A directed labeled multigraph is used to describe relations like overlap and inclusion. Thus the layout structure is given by a multi-graph where the vertices are the document objects O g and the edges R g denote a relation between the objects. The graph can be directed or undirected and can have weights to encode attributes of the edges. Thus, the lay-out structure is defined as follows: out) can span more than one page, we use, for simplic-ity, a page-based approach where every page receives a layout and logical structure. So a full document D is represented by: generic model defined above is instantiated to describe the ground truth for the dataset. 2.3 Geometric description For the geometric description of a document we con-sider three major different categories of document ob-jects, namely, text, image, and graphics.
 make a distinction between the perceived shape and the real shape of a document object. The real shape describes the boundary of the object in the document image. The perceived shape is the boundary of the object as per-ceived by a human. That is, in a layered document, the perceived shape of a partially obscured document object is the whole object, without missing parts or holes. An illustrative example can be seen in Fig. 1. In the follow-ing discussion, the object itself will be indicated as o , the perceived shape of the object as o , and the real shape of the object as  X  o . In a similar way  X  O , where O is a set of objects, denotes the set of real shapes of objects O . troduction that we focus on properties of the document that are specific to color documents. Therefore, we do consider color characteristics of textual document ob-jects but not font style or size. To be precise, to describe a geometric document object, the following attributes are used:  X  Geometric attributes;  X  Color attributes for text objects will be represented as a polygon. For later use, let us define notations for the following subsets of geometric document objects based on individual categories and one mixed class for pictorial information: T = { o  X  X  g | category ( o )= text } G = { o  X  X  g | category ( o )= graphics } I = { o  X  X  g | category ( o )= image } P = G  X  I and with respect to the shape of the document object: hand notations to indicate different classes based on the color of the text and the background on which it is placed. To that end, we use the generic notation T b f in-dicating a text object with foreground type f and back-ground type b . Choices for f and b are uniform (u), non-uniform (  X  u ), graphic (g), image (i), or arbitrary (), the latter indicating that the foreground or background can be any of the given types. As an example, T  X  u is the set of nonuniform text strings on an arbitrary background. ture induced by the layers in the document. From there one can also define the structure within a layer, but that is not considered here. Edges in the geometric structure graph are defined by the on-top relation, indicating that the object is in a higher layer. The relation is formally defined as: perceived shape of the two objects have a partial overlap and when one fully contains the other. To make the dis-tinction, we explicitly introduce the relation within , de-noted by  X  W , which indicates that the perceived shape of one object is fully contained within the area of the other: out structure relations, the first dealing with overlapping objects, the other with included objects: Finally, R g = R s g  X  X  w g .
 to define as many layers as desired, only adhering to all desired on-top relations. For a consistent definition of the ground truth a well-defined layer definition is required. tions R g as follows. In the graph R g all paths connect-ing document objects o  X  X  g are detected. Each layer is identified by an index. The layer with index zero, also called the  X  X aper layer, X  is the lowest in the layer hier-archy. A document object o  X  X  g is assigned to the layer with index z , where z is the maximum number of prede-cessors on any of the paths that reaches o in the graph. When a cycle exists in the graph of on-top relations, no consistent layer definition exists. We restrict ourselves to documents in which there are no cycles in the graph. the left X  can be easily defined later as the ground truth information already has all the required spatial informa-tion. 2.4 Logical description After an analysis of the magazines in the dataset, for each type of document object a set of possible represen-tative logical labels are selected. Object classes that do not appear frequently in the dataset receive the label  X  Other . X  Of course, they could be refined later. This leads to:  X  Logical attributes labels could be part of the logical structure of the doc-ument. As reading order is most important, we focus on this particular structure.
 resentative of page-based analysis. The reading order is based on the relation before in reading denoted by r . So the logical structure graph has as vertices the logi-cal document objects O l , and there is a directed edge between o 1 ,o 2  X  X  l whenever o 1 r o 2 . To be a proper reading order graph it should be acyclic. Then, a path in the graph is an independent reading order in the docu-ment. When there are multiple paths in the graph, they are related to groups of document objects that can be read in arbitrary order. So for the logical structure we have: 3 Document complexity The performance of an algorithm on a given dataset de-pends on two things: the quality of the algorithm itself and the complexity of the data. This complexity is task dependent. When the ground truth is available, the com-plexity can be computed beforehand. It can then be used to order the documents in the dataset so that one can choose a certain level of complexity for designing and testing the algorithm.
 first consider which steps are performed when doing color document analysis. 3.1 Document analysis steps We decompose color document analysis into four major steps. The first two deal with the geometric aspects of the documents; the third and fourth steps deal with the logical content of the document.  X  Page segmentation : determination of the set of geo-In this step the page is decomposed into text zones, im-age zones, and graphics zones. For the resulting objects the attributes are computed.  X  Layout detection : determination of the relation R g . This process yields the layered structure of the document captured in the relations between document objects.  X  Logical object classification : determination of the set Logical labels for each of the different categories of ob-jects are assigned to the document objects.  X  Reading order detection : determination of the rela-At this point in the process the vertices and edges of both the geometric and logical graphs are computed. derived:  X  C 1 : Complexity of page segmentation  X  C 2 : Complexity of layout detection  X  C 3 : Complexity of logical object classification  X  C 4 : Complexity of reading order detection page and can be computed from the ground truth graphs corresponding to the page. For a document, the complex-ity of each task is computed by averaging the complex-ities of individual pages. The different tasks and their complexity measures are illustrated in Fig. 2. 3.2 Document complexity for page segmentation In analyzing the difficulties of the page segmentation al-gorithms described in the literature [14, 16, 23], we iden-tify four main factors that influence the quality of the results. They are: 1. Nonuniformity in color : If the color of a text string 2. Shape irregularity : Most documents are based on 3. Picture/text ratio : Pictures contain a much wider 4. Amount of pictorial document objects containing document page containing only uniformly colored text objects and having rectangular shapes on a uniform background to have a complexity of zero. An example of a document page of maximum complexity is one con-taining an image in the background, completely covering the page, with text objects with nonuniform color and irregularly shaped boundaries placed on top of it. For each of the four factors we have designed a complexity measure.
 either not uniformly colored or have a nonuniform back-ground. Using the shorthand notations from Sect. 2.3: regular shapes: the geometric union of all the shapes corresponding to pictorial document objects, normalized by the width (w) and height (h) of the page: graphics and image objects containing text, denoted by P ct : ized to yield values in the range [0,1]. Note that we use the area of objects in a set instead of the cardinality of the set. This can be seen as a weighted mean value, where large objects contribute more to the complexity than small objects.
 segmentation is defined as a linear combination of the four complexity features defined above. Weights could be used to emphasize one of the four components. Here, we consider them equally important: 3.3 Document complexity for layout detection The problem of detecting multiple layers in color docu-ments has, to our knowledge, not been addressed. The DjVu system [2] could be seen as an exception; however, the system is restricted to one foreground and one back-ground layer, and, more importantly, the goal is com-pression, not analysis.
 based on the observation that we perceive a regularly shaped object as the full object even if it is partly oc-cluded. Clearly the larger the occlusion, the less appli-cable this observation. Therefore, to measure the com-plexity of the decision on whether two elements overlap, we consider the area of the intersection relative to the union of the two objects. Subsequently this is summed over all object pairs: ment has a complexity of zero when none of the objects in the document have an overlap. A document of maximum complexity (1.0), although not realistic, is a document consisting of two objects having a partial overlap almost equal to one of the object X  X  perceived shapes. 3.4 Document complexity for logical object classification In general, logical object classification is based on layout features, i.e., visual appearance, content, and possible a priori information about the document class. As in-dicated earlier, we do not consider document content. Furthermore, a priori information cannot be made part of the ground truth as it is user and application depen-dent. Therefore, for deriving a complexity measure we use visual appearance only.
 termined by the similarity in visual appearance within a logical class and the dissimilarity between different logi-cal classes. However, variability and separability depend on the geometric features used and on the classification method. As we want the complexity measure to be in-dependent of the specific method used, we focus on the number of different classes on the page that have to be distinguished. We do so separately for text, images, and graphics so that they can be weighted differently. labels for logical objects and let L i and L g be defined likewise for image labels and graphics labels. Further-more, let L denote the set of labels actually present on the page. Then the complexity measure for logical label-ing is given as: pages. The most complex ones ( C 3 = 1) are documents with all classes of text, image, and graphics appearing at least once in the document. 3.5 Document complexity for reading order detection In analyzing existing methods for reading order detec-tion [20, 21], it is observed that methods work well if document objects are nicely ordered, e.g., in a column. Performance degrades if the reading order  X  X umps X  from one object to another in an irregular way. To that end we derive a complexity measure that measures the irreg-ularity of the reading path when visiting the different text objects in the document.
 before in reading order relation r . Each maximal path in the graph with edges defined through the before in reading relation gives an independent reading path. Thus we can write the relation R l as { r o ,r 1 ,... } , where each is such a maximal path in the graph.
 First, note that we cannot rely on the first and last word of the block as we aim at measures that are independent of the content. Therefore, we consider the polyline with vertices p j for j =1 ,m ( i ) that results if one connects the centers of gravity of the subsequent document objects in r . For analysis of reading order, based on geometric in-formation, the simplest assumption one can make is that for finding p j +1 from p j one continues in the direction of the vector from p j  X  1 to p j . If this is the case we assign a complexity of zero. In general cases, the point is found in a different direction. Therefore, we define the turning angle  X  j at p j as the angle between the expected direc-tion and the actual direction in which p j +1 can be found. Locally the complexity is maximal if one has to search in exactly the opposite direction that one came from. The turning angle can be computed using the inner product as: last point on the path.
 computed. Normalizing to [0,1], the complexity measure for reading order detection is given by: containing two elements. As in such cases deriving the reading order is mostly trivial, we assign C 4 = 0 in such cases. 3.6 Document statistics For the four complexity measures, examples of increasing complexity are presented in Figs. 3 X 6. 3 uments in the dataset, Table 1 gives the four complexity values averaged over all documents in the UvA dataset. of layers per page. Thus, in the UvA dataset 61% of the pages have two layers, 10% have three layers and 1.5% have four layers. The remaining 27% are  X  X imple X  pages with only one layer. 4 Evaluation measures Complexity measures give an indication of the expected difficulty of a task based on the data prior to the use of an algorithm. Evaluation measures are needed to compare different algorithms performing the task. 4.1 Precision and recall Using the graph-based document model, evaluation mea-sures can be posed as a graph matching problem between a ground truth graph and the detected graph.
 tasks leads to an important simplification as in each step either vertices or edges are used.
 rithm should be evaluated. First, is the result correct  X  are these indeed elements the system was supposed to find? Second, is the result complete  X  have any elements been missed? retrieval [1] to be indicators of these two often conflicting factors. They are used explicitly [8] or implicitly [10, 11] in the evaluation of document analysis tasks. Let us first consider the general definition. Let S be a set of ground truth elements and S be the result of any task aiming at deriving the ground truth elements. Then precision and recall are given by: range [0,1]. Maximum precision is achieved when all the elements in the detected set are indeed part of the ground truth set. Or, in other words, there are no false alarms detected. The maximum value for recall is reached when all the elements in the ground truth set are also present in the detected set, i.e., no false negatives. regions in the image, the same definitions can be used by using the area of the regions instead of counting the number of elements in a set.
 and recall measures, we can derive the following sets:  X  Correct = S  X  S  X  Misdetection = S \ S  X  False alarm = S \ S made specific for the evaluation of the different tasks. 4.2 Page segmentation For the evaluation of page segmentation we are faced with the problem that there is no one-to-one correspon-dence defined between the areas found by the algorithm and the areas given in the ground truth. The same prob-lem was encountered in the evaluation of segmentation of a page into text lines by Liang et al. [10, 11]. We base our measures on the method proposed in [10, 11] and extended by Mao and Kanungo in [12]. It is straightfor-ward to use the definitions for the more general objects we consider.
 objects are given by O g . Let the result of the page seg-mentation be given by O g . To find the likelihood of a match between elements in the two sets, we consider the pairwise precision and recall between the object with in-dex i in O g and the object with index j in O g as follows: pairs, Liang et al. introduced six categories to measure the quality of detection. The first three are similar to those we encountered, but the imprecision of the match between two objects is taken into account.
 define the approximate intersection X  X   X  Y , which gives the pairwise area intersection of all elements for which r 1  X  1 and p  X  Misdetection if for all j : r ij 1  X  0.  X  False alarm if for all i : p ij 1  X  0.
 gory of error:  X  Split if for all j : r ij 1 &lt; 1 and N j =1 r ij 1  X  1.  X  Merge if for all j : p ij 1 &lt; 1 for all i and M i =1  X  Spurious for any other detection.
 olds T l and T h to judge whether values are close to 0 or 1, respectively. The actual values for these two thresh-olds were selected by analyzing the p ij 1 and r ij 1 matrices, for seven randomly selected pages from each of the mag-azines in the dataset, groundtruthed twice. We found T h =0 . 80 and T l =0 . 05 to be the appropriate threshold values for the UvA dataset.
 formation. The definitions of global precision and recall for a page are: match between O and O defined by the pairs of elements in the two sets for which r ij 1  X  1 and p ij 1  X  1. The objects in the matched graphs will be denoted by  X  O and  X  O , respectively. Likewise, relations between those objects in the result and the ground truth are indicated by  X  R g and  X  R g . Further evaluation is restricted to those two object sets and relations to assure that errors made in the page segmentation do not propagate into further evaluation. Note, however, that in some cases it might be better to apply subsequent steps of the algorithm to the ground truth data from the previous step. 4.3 Evaluation of layout detection In the layout detection for color documents, what needs to be evaluated is whether the geometric relations be-tween document objects are found correctly. In our case this corresponds to evaluating whether the edges corre-sponding to pairs in the overlap relation R g are correct. following precision and recall measures for step 2 of the analysis process: 4.4 Evaluation of logical object classification To evaluate the classification of objects into logical classes, we must find the objects in both the ground truth and the results with a specific label. Respectively we define:  X 
O  X  O jects in the result and the ground truth according to the labels: well-known confusion matrix for classification. need to identify the set of objects M that were classi-fied correctly, i.e., all elements in m ii . This leads to the following overall measures: those elements that were matched previously. Hence, the two object sets have the same cardinality. 4.5 Evaluation of reading order detection Evaluation of the final step in the analysis is similar to the layout detection as both are directly computed from the match between the edges of the graph. Again to avoid error propagation, only those elements that received the correct label in the previous step are considered when matching the edges in the logical graph. Following the same notation conventions as earlier the relations be-tween those objects in the result and the ground truth are indicated by  X  R l and  X  R l , respectively. 5 Implementation Groundtruthing a complex color document is a difficult task first because of the many relations between the different objects, and second because some subjective choices have to be made. We have therefore defined a set of rules the groundtruther has to obey.
 will always be a variation between different evaluators as the boundary of an object has to be indicated manually. 5.1 Guidelines for ground truth creation As there are many geometric relations between docu-ment objects, it is more convenient to use layers to de-fine the geometric structure. Later in the process the relations defining the geometric structure can be derived easily from the layer-based definition.
  X  Rule g1: Put overlapping objects in different layers.  X  Rule g2: Put objects having different background in  X  Rule g3: If objects do overlap, specify that the top to start with all objects that are fully visible, i.e., their perceived shape is the same as their real shape. These form the top layer. From there continue downwards.  X  Rule g4: Prefer regular shapes over polygonal shapes,  X  Rule g5: Specify the  X  X ackground color X  for textual  X  Rule g6: Mark tables as a whole, not as independent  X  Rule l1: Assign logical labels based on visual appear- X  Rule l2: If two zones have a different background,  X  Rule l3: Link objects in one reading order iff they are 5.2 Variability To measure the inherent variability in the ground truth definition, we perform a variability test. From each mag-azine we select 4 document pages for each of the four complexity classes, thus 16 document pages in total. For each complexity class, we select randomly docu-ment pages of lowest, highest, and two other intermedi-ary complexities, respectively. They are groundtruthed 4 times in total by two different evaluators.
 uation runs are evaluated in pairs, each of them playing the role of ground truth and result, respectively. We use the same evaluation measures as before for each step to compute the variability.
 averaged to obtain the variability measure. This is ex-pressed as average value.
 ground truth specification.
 carefully the guidelines for ground truth specification, there should be no variation between their ground truth definitions. As shown in Table 3, the variability error is quite small. As expected, the largest variability errors are reported for document object specification  X  p 1 /r 1 This is due to human imprecision in specification of the document objects X  boundaries. The smallest variability is reported for reading order specification  X  p 4 /r 4 .For several human observers it is far easier to indicate the correct reading order consistently than to click on the same boundary points.
 UvA-CDD is reproducible up to 97 X 99% depending on the task. 5.3 GT-UvA  X  The ground truth editor Following the guidelines defined in Sect. 5.1, the ground truth is manually generated for every page in the UvA-CDD dataset using the GT-UvA ground truth editor software.
 are groundtruthed by a student, then they are checked by the author. The author corrects wrongly assigned la-bels or features and reshapes the contours of document objects in case of visually estimated significant error. alC++ using MFC and Visual SDK [13] classes. The user interface allows the user to draw a rectangular, cir-cular, elliptical, or polygonal shape around the document objects. The layout and logical descriptions are then in-troduced via a property dialog box.
 or in XML format. Figure 8 shows the document type definition for the UvA color document dataset, where all the possible document objects are defined. For visualiza-tion of the geometric and logical descriptions, we store the ground truth in SVG format. A screenshot of the application is shown in Fig. 7. 5.4 Eval  X  The evaluation toolkit The evaluation measures described in Sect. 4 are imple-mented as a program in C, called Eval , to be run in batch mode. Eval has two operating modes: page evaluation and dataset evaluation. In page evaluation mode, Eval takes as arguments two text files, one containing the ground truth information, the other the result descrip-tion of a document page. In dataset evaluation mode, the input argument is the directory where the dataset is located. For this case, evaluation is performed for each individual page. Statistics are generated at the end for the entire dataset.
 6 Conclusion To advance the field of color document analysis a well-defined dataset is essential. We have created the UvA color document dataset consisting of over 1000 document pages, groundtruthed at the geometric and logical levels. model is proposed. Based on the model, the process of document analysis has been decomposed into four steps dealing with the vertices or edges of either the geometric graph or the logical graph describing the document. simple to complicated structures, we have defined four complexity measures that rank the document complexity for each of the four steps independent of the algorithm used for analysis.
 defined. All of the measures are derived from the general evaluation measures precision and recall. The complex-ity and the evaluation measures are scale independent. They are also independent of the textual content of the document.
 ground truth in UvA-CDD is valuable up to 97 X 99% de-pending on task reproducibility.
 able on a restricted basis to the research community via a special Web site.
 References
