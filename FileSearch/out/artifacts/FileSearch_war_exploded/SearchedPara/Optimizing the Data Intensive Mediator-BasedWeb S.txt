 Currently, effective communication within and among organizations, depart-ments, agents in different locations is critical to their success. Government orga-nization requires an integrated enterpri ze system, which can provide the latest, unified spatial information to its own employees and customers as well. Various mediator systems have been used to provide a unified query interface to various data sources, however, t hey only accept a specific user query and answer such query by reformulating it into a combinati on of source queries. Web services tech-nology [1] has been used extensively in d istributed environment. They provide seamless integration of information from various data sources. Mediator-based approaches support the automatically comp osition of web services. According to these methods, the existing web servi ces can be viewed as data sources, which can compose new web services automati cally. The mediator can optimize a plan by adding sensing operations for further optimization. However, in a data in-tensive environment, most of these optimization techniques are not effective. In this paper, we address the overhead that web services bring, and the necessity to reduce the cost of spatial join of mediato r based web service composition in data intensive environment, which is a very expensive operation in communication processing. We propose histogram based cost model for the plan optimization. Some commercial web services involve complex transactions and fully automatic web service composition may not be possible. However, it is possible to fully au-tomate the composition of the large class of information-producing web services. In this paper, we build on existing mediator-based approaches to support the automatic composition of web services. The extension from the traditional me-diator approach is proposed to the Inverse Rules Query reformulation algorithm that produces a generalized service com position in response to a user request. Instead of generating a plan limited to th e specific user request, their system produces an integrated web services th at can answer a range of requests. In a sense, their system produces a universal integration plan. However, in a data intensive environment, this system might not perform as shown in the previ-ous work before, because there is more communication cost and web services overhead involved. Therefore, we propose new optimization techniques later in the paper. These techniques are developed from the cost model in that assumes the data consists of uniformly distributed rectangles and estimates the I/O and CPU costs of both filtering and the refinement steps of a window query. In the next section, we will firstly go through come key components of mediator-based system. Mediator service is a key component of the mediator based web services compo-sition system. It consists of three main pa rts: (1) Query Reformulation (QR); (2) Query Optimization (QO); (3) Composit e Web Services (CWS). Query Refor-mulation is to deal with the mapping between global schema and local schema, which accepts user X  X  selected service in t he data log notation f ormat. Here, we as-sume the services system provides all conj unctive queries. System administrator can set up several global schemas facing to users. Along with the global schema, the descriptions of the available web services are also supplied for specifying the relationship between the relations in the mediated schema and those in the lo-cal schemas. The Local-As-View model is used to describe the relationship. To answer queries using views, [2] Mediato r utilizes the Inverse Rules Algorithm to generate a datalog program for the new web services based on the descriptions of relationships between global schema and local schema. CWS calls the web services according to the plan which is produced from last module QO. After all the called web services return their res ults back, CWS combines them and pass to presentation services. We propose a new cost model based query optimization strategy which is suitable to the data intensive environment and can reduce the communication cost and web services overhead involved. This new optimization technique is described as follows. For a certain query, after proce ssed, there are possibly four plans for it. We establish a cost model to measure th e spatial join cost and compare them for choosing the best. The cost model assumes that the query window and the data objects are general polygons. There are two situations we need to cope with: Direct Join and MBR Join. The former sends objects directly. While the later sends objects followed by MBRs. We estimate those two approaches with total I/O and CPU costs in the followings. The parameters related to side B have single quotes to separate from A X  X . We will describe two models, Direct Join Cost Model and MBR Join Cost Model, for these two cases in detail in the subsection 4.1 and 4.2. 4.1 Direct Join Cost Model To estimate the cost of retrieving obj ects which are indexed by R-tree within a query window in side A, we need to know the number of tuples locating in the query window, F (window). Assuming that a good R-tree implies the tuples retrieved will be in the minimum number of R-tree leaf nodes. The total I/O cost of this step is given by: where h is the height of the R-tree and Crandio is the cost per page of a random read. The CPU cost can be estimated by where C MBRtest is the CPU cost of per test between two MBRs. It tests all the entries in each R-tree noted read from the disk for overlapping with the query window. After being identified within the query window, the objects need to be transferred to the other side B. The comm unication cost occurs in this step can be estimated since we know the number of candidates to be transferred. Thus, the communication cost of sending polygons is given as: where Ctrans is the cost of sending per spatial point. C (window) is the average number of vertex in the query window. After the candidates arriving side B, we firstly retrieve the data in B, and do the join operation. The I/O cost is given as similar reason: The CPU cost depends on the algorithm used for testing overlap. Detecting if two polygons overlap can be done in O (n log n) using a plane sweep algorithm, where n is the total number of vertices in both polygons. We estimate the cost assuming using plane sweep algorithm. We assume that average number of vertices within a query window is C X  (window), C polytest is proportionality constant. The spatial join CPU cost is estimated as follows: 4.2 MBR Join Cost Model In the MBR join cost model, the total IO cost and CPU cost can be estimated according to the same equations as that in direct join. But different from direct join cost model, in this process, we n eed to estimate the communication cost of sending MBR, while not need that of sending polygons. The communication cost for sending MBR is given as follows: where Ctrans is the cost of sending per spatial point. C (window) is the number of vertex in the query window. Different from the direct join, for MBR join, after the candidates arrive side B, the candidates considered are MBRs, while not simple data. The data in B are retrieved, and used for the join operation. The I/O cost is estimated by a similar equation as that for direct join: The CPU cost can be estimated in the same way as direct join.
 After the spatial join of objects X  MBR, the number of candidates produced from this step is needed, which can be obtained by using the histogram and overlap-ping probability model. The first cost from this is the I/O cost which occurs of retrieving candidates after A knows which candidates need to be transferred to B. Here, the cost for sending object id can be neglected, since it is too small comparing to spatial operation. The I/O cost for this step can be estimated by the following way: where F p is the number of candidates we estimated before, and Cvertio is the per vertex I/O cost of reading a polygon. The communication cost of sending those candidates back to side B is given as below: The CPU cost involved in dataset A of polygons spatial join is given as: F p  X  ( C ( window )+ C ( window )) log( C ( window )+ C ( window ))  X  C polytest So far, we present all components of the cos t model to estimate spatial join. There C get these parameters, some are provided by the system implementer at system development or installation time. The other can be estimated by histogram [3]. In this part, we will study the performance of our proposed web service optimiza-tion strategy by extensive experiments. In our experiment, two datasets are used for the performance evaluation. One is the Queensland Regional Ecosystem layer from Environmental Prot ection Agency (EPA) in Queensland, Australia. Experi-ments were conducted on two Pentium 2.2GHz machines with 256 Mbytes of Ram running Microsoft Windows XP. Please refer the detail to the full technical report. 5.1 Web Services Overhead Effects In this part, we experimentally evaluate the performance of using web services based on three different scenarios of local spatial join, traditional distributed spatial join and using web services in distributed join. For local spatial join, the data are not needed to be moved around, thus this process is costless. For the rest of two scenarios, the candidates are transferred from one PC to the other, which involves great communicati on costs. The difference between these two is that web services technology overhead cost occurred in web services based distributed join. We input four different groups, 0.001, 0.05, 0.01 and 0.1, from different areas of query windows to our system. This process was conducted 100 times, producing the means of this 100 times queries X  results. Figure 1 shows query results X  comparison from one group window. Averagely, using web services can increases the processing time by 13.099%. 5.2 Efficiency of Query Optimization In this part, we demonstrate the efficiency of the query optimization strategy by using cost model and self-tuned histogram. In the experiment, we input a number of queries, testing which plan it chooses and the execution time. For each query, four plans run separately an d the execution time of each is recorded. The information recorded is shown in F igure 2. Execution Plan column is the plan chosen by system. Other four plan columns X  fields are the exact execution time (second). Figure 3 shows the effect a ccuracy of query opt imization over 500 queries. The error rate is calculated as the number of wrong decision divided by the number of queries. As expected, s ystem becomes more a nd more accurate as the error rate keeps going down. Thus, we can make the conclusion that the query optimization is able to i ncrease system X  X  performance.
 In this paper, we evaluated the current web services technology used to support dynamical composite services over the I nternet, showing that the requirement and performance of web services in data intensive situation. For the purpose of reducing the cost of spatial join, we proposed a new cost model based query opti-mization strategy. The proposed strate gy can effectively reduce the communica-tion cost and web services overhead invo lved in the data intensive environment. We proposed two cost models: Direct Join cost model and MBR Join cost model, for estimating the cost of direct join and MBR join respectively. We performed experimental study over two types of datasets. The experimental results show that the optimization strategy propose d can greatly improve the query efficiency of web service system.

