 Efforts in parameter tuning algorithms for SMT, such as M ERT (Och, 2003; Galley et al., 2013), M IRA (Watanabe et al., 2007; Chiang et al., 2009; Cherry and Foster, 2012; Chiang, 2012), and P
RO (Hopkins and May, 2011) have improved the translation quality considerably in the past decade. These tuning algorithms share the same characteristic that they treat the decoder as a black box. This decoding insensitiveness has two ef-fects: 1) the parameter tuning algorithm can be more general to choose the most effective decod-ing paradigm for different language pairs; 2) how-ever, it also means that the learned parameters may not fit the decoding algorithm well, so that promis-ing partial translations might be pruned out due to the beam search decoding.

Recent researches reveal that the parameter tun-ing algorithms tailored for specific decoding al-gorithms can be beneficial in general structured prediction problems (Huang et al., 2012), and in machine translation (Yu et al., 2013; Zhao et al., 2014; Liu and Huang, 2014). Particularly, Liu and Huang (2014) show that by requiring the conven-tional parameter tuning algorithms to consider the final decoding results (full translations) as well as the intermediate decoding states (partial transla-tions) at the same time, the inexact decoding can be significantly improved so that correct interme-diate partial translations are more likely to survive the beam. However, the underlying phrase-based decoding model suffers from limited distortion, and thus, may not be flexible enough for translat-ing language pairs that are syntactically different, which require long distance reordering.

In order to better handle long distance reorder-ing which beyonds the capability of phrase-based MT, we extend the search-aware tuning frame-work from phrase-based MT to syntax-based MT, in particular the hierarchical phrase-based transla-tion model (H IERO ) (Chiang, 2007).

One key advantage of search-aware tuning for previous phrase-based MT is the minimal change to existing parameter tuning algorithms, which is achieved by defining B LEU -like metrics for the intermediate decoding states with sequence-structured derivations. To keep our approach simple, we generalize these B LEU -like metrics to handle intermediate decoding states with tree-structured derivations in H IERO , which are cal-culated by dynamic programming algorithms in-spired by the inside-outside algorithm.

We make the following contributions: 1. We extend the framework of search-aware 2. We propose two B LEU metrics and their vari-3. Our method obtains significant improve-We first briefly describe the hierarchical phrase-based translation (Chiang, 2007), H IERO , by a Chinese-English translation example (Figure 1).
A H IERO decoder translates a source sentence by using a synchronous grammar (Figure 1 (a)) to parse it into a bilingual derivation tree, as shown in Figure 1 (b) and Figure 1 (c). An example rule of the synchronous grammar is where the left-hand-side is a non-terminal symbol, and the right-hand-side is a pair of source and tar-get strings, each of which consists a sequence of lexical terminals and non-terminals. Specifically, the same subscript on both sides denotes a one-to-one correspondence between their non-terminals. We use | r | to denote the arity of rule r , i.e., the number of non-terminals. Usually, the rule used in H IERO system has a maximum arity 2.

Let  X  x,y  X  be a Chinese-English sentence pair in tuning set, the H IERO decoder will generate a derivation tree for it (Figure 1 (b)), which can be defined recursively in a functional way: where d is a (partial) derivation, i.e., the (sub-) derivation tree. When r is a fully lexicalized rule ( | r | = 0 ), the decoder generates a tree node di-rectly (e.g., X [3 , 5] in Figure 1 (b)). If | r | &gt; 0 , a new (partial) derivation will be created by apply-ing r to its children nodes. In our notation, we denote this process as applying a function of rule r to its arguments. For example, node X [1 , 5] in Figure 1(b) is created by applying rule r 8 in Fig-ure 1(a), where the arguments are d 1 = X [1 , 2] and d
Practically, we organize the partial derivations based on spans in H IERO decoder, and use a beam B [ i,j ] to keep the k -best partial derivations for each span [ i,j ] : where D [ i,j ] is the set of all possible partial deriva-tions for span [ i,j ] , and top k w (  X  ) returns the top k ones according to the current model w . Figure 2 shows an example of the H IERO beam-search de-coding. As we discussed in Section 1, current tuning meth-ods for H IERO system (M ERT , M IRA , or P RO ) are mostly search-agnostic . They only consider the complete translations in final beam B [1 , | x | ] , but ig-nore the partial ones in the intermediate beams. However, because MT decoding is inexact (beam-search), many potentially promising derivations might be pruned before reaching the final beam (e.g., the partial derivation X [1 , 5] of Figure 1(b) is pruned in beam B [1 , 5] in Figure 2). Consequently, once we lose these good partial derivations in de-coding, it is hard to promote them by these search-agnostic tuning methods.

In order to address this problem, search-aware tuning (Liu and Huang, 2014) aims to promote not only the accurate complete translations in the final beam, but more importantly those promising par-tial derivations in non-final beams.
 In this section, we apply search-aware tuning to H
IERO system. Similar to the phrase-based one, the key challenge here is also the evaluation of par-tial derivations. Following (Liu and Huang, 2014), we design two different evaluation metrics, partial B
LEU and potential B LEU respectively for H IERO decoding. 3.1 Partial B LEU Given a partial derivation d of span [ i,j ] , partial B
LEU evaluates it by comparing its partial trans-lation e ( d ) directly with the (full) reference. We explore two different partial B LEU measures here: full partial B LEU and span partial B LEU .

Full partial B LEU is similar to the one used in (Liu and Huang, 2014), which compares e ( d ) with the full reference y and computes B LEU score us-ing an adjusted effective reference length propor-tional to the length of the source span [ i,j ] (i.e., Figure 2: An example of H IERO beam search decoding (beam size = 2). We can see the good derivation (Figure 1(b)) is pruned very early, while the bad derivation (Figure 1(c)) ranks first at the fi-nal beam. the number of translated source words). See (Liu and Huang, 2014) for more details.
 Span partial B LEU differs from full partial B
LEU by creating a span reference for span [ i,j ] to evaluate its partial derivations, rather than us-ing the full reference. We use word alignment to determine the span references of different spans. Specifically, we first add the tuning set into train-ing data, and then run GIZA++ to get the word alignment. For a pair of source and target span string of target span is used as the span reference the span reference of source span [1 , 5] is  X  X ived in Berlin before getting married X .

Partial B LEU is quite an intuitive choice for evaluating partial derivations. However, as Liu and Huang (2014) discussed, partial B LEU only evaluates the partial derivation itself without con-sidering any of its context information, leading to a performance degradation. Thus, in order to take the context information into account, we investi-gate a more reasonable metric, potential B LEU , in the next section. 3.2 Potential B LEU Potential B LEU evaluates the partial derivation d by assessing its potential , which is a complete translation generated from d , rather than e ( d ) as in partial B LEU . In phrase-based decoding, Liu and Huang (2014) introduce a future string f ( d ) to denote the translation of the untranslated part, and get the potential of d by concatenating e ( d ) and f ( d ) .

Different from their work, we define an outside string for d in H IERO system. Suppose a complete translation generated from d is  X  e ( d ) , it can be de-composed as follows: where  X  is an operator that concatenates strings monotonically,  X  ( d ) and  X  ( d ) are the left and right parts of  X  e ( d ) apart from e ( d ) , which we call left and right future strings of d . The pair of  X  ( d ) and  X  ( d ) is defined as the outside string of d : An example of the outside string is shown in Fig-ure 3. Assume we are evaluating the partial deriva-tion which translates Chinese word  X  X ian X  to En-glish word  X  X efore X , and get a complete transla-tion  X  X my lived in Berlin before getting married X  from it, then its outside string would be: Figure 3: Example of outside string when we use X  X my lived in Berlin before getting married X  as the potential for the partial derivation which trans-lates word  X  X ian X  to  X  X efore X .

Theoretically, different partial derivations of the same span could have different outside strings. To simplify the problem, we use the same outside string for all partial derivations of the same span. The outside string for span [ i,j ] is defined as:
For a specific partial derivation d of span [ i,j ] , by combining O ([ i,j ]) and e ( d ) , we can compute its potential B LEU against the reference. Appar-ently, different outside string will lead to different potential B LEU score. In the rest of this section, we will explore three different methods to gener-ate outside strings. 3.2.1 Concatenation In order to generate outside string, one simple and straightforward way is concatenation. For a spe-cific span [ i,j ] , we first get the best translation of its adjacent spans [0 ,i ] and [ j, | x | ] ( e ([0 ,i ]) and e ([ j, | x | ]) respectively). 3 Then for a partial deriva-tion d of span [ i,j ] , we generate the outside string of d by concatenation
Also take the example of Figure 3, if we per-form concatenation on it, the outside string of the corresponding partial derivation is: Obviously, this outside string is not good, since it does not consider the reordering between spans. In order to incorporate reordering into outside string, we propose a new top-down algorithm in the next subsection. 3.2.2 Top-Down Top-down method (Algorithm 1) is defined over the derivation tree, and takes the complete transla-tions in the final beam as the potential for comput-ing potential B LEU .

Suppose we have a partial derivation d = r ( d 1 ,d 2 ) as shown in Formula 1, and the target side string of rule r is: The corresponding (partial) translation e ( d ) of d could be generated by applying an r -based func-tion e r (  X  ) with d 1 and d 2 as the arguments: e ( d 1 ,d 2 ) = w 1  X  X  X  w p e ( d 1 ) w q  X  X  X  w m e ( d 2 ) w where e ( d 1 ) and e ( d 2 ) are the partial translations of d 1 and d 2 . We can further decompose e r ( d 1 ,d 2 ) based on e ( d 1 ) : w 1  X  X  X  w p | {z } where we call  X  d ( d 1 ) and  X  d ( d 1 ) the partial left and right future strings of d 1 under d . Similar Algorithm 1 Top-Down Outside String. to the outside cost of inside-outside algorithm, we compute the outside string  X   X  ( d 1 ) , X  ( d 1 )  X  for d based on the decomposition: Similarly, if we decompose e r ( d 1 ,d 2 ) based on e ( d 2 ) we have: w 1  X  X  X  w p e ( d 1 ) w q  X  X  X  w m | {z } and the outside string  X   X  ( d 2 ) , X  ( d 2 )  X  for d 2 is:
The top-down method works based on the above decompositions. For a complete translation in the final beam B [0 , | x | ] , the algorithm tracebacks on its derivation tree, and gets the outside string for all spans in the derivation. Taking the span [1 , 2] in Figure 1(b) as an example, if we do top-down, its outside string would be: where denotes the empty string. Compared to the concatenation method, top-down is able to consider the reordering between spans, and thus would be much better. However, since it bases on the k -best list in the final beam, it can only handle the spans appearing in the final k -best derivations. In our experiments, top-down algorithm only cov-rate more spans into search-aware tuning, we en-hance the top-down algorithm and propose guided backtrace algorithm in the next subsection. 3.2.3 Guided Backtrace The guided backtrace algorithm is a variation of top-down method. In guided backtrace, we first introduce a container s [ i,j ] to keep a best partial derivation for each split point of [ i,j ] during de-coding. 5 Hence, there will be at most j  X  i par-tial derivations in s [ i,j ] . 6 For instance, suppose the span is [2 , 5] , we will keep three partial derivations in s [ i,j ] for split point 2, 3, and 4 respectively. Dif-ferent from the similar k -best list in the decoding beam, s [ i,j ] introduces more diverse partial deriva-tions for backtracing, and thus could help to cover more spans.

After decoding, we employ algorithm 2 to do backtrace. The algorithm starts from the best translation in the final beam. At first, we get the corresponding span of the input partial derivation d (line 2), and the outside string for this span (line 5-6). We then sort the partial derivations in s [ i,j ] based on their potential Bleu +1 (line 12). Thus, the sorting will guide us to first backtrace the partial derivations with better potential Bleu +1 scores. Then we traverse all these partial deriva-tions (line 13-14), and do guided backtrace recur-sively on its child partial derivations (line 16-19). In this process, about 90% of all spans are visited in our experiments. We demand each span will only be visited once (line 3-4),
During the above process, guided backtrace will collect good partial derivations which have bet-ter potential Bleu +1 scores than the best Bleu +1 score MaxSenBleu of the final beam (line 10-11) into goodcands . Meanwhile, we also collect the good partial derivations from descendant nodes (line 19), and apply rule r to them to form good partial derivations for span [ i,j ] (line 20-21). At last, we add the top 50 good partial derivations to the beam B [ i,j ] for tuning (line 22).

The purpose of adding good partial derivations for tuning is to recover the good ones pruned out of the beam. For example, the partial derivation X [1 , 5] in Figure 1 has been pruned out of the beam B [1 , 5] in Figure 2. If we only consider the partial derivations in the beam, it is still hard to promote it. After adding good partial derivations, we will have more good targets to do better tuning.

From Algorithm 2, we can also get a new way to compute oracle B LEU score of a translation sys-tem. We memorize the string that has the maxi-mum potential Bleu +1 score of all strings (line 9). We then collect the best string of all source sen-Algorithm 2 Guided Backtrace Outside String. tences in the tuning or test set, and use them to compute B LEU score of the set. This can be seen as an approximation upper bound of the current model and decoder, which we call guided oracle . 3.3 Implementation The major process of search-aware tuning is sim-ilar to traditional tuning pipeline. We first decode the source sentence, and then output both the com-plete translations in the final beam and the partial derivations from the shorter spans as training in-stances. For potential B LEU , the outputs of par-tial derivations would be the corresponding com-plete translations generated by Equation (2). If we use partial B LEU , the outputs are the correspond-ing partial translations. Each span will serve as a single tuning instance. Different from (Liu and Huang, 2014), we only use the features from par-tial derivations for tuning.

For the spans that top-down or guided backtrace algorithm cannot get outside strings, we use con-catenation for them to maintain consistent number of tuning instances between different tuning iter-ations. However, since we do not want to spent much effort on them, we only use the one-best par-tial derivation for each of them. To evaluate our method, we conduct experiments on Chinese-to-English translation. The train-ing data includes 1.8M bilingual sentence pairs, with about 40M Chinese words and 48M English words. We generate symmetric word alignment using GIZA++ and the grow-diag-final-and strat-egy. We train a 4-gram language model on the Xinhua portion of English Gigaword corpus by SRILM toolkit (Stolcke, 2002). We use B LEU 4 with  X  X verage reference length X  to evaluate the translation performance for all experiments.
We use the NIST MT 2002 evaluation data (878 sentences) as the tuning set, and adopt NIST MT04 (1,789 sentences), MT05 (1,082 sentences), MT06 (616 sentences from new portion) and MT08 (691 sentences from new portion) data as the test set.

Our baseline system is an in-house hierarchical phrase-based system. The translation rules are ex-tracted with Moses toolkit (Koehn et al., 2007) by default settings. For the decoder, we set the beam size to 30, nbest list to 50, and 20 as the maximum length of spans for using non-glue rules.

The baseline tuning methods are batch tun-ing methods based on k -best translations, includ-ing M ERT (Och, 2003), M IRA (Cherry and Fos-ter, 2012) and P RO (Hopkins and May, 2011) from Moses. Another baseline tuning method is hypergraph-M ERT from cdec toolkit (Dyer et al., 2010). To guarantee the tuning efficiency, we con-strain the minimum length of spans for search-aware tuning to restrict the number of training in-stances. For the sentences with less than 20 words, we only use the spans longer than 0.75 times sen-tence length. For the ones with more than 20 results are achieved by averaging three indepen-dent runs for fair comparison (Clark et al., 2011). 4.1 Translation Results Table 1 compares the main results of our M ERT -based search-aware tuning with traditional tuning: M ERT and hypergraph-M ERT .
 From the results, we can see that hypergraph-M
ERT is better than M ERT by 0.5 B LEU points, verifying the result of (Kumar et al., 2009). For search-aware tuning, partial B LEU (both full and span one) only gets comparable results with base-line tuning method, confirming our previous anal-ysis in section 3.1, and the results are also consis-tent with (Liu and Huang, 2014). 30 for testing. Table 2: The oracle B LEU comparison between baseline M ERT and guided backtrace.

Compared to partial B LEU , potential B LEU is more helpful. Both concatenation and top-down method are better than M ERT on all five test sets. Guided backtrace gets the best performance over all methods. It outperforms traditional M ERT by 1.1 B LEU points on average, and better than hypergraph-M ERT by 0.6 B LEU points. 4.2 Analysis In this section, we analyze the results of search-aware tuning by comparing M ERT -based baseline and guided backtrace in detail.
 Oracle BLEU We first compare the oracle B LEU scores of baseline and guided backtrace in Table 2. In order to get the k -best oracle, we first look for the best Bleu +1 translation in the k -best list for each source sentence, and then use these best translations to compute the B LEU score of the entire set. To get the guided oracle, we use the weights from baseline M ERT to run Algorithm 2 on tuning set (nist02) and nist04 test set, and gen-erate the best oracle translation (section 3.2.3) for each source sentence for evaluation.
 The final oracle B LEU comparison is shown in Table 2. On both nist02 tuning set and nist04 test set, guided backtrace method gains at lease 1.0 Table 3: The diversity comparison based on k -best list in the final beam on both tuning set (nist02) and nist04 test set. The higher the value is, the more diverse the k -best list is.
 B
LEU points improvements over traditional M ERT on both k -best oracle and guided oracle. More-over, k -best and guided oracle get more improve-ments than 1 -best, indicating that by search-aware tuning, the decoder could generate a better k -best list, and has a higher upper bound.
 Diversity As shown in (Gimpel et al., 2013; Liu and Huang, 2014), diversity is important for MT tuning. An k -best list with higher diversity can better represent the entire decoding space, and thus tuning on it will lead to a better performance.
Similar as (Liu and Huang, 2014), our method encourages the diversity of partial translations in each beam, including the ones in the final beam. We use the metric in (Liu and Huang, 2014) to compare the diversity of traditional M ERT and guided backtrace. The metric is based on the n -gram matches between two sentences y and y 0 : where q = n  X  1 and  X  x  X  equals to 1 if x is true, 0 otherwise. The final diversity results are shown in Table 3. We can see guided backtrace gets a better diversity than traditional M ERT . Figure 4: The B LEU comparison between M ERT and guided backtrace on nist04 test set over differ-ent beam sizes.

Beam Size As we discussed before, search-aware tuning helps to accommodate search errors in decoding, and promotes good partial deriva-tions. Thus, we believe that even with a small beam, these good partial derivations can still sur-vive with search-aware tuning, resulting in a good translation quality. Figure 4 compares the results of different beam sizes (2 , 4 , 8 , 16 , 30) between traditional M ERT and guided backtrace. The com-parison shows that guided backtrace achieves bet-ter result than baseline M ERT , and when the beam is smaller, the improvement is bigger. More-over, guided backtrace method with a beam size 8 could achieve comparable B LEU score to tradi-tional M ERT with beam size 30.

Span Size For a big tuning set, in order to make the tuning tractable, we constrain the length of spans for search-aware tuning. Intuitively, towards search-aware tuning, more spans will get better re-sults because we have more training instances to guide the tuning process, and accommodate search errors in early decoding stage (shorter spans). To verify this intuition, we perform experiments on a small tuning set, which is generated by select-ing the sentences with less than 20 words from the original NIST MT 02 tuning set.
 Figure 5 compares the results of traditional M
ERT and guided backtrace over different mini-mum span length. The curve in the figure shows that by using more spans for search-aware tuning, we can achieve better translation performance. Figure 5: The B LEU comparison between M ERT and guided backtrace on nist04 test set over dif-ferent span sizes. L denotes the sentence length. The value of x -axis refers to the minimum length of spans used for search-aware tuning. More spans will be used in tuning with smaller minimum span length. 4.3 MIRA and PRO Results Table 4 and Table 5 shows the final results of M
IRA and P RO for traditional tuning and search-aware tuning using potential B LEU . We can see that potential B LEU is helpful for tuning. Guided backtrace is also the best one, which outperforms the baseline M IRA and P RO by 0.9 and 0.8 BLEU points on average. 4.4 Efficiency Table 6 shows the training time comparisons be-tween search-aware tuning and traditional tuning. From this Table, we can see that search-aware tun-training is due to three reasons.

Similar to (Liu and Huang, 2014), as search-aware tuning considers partial translations of spans besides the complete translations, it has much more training instances than traditional tun-ing. In our experiments, although we have con-strained the length of spans, we get a total of 38,539 instances for search-aware tuning, while it is 878 for traditional tuning.

Another time consuming factor is the compu-tation of Bleu +1 scores. In guided backtrace set-ting, we need to compute the Bleu +1 scores for all candidates of spans we consider. This is why the words) from nist02.
 Table 6: Comparison on training efficiency. The time (in minutes) is measured at the last iteration of tuning. Column  X  X otal X  refers to the time for an entire iteration, while  X  X ptim. X  is the time of op-timization. We use a parallelized M ERT for tuning by 24 cores. decoding of guided backtrace is much slower than baseline or top-down.

Finally, adding good candidates enlarges the k -best lists of training instances, which further slows down the tuning process of guided backtrace.
It should be noted that although search-aware tuning is slower than traditional tuning method, since the decoding is all the same for them in test-ing time, it does not slow down the testing speed. We have presented an extension of  X  X earch-aware tuning X  to accommodate search errors in hier-archical phrase-based decoding and promote the promising partial derivations so that they are more likely to survive in the inexact beam search. In order to handle the tree-structured derivations for H
IERO system, we generalize the B LEU metrics and propose corresponding partial B LEU and po-tential B LEU to evaluate partial derivations. Our approach can be used as a plugin for most popu-lar parameter tuning algorithms including M ERT , M
IRA and P RO . Extensive experiments confirmed substantial B LEU gains from our method. We thank the three anonymous reviewers for the valuable suggestions. This project was supported in part by DARPA FA8750-13-2-0041 (DEFT), NSF IIS-1449278, and a Google Faculty Research Award.

