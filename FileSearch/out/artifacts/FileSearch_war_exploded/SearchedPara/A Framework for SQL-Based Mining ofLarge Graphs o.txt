
Sriganesh Srihari 1 , Shruti Chandrashekar 2 , and Srinivasan Parthasarathy 3 Over the past few years data generated from real-world processes have increas-ingly attracted the attention of researchers from all domains. A lot of effort has gone into analyzing this data from different perspectives to extract valuable in-formation. In this respect, mining of graph data has always demanded its share of lime-light. This is primarily because graphs are ubiquituous and many real world scenarios are modeled as graphs. For exam ple, the physical interactions between proteins in an organism are modeled as a protein interaction graph with pro-teins as vertices and their interactions as edges. Protein interaction graphs are a major resource for knowledge discovery: d etecting protein complexes, predicting protein functions and reliabilities of interactions [10].

There are many efficient techniques deve loped for storing and manipulating graphs in main memory (RAM): for traversals, answering reachability queries, mining frequent patterns, etc. [5] How ever, as more and more graph data is accumulated, it is not feasible to store and manipulate entire graphs in main memory. Therefore, graphs are stored on disks and efficiently fetched into main memory in parts for manipulation [2]. The computational power of processors is increasing, while the speed gap be tween main and secondary (disk) memo-ries is widening. Therefore, graphs are compressed and stored on disks so that they can be retrieved in parts with as li ttle I/O reads as possible, and uncom-pressed quickly in main memory [1]. To summarize, these approaches used to handle graphs can be classified broadly into two categories: (a) efficient stor-age and manipulation of graphs in main memory; (b) efficient storage and in-dexing of graphs on disks and their retrieval into main memory (out-of-core approach).

As graph sizes continue to grow larger, it will be interesting to look at alter-native approaches to mine large graphs (any data in general). The SQL-based approach for integrating mining with RDBMS (relational database manage-ment systems) was proposed long back (in 1998) for association rule mining [9], followed by k -way join variants for association rule mining in 2003 [6], Subdue-based substructure mining in 2004 [3], and frequent subgraphs mining in 2008 [4]. The SQL-based approach proposed storing data in relational databases and min-ing it using SQL queries. Even though this approach was considered novel and promising, the idea was mainly constraine d to transactional datasets, and never became popular for mining graphs. One probable reason, we believe, was the complications (awkwardness) involved in  X  X apping X  graphs onto the relational framework of a RDBMS. This involved expressing the whole problem (graph data, storage and manipulation) declaratively (using SQL).

In spite of the non-trivial nature of the SQL-based approach, it can be very useful and promising. The RDBMS displays data to the designers and pro-grammers as relational structures, while internally it stores this data on disk blocks using efficient disk-based data structures (example, B + trees). Hence, if we can reasonably  X  X ap X  graph data structures and algorithms onto re-lational structures, then we can leverage all the services RDBMS can offer: handling dynamic updates, buffer management, indexing and retrieval, and par-allelism. After all, more than two decades of research has gone into making database systems fast, scalable, robust, and concurrent. Secondly, in many in-stances, main memory and out-of-core imp lementations can get exceedingly non-trivial. However, the development and deployment time of SQL-based code can be significantly shorter because one can avoid denormalizing data and storing into flat files prior to data mining, and also writting code for indexing and retrieval [9].
 The main contribution of our work is to propose a lightweight framework for SQL-based mining of graphs on RDBMS. It is shown in Figure 1. This framework is designed for making effective use of the RDBMS features for efficient handling of large graphs. The network layer forms the most important component of the framework. Several graph mining applications can be  X  X apped X  onto the RDBMS through the services offered by this layer. 2.1 The Network Layer The network layer rests conceptually within the RDBMS (see Figure 1) and runs in the same address space as the RDBMS. It is implemented using procedural SQL (stored procedures using Oracle X  X  PL/SQL [8]). The advantage of imple-menting this way is that the network layer is tightly-coupled to the RDBMS: it has direct access to all the services offer ed by the RDBMS. This layer provides the necessary graph-abstraction to abstract away all the complications involved in handling large graphs. It houses all the basic table designs and  X  X tilities X . Graph applications can either be implemented lo osely-coupled or tightly-coupled to the RDBMS. For loosely-coupled applications, the network layer acts as a transla-tion layer (For example, converting C or Java c alls into SQL queries), while for tightly-coupled applications (written in procedural SQL), it provides ready-to-use libraries and utilities. 2.2 Efficient Storage of Graphs in the Network Layer The basic schema design consists of storing all graphs G = { G 1 ,G 2 , .., G k } in a hierarchical  X  X aster-detail X  fashion in the following tables: a graph ta-ble Graph (GraphId , NoOfVertices, NoOfE dges), a vertex table Ve r t ex (GraphId , VertexId ), and a connectivity table AdjMatrix (GraphId ,Vertex1 ,Vertex2 ). For every graph G i =( V i ,E i )  X  G , there is a record (tuple) in Graph , uniquely iden-tified by the primary key { GraphId } X  X  G i } . For every vertex v  X  V i of graph G , there is a record in Ve r t ex , uniquely identified by primary key { GraphId, VertexId } X  X  G i ,v } . The whole connectivity struc ture is then stored as records in AdjMatrix . For every edge ( u, v )  X  E i , there is a record in AdjMatrix uniquely identified by the primary key { GraphId, Vertex1, Vertex2 } X  X  G i ,u,v } .Notice how GraphId is propagated as part of the primary key in all tables. The whole graph G i can be uniquely queried from the tables using GraphId . 2.3 Implementing a Basic Utility within the Network Layer: BFS We next describe how a basic utility like the breadth-first search (BFS) on a graph is efficiently implemented within the network layer.

The BFS algorithm on a graph G i =( V i ,E i ) and its SQL-based design are shown in Algorithm 1. We first store the graph G i in the above-proposed tables. To simulate the FIFO queue used in BFS, we design a table Queue (Line: 1). Algorithm 1. BFS( G, s ) For every vertex v  X  V i that is enqueued, there is a record in Queue , uniquely identified by { GraphId, VertexId } X  X  G i ,v } .The position attribute in Queue gives the position of v in the queue. The smaller the position , the earlier v will be dequeued. Additionally, for every vertex v  X  V i , there is a record in table Discovery , uniquely identified by the primary key { GraphId, VertexId } X  {
G i ,v } . There are attributes visited and discoveryNo to keep track of whether v has been visited and its order in the visited sequence.

The BFS algorithm begins by inserting the source s into Queue (Line: 2). In each iteratio n, the vertex v with the minimum position is selected (Line: 4) from Queue .Allunvisitedneighbors u of v (Line: 5) are then selected from the join: These vertices are inserted into Queue (Line: 6) and updated as  X  X isited X  in Dis-covery (Line: 7, 8). These iterations continue till Queue is empty. 2.4 Extending to Graph Mining: Quasi Clique Detection Quasi cliques are very interesting structures from the point of view of graph mining. Very simply, a quasi clique in a graph is an  X  X lmost X  complete subgraph. Quasi cliques are used to model real-world communities in protein networks, social networks, scientific collaboration networks, etc. [10]
There are several ways to model quasi cliques; one way is by the notion of a  X  -quasi clique .Givenagraph G =( V, E ), a subgraph Q =( V Q ,E Q ), V Q  X  V and E Q  X  E , is called a quasi clique with clustering co-efficient 0  X   X   X  1if, | E of the same size. This is given by: | E Q | X   X . | V Q | 2 . Therefore, the number of edges missing in Q is given by:  X   X  (1  X   X  ) . | V Q | 2 .

To study quasi clique detection on our framework, we chose the algorithm proposed in [10]. We only give the essense of the algorithm here so that the purpose of our work is served; for details see [10]. The inputs to the algorithm are graph G =( V, E ), and fixed parameters k&gt; 0and  X   X  0. The algorithm performs a bounded recursive search to find a quasi clique Q  X  V of size at most k with at most  X  edges missing. The time complexity of the algorithm is O (3 k +  X  .f poly ( | V | )). The recursive search procedure makes the algorithm highly memory-intensive with the amount of additional memory required per search-non-trivial the memory management can be in such applications, especially when implemented in-memory or out-of-core. 2.5 The RCR Strategy i n SQL-Based Approach In order to implement the quasi clique algorithm using the SQL-based approach, we made use of the earlier proposed table designs. Additionally, we designed the following interesting strategy, which we call replicate-cleanup-rebuild (RCR). This strategy can be adopted to other recursive algorithms as well. Algorithm 2. bool QCRecursive ( G, Q, V \ Q, k,  X  ): recursive call
In this strategy, each call replicates (stores an additional copy) all the val-ues received from its pare nt into a working table Working (see Algorithm 2). It makes its computations on the receive d values and passes the results to its child. When the child backtracks, instead of reverting back each computation, the current computed values are blindly cleaned-up (discarded), and the original values are rebuilt (queried) from Working . Subsequently, new computations are performed on these original values and sent to the next child. Also, when a child call backtracks, its records a re permanently deleted from Working . The records stored for each call c are uniquely identified by the primary key { GraphId, CallNo } X  X  G i ,c } in Working . Considering h poly ( | V | ) number of records in-
Notice the intuition behind this strategy: to remove all the non-trivial memory management (local storage of values, and reverting back of computations from unsuccessful paths) within the calls and instead rely on the RDBMS for efficient mechanisms. It also illustrates how code development time can be significantly shorter using the SQL approach.
 We compared SQL-based implementations against straight-up main memory im-plementations for: (a) breadth-first search (BFS) as a basic graph utility, and (b) quasi clique detection as a graph mining application. We implemented the main memory versions of the algorithms in C ++ using the g++ 4.1.2 compiler on the GNU/Linux Debian distribution (2.6 kernel) installed on an Intel Xeon Dual Core 2.4GHz machine with 3GB RAM, 2.7GB swap partition and 250GB hard disk. Whenever the memory requirement was more than 3GB we relied on virtual memory. The procedural SQL ver sions were implemented in PL/SQL [8] on Oracle 10g on the same machine. 3.1 Evaluation of Breadth-First Search We first compared the two im plementations of BFS: (a) main memory (referred as BFSiMM) versus (b) procedural SQL (referred as BFSiSQL).

We generated random networks of n nodes and m =4 n edges by replacement (that its, selecting m times nodes u and v such that u = v and removing the edges between duplicated pairs). Figure 2(a) shows the comparison plots of runtimes (seconds) on networks for n between 2 16 to 2 23 . The figure shows that even though BFSiMM performed better than BFSiSQL for small networks, BFSiSQL outperformed BFSiMM for large networks. 3.2 Evaluation of Quasi Clique Detection We next compared the two implementations of the quasi clique algorithm: (a) main memory (referred as QiMM) versus (b) procedural SQL (referred as QiSQL).
We generated scale-free networks with n = 10K to 90K (  X  2 13 . 28 to  X  2 16 . 45 ), and random networks with n = 10K to 40K (  X  2 13 . 28 to  X  2 15 . 28 ) vertices. We clustered them and stored co-clustered vertices on close-by disk blocks. Very small quasi cliques are easy to find and are not interesting, therefore we set k =25and  X  = 180, giving  X   X { k 2  X   X  } / k 2 =0 . 4. In each execution, 20  X  -quasi cliques were detected by iterat ively deleting the current quasi clique and searching for the next one in the remaining network. Figure 2(b) shows the comparison of runtimes (in lg scale) for QiMM and QiSQL. It shows that even though QiMM performed better than QiSQL for small networks, QiSQL outperformed QiMM for large networks. For scale-free networks, this cross-over occurred around 60K (  X  2 15 . 7 ) nodes. For random networks of size 25K (  X  2 14 . 6 ), QiMM continuously aborted finding only 13 quasi cliques, while QiSQL found all 20 quasi cliques.

We next considered a variety of real-world networks obtained from [7]. These included social (Epinions: Ep X 03, Slashdot: Sd X 08 and Sd X 09), scientific collabora-tions (Astro-physics: AP X 03, General Relativity: GR X 07) and protein interaction networks (Gavin: GA X 06, Krogan: KN X 06). Figure 2(c) shows the comparisons for fixed k and  X  . It shows that QiSQL outperformed QiMM for all networks, except the small ones like PPI GA X 06 and KN X 06. Analysis of deteriorating performance of QiMM: Even though the synthetic and real-world networks considered in the quasi clique experiments resided com-pletely in main memory, QiMM displayed worse behavior compared to QiSQL for the larger networks. This was primarily because of the significant amount of additional memory required for recu rsive calls, which subjected QiMM to heavy thrashing . See Figure 2(c). Snapshots of memory usage (from top and vmstat ) of the overall system when QiMM was executing showed 100% RAM and 100% CPU usage. The high swap-in (si) and swap-out (so) values (always zero while not thrashing) clearly indicated critical thrashing. The high scan indicated wastage of CPU cycles while waiting for the page handler to scan for free pages. In this work we have proposed a lightweight framework to extend the SQL-based approach to mine large graphs. We showed that this approach outperformed straight-up main memory implementations for BFS and quasi clique detection on large graph datasets. It will be interesting to realize our framework on grid tech-nologies (like Oracle 10g/11g) for mining large graphs in a parallel distributed fashion.
 Acknowledgements. We would like to thank Hon Wai Leong (NUS) and Anthony Tung (NUS) for the interesting discussions during this work, and the reviewers for their valuable comments. SP would like to acknowledge support from the following NSF grants  X  IIS-0917070, CCF-0702587, IIS-0347662. SS is supported under the NUS research scholarship.

