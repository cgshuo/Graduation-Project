 ARISTIDIS PAPPAIOANNOU, MARINA SPIVAK, and L  X  EON BOTTOU , NEC Labs Consider a binary classification problem with patterns x  X  X and classes y = X  1 obeying an unknown probability distribution dP ( x , y ). The probabilities of nondetection P nd and of false alarm P fa measure the two kinds of errors made by a discriminant function f : The statistical decision theory recognizes the need to associate different costs to these two types of errors. This leads us to searching a classifier f that minimizes the Asym-metric Cost (AC) formulation : Although C + and C  X  have a meaningful interpretation, it is often very difficult to specify these costs in real situations such as medical diagnosis or fraud detection. There are also cases where such costs have no meaningful interpretation, for instance, as discussed in Section 4, when one uses a classification framework to approach a false discovery problem.

In contrast, the Neyman-Pearson (NP) formulation requires only the specification of the maximal false alarm rate  X  and can be meaning-fully applied to false discovery problems.

It is well known that the optimal decision function for both problems are obtained by thresholding the optimal ranking function that is Although this result suggests equivalent capabilities, it misses several important with the empirical counterparts of P nd and P fa .Wehave where D + and D  X  represent, respectively, the set of positives and negatives with car-dinality n + and n  X  . We must also choose the decision function f within a restricted class H that is unlikely to contain the optimal decision function. This approach is sup-ported by standard results in statistical learning theory (e.g., Vapnik [1998] and their extension to the Neyman-Pearson formulation [Scott and Nowak 2005]).

Secondly, the empirical counterparts of problems (1) and (2) involve the 0 X 1 loss SVM Hinge loss has been studied for both the asymmetric cost [Bach et al. 2006] and Neyman-Pearson [Davenport et al. 2010] formulations. This substitution introduces additional complexities. In particular, in order to hit the specified goals on P nd and P fa , one must use asymmetric costs that are different from C + and C  X  . Both works eventually rely on hyperparameter searches in the asymmetric cost space.

An alternative approach consists in first learning a scoring function that orders in-put patterns like the optimal ranking function (3). Both problems (1) and (2) are then reduced to the determination of a suitable threshold (e.g., Cortes and Mohri [2004]). However, it is quite difficult to ensure that the ranking function is most accurate in the threshold area. Theoretical investigations of this problem conclude that Neyman-Pearson classification remains an important primitive for such focussed ranking algo-rithms [Cl  X  emenc  X on and Vayatis 2007, 2009].

This contribution proposes two practical and efficient algorithms for NP classification using nonconvex but continuous and mostly differentiable loss functions. In particu-lar, these algorithms are shown to work using asymmetric costs that maintain a clear relation with the specified goals. The first algorithm leverages modern nonconvex opti-mization techniques [Tao and An 1998]. The second algorithm is a stochastic gradient algorithm suitable for very large datasets. Various experimental results illustrate their properties.
 vex approximation such as the sigmoid loss or the ramp loss The positive parameter  X  determines how close the nonconvex costs are to the 0 X 1 loss and those approximations tend toward the 0 X 1 loss as  X  tends to 0. Figure 1 illustrates such approximations. The selection of an optimization algorithm usually dictates the choice of an approximation. The differentiable sigmoid loss lends itself to gradient descent, whereas the ramp loss is attractive with dual optimization algorithms.
Following common practice, we also add a regularization term ( f ) to control the capacity of our classifiers. We therefore seek the solution of where C  X  R + is the regularization parameter and For instance, in the case of a Neyman-Pearson SVM (NP-SVM), the discriminant func-tions is f ( x ) = f 0 ( x ) + b with f 0 taken from a RKHS induced by a kernel k x , x ,and the regularizer is ( f ) = f 0 2 H .
 The nonconvex optimization problem (6) comes with the usual caveats and benefits. We can only obtain a local minimum of (6). On the other hand, we can obtain a local minimum that is better than the solution of any convex relaxation of (6), simply by initializing the nonconvex search using the solution of the convex relaxation. The NP classification problem has been extensively studied. Past methods can be roughly divided in two categories: generative and discriminative.

One of the earliest attempts [Streit 1990] uses multilayered neural networks to estimate class-conditional distributions as mixture of Gaussians. The discriminant function is then inferred with a likelihood ratio test. In the same vein, recent methods [Kim et al. 2006] assume the class-conditional distributions are Gaussian with means  X   X  and covariances  X  , and consider a linear classifier f ( x ) = w , x + b . This amounts to solving (2) with the following definitions where is the cumulative distribution function of standard normal distribution and  X   X   X  and  X   X  are empirical estimations. Since the Gaussian assumption proves too re-strictive, some authors [Huang et al. 2006; Kim et al. 2006] replace the cumulative by nonlinear discrimination using the kernel trick. A third flavor of generative approach addresses the estimation of class-condition distributions by Parzen window [Bounsiar et al. 2008]. These generative methods share the same drawbacks: (1) the final classi-fiers are derived from estimated distributions whose accuracy is questionable when the datasets are small, and (2) the kernel version of these models lacks sparsity because all the examples are involved in the model.

On the discriminative side, the asymmetric cost SVM [Bach et al. 2006; Davenport et al. 2010] introduces costs C + and C  X  in the SVM formulation. As mentioned before, even if the true asymmetric costs were known, the benefits of the convex loss, such as the guaranteed convergence to global optimum, are balanced by the necessity of searching for different asymmetric costs to achieve the desired NP constraint [Bach et al. 2006]. SVMPerf [Joachims 2005] optimizes in polynomial time a convex upper bound of any performance measures computable from the confusion table. Since  X  P fa and  X  P nd can be computed from the confusion table, SVMPerf can address the Neyman-Pearson problem. Computing times grow very quickly with the number of examples n , typically with degree four for linear models, worse for nonlinear models. Finally, most similar to our approach, Mozer et al. [2002] also consider sigmoid approximation of 0-1 loss. Compared to this work, our contributions are threefold: we extend the nonconvex NP idea to SVM in order to benefit from off-the-shelf SVM solvers, we propose a stochastic approach to deal with large-scale datasets, and we extend the potential of our approaches to related problems such as q -value optimization (Section 4). The algorithms discussed in this article find a local minimum of (6) by searching a local saddle point ( f , X  )  X  H  X  R + of the related Lagrangian The appendix summarizes several results that apply to nonconvex optimization. Local saddle points of the Lagrangian (7) are always feasible local minima of (6). Conversely, assuming differentiability, the local minima of (6) are always critical points of the Lagrangian. The Uzawa algorithm [Arrow et al. 1958] is a simple iterative procedure for finding a saddle point of the Lagrangian (7). Each iteration of the algorithm first computes a minimum f  X   X  of the Lagrangian for the current value of  X  , and then performs a small gradient ascent step in  X  (Algorithm 1) with  X   X  L =  X  P fa  X   X  . The convergence of the Uzawa algorithm is not obvious because the function  X   X  L ( f  X   X  , X  ) can easily contain discontinuities. However, a simple argument (see Theorem 3 in the appendix)  X 
L =  X  P general we prefer using a multiplicative update  X   X   X  (1 +  X   X   X  L ) because it keeps the  X  positive. This makes very little difference in practice: the key is to adjust  X  in very small increments, for instance, using a very small gain  X  .

The two algorithms discussed in this article are essentially derived from the Uzawa algorithm. They differ in the minimization step. The first algorithm uses the DC 1 approach [Tao and An 1998] and is suitable for kernel machines. The second algorithm relies on a stochastic gradient approach [Tsypkin 1971; Andrieu et al. 2007] suitable for processing large datasets. The most difficult step in the Uzawa algorithm is minimization of L over f for  X  fixed. In the case of the SVM classifier, the Lagrangian (7) reads where C + = C / n + , C  X  =  X / n  X  and ( z ) stands for the ramp loss (5). This amounts to solving a nonconvex asymmetric cost SVM [Collobert et al. 2006b]. Since the analytical Lagrangian can also be expressed as the difference of two convex functions amenable to DC programming [Tao and An 1998]. Consider the nonconvex optimization problem the convex problem obtained by linearizing J 2 ,thatis, decreases after each iteration by summing the following two inequalities resulting from (8) and from the convexity of J 2 .
 Following Collobert et al. [2006b], we write L ( f , X  ) = J 1 ( f )  X  J 2 ( f )with where notation C y function of a standard convex SVM. Each DC iteration then reduces to solving the following convex problem Standard SVM techniques can be used to obtain the dual formulation of this problem. This dual formulation turns out to be similar to that of a standard SVM problem with shifted box constraints [Collobert et al. 2006a, appendix]. This derivation leads to Algorithm 2. To summarize, applying the Uzawa algorithm (Algorithm 1) to the NP-SVM results in repeatedly solving a nonconvex asymmetric cost SVM via Algorithm 2 and updating  X  by gradient ascent.

This slow procedure requires solving many times a nonconvex SVM problem. Much faster convergence is observed by moving the gradient ascent step inside the DC it-erations, leading to the annealed nonconvex NP-SVM algorithm (Algorithm 3). This algorithm departs from the Uzawa template because the Lagrange coefficient  X  is updated after each iteration of the DC algorithm (9) instead of performing it in an additional loop surrounding the optimization of the nonconvex asymmetric cost SVM. Although we have no formal convergence guarantee for this algorithm, empirical evi-dence shows that it works as reliably and much faster than the plain Uzawa algorithm (see Section 5.2.)
We pick an initial value for  X  such that C / n + =  X / n  X  in order to balance the initial regularization parameters for positives and negatives. Since the DC iterations start with  X  = 0 , the first iteration solves the classical asymmetric cost SVM problem whose solution is progressively improved by taking the nonconvexity into account and updating  X  in order to achieve the target P fa . The algorithm is stopped when the NP constraint is satisfied with a predefined precision  X  . The computational cost of the batch learning algorithm discussed earlier increases quickly when the dataset size becomes large. Faster algorithms are therefore desirable.
Let vector w and the scalar bias b be the parameters of the discriminant function,  X  = 1 / C , and reformulate problem (6) as Expanding  X  P nd and  X  P fa leads to the Lagrangian with the coefficients
Algorithm 4 is a stochastic variant of the Uzawa algorithm. Each iteration performs a stochastic gradient descent step for ( w , b ) and a stochastic ascent step for the Lagrange coefficient  X  . Since the false alarm rate depends only on the negative examples, the update of  X  only happens when sampling a negative example.

The convergence analysis of this stochastic descent/ascent procedure establishes how closely the updates (11-12) follow the trajectory described by the corresponding ordinary differential equation. Almost sure convergence to a local saddle point is guar-anteed under mild conditions [Tsypkin 1971; Andrieu et al. 2007]. Such direct results are in fact stronger than those available for the generic Uzawa approach.
Linear NP-SVM. Following Bottou [2007], when training a linear SVM (that is f ( x ) =  X  chosen to ensure that the initial updates of w are compatible with its expected size. Choosing  X  0 = 0 . 1 works well when x i  X  1.

Empirical evidence, on the other hand, suggests that  X  should be smaller than  X  t in order to ensure that  X  remain consistent. Otherwise the algorithm strongly enforces the false alarm rate constraint at the expense of the nondetection rate. In our experi-mentations we always choose  X  proportional to 1 / n  X  .

Using the ramp loss makes the Lagrangian nondifferentiable when y t f ( x t ) = X   X  .In such cases, we simply consider that the gradient is zero and skip the stochastic update. On the other hand, using the sigmoid loss simply avoids the problem. Both approaches work well in practice.

Nonlinear Extensions. Algorithm 4 extends naturally to nonlinear discriminant func-tions such as multilayer neural network. Gradients are easily computed using the standard back-propagation algorithm. The learning rate  X  t must then be chosen using a trial-and-error approach.

Extending Algorithm 4 to kernel representations is more complicated. The param-eter w can be expressed with a kernel expansion w = n i = 1  X  i  X  ( x ) where  X  ( x )isthe mapping function associated with the kernel. Since f ( x ) = w , X  ( x ) + b we can plug the update However, the noise introduced by the stochastic procedure compromises the sparsity of  X  . The computation of the gradient then requires numerous kernel evaluations in order to compute f ( x t ). Although kernel values can be cached, these problems reduce the appeal of the stochastic approach. We plan to investigate this issues more closely in a forthcoming work.

Imbalanced Dataset. When the dataset is highly imbalanced, for instance, when there are many negatives and just a few positives, considerable speedups are achieved by picking random training examples from each class with equal probability. Since this procedure oversamples the examples from the minority class, we must adjust the coefficients a i in Algorithm 4 in proportion. The coefficients then become So far we have considered problems in fully supervised setting, with positive and negative labels assigned with equal confidence. The situation explored in this section is slightly different in the sense that we assume the labels of the negative class are confidently assigned and the goal of the classifier is to assign a confidence measure to labels of the first class.

Such problems are often encountered in large-scale biological screening, where mul-tiple independent events are tested against a null hypothesis to discriminate real biological effects from noisy data. In microarray experiments, the expression level of genes is tested against the background signal [Storey and Tibshirani 2003]. In mass spectrometry protein screening, potentially positive matches between spectra and pep-tide sequences are tested for correctness against peptide-spectrum matches that are known to be negative because they were generated randomly [Elias and Gygi 2007].
Given a scoring function for these events, a widely used approach, both in microarray and proteomic applications, is to assign to each event a statistical confidence measure, the q-value , defined as the proportion of higher scoring events that turn out to be known negatives. Events below a certain user-specified q-value threshold are considered sta-tistically significant and are selected for further biological identification. In practical terms, a q-value threshold can be interpreted as the proportion of significant events that will turn out to be false leads [Storey and Tibshirani 2003].

When such problems are addressed in classification framework, the goal is to dis-criminate the significant events from the nonsignificant ones. In this setup, the labels of the negatives are confidently assigned, while the labels of the positives are to be ver-ified. In order to hit the user-specified q-value threshold q , the classifier must satisfy the constraint Earlier works simply train a classifier using the available labels, without taking into account the uncertain nature of the positive labels. Then, they use the ordering induced by the classifier to assign q-values, and, finally, select a subset of examples with q-values below a desired threshold [K  X  all et al. 2007]. This approach is equivalent to constructing an ROC curve of the classifier and taking a single point on the ROC curve.
Alternatively, Spivak et al. [2009] propose an algorithm that directly optimizes the classifier for a single specified q-value threshold or a set of such thresholds. Their approach is equivalent to optimizing the ROC curve in the vicinity of the point cor-responding to the q-value threshold q . A precise formulation of this objective leads to a formulation that is strikingly similar to NP classification. Indeed, maximizing true positives rate while keeping the user-specified q -value amounts to solving The machinery of Section 3 is easily adaptable with the new Lagrangian This Lagrangian is obviously related to (7) and therefore is amenable to similar al-gorithms. Adapting the stochastic algorithm requires some ingenuity because the  X  update depends on both the positive and negative examples. We have modified Algo-rithm 4 to pick at each iteration both a random positive example x + t and a random negative example x  X  t . We update the model parameters w using the gradient of the Lagrangian (13) restricted to these two randomly picked examples. Finally we update the Lagrange parameter  X  with This section reports experimental results obtained with the various algorithms dis-cussed in this article. Section 5.1 presents the various datasets used in our experi-ments. Sections 5.2 and 5.3 present exploratory results characterizing the performance of the annealed nonconvex NP-SVM algorithm. Sections 5.4 and 5.5 present Neyman-Pearson classification results obtained using Gaussian kernel SVMs on small-scale and medium-scale datasets and linear SVMs on medium-scale and large-scale datasets. Fi-nally, Section 5.6 reports on a real-life q-value optimization problem using both a Gaussian kernel SVM and a nonlinear multilayer network as classifiers (Section 5.6.) Table I summarizes the main characteristics of our datasets.

Some exploratory results reported in Section 5.2 were obtained using synthetic data inspired from Bach et al. [2006]. The dataset consists of 2500 two-dimensional points. An equal number of positives and negatives points are drawn from two Gaussian distributions shown in Figure 2.

The Neyman-Pearson classification experiments were carried out using two small-scale datatsets (B REAST and P IMA ), three medium-scale datasets (S PAMBASE ,P AGEBLOCKS , and G AMMA T ELESCOPE ), and two large scale datasets (C OVERTYPE and RCV1-V2). The first six datasets are well-known classification datasets available from the UCI machine learning repository. 2 The small-scale and medium-scale datasets originally specify two classes. We always use the majority class as positive examples and the minority class as negative examples. For the datasets B REAST and P IMA we set aside one quarter of the examples as a testing set and we use four-fold cross-validation on the remaining and C OVERTYPE , we set aside one quarter of the examples as a testing set and one quarter of the examples as a validation set for model selection. The remaining half of the examples are used as the training set. In the case of the C OVERTYPE dataset, a binary classification problem was formed by picking species Spruce-Fir and Krummholz as positive and negative classes, respectively. Finally, the dataset RCV1-V2 is available from the RCV1-V2 Web site. 3 In order to make the problem large scale, we use the official testing set (781,265 documents) as the training set and the official training set (23,149 documents) as the testing set. The RCV1-V2 TF/IDF features were recomputed to account for this new split. The documents associated with the category ECAT are used as negative examples. All the remaining documents are used as positive examples.
The q-value optimization experiments were carried out using a proteomics dataset consisting of 139410 samples with positive and negative samples equally repre-sented [Spivak et al. 2009]. This section compares the performance of the annealed nonconvex NP-SVM (Algorithm 3) with the performance of a more direct implementation of the Uzawa algorithm consisting of using Algorithm 2 as the minimization step of the Uzawa Algorithm 1.

Our first experiments train a Gaussian kernel SVM on the S YNTHETIC dataset. We of the kernel and C + the cost assigned to positive samples. Both algorithms were tested implemented in C++ using a SMO optimizer [Platt 1999] and a kernel cache. The cache vastly speeds up the algorithms because kernel matrix coefficients computed during the earlier iterations can be used during the later iterations.

Table II reports results averaged on all values of the hyperparameters ( C + , X  ). The annealed nonconvex NP-SVM algorithm considerably accelerates the convergence. The tablealsoshowsthe P fa and P nd differences evaluated by directly sampling test exam-ples from the Gaussian distributions. These differences are statistically insignificant according to a Wilcoxson signed rank test with p-value threshold 10  X  3 .
Table III reports the speedup factors achieved by repeating this experiment on the medium-size dataset S PAMBASE . We do not report on the final P fa and P nd because the differences were similarly insignificant.

Both tables reveal that the annealed nonconvex N-SVM speedup is higher for small values  X  . This probably happens because such values of  X  lead to extreme ratios be-tween the quantities C + and C  X  =  X / n  X  and penalize the computing times of the asymmetric nonconvex SVM solver called during the minimization step of the Uzawa algorithm. This section investigates the influence of the initialization on the solution computed by the annealed nonconvex NP-SVM solver (Algorithm 3). For the sake of simplicity, we only consider a linear SVM trained on the S PAMBASE dataset. Besides the initialization  X  = 0 , which corresponds to training a plain SVM during the first iteration, we run the algorithm using 24 randomly generated initial vectors  X  and measure the error probabilities  X  P nd and  X  P fa achieved at convergence on the training set. The experiment was repeated for different values of C .

Figure 3 reports the results. Unsurprisingly, since the NP problem is intrinsically nonconvex, the initializations impact the solutions. The simplest initialization  X  = 0 does not always lead to the best solution. However, all the results are empirically very close to those achieved by using  X  = 0 . This section compares Gaussian kernel SVMs trained on the small-scale and medium-scale datasets using the annealed nonconvex NP-SVM algorithm (NP-SVM, Algorithm 3), the convex cost-sensitive SVM (AC-SVM) [Davenport et al. 2010], and the generative approach (GEN) [Huang et al. 2006]. We only report the best GEN results achieved using Chebychev bound ( u ) to model probabilities of error (see Section 2.1). We do not report results using the stochastic NP optimizer (Algorithm 4) because it is not suited to kernel machines. We do not report results obtained with SVMPerf [Joachims 2005] because running the algorithm for plain kernel machines is  X  X ainfully slow, X  according to the SVMPerf Web site.
 The hyperparameters of the different methods were determined by cross-validation. Different algorithms have different model selection requirements: GEN only requires choosing a kernel bandwidth  X  , whereas NP-SVM requires finding a pair ( C , X  ), and was selected using the validation criterion [Davenport et al. 2010].
 This criterion has the property to enforce strongly the false alarm rate constraint for small values of  X  . All reported results were, of course, measured on the testing set after completing all the model selection procedure, using a validation set or using four-fold cross-validation, as explained in Section 5.1. Following Davenport et al. [2010], for each parameter, 10 logarithmically spaced values in the range 10  X  2 , 10 2 were explored. This means that 10 3 triplets ( C + , C  X  , X  ) were tested for AC-SVM while only 100 pairs ( C , X  ) and 10 parameters  X  were respectively tested for NP-SVM and GEN. We used a C++ implementation of the SVM solvers with Torch 4 bindings, and a Matlab implementation of the generative approach. 5
Figure 4 reports the final classification errors P nd and P fa , and the corresponding computation time achieved for several values of  X  .
 As expected, NP-SVM tightly satisfies the false alarm constraint. NP-SVM achieves P nd misclassification rates similar or slightly better than AC-SVM on the S PAMBASE , B
REAST ,andP IMA datasets. AC-SVM seems to perform better on P AGE B LOCKS . The rea-son could be related to the small number of negative samples available for the latter dataset. Indeed, according to the experimental protocol and Table I, when running NP-SVM for  X  = 0 . 01, one seeks a classifier with solely two misclassified negatives. NP-SVM strives to fullfill the constraint and overfits. On the other hand, on G AMMA T E -LESCOPE , the number of examples is significantly higher, and NP-SVM reaches a better P nd than the competing techniques.

Except for S PAMBASE and B REAST , GEN was not able to attain P nd results competitive with NP-SVM or AC-SVM. GEN achieves a better P nd on P AGE B LOCK at the price of violating the P fa constraint. Despite its Matlab implementation, GEN appears to be the fastest method on the small-size datasets. However, GEN slows down as soon as the size of the data grows, because its lack of sparsity results in expensive manipulations of the full kernel matrix. NP-SVM is very competitive with AC-SVM in terms of computation time, and even runs twice faster on S PAMBASE . 6 The computational load of NP-SVM is high for small  X  s and decreases when  X  increases. This phenomenon could be explained as follows: for small  X  s, NP-SVM sets  X  at high values during training, leading to highly skewed asymmetry. The SVM solver is then driven into extreme situations and runs slowly. This section compares linear SVMs trained on the medium-scale and large-scale datasets using the batch annealed nonconvex NP-SVM solver (BNP-SVM, Algorithm 3), the online Stochastic NP optimizer (ONP-SVM, Algorithm 4), the convex cost-sensitive SVM (AC-SVM) [Davenport et al. 2010], the generative approach (GEN) [Huang et al. 2006], and the SVMPerf algorithm (SVMPerf) [Joachims 2005].

In the case of ONP-SVM, the hyperparameter selection searches the regularization  X  epochs on the medium-scale datasets and 50 epochs on the large-scale datasets.
In the case of AC-SVM, 15  X  15 values of ( C + , C  X  ) were searched in the hyperbox [0 . 001 , 1000] 2 for P AGEBLOCKS and [0 . 01 , 100] 2 for the other datasets. The search for BNP-SVM only explores 25 values of C for P AGEBLOCKS and 15 values of C for the other datasets. The generative approach GEN is parameter free.
 The SVMPerf results were obtained by adapting the SVMPerf program 7 to solve the Neyman-Pearson problem by exploiting its precision/recall at k mode. In this mode, SVMPerf computes a classifier yielding exactly k positive instances on the training set. Therefore the algorithm requires the specification of C and k . The hyperparameter C was searched as for the other SVM algorithm. Meanwhile, we explore ten values of k linearly spaced in the interval (1 / n + , 1) and select the value that most closely achieves the target P fa on the validation set. However, the reported SVMPerf training times exclude the time required to search parameter k . We simply report the running time associated with the final value of k because it would theoretically have been possible, but far from easy, to modify the intricate SVMPerf loops to do this automatically.
Experiments on the large-scale datasets C OVERTYPE and RCV1-V2 were carried out using a number of speed optimizations. The SVM solver for AC-SVM was replaced by LIBLINEAR which is one of the most efficient solvers for linear SVM [Hsieh et al. 2008]. For the ONP-SVM experiments on RCV1-V2, we modified the stochastic gradient code of Bottou [2007] because it handles sparse vectors more efficiently than our baseline code.

Figure 5 reports the results obtained on all datasets but RCV1-V2. For readability, the SVMPerf results on C OVERTYPE are shown separately in Figure 6. The RCV1-V2 results are shown separately in Table IV.
 Several conclusions could be drawn: GEN is fast but performs poorly in terms of P nd . The stochastic NP optimizer has a constant numerical cost regardless of  X  . It is really fast, especially for Gammatelescope where the computation gains compared to BNP-SVM and AC-SVM are respectively around 12 and 20. Moreover, the performances of ONP-SVM in terms of P fa and P nd are similar to those of batch methods. Interestingly, P nd for ONP-SVM on P AGEBLOCKS is slightly better than its counterpart for the other algorithms, suggesting that ONP-SVM overcomes the lack of robustness of BNP-SVM in this regime. For G AMMA T ELESCOPE , our proposed approaches clearly outperform AC-SVM and GEN. The performances for AC-SVM could be improved using a finer grid search for C + and C  X  or using a regularization path procedure [Yu et al. 2009]. How-ever, this would increase the computing times. In particular the regularization path approach, in worst-case scenario, has to visit an exponential number of kinks [G  X  artner et al. 2009].
 SVMPerf matches the speed and accuracy of ONP-SVM on the S PAMBASE and P AGE -BLOCKS datasets. It remains competitive in speed on the G AMMA T ELESCOPE dataset, but shows poor accuracies for small values of  X  . Enlarging the search interval for C or sampling k more finely did not provide any improvement. A possible explanation may lie with the fact that SVMPerf optimizes a convex upper bound of the target criterion, instead of the intrinsically nonconvex Neyman-Pearson objective. The scalability is-sues of SVMPerf become apparent on the C OVERTYPE dataset (Figure 6). Although the performances of SVMPerf could be improved by exploring more hyperparameters, its very long training time discourages such a search.

The RCV1-V2 results shown in Table IV again comfirm the good performance of the stochastic NP optimizer (ONP-SVM). Each run of ONP-SVM takes 30.44 seconds on average, whereas each call to the LIBLINEAR solver in AC-SVM takes 79.50 seconds. As we tested 100 pairs of parameters ( C + , C  X  ) for AC-SVM and only 36 pairs (  X , X  )for ONP-SVM, the computing time gain is highly appreciable. This subsection experimentally evaluates the q -value algorithms described in section 4 using the proteomics dataset described in Spivak et al. [2009]. Following Spivak et al. [2009], the performance was measured in terms of number of true positives correctly ranked over false positives. Table V summarizes the outcome of training a Gaussian kernel SVM using of batch annealed nonconvex approach (qSVMOpt), and training a neural network using a stochastic gradient approach (qNNOpt). The neural network replicates the structure of the state-of-the-art model (qRanker) [Spivak et al. 2009] with a single hidden layer with 5 units. We use a sigmoid loss for qNNOpt and a ramp loss for qSVMOpt. Clearly our methods achieve the best generalization results, mainly for small q values which are of great importance in practice. The performance gain is greater than 10%. We also mention that for qSVMOpt the computation time to solve for only one pair ( C , X  ) is about 41h while the neural network takes only 1h for 100 epochs. This illustrates the efficiency of the stochastic algorithm. We have proposed a batch approach suited for kernel machines and online learn-ing strategy for large datasets to tackle the nonconvex Neyman-Pearson classification problem. Experimental evaluations clearly illustrate the improvments achieved when dealing with the nonconvex NP problem. The stochastic gradient method was shown fast and interestingly efficient in generalization. The approach was extended succes-fully to solve the q -value optimization problem in mass spectrometry protein screening applications. Interesting perspectives concern the extension of the online approach to the kernel case or application of our NP solver to address the bipartite ranking problem [Cl  X  emenc  X on and Vayatis 2007].
 This appendix summarizes known results about the constrained optimization of non-convex functions. We consider the problem saddle point when there exists an open set x  X  V ( x )  X  R n such that The sufficiency result needs no additional assumption.

T HEOREM 1. If ( x , X  ) is a local saddle point (15) then x is a feasible local minimum of (14) .
 setting  X  = 0 gives  X  i g i ( x )  X  0. Therefore  X  i g i ( x ) = 0. Combining with inequality g ( y ) . Therefore x is a local minimum of problem (14).
 Necessity results are more complicated because they involve delicate aspects of the Karush-Kuhn-Tucker (KKT) theory. But it is important to note that convexity is not required to establish that the KKT conditions are necessary:
T HEOREM 2. [C IARLET 1989] . Let x be a local minimum of problem (14) and let I = { The Neyman-Pearson problem involves a single inequality constraint that is trivially KKT-qualified via the linear independence constraint qualification criterion. On the other hand, this theorem does not apply when we use the ramp loss because the minimum is likely to be achieved on a nondifferentiable point. But even in that case, Theorem 1 ensures that any saddle point discovered by our algorithms is a feasible local minimum.

We now consider problem (14) with a single inequality constraint grangian for the fixed values  X  and  X  . We can assume that our local minima satisfy the following inequalities.
 Assume, for instance, that the first, inequality preceding is not satisfied. This would minimum instead of the inferior one.

T HEOREM 3. Consider a family of local minima { x  X   X  :  X   X   X  R  X  + } satisfying the respectively nondecreasing and nonincreasing functions of  X  .

P ROOF . The inequalities (16) can be rewritten as If than the upper bound. Therefore g ( x  X   X  )  X  g ( x  X   X  )and f ( x  X   X  )  X  f ( x  X   X  ).
Therefore, under the assumption (16), the Uzawa algorithm (Algorithm 1) amounts to searching the correct Lagrange coefficient in the nonincreasing sequence  X  P fa ( f  X   X  ). above or below the correct value. Furthermore observe that assumption (16) can be realized by initializing each minimization with the local optimum obtained for the previous value of the Lagrange coefficient  X  .

