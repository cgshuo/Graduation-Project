 1. Introduction
Latent semantic indexing (LSI) has emerged as a competitive text retrieval technique ( Deerwester, Dum-approximation to the vector space representation of the database is computed ( Berry, Drmac, &amp; Jessup, by variability in word choice. It uses a truncated singular value decomposition (SVD) of the term X  X ocument matrix to estimate the structure in word usage across the documents. Retrieval is per-formed using the databases of singular values and vectors obtained from the truncated SVD, not on the original term X  X ocument matrix. Several experimental tests show that these statistically derived vectors are more robust indicators of meaning than individual terms ( Dumais, 1991 ). However, recent studies bands, Simon, &amp; Ding, 2001 ).

In addition, for large datasets the SVD computation may be too expensive to be carried out on conven-tional computers. Also, the dense data structure of the truncated SVD matrices poses a huge challenge for both disk and memory spaces of conventional computers ( Gao &amp; Zhang, 2003 ). These problems seem to cost and enhance retrieval accuracy. However, some of these reports do not provide convincing experimen-tal results on large inhomogeneous datasets.

In this paper, we construct a large inhomogeneous text dataset by merging three popular text datasets of moderate size. We then use a k -means clustering technique to partition the dataset into a few compactly structured datasets. The truncated SVD is performed on the clustered small datasets individually. Our experimental results show that the clustered SVD strategies may enhance the retrieval accuracy on large scale data collections and reduce the SVD computation time and storage space.

This paper is organized as follows. In Section 2 we review the truncated SVD concept on text data ma-experimental results and discussions. We summarize this paper in Section 5. 2. Singular value decomposition
A text document may be represented by the terms (words) it contains. A set of documents can be rep-resented by a term X  X ocument matrix. The entries (elements) of the term X  X ocument matrix are the occur-rences of each word in a particular document. Suppose we have m terms and n documents, we can construct an m  X  n term X  X ocument matrix as A =[ a ij ], where a ij denotes the frequency in which the term i occurs in the document j . Since every word does not normally appear in each document, the matrix A is usually sparse. It is estimated that, for typical term X  X ocument matrices, more than 99% of the entries may be zero. In practice, local and global weightings are applied to increase or decrease the importance A is factored into the product of three matrices using SVD ( Golub &amp; van Loan, 1989 )as m  X  m orthonormal dense matrix and V is an n  X  n orthonormal dense matrix, the decomposition (1) actu-ally consumes much more storage space than the original matrix A does.

LSI computes a low rank approximation to A using an truncated SVD ( Golub &amp; van Loan, 1989 ). Let k V
T (see Fig. 1 ). We let H as a new pseudoterm X  X ocument matrix with reduced dimension.

Several studies reported that LSI based on truncated SVD has been compared favorably with other datasets, the computing and storage costs associated with the truncated SVD representation may be pro-riorate if the document sets are large ( Husbands et al., 2001 ).

Several strategies have been proposed to deal with LSI on large datasets. Sparsification strategy is used
Unfortunately, the reports of both clustered and distributed SVD strategies are incomplete. The former ( Tang, 2003 ) does not use large inhomogeneous datasets for experiments and the results may not valid at all.

The idea used in this paper is similar to the clustered or distributed SVD strategies, but we propose some interesting retrieval strategies and conduct a detailed study with experimental tests on a large inhomoge-neous dataset. 3. Clustered dataset with SVD A large dataset can be divided into a few smaller ones, each contains data that are close in some sense.
This procedure is called clustering, which is a common operation in data mining. In information and text cover obscured words in sets of unstructured text documents.
 documents in that cluster. An ideal cluster contains homogeneous documents that are relevant to each other. 3.1. Document clustering
First we use the k -means algorithm to partition a large collection of documents into s subsets of tightly structured documents. Let the set of document vectors be where a i is the i th document in the collection. We would like to partition the documents into s sub-collections f p i g s i  X  1 such that
For each fixed 1 6 j 6 s , the centroid vector of each cluster is defined as where n j = j p j j is the number of documents in p j . We normalize the centroid vectors such that
An intuitive definition of the clusters is that, if then and each cluster is compact enough, the centroid vector may represent the abstract concept of the cluster. 3.2. Query strategy on clustered database After clustering the original document collection, we have We also obtain the centroid vectors of each clusters:
Given a query vector q , we can find the closest matching clusters by computing and comparing the cosine values (similarity measures) between the query vector and the centroid vectors
We may retrieve the closest matching documents by computing and comparing all or part of base. The problems associated with querying the original document collection, such as polysemy and syn-onymy, will still persist.

To have better retrieval accuracy, we apply the LSI technique with truncated SVD on each individual cluster. In this way, either we query all or part of the cluster list, the truncated SVD encoded document sets are different from the original dataset. 3.3. Three strategies for retrieval 3.3.1. Non-clustered retrieval (NC + SVD) 3.3.2. Full clustered retrieval (FC + SVD)
After clustering the large dataset with a k -means algorithm, we need use SVD to approximate the matrix of the document vectors in each cluster. We sort the similarity measure of query to each document vector and return the documents which have the highest similarity measure (cosine values) in all documents. Since to expect that some documents may be misclassified. 3.3.3. Partial clustered retrieval (PC + SVD) set consists of where the centroid vectors of the p j s have the highest similarity values in q T C . 3.4. Computing and storage cost analysis 3.4.1. Computing cost of truncated SVD The cost of computing the truncated SVD of a sparse matrix A can be expressed as ( Berry, 1992 ) where I is the number of iterations required by a Lanczos-type procedure to approximate the eigensystem of A
A , and k is the rank of the truncated SVD. Here x is an arbitrary document vector. The dominant cost in (and A T ).
 SVD computation, that
To simplify the analysis, we assume that the number of iterations in the Lanczos-type procedure is the same for the large matrix and the partitioned matrices. Then we have
Note that the first two parts in the right-hand side of Eq. (3) are the corresponding cost associated with computing the truncated SVD of the two smaller matrices A 1 and A 2 .
 tered datasets is less than that of computing the truncated SVD on the combined large dataset. 3.4.2. Storage cost of clustered SVD
Let m and n be the number of terms and documents in the original dataset, respectively. Suppose there obvious that clustered subset. Based on our experience, we have k i 6 k for all i . In our experiments, we usually see P
The storage cost of the truncated SVD matrices of the original database is k ( m + n + 1) data values, and clustered subsets is
In a special case, we assume that the sizes of the clustered subsets are the same, the terms of individual have a rough idea on the approximate storage cost of the clustered SVD strategies, then we have
It follows that the storage cost of the truncated SVD on the clustered subsets is inversely quadratically truncated SVD on large scale datasets is a major disadvantage of the LSI technique, the clustered SVD strategies provide an attractive solution to reducing the storage cost. 4. Evaluation and results
To evaluate our clustered SVD strategies, we apply it to a large collective inhomogeneous database which consists of three popular document databases: CRAN, MED, and CISI. The large database collec-tion is generated by merging terms and documents of these three databases. The terms of the large database collection are obtained by adding up all terms of these three matrices. If a term occurs in more than one databases. The combined dataset is refereed to as the Merged DB. The queries used are the original queries provided with the three databases. Similar strategy was used in Dhillon and Modha (2001) to create a large inhomogeneous dataset. The database information is shown in Table 1 .

A standard way to evaluate the performance of an information retrieval system is to compute precision lated average precision where tegies for text retrieval based on their precision X  X ecall performance. 4.1. Experimental results without clustering
We first perform truncated SVD operation on the combined dataset Merged DB, and then compare the mance on the Merged DB, we choose SVD rank k = 300 (after some experiments). Fig. 2 shows the preci-sion X  X ecall results of the Merged DB and the individual datasets. The retrieval accuracy of the Merged DB is worse than that of the individual homogeneous datasets. The retrieval accuracy degradation is most se-vere for the dataset MED, and least significant for the dataset CRAN. 4.2. Experimental result with clustering 4.2.1. Full clustered SVD retrieval (FC + SVD) the low-rank approximation of each subset with SVD. Finally, we retrieve on all subsets and compute their from the SVD without clustering strategy. The former applies SVD on the individual (small) datasets (from the clustering), the latter on the whole (large) dataset.

To see how well the combined dataset represents the original three datasets, we partition the Merged DB into three clusters using the k -means algorithm. Table 2 shows the comparison between the computed sub-To test the performance of the strategy FC + SVD, we use the k -means algorithm to cluster the Merged of SVD is around 100. For the 64-cluster case, the best rank of the SVD of each cluster is 20. For each the 6-cluster solution yields the best performance. For the query set of CRAN, the 8-cluster solution is shown to be the best. 4.2.2. Partial clustered SVD retrieval (PC + SVD)
For this strategy, we only query part of the relevant clusters which contain most relevant documents. We the best precision ( Fig. 5 ). 4.3. Comparison of all strategies the rank of the truncated SVD is 100. With the FC + SVD strategy, we use a 4-cluster database for the query sets of MED and CISI, and a 8-cluster database for the query set of CRAN. In general, the retrieval precision of the FC + SVD strategy is better than that of the NC + SVD strategy. However, the retrieval precision of the PC + SVD strategy is seen to be the best in most cases.

It seems that the improvement from the clustered SVD strategies is more on the MED database than on the CISI and CRAN databases. This is probably because that MED is less homogeneous than CISI and CRAN (see Table 2 ). The queries associated with MED are also less homogeneous and they may mingle with some documents in CISI and CRAN. Thus, clustering helps MED restrict the influence from CISI and CRAN. On the other hand, CISI and CRAN are already highly homogeneous and their queries are also highly homogeneous and are not affected by the documents in MED. Additional clustering does not help very much. 4.4. Computing and storage costs
Table 4 lists the CPU time in seconds (on a SUN Ultra 10 workstation running at 500MHz with 128Mb memory under the MATLAB environment) and the storage cost in MB in computing the truncated SVD matrices in the non-clustered SVD (original database) and clustered SVD (4 clusters) strategies. It can be seen that both the computing and storage costs are reduced substantially in the clustered SVD strategy. 5. Summary
We merged three popular text retrieval databases to form a large inhomogeneous test dataset. We pro-posed to partition a large text dataset into a few tightly clustered subsets. We then performed truncated
SVD computation on the clustered datasets individually. Our experimental results confirm claims by other researchers that the retrieval accuracy of the LSI technique may deteriorate when retrieval on large size inhomogeneous datasets. We show that the accuracy of the LSI technique may be improved when retrieval clustered SVD matrices have the advantages of lower computing and storage costs, compared with the SVD matrices computed from the original large databases.

Like the classical LSI, there are some parameters that may affect the performance of a clustered SVD retrieval system. The most important parameters are the rank of the truncated SVD matrices and the num-ber of clusters chosen in the partial clustered SVD retrieval. How to determine the best rank of the trun-cated SVD matrices is an unsolved classical problem in LSI. The number of clusters chosen for a particular mined based on certain heuristics and experiments, which could be an interesting topic for future study. References
