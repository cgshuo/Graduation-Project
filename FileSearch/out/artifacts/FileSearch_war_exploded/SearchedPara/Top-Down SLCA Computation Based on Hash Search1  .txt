 Keyword search over XML data has attracted a lot of research efforts [1 X 3, 5 X 13] in the last decade, where a core problem is ho w to efficiently answer a given keyword query. Typically, an XML document can be modeled as a node-labeled tree T ,andfora given keyword query Q , lowest common ancestor (LCA) is the basis of existing XML keyword search semantics [5, 6, 10, 13], of which the most widely followed variant is smallest LCA (SLCA) [8, 10]. Each SLCA node v of Q on T satisfies that v is an LCA node of Q on T , and no other LCA node of Q can be v  X  X  descendant node. The meaning of SLCA semantics is straightforward, i.e., smaller trees contain more meaningfully related nodes.

To facilitate SLCA computation on XML data, existing methods [2, 8 X 12] usually assign to each node v a unique ID that is either node ID (underlined number in Fig. 1) that is compatible with the document order [12], or Dewey label [8, 10, 11], or its variant, such as JDewey [2] and IDDewey [9] (Dewey labels consisting of node ID). For simplicity, we do not differentiate a node, its ID and the corresponding IDDewey unless there is ambiguity. For example, when we say node 3, it denotes node x 2 in Fig. 1 with ID 3 and IDDewey label 1.2.3. Based on the adopted labeling scheme, inverted lists are built for all keywords for fast SLCA computation.

Table 1 shows the comparison of these algorithms, from which we have the follow-ing observations: (1) HS [9], LPSLCA [11] and FwdSLCA/BwdSLCA [12] are better than Stack [10], IL [10], IMS [8] and JDewe y [2] according to their time complexity; (2) Among HS [9], LPSLCA [11] and FwdSLCA/BwdSLCA [12], LPSLCA (Fwd-SLCA/BwdSLCA) needs to afford log | L m | (log | L ID m | ) cost to check whether a given node directly or indirectly contains a keyword by probing other inverted lists. On the contrary, the HS algorithm takes the shortest list L 1 as the working list and sequentially processes all IDDewey labels of L 1 . In each iteration, it picks from L 1 an IDDewey label l and checks whether nodes represented by IDs of l contain all keywords of the given query in their subtree. By mainta ining a hash mapping between each pair of node and keyword, the checking of whether a node contains a certain keyword in its subtree becomes a hash search, instead of probing other inverted list. Therefore, HS removes much redundant computations when the number of results is much less than the length of the shortest inverted list, no matter the shortest inverted list is short or long, as shown by the following example.
 Ta b l e 1 . Worst case time complexities of different algorithms on SLCA computation, Dewey/JDewey/IDDewey labels, | L ID 1 | ( | L ID m | ) is the number of distinct node IDs in the shortest (longest) inverted IDDewey label list.
 Example 1. Consider processing Q = { a, b } on D in Fig. 1. As | L a | = 200 &lt; | L b | = 1000 , the HS algorithm takes L a as the working list. In each iteration, it sequentially picks an IDDewey label l from L a , and processes all node IDs of l to compute a can-didate SLCA node by probing the hash table. For this query, HS needs to check, for each label of a 1 to a 100 , whether node 2 and node 3 contain keyword b in their sub-trees by probing the hash table; similarl y, HS needs to check, for each label of a 101 to a 200 , whether node 105 and node 106 contain keyword b in their subtrees. Even though there are only two qualified SLCA nodes, i.e., x 1 (node 2) and x 3 (node 105), after processing this query, HS probes the hash table 400 times, which is unnecessary and time-consuming in practice.
 The main reason for the redundancy problem of HS lies in that it processes each ID-Dewey label individually, without noticing that some IDs are repeatedly appearing in many different IDDewey labels in the same in verted IDDewey label list. For example, consider query Q = { a, b } again. In L a of Fig. 1, node a 1 to a 100 share three IDs, i.e., 1,2 and 3, and node a 101 to a 200 share three IDs, i.e., 1, 105 and 106. Even though it does not need to check whether node 1 contains b by using binary search on each
L
L IDDewey label, it needs to repeatedly ch eck the satisfiability of node 2, 3, 105 and 106 for 100 times, respectively.
 To realize fine-grained optimization , we propose an efficient algorithm, namely TDHS, that computes all candidate SLCA nodes in a top-down manner to accelerate the SLCA computation. Intuitively, our method takes all nodes in the set of inverted IDDewey label lists as leaf nodes of an XML tree T , and checks whether it contains all keywords of the given query. The  X  X op-down X  processing strategy means that if T contains all keywords, T must contain at least one SLCA node, we then remove the root node of T and get a forest F T = { T 1 ,T 2 , ..., T n } of subtrees corresponding to the set of child nodes of T  X  X  root node. Based on F T , we check whether each subtree contains all keywords. If no subtree in F T contains all keywords, it means that T is a smallest tree that contains all keywords, then we directly output T  X  X  root node as an SLCA node; otherwise, for each subtree in F T that contains all keywords, we just need to recursively compute its subtree set until no subtree in a subtree set contains all keywords.
To check whether there exists some subtrees of T that contain all keywords, our method records in a hash table H , for each pair of node v and keyword k , the number of occurrence of k in the subtree rooted at v , as shown in Fig. 1. During processing, our method takes the shortest inverted IDDewey label list L 1 (corresponding to k 1 )as the working list, and checks whe ther a node represented by each distinct node ID is a qualified SLCA node, rather than repeatedly processing an ID as HS does when it is contained by many IDDewey labels. Sp ecifically, Our method computes all common ancestor ( CA ) nodes in a top-down way. After processing a node v , it firstly gets the number of occurrence of k 1 in subtree T v by one probe operation on the hash table, then skips all IDDewey labels that contain v  X  X  ID to get its next sibling node. Therefore, our method avoids the redundant probe operations on the hash table, and achieves the worst-case time complexity of O ( m  X | L ID 1 | ) ,where | L ID 1 | is the number of distinct node IDs in the shortest inverted IDDewey label list for a given keyword query. Example 2. Continue Example 1. To process query Q = { a, b } on the XML document in Fig. 1, our method takes L a as the working list and computes CA nodes in a top-down way. It firstly checks whether node x 1 is a CA node by probing the hash table one time, then checks whether x 1  X  X  child node, i.e., x 2 , is a CA node by another probe operation on H .Since x 2 is not a CA node, we directly skip all IDDewey labels containing 3 ( x 2  X  X  ID) by the third probe operation on H .As x 2 does not have a sibling node, the processing of x 1 stops and we output x 1 as an SLCA node. Similarly, we just need to afford three probe operations on H to process x 3 and x 4 , and output x 3 as an SLCA node. As a comparison, to process Q , our method just needs to probe H 6 times, while HS needs 400 probe operations on H .
 The rest of the paper is organized as follows. In Section 2, we introduce background knowledge. We introduce our TDHS algorithm in Section 3. In Section 4, we present the experimental results, and conclude our paper in Section 5. 2.1 Data Model We model an XML document as a node-labeled tree, where nodes represent elements or attributes, while edges represent direct nesting relationship between nodes in the tree. If akeyword k appears in the node name or attribute name, or k appears in the text value of v ,wesay v directly contains k . Fig. 1 is a sample XML document.
 The positional relationships between two nodes include Document Order (  X  d ) , Equivalence (=), AD ( ancestor-descendant,  X  a ), PC (parent-child,  X  p ), Ancestor-or-self ( a ) and Sibling relationship. u  X  d v means that u is located before v in document order, u  X  a v means that u is an ancestor node of v , u  X  p v denotes that u is the parent node of v .If u and v represent the same node, we have u = v , and both u d v and u a v hold. 2.2 Query Semantics For a given query Q = { k 1 ,k 2 , ..., k m } and an XML document D , inverted lists are often built to record which nodes directly contain which keywords. We use L i to denote the inverted list of k i , of which all nodes are sorted in document order. Let common ancestor (LCA) of all nodes in S .

The LCAs of Q on D are defined as LCA ( Q )= LCA ( L 1 ,L 2 , ..., L m )= { v | v = Fig. 1 include r , x 1 and x 3 . Compared with LCA, SLCA [8, 10] defines a subset of LCA ( Q ) , of which no LCA in the subset is an ancestor of any other LCA, which can be formally defined as SLCA ( Q )= { v | v  X  LCA ( Q ) and v  X  LCA ( Q ) , such that v  X  a v } .InFig.1, although r is an LCA node, r is an ancestor of x 1 and x 3 , thus the set of SLCAs for Q = { a, b } on D in Fig. 1 are x 1 and x 3 .

For SLCA computation, researchers have proposed many algorithms [2,8 X 12], which have been discussed in Section 1. 3.1 Data Organization We assign to each node an ID that equals to its visiting order when traversing the XML document in deep-first order, as shown by the italics numbers in Fig. 1, based on which we construct two kinds of indexes.

The first index is an inverted list L of IDDewey labels for each keyword k ,where each IDDewey label l  X  L represents a node v that directly contains k , l consists of node IDs corresponding to all nodes on the path from the document root to v . E.g., L a and L b in Fig. 1 are the two inverted IDDewey label lists of keyword a and b , respectively.
The second index is a hash table, which records, for each pair of node v and keyword k , the number of occurrence of k in the subtree rooted at v ,whichisshownbythe  X  X ount X  value. H in Fig. 1 shows partial content of the hash table, from which we know that there are 100 occurrence of keyword a in the subtree rooted at node 2 by using  X  (2 ,a )  X  as a key to probe H , which can be denoted as 100 = H [(2 ,a )] ;onthe contrary, using  X  (3 ,b )  X  as a key to probe H , we know that the subtree rooted at node 3 does not contain keyword b , which can be denoted as (3 ,b )  X  H . 3.2 The TDHS Algorithm For a given query Q = { k 1 ,k 2 , ..., k m } , we always assume that 0 &lt; | L 1 | X | L 2 | X  ...  X | L m | , the case where at least one IDDewey label list is empty can be easily processed before line 1. We omit it for simplicity. As shown by Algorithm 1, our method takes the shortest inverted IDDewey label list L 1 as the working list, which is associated with a  X  cursor  X  pointing to some IDDewey label of L 1 .Let l be the i th IDDewey label of L 1 , id v the j th ID of l denoting node v ,wehave l = L 1 [ i ] , id v = l [ j ] and id v = L 1 [ i ][ j ] . In the following discussion, we use and | L 1 | the number of IDDewey labels of L 1 .

We u s e T to denote a subtree rooted at a certain node. T.root represents the IDDewey label of the root node of T , T.start ( T.end ) denotes, in L 1 , the position of an IDDewey label, which corresponds to the first (last) node in T that directly contains k 1 .Asshown by Algorithm 1, initially, we set node 1 as the root node of T (line 1), and all nodes of L 1 as leaf nodes of T (line 2 and 3). In line 4, we recursively process T by calling procedure processSubTree ( T ) .

In line 5 to 17, we recursively process subtree T and output T.root as an SLCA node if no child node of T.root is a CA node. In line 5, we set flag with default value  X  X RUE X  to denote that T.root is an SLCA node. In line 6 to 7, we make  X  cursor  X  point to the first IDDewey label of L 1 , such that the length of L 1 [ cursor ] is greater than that of T.root . In line 8 to 16, we repeatedly check whether each child node of T.root is a CA node. In each iteration, we get the ID id v corresponding to a child node v of T.root in line 9, then we check whether node v is a CA node in line 10. If function isCA ( id v ) returns TRUE, it means that v is a CA node, which also means that T.root is not an SLCA, thus we set flag with the  X  X ALSE X  value (line 11). In line 12, we get the subtree T rooted at v , and recursively process T in line 13. If function isCA ( id v ) returns FALSE in line 10, we firstly get the number of occurrence of k 1 in the subtree rooted at v in line 15, then skip all IDDewey labels containing id v in line 16. After processing all child nodes of T.root , in line 17, if flag = TRUE, it means that no one of T.root  X  X  child nodes is a CA node, then we directly output T.root as a qualified SLCA node.

In line 18 to 22, to get the subtree T rooted at v , we firstly get the number of oc-currence of k 1 in T by probing the hash table H using ( id v ,k 1 ) (line 18), then set the IDDewey of v as T.root .id v in line 19, where T.root is the IDDewey of v  X  X  parent node. In line 20, we set the value of T .start ( T .end ) , which corresponds to the first (last) node in T that directly contains k 1 .

In line 23 to 25, we check whether a given node v is a CA node, which needs to repeatedly check, in line 23 to 24, whether k i ( i&gt; 1) appears in the subtree rooted at v by using ( id v ,k i ) as the key to probe the hash table H at most m  X  1 times. Example 3. Consider processing query Q = { a, b } on the XML document in Fig. 1, Algorithm 1 takes L a as the working list. As node r is the document root node, our method recursively finds child CA nodes of node r . The first CA node found by our method is x 1 by using (2 ,b ) as the key to probe the hash table. After that, our method checks whether x 2 is a CA node, which can be done by another probe operation on the hash table using (3 ,b ) to find whether there are occurrence of b in the subtree rooted at x 2 .Since (3 ,b ) does not appear in the hash table in Fig. 1, x 2 is not a CA node, our method skips all IDDewey labels containing 3 to find x 2  X  X  next sibling node. Note that the number of skipped nodes equals to the number of occurrence of keyword a in the subtree rooted at x 2 , which is 100 and can be found by another probe operation on the hash table using (3 ,a ) .As x 2 does not have other sibling nodes, the skipping operation moves the  X  cursor  X  to the IDDewey of a 101 , and the processing of x 1 is stopped, then x 1 is outputted as an SLCA node. The following processing is similar, our method needs to check the satisfiability of x 3 and x 4 . For each one of them, we need to use one probe operation to check whether it is a CA node, and another probe operation for x 4 to skip IDDewey labels containing 106. In summary, to process Q = { a, b } , our method needs skipping useless IDDewey labels by probing the hash table two times. The total number of probe operations invoked by our method is 6 .
 Now we analyze the complexity of TDHS. Assume that for a given query Q = { k 1 ,k 2 , ..., k m During processing, our method takes the shortest inverted IDDewey label list L 1 (cor-responding to k 1 ) as the working list, and checks w hether a node represented by each distinct node ID is a CA node, rather than repeatedly processing an ID as HS does when it is contained by many IDDewey labels. Therefore, the total number of processed node IDs equals to the number of distinct IDs in all IDDewey labels of L 1 , which is de-noted by L ID 1 . For each ID id v corresponding to node v , we need at most m  X  1 probe operations to check whether v is a CA node, and at most one probe operation to skip IDDewey labels containing id v . That is, for each id v , our method needs at most m probe operations on the hash table H . Therefore, the worst-case time complexity of our method is O ( m  X | L ID 1 | ) .

Algorithm 1. TDHS( Q )/* Q = { k 1 ,k 2 , ..., k m } , 0 &lt; | L 1 | X | L 2 | X  ...  X | L m | */ 4.1 Experimental Setup Our experiments were implemented on a PC with Intel(R) Core(TM) i5 M460 2.53GHz CPU, 2 GB memory, and Windows 7 as the operating system. The algorithms used for comparison include the IL [10], IMS [8], JDewey [2], LPSLCA [11], FwdSLCA [12] and HS [9] algorithms. All algorithms were implemented using Microsoft VC++, all results are the average time by ex ecuting each algorithm 1000 times on hot cache. We did not make comparison with Stack [10] because Stack has been verified not as efficient as other existing methods [8 X 12].

We used XMark (582MB) dataset for our experiment. We have selected 30 key-words classified into three categories accord ing to their occurrence frequencies (i.e. | L (10000-40000), (3) high frequency (300000-600000). Based on these keywords, we Dewey/JDewey/IDDewey is for IL, IMS, JDewey and LPSLCA; Node ID is for Fwd-SLCA, while IDDewey+Hash Table is for HS and TDHS.
 Ta b l e 3 . Queries on 582MB XMark dataset, | L min | denotes the length of the shortest IDDewey label list for a query, N S is the number of qualified SLCA results, R S = N 4.2 Performance Comparison and Analysis For a given query, we define the result selectivity as the size of the results over the size of the shortest inverted list. The metrics for evaluating these algorithms include: (1) running time, and (2) number of probe operations on the hash table, which is only used for the HS and TDHS algorithms. The reason we use the second metric is that for all compared algorithms, only HS and TDHS are b ased hash search, which do not need the comparison operation between IDDewey lab els. For other algorithms, we only compare their running time.

Fig. 2 shows the running time of different algorithms for query QX1 to QX18. Ta-ble 5 shows the number of probe operations of HS and our TDHS algorithms on the hash table for these queries, which can be used to facilitate the understanding of the performance difference between HS and T DHS. From Fig. 2 and Table 5, we have the following observations. (1) our method outperforms the HS algorithm for most of these queries. The reason lies in that for each distinct ID in IDDewey labels o f the shortest inverted IDDewey label list, our method processes it without redundant probe operations on the hash table, which is further verified by Table 5. E.g., for query QX2, QX4, QX6, QX11, QX12, QX15 QX16, QX17 and QX18, the number of probe operations invoked by our method is much less than that of the HS algorithm. For query QX11 and QX12, our method outperforms HS by up to two orders of magnitude. The lower the selectivity, the more benefits can be brought by our method. (2) compared with LPSLCA and FwdSLCA, our method can work better than them for many queries, such as QX2 to QX4, QX10 to QX12, and QX14 to QX18, this is because when checking wether a node is a CA node, our method does not need to probe other inverted lists based on binary search, instead, we simplify this operation with a simple hash search, which can be done more efficiently. Even though, our method suffers from inflexibility when compared with these two algorithms, such as QX5. The reason lies in that our method takes the shortest inverted IDDewey list as the working list, and it needs to verify the satisfiability of CA node fo r IDs of IDDewey labels in this list. As a comparison, LPSLCA and FwdSLCA may skip more useless IDs by using IDs of other lists to probe the shortest list. (3) our method is much more efficient than IL, IMS and JDewey, because our method only processes IDs of the shortest inverted list, while IL, IMS and JDewey need to make repeatedly comparison between Dewey labels to check their positional relationships and compute their LCA node, which is costly in practice.
 Besides the above observations, for existing methods, we have the follow results: (1) IL could perform better than IMS in some cases, such as QX1, QX3, QX4, QX11, QX13 Ta b l e 5 . Comparison of the number of probe operations on hash table, where N ID L min is the number of IDs in all IDDewey label of the shortest inverted list, while N DistID L min is the number of distinct IDs in all IDDewey labels of the shortest list.
 and QX16, but the performance gain is usually much less than that of IMS on IL, such as QX5, QX6, QX14 and especially QX12, b ecause for these queries, the set of Dewey label lists for each one has different keyword distributions, and IL is not as flexible as IMS on utilizing various keyword distributions to accelerate the computation. (2) JDewey is usually beaten by IL and IMS, especially for queries with Dewey label lists having huge difference on their lengths, such as QX11, and QX13 to QX18, this is because JDewey needs to process all lists of each level from the leaf to the root; and for all lists of each level, after finding the s et of common nodes, it needs to recursively delete all ancestor nodes in all lists of higher levels, which is very expensive in practice. (3) LPSLCA and FwdSLCA outperform HS for m any queries, because HS suffers form much redundant probe operations on hash table. Besides, all LPSLCA, FwdSLCA and HS are much better than IL and IMS, the reason lies in that LPSLCA, FwdSLCA and HS do not need to repeatedly check the positional relationships and compute LCA node for two Dewey labels.
 Besides the 18 queries in Table 3, we ra ndomly generated 174406 queries with 2, 3, 4 and 5 keywords based on the 30 keywords of Table 2, which contains all possible combinations of these keywords, that is, 174406 = C 2 30 + C 3 30 + C 4 30 + C 5 30 . Based on these random queries, we record their average running time based on different result selectivities, which provides us a way to b etter understand different algorithms. Fig. 3 shows the impacts of result selectiv ity on performance of these algorithms. Again, from the four figures in Fig. 3 we know that the average performance of our TDHS algorithm is better than other existing methods, the more keywords involved in a given query, the more benefits can be got by our method. Compared with the HS algorithm, our method performs much better when the result selectivity is low. Com-paredwithIL,IMS,LPSLCAandFwdSLCA,t he performance gain increases when the number of keywords involved in a query increases.

Note that in Fig. 3 (A) and (B), with the increase of the result selectivity, the average time used by all methods for result selectivity in [40,100] is less than that in [30,40), which can be explained by Fig. 4, where for queries with 2 and 3 keywords, the number of results decreases with the change of result selectivity from [30,40) to [40,100], which means that the performance of all algorithms is also affected by the number of results.
We shown the scalability from two aspects based on Fig. 3: (1) fixing the number of keywords and varying the result selectivity, which is just explained in the previous paragraphs, (2) fixing the result selectivity and varying the number of keywords, which can be got from the four sub-figures of Fig. 3 and is omitted by limited space. The general trend can be stated as: the performance of IL, IMS, JDewey, LPSLCA and FwdSLCA will be better with the increase of the number of k eywords, this is becau se the performance of IL, IMS, JDewey, LPSLCA and FwdSLCA can utilize the positional relationships between keyword nodes to skip useless nodes, the more keywords involved, the more possibility for these algorithms to make optimization. Compared with IL, IMS, JDewey, LPSLCA and FwdSLCA, HS can work better with the increase of result selectivity and the number of processed keywords in a given query. Compared with HS, our TDHS al-gorithm can work better when the result selectivity is low.
Further, we shown in Fig. 5 the scalability when executing Q10 on XMark dataset from 116MB to 1745MB (15x). The query time of these algorithms grows sublinearly with the increase of the data size. Also, the query time for TDHS is consistently about 30 times faster than IL, 9 times faster than IMS, 40 times faster than JDweey, 2.5 times faster than LPSLCA, 2 times faster than Fw dSLCA and 2.3 times faster than HS. For other queries, we have similar results, which are omitted due to space limit. In this paper, we proposed an efficient algorithm, namely TDHS, that computes all qualified SLCA nodes in a top-down way based on hash search . Our method records in a hash table H , for each pair of node v and keyword k , the number of occurrence of k in the subtree rooted at v . During processing, our method takes the shortest inverted IDDewey label list L 1 as the working list, and checks whether a node represented by each distinct node ID id v is a qualified SLCA node, rather than repeatedly processing id v as HS does when it is contained by many IDDewey labels. As a result, our method avoids the redundant probe operations on the hash table, and achieves the worst-case time complexity of O ( m  X | L ID 1 | ) ,where | L ID 1 | is the number of distinct node IDs in L . Experimental results verify the perform ance advantages of our method according to various evaluation metrics.
 Acknowledgment. This research was partially supported by grants from the Natural Science Foundation of China (No. 61073060, 61040023, 61103139), the Fundamen-tal Research Funds of Hebei Province (No. 10963527D), and the Hebei Science and Technology research and development program (No. 11213578).

