 Traditional machine learning methods, such as Support Vec-tor Machines (SVMs), usually assume that training and test data share the same distributions. Due to the inherent dy-namic data nature, it is often observed that (1) the volumes of the training data may gradually grow; and (2) the existing and the newly arrived samples may be subject to different distributions or learning tasks. In this paper, we propose a Transfer Incremental Support Vector Machine(TrISVM), with the objective of tackling changes in data volumes and learning tasks at the same time. By using new updating rules to calculate the inverse matrix, TrISVM solves the ex-isting incremental learning problem more efficiently, espe-cially for high dimensional data. Furthermore, when using new samples to update the existing models, TrISVM em-ploys sample-based weight adjustment procedures to ensure that the concept transferring between auxiliary and target samples can be leveraged to fulfill the transfer learning goal. Experimental results on real-world data sets demonstrate that TrISVM achieves better efficiency and prediction accu-racy than both incremental-learning and transfer-learning based methods. In addition, the results also show that TrISVM is able to achieve bidirectional knowledge transfer between two similar tasks.
 I.5.4 [ Pattern Recognition ]: Applications X  computer vi-sion, text processing Algorithms  X  Corresponding author.
 Machine learning, support vector machines, incremental learn-ing, transfer learning
As our data-gathering ability continuously grows, scaling up to large volume data has become increasingly impor-tant for many applications which rely on machine learning techniques for rapid prediction and decision making. To handle data with changing volumes, a common approach is to develop some incremental/decremental learning mech-anisms [1]. Many methods exist, which use mechanisms such as proximal SVM [5], to enable the incremental learn-ing functionality. While existing incremental learning re-searches have significantly advanced the techniques and so-lutions, most of them assume that existing training data and the newly arrived data are under the same distribution, so the main focus is to use new samples to update the exist-ing models. Notice that in a dynamic environment, such a same-distribution assumption may rarely be the case. It is possible that the distributions of the existing training data are largely different from the newly arrived samples. In addi-tion, it is also possible that the learning tasks of the two sets of samples are closely related, but not identical. So an incre-mental learning method is supposed to take such dynamic data nature into consideration to transfer old knowledge into the new data (or tasks).

When data are experiencing changing distributions or learn-ing tasks, one simple solution is to abandon historical data and label enough new instances which are able to describe new concepts or new data distributions. Such a forgetting-and-relearning approach, in practice, suffers at least two dis-advantages: (1) labeling instances is a labor-intensive and costly process, and (2) historical data may contain rich in-formation to benefit the learning of the current tasks.
To simulate the generalization ability of human brain [7], transfer learning methods often use some labeled data from different tasks as auxiliary data to assist the learning of the current learning tasks. Many transfer methods exist [6], including lifelong learning [10], multi-task learning [3], etc.
The above observation implies that, incremental learning is mainly developed to handle data with increasing volumes, whereas transfer learning mainly focuses on the change of the data distributions or learning tasks. Neither of them, however, is developed with the objective of dealing with data with changing volumes and sample distributions. In this paper, we propose a transfer incremental support vector machine (TrISVM) to enable the transfer learning function-ality for an incremental learner [4, 5]. Experimental results on real-world text and image data demonstrate that TrISVM achieves faster convergence and higher prediction accuracy than its other peers. In addition, TrISVM is also able to transfer knowledge between similar learning tasks. PSVM is a simple yet effective SVM classifier [4]. Assume X =[ x 1 ,x 2 , ..., x n ]  X  X  m  X  n is the instance matrix consist-ing of n instances. The column vector L is used to assign a class label { +1 ,  X  1 } for each instance. The column vector of ones in an n -dimensional space is denoted by e . Finally, the classifier of PSVM is described as follows  X  =(  X I + ZZ T )  X  1 ZL =(  X I + A )  X  1 ZL =  X  A  X  1 ZL, (1) where, Z =[ X ;  X  e ]( z =[ x T ,  X  1] T  X  Z ).

To enable incremental learning for PSVM, Fung [5] pro-posed an ISVM approach with the weight  X  updated by where z i is a column vector denoting the new (extended) instance, and l i  X  L represents the label of z i .
Note that, ISVM needs to directly invert the matrix (  X  A + z i ) as defined in Eq.(2), which makes ISVM ineffective for large size matrix (  X  A + z i z T i ).
To make ISVM effective and efficient for dynamic data, two fundamental challenges include the tackling of the in-creasing size of the data and the dynamic changing of the data distributions. The former is solved by reconstructing Sherman-Morrison formula [2] and for the latter, we use an instance-level weighting mechanism.
For original ISVM algorithm, it has to solve a matrix in-verse as defined by Eq.(2), which makes it inefficient for high dimensional data. This problem is solved by using the Sherman-Morrison formula, In dynamic data environments, however, the sample dis-tribution may continuously change and the current A  X  1 in Eq.(3) may not be appropriate for prediction. To solve the problem, we extend Eq.(3) and employ an instance weight-ing as well as a feedback mechanism to accommodate and capture the changing underneath the data.

Formally, we consider that training data Z consists of two parts: different-distribution (auxiliary) data D =[ d 1 ,d ] and same-distribution (target) data S =[ s 1 ,s 2 ,  X  X  X  ,s
According to Eq.(1), all data in Z should be used to cal-culate parameter  X  . To enable incremental learning, we ini-tially set training data Z  X  D .So A equals ZZ T which is further regularized by adding the term  X I .Afterthat, the target data s i  X  S, ( i =1 ,  X  X  X  ,t ), is incrementally in-cluded, one by one like Eq.(2), into the training set Z for adjusting  X  . To handle a new instance s i +1 , the matrix Z is extended as [ D,s 1 ,  X  X  X  ,s i ] with all instances in the current Z
T adjusted by left multiplying a diagonal weight matrix  X  is formulated in Eqs.(4) to (7). Similar to Eq.(3), to invert B + Z  X  Z T = s i s T i +  X I + Z X  T  X Z T ,wehave, where B = s i s T i +  X I ,  X  is the diagonal matrix (  X  T accounts for the instance weight, Y = B  X  1 Z ,and
For our problem, the changes in Eqs.(4) and (5) arise from the continuous inclusion of the instance in the form of s Since the test data are assumed to have different distribu-tions from the auxiliary data in Z , the instance weight  X  needs to be adjusted accordingly. When adding the current the parameter  X  is derived and updated as follows,  X  =( B + Z  X  Z T )  X  1 ( Z  X  L + s i l i ) where Y = B  X  1 Z , G = Y T Z , M = X   X  1 + G ,  X  = X  L and  X  = B  X  1 s i l i which are all intermedium variables. Based on Eq.(5), the update of Y , G and  X  are simplified as Since  X  is a diagonal matrix,  X  j is equal to  X  jj l j .
To achieve the transfer learning, we first normalize all instances such that the L 2 norm of each instance vector is equal to 1. Then, we adjust the weight matrix  X , with the initial values given in Eq.(8) where I is the unit matrix, During the weight updating process,  X  is adjusted by using the feedback mechanism based on the prediction errors on the instance matrix Z . Formally, this updating process is formulated in Eq.(9), where P ( z j ) is the predicted label of the instance z j , with the label set denoted by { +1 ,  X 
In Eq.(9),  X  i is given in Eq.(10)
To smooth the diagonal matrix  X , we adjust the weight by using Eq.(11) Algorithm 1 lists the detailed procedures of the TrISVM. Algorithm 1 Pseudocode of TrISVM algorithm Input: Auxiliary data &lt;D, L D &gt; , target data Output: Prediction accuracy based on  X  . 1: t  X  TargetInstanceNumber(S); m  X  FeatureSize(S); 2: Z  X  D ; L  X  L D ; 3:  X   X  Initialization using Eq.(1); 4: for i =1to t do 5: if i&gt; 1 then 6: Extend Z and L to include the ( i  X  1) th (  X .e. the 7: end if 8:  X   X  Updating using Eqs.(8) to (11); 9: Y , G , M ,  X  and  X   X  Updating using Eq.(7); 10:  X   X  Updating using Eq.(6). 11: end for
Note that, when the number of training instances is smaller than that of dimensions, TrISVM transforms the inverse of m  X  m matrices into the n  X  n ones. Consequently, TrISVM is more efficient than ISVM for high dimensional data.
In this section, TrISVM is compared with an incremental method ISVM [4] and a transfer algorithm TrAdaBoost [11]. These methods are implemented by using Matlab 6.5 on a PC with a 2.00 GHz CPU and 1.00 GB memory. Finally, the learning efficiency and prediction accuracy are reported.
Our test bed consists of two real-world data sets including 20 News Group (20NG) [8] and USPS image data [9]. Their domain information is briefly summarized as follows. Table 1: Data from 20NG for transfer learning.
 20NG data sets are reassigned like that in [11]. In Table 1, the symbols + and  X  indicate the positive and negative instances, respectively. The original dimension number is 74000 and we select 4000 discriminative dimensions to re-duce the runtime.
 Figure 1: Samples for printed and hand-written dig-its.

USPS Digit data sets are collected from the US Postal Ser-vice (USPS) database. Each digit has a fixed size 28  X  28. To enable the transfer learning, we use printed digits as aux-iliary data to predict the hand-written digits. Fig.1 visually demonstrates the images. In our experiments, one thousand instances are produced for each printed digit. The test in-stances in the USPS data set are for target data. Because digit pair: 3 and 8 is visually similar, we choose this pair to compare the prediction performance of three methods.
In our experiments, the auxiliary data and target data are similar to each other. Therefore, the roles of them can be switched, and we also report the reverse (from target data to auxiliary ones) transfer learning results.
For fairness of the comparison, we use PSVM [4] as the basic learner for all methods and report average experimen-tal results of ten times on each data set. In each repetition, we randomly choose 500 instances from the auxiliary set and 100 instances from the target set for training, with the the rest target data for testing.

PSVM method has a free parameter  X  .Inthispaper, we set  X  = 1 for 20NG and  X  = 10 for USPS. In addition, because TrAdaBoost is a batch learning method, to compare three methods on the same basis, the number of iterations for TrAdaBoost is set to be the number of same-distribution training instances. Figure 2: Average runtime on 20NG 1and3&amp;8data sets.
Fig.2 reports the system runtime comparison on 20 NG 1 and 3&amp;8 pair. For ISVM and TrISVM, we incrementally include each target instance into the training process and record the system runtime. For TrAdaBoost, we use all 100 target instance to train a weak classifiers in each iteration, and record the system runtime with respect to the increasing number of iterations.

Fig.2 shows that all methods linearly scale up to the in-creasing size of the target instances. The results in Fig.2(a) assert that TrISVM is much more efficient than both ISVM and TrAdaBoost. On the other hand, the results in Fig.2(b) show that the runtime performance of TrISVM is inferior to ISVM, but is still more efficient than TrAdaBoost. Notice that 20 NG 1 data set has 4000 dimensions, whereas image pair data set has comparable feature ( m =28  X  28) and training set sizes ( n + t ). The above results clearly demon-strate the efficiency of the TrISVM over its other peers, es-pecially for high-dimensional data. (a) Transfer learning for 20NG 1 (c) R. transfer learning for 20NG 1 Figure 3: Average prediction accuracy on 20NG 1 and 3&amp;8 pair. Transfer learning from auxiliary data to target ones (a) 20NG 1, (b) 3&amp;8; The reverse transfer from target to auxiliary data (c) 20NG 1, (d) 3&amp;8.

In Figs.3 (a) and (b) we report the prediction accuracy on 20NG 1 and 3&amp;8. From the results, it is clear that the accuracy of TrISVM is always better than TrAdaBoost and ISVM, and the accuracy gain of TrISVM is particularly sig-nificant when only a very limited number of target instances are used for training. For most data sets we observed in our experiments, the results of TrAdaBoost are relatively poor in the beginning. After a sufficient number of iterations, the results of TrAdaBoost can pick up and eventually be comparable to TrISVM and ISVM most of times. This in-dicates that, compared to ISVM and TrAdaBoost, TrISVM is suitable for the transfer learning tasks where only a very limited number of training samples are available from the target domain.
 When comparing TrISVM with ISVM, we can find that TrISVM can not avoid negative transfer effect, which was also observed in the previous studies [3].

In Figs.3(c) and (d), we also report the reverse transfer learning results which indicate that the knowledge transfer between target and auxiliary data is largely bidirectional, as long as the two tasks are similar to each other.
In summary, the experimental results reported in this sec-tion indicate that TrISVM, with the help of the auxiliary data, achieves much better runtime performance, faster con-vergence speed and better prediction accuracy than its op-ponent ISVM and TrAdaBoost.
In this paper, we proposed a transfer learning based incre-mental learning model (TrISVM). We argued that existing researches on incremental learning have largely ignored the data dynamic nature and may not be suitable for the learn-ing environments where old samples and newly arrived data are subject to different distributions or changing learning tasks. To solve the problem, we proposed TrISVM which en-ables the transfer incremental learning for dynamic changing data environments. TrISVM employs an accelerated updat-ing process for incremental SVM so that it can be more efficient for model updating. In addition, TrISVM also em-ploys an instance level weighting approach to ensure that the incremental learning process can accommodate chang-ing data distributions and changing learning tasks for trans-fer learning. Experimental results on text and image data demonstrated that TrISVM can achieve faster convergence speed and higher prediction accuracies than an incremental non-transfer learning method (ISVM) and a non-incremental transfer learning method (TrAdaBoost). The results also in-dicated that TrISVM is able to achieve bidirectional knowl-edge transfer for two related learning tasks.
 This work was partially supported under Australian Re-search Council X  X  Discovery Projects funding scheme (project number DP1093762), and by National 973 Program (No. 2010CB327900), NSF of China under Grant (No. 60873178, No. 60875003, and No. 60674109), the National High Tech-nology Research and Development Program of China (No. 2009AA01A346). [1] G. Cauwenberghs, T. Poggio. Incremental and [2] M. Bartlett. An inverse matric adjustment arising in [3] R. Caruana. Multitask learning. Machine Learning , [4] G. Fung and O. Mangasarian. Proximal support [5] G. Fung and O. Mangasarian. Incremental support [6] P. S. Jialin and Y. Qiang. A survey on transfer [7] A. W. Kyoung and B. W.F. Psychological studies of [8] K. Lang. Newsweeder: Learning to filter netnews. In [9] Y. LeCun, L. Bottou, Y. B. P., and Haffner.
 [10] S. Thrun. Is learning the n -th thing any easier than [11] D. Wenyuan, Y. Qiang, X. Gui-Rong, and Y. Yong.
