 C.L. Wu, K.W. Chau n 1. Introduction operation and flooding prevention because it can provide an extension of lead-time of the flow forecast, larger than the response time of the watershed, in particular for small and medium-sized mountainous basins.
 response using conventional approaches in modeling rainfall time series is far from a trivial task since the hydrologic processes are complex and involve various inherently complex predictors such as geomorphologic and climatic factors, which are still not well understood. As such, the artificial neural network algorithm becomes an attractive inductive approach in rainfall prediction owing to their highly nonlinearity, flexibility and data-driven learning in building models without any prior knowledge about catchment behavior and flow processes. They are purely based on the information retrieved from the hydro-meteorological data and act as black box.

Many studies have been conducted for the quantitative precipi-tation forecast (QPF) using diverse techniques including numerical weather prediction (NWP) models and remote sensing observations ( Davolio et al., 2008 ; Diomede et al. 2008 ; Ganguly and Bras, 2003 ; Sheng et al., 2006 ; Yates et al., 2000 ), statistical models ( Chan and
Shi, 1999 ; Chu and He, 1995 ; DelSole and Shukla, 2002 ; Li and Zeng, 2008 ; Munot and Kumar, 2007 ; Nayagam et al., 2008 ), chaos-based approach ( Jayawardena and Lai, 1994 ), non-parametric nearest-neighbors method ( Toth et al., 2000 ), and soft computing-based methods including artificial neural networks (ANN), support vector regression (SVR) and fuzzy logic (FL) ( Brath et al., 2002 ; Dorum 2001 ; Sedki et al., 2009 ; Silverman and Dracup, 2000 ; Sivapragasam 2000 ; Venkatesan et al., 1997 ). The contemporary studies focused on soft computing-based methods. Several examples of such meth-ods can be mentioned. Venkatesan et al. (1997) employed the ANN to predict the all India summer monsoon rainfall with different meteorological parameters as model inputs. Chattopadhyay and
Chattopadhyay (2008a) constructed an ANN model to predict monsoon rainfall in India depending on the rainfall series alone. The fuzzy logic theory was applied to monthly rainfall prediction by Pongracz et al. (2001) . Toth et al. (2000) applied three time series models, auto-regressive moving average (ARMA), ANN and k-near-est-neighbors (KNN) method, to short-term rainfall prediction. The results showed that the ANN performed the best in the improve-ment of the runoff forecasting accuracy when the predicted rainfall wasusedasinputsoftherainfall -runoff model. ANN has also been applied on general circulation model (GCM). Chadwick et al. (2011) employed an artificial neural network approach to downscale GCM temperature and rainfall fields to regional model scale over Europe. Sachindra et al. (2011) developed a model with various soft computing techniques capable of statistically downscaling monthly GCM outputs to catchment scale monthly streamflows, accounting for the climate change.

Recently, models based on combining concepts have been paid more attention in hydrologic forecasting. Depending on different combination methods, combining models can be categorized into ensemble models and modular (or hybrid) models. The basic idea behind the ensemble models is to build several different or similar models for the same process and to combine them in a combining method ( Abrahart and See, 2002 ; Kim et al., 2006 ; Shamseldin et al., 1997 ; Shamseldin and O X  X onnor, 1999 ; Xiong et al., 2001 ). For example, Xiong et al. (2001) used a Takagi-Sugeno fuzzy technique to combine several conceptual rainfall-runoff models. Coulibaly et al. (2005) employed an improved weighted-average method to coalesce forecasted daily reservoir inflows from the KNN model, conceptual model and ANN model. Kim et al. (2006) investigated five combining methods for improv-ing ensemble streamflow prediction.

Physical processes in rainfall and/or runoff are generally com-posed of a number of sub-processes so that their accurate modeling by the building of a single global model is often not possible. Modular models are therefore proposed where sub-processes are first of all identified and then separate models (also called local or expert model) are established for each of them ( Solomatine and Ostfeld, 2008 ). In these modular models, the split of training data can be soft or crisp. The soft split means the dataset can be overlapped and the overall forecasting output is the weighted-average of each local model ( Shrestha and Solomatine, 2006 ; Zhang and Govindaraju, 2000 ; Wang et al., 2006 ; Wu et al., 2008 ). Zhang and Govindaraju (2000) examined the performance of modular networks in predicting monthly discharges based on the Bayesian concept. Wu et al. (2008) employed a distributed SVR for daily river stage prediction. On the contrary, there is no overlap of data in the crisp split and the final forecasting output is generated explicitly from one of the local models ( Corzo and Solomatine, 2007 ; Jain and Srinivasulu, 2006 ; See and Openshaw, 2000 ; Sivapragasam and Liong, 2005 ; Solomatine and Xue, 2004 ). Solomatine and Xue (2004) used M5 model trees and neural networks in a flood-forecasting problem. Sivapragasam and Liong (2005) divided the flow range into three regions, and employed different SVR models to predict daily flows in high, medium and low regions.

Apart from the adoption of the modular model, the improve-ment of predictions may be expected by suitable data preprocessing techniques. Besides the conventional rescaling or standardization of training data, preprocessing methods from the perspective of signal analysis are also crucial because rainfall time series may be also viewed as a quasi-periodic signal, which is contaminated by various noises. Hence techniques such as singular spectrum analysis (SSA) were recently introduced to hydrology field by some researchers ( Marques et al., 2006 ; Partal and Kis -i, 2007 ; Sivapragasam et al., 2001 ). Sivapragasam et al. (2001) established a hybrid model of support vector machine (SVM) and the SSA for rainfall and runoff predictions. The hybrid model resulted in a considerable improve-ment in the model performance in comparison with the original SVM model. The application of wavelet analysis to precipitation was undertaken by Partal and Kis -i (2007) . Their results indicated that the wavelet analysis was highly promising. In addition, the issue of lagged predictions in the ANN model was mentioned by some researchers ( Dawson and Wilby, 2001 ; Jain and Srinivasulu, 2004 ; De Vos and Rientjes, 2005 ; Muttil and Chau, 2006 ). A main reason on lagged predictions was the use of previous observed data as ANN inputs ( De Vos and Rientjes, 2005 ). An effective solution was to obtain new model inputs by moving average over the original data series.

The scope of this study was to investigate the effect of the MA and SSA as data-preprocessing techniques and to couple with modular models in improving model performance for rainfall prediction. The modular model included three local models which were associated with three crisp subsets (low-, medium-and high-intensity rainfall) clustered by fuzzy C-mean (FCM) method. The
ANN was first used to choose data-preprocessing method from MA and SSA. Depending on the selected data-preprocessing technique, modular models were employed to perform rainfall prediction.
Generally, the ANN is very efficient in processing large-size training samples due to its parallel information processing configuration.
The biggest drawback is that the model outputs are variable because of the random initialization of weights and biases. The SVR holds a good generalization and more stable model outputs.
However, it is suitable for a small-size training sample (e.g. below 200) because the training time exponentially increases with the size of training samples. For the current rainfall data, the majority of subsets after data split belong to a small-size sample except for the low-intensity daily rainfall. Therefore, three local SVRs (hereafter referred as to MSVR) were employed for monthly rainfall data whereas two local SVRs and one ANN (hereafter referred to as ANN-
SVR) were adopted for daily rainfall data. For daily rainfall record, the low-intensity subset was modeled by the ANN because it was overwhelming in the training data. For the comparison purpose, the global ANN and the persistence model were used as benchmarks.
To ensure generalization of this study, four cases consisting of two monthly rainfall series and two daily rainfall series from India and
China, were explored. 2. Methodology 2.1. Data-preprocessing techniques 2.1.1. Moving average (MA)
The moving average method smoothes data by replacing each data point with the average of the K neighboring data points, where K may be called the length of memory window. The basic idea behind the method is that any large irregular component at any point in time will exert a smaller effect if we average the point with its immediate neighbors ( Newbold et al., 2003 ). The most common moving average method is the unweighted moving average, in which each value of the data carries the same weight in the smoothing process. For time series { x 1 , x 2 , y (where t  X  K , y N ; x n t stands for the moving average value) when the backward moving mode is adopted ( Lee et al., 2000 ). The choice of the window length K is by a trial and error procedure to minimize the ANN prediction error. 2.1.2. Singular spectrum analysis (SSA)
The SSA is able to decompose the daily rainfall series into several additive components that typically can be interpreted as  X  X rend X  components, various  X  X scillatory X  components, and  X  X oise X  components ( Golyandina et al., 2001 ). The basic algorithm of the
SSA can be referred to Vautard et al. (1992) and Golyandina et al. (2001) . Following the methodology in Vautard et al. (1992) , four steps are performed for the explanation of the SSA algorithm on a the  X  X rajectory matrix X . The  X  X rajectory matrix X  results from the method of delays. In the method of delays, the coordinates of the phase space will approximate the dynamic of the system by using lagged copies of the time series. The  X  X rajectory matrix X , denoted by X , therefore reflects the evolution of the time series with a suitable choice of ( t , m ) window, where m is the window length (also called singular number) and t is the delay time.
Let S  X  X T X (called the lagged-covariance matrix). With SVD, X can be written as X  X  DLE T where D and E are left and right singular vectors of X , and L is a diagonal matrix of singular values.
E consists of orthonormal columns, and is also called the  X  X mpiri-cal orthonormal functions X  (EOFs). Substituting X into the defini-tion of S yields the formula of S  X  EL 2 E T . Further S  X  E K E
L 2  X  4 where 4 is a diagonal matrix consisting of ordered values 0 r l 1 r l 2 r y l m . Therefore, the right singular vectors of X are the eigenvectors of S . In other words, the singular vectors E and singular values of X can be respectively attained by calculating the eigenvectors and the square roots of the eigenvalues of S . by projecting the original time record onto the eigenvectors as follows: where e k j represents the jth component of the k th eigenvector.
Each principal component is a filtered process of the original series with length n , where n  X  N m  X  1.
 with the length size being the same as the original series. The generation of each RC depends on a convolution of one principal component with the corresponding singular vector ( Vautard et al., 1992 ). Therefore, The m RCs can be achieved if all m principal components and their associated eigenvectors are employed in the process of signal reconstruction. Also, the original record can be filtered by choosing p ( o m ) RCs. 2.2. Forecasting models 2.2.1. Persistence model future rainfall estimate, i.e. x F t  X  T  X  x t , for 8 T , where x observed record at instant time t , and x F t  X  T stands for the estimated rainfall at the lead-time T . For a modified version of the persistence model, each forecasted rainfall at the lead-time T equals to the mean value over the last T observations, given by x F t  X  T  X  P T i  X  1 x t i  X  1 = T . The modified version was adopted in this study. 2.2.2. Artificial neural networks
ANN paradigms is by far the most popular, which usually uses the technique of error back propagation to train the network config-uration. The architecture of the ANN consists of the number of hidden layers and the number of neurons in input layer, hidden layers and output layer. ANNs with one hidden layer are com-monly used in hydrologic modeling ( Dawson and Wilby, 2001 ; De
Vos and Rientjes, 2005 ) since these networks are considered to provide enough complexity to accurately simulate the nonlinear properties of the hydrologic process. A three-layer ANN is chosen for the current study, which comprises the input layer with m nodes (i.e., m past daily rainfall), the hidden layer with h nodes (neurons), and the output layer with one node. The hyperbolic tangent functions are used as transfer functions in the hidden layer and the output layer. The model architecture is described by the equation x t  X  T  X  f  X  X t , w , y , m , h  X  X  y 0  X  where x t i  X  1 , i  X  1, y , m is the m element in the input vector X are the weights defining the link between the ith node of the input layer and the jth of the hidden layer; y j are biases associated to the jth node of the hidden layer; w out j are the weights associated to the connection between the jth node of the hidden layer and the node of the output layer; and y 0 is the bias at the output node. The Levernberg-Marquardt (LM) training algorithm is used to adjust the w and y in view of being faster and less easily trapped in local minima compared with some local optimization methods ( Toth et al., 2000 ). 2.2.3. Support vector regression
SVR performs structural risk minimization (SRM) that aims at minimizing a bound on the generalization error ( Gunn, 1998 ;
Kecman, 2001 ; Yu et al., 2006 ; Wu et al., 2008 ). It creates a model with good generalization. The SVR can be divided into linear and nonlinear depending on the kernel function being linear or non-linear. A nonlinear SVR was used in this study. Similar to Eq. (1), the underlying function f ( ) in the context of the nonlinear SVR is given by x t  X  T  X  f  X  X t , o  X  X  o f  X  X t  X  X  b  X  3  X  where the input vector X t in the input space is mapped to a high dimensional feature space via a nonlinear mapping function f ( X t ). The objective of the SVR is to find optimal o , b and some parameters in kernel function f ( X t ) so as to construct an approximation function of the f ( ).

When introducing Vapnik X  X  e -insensitivity error or loss func-be defined as
L  X  y , f  X  X t , o  X  X  X  y f  X  X t , o  X  e where y represents observed value. The nonlinear SVR problem can be expressed as the following optimization problem ( Kecman, 2001 ; Yu et al., 2006 ) min imize R o , x subject to where X i represents X t for simplicity, the term of 1 2 : generalization, and the term of C P n risk. The objective in Eq. (5) is to minimize them simultaneously, which implements SVR to avoid underfitting and overfitting the training data. x i and x n i are slack variables for measurements  X  X  X bove X  X  and  X  X  X elow X  X  an e tube. Both slack variables are positive values. C is a positive constant that determines the degree of penalized loss when a training error occurs.

By introducing a dual set of Lagrange multipliers, a i and a n objective function in dual form can be represented as ( Gunn, 1998 ) maximize L d a , a n  X  e subject to
By using a  X  X  X ernel X  X  function K ( X i , X j )  X  ( f ( X i inner products in feature space, the computation in input space can be performed. In the present study, Gaussian radial basis function (RBF) was adopted in the form of K  X  X i , X j  X  X  exp  X  : Once parameters a i , a n i ,and b 0 are obtained, the final approximation function of the f ( )becomes f  X  X i  X  X  where X k stands for the support vector, a k and a n k are parameters associated with support vector X k , n and s represent the number of training samples and support vectors, respectively. Three para-meters ( C , e , s ) need to be optimized in order to identify the optimal f ( ) as Eq. (5). In the current study, a two-step genetic algorithm method was adopted for the optimization ( Wu et al., 2008 ). 2.2.4. Modular model
As described at the end of the introduction, the modular model consisted of three local models which were based on the crisp data split. The three models simulated three-type rainfall events, i.e., no (dry period) or low-intensity, medium-intensity, and high-intensity rainfalls (or storm events). The final output of the hybrid models was obtained directly from the output of a triggered local model. For daily rainfall simulation, the modular model was referred to as ANN-SVR, and the modular model was denoted as MSVR for monthly rainfall simulation. 2.3. Models coupled with MA or SSA
The combination of studied models (i.e. ANN or modular models) with MA was very simple where a new series was obtained by the moving average over the raw rainfall data and then the new series was used to construct the model inputs. On the other hand, the combination of studied models with the SSA was somewhat complex. The methodological procedures of the combination were summarized in the following steps:
First, the raw rainfall series was decomposed into m compo-nents by the SSA.

The cross-correlation functions (CCFs) between each RC and the raw rainfall series were computed. The mean CCF was then generated by averaging over all CCFs at the same lag.

The CCFs were sorted in a descending or ascending order depending on the mean CCF was negative or positive (e.g. An ascending order was adopted if the mean CCF is negative)
The sorted RCs were filtered by systematically deleting the RCs where all m RCs were originally remained and only the first RC was left in the end. A new series was constituted by summing the remaining RCs each time. The new series was used to construct model inputs. Repeating the filtering operation, the optimal RCs can be attained, which was associated with the optimal model performance. 2.4. Evaluation of model performances
As suggested by Legates and McCabe (1999) , a complete assess-ment of model performance at least include absolute error measure and relative error measure. Therefore, the measures of model performance evaluation for the present study comprise root mean square error (RMSE), the Nash-Sutcliffe coefficient of efficiency (CE), the persistence index (PI) ( Kitanidis and Bras, 1980 ), and Willmott X  X  index (d) ( Chattopadhyay and Chattopadhyay 2008b ).
They are respectively formulated as:RMSE  X  CE  X  1 P n i  X  1  X  y i ^ y i  X  2 = P n i  X  1  X  y i y  X  2 ,PI  X  1
P  X  9 y i y 9  X  2 . In these formula, n  X  number of observations, ^ y  X  forecasted rainfall, y i  X  observed rainfall, y  X  average observed rainfall, and y i T is the rainfall estimate from the persistence model.
CE and PI values of 1 stand for perfect fits. Higher d indices would be more efficient predictive models than those with lower d values. 3. Case study
Two daily mean rainfall series (at Zhenwan and Wuxi rain-gauge stations, respectively) from Zhenshui and Da X  X inghe water-sheds of China, and two monthly mean rainfall series from India and Zhongxian raingauge station of China, were analyzed in this study.

The Zhenshui basin is located in the north of Guangdong province and adjoined by Hunan province and Jianxi Province.
The basin belongs to a second-order tributary of the Pearl River and has an area of 7554 km 2 . The daily rainfall time series data of Zhenwan raingauge was collected between 1 January 1995 and 31 December 1998 (hereafter the rainfall series is referred to as Zhenwan).

The Da X  X inghe basin, a first-order tributary of the Yangtze River, is located in the northwest of Hubei Province. The daily rainfall data from Jan. 1, 2004 to Dec. 31, 2007 were measured at six raingauges located at the upstream of the study basin. The upstream part of the
Da X  X inghe basin is controlled by Wuxi hydrology station, with a drainage area of around 2000 km 2 . The rainfall was spatially average with the Thiessen polygon method (hereafter the averaged rainfall series is referred to as Wuxi).

The all Indian average monthly rainfall was estimated from area-weighted observations at 306 land stations uniformly dis-tributed over India. The data period spanned from January 1871 to December 2006 available at the website http://www.tropmet. res.in run by the Indian Institute of Tropical Meteorology.
The other monthly rainfall series was from Zhongxian raingauge which is located in Chongqing city, China. The basin containing this raingauge belongs to a first-order tributary of the Yangtze River. The monthly rainfall data were collected from January 1956 to December 2007.

Hence, Zhenwan and Wuxi series are of daily rainfall and India and Zhongxian are of monthly rainfall. Each rainfall series was partitioned into three parts as training set, cross-validation set and testing set. The training set served the model training and the testing set was used to evaluate the performances of models. The cross-validation set aimed to implement an early stopping approach for avoiding the overfitting. The same data partition format was adopted in four rainfall series: the first half of the entire data as training set and the first half of the remaining data as cross-validation set and the other half as testing set. 4. Applications to the rainfall data 4.1. Decomposition of rainfall data
The decomposition of the daily average rainfall series requires identifying the window length m (or the singular number) if the interval of neighboring points in discrete time series is defaulted as the lag time (i.e. t  X  1 day for daily rainfall data or 1 month for monthly rainfall data). The reasonable value of m should give rise to a clear resolution of the original signal. The present study does not need accurately resolve any trends or oscillations in the raw rainfall signal. A rough resolution can be adequate for the separation of signals and noises. Therefore, a small value of m was chosen for the present analysis. Fig. 1 displays the singular spectrum as a function of lag using various window lengths m from 5 to 10 for four rainfall series. Results show that the decomposition of the Wuxi rainfall was insensitive to m because singular values were distinguishable for all m . Thus, we set a criterion to decide the value of m ,i.e.the
SSA with the targeted m can generate clearly identified singular values. Therefore, the value of m for Wuxi was arbitrarily chosen from 5 to 10, say 5 here. The values of m were, respectively, 7, 6, and 7 for India, Zhongxian, and Zhenwan.
 rainfall records excluding the testing data. The RC1 represents an obvious low-frequency oscillation, which exhibits a similar mode to the raw rainfall. The other RCs reflect high-frequency oscillations, part of which can be deleted to improve the mapping between the
ANN inputs and output. Fig. 3 depicts cross-correlation functions (CCF) between RC and the original rainfall data. The last plot in
Fig. 3 denotes the average CCF, which was generated by averaging over all five CCFs at the same lag. 4.2. Identification of the ANN architecture
The ANN was used to choose data-preprocessing method from MA and SSA for modular models. Therefore, it is imperative to identify a reasonable ANN architecture before evaluating MA and SSA.
The architecture identification included the determination of model inputs and the number of nodes (or neurons) in the hidden layer when there was one model output. Input selection is one of the important tasks in the identification but is very subjective although many methods have been documented ( Bowden et al., 2005 ). The statistical approach to examine aut o-and partial-auto-correlation of the observed time series was recognized as a good and parsimo-nious method in the determination of model inputs ( Kis -Sudheer et al., 2002 ). The model inputs in the approach are mainly determined by the plot of partial-auto-correlation function (PACF). According to the approach, model inputs were respectively previous 12-month observations for India, 13-months observations for Zhongxian, 7-days observations for Wuxi, and 3-days observations for Zhenwan because the PACF values decayed within the con-fidence band around at these lags ( Fig. 4 ). The ensuing task was to optimize the size of the hidden layer with identified model inputs and one output. The optimal size h of the hidden layer was found by systematically increasing the number of hidden neurons from 1 to 10. The identified ANN architectur es were: 12-5-1 for India, 13-6-1 for Zhongxian, 7-6-1 for Wuxi and 3-4-1 for Zhenwan.

In the process of forecasting, the training data was rescaled to [ 1, 1] due to the use of hyperbolic tangent function as transfer function in this study. Considering the instability of the ANN output, the ANN prediction was an average of the best 10 outputs from entire 30 runs. In addition, the same ANN was applied to multi-step lead-time forecasting in which a static method (directly having the multi-step-ahead prediction as output) was adopted. 4.3. Implementation of models 4.3.1. ANN-MA
The window length K in MA can be determined by trial and error with various K from 1 to 10. The targeted value of K was associated with the optimal ANN performance in terms of RMSE.
Table 1 shows the values of K at one-, two-, and three-day-ahead predictions for all studied cases. 4.3.2. ANN-SSA filter of RCs for one-day-ahead prediction was described below using the Wuxi rainfall data.
 horizons using the rainfall data from India and Wuxi. It can be seen that the number of the remained RCs can be different at various prediction horizons. For instance, the numbers of chosen RCs in three forecasting horizons were respectively 3, 4, and 3 for
India, and 3, 1, and 3 for Wuxi. The results of the SSA filter for all four rainfall case are presented in Table 1 . 4.3.3. Modular models
The MA was more effective than the SSA when they were in conjunction with the ANN (see Tables 2 and 3 below). Therefore, modular models were only coupled with the MA in the current rainfall prediction. Moreover, the identified parameter K in MA by the ANN was also applied to modular models. 5. Results and discussion 5.1. Results
The overall performances of each model in terms of RMSE, CE, and PI are presented in Table 2 for two monthly rainfall series and Table 3 for two daily rainfall series. It can be seen that two benchmark models of persistence and ANN demonstrated very poor performances for all four cases except for India. The performances from ANN-MA and ANN-SSA indicate that data-preprocessing methods resulted in considerabl e improvement in the accuracy of the rainfall forecasting. Moreover, the MA seems superior to the SSA except for the Zhongxian rainfal l at three-month lead prediction, even where the MA and the SSA also showed similar performance.
Coupled with the MA, modular models performed the best among all models for each rainfall series.

Fig. 6 shows the hyetograph graphs and scatter plots of the results of one-month lead prediction from the ANN, ANN-MA, and
MSVR using the Zhongxian data. For Zhenwan, one-day lead rainfall estimates of the ANN, ANN-MA, and ANN-SVR are depicted in Fig. 7 in the form of hyetographs and scatter plots (the former was plotted in a selected range for better visual inspection). As seen from the hyetograph graphs that the modular models, MSVR or ANN-SVR, were able to reproduce the corresp onding observed rainfall data better than ANN and ANN-MA. It can be also seen from the scatter plotsthatthepredictionsofthemodularmodelsweremuchcloser to the exact fit line than those of ANN and ANN-MA. The scatter plots from the modular model and ANN-MA indicate that three local models better approximated different rainfall characteristics than a single global model. It is worth noting that the modular model generated some negative estimates at low-intensity rainfall points although it well pursued most of observed rainfall data. As far as ANN-MA is concerned, the prediction accuracy was substantially improved. However, the model underestimated quite a number of moderate peak rainfalls although low-intensity rainfalls were mostly well simulated. 5.2. Discussion The poor performances of ANN ( Tables 2 and 3 ) imply that the ANN fed by the original data is less viable for the rainfall forecasting, in particular using daily rainfall data. Actually, the ANN mainly captured the zero or low-intensity rainfall patterns (dry periods) in daily rainfall series because the type of pattern was dominant when using the original rainfall data to construct model input/output pairs. The MA and the SSA filter on the raw rainfall records substantially eliminated those patterns. Therefore, the trained ANN coupled with the MA or SSA was able to pay more attention to medium or high-intensity rainfall patterns, which improve the ANN generalization.

It may be noted that, the ANN performed better using the India data than using the Zhongxian data although both of them were monthly rainfall series ( Table 2 ). This implies that the data characteristic may be an important factor to the performance of ANN. Some studies have indicated that considerations of statis-tical principles may improve ANN model performance ( Cheng and Titterington, 1994 ; Sarle, 1994 ). For example, the training data was recommended to be normally distributed ( Fortin et al., 1997 ). Sudheer et al. (2003) suggested that the issue of stationarity should be considered in the ANN development because the ANN cannot account for trends and heteroscedasticity in the data.
Their results showed that data transformation to reduce the skewness of data can significantly improve the model perfor-mance. Depending on the statistical properties of the studied data series, the method of n -th root data transformation was used. In the meantime, for the purpose of comparison with the rescaling method, the standardization/normalization was also considered as a data-preprocessing approach for transfer functions in the
ANN. When the standardization approach was adopted, we used the linear transfer function (e.g. purelin) instead of the hyperbolic tangent function in the output layer. Therefore, four preproces-sing procedures including the original rescaling were addressed: Rescaling the raw data (referred to as Resc_raw); Rescaling the n -th root transformed data (referred to as Resc_ n th_root); Standardizing the original data (referred to as Std_raw); Standardizing the n -th root transformed data (referred to as Std_ n th_root).
 The ANN forecasts with these procedures are presented in
Table 4 . Compared with the Resc_raw, it can be seen that using the root of n -th degree as data transformation was ineffective for the improvement of the ANN performance. However, the stan-dardization method was effective for the Zhongxian data, which considerably improved the forecast accuracy. It can be concluded that standardization/normalization is a good alternative to rescal-ing for the ANN in the present study.
 skewness coefficient and kurtosis, in three scenarios of no treat-ment, moving average and root of n -th degree. Each original rainfall series were extremely non-stationary except for the India data being more stationary. The n th-root data transformation did not result in an expected improvement of the ANN performance although the transformed rainfall series was closer to a normal distribution. On the contrary, the moving average truly improved the ANN performance but the transformed rainfall series was still far from a normal distribution. Seemingly, the requirement of a normal distribution on studied data is not necessary.
 the moving average over the filtered rainfall series. Table 6 demonstrates one-day lead prediction for four case studies. The
ANN with the single MA still outperformed the ANN with the combination of SSA and MA.

In summary, the optimal data-preprocessing for the ANN was the MA and the standardization in the present study. The former was for the purpose of smoothing the raw rainfall whereas the latter was needed by the transfer function in the ANN. 6. Conclusions
The purpose of this study was to investigate the effect of modular models coupled with data-preprocessing techniques in improving the accuracy of rainfall forecasting. The modular models consisted of three local SVR and/or ANN. A three-layer feed-forward
ANN was used to examine two data-preprocessing techniques, MA and SSA. Results show that the MA was superior to the SSA. Four rainfall records, India, Zhongxian, Wuxi and Zhenwan, from India and China, were used as testing cases.

With the help of the MA, modular models showed the best performance when compared with the ANN-MA and two baseline models, the persistence model and the ANN. Reasonable rainfall estimates were also obtained from the ANN-MA model. The model, however, underestimated quite a number of moderate peak rain-falls although low-intensity rainfalls were mostly well simulated. The ANN model, directly fed by the original data, seemed unsuitable for the current rainfall series except for India. As far as the daily rainfall data were concerned, the ANN mainly captured the zero or low-intensity rainfall patterns (dry periods) in daily rainfall series because the type of pattern was dominant when using the original rainfall data to construct model input/output pairs. The MA or the SSA filter on the raw rainfall records substantially eliminated those patterns. Therefore, the trained ANN with the help of MA or SSA was able to pay more attention to medium or high-intensity rainfall patterns, which improve the ANN generalization.

In addition, the effect of other data-preprocessing techniques including data-transformation and standardization on the ANN performance was also examined. It was found that the standardi-zation method was able to substitute for the rescaling method from the perspective of the transfer function in the ANN. How-ever, the data-transformation method to meet an approximately normal distribution seemed to be unnecessary for the ANN. References
