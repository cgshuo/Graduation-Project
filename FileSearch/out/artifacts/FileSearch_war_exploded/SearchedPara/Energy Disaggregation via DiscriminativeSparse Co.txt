 Energy issues present one of the largest challenges facing o ur society. The world currently consumes an average of 16 terawatts of power, 86% of which comes from fo ssil fuels [28]; without any effort to curb energy consumption or use different sources of energ y, most climate models predict that the earth X  X  temperature will increase by at least 5 degrees Fahr enheit in the next 90 years [1], a change that could cause ecological disasters on a global scale. Whil e there are of course numerous facets to the energy problem, there is a growing consensus that many en ergy and sustainability problems are fundamentally informatics problems, areas where machine l earning can play a significant role. This paper looks specifically at the task of energy disaggreg ation, an informatics task relating to energy efficiency. Energy disaggregation, also called non-intrusive load monitoring [11], involves taking an aggregated energy signal, for example the total po wer consumption of a house as read by an electricity meter, and separating it into the different e lectrical appliances being used. Numerous studies have shown that receiving information about ones en ergy usage can automatically induce energy-conserving behaviors [6, 19], and these studies als o clearly indicate that receiving appliance-specific information leads to much larger gains than whole-h ome data alone ([19] estimates that appliance-level data could reduce consumption by an averag e of 12% in the residential sector). In the United States, electricity constitutes 38% of all energ y used, and residential and commercial amount of energy that could potentially be saved. However, t he widely-available sensors that provide electricity consumption information, namely the so-calle d  X  X mart Meters X  that are already becoming ubiquitous, collect energy information only at the whole-h ome level and at a very low resolution (typically every hour or 15 minutes). Thus, energy disaggre gation methods that can take this whole-home data and use it to predict individual appliance usage pr esent an algorithmic challenge where advances can have a significant impact on large-scale energy efficiency issues. Energy disaggregation methods do have a long history in the e ngineering community, including some which have applied machine learning techniques  X  early algorithms [11, 26] typically looked for  X  X dges X  in power signal to indicate whether a known devic e was turned on or off; later work focused on computing harmonics of steady-state power or cur rent draw to determine more complex device signatures [16, 14, 25, 2]; recently, researchers ha ve analyzed the transient noise of an elec-trical circuit that occurs when a device changes state [15, 2 1]. However, these and all other studies we are aware of were either conducted in artificial laborator y environments, contained a relatively small number of devices, trained and tested on the same set of devices in a house, and/or used cus-tom hardware for very high frequency electrical monitoring with an algorithmic focus on  X  X vent detection X  (detecting when different appliances were turn ed on and off). In contrast, in this paper we focus on disaggregating electricity using low-resoluti on, hourly data of the type that is readily available via smart meters (but where most single-device  X  X  vents X  are not apparent); we specifically look at the generalization ability of our algorithms for dev ices and homes unseen at training time; and we consider a data set that is substantially larger than t hose previously considered, with 590 homes, 10,165 unique devices, and energy usage spanning a ti me period of over two years. The algorithmic approach we present in this paper builds upo n sparse coding methods and recent work in single-channel source separation [24, 23, 22]. Spec ifically, we use a sparse coding algorithm learned models to predict the power consumption of differen t devices in previously unseen homes, using their aggregate signal alone. While energy disaggrega tion can naturally be formulated as such a single-channel source separation problem, we know of no pr evious application of these methods to the energy disaggregation task. Indeed, the most common a pplication of such algorithm is audio signal separation, which typically has very high temporal r esolution; thus, the low-resolution energy disaggregation task we consider here poses a new set of chall enges for such methods, and existing approaches alone perform quite poorly.
 As a second major contribution of the paper, we develop a nove l approach for discriminatively train-ing sparse coding dictionaries for disaggregation tasks, a nd show that this significantly improves performance on our energy domain. Specifically, we formulat e the task of maximizing disaggrega-tion performance as a structured prediction problem, which leads to a simple and effective algorithm for discriminatively training such sparse representation for disaggregation tasks. The algorithm is [12, 17, 18]. However, these past works were interested in di scriminatively training sparse cod-ing representation specifically for classification tasks, whereas we focus here on discriminatively training the representation for disaggregation tasks, which naturally leads to substantially different algorithmic approaches. We begin by reviewing sparse coding methods and their applic ation to disaggregation tasks. For con-creteness we use the terminology of our energy disaggregati on domain throughout this description, but the algorithms can apply equally to other domains. Forma lly, assume we are given k differ-ent classes, which in our setting corresponds to device cate gories such as televisions, refrigerators, heaters, etc. For every i = 1 , . . . , k , we have a matrix X contains a week of energy usage (measured every hour) for a pa rticular house and for this particular type of device. Thus, for example, the j th column of X energy consumption for a refrigerator (for a single week in a single house) and x ( j ) weekly energy consumption of a heater (for this same week in t he same house). We denote the aggregate power consumption over all device types as  X  X  X  P k  X  x time, we assume we have access to the individual device energ y readings X example from plug-level monitors in a small number of instru mented homes). At test time, however, we assume that we have access only to the aggregate signal of a new set of data points  X  X  X  (as would be reported by smart meter), and the goal is to separate this s ignal into its components, X  X  The sparse coding approach to source separation (e.g., [24, 23]), which forms for the basis for our disaggregation approach, is to train separate models for ea ch individual class X models to separate an aggregate signal. Formally, sparse co ding models the i th data matrix using the approximation X called the dictionary , and the columns of A [20]. Sparse coding additionally imposes the the constrain t that the activations A that they contain mostly zero entries, which allows us to lea rn overcomplete representations of the data (more basis functions than the dimensionality of the da ta). A common approach for achieving this sparsity is to add an  X  Since energy usage is an inherently non-negative quantity, we impose the further constraint that the activations and bases be non-negative, an extension known a s non-negative sparse coding [13, 7]. Specifically, in this paper we will consider the non-negativ e sparse coding objective where X problem is not jointly convex in A holding the other fixed, so a common strategy for optimizing ( 1) is to alternate between minimizing the objective over A After using the above procedure to find representations A its individual components), using the following procedure (used by, e.g., [23], amongst others). We concatenate the bases to form single joint set of basis funct ions and solve the optimization problem where for ease of notation we use A mization objective as F (  X  X , B The intuition behind this approach is that if B require smaller activations) than all other bases B resulting disaggregation by what we refer to as the disaggregation error , which quantifies how accurately we reconstruct each individ ual class when using the activations obtained only via the aggregated signal. 2.1 Structured Prediction for Discriminative Disaggregat ion Sparse Coding An issue with using sparse coding alone for disaggregation t asks is that the bases are not trained to minimize the disaggregation error. Instead, the method rel ies on the hope that learning basis func-tions for each class individually will produce bases that ar e distinct enough to also produce small disaggregation error. Furthermore, it is very difficult to o ptimize the disaggregation error directly over B negativity constraint. One could imagine an alternating pr ocedure where we iteratively optimize over B but ignoring how  X  A performs very poorly in practice. Alternatively, other met hods (though in a different context from disaggregation) have been proposed that use a differentiab le objective function and implicit differ-however, this formulation loses some of the benefits of the st andard sparse coding formulation, and computing these derivatives is a computationally expensiv e procedure. Instead, we propose in this paper a method for optimizing dis aggregation performance based upon structured prediction methods [27]. To describe our approa ch, we first define the regularized disag-gregation error , which is simply the disaggregation error plus a regulariza tion penalty on  X  A as we wish to obtain a sparse set of coefficients that can achieve low disaggregation erro r. Clearly, the best possible value of  X  A which is precisely the activations obtained after an iterat ion of sparse coding on the data matrix X error, we can discriminatively optimize the bases B produces activations that are as close to A  X  optimize this criterion would also change the resulting opt imal coefficients A  X  used to reconstruct the signals. We define an augmented regul arized disaggregation error objective where the B sparse coding while the  X  B optimized in order to move  X  A Discriminatively training the disaggregation bases  X  B task: the input is  X  X , the multi-variate desired output is A  X  discriminant function is F (  X  X ,  X  B method based on the structured perceptron algorithm [5]. Gi ven some value of the parameters  X  B we first compute  X  A using (2). We then perform the perceptron update with a step s ize  X  , or more explicitly, defining  X  B = h  X  B To keep  X  B each column to have unit norm. One item to note is that, unlike typical structured prediction where the discriminant is a linear function in the parameters (which guarantees convexity of t he problem), necessarily reach a global optimum of the prediction proble m; however, since sparse coding itself is a non-convex problem, this is not overly concerning for ou r setting. Our complete method for discriminative disaggregation sparse coding, which we cal l DDSC, is shown in Algorithm 1. Algorithm 1 Discriminative disaggregation sparse coding Input: data points for each individual source X  X   X  R + , gradient step size  X   X  R + .
 Sparse coding pre-training: Discriminative disaggregation training: Given aggregated test examples  X  X  X  : 2.2 Extensions Although, as we show shortly, the discriminative training p rocedure has made the largest difference in terms of improving disaggregation performance in our dom ain, a number of other modifications to the standard sparse coding formulation have also proven u seful. Since these are typically trivial extensions or well-known algorithms, we mention them only b riefly here.
 Total Energy Priors. One deficiency of the sparse coding framework for energy disa ggregation is that the optimization objective does not take into consid eration the size of an energy signal for determinining which class it belongs to, just its shape. Sin ce total energy used is obviously a dis-criminating factor for different device types, we consider an extension that penalizes the  X  between a device and its mean total energy. Formally, we augm ent the objective F with the penalty where 1 denotes a vector of ones of the appropriate size, and total energy of device class i .
 Group Lasso. Since the data set we consider exhibits some amount of sparsi ty at the device level (i.e., several examples have zero energy consumed by certai n device types, as there is either no such device in the home or it was not being monitored), we also woul d like to encourage a grouping effect encourage other coefficients to also be active in that class. To achieve this, we employ the group Lasso algorithm [29], which adds an  X  to the standard sparse coding framework where each basis is c onvolved over the input data, with beneficial for the energy disaggregation task, where a given device might exhibit the same energy signature at different times. However, as we will show in the next section, this extension actually perform worse in our domain; this is likely due to the fact tha t, since we have ample training data day times 7 days in the week), the standard sparse coding base s are able to cover all possible shift positions for typical device usage. However, pure shift inv ariant bases cannot capture information about when in the week or day each device is typically used, and such info rmation has proven crucial for disaggregation performance. 2.3 Implementation Space constraints preclude a full discussion of the impleme ntation details of our algorithms, but for the most part we rely on standard methods for solving the opti mization problems. In particular, most of the time spent by the algorithm involves solving spar se optimization problems to find the activation coefficients, namely steps 2a and 4a in Algorithm 1. We use a coordinate descent approach here, both for the standard and group Lasso version of the opt imization problems, as these have been recently shown to be efficient algorithms for  X  added benefit that we can warm-start the optimization with th e solution from previous iterations. To solve the optimization over B update from [7]. 3.1 The Plugwise Energy Data Set and Experimental Setup We conducted this work using a data set provided by Plugwise, a European manufacturer of plug-level monitoring devices. The data set contains hourly ener gy readings from 10,165 different devices in 590 homes, collected over more than two years. Each device is labeled with one of 52 device types, which we further reduce to ten broad categories of ele ctrical devices: lighting, TV, computer, washer, heating/cooling, and a miscellaneous category. We look at time periods in blocks of one week, and try to predict the individual device consumption o ver this week given only the whole-home signal (since the data set does not currently contain tr ue whole-home energy readings, we approximate the home X  X  overall energy usage by aggregating the individual devices). Crucially, we focus on disaggregating data from homes that are absent from the training set (we assigned 70% of the homes to the training set, and 30% to the test set, resulti ng in 17,133 total training weeks and 6846 testing weeks); thus, we are attempting to generalize o ver the basic category of devices, not just over different uses of the same device in a single house. We fit the hyper-parameters of the algorithms (number of bases and regularization parameters ) using grid search over each parameter independently on a cross validation set consisting of 20% of the training homes. 3.2 Qualitative Evaluation of the Disaggregation Algorith ms We first look qualitatively at the results obtained by the met hod. Figure 1 shows the true energy en-ergy consumed by two different houses in the test set for two d ifferent weeks, along with the energy consumption predicted by our algorithms. The figure shows bo th the predicted energy of several devices over the whole week, as well as a pie chart that shows t he relative energy consumption of different device types over the whole week (a more intuitive display of energy consumed over the week). In many cases, certain devices like the refrigerator , washer/dryer, and computer are predicted quite accurately, both in terms the total predicted percent age and in terms of the signals themselves. There are also cases where certain devices are not predicted well, such as underestimating the heat-ing component in the example on the left, and a predicting spi ke in computer usage in the example on the right when it was in fact a dishwasher. Nonetheless, de spite some poor predictions at the hourly device level, the breakdown of electric consumption is still quite informative, determining the approximate percentage of many devices types and demons trating the promise of such feedback. In addition to the disaggregation results themselves, spar se coding representations of the different device types are interesting in their own right, as they give a good intuition about how the different devices are typically used. Figure 2 shows a graphical repre sentation of the learned basis functions. In each plot, the grayscale image on the right shows an intens ity map of all bases functions learned for that device category, where each column in the image corr esponds to a learned basis. The plot example, that the bases learned for the washer/dryer device s are nearly all heavily peaked, while the refrigerator bases are much lower in maximum magnitude. Additionally, in the basis images devices like lighting demonstrate a clear  X  X and X  pattern, i ndicating that these devices are likely to Figure 1: Example predicted energy profiles and total energy percentages (best viewed in color). Blue lines show the true energy usage, and red the predicted u sage, both in units of kWh. Figure 2: Example basis functions learned from three device categories (best viewed in color). The plot of the left shows seven example bases, while the image on the right shows all learned basis functions (one basis per column). be on and off during certain times of the day (each basis cover s a week of energy usage, so the seven bands represent the seven days). The plots also suggests why the standard implementation of shift the time of usage is an important factor, simple shift-invariant bas es miss key information. 3.3 Quantitative Evaluation of the Disaggregation Methods There are a number of components to the final algorithm we have proposed, and in this section we present quantitative results that evaluate the performa nce of each of these different components. While many of the algorithmic elements improve the disaggreg ation performance, the results in this section show that the discriminative training in particula r is crucial for optimizing disaggregation performance. The most natural metric for evaluating disagg regation performance is the disaggrega-tion error in (4). However, average disaggregation error is not a particularly intuitive metric, and so we also evaluate a total-week accuracy of the prediction sys tem, defined formally as Table 1: Disaggregation results of algorithms (TEP = Total E nergy Prior, GL = Group Lasso, SISC = Shift Invariant Sparse Coding, DDSC = Discriminative Disa ggregation Sparse Coding). Figure 3: Evolution of training and testing errors for itera tions of the discriminative DDSC updates. Despite the complex definition, this quantity simply captur es the average amount of energy predicted correctly over the week (i.e., the overlap between the true a nd predicted energy pie charts). Table 1 shows the disaggregation performance obtained by ma ny different prediction methods. The advantage of the discriminative training procedure is clea r: all the methods employing discrimina-tive training perform nearly as well or better than all the me thods without discriminative training; the group Lasso, outperforms all competing methods on both m etrics. To put these accuracies in of hand-engineered features, to classify individual energy signals into their device category, and were able to achieve at most 59% classification accuracy. It t herefore seems unlikely that we could disaggregate a signal to above this accuracy and so, informa lly speaking, we expect the achievable performance on this particular data set to range between 47% for the baseline of predicting mean en-ergy (which in fact is a very reasonable method, as devices of ten follow their average usage patterns) is crucial to improving the performance of the sparse coding disaggregation procedure within this range, and does provide a significant improvement over the ba seline. Finally, as shown in Figure 3, both the training and testing error decrease reliably with i terations of DDSC, and we have found that this result holds for a wide range of parameter choices and st ep sizes (though, as with all gradient methods, some care be taken to choose a step size that is not pr ohibitively large). Energy disaggregation is a domain where advances in machine learning can have a significant impact on energy use. In this paper we presented an application of sp arse coding algorithms to this task, meters. We developed the discriminative disaggregation sp arse coding (DDSC) algorithm, a novel discriminative training procedure, and show that this algo rithm significantly improves the accuracy of sparse coding for the energy disaggregation task.
 Acknowledgments This work was supported by ARPA-E (Advanced Research Projec ts Agency X  Energy) under grant number DE-AR0000018. We are very gratef ul to Plugwise for providing us with their plug-level energy data set, and in particular we t hank Willem Houck for his assistance with this data. We also thank Carrie Armel and Adrian Albert f or helpful discussions.
