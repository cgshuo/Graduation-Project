 In this paper, we propose a generic framework to learn context-aware latent representations for context-aware collaborative filtering. Contextual contents are combined via a function to produce the context influence factor, which is then combined with each latent factor to derive latent representations. We instantiate the generic framework using biased Matrix Fac-torization as the base model. A Stochastic Gradient Descent (SGD) based optimization procedure is developed to fit the model by jointly learning the weight of each context and la-tent factors. Experiments conducted over three real-world datasets demonstrate that our model significantly outper-forms not only the base model but also the representative context-aware recommendation models.
 H.3.3 [ Information Search and Retrieval ]: Information filtering; H.4 [ Information Systems Applications ]: Mis-cellaneous Algorithms, Performance Context-aware; collaborative filtering; recommendation; la-tent factor models
Rich contextual information that is pervasively available in many online applications provides an important informa-tion source to accurately model users X  preference for collabo-rative filtering (CF) tasks such as rating prediction and top-N recommendation [1, 11, 5, 8, 3, 2]. For instance, in Point-of-Interest (POI) recommendation, the information such as time, weather and emotion may influence a user X  X  preference on a certain POI, and hence influences the recommendations generated for this user.
 c
Conventional context-aware CF models either separately process contexts, e.g., using contexts to partition input data (pre-processing) or adjust the order of recommended item list (post-processing) [1, 8] or jointly learn the context in-fluence and other parameters during model building [10, 14, 13]. In this work, we follow the joint learning approach, which provides strong mathematical foundation for context modeling. Recent such models are designed based on latent factor models such as Matrix Factorization (MF). However, most of these approaches assume users, items and contexts share the same latent space (i.e., the relations among the three entities are captured by the inner product of their la-tent factors), which may not always make sense in complex real-world applications. Moreover, treating users, items and contexts as the same level entities may over-estimate the influence of contextual information, thus weakening the im-pacts of other latent aspects.

In order to address these issues, we propose a generic context-aware framework for latent factor models. The con-textual information is firstly processed to generate user-related and item-related context influence factors. Such in-fluence factors are then directly combined with users X  and items X  latent factors to derive the context-aware latent rep-resentations, which can be used to calculate users X  context-aware preference on items. Such an approach not only han-dles user-related and item-related contexts for users X  and items X  latent factors respectively, but also properly inte-grates context influence into latent factors to balance the impacts of contexts.

We instantiate the proposed framework using biased MF model, a popular MF based model for rating prediction. We develop a Stochastic Gradient Descent (SGD) based opti-mization procedure to learn the context-aware latent rep-resentations by jointly estimating context related parame-ters and users X  and items X  latent factors. Experiments us-ing three real-world datasets demonstrate that our context-aware biased MF evidently outperforms the conventional bi-ased MF, as well as a representative context-aware model called Factorization Machines (FM) [11].
Recent research focuses on integrating contexts into la-tent factor models. By modeling feedback information as a user-item-context tensor, Karatzoglou et al. [5] proposed a multiverse recommendation model, where tucker decompo-sition is applied to factorize the tensor. However, the type of contexts is restricted to be categorical. Similar ideas are presented in [15], which was particularly designed for top-N recommendation by directly optimizing Mean Average Pre-cision (MAP). Another line of research focuses on Factor-ization Machines [11, 13], which can handle diverse types of contexts for context-aware CF. The basic idea is to assign same dimension latent vectors to users, items and contexts and model all interactions between pairs of the three enti-ties with respect to the target. An improvement that selects useful contexts for FM using gradient booting was intro-duced in [4]. In [10], the authors improve FM by breaking the limits of linearly combining latent factors. A non-linear probabilistic algorithm for context-aware recommendation was proposed using Gaussian processes. As mentioned in introduction section, such approaches suffer from the issue that restricts users, items and contexts to share the same la-tent space, which may not capture the real relations among the three entities.

There are also some models proposed to handle specific types of context such as social information [9] or time [7]. However, these methods cannot be directly applied to pro-cess general contextual information.
In this section, we present a generic framework for context-aware collaborative filtering. We denote user set by U = { u 1 , u 2 , ... } , where the real-valued latent factor vector (with the dimensionality of D ) of user u is represented by u , and item set by V = { v 1 , v 2 , ... } , where the real-valued latent factor vector (with the dimensionality of D ) of item v is represented by v . The outcome of the interaction between user u and item v is denoted by y u,v , which can be explicit (e.g., 5-point scale rating) or implicit (e.g., clicked an ad-vertisement). Tensor Y  X  R |U| X |V| X  K records all observed interactions between users and items under the correspond-ing K types of contexts.

The research problem of context-aware collaborative filter-ing is formulated as given observed users X  feedback to items and the associated contextual information, model the inter-action between feedback data and context data to predict users X  feedback to unobserved items under certain context situa-tions . Mathematically, we want to find context-aware la-tent representations  X  for user u and item v to derive u  X  X  feedback to v : where  X  x ( x = u or v ) denotes the context influence factor derived for the user or the item.  X  ( ., . ) is a function that combines the user X  X  or item X  X  latent factor and the corre-sponding context influence factor for latent representations. f ( ., . ) is a function that formulates users X  and items X  la-tent representations for predicting users X  feedback score to items 1 .

The framework is generic from two aspects: (1) any form of function (linear or non-linear)  X  ( ., . ) can be applied to combine latent factor and context influence factor to derive context-aware latent representations, and (2) the idea can be applied to any latent factor model such as basic MF, SVD++ [6], even social recommendation models like SoReg
For most latent factor models like MF, such a function calculates the inner product of the latent factors of the cor-responding user and item Figure 1: An example of user-related and item-related contextual information in the context of movie recommendation. Dashed rectangle indicates continuous-valued context and regular rectangle in-dicates categorical-valued context (binary variable where 1 indicates  X  X elong to X  and 0 otherwise). [9]. In the next section, we instantiate this generic frame-work using biased MF to demonstrate how it works.
In order to better model the influence of contexts on users X  and items X  latent factors, we divide all contexts into user-related contexts that may influence users X  behavior (e.g., in movie recommendation, users X  age, gender, time of watching, mood, etc.) and item-related contexts that may character-ize items (e.g., in movie recommendation, movies X  genres, showed in cinema or on TV, etc.). For an interaction be-tween user u and item v , the associated user-related contex-tual information is denoted by C a which consists of K a types of contexts 2 . Similarly, the associated item-related contex-tual information, which consists of K b types of contexts, is denoted by C b . To support both continuous valued contexts and categorical valued contexts, following FM [11], C a / C is represented as a real-valued variables vector (see Figure 1 as an example).

We use a sigmoid function to linearly combine contexts to derive the context influence factor: where x = a or b , indicating the context influence factor is derived for users or items, and d denotes the index of the latent factor in the vector.  X  i denotes the i th context value and w i is the corresponding weight,  X  is the bias to adjust the context influence to the corresponding latent factor. In-tuitively, each latent factor of each user or item expects a unique influence factor (i.e., the unique context influence pa-rameters including the bias and context weights for contexts combination) for context-aware latent representation. How-ever, this significantly increases model complexity in terms of parameter update computation and storage. To make the model applicable in practice, we propose to maintain D sets of context influence parameters for the D latent factors of all users and all items respectively, that is, we introduce totally 2  X  D  X  ( | C a | + | C b | + 1 + 1) context influence parameters. We argue that the introduced complexity is minor in that it won X  X  increase with the increasing number of observations but only rely on latent vector dimensionality and the size of the context variable vector, which are typically small (com-pared to the number of latent factors) in most application scenario.
Note that user-related contexts and item-related contexts may overlap.
We can then derive the latent representations that com-bine 3 latent factors and context influence factors for user u and item v : where d indicates the d th latent factor of u  X  X  or v  X  X  latent vector. After obtaining latent representations, following the design of biased MF, user u  X  X  feedback to item v can be predicted as: where  X  is the global mean, b u and b v are user bias and item bias respectively. The loss function is formulated as:
L = where  X  indicates the training set. The second and third terms are used to avoid overfitting, where  X  1 and  X  2 are reg-ularization terms for latent factors (and biases), and context influence parameters respectively, d indicates the d th latent factor of latent vector.

To fit the proposed context-aware biased MF, we develop a SGD based optimization procedure which iteratively up-dates all parameters until the loss converges or pre-defined iterations have reached: where  X  f indicates latent factors, users X  and items X  biases, and  X  c indicates context influence parameters (i.e., context weights and biases).  X  f and  X  c are the corresponding learn-ing rates. The gradient of L with respect to each user X  X  or item X  X  latent factor as well as the bias is computed as follows:
The gradient of L with respect to each context influence parameter (i.e., the weight of each context and context bias for users and items) is computed as follows:
We also tried other combination methods such as multipli-cation, but experimental results show that addition gener-ates better performance.  X  X  where i indicates the i th context value in the user-related context vector C a .  X  X  where j indicates the j th context value in the item-related context vector C b .  X  X   X  X  Once all parameters have been learned, user u  X  X  feedback to item v can be predicted by using Eq. 5.
We evaluate the performance of the proposed model using three real-world datasets: (1) Movielens-100K 4 , which con-sists of 100,000 ratings (ranging from 1 to 5) from 943 users on 1682 movies. The user-related contexts include age, gen-der, occupation; the movie-related contexts include genres. (2) Douban 5 book data [16], which records 1,097,148 ratings from 33,523 users on 381,767 books. The user-related con-texts include the number of friends, the number of  X  X ish 6 issued and the number of ratings provided; the book-related contexts include the number of  X  X ish X  X eceived and the num-ber of ratings got. (3) Douban music data [16], which records 1,387,216 ratings from 29,287 users on 257,288 music items. The user-related and item-related contexts are the same with those used in Douban book data.

We compare the proposed context-aware biased MF with conventional biased MF and a representative context-aware model FM. Note that FM and our model share the same context set. The latent factors are initialized following uni-form distribution [0 , 1E-4]. The parameters of latent factor models such as latent vector dimensionality, regularization term, learning rate, etc. are determined by cross-validation.
We randomly divide each dataset into training set that consists of 80% data and test set that contains 20% data. We measure the performance using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE), which are conventional metrics for measuring rating prediction accu-racy. Each experiment is conducted 10 times, and we report the averaged results. Standard errors are shown (in Table 1) to indicate the confidence of the results.
Figure 2 shows when Movielns-100K data is used, how the performance of our model varies with different latent http://grouplens.org/datasets/movielens/ Douban (http://www.douban.com/) is one of the largest Chinese based social platforms for sharing reviews and rec-ommendations for books, movies and music. A social net-work is also provided to connect users.
A user, although has not read a book, may still express her interest by indicating  X  X ish X  Figure 2: Performance with different latent dimen-sionality. vector dimensionality. We set  X  f = 0 . 012,  X  c = 0 . 0016,  X  1 = 0 . 0125,  X  2 = 0 . 000003. We observe that MAE and RMSE are improved when the latent vector dimensionality increases. The best results are achieved when the dimension-ality is 20, after which MAE and RMSE increase and become relatively stable. In the same way, we set latent dimension-ality to 30 for Douban data (  X  f = 0 . 005,  X  c = 0 . 00005,  X  1 = 0 . 01,  X  2 = 0 . 0001), and 35 for Douban music data (  X  f = 0 . 005,  X  c = 0 . 00005,  X  1 = 0 . 04,  X  2 = 0 . 0001).
Table 1 summarizes the performance of all models when different datasets are used. By modeling pair-wise interac-tions among contexts, users and items, which are all repre-sented by latent vectors, FM evidently outperforms biased MF, indicating the importance of contextual information in collaborative filtering. In all cases, our context-aware model outperforms FM (and biased MF), demonstrating the ad-vantage of directly integrating contextual information into latent factors to learn context-aware latent representations. The results also reveal the limitation of restricting contexts to share the same latent space with users and items.
In this paper, we propose a generic framework to integrate contextual information into latent factor models. Context influence factor, which is derived by combining contexts, is directly combined with latent factor to generate content-aware latent representations. Such a framework is instanti-ated by using biased MF model. SGD based optimization procedure is developed to fit the context-aware biased MF model. Experimental results demonstrate the advantages of our model by comparing with the base model and FM.
An immediate next step is to instantiate the generic frame-work by using CF models for implicit feedback data such as Bayesian Personalized Ranking (BPR) [12] to provide context-aware top-N recommendation, which is useful in more application scenarios. Another direction is to investigate more sophisticated ways (e.g., non-linear methods) to com-bine contexts to better model context influence factor. [1] Gediminas Adomavicius, Ramesh Sankaranarayanan, [2] Deepak Agarwal, Bee-Chung Chen, and Bo Long.
 [3] Tianqi Chen, Hang Li, Qiang Yang, and Yong Yu. [4] Chen Cheng, Fen Xia, Tong Zhang, Irwin King, and [5] Alexandros Karatzoglou, Xavier Amatriain, Linas [6] Yehuda Koren. Factorization meets the neighborhood: [7] Yehuda Koren. Collaborative filtering with temporal [8] Xin Liu and Karl Aberer. Soco: A social network [9] Hao Ma, Dengyong Zhou, Chao Liu, Michael R. Lyu, [10] Trung V. Nguyen, Alexandros Karatzoglou, and Linas [11] Steffen Rendle. Factorization machines with libFM. [12] Steffen Rendle, Christoph Freudenthaler, Zeno [13] Steffen Rendle, Zeno Gantner, Christoph [14] Yue Shi, Alexandros Karatzoglou, Linas Baltrunas, [15] Yue Shi, Alexandros Karatzoglou, Linas Baltrunas, [16] Erheng Zhong, Wei Fan, Junwei Wang, Lei Xiao, and
