 Faced with growing knowledge management needs, enter-prises are increasingly realizing the importance of seamle ssly integrating critical business information distributed ac ross both structured and unstructured data sources. In existing information integration solutions, the application needs to formulate the SQL logic to retrieve the needed structured data on one hand, and identify a set of keywords to retrieve the related unstructured data on the other. This paper pro-poses a novel approach wherein the application specifies its information needs using only a SQL query on the structured data, and this query is automatically  X  X ranslated X  into a se t of keywords that can be used to retrieve relevant unstruc-tured data. We describe the techniques used for obtaining these keywords from (i) the query result, and (ii) additiona l related information in the underlying database. We further show that these techniques achieve high accuracy with very reasonable overheads.
 Categories and Subject Descriptors: H.2 [Database Management]: Systems-Query Processing General Terms: Algorithms, Design, Experimentation Keywords: Information Integration, Context, SQL, Key-word Search
Digital information within an enterprise is composed of two kinds of content: structured and unstructured . The structured content includes mainly the operational busine ss data such as sales, accounting, payroll, inventory, etc. wh ile the unstructured content includes the reports, email, web-pages, etc. The structured data is strictly typed and can be meaningfully decomposed into relations, and queried using a query language (SQL) with a well-defined semantics. The unstructured content, in contrast, is free-flow and untyped ,
Currently at Georgia Institute of Technology, Atlanta, GA Currently at University of Massachusetts, Amherst, MA and is typically queried using a set of keywords. This inher-ent difference in the way the structured and unstructured content are managed and queried creates an artificial sepa-ration between the two, which is unfortunate since they are complementary in terms of information content.

Effective knowledge management, however, requires seam-less access to information in its totality, and enterprises are fast realizing the need to bridge this separation. This has led to a significant effort towards integration of structured and unstructured data [6, 17, 23, 20, 16, 11, 22, 14].
Existing solutions typically enable this integration by pr o-viding a single point of access to both structured and un-structured data sources. DB2 NSE [20], for instance, ex-poses the unstructured data as a virtual relational table (with one row per document) and introduces a CONTAINS predicate that can be used to filter the relevant documents from this table based on a set of keywords. 1 While this alleviates the issue of having to interface with each source individually, the application still needs to formulate the SQL logic to retrieve the needed structured data on one hand, and identify a set of keywords to retrieve the related unstruc-tured data on the other. This is not ideal for the following reasons:
In this paper, we introduce the SCORE 2 system that ef-fectively addresses the limitations mentioned above by auto-matically associating related unstructured content with the SQL query result, thereby eliminating the need for the ap-plication to specify a set of keywords in addition to the SQL query. Specifically, SCORE works as follows: 1. The application specifies its information needs using 2. SCORE  X  X ranslates X  the given SQL query into a set
See also SQL-Server [16], and Oracle [11].
SCORE stands for S ymbiotic C ontext-O riented Informa-tion RE trieval  X  where symbiotic emphasizes the mutu-ally beneficial role of the structured and unstructured data sources. 3. SCORE uses these keywords to retrieve relevant un-This is illustrated in the following example.

Example 1. Consider an investment information system that helps users to analyze stock market data. The system maintains the stock ticker archived over the past week, com-pany profile, information about the various institutional i n-vestors, mutual-fund portfolios, etc. (structured data). It also maintains a searchable repository of past week X  X  news stories, advisories and recent analyst reports (unstructu red data). Now, consider the scenario illustrated in Figure 1, wherein the application submits a query asking for the names of the three companies with maximum stock price variation in the past week. With this query as input, SCORE explores the query X  X  result as well as neighboring tables 3 contain-ing related information, and identifies the keywords that ar e most relevant to the profiles of these stocks. These keywords form the context of the input query. In this example, these keywords are  X  X BM X ,  X  X RCL X ,  X  X SFT X  (obtained from the stocks table) and  X  X atabase X ,  X  X oftware X  (obtained from th e company profile tables). These keywords are then used to retrieve relevant news stories and related advisories and r e-ports using the search engine, which are then returned to the application along with the SQL query result.

As illustrated in the above example, SCORE computes the context of the input SQL query by analyzing not only the in-formation present in the result of the query, but also relate d information present elsewhere in the database. This related information is found by exploiting the semantic informa-tion (foreign-key dependencies) embedded in the database. Moreover, since traversing all potentially related inform a-tion present in the database does not scale, SCORE heuris-tically determines what subset of the available informatio n to focus on.

SCORE X  X  approach to integrating structured and unstruc-tured information has several advantages over the existing tables reachable from the stocks table through foreign keys ; these include tables containing company profiles, etc. approaches to the problem. Some of these advantages are listed below (ref. Section 2 for a detailed discussion.): As a result of the above unique advantages of its approach, SCORE can work with an existing product/technology that interfaces with an RDBMS using SQL (e.g. SQL-based publish-subscribe systems), and gracefully extend it to re -trieve relevant documents from an external source. In such an extended environment, SCORE would exist as a loosely coupled component with minimal intrusion into the core of the given product/technology.
 Contribution. Clearly, the hardest task in SCORE is iden-tifying the context of the input query X  X hat is, deriving the set of keywords that succinctly represent the information need of the input SQL query. The naive solution that in-cludes every term available in the query result is not appro-priate, since the resulting set is very likely to be a potpour ri of unrelated terms. The focus of this paper is thus on tech-niques to pick relevant and informative keywords from the entire set of available terms in the database. The main tech-nical contributions of this paper are as follows: Organization. The rest of this paper is organized as fol-lows. We begin with a discussion of related work in Sec-tion 2. In Section 3, we present the algorithm for comput-ing the context of a SQL query. The related implementation approaches are discussed in Section 4. A preliminary perfor -mance study is presented in Section 5 and an anecdotal ex-ample appears in Section 6. Finally, in Section 7, we present the conclusion and interesting future work directions.
There has been significant work in both the DB and IR communities towards integrating unstructured and struc-tured data into a single physical system [13, 10]. Several vendor database systems provide full text search embed-ded within SQL [20, 16, 11]. SCORE simplifies the use of this feature by automatically suggesting the appropriat e set of keywords for querying the unstructured data. More-over, unlike current information integration solutions [1 5, 18], SCORE does not need the user (or the DBA) to design a common schema , a task that needs considerable skill on the part of the user and can, at best, be semi-automated.
WHIRL [9] supports  X  X imilarity X  joins between text-based fields in database tables. Chaudhuri et al. [7] address joins between the structured data and unstructured data (virtu-alized as tables) in a loosely coupled system. WSQ [14] uses virtual tables as an interface to a search engine; integra-tion with the unstructured data is simulated by including joins with these virtual tables in the SQL query. To formu-late the joins in each of these systems, the user needs to be aware of the specific columns to be used in the search. In contrast, the specific columns and rows from which the key-words are picked are determined automatically in SCORE, and can vary across different executions of the query as the database gets updated and the focus of the query result changes. Moreover, in these approaches, each row in the query result is associated with unstructured data indepen-dently of the other rows in the query, unlike SCORE.
A related approach involves populating pre-defined tables using information extracted from the unstructured data. These tables can then be queried and analyzed along with the existing structured data (e.g. [8]). In this approach, t he user has to define apriori what information to extract from the text. SCORE, on the other hand, handles association of unstructured content with structured data based on full-te xt search, which is more general.

Fisher and Sheth [12] make a case for finding similarities in the metadata across structured and semi-structured data and exploiting these similarities for information integra tion. These solutions essentially rely on a high quality domain ontology for their operation [19]. SCORE, in contrast, does not need any external semantic information. However, if an ontology is available, then SCORE can be easily extended to exploit the same.

The context computation step in SCORE is also concep-tually similar to question-answering and query-expansion in Information Retrieval [2]. Question-answering typical ly takes as input a natural language query (e.g.  X  X ho invented the relational database model? X ) and generates a ranked list of possible answers, ideally containing the right answ er ( X  X . F. Codd X ) with a high rank. Query-expansion, on the other hand, starts with an initial set of keywords (the searc h query) and, by explicit or implicit relevance feedback, add s in additional keywords relevant to the user X  X  information needs. Context computation in SCORE is similar as it starts with an empty set of keywords, and adds keywords to this set. However, this feedback comes from a source (the struc-tured database) that is different from the source that is to be queried, and is more focused since it is based on the se-mantic information embedded in the database.

Recent research [5, 1, 3] on enabling keyword-based query on (relational) databases can be used to integrate structur ed and unstructured data sources by enabling keyword-based query as the common medium of retrieving data from both the sources. While this has the advantage of simplicity, the re is an accompanying loss in expressibility, as compared to SQL, in querying the relational database X  X his is because, as mentioned earlier, the keyword-based query paradigm as-sumes that the user knows the relevant terms that can en-code her information need. SCORE, on the other hand, allows the user to express the information needs in terms of the more expressive SQL (cf. Example 1). Nevertheless, one way to look at the context computation in SCORE is as an inverse of the keyword search in databases X  X ontext computation determines a minimal set of terms in the query result that, when given to the keyword search in databases engine, would return roughly the same query result with a high rank.
In this section, we discuss the techniques used in SCORE to compute the context of a given SQL query. First, in Sec-tion 3.1, we provide a working definition of the context of a query. Based on this definition, we develop an algorithm to compute the context from the result of the input query, with-out any augmentations. Next, in Section 3.2, we show how to determine the optimal augmentation of the query from the several alternatives, and how to extend the algorithm of Section 3.1 to work on the result of the augmented query. The consolidated algorithm is presented in Section 3.3.
Consider a query Q on a single table R , 4 and let Q ( R ) denote the result of the query Q . We model the context of Q as the set of terms that (a) are popular in Q ( R ), and (b)
While this discussion is limited to single-table queries fo r sake of clearer exposition, the extension of the ideas to the multi-table query case is not hard. are rare in R  X  Q ( R ). Intuitively, these terms differentiate the query result Q ( R ) from R  X  Q ( R ), the remaining rows in the table.

Let N Q ( A, t ) denote the number of rows in which the term t appears in the column A  X  cols ( Q ) (formally, N Q ( A, t ) = |  X 
A = t ( Q ( R )) | ). Further, let N R ( A, t ) denote the number of times the term t appears in the column A  X  cols ( R ) (formally, N R ( A, t ) = |  X  A = t ( R ) | ). Then, for a term t  X  A where A  X  cols ( Q ), SCORE measures the term t  X  X  relevance to the query Q as:
T W ( A, t ) = N Q ( A, t )  X  log 1 + | R | X  X  Q ( R ) | In the above, the first expression measures the popularity of t in Q ( R ) while the second expression measures the rarity of t in R  X  Q ( R ). 6
A straightforward algorithm to compute the context of a query Q is to rank the terms in the query result on the basis of T W ( A, t ) and pick the top N terms, where N is a user defined parameter. In the next section, we extend this algorithm to look for the context beyond the given query result.
The algorithm presented in the previous section computes the context of a query from its result. In this section we extend the algorithm to look for the context beyond the given query.

A simple way to include more terms of relevance to a particular row in the query result is to look at columns that are present in the underlying tables in the database, but do not appear in the query result because they are projected out for convenience. This is easily incorporated by analyzing t he input SQL query and removing the projection constraints upfront. However, the algorithm so far is still limited to the boundaries of tables that, in effect, are decided by how normalized the database schema is.

Normalization results in distribution of related informa-tion across several tables, connected by foreign-key relat ion-ships. For instance, consider a bio-classification databas e with two tables: Species with one row per distinct species and Genus with one row per distinct genus. The information about the genre of a particular species in the Species table is encoded as a foreign key  X  X ointing X  to the corresponding row in the Genus table. In this section, we show how the algorithm presented in the previous section can be extended in order to exploit these relationships among the tables.
Before we get into the details of this extension, it is impor-tant to realize that there are two ways in which the foreign key relationships can be exploited. The first, as illustrate d above, is by following the foreign-key  X  X ointers X  in the for-ward direction; this takes us from sub-concepts to encom-passing super-concepts X  X or instance, from species to thei r
We abuse notation in this paper, with t  X  A meaning |  X 
A = t ( Q ( R )) | &gt; 0.
This definition of T W is in the spirit of the  X  X f-idf X  weight-ings commonly used in Information Retrieval literature [2] ; it is intuitive and works well on our benchmark. However, we emphasize that SCORE is extensible enough to support reasonable alternatives. genus in the bio-classification database. In relational ter ms, this involves joining with tables referenced by foreign key columns present in tables included in the query. The second way is by following the foreign keys in the backward direc-tion; this takes us from super-concepts to all encompassed sub-concepts X  X or instance, from genus to all the species in that genus in the bio classification database. In relational terms, this involves joining with tables that contain forei gn key columns that reference tables included in the query.
Currently SCORE exploits the foreign-key relationships in the forward direction only. This is justified since ex-ploration in the forward direction works well in most tar-get applications. For instance, the Star/Snowflake schema, commonplace in the OLAP/BI environments, consists of a  X  X act X  table with foreign-keys to multiple  X  X imension X  ta-bles, and queries on this schema typically involve the fact table. Exploiting backward relationships is an interestin g future work.
Moving back to the details of the algorithm, recall that for each row in the query result, we want to follow the foreign-key pointers and gather more terms, beyond those present in the query result. In relational terms, this amounts to augmenting the query by adding a foreign-key (left-outer) join with the referenced table. Note that, with this per-spective, following foreign keys in the forward direction a lso has the desirable effect that the extra information is just an appendage to the original query result, which remains untouched. In other words, the original query result can be extracted from the augmented query result by simply reintroducing the projection constraints; formally, if Q is the original query and AQ is the augmented query then
In essence, thus, the algorithm aims to extend the in-put query (with its projection constraints already removed ) by augmenting with other tables in the database reachable through foreign-key relationships. To achieve this, two is -sues need to be addressed. First, joining with all possible tables reachable through foreign-key relationships might be too expensive, and unnecessary, and we need to select a sub-set. In the rest of this section, we show how SCORE selects the optimal subset from the possible alternatives.
Since we need to limit the computation involved, we define a parameter M as the maximum number of tables that can be augmented to the query. Ideally, we would like to select a subset of M tables on which the query has maximum focus; but before we can do that, we need to quantify the focus of the query on a table.

Let F  X  cols ( Q ) be a foreign-key column in the query, and let R be the table referenced by F 7 Since each term t in the column F references a single row in R , we can in-terpret T W ( F, t ), our measure of the query X  X  focus on the term t (Section 3.1), as a measure of the query X  X  focus on the corresponding row in R as well. Now, given two foreign-key columns F A , F B  X  cols ( Q ) referencing tables R A R B respectively, we say that the query is more focused on R
A than on R B if there exists a term t  X  F A such that the We assume that each foreign key references a unique table. In case foreign keys F 1 and F 2 both reference the same table R , then we alias (clone) R into R 1 and R 2 and interpret the latter as two different tables (same semantics as R AS R 1 R AS R 2 in SQL X  X  FROM clause). query X  X  focus on t is more than its focus on any term in F The focus of a query Q on the table referenced by a foreign-key column F  X  cols ( Q ) is accordingly measured using a column weight function CW defined as:
A simple-minded algorithm to select the optimal subset of tables could thus be to find, by traversing the schema graph, all the tables reachable from the tables already present in the query by foreign-key relationships and pick the M ta-bles with the maximum focus. However, this algorithm is not practical X  X ot only because it is exponential-time in the number of tables, but also because the query X  X  focus on a table is known only if the corresponding foreign key F  X  cols ( Q ) (in other words, we only know the query X  X  fo-cus on the tables directly referenced by the query, but not on the tables referenced in turn by the foreign-keys in these tables).

In SCORE, thus, we follow a greedy strategy wherein we iteratively build up the set of tables to augment with. The algorithm maintains the set S of candidate foreign-key columns in the query as augmented so far (call this the aug-mented query AQ ); since S  X  cols ( AQ ), we know CW ( F ) for each foreign key column F  X  S . In each iteration, the algorithm picks F  X  S with the maximum CW ( F ) and aug-ments AQ with the table referenced by F ; as it does so, it computes the weights of the foreign-key columns added as a result and replaces F in S by these foreign keys. The algorithm is presented formally in Section 3.3.
Since the terms in the columns added as a result of the query expansions as discussed above are not part of the orig-inal query result, it can be argued that the weights of these terms should be scaled down. Since this is subjective, de-pending on the way the data is structured and on the specific queries that form part of the workload, we leave the decision to the user (or the DBA) and define a tunable scaling param-eter  X   X  [0 , 1] that scales down the weights of these terms from what they would have been if these columns formed part of the original query. For all the cases we came across, however, it seemed reasonable to take  X  = 1 (no scaling).
The discussion so far on how to compute the context of a given query leads to the algorithm in Figure 2. In this section, we describe this algorithm in detail.
 The procedure QueryContext takes as input the query Q . The first step (line 1) is to remove the projection constraint s in Q (ref. Section 3.2). Next, the set S of the initial can-didate foreign-key columns is constructed (line 2) and CW is computed for these columns (lines 3-4). The procedure next enters a loop, wherein in each iteration (lines 6-14) it picks the most  X  X romising X  candidate foreign-key, joins wi th the referenced table and computes CW for the foreign-key columns added to AQ as a result, closely following the dis-cussion in Section 3.2.2. The loop exits when no more can-didate foreign keys exist, or when M augmentations have already been performed. The terms in AQ  X  X  result are then, as discussed in Section 3.1, ranked according to their term weights ( T W ), and the top N terms, along with the cor-responding column names and their overall weights, are re-turned as the context of the query Q (lines 15-16).
In the previous section, we formalized the context com-putation process in terms of an algorithm. The challenge in efficiently implementing this algorithm (cf. Figure 2) arise s primarily due to the interplay between the term weight com-putations and the query augmentations in the algorithm. Recall that in every iteration, in order to decide which fore ign-key column to follow, the algorithm needs the column weights CW ( F ) of the foreign-key columns F  X  S at that point; however, to compute the same, the algorithm needs to know all the terms t  X  F and their distribution in the query re-sult, so that it can compute T W ( F, t ). We considered three alternate implementation approaches.

The Brute-Force Approach (BFA) solves this problem by actually executing the augmented query so far before each iteration. Furthermore, after all the augmentations are done, the final query is executed as well and the result used to compute the context. Advantages: Simplicity. Follows the algorithm exactly. Disadvantage: Does not scale.
The Simple Histogram-based Approach (SHBA) refines the Brute-Force approach by exploiting histogram-based estimation techniques [21] to avoid expensive query executions. Only the initial query is actually executed; th e term-weights and column-weights on the augmented columns in each step are estimated using histograms. Since the qual-ity of the context relies on value correlations across colum ns, the one-dimensional histograms are not appropriate for the se estimations X  X e need two-dimensional histograms. Unfor-tunately, since DB2 does not support two-dimensional his-tograms, these histograms are computed in a preprocessing step and stored locally. However, note that the augmenta-tions are essentially foreign-key joins. Thus, in order to e sti-mate the distribution of a column added as a result, we only need the two-dimensional histograms for the column against the underlying table X  X  primary key; the extra space needed to store these histograms is thus not significant. Further note that since primary keys are involved, the histograms necessarily needs to bucket the primary key values. Advan-tages: Efficient, scales well. Disadvantages: Term and column weight estimations using histogram might result in different choices in augmentation as compared to the exact brute-force approach. Thus, the returned context may not include some keywords present in the brute-force implemen-tation X  X  context ( X  X alse-negatives X ). Furthermore, sinc e the bucketing of the primary keys in the histograms makes rele-vant values in a bucket indistinguishable from the irreleva nt values, the context might include several irrelevant keywo rds ( X  X alse-positives X ).

The Modified Histogram-based Approach (MHBA) further refines the Simple Histogram-based approach to re-move the false-positives problem. The idea is to augment the queries based on estimated term and column weights, just like the Simple Histogram-based approach; but once the final augmented query has been formed, execute it on the database. The context is then computed based on the exact result of this query, eliminating the possibility of f alse-positives. Advantages: No false-positives. Efficient, scales well. Note that since histograms are only used for augmenta-tion, for a given table, only the two-dimensional histogram s for the foreign-keys in the table against the table X  X  primar y key are needed. Disadvantages: False-negatives X  X he re-turned context may miss some relevant keywords; however, as we demonstrate in Section 5, the difference is marginal on our benchmark.
In this section, we present a preliminary experimental study to evaluate the techniques and design decisions pro-posed above.
 System Parameters and Configuration. For the pur-pose of this experimental study, the parameters M , N and  X  (ref. Section 3) were assigned values 3, 10 and 1.0 respec-tively. Each histogram consisted of only the top 1000 buck-ets; the remaining buckets were assumed to be of equal size. The implementations were done in Java with J2SE v1.4.2 (approx. 3000 lines of code), and executed on a Pentium-M 1.5 GHz IBM Thinkpad T40 with 768 MB RAM running Windows XP SP1. The relational database used was IBM DB2 v8.1.5 co-located on the same machine. The page size was 4KB and the associated total bufferpool size was 250 pages (1000KB). The communication between SCORE and DB2 was through JDBC.
 Dataset. The evaluation was performed on a subset of the Open Music Directory data (http://www.musicmoz.org) containing information about 10 6 music tracks, 10 5 records, 10 5 members and 3  X  10 4 bands, each stored in a separate table and linked using foreign keys. To make the schema more complex, we introduced a dummy table and added foreign keys to this table from the other tables. The total size of the dataset was 116 MB.
 Workloads. The generated workloads consist of selection queries resulting in a specified number N T RACKS of tracks; for each query, the specific N T RACKS tracks are chosen such that they have a common band (called band queries), or a common record (called record queries). These workloads are generated randomly from the data given N T RACKS as a parameter and have an equal mix of band and record queries.

Each generated query is also associated with a target con-text term  X  X hat is, the term of maximum relevance to the query among all the terms in the database. Specifically, each band/record query has the band/record X  X  name (as men-tioned in the corresponding row in the bands/record table) as its target context term.
 Evaluation Metrics. This study uses the following metrics for measuring context quality and computational overheads . Context Quality Metric: Recall that the target context term t Q is, by design, the term in the entire database most relevant to the query Q . Thus, we expect t Q to be the the highest ranked keyword in the context returned by SCORE for each query. We choose a quality metric that quantifies this expectation. 8
Given the query Q , let t Q be its target context term and let C ( Q ) = [ t 1 , t 2 , . . . , t N ] be the list of N keywords re-trieved by SCORE as its context, ranked in decreasing order of their term-weights. We define the Reciprocal Rank (RR) of SCORE for the query Q as: The Mean Reciprocal Rank (MRR) of SCORE on a query workload S is then defined as MRR(S) = 1 | S | P Q  X  S RR ( Q ), i.e. the mean RR of SCORE over the queries Q  X  S .
We use this MRR as our quality metric in the experiments in this section. MRR is not a novel metric; in fact, it is the standard metric for the quality of Question-Answering systems in IR [24], a closely related problem (ref. Section 2 ). Computational Overhead Metric: We measure the com-putational overheads in terms of the additional time spent on a query when using SCORE as compared to when not using SCORE.
 EXPERIMENT 1 Purpose: To evaluate efficacy of the query augmentation algorithm and study how augmenting the queries impacts the context quality and computational overheads for BFA, SHBA and MHBA respectively.
 Methodology: We generated a workload with fixed result size N T RACKS = 32, and for increasing number of aug-mentations M = 0 (no augmentation), 1 , 2 , 4 and 8 invoked the BFA, SHBA and MHBA implementations for the work-load and computed the respective MRR and the overheads. Result: The quality (MRR) and overhead results are sum-marized in the following table. Discussion: Recall that the target context term for a record query is reached after augmentation with the records table, while that for a band query is reached after augmentation
Note that we measure the quality of the context instead of the quality of the search results. This is because (a) the search engine is an external component in SCORE, and factoring its quality in this evaluation is not fair, (b) the techniques proposed in this paper only involve obtaining th e context, and (c) assuming that the search engine is well-behaved in the sense that better quality context will lead to better quality search results, measuring the quality of the context is equivalent to measuring the quality of the corresponding search result. with both the records and the bands table. 9 We see that the MRR for BFA improves from 0.00 for no augmentation (expected, since the target context term is not present in th e TRACKS table) to 0.47 for M = 1 (most record queries find the target context term) and 0.98 for M = 2 (most record and band queries find their target context term). This im-plies that for almost all queries in the workload, the aug-mentations occur in the optimal order, clearly validating the choice of T W and CW , and attesting to the efficacy of the context computation algorithm.

However, BFA X  X  accuracy comes at the price of a high overhead. Comparing with the results for SHBA, we see that using in-memory histogram-based estimations instead of actually querying the data results in drastic reduction o f the overheads, but the MRR falls drastically as well. In contrast, the MRR for MHBA is almost the same as that for BFA and, surprisingly, is achieved with even less over-head than SHBA for M &gt; 2. This happens because, as the number of augmentations increase, so do the number of augmented columns; eventually, for M &gt; 2, the overhead for estimating the distributions for all the augmented columns becomes more than the cost of actually evaluating the final augmented query.

Overall, for all the approaches, the overheads increase rapidly with increasing number of augmentations; the in-crease is highest for BFA and the lowest for MHBA. For MHBA, however, the overhead of 92 ms for even M = 8 is not very significant. We thus conclude that MHBA is clearly the implementation of choice, achieving a quality compara-ble to BFA with a very reasonable overhead even in the presence of a large number of augmentations.
 EXPERIMENT 2 Purpose: To study how increasing query size impacts the context quality and computational overheads for BFA, SHBA and MHBA respectively.
 Methodology: We generated workloads with result size N T RACKS = 12 , 20 , 28 , 36 , 44 and 52 respectively. For each workload, we invoked each SCORE implementation and computed the respective MRRs and the overheads. (The number of augmentations were fixed at M = 4.) Result: Summarized in the following table.
 Discussion: The results further corroborate our observa-tions in Experiment 1 about the relative context quality determined by the respective approaches and their relative overheads. In these results, we further observe that the ove r-head for BFA increases rapidly with increasing query size. The overhead for MHBA, in sharp contrast, shows a very slow and roughly linear increase. It is again evident that MHBA is consistently more efficient as compared to SHBA; the overhead for MHBA even for a query size of 52 rows is 68 ms, which is again very reasonable, almost one-third of the corresponding overhead for BFA. These observations
Incidentally, this motivates the need to explore beyond the query result that spans only the tracks table. clearly validate the design choices made in formulating the MHBA approach.
 EXPERIMENT 3 Purpose: To study how increasing the number of buck-ets per histogram (equivalently, memory overhead) impacts the context quality and computational overheads for BFA, SHBA and MHBA respectively.
 Methodology: We generated a workload with result size N T RACKS = 32. Then, fixing the number of buckets per histogram (NBUCKETS) as 125, 250, 500 and 1000 respec-tively, we invoked each SCORE implementation and com-puted the respective MRRs and the overheads. (The num-ber of augmentations were fixed at M = 4.) Result: Summarized in the following table.
 Discussion: From the results, we note that SHBA is most sensitive to NBUCKETS; this is expected since it performs most computations on the histograms. Each histogram mul-tiplication performed is roughly linear in NBUCKETS; how-ever, given the large number of histograms involved (one per column in the augmented query), the overall increase is very rapid. In contrast, MHBA performs histogram compu-tations only for the foreign key columns in the augmented query, which are a small fraction of the total number of columns. Accordingly, MHBA X  X  overhead increases rather slowly with increasing NBUCKETS. The context quality of SHBA and MHBA improves with increasing NBUCKETS.
 For NBUCKETS = 125, the fraction of the database repre-sented in the histograms is small, leading to a large number of false-negatives in SHBA and MHBA. However, even at such a small value of NBUCKETS, MHBA achieves MRR of 0.60, which is encouraging. As NBUCKETS increases, the fraction of the database represented in the histograms increases, leading to fewer false-negatives and therefore a better quality context. (BFA context computation does not involve histogram operations; BFA results appear in the re-sults above as a baseline.) EXPERIMENT 4 Purpose: To study how increasing the database size im-pacts the computational overheads for MHBA.
 Methodology: We generated a workload with result size N T RACKS = 32. Starting with the initial database of size 116MB, we generated artificial datasets of size 232MB, 464MB and 928MB by repeated duplication. For each gen-erated database, we invoked the MHBA SCORE implemen-tation and computed the respective overheads on the gen-erated workload. (The number of augmentations were fixed at M = 4).
 Result: Summarized in the following table.
 Discussion: MHBA scales well with increasing DBSIZE. Even for DBSIZE of 928MB, the overhead is only 571ms. This is because the augmentations introduced in the input query are merely foreign-key joins that can efficiently explo it the primary key indexes for fast execution.
The following query, that selects ten titles by The Beatles, was executed on the dataset mentioned in Section 5:
In response to the above SQL query, SCORE (MHBA im-plementation) returns the following context: As we can see, the input SQL query was augmented with the RECS , MEMBER and BAND tables. The system identified  X  X eorge Harrison X  and  X  X uitarist, vocalist, sitar X  from th e MEMBER table, and  X  X he Beatles X  from the BAND table as the most relevant terms, which is encouraging. It also identi-fied the band X  X  foundation year, its foundation name and its country from the BAND table, and the style from the RECS table. Apart from these keywords from the neighborhood, the context includes, with lower weight, the tracks titles themselves.

Notice that SCORE is able to filter out terms such as  X  X D X  in RECS.format that relate little to the input query even though they are present in most rows of the query re-sult. This validates our choice of T W (ref. Section 3.1), that not only considers the popularity of a term in the query re-sult, but also its rarity in the rest of the underlying databa se.
In this paper, we introduced a context-oriented approach to associate unstructured content with structured databas e query results and described the design and implementation of SCORE, a system based on this approach. We developed an efficient algorithm to compute the context of a SQL query by analyzing the query result as well as related information elsewhere in the database. The computed context is used to retrieve relevant unstructured content and associated wit h the result of the given SQL query. We also described the im-plementation challenges involved, and presented a solutio n that achieves high context quality with reasonable overhea ds by judicious exploitation of available histogram informat ion. Finally, we presented an experimental study that showed that SCORE is able to compute the high-quality context of SQL queries with reasonable performance overheads.
SCORE, as discussed in this paper, associates unstruc-tured content as a whole with the entire query result; we are currently working in an extension wherein the query re-sult is first clustered based on the context [4], and then rele -vant unstructured content is associated with each individu al cluster. An interesting future direction for this work is to incorporate the ideas here in an XML/XQuery environment. Also, instead of considering the context of a single, isolat ed query, it would be interesting to investigate the context of an entire query session instead. As mentioned earlier, we also plan to extend SCORE by enabling it to exploit the foreign-key relationships in the backward direction as wel l.
