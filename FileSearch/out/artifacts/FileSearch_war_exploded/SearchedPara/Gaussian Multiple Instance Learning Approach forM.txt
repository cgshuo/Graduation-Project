 In this paper, we present a computationally efficient algo-rithm based on multiple instance learning for mapping infor-mal settlements (slums) using very high-resolution remote sensing imagery. From remote sensing perspective, infor-mal settlements share unique spatial characteristics that dis-tinguish them from other urban structures like industrial, commercial, and formal residential settlements. However, regular pattern recognition and machine learning methods, which are predominantly single-instance or per-pixel classi-fiers, often fail to accurately map the informal settlements as they do not capture the complex spatial patterns. To overcome these limitations we employed a multiple instance based machine learning approach, where groups of contigu-ous pixels (image patches) are modeled as generated by a Gaussian distribution. We have conducted several experi-ments on very high-resolution satellite imagery, represent-ing four unique geographic regions across the world. Our method showed consistent improvement in accurately iden-tifying informal settlements.
 H.2.8 [ Database Applications ]: Data Mining; I.5 [ Pattern Recognition ]: Models X  Statistical  X 
P repared by Oak Ridge National Laboratory, P.O. Box 2008, Oak Ridge, Tennessee 37831-6285, managed by UT-Battelle, LLC for the U. S. Department of Energy under contract no. DEAC05-00OR22725.  X  (Partial) support for this work was provided through Scientific Discovery through Advanced Computing (Sci-DAC) program funded by U.S. Department of Energy, Office of Science, Advanced Scientific Computing Re-search (and Basic Energy Sciences/Biological and Environ-mental Research/High Energy Physics/Fusion Energy Sci-ences/Nuclear Physics) Spatial Data Mining, Remote Sensing, MIL
Multi-spectral remote sensing imagery is widely used in mapping settlements, forests, crops and other natural and man-made objects on the Earth. On the other hand, very high resolution (VHR) imagery is useful in mapping complex patterns, such as formal and informal settlements. VHR im-age classification poses several challenges because the typi-cal object size is much larger than the pixel resolution. Any given pixel (spectral features at that location) by itself is not a good indicator of the object it belongs to without looking at the broader spatial footprint. However, exist-ing per-pixel (single instance) based thematic classification schemes are designed for moderate spatial resolution (10 me-ters and above). This is not to say that well-known single instance learning algorithms are not applicable in classify-ing VHR images, in fact they are highly effective in iden-tifying primitive objects such as buildings, roads, forest, and water. However, what we are pointing at is that the single-instance learning algorithms are inadequate in mod-eling complex (spatial) patterns. The same limitations are also applicable to spatial contextual classifiers (e.g, Markov Random Fields ), as these classifiers look at the immediate neighboring pixels to modify the label of a single instance. Therefore, there is a great need for newer approaches which looks at a bigger window or image patch (consisting 100 X  X  of adjacent pixels) in building a classification model.
In this work, we present a classification framework based on image window or patch (multi-instance) learning for map-ping informal settlements using VHR images. From remote sensing perspective, informal settlements share unique spa-tial characteristics that distinguish them from other urban structures like industrial, commercial, and formal residen-tial settlements [10]. To overcome the limitations posed by single-instance classifiers in modeling complex patterns, we developed a novel multi-instance based machine learning ap-proach, which showed improvements in accurately identify-ing informal settlements. We have conducted several experi-ments on high-resolution satellite imagery, representing four unique geographic regions across the world.
With the recent launch of satellites by private companies such as Digital Globe (e.g., WorldView-2 in late 2009), ap-plications around very high resolution (VHR) imagery (sub-m eter) are emerging fast. Such imagery provides new oppor-tunities to monitor and map both natural and man made structure across the globe. For past several years, we are engaged in developing several new approaches to efficiently process these imagery to support applications of national importance, such as biomass monitoring [6,7], nuclear pro-liferation monitoring [22,24], and settlement mapping [10] at finer spatial and temporal scales. Mapping informal settle-ments is an important task both from national security and as well as humanitarian grounds. The high rate of urban-ization, political conflicts and ensuing internal displacement of population, and increased poverty in the 20 th century has resulted in rapid increase of informal settlements. These un-planned, unauthorized, and/or unstructured homes, known as informal settlements, shantytowns, barrios, or slums, pose several challenges to the nations as these settlements are often located in most hazardous regions and lack basic ser-vices. Though several World Bank and United Nations spon-sored studies stress the importance of poverty maps in de-signing better policies and interventions, mapping slums of the world is a daunting and challenging task. This work is a step towards developing a computationally efficient and automated framework that is capable of detecting new set-tlements (especially slums) across the globe.
Most of the existing classification approaches work with spectral features (e.g., blue, green, red, thermal infrared) and derived features (e.g., texture, band ratios like Normal-ized Difference Vegetation Index (NDVI), Histogram of Ori-ented Gradients (HOG)), extracted from each pixel (spatial location). This process is shown in Figure 1. Typical classifi-cation involves: (i) collection of ground-truth (training/test) data at few locations (Figure 1(a)) in the image for sim-ple thematic classes (e.g., urban, water, forest, agriculture) or finer classes (e.g., high-density urban, low-density urban, deep water, shallow water, hardwood forest, conifer forest, soybean, wheat, corn), (ii) build a classification model (e.g., Naive Bayes, decision trees, neural networks), and (iii) pre-dict labels for entire image (Figure 1(b)). A review of these techniques can be found in [10,25].
 Figure 1: Raw satellite image and the corresponding c lassified image
An improvement over per-pixel classification schemes are the spatial classification schemes such as MRF [18]. Most classification schemes model the correlations in feature space and often ignore spatial correlations in spatial data, such as satellite images. In spatial classification schemes both spatial correlations (context) and feature correlations are modeled simultaneously, as a result the final classified image contains much smoother (spatially) class distribution and eliminates salt and pepper noise. Figure 2 compares (a) non-spatial (maximum likelihood) and (b) spatial (MRF) classification schemes. However, it should be noted that both of these schemes based on single instance learners. Figure 2: Classified images: (a) non-spatial, (b) spa-t ial
Though single instance learning schemes are widely used in remote sensing image classification (approximately 30 me-ter spatial resolution), they are mostly applied for discrim-inating simple thematic classes (both aggregate and finer). However with increasing spatial resolution (sub-meter) cur-rent satellite images contains much more spatial heterogene-ity (rich spatial information), see Figure 3. As result, it is possible to extract more complex classes, such as, informal (slums, shanty towns, burrows) settlements from these very high resolution images. Single instance learning (non-spatial or spatial) are ineffective in such cases due to the fact that the size of the pixel (less than one m 2 ) is much smaller than the size of the objects (for example, average building size in US is 250 m 2 ).
 Figure 3: Accra (Ghana) city with two distinct set-t lement patterns speared by hand drawn boundary (red)
One way to overcome single instance limitation is to look a t additional features beyond spectral features, because fea-tures that exploit spatial contextual information are highly useful in the classification of very high-resolution images. Recent studies [10,21,25] show the improved performance of single instance learners when the spectral features are com-bined with a broad set of extended features such as morpho-logical, texture, and edge density. Although these studies showed that the extended features which exploit spatial con-textual information resulted in improved accuracy, the clas-sification schemes utilized are still single-instance learners. For complex object recognition we need to look at a bigger spatial region. Figure 3 illustrates this problem clearly. As can be seen in this figure, humans can easily identify two dis-tinct settlement patterns, north of boundary is formal and south is informal. However, there is not much difference be-tween spectral values if you look at individual pixels drawn for similar objects across the boundary, for example, build-ings. To illustrate this point, we selected two small windows (blue windows) around buildings, window (a) is drawn from informal settlements and window (b) is drawn from the for-mal settlements. These windows are zoomed in Figure 4. As one can see, the difference between these building (at pixel level) is minimal, as a result per-pixel (single instance) classification schemes cannot predict them into formal vs in-formal classes, rather they can accurately predict both into buildings. On the other hand, when you a look at bigger patch as a whole, then it is easy to see the difference between informal and formal settlements, as these patches contains much richer spatial information.
 Figure 4: Two small patches drawn from informal a nd formal settlements in Accra city
Object based classification schemes [3, 15] are one step in that direction. Typically, object based methods seek to segment the image into meaningful objects by exploiting spatial and spectral features. One can build a meta clas-sifier on the features extracted from the objects, for exam-ple, area, perimeter, compactness, shape index, and fractal dimension. Or one can aggregate all feature vectors into a single feature vector and then apply any single instance learning algorithm. However, all these approaches loose im-portant structural and spatial properties in the aggregation process.

Multi-instance (or Multiple instance) learning (MIL) meth-ods have been developed to overcome some of the limitations of single instance learning schemes. Notable approaches in-clude the seminal work of Dietterich et. al. [8], Diverse Den-sity [14], and Citation-KNN [26]. Recently, MIL algorithms have also been applied to remote sensing image classifica-tion as well. For example, in [20] MIL approach is explored for sub-surface landmine detection using hyperspectral (HS) imagery. In [4], authors have developed MIL based binary classification scheme for identifying targets (landmines) in HS imagery. While each of these algorithms have advan-tages and disadvantages over per-pixel based classification schemes, in general they are shown to perform (accuracy) better than single instance learning schemes. Key idea be-hind multi-instance learning schemes is the utilization of all instances drawn from the image patches or windows. In multi-instance learning, the training data consists of many bags (windows) where each bag contains several examples (pixels). A bag is positively labeled if it contains at least one positive instance (e.g., informal settlement) and neg-ative otherwise (e.g., formal settlement). This scheme is conceptually depicted in the Figure 5(a). As shown in this figure, the decision boundary is optimized such that positive and negative bags are separated using decision rule just de-scribed. On the other hand, Figure 5(b) shows traditional single instance learning schemes where the objective is min-imize the number of misclassified (single) instances. Key point to note here is that in multi-instance learning entire bag is assigned a single label, where as in single instance learning a single bag may have both positive and negative instances. Therefore, single instance learning algorithms are appropriate for thematic classification (e.g., roads, build-ings), whereas multi-instance learning algorithms are de-signed for recognizing complex patterns (e.g., informal and formal settlements).
 Figure 5: Decision boundaries resulting from: (a) m ulti-instance learning, and (b) single instance learning In a recent feasibility study we successfully applied Citaion-KNN algorithm for complex settlement mapping [23]. How-ever, the high computational cost of Citaion-KNN has led us to design a computationally efficient algorithm. This al-g orithm is very similar to the Citation-KNN approach in spirit. In Citation-KNN approach, the similarity between bags (patch in image parlance) is determined by minimiz-ing the Hausdroff distance which is computationally expen-sive. As can be seen in the following sections, our proposed method is not only computationally efficient but is also con-sistently accurate than the Citation-KNN algorithm.
The key idea behind the proposed GMIL algorithm is to model each bag as a Gaussian distribution. As a result we are simplifying the computation of similarity measure (e.g., Hausdroff distance) and at the same time capturing the het-erogeneity through the covariance matrix. Parameters of this distribution can be estimated from the training data di-rectly. Since we are abstracting each window (or patch) as a Gaussian distribution, the trained model essentially con-sists a bag of Gaussians (BoG) of size  X  X , X  where  X  X  X  is the number of training bags. We assume a bag representation instead of a set representation, because it may be possible that two Gaussian distributions may be extremely close (or highly overlapping), if not exactly the same. Once we have a BoG model generated from the training data, we can use this model to predict a class label for any new image patch or window. Therefore, the BoG algorithm can abstracted into following key steps.

Basic primitives of BoG algorithm are as follows:
Our objective is to design these steps such that accuracy is maximized while the computational complexity is mini-mized.
In the first step, we divide the image into regular grids, or blocks, or patches. A grid is essentially a square or rectan-gular block whose size (pixels x lines) determines the quality and computational cost of the algorithm. If the grid is too large, it may result in poor representation. For example, larger grids may contain more than a single object, there-fore the Gaussian distribution fitted to the grid may not have a single peak. However, the computation time drasti-cally reduces with the increase in grid size. On the contrary, if the grid size is too small it would increase the computa-tional cost, and may also lead to errors in model parameter estimation and matrix inversion problems. The optimal size is typically dictated by the pixel resolution, typical object sizes found in the imagery, and the number of image bands (i.e., dimensions). Figure 6 shows the grids superimposed on a high-resolution satellite image. In the remaining sections, we refer to the term grid when referencing this first step. Figure 6: User defined grids superimposed on a h igh-resolution satellite image
One of the bottlenecks in image classification is the ac-quisition of the training data. Often an analyst has to ac-curately digitize the object boundaries and label them. By the very design of our algorithm, analyst do not have to digitize at all. An analyst simply displays the image with grids overlaid and picks up a few representative grids by just clicking on the grids for each class (or thematic category). The training acquisition system is integrated with the pop-ular open source QGIS [1]. Resulting training data is shown in Figure 7. Each colored grid represents a class label given by the analyst.
We model the image data in each grid, that is, all multi-dimensional feature vectors from each pixel in the grid, are generated by a multi-variate Gaussian distribution described in the following equation.
The standard multi-variate Gaussian distribution is de-scribed by the parameters mean (  X  ) and covariance matrix ( X ). These parameters are estimated for each grid sepa-rately from the corresponding image data, as shown in Fig-ure 8.
Once BoG model is constructed, then class labels can be predicted based on how similar the new image windows (or patches) are to the examples in the trained model. For each new window, the algorithm works as follows. 1. Compute the probabilistic distance between a given Figure 7: Ground-truth collection system (each c olor represents a unique class) Figure 8: BoG Model Constructed From The Train-i ng Data 2. Rank the distances (similarity score) 3. Assign label to the window (or patch) based on the This prediction process is schematically represented in Figure 9. As shown in the figure, after ranking the computed similarity between a given image (or query) patch and all the training patches,  X  X ormal X  class label is assigned to the query window as it got the maximum votes (3) in comparison to the  X  X nformal X  class. Though the example is shown for two class problem, the actual algorithm is designed for multiple classes.
 Figure 9: Prediction based on similarity (probabilis-t ic distance) measure
This general framework can be adopted for Citation-KNN by simply replacing the modeling and prediction as follow-ing. In addition, single instance learning algorithms can also be applied by transforming the patch into a single feature v ector (e.g., centroid, average).
The training dataset is collected as described previously (section 3.2). Citation-KNN is a simple extension of regular kNN algorithm. In its simplest form (k=1), the kNN algo-rithm assigns a given pixel (feature vector) to the same class label as the closest data point. Though computation of dis-tance (Euclidian or probabilistic) between feature vectors is straight forward, computing distance between bags is not as straight forward. Citation-KNN algorithm uses Hausdorff distance as the distance between two bags. Let us assume that A and B are two given bags, and a i , b j are instances from the corresponding bags, then the distance between A and B is found by minimizing the following equation.
This minimal Hausdorff distance allows regular kNN al-gorithm to be applied to the multi-instance learning. Once all the minimal Hausdorff distances have been computed be-tween query bag and training bags, a simple majority voting is used to choose the label for the query bag. In addition, Citation-KNN uses the notion of reference, that is, a query bag is assigned not only based on its neighbor relationships but also by taking into account the bags that regard the query bag as its neighbor. This citation approach is shown to be more robust to the noise in the training data.
We now briefly describe four major classification schemes used to evaluate the performance against the Citation-KNN and the GMIL classification schemes. Given an n  X  vector y of observations and an n  X  m matrix X of explanatory data, classical linear regression models the r elationship between y and X as y = X  X  +  X  . One simple way to extend regression for classification is to perform re-gression for each class. While this simple extension works for classification, it violates the basic assumptions of regres-sion. That is, errors are statistically independent and nor-mally distributed because the observations ( y ) take only 0 and 1 values. Logistic regression [9,13] does not suffer from these limitations. In the case of Logistic regression, the tar-get variable ( y ) is transformed via the Logistic function and the dependent variable is interpreted as the probability of finding a given class.
Random forests is an ensemble method used to construct a series of decision trees. Each tree is constructed on a different training dataset of the same size generated by ran-dom sampling, with replacement from the original training dataset. Random forests retain many benefits of decision trees and avoid pruning. Random forests have also shown to generalize well, and accuracies are typically higher than a single tree. Uses of random forests for image classification can be found in [11].
Artificial neural networks, which are non-parametric clas-sifiers as opposed to Bayesian classifiers, are gaining popu-larity in remote sensing image classification. This popular-ity can be attributed to several factors: 1) previous stud-ies [2,16] have shown that their performance is as good as MLC and in many cases more accurate, 2) they are non-parametric, so they are capable of classifying multi-source data, and 3) they have several desirable characteristics like nonlinearity, adaptability, and fault tolerance.

The use of neural networks in remote sensing data anal-ysis has been somewhat limited until recent years because of the complexities associated with establishing suitable pa-rameters for network training, the lack of knowledge about the internal workings of networks (especially how they di-vide the feature space), and lack of comparative studies. The previous  X  X lack box X  view of neural networks  X  which limited its use  X  is now clear with the insights provided by recent studies [12], [19], [17]. Several recent studies [5], [2], [16] were also focused on comparing statistical and neu-ral network classification of remote sensing data. We used the Multi-layer perceptrons (MLP) architecture in this ex-periment.
One of the simplest Bayes classifiers is naive the Bayes (NB) classifier. In the general Bayesian setting, it is assumed that the samples in feature space are correlated, meaning greater emphasis is placed on an accurate estimation of the covariance matrix ( X ). One challenge in estimating the full covariance matrix is that one needs a large number of train-ing samples. This assumption is relaxed in a NB classifier, where it is assumed that features are independent. That is, a naive Bayes classifier assumes that the presence (or ab-sence) of a particular feature of a class is not dependent on the presence (or absence) of other features. As a result, the full covariance matrix does not have to be estimated. In-stead, estimation of variance is sufficient to construct a NB classifier. With independent feature assumption, the Gaus-sian distribution simplifies to:
Four cities were chosen for this study to thoroughly eval-uate the performance of the proposed algorithm. The cities chosen are as follows: Accra (1), Caracas (2), La Paz (3), and Kandahar (4). The population estimate in 2010 for Caracas and La Paz was 3.098 million and 1.69 million, re-spectively. As of 2006 estimate Kandahar has population of 468,200. The imagery used for this study is came from the DigitalGlobe CityShere database. Spatial resolution is 0.6m and each image has 3 spectral bands.

We chose these four cities as they represent diversity in terms of different climates, cultures, and economies. Cara-cas, Kandahar, and La Paz reside in a tropical, dry, semi-arid, and sub-tropical highland climate, respectively. Cara-cas, which has one of the largest  X  X ega-slums X  on the planet, has an estimated 44% of its population living in informal settlements. Table 1: GMIL test accuracy (contingency table) for A ccra city
City C-KNN Log.Reg. RF MLP NB GMIL 1 76.25 71.25 72.08 69.58 75.66 95.66 2 82.96 78.15 81.85 81.81 74.07 85.00 3 80.97 77.17 78.26 80.23 76.08 83.25 4 79.78 64.89 69.14 73.93 60.10 81.20 Table 2: Overall classification accuracy for each s tudy site
For each study site, we have chosen roughly 4% of grids for training data. Couple of domain experts who have close knowledge about these cities then labeled these grids. The classes considered for these cities are: formal (F), informal (I), vegetation (V), bare soil (B), and water (W). This data is then divided into independent training (40%) and test (60%) datasets. Trained model is then used to predict la-bels for entire study site. The performance is evaluated by constructing contingency table. Table 1 shows the contin-gency table for GMIL classifier for Accra. Reporting full contingency table for each city and each classifier would be overwhelming, therefore for simplicity we are just reporting the overall accuracies. The overall classification results were summarized in the Table 2.

As can be seen from the table, GMIL performs better than all other classification schemes. It is interesting to note that Citation-KNN model is also performed better than single instance approaches. Figure 10 shows the GMIL classifica-tion output (overlaid on raw image) of the Accra city. As single instance learning algorithms can X  X  be directly applied on the bags, we did post-processing by converting grids into a single class by applying majority vote ( Modal filtering ).
Though the performance of Citaiton-KNN is close to GMIL except in Accra, the computational complexity makes it in-feasible for image classification. Let n be the average number of instances per bag, and N be the number of training bags, and d be the number of dimensions, then the computational complexity of Citation-KNN is O ( n 2 Nd ). As a result this al-gorithm can not be applied to large images. Computational complexity is greatly reduced for GMIL as we are computing the distance between two distributions rather than the n 2 pair-wise distances between instances across the bags. To measure the actual difference in cpu-time, we ran the ex-periment on a very high-resolution (1 m 2 ) multispectral (3 bands) satellite imagery. The image cropped to 1 km 2 con-sisting of 1,000 x 1,000 pixels. This image is then divided into 10,000 blocks where each block consists of 10 x 10 pix-els. Of these 10,000 blocks, we have selected 380 blocks for training. This data is divided into independent training Figure 10: GMIL Classified Image Overlaid on Raw I mage (130 blocks) and test (250 blocks) datasets. We ran both GMIL and Citaion-KNN algorithms on a single node with two dual Xeon hex-core processors (3.46 GHz) with 48 GB of 1333 MHz ECC DDR3 memory. Even for this small im-age, Citation-KNN took about 27.8 hours, where as GMIL took 3.1 hours. GMIL is 9 times faster than Citation-kNN in addition to being more accurate on all study sites. Though GMIL is faster, it requires parallel implementation to make it operational.
In this study, we presented a computationally efficient multiple instance learning algorithm. Experimental studies showed that algorithm is capable of finding complex patterns in the high resolution satellite images. Comparative analysis showed our algorithm performed better than many standard per-pixels classification algorithms as well as the Citation-KNN algorithm. In addition, our algorithm is computation-ally efficient. We are using this algorithm for mapping the slums (informal settlements) across the globe. Analyzing very high resolution remote sensing images for complex pat-tern extraction is an emerging research topic. In addition, automated mapping of informal settlements fills a critical need of national governments and planning agencies. We are working on further improving the algorithm as we are classifying more and more cities. We are also working on parallel implementation of this framework on GPUs. As mentioned earlier, our ultimate goal is to build a computa-tionally efficient and automated framework that is capable of detecting new settlements (especially slums) across the globe in a continuous manner. As our work matures, we hope that this framework becomes an important tool in com-plex settlement mapping using very high-resolution satellite imagery for a broader community. I would like to thank my collaborators B. Bhaduri, J. Graesser, A. Cheriyadat, E. Bright, V. Chandola, and C. Symons for their invaluable feedback into this research. This manuscript has been authored by employees of UT-Battelle, LLC, under contract DE-AC05-00OR22725 with the U.S. Department of Energy. Accordingly, the United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevo-cable, world-wide license to publish or reproduce the pub-lished form of this manuscript, or allow others to do so, for United States Government purposes. [1] Quantum GIS: open source geographic information [2] A. Benediktsson, P. Swain, and O. Ersoy. Neural [3] T. Blaschke, S. Lang, and G. Hay. Object-Based Image [4] J. Bolton and P. Gader. Application of [5] L. Bruzzone, C. Consese, F. Masellit, and F. Roli. [6] V. Chandola and R. R. Vatsavai. Scalable time series [7] V. Chandola and R. R. Vatsavai. A scalable gaussian [8] T. G. Dietterich, R. H. Lathrop, T. Lozano-Perez, and [9] S. Dreiseitl and L. Ohno-Machado. Logistic regression [10] J. Graesser, A. Cheriyadat, R. Vatsavai, V. Chandola, [11] J. Ham, Y. Chen, M. M. Crawford, and J. Ghosh. [12] I. Kanellopoulos and G. G. Wilkinson. Strategies and [13] B. Krishnapuram, L. Carin, M. A. Figueiredo, and [14] O. Maron and T. Lozano-P  X  Al X  X ez. A framework for [15] S. Nussbaum and G. Menz. Object-Based Image [16] J. Paola and R. Schowengerdt. A detailed comparison [17] J. Paola and R. Schowengerdt. The effect of [18] S. Shekhar, P. Schrater, R. Vatsavai, W. Wu, and [19] A. Skidmore, B. Turner, W. Brinkhof, and [20] P. Torrione, C. Ratto, and L. Collins. Multiple [21] R. R. Vatsavai. High-resolution urban image [22] R. R. Vatsavai. A data mining framework for [23] R. R. Vatsavai, B. Bhaduri, and J. Graesser. Complex [24] R. R. Vatsavai, B. L. Bhaduri, A. Cheriyadat, L. F. [25] R. R. Vatsavai, E. A. Bright, V. Chandola, B. L. [26] J. Wang. Solving the multiple-instance problem: A
