 Chikara Hashimoto  X  Daisuke Kawahara Abstract Some phrases can be interpreted in their context either idiomatically achieve full-fledged natural language processing. Because of this, the authors of this paper have created an idiom corpus for Japanese. This paper reports on the corpus itself and the results of an idiom identification experiment conducted using the corpus. The corpus targeted 146 ambiguous idioms, and consists of 102,856 examples, each of which is annotated with a literal/idiomatic label. All sentences were collected from the World Wide Web. For idiom identification, 90 out of the 146 idioms were targeted and a word sense disambiguation (WSD) method was adopted using both common WSD features and idiom-specific features. The corpus and the experiment are both, as far as can be determined, the largest of their kinds. It was discovered that a standard supervised WSD method works well for idiom identification and it achieved accuracy levels of 89.25 and 88.86%, with and without idiom-specific features, respectively. It was also found that the most effective idiom-specific feature is the one that involves the adjacency of idiom constituents. Keywords Japanese idiom  X  Corpus  X  Idiom identification  X  Language resources 1 Introduction For some phrases, such as kick the bucket , the meaning is ambiguous in terms of whether the phrase has a literal or idiomatic meaning in a certain context. It is necessary to resolve this ambiguity in the same manner as for the ambiguous words that have been dealt with in the WSD literature. Hereafter, literal/idiomatic ambiguity resolution is referred to as idiom (token) identification.

Idiom identification is classified into two categories; one for idiom types and the other for idiom tokens. The former is used to find phrases that can be interpreted as idioms in the text corpora, typically for compiling idiom dictionaries, while the latter helps identify a phrase in context as a true idiom or a phrase that should be latter, i.e., idiom token identification.

Despite the recent enthusiasm for multiword expressions (MWEs) (Villavicencio 2008 ), idiom token identification is at an early stage of development. Given that many natural language processing (NLP) tasks, such as machine translation or parsing, have been developed thanks to the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. It is for this purpose that the authors of this paper have constructed a Japanese idiom corpus. An idiom identification experiment has also been conducted using the corpus, which is expected to become a good reference point for future studies on the subject. A standard WSD framework was drawn from with machine learning that exploited features used commonly in WSD studies and features that were idiom-specific.

This paper reports the corpus and the results of the experiment in detail. It is important to note here that the corpus and the experiment are believed to be the largest of their kind in existence.

While only the ambiguity between literal and idiomatic interpretations is dealt with, some phrases have two or more idiomatic meanings without context. For example, one Japanese idiom, te-o dasu (hand-ACC stretch), can be interpreted as either  X  X unch, X   X  X teal, X  or  X  X ake moves on. X  This kind of ambiguity is not addressed in this paper and is left to future work. Note that ACC indicates the accusative case marker in this paper and, likewise, the following notation is used hereafter; NOM for the nominative case marker, DAT for the dative case marker, GEN for the genitive case marker, INS for the instrumental case marker, ONLY for the restrictive case marker, PASS for the passive morpheme, and CAUS for the causative morpheme. FROM and TO stand for the Japanese counterparts of from and to . NEG represents a verbal negation morpheme.
 The problem of what constitutes the notion of  X  X diom X  is not addressed here. Only phrases listed in Sato ( 2007 ) are regarded as idioms in this paper. Sato ( 2007 ) consulted five books in order to compile Japanese idiom lists. Among these five books, Miyaji ( 1982 ) provides a relatively in-depth discussion of the notion of  X  X diom. X  In short, Miyaji ( 1982 ) defines idioms as phrases that (i) consist of more than one word that tend to behave as a single syntactic unit and (ii) take on a fixed, conventional meaning. The idioms dealt with here fall within the definition of Miyaji ( 1982 ). A further discussion of Japanese idioms will be presented in Sect. 3.1 .

The remainder of this paper is organized as follows. Related works are presented in Sect. 2 , while Sect. 3 shows the target idioms. The idiom corpus is described in Sect. 4 , after which the idiom identification method used and the experiment are detailed in Sect. 5 . Finally, Sect. 6 concludes the paper. 1 2 Related work Only a few works on the construction of an idiom corpus have been carried out to date, with Birke and Sarkar ( 2006 ) and Cook et al. ( 2008 ) being notable exceptions.
Birke and Sarkar ( 2006 ) automatically constructed a corpus of ~50 English idiomatic expressions (words that can be used non-literally), and ~6,600 examples thereof. This corpus, referred to as TroFi Example Base, is available on the Web. 2
Cook et al. ( 2008 ) compiled a corpus of English verb-noun combination (VNC) tokens, which deals with 53 VNC expressions and consists of about 3,000 sample sentences and is also available on the Web. 3 As with our corpus, theirs assigned a label to each example indicating whether an expression in the example is used literally or idiomatically. Our corpus can be regarded as the Japanese counterpart of these works, although it should be noted that it targets 146 idioms and consists of 102,856 example sentences.

Another exception is MUST, a database of Japanese compound functional expressions that was constructed manually by Tsuchiya et al. ( 2006 ) and is available online. 4 Some compound functional expressions in Japanese are, like idioms, ambiguous. 5
The SAID dataset (Kuiper et al. 2003 ) provides data about the syntactic in Hashimoto et al. ( 2006a ) and Cook et al. ( 2007 ), among others, the syntactic behavior of idioms is an important clue to idiom token identification.
While previous studies have focused mainly on idiom type identification (Lin 1999 ; Krenn and Evert 2001 ; Baldwin et al. 2003 ; Shudo et al. 2004 ; Fazly and Stevenson 2006 ), there has been a recent growing interest in idiom token identification (Katz and Giesbrecht 2006 ; Hashimoto et al. 2006a , b ; Birke and Sarkar 2006 ; Cook et al. 2007 ).
 Katz and Giesbrecht ( 2006 ) manually annotated the 67 occurrences of a German MWE with literal/idiom labels, from which they built LSA (Latent Semantic Analysis) vectors for the two usages. They used these two vectors and the cosine similarity metric to identify tokens of the German MWE as either literal or idiomatic.
Hashimoto et al. ( 2006a and b ) (henceforth, HSU) focused their attention on the differences in grammatical constraints imposed on idioms and their literal counter-the grammatical knowledge it has provided has been drawn on by our corpus, the scale of their experiment was relatively small, using only 108 sentences for idiom identification. Further, unlike HSU, matured WSD technology was employed in our study. A more detailed description of HSU is provided in Sect. 5.1.3 .
Cook et al. ( 2007 ) (CFShenceforth) propose anunsupervised methodfor English based on the observation that idioms tend to be e xpressed in a small number of fixed forms.
While these studies mainly used the characteristics of idioms our study employed a WSD method, for which there have been many studies and matured technologies, in addition to the characteristics of idioms. While Birke and Sarkar ( 2006 ) also used WSD, they employed an unsupervised method, compared to the completely supervised one used in this study.

A supervised method was adopted in order to learn how accurately idioms could be identified if a sufficient amount of training data was available. Supervised methods do, admittedly, have scalability problems, so an unsupervised method, like that of CFS, therefore needs to be developed. Nevertheless, revealing the supervised accuracy is helpful for clarifying the accuracy of an unsupervised method. In other words, the experimental results obtained in this study are expected to serve as a reference point for future studies.
 Apart from idioms, Uchiyama et al. ( 2005 ) conducted the token classification of Japanese compound verbs by employing a supervised method.

With regard to the idiom identification method adopted in our study, it is also worth mentioning Lee and Ng ( 2002 ) (hereafter, LN). Our study drew heavily on LN, which evaluated a variety of knowledge sources (part-of-speech of neighboring words, content words in the context, N-grams surrounding the target word, and syntactically related words) and supervised learning algorithms for word sense disambiguation. Their results showed that the best performance was provided by a combination of all the knowledge sources and support vector machines (SVM). Our study, in turn, used the best performing combination for the idiom identification task. A more detailed description of LN will be provided in Sect. 5.1.1 . 3 Target idioms This section describes the characteristics of Japanese idioms (see Sect. 3.1 ) and how certain target idioms were selected from among them for this study (see Sect. 3.2 ). 3.1 Overview of Japanese idioms In order to achieve an overall perspective of Japanese idioms, their distribution was investigated with regard to their morpho-syntactic structures, as follows. 1. A total of 926 idioms were extracted from Sato ( 2007 ). Sato compiled about 2. These 926 idioms were parsed using JUMAN (Kurohashi et al. 1994 ), 8 a 3. Two native speakers of Japanese (a member of Group B who will be mentioned
As a result, we obtained the distribution illustrated in Table 1 , which shows the five most prevalent morpho-syntactic structures. 11 Note that the sequence of symbols in the first column, such as  X (N-P V) X  and  X (N-P (N-P V)) X  indicate the morpho-syntactic structures of idioms as follows. 12
In addition, note that  X  X  X  of  X (N-P V-S) X  in the sixth row indicates verbal suffixes, such as the negation morpheme, passive, and causative morphemes.
The second column indicates the part-of-speech (i.e., the verb, noun, adjective, etc.) to which the idioms as a whole correspond. For example, the (N-P V) idiom goma-o suru is a verbal idiom.

As can be seen, more than half are of the (N-P V) type, which is consistent with the observation made by HSU (Hashimoto et al. 2006b , Sect. 3.3). The 530 idioms of (N-P V) type can further be classified on the basis of which postposition (case marker) they contain, as in Table 2 . More than half of the idioms of this type contain the accusative ( ACC ) case marker, followed by the dative ( DAT ), the nominative (
NOM ), and the instrumental ( INS ) case markers. This distribution is consistent with the observation made by Yonekawa and Ohtani ( 2005 ) (p. 549). 3.2 Selection of target idioms One hundred and forty-six idioms were selected for this study using the following procedure. 1. The 926 basic idioms were extracted from Sato ( 2007 ), as mentioned in 2. From these, all the ambiguous idioms were picked up, which amounted to 146,
As for 2, it is not trivial to determine whether a phrase is ambiguous, since one meaning of a phrase is sometimes so much more common and familiar than the other meaning(s), if any, that it can be regarded as unambiguous. Our efforts are concentrated on evenly ambiguous idioms, the disambiguation of which will surely contribute to the development of NLP.

Two native speakers of Japanese (Group A) were then asked to classify the 926 idioms into two categories: (1) (evenly) ambiguous ones and (2) unambiguous ones. On the basis of the classification, one of the authors made final judgments. 14
For example, the phrase goma-o suru (sesame-ACC crush) is ambiguous in terms of its literal ( X  X rushing sesame X ) and idiomatic ( X  X lattering people X ) meanings. On the other hand, the phrase saba-o yomu (chub.mackerel-ACC read) is an unambig-uous idiom that means  X  X heating in counting. X  Unambiguous idioms in this study life are mostly used idiomatically. The phrase kage-ga usui (shadow-NOM blurred) is mostly used in real life as an idiom that means  X  X ow profile X  and is thus regarded as unambiguous in this study. A context could be devised in which one is drawing a picture of a building and believes that the shadow of the building in the picture should have been thicker and sharper. In this artificial context, the phrase kage-ga usui (shadow-NOM blurred) might be used literally, though native speakers of Japanese may believe that kage-no iro-ga usui (shadow-GEN color-NOM blurred) sounds more natural in the context.

To verify the stability of this ambiguity endorsement, two more native speakers of Japanese (Group B) were asked to perform the same task and the Kappa statistic between the two speakers was then calculated. One hundred and one idioms were sampled from the 926 chosen earlier and the two members of Group B then classified the 101 sampled idioms into the two classes. The Kappa statistic was found to be 0.6576 (the observed agreement was 0.7723), which indicates moderate stability.

All of the idioms on which the two members of Group B disagreed were finally judged as unambiguous by one of the authors (in that only idiomatic interpretation is possible), but might be interpreted literally if some artificial and unlikely context is provided. In other words, they can be described as borderline cases. 15
Table 3 shows the five most prevalent morpho-syntactic structures among the 146 selected idioms. 16 The tendency for the (N-P V) type to prevail is clearer; this type comprised 78.23% of the 146 idioms.

Note that  X  X ux X  of  X (N-P V-Aux) X  in the sixth row indicates auxiliary morphemes. The auxiliary morpheme you in the example of the sixth row attaches a verb and changes it into an adjective.

Table 4 shows the breakdown of the 115 idioms of (N-P V) type in terms of their postpositions (case markers). Again, the observed distribution is mostly the same as Table 2 , with the difference being that the ACC type is slightly more pervasive, and the NOM type comes second.

Table 5 lists 90 out of the 146 target idioms that were used for the experiment. 17 4 Idiom corpus 4.1 Corpus specification The corpus is designed for the idiom token identification task. That is, each example sentence in the corpus is annotated with a label that indicates whether the corresponding phrase in the example is used as an idiom or a literal phrase. The former is referred to as the idiomatic example and the latter is called the literal example. More specifically, the corpus consists of lines that each represent one example. A line consists of four fields, as follows.

Label indicates whether the example is idiomatic or literal. Label i is used for idiomatic examples and l for literal ones.

ID denotes the idiom that is included in the example. In this study, each idiom has a unique number, which is based on Sato ( 2007 ).

Lemma also shows the idiom in the example. Each idiom was assigned its canonical (or standard) form (orthography) on the basis of Sato ( 2007 ). Example is the sentence itself containing the idiom.

Below is a sample of a literal example of goma-o suru (sesame-ACC crush)  X  X latter. X  (1) 1 1417  X  X  X  X  X  X  X  X  X  X   X   X  X  X  X  X  X  X  X  X  ...

The third field is the lemma of the idiom and the last one is the example that reads  X  X rushing sesame in a mortar... X 
Before working on the corpus construction, a reference was prepared by which human annotators could consistently distinguish between the literal and figurative meanings of idioms. More precisely, this reference specified literal and idiomatic meanings for each idiom, similar to the way it is done in dictionaries. For example, the entry for goma-o suru in the reference reads as follows.
 Idiom: To flatter people.
 Literal: To crush sesame.

As for the corpus size, examples were annotated for each idiom, regardless of the proportion of idioms and literal phrases, until the total number of examples for each idiom reached 1,000. 18 In the case of a shortage of original data, as many examples as possible were annotated.
 The original data was sourced from the Japanese Web corpus (Kawahara and Kurohashi 2006 ). Kawahara and Kurohashi ( 2006 ) collected Web pages using a Web crawler (Takahashi et al. 2002 ). From these, pages written in Japanese were extracted by checking either the character encoding information obtained from HTML source files or the number of Japanese postpositions that existed in the pages. The pages were then split into sentences based on periods and HTML tags such as \ br [ and \ p [ . 4.2 Corpus construction The corpus was constructed in the following manner. 1. From the Web corpus mentioned above, example sentences were collected that 2. The 102,856 examples among all the collected ones were classified as either
The classification of the 102,856 examples was performed by the two members of Group A and took a total of 230 h.

The classification decisions could be more reliable if additional context information, such as entire documents, was provided. This was not the case, however, because the Web corpus adopted for the original data of the idiom corpus sometimes lacked the context of the example sentence before and/or after it, and it costs too much to consult the neighboring sentences to label more than 100,000 examples.

This relates to the policy (2. above) to give higher priority to longer sentences for annotation. Attempts were made to give annotators sufficient context (one long sentence) to make the I/L annotations easier and more reliable without relying on neighboring sentences. 4.3 Status of corpus The corpus consists of 102,856 examples, each of which contain one example. Note that the figures reported in this subsection are those of the corpus of the 2008-06-25 version, which was used for the experiment in this paper. 20 The total number of idiomatic examples is 68,239, in addition to 34,617 literal examples. Table 5 shows the number of idiomatic and literal examples for each individual idiom that was used for the experiment in Sect. 5 . Figure 1 shows the distribution of the number of examples. For 68 idioms, more than 1,000 examples were annotated. However, \ 100 examples were annotated for 17 idioms due to a lack of original data.
The average number of words in a sentence is 46. Idiom in Fig. 2 shows the distribution of sentence length (the number of words) in the corpus. Web and News indicate the sentence length in the Web corpus and a newspaper corpus, respectively. The figures for the Web corpus and the newspaper corpus are drawn from Kawahara and Kurohashi ( 2006 ). It is noticeable that our corpus contains a larger number of long sentences; this is because longer sentences were given examples for both the idiomatic and literal meanings of goma-o suru drawn from the corpus.

To determine the consistency of the idiomatic/literal annotation between different human annotators, 1,421 examples were sampled from the corpus. The two members of Group B were asked to perform the same annotation, and the Kappa statistic between the two was calculated. The value was 0.8519 (the observed agreement was 0.9247), which indicates a very high level of agreement. 4.4 Distribution of corpus The corpus is available online. 21 Figure 4 is a screenshot of the corpus X  Website. The download instructions can be found on the Website. The BSD license was adopted for the corpus. The size of the corpus (.tar.bz2) is 5.7MB and it is euc-jp encoded.

Prior to the corpus being distributed, any examples that were overly sexual or discriminatory were removed by referring to a dictionary that listed 257 common sexual/discriminatory expressions. 22 The distributable corpus contains 101,500 examples, among which 67,575 are idiomatic and 33,925 are literal.

Anyone wishing to access the complete corpus that was used for the experiment in this study may do so via the contact information provided on the Website.
In order to make it easy to browse the corpus, an online Browser has been developed. 23 This browser makes it possible to (i) highlight certain constituents of idioms (recognized automatically by KNP) and (ii) display examples either in full or in the keyword-in-context (KWIC) format, which can be either left-aligned or right-aligned. The context length can also be chosen by the number of characters.
Figure 5 shows a screenshot of the online browser. In the figure, examples of the idiom goma-o suru (sesame-ACC crush)  X  X latter X  are displayed in the left-aligned KWIC format.
 5 Idiom identification experiment 5.1 Method of idiom identification A standard WSD method was adopted using machine learning, specifically, an SVM (Vapnik 1995 ) with a quadratic kernel implemented in TinySVM 24 . The knowledge sources used are classified into those that are commonly used in WSD, along the lines of Lee and Ng ( 2002 ) (LN), or those that have been designed for Japanese idiom identification, as proposed by HSU. 25
The next two subsections describe the features developed by LN and HSU. 5.1.1 Features of Lee and Ng ( 2002 ) For WSD, LN considered four kinds of features; part-of-speech (POS) of neighboring words, single words in the surrounding context, local collocations, and syntactic relations.

Part-of-speech of neighboring words: LN used the POS of three words that preceded/followed a target word of WSD, as well as the POS of the target word itself. The neighboring words were within the same sentence as the target.
Single words in the surrounding context: All single words (unigrams) in the surrounding context of the target word were used, and the surrounding context could be up to a few sentences in length.
 Local collocations: These are 11 n-grams around the target word; C  X  1,-1 , C 1,1 , C sequence of tokens in the local context of the target. i and j denote the start and end position of the sequence (relative to the target), where a negative (positive) offset refers to a token to its left (right).

Syntactic relations: If the target word was a noun , this knowledge source h is not a verb), and the relative position of h from the target (left or right). If the target was a verb , LN used six clues: (1) the nearest word l to the left of the target, such that the target was the parent headword of l , (2) the nearest word r to the right the POS of r , (5) the POS of the target, and (6) the voice of the target. If the target was an adjective , the target X  X  parent headword h and the POS of h were used.
With these features, LN were able to achieve a higher level of accuracy than the best official scores on both SENSEVAL-2 (Edmonds and Cotton 2001 ) and SENSEVAL-1 (Kilgarriff and Palmer 2000 ) test data.

In short, LN used several kinds of contextual information regarding the target word of WSD, as has often been used for many sense-oriented natural language tasks. 5.1.2 Features of Hashimoto et al. ( 2006a , b ) Based on Miyaji ( 1982 ), Morita ( 1985 ) and Ishida ( 2000 ), HSU proposed the following linguistic knowledge to identify idioms. 1. Adnominal modification constraints 2. Topic/restrictive postposition constraints 3. Voice constraints 4. Modality constraints 5. Detachment Constraint 6. Selectional Restriction
For example, the idiom, hone-o oru , (bone-ACC break)  X  X ake an effort, X  does not allow adnominal modification by a genitive phrase. It is therefore only possible to interpret (2) literally. (2) kare-no hone-o oru
That is, the above genitive phrase prohibition is in effect for the idiom. In other words, the idiom is lexicalized so that it resists the modification of only its nominal part.

Likewise, the idiom does not allow its postposition o ( ACC ) to be substituted with restrictive postposition such as dake (only), and therefore, (3) represents only a literal meaning. (3) hone -dake oru
This means that the restrictive postposition constraint above is also in effect, of its nominal part. (4) is an example of the passivization prohibition of the voice constraints. (4) hone -ga o -rareru
That is, because of the syntactic unity of the idiom hone-o oru , it cannot be passivized, unlike its literal counterpart.

Idioms that are subject to modality constraints cannot be negated and/or take on volitional modality. This is believed to be caused by the semantic irregularity of idioms.

The detachment constraint states that the constituents of some idioms cannot be separated from one another. In other words, some idioms do not allow intervening phrases or words, such as adverbs, among their constituents, which is reflected by this constraint.

Although HSU did not implement it, selectional restriction makes use of the semantic restriction on the syntactic arguments of an idiom. For example, if tyuu-ni uku (midair-DAT float) is used idiomatically (meaning  X  X o be up in the air X ), it should take an abstract thing, such as yosanan (budget plan) as its nominative argument. On the other hand, if the phrase is used literally (meaning  X  X o float in midair X ), its nominative argument should be a concrete thing, such as bo  X  ru (ball).
Note that the linguistic constraints above (1 X 6) are not always in effect for an idiom. For instance, the causativization prohibition is invalid for the idiom, hone-o oru . In fact, (5a) can be interpreted both literally and idiomatically. (5) a. kare-ni hone-o or -aseru
Based on these linguistic knowledge sources, HSU achieved an F-Measure of 0.800 to identify idioms (Class C idioms of HSU). 27
The intuition behind the linguistic knowledge of HSU is that, in general, usages that are applicable to idioms (such as adnominal modification or passivization) are also applicable to literal phrases, but the reverse is not always true (Fig. 6 ). HSU then attempted to find usages that were applicable only to literal phrases, which correspond to the shaded area in Fig. 6 , based on the observations in Miyaji ( 1982 ), Morita ( 1985 ) and Ishida ( 2000 ).

In short, HSU X  X  linguistic knowledge captures the intolerance of idioms for certain syntactic and semantic operations, such as adnominal modification, passivization, or the detachment of constituents. 5.1.3 The proposed features This paper proposes a set of features that combines those of LN and HSU, as below.  X  Common WSD Features  X  Idiom-Specific Features
JUMAN and KNP were used to extract these features. f1 , f2 and f3 are mostly the same as those described in LN. The differences between them and the corresponding features of LN are as follows. Unlike LN, the POS of a target word itself was not used for f1 , since the targets of this study (idioms) are not single words and two or more POSs of a target would have to be posited. For f2 , a sentence containing a target was used as a context, unlike LN, which used up to a few sentences. This is due to the restriction on corpus construction (described in Sect. 4 ), whereby some sentences are collected from the Web in isolation, without information about the sentences that precede or follow them. In this work for f3 , words or phrases between constituents of a target idiom were not considered part of local collocation, since this feature was intended to be as close as possible to that of LN. (6b) Illustrates the values of f1 , f2 , and f3 for an example (6a). The target idiom is mune-o utu (chest-ACC hit)  X  X mpress. X  (6) a. tyousyu-no mune-o utu utukusi uta
More precisely, f1 is \ / , N , P ,( idiom ), A , N , / [ . f2 is the sparse vector in which all values except for tyousyu , utukusi , and uta are zero. Note that f2 deals with content words and that no in (6b) is a postposition and is therefore not considered for the feature. f3 consists of the eleven n-grams listed in (6b). f4 and f5 correspond roughly to the syntactic relations of LN. The difference between this study and LN X  X  is that this study considered only the POS and the lemma of the syntactic child of the leftmost constituent and that of the syntactic parent of the rightmost constituent. This is because idioms have a more complicated internal structure than single words. In other words, the intention was to keep features f4 and f5 simple, while observing the intuition of the original features posited by LN. In the case of the example of mune-o utu (chest-ACC hit)  X  X mpress, X  below, f4 is the POS and lemma of tyousyu and f5 corresponds to those of uta . 29 f6 and f7 are available from JUMAN X  X  output. For example, the hypernym of tyousyu (audience) is human and its domain is culture/media . Those of uta (song) are abstract-thing and culture/recreation . Although they are not used in LN, they are known to be useful for WSD (Tanaka et al. 2007 ; Magnini et al. 2002 ). f8 indicates whether the nominal constituent of an idiom, if any, undergoes adnominal modification. While this corresponds to HSU X  X  adnominal modification constraints, in order to avoid data sparseness the present study did not distinguish the sub-constraints, the relative clause prohibition, the genitive phrase prohibition, and the adnominal word prohibition. KNP was used for its robust ability to detect adnominal modification structures in an input sentence. f9 indicates whether one of Japanese topic case markers is attached to a nominal constituent of an idiom; this corresponds to HSU X  X  topic or restrictive postposition constraints. f10 is turned on when a passive or causative suffix is attached to a verbal constituent of an idiom. This is the counterpart of HSU X  X  voice constraints, but the sub-constraints, the passivization prohibition and the causativization prohibition were not distinguished, so as to avoid data sparseness. KNP X  X  output was used to see if a target idiom is passivized or causativized. 30 f11 and f12 are similar to f10 . The former is used for negated forms and the latter for volitional modality suffixes of a predicate part of an idiom. 31 f11 and f12 jointly correspond to HSU X  X  modality constraints. A wide range of modality expressions can be reliably recognized by KNP, and its output was used to obtain the values of the features.

Finally, f13 indicates the adjacency of constituents of an idiom to one other, and thus corresponds to HSU X  X  detachment constraint. 5.2 Experimental condition Ninety idioms were considered in the experiment, for which more than 50 examples of both idiomatic and literal usages were available. 32 The 90 idioms are shown in Table 5 . The column  X  X :L X  indicates the number of idiomatic and literal example sentences used for the experiment. Experiments were conducted for each idiom. The performance measure is the accuracy.

The baseline system uniformly regards all examples as either idiomatic or literal depending on which is more dominant in the idiom corpus. Naturally, this is pre-pared for each idiom.
The accuracy and baseline accuracy for each idiom is calculated in a tenfold cross validation style; examples of an idiom are split randomly into ten pieces prior to the experiment.

The overall accuracy and baseline accuracy is then calculated from the individual results. The accuracy scores of all 90 idioms are summed up and then this number is divided by 90, which is called the macro-average. This calculation was also performed for the baseline accuracy.
 Another performance measure is the relative error reduction (RER).
 ER stands for Error Rate in the formula. Error rate is defined as 1 X  accuracy .
Using the above formula, the overall RER is calculated based on the overall accuracy and the overall baseline accuracy.

In addition, the effectiveness of each idiom-specific feature was investigated by measuring performance without the use of one of the idiom features. 5.3 Experimental result Table 6 shows the overall performance. The first column is the baseline accuracy (%) and the second column is the accuracy (%) and relative error reduction (%) of the system without the idiom-specific features. The third column is the accuracy (%) and relative error reduction (%) of the system with the idiom features.

Tables 7 and 8 show the individual results of the 90 idioms. The first column shows the target idioms and the second column shows the baseline accuracy (%). The accuracy (%) and relative error reduction (%) of the system without the idiom-specific features is described in the third column. The fourth column shows those of the system with the idiom features. Bold face indicates a set of features with better performance (either w/o I or w/ I ).

All in all, although relatively high baseline performances can be observed, both systems outperformed the baseline. In particular, the system without the idiom-specific features has a noticeable lead over the baseline, which shows that WSD technologies are effective in idiom identification. Incorporating the idiom features into the system improved the overall performance, which is statistically significant (McNemar test, p \ 0.01). 33 However, there were some cases in which the individual performances of some idioms were slightly degraded by the incorpora-tion of the idiom features.
 Table 9 shows the overall results without using one of the idiom features. 34
It can be seen that the adjacency flag (f13) makes the greatest contribution to idiom identification. 35 The adnominal modification flag (f8), meanwhile, makes only a slight contribution to the task. 36 All of the degradations in the table are statistically significant (McNemar test, p \ 0.01) except for that of the adnominal modification flag ( p = 0.1589).

Tables 10 and 11 show the individual results [accuracy (%)] obtained without using one of the idiom features. Bold face indicates the lowest accuracy. As expected, the contribution of idiom features varied depending on the idioms to be identified, and in some cases the addition of certain idiom features even degraded the accuracy of their identification. 37 6 Conclusion This paper has reported on the idiom corpus that the authors constructed and the idiom identification experiment conducted using the corpus.

As mentioned in Sect. 3 , some idioms are short of examples in the current idiom corpus and, accordingly, we intend to collect more examples by using different characters. In the Japanese language, there are three basic character systems, Hiragana, Katakana, and Chinese characters. This means that an idiom can be written in different characters, for example, mune-o utu (chest-ACC hit)  X  X mpress X  can be either or.
In spite of its imperfection, a lot can be learned from the corpus about idiom identification experiment reported in Sect. 5 .

This paper has also shown that a standard supervised WSD method works well for idiom identification. Our system achieved accuracy of 89.25 and 88.86% with/ without idiom-specific features.

This study dealt with 90 idioms, but practical NLP systems are required to deal with many more. In order to achieve scalable idiom identification, it is necessary to develop an unsupervised or semi-supervised method. One possibility would be to follow the unsupervised method of Birke and Sarkar ( 2006 ) using the Japanese WordNet (Isahara et al. 2008 ), while the language-independent unsupervised method proposed by CFS could also be of help.

In any case, this idiom corpus will play an important role in the development of unsupervised and semi-supervised methods, and the experimental results obtained in this study will provide a good reference point for evaluating those methods. References
