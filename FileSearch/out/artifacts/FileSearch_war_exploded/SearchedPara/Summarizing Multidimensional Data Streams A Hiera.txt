 With the rapid development of information technology, many applications (web log analysis, medical equipment monitoring, etc.) have to deal with data streams. A data stream is defined as a potentially infinite sequence of precise and changing data arriving at an intensive rate. Due to the high-speed constraint, stream data can be read only once (one-pass constraint [1]) and storing the whole stream his-tory is impossible. Nevertheless, decision makers need to analyze the data stream history, leading us to propose data st ream summarization methods. As most of stream data are multidimensional and can be considered at multiple levels of precision (referred to as MD/MT data), providing an on-line multidimensional and multilevel analysis on such data streams would be interesting in order to make profit of the OLAP technology in static datawarehouses.

To the best of our knowledge, only two approaches profit from OLAP technolo-gies for the MD/ML data stream summarization. In [2], the temporal dimension is compressed thanks to Tilted Time Windows [3] (TTW). The most recent his-tory is registered at the finest granularity while the older history is registered at coarser granularity. The user habits are exploited to choose the materialized cuboids. In spite of an interesting archit ecture, the storage co st can be reduced. [4] overcame this drawback by introducing precision functions which define for each granularity level of every dimension the minimal interval of a TTW to avoid storing unqueried or computable data. Globally, the existing approaches focus on which cuboids must be materialized but none of them reconsiders the use of TTWs. In spite of a good compression ratio, changing the time granularity at regular intervals can lead t o an important loss of preci sion. Indeed, this mecha-nism does not take the data distribution into account. For instance, if an item rarely occurs in the stream, it could be u seful to keep precise informations about its occurrences. However, with the TTW mechanism, this information would be lost after the first aggregation.
 In this paper, we thus propose a graph-based framework for summarizing MD/ML data streams In this approach, if an item frequently appears in the stream, it is useless to conserve the preci se history of its occurrences. Conversely, rare items are kept as conserving their p recise occurrences could be useful for supporting decisions. Thanks to dynamic lists, aggregations are performed only if an item occurs in several close windows of the stream. On the contrary, non-close occurrences are kept during a significant period. MT/ML Data. Let D = { D 1 , ..., D M } be a set of M dimensi ons. Every dimen-sion D i is defined over a (finite or not) set of values Dom ( D i ). Every dimension D i can be considered at several levels of granularity, composing a hierarchy H i where: max i is the number of levels in H i with H max i i the finest level and H i the coarsest. Note that for every dimension we consider a value * which canbedefinedas all the values .Wehave x  X  Dom ( D j i )if x is defined on the level H j i . For instance, a hierarchy of a geographic dimension D Geo could be H have France  X  Dom ( D 3 Geo ). A (multidimensional) item t is then defined as t =( d 1 , ..., d M )sothatforevery i =1 ...M , d i  X  Dom ( D i ). t is said to be a Lowest Level Item (LLI) if  X  d i  X  [1 ,M ], d i  X  Dom ( D max i i ). On the opposite, t is said to be a Highest Level Item (HLI).
 Mining Multidimensional Items in Data Streams. Adatastream S = B 0 ,B 1 , ..., B n is an infinite sequence of batches (temporal windows), where every batch is associated with a timestamp t (denoted by B t ). A batch B i is defined as a set of transactions appearing over the stream at the i th time unit. In a MD data stream context, the support is defined as: supp B i ( X )= count ( X ) / | B i | where count ( X ) is the number of transactions of B i in which X appears and |
B Tilted Time Windows. In stream data analysis, users are usually interested in recent changes at a fine granularity, an d in long term changes at coarse scale. Tilted Time Window [3] have thus been introduced, and the degree of coarseness depends on the application requirements and on how old the time point is (see Figure 1(a)). However, changing the time granularity at regular intervals can lead to an important loss of precision. For instance, Figure 1(b) shows an item i that occurs rarely: classical TTW would rapidly aggregate these occurrences. The hierarchies associated to the dimensi ons compose the base-structure. These nodes are structural and do not store anything. As multidimensional items keep coming, nodes storing the summary at different levels of granularity are created, updated or deleted dynamically. To overcome the above-mentioned drawback of TTW, the history of each LLI is conserved in dynamic lists which store the pre-cise occurrences. Thus, aggregations are not performed at regular time intervals but only when some conditions (e.g., tem poral proximity between elements of the list) are validated. Higher granularity nodes store classical TTWs. Figure 2 displays a simple example. Due to the potentially infinite length of a stream, the accumulation of occurrences in dynamic lists is impossible. Mechanisms for aggregating or merging data are thus proposed: 1. If the same item appears in close temporal windows, they are merged and 2. A maximum size for each list is fixed. When a list reaches its maximal size, 3.1 Description of the Structure Initially, the graph structure is composed by the dimension hierarchies. These nodes are called structural nodes SN .Historiesof LLIs are stored in nodes called the Lowest Level Nodes ( LLN ). Let N X =( X, Hist X )bea LLN node so that X is a LLI and Hist X is a list containing pairs &lt;W : Count W &gt; where W is a time interval and Count W is the number of occurences of X R in W . If W represents more than one time unit, W beg and W end denote the bounds of the interval. Otherwise, the notation W is used. HLI are represented in our structure by High Level Nodes ( HLN ). Let M X =( X, T X )bean HLN so that X is an HLI and T X is a TTW storing the history of X . 3.2 Updating the Structure A distance measure between LLI. Since stream data arrives at a very low level of granularity, the number of potential items can be huge. [2] proposes to tackle this problem by electing the lowest level of granularity which is inter-esting for the user (m-layer). Data are systematically aggregated to this level of granularity. Sometimes, users need to keep a track of precise data. In such a context, two items could be different but semantically close. For this pur-pose, we propose a hierarchy-based distance dist .Let A = { X A 1 ,X A 2 , ..., X A N } et B = { X B 1 ,X B 2 , ..., X B N } be two LLI. We define dist ( A, B )as: where N is the number of dimensions, lv ( x ) the level of granularity of x (with lv ( x )=1if x is a sheet of the hierarchy) and NCA ( x 1 ,x 2 ) is the nearest common ancestor of x 1 and x 2 .Twoitems A and B are semantically close if dist ( A, B ) &lt;distMax where distM ax is a user-defined threshold. Example 1. Let A=(Wine,Paris) and B=(Wine,Lyon) be two LLI. We have NCA ( Wine,Wine )= IdProduct ( prox ( Wine,WIne )=1 )and NCA ( Paris, Lyon )= Country ( Prox ( Paris,Lyon )= 1 2 2 ). Thus dist ( A, B )=1  X  1+0 . 25 2 . When a node N X (where N X is an LLN) already exists, it must be updated if X reappears (in the batch t for instance). Indeed, the pair &lt;t,count t &gt; is to Hist X . Due to the storage constraint, a merge mechanism is proposed. The Merge Operation. If an item occurs in close time intervals, it is unec-essary to keep all its occurrences. Mer ging these occurrences in a naive manner would perturb the propagation on the HLN . For instance, let us consider the LLN (Wine,NY) and the TTW displayed on Figure 2 where an agregation is performed every three time units. Considering the aggregated value of [ T 0 ; T 3 ], it cannot be inserted in the second window of the TTW because it overlaps the first two windows. Indeed, each value in the second window represents three time units (more generally, each value stored in a window k represents the aggrega-tion of W 1  X  ...  X  W k  X  1 time units). So, a merging can be performed if and only if the impacted interval represents one temporal granularity of the TTW.
Merging pairs stored in a node N X and propagating the aggregated values along the generalization of X is performed as follows. Firstly, the pair f aris-ing from the merging is computed and the associated pairs are deleted from Hist X . This process launches a propagation along the generalization of the con-cerned item. The nodes sharing the same generalization are sought. Every Hist is scanned for locating entries to participate to the aggregation. A pair cannot participate to two different merge operations. So, every located pair is marked. Lastly, the aggregated value is inserted at the appropriate position in the TTWs corresponding to the generalizations of X .
 Example 2. Let us consider the example from Figure 2 and let us suppose that a merging has to be performed on the (Water-LA) node. The pairs &lt;t 10 :1 &gt; and &lt;t 12 :8 &gt; are aggregated. Then, nodes sharing the same generalization (i.e., (Drink-USA) ) are sought, retrieving the node Wine-NY . Its list contains &lt;t 11 , 5 &gt; , which can participate to the aggregation.
 Limiting the Size of the Lists. The merge mechanism allows for compression of lists but is insufficient to guarantee that the structure fits in main memory. Additional methods must be proposed in order to avoid memory overflows. A merging is performed if the interval represents one temporal granularity of the TTW. But it is unrealistic to consider all the granularities. Let us suppose that the TTW displayed in Figure 1(a) is used. Considering the whole TTW for the merging mechanism implies that we can potentially wait for 1 year before any merging. Storing a so long history in each list is inconceivable. So, we introduce a user-defined numerical parameter, W MAX , which means that the maximum size of the possibly merged interval is W 1  X  ...  X  W MAX  X  1. Secondly, the merging mechanism is not sufficient to limit the number of elements stored in a list. In fact, it is not possible to determine the data distribution in a stream and, consequently, it is impossible to predict the number of merging operations. So, a user-defined numerical parameter, MAX-SIZE , is introduced.Since the MAX-SIZE th element of the list can be possibly merged in the future, we authorize MAX-SIZE +( W 1  X  ...  X  W MAX  X  1)  X  1 elements per list.
 Example 3. Let us consider the TTW from Figure 2, with MAX-SIZE= 3 and W
MAX = W 3 . The maximum size of the list is then 3+(3 General Update Algorithm. When updating an LLN, the size of Hist is evaluated and compared to MAX-SIZE . If the size is smaller than MAX-SIZE ,we check in the list if a merge operation is possible. If necessary, a merge operation is performed. Otherwise, the pair is inserted at the end of the Hist .Ifthesizeof the Hist isgreaterthanorequalto MAX  X  SIZE ,wegetthe MAX  X  SIZE th element in Hist and we check if a merge operation is possible. Otherwise, we check if t c  X  t m &lt; ( W 1  X  ...  X  W MAX  X  1). This check allows us to verify if the MAX  X  SIZE th element could be merged in the future. Otherwise, the list is full and any element could be merged. The oldest pair is thus deleted. Frequent itemsets extracted over tem poral windows can be considered as an interresting data stream summarization technique. However, we discussed the difficulty for decision makers to analyze the numerous and independent set of results manually. In this section, the minor adjustments to perform in order to take into account such specific input are presented. Storing frequent itemsets instead of it ems requires that dynamic lists (resp. TTWs) cannot be stored in LLN (resp. HLN ). So, some definitions must be adapted. Indeed, LLN and HLN nodes are now considered as structural nodes and do not store any history. Likewise LLIs , the history of each LLIS is stored in nodes named the Lowest Level Itemset Nodes ( LLISN ). Let N X =( X : Hist X )bea LLISN node so that X is a LLIS and Hist X is a set of pairs &lt;W : Supp W &gt; where W is a time interval and Supp W is the support of X in W .If W represents more than one time unit, we note W beg (resp. W end )the beginning (resp. the end) of the interval. On the contrary, the notation W is used. HLIS are stored in nodes called Highest Level Itemset Nodes ( HLISN ). Let R =( X : T )bean HLR so that X is an HLI and T is a TTW.

Methods presented in Section 3 can eas ily transposed to the synthesis of fre-quent itemsets. Due to both the lack of space and the extreme proximity with the above-written algorithms, they are not given here. The feasibility of our approach is evaluated by considering the update time of the data structure and the main memory consumption. Experiments are conducted on a Intel(R) Xeon(R) CPU E5450@3.00G Hz with 2GB of main memory, running Ubuntu 9.04. The methods are written in Java 1.6. We report and discuss here the most representative ones. Refer to our website 2 for complete results. 5.1 Synthetic Datasets The data stream is simulated using a multidimensional random data generator (following a Random Uniform Distribution). D10L3C5W20T100SM10 stands for 10 dimensions, 3 granularity levels per dimension (except level *), node fan-out factor (cardinality) of 5 (i.e., 5 children per node), 20K temporal windows of 100 tuples each and proper-approach parameters of SIZE-MAX=10. Figure 3 presents a representative result obtained during the experimentations. On Figure 3(b), three distinct behaviors can be ob served: quick increase of the memory consumption (no merging performed) then fair increase of the RAM consumption (occurrence of two concurrent phenomena: merging and filling up lists), and finally, stabilization of the memory usage because all the potential LN are created and insertions in lists are balanced by merging. Regarding the update time per window (Figure 3(a)), three distinct time scales can be noticed. The lowest one corresponds to a node creation or to a simple insertion in a list (performed almost instantaneously), the second one corresponds to merging and aggregation mechanisms (approximately 15ms) and the highest one is explainable by both insertion and merging (approximately 20ms).

Due to the Random Uniform Distribution of data, paramaters which impact directly the number of potential items to store have a logical influence on both time and memory consumption performances. Indeed, the higher the number of items, the longer the time to perform a me rge operation. Nevertheless, it can be noticed that performances become cr itical when the par ameter values are extreme (e.g., when the depth of the hierarchies equals 7). In other experiments, results show the feasibility of the proposed method. 5.2 Real Dataset We consider here industrial pumps transmi tting physical informations (e.g., pres-sure, external temperature) over 10 dimensions. Hierarchies were arbitrarily built with the following characteristics. Every dimension has 3 levels of granularity and the average fan-out factor is 100. the dataset is dense. The input file is divided into windows containing 100 tuples.
 Summarizing Items. We observe that memory is rapidly bounded as the dataset is very dense. The average insertion time is 50ms, and distinct time scales are observable. Moreover, the inse rtion time is relatively stable and this time is at worst 230ms.
 Synthesizing Frequent Itemsets. Multidimensional itemsets and customer sequences were arbitrarily built. The av erage number of items per itemset is 25 and the average number of customers per client is 100. Then, a frequent item-set mining algorithm was applied 3 with a minSupp=10%. The average number of frequent itemsets per window is approximatively 100. Finally, we run our algorithm on those frequent itemsets. Figure 4(b) displays the results of memory consumption. The memory consumption st abilizes quickly (the frequent itemsets are almost the same on the whole data stream). The two off-peaks can be ex-plained by the garbage collector. Regarding the insertion time, it can be noted that the simple insertions or list creations are a little slower than with items. This is explainable by the higher complexity of itemsets in comparison to items. Several merging and generalization mechanisms can also be observed. In this paper, we tackle the problem of summarizing multidimensional and mul-tilevel data stream thanks to a graph structure and provide efficient algorithm for updating this structure. Moreover, thanks to dynamic lists, we overcome the major drawback of the TTW: taking the data distribution into account. Finally, we show how frequent itemsets can be synthesized in order providing a comfort-able solution for decision support. Our experiment study on both synthetic and real datasets shows that our summarization structure is efficient in both time and space, allowing us to consider numerous possible extensions.

