 Providing justification to a recommendation gives credibil-ity to a recommender system. Some recommender systems (Amazon.com etc.) try to explain their recommendations, in an effort to regain customer acceptance and trust. But their explanations are poor, because they are based solely on rating data, ignoring the content data. Our prototype system MoviExplain is a movie recommender system that provides both accurate and justifiable recommendations. H.3.3 [ Information Search-Retrieval ]: Information Fil-tering. General Terms: Algorithms, Performance. Key-words: Recommender Systems, Explanations
Recent research noticed that the acceptance of Collabora-tive Filtering (CF) recommender systems (like Amazon.com, MovieLens etc.) increases, when users receive justified rec-ommendations [3]. For instance, Amazon adopted the fol-lowing two styles of justification: (i)  X  X ustomers who bought item X also bought items Y,Z,...  X . This is the so called  X  X earest neighbor X  style [1] of justification. (ii)  X  X tem Y is recommended because you rated item X  X . This is the so called  X  X nfluence X  style, where the system isolates the item, X , that influenced most the recommendation of movie Y .
Pure Content-Based filtering (CB) systems [6] make rec-ommendations for a target user based on the past data of that user without involving data from other users. Based on pure CB, several research works [2, 6] were able to pro-vide explanations for their recommendations. For instance, Billsus and Pazzani [2] recommend news articles to users, providing the following style of justification.  X  X his story re-ceived a high relevance score, because it contains the words f , f 2 ,and f 3  X . This is the  X  X eyword X  [1] justification style.
Bilgic et al. [1] claimed that the  X  X nfluence X  and  X  X eyword X  styles are better than the  X  X earest neighbor X  style, because they allow users to accurately predict their true opinion of an item. Nevertheless, both  X  X nfluence X  and  X  X eyword X  styles can not justify adequately their recommendations, because they are based solely either on data about ratings (rating data), or solely on content data, which are extracted in the form of features that are derived from the items.
Several CF systems have proposed the combination of con-tent data with rating data [5, 7]. By combining CF with CB, data sparsity can be reduced, yielding to more accu-rate recommendations. For this reason, recently proposed recommender systems, like CinemaScreen [7] and Libra [1], combine CB and CF in their recommendations.

Our prototype system MoviExplain is a movie recom-mender system with explanations. It relies on the demo-cratic nature of voting. In essence, MoviExplain uses a sim-ple heuristic to interpret a rating by a user A to a movie B, as a vote to the features of movie B (actors, directors etc.). Based on these features, MoviExplain builds a feature profile for each user.

MoviExplain groups users into biclusters , i.e., group of users which exhibit highly correlated ratings on groups of movies, to detect partial matching of user X  X  preferences. Each bicluster acts like a community for its corresponding movies; e.g., in a system that recommends movies, such a group may be users that prefer comedies. Moreover, by using groups instead of individual users, the extracted features are col-lective, reflecting preferences of whole communities. As a result, collective features cover a wider range of users pref-erences and result to better explanations.

The justification style of MoviExplain combines  X  X eyword X  with  X  X nfluence X  explanation styles [1], having the following form:  X  X ovie X is recommended because it contains fea-tures a,b,... which are also included in movies Z, W, . . . you have already rated X . If inside the user X  X  feature profile, these features are frequent, this is a strong evidence for justifying the recommendations.
There have been several hybrid attempts to combine CB with CF. The Libra [1] System employs an approach called Content-Boosted Collaborative Filtering (CBCF) [5]. The basic idea of CBCF is to use content-based predictions to  X  X ill out X  the user-item ratings matrix. In contrast to Fab and Libra, the CinemaScreen System [7] reverses the strategy and runs firstly CF and then CB (CFCB). In particular, CinemaScreen system computes predicted rating values for movies based on CF and then applies CB to generate the recommendation list.
Regarding research on explanations, many pure CB sys-tems have tried to provide explanations to users. For in-stance, Billsus and Pazzani [2] recommend news articles to users, providing also explanations for reasoning their rec-ommendations. In 2000, Mooney and Roy [6] proposed a method based also on pure CB for recommending books. These works were pioneering for the problem of explana-tion and inspired subsequent research on combining CF and CB for explanation purposes. In the area of CF, there is a little existing research on explaining. In 2000, Herlocker et al. [3] proposed 21 different interfaces of explaining CF recommendations. By conducting a survey, they claim that the  X  X earest neighbor X  style is effective in supporting expla-nations. Amazon.com X  X  recommender system early adopted the  X  X earest neighbor X  explanation style. In 2005, Bilgic et al. [1] demonstrate, through a survey, that the  X  X nfluence X  and  X  X eyword X  styles are better than the  X  X earest neighbor X  style, because they help users to accurately predict their true opinion of a recommendation.
MoviExplain system consists of several components. The system X  X  architecture is illustrated in Figure 1, where the main four sub-systems are described: (i) a Web Crawler, (ii) the Database Profiles, (iii) a Recommendation Engine and (iv) the Web Site. In the following sections, we describe each sub-system of MoviExplain in details.
MoviExplain uses a web crawler to search for information about movies on the Web. The movies information concerns the basic movies characteristics like its cast (directors and actors), their official web pages, posters and various photos, movie genres etc. Moreover, a search engine summarizes this content and adds the appropriate links to their indexes. Thus, a user can search for his favorite movie using the Movi-Explain search engine and get updated information about its features. MoviExplain is fully integrated to the well-known Internet Movie Data Base (IMDB) web site.
As described previously, MoviExplain X  X  database profiles contain users ratings and movies X  features. The feature ex-traction has been done from the Internet Movie Database (IMDB). In this work, following related research, e.g. [7], we select as movies X  features the actors, directors, and genres. The Recommendation Engine is the heart of the Movi-Explain system. It aims to provide both accurate and jus-tifiable recommendations. The recommendation algorithm contains four stages: (i) The creation of user groups, (ii) the feature-weighting, (iii) the neighborhood formation, and (iv) the generation of the recommendation and justification lists. Users interact with MoviExplain through its web site 1 . MoviExplain consists of 3 sub-systems: (i) the Search En-gine, (ii) the Rating System and (iii) the Recommendation with Explanation System. The Search Engine keeps updated information about movies and their features, which are col-lected by the web-crawler. The Rating System is meant to help a user to keep track of the movies he has rated. Based on these features, MoviExplain builds a feature profile for each user. Finally, MoviExplain provides as explanation, the feature that influenced most a recommendation, show-ing also how strong is this feature in the feature profile of a user. As shown in Figure 2, the link  X  X he reason is X  reveals the favorite feature that influenced most the MoviExplain X  X  recommendations, while the link  X  X ecause you rated X  shows how strong is this feature in the feature profile of a user.
In this section, we experimentally study the performance of the proposed MoviExplain System. For comparison pur-poses, we include as representative of the hybrid CFCB al-gorithms, the CinemaScreen Recommender Agent [7] de-noted as CinemaScreen. As representative of the hybrid CBCF algorithms, we use the Libra System [1] denoted as Libra. Finally, we include in our experiments a state-of-the-art cluster-based CF algorithm [4] denoted as DM. Our experiments are performed with the 100K MovieLens real data set, which consists of 100,000 ratings assigned by http://delab.csd.auth.gr/MoviExplain 943 users on 1,682 movies. The range of ratings is between 1(bad)-5(excellent). The extraction of the content features has been done by joining with the contents of the internet movie database (imdb) and selecting 3 different classes of features: genres, actors, and directors. The join process yielded 23 different genres, 1,050 directors and 2,640 differ-ent actors and actresses. In the following experiments, the default size of the recommendation list, N ,issetto20,the neighborhood size k , is set to 10 (after tuning), and the size of the training set is set to 75%.
To measure the accuracy of recommendations, we use the well known measures of precision and recall. Precision and recall are defined as follows: where N denotes the size of the recommendation list L , R
L denotes the number of relevant items that are included in L ,and R denotes the total number of relevant items.
Precision and recall concern only the rating profile of a user u and measure the accuracy of L . However, precision and recall cannot distinguish between a relevant item from a more relevant item. To cope with this problem and to measure the quality of the justification, we introduce a user-oriented measure, called explain coverage .

For a user u that receives a recommendation list L ,the explain coverage for the justification list J is defined as fol-lows:
Explain coverage ( u, J )= where each pair ( f i ,c f i ) denotes that feature f i has overall frequency c f i inside L and P ( u, f i ) is the frequency of f the feature profile of u . Explain coverage takesvaluesinthe range [0, 1], whereas values closer to 1 correspond to better coverage.
First, we compare the four algorithms by measuring preci-sion vs. recall. Figure 3a plots the precision-recall diagram for the four algorithms (precision and recall are given as per-centages). In particular, to obtain varying precision-recall values, we varied the number of the recommended movies (i.e., the parameter N ). As expected, MoviExplain attains the best precision in all cases. The reason is two-fold, Movi-Explain takes into account the duality between users and items by using biclustering, and, moveover, it detects par-tial matching of users X  preferences. Figure 3: Comparison between MoviExplain, Cine-maScreen, Libra and DM in terms of (a) precision vs. recall and (b) explain coverage vs. N.

Next, we compare the four approaches in terms of explain coverage vs. the size N of the recommendation list. The results are presented in Figure 3b ( explain coverage is given as percentage). MoviExplain outperforms the other meth-ods in all cases. The reason is that MoviExplain uses groups of users, whereas the other methods are based solely on in-dividual users.
We conducted a survey to measure user satisfaction against the three styles of explanations:  X  X eyword X  style (denoted as KSE),  X  X nfluence X  style (denoted as ISE), and our style of explanation (denoted as KISE), which combines the two aforementioned ones. We designed the user study with 42 pre-and post-graduate students of Aristotle University, who filled out an on-line survey, following a procedure that is similar to the one in Bilgic and Mooney work [1].
The survey was conducted in three steps (more details can be found in [1]): Firstly, we asked each target user to provide our system with ratings for at least five movies, so that a decent recommendation along with some meaningful explanations could be provided. Secondly, we asked them to rate separately, from 1 (dislike) to 5 (like), each recom-mended movie based on the three different styles of expla-nations (these ratings are denoted as Explanation ratings). This rating has been done after we had removed the titles of the recommended movies, because we did not want the target users to be influenced by them. Thirdly, the target users rated again each recommended movie (this rating is denoted as Actual rating), after they had seen the hidden information about it. If we accept that a good explanation lets the user accurately assess the quality of the movie, the explanation style that minimizes the difference between the ratings provided in the second and the third step is the best. Moreover, after we conducted the survey, we asked target users to rate separately each explanation style to explicitly express their actual preference among the three styles.
We assume that, (1) KISE will allow users to accurately estimate ratings better than KSE and ISE and (2) that KISE will be the users X  favorite choice, because it is more infor-mative and combines the other two explanation styles.
Our results are illustrated in Table 1. The second and third columns contain for each explanation style, the mean  X  r and standard deviation  X  r of the ratings provided by users in the second step of the survey (Explanation ratings). Regarding the third step of the survey, the mean value of the Actual ratings was 3.24, whereas the standard deviation of the Actual ratings was 0.45.

As earlier described, the best explanation is the one that allows users to best approximate the Actual rating. That is, the distribution of difference between Explanation rat-ings and Actual ratings should be centered around 0. We measured the mean  X  d and standard deviation  X  d of the differences between Explanation ratings and Actual ratings. These values, for each explanation style, are presented in the fourth and fifth columns of Table 1. KISE has the smallest  X  d value equal to 0.06. We run paired t-tests with the same null hypothesis H 0 (  X  d = 0) for all three styles. We found that for KISE H 0 (  X  d = 0) is accepted at the 0.01 significance level. In contrast, for KSE and ISE we reject H 0 (  X  d =0) at the same significance level. This verifies our first (1) as-sumption.

We also calculated Pearson Correlation (denoted as Corr ) between Actual and Explanation ratings, to show that the Actual and Explanation ratings follow similar patterns. The results are presented in the sixth column of Table 1. KISE has positive correlation with Actual rating, equal to 0.25. This also supports our first (1) assumption, because it shows that the Actual and KISE ratings are positively correlated.
Finally, the last two columns of Table 1 present the mean  X  p and standard deviation  X  p of ratings provided by the users to explicitly express their preference for each explana-tion style. KISE attained a  X  p value equal to 3.71 (in 1 to 5 scale), which is the largest among all styles. We run paired t-test, and found out that the difference of KISE from KSE and ISE is statistically significant at the 0.01 level. This supports our second (2) assumption.
The need of providing justifiable recommendations has re-cently attracted significant attention, especially in e-commerce sites (Amazon, e-Bay etc.). In this paper, we proposed MovieExplain, a movie recommender system that goes far beyond just recommending movies. It attains both accurate and justifiable recommendations, giving the ability to a user, to check the reasoning behind a recommendation. In the fu-ture, we intent to use in MoviExplain also natural language processing to provide more robust explanations. [1] Bilgic, M. and Mooney, R.J. Explaining [2] Billsus, D. and Pazzani, M. A personal news agent [3] Herlocker, J. and Konstan, J. and Riedl, J. Explaining [4] Jin, R. and Si, L. and Zhai, C. A study of mixture [5] Melville, P. and Mooney, R. J. and Nagarajan, R. [6] Mooney, R. and Roy, L. Content-based book [7] Salter, J. and Antonopoulos, N. CinemaScreen
