 1. Introduction
The overwhelming amount of data that is available nowadays [1] in any field of research poses new problems for data mining and knowledge discovery methods. This huge amount of data makes most of the existing algorithms inapplicable to many real-world problems. For these very large datasets scalability becomes an issue. One of the most common ways of dealing with huge amounts of information is data reduction, which consists of removing missing, redundant and/or erroneous instances from the data to get a tractable amount of data. One of the most common methods for data reduction is instance selection.
However, being a data mining algorithm itself, instance selection also suffers scalability problems. Most existing instance se-ory requirements. In this paper we present a parallel methodology to scale up any instance selection algorithm in a simple way which is able to achieve very good results in terms of testing error and storage reduction, and markedly good results in terms of scalability.

As the main purpose of this paper is scaling up instance selection, we must consider which methods have been used for scaling fast algorithms, partitioning the data and using relational representations. Using relational representations is only applicable alternative.

Designing fast algorithms is the most straightforward way of scaling up a learning algorithm [3] . Common methods are restricting the model space for searching possible solutions, using powerful search heuristics, optimizing the algorithm or the programming and parallelizing the method. One of the problems with this approach is that it is not always feasible, and even when it is, it may be a very difficult task.

On the other hand, data partitioning has advantages: it can be applied to any method, it does not modify the learning algo-formance of the algorithms. In this paper we present an approach that is based on data partitioning, which also benefits from the advantages of parallelization.
 tion for instance-based learning.

In a previous paper [5] we proposed an algorithm called democratic instance selection that was able to achieve a large reduc-tion in the execution time of the instance selection algorithms while keeping their performance. The underlying idea was based upon the following premises: tioning the dataset into disjoint subsets and applying the instance selection algorithm to each subset separately. talk of  X  weak learners  X  in a classifier ensemble construction framework, we can consider an instance selection algorithm ap-plied to a subset of the whole dataset as a  X  weak instance selection algorithm 3. Following the philosophy of classifier ensembles, we can carry out several rounds of weak instance selection algorithms and combine them using a voting scheme.

In this paper we show a parallel algorithm based on democratization that is able to achieve an enormous reduction in the ex-ecution time of any instance selection algorithm while keeping its performance in terms of reduction and accuracy. The main ad-vantage of our method is that as the instance selection algorithm is applied only to small subsets, the time is reduced very significantly. In fact, as the size of the subset is chosen by the researcher, we can apply the method to any problem regardless in our method the instance selection method is a parameter, and any algorithm can be used. The proposed method is called cution time is achieved without harming the performance of the instance selection process in terms of accuracy and reduction, mance of our method.

A further advantage is the reduction in memory storage requirements. The algorithm does not need to have the whole dataset in memory, thus for very large problems where we have millions of instances, it means that we can perform the instance selection when other algorithms would be limited by the amount of available memory. This feature is very relevant for scaling up any in-stance selection algorithm. While we can design fast algorithms, most of them would need the whole dataset in memory. In we only need to have in memory a subset of size s each time. As it will be shown in our experiments, a size of 1000 instances is enough to obtain very good results.

The proposed algorithm has many advantages that make it a very good solution for instance selection in large and very large datasets. Thus, the most important contributions are: 1. The algorithm is inherently parallel. The communication among the different tasks is small and most of the tasks can be per-formed concurrently. 2. No task is performed using the whole dataset. There is no need to have the whole dataset in memory. That removes any con-straint imposed on the size of the dataset by memory availability. 3. The instance selection algorithm used by each task is a parameter of the method, so we can choose any algorithm suitable for our datasets. Furthermore, the algorithm is used without any modification, which avoids difficult adaptations of the algorithm which are common in other scaling up methods. 4. The complexity of the algorithm is linear, and in case we have enough processors, constant. 5. The philosophy of the method can be extended to other learning tasks such as feature selection, classifier learning, etc. One of the most important problems when implementing a parallel version of instance selection is data dependencies. Any partition of the data that can be efficiently made will spread the neighbors of every instance into different subsets.
Stratification just ignores this fact, and applies the instance se lection algorithm to each subset independently. Our approach is almost as efficient as stratification, because it also applies t he instance selection algorithm to each subset concurrently.
However, unlike stratification, our approach deals with data dependencies by means of two mechanisms. Firstly, using dif-ferent rounds of stratification, to ameliorate the effect of the ra ndom partition of instances; and secondly, combining the dif-ferent rounds by means of a voting process. Furthermore, as it will be shown in the experiments, the advantage of our approach over stratification is higher for very large data sets, where the need for scaling up instance selection is more dramatic.
 This paper is organized as follows: Section 2 presents the proposed model for instance selection based on our approach;
Section 3 reviews some related works; Section 4 shows the results of the experiments; and Section 5 states the conclusions of our work. 2. Federal instance selection method a number of votes above a certain threshold are removed.

The most relevant advantage of our method is the large reduction in execution time. The reported experiments will show a large difference when using standard widely used instance selection algorithms.

An important step in our method is partitioning the training set into a number of disjoint subsets, t results provided it is small enough to avoid large execution time. Furthermore, the time spent by the algorithm depends on the size of the largest subset, so it is important that the partition algorithm produces subsets of approximately equal size.
 that is of the utmost importance for the performance of the method.

Each partition represents a different optimization problem, and so a different error surface for the instance selection algo-ferent applications of the instance selection algorithm are almost randomly distributed, and the obtained performance is poor. Thus, to obtain a good performance, the different partitions must vary smoothly.

These two previous requirements are met using the theory of Grand Tour [6] . We obtain the first partition by projecting our dataset into a random vector and then dividing the projection into equal sized subsets. The next vector is obtained using Grand
Tour and a new partition is made. The procedure is repeated to get the subsequent partitions. Algorithm 1 shows the method for performing the partition based on this methodology. 2.1. Determining the number of votes An important issue in our method is determining the number of votes needed to remove an instance from the training set.
Preliminary experiments showed that this number highly depends on the specific dataset. Thus, it is not possible to set a general
Algorithm 1. Algorithm for partitioning the training set into disjoint subsets. time. Our method to obtain this threshold is based on estimating the best value for the number of votes from the effect on the training set. The election of the number of votes must take into account two different criteria: training error, memory, requirements m . Both values must be minimized as much as possible. Using these two criteria we define an objective function, f ( v ), that must be minimized by the chosen threshold: our method complexity would also be quadratic.

To avoid this bottleneck, we also evaluate the criterion in a federalized way. The threshold of votes, v , must be v to the master. The master records the evaluations made by each slave and assigns the fitness, f ( v ), averaged by the slaves to removing the instances whose number of votes is above or equal to the obtained threshold v . In this way, the evaluation of each threshold of votes is also federalized . 2.2. Complexity of our methodology
We have stated that our method is linear in the number of instances. Consider a dataset of n instances and r partitions. We a subset of fixed size, s . The complexity of this application of the algorithm depends on the base instance selection algorithm formed concurrently with a complexity constant K . Fig. 1 shows the computational cost of a quadratic algorithm, as a function of the number of instances, and our approach when that algorithm is used with subset sizes of s =100, 1000, 2500 and 5000 instances, r =10 partitions and p =256 processors.

As we have stated, two additional processes complete the method, the partition of the dataset and the determination of the number of votes. Regarding the determination of the number of votes, as the process is also federalized and parallelized, it is also of linear complexity, (1/ p ) r ( n / s ) K  X  , being K plexity is constant if the number of processors is p = r ( n / s ).

The partition described can be implemented with a complexity O ( nlog ( n )), using a quicksort algorithm for sorting the values to make the subsets, or with a complexity O ( n ) dividing the projection along the vector in equal sized intervals. Both methods achieve the same performance as the obtained partition is very similar. In our experiments we have used the latter to keep the complexity of the whole procedure linear. However, this partition is specially designed for k -NN classifier. When the method is used with other classifiers, other methods can be used, such as a random partition, which is also of complexity O ( n ). 2.3. Parallel implementation
The parallel implementation is based on a master/slave architecture. The master performs the partition of the dataset and sends the subsets to each slave. Each slave performs the instance selection algorithm using only the instances of its subset and of the dataset must be kept in memory.

The threshold of votes is obtained using the same parallel federal approach. Again, we divide the dataset into disjoint subsets value of evaluating Eq. ( 1 ) in each subset.

On any parallel implementation, the communication between the different tasks is an important issue as an excess of informa-tion exchange harms the performance of the algorithm. In our method, the communication between the master and the slaves of information between tasks is needed. The communication between the different slaves and the master is needed in the follow-ing steps:
Furthermore, if the slaves can access the disk, they can read the needed data directly from it. a list of the selected instances, which is a small sequence of integers.

When the process of selection is finished, the step of obtaining the best value for the votes threshold must be carried out. As shown, this step is also performed in parallel. The exchange of information between the master and the slaves is similar to the previous one: 1. Before each slave initiates the evaluation of a certain threshold, it must receive the subset of data to perform that task. This amount of information is always small as the basis of the method is that each slave takes care of only a small part of the whole dataset. As in the previous case, if the slaves can access the disk, they can read the needed data directly from it. 2. Once the evaluation process is finished, the slaves send the evaluation performed to the master. The evaluation is the error obtained when the corresponding threshold is used, which is a real number.

Thus, in both cases the data exchanged between the master and the slaves is not large, avoiding a bottleneck in the algo-rithm. The whole parallel procedure is shown in Algorithm 2 . First, the algorithm sends a subset to every slave. Then it waits for the first slave to finish, gets the results and sends the fini shed slave a new subset, until all subsets are processed. The same procedure is performed for evaluating the best votes threshold. The final selection of instances in performed in line 14 of the algorithm. 3. Related work
Although, there are many papers that have addressed the problem of instance selection, few of them have dealt with large ing data into disjoint strata with equal
Algorithm 2. Federal instance selection ( FEDIS ) algorithm. class distribution. 2 The training data, T , is divided into t disjoint datasets, D
Next, the evolution is applied to each subset separately and the results of all such applications are combined for the final solution. If we have an algorithm of quadratic complexity, O ( n found that although stratification decreased the accuracy of standard instance selection methods, namely DROP3 and FCNN, the approach based on a memetic algorithm and stratification was able to beat the performance of DROP3 [9] and FCNN [10] on the the method can still be able to improve the results of classical methods applied to the whole dataset. Similar principles can be ification, as it shares the same design philosophy.
Algorithm 3. Algorithm for obtaining the optimum threshold of votes. problems. The basic philosophy of data partitioning has also been used in other data mining tasks, such as clustering [14,15] or multi-agent systems [16] .

Czarnowski [17] proposed an agent-based approach for distributed prototype selection. First, clusters of data are induced, and then prototypes are selected by a applying the agent-based population learning algorithm [18] . A global procedure pools the se-lected data and produce a global model. However, the method is tested only in medium datasets with a maximum size of 30,162 instances. Andrews and Fox [19] proposed a divide-and-conquer approach for data reduction in large datasets. First, the data is roughly divided into balanced clusters using bisecting k -means, then the prototypes are searched for in each cluster by affinity propagation. This method shares the philosophy of stratification, substituting the random sampling by a clustering method.
Only results in medium sized datasets are reported. 4. Experimental results
In order to make a fair comparison between the standard algorithms and our proposal, we have selected a set of 35 problems from the UCI Machine Learning Repository. For estimating the storage reduction and generalization error we used a 10-fold cross-validation method. Table 1 shows a summary of the features of the datasets. We have chosen datasets of at least 1000 instances.
The table shows the 10-fold cv generalization error of a 1-NN classifier without instance selection, that can be considered as a baseline measure of the error of each dataset. These datasets can be considered representative of problems from medium to large size.

The source code, in C and licensed under the GNU General Public License, used for all methods as well as the partitions of the datasets are freely available upon request to the authors.

All the experiments have been carried out in a cluster of 32 blades. Each blade is a bi-processor DELL Power Edge M600 with four cores per processor. Thus, we count with 256 cores. The blades are interconnected with a master node and among them with a 1 Gb network. In all the parallel implementations, we use a master/slave model, where all the information processed by the slaves is sent by the master. The processors run at 2.5 GHz and each blade has 16 Gb of memory.

To test our model we have chosen the most successful state-of-the-art algorithm, performed a comprehensive comparison of the performance of different evolutionary algorithms for instance selection and found that evolutionary based methods were able to outperform classical algorithms in both classification accuracy and data re-duction. Among the evolutionary algorithms, CHC achieved the best overall performance.

Furthermore, the major problem addressed when applying genetic algorithms to instance selection is the scaling of the algo-rithm. As the number of instances grows, the time needed for the genetic algorithm to reach a good solution increases exponen-method to test our approach.

For CHC we used a value of k =1, a population of 100 individuals evolved for 1000 generations with a mutation probability of 10% and a bit mutation probability of 10%. A mutation based on Reduced Nearest Neighbor (RNN) rule was applied with a prob-ability of 5%. These same values are used each time any of these methods is applied, both alone and within fitness function used for the individuals is the standard one in evolutionary instance selection: where r i is the reduction in storage, e i the training error, and 0 duction and accuracy are considered in equal terms. To evaluate e an individual that selects a subset of instances S is evaluated using as prototype set S \{ x }.

For the application of FEDIS we used subsets of s =1000 instances, and a minimum of at least 2 subsets, and performed r =10 rounds. For f ( v ) function, see Eq. (1) , we used  X  =0.5.

The execution time shown in the tables is the wall-clock time spent by the algorithms, including every part of them. We mea-votes is included in the reported time. In that way, no artificial advantage is put in our proposal.
As main statistical test, we used the Wilcoxon test [24] for comparing pairs of algorithms. The Wilcoxon test was chosen significant differences between the two compared methods. In all the comparison tables, we also show the win/draw/loss record algorithm in the column was better than the algorithm in the row (win), was equal (draw), or was worse (loss). as explained above. The figure shows the difference between the standard method and of our method whereas a negative value means a better result of the standard method. The comparison between the standard version and the federalized one is shown in Table 3 .
 dard method, and even improve them for some datasets. In terms of storage reduction, the most extreme case, krkopt dataset, FEDIS .chc is more than 2400 times faster than standard CHC, from an average execution time of 128418.3 s to an average execution time of 52.8 s.
 ing information between the master and the slaves. Other tasks includes all other programming instructions, such as allocating to any implementation of instance selection, regardless of any other differences. When two tasks are made concurrently, only the time spent as a whole is considered.

The figure shows that the different parts of our algorithm are not overburdening the execution. Data partitioning and data transfer represent, on average, only the 0.1% of the time. In the worst case, both tasks consume less than the 3% of the time. the time needed for this process is not dramatic.
 4.1. Class-imbalances datasets
In the previous section, we showed that our proposal matched the performance of the standard CHC algorithm in terms of
The relevance of this kind of problems [26] can hardly be overestimated because of the high number of interesting real-world problems that are class imbalanced [27] .
 We must bear in mind that we are not proposing a method for informative undersampling for the class-imbalanced problem [28] . Our aim is to study whether our proposal is able to match the results of the standard CHC algorithm in class-imbalanced problems. A positive answer will open a new research line of developing a specific version of imbalanced problems.

To test the ability of our method in class imbalanced datasets, we have used the problems shown in Table 4 . All problems are two-class problems, with an imbalance ratio of the minority class to the majority class from 1:2 to 1:130. The datasets breast-cancer, cancer, euthyroid, german, haberman, hepatitis, ionosphere, ozone1hr, ozone8hr, phoneme, pima, sick, tic-tac-toe and titanic are from the UCI Machine Learning Repository. The remaining datasets were artificially created following Garc X a et al. [29] .
 experiments, for the fitness function of CHC algorithm, we used training accuracy. However, accuracy is not a useful measure for have been developed to take into account the imbalanced nature of these problems. Given the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN), we can define several measures. Perhaps the most common is the true positive rate ( TP rate ), or recall ( R ), or sensitivity ( Sn ): which is relevant if we are only interested in the performance on the positive class; and the true negative rate ( TN ficity ( Sp ):
From these basic measures, others have been proposed, such as the F -measure [31] or, if we are concerned about the perfor-mance on both negative and positive classes, the G -mean measure [32] : This measure is a good compromise between specificity and sensitivity, so is the measure used for the fitness function for the
CHC algorithm. The G -mean is also the measure used in the plots. The remaining parameters of the evolution are the same as in previous experiments.

The comparison between CHC and FEDIS .chc is shown in Table 6 . The results follow the same pattern than the case for medium and dramatic differences. Again, the reduction in execution time is very significant.
 4.2. Very large datasets
In the previous experiments we showed the performance of FEDIS rithm to several very large problems. We used seven problems from the UCI Machine Learning repository and one from the
Pattern Analysis, Statistical Modeling and Computational Learning (PASCAL) challenge. problems, census , chrom21 and dna , are class-imbalanced problems, so we will address them separately. the memory needed to storage each dataset in a standard computer using 8 bytes for a real value in double format. Due to the size of these datasets no results with the standard methods can be shown, as the execution time would be prohibitive. Thus, as a base-line performance, we show the 1-NN testing error using all the training set. The table shows the potential of our parallel algo-rithm. Even for a dataset with almost five million instances, reduced amount of time of less than one hour. If we take into account that standard CHC needed more than 35 h for set, which has only 28,056 instances, we can get a clear idea of the usefulness of our approach. Furthermore, we are executing our method in a modest cluster of 256 cores. With larger clusters, the execution time would be even shorter. the same achieved with the whole dataset with the exception of
The other three datasets are class-imba lanced problems. Results are shown in Table 8 . The table also shows the minority/ majority class imbalance ratio and as baseline measure the G -mean value using all the available data. needing less than 18 h for a dataset with 50,000,000 instances. Furthermore, the performance is also very good. The G -mean value is clearly improved with a large reduction in the storage.

The major difference is the time spent in other tasks, especially the time needed for memory allocation and data preprocessing. 4.3. Comparison with strati fi cation and stratification using CHC as base method. We have used a parallel implementation of stratification using the same architecture of
FEDIS . As for the previous experiments, times reported show wall clock times including all the stages of the algorithms. All the parameters of the two methods, FEDIS and stratification, are the same, including a subset size of 1000 instances.
The comparison between stratification and FEDIS is shown in Table 9 . The table shows results for medium/large sized datasets, class-imbalanced datasets and very large datasets. The results for medium/large datasets are plotted in Fig. 7 . The comparison in terms of reduction.

The comparison also shows that FEDIS is almost as fast as stratification. These results need explanation. In medium sized data-sets, all the rounds of voting can be made at once in the 256 cores, when we have less than 256 subsets. This occurs for datasets with less than 25,000 instances. For these datasets, FEDIS not large for any dataset, being the largest difference below 54 s.
 The results for class-imbalanced problems are plotted in Fig. 8 . The comparison shows the same behavior of both algorithms. expected, but the differences are not large. This is because, although tions, all these rounds can be done simultaneously. In fact, with a larger cluster, both stratification and Table 9 ). In fact, in very large class-imbalanced datasets, the performance of 5. Conclusions and future work
In this paper we have presented a new parallel method for scaling up instance selection algorithms that is applicable to any instance selection method without any modification. The method consists of concurrently applying instance selection on small disjoint subsets of the original dataset and combining them by means of a voting method. Using a CHC genetic algorithm, we have shown that our method is able to match the performance of the original algorithm with a considerable reduction in execution time.

The results show that our parallel approach allows the scaling up of instance selection algorithms to problems of almost over small datasets, keeping the time spent by the process low; secondly, only those small subsets of instances must be kept in memory, removing any scalability constraint due to memory limits.

A comparison with a parallel implementation of the stratification method, which shares the philosophy of our approach, showed that our proposal is better in terms of achieved accuracy whereas keeps the same reduction of stratification. The cost is a higher running time. This pattern of behavior has been shown in medium/large datasets and class-imbalanced problems.
We have also shown that our approach is able to scale up to very large problems with up to 50 millions of instances. Using the testing error similar, and sometimes better, to the 1-NN error using the whole dataset. This is due to the relaxation of the constraints on the complexity of the base method through the possibility of using federal instance selection. For these very large datasets, FEDIS is significantly better than stratification.

As an additional ability of our method, we must mention that it is applicable to other data mining tasks, such as feature selec-tion, construction of ensembles of classifiers and cluster analysis.

References
