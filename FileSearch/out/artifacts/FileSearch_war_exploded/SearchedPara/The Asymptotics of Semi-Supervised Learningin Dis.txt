 Nataliya Sokolovska sokolovska@telecom-paristech.fr Olivier Capp  X e cappe@telecom-paristech.fr Fran  X cois Yvon yvon@limsi.fr Universit  X e Paris-Sud 11 and LIMSI-CNRS, 91403 Orsay, France In most real-world pattern classification problems (e.g., for text, image or audio data), unannotated data is plentiful and can be collected at almost no cost, whereas labeled data are comparatively rarer, and more costly to gather. A sensible question is thus to find ways to exploit the unlabeled data in order to improve the performance of supervised training pro-cedures. Many proposals have been made in the re-cent years to devise effective semi-supervised training schemes (see (Chapelle et al., 2006) for an up-to-date panorama). In this contribution, we focus on meth-ods applicable to probabilistic classifiers, that is, clas-sifiers designed to provide a probabilistic confidence measure associated with each decision. These classi-fiers do not necessarily perform better than other alter-natives  X  particularly since probabilistic classification and minimum error classification are related, but dif-ferent, tasks  X  but are important in some applications, for instance when it comes to predicting the general-ization error, dealing with uneven error costs, ranking, combining decisions from multiple sources, etc. Probabilistic generative models fare easily with the use of unlabeled data, usually through Expectation-Maximization (see, e.g., (Nigam et al., 2000; Klein &amp; Manning, 2004) for successful implementations of this idea). It is however an extensively documented fact that discriminative models perform better than Gen-erative models for classification tasks (Ng &amp; Jordan, 2002). Integrating unlabeled data into discriminative models is however a much more challenging issue. Put in probabilistic terms, when learning to predict an out-put y from an observation x , a discriminative model at-tempts to fit P ( y | x ;  X  ), where  X  denotes the parameter. The role to be played by any available prior knowledge about the marginal probability P ( x ) in this context is not obvious. Several authors indeed claim that knowl-edge of P ( x ) is basically useless (Seeger, 2002; Lasserre et al., 2006), although one of the contribution of this paper will be to show that this intuition relies on the implicit assumption that the model is well-specified , in the sense of allowing a perfect fit of the conditional probability.
 The most common approach is to make the unknown parameter vector  X  depend on the unlabeled data, ei-ther directly or indirectly. One way to achieve this goal is to use the unlabeled data to enforce constraints on the shape of P ( y | x ): the cluster assumption , for in-stance, stipulates that the decision boundary should be located in low density regions (Seeger, 2002; Chapelle &amp; Zien, 2005). (Grandvalet &amp; Bengio, 2004) use this intuition to devise a semi-supervised training method (termed entropy regularization ), which com-bines the usual log-likelihood term with an entropy-based penalty; see also (Jiao et al., 2006), who extend this methodology to Conditional Random Fields, (Laf-ferty et al., 2001), or (Corduneanu &amp; Jaakkola, 2003) for related ideas. This approach, as any attempt to dis-tort the supervised training criterion with supplemen-tary terms faces two risks: (i) to turn a well-behaved convex optimization problem into a non-convex one, fraught with local optima, thus making the results highly dependent of a proper initialization; (ii) to loose the asymptotic consistency property of the usual (con-ditional maximum likelihood) estimator. As a result, these methods are not guaranteed to improve over a trivial baseline which would only use the available an-notated data. They furthermore require a fine tuning of the various optimization parameters (Mann &amp; Mc-Callum, 2007). The cluster assumption is also used in graph-based methods, which exploit the intuition that unlabeled data points should receive the same label as their labeled neighbors: in (Zhu &amp; Ghahramani, 2002), a neighborhood graph is used to iteratively propagate labels from labeled to unlabeled data points until con-vergence. (Lasserre et al., 2006) explores yet another avenue, introducing two sets of parameters: one for the condi-tional P ( y | x ;  X  ), and one for the marginal P ( x ;  X  ): the case where  X  and  X  are unrelated corresponds to the purely discriminative model, where unlabeled data are of no help; taking  X  =  X  recovers the traditional gener-ative model; introducing (via their Bayesian prior dis-tribution) dependencies between (  X , X  ) allows to build a full range of hybrid models. Finally, we also men-tion (Mann &amp; McCallum, 2007) who try to also exploit prior knowledge on the distribution of the labels Y , which may be available in some specific applications. In this paper, we try to challenge the view that un-labeled data cannot help purely discriminative mod-els by exhibiting a semi-supervised estimator of the parameter  X  which is asymptotically optimal and, in some situations, preferable to the usual maximum (conditional) likelihood estimator. To this aim, we make the simplifying assumption that the marginal P ( x ) is fully known, which is true in the limit of in-finitely many unlabeled data. An interesting obser-vation about the proposed method is that it is most efficient when the Bayes error is very small which cor-relates well with the intuition underlying most semi-supervised approaches that unlabeled data is most useful if one can assume that the classes are  X  X ell-separated X . In addition to the asymptotic results, we also discuss a number of empirical findings pertaining to logistic regression.
 This paper is organized as follows: in Section 2, we in-troduce our formal framework and formulate the main result of the paper (Theorem 1), which is first exposed in its full generality, then particularized to the case of the logistic regression. Experiments with the logistic regression model are discussed in Section 3. Conclud-ing remarks and perspectives close the paper. Let g ( y | x ;  X  ) denote the conditional probability den-sity function (pdf) corresponding to a discriminative probabilistic model parameterized by  X   X   X . In the following, we will always assume that the class vari-able Y takes its values in a finite set, Y , with a special interest for the binary case where Y = { 0 , 1 } . We will further assume that the input (or explanatory) vari-able X also takes its values in a finite set X , which may be arbitrary large.
 The training procedure has access to a set of n i.i.d. tentially unlimited number of unlabeled observations, where the quantity of unlabeled data is so large that we can consider that the marginal probability of X is fully known.
 Finally, for a function f : R p 7 X  R , we denote by  X  z f ( z  X  ) the p  X  1 gradient vector and by  X  z T  X  z f ( z the p  X  p Hessian matrix in z  X  . When f : R p 7 X  R r , the notation  X  z T f ( z  X  ) will be used to denote the r  X  p Jacobian matrix in z  X  . 2.1. Preliminary: A Simple Case We first consider the case where the  X  X odel X  of in-terest is very basic and simply consists in estimating the complete joint probability of X and Y , which is denoted by  X  ( x,y ). We will also denote by  X  ( y | x ) and q ( x ), respectively, the conditional and the marginal probabilities associated with  X  . Although this case is not directly of interest for real-life statistical learning tasks, it highlights the role played by the knowledge of the marginal q in semi-supervised learning.
 It is well known that the maximum-likelihood estima-tor of  X  ( x,y ) defined by is asymptotically efficient with asymptotic variance  X  ( x,y ) =  X  ( x,y )(1  X   X  ( x,y )) (assuming that 0 &lt;  X  ( x,y ) &lt; 1).
 Assume now that we are given q ( x ), the marginal distribution of X , and that 0 &lt; q ( x ) &lt; 1. It is easily checked that the maximum-likelihood estima-tor of  X  ( x,y ) subject to the marginal constraint that P y  X  X   X  ( x,y ) = q ( x ) is given by where the superscript s stands for  X  X emi-supervised X  and the ratio is recognized as the maximum-likelihood estimate of the conditional probability  X  ( y | x ). As ( x,y ) is a ratio of two simple estimators, its asymp-totic variance can be computed using the  X  -method, yielding As 0 &lt;  X  ( x,y )  X  q ( x ) &lt; 1,  X  s ( x,y ) is less than  X  ( x,y ). Hence, in general the semi-supervised esti-mator  X   X  s n ( x,y ) and  X   X  n ( x,y ) are not asymptotically equivalent, and  X   X  s n ( x,y ) is preferable. More precisely, which tends to zero as  X  ( x,y ) gets closer to q ( x ). In other words, the performance of  X   X  s n ( x,y ) is all the more appreciable, compared to that of  X   X  n ( x,y ), that y is a frequent label for x . In this case, knowledge of the marginal q ( x ) makes it possible to obtain a precise estimate of  X   X  s n ( x,y )  X  q ( x ) even with a very limited number of observations of x . 2.2. General Discriminative Model We now consider the extension of the previous sim-ple observation to the case of a general discrimina-tive probabilistic model; the main difference being the fact that a given parametric model { g ( y | x ;  X  ) }  X   X   X  generally not be able to fit exactly the actual condi-tional distribution  X  ( y | x ) of the data. As in the fully-specified case above, it is nonetheless possible to ex-hibit a semi-supervised estimator which is asymptot-ically optimal and preferable to the usual conditional maximum likelihood estimator defined by the conditional log-likelihood function.
 Under the (classical) assumptions of Theorem 1 be-low, 1 E  X  [  X  ( Y | X ;  X  )] and thus the limiting value of by The maximum likelihood estimator in (3) may also be interpreted as  X   X  n = arg min  X   X   X  E  X   X  denotes the empirical measure associated with the sample ( X i ,Y i ) 1  X  i  X  n , which also coincides with the maximum likelihood estimate of  X  ( x,y ) defined in (1). If we now assume that the marginal q ( x ) is available, we know that  X   X  n ( x,y ) is dominated (asymptotically) by the estimator  X   X  s n ( x,y ) defined in (2), which we here particularize to  X   X  s n ( x,y ) =  X   X   X   X   X  By analogy with the construction used in the absence of information on q , we now define the corresponding semi-supervised estimator as  X  E somewhat loosely here as it may happen that, for finite to one with probability one, for sufficiently large n . It is easily checked that  X   X  s n may also be rewritten as  X   X  s n = arg min Eq. (6) is a weighted version of (3) where the weight given to observations that share the same input x is common and reflects our prior knowledge on the marginal q ( x ).
 Theorem 1 Let the joint probability of X and Y fac-torize as  X  ( x,y ) =  X  ( y | x ) q ( x ) , where q is known, and define the following matrices Assume that (1) X and Y are finite sets; (2)  X  ( x,y ) &gt; 0 for all ( x,y )  X  X  X Y ; (3) for all ( x,y )  X  X  X Y ,  X  ( y | x ;  X  ) is bounded on  X  ; (4)  X   X  is the unique mini-mizer of E  X  [  X  ( Y | X ;  X  )] on  X  ; (5) for all ( x,y )  X  X  X Y ,  X  ( y | x ;  X  ) is twice continuously differentiable on  X  ; (6) the matrices H (  X   X  ) and J (  X   X  ) are non singular. Then,  X   X  n and  X   X  s n are consistent and asymptotically normal estimators of  X   X  , which satisfy  X   X  Furthermore,  X   X  s n is asymptotically efficient. Theorem 1 asserts that the asymptotic covariance ma-trix associated with  X   X  s n is optimal. Understanding the relations between H (  X   X  ) and I (  X   X  ) is thus important to assess the asymptotic performance achievable by any semi-supervised training method which assumes prior knowledge of q ( x ). Indeed, the well-known Rao-Blackwell variance decomposition shows that As a result, the difference between both estimators will mostly depend on whether E  X  [  X   X   X  ( Y | X ;  X   X  ) | X = x ] varies significantly or not around 0 as a function of x , given that, by definition,  X   X  is such that E q (E  X  [  X   X   X  ( Y | X ;  X   X  ) | X ]) = 0.
 Note that in the particular case where the model is well-specified , in the sense that  X   X  is such that g ( y | x ;  X   X  ) =  X  ( y | x ) for all ( x,y )  X  X  X Y , not only is E q (E  X  [  X   X   X  ( Y | X ;  X   X  ) | X ]) null but one in-deed has the stronger result that for all x  X  X  , E which H (  X   X  ) = I (  X   X  ), and hence, where both estima-tors are asymptotically equivalent; it is also well known that in this case J (  X   X  ) = I (  X   X  ) so that all asymptotic covariance matrices coincide with the usual expression of the inverse of the Fisher information matrix for  X  . Theorem 1 gives formal support to the intuition that it is impossible to improve over the classic maximum likelihood estimator for large n  X  X  when the model is well-specified, even when the marginal q is known. The results of Theorem 1 are stated in terms of pa-rameter estimation which is usually not the primary interest for statistical learning tasks. Due to the non-differentiability of the 0 X 1 loss, it is not directly possi-ble to derive results pertaining to the error probability from Theorem 1. One may however state the follow-ing result in terms of the logarithmic risk , in which the negated log-likelihood  X  ( y | x ;  X  ) is interpreted as a loss function.
 Corollary 2 In addition to the assumptions of Theorem 1, assume that  X  ( y | x ;  X  ) has bounded second derivative on  X  . Then, the logarith-mic risk admits the following asymptotic equiva-2 n trace I (  X   X  ) J notes the expectation with respect to the train-ing data ( X i ,Y i ) 1  X  i  X  n ; for the semi-supervised es-timator  X   X  s n , the first order term is given by 2 n trace H (  X   X  ) J As a final comment on Theorem 1, note that the form of the semi-supervised estimator in (6) shows that  X   X  s n will be consistent also in the presence of covariate shift (i.e., when the marginal distribution of the training sample differs from q ), whereas the logistic regression estimates can only be consistent in this case if we assume that the model is well-specified (Shimodaira, 2000). In the presence of covariate shift however, the expressions of the asymptotic covariance matrices will be different. 2.3. Application to Logistic Regression To gain further insight into the results summarized in Theorem 1, we consider the example of the logistic regression model with binary labels Y and input vari-ables X in R p ; the parameter  X  is thus p -dimensional. In this model, the negative log-likelihood function is given by  X  ( y | x ;  X  ) =  X  y X  T x + log(1 + e  X  T x ) 1 . Thus, the estimation equation which implicitly defines the value of the optimal fit  X   X  as the value for which E  X  [  X   X   X  ( Y | X ;  X   X  )] = 0 may be rewritten as Similar direct calculations yield H (  X   X  ) = E q  X  (1 | X )(1  X   X  (1 | X )) XX T (13) J (  X   X  ) = E q g (1 | X ;  X   X  ) { 1  X  g (1 | X ;  X   X  ) } XX J (  X   X  ) is the Fisher information matrix traditionally found in logistic regression. Interestingly, H (  X   X  ) is rec-ognized as the Fisher information matrix for  X   X  cor-responding to the fully supervised logistic regression model in the well-specified case (i.e. assuming that g ( y | x ;  X   X  ) =  X  ( y | x )), although we made no such as-sumption here.
 For logistic regression, the difference
I (  X   X  )  X  H (  X   X  ) = E q {  X  (1 | X )  X  g (1 | X ;  X   X  is clearly a term that is all the more significant that the fit achievable by the model is poor. The second im-portant factor that can lead to substantial differences between the asymptotic performances of  X   X  n and  X   X  s n is revealed by the following observation: for a given dis-tribution  X  , the largest (in a matrix sense) achievable value for I (  X   X  ) is given by whereas H (  X   X  ) in (13) may be rewritten as
H (  X   X  ) = E q max {  X  (1 | X ) , 1  X   X  (1 | X ) } Hence the difference between I (  X   X  ) and H (  X   X  ) can only become very significant in cases where min {  X  (1 | X = x ) , 1  X   X  (1 | X = x ) } is small, that is, when the prob-ability of incorrect decision is small, for some values of x . The overall effect will be all the more significant that this situation happens for many values of x , or, in other words, that the Bayes error associated with  X  is small. 3.1. A Small Scale Experiment We consider here experiments on artificial data which correspond to the case of binary logistic regression discussed in Section 2.3. We focus on a small-scale problem where it is possible to exactly compute error probabilities and risks so as to completely bypass the empirical evaluation of trained classifiers. This setting makes it possible to obtain an accurate assessment of the performance as the only source of Monte Carlo error lies in the choice of the training corpus. More precisely, we consider the case where each observation consists of a vector of p = 10 positive counts which sums to k = 3. Hence the logistic regression parame-ter  X  is ten-dimensional and the set X of possible count tors.
 In this case, it is well-known that one can simu-late data from well-specified logistic models by re-sorting to mixture of multinomial distributions. De-note by  X  1 the prior probability of class 1, and by  X  0 and  X  1 the vectors of multinomial parame-ters. Count vectors X generated from the mixture of multinomial have marginal probabilities q ( x ) =  X  1 mult( x ;  X  1 ) + (1  X   X  1 ) mult( x ;  X  0 ) and conditional probabilities P( Y = 1 | X = x ) = { 1 + exp  X  [(log  X  1  X  derstood componentwise. In the following, we take  X  1 = 0 . 5, i.e., balanced classes, so as to avoid the bias term.
 In order to generate misspecified scenarios, we simply flipped the labels of a few (three in the case shown on figures. 1 X 2) x  X  X  taken among the most likely ones. This label flipping transformation leaves the Bayes er-ror unchanged to that of the underlying unperturbed logistic model but the performance achievable by logis-tic regression is of course reduced. Figures 1 and 2 cor-respond to a case where the underlying unperturbed logistic model has a Bayes error of 1.7% and the prob-ability of error associated with the best fitting logistic model is of 9.4%. Remember that in these figures, the only source of randomness is due to the choice of the training sample, which is repeated 1000 times inde-pendently for each size of the training sample, from n = 10 to n = 5000 observations.
 As logistic regression is very sensitive to the use of reg-ularization for small sample sizes (here, when n is less than one thousand), both (3) and (6) were regular-ized by adding a L 2 penalty term of the form  X  n k  X  k 2 , where  X  n has been calibrated independently for each value of n . This being said, the optimal regularization parameter was always found to be within a factor 2 of  X  for (6). The effect of regularization is also negligible for the two rightmost boxplots in each graph (i.e., when n is greater than 1000). On figures 1 and 2, the su-perimposed horizontal dashed lines correspond to the theoretical averages computed from Theorem 1 and Corollary 2, respectively.
 When n is larger than one thousand, figures 1 and 2 perfectly correlate with the theory which predicts some advantage for the semi-supervised estimator as we are considering a case where the Bayes error is small and the model misspecification is significant. For large values of n , the semi-supervised estimator not only achieves better average performance but also does so more constantly, with a reduced variability. For smaller values of n , the picture is more contrasted, particularly when n ranges from 50 to 100 where the semi-supervised estimator may perform comparatively worse than the logistic regression. In this example, in terms of the probability of error, the semi-supervised estimator performs marginally better than logistic re-gression when n = 10 and n = 5000 (although the difference is bound to be very small in the latter case) and somewhat worse in between.
 As expected, the difference between both approaches for large values of n decreases for scenarios with larger error probabilities. In those scenarios, the semi-supervised estimator performs worse than logistic re-gression for smaller values of n and equivalently for large values of n . A finding of interest is the fact that for well-specified models (i.e., with data generated from a multinomial mixture model) with low Bayes er-ror, the semi-supervised approach does perform better than logistic regression, for small values of n . This ef-fect can be significant even when considering the prob-ability of error of the trained classifiers, as exemplified on Figure 3 in a case where the Bayes error is 6.3%. This observation is promising and deserves further in-vestigation as the analysis of Section 2 only explains the behavior observed for large values of n , which in the case of well-specified models results in the two ap-proaches being equivalent. 3.2. Text Classification Experiment To evaluate our methodology on a more realistic test bed, we have used a simple binary classification task, consisting in classifying mails as spam or ham based on their textual content. The corpus used is the Spa-mAssassin corpus (Mason, 2002), which contains ap-proximately 6 000 documents. Adapting our technique to real-world data requires to provide an estimate for the marginal q ( x ). This was carried out by perform-ing a discrete quantification of the data vectors as fol-lows. We first use unsupervised clustering techniques to partition the available unlabeled collection of docu-ments in k clusters. More specifically, we used a mix-ture of multinomial model as in (Nigam et al., 2000) with k = 10 components. We then simply adapt (6) by replacing q ( X i ) by the empirical frequency of the cluster to which X i belongs, likewise the denominator P j =1 1 { X j = X i } is replaced by the number of train-ing documents belonging to the same cluster as X i . We believe that this methodology is very general and makes the proposed approach applicable to a large va-riety of data. In effect, observations belonging to clus-ters which are underrepresented in the training corpus have higher relative weights, while the converse if true for observations belonging to overrepresented clusters. Note that, at this stage, no attempts have been made at tuning the number k of clusters, although intuition suggests that it would probably be reasonable to in-crease k (slowly) with n .
 We tested the method with n = 50 and n = 300 randomly chosen training documents, the remaining mails serving as the test set; each trial gave rise to 50 Monte Carlo replications. For each value of n , the best regularization parameter was determined experi-mentally both for the usual logistic regression and the semi-supervised estimator. Each document is here rep-resented as a count vector of dimension 1500. The resulting error rates are plotted as boxplots on Fig-ure 4. Although the difference between both meth-ods is certainly not very significant in this prelimi-nary experiment, we note that, as in the simple case of Section 3.1, the semi-supervised estimator provides a more less variable performance when n is small. In this contribution, we have tried to address the problem of semi-supervised learning without using any prior idea on what type of information is to be pro-vided by the unlabeled data. The result of Theorem 1 provides both proper theoretical support for the claim that the unlabeled data does not matter asymptot-ically when the model is well-specified and a better understanding of the cases where the unlabeled data does matter. In particular, it confirms the intuition that unlabeled data is most useful when the Bayes er-ror is small. One advantage of the proposed method is that it does not compromise the simplicity of the maximum likelihood approach because the weighted semi-supervised criterion stays convex. In addition, one could easily incorporate prior knowledge as used in other semi-supervised approaches: for instance the  X  X luster assumption X  can be implemented by modi-fying (5) so as to incorporate a Bayesian prior that connects conditional probabilities for neighboring val-ues of the input vector. In Section 3.2, we suggested a means by which the method can be extended to larger scales problem, including applications in which the fea-ture vector is either continuous or has a more complex structure. We are in particular currently investigat-ing the extension of the proposed approach to the case of sequence labelling with conditional random fields. Another open issue is the theoretical analysis of the behavior of the proposed criterion when n is small, which cannot be deduced from the asymptotic analy-sis presented here.
 First note that (10) is the well-known result that per-tains to the behavior of the maximum likelihood es-timator in misspecified models  X  see, for instance, (White, 1982) or Lemma 1 of (Shimodaira, 2000). Now, the fact that  X   X  s n = arg min  X   X   X  E  X   X  s plicitly defines the semi-supervised estimator  X   X  s n as a function of the maximum-likelihood estimator of the conditional probabilities In our setting, the conditional probability  X  may be represented by a finite dimensional vector block de-fined by  X  = (  X  ( x 1 ) ,...,  X  ( x d )) T , where  X  ( x (  X  ( y 1 | x i ) ,..., X  ( y k | x i )) T , { x 1 ,...,x d ments of X , and, { y 0 ,...,y k } denote the elements of Y . As usual in polytomous regression models, we omit one of the possible values of Y (by convention, y 0 ) due to the constraint that P y  X  X   X  ( y | x ) = 1, for all x  X  X  . stituted for  X  n ( y | x ).  X   X  n is the maximum likelihood estimator of  X  and it is asymptotically efficient with asymptotic covariance matrix given by K  X  1 (  X  ), the inverse of the Fisher information matrix for  X  , block-defined by where
K  X  1 ( x i ;  X  ) = q ( x i )  X  1 diag (  X  ( x i ))  X   X  ( x To obtain the asymptotic behavior of the semi-supervised estimator  X   X  s n , remark that  X   X  s n is obtained as a function  X  of  X   X  n , where  X  is implicitly defined by the optimality equation s (  X  , X  (  X  )) = 0 where s is the (negative of the) score function defined by s (  X  , X  ) =  X   X  E  X  [  X   X   X  ( Y | X ;  X  )] = ically efficient estimator of  X   X  with asymptotic covari-ance matrix given by  X  The Jacobian matrix  X  thanks to the implicit function theorem as From the definition of the score function in (16), it is obvious that  X   X  T s (  X  , X   X  ) = J (  X   X  ). In order to cal-culate  X  pression in (16) using the fact that  X  ( y 0 | x ) = 1  X  P The expression given in Theorem 1 or the asymp-totic variance of  X   X  s n follows by computing the product  X  ries into blocks of size k  X  and using the fact that  X  ( y 0 | x ) = 1  X  P y 6 = y Corollary 2 is based on the classical asymptotic ex-pansion of E  X  [  X  ( Y | X ;  X   X  n )]  X  E  X  [  X  ( Y | X ;  X   X  ) T J (  X   X  )(  X   X  n  X   X   X  ) + o p ( 1 2006).
 Bach, F. (2006). Active learning for misspecified gen-eralized linear models. NIPS .
 Chapelle, O., Sch  X olkopf, B., &amp; Zien, A. (2006). Semi-supervised learning . MIT Press.
 Chapelle, O., &amp; Zien, A. (2005). Semi-supervised clas-sification by low density separation. In Proc. of the
Tenth International Workshop on Artificial Intelli-gence and Statistics .
 Corduneanu, A., &amp; Jaakkola, T. (2003). On informa-tion regularization. In Proc. of the 19th conference on Uncertainty in Artificial Intelligence (UAI) . Grandvalet, Y., &amp; Bengio, Y. (2004). Semi-supervised learning by entropy minimization. NIPS .
 Jiao, F., Wang, S., Lee, C. H., Greiner, R., &amp; Schuur-mans, D. (2006). Semi-supervised conditional ran-dom fields for improved sequence segmentation and labeling. ACL/COLING .
 Klein, D., &amp; Manning, C. D. (2004). Corpus-based induction of syntactic structure: models of depen-dency and constituency. ACL .
 Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Con-ditional random fields: probabilistic models for seg-menting and labeling sequence data. ICML .
 Lasserre, J. A., Bishop, C. M., &amp; Minka, T. P. (2006).
Principled hybrids of generative and discriminative models. IEEE CVPR .
 Mann, G., &amp; McCallum, A. (2007). Simple, robust, scalable semi-supervised learning via expectation regularization. ICML .
 Mason, J. (2002). SpamAssassin corpus.
 Ng, A., &amp; Jordan, M. (2002). On discriminative vs. generative classifiers: A comparison of logistic re-gression and naive Bayes. NIPS .
 Nigam, K., McCallum, A. K., Thrun, S., &amp; Mitchell,
T. (2000). Text classification from labeled and unla-beled documents using EM. Machine Learning , 39 , 103 X 134.
 Seeger, M. (2002). Learning with labeled and unlabeled data (Technical Report). University of Edinburgh, Institute for Adaptive and Neural Computation. Shimodaira, H. (2000). Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of Statistical Planning and Infer-ence , 90 , 227 X 244.
 White, H. (1982). Maximum likelihood estimation in misspecified models. Econometrica , 50 , 1 X 25. Zhu, X., &amp; Ghahramani, Z. (2002). Learning from labeled and unlabeled data with label propagation
