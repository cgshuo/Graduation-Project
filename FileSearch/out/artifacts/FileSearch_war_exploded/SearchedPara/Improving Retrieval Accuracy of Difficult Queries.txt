 When a query topic is difficult and the search results are very poor, negative feedback is a very useful method to improve the retrieval accuracy and user experience. One challenge in negative feedback is that negative documents tend to be distracting in different ways, thus as training examples, negative examples are sparse. In this paper, we solve the problem of data sparseness in the language mod-eling framework. We propose an optimization framework, in which we learn from a few top-ranked non-relevant ex-amples, and search in a large space of all language mod-els to build a more general negative language model. This general negative language model has more power in prun-ing the non-relevant documents, thus potentially improving the performance for difficult queries. Experiment results on representative TREC collections show that the proposed optimization framework can improve negative feedback per-formance over the state-of-the-art negative feedback method through generalizing negative language models.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models Algorithms, Experimentation Negative Feedback, Language Models, Difficult topics, Gen-eralizing Language Model, Optimization.
When a query is so difficult that a large number of top-ranked documents are non-relevant, a user would have to ei-ther reformulate the query or go far down on the ranked list to examine more documents, both may decrease the user sat-isfaction. As a result, improving the effectiveness of search results for such difficult queries would bring user satisfaction which is the ultimate goal of search engines.

A commonly used strategy to improve search results is through feedback techniques, including relevance feedback (e.g., [29, 30, 31]), pseudo-relevance feedback (e.g., [1, 3, 42]) and implicit feedback [33]. In the case of difficult queries, if we can perform effective negative feedback when a user could not find any relevant document on the first page of the search results, we would be able to improve the rank-ing of the unseen results in the next few pages. It is clear that in this case of negative relevance feedback, we only have negative (i.e., non-relevant) documents since a query is difficult that none of the top-ranked documents are rel-evant. When a user is unable to reformulate an effective query (which happens often in informational queries due to insufficient knowledge about the relevant documents), neg-ative feedback can be quite beneficial, and the benefit can be achieved without requiring extra effort from users (e.g., by assuming the skipped documents by a user to be non-relevant).

While relevance feedback has been studied extensively, negative feedback has just attracted attention recently. In [40, 41], the authors studied different methods for negative feedback in both language models and vector space model and concluded that negative feedback for language modeling approaches works better than the vector space model. Neg-ative feedback works by excluding documents that are sim-ilar to an example negative document. Previous work [41] has shown MultiNeg strategy is most useful when each indi-vidual negative document is considered independently, sug-gesting that negative documents are distracting in different ways. Thus, as training examples, negative examples are sparse. Intuitively, if we can learn from each single negative example to prune aggressively a lot of non-relevant docu-ments from the top-ranked documents, we should improve the performance more, but in reality there is a risk of over-generalization of a negative example. Thus, an important, yet difficult question is how to appropriately generalize a negative language model; specifically, there are two techni-cal challenges to be solved: 1. What does a general language model mean? How do 2. Among all the general negative language models of a
In this paper, we tackle these two challenges in the lan-guage modeling framework. To address the first research question, we propose a formal definition of generality of a language model to measure if one negative language model is more general than another. For example, if the query is  X  X aguar X  and the user is looking for documents about jaguar animals, a document containing a jaguar car would be a non-relevant example. This document, however, may not men-tion the word  X  X ar X  that often, so if we construct a negative document language model based on this document, the high probability words may be words of a particular jaguar car model such as X  X lezon X  X nd X  X xford models X . While it is safe to use such words to prune non-relevant documents, their pruning power is limited. A more common word like  X  X ar X  would be able to prune non-relevant documents more effec-tively. This generalized negative language model is meant to capture this intuition, and it can be expected to be more ef-fective than the original negative document language model in removing other unseen non-relevant documents, thus im-proving the accuracy of search results.
 Figure 1: An illustrative example. Only case (a) is desirable.

To address the second research question, we propose an optimization framework where we seek a generalized nega-tive language model that optimizes three criteria: 1) close-ness to the original negative language model, 2) closeness to the query (if it is far from the query, the pruning power is not very effective), and 3) a generalization constraint that de-fines the amount of generalization we would like to achieve. The reason why all these three components are important can be explained in Figure 1, where (a) shows that the gen-eral negative language model (i.e., green circle) is safe since it is both close to the original negative language model (thus ensures that the pruned documents to be non-relevant) and reasonably close to the query (thus can make a difference in the top-ranked results through pruning). Figure 1 (b) shows that if we move too far away from the original negative lan-guage model and very close to the query, there would be a danger that we would move into the relevant documents zone (red circle). Figure 1 (c) shows another undesirable case where we move too far away from the query and as a result, pruning would only affect the lowly ranked docu-ments, and thus is less effective; specifically, although those documents (shown in red circle) are negative documents, removing those documents does not help improving the re-trieval accuracy for the given query since they are not in the query zone. So, it is very important to ensure the general-ized negative language model to be close to both the given query and the original negative language model .

Since the space of all possible negative language models is infinite, we propose two instantiations of our proposed opti-mization framework to search in a finite space of all feasible language models, which is more tractable.

The first instantiation is based on the KL-divergence distance function where we propose two different methods: 1) Perturbation: to remove the terms (based on the gener-ality measure) in the original negative language model that have less power in pruning non-relevant documents. 2) K-nearest neighborhood (KNN): to search in the neigh-borhood of the original negative language model to find a more general negative language model.

The second instantiation is based on selecting only powerful terms from the original negative language model where we define an optimization formulation and find an exact solution by solving the optimization formulation di-rectly.

We evaluate the proposed methods by comparing them with the best-performing negative feedback method from the existing work (i.e., MultiNeg) [41] on several representative TREC data sets. Experiment results show that our pro-posed solutions are more effective in removing non-relevant documents, thus improving the accuracy of search results for difficult queries.

The rest of the paper is organized as follows. We first review related work in section 3. We then describe our optimization framework for generalizing negative language models in section 4. In section 5, we describe the general-ity notion and instantiations of the proposed optimization framework. In sections 6 and 7, we describe our experimen-tal design and results. Finally, we conclude the paper in section 8.
The study of difficult queries has attracted much atten-tion recently especially with the launch of ROBUST track in TREC conference which aims at studying the robustness of retrieval models [37, 38]. However, the most effective re-trieval models that are developed by ROBUST participants relied on external resources (mostly Web) to perform query expansion which has bypassed the difficulty of the problem in reality. Because there are often no such external resources to exploit and indeed the web resources would not help im-prove the search accuracy for difficult queries on the Web itself. In this work, we aim at exploiting negative feedback information in the target collection through an optimization framework.

There has been some work on understanding why a query is difficult [4, 6, 15] or identifying difficult queries [38] or on predicating query performance [11, 43] but none of this work has addressed how to improve the search accuracy for difficult queries.

Feedback techniques have proven to be very effective for improving retrieval performance (e.g. [1, 14, 18, 20, 29, 30, 31, 33, 42, 44]). Most feedback methods rely on pos-itive documents, i.e., documents that are judged as rele-vant to provide useful related terms for query expansion. In contrast, negative (non-relevant) documents have not been found to be very useful. However, there have been some at-tempts to exploit non-relevant documents; query zone [34] appears to be the only major heuristic proposed to effec-tively exploit non-relevant information for document rout-ing tasks. It showed that using non-relevant documents that are close to the original query is more effective than using all non-relevant documents in the collection. Also, the work in [27] exploits high-scoring documents outside of top N documents (called pseudo-irrelevant documents) to improve the performance of pseudo-relevance feedback. The work in [40] and later extension to that [41] are the first stud-ies of negative relevance feedback that exploit the top non-relevant documents to improve the ranking of documents. Our work defines an important concept called generaliza-tion of a language model and we propose an optimization framework based on this concept to more aggressively (but carefully) prune non-relevant documents, leading to a more effective negative feedback method.

Since we define an optimization framework for negative feedback, our work is also related to previous optimization techniques for pseudo-relevance feedback [7, 8, 12]. Our work is similar to all this work since we also define an op-timization framework for term selection. However, it differs in that 1) our optimization framework is defined based on generalizing a negative language model, an important con-cept that none of the previous work considered; 2) our opti-mization framework is for negative feedback not for positive feedback, thus helps improving difficult queries.
Our work is also similar to other previous work that con-sider co-occurrence thesaurus to improve retrieval ranking(e.g., [2, 16, 21, 24, 26, 32, 35]) or hand-crafted thesaurus [22, 39]. Some other work has considered to combine both approaches [5, 23]. Also, the query expansion work in [9] used a term de-pendency graph in which word co-occurrence was one of the several dependency types. In this paper, we consider word co-occurrence relationship based on Mutual Informa-tion [28] (which has shown to be effective for word-to-word translation probabilities in Statistical Translation Language Model [17]) to find the similarity between words in our op-timization framework.
In the following we review basic retrieval model and feed-back methods used throughout this paper.
KL-divergence retrieval model [19] is one of the most ef-fective retrieval models in the language modeling frame-work. This model is a generalization of the query likelihood retrieval model [25] and would score a document D w.r.t query Q based on the negative Kullback-Leibler divergence between the query language model  X  Q and the document language model  X  D :
S R ( D,Q )=  X  D (  X  Q ||  X  D )=  X  where V is the words in the vocabulary.

Clearly, the two main tasks are to estimate the query language model  X  Q and the document language model  X  D . The document language model  X  D is usually smoothed us-ing Dirichlet prior smoothing which is an effective smoothing method [45].

The query model intuitively captures what the user is in-terested in, thus would affect retrieval accuracy significantly. The query language model, is often estimated (in case of no feedback) based on p ( w |  X  Q )= c ( w,Q ) | Q | ,where c ( w,Q )isthe count of word w in query Q and | Q | is the total number of words in the query. Such a model, is not very discriminative because a query is typically extremely short. When there is feedback information, the information would be used to improve our estimate of query language model,  X  Q .
Since a query model described above is usually short, the simple estimation method explained before is not discrimi-native. Several methods have proposed to improve the es-timation of  X  Q by exploiting documents terms, i.e., docu-ments that are used for either relevance or pseudo-relevance feedback [19, 20, 36, 44]. In [44], authors have defined a two-component mixture model (i.e., a fixed background lan-guage model, p ( w |C ), estimated using the whole collection and unknown topic language model to be estimated) and assumed that the feedback documents are generated using such a mixture model.

The basic idea in relevance feedback is to extract useful terms from positive documents and use them to expand the original query. When a query is difficult, it is often impossi-ble to obtain positive (or relevant) documents for feedback. Therefore, the best way would be to exploit the negative documents to perform negative feedback [41]. The idea of negative feedback is to identify distracting non-relevant doc-uments and penalize unseen documents containing such in-formation. More formally:
Given a query Q and a document collection C , a retrieval system returns a ranked list of documents L where l i is the i  X  th ranked document in the ranked list L .Weas-sume that the query Q is difficult so that the top n ranked documents (seen so far by the user) are non-relevant. The goal is to study how to use these negative examples, i.e., N = { l 1 ,...,l f } , to re-rank the next r unseen documents in the original ranked list: U = { l f +1 ,  X  X  X  ,l f + r } experiments we set f = 10 to simulate the first-page result and set r = 1000 but any other values could be used without loss of generality.
 The two negative feedback methods proposed in [41] are SingleNeg and MultiNeg methods which we briefly describe below:
SingleNeg : This method adjusts the original relevance score of a document with a single negative model. Let  X  Q and  X  D be estimated query model and document model, re-spectively. Let  X  N be a negative topic model estimated based on negative feedback documents N = { l 1 ,...,l f } . The new scoring according to this model is: In order to estimate  X  N , it is assumed that all non-relevant documents are generated from a mixture model of a unigram language model  X  N and a background language model (gen-erating common words). The log-likelihood of the N sample documents is: L ( N|  X  N )= Where  X  (=0.9 in our experiments) is a mixture parame-ter that controls the weight of the background model, i.e., estimate parameters p ( w |  X  N ).

MultiNeg : This method adjusts the original relevance scores with multiple negative models. Document D w.r.t queryQisscoredasfollows: where Q neg is a negative query representation and  X  is a parameter that controls the influence of negative feedback. EM algorithm is used to estimate a negative model  X  i for each individual negative document l i in N . Then we obtain f negative models and combine them with the above for-mula in our experiments.
 Improving negative document language model: Aba-sic component in both SingleNeg and MultiNeg is a negative document language model (i.e.,  X  N in SingleNeg and  X  i in MultiNeg), and the accuracy of the estimate of these neg-ative document models may affect the effectiveness of the negative feedback significantly. A main goal of our study is to improve the estimate of a negative document language model through generalizing a basic negative document lan-guage model (estimated with an existing approach) with an optimization framework. The improved negative document language models can then be directly plugged into an exist-ing negative feedback method to replace a current negative document language model. In the next section, we present an optimization framework for improving the estimate of negative document language models.
Given a query Q and a document collection C , a retrieval system returns a ranked list of documents L where l i is the i  X  th ranked document in the ranked list L . We assume that the query Q is difficult so that the top n ranked documents (seen so far by the user) are non-relevant. The goal of our study is to use these negative examples, i.e., N = { l 1 ,...,l (with language model  X  N ) to build a set of more general negative language models, each corresponding to a negative example, so that these general negative language models are better able to describe other unseen negative documents and improve the ranking of documents by pushing down nega-tive documents in the ranked list. More formally, given  X  N = {  X  1 ,..., X  f } which is the original negative language model based on documents in N , where  X  1 = { w 1 : p 1 ,...,w m : p w } (similarly for { i.e., each language model consists of words along with their probabilities.

Our goal is to estimate  X  G N = {  X  G 1 ,..., X  Gf } ,asetof more general negative language models than  X  N ,whereeach negative language model  X  G i is more general than its corre-sponding negative language model,  X  i . The improved nega-tive language models  X  G N can then be plugged into a nega-tive feedback method to improve feedback performance.
In order to build a more general negative language model, we propose an abstract optimization framework that given  X  , searches in the space of all language models and finds a set of more general negative language models, i.e.,  X  G N Note that since there are so many general language models, we make it tractable by searching in a finite space of all fea-sible solutions, S.

The objective function is defined as: Subject to:
This abstract optimization framework defines that we would like to search in the finite space of all language models S ,to find a more general negative language model  X  G  X  N ,thatis 1) close to the original negative language model  X  N (the first term), 2) and close to query Q (the second term). The close-ness to the query ensures the pruning power and the close-ness to the original negative language model ensures that the feedback model is indeed accurate . The generalization constraint is to avoid over-generalization . So, we want the general negative language model to deviate by only from its original negative language model (i.e., G (  X  G  X  N ) &gt;  X  and  X  are distance functions. G (  X  ) is a generality mea-sure defined in the next section.  X  is a tradeoff between closeness to the query and closeness to the original negative language model. controls the deviation from the original negative language model. These parameters can be opti-mized based on training data (i.e., cross validation) as done in our experiments.

In order to use the proposed optimization framework for negative feedback, there are three remaining problems to be solved: 1. Definition of the generality measure, i.e., G (  X  ). 2. Definition of the similarity/distance functions  X  and  X  . 3. Definition of a search algorithm to efficiently enumer-
In the next section, we discuss how we solve these prob-lems.
In this section, we propose to quantify the generality of a language model by introducing a new notion called Gener-ality , which is defined as the expected number of documents that hit a word. More Formally:
Generality G (  X  ): A language model  X  G K is more general than language model  X  K iff G (  X  G K ) &gt; G (  X  K )where defined as: Where df ( w ) is the number of documents containing word w in collection C (document frequency) and p ( w |  X  )isthe probability of word w given language model  X  .Intuitively, the generality in this formula is captured through both the probability of the word in the language model and the num-ber of documents containing that word in the collection.
Next, we define the distance functions,  X  and  X  in our optimization framework, and discuss how to efficiently solve the optimization problem.
We define two distance functions based on KL-divergence [10] and Term-based-Similarity, respectively. The search strate-gies vary according to the distance functions.
The first instantiation of the abstract optimization frame-work is to define the distance functions based on KL-divergence. Formally: where  X  Q is the query language model. Since there might be some terms which are absent in each of those distribu-tions, we use the symmetric version of KL-divergence for the similarity between two distributions  X  N and  X  G N , (i.e.
With these instantiations, our objective function is com-pletely defined. So the next challenge is how to efficiently search in the space S to find an optimal solution. Here we propose two strategies: 1. Perturbation of  X  N :Foreach  X  i in the original nega-2. K-nearest Neighborhood (KNN) : For this method,
In this section, we present another instantiation of our abstract optimization framework where we seek an exact solution in a finite space of all language models defined based on term similarity and selection. Specifically, for each top non-relevant document, we get m non-relevant words gained from MultiNeg strategy and feed those terms to the following objective function.

In the abstract optimization framework defined earlier, there are two important components, which we now discuss how to instantiate using term-based similarity. For conve-nience, in the following we use  X  and  X  to denote similarity instead of distance as in the original optimization frame-work. 1) Closeness to the original negative language model: We instantiate this component as where
DF =[ df ( w 1 ) ,...,df ( w m )] T is a vector of document fre-quencies (in the collection) for each word w i (document fre-quency for word w i ).
 10 for each of the 10 non-relevant documents (e.g., p ( w is the probability of word w 1 given the language model  X  X =[ x 1 ,...,x m ] T is the solution vector, which tells which of the words among m words should be included as final words according to the objective function. 2) Closeness to query: where Sim Q =[ Sim ( w 1 ,q ) ,...,Sim ( w m ,q )] T which is the similarity between each word and query word. In case a query consists of multiple words, we get their average sim-ilarity. We define the co-occurrence between two words as their similarity. The co-occurrence similarity is based on Mutual Information [28]. Mutual Information is a good mea-sure to assess how two words are related. We compute the mutual information scores for each pair of two words w and u in the collection. Informally, mutual information com-pares the probability of observing w and u together (the joint probability) with the probabilities of observing w and u independently. The mutual information between words w and u is calculated as follows: I ( w ; u )= where X u and X w are binary variables indicating whether u or w is present or absent.
And, The objective function is then defined as follows:
Since the two components defined in this optimization framework (i.e., closeness to query and closeness to original negative language model) are not really comparable, we re-parameterize it as above, i.e.,  X  in the abstract optimization framework is replaced with  X  parameter when we instantiate it as shown in the figure.

Our solution, i.e., X would tell us which terms should be added to the final negative language model. x i =1,ifthe word should strongly be selected and zero otherwise. In all other cases, it is between 0 and 1. So, it can serve as our confidence in selecting the terms. We can then recover the  X 
G N based on X as follows (re-normalization is done):
We denote this method as OptMultiNeg in our experiment results.
We experiment with two data sets that are representative of heterogeneous and homogeneous data sets, respectively. Our first data set is ROBUST track of TREC 2004 which has 528,155 news articles [38]. On average, each document has 521.89 words and there are 249 queries 1 in this set. The robust track is a standard ad hoc retrieval with an emphasis on the overall reliability of IR systems which contains diffi-cult queries and is a heterogeneous data set. The data set is called  X  X OBUST X .

The second data set is the AP88-90 in ad hoc retrieval which is a homogeneous data set. It contains 242,918 documents. On average, each document has about 464.226 terms. We used queries 51  X  200 for our experiments. The data set is called  X  X P88-90 X .
One query was dropped because the evaluators did not pro-vide any relevant documents for it.

For both data sets, preprocessing of documents and queries is minimum and involves only stemming with Porter stem-mer but without removing any stopwords. As in some pre-vious work (e.g., [45]), we did not remove stop words for two reasons: (1) A robust model should be able to discount the stop words. (2) Removing stop words would introduce one extra parameter (e.g. the number of stop words) into our experiments.

Since our goal is to study difficult queries, we consider naturally difficult queries from our data sets as follows:
We follow the definition of naturally difficult queries as in [41]. A query is naturally difficult when its P@10=0 given a retrieval model. For language model (LM), we use the standard ranking function (i.e., KL-divergence retrieval model with Dirichlet Prior Smoothing [19]) to select their naturally difficult queries. We first optimize the parameter  X  (Dirichlet Prior) for LM on all data sets. The optimal is gained when  X  = 2000 for ROBUST data set and  X  = 3000 for AP88-90 data set using Lemur toolkit 2 .Wethenfix these parameters in all the following experiments. Using the optimal parameter setting, we select those queries whose P@10=0 as our naturally difficult queries. 26 queries in RO-BUST and 38 queries from AP88-90 are selected as naturally difficult queries and we experiment with these query sets in the rest of the paper.
Since previous work has shown MultiNeg is the most ef-fective negative feedback method [41], we focus on apply-ing the proposed language model generalization method to MultiNeg, and compare our proposed methods (i.e., Opt-MultiNeg, KNN and Perturbation) with two state of the art methods proposed in [41], i.e., SingleNeg and Multi-Neg. All our proposed solutions follow the same scoring as in [41], i.e., each negative document is used to penal-ize unseen documents, however the language models in our methods are more general. All the experiments are done using Lemur toolkit. The exact solution for OptMultiNeg method is solved using MATLAB.

Our experiment setup is the same as the one adopted in [41]. The goal is to simulate a scenario when a user has found the top-K ranked documents are non-relevant (i.e., these document were skipped by a user without being viewed) and is about to view the rest of the search results. At this point, we can naturally apply negative feedback to re-rank all the unseen documents. As in [41], we set K = 10, which simulates the scenario of applying negative feedback when a user has not found any relevant document on the first page of search results and is about to view the next page of results (a realistic assumption in the case of difficult topics).
With this setup, the top-ranked 1000 unseen documents for all runs were compared in terms of two sets of perfor-mance measures: (1) Mean Average Precision (MAP) and Geometric mean Average Precision (GMAP), which serve as good measures for the overall ranking accuracy. (2) Mean Reciprocal Rank (MRR) and Precision at 10 (P@10), which reflect the utility from users perspective who only read the top-ranked documents. Please note that since we are work-ing with difficult queries, GMAP is considered as our main measure , however, we show our experimental results based on all measures for the sake of completeness.

In order to set two baseline parameters (i.e.,  X  and  X  ), we do cross validation as follows: We fix the number of feed-back terms to 100 and learn two baseline parameters, i.e.,  X  (described in section 3, i.e., a parameter to control the in-http://www.lemurproject.org/ only based on 100 words extracted from each top non-relevant document. only based on 100 words extracted from each top non-relevant document. fluence of the negative feedback) and  X  X umber of documents to penalize X  (  X  in [41]) based on the training data. Since there are not so many naturally difficult queries in TREC data sets, we do leave-one-out cross validation to learn the parameters for the baselines. The parameters of our pro-posed methods, i.e.,  X  ,  X  , X and are also leaned through leave-one-out cross validation. Thus, the parameters of all the methods (i.e., our proposed methods and baseline meth-ods) are optimized in the same way (i.e., leave-one-out cross validation) to have a fair comparison. Please note that the number of feedback terms is chosen to be 100 (for each doc-ument) without loss of generality. As shown in Figure 2, when the number of feedback terms are small (smaller than 100), the performance is not good (with MultiNeg baseline method) and when the number of feedback terms are very large (larger than 200), the performance drops. To aid ex-position, we increase the number of feedback terms to even 10000 in Figure 2 (right), and as shown, the performance drops when the number of feedback terms increases.
We also experiment to get the optimal performance on test queries. For that, we vary  X  from 0 . 1to0 . 9and  X  from 50 to 1000 on test queries and select the best-performing set of parameters (i.e., one  X  and one  X  for all test queries) according to GMAP measure as done in [41] 3 but our main focus would be on the results gained from cross validation.
The authors only reported the upper bound results (or the optimal results) without reporting the results based on cross validation. However, one should note that parameters should be learned based on training data sets.
 We also vary  X  ,  X  , X and in our proposed solutions as shown in Figures 4 and 5 to get the optimal parameters.
In order to see the effectiveness of our proposed solutions, we compare them with the baselines methods.

The results are shown in Tables 1 and 2 based on both col-lections ROBUST and AP88-90, respectively. Table 1 (left) shows the cross validation results on ROBUST data set and Table 1 (right) shows the upper bound results. The results in Table 2 (left) and (right) also show cross validation and up-per bound results based on AP88-90 data set, respectively. The upper bound baseline results are comparable to their corresponding results reported previously [41] (the authors of [41] did not report the cross validation results). From these two tables, we have the following observations: (1) The results both based on upper bound and cross validation show that our proposed methods outperform the baselines in terms of GMAP (since this serves as our main measure and we maximize based on this measure when learn-ing the parameters). For example, on ROBUST data set, the OptMultiNeg method can improve GMAP from 0 . 0132 (in MultiNeg method) to 0 . 0144, about 9% relative improve-ment which is a significant improvement given that the dif-ficult queries are harder to be improved. On AP88  X  90, our proposed methods can also significanlty improve over base-line methods. The results are also statistically significant based on Wilcoxon signed-rank tests (for GMAP measure) for those cases marked in the tables. We also show the percentage improvement for our methods over the baselines (based on cross validation only) in Tables 1 and 2 (left). For example, OptMultiNeg / MultiNeg means the improvement of OptMultiNeg over MultiNeg baseline method. Please note that we only show the percentage improvement for cross val-idation results only since these are our main results. (2) Another interesting observation is that although we only maximize based on GMAP, the results of our proposed methods also outperform MAP and MRR measure in most cases (cross validation results). (3) Comparing our proposed methods shows that the Opt-MultiNeg method outperforms (according to GMAP mea-sure) all the other proposed methods since it finds an exact optimal solution.

Given that these are all very difficult queries where the state of the art retrieval models worked poorly and nega-tive feedback can be done automatically based on implicit feedback information without requiring any additional user effort, these results are quite encouraging.

Table 5 shows some sample words along with their prob-abilities selected both based on MultiNeg and OptMultiNeg for TREC query 690 (This is an example where our Opt-MultiNeg outperformed the baselines in terms of GMAP measure a lot). We only show top 10 selected terms and also calculate their generality measures for these two methods. It is shown that our OptMultiNeg method is more general ues calculated here is based on only 10 shown words; we should also mention that G 100 (  X  ) &gt; G 100 (  X  ), i.e., our Opti-mizeMultiNeg is more general than MultiNeg when top 100 words are selected (this is the number of feedback terms that we experimented with). In addition, we show another exam-ple (TREC query 343) where the performance was hurt a lot. The sample words selected are shown in Table 6 which shows the over-generalization both in terms of the words them-selves (e.g., words are not specific compared to the original words) and in terms of the generalization value.

Another experiment setup is to give all the words ex-tracted from the original non-relevant documents to the Opt-MultiNeg method and let the method choose among them (instead of choosing among top 100 words). Our hypothesis is that the results of our OptMultiNeg from this experiment should also be better than that of baselines for the case when we have only 100 terms. The results of such experiments are shown in Tables 3 and 4 for both data sets. As shown in the tables, the results are worse than their corresponding results in Tables 1 and 2 (as we expected from the analyses shown in Figure 2). However, the OptMultiNeg still outperforms the baselines which confirms our hypothesis.

Efficiency of our Proposed Methods : Since we only have 10 negative examples (first-page result simulation), build-ing a language model for each of them can be done efficiently online. Also, since we search in the finite space of all the po-tential language models, the search is fast enough to be done online, i.e., even for the OptMultiNeg method, search does not take a lot of time to select words since the space of the selection is also finite.
 Table 5: 10 Sample word selected from MultiNeg model
Since there are parameters associated with our proposed methods, in this section, we analyze the sensitivity of the parameters to GMAP measure.
 Figure 4 (left) shows sensitivity of  X  to GMAP in Opt-MultiNeg method for both ROBUST and AP88-90 data sets. We first fix  X  ,  X  to their optimal values and vary  X  to see how it changes to the GMAP value. As shown in the figure, the two-end points show poor performance of the OptMulti-Neg method which indicates that over-generalization hurts the performance.  X  in Perturbation method to GMAP (right). KNN method to GMAP (right).
 Table 6: 10 Sample word selected from MultiNeg model
Figure 4 (right) shows the sensitivity of  X  in Perturba-tion method. As shown in the figure, when we increase the amount of  X , it hurts the performance, so it indicates that over-generalization hurts the performance and  X  should be set to: 1 &lt;  X  &lt; 5 to ensure improvement in the perfor-mance.
 Figure 5 (left) also shows the sensitivity of parameter  X  in KNN method 4 which is a tradeoff between closeness to query and closeness to negative language model. The best perfor-mance is gained when 0 . 4 &lt; X &lt; 0 . 6 which confirms our hypothesis that the general negative language model should be close to both query and original negative language model.
Figure 5 (right) also shows the sensitivity of parameter in KNN method. As we increase , the performance hurts in-
The same pattern can also be seen with Perturbation method. dicating that over-generalization hurts the performance and should be set to: 1 &lt;&lt; 50.
How to help users when their queries do not work well with state of the art retrieval methods is a very important, yet difficult challenge. Negative feedback is an important and useful technique for tackling this challenge, and can be done automatically without requiring extra user effort based on implicit feedback information (such as skipping all the results on the first page and attempting to view addi-tional results on the next page). In this paper, we addressed the problem of data sparseness in negative feedback in the language modeling framework by proposing an abstract op-timization framework, in which we learn from a few top-ranked non-relevant examples, and search in the space of all candidate language models to build a more general nega-tive language model. This general negative language model has been shown to have more power in pruning the non-relevant documents on two representative TREC data sets, outperforming state of the art negative feedback methods significantly for difficult queries. The proposed method is general and can be potentially implemented in any search engine applications to improve a user X  X  experience in the case of difficult topics.

Our work is only a first step in the exploration of the gen-eral idea of generalization of language models. There are many interesting directions to further explore. First, we can relax the feedback condition to include a small number of positive feedback examples, which would lead to the interest-ing problem of how to generalize both negative and positive language models simultaneously. Second, it would be inter-esting to apply Explanation-based Learning (EBL) [13] to feedback and construct a generalized language model based on a formal explanation of why a document has been judged as non-relevant (or relevant). Finally, we believe that the idea of generalizing language models can also be potentially applied to many other tasks in interactive retrieval where we need to infer a user X  X  intent based on the user X  X  behavior.
This material is based upon work supported by the Na-tional Science Foundation under Grant Numbers IIS-0713581, CNS-0834709, and CNS 1028381, by NIH/NLM grant 1 R01 LM009153-01, and by a Sloan Research Fellowship. Maryam Karimzadehgan was supported by the Google PhD fellow-ship. Any opinions, findings, conclusions, or recommenda-tions expressed in this material are the authors X  and do not necessarily reflect those of the sponsors.
