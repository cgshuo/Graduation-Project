 In this paper, we deal with two research issues: the automation of visual attribute identification and semantic relation learning between visual attributes and object categories. The contribution is two-fold, firstly, we provide uniform framework to reliably extract both categorical attributes and depictive attributes. Secondly, we incorporate the obt ained semantic associations between visual attributes and object categories into a text-based topic model and extract descriptive latent topics from external textual knowledge sources. Specifically, we show that in mining natural language descriptions from external knowledge sources, the relation between semantic visual attributes and object categories can be encoded as Must-Links and Cannot-Links, which can be represented by Dirichlet-Forest prior. To alleviate the workload of manual supervision and labeling in image categorization process, we introduce a semi-supervised training framework using soft-margin semi -supervised SVM classifier. We also show that the large-scale ima ge categorization results can be significantly improved by comb ining automatically acquired visual attributes. Experimental results show that the proposed model achieves better ability in describing object-related attributes and makes the inferred latent topics more descriptive. I.2.6 [ Artificial Intelligence ]: Learning  X  Parameter learning ; H.2.8 [ Database Management ]: Database applications  X  Data mining ; Image databases ; H.1.2 [ Models and Principles ]: User/Machine Systems  X  Human factors, Human information processing Algorithms, Experimentation, Human Factors, Design. Visual attribute identification, topic model, Dirichlet-Forest prior In our daily life, a large amount of our verbal communication describes the scene/environmen t around us. Also, recent years have seen increasing amount of on line visual resources (such as images and videos) with natura l language descriptions. Such information may potentially serve as a rich knowledgebase of how people construct natural language to describe visual content. In order that an image annotation system facilitate extracting and understanding the knowledge encoded in the visual content, it is very important to generate descriptive topic models that combines natural languages descriptions with image visual attributes. This work differs from conventional computer vision approaches such as scene recognition and object classification. Instead, it will encode additional semantic information such as the relation between object categories and differe nt visual attributes, which is then linked to natural language descriptions of human knowledge (such as Wikipeida) to generate descriptive topic model regarding object with those visual attributes (Fig. 1). Fig. 1 illustration of lexical concept, narrative natural language description and visual attributes Image annotation was conventionally solved as nearest-neighbor problem [3, 20]. Similar appro aches range from studying the relevance between visual similarity and semantic si milarity [15], using language entities to construct visual ontologies [7] or jointly modeling images and tags [11]. However, those approaches are infeasible when labeled reference exemplars are not available. An alternative way is to rely on st ructured knowledge bases of natural language descriptions (such as Wikipedia). Due to the increasing need of linking visual appearance to structured human knowledge in scalable image cat egorization/annotation, the extraction of semantic visual attributes has received increasing research focus. By its literal definition, the term  X  X ttribute X  means  X  X  quality or characteristic inherent in or ascribed to an object X . Compared to low-level image features, semantic visual attributes have much stronger relation to both objec t categories and human knowledge. It should be noted that although various types of attributes can be used to literally describe an object, however, only a small fraction of those attributes may be visible from an object image. Moreover, the usage of textual attributes may differ in different context. For example, in addition to color, texture, shape, body parts, semantic attributes of an animal may also involve its behavior, nutrition, activity, habitat and characters; on the contrary, the attributes about a plant may involve its cultivation and uses, which may be related to botany study. In order that the semantic attributes be useful for image annotat ion, these attributes should be visible and discrimi nating among different object categories, also, the union of se mantic visual attributes should have sufficient coverage, which means that each object category be covered by at least one attribute. In our research, we focus on the automation of attribute identification process and semantic relation learning between visual attributes and external textual knowledge sources. The contribution is two-fold, firstly, we provide uniform framework to reliably extract both categorical attributes and depictive attributes. Secondly, we incorporate the obt ained semantic associations between visual attributes and object categories into a text-based topic model and extract descriptive latent topics from natural language knowledge base. Specificall y, we show that in mining large scale knowledge base of na tural language descriptions, the relation between semantic visual attributes and object categories can be encoded as Must-Links and Cannot-Links, which can be represented by Dirichlet-Forest prior. To reduce the amount of framework using soft-margin se mi-supervised SVM classifier (Fig. 2). We also show that th e large-scale image categorization results can be significantly impr oved by combining automatically acquired visual attributes. The remainder of this paper is or ganized as follows. In Section 2, we introduce the preliminary task in providing reliable source for attribute learning. In Section 3, we introduce our approach for image attribute classification. In Section 4, we present the framework of associate semantic visual attributes with text-based topic models via Dirichlet Fore st prior and provide the Gibbs sampler for model estimation. Sec tion 5 reports the experimental results. We conclude the paper in Section 6. ImageNet dataset [9] is a recently established large scale image ontology (over 15 million images from more than twenty thousand synsets) built upon the WordNet Structure, covering a subset of the nouns of WordNet. In ImageNet dataset, bounding boxes are available for over 3000 popular synsets. For each synset, there are on average 1 50 images with bounding boxes. The bounding boxes are manually annotated and verified through Amazon Mechanical Turk (AMT) workers. Comparing to attribute learning from full image (FI), the advantage of attribute learning in bounding boxes is obvious, the concept is much cleaner than the full image, no background clutter and other unrelated objects. Related resear ches have shown that image visual recognition algorithms significantly benefi t from explicitly localizing category instance in the image [15]. Moreover, the association between image categories and visual attributes can also be significantly strengthen when using bounding box annotation. While high-qualit y manual labeled bounding boxes have led to impressive object recognition results, however, the main drawback of this approach is that it requires labor-intensive manual labeling and is not scalable to new object categories. In our approach, we proposed to r obustly classify object categories and learn visible semantic attri butes from automatically detected bounding boxes in ImageNet images (Fig. 2). Fig. 2 Bounding boxes as reliable source for attribute learning In our approach, we extract the HOG-LBP feature [20] for bounding box detection. We follow the settings in [3] to train the preliminary non-linear SVM classifiers, in which the kernel of categorical classification is the sum of individual  X  of each features. We use 80% image data for training and remaining 20% for validation. Achieves average multi-class classification accuracy of 38.5%. Specifically, we densely sample multi-scale detection windows  X   X   X   X   X , X , X   X  in whole-image range and then perform the 3D mean-shift [17] mode seeking algorithm (in both spatial and scale dimension) on the density map of SVM decision scores across the image to effectively locate the bounding boxes of objects. Give n an detected window  X   X  X  ,y ,s  X  , the 3D mean-shift is calculated as: windows within the neighborhood of  X   X   X  X  X  ,  X   X   X  decision score associated to each location  X   X  , and  X  X  X  X  X  is the profile of kernel  X  , which satisfies  X   X   X   X   X  X   X  X   X   X  with  X   X   X   X  X   X   X ,  X  ,s  X 0  X  , iteratively compute j th mean shift vector  X   X  X  X  X  and move the estimation window by  X   X   X  X  X  X  repeat until convergence. We choose a set of kernel scales around the original image scale as  X  X   X   X  X   X   X 1.17  X   X  X  X  X  X  X  X  X  X , , in which n=2 use the Gaussian kernel  X   X   X   X   X  X  X  X   X   X   X   X   X   X  X   X   X   X  X 2/ its shadow kernel  X   X   X   X   X  X / X  X 1 X  X  X   X  . Given the relatively low accuracy (38.5%) in preliminary bounding box detection, directly assigning hard labels to the detected bounding boxes is sub-optimal . Instead, it is reasonable for us to consider the boun ding box data as high-quality  X  X nlabeled X  data with balanced positive and negative samples (i.e. accurate bounding boxes and inaccurate bounding boxes, respectively). In order to achieve optimal performance in object categorization, we propose to us e soft-margin semi-supervised classifier in training (Fig. 2). However, one of the major challenges is how to appropriate ly involve unlabeled examples and efficiently update the discr iminative model in an online semi-supervised setting. In our approach, we focus on exploring the intrinsic manifold structure of data marginal distribution and studying its role in kernel function optimization. As shown in [2], general SVM training problem can be extended by considering the ambient space and the marginal distribution of the target function, thus two ap propriate penalty terms can be introduced to reflect both the ambient space and the intrinsic structure of the data marginal distribution  X   X  . Specifically, the target function could be estimated by:  X  Beltrami operator associated with  X   X   X   X   X   X   X   X   X   X   X   X  X  X  X  X   X   X  examples  X  X   X   X  manifold  X  X  X   X  can be approximated by the graph Laplacian  X  on the basis of labeled and unlabeled data i.e.  X   X  Laplacian given by  X  X  X  X  X  X  , in which  X   X  X  X  is similarity between  X   X  and  X   X  calculated by kernel function k ,  X  X   X   X , X   X   X   X   X  X  X   X  X  X   X  X  X  X  . The optimization pr oblem (2) becomes: functions over both labeled and unlabeled data: kernel matrix K with its entries K  X , X   X  X  X  X   X   X   X   X   X   X  Similarly,  X   X  X   X  X   X   X   X   X   X   X  X ,  X   X   X  X   X  KLK X  . By substituting into (3) the hinge loss function  X  X 1 X   X   X   X   X   X   X   X  by introducing the Lagrangian in which two Lagrange multipliers  X   X ,  X   X 0 are defined for either constraint:  X   X   X , X , X , X , X   X   X   X   X   X   X   X  X   X   X   X   X   X   X  X  X   X  X  X  X   X  X  X   X   X ,  X   X   X  X 1 X  X  X  X  X   X   X   X  X  X   X   X   X   X   X   X   X   X  X  X  X  (6)  X   X   X   X   X  into (6) with  X  and  X   X  removed, it gives:  X   X   X   X , X   X   X  X   X   X  X   X  K X   X   X   X  X   X  K X   X  X  X  expansion coefficients  X   X  ,...,  X   X  X  X  can be obtained by solving the following quadratic dual program:  X  X  X  X  X Q X   X  I X   X   X  (8) is a standard restricted quadratic program which can be solved via conjugate gradient descent in Ch. 6 of [2]. During training, the labeled data  X   X   X   X   X ,  X   X   X   X  X  X  X   X  and unlabeled data  X  X  solving  X   X  , X   X  by conjugate gradient descent, where  X   X  X  X 1, X 1 X  . By substituting the solution  X   X  , X   X  of quadratic program (7) to (4), we obtain the expansion of kernel function over both labeled data  X   X   X   X   X ,  X   X   X   X  X  X  X   X  and unlabeled data  X  X  stage of detection, the decision function classified new samples into class +1 or -1 by  X   X   X   X   X  X  X  X  X  X  X  X   X   X   X   X  ). . Previous studies on descriptive visual attributes have shown beneficial to improve the perform ance of object ategorization and text description generation [14]. The depictive visual attributes involves color attributes, texture a ttributes (such as furry, wooden, rough), pattern attributes (spotted, striped) and shape attributes (long, round, rectangle). The attribut es may also be associated to the visual similarity with known obj ect classes (for example, giant panda and polar bear both have bea r-like attribute). Ideally, these attributes should be able to di scriminate between object classes (being associated to some but not all of them), provide sufficient coverage (all classes have at least a single attribute association), and be correlated to visual object class properties that can be observed in images. In our approach, three types (Fig. 3) of features are used for attribute extraction, i.e. GIST feature [4], densely sampled SIFT [6] and HOG-LBP feature [20]. Each of the three feature types is normalized independently to unit length, then a histogram intersection kern el SVMs [14] is performed to function [10] to the SVM decision score and convert the output to a probability. The probability  X  X  X  X  X  X  X  X  X | X  X  X  X  X  X  X  X  X  X  X  can be aggregated across the whole dataset and eventually build the semantic relations (such as Must -link and Cannot-link) between visual attributes and object categories. Given images of an object category , some visual attributes may be presented while some may not, which results in unique attribute signatures associated with each category. Let  X   X   X  X  X  X  be a vector of binary associations  X   X   X   X 0,1 X  X  between attributes  X  and trained object category  X  . An aggregation of all results (in which  X   X   X   X 1 for positive samples and 0 for negative samples) from binary classifier of attribute  X   X  can provide an estimation of in category  X  . By assuming mutual independence among attributes, we have  X   X  |  X   X   X   X   X   X   X   X  |  X   X   X   X  X  X  X  . Following the idea of Direct Attribute Prediction model (DAP) in [3], For an image  X  with  X  X  X  attributes  X   X   X ,..., attribute corresponds to exactly one conditional probability category  X  is given as Our experiment results show the performance of object categorization can be signi ficantly improved when the categorization results are smoothed by (9), with  X 10  X  most relevant attributes used (Fig. 7). By aggregating the results of binary attribute classifiers for all the object categories, we obtain an aggregated attribute-category concurrence map. From which we threshold the aggregation score to produce both Must-Link and Cannot-Link relations for each attribute-category pair  X  X , X  X  . In this section, we introduce a novel topic model to infer depictive latent topics from both text corpora and attribute-category classification in ImageNet [8, 15] suggest that visual classification across semantically-defined class boundaries is feasible. In [13], the author proposed to infer object class-attribute association by text-based semantic relatedness on WordNet and Wikipedia. The WordNet is a large scale lexical database of English Language, in which English words are organized into concepts (synonym sets or synsets) according to synonymy and various lexical and semantic relations between lexicalized concepts. Wikipedia is one of the most comprehensive and well-formed electronic knowledge repositories on the web with millions of articles contributed collaboratively by volunteers. Because of its reliability, accuracy and neutral point of view. Wikipedia has been exploited as external knowledge source in various data mining applications [13, 19]. Although Wikipedia is different from standard WordNet ontology, whic h is backed up by structured thesaurus, however, each article in Wikipedia only describes one single concept under a hierarchic al categorization system. We have found a large amount of Wiki pedia articles share the same lexicalized entry as ImageNet synsets, which makes mapping between ImageNet synset to a Wikipedia articles possible. (In our study, about 75% of the ImageNet synsets have corresponding Wikipedia articles). In our a pproach, the semantic relations between attribute-category pair s (i.e. Must-Links and Cannot-Links) are encoded as Dirichlet Fo rest prior in the proposed topic model. In order to effectively encode the semantic relations, we explore the WordNet synonym se t and extend Must-Links and Cannot-Links between attribute-cat egory terms (i.e. the lexical word of both attribute and object) to their synonyms. The Dirichlet Tree Distribution[17] is a generalization of Dirichlet distribution that allow to break the mutual independence in words generation process, makes the ge nerative process controlled by word-link such as Must-Link  X  X , X  X  . The Dirichlet-tree distribution is a tree with the words as leaf nodes; let  X  children of node  X  in the tree,  X  the leaves of the tree,  X  the internal sample  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X ~ X  , one first draws a multinomial at weights from  X  to its children as the Dirichlet parameters. The probability  X   X  of a word  X  X  X  is then simply the product of the multinomial parameters on the edges from  X  to the root. It can be shown that, the above procedure gives  X  X  X  X  X  X  X  X  X  X  X  X  X   X   X   X   X  X   X   X  |  X   X   X  In which  X   X  X  X  X  is the gamma function, and the notation  X  means  X   X  X  X  X  ; the function  X   X   X   X   X  X   X   X   X   X   X   X   X  X  X  X  difference between the in-degree and out-degree at internal node  X  . (When the difference  X   X   X   X   X 0 , for all internal node  X  , the Dirichlet tree reduces to a Dirichlet distribution). Like the Dirichlet distribution, the Dirichlet tree distribution is conjugate to the multinomial. It X  X  possible to integrate out  X  to get a distribution over word counts directly, similar to the multivariate Polya distribution (a.k.a. Dirichlet-Multinomial) in [16]:  X   X   X  |  X   X   X  X  X  X   X  X  X  X  X  ,  X  X  X  X  X  is the leaves in the subtree under  X  .  X  X  X  X  X  is the immediate children of node  X  . The definition of Must-Link is transitive. Must-Link  X  X , X  X  and Must-Link  X  X , X  X  define a transitive closure of and Must-Link  X  X , X , X  X  . In Dirichlet Tree for Must-L inks, each transitive closure is subtree, in which words are leaves nodes with symmetric uniform base measure  X  X  from one internal node  X  and each of theinternal node  X  is connected to the root node with weight |  X  X  X  X  X  |  X  , in which |  X  X  X  X  X  | is the size of leavens in sub-tree under . X  If  X 1 X  , then in-degree equals out-degree for any internal nodes(both are |  X  X  X  X  X  |  X  ), and the tree reduces to a Dirichlet distribution with symmetric prior  X  . When we take  X  X  |  X  X  X  X  X  | , it will re-distribute the probability mass at node  X  . Which results in increased concentration, and re-distribute the mass evenly in the transitive closure  X  . The independence (which is enforced in Dirichlet distribution) among Must-L ink words is thus eliminated and allows for similar but not identical probabilities for the Must-Link words. From the aggregated concurrence map of attribute-category relations, we are able to assign both Must-Links and Cannot-Links to an object category. It should be noted that, given the presence of an object category in an im age, the Must-Links and Cannot-Links corresponding to that cat egory should be simultaneity observed, therefore, such Must-L inks and Cannot-Links should be encoded in the same latent topic. With this consideration, we propose a clique-based topic sampling process as follows . In our approach, each  X  X lique X  is associated with one single object sub-tree corresponding to Must-Links of that object category, the second parts is all other words (other than words in Must-Links) that are allowed to simultaneously have large probability without violating the Cannot-Links of that object category (Fig. 4b). Each clique is also a Dirichlet tree. For each object category  X  , we generate a total of  X  cliques  X ,..., X 1 X   X  X  X  X  , in this way, we create a mixture model of  X   X  X  X  X  Dirichlet subtrees, one for each of the  X   X  X  X  X  cliques. In generating the latent topics, the cliques are sampled according to their probability  X   X   X   X   X ,..., X 1 X ,  X  X  X  X  . The clique X  X  root node connects to an internal node  X  (root node of Must-Link sub-tree) with weight  X  X  |  X  X  X  X  X  |  X  X  , the node  X  then connects to words in Must-Links with weight  X  . The clique X  X  root also directly connects to words that is not in Must-Links (but not violating the Cannot-Links of that object category) with weight  X  . This structure will send majority probability mass down to  X  and then re-distribute it among words in Must-Links. Which results in strong association among Must-Link words Let  X  be the number of object cate gories. Our Dirichlet Forest (cliques), each Dirichlet tree has  X  branches under the root, one for each connected component, for the r-th branch, there are  X  possible Dirichlet subtrees corresponding to  X   X  X  X  X  cliques, which tree in the forest is uniquely identified by an index vector  X   X   X  X  In generating a Dirichlet Fo rest model (Fig. 4a), let  X  number of word tokens in document  X  assign to topic  X  , integrating out  X  ,  X  can be generated as: For each topic T,..., X 1 X  , we sampled a Dirichlet tree  X   X  X   X   X   X   X   X ,...,  X   X   X   X   X  from the Dirichlet Forest prior  X  X , X  X  In which each  X   X   X  X  X  X   X ..., X 1 X , is sampled by:  X  X   X  X  X  X  X  X  X   X  Finally, the model can be generated by:  X   X   X , X , X   X :T |  X , X , X   X   X  X   X   X  |  X   X :T  X , X , X ,  X   X  X  X  X  X  X  X  X  X  X  X  X  X  In this section, we introduce the Markov Chain Monte Carlo and Gibbs sampling process of the proposed topic model. Let  X   X  X  X , X   X  X  X  X  be the number of word tokens in document  X  assigned to topic  X  , excluding the word  X   X  . Let  X   X  X  X , X   X  X  X  X  word tokens in the corpus that are under node  X  in topic  X   X  X  topic labels T,..., X 1 X  , we have:  X   X   X   X   X | X  X   X  X  X   X ,  X : X   X ,  X   X  X  X   X  X  X , X   X  X  X  X   X   X  X  X  X  In which  X  X  X  X  X  X   X  denotes the subset of internal nodes in topic  X  Dirichlet tree that are ancestors of leaf  X   X  and  X   X  node that is  X   X  X  immediate child and is also an ancestor of  X  (including  X   X  itself). Since the  X  branches (each corresponding to an object category, featured by both Must-Links and Cannot-Links) are independent, sampling the Dirichlet tree  X   X  is factorized to sampling the cliques for each  X   X   X  X  X  X  . For candidate cliques of connected component  X  : X   X   X  X  X  X  X  X 1,..., we have: In which I  X , X  X  X  X   X  denotes the internal nodes below the  X  tree  X   X  when clique  X   X   X  X  X  X  is selected. In this section, we evaluate the performance of the proposed methods, including automatic attr ibute identification, object categorization, and modeling th e semantic relations between visual attributes and object categories. In learning the visual attributes of object categories, we use the Animals with Attributes (AwA) da taset introduced by [3] (which is a fraction of ImageNet databa se). The AwA dataset consists of 50 mammal object categories with a human provided attribute inventory and corresponding object class-attribute associations. In our experiment, we split the data set into 80% training and 20% testing (i.e. 24,295 training images and 6,180 test images) for learning the attribute classifiers. We map all the 50 AwA categories to the corresponding synsets (identified with WordNet ID) under the ImageNet hierarch ical taxonomy, from which we are able to calculate the se mantic metric among different categories. Also, with the help of word entities from the corresponding WordNet ID (wnid), we download 75 Wikipedia articles that share the same lexicalized entry as WordNet entities (considering synonyms). The Wikipedia articles are then considered as the knowledge base of natural language description for corresponding ImageNet synsets or AwA categories. The first part of our experiment s is semi-supervised learning for object categorization. As menti oned in Section 2, bounding box detection is performed to ensure that we identify clean attributes from each object category. We are the learning process from 50 labeled images bounding box per class (i.e. 2500 image bounding boxes in total) for training, The semi-supervised SVM use 50 labeled bounding boxes and an addition of 50 unlabeled bounding box samples (from preliminary dete ction in Section 2.1). We use another 100 images from each class (other than the 5000 training image) for testing. For each test image  X  , if it is correctly classified  X   X 1 . Fig. 5 shows the Receiver Operating Characteristic ( ROC) curves of the object categorization results. Each curve is the result of the one-vs-all semi-supervised SVM categorical classifier on HOG-LBP feature. The Area Under Curves (AUC) are also provided. Higher AUC indicate better classify performance. For example, the AUC scores of gi ant panda (AUC=0.912) and zebra (AUC=0.975) are among the highest, indicating that these object categories are well represented by HOG-LBP feature and are well raccoon and lion is fair, which are possibly caused by the high diversity of object appearance among training samples. Fig. 5 Part of the object classification results plotted in receiver operating characteristic ( ROC) curves. Each curve is the result of the one-vs-all semi-supervised SVM categorical classifier on HOG-LBP feature. Fig. 7 Confusion matrix of cla ssifying 50 AWA animal classes. Upper: confusion matrix by semi-supervised SVM classifier. Lower: confusion matrix after object-attribute signatures being introduced in, categorization results are smoothed by (eq. 9), with  X  X  X  X  X  X  most relevant visual attributes used. In Fig. 6, we compare our catego rization method (semi-supervised SVM with HOG-LBP features) to tw o state-of-the-art approaches, i.e. SVM classifier using spatial bag of word (sBoW) features and SVM using HOG-LBP features. Specifically, Fig. 6a shows the Average Flat Error (AFE) with respect test images with top predictive scores. The AFE score is defined as:  X  X   X   X 5000  X , X 0,1 X  , the lower AFE score indicates better classification performance. Fig. 6b represents the Average Hierarchical Error (AHE) of different approaches. Supposing that the image from class  X  is mis-classified as class  X  , and  X  X , X  X  X  is the lowest common ancestor between class  X  and  X  in the hierarchy of ImageNet taxonomy. The height  X  X  X   X   X , X   X   X  of node  X  X , X  X  X  on the hierarchy is then defined as the length of the longest path to one of its leaf node. Leaf nodes have height 0. The AHE is the average of  X  X  X   X   X , X   X   X  for all the testing images,  X  X   X  5000 , the lower AHE score indicate higher semantic accuracy in object categorization. As shown in Fig. 6, the proposed object categorization method consistently outperforms the state-of-the-art approaches under both AFE and AHE comparisons. Fig. 7 shows the confusion matrix of object categorization in all the 50 AWA categories. By comparing the confusion matrix of semi-supervised SVM classifica tion and the confusion matrix categorization results are smoothed by the signature of the most relevant attributes, we can see that, the performance of object categorization can be significa ntly improved when attribute signatures are introduced. For example, in the original semi-supervised SVM classification resu lts (upper part of Fig.7), the giant panda category is to some extends confused with the tiger category and the spider monkey category. However, after introducing in the object-attribute signatures and smoothing the categorization results with poste rior object-attribute prediction model (eq. 9), the categorization ambiguity is mostly eliminated (lower part of Fig. 7). The si gnificantly reduced categorization ambiguity across the 50 AWA animal classes (Fig. 7) evidences the effectiveness of identified attribute-object relations. In this section, we perform both quantitative and qualitative evaluation on the performance of proposed topic model. The quantitative evaluation includes comparing both log-likelihood and perplexity, while qualitative evaluation is achieved by visualizing the inferred latent topics and evaluate its relevance to the object-attribute relations. Log-likelihood is one of the stan dard criteria in generative model evaluation. It provides a quantitative measurement of how well a topic model fits the training data. The score of log-likelihood (which is a negative real number) is the higher the better. In practice, the log-likelihood of word s given latent topics can be calculated by integrating out all the latent variables: (|) (|, )( |) ppzpz d  X  X  X   X  X  X   X  X  X   X  X   X  X  X  X  X  X  X  X   X  X  wz w (10) The perplexity is another standard criterion for generative probabilistic models that evaluates how well the model predicts the testing data. The perplexity of a testing dataset D The perplexity score for a model is the lower the better. Fig. 8a represents the log-likelihood comparison results between our proposed model and the LDA model over the iterations. As we can see from Fig. 8a, our proposed topic model has consistently higher log-likelihood than standard LDA model, which can be explained by the introduced Dirich let Forest priors, which make our model fit better to training data than the LDA model. Fig. 8b shows the comparison of perplexity between our model and the LDA model over the iterati ons. Our model achieves best perplexity scores when Q=3, wh ile the LDA model achieves best perplexity scores when topic number is 250. Although LDA model has relative lower perplexity score compared to our model, however, as we can see in the next section, the LDA model may not be able to accurately link object category to its attributes. On the convergence of the Markov Chain Monte Carlo and Gibbs sampling process, the conditional probability of each word/entity given each inferred latent topic can be obtained. ImageNet object categories (i.e. n02391049: zebra , n02129165: lion and n02581957: dolphin ), including the category names, the identified visual attributes, the Must-Links and Cannot-Link from aggregated attribute-object concurrence map. We also visualize the most relevant inferred latent topics with respect to each object category name entity. The relevance between object category name entities and the inferred la tent topics can be obtained by calculating the Mutual In formation (MI) score. The calculation of MI between a specific word entity and a latent topic is shown as eq. 12, in which R g and Z t variables corresponding to the word and the latent topic, respectively. The variable pair (R g ,Z t ) indicates the cases that latent topic Z t being assigned to word entity R g . Given the training data, both the joint probability (,) the marginal probabilities () estimated by counting the number of evidences over the training dataset. As we can see from Fig. 9 -Fig. 11, for the LDA model, the inferred latent topic that is most relevant to the object category doesn X  X  contain much visual attribute names associated with that object category. On the contrary, the latent topics inferred from our model have a lot of important visual attributes among the top-ranked words of the most relevant latent topic. Specifically, for the object category  X  dolphin  X  in Fig. 11, the most relevant latent topic inferred from our model invol ve visual attributes that are highly consistent with the identified Must-Link relations associated with the dolphin category such as  X  X lue X ,  X  X ater X ,  X  X hite X ,  X  X ish X , etc. while the most relevant latent topic inferred by LDA model doesn X  X  involve any visu al attributes a ssociated with dolphin in its top-ranked words. Similarly, for the object category model involve most visual attr ibutes associated with the dolphin suggesting that the Must-Link relationships between object categories and visual attributes are well preserved by the Dirichlet-tree distribution in our proposed model (Section 4.1). It X  X  also worth mentioning that, in Fig. 10, one of the attributes (i.e.  X  X potted X ) that cannot be linked to lion category is among the top-ranked words of the most releva nt latent topic inferred by the conventional LDA model. As a co mparison, none of the latent topics inferred by our proposed model violate Cannot-Link relations. The experiment result s indicate that the Cannot-Link relations between object categories and visual attributes can be effectively encoded by the Dirhchlet Forest prior introduced in Section 4.2, which enables the topic model to purify the inferred latent topics, filter out the  X  X oisy X  and  X  X elf-contradictory X  information from the textual descri ptions and produce consistently well topical abstraction of object categories and associated visual attributes. 
Most relevant latent topic: Fig. 9 the most relevant latent topic of object category  X  X ebra X  Fig. 10 the most relevant latent topics of object category  X  X ion Fig. 11 comparison the most rel evant latent topics of object category  X  X olphin X  In this paper, we deal with two research issues, i.e. the automation of visual attribute identification and semantic relation learning between visual attributes and object categories. The contribution is two-fold, firstly, we provide uniform framework to reliably extract both categorical attributes and depictive attributes. Secondly, we incorporate the obt ained semantic associations between visual attributes and object categories into a text-based topic model and extract descriptive latent topics from natural language knowledge base. Specificall y, we show that in mining large scale text corpora of na tural language descriptions, the relation between semantic visual attributes and object categories can be encoded as Must-Links and Cannot-Links, which can be represented by Dirichlet-Forest prior. To reduce the amount of categorization, a semi-supervised training framework using soft-margin semi-supervised SVM classifier is introduced. Last but not posterior object-attribute predicti on model to further improve the performance of object categorization. Experimental results show that the proposed model achieves better ability in describing object-related attributes and makes the inferred latent topics more descriptive. This work was supported in part by NSF IIP 1160960NSF CCF 1049864, NSF CCF 0905291, Project in the National Science &amp; Technology Pillar Program in the Twelfth Five-year Plan Period (No. 2012BAK24B01),and NSFC 90920005. [1] Andrzejewski D, Zhu X, Craven M. (2009) Incorporating [2] B. Schoelkopf, A. Smola, Learning with Kernels, 644, MIT [3] C. H. Lampert, H. Nickisch, and S. Harmeling. Learning to [4] C. Siagian and L. Itti, Ra pid Biologically-Inspired Scene [5] C. Wang, L. Zhang, and H. Zhang. Learning to reduce the [6] D. G. David G. Lowe, Di stinctive Image Features from [7] H. Wang, X. Jiang, L.-T. Chia, and A.-H. Tan. Ontology [8] J. Deng, A. Berg, K. Li and L. Fei-Fei, What does [9] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei, [10] J. Platt. Probabilistic outputs for support vector machines [11] L. Li, C. Wang, Y. Lim, D. Blei and L. Fei-Fei. Building [12] M. Belkin, P. Niyogi &amp; V. Sindhwani (2004) Manifold [13] M. Rohrbach, M. Stark, G. Szarvas, I. Gurevych, and B. [14] O. Russakovsky and L. Fe i-Fei, Attribute Learning in [15] T. Deselaers and V. Ferrari. Visual and Semantic Similarity [16] T. P. Minka. Estimati ng a dirichlet distribution. [17] T. P. Minka, "The dirichlet-tree distribution," in [18] X. Chen, X. Hu, Z. Zhou, C. Lu, G. Rosen, T. He, E.K. Park, Image Annotation, the 19th ACM Conference on [19] X. Hu, X. Zhang, C. Lu, E.K. Park, and X. Zhou, Exploiting [20] X. Wang, T. X. Han an d S. Yan,  X  X n HOG-LBP Human [21] Y. Cheng: Mean Shift, Mode Seeking, and Clustering. IEEE 
