 Query spelling correction is a crucial component of modern search engines. Existing methods in the literature for search query spelling correction have two major drawbacks. First, they are unable to handle certain important types of spelling errors, such as concatenation and splitting. Second, they cannot e ffi ciently evaluate all the candidate corrections due to the complex form of their scoring functions, and a heuris-tic filtering step must be applied to select a working set of top-K most promising candidates for final scoring, leading to non-optimal predictions. In this paper we address both limitations and propose a novel generalized Hidden Markov Model with discriminative training that can not only handle all the major types of spelling errors, including splitting and concatenation errors, in a single unified framework, but also e ffi ciently evaluate all the candidate corrections to ensure the finding of a globally optimal correction. Experiments on two query spelling correction datasets demonstrate that the proposed generalized HMM is e ff ective for correcting mul-tiple types of spelling errors. The results also show that it significantly outperforms the current approach for gener-ating top-K candidate corrections, making it a better first-stage filter to enable any other complex spelling correction algorithm to have access to a better working set of candidate corrections as well as to cover splitting and concatenation er-rors, which few existing method in academic literature can correct.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Query Alteration Query Spelling Correction, Generalized Hidden Markov Mod-els, Discriminative Training for HMMs
The ability to automatically correct potentially misspelled queries has become an indispensable component of modern search engines. People make errors in spelling frequently. Particularly, search engine users are more likely to commit misspellings in their queries as they are in most scenarios ex-ploring unfamiliar contents. Automatic spelling correction for queries helps the search engine to better understand the users X  intents and can therefore improve the quality of search experience. However, query spelling is not an easy task, es-pecially under the strict e ffi ciency constraint. In Table 1 we summarize major types of misspellings in real search engine queries. Users not only make typos on single words, (inser-tion, deletion and substitution), but can also easily mess up with word boundaries (concatenation and splitting). More-over, di ff erent types of misspelling could be committed in the same query, making it even harder to correct. Unfortunately, Table 1: Major Types of Query Spelling Errors no existing query spelling correction approaches in the liter-ature are able to correct all major types of errors, especially for correcting splitting and con catenation errors. To the best of my knowledge, the only work that can potentially address this problem is [24] in which a Conditional Random Field (CRF) model is proposed to handle a broad set of query refinements. However, this work considers query correction and splitting/merging as di ff erent tasks, hence it is unable to correct queries with mixed types of errors, such as sub-stitution and splitting errors in one query. In fact splitting and merging are two important error types in query spelling correction, and a major research challenge of query spelling correction is to accurately correct all major types of errors simultaneously. On the other hand, while modern industrial systems such as Google can handle this problem relatively well, it X  X  unclear what they have done, especially what re-sources they have employed in order to solve the challenges.
Another major di ffi culty in automatic query spelling cor-rection is the huge search space. Theoretically, any sequence of characters could potentially be the correction of a mis-spelled query. It is clearly intractable to enumerate and evaluate all possible sequences for the purpose of finding the correct query. Thus a more feasible strategy is to search in aspaceofallcombinationsofcandidatewordsthatareina neighborhood of each query word based on editing distance. The assumption is that a user X  X  spelling error of each single word is unlikely too dramatic, thus the correction is most likely in the neighborhood by editing distance. Unfortu-nately, even in this restricted space, the current approaches still cannot enumerate and evaluate all the candidates be-cause their scoring functions involve complex features that are expensive to compute. As a result, a separate filter-ing step must first be used to prune the search space so that the final scoring can be done on a small working set of candidates. Take [7] as a two-stage method example, in the first stage, a Viterbi or A* search algorithm is used to generate a small set of most promising candidates, and in the second stage di ff erent types of features of the candi-dates are computed and a ranker is employed to score the candidates. However, this two-stage strategy has a major drawback in computing the complete working set. Since the filtering stage uses a non-optimal objective function to en-sure e ffi ciency, it is quite possible that the best candidate is filtered out in the first stage, especially because we can-not a ff ord a large working set since the correction must be done online while a user is entering a query. The inabil-ity of searching the complete space of candidates leads to non-optimal correction accuracy.
 In this paper, we propose a generalized Hidden Markov Model (gHMM) for query spelling correction that can ad-dress deficiencies of the existing approaches discussed above. The proposed gHMM can model all major types of spelling errors, thus enabling considera tion of multiple types of errors in query spelling correction. In the proposed gHMM, the hidden states represent the correct forms of words, and the outcomes are the observed (potentially) misspelled terms. In addition, each state is associated with a type, indicat-ing merging, splitting or in-word transformation operation. The proposed HMM is generalized in the sense that it would allow adjustment of both emission probabilities and transi-tion probabilities to accommodate the non-optimal param-eter estimation. Unfortunately, such an extension of HMM makes it impossible to use a standard EM algorithm for parameter estimation. To solve this problem, we propose aperceptron-baseddiscriminativetrainingmethodtotrain the parameters in the HMM.

Moreover, a Viterbi-like search algorithm for top-K paths is designed to e ffi ciently obtain a small number of highly confident correction candidates. This algorithm can han-dle splitting/merging of multiple words. It takes into ac-count major types of local features such as error model, lan-guage model, and state type information. The error model is trained on a large set of query correction pairs from the web. And web scale language model is obtained by leveraging the Microsoft Web N-gram service [1].
 We conducted extensive evaluation on our proposed gHMM. For this purpose, we have constructed a query correction dataset from real search logs, which has been made publicly available. Experimental results verify that the gHMM can e ff ectively correct all major types of query spelling errors. It also reveal that the gHMM can run as e ffi cient as the common used noisy channel model, while it achieves much better results for obtaining the candidate space of query corrections. Therefore, in addition to being used as stand-ing alone query correction module, the proposed gHMM can also be used as a more e ff ective first-stage filtering module to more e ff ectively support any other complicated scoring functions such as those using complex global features.
Spelling correction has a long history [8]. Traditional spellers focused on dealing with non-word errors caused by misspelling a known word as an invalid word form. A com-mon strategy at that time was to utilize a trusted lexicon and certain distance measures, such as Levenshtein distance [13]. The size of lexicon in traditional spellers is usually small due to the high cost of manual construction of lexicon. Conse-quently, many valid word forms such as human names and neologisms are rarely included in the lexicon. Later, statis-tical generative models were introduced for spelling correc-tion, in which the error model and n-gram language model are identified as two critical components. Brill and Moore demonstrated that a better statistical error model is crucial for improving a speller X  X  accuracy [3]. But building such an error model requires a large set of manually annotated word correction pairs, which is expensive to obtain. Whitelaw et al. alleviated this problem by leveraging the Web to auto-matically discover the misspelled/corrected word pairs [12].
With the advent of the Web, the research on spelling cor-rection has received much more attention, particularly on the correction of search engin equeries.Manyresearchchal-lenges are raised, which are non-existent in traditional set-tings of spelling correction. More specifically, there are many more types of spelling errors in search queries, such as mis-spelling, concatenation/splitting of query words, and misuse of legitimate yet inappropriate words. Research in this di-rection includes utilizing large web corpora and query log [4, 5, 2], training phrase-based error model from clickthrough data [10] and developing additional features [7]. However, two important challenges are under addressed in these ap-proaches, i.e., correcting splitting and concatenation errors, and ensuring complete search in the candidate space to eval-uate an e ff ective scoring function.

Query alteration/refinement is a broader topic which nat-urally subsumes query spelling correction. Beside correcting the misspelled query, query alteration/refinement also need to modify the ine ff ective query so that it could be more suitable for the search intent. For this purpose, many re-search topics have been studied. Query expansion expands the query with additional terms to enrich the query for-mulation [14, 15, 16]. Query segmentation divides a query into semantically meaningful sub-units [17, 18]. Other query reformulation methods intend to replace the inappropriate query terms with e ff ective keywords to bridge the vocabu-lary gaps [19]. Particularly, there is research attempt [24] to use a unified model to do a broad set of query refinements such as correction, segmentation and even stemming. How-ever, it treats query correction and splitting/merging as sep-arate tasks, which is not true for real world queries. Also, it has very limited ability for query correction. For example, it only allows one letter di ff erence in deletion/insertion/substitution errors.

Query spelling correction also shares similarities with many other NLP tasks, such as speech recognition and machine translation. In many of these applications, HMM has been found very useful [21, 20]. Our generalized HMM model for query spelling correction is novel in that it models all the major types of misspellings in a unified framework. A discrete training method is also proposed to train the pa-rameters in the model. It is demonstrated that the gHMM model we use is very e ff ective for the task of query spelling correction.
Formally, let  X  be the alphabet of a language and L  X   X  + be a large lexicon of the language. We define the query spelling correction problem as:
Given a query q  X   X  + ,generatetop-Kmoste ff ectivecor-rections Y =( y 1 ,y 2 ,...,y k )where y i  X  L + is a candidate correction, and Y is sorted according to the probability of y being the correct spelling of the target query.

It is worth noting that from a search engine perspective, the ideal output Y should be sorted according to the prob-ability of y i retrieving the most satisfying results in search. However, in practice it is very di ffi cult to measure the satis-faction as unlike in ad hoc retrieval where the query is given in its correct form, here the real query is unknown. As a re-sult, di ff erent corrections could simply lead to queries with di ff erent meanings and it would be very subjective to deter-mine which query actually satisfies the user. In this paper, we are mostly concerned with the lexical and semantic cor-rectness of queries with the assumption that correction of mis-spelled query terms most likely would lead to improved retrieval accuracy.

The problem of query spelling correction is significantly harder than the traditional spelling correction. Previous re-searches show that approximately 10-15% of search queries contain spelling errors [5]. First, it is di ffi cult to cover all the di ff erent types of errors. The spelling errors generally fall into one of the following four categories: (1) in-word trans-formation, e.g. insertion, deletion, misspelling of characters. This type of error is most frequent in web queries, and it is not uncommon that up to 3 or 4 letters are misspelled; (2) mis-use of valid word, e.g.  X  X ersian golf X   X   X  X ersian gulf X . It is also a type of in-word tranformation errors; (3) concate-nation of multiple words, e.g.  X  X nitedstatesofamerica X   X   X  X nited states of america X ; (4) splitting a word into parts, e.g.  X  X ower point slides X   X   X  X owerpoint slides X . Among all these types, the splitting and concatenation errors are espe-cially challenging to correct. Indeed, no existing approaches in the academic literature can correct these two types of errors. Yet, it X  X  important to correct all types of errors be-cause users might commit di ff erent types of errors or even commit these errors at the same time. A main goal of this work is to develop a new HMM framework that can model and correct all major types of errors including splitting and concatenation.

Second, it is di ffi cult to ensure complete search of all the candidate space because the candidate space is very large. The existing work addresses this challenge by using a two-stage method, which searches for a small set of candidates with simple scoring functions and do re-ranking on top of these candidates. Unfortunately, the simple scoring function used in the first stage cannot ensure that the nominated candidate corrections in the first stage always contain the best correction, thus no matter how e ff ective the final scoring function is, we may miss the best correction simply because of the use of two separate stages. In this paper, we address this challenge by developing a generalized HMM that can both be e ffi ciently scored to ensure complete search in the candidate space and accurately correct all types of errors in aunifiedway.
Our algorithm accepts a query as input, and then gener-ates a small list of ranked corrections as output by a general-ized Hidden Markov Model (gHMM). It is trained by a dis-criminative method with labeled spelling examples. Given a query, it scores candidate spelling corrections in a one-stage fashion and outputs the top-K corrections, without using a re-ranking strategy. Other components of our algorithm in-clude a large clean lexicon, the error model and the language model. In this section we will focus on the gHMM model structure, the discriminative training of it, as well as the e ffi cient computation of spelling corrections.
We propose a generalized HMM Model to model the spelling correction problem. We call it a generalized HMM because there are several important di ff erences between it and the standard HMM model which will be explained later. With-out loss of generality, let an input query be q = q [1: n ] acorresponding correction be y = y [1: m ] where n, m are the length of the query and correction, which might or might not be equal. Here we introduce hidden state sequence z = z [1: n ] =( s 1 ,s 2 ,...,s n )inwhich z and q have the same length. An individual state s i is represented by a phrase corresponding to one or m ore terms in correction y [1: m ] gether the phrase representing z is equal to y .Therefore, finding best-K corrections Y =( y 1 ,y 2 ,...,y k )isequivalent to finding best-K state sequences Z =( z 1 ,z 2 ,...,z k ). In addition, there is a type t associated with each state, indi-cating the operation such as substitution, splitting, merging etc .Also,inordertofacilitatethemergingstateweintro-duce a NULL state. The NULL state is represented by an empty string, and it doesn X  X  emit any phrase. There can be multiple consecutive NULL states followed by a merging state. Table 2 summarizes the state types and the spelling errors they correspond to. Having the hidden states defined, the hypothesized process of observing a mis-spelled query is as follows: 1. sample a state s 1 and state type t 1 from the state space 2. emit a word in q 1 ,oremptystringifthe s 1 is a NULL 3. transit to s 2 with type t 2 according to the state tran-4. continue until the whole (potentially) mis-spelled query
Figure 1 illustrates our gHMM model with a concrete example. In this example, there are three potential er-rors with di ff erent error types, e.g.  X  X overment X   X   X  X ov-ernment X  (substitution),  X  X ome page X   X   X  X omepage X  (split-ting),  X  X llinoisstate X   X   X  X llinois state X  (concatenation). The state path shown in Figure 1 is one of the state sequences Transformation Substitution Substitution that can generate the query. Take state s 3 for example, s 3 is represented by phrase homepage .Since s 3 is a merg-ing state, it emits a phrase home page with probability P ( home page | homepage ). And s 3 is transited from state s with probability P ( s 3 | s 2 ). With this model, we are able to come up with arbitrary corrections instead of limiting ourselves to an incomprehensive set of queries from query log. By simultaneously modeling the misspellings on word boundaries, we are able to correct the query in a more inte-grated manner.
For a standard HMM [23], let  X  = { A, B,  X  } be the model parameters of the HMM, repres enting the transition prob-ability, emission probabilities and initial state probabilities respectively. Given a list of query words q [1: n ] (obtained by splitting empty spaces), the state sequence z  X  =( s  X  1 ,s that best explains q [1: n ] can be calculated by: However, theoretically the phrase in a state can be chosen arbitrarily, so estimating { A, B,  X  } is such a large space is al-most impossible in the standa rd HMM framework. In order to overcome this di ffi culty, the generalized Hidden Markov Model proposed in this work generalizes the standard HMM as follows: (1) gHMM introduces state type for each state, which indicates the correction operations and can reduce the search space e ff ectively; (2) it adopts feature functions to parameterize the measurement of probability of a state sequence given a query. Such treatment can not only map the transition and emission probabilities to feature functions with a small set of parameters, but can also add additional feature functions such as the ones incorporating state type information. Another important benefit of the feature func-tion representation is that we can use discriminative training on the model with labeled spelling corrections, which will lead to a more accurate estimation of the parameters.
Formally, in our gHMM model, there is an one-to-one rela-tionship between states in a state sequence and words in the original query. For a given query q = q [1: n ] and the sequence of states z =( s 1 ,s 2 ,...,s n ), we define a context h state in which an individual correction decision is made. The context is defined as h i = &lt;s i  X  1 ,t i  X  1 ,s i ,t i s i  X  1 ,t i  X  1 ,s i ,t i are the previous and current state and type decisions and q [1: n ] are all query words.

The generalized HMM model measures the probability of astatesequencebydefiningfeaturevectorsonthecontext-state pairs. A feature vector is a function that maps a context-state pair to a d -dimensional vector. Each compo-nent of the feature vector is an arbitrary function operated on ( h, z ). Particularly, in this study we define 2 kinds of fea-sures the interdependency of adjacent states. We can map this function to a kind of transition probability measure-ment. The other kind of feature function, f k ( s i ,t i ,q 1 ...d # measures the dependency of the state and its observa-tion. We can consider it as a kind of emission probability in the standard HMM point of view. Such feature vector representation of HMM is introduced by Collins [22] and successfully applied to the POS tagging problem.

Specifically, we have designed several feature functions as follows: we define a function of  X  ( s i  X  1 ,t i  X  1 ,s i to measure the language model probabilities of two consec-utive states. Where P LM ( s i | s i  X  1 )isthebigramprobability calculated by using Microsoft Web N-gram Service [1]. The computation of P LM ( s i | s i  X  1 )maydependonthestatetypes, such as in a merging state.

We have also defined a set of functions in the form of f ( s i ,t i ,q [1: n ] ), which are dependent on the query words and state type, measuring the emission probability of a state. For example, we define f as a function measuring the emission probability given the state type is in-word transformation and q i is out of dic-tionary. e.g.  X  X overment X   X   X  X overnment X . P err ( s i ,q is the emission probability computed by an error model which measures the probability of mis-typing  X  X overnment X  to  X  X overment X . (see Section 5.2). f to capture the emission probability if the state is of split-ting type and q i is in dictionary. e.g.  X  X omepage X   X   X  X ome page X . f to get the emission probability if a valid word is trans-formed to another valid word.

Note that in Equation (3), (4), and (5), we use the same error model P err ( s i ,q i )(seeSection5.2fordetail)tomodel the emission probabilities from merging, splitting errors etc . in the same way as in-word tra nsformation errors. However we assign di ff erent weights to the transformation probabil-ities resulted from di ff erent error types via discriminative training on a set of labeled query-correction pairs.
Overall, we have designed a set of feature functions that are all relied on local dependencies, ensuring that the top-Kstatesequencescanbecomputede ffi cientlybyDynamic Programming.

After establishing the feature vector representation, the log-probability of a state sequence and its corresponding types logP ( z, t | q [1: n ] )isproportionalto: where  X  j , X  k are the component coe ffi cients needed to be estimated. And the best state sequence can be found by:
Note that the form of Score ( z, t )issimilartotheobjec-tive function of a Conditional Random Field model [26], but with an important di ff erence that there is no normalization terms in our model. Such di ff erence also enables the e ffi -cient search of top-K state sequences (equivalent to top-K corrections) using Dynamic Programming, which will be in-troduced shortly.
Motivated by ideas introduced in [22], we propose a per-ceptron algorithm to train the gHMM model. To the best of our knowledge, this is the first attempt to use discriminative approach to train a HMM on the problem of query spelling correction. Now we describe how to estimate the parameters  X  , X  k from a set of &lt; query, spelling correction &gt; pairs. The estimation procedure follows the perceptron learning frame-work. Take the  X  j for example. We first set all the  X  j at random. For each query q ,wesearchforthemostlikelystate sequence with types z i [1: n ter settings. Such search process is described in Algorithm 2bysetting K =1. Afterthat,ifthebestdecodedsequence is not correct, we update  X  j by simple addition: we promote the amount of  X  j by adding up  X  j values computed between the query and labeled correction y # ,anddemotetheamount of  X  j by the sum of all  X  j values computed between the query and the top-ranked predictions. We repeat this pro-cess for several iterations un til converge. Finally in step 11 and 12, we average all  X  o,i j in each iteration to get the final estimate of  X  j ,where  X  o,i j is the stored value for the param-eter  X  j after i  X  X  training example is processed in iteration o .Similarprocedurescanapplyto  X  k .Thedetailedsteps are listed in Algorithm 1 .Notethatinstep7and8the feature functions  X  j ( q i ,y # i ,t # i )and f k ( q i ,y unknown types t # i that are inferred by computing the best word-level alignment between q i and y # i .

Algorithm 1 :DiscriminativeTrainingofgHMM input :Asetof &lt; query, spelling correction &gt; pairs output :Optimalestimateof  X   X  j ,  X   X  k ,where
Init Set  X   X  j ,  X   X  k to random numbers; for o  X  1 to O do /* Average the final parameters by: */  X   X   X  k = return parameters  X   X  j ,  X   X  k ;
This discriminative training algorithm will converge after several iterations. Here we state the following theorem on its convergence: Theorem 1 :Foranytrainingexample( q i ,y # i )whichis separable with margin  X  ,thenforAlgorithm1: where R is a constant satisfying  X  i,  X  z  X  { G ( q i )  X  { y # i }} : ||  X  ( q i ,y # i ,t where G ( q i )isasetofpredictionsgeneratedbyAlgorithm 2, and the  X  functions can be calculated from Eq. (6) by ignoring  X  and  X  .Theproofof Theorem 1 is not shown due to the space limitation.
Once the optimal parameters are obtained by the discrim-inative training procedure introduced above, the final top-K corrections can be directly computed, avoiding the need for a separate stage of candidate re-ranking. Because the feature functions are only relied on local dependencies, it enables the e ffi cient search of top-K corrections via Dynamic Pro-gramming. This procedure involves three major steps: (1) candidate states generation; (2) score function evaluation; (3) filtering.

At the first step, for each word in query q ,wegeneratea set of state candidates with types. The phrase representa-tions in such states are in Lexicon L and within editing dis-tance  X  from the query word. Then a set of state sequences are created by combining these states. In addition, for each state sequence we have created, we also create another state sequence by adding a NULL state at the end, facilitating a (potential) following merging state. It is important to note that if the  X  is too small, it will compromise the final results due to the premature pruning of state sequences. In this work  X  =3ischoseninordertointroduceadequatepossible state sequences.

At the score function evaluation step, we update the scores for each state sequence according to Eq. (6). The eval-uation is di ff erent for sequence with di ff erent ending state types. Firstly, for a sequence ending with a NULL state, we don X  X  evaluate the scoring function. Instead, we only need to keep track of the state representation of its previ-ous state. Secondly, for a sequence ending with a merging state, it merges the previous one or more consecutive NULL states. And the scoring function takes into account the in-formation stored in the previous NULL states. For instance, to  X  1 ( s i  X  1 ,t i  X  1 = NULL,s i ,t i = merging ), we have i.e. skipping the NULL state and pass the previous state representation to the merging state. In this way, we can evaluate the scoring function in multiple consecutive NULL states followed by a merging state, which enables the cor-rection by merging multiple query words. Thirdly, for a sequence ending with a splitting state, the score is accumu-lated by all bigrams within the splitting state. For example, where s i = w 1 w 2 ...w k .Ontheotherhand,theevaluationof f ( s i ,t i ,q [1: n ] )iseasierbecauseitisnotrelatedtoprevious states. The error model from the state representation to the query word is used to calculate these functions.

At the final step, we filter most of the state sequences and only keep top-K best state sequences in each position corre-sponding to each query word. In sum, we have proposed and implemented an algorithm via Dynamic Programming (see Algorithm 2) for e ffi ciently computing top-K state sequences (corrections). If there are n words in a query, and the maxi-mum number of candidate states for each query word is M , the computational complexity for finding top-K corrections is O ( n  X  K  X  M 2 ).
Besides the gHMM model and its discriminative training, our spelling correction algorithm also relies on other impor-tant components, such as a larg etrustedlexicon,theerror model, and the language model. In this section we will de-scribe these components.

Algorithm 2 :DecodingTop-KCorrections input :Aquery q [1: n ] ,parameters &amp;  X  , &amp;  X  output :top K state sequences with highest likelihood
Init Z [0] = {} for i  X  1 to n do sort Z [ n ]by score truncate Z [ n ]tosize K return Z [ n ]; As mentioned in Section 3, how to define a proper lexicon L is important to a successful speller. We find that with acleanvocabulary,itwillsignificantlyimprovetheperfor-mance of spelling correction. However, to obtain such a clean vocabulary is usually di ffi cult in practice. To do this, we make use of the Wikipedia data. Particularly, we select the top 2 million words from Wikipedia by their word fre-quencies, and automatically curate the obtained words by removing those frequent but illegitimate words from the vo-cabulary. This curate process involves checking if the word appears in the title of a Wikipedia article, comparing the bigram probability of other words etc. Finally we obtained 1.2 million highly reliable words in the vocabulary. Please note that all words in this vocabulary are unigrams; num-bers and punctuations are not included. And no stemming and other forms of modification are conducted.
Error Model. The feature functions f k () depend on an er-ror model, which measures the probability that one word is misspelled into another. Previous studies have shown that aweightededitingdistancemodeltrainedwithasu ffi cient large set of correction pairs co uld achieve a comparable per-formance with a sophisticated n-gram model [6]. Meanwhile, ahigherordermodelhasgreatertendencytooverfitifthe training data is not large enough. Given these considera-tions, we adopt the Weighted Edit Distance (WED) to esti-mate the error model. More specifically, we first compute the best character-level alignment of two words, and the WED between these two words is the summation of the WED of all aligned character pairs. We model the character-level WED as the character transformation probability. In addition, null character is included in the vocabulary to accomodate the insertion and deletion operations. In order to compute such a probability, a large set of query-correction pairs is ob-tained by leveraging the spelling services from Google and Bing; and then this probability is estimated as the expected number of transformation from one character to another in these aligned pairs. The training queries are from the MSN search query log released by the Microsoft Live Labs in 2006 (6.5 million queries). They are submitted to the spelling ser-vices, and the corrections are recorded once consensus is reached.
Another important factor in selecting and ranking the cor-rection candidates is the prior probability of a correction phrase. It represents our prior belief about how likely a query will be chosen by the user without seeing any input from the user. In this work we make use of the Web n-gram service provided by Microsoft [1]. Web n-gram model in-tends to model the n-gram probability of English phrases with the parameters estimated from the entire Web data. It also di ff erentiates the sources of the data to build di ff er-ent language models from the title, anchor text and body of Web pages, as well as the queries from query log. In our study, we find the title model is the most e ff ective for query spelling correction. We hypothesize that this may be because the training data for query model is much noisier. Particularly, misspelled queries may be included in the train-ing data, which makes it less e ff ective for the task of spelling correction. Despite trained with the Web data, Web n-gram model may also su ff er from data sparseness in higher order models. To avoid this issue, we make use of the bigram model in building our spelling system.
In order to test the e ff ectiveness and e ffi ciency of our pro-posed gHMM model, in this section we conduct extensive experiments on two web query spelling datasets. We first introduce the datasets, and describe the evaluation metrics we use for evaluation. Then we compare our model with other baselines in terms of accuracy and runtime.
The experiments are conducted on two query spelling cor-rection datasets. One is the TREC dataset based on the publicly available TREC queries (2008 Million Query Track). This dataset contains 5892 queries and the corresponding corrections annotated by the MSR Speller Challenge 1 orga-nizers. There could be more than one plausible corrections for a query. In this dataset only 5.3% of queries are judged as misspelled.

We have also annotated another dataset that contains 4926 MSN queries, where for each query there is at most one correction. Three experts are involved in the annotation process. For each query, we consult the speller from two ma-jor search engines (i.e. Google and Bing). If they agree on the returned results (including the case if the query is just unchanged), we take it as the corrected form of the input query. If the results are not the same from the two, as least one human expert will manually annotate the most likely http://web-ngram.research.microsoft.com/spellerchallenge/ corrected form of the query. Finally, about 13% of queries are judged as misspelled in this dataset, which is close to the error rate of real web queries. This dataset is publicly available to all researchers.

We divide the TREC and MSN datasets into training and test sets evenly. Our gHMM model as well as the baselines are trained on the training sets and finally evaluated on the TREC test set containing 2947 queries and MSN test set containing 2421 queries.
We evaluate our system based on the evaluation metrics proposed in Microsoft Speller Challenge [1], including ex-pected precision, expected recall and expected F1 measure. As used in previous discussions, q is a user query and Y ( q )=( y 1 ,y 2 ,,y k )isthesetofsystemoutputwithposte-rior probabilities P ( y i | q ). Let S ( q )denotethesetofplausi-ble spelling variations annotated by the human experts for q .ExpectedPrecisioniscomputedas: where I p ( y, q )=1if y  X  S ( q ), and 0 otherwise. And ex-pected recall is defined as: where I r ( Y ( q ) ,a )=1if a  X  Y ( q )for a  X  S ( q ), and 0 otherwise.
 Expected F1 measure can be computed as:
We first investigate the overall e ff ectiveness of the gHMM model. For suitable query spelling correction baselines, espe-cially approaches that can handle all types of query spelling errors, we first considered u sing the CRF model proposed in [24]. This method aims at a broad range of query refine-ments and hence might be also applicable to query correc-tion. However, we decided not to compare this model for the following reasons. Firstly, we communicated with the authors of [24] and knew that the program is un-reusable. Secondly, as mentioned in Section 1 this work su ff ers from several drawbacks for query spelling correction: (1) it is un-able to correct queries with mixed types of errors, such as substitution and splitting errors in one query, because the model treats query correction and splitting/merging as dif-ferent tasks; (2) this model only allows 1 character error for substitution/insertion/deletion. And the error model is trained on the &lt; query, correction &gt; examples that only con-tain 1 character error. Such design is over simplified for real-world queries, in which more than 1 character errors are quite common. In fact, within the queries that contain spelling errors in the MSN dataset, there are about 40.6% of them contain more than 1 character errors. Therefore it is expected model in [24] will have in inferior performance
Because of the reasons stated above, the best baseline method that we can possibly compare with is the system that achieved the best performance in Microsoft Speller Chal-lenge [25] (we call it Lueck-2011). This system relies on can-didate corrections from third-party toolkits such as hunspell and Microsoft Wrod Breaker Service [11] , and it re-ranks the candidates by a simple noisy channel model. We com-municated with the author and obtained the corrections by running the Web API of this baseline approach. We also include a simple baseline called Echo ,whichisjustechoing the original query as the corre ction response with posterior probability 1. It reflects the basic performance for a naive method. Experiments are conducted on TREC and MSN datasets.

We report the results of all methods in Table 3. In this experiment up to top 10 corrections are used in all ap-proaches. The results in Table 3 indicate that gHMM out-performs Lueck-2011 significantly on recall and F1 on the TREC dataset. Lueck-2011 has a small advantage on pre-cision, possibly due to the better handling the unchanged queries. On the MSN dataset which is considered harder since it has more misspelled queries, gHMM also achieves high precision of 0.910 and recall of 0.966, which are both significantly better than that of the Lueck-2011 (0.896 and 0.921). On another important performance metric, which measures the F1 on misspelled queries (F1 Mis), gHMM out-performs Lueck-2011 by a large margin (0.550 vs. 0.391 on TREC and 0.566 vs. 0.363 on MSN). These results demon-strate that gHMM is very e ff ective for handling all types of spelling errors in search queries overall.
 Dataset Method Precision Recall F1 F1
TREC Lueck-2011 0.963 0.932 0.947 0.391
MSN Lueck-2011 0.896 0.921 0.908 0.363
Further, we also break down the results by error types that are manually classified so that we can see more clearly the distribution of types of spelling errors and how well our gHMM model addressing each type of errors. We present the results of this analysis in Table 4, only with our model on both datasets. Top 40 corrections are used since it achieves the best results. The breakdown results show that most queries are in the group of  X  X o error X , which are easier to handle than the other three types. As a result, the overall excellent performance was mostly because the system per-formed very well on the  X  X o error X  group. Indeed, the sys-tem has substantially lower precision on the queries with the other three types of errors. T he concatenation errors seem to be the hardest to correct, followed by the splitting errors, and the in-word transformatio nerrors(insertion,deletion and substitution, word mis-use) seem to be relatively easier. Since the gHMM can e ffi ciently search in the complete
Dataset Error Type % Queries Precision Recall F1 candidate space and compute the top-K spelling corrections in a one-stage manner, it is very interesting to test its e ff ec-tiveness for constructing a working set of candidate correc-tions to enable more complex scoring functions to be used for spelling correction. For this purpose, we compare gHMM with the common used noisy channel model, whose parame-ters, namely error model probabilities and bigram language probabilities are estimated by the procedure mentioned in previous sections. We use recall to measure the complete-ness of the constructed working set, because it represents the percentage of true corrections given the number of predicted corrections. Table 5 shows the recall according to di ff erent number of outputs. It indicates that the recall of gHMM is steadily increasing by a larger number of outputs. By only outputting top-5 corrections, gHMM reaches recall of 0.969 in TREC and 0.964 in MSN. In contrast, the noisy channel model has a substantial gap in term of recall compared to gHMM. This result strongly demonstrates the superior e ff ec-tiveness of gHMM in constructing a more complete working set of candidate corrections, which can be utilized by other re-ranking approaches which could further improve the cor-rection accuracy.
 Table 5: gHMM vs. Noisy Channel Model on Recall
TRECN-C 0.869 0.896 0.899 0.901 0.902
MSNN-C 0.866 0.870 0.873 0.876 0.886
The runtime requirement of query correction is very strin-gent. Theoretically, the gHMM with local feature functions can search top-K corrections e ffi ciently by our proposed tok-KViterbialgorithm. Herewemakeadirectlycomparison between the runtime of gHMM and a basic noisy channel that only needs to compute the error model probabilities and bigram language probabilities. Such a basic model is also implemented with Viterbi algorithm. It is run on a Windows server equipped with 2 Quad-core 64 bit 2.4 GHz CPUs and 8 GB RAM. All necessary bigram language prob-abilities are crawled from Microsoft Web N-gram Service and cached in local memory. We plot the runtime per query (in milliseconds) according to the number of predicted correc-tions in Figure 2. According to Figure 2, the computation of top-1 correction by gHMM is fast (34 ms) if the number of output is set to 1. It increases as the number of output in-creases because the search space is increased. Interestingly, the runtime of gHMM and the noisy channel model is of the same order of magnitude. This empirical evidence con-firms the theoretical result that top-K spelling corrections can be computed e ffi ciently via our proposed top-K Viterbi algorithm.

Finally we discuss how the proposed gHMM model be-haves according to the variation of important factors. Such as the number of spelling corrections in the output and the size of lexicon L etc . Our datasets include all plausible corrections for a query. However it X  X  unknown that how many corrections an algo-rithm should output to achieve a perfect recall. In this sec-tion we investigate how the number of predicted spelling cor-rections a ff ects the precision and recall. We have carried out experiments on five correction sizes (1,5,10,20,40) on both datasets. Figure 3 summarizes the results. As expected, a bigger number of corrections leads to higher recall, and the most drastical increase of rec all lies from 1 correction to 5.
The size of the trusted lexicon is an important factor influ-encing the speller correction result. In order to investigate the e ff ect of lexicon size, we conducted a set of experiments on both datasets using di ff erent lexicon sizes (ranging from 100,000 to 900,000). Results in Figure 4 show that the ef-fect of lexicon size is significant on precision: the precision increases as the lexicon size increases. However the recall is not sensitive to the lexicon size.

In Table 6, we show the e ff ects of using a clean lexicon for improving the precision and recall of the spelling sys-tem. We can see that for both test sets, there is noticeable improvement in precision. By removing the noise in the au-tomatically constructed lexicon, our system is able to find matches for candidate queries more precisely.
 In this paper, we presented a novel generalized hidden Markov model (gHMM) for query spelling correction that can address two major deficiencies of previous approaches to query spelling correction, i.e., inability of handling all the major types of spelling errors, and inability of search-ing e ffi ciently in the complete candidate space. We have also proposed a novel discriminative training method for the gHMM model which enables us to go beyond regular HMM to incorporate useful local features for more e ff ective query spelling correction. Experiment results on two query cor-rection datasets show that gHMM can e ff ectively handle all the major types of spelling errors and outperforms a state-of-the-art baseline by a large margin.

Moreover, our generalized HMM, equipped with the dis-criminative training, scores the query corrections directly and output a final ranked list of spelling corrections, without needing a filtering stage to prune the candidate space as typi-cally required by an existing method. We have demonstrated that as an e ffi cient one-stage approach, the proposed gHMM can also be used as a filter to construct a more complete working set than the existing noisy channel filter, making it possible to combine it with any complicated spelling correc-tion methods to further improve accuracy. In other words, the proposed gHMM model can serve as a better candidate generation method in a two-stage framework where any so-phisticated and potentially more e ff ective spelling correction method can be applied to re-rank the generated candidates for more accurate corrections. In addition, we have also curated a large spelling correction dataset from real-world queries and made it available to the research community.
In this work, we only focused on local feature functions in order to ensure e ffi cient evaluation of all the candidates in the search space. However, some global features, such as the overall editing distance, frequency of the query in aquerylogcanbepotentiallyutilizedtofurtherimprove the correction accuracy. How to add the global features to the gHMM model, while still ensuring e ffi cient search and evaluation of all the candidates in the search space, is an interesting direction for future work.
This paper is based upon work supported in part by a Mi-crosoft grant, the National Science Foundation under grant CNS-1027965, and MIAS -the Multimodal Information Ac-cess and Synthesis center at UIUC, part of CCICADA, and aDHSCenterofExcellence. [1] http://research.microsoft.com/en-[2] F. Ahmad and G. Kondrak. Learning a spelling error [3] E. Brill and R. Moore. An improved error model for [4] Q. Chen, M. Li, and M. Zhou. Improving query [5] S. Cucerzan and E. Brill. Spelling correction as an [6] H. Duan and B.-J. P. Hsu. Online spelling correction [7] J. Gao, X. Li, D. Micol, C. Quirk, and X. Sun. A large [8] K. Kukich. Techniques for automatically correcting [9] M. J. D. Powell. An e ffi cient method for finding the [10] X. Sun, J. Gao, D. Micol, and C. Quirk. Learning [11] K. Wang, C. Thrasher, and B.-J. P. Hsu. Web scale [12] C. Whitelaw, B. Hutchinson, G. Chung, and G. Ellis. [13] Levenshtein, V I. Binary codes capable of correcting [14] Jinxi Xu and W. Bruce Croft. Query expansion using [15] Yonggang Qiu and Hans-Peter Frei. Concept based [16] Mandar Mitra, Amit Singhal, and Chris Buckley. [17] B. Tan and F. Peng. Unsupervised query segmentation [18] Y. Li, B.-J. P. Hsu, C. Zhai, and K. Wang.
 [19] Xuanhui Wang, ChengXiang Zhai. Mining Term [20] Stephan Vogel, Hermann Ney, and Christoph [21] B.H. Juang. Hidden Markov models for speech [22] M. Collins. Discriminative training methods for [23] L. R. Rabiner. A tutorial on hidden markov models [24] J. Guo, G. Xu, H. Li, and X. Cheng. A unified and [25] G. Luec. A data-driven approach for correcting search [26] J. La ff erty, A. McCallum, and F. Pereira. Conditional
