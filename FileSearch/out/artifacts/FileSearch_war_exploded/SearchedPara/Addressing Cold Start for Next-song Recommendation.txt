 The cold start problem arises in various recommendation applications. In this paper, we propose a tensor factorization-based algorithm that exploits content features extracted from music audio to deal with the cold start problem for the emerg-ing application next-song recommendation. Specifically, the new algorithm learns sequential behavior to predict the next song that a user would be interested in based on the last song the user just listened to. A unique characteristic of the algorithm is that it learns and updates the mapping between the audio feature space and the item latent space each time during the iterations of the factorization process. This way, the content features can be better exploited in forming the latent features for both users and items, leading to more effec-tive solutions for cold-start recommendation. Evaluation on a large-scale music recommendation dataset shows that the recommendation result of the proposed algorithm exhibits not only higher accuracy but also better novelty and diver-sity, suggesting its applicability in helping a user explore new items in next-item recommendation. Our implementation is available at https://github.com/fearofchou/ALMM .
 Next-song recommendation, content-based recommendation, matrix factorization, real-life setting, context-aware system
Music recommendation is extensively used by online music streaming service providers, such as Spotify and Pandora. 1 The goal of a recommendation algorithm is to model the preference of users from observed user-item associations (ei-ther explicit or implicit feedback), and then use the model to predict the items a user may like but is not aware before.
The user preference also can be modeled with additional context information [ 8, 10 ] and content feature [ 2, 6, 9]. Music recommendation can be contextualized in a number of ways, http://www.spotify.com , http://www.pandora.com The approach counts the number of transitions between pairs of items for each user, and then learns latent feature representations for the users and items from the resulting { user, item, last-time item } triplets. This leads to user, item, and last-time item latent vectors , whose inner product can be used to perform next-item recommendation.

For the specific application of next-song recommendation, it is important to deal with the so-called cold-start problem [6 ] associated with newly released or less popular songs, which are commonly seen in real-world music streaming services. It is well-known that MF-based methods, or other collaborative filtering (CF)-based methods in general, cannot perform well for items with sparse association with users in the training data. Due to the cold-start problem, the recommendation result may lack diversity and novelty, which are both important for user satisfaction. While CB methods may remedy this issue by exploiting item-item association in the audio feature space, little effort has been made to develop content-based algorithms for next-item recommendation.
The specific goal of this paper is to address cold start next-song recommendation. Following Rendle et al.  X  X  approach [8 ], the new algorithm additionally learns a linear transformation matrix to learn a mapping from an audio feature space to the item latent feature space, each time as we update all the latent features in the tensor factorization process. In other words, the mapping between the content features and song latent vectors is constructed in an interactive way during , instead of after (e.g. as a prior work [6 ] did), the factorization process. This way, the coupling between content features and item latent vectors is made stronger. Moreover, the content features would affect not only the learning of the item latent and last-time item latent features, but also the user latent features. In our experiments, the proposed method leads to better accuracy as compared with two competing methods in both warm-start and cold-start settings. Moreover, its recommendation features higher novelty, diversity and lower popularity, which are desirable to user satisfaction.
The goal is to recommend songs to a specific user, given knowledge of the song the user just listened to. Let U = ( u be a set of songs. According to the listening timestamp, we have the listening sequence L u = ( L u 1 ,L u 2 , ... ,L u t ) for each user u . The listening sequences of all users is collectively sequences to a transition matrix between different songs for each user by counting the number of adjacent song pairs. To mine sequential patterns, we remove the transitions between a song and itself, and require the time interval between adjacent songs to fall within half an hour to be considered as a valid pair. The resulting tensor P  X  R | U | X | S | X | S | for the transition preference for each user is defined as: Given P , a model can be trained to learn personal transition preference and to recommend a number of songs to a user based on the very last song the user just listened to. Following Hu et al. [3], we transform the counts P u i,j into confidence Table 1: The statistics of the training, validation and two test sets in our experiments
Oord [ 6]: Unlike Forbes, here the mapping matrices  X  X and  X  Y are learned after the latent vectors have been ob-tained from tensor factorization. The objective function maps all the estimated song latent vectors from audio features, by minimizing the mean squared error. where  X  X i  X   X  X A i and  X  Y j  X   X  Y A j . For fair comparison, the two baseline models Forbes and Oord are learned with similar settings. The two baseline methods have different limitations. The Forbes method [ 2] might not obtain good latent features, as the constraints imposed by the content features might be too strong. On the other hand, the Oord method [6 ] is more flexible, but as the mapping is learned after tensor decomposition, the inner product between the user latent vectors U u and the mapped item latent vector  X  Y j might not be able to accurately predict user preference.

To deal with this issues, we propose the adaptive linear mapping model (ALMM) method, which learns the mapped latent vectors during, instead of after, iterations of the factor-ization process. Specifically, the proposed method follows the PF method and optimizes the user and item latent features using (3)  X  (5) , but at the same time updates the mapping matrices such that the inner product among U u and the mapped last-time item and item latent vector  X  X i and  X  Y j predicts user transition preference. The content feature and all the latent vectors can be therefore coupled strongly.
The above steps are summarized in Algorithm 1. The updating rules for  X  X and  X  Y can be derived with simple algebra. A new song can be recommended by mapping the computed audio features to the latent space. Other non-linear mapping function can be employed (e.g. by using deep neural nets), but we leave this as a future work.
We evaluate our method on a real-world dataset collected from a regional leading music streaming service provider (anonymized for review) from October 2012 to September 2013. The dataset includes 28k users, 124k songs and 0.1 billion listening records. Each of the listening record contains a listening timestamp, song title, artist name, album name, release date and genre labels. The dataset also allows us to access to the corresponding audio files from which various audio features can be extracted. In this work, we consider as is compared in term of warm start (WS) and cold start (CS) tures in both WS and CS. In contrast, Forbes yields the worst MAP and recall among the competing methods, which indicates this CB method can not work well for next-song recommendation. Moreover, this method requires more com-putation time than the other method. On the other hand, we can find that the Oord method has similar performance with ALMM. This is because our method is extended from Oord. However, the proposed method leads to slightly better performance measurement in both MAP and recall.

Possibly equally importantly, Figure 2 shows that the rec-ommendation result of the proposed ALMM method exhibits higher novelty, higher novelty, lower freshness and lower popularity than the result of PF. This result suggests that ALMM can better discover new songs across different levels of popularity. In contrast, although Oord has comparable accuracy with ALMM, its result exhibits higher popularity and the lowest diversity, which may be attributed to the mismatch between the user latent vectors and the mapped item latent vectors. In sum, ALMM can obtain better ac-curacy, and can provide higher diversity and novelty with lower freshness and popularity, comparing to other methods.
In this paper, we address the cold start problem for next-song recommendation. The proposed algorithm captures the content-based transition preference by mining both sequential behavior and content feature simultaneously. Experimental result shows that the proposed method outperforms other CB methods in both warm start and cold start settings. Additionally, the use of content feature leads to recommen-dations that feature greater diversity and novelty. Although
