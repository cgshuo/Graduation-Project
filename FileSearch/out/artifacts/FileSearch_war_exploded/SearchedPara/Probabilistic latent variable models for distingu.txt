 The challenge of inferring whether X causes Y ( X  X  X  Y  X ) or vice versa ( X  Y  X  X  X ) from joint observations of the pair ( X,Y ) has recently attracted increasing interest [1, 2, 3, 4, 5, 6, 7, 8]. While the traditional causal discovery methods [9, 10] based on (conditional) independences between variables require at least three observed variables, some recent approaches can deal with pairs of variables by exploiting the complexity of the (conditional) probability distributions. On P (cause) P (effect | cause) typically yields models of lower total complexity than the factorization into P (effect) P (cause | effect) . Although the notion of  X  X omplexity X  is intuitively appealing, it is not obvious how it should be precisely defined.
 If complexity is measured in terms of Kolmogorov complexity, this kind of reasoning would be be embedded into a general theory of algorithmic-information-based causal discovery [12]. The following theorem is implicitly stated in the latter reference (see remarks before (26) therein): Theorem 1 Let P ( X,Y ) be a joint distribution with finite Kolmogorov complexity such that P ( X ) and P ( Y | X ) are algorithmically independent, i.e., where + = denotes equality up to additive constants. Then: The proof is given by observing that (1) implies that the shortest description of P ( X,Y ) is given complexity of the causal model consists of both the complexity of the conditional distribution and of the marginal of the putative cause. However, since Kolmogorov complexity is uncomputable, this does not solve the causal discovery problem in practice. Therefore, other notions of complexity need to be considered.
 The work of [4] measures complexity in terms of norms in a reproducing kernel Hilbert space, but due to the high computational costs it applies only to cases where one of the variables is binary. The methods [1, 2, 3, 5, 6] define classes of conditionals C and marginal distributions M , and prefer X  X  Y whenever P ( X )  X  M and P ( Y | X )  X  C but P ( Y ) 6 X  M or P ( X | Y ) 6 X  C . This can be interpreted as a (crude) notion of model complexity: all probability distributions inside the class are simple, and those outside the class are complex. However, this a priori restriction to a particular class of models poses serious practical limitations (even when in practice some of these methods  X  X often X  the criteria by, for example, using the p -values of suitable hypothesis tests). key idea is to define appropriate priors on marginal distributions (of the cause) and on conditional distributions (of the effect given the cause) that both favor distributions of low complexity. To decide upon the most likely causal direction, we can compare the marginal likelihood (also called evidence) of the models corresponding to each of the hypotheses X  X  Y and Y  X  X . An important novel aspect of our work is that we explicitly treat the  X  X oise X  as a latent variable that summarizes the influence of all other unobserved causes of the effect. The additional key assumption here is the independence of the  X  X ausal mechanism X  (the function mapping from the cause and noise to the effect) and the distribution of the cause, an idea that was exploited in a different way recently for the deterministic (noise-free) case [13]. The three main contributions of this work are:  X  to show that causal discovery for the two-variable cause-effect problem can be done without  X  to point out the importance of accounting for the complexity of the distribution of the cause, in  X  to show that a Bayesian approach can be used for causal discovery even in the case of two The last aspect allows for a straightforward extension of the method to the multi-variable case, the details of which are beyond the scope of this article. 1 Apart from discussing the proposed method on a theoretical level, we also evaluate our approach on both simulated and real-world data and report good empirical results. We start with a theoretical treatment of how to solve the basic causal discovery task (see Figure 1a). (a) Figure 1: Observed variables are colored gray, and unobserved variables are white. (a) The basic causal discovery task: which of the two causal models gives the best explanation of the observed data D = { ( x i ,y i ) } N i =1 ? (b) More detailed version of the graphical model for  X  X causes Y  X . 2.1 Probabilistic latent variable models for causal discovery First, we give a more precise definition of the class of models that we use for representing that X causes Y ( X  X  X  Y  X ). We assume that the relationship between X and Y is not deterministic, but disturbed by unobserved noise E (effectively, the summary of all other unobserved causes of Y ). The situation is depicted in the left-hand part of Figure 1a: X and E both cause Y , but although X and Y are observed, E is not. We make the following additional assumptions: (A) There are no other causes of Y , or in other words, we assume determinism : a function f exists (B) X and E have no common causes, i.e., X and E are independent: (C) The distribution of the cause is  X  X ndependent X  from the causal mechanism. 2 (D) The noise has a standard-normal distribution: E  X  X  (0 , 1) . 3 Several recent approaches to causal discovery are based on the assumptions (A) and (B) only, but pose one of the following additional restrictions on f :  X  f is linear [2];  X  additive noise [5], where f ( X,E ) = F ( X ) + E for some function F ;  X  the post-nonlinear model [6], where f ( X,E ) = G ( F ( X ) + E ) for some functions F,G . For these special cases, it has been shown that a model of the same (restricted) form in the reverse direction Y  X  X that induces the same joint distribution on ( X,Y ) does not exist in general. This asymmetry can be used for inferring the causal direction.
 In practice, a limited model class may lead to wrong conclusions about the causal direction. For example, when assuming additive noise, it may happen that neither of the two directions provides a sufficiently good fit to the data and hence no decision can be made. Therefore, we would like to drop this kind of assumptions that limit the model class. However, assumptions (A) and (B) are not enough on their own: in general, one can always construct a random variable  X  E  X  N (0 , 1) and a function  X  f : R 2  X  R such that (for a proof of this statement, see e.g., [14, Theorem 1]).
 In combination with the other two assumptions (C) and (D), however, one does obtain an asymmetry that can be used to infer the causal direction. Note that assumption (C) still requires a suitable math-ematical interpretation. One possibility would be to interpret this independence as an algorithmic independence similar to Theorem 1, but then we could not use it in practice. Another interpretation has been used in [13] for the noise-free case (i.e., the deterministic model Y = f ( X ) ). Here, our aim is to deal with the noisy case. For this setting we propose a Bayesian approach, which will be explained in the next subsection. 2.2 The Bayesian generative model for X  X  Y The basic idea is to define non-parametric priors on the causal mechanisms and input distributions that favor functions and distributions of low complexity. Inferring the causal direction then boils down to standard Bayesian model selection, where preference is given to the model with the largest marginal likelihood.
 We introduce random variables x i (the cause), y i (the effect) and e i (the noise), for i = 1 ,...,N where N is the number of data points. We use vector notation x = ( x i ) N i =1 to denote the whole N -tuple of X -values x i , and similarly for y and e . To make a Bayesian model comparison between the two models X  X  Y and Y  X  X , we need to calculate the marginal likelihoods p ( x , y | X  X  Y ) and p ( x , y | Y  X  X ) . Below, we will only consider the model X  X  Y and omit this from the notation for brevity. The other model Y  X  X is completely analogous, and can be obtained by simply interchanging the roles of X and Y .
 The marginal likelihood for the observed data x , y under the model X  X  Y is given by (see also Figure 1b): p ( x , y ) = p ( x ) p ( y | x ) = " Here,  X  X and  X  f parameterize prior distributions of the cause X and the causal mechanism f , respectively. Note how the four assumptions discussed in the previous subsection are incorporated into the model: assumption (A) results in Dirac delta distributions  X  y i  X  f ( x i ,e i ) for each i = is obvious by taking p E ( e ) := N ( e | 0 , 1) . 2.3 Choosing the priors In order to completely specify the model X  X  Y , we need to choose particular priors. In this work, we assume that all variables are real numbers (i.e., x , y and e are random variables taking values in R
N ), and use the following choices (although other choices are also possible):  X  For the prior distribution of the cause X , we use a Gaussian mixture model  X  For the prior distribution p ( f |  X  f ) of the causal mechanism f , we take a Gaussian process with 2.4 Approximating the evidence Now that we have fully specified the model X  X  Y , the remaining task is to calculate the integral (4) for given observations x , y . As the exact calculation seems intractable, we here use a particular approximation of this integral.
 The marginal distribution For the model of the distribution of the cause p ( x ) , we use an asymptotic expansion based on the Minimum Message Length principle that yields the following approximation (for details, see [15]): The conditional distribution For the conditional distribution p ( y | x ) according to the model X  X  Y , we start by replacing the integral over the length-scales  X  f by a MAP estimate: Integrating over the latent variables e and using the Dirac delta function calculus (where we assume invertability of the functions f x : e 7 X  f ( e,x ) for all x ), we obtain: 4 where ( f ) is the (unique) vector satisfying y = f ( x , ) , and is the absolute value of the determinant of the Jacobian which results when integrating over the Dirac delta function. The next step would be to integrate over all possible causal mechanisms f (which would be an infinite-dimensional integral). However, this integral again seems intractable, and hence we revert to the following approximation. Because of space constraints, we only give a brief sketch of the procedure here.
 Let us suppress the hyperparameters  X  f for the moment to simplify notation. The idea is to ap-proximate the infinite-dimensional GP function f by a linear combination over basis functions  X  j parameterized by a weight vector  X   X  R N with a Gaussian prior distribution: spondence between and  X  (for fixed x and y ), which we assume to be one-to-one. In particular,  X  =  X ( x , )  X  1 y . We can then approximate equation (7) by replacing the integral by a maximum:
Z where in the last step we used the one-to-one correspondence between and  X  . becomes:  X  log p ( y | x )  X  min Here, the kernel (Gram) matrix K is defined by K ij := k ( x i , i ) , ( x j , j ) , where k : R 4  X  R is the covariance function (5). It corresponds to  X  X  T in our approximation. The matrix M contains the expected mean derivatives of the GP with respect to e and is defined by M ij :=  X  X  ( x i , i ) , ( x j , j ) . Note that the matrices K and M both depend upon .
 The Information term in the objective function (involving the partial derivatives  X  X   X  X  ) may be sur-prising at first sight. It is necessary, however, to penalize dependences between x and : ignoring it would yield an optimal that is heavily dependent on x , violating assumption (B). Interestingly, this term is not present in the additive noise case that is usually considered, as the derivative of the causal mechanism with respect to the noise equals one, and its logarithm therefore vanishes. In the next subsection, we discuss some implementation issues that arise when one attempts to solve (6) and (9) in practice.
 Implementation issues First of all, we preprocess the observed data x and y by standardizing them to zero mean and unit variance for numerical reasons: if the length scales become too large, the kernel matrix K becomes difficult to handle numerically.
 We solve the optimization problem (6) concerning the marginal distribution numerically by means of the algorithm written by Figueiredo and Jain [15]. We use a small but nonzero value ( 10  X  4 ) of the regularization parameter.
 The optimization problem (9) concerning the conditional distribution poses more serious practical problems. Basically, since we approximate a Bayesian integral by an optimization problem, the the objective function diverges. In addition, the kernel matrix corresponding to (5) is extremely ill-posed. To deal with these matters, we propose the following ad-hoc solutions:  X  We regularize the numerically ill-behaving logarithm in the last term in (9) by approximating  X  We add a small amount of N (0 , X  2 ) -uncertainty to each observed y i -value, with  X  1 . This Further, note that in the final optimization problem (9), the unobserved noise values can in fact also be regarded as additional hyperparameters, similar to the GPLVM model [16]. In our setting, this optimization is particularly challenging, as the number of parameters exceeds the number of observations. In particular, for small length scales  X  X and  X  E the objective function may exhibit a large number of local minima. In our implementation we applied the following measures to deal with this issue:  X  We initialize with an additive noise model, by taking the residuals from a standard GP re- X  We implemented a log barrier that heavily penalized negative values of  X  X  The resulting optimization problem can be solved using standard numerical optimization methods (we used LBFGS). The source code of our implementation is available as supplementary material and can also be downloaded from http://webdav.tuebingen.mpg.de/causality/ . To evaluate the ability of our method to identify causal directions, we have tested our approach on simulated and real-world data. To identify the most probable causal direction, we evaluate the marginal likelihoods corresponding to both possible causal directions (which are given by combin-ing the results of equations (6) and (9)), choosing the model that assigns higher probability to the observed data. We henceforth refer to this approach as GPI-MML . For comparison, we also con-sidered the marginal likelihood using a GP covariance function that is constant with respect to e , i.e., assuming additive noise. For this special case, the noise values e can be integrated out ana-lytically, resulting in standard GP regression. We call this approach AN-MML . We also compare with the method proposed in [1], which also uses an additive noise GP regression for the conditional model, but uses a simple Gaussian model for the input distribution p ( x ) . We refer to this approach as AN-GAUSS .
 We complemented the marginal likelihood as selection criterion with another possible criterion for causal model selection: the independence of the cause and the estimated noise [5]. Using HSIC [17] as test criterion for independence, this approach can be applied to both the additive noise GP and the more general latent variable approach. As the marginal likelihood does not provide a signif-icance level for the inferred causal direction, we used the ratio of the p -values of HSIC for both causal directions as prediction criterion, preferring the direction with a higher p -value (i.e., with less dependence between the estimated noise and the cause). HSIC as selection criterion applied to the additive or general Gaussian process model will be referred to as AN-HSIC and GPI-HSIC respectively.
 We compared these methods with other related methods: IGCI [13], a method that is also based on assumption (C), although designed for the noise-free case; LINGAM [2], which assumes a linear causal mechanism; and PNL , the Post-NonLinear model [6]. We evaluated all methods in the  X  X orced decision X  scenario, i.e., the only two possible decisions that a method could take were X  X  Y and Y  X  X (so decisions like  X  X oth models fit the data X  or  X  X either model fits the data X  were not possible).
 Simulated data Inspired by the experimental setup in [5], we generated simulated datasets from the model Y = ( X + bX 3 ) e  X E +(1  X   X  ) E . Here, the random variables X and E where sampled from a Gaussian distribution with their absolute values raised to the power q , while keeping the original additive noise (  X  = 0 ) and purely multiplicative noise (  X  = 1 ). The coefficient b determines the non-linearity of the true causal model, with b = 0 corresponding to the linear case. Finally, the parameter q controls the non-Gaussianity of the input and noise distributions: q = 1 gives a Gaussian, while q &gt; 1 and q &lt; 1 produces super-Gaussian and sub-Gaussian distributions respectively. For alternative parameter settings  X ,b and q , we generated D = 40 independent datasets. Each dataset consisted of N = 500 samples from the corresponding generative model. Figure 2 shows the accuracy of the considered methods evaluated on these simulated datasets. Encouragingly, GPI appears to be robust with respect to the type of noise, outperforming additive noise models in the full range between additive and multiplicative noise (Figure 2a). Note that the additive noise models actually yield the wrong decision for high values of  X  , whereas the GPI methods stay well above chance level. Figure 2b shows accuracies for a linear model and a non-Gaussian noise and input distribution. Figure 2c shows accuracies for a non-linear model with Gaussian additive noise. We observe that GPI-MML performs well in each scenario. Further, we observe that AN-GAUSS, the method proposed in [1], only performs well for Gaussian input distributions and additive noise. Figure 2: Accuracy of recovering the true causal direction in simulated datasets. (a ) From additive Gaussian noise ( q = 1 ,  X  = 0 ).
 Table 1: Accuracy (in percent) of recovering the true causal direction in 68 real world datasets. Results on cause-effect pairs Next, we applied the same methods and selection criteria to real-http://webdav.tuebingen.mpg.de/cause-effect/ . We considered a total of 68 pairs in this dataset collected from a variety of domains. To reduce computation time, we subsam-pled the data, using a total of at most N = 500 samples for each cause-effect pair. Table 1 shows the prediction accuracy for the same approaches as in the simulation study, reporting averages and standard deviations estimated from 3 repetitions of the experiments with different subsamples. We proposed the first method (to the best of our knowledge) for addressing the challenging task of distinguishing between cause and effect without an a priori restriction to a certain class of mod-els. The method compares marginal likelihoods that penalize complex input distributions and causal mechanisms. Moreover, our framework generalizes a number of existing approaches that assume a limited class of possible causal mechanisms functions. A more extensive evaluation of the perfor-mance of our method has to be performed in future. Nevertheless, the encouraging results that we have obtained thus far confirm the hypothesis that asymmetries of the joint distribution of cause and effect provide useful hints on the causal direction.
 Acknowledgments We thank Stefan Harmeling and Hannes Nickisch for fruitful discussions. We also like to thank the authors of the GPML toolbox [18], which was very useful during the development of our software. OS was supported by a fellowship from the Volkswagen Foundation. References
