
Shaofeng Hu 1 ,JiangtaoRen 1 , Changshui Zhang 2 , 3 , 4 , and Chaogui Zhang 1 The common assumption that training and testing samples share the same dis-tribution is often violated in practice. When this happens, traditional learning models may not generalize well even with abundant training samples. Domain Adaptation is one of these situations where little labeled data is provided from target domain, but large amount of labeled data from source domains are avail-able. Domain adaptation methods [1,2] learn robust decision function by lever-aging labeled data both from target and source domains which usually don X  X  share the same distributions. This problem involves in many real world applica-tion such as natural language processing[3], text categorization[4], video concept detection[5], WiFi localization[ 4], remote sensor network[2], etc.

Most of domain adaptation methods can be classified into two classes accord-ing to their strategies of adapting source information: either with sources labeled data or with sources classifier. The forme r strategy selects source labeled sam-ples that match target distribution to overcome distribution discrepancy. For example, [6] predicts unlabel samples via an ensemble method in local region including labeled samples of sources. [7] iteratively draws sources labeled sam-ples that are in the same cluster with tar get labeled data in projected subspace. Alternately, the latter strategy try to get the final target classifier by weighted sum of target classifier f T trained from target domain data and multiple source classifiers { f S 1 ,f S 2 ,...,f S m } trained from source domain data. [8] seeks a con-vex combination of f T and 1 m k f S k by cross validation. [9] proposes Adaptive Support Vector Machine (ASVM) to learn f T by incorporating the weighted sum of source classifiers k  X  k f S k into the objective function of SVM, where  X  k is evaluated by a meta-learning procedure. [10] obtains the final f T by maximizing output consensus of source classifiers. [11] modifies f T and penalizes the output difference between f T and each f S k on unlabeled data.

We focus on the strategy of adapting source classifiers in this paer. Based on the related works, it can be summarized one of the simplest methods to adapt source classifiers is treati ng their weighted sum as a single classifier. However, performance of this strategy is dependent on the weights for target and sources classifiers. It would be appropriate to assign higher weights to sources that are more similar with target domain. To our best of knowledge, although a few works have been addressed on domain weights assignment, little of them try to learn the appropriate weights automatically. [8] weights each source equally. [9] evaluates weights by meta-learning algorithm which is not promising since fea-tures of meta-learning are only dependent on the output of source classifiers. [11] determines domain weights by estimating the distribution similarity by MMD.
In this paper, we propose a novel way of adapting source classifiers by con-sidering multiple source classifiers as prior information. Instead of learning the combination weights of target and source classifiers explicitly, we learn the tar-get classifier directly from target domain data while keeping the target classifier approximates a convex combination of source classifiers as closely as possible, and the convex combination weights of source classifiers will be learned jointly with the learning of target classifier through optimization methods.
To illuminate the motivation of our paper, let us consider an example in Fig-ure 1. Because of the rareness of labeled data in target domain, it is hard to learn a good target classifier directly. For example, in Figure 1 (a), only one la-beled sample of each class is provided, denoted by /  X  respectively. There exists a very large classifier space in which every classifier can separate the training samples well with high uncertainty on test samples however. As depicted in Fig-ure 1(a), the horizontal hyperplane (solid line with circle) generalizes best based on the real classes distribution indicated by different colors. But we will get a bad hyperplane (dotted line with triangular) by large margin principle[12]. How-ever, by the introduction of some useful prior information contained in related source domains, we can improve the targe t classifier performance on test samples. We can restrict the target classifier approximates the convex combination of source classifiers, because we think the convex combination of the source clas-sifiers is a compact version of the source classifiers. In this way, we can exploit every source classifier with high confidence. Further, when we add the convex combination of the source classifiers as a r egularization term to object function, it will shrink the search space of target classifier greatly and provide a good way to optimize it. For example, Figure 1(b) presents two source classifiers (dotted line with diamond), and a gray region which represents the convex combination space of the two source classifiers. It is clear that if the target classifier is in or near to the convex combination space of source classifiers, the target classi-fier (dotted line with triangular in Figure 1 (b)) will have better generalization performance than the one learned by large margin principle.

Therefore, we propose a multiple sources regularization framework based on the above motivation. The framework extends general classification model with regularization by adding a special regularization term, which penalizes the tar-get classifier far from the convex combination of source classifiers. Then this framework make sure the target classifier minimizes the empirical risk in target domain and the distance from the convex combination of source classifier simul-taneously. By the way, the weights of the convex combination of source classifiers are embedded into the learning model as parameters, and will be learned through optimization algorithm automatically, which means our framework can identify similar or related domains adaptively. we propose an iterative algorithms to solve this optimization problem efficiently. To solve multiple sources domain adaptation problem, we propose a multi-ple sources regularization framework. Supposed there exist m source domain data sets, denoted by S = { S 1 ,S 2 ,...,S m } . We assume that all the samples in source data sets are labeled, etc. S k = { X s k ,y s k } and | X s k | = | y s k | for all k  X  X  1 ,...,m } . y s k is output variable, which can be either continuous or discrete. Correspondingly, target domain is unique and is divided into labeled training set and unlabel testing set, etc. T = { ( X L ,y L ) ,X U } . A multiple sources domain adaptation problem can be summarized as: (a) each source domain has a different but similar distribution with target domain, Pr S k ( X,Y ) = Pr T ( X,Y ). (b) scale of training set of target domain is much smaller than that of test set, | X the objective of multiple sources domain adaptation is to utilize source data S to improve learning perfo rmance of target domain T . We firstly discuss our regu-larization framework under general linear form. Then the framework is extended to RKHS (Reproducing Kernel Hilbert Space) with SVM hinge loss function for classification problem. Thirdly, an iterative optimization algorithm is proposed to efficiently solve multiple sources regularization SVM. 2.1 Multiple Sources Regularization Framework In this section, multiple source regularization (MSR) framework is introduced for classification. We start from the linear classification model. Linear model is more intuitive and geometrically interpretable. Denote linear predictive function f ( x )= w T x + b ,where w is feature weights and b is bias term of separating hyperplane. Learning algorithms seek to find optimum w and b that minimize structural risk, such as hinge loss. Generally, structural risk trade off between empirical risk and regularization: L (  X  ) is loss function while (  X  ) is regularization term. (  X  ) penalizes function com-plexity to avoid overfitting. When labeled data number l is large enough, Eq(1) is a tight upper bound of expected risk. However, under domain adaptation setting, training samples of T would be scarce. Therefore, st ructural risk will be too loose to be used as upper bound under supervised learning setting. As we know, loose bound created by Eq(1) will be tightened by introducing unlabeled data which is referred as semi-supervised learning. Alternately, our framework alleviates this problem by including multiple source classifiers trained from source domain la-beled data. To do this, we modify Eq(1) by adding an extra regularization term as following: where W s =[ w s 1 ,w s 2 ,...,w sm ]  X  R d  X  m . w sk is a feature weight vector learned from the k -th source domain S k . Learning model of each source domain should be consistent with that of target domain in order to maintain homogeneity of model coefficients. The last regularization term of Eq(2) penalizes w far away from the convex combination of m source classifiers.  X &gt; 0 trade off between structural risk and multiple source regularization. Moreover,  X   X   X  denotes the weight vector that determines conv ex combination of source classifiers.  X  represents the m dimensional simplex:  X  = {  X  : m k =1  X  k =1 , X  k  X  0 } .Our method of determining  X  also differs from other state-of-art multiple source domain adaptation methods: other than manual setting, meta learning or model selection, our framework embedded the auxiliary domain weights vector  X  into model Eq(2) as a parameter, then  X  can be learned by optimization method automatically. When m = 1, Eq(2) degenerate to a simple situation.  X  is fixed to be 1 which make Eq(2) much similar to Eq(1) from optimization aspect. Therefore, we only focus on the situation where m&gt; 1 in Eq(2) in our paper. 2.2 Multiple Sources Regularization SVM (MSRSVM) Loss function L in Eq(2) varies according to different models. It is easy to realize that our framework can be adapted to a wide variety of models including SVM, logistic regression, ridge regression and so on. SVM hinge loss is discussed in detail in the following. We choose SVM for discussion with the following reasons: (a) It is convenient to transform Eq(2) to its dual problem, extending linear model to kernel form.(b) SVM fits for problems with very little training samples which is consistent with the setting of domain adaptation.

Firstly, with hinge loss, Eq(2) can be reformulated as: where  X  is the slack variable. From the viewpoint of optimization, Eq(3) is a QP problem. While Eq(3) is QP, it can be solved by numeric optimization package directly.

However, we transform Eq(3) to dual form instead of optimizing the prime problem directly for two reasons: a) variable dimension of Eq(3) is d + n + m +1 while dual problem shrinks to n + m . Optimizing the dual problem reduces the problem complexity. b) the dual pro blem can generalize the linear model to nonlinear case in RHKS (Reproduced Hilbert Kernel Space). It is worth to note that we do not transform all variables to dual problem.  X  remains fixed in prime form. This is because Eq(3) can be transform to an optimization whose structure is very closed to regular SVM dual problem without  X  . Then the Lagrange function of Eq(3) can be formulated as: Setting derivative of Lagrange function with ( w,b, X  ) to zero and adding other constraints under KKT condition, we obtain the dual problem: Where  X  s  X  R m  X  m is a symmetric matrix representing correlation of feature weight among multiple source domains, analogous to covariance matrix of Gaus-sian distribution. Moreover,  X  X  is a vector related to the correlation of feature weight between target domain and source domain.  X  s and  X  can be evaluated using definition of its element in kernel space: Where  X  and Y = diag ( y ) denote dual variable and output diagonal matrix respectively. K are the kernel matrix constructed by input patterns from either source or target domains. We need to note that  X  sk is optimized SVM dual variable training only on S k .

Eq(4) appears to be more complicated than Eq(3). Actually, Eq(4) is a saddle-point minmax problem, which can be r egard as a zero sum game between two players. In section 2.3, we develop a two stage iterative optimization algorithm to solve Eq(4) in a general framework. This problem is similar to the optimization problem referred in DIFFRC[13], SimpleNPKL[14] and SimpleMKL[15]. 2.3 Iterative Optimization Algorithm for MSRSVM The special structure of Eq (4) indi cates that MSRSVM needs a customized optimization algorithm. Fortunately, many optimization algorithms have been proposed to solve similar min-max problems. The main idea of such algorithms is to separately optimize part of variables while keep others fixed. It turns out that Eq (4) can be decomposed into two subproblems.

The main steps of our optimization algorithm for MSRSVM is described as following. Denote J (  X ,  X  ) as the objective function of Eq (4) and  X   X  and  X   X  as the optimal solution of model variables. The complicated min-max problem of Eq (4) can be decomposed into two simple optimization problems: minimizing after initialization of  X  and  X  , the algorithm will loop over two steps until stop condition is met:  X  Step 1: solve subproblem min 0  X   X   X  C, X  T y =0 J (  X ,  X   X  ) under fixed  X   X  .  X  Step 2: solve subproblem max
The optimization problem in Step 1 shares similar problem structure with common SVM. They differ only on the first order term of objective functions. The first order term of common SVM X  X  ob jective function is all one vector e while Eq (4) has an extra negative term  X  X  T  X  . Fast algorithms such as SMO or SVM light could be adapted to solve this subproblem of MSRSVM without many modifications. Thus we optimize subproblem of Step 1 using a modified version of regular SVM algorithms. Without referring any specific implementation of SVM algorithm, we use SVMSolver ( K,f,y ) to define a general solver for SVM optimization where K,f,y denote kernel matrix, first order term and label vector respectively.

The subproblem of Step 2 is a classical QP problem. Since dimension of  X  is m and m is not large usually, Newton method is appropriate to optimize  X  . However, as stated in section 2.1, Eq (4) is a saddle point minmax problem. If both optimization steps are taken to local optimum point, fluctuation happens and progress towards global optimum slows down. Therefore, as an alternately strategy we update  X  by taking one gradient step at each iteration. Regular gradient update formula can not be used here because the simplex constraint exists, and gradient method is for unconstrained optimization generally. In this paper, reduced gradient method is introduced to handle this simplex constraint optimization problem [15]. This method evaluates ascent gradient firstly, then projects the gradient into simplex using the formula stated below: and  X  are vector indexes. Then we update  X  by using:  X  t +1 =  X  t +  X D .  X  denotes the step length. Boyed [16] showed that when  X  is small enough at each iteration, global convergence could be guaranteed.  X  is choosen to be O ( 1 t ). We use objective gap as convergence criterion. Objective gap represents absolute difference between the objective value after Step 1 and Step 2 within the same iteration. Algorithm 1 summarizes the whole iterative optimization algorithm. Algorithm 1. Iterative optimization algorithm for MSRSVM To demonstrate the effectiveness of our proposed framework MSRSVM, we per-form experiments on multiple transfer l earning data sets. They are real world data sets that frequently used in the context of transfer learning or multitask learning. Performance of MSRSVM are compared with some other state-of-art algorithms that can handle multiple source domains. 3.1 Data Sets and Experiment Setup Three data collections are used in our experiment study, they are Reuters-21578[17], 20-Newsgroups[18] and Letters. Among them, Reuters-21578 and 20-Newsgroups are benchmark of text categorization for transfer learning. Letters is optical recognition dataset that is preprocessed for multitask learning. Data Sets. All data sets that have been used in our experiment study are binary classification tasks. Reuters-21578 and 20-Newsgroups are both text categoriza-tion data collections with hierarchical class structure. For each dataset, we need to construct both target and source domain dataset. Target and source domain datasets are sampled from different subcategories of the same top categories. For example, for dataset  X  comp vs rec X , its so urce task dataset is sampled from subcategories  X  X omp.windows.x X  and  X  X ec.autos X , while target task dataset is sampled from subcategories  X  X omp.graphi cs X  and  X  X ec.motocycles X . Therefore, source and target domain datasets share the same feature space but different words distribution. But in our multiple source adaptation setting, we need more than one source domain datasets for one target domain prediction task. To solve this problem, all the source domain datasets are grouped and shared as source do-main datasets. For example, in 20-Newsgroups task, the source domain datasets of  X  X omp vs sci X ,  X  X ec vs talk X ,  X  X ec vs sci X ,  X  X ci vs talk X ,  X  X omp vs rec X  and  X  X omp vs talk X  constitute of the multiple source domains. While keeping the 6 source domains fixed, we can construct different multiple source adaptation problems with different target domain datasets.

For Letters dataset without hierarchical class structure, we build different learning tasks by randomly sampling from two different handwritten digit letters that are difficult to be distinguished. For example,  X  X /e X  denotes a prediction task that  X  X  X  is the positive class while  X  X  X  is the negative class. Each task is treated as target task and all the other tasks as source tasks. For example, if  X  X /e X  is target task, then task  X  X /y X ,  X  X /n X ,  X  X /g X ,  X  X /j X ,  X  X /o X ,  X  X /t X  and  X  X /n X  form the 7 source domain tasks.
 Baseline. We compare the performance of MSRSVM with other SVM based learning algorithms which can cope with multiple sources adaptation problems. They are ASVM[9], FR[19], MCCSVM[8]and regular SVM without any transfer. ASVM can be obtained online, which is based on LibSVM and programmed in C++. Others including MSRSVM are implemented in matlab basing on SMO. ASVM combines source classifiers with weights by an independent meta learning algorithm. SVM classification parameter C is fixed to 10. Other related parame-ter are set to default values. Moreover, RBF kernel k ( x, y )= e  X   X  x  X  y 2 is chosen as kernel function, where  X  is set to 0.0001 for text data and 0.01 for optical recognition. For MSRSVM, model parameter  X  is set to 1. 3.2 Performance Study We adopt classification accuracy as evaluation metric to compare MSRSVM with other four state-of-art methods. All of the accuracy results in this paper are the average results of 10 experiments. The a ccuracy comparison results are summa-rized in Table 1 and Table 2 for text and Letters dataset respectively. Training ratio are fixed to 20% for text datasets, and 30 points are randomly selected as training set for Letters dataset. Note that the best results are highlighted in bold in the Table 1 and Table 2. On Reuters-21578 dataset, MSRSVM performs better than all of the baseline algorithms on all of the 3 tasks. For example, MSRSVM get the accuracy of 60.81% on Pe vs PI dataset, while ASVM get the accuracy of 59.27%, which is the best one of baseline methods. On 20-Newsgroup dataset, MSRSVM improves the accuracies signifi cantly in most of time, comparing with the baseline methods. MSRSVM performs at least 3% better than regular SVM on 4 of 6 data sets. Meanwhile, MSRSVM outperforms other methods on all data sets except Comp Vs Talk where MCCSVM achieves highest accuracy, slightly better than MSRSVM (less than 2%). Moreover, ASVM performs surprisingly poor on some tasks of 20-Newsgroup such as Sci vs Talk and Comp vs Rec , while MSRSVM behaves stable on all of the text datasets. Similar conclusions can be reached according to Letters data set. MSRSVM achieves the highest ac-curacy on 5 of 8 datasets, and MCCSVM achieves on 3 of 8. And the performance of MSRSVM is still more stable than the others. Thus on the whole, MSRSVM significantly improves th e accuracy most of the time.
 Performance of classifier may be dependent on the number of training data. When we refer training data here, it means training data of target domain. As mention before, samples of sources domains are fixed and all labeled. Figure 2 depicts the performance of MSRSVM, regular SVM and MCCSVM, with respect to different ratio or number of training data in target domain. Training data of target domain is assumed to be sparse in domain adaptation problem. Thus the ratio of training data varies from 0.05 to 0.3 for text datasets, and number of training data for Letters datasets varies from 18 to 38(1  X  2% of the whole sample set) in the experiments. MSRSVM is compared with regular SVM and MCCSVM because they are more sensitive to the size of training data. Two important conclusions can be reached ba sed on Figure 2. Firstly, performance of the three algorithms improve with the increase of the size of training data most of time. This is because the target classifier can get more information about target domain with more and more label ed data coming from target domain. Secondly, MSRSVM outperforms regular SVM and MCCSVM steadily most of time, especially when the size of training data are small. For example, MSRSVM wins on nearly all 20-Newsgroup data sets with only 5% of training data except for Rec vs Sci . Similar phenomena happens for Letters datasets. The accuracy gap between MSRSVM and MCCSVM is maximum when the number of training data is about 18-22. The curves also demonstrate MSRSVM can utilize the information of source domains more effectively than MCCSVM. We address multiple source domain adaptation problem in this paper. There exist more than one similar or related source domains whose distributions are not identical with the target domain. To adaptively utilize the information of sources domains and improve the performance of target classifier, we propose a simple framework named Multiple Source Regularization framework. This framework regularizes target classifier and make it approximate the convex combination of sources X  classifier, while the combination weights will be learned adaptively. Our idea is that the sources information in regularization function acts as a prior to target domain. By substituting SVM X  X  loss function into MSR framework, we propose a Multiple Source Regularization SVM (MSRSVM) model, and develop an optimization algorithm to solve this model in iterative manner. Experiments on both text and optical recognition datasets verify that MSRSVM outperforms many other state-of-art domain adaptation algorithms.
 Acknowledgements. This work is supported by the Fundamental Research Funds for the Central Universities under grant 12lgpy40, Guangdong Natural Science Foundation under grant S 2012010010390 and Beiji ng Municipal Educa-tion Commission Science and Technology Development Plan key project under grant KZ201210005007.

