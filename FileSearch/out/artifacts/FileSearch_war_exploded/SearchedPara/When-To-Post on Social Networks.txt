 For many users on social networks, one of the goals when broadcasting content is to reach a large audience. The prob-ability of receiving reactions to a message differs for each user and depends on various factors, such as location, daily and weekly behavior patterns and the visibility of the mes-sage. While previous work has focused on overall network dynamics and message flow cascades, the problem of recom-mending personalized posting times has remained an under-explored topic of research.

In this study, we formulate a when-to-post problem, where the objective is to find the best times for a user to post on social networks in order to maximize the probability of audi-ence responses. To understand the complexity of the prob-lem, we examine user behavior in terms of post-to-reaction times, and compare cross-network and cross-city weekly re-action behavior for users in different cities, on both Twitter and Facebook. We perform this analysis on over a billion posted messages and observed reactions, and propose mul-tiple approaches for generating personalized posting sched-ules. We empirically assess these schedules on a sampled user set of 0 . 5 million active users and more than 25 mil-lion messages observed over a 56 day period. We show that users see a reaction gain of up to 17% on Facebook and 4% on Twitter when the recommended posting times are used.
We open the dataset used in this study, which includes timestamps for over 144 million posts and over 1 . 1 billion reactions. The personalized schedules derived here are used in a fully deployed production system to recommend posting times for millions of users every day.
 J.4 [ Computer Applications ]: Social and Behavioral Sci-ences; H.1.2 [ Information Systems ]: Models and Prin-ciples X  User/Machine Systems ; J.4 [ Computer Applica-tions ]: Information Systems Applications user modeling; personalization; behavior analysis; recom-mended systems; online social networks; posting times;
Social networks have emerged as major platforms for com-munication in recent years, with hundreds of millions of in-teractions created by users every day. Though the underly-ing mechanisms may vary, a large number of active interac-tions may be classified under (a) users posting messages, or (b) users reacting to messages. Posted messages may some-times be intended for a few friends and family members, while other times they may be geared towards larger audi-ences. The latter is especially true for users such as brands, marketers and public figures, who leverage social media as platforms for broadcasting messages.

One of the goals while broadcasting messages is to capture the attention of audience members so that they may react to the posted message. The probability that an audience member reacts to a message may depend on several factors, such as his daily and weekly behavior patterns, his location or timezone, and the volume of other messages competing for his attention. The problem of broadcasting messages at the right time in order to elicit responses from one X  X  audience is therefore a complex one with many dimensions.

A large body of research in this area has focused on the problem of influence maximization and related topics, where the goal is to target a specific subset of users in order to cre-ate information cascades in the network. However, the dy-namics of broadcasting to entire audiences, rather than pick-ing specific individuals to target, has been an under-explored topic of study. Further, since each user has a unique audi-ence, any recommendations for posting times need to be personalized to be effective, as we show in this study. We hence formulate a when-to-post problem here, where the ob-jective is to find the best times for a user to post on social networks in order to increase audience responses.
Apart from introducing the problem, our contributions in this work are three-fold. First, in order to understand the complexity of the when-to-post problem and the factors that affect it, we perform in-depth user reaction behavior analysis , which includes: 1. Post-to-reaction behavior: We analyze the delays be-2. Cross-network analysis: We examine the similarities 3. Cross-city analysis: We compare cycles of daily and
Second, we formally define the when-to-post problem in a probabilistic setting, and propose multiple approaches for recommending personalized posting schedules . Among these are the First-Degree and the Second-Degree schedules, and their corresponding weighted counterparts. We empiri-cally assess these schedules against two global baselines, on a real-world set of 0 . 5 million active users observed over a 56 day period. We define a metric called Reaction Gain that helps us evaluate the effectiveness of the two approaches, and show that users see an average reaction gain of up to 17% for Facebook and upto 4% for Twitter.

Third, we open a public dataset consisting of anonymized user ids and timestamp data that could help future research in this area. This dataset contains timestamps for 144 mil-lion posts and 1.1 billion reactions from a 120 -day period.
We performed our study and analysis on a full produc-tion system deployed on klout.com . Klout 1 is a social media platform that aggregates and analyzes data from social net-works [14] such as Twitter, Facebook, Google+ and others. Our system recommends personalized posting schedules for millions of users to share content on Twitter and Facebook.
The subject of user behavior dynamics on social networks has attracted significant research attention [10, 6, 2]. Wu et al. [16] categorized Twitter users into elite and casual users and analyzed the differences in how they generate and consume information. In their study, they showed that re-gardless of the type of content, all content had very short life spans that usually dropped exponentially after a day. An-other study in [1] also showed that only a few topics lasted for a long time on social media platforms, while most topics faded away quickly in the order of 20-40 minutes.
Besides the life span of messages, researchers have also an-alyzed the effects of timezone and location on user activity patterns. Kwak et al. [9] analyzed the timezone character-istics of user audiences on Twitter and reported that the average timezone difference between a user and her friends varied with the number of friends. In our study, we further analyze the impact of audience location on the volume of responses towards a message.

There have been several studies on modeling the dynamics of social network events [12, 15]. For example, the work in [15] used different convolution functions to analyze the flow of news events and sentiments through Twitter. While the approach of these studies has been to analyze the overall temporal characteristics on social media, here we take the further step of analyzing reaction behavior from the point of view of each individual user, thereby enabling personalized recommendations for posting messages.

Another line of related research is in the area of infor-mation flow and diffusion. Studies such as [11, 13, 5] have analyzed how factors such as the topological structure of so-cial networks play a role in information cascades. Yang et
Klout platform is a part of Lithium Technologies, Inc. al. [17] presented results on analyzing message flow based on Twitter mentions, and found that long-term historical user properties such as the rate of previous mentions were as important as the tweet content. The authors in [18] stud-ied the importance of hashtag adoption in determining the popularity and spread of tweets. The study in [7] proposed a predictive approach to model dynamics of diffusion in so-cial networks based on social, semantic and temporal di-mensions. However, the problem of examining the flow of messages in the entire network differs significantly from the one in our study. Here we are instead concerned with the reactions received by a single user in a short time window.
A large body of research has also focused on influence maximization [8, 4, 3], which also differs from the when-to-post problem. Influence maximization aims to find a subset of users in a social network, such that targeting them with a message maximizes the propagation or adoption of the message throughout the network. However, the effects of broadcasting messages to entire audiences, rather than tar-geting specific individuals, has not been as well studied. It is this problem that we propose and analyze here, by examin-ing the temporal aspects of broadcasting to one X  X  audience, in order to get a large volume of responses.
In this section, we formulate the when-to-post problem and provide details about the system and dataset used.
The actions taken on any social networking site may be categorized as passive or active in nature. The passive cat-egory may include actions such as views , while the active category may broadly be classified into two groups  X  post and reaction . Typical post behavior may include creating and sending messages, sharing photos, or posting news arti-cles on a social network. Typical reaction behavior includes resharing, liking, commenting, endorsing or replying to posts created by other users. We restrict the scope of this study to the post and reaction behavior of users.

Sometimes the post behavior is used in the context of one-on-one or personal communication, while other times it may be geared towards a larger audience. Here we focus on the latter case, where one of the motivations behind posting is to reach a large audience and to capture their attention. In particular, we examine the time-related aspects of this behavior and frame a when-to-post problem as follows:
Problem Statement : For a user on a social network, find the best time to post a message within a specified time period in order to maximize the probability of receiving audience reactions.

Note that we only consider first-degree reactions such as replies and retweets on Twitter and comments on Facebook, and not those caused by an audience member resharing the original post. In other words, we focus mainly on the reac-tions a post receives by the user X  X  immediate audience, and not on how the post propagates through the network.
We collect user posts from Facebook through the oauth-token provided by registered users on Klout. We also use the oauth-token-based approach to collect the friend graph of users on Facebook and the follower graph for users on Twitter. Klout partners with GNIP to collect public data generated in the Twitter Mention Stream 2 . For location analysis, we use the city, state and country information pro-vided by registered users on the Klout application.
The collected data is written out to a Hadoop cluster 3 that uses HDFS as the file system, HBase as the serving data-store, and Hive 4 to process, query and manage the large datasets. We implement independent Java utilities with Hive UDF (User Defined Function) wrappers, with func-tions to process user locations and timezones, and operators such as discrete convolution to process time-series vectors. The combination of Hive Query Language and UDFs allows us to build map-reduce jobs that can scale up to analyze billions of messages posted to social platforms every day. A pipeline run on a 150-node cluster has a cumulative I/O footprint of 224GB of reads, 78GB of writes, and 9.62 days of CPU usage. Fig. 1 shows an overview of the system.
The dataset used to run experiments and build models has been opened at https://github.com/klout/opendata . The corpus has event timestamps for posts that were created be-tween October 15, 2014 and February 11, 2015 and received at least one reaction. The dataset was generated from more than 1 million users apiece from Facebook and Twitter, with accounts registered on Klout.com. For Facebook the dataset includes more than 25 million post timestamps and 104 million reaction timestamps, while for Twitter these numbers are 119 million and 1 billion respectively. In or-der to preserve privacy, timestamps were slightly perturbed and user and post ids were anonymized using custom fin-gerprint functions.
In this section we perform in-depth user behavior anal-ysis across temporal and local dimensions, such as post-to-reaction delay, user location and the network of activ-ity. This analysis provides some interesting observations and valuable insights into the when-to-post problem.
To start with, we note that there is always an inherent delay between when a post was created and when a user reacts to it. This delay is crucial to consider when we study the when-to-post problem.

Specifically, we are concerned with the post-to-reaction delay within a short time window, and we choose this win-dow to be 24 hours. This is also in accordance with previous studies such as [16] that have shown that messages on social media are short-lived with exponential dropoff after a day. In the limiting case when there is no dropoff and the de-lay is infinite all posts have the same probability of getting responses. Thus it is because of this dropoff within a finite duration that the when-to-post problem becomes important. Further, since most reactions occur in narrow time windows for both networks, the goal should be to recommend post-ing times in narrow time buckets. To examine the speed of reactions, we define a metric T d ( p ) as follows:
Definition 1. Let R be the total number of reactions re-ceived by all posts within a time period d since posting time. Then T d ( p ) is defined as the amount of time that passes be-tween posting time and the time when the cumulative reac-tion count is equal to a fraction p of R . 2
Along with the reaction counts, we use this metric T d ( p ) to further analyze post-to-reaction behavior across differ-ent dimensions of the problem. Fig. 2 plots the fraction of cumulative reaction counts occurring within 24 hours of posting and Table 1 shows the T 24 h ( p ) values respectively.
Further, we would also like to understand the probability distribution of a reaction occurring within a given time win-dow since the time of post creation. In order to do this, we define a Post-to-Reaction Filter function as follows:
Definition 2. Post To Reaction Filter For a time in-terval d , the post-to-reaction filter function PTR ( d ) is de-fined as a discrete probability distribution over the event that a reaction occurs within time d of creating a post. 2
We estimate the post-to-reaction filter function PTR ( d ) by aggregating reaction times across all observed messages and reactions in a network. This filter function will be used in Sec. 5 when we derive personalized user schedules.
Posting and reaction behavior varies on social networks because of many factors, such as manner of posting, pre-sentation of posts to users and the set of possible reactions that a user can perform. We compare post-to-reaction times across three major social networks  X  Twitter (TW), Face-book (FB) and Google+ (GP). We also treat Facebook Fan Pages (FP) as a separate network, since the dynamics of posting and reacting on these pages diverge significantly from personal Facebook pages. The top halves of Fig. 2 and Table 1 show the reaction times for different networks.
We observe that Twitter exhibits a much higher speed of reactions compared to the Facebook. On Twitter, 25% of the reactions take place in the first 3 minutes, 50% within the first half hour, and 90% within the first 9 hours. Other networks exhibit slightly slower speeds compared to Twit-ter, with 50% of reactions on Facebook, Facebook Pages and Google+ taking place within the first 2 hours of post-ing. Interestingly, we see that the Facebook Pages network shows more similar reaction times to Google+ rather than Facebook, indicating that similar responses can be elicited from users belonging to completely disjoint user sets, if the underlying dynamics of interactions are similar.

In the rest of this paper, we mainly focus on Twitter and Facebook, which show significant variations in post-to-reaction delays. The distribution of post-to-reaction delay for Twitter is narrower and falls off more quickly compared to Facebook. The T 24 h ( p ) values in Table 1 suggest that a 15 minute bucket can capture the necessary granularity of reactions, which we choose as the length of our time buckets.
These variations also highlight that social networks op-erate on different timescales, and the post-to-reaction filter function needs to be computed separately for each network during comparison. Next, we consider the dependence of re-action behavior on the in-degree of users posting messages.
Next, we explore the hypothesis that network sizes of users may be a factor that affects reaction times. To do so, we analyze how an audience member X  X  in-degree affects his re-action behavior. Fig. 2 (bottom) plots the fractions of 24 hour reaction counts against the time elapsed, for different sets of in-degrees of audience members on Twitter. Table 1 (bottom) shows the reaction times at various T 24 h ( p ) values.
We find that a large section of audience members with in-degrees between 100 to 100k exhibit similar behavior. More than 60% of the reactions from such users are created in the first 1 hour. Users with low in-degrees between 10-100 have slower response times, perhaps they may not be very active users. The users with in-degrees of greater than 1M have the slowest reaction times among all users. This may be at-tributed to such users being celebrities and brands who may not react to messages as quickly as other users do, because of the large volume of messages they see.

Thus, a large portion of audience members show simi-lar reaction behavior, though they may have differing in-degrees. We can therefore infer that the when-to-post prob-lem does not have a large dependency on the network sizes of audience members, unless these sizes are very small or very large. This permits us to use a common post-to-reaction filter function for all users in a given network.
User post and reaction behaviors are multi-dimensional and are highly dependent on the location, network and time-zone of the user. In this section, we analyze normalized ag-gregated user audience reaction behaviors S ( u ) , for user co-horts within and across various cities as well as across Face-book and Twitter within a given city. For behavior analysis we use correlation and cosine similarity metrics. Correla-tion and cosine similarity between finite time series S ( u and S ( u 2 ) are defined in Equations 1 and 2 respectively.
Cosine similarity reveals the overlap between time series, while correlation reveals closeness in time dependent pat-terns between them. We observe metric distributions for 10 to 50 million user pairs, depending on the cohorts compared, where u 1 is selected from the first cohort and u 2 from the second. In addition to the metrics above, we compare the raw time series to gain further insights into reaction behav-iors in Figs. 4 and 5. corr ( S ( u 1 ) , S ( u 2 )) = In this section, we analyze the user reaction profiles across Twitter and Facebook for users in New York City (NYC). Fig. 3 top shows expected audience reactions, aggregated across all users in NYC.

We observe that the daily seasonality is more pronounced for Twitter than Facebook, with taller peaks and deeper troughs. Twitter usage seems to peak during working hours and drops quickly thereafter. Both networks also exhibit secondary peaks at around 7-8pm daily. The amplitude of expected reactions on Twitter is around twice that of Face-book X  X , meaning posting on Twitter at the right times can lead to comparatively larger gains. Also, compared to Twit-ter, Facebook usage is more consistent throughout the day.
With respect to weekly trends, we find that Twitter activ-ity falls to almost half of its weekday amplitude on Saturday and Sunday, whereas Facebook activity seems to be less af-fected by weekends. It is interesting to note that Facebook is most consistently used throughout the day on Sundays. We compare aggregated user audience reaction behaviors S
F B ( u 1 ) and S T W ( u 1 ) for Facebook and Twitter respec-tively using Eq. 1 and 2 in Fig. 3 bottom. We observe that correlation is positive, and relatively uniform in the 0 . 3  X  0 . 8 range, which means that daily audience patterns across Twitter and Facebook are only moderately correlated. Both the similarity and correlation curves suggests that al-though audience reactions exhibit some similarity and cor-Figure 3: Top: Per-Network Globally Aggregated User Audience relation across networks for a given user, there are still sig-nificant differences. This again reinforces the need for any recommended schedules to be personalized per network.
In this section we analyze differences in behavior for mul-tiple cities across Facebook and Twitter. Figs 4a and 5a show reaction behaviors, shifted to the local timezone of the city, for Facebook and Twitter respectively.

Observing the Facebook reactions in Fig. 4a, we notice that the US cities of San Francisco and New York exhibit similar shapes, where reactions peak at the beginning of work hours. For Paris, the reactions peak in the second half of working hours, while for London most reactions are expected towards the end of working hours. Finally, the pattern for Tokyo is quite different from the rest with two peaks, both occurring off working hours.

The Twitter reactions in Fig. 5a have similar patterns as Facebook. The notable difference is that Twitter reac-tions for US cities have more pronounced daily peaks, while for London, Paris and Tokyo the behavior seems more con-sistent throughout the day. All the curves show significant drops on weekends, and Saturday has noticeably lower activ-ity than Sunday. We also observe that New York schedules lag slightly as compared to San Francisco, which may be explained due to lifestyle differences in the two cities.
In addition to the visual analysis, we also analyze simi-larity and correlations for reaction behaviors between cities, calculated according to Eq. 1 and 2. The time series com-pared in this case are the reactions aggregated across users in two cities, denoted by S ( C 1 ) and S ( C 2 ) . Figures 4b-4e, 5b-5e show these distributions for Facebook and Twitter within the same city and across different cities.

Interestingly in US cities (New York and San Francisco) cross-city correlation and similarity for both Facebook and Twitter are not very different from their within city metrics. Globally Twitter reaction behavior compared to Facebook seems to be more correlated and similar. On Facebook, be-havior correlation and similarity within city are lowest for London and Tokyo, and have high deviation. This indicates that users within these cities exhibit more diverse behavior patterns compared to US cities. Therefore a city level model built for London may not apply to all users within the city.
The analysis in the previous section highlights the im-portance of having personalized posting schedules. Here we present multiple approaches to derive such schedules.
To start with, we simplify the computation by bucketizing time within a period P into discrete time intervals t i . Based on the analysis in Sec. 4, we use 15 minute time intervals within a period of one week for a total of 4  X  24  X  7 = 672 buckets, though the methods described here are applicable to any time interval and period. Because the number of reactions in one bucket in each period is usually small for most users, we aggregate the actions from multiple periods into the same bucket. For example, all the actions taken by a user between 00:00 to 00:15 on Mondays, in a 90 day time window, will be grouped into the first bucket t 1 . We also define the following sets associated with a user:
Definition 3. For a user u , the set U out ( u ) is defined as the set of all users who are connected to u , and can poten-tially react to the posts created by u .

Definition 4. For a user u , the set U in ( u ) is defined as the set of all users to whom u is connected, and whose posts can be potentially be reacted upon by u .
 Note that though we treat the above sets as separate enti-ties in order to differentiate between the post and reaction behavior, we do not assume that they are disjoint sets. 5
Let N be the number of time buckets within the time pe-riod P under consideration. To represent the actions associ-ated with a user with respect to time, we create time-based action profiles for each user computed from a user X  X  actions in the period P , and aggregated into the buckets t k . These profiles can thus be represented as vectors of length N .
We define four primary action profiles for each user:
As noted in previous works such as [1] and [15], and as analyzed in Sec. 4, there is usually a time difference between when a post is created by a user in U in ( u ) , and when the user u may react to it. Thus a specific post may be visible in the time bucket t k in V ( u ) , but may only be reacted upon in a later time bucket t k 0 in R ( u ) . The post-to-reaction filter function defined in the previous section represents this lag in terms of a time interval d , discretized into time buckets For some bi-directional relationships such as Facebook Friends, U out ( u ) and U in ( u ) are equivalent. of size t k . We can therefore compute a Delayed Reac-tion Profile for a user by performing a discrete convolution operation of the original reaction profile with the post-to-reaction filter function.
 where  X  is the discrete convolution operator. 6
Each element r d,k ( u ) in the delayed reaction profile repre-sents the number of reactions that the user u would generate in the time interval d following the bucket t k . Thus for a post created by a user in the current time bucket, using R d ( u ) for his audience members provides a better estimate of anticipated future reactions.

These estimates for q i ( u ) could be computed in multiple ways, as described in the following section. Once Q ( u ) is known, we can determine a probability mass function which represents a post schedule for the user. These probabilities s ( u ) can be computed as:
Finally, the vector consisting of these probabilities deter-mine the Post Schedule for the user. Once we have S ( u ) , we simply pick the buckets with the highest values of s i which are the desired best times to post. Next, we describe multiple approaches to compute S ( u ) using the above nota-tion and definitions, which are summarized in Table 2.
To illustrate the when-to-post problem with a concrete example, consider a simplified social network graph, as rep-resented in Fig. 6. For the user a 0 , her audience is made up of other users b i , so we have: U out ( a 0 ) = { b 0 ,b
When a 0 creates a post, it may be potentially seen by all the members b i of her audience. Let us focus on a particular audience member b 0 . This audience member b 0 also belongs to the audience sets of other users a i , and may see posts that are created by each of them. We can represent this relation-ship between the users as: U in ( b 0 ) = { a 0 ,a 1 ,a 2 Figure 6: Simplified representation of a user X  X  social graph
We would like to derive the post schedule S ( a 0 ) for the user a 0 . In order to do so, we want to answer the following question: For the user a 0 , what is the expected number of re-actions received from U out ( a 0 ) for a post created in the time bucket t k ? We describe two approaches below to answer this question and compute the recommended schedule.
In this approach, we consider the reactions of a 0  X  X  audi-ence U out ( a 0 ) , ignoring the second-degree effects of the other posting users a i . With respect to Fig. 6, we consider only
For two functions f , g defined on the set of integers Z , the discrete convolution of f , g is given by: ( f  X  g )[ n ] = the left part of the diagram that represents a 0 and U out (including b 0 ), and ignore all other a i .

Since we know the reaction profiles R ( b j ) for the members of a 0  X  X  first-degree graph, we can accumulate these reaction counts per time bucket to get the combined audience reac-tion profile. However, since this does not take into account the post-to-reaction delay, a better approach is to aggregate the delayed reaction profiles R d ( b j ) for all b j in U
This sum of delayed reactions per bucket gives us the es-timated audience reaction profile Q ( a 0 ) for the user, where the elements of the vector are given by:
Thus in this case, the probability of receiving a reaction in any given time bucket s k ( a 0 ) can then be computed from Q ( a 0 ) as per Eq. 4. These probabilities determine the First-Degree Reaction posting schedule S 1 ( a 0 ) .

Note that S 1 ( a 0 ) does not take into account the behav-ior of an audience member b j with respect to posts from other users a i . In other words, this approach only takes into account the first-degree dependency for the user a 0 . We therefore describe another approach that takes into account the second-degree dependency as well.
In Fig. 6, the actions of the users a i represent the second-degree effects for user a 0 , since they affect how a 0  X  X  first-degree connection b 0 reacts to messages. To consider these second-degree effects, we define a Second-Degree Reaction schedule S 2 ( a 0 ) , which can be derived by answering the fol-lowing questions first, before the original one above.
The answer to the first question is given by the post cre-ation profiles C ( a i ) for each user a i , computed by aggre-gating the past history of post creation events for the user into time buckets. To answer the second question, we first compute the reaction profile R ( b 0 ) . Again, this profile is computed by aggregating the past history of reaction events for b 0 , which tells us how often he reacts in any given time bucket. The answer to when b 0 reacts with respect to post-ing times is then given by the delayed reaction profile R which takes into account the post-to-reaction delay.
For the third question, let p ( b 0 ,t k ) be the probability that user b 0 reacts to a post in time bucket t k . This event can be modeled as a Bernoulli random variable X b 0 ,k , with the probability of the reaction given by p ( b 0 ,t k ) , thus: From the point of view of b 0 , the probability that he reacts to some post in the time bucket t k depends on the number of posts that he sees, and his usual reaction behavior in t
To estimate the number of posts that are potentially vis-ible to the user b 0 in each time bucket, we aggregate the
Since we are concerned only with the time aspects here, we assume that the posts seen by the user are equally likely to be reacted upon in all other aspects. User Action Profile Vector Element Description for user u in time bucket t k interval d following t k post creation profiles for all a i . The number of posts that are actually visible to the user may be modeled as a linear function of the total created posts. Thus for a given time bucket t k , the number of posts visible to b 0 is given by: Where  X  and  X  are constants and c 0 k ( a i ) is a rescaled version of c k ( a i ) . These constants may depend on network-specific factors, and we assume that the factor is globally applicable to all users in a given network.

With this information, the a priori probability in Eq. 6 can now be computed as: p ( b 0 ,t k ) = number of delayed reactions by b 0 in t Now we turn our attention back to the original user a 0 . Let Y a 0 ,k to be the random variable representing the number of reactions that a 0 receives for a post created in a specific time bucket t k . We would like to find the expected number of reactions E ( Y a 0 ,k ) , which can be computed as: Thus, these expected values computed from the observed R d ( u ) and C ( u ) give us the estimates for the number of reac-tions received by a 0 . The elements of the audience reaction profile Q ( a 0 ) are hence given by:
Finally, we can infer the desired posting schedule S 2 ( a for the user a 0 as the probability mass function for the dis-crete random variable Y a 0 ,k . Again, the elements of S are computed from Q ( a 0 ) as per Eq. 4.
In the sums computed above for the first-and second-degree schedules, all audience members are treated equally. However, audience members may have differing tendencies to react to the user X  X  posts depending on their affinity to the user. These differences can be accounted for by associating a weight with each audience member who may react to the user, computed based on previous actions as follows: w ( a 0 ,b i ) = total reactions received by a 0 from b i Eq. 5 can now be modified with this weight as: Similarly, the expected number of reactions for the second-degree schedule in Eq. 9 can also be modified as:
We denote these weighted schedules as S 1 ,w ( u ) and S 2 ,w respectively. In Sec. 6 we evaluate the performance of all four schedules described above.
In this section, we evaluate the user post schedules derived above  X  S 1 ( u ) , S 2 ( u ) and their respective weighted counter-parts. We evaluate them on empirical observations of real user behavior over a 56 -day period for 0 . 5 million users and more than 25 million messages.
Because there are no previous baselines on the when-to-post problem, we design two schedules to compare our ap-proaches with. We consider all users in a given timezone and aggregate their behavior to create these baseline sched-ules. Both the baselines are thus uniquely determined for each timezone and are not personalized per user.

One natural baseline can be created by observing the most frequently used time buckets for posting, aggregated across all users in each timezone T . We thus obtain our first base-line, the Most Frequently Used (MFU) Schedule , denoted as BS mfu ( T ) , with bucket values bs mfu i ( T ) computed as: where U T is the set of users in the timezone T .
As explained in Sec. 5, the First-Degree Reaction Sched-ule for a user is based on his first degree audience behavior. To generate another baseline for global behavior, we simply aggregate the first-degree reaction schedules from all users in the timezone. We call this second baseline schedule Aggre-gated First-Degree (AFD) Schedule , denoted as BS afd ( T ) , whose bucket values are given by: where U T is the set of users in the timezone T who have a first-degree reaction schedule Q ( u ) .
Once we have the baseline schedules, we pick the buckets with the highest values of bs i ( T ) as the best recommended times to post for users in timezone T . For the purposes of evaluation of schedules, we propose a ReactionGain metric, which we compute as below.

Let U be the user sample set under consideration, ob-served over M days. Let us first consider a single user u in this sample. For this user u , we can rank the posting time buckets as recommended by a schedule S ( u ) over a period of 24 hours, with the first bucket being the best time to post and the last one being the worst.

For the k th ranked bucket as per S ( u ) we compute the average reactions per message , RPM ( u,k ) : where r k,j ( u ) and c k,j ( u ) are respectively the reactions re-ceived and the posts created by the user in the time bucket corresponding to the k -th rank, on the j -th day. As before, we compute r k,j ( u ) as the reactions received in the first 24 hours after the posting time.

We similarly define RPM ( u ) as the ratio of all the re-actions received to all the posts created by the user in the same 56 -day period, across all the time buckets. We now compute the ReactionGain , RG ( u,k ) , for the k -th bucket for the user as: This ratio tells us the increase or decrease in reactions re-ceived by the user when she posts in a specific bucket, com-pared to the average reactions per message she receives.
Finally, we compute the global average reaction gain for each bucket RG avg ( k ) as the average of RG ( u,k ) values over all the users in the sampled population U who created posts in that bucket. We use this average reaction gain metric to evaluate the schedules below.
We evaluate real user behavior and measure schedule per-formance based on how many reactions were received when the recommended times were used.

In our experiments, we sampled 0 . 25 million active users each from Twitter and Facebook from the dataset described in Sec 3.3. For each sampled user u , we compute S 1 ( u ) , S ( u ) and their corresponding weighted schedules as de-scribed in Sec. 5, for a 63 -day time period. We empirically chose the  X  and  X  parameters to be both 1 . 0 , and c k ( a rescaled to c 0 k ( a i ) with the mean. We then evaluate the rec-ommended times on 25 million messages generated by the sampled users in a 56 -day time period, with no overlap over the time period used to derive schedules.

To compare the performance of the top posting times rec-ommended by the schedules, we compute the average reac-tion gain RG avg ( k ) for the bucket rank k , for each schedule. Fig. 7 plots these values for the top 32 buckets for a week-day 8 , for both Facebook and Twitter.
We exclude weekends here since they show diverging be-havior compared to weekdays, as shown in Sec. 4, but a similar analysis can also be performed for weekends. We observe from Fig. 7 that the First-Degree Weighted Schedule outperforms all the others on both Facebook and Twitter. On Facebook, this schedule shows a reaction gain of more than 17% in the highest bucket, and on Twitter the highest gain is 4% . The second best schedule on Facebook is the First-Degree Schedule , while that on Twitter is the Second-Degree Weighted Schedule . Both the MFU and the AFD baseline schedules show a reaction gain that is slightly above 1 . 0 on Facebook, and mostly below 1 . 0 on Twitter, showing that users who post according to these schedules see little to no increase in reactions received.

Both the second-degree schedules on Facebook show only a small reaction gain, very similar to the baseline schedules. The superior performance of the first-degree schedules on Facebook suggests that second-degree effects on this network are less dominant. This may stem from the inherent nature of the interactions on Facebook, and the manner in which users are shown posts that they could react upon.
On Twitter, we observe that the weighted schedules for the first degree as well as second degree perform better than the baselines and the non-weighted ones. Thus the mutual rela-tionships between a user and his audience members play an important role on Twitter in determining the expected reac-tions. This observation highlights the importance of treating each edge in a user graph differently.

Note that a good recommended schedule should show a decreasing trend in reaction gains from the higher to the lower ranked buckets, such that posting at the higher recom-mended times leads to higher reaction gains. The baseline schedules fall short in this regard, and show a decreasing trend only in the first 10 buckets on Twitter, and none at all on Facebook. The global baseline schedules thus prove to be less effective in magnitude of reaction gains, as well as order-ing of buckets, validating our hypothesis that personalized recommendations show better performance.

As an example of recommended schedules, Fig. 8 shows the reaction profiles and schedules for a sample user on Twit-ter. The purple curve in Fig. 8 shows the probability distri-bution of post-to-reaction delay on Twitter, which is plot-ted by aggregating reactions observed in a 63 -day period. Note that this function falls off steeply in the first few hours from posting time, and almost vanishes after 12 hours. The dashed curve plots the aggregated audience reactions for the user, without the post-to-reaction delay. The red and the blue curves show the First-Degree Weighted Schedule and the Second-Degree Weighted Schedule respectively. The rec-ommended best times to post over one day and one week are the peaks in the plot.
In this study, we introduce and formulate a when-to-post problem to find the best times to post on social networks in order to increase the number of received reactions.
We analyze various factors that affect audience reactions on a dataset containing over a billion reactions on hundreds of millions of messages. We find that a majority of reac-tions occur within the first 2 hours of posting times on most networks. Audience behavior differs significantly on differ-ent networks, with Twitter having larger reaction volumes in shorter time windows as compared to Facebook. We also perform location analysis and find interesting similarities and differences between cities in terms of reaction patterns. Future studies could also study other factors such as content and topical relevance of posted messages.

Further, we present multiple approaches for deriving per-sonalized posting schedules for users, and compare them to two baselines. We evaluate these schedules on empirical data from 0 . 5 million real-world users and 25 million messages ob-served over a 56 -day period. We find that the First-Degree Weighted Schedule performs the best among all, providing a reaction gain of 17% on Facebook and 4% on Twitter. Both first-degree schedules perform better on Facebook and both weighted schedules perform better on Twitter. These schedules are deployed on a full production system that rec-ommends posting times to millions of users daily.
We hope that this study and the accompanying dataset provided enables further research in this area.
We thank Gaurav Ragtah, Sarah Ellinger, Tyler Single-tary and Trevor D X  X ouza for their valuable contributions towards this study. We also thank Sunil Rajasekar and Sateesh Chilukuri for their support throughout this work. [1] S. Asur, B. A. Huberman, G. Szabo, and C. Wang. [2] A. Bennamane, H. Hacid, A. Ansiaux, and [3] S. Bharathi, D. Kempe, and M. Salek. Competitive [4] W. Chen, Y. Wang, and S. Yang. Efficient influence [5] J. Cheng, L. Adamic, P. A. Dow, J. M. Kleinberg, and [6] R. Crane and D. Sornette. Robust dynamic classes [7] A. Guille and H. Hacid. A predictive model for the [8] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [9] H. Kwak, C. Lee, H. Park, and S. Moon. What is [10] J. Lehmann, B. Gon X alves, J. J. Ramasco, and [11] K. Lerman and R. Ghosh. Information contagion: An [12] J. Leskovec, L. Backstrom, and J. Kleinberg. [13] J. Leskovec, M. McGlohon, C. Faloutsos, N. S. [14] N. Spasojevic, J. Yan, A. Rao, and P. Bhattacharyya. [15] M. Tsytsarau, T. Palpanas, and M. Castellanos. [16] S. Wu, J. M. Hofman, W. A. Mason, and D. J. Watts. [17] J. Yang and S. Counts. Predicting the speed, scale, [18] J. Yang and J. Leskovec. Patterns of temporal
