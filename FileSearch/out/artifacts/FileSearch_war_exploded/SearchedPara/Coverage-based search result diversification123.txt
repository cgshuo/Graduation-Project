 Abstract Traditional retrieval models may provide users with less satisfactory search experience because documents are scored independently and the top ranked documents often contain excessively redundant information. Intuitively, it is more desirable to diversify search results so that the top-ranked documents can cover different query sub-topics, i.e., different pieces of relevant information. In this paper, we study the problem of search result diversification in an optimization framework whose objective is to maximize a coverage-based diversity function. We first define the diversity score of a set of search results through measuring the coverage of query subtopics in the result set, and then discuss how to use them to derive diversification methods. The key challenge here is how to define an appropriate coverage function given a query and a set of search results. To address this challenge, we propose and systematically study three different strategies to define coverage functions. They are based on summations, loss functions and evaluation measures respectively. Each of these coverage functions leads to a result diversification method. We show that the proposed coverage based diversification methods not only cover several state-of-the-art methods but also allows us to derive new ones. We compare these methods both analytically and empirically. Experiment results on two standard TREC collections show that all the methods are effective for diversification and the new methods can outperform existing ones.
 Keywords Information retrieval Diversification Coverage Subtopic 1 Introduction Traditional retrieval models rank documents based on only their relevance scores and ignore the redundancy among the returned documents. As a result, the top ranked documents may contain the same piece of relevant information. It has been noticed that a large fraction of search queries are short and thus ambiguous or under-specified (Clarke et al. 2009a ; Radlinski et al. 2009 ). For these queries, the targeted information for the same query can be information (i.e., subtopics of a query) are less risky and more desirable because they can provide diversified information that satisfies different information needs of users. For example, different users issuing the same query  X  X  X ava X  X  may look for different information, such as java programming language and java coffee. A user searching for  X  X  X loud computing X  X  may want to conduct a survey and learn different research topics related to cloud computing. It is clear that search result diversification can benefit ambiguous queries, under-specified queries and exploratory queries in general which account for a large portion of search queries (Clarke et al. 2009a ; Radlinski et al. 2009 ; White and Roth 2009 ).
 Search result diversification has recently attracted a lot of attentions (Clarke et al. 2009a ; Radlinski et al. 2009 ;Zhaietal. 2003 ; Macdonald et al. 2011 ). The goal of result diversifi-cation is to return a list of documents which are not only relevant to a query but also cover many subtopics of the query. Here a query subtopic corresponds to a representative infor-mation need associated with the query, which is also referred to as a nugget (Clarke et al. 2008 ) or query aspect (Clarke et al. 2009b ) in previous work. Using query subtopics for result diversification has received much attention. In particular, most of the commonly used eval-uation measures, including a -nDCG (Clarke et al. 2008 ), Precision-IA (Agrawal et al. 2009 ), NRBP (Clarke et al. 2009 )and ERR-IA (Chapelle et al. 2009 ), are all based on the coverage of query subtopics in the documents. Moreover, a few recent studies tried to diversify search results explicitly based on the query subtopics (Agrawal et al. 2009 ; Carterette and Chandar 2009 ; Santos et al. 2010b , c ; Yin et al. 2009 ). However, none of existing studies has sys-tematically studied and compared different subtopic-based diversification methods. Thus, the underlying commonalities of these methods are not well understood, and there is no guidance that can be used to derived new and possibly more effective diversification methods.
In this paper, we study the search result diversification problem in a coverage-based optimization framework. Following previous studies, we define the optimization objective function as a linear combination of relevance and diversity scores and then use a greedy propose to model the diversity scores of search results based on their coverage of query subtopics, i.e., how much relevant information of query subtopics is contained in the respect to the subtopics and the importance of these subtopics. Moreover, with the assumption that all the query subtopics are independent, the diversity score is computed as the weighted sum of its coverage for every query subtopic. Thus, the key challenge is how to define appropriate coverage functions given a query subtopic and a set of search results. To address this challenge, we explore three different strategies. The first summation-based strategy is to compute the coverage score of a document set by summing up those of individuals in the set. The second strategy defines a coverage function through a loss coverage functions based on a few commonly used evaluation measures. With these three strategies, different variants of coverage functions are defined and each of them can lead to a potentially different coverage-based diversification method. We analyze the similarity among these methods and select five representative ones to study in this paper. Among the derived diversification methods, two of them are variants of some existing diversification methods (Agrawal et al. 2009 ; Santos et al. 2010c ; Yin et al. 2009 ) and three of them are new diversification methods that have not been studied before. We first analytically compare the characteristics of these five methods from the following aspects: diminishing return, favoring diversity , and novelty emphasis , and then conduct experiments over two standard TREC collections. Experimental results show that most of the diversification methods derived in the optimization framework are effective. Furthermore, one of the new derived methods, i.e., SQR , can consistently outperform the state-of-the-art methods over different collections and with different retrieval models.

The rest of the paper is organized as follows. We discuss the related work in Sect. 2 .We review the main idea of optimization framework for result diversification in Sect. 3 .We then propose and study different coverage functions and corresponding diversification methods in Sect. 4 . We analytically compare these diversification methods in Sect. 5 and empirically compare their results in Sect. 6 . Finally, we conclude in Sect. 7 . 2 Related work The study of search result diversification can be traced back to early sixties (Goffman 1964 ). Since then, many studies have tried to rank documents based on not only relevance but also diversity (Agrawal et al. 2009 ; Boyce 1982 ; Carbonell and Goldstein 1998 ; Carterette and Chandar 2009 ; Chen and Karger 2006 ; Gollapudi and Sharma 2009 ; McCreadie et al. 2009 ; Radlinski et al. 2009 ; Radlinsk and Dumais 2006 ; Santos et al. 2010c ; Yin et al. 2009 ; Yue and Joachims 2008 ; Zhai et al. 2003 ). Roughly speaking, the proposed methods can be classified into two categories (Santos et al. 2010b , c ).
The first category implicitly models diversity through the relations among documents in order to minimize the redundant information among the selected documents (Carbonell and Goldstein 1998 ; Chen and Karger 2006 ; Craswell et al. 2009 ;Demidovaet al. 2010 ;Gollapudi and Sharma 2009 ;Santosetal. 2010b ;Yue and Joachims 2008 ;Zhaietal. 2003 ). Carbonell and Goldstein ( 1998 ) proposed the maximal marginal relevance ( MMR )rankingstrategyto balance the relevance and the redundancy. Motivated by this work, Zhai et al. ( 2003 )com-bined both relevance and novelty in the statistical language modeling framework. Chen and Karger ( 2006 ) presented a sequential document selection algorithm to optimize an objective function that aims to find at least one relevant document for all users. Yue and Joachims ( 2008 ) treated the diversification as a process to learn the function of choosing the optimum set of diversified documents, which is a learning problem. Their learned function can sequentially select documents which cover maximally distinct words. Craswell et al. ( 2009 ) removed the redundant documents based on the host information of the documents. Gollapudi and Sharma ( 2009 ) proposed an axiomatic approach to characterize the problem of result diversification and studied several redundancy functions in their axiomatic framework. The main difference among different methods is how to model the redundancy between a new document and the previous selected documents without an explicit modeling of query subtopics.

The second category of search result diversification explicitly model diversity among documents through their relation to the subtopics of the queries (Agrawal et al. 2009 ; Carterette and Chandar 2009 ; Radlinsk and Dumais 2006 ; Santos et al. 2010a , b , c ; Yin et al. 2009 ). Subtopics are often identified using topic modeling (Carterette and Chandar 2009 ), existing taxonomy (Agrawal et al. 2009 ), query suggestions (Santos et al. 2010b )or frequent patterns (Zheng and Fang 2010 ). Most of the state-of-the-art diversification methods often formalize the problem in an optimization framework, where the objective function is defined based on the combination of relevance and diversity scores. Since it is an NP-hard problem to select an optimum document set in general, a greedy algorithm is often used to iteratively select documents. In particular, Carterette and Chandar ( 2009 ) proposed a probabilistic set-based approach that maximizes the likelihood of capturing all of the query subtopics. Agrawal et al. ( 2009 ) formalized the problem as the one that maximizes average user satisfaction based on a classification taxonomy over queries and documents. Santos et al. ( 2010b , c ) proposed a probabilistic framework that estimates the diversity based on the relevance of documents to query subtopics and the importance of query subtopics. Yin et al. ( 2009 ) derived a diversification method using the language modeling approach. Since these existing diversification methods were proposed and studied in different work, the connection of these methods remains unclear. It is difficult to analytically compare these methods although there are empirical comparisons among them (Zheng and Fang 2011 ). Moreover, there is no systematic way of developing new diver-sification methods. Finally, almost all of the existing diversification methods are based on probabilistic models, and it remains unclear how to diversify search results for non-probabilistic retrieval models.

Developing effective evaluation measures has also attracted a lot of attention. Most commonly used evaluation measures, including Precision-IA (Agrawal et al. 2009 ), ERR-IA (Chapelle et al. 2009 ), a -nDCG (Clarke et al. 2008 ) and NRBP (Clarke et al. 2009b ), are all based on the coverage of query subtopics. We review them briefly in this section.
Intent-aware precision at retrieval depth k ( Precision-IA@k ) is based on a weighted average of precision at depth k across different subtopics (Agrawal et al. 2009 ; Clarke et al. 2009a ). The Precision-IA@k in a query q can be computed as judgment of the document d j to the subtopic s . Precision-IA@k uses the binary relevance score as r ( s , d j ).

Intent-aware expected reciprocal rank at retrieval depth k ( ERR-IA@k ) uses cascade-style user browsing model to estimate the expected reciprocal length of time for the user to find a relevant document. It is computed as follows (Chapelle et al. 2009 ): where r 0 ( d j , s ) is the probability of relevance mapped from relevance grade of d j to s .
Another commonly used evaluation measure is a -nDCG (Clarke et al. 2009a ). It inte-grates the novelty of subtopic into normalized discounted cumulative gain measure. It is computed as: where and a -DCG 0 @k is the maximum value of a -DCG@k given the ideal order of the returned document list.

Novelty-and Rank-Biased Precision ( NRBP ) is a measure that combines user browsing model, intent aware and a -nDCG . The function is as follows: where a is the parameter to describing user X  X  ability to judge the relevance of document given the subtopic and b is the parameter to estimate user X  X  interest in reading more documents after finding one relevant document.

Intuitively, these evaluation measures can provide guidance on how to derive subtopic-based diversification methods. As mentioned in a recent study (Chapelle et al. 2009 ), a state-of-the-art diversification method, i.e., IA-SELECT (Agrawal et al. 2009 ), is similar to a standard evaluation measure, i.e., ERR-IA (Chapelle et al. 2009 ). Sakai and Song ( 2011 ) compared the existing evaluation measures and analyzed the advantages of each method in queries with different types of subtopics. They found that a -nDCG is one of the best evaluation measures in the existing measures. However, to our best knowledge, none of the existing work studied how to derive new diversification methods based on the evaluation measures for diversity.

Our work is similar to previous studies (Agrawal et al. 2009 ; Santos et al. 2010b )inthe sense that we also formulate the problem as an optimization problem and use a greedy algorithm to select documents. However, our framework is more general that provides a systematically way of deriving and analyzing new diversification methods. Under the guid-ance of the framework, we define different functions measuring the coverage of the document on subtopics and systematically derive five diversification methods, three of which are new diversification methods. We then analytically and empirically compare these methods. 3 An optimization framework for result diversification The goal of result diversification is to return a set of relevant search results that can cover diverse pieces of relevant information. The problem is often formulated as an optimization problem that aims to maximize an objective function related to both the relevance and diversity of the search results (Agrawal et al. 2009 ; Carbonell and Goldstein 1998 ; Santos et al. 2010b , c ; Zhai et al. 2003 ).

Formally, given a query q , a set of documents D and an integer k , the goal is to find D , i.e., a subset with k documents from the document set, that can maximize the following objective function: where D D . The objective function is based on both rel ( q , D ), which measures the relevance score of document set D with respect to the query q , and div ( q , D ), which measures the diversity score of D for q . It is similar to the ideas of existing methods (Carbonell and Goldstein 1998 ; Santos et al. 2010b , c ). k 2 X  0 ; 1 is a parameter that controls the tradeoff between diversity and relevance. When k = 1, the optimization goal is to select top k documents ranked based on their relevance scores, which is consistent with the traditional retrieval models.

Finding the optimal solution for the above problem is in general NP-hard since it can be reduced from Maximum Coverage Problem (Agrawal et al. 2009 ). Fortunately, if G ( D )isa submodular function, a greedy algorithm which sequentially selects a document that maximizes the marginal gain of the submodular function can achieve (1 1 e ) approxima-tion of the optimal solution and has been shown to be almost optimal in practices (Agrawal et al. 2009 ; Khuller et al. 1999 ; Leskovec et al. 2007 ).

Specifically, the greedy algorithm starts with an empty document set D = [ , and then iteratively selects a local optimal document, which is defined as follows (Agrawal et al. 2009 ; Santos et al. 2010b ): The local optimal document is then added to document set D until the number of docu-ments in D is k . The order that the documents are selected gives us a ranked list and it only depends on the definition of the objective function.

We now discuss how to define an objective function. The objective function is related to mation is contained in the document set with respect to the query. One possible way of computing rel ( q , D )is where rel ( q , d ) is the relevance score of document d for query q and can be computed using any existing retrieval functions.

Existing studies mainly differ in how to compute div ( q , D ), which measures the diversity score of document set D with respect to query q . One strategy is to compute the diversity score based on the redundancy of the document set D (Carbonell and Goldstein 1998 ; Zhai et al. 2003 ). The diversity score is smaller when there is more redundant information in the document set. One major limitation of this approach is that the diversity is query-independent. Thus, the diversity score can be arbitrarily boosted by the non-relevant information of the search results and may not be used to effectively diversify relevant search results (Santos et al. 2010b ). An alternative strategy is to compute the diversity score based on the query subtopics. (Note that query subtopics are also referred to as nuggets or query aspects in previous studies (Clarke et al. 2008 ; Santos et al. 2010b , c ).) Most existing studies adopt probabilistic methods. For example, Agrawal et. al. ( 2009 ) proposed an objective function based on only the diversity score, which is estimated with the probability that the document set would satisfy the user who issues the query. The probabilities are estimated based on a classification taxonomy. Santos et. al. ( 2010b ) proposed an objective function based on the relevance of documents to query subtopics and the importance of query subtopics in a probabilistic framework. However, it is difficult to derive more diversity functions using these methods and analytically compare different more general approach that can be used to guide the derivation of new diversification functions. 4 Coverage-based diversification methods In this paper, we aim to explore a general way of computing the diversity score, i.e., div ( q , D ). In this section, we first describe the general idea of modeling diversity based on the coverage of query subtopics, and then propose three strategies for defining coverage functions. The coverage measures the relevant information of the query subtopics con-tained in the documents. After that, we explain how to derive the diversification methods based on the coverage functions. 4.1 General idea score as follows: where weight ( s , q ) measures the importance of the subtopic s of the query q and cov ( s , D ) measures the coverage of a specific subtopic s in the document set D . It assumes that the subtopics are covering different relevant information of the query and are independent of each other. Intuitively, the more subtopics that D covers and the more important that the covered subtopics are, the higher diversity score that D has. Our definition is consistent with existing methods (Santos et al. 2010b , c ; Yin et al. 2009 ) and more general.
Given the coverage-based diversity function, we can re-write the objective function shown in ( 6 ) as follows: As described in Sect. 3 , it is NP-hard problem to find the optimum set of diversified documents. Given an objective function G ( D ), we need to prove that the objective function is submodular in order to use the greedy algorithm to approximate the solution of the optimization problem. With a submodular function, the benefit of adding an element to a document set is not larger than adding the element to a subset of the document set. Thus, in order to prove that a function G ( D ) is a submodular function with respect to D , we need to show that, for all sets A ; B D such that A B , and d 2 D n B , we have As shown in ( 10 ), the objective function G ( D ) is a linear combination of two components, submodular function with respect to D : Since the linear combination of submodular functions is still a submodular function (Nemhauser et al. 1978 ), G ( D ) is a submodular function if cov ( q , D ) is a submodular function. In order to prove cov ( q , D ) is a submodular, we need to show In summary, in order to prove G ( D ) is a submodular function with respect to D , for all sets A ; B D such that A B , and d 2 D n B , we need to show where Therefore, in each diversification method, we need to prove that ( 12 ) holds in order to use the greedy algorithm described in Sect. 3 that diversifies search results by iteratively document d * can be selected based on: 4.2 Coverage functions We now discuss how to define the coverage function, i.e., cov ( s , D ), which measures how well a document set D covers the information of the query subtopic s . Intuitively, cov ( s , D ) is related to the subtopic coverage of each document in the set, i.e., cov ( s , d ), where d 2 D . Furthermore, as discussed in the previous subsection, we require that cov ( s , D ) should be a submodular function. Thus, the problem is how to combine the coverage of individual documents in D so that cov ( s , D ) is submodular, i.e., the dif-ference function defined in ( 13 ) satisfies the requirement shown in ( 12 ). We explore three set of methods to compute the coverage of D based on the coverage of documents in D , the coverage of documents that are not included in D , and following the idea of evaluation measures. 4.2.1 Summation-based coverage functions A simple strategy of computing the coverage score of a document set is to sum up the coverage scores of its individual documents. We explore the following two ways of combining the individual coverage scores.  X  SUM: It assumes that the coverage of a document set on a subtopic increases linearly Thus, we have We prove that cov SUM ( s , D ) and its diversification function in ( 9 ) are submodular functions in Theorem 1 in the appendix.  X  LOG: It is similar to SUM but with a log transformation to ensure the decrease of So, we have We prove that cov LOG ( s , D ) is a submodular function in Theorem 2. 4.2.2 Loss-based coverage functions In the second strategy, we propose to define coverage functions of a document set based on the coverage of documents that are not included in the document set cov  X  s ; D  X  . Without loss of generality, we assume the values of cov ( s , d ) in each subtopic are normalized so that cov ( s , d ) and cov ( s , D ) are between 0 and 1.  X  PCOV: We follow the idea of derivation based on probability model in xQuAD and In fact, if cov ( s , d ) is treated as the probability that document d is relevant to the query subtopic s , cov PCOV ( s , D ) can also be interpreted as the probability that at least one doc-ument from D is relevant to s (Agrawal et al. 2009 ; Santos et al. 2010b ).
  X  SQR: SQR is a loss-based method which is not restricted to probability model and uses Squared loss functions have been widely used in regression problems (Hastie et al. 2009 ). In our case, more generally, we can define the loss function based on any power c . When c = 1, the coverage function is the same with SUM where the coverage of a document set on a subtopic increases linearly with the coverage of each document. The power c provides flexibility to model non-linear relationship of the coverage as described in Sect. 4.2.1 . For any c C 1, the defined function can be proved to be submodular. In our paper, we focus our study on SQR where c = 2 and leave other settings as future work. For SQR ,wehave We prove cov SQR ( s , D ) is a submodular function in Theorem 4. 4.2.3 Measure-based coverage functions Another possible way of defining coverage functions is based on evaluation measures for diversity, since most of them are designed based on query subtopics as well. In particular, we study four commonly used measures, i.e., Precision-IA , ERR-IA , a -nDCG and NRBP . In the following, we assume that the relevance judgment r ( s , d ) in (1) X ( 5 ) can be estimated using cov ( s , d ), where 0 B cov ( s , d ) B 1.  X  EVAL1: Intent-aware precision at retrieval depth k ( Precision-IA@k ) is based on a Unfortunately, cov EVAL1 ( s , D ) is not a submodular function as shown in Theorem 5. function, which is the same as cov SUM ( s , D ).  X  EVAL2: Intent-aware expected reciprocal rank at retrieval depth k ( ERR-IA@k )isa The coverage function based on DIFF EVAL2 is a submodular function as described in document selection in the greedy algorithm. It is the same as the DIFF PCOV .  X  EVAL3: a -nDCG and NRBP are also commonly used evaluation measures (Clarke where k = | D |, and a is a parameter. The larger a is, the more impact that cov ( s , d ) has on the coverage score.

We prove that EVAL3 is a submodular function in Theorem 7. As seen in ( 12 ) and ( 14 ), not explicitly define a coverage function based on this measure, the derived DIFF EVAL3 ( s , d , D ) is enough to be used to derive a new diversification method.
Plugging the DIFF functions [as shown in ( 16 ) X ( 25 )] into ( 14 ), we can derive different diversification methods as shown in Table 1 . 4.3 Discussions cov ( s , d ), that we need to discuss how to compute. These components can be instantiated using any retrieval models by treating q or s as a query. In fact, this is one major advantage of the framework because the derived diversification methods are general and can be combined with any existing retrieval functions.

Since most existing diversification methods are based on probabilistic models, we now describe how to instantiate the component functions using language modeling approaches (Lafferty and Zhai 2001 ; Ponte and Croft 1998 ) and discuss the connections between our derived methods and the state-of-the-art methods.

In language modeling framework, the relevance score of a document d given query q , P ( d | q ), is usually estimated as follows (Lafferty and Zhai 2001 ): where P ( q | d ) is the query likelihood (Zhai and Lafferty 2001 ) and P ( d ) is the prior of d . Since follows: ability that d is relevant to s (Agrawal et al. 2009 ; Santos et al. 2010b ). Both probabilities can be estimated in a similar way as P ( d | q ). We compute these probabilities using Dirichlet method (Zhai and Lafferty 2001 ).

With these instantiations, it is interesting to see that the diversification method SUM is similar to the existing method WUME (Yin et al. 2009 ) and PCOV is similar to IA-Select and xQuAD methods (Agrawal et al. 2009 ; Santos et al. 2010b ). The main differences between our methods and these existing methods are the subtopic extraction Dirichlet method (Zhai and Lafferty 2001 ). The existing methods estimate P ( s | q ) based on the query suggestion scores from web search engines (Yin et al. 2009 ), relevance between s and q (Agrawal et al. 2009 ), popularity of subtopics in the collection (Santos et al. 2010b ) and the coherence between retrieval results of query and subtopics (Santos et al. 2010b ). They also used different similarity measures to estimate P ( d | s ), i.e., BM25, DPH (Divergence From Randomness) model and language modeling (Agrawal et al. 2009 , Santos et al. 2010b ; Yin et al. 2009 ). The other difference between PCOV and IA-Select is that IA-Select does not consider the relevance score of the documents given the query in their diversification function while PCOV integrates the relevance score in ( 14 ). 5 Analytical comparison of diversification methods In this section, we describe the desirable properties of the diversification method and analytically compare the proposed diversification methods based on these properties. 1. Diminishing return . Intuitively, if the document d covers the subtopics that have been 2. Favoring diversity . The underlying assumption of this property is that we should 3. Novelty emphasis . This property captures the intuition that we should favor where b = cov ( s 2 , d 2 ) -cov ( s 3 , d 3 ).

The requirement of selecting d 3 is diff SQR [ 0. According to the above equation, we can find that the requirement is:
Similarly, we can get the requirement of selecting d 3 in other methods as follows:  X  SUM : b \ 0  X  LOG : b \ cov  X  s 2 ; d 1  X  cov  X  s 3 ; d 3  X   X  PCOV : b \ cov  X  s 2 ; d 1  X  cov  X  s 2 ; d 2  X  LOG , PCOV , EVAL and SQR can select d 3 first while SUM may not. When EVAL varies with different value of a . In the other methods, the upper bound of b in SQR is the largest, the upper bound in PCOV is smaller than that in SQR and the upper bound in LOG is smaller than that in PCOV . Given the data in Table 2 , SUM , LOG will select d 2 before d 3 , PCOV may select either d 2 or d 3 , EVAL will select d 3 when a [ 0.651 and SQR will select d 3 . Therefore, SQR and EVAL are more effective in favoring documents relevant to novel subtopics.

As we discussed in Sect. 4.3 , WUME (Yin et al. 2009 ) is similar to SUM , and IA-Select (Agrawal et al. 2009 ) and xQuAD (Santos et al. 2010b ) are similar to PCOV . These existing methods have the same properties with the corresponding methods proposed in this paper. The reason is that the properties listed above are only related to the relationships between different components in the functions while not related to the method of com-puting each component.

In summary, our analysis suggests that SQR is the most effective diversification method while SUM is the least effective one. Experiment results shown in Sect. 6 are consistent with our analysis. 6 Empirical comparison of diversification methods 6.1 Experiment setup We evaluate the effectiveness of the proposed framework over two standard collections used for the diversity task in the TREC Web track (Clarke et al. 2009a , 2010 ). The first collection is denoted as TREC09 , which contains 50 queries and uses the ClueWeb09 Category B as the document collection. The second collection is denoted as TREC10 , which contains 48 valid queries with judgment files and uses the ClueWeb09 Category A collection as the document collection. The average number of subtopics per query is 4.83 for TREC09 and 4.36 for TREC10. The preprocessing involves stemming with Porter stemmer, stop word removal and deleting spam documents from the collection (Cormack et al. 2010 ). The performance is measured with several official measures including a -nDCG , where a is set to be 0.5, and ERR-IA at two retrieval depths, top 10 and top 20 documents. a -nDCG@10 is used as the primary measure.

The baseline systems include: (1) NoDiversity which ranks documents based on their original relevance scores computed using Dirichlet method (Zhai and Lafferty 2001 )as retrieval function; (2) MMR which uses Maximal Marginal Relevance method (Carbonell and Goldstein 1998 ) to re-rank documents.

We have derived five diversification methods as shown in Table 1 . As discussed in Sect. 4.3 , SUM is similar to the WUME (Yin et al. 2009 ). PCOV is similar to xQuAD (Santos et al. 2010b ) 1 and IA-SELECT (Agrawal et al. 2009 ). The main differences between these two methods and PCOV are that they rely on external resources to extract subtopics and use different methods to instantiate the components in the function. Therefore, PCOV and SUM can be regarded as two strong baselines because they are similar to the state-of-the-art techniques.

The proposed optimization framework assumes that the subtopics of a query have been identified. We conduct two sets of experiments. In the first set of experiments, we use subtopics extracted from the collection to test the performances of the methods in real diversification systems. However, the effectiveness of the subtopic extraction method may affect the performance comparison. We therefore use the real query subtopics for diver-sification in the second set of experiments. 6.2 Performance comparison with extracted subtopics We now report the performance when we extract query subtopics from the collection. The existing diversification methods use the topic mining method (Carterette and Chandar 2009 ) to extract query subtopics from the collection or external resources to extract sub-topics (Santos et al. 2010b ). However, the topic mining method is very time-consuming. External resources, i.e., query suggestions from search engines, are independent of the collection and the subtopics may not represent the relevant information of the query in the collection. Therefore, we use a pattern-based method (Zheng et al. 2011 ) to extract sub-topics of the query. It extracts each group of terms that frequently co-occur in the retrieved documents of the query as a subtopic candidate of the query. It then computes the semantic similarity between the subtopic candidate and the query based on the average mutual information between the subtopic terms and query terms. The top-ranked subtopic can-didates are selected as the subtopics of the query.
 We first compare the performance of different diversification methods when using Dirichlet method (Zhai and Lafferty 2001 ) as retrieval function. The parameter l is set to be 500. Table 3 shows the optimal performance of different diversification based on a -nDCG at different retrieval depths. The Wilcoxon signed rank tests compare the new functions with the existing methods, i.e., NoDiversity, MMR, SUM and PCOV . Table 4 shows the parameter values corresponding to the performances in Table 3 . SUPP is the minimum number of documents that each subtopic candidate must appear (Zheng et al. 2011 ), SUB is the number of extracted subtopics, TERM is the number of terms to use in each subtopic, DOC is the number of re-ranked documents using diversification functions and k is the parameter of functions in Table 1 . EVAL has another parameter a in Equation ( 25 ) whose optimal values are 0.4 on TREC09 and 0.6 on TREC10. These parameter values are the best possible values in each method. We have the following observations:  X  All the subtopic-based diversification methods are effective to diversify search results,  X  SQR outperforms all other diversification methods. This provides empirical supports  X  SUM often performs worse than the other methods. This is expected because SUM does
We also compare our results with the top runs of TREC here. The performance of SQR is better than the 4 th best run of TREC09 whose a -nDCG@10 value is 0.250 on TREC09 collection and is close to the 6 th best run of TREC10 whose ERR-IA@20 value is 0.248. However, they are not directly comparable because we use different baseline functions to retrieve and use different parameter tuning processes. Another observation is that PCOV result in this paper is worse than xQuAD , whose a -nDCG@10 value is 0.282, on TREC09 collection, although they have similar diversification function. This is because that they use different baseline functions, component estimation methods and subtopic extraction methods.

The results in Table 3 are the best performances of each method. We then test the robustness of these methods. Table 5 shows the 5-fold cross-validation results based on a -nDCG@10 on TREC09 and TREC10 collections. It tunes the values of all parameters shown in Table 4 and the parameter a in EVAL . It shows that SQR is more robust than existing functions, i.e., SUM and PCOV , on both collections. What X  X  more, LOG and EVAL also outperform the existing functions on TREC09 and TREC10 collection, respectively. The diversification methods have different diversification properties as we analyzed in Sect. 5 The queries also have different diversification features. For example, some queries effect of different methods in different kinds of queries. We compare the average per-formance of each method in queries with different number of real subtopics and report the results in Table 6 . Queries are divided into 5 bins according to the number of subtopics. An interesting observation is that when the number of subtopics becomes large, i.e., the relevant documents are more diverse, SQR performs the best among all the diversification methods. However, SQR does not perform best when the number of subtopics is 3 or 5. This indicates there is some potential to combine different diversification methods based on the number of subtopics and we leave this as future work.

As discussed earlier, one advantage of the derived diversification methods is that they can be combined with any retrieval functions. In order to evaluate the effectiveness of these diversification methods for different retrieval functions, we use four state-of-the-art retrieval functions and report the optimal performance of five diversification methods for these four retrieval models on both collections in Table 7 . These retrieval functions include pivoted normalization method (Singhal et al. 1996 ), Dirichlet (Zhai and Lafferty 2001 ), axiomatic retrieval function, i.e., F2exp (Fang and Zhai 2005 ), and Okapi (Robertson and Walker 1999 ) which was also applied in xQuAD (Santos et al. 2010b ). When using one retrieval function, we use the same retrieval function to compute components in diversification functions and normalize these scores as the probability in the functions of Table 1 . We tuned the parameters in these retrieval functions. The parameters values are: (1) the values of s are 0.1 on TREC09 collection and 0.2 on TREC10 collection in Pivot; (2) k 1 , b and k 3 are set to be 1.2, 0.75 and 1000, respectively in Okapi; (3) l is set to be 500 in Dirichlet and (4) the values of s are set to be 0.8 on TREC09 and 0.9 on TREC10, and k is set to be 0.35 in F2exp. We can see that SQR is the most robust diversity function and can perform best when using any traditional retrieval models. Note that the diversity performance is closely related to the retrieval function. If we use a stronger baseline that considers factors other than keyword matching, such as the methods used by top runs by TREC participants (Clarke et al. 2009a , 2010 ), the diversity performance would be expected to increase.
 6.3 Performance comparison using real subtopics We also compare different diversification methods using real subtopics. This would allow us to factor out the effects of subtopic quality and directly compare the effectiveness of different diversification methods.

Table 8 shows the optimal performance of all the five diversification methods when we use real subtopics from judgment file as the subtopics of the query and use Dirichlet method (Zhai and Lafferty 2001 ) to retrieve documents. We can see that the performance of these different diversification methods are similar, and SQR performs slightly better than the other four diversification methods. Table 9 shows the cross-validation results of these methods when tuning parameters k and a . We can see that SQR consistently outperform the existing functions, i.e., SUM and PCOV , on both collection. LOG can also outperform existing functions on TREC10 collection.

We also examine the performance sensitivity with respect to parameter values of the diversification functions. All of the derived diversification methods as shown in Table 1 have the same parameter, k , which controls the balance between relevance and diversity scores. In addition, EVAL has one more parameter a , which controls the impact of the individual documents in the coverage function.

Figure 1 shows the performance sensitivity curve for k . When k is 1, all the methods have the same performance since the documents are selected based on only relevance scores. We can also see that, when k is 0, the performance is much better than the performance when k is 1. The reason is that when k is 0, the objective function is only related to the diversity score which is computed based on the relevance score between documents and query subtopics. Since the subtopics are chosen from judgment file, they have real good quality, which would lead to better performance. We can imagine that, when the quality of query subtopics decreases, the performance when k is 0 would be worse than the one shown on the plot. Moreover, it is interesting to see that the lines of SQR and PCOV have different trends with other methods. However, the performances of SUM and EVAL in Fig. 1 are very close to each other when we use real subtopics. The results in Table 9 also shows that EVAL does not work well. These results indicates that the component  X  1 a  X 
Figure 2 shows the results of diversity function EVAL with different values of a . We can see that EVAL is not sensitive to the parameter when a is smaller than 1 and the performance change is small when using different values. The result of EVAL is the same as NoDiversity when a is 1. 7 Conclusions The task of search result diversification is to return a list of documents that are not only relevant to a query but also diverse to cover multiple subtopics of the query. In this paper, we propose to study this problem in a coverage-based optimization framework based on explicit query subtopic modeling. In this framework, we propose to model diversity scores based on the coverage of query subtopics and then discuss three strategies to define coverage functions. Not every function can be coverage function. A coverage function needs to be a submodular function so that we can use a greedy algorithm to iteratively select documents for diversity. Each coverage function corresponds to a diversification method. We derive five diversification methods in this paper, and show that the obtained methods include not only several existing methods, but also new ones which have not been studied before. One of the method, i.e., SQR , not only has the desired favoring diversity and novelty emphasis properties that the existing methods do not have, but also can consistently outperform the existing methods in the experiments.

Our work opens up many interesting future research directions. First, we plan to define more coverage functions in our framework and thus derive effective retrieval functions. For example, we can use better evaluation measures (Sakai and Song 2011 ) to derive diversification functions with desired properties. We can also combine different types of coverage functions (e.g., linear combination) to define more sophisticated ones in our framework. Second, it would be interesting to derive reasonable coverage functions based on a set of desirable properties such as the three we discuss in this paper.
 Appendix Theorem 1 div SUM ( q , D ) is a submodular function with respect to D .
 Proof In order to prove that div SUM ( q , D ) is submodular, we need to prove that 12 holds according to the analysis in Sect. 4.1 Based on 16 , Therefore, div SUM ( q , D ) is a submodular function.
 Theorem 2 div LOG ( q , D ) is a submodular function with respect to D .
 Proof Based on ( 18 ), It is clear that and DIFF SUM ( s , d , A ) -DIFF SUM ( s , d , B ) C 0. cov LOG ( s , D ) is a submodular function. Theorem 3 div PCOV ( q , D ) is a submodular function with respect to D Proof Based on ( 20 ), Thus, cov PCOV ( s , D ) is a submodular function.
 Theorem 4 div SQR ( q , D ) is a submodular function with respect to D Proof Based on ( 23 ), Thus, cov SQR ( s , D ) is a submodular function.
 Theorem 5 div EVAL 1 ( q , D ) is not a submodular function with respect to D Proof Based on ( 24 ), and this may be smaller than 0. Thus, cov EVAL 1 ( s , D ) is not a submodular function. Theorem 6 div EVAL 2 ( q , D ) is a submodular function with respect to D Proof Based on ( 24 ), We know that VAL2 ( s , D ) is a submodular function.
 Theorem 7 div EVAL3 ( q , D ) is a submodular function with respect to D Proof Based on ( 25 ), We can find that  X  1 a  X  P DIFF EVAL3 ( s , d , B ) C 0. Thus, cov EVAL3 ( s , D ) is a submodular function. References
