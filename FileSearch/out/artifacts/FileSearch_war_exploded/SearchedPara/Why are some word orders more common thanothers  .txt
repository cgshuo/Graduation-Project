 Many of the world X  X  languages are sensitive to word order. In these languages, the order in which words are spoken conveys a great deal of the sentence X  X  meaning. The classic English example is the distinction between  X  X og bites man X  and  X  X an bites dog X , which differ in terms of who is biting whom. The so-called  X  X asic X  word order of a language is defined according to the order of three of the principal components of basic transitive sentences: subject (S), verb (V) and object (O). This results in six logically distinct word orders: SOV, SVO, VSO, VOS, OVS and OSV (e.g., English has SVO basic word order). Curiously, the world X  X  order-sensitive languages make use of these six possibilities in an uneven fashion. According to a survey of 402 languages [17], the majority of languages are either SOV (44.78%) or SVO (41.79%). VSO (9.20%) is much less frequent but still significant, and very few languages make use of VOS (2.99%), OVS (1.24%) or OSV (0.00%) as their basic word order. Broadly speaking, the basic pattern appears to be (SOV, SVO) &gt; VSO &gt; (VOS, OVS) &gt; OSV. This non-uniformity is a striking empirical finding that demands some explanation. Unfortunately, most of the explanations that have been offered are either proximate explanations that simply shift the question, or else are circular.
 One of the most straightforward explanations is that the observed word order frequencies may be the consequence of genetically encoded biases toward particular orders, as part of the universal grammar hypothesis; this possibility is considered in [4]. However, this can be only a proximate explanation: why does our genetic endowment happen to bias us in the particular way that it does? And if there is nothing special about the observed distribution  X  if it is not an adaption to the environment  X  why have thousands of years of adaption and genetic drift not blurred it into something closer to uniformity? A similar objection can be made against the proposal that all languages which are alive today de-scend from a single common ancestor, and that this proto X  X anguage used SOV word order [8], ex-plaining the observation that SOV is the most common word order today. If there is nothing special about SOV, why has random drift (this time in language evolution, not human genetic evolution) not more significantly changed the word order distribution from its ancient form? Furthermore, it is clear that ancient SOV languages must have changed into SVO languages much more frequently into than, say, VOS languages in order to arrive at the current state of affairs. Common descent from SOV cannot explain this by itself.
 Another explanation seeks to derive word order frequencies as a consequence of more fundamental or general linguistic principles. Three such principles are presented in [17]: the  X  X heme-first princi-ple X ,  X  X erb-object bonding X  and the  X  X nimate-first principle X . These principles do an excellent job of explaining the observed word order frequencies; the frequency of each word order is proportional to the number of the principles which that word order permits to be realized (all three principles are realized in SOV and SVO, two are realized in VSO, one in VOS and OVS, and none in OSV). How-ever, these principles are primarily motivated by the fact that a large body of cross-linguistic data is consistent with them. Without a deeper justification, they are, in essence, a useful recharacterization of the data; to offer them as explanations of patterns in that data is circular. In other words, it is not clear why these principles work.
 In this paper we propose a novel explanation for the observed distribution of word orders across languages, based on uniform information density (UID). The UID hypothesis [13, 10] suggests that language producers unconsciously endeavor to keep the rate of information transmission as close to constant as possible when speaking. We use the term  X  X nformation X  here in its information-theoretic sense of reduction of entropy (uncertainty) of a random variable (where the random variable is the underlying meaning of an utterance). Conveying information via speech with a uniform information density represents an optimal solution to the computational problem of conveying information over a noisy channel in a short time with low probability of error. A listener X  X  comprehension of an utterance is made more difficult if a syllable, word or clause which carries a lot of information is lost due to ambient noise or problems with articulation or perception. The most error resistant strategy is therefore to convey minimal information with each unit of speech. Unfortunately, this leads to other problems  X  namely, that it will take excessive time to convey any meaningful quantity of information. The best trade off between time efficiency and error resistance is to spread information content as equally as possible across units and have each unit carry as much information as it can without exceeding the threshold for error correctability (the channel capacity). Also, UID minimizes the difficulty involved in online sentence processing, assuming that the difficulty of processing a speech unit increases superlinearly with that unit X  X  surprisal [13].
 The UID hypothesis is supported by a range of empirical evidence. It suggests that speakers should attempt to slow down the rate at which information is conveyed when unexpected, high entropy content is being discussed, and increase the rate when predictable, low entropy content is being discussed. This prediction is supported by findings indicating that certain classes of words [1] and syllables [3] are spoken more slowly in unexpected contexts. In addition, analysis of corpus data suggests that the entropy of sentences taken out of context is higher for sentences further into a body of text [7, 12]. Furthermore, the use of both optional contractions (e.g.,  X  X ou are X  vs.  X  X ou X  X e X ) [2] and optional function words in relative clauses (e.g.,  X  X ow big is the house that you live in? X  vs.  X  X ow big is the house you live in? X ) [14, 11] appears to be affected by information density considerations, with contractions used less often when the relative clause is unexpected. We propose that the basic word order of a language influences the average uniformity of information density for sentences in that language, and that a preference for languages that are closer to the UID ideal can explain some of the structure in the observed distribution over basic word orders. The layout of the rest of the paper is as follows. In Section 2 we describe the underlying conceptual model and terminology using a simple illustrative example. In Section 3, This work is based on a simple probabilistic model of language production. We assume that lan-guages are grounded in a world , consisting of objects (elements of a set O ) and actions (which are binary relations between objects, and elements of a set R , such that if r  X  X  then r  X  X  X O ). An Events in the world are generated probabilistically in a sequential fashion, as independent identically distributed draws from a probability distribution P over the set of events O X R X O . We assume that a language consists of nouns (each of which corresponds to a unique object) and verbs (each of which corresponds to a unique action). Utterances are generated from events by combining the three relevant words in one of the six possible orders. Each utterance is therefore three words long (there are no function words in the model). This defines a probabilistic generative model for three-word utterances.
 To make this idea more concrete, we construct a simple toy world consisting of thirteen objects and two relations. Five of the objects represent individual people (A LICE , B OB , E VE , M ALLORY , T
RENT ) and the other eight represent items which are either food (A PPLE , B READ , C AKE , R ICE ) or drink (C OFFEE , C OLA , J UICE , W ATER ). The two relations are E AT and D RINK , so that the events in this world represent particular people eating or drinking particular items (e.g. (A LICE , D
RINK , C OFFEE )). Impossible events (e.g., (C OFFEE , D RINK , A LICE )) are given zero probability in the event distribution P . A diagrammatic representation of all the non-zero probabilities of P is available in the supplementary material, but the salient features of the example are as follows: each of the five people eat and drink equally often, and equally as often as each other; nobody drinks foods or eats drinks; and each person has their own particular idiosyncratic distribution over which foods they prefer to eat and which drinks they prefer to drink.
 What is the link between word order and information density in this toy world? Consider a listener who learns about events in this toy world by hearing three-word utterances (such as  X  X lice eats apples X  or  X  X ob drinks coffee X ), one word at a time. Until they have heard all three words in the utterance, there will generally remain some degree of uncertainty about what the event is, with the uncertainty decreasing as each word is heard. Formally, the event underlying an utterance is a random variable, and the listener X  X  uncertainty is represented by the entropy of that random variable. Before any words are spoken, the observer X  X  uncertainty is given by the entropy of the event distri-bution (which we refer to as the base entropy and denote H 0 ): where the sum is taken over all possible events in the world. After the first word, the observer X  X  uncertainty about the event is reduced, and now corresponds to the entropy of one of the condi-corresponds to the action (VSO or VOS word order), the person (SVO or SOV word order) or the food/drink (OVS or OSV word order). Similarly, after the second word, the uncertainty is the again on word order. After the third word the event is uniquely determined and the entropy is zero. This means that for any particular event, the six different choices of word order each define a differ-ent monotonically decreasing sequence of intermediate entropies, with the first point in the sequence always being H 0 and the final point always being zero. Equivalently, the different choices of word order result in different distributions of the total information content of a sentence amongst its con-stituent words. We call sequences of entropies ( H 0 , H 1 , H 2 , 0) entropy trajectories , and sequences of information ( I 1 = H 0  X  H 1 , I 2 = H 2  X  H 1 , I 3 = H 2 ) information profiles . Figure 1 shows the entropy trajectories and corresponding information profiles for the event (A LICE , E AT A PPLE ) in our toy world, for three different word orders. The figure demonstrates the correspondence between trajectories and profiles, as well as the dependency of both on word order. Note that in the figure we have normalized entropies and informations, so that H 0 = 1 .
 If we make the simplifying assumption that all words are of equal length 1 , the UID hypothesis base entropy to the eventual zero entropy, or, equivalently, that the ideal shape of an information profile is for each word to convey one third of the total information. Figure 1 demonstrates that some trajectories are better realizations of this ideal than others. For example, in our toy world the entropy trajectories for the word orders SOV, OSV and OVS (two of which are pictured in Figure 1) are perfectly horizontal at various points (equivalently, some words carry zero information) because Figure 1: The entropy trajectories and corresponding information profiles for the event (A LICE , E
AT , A PPLE ) in our toy world, for three different word orders. Dotted lines indicate the ideal trajectory and profile according to the UID hypothesis. Observe that word orders in which the object preceeds the verb have significant  X  X roughs X  in their information profiles, making them far from ideal. This pattern arises because of the event structure in our toy world; our question is what word orders are optimal given real-world event structure. knowledge of the object in this world uniquely determines the verb (since foods are strictly eaten and drinks are strictly drunk). Thus, any word order that places O before V renders the verb entirely uninformative, in significant conflict with the UID hypothesis.
 To formalize the intuitive notion of distance from the UID ideal we define the UID deviation score D ( I ) of any given information profile I = ( I 1 , I 2 , I 3 ) . D ( I ) is given by the formula: It is easy to verify that the UID ideal information profile, with I 1 = I 2 = I 3 , has a deviation score of zero, and the least-ideal profile, in which all information is conveyed by a single word, has a deviation score of 1.
 The UID deviation score allow us, for each event in the model world, to produce both an ordering of the word orders from  X  X ost UID-like X  to  X  X east UID-like X , as well as a quantitative measure of the extent to which each word order approaches uniform information density. We can straightforwardly calculate a mean deviation score for the entire model world, by summing the scores for each indi-vidual event and weighting by that event X  X  probability according to the event distribution P . This lets us assess the extent to which each word order is UID-suited to a given world. For our toy world, the ordering of word orders from lowest to highest mean deviation score is: VSO, VOS, SVO, OVS, SOV, OSV.
 Of course, our toy world is a highly contrived example, and so there is no reason to expect it to produce the observed cross-linguistic distribution of word orders. This is because we constructed the artificial P distribution to be pedagogically useful, not to reflect the real-world distribution of events. The toy example is intended only as a demonstration of the core idea underlying our hypothesis: that different choices of word order map the same probabilistic structure of the world ( P ) onto different information profiles. Since these profiles have differing levels of information density uniformity, the UID hypothesis implies a preference ranking of word orders.
 What are the mean deviation scores when the event distribution P more accurately approximates re-ality? Does the preferred ranking of word orders implied by the UID hypothesis reflect the observed cross-linguistic distribution of word orders? We investigate these questions in the rest of the paper. Our work above implies that a particular word ordering in a language is good to the extent that it produces minimal UID deviation scores for events in the world. Accordingly, it would be ideal to assess the optimality of a particular word ordering with respect to the true distribution over  X  X sy-chologically meaningful X  events in the everyday environment. Although we do not have access to this distribution, we may be able to construct sensible approximations. One option is to assume that spontaneous speech is informative about event probabilities  X  that the probability with which speak-ers discuss an event is roughly proportional to the actual frequency or psychological importance of that event. Guided by this assumption, in this section we estimate P on the basis of child-directed Figure 2: Distribution of information across words for the world instantiated from an English corpus Figure 3: Distribution of information across words for the world instantiated from a Japanese corpus speech corpora in two languages, English and Japanese. We use child-directed speech even though the UID hypothesis applies equally well to adult speakers for two reasons: because child-directed speech is more amenable to the particular analysis we provide (which requires relatively simple sen-tences), and because children learn their language X  X  basic word very quickly and accurately [9, 5], suggesting that any aspect of primary linguistic data relevant to word order learning must be present in simple child-directed speech.
 As our source of English data, we take the  X  X dam X  transcripts from the Brown corpus [5] in the CHILDES database [15]. From this data we extract all of the child-directed utterances involving a random subset of the singly transitive verbs in the corpus (a total of 544 utterances). The subjects and objects of these utterances define the set O and the verbs define the set R . In our analysis, we treat each utterance as a distinct event, setting the probability of an event in P to be proportional to the number of times the corresponding utterance occurs in the corpus. Thus the event distribution P is a measure of the probability that speakers of the language choose to discuss events (rather than their frequency in the real world). For simplicity, we ignore adjectives, plurality, tense, and so forth: for instance, the utterances  X  X he black cat sat on the mat X  and  X  X he cats are sitting on the soft mat X  would both be mapped to the same event, (C AT , S IT , M AT ). Utterances involving pronouns which were considered likely to refer to a wide range of objects across the corpus (such as  X  X t X ,  X  X his X , etc.) were discarded, while those involving pronouns which in the context of the discourse could be expected to refer to a small set of objects (such as  X  X e X  or  X  X he X ) were retained.
 Figure 2 shows the distribution of information amongst words (summarizing all of the model world X  X  information profiles) for all six word orders according to the event distribution P derived from the  X  X dam X  transcripts. The mean deviation scores for the six word orders are (from lowest to highest) VSO (0.38), SVO (0.41), VOS (0.48), SOV (0.64), OSV (0.78), OVS (0.79).
 To guard against the possibility that these results are a by-product of the fact that English has basic word order SVO, we repeat the method discussed above using utterances involving singly transi-tive verbs taken from the  X  X sato X ,  X  X anami X  and  X  X omito X  transcripts in the MiiPro corpus of the CHILDES database, which is in Japanese (basic order SOV). From these transcripts we retreive 134 utterances. The distribution of information amongst words for the event distribution derived from the Japanese transcripts are shown in Figure 3. The mean deviation scores are SVO (0.66), VSO (0.71), SOV (0.72), VOS (0.72), OSV (0.82), OVS (0.83). This is not precisely the ranking recovered from the English corpus, but there are clear similarities, which we discuss later. In the previous analyses, the event distribution P was estimated on the basis of linguistic input. While this is sensible in many respects, it blurs the distinction between the frequency of events in Table 1: Objects and relations in our experiment X  X  model world. Asterisks denote  X  X ctor X  status. Table 2: Most and least probable completions of event frames according to experimentally deter-mined event distribution P the world and the frequency with which speakers choose to discuss those events. In one version of the UID hypothesis, we would expect that word order would be optimal with respect to the latter,  X  X peaker-weighted X  frequencies. We refer to this as the  X  X eak X  hypothesis since it only requires that a language be  X  X nternally X  consistent, insofar as the word order is expected to be optimal with respect to the topics spoken about. However, there is also a  X  X trong X  version of the hypothesis, which states that the language must also be optimal with respect to the perceived frequencies of events in the external world. To test the strong version of the UID word order hypothesis, it is not valid to rely on corpus analysis. Accordingly, in this section we present the results of an experiment designed to measure people X  X  perceptions regarding which events are most likely.
 Our experiment consists of three parts. In the first part we identify the objects O and relations R for the model world based on the first words learned by English-speaking children, on the assumption that those words would reflect the objects and relations that are highly salient. The MacArthur Communicative Development Inventory [6] provides a list of those words, along with norms for when they are learned. We identified all of the words that were either singly-transitive verbs or nouns that were potential subjects or objects for these verbs, yielding 324 nouns and 81 verbs. The only transformation we made to this list was to replace all nouns that referred to specific people (e.g.,  X  X ommy X  or  X  X randpa X ) with a single noun  X  X erson X . In order to limit the total number of possible events to a number tractable for parts two and three of the experiment, we then identified the 40 objects and 10 relations 2 uttered by the highest percentage of children below the age of 16 months; these comprise the sets O and R . The objects and relations are shown in Table 1. The 40 objects and 10 relations in our world define a total of 16,000 events, but the overwhelming majority of the events in the world are physically impossible (e.g., (T ELEVISION , D RINK , C AT )) and thus should receive a probability of 0. The goal of the second part of the experiment was subjects were non-actors to zero, leaving 6,800 events. To identify which of these events were still impossible, we had two participants 3 judge the possibility or impossibility of each, obtaining two judgements for each event. When both judges agreed that an event was impossible, its probability was set to zero; if they disagreed, we solicited a third judgement and set the event probability to zero if the majority agreed that it was impossible. At the end of this process, a total of 2,536 events remained. Subsequent analysis revealed that many participants had interpreted the noun O UTSIDE as an adverb in events such as (B EAR , E AT , O UTSIDE ), leading to events which should properly Figure 4: Distribution of information across words for the world instantiated from the experimentally produced event distribution. have been considered impossible being classed as possible; we therefore set all events involving the noun O UTSIDE which did not involve the verb S EE to also be impossible. This reduced the number of events to 2,352.
 In the final part of the experiment, we derived a probability distribution over the remaining, possi-ble events using the responses of participants to a large number of judgement tasks. In each task, participants were presented with a pair of events and asked to indicate which of the two events they considered most probable. Full details of this part of the experiment are available in the supple-mentary material. Table 2 shows the most and least probable completions of several event frames according to the distribution P produced by our experiment. The completions are in line with com-mon sense, although some of the least probable completions are in fact physically impossible (e.g. (C AT , D RINK , B ED )), suggesting that the filtering in part two was not quite perfect.
 We now analyse the P distribution we have estimated. The distribution of information among words is shown in Figure 4 and the mean deviation scores are VSO (0.17), SVO (0.18), VOS (0.20), SOV (0.23), OVS (0.23), OVS (0.24). On the basis of two corpora of child-directed speech, in different languages, and an experiment, we have derived three different event distributions which are assumed to represent the important features of the probabilistic structure of the physical world. From these different distributions we derive three different preferential rankings of word orders according to the UID hypothesis. From the English corpus, we get VSO &gt; SVO &gt; VOS &gt; SOV &gt; OSV &gt; OVS; from the Japanese corpus, we get SVO &gt; VSO &gt; SOV = VOS &gt; OSV &gt; OVS; from the experiment, we get VSO &gt; SVO &gt; VOS &gt; SOV = OVS &gt; OSV. While these three rankings are not in perfect agreement, there is some degree of common structure. All three rankings are compatible with the partial ranking (SVO, VSO) &gt; (SOV, VOS) &gt; (OVS, OSV). How does this compare with the empirically observed ranking (SOV, SVO) &gt; VSO &gt; (VOS, OVS) &gt; OVS? The strongest empirical regularity regarding word order frequency -that object-first word orders are extremely rare -coincides with our most robust finding: object-first word orders lead to the least uniform information density in all three of our estimated event distributions. These orders together account for less than 2% of the world X  X  word order-sensitive languages, and in all our models have deviation scores that are notably greater than the deviation scores of the other word orders. What is the reason for this effect? As the profiles in Figures 2, 3 and 4 indicate, object-first word orders deviate from uniformity because the first word (the object) carries disproportionate amount of information. This seems to occur because many objects are predictive of very few subjects or verbs. For instance, hearing the object word  X  X ater X  implies only a few possibilities for verbs (e.g.,  X  X rink X ), which in turn restricts the subjects (e.g. to living things). By contrast, hearing the verb  X  X rink X  implies many possibilities for objects (e.g.,  X  X ater X ,  X  X offee X ,  X  X ola X ,  X  X uice X , etc.). There are further points of agreement between the rankings produced by our analyses and the em-pirical data. All three of our estimated event distributions lead to word order rankings in which VSO is ranked more highly than VOS, which is in agreement with the data. In fact, in all of our rankings, SVO and VSO occupy the two highest positions (though their relative position varies), consistent with the fact that these word orders occupy the second and third highest positions in the empirical ranking respectively, and are two of the only three word orders which appear with any appreciable frequency.
 The greatest apparent discrepancy between the rankings produced by our analyses and the empirical data is the fact that SOV word order, which occurs frequently in real languages, appears to be only moderately compatible with the UID hypothesis. One possible explanation for this is that some other factor besides UID-compatibility has influenced the distribution of word orders, and this factor may favour SOV sufficiently to lift it to the top or equal-top place in a combined ranking. Another possibility is to combine the idea we saw earlier of common descent from SOV with the idea that word order change away from SOV is influenced by the UID hypothesis. This explanation could also lift SOV word order to a higher position in the word order ranking.
 To what extent are our rankings consistent with the the theme-first principle (TFP), verb-object bonding (VOB) and animate-first principle (AFP) principles of [17], which perfectly explain the empirical ranking? The three orders that permit the greatest realization of the TFP and AFP prin-ciples are SOV, SVO, and VSO. We note that two of these orders, SVO and VSO, are consistently ranked highest in our results, and the third, SOV, is typically not too far behind. In fact, with the event distribution derived from the Japanese corpus, SOV is in equal third place with VOS. This suggests that perhaps the UID word order hypothesis is unable to provide a complete explanation of all of the word order rankings, but is able provide a sensible justification for the TFP and/or AFP. A full consideration of the effects of word order on information density should not limit itself only to the considerations made in this paper, and so our results here must be considered only prelim-inary. For instance, we have given no consideration to sentences involving intransitive verbs (SV sentences), sentences without an explicit subject (VO sentences), or sentences involving ditransitive verbs (SVO 1 O 2 sentences). A word order optimal for one of these sentence classes may not be opti-mal for others, so that the question of how to meaningfully combine the results of separate analyses becomes a central challenge in such an extended study. Furthermore, a number of other word order parameters beyond basic word order may have a significant effect on information density, such as whether a language uses prepositions or postpositions, or the relative position of nouns and adjec-tives or nouns and relative clauses. For instance, consider the order of nouns and adjectives. The utterance  X  X  ate the... X  can be completed by any edible object, but  X  X  ate the red... X  only by those objects which are both edible and red. Thus, adjectives which preceed unexpected nouns can be used to  X  X mooth out X  what might otherwise be sudden spikes in information density. Adjectives which come after nouns cannot do this. Several correlations and rules are known to exist between various word order parameters, and it is possible that these effects may be able to be explained in terms of information density.
 On the whole, while the word order rankings recovered from our analyses do not perfectly match the empirically observed ranking, they are in much better agreement with observation than one would expect if a preference for UID had played no role whatsoever. Furthermore, the particular pattern of what our rankings do and do not explain, and the ways our two rankings differ, are consistent with a weaker hypothesis that UID may be able to provide a principled cognitive explanation for the theme-first and/or animate-first principles of earlier work. It is possible that the discrepancies which do exist between our results and the empirical distribution could be explained by a combination of more and richer data and consideration of additional word order parameters. It is also the case that even if information theoretic concerns have exerted a significant influence on language evolution, there is no reason to expect them to have been the only such influence: genetic and social factors as well additional cognitive constraints may have played some role as well, so that the UID hypothesis alone need not explain all the observed regularity. Regardless, we have shown that information-theoretic principles can explain several aspects of the empirical distribution of word orders, and most robustly explains the most pronounced of these aspects: the nearly complete lack of object-first languages. Moreover, they do so on independently justified, general cognitive principles, and as such represent a significant advance in our understanding of word order. DJN was supported by an Australian Research Fellowship (ARC grant DP-0773794). Kirsty Maurits assisted significantly in the translation of utterances from the Japanese transcripts. [1] Alan Bell, Daniel Jurafsky, Eric Fosler lussier, Cynthia Girand, Michelle Gregory, and Daniel [2] Austin F. Frank and T. Florian Jaeger. Speaking Rationally: Uniform Information Density as [3] M. Aylett and A. Turk. The Smooth Signal Redundancy Hypothesis: A functional explana-[4] Ted Briscoe. Grammatical Acquisition: Inductive Bias and Coevolution of Language and the [5] R. Brown. A first language . Harvard University Press, Cambridge, MA, 1973. [6] Larry Fenson, Philip S. Dale, J. Steven Reznick, Elizabeth Bates, Donna J. Thal, and Stephen J. [7] D. Genzel and E. Charniak. Entropy rate constancy in text. In In Proceedings of ACL , 2002. [8] Talmy Giv  X  on. On Understanding Grammar . Academic Press, New York, NY, 1979. [9] R. Hirsh Pasek, K.and Golinkoff. The origins of grammar: Evidence from early language [10] T. F. Jaeger. Redundancy and syntactic reduction in spontaneous speech . Unpublished doctoral [11] T. Florian Jaeger. Redundancy and reduction: Speakers manage syntactic information density. [12] F. Keller. The entropy rate principle as a predictor of processing effort: An evaluation against [13] R. Levy. Probabilistic Models of Word Order and Syntactic Discontinuity . PhD thesis, Stanford [14] R. Levy and T. F. Jaeger. Speakers optimize information density through syntactic reduction. [15] B. MacWhinney. The CHILDES project : Tools for analyzing talk . Lawrence Erlbaum Asso-[16] B. Miller, P. Hemmer, M. Steyvers, and M.D. Lee. The wisdom of crowds in rank ordering [17] Russel S. Tomlin. Basic word order: functional principles . Croom Helm, 1986.
