 Images of natural environments contain a rich diversity of s patial structure at both coarse and fine scales. We would like to build systems which can automatical ly discover the visual categories (e.g., foliage, mountains, buildings, oceans) which compo se such scenes. Because the  X  X bjects X  of interest lack rigid forms, they are poorly suited to tradi tional, fixed aspect detectors. In simple cases, topic models can be used to cluster local textural ele ments, coarsely representing categories via a bag of visual features [ 1 , 2 ]. However, spatial structure plays a crucial role in genera l scene interpretation [ 3 ], particularly when few labeled training examples are avai lable.
 One approach to modeling additional spatial dependence beg ins by precomputing one, or several, segmentations of each input image [ 4  X  6 ]. However, low-level grouping cues are often ambiguous, and fixed partitions may improperly split or merge objects. M arkov random fields (MRFs) have been used to segment images into one of several known object c lasses [ 7 , 8 ], but these approaches require manual segmentations to train category-specific ap pearance models. In this paper, we instead develop a statistical framework for the unsupervised discovery and segmentation of visual object categories. We approach this problem by considering sets of images depicting related natural scenes (see Fig. 1 (a)). Using color and texture cues, our method simultaneous ly groups dense features into spatially coherent segments, and refines these partiti ons using shared appearance models. This extends the cosegmentation framework [ 9 ], which matches two views of a single object instance, to simultaneously segment multiple object categories across a large image database. Some recent work has pursued similar goals [ 6 , 10 ], but robust object discovery remains an open challenge. Our models are based on the Pitman X  X or (PY) process [ 11 ], a nonparametric Bayesian prior on infinite partitions. This generalization of the Dirichlet process (DP) leads to heavier-tailed, power law distributions for the frequencies of observed objects o r topics. Using a large database of manual scene segmentations, Sec. 2 demonstrates that PY priors closely match the true distribu tions of natural segment sizes, and frequencies with which object ca tegories are observed. Generalizing the hierarchical DP [ 12 ], Sec. 3 then describes a hierarchical Pitman X  X or (HPY) mixture model which shares  X  X ag of features X  appearance models among rela ted scenes. Importantly, this approach coherently models uncertainty in the number of object categories and instances. As described in Sec. 4 , we use thresholded Gaussian processes to link assignments of features to regions, and thereby produce smooth, coherent segments. Si mulations show that our use of contin-uous latent variables captures long-range dependencies ne glected by MRFs, including intervening contour cues derived from image boundaries [ 13 ]. Furthermore, our formulation naturally leads to an efficient variational learning algorithm, which autom atically searches over segmentations of varying resolution. Sec. 5 concludes by demonstrating accurate segmentation of compl ex images, and discovery of appearance patterns shared across natural scenes. To better understand the statistical relationships underl ying natural scenes, we analyze manual seg-mentations of Oliva and Torralba X  X  eight categories [ 3 ]. A non-expert user partitioned each image into a variable number of polygonal segments corresponding to distinctive objects or scene elements (see Fig. 1 (a)). Each segment has a semantic text label, allowing study of object co-occurrence fre-quencies across related scenes. There are over 29,000 segme nts in the collection of 2,688 images. 1 2.1 Stick Breaking and Pitman X  X or Processes The relative frequencies of different object categories, a s well as the image areas they occupy, can be P k =1  X  k = 1 , denote the probability mass associated with each subset. I n nonparametric Bayesian statistics, prior models for partitions are often defined vi a a stick-breaking construction: This Pitman X  X or (PY) process [ 11 ], denoted by  X   X  GEM(  X  a ,  X  b ) , is defined by two hyperparam-eters satisfying 0  X   X  a &lt; 1 ,  X  b &gt;  X   X  a . When  X  a = 0 , we recover a Dirichlet process (DP) with concentration parameter  X  b . This construction induces a distribution on  X  such that subsets with more mass  X  k typically have smaller indexes k . When  X  a &gt; 0 , E [ w k ] decreases with k , and the resulting partition frequencies follow heavier-tailed, power law distributions.
 While the sequences of beta variables underlying PY processe s lead to infinite partitions, only a random, finite subset of size K  X  = { k |  X  k &gt;  X  } will have probability greater than any threshold  X  . Implicitly, nonparametric models thus also place priors on the number of latent classes or objects. 2.2 Object Label Frequencies Pitman X  X or processes have been previously used to model the well-known power law behavior of text sequences [ 15 , 16 ]. Intuitively, the labels assigned to segments in the natur al scene database have similar properties: some (like sky , trees , and building ) occur frequently, while others ( rainbow , lichen , scaffolding , obelisk , etc.) are more rare. Fig. 1 (b) plots the observed frequencies with which unique text labels, sorted from most to least frequent, occu r in two scene categories. The overlaid quantiles correspond to the best fitting DP and PY processes, with parameters ( X   X  a ,  X   X  b ) estimated producing power law behavior which accurately predicts obs erved object frequencies. In contrast, the closest fitting DP model ( X   X  a = 0) significantly underestimates the number of rare labels. We have quantitatively assessed the accuracy of these model s using bootstrap significance tests [ 17 ]. The PY process provides a good fit for all categories, while th ere is significant evidence against the DP in most cases. By varying PY hyperparameters, we also capt ure interesting differences among scene types: urban, man-made environments have many more un ique objects than natural ones. 2.3 Segment Counts and Size Distributions We have also used the natural scene database to quantitative ly validate PY priors for image parti-tions [ 17 ]. For natural environments, the DP and PY processes both pro vide accurate fits. However, some urban environments have many more small objects, produ cing power law area distributions (see Fig. 1 (c)) better captured by PY processes. As illustrated in Fig. 1 (d), PY priors also model uncertainty in the number of segments at various resolutions.
 While power laws are often used simply as a descriptive summar y of observed statistics, PY pro-cesses provide a consistent generative model which we use to develop effective segmentation algo-rithms. We do not claim that PY processes are the only valid pr ior for image areas; for example, log-normal distributions have similar properties, and may also provide a good model [ 18 ]. How-ever, PY priors lead to efficient variational inference algo rithms, avoiding the costly MCMC search required by other segmentation methods with region size pri ors [ 18 , 19 ]. We now develop hierarchical Pitman X  X or (HPY) process models for visual scenes. We first describe a  X  X ag of features X  model [ 1 , 2 ] capturing prior knowledge about region counts and sizes, a nd then extend it to model spatially coherent shapes in Sec. 4 . Our baseline bag of features model directly generalizes the stick-breaking representation of the hier archical DP developed by Teh et al. [ 12 ]. N-gram language models based on HPY processes [ 15 , 16 ] have somewhat different forms. 3.1 Hierarchical Pitman X  X or Processes Each image is first divided into roughly 1,000 superpixels [ 18 ] using a variant of the normalized cuts spectral clustering algorithm [ 13 ]. We describe the texture of each superpixel via a local text on histogram [ 20 ], using band-pass filter responses quantized to W t = 128 bins. Similarly, a color histogram is computed by quantizing the HSV color space into W c = 120 bins. Superpixel i in Figure 2 contains a directed graphical model summarizing our HPY mod el for collections of lo-cal image features. Each of the potentially infinite set of gl obal object categories occurs with fre-quency  X  k , where  X   X  GEM(  X  a ,  X  b ) as motivated in Sec. 2.2 . Each category k also has an asso-the W t texture and W c color bins, respectively. These parameters are regularize d by Dirichlet priors  X  k  X  Dir(  X  t ) ,  X  c k  X  Dir(  X  c ) , with hyperparameters chosen to encourage sparse distribu tions. Consider a dataset containing J images of related scenes, each of which is allocated an infini te set of potential segments or regions . As in Sec. 2.3 , region t occupies a random proportion  X  jt of the area in image j , where  X  j  X  GEM(  X  a ,  X  b ) . Each region is also associated with a particular global object category k jt  X   X  . For each superpixel i , we then independently select a region t ji  X   X  j , and sample features using parameters determined by that segmen t X  X  global object category: As in other adaptations of topic models to visual data [ 8 ], we assume that different feature channels vary independently within individual object categories an d segments. Figure 2: Stick-breaking representation of a hierarchical Pitman X  X or (HPY) mod el for J groups of features. 3.2 Variational Learning for HPY Mixture Models To allow efficient learning of HPY model parameters from larg e image databases, we have devel-oped a mean field variational method which combines and exten ds previous approaches for DP mixtures [ 21 , 22 ] and finite topic models. Using the stick-breaking represen tation of Fig. 2 , and a factorized variational posterior, we optimize the followi ng lower bound on the marginal likelihood: q ( k , t , v , w ,  X  ) = Here, H ( q ) is the entropy. We truncate the variational posterior [ 21 ] by setting q ( v jT = 1) = 1 for each image or group, and q ( w K = 1) = 1 for the shared global clusters. Multinomial assignments update equations. To avoid bias, we sort the current sets of i mage segments, and global categories, in order of decreasing aggregate assignment probability af ter each iteration [ 22 ]. We now generalize the HPY image segmentation model of Fig. 2 to capture spatial dependencies. For simplicity, we consider a single-image model in which fe atures x i are assigned to regions by indicator variables z i , and each segment k has its own appearance parameters  X  k (see Fig. 3 ). As in Sec. 3.1 , however, this model is easily extended to share appearance parameters among images. 4.1 Coupling Assignments using Thresholded Gaussian Proce sses Consider a generative model which partitions data into two c lusters via assignments z i  X  X  0 , 1 } sampled such that P [ z i = 1] = v . One representation of this sampling process first generate s a Gaussian auxiliary variable u i  X  X  (0 , 1) , and then chooses z i according to the following rule: Here,  X ( u ) is the standard normal cumulative distribution function (CDF). Since  X ( u i ) is uniformly We adapt this idea to PY processes using the stick-breaking r epresentation of Eq. ( 1 ). In particu-lar, we note that if z i  X   X  where  X  k = v k v ability of choosing cluster k , given that clusters with indexes  X  &lt; k have been rejected. Combining Figure 3: A nonparametric Bayesian approach to image segmentation in which thresh olded Gaussian processes this insight with Eq. ( 4 ), we can generate samples z i  X   X  as follows: As illustrated in Fig. 3 , each cluster k is now associated with a zero mean Gaussian process (GP) u k , and assignments are determined by the sequence of thresholds in Eq. ( 5 ). If the GPs have identity covariance functions, we recover the basic HPY model of Sec. 3.1 . More general covariances can be used to encode the prior probability that each feature pai r occupies the same segment. Intuitively, the ordering of segments underlying this dependent PY model is analogous to layered appearance models [ 23 ], in which foreground layers occlude those that are farther from the camera. To retain the power law prior on segment sizes justified in Sec . 2.3 , we transform priors on stick proportions v k  X  Beta(1  X   X  a ,  X  b + k X  a ) into corresponding random thresholds: Fig. 2 illustrates the threshold distributions corresponding to several different PY stick-breaking priors. As the number of features N becomes large relative to the GP covariance length-scale, t he proportion assigned to segment k approaches  X  k , where  X   X  GEM(  X  a ,  X  b ) as desired. 4.2 Variational Learning for Dependent PY Processes Substantial innovations are required to extend the variati onal method of Sec. 3.2 to the Gaussian pro-cesses underlying our dependent PY processes. Complicatio ns arise due to the threshold assignment process of Eq. ( 5 ), which is  X  X tronger X  than the likelihoods typically used i n probit models for GP classification, as well as the non-standard threshold prior of Eq. ( 6 ). In the simplest case, we place surfaces q ( u ki ) = N ( u ki | ki ,  X  ki ) , and exploit the following key identities:
P q [ u ki &lt;  X  v k ] =  X  The first expression leads to closed form updates for Dirichl et appearance parameters q (  X  k |  X  k ) , while the second evaluates the beta normalization constant s in Eq. ( 6 ). We then jointly optimize conjugate gradient (CG) with line search. For details and fu rther refinements, see [ 17 ]. Figure 4: Five samples from each of four prior models for image partitions (color coded). Top Left: Nearest 4.3 Related Work Recently, Duan et. al. [ 24 ] proposed a generalized spatial Dirichlet process which links assignments via thresholded GPs, as in Sec. 4.1 . However, their focus is on modeling spatial random effects for prediction tasks, as opposed to the segmentation tasks w hich motivate our generalization to PY processes. Unlike our HPY extension, they do not consider ap proaches to sharing parameters among related groups or images. Moreover, their basic Gibbs sampl er takes 12 hours on a toy dataset with 2,000 observations; our variational method jointly segmen ts 200 scenes in comparable time. Several authors have independently proposed a spatial mode l based on pointwise, multinomial logis-tic transformations of K latent GPs [ 25  X  27 ]. This produces a field of smoothly varying multinomial distributions  X   X  i , from which segment assignments are independently sampled as z i  X   X   X  i . As shown in Fig. 4 , this softmax construction produces noisy, less spatially coherent part itions. Moreover, its bias towards partitions with K segments of similar size is a poor fit for natural scenes. A previous nonparametric image segmentation method defined its prior as a normalized product of a DP sample  X   X  GEM(0 ,  X  ) and a nearest neighbor MRF with Potts potentials [ 28 ]. This construction effectively treats log  X  as the canonical , rather than moment, parameters of the MRF, and does not produce partitions whose size distribution matches GEM(0 ,  X  ) . Due to the phase transition which occurs with increasing potential strengt h, Potts models assign low probability to realistic image partitions [ 29 ]. Empirically, the DP-Potts product construction seems to have similar issues (see Fig. 4 ), although it can still be effective with strongly informat ive likelihoods [ 28 ]. Figure 5 shows segmentation results for images from the scene catego ries considered in Sec. 2 . We compare the bag of features PY model (PY-BOF), dependent P Y with distance-based squared exponential covariance (PY-Dist), and dependent PY with co variance that incorporates intervening contour cues (PY-Edge) based on the P b detector [ 20 ]. The conditionally specified PY-Edge model scales the covariance between superpixels i and j by on the straight line connecting them. We convert these local covariance estimates into a globally consistent, positive definite matrix via an eigendecomposi tion. For the results in Figs. 5 and 6 , we independently segment each image, without sharing appearance models or su pervised training. We compare our results to the normalized cuts spectral clust ering method with varying numbers of segments (NCut( K )), and a high-quality affinity function based on color, text ure, and intervening contour cues [ 13 ]. Our PY models consistently capture variability in the num ber of true segments, and detect both large and small regions. In contrast, normal ized cuts is implicitly biased towards regions of equal size, which produces distortions. To quant itatively evaluate results, we measure overlap with held-out human segments via the Rand index [ 30 ]. As summarized in Fig. 6 , PY-BOF performs well for some images with unambiguous features, bu t PY-Edge is often substantially better. We have also experimented with our hierarchical PY extensio n, in which color and texture distribu-tions are shared between images. As shown in Fig. 7 , many of the inferred global visual categories align reasonably with semantic categories (e.g., sky , foliage , mountains , or buildings ). We have developed a nonparametric framework for image segme ntation which uses thresholded Gaussian processes to produce spatially coupled Pitman X  X o r processes. This approach produces empirically justified power law priors for region areas and o bject frequencies, allows visual appear-ance models to be flexibly shared among natural scenes, and le ads to efficient variational inference algorithms which automatically search over segmentations of varying resolution. We believe this provides a promising starting point for discovery of shape-based visual appearance models, as well as weakly supervised nonparametric learning in other, non-visual application domains. Acknowledgments We thank Charless Fowlkes and David Martin for the P b boundary estimation and seg-
