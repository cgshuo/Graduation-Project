 tection, discovery of criminal activities in electronic com-merce, video surveillance, weather prediction, and pharma-ceut, ical research. 
An outlier is an observation that deviates so much from other observations so that it, arouses suspicions ttrat it is generated by a different mechanism [6]. Studies on outlier detectiou are numerous and carl be grouped into five general categories. The first is distribution-based, where outliers are observations which deviate from a standard distribution (e.g., Normal, Poisson, etc.) [1]. Outfier detection can also be depth-based which relies on the computation of differ-ent layer's el" k-d convex hulls. In depth-based methods, out-category of outlier detection method is distance-based. In-troduced by Knorr and Ng in [7], a distance-based outfier in a data.set D is all object with pet% of the objects in D having a distance of more than dmm away from it. This notion of distance-based outlier generalizes many notions from distribution-based approaches and is further extended in [9] so that outliers can be more efficiently discovered and ranked. In many clustering algorithms like [8], DBSCAN [4], BIRCH [10] and CURE [5], outliers are by-products of clustering and we refer to such outlier-detection method as clustering-based. 
While the above four categories of outlier detection are interesting and useful in their own rights, our paper will only fbcus on the fifth category which detect local outliers-based on the local density of an object's neighborhood. We refer to this category as density-based. The concept of a local outlier is an important one since in mauy applica-ent characteristics, and it. is more meaningful to decide on the outlying possibility of an object based on other objects in its neighborhood. In view of this, [3] defines the con-cept of a local outlier factor(l_OF), wtfich is intuitively a measure of difference in density between an object, and its neighborhood objects. Unfortunately, the work done in [3] requires the computation of LOF for all objects which is rather expensive because it requires a large number of k-nearest-neighbors queries. As it, is observed that many ob-jects have I_OF values whirl1 are very close and are unlikely to be interesting outliers, we believe that a system should the top-rz local outliers instead of computing the LOF of ev-er'y object in a database. 
Given our motivation, it is obvious that finding COF for all objects and then selecting the top-n among them is not a solution in our consideration. However, if careful pruning is 
Note that since there may be more than k objects within k-distance(p), the number of objects in gk(p) may be more value is strongly influenced by the k-distance of the objects in its k-distance neighborhood. 
DEFINITION 3. (reachabillty distance ofp w.r.t object The teachability distance of object p with respect to object o is defined as DEFINITION 4. (local reachabillty density of p) the average reachability distance from the k-nearest-neighbors oSp. 
Essentially, the local reachability density of an object p is an estimation of the density at point p by analyzing the k-distance of the objects in Nk(p). The local reachability density of p is just the reciprocal of the average distance between p and the objects in its k-neighborhood. Based on local reachability density, the local outlier factor can be defined as follows. DEFINITION 5. (local outlier factor of p) 
LOF is the average of the ratios of the local reachability density of p and those ofp's k-nearest-neighbors. Intuitively, bility density is much lower than those of its neighbors. 
Given the earlier definition of local outliers, our problem is to find the top-n outliers in terms of LOF values when n analyze this problem and then introduce various concepts involved in our algorithm for finding top-r: local outliers ef-ficiently. 
From tile definitions given in the previous section, our analysis shows that an upper bound and lower bound on the LOF of an object p can be obtained if an upper and lower bound on the local reachability density of p and objects in Nk(p) are available. More specifically, we have (;tie following theorem. THEOaEM 3.1. Let lrdk(o).lower and lrdk(o).upper denote the lower and upper bound on the local reachability density of an object o respectively, and o E Nk(p), then 
M in{ lrdk (o).lower } Max{ lrdk (o).upper } 
To ensure that not too much accuracy is sacrificed by using micro-cluster, we limit radius of each micro-cluster to be below a user-specified threshold, maxradius. When a micro-cluster with a radius higher than maxradins is found, it is split by choosing two data that are farthest apart in the micro-cluster as seeds and reassigning other data left to the nearest seed. Since we use a micro-cluster to represent a dataset in outlier detection, the distance measurement to a micro-cluster must also be defined. 
In the rest of this paper, let D be a database and M be a and a micro-cluster in M is denoted as MC(n, c, r). THEOREM 3.3. Let p be an object and MC(n,e,r) a micro-minimum distance between an object p and a micro-cluster MC will be: 
DistM~,,(p, MC) = d(p, c) -r and the maximum distance between p and MC will be: DistM,~(p, M C) = d(p,c) + r 
Figure 1 illustrates the maximum and minimum distance between a point p and a micro-cluster, MC(n, c, r), when p is not within a distance of r from c. Intuitively, any point within the micro-cluster MC(n,c, r) will be at a distance of at least DistMi,,(p, MC) and at most DistM~(p, MC) from p. The situation is different if p is within a distance the maximum distance remains unchanged, the minimum distance must be set to 0. Such a situation, however, is undesirable since we will be estimating the k-distance of a point based on its distance to its neighboring micro-clusters, and a k-distance of 0 will mean extremely high density. To overcome this problem, our solution is to ensure that each object in a micro-cluster MC(n, c,r') is in fact nearest to c than to the center of any other micro-clusters. This can be achieved by first, forming micro-clusters using an algorithm like BIRCH [10], fixing the centers of each micro-cluster and then do a simple redistribution of the objects to the nearest the BIRCH structure resides in the main memory. With such an assumption, we will now define the concept of a cut plane. DEFINITION 7. (Cut-Plane) Let MCi, MCj be two mictv-clusters, a cut-plane for MC~ and MCj, denoted as cp( MC,, MCj), is a hyperplane that line into exactly two halves. [] 
We illustrate a cut plane between two micro-clusters MCi and MCj in Figure 2. With the definition of a cut-plane, we will now define the minimum distance between p and a micro-cluster MCj(nj,cj, rj) when p is within a distance of rj fl'om cj. DEFINITION 8. (Mill distance between all object and a micro-cluster with overlapping) Let p be an object within a micro-cluster MCi(n,, ci, ri). [f 
COP~OLLARY 3.2. Let p be an object and MC(n,c,r) be the micro-cluster that contains p. Let MC1 (m, cl, rl), ... , tially contain the k-nearest neighbors of p. For ease of dis-cussion, we will treat the other (n -1) objects as micro-Thus we will now have l + n -1 micro-clusters. 1. Let { Dist Mi~(p, M Ct ) ..... Dist Mi,,(p, MCt+~_x)} be 2. Let { DistM~(p, MC, ),... , DistM~(p, MC,+,_, )} be 
Given a micro-cluster MC containing pt,... ,p,, we will use k,~-distance(MC) to denote Max(k,~-distance(pl), .... km~-distance(pl ) ) and kmi~-distance( M C) to denote gin(kmin-distance(pa ) ..... k,ni~-distance(pi ) ). We now de-rive a bound for the internal reachability of a micro-cluster. DEFINITION 10. (Internal teachability bound of a micro-cluster) We define the internal reachability bounds of a micro.cluster MC(n, c, r) as follows, 2. r'm,n( MC) ----kmin-distar, ce( MC) Intuitively, given two objects p and o within micro-cluster MC, rm.~(MC) avid rmi,~(MC) represent the maximun, and minimum bound for reaeh-distance(p,o) respectively. This definition is used for estimating the reachability dis-lance bound of a pair of data wittfin one nficro-cluster. DEFINITION 11. (External reaehability bound of two micro-clusters) We define the external reachability bounds of a micro-cluster MCi with respect to another" micro-cluster MC~ as follows, 1. rm,x(MCl, MCj) = 2. ,'mi,(MCi,MC3)= Intuitively, given two objects p and o within micro-cluster MCi and MC~ respectively, r'ma~ and "mln represent~ the maximum and minilnum bound ['or reach,-distance(p, o) re-spectively. This definition is used for estimating the reach-clusters. One thing to note is tllat the external reachability bound of two micro-clusters will NOT be affected by over-lapping between the micro-clusters as long a.s we have good estimation of the k-distance bound for the objects inside the mlcro-clusters. Having introduced the various concepts, we will have a look at our algorithm in tile nexL section. /.for each micro-cluster MCI do 2. find a micro-clusters set Po] MCI by Corollary 8.2; 3. get internal rmaz(MOl)/rmin(MCi) bound for MOl; 4. LOF(Mel).upper = rmaz(Mel)/rmln(MCi); 
LOY(MCi).lower = rmln(MCi)/rrna=(MOl); 5. for each micro-cluster MC7 E P do 6. get external rmax(MCi, MC3),rmln(MCi,MC~); 7. if LOF(Mel).upper &lt; rmax(MCi, MCj)/rmi,:(MCi, MCj) 8. LOF(MOl).upper = r .... (MCi,MCj)/rmln(MCI,MC3); 9. if LOF(MCl).lower &gt; rmin(MOi, MOj)/r .... (MCI, MCj) 10. LOF(MCi).lower = rmi,(MCi,MCj)/rmax(MCi,MCj); 
This algorithm is used to compute the LOF bound of a micro-cluster. In steps 3 and 4, it first handles data within one micro-chister. Then in steps 6-t0, it considers those potential neighbor micro-clusters to obtain their lower and upper bounds. 
Given an upper and lower bound for the LOF of micro-cluster, we can easily rank Top-n local outliers. ALGORITHM 3. Algorithm t~nk-TOPn-LOF. Input: A set of MC1, . .. , MCl and their LOF_bound. Output: TOP-n local outliers. 
Metlmd: l. Sort the first n micro-clusters in ascending LOF.Iower 2. for any other micro-clusters MCi do 3. if LOF(MCi).upper &lt; Min-TOPn-LOF 4. then delete MCI; 5. else if LOF(MCi).lower &gt; Min-TOPn-LOF 6. then delete the current sorted n-th micro-cluster; 7. add MCI into current top n sorted micro-clusters; 8. re-sort current n micro-clusters, 9. for any data in the remaining micro-clusters MC~ do 10. calculate detailed LOF value; 11. prune those that are impossible to become TOP.n LOFs; 12. obtain TOP-n local outliers; We compare our micro-cluster TOP-n LOF algorithm with 
X-tree-based LOF method [3]. We did experiments on both the synthetic data due to lack of space. The experiments are conducted on a PentiumllI-450 PC with 256MB main memory under Windows NT4.0 and implemented in Visual 
C++6.0. The cost, of time in the experiments includes build-ing an index tree. i lO00 ,~ 800 i 600 z 400 Figure 4: No. of unpruned candidates vs max-radius 
The synthetic datasets we used for our experiments are generated using Gaussian random distribution. We evaluate the performance based on three aspects. 
