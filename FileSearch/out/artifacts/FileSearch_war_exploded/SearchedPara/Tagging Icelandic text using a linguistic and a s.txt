 In this paper, we use a linguistic rule-based method (LRBM) and a data-driven method (DDM) for tagg-ing text in the morphologically complex Icelandic language.

We present a novel LRBM. The tagger based on this method, hereafter called IceTagger , uses about 175 local rules for initial disambiguation, and a set of heuristics, to force feature agreement where ap-propriate, for further disambiguation.

The average tagging accuracy of IceTagger is 91.54%, compared to 90.44% achieved by the TnT tagger, a state-of-the-art statistical tagger (Brants, 2000). IceTagger makes 11.5% less errors than TnT . On the other hand, when tag profile gaps in the lex-icon, used by TnT , are filled with tags produced by IceMorphy , our morphological analyser, TnT X  X  tagg-ing accuracy increases to 91.18%. In that case, Ice-Tagger makes 4.1% less errors than TnT .

The remainder of this paper is organised as fol-lows: In Sect. 2, we describe the different tagging methods in more detail. Sect. 3 briefly describes the Icelandic language and the tagset. The components of IceTagger are described in Sect. 4, and evaluation results are presented in Sect. 5. DDMs use machine learning to automatically derive a language model from, usually, hand-annotated cor-pora. An advantage of the DDMs is their language and tagset independence property. Their disadvan-tage is that a tagged corpus is essential for training. Furthermore, the limited window size used for dis-ambiguation (e.g. three words) can be responsible for some of the tagging errors.

One of the better known statistical data-driven tagger is the TnT tagger (written in C). The tag-ger uses a second order (trigram) Hidden Markov model. The probabilities of the model are esti-mated from a training corpus using maximum like-lihood estimation. New assignments of part-of-speech (POS) to words is found by optimising the product of lexical probabilities ( p ( w i | t j ) ) and con-textual probabilities ( p ( t i | t i  X  1 , t i  X  2 )) (where w t are the i th word and tag, respectively).

In contrast to DDMs, LRBMs are developed with the purpose of tagging a specific language using a particular tagset. The purpose of the rules is, usu-ally, to remove illegitimate tags from words based on context. The advantage of LRBMs is that they do not rely (to the same extent as DDMs) on the existence of a tagged corpus, and rules can be written to refer to words and tags in the entire sentence. The con-struction of a linguistic rule-based tagger, however, has been considered a difficult and time-consuming task (Voutilainen, 1995).

One of the better known LRBMs is the Con-straint Grammar (CG) framework (Karlsson et al., 1995), in which both POS and grammatical func-tions are tagged. The EngCG-2 tagger, developed over several years and consisting of 3,600 rules, has been shown to obtain high accuracy (Samuelsson and Voutilainen, 1997).
 The development time of our LRBM (written in Java; including a tokeniser, IceMorphy and Ice-Tagger ) was 7 man-months, which can be consid-ered a short development time for a LRBM. This is mainly due to the emphasis on using heuristics (see Sect. 4.3) for disambiguation, as opposed to writing a large number of local rules. The Icelandic language is one of the Nordic lan-guages. The language is morphologically rich, mainly due to inflectional complexity. A thorough description of the language can, for example, be found in ( X r X insson, 1994).

The main Icelandic tagset, constructed in the compilation of the tagged corpus Icelandic Fre-quency Dictionary ( IFD ) (Pind et al., 1991), is large (about 660 tags) compared to related languages. In this tagset, each character in a tag has a particular function. Table 1 shows the semantics of the noun and the adjective tags.

To illustrate, consider the phrase  X  fallegu hes-tarnir  X  (beautiful horses). The corresponding tag for  X  fallegu  X  is  X  lkfnvf  X , denoting adjective, mascu-line, plural, nominative, weak declension, positive; and the tag for  X  hestarnir  X  is  X  nkfng  X  denoting noun, masculine, plural, nominative with suffixed definite article. IceTagger consists of three main components: an unknown word guesser, local rules for initial disam-biguation and heuristics for further disambiguation. Both the local rules and the heuristics have been de-
Char Category/ Symbol  X  semantics # Feature 1 Word class n  X  X oun, l  X  X djective 2 Gender k  X  X asculine, v  X  X eminine, 3 Number e  X  X ingular, f  X  X lural, 4 Case n  X  X ominative, o  X  X ccusative, 5 Article g  X  X ith suffixed article 5 Declension s  X  X trong, v  X  X eak 6 Proper noun m  X  X erson,  X   X  X lace, s  X  X ther 6 Degree f  X  X ositive, m  X  X omparative, Table 1: The semantics of the noun and the adjective tags. veloped using linguistic knowledge and tuned using a development corpus (described in Sect. 5). 4.1 The unknown word guesser The purpose of our morphological analyser Ice-Morphy , which is used as an unknown word guesser by IceTagger , is to generate all appropriate tags for a given word. It uses a familiar approach to unknown word guessing, i.e. it performs mor-phological/compound analysis and ending analysis (Mikheev, 1997; Nakov et al., 2003). Additionally, IceMorphy includes an important module for handl-ing tag profile gaps (for a thorough description of IceMorphy , consult (Loftsson, 2006a)).

A tag profile gap arises when a particular word, listed in a lexicon derived from a corpus, has some missing tags in its tag profile (set of possible tags). The missing tag(s) might just not have been encoun-tered during the derivation of the lexicon (e.g. dur-ing training). For each noun, adjective or verb, of a particular morphological class, IceMorphy is able to fill in the gaps for the given word.

To illustrate, consider the word  X  konu  X  (woman), and let us assume that only the tag  X  nveo  X  (denoting noun, feminine, singular, accusative) is found in the lexicon. Based on the  X  u  X  morphological suffix and the accusative case of the tag, IceMorphy assumes the word belongs to a particular morphological fem-inine noun class, in which singular accusative, dative and genitive cases have the same word form. Con-sequently, IceMorphy generates the correct missing tags:  X  nve X   X  and  X  nvee  X . 4.2 Local rules The purpose of a local rule is to eliminate inappro-priate tags from words, based on a local context (a window of 5 words; two words to the left and right of the focus word). This reductionistic approach is common in rule-based taggers. It is, for example, used in the CG systems.

In principle, the local rules are unordered. The fir-ing of a rule is, however, dependent on the order of the words in a sentence. A sentence to be tagged is scanned from left to right and all tags of each word are checked in a sequence. Depending on the word class (the first letter of the tag) of the focus word, the token is sent to the appropriate disambiguation rou-tine, which checks a variety of disambiguation con-straints applicable to the particular word class and the surrounding words. At each step, only tags for the focus word are eliminated.

The format of a local rule is: If &lt;condition&gt; eliminate tag t . A &lt;condition&gt; is a boolean expression, whose individual components can re-fer to lexical forms or individual characters (word class/morphological features) of tags. The follow-ing are examples of &lt;condition&gt; ( L 1 / R 1 and L 2 denote tokens one and two to the left/right of the fo-cus word, F , respectively):
To exemplify, consider the sentence part:  X  vi X  vorum . . .  X  (we were . . . ). The word  X  vi X   X  can have the following five tags ( X  X  X  is used as a sep-arator between tags):  X  ao_a X _fp1fn_aa_nkeo  X . For illustration purposes, it is sufficient to point out that the first two tags denote prepositions govern-ing the accusative and the dative cases, respec-tively. Since the following word is a verb ( X  vo-rum  X ) and prepositions only precede nominals, a rule, with &lt;condition&gt;= R 1 .isOnlyWordClass(Verb), eliminates preposition tags in this context, leaving only the tags  X  fp1fn_aa_nkeo  X .

The current version of our tagger has 175 local rules. The rules are written in a separate file and compiled to Java code. 4.3 The heuristics Once local disambiguation has been carried out, each sentence is sent to a global heuristic mod-ule, consisting of a collection of algorithmic proce-dures. Its purpose is to perform grammatical func-tion analysis, guess prepositional phrases (PPs) and use the acquired knowledge to force feature agree-ment where appropriate. We call these heuristics global because, when disambiguating a particular word, a heuristic can refer to a word which is not in the nearest neighbourhood.

The heuristics repeatedly scan each sentence and perform the following: 1) mark PPs , 2) mark verbs , 3) mark subjects , 4) force subject-verb agreement , 5) mark objects , 6) force subject-object agreement , 7) force verb-object agreement , 8) force nominal agreement , and 9) force PP agreement . Lastly, the default heuristic is simply to choose the most fre-quent tag according to frequency information de-rived from the IFD corpus. A detailed description of all the heuristics can be found in (Loftsson, 2006b). For evaluation, we used the pairs of ten training and test corpora of the IFD corpus, produced by Helga-d X ttir (2004). We used the first nine of these test cor-pora for evaluation, but the tenth one was set aside and used as the development corpus for IceTagger .
For each test corpus (10% of the IFD ) the corre-sponding training corpus (90% of the IFD ) was used to deduce the lexicon(s) used by TnT , IceTagger and IceMorphy . When testing the two taggers, we thus made sure that the ratio of unknown words was (al-most) the same.

The accuracy of a base tagger, which assigns each known word its most frequent tag, and the most fre-quent noun tag/proper noun tag to lower case/upper case unknown words, is 76.27% (see table 2).
The average tagging accuracy of IceTagger for all words is 91.54%, compared to 90.44% for TnT (see table 2). IceTagger makes 11.5% less errors than TnT 1 .

In order to improve the tagging accuracy of TnT , we used the tag profile gap filling mechanism of Ice-Words Base TnT TnT* IceTagger Unkn. 4.39% 71.68% 72.75% 75.09% Known 81.84% 91.82% 92.53% 92.74% All 76.27% 90.44% 91.18% 91.54% Table 2: Average tagging accuracy of the various taggers.
 Morphy in the following manner. Each record in the lexicon used by TnT consists of a word and the cor-responding tags found in the training corpus. Addi-tionally, to facilitate lexical probability calculations, each tag is marked by its frequency (i.e. how of-ten the tag appeared as a label for the given word). We made IceMorphy generate a  X  X illed X  lexicon such that each generated missing tag was marked with the frequency 1 2 . We call the resulting tagger TnT* . In-deed, when testing TnT* , we obtained an overall av-erage tagging accuracy of 91.18% (see table 2). Ice-Tagger makes 4.1% less errors than TnT* .

The development of IceTagger/IceMorphy took 7 man-months, but it has been worth the effort. First, IceTagger does make fewer errors than TnT , and its accuracy can probably be increased by improving its individual components. Secondly, we have used IceTagger in various tagger combination methods to further increase the tagging accuracy of Icelandic text (Loftsson, 2006c). In this paper, we have compared the tagging accu-racy of our linguistic rule-based tagger, IceTagger , to the accuracy of TnT , a state-of-the-art statistical tagger.

IceTagger uses only about 175 local rules, but is able to achieve high accuracy through the use of global heuristics along with automatic tag profile gap filling. The average tagging accuracy of Ice-Tagger is 91.54%, compared to 90.44% obtained by the TnT tagger. On the other hand, we were able to obtain 91.18% accuracy using TnT along with the tag profile gap filling mechanism of IceMorphy .
In future work, we would like to improve individ-ual components of IceTagger and IceMorphy , with the purpose of further increasing the tagging accu-racy.

