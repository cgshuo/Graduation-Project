 This demonstrator Senior Companion (SC) was built during the in i tial phase of the Companions project and aims to change the way we think about the relatio n ships of people to computers and the i nternet by developing a virtual conve r-sational 'Compa n ion that will be an agent or 'presence' that stays with the user for long per i-ods of time, developing a relationship and 'kno w-ing its owners X  pre f erences and wishes. The Companion communicates with the user prima r-ily through speech, but also using other tec h-nologies such as touch screens and sensors.
 This paper describes the functionality and system modules of the Senior Companion, one of two initial prototypes built in the first two years of the pr oject. The SC provides a multimodal inte r-face for eliciting, retrieving and inferring pe r-sonal info r mation from elderly users by means of conversation about their photographs. The Co m-panion, through conversation, elicits life mem o-ries and reminiscences, of ten prompted by di s-cussion of their phot o graphs; the aim is that the Companion should come to know a great deal about its user, their tastes, likes, dislikes, em o-tional reactions etc, through long periods of co n-versation. It is assumed that most life infor m a-tion will soon be stored on the internet (as in the Memories for Life pr o ject: http://www.memoriesforlife.org/) and we have linked the SC directly to photo inventories in Fac e book (see below). The overall aim of the SC project (not yet achieved) is to pr oduce a cohe r-ent life narrative for its user from conversations about personal photos, a l though its short -term goals, reported here , are to assist, amuse and e n-te r tain the user. The technical content of the project is to use a number of types of machine l earning (ML) to achieve these ends in original ways, initially u s-ing a methodology developed in earlier research: first, by means of an Information Extraction (IE) approach to deriving content from user input u t-terances; secondly, using a training method for attaching Di a logue Acts to these utterance and , lastly, using a specific type of dialogue manager (DM) that uses Dialogue Action Forms (DAF) to d e termine the context of any utterance . A stack of these DAFs i s the vi r tual machine that models the o n goin g dialogue by means of shared user and Companion initiative and generates a p-propriate responses. In this d e scription of the demo, we shall: A mini -version of the demo running in real time can be seen at: URL The Senior Companion prototype ( Wilks, 2010 ) was designed to make a rapid advance in the first two years of the project so as to be basis for a second round of prototypes embodying more advanced ML. This strategy was deliberately chosen to avoid a well -known problem with e x-per i mental AI systems: that a whole project is spent in design so that a prot o type never emerges until the very end, but which is then never fully evaluated and, most impo r tantly, nothing is ever built on the experience obtained in its constru c-tion. The central function of the SC is engaging the user in discu s sion about their photographs: where and when they were taken, details about the people in them and their relationship to the user and each other. Once a photo is loaded, it is pro cessed with face re c ognition software to identify any faces in it. The re c ognition software, OpenCV, provides positional i n formation by identifying the face coordinates and this information is exploited in the Dialogue Manager by making explicit refe r-ence to the position of people in the photograph (the person on the left, right, center, etc.) as well as recognizing when there are groups of people. The system discusses properties of the photo as well as properties and relationships of the people in the phot os. The news reading feature adds an interesting a c-companiment to the photo domain and demo n-strates the ability of the system to handle more than one kind of application at a time, and news has, of course, an u n constrained vocabulary . The following is a fairly typical example of its cu r-rent cap a city, depending of course on the i m ages loaded, and comes from the middle part of a sample dialogue generated by the sy s tem when discussing a group photo from a vacation in Za n-zibar, and after the system had alread y stored, from an earlier conversation, that the user has a daughter Zoe (using researchers X  children to avoid any problems) : SC: What is your relationship to the doctor? User: There is no relationship.
 SC: Please tell me how you know the doctor U: Uh, he 's a friend.
 SC: How old was the doctor when this photo was taken? U: I'm not sure but I think about 30.
 SC: How do you know Octavia? U: She's my daughter.
 SC: Aha! I see. Octavia's sister is Zoe.
 SC: How old was your daughter Octavia when this photo was t aken? U: Octavia was 19 years old.
 SC: What was the occasion of this photo? U: This was another family holiday.
 SC: Where was this photo taken? U: This photo was taken in Tanzania.
 SC: have you ever been to Zanzibar? U: Yes, I have.
 SC: Great place, I hope you saw the beaches. When was this photo taken? U: last year.
 It is a key feature of the SC that it can make si m-ple inferences from family relationships it a l-ready knows (e.g. that daughters of the same pa r-ent are siblings) and that it can access real -ti me information about places to show that it has some knowledge of what is being talked about, in this case the beaches on Zanz i bar, and how this is done is discussed below. This real time access to unconstrained place information on the internet is an atte mpt to break out of classic AI sy s tems that only know the budget of facts they have been primed with.
 This basic system provides the components for future development of the SC, as well as its main use as a device to generate more conversation data for m a chine learning research in the future. Key features of the SC are listed below followed by a description of the system architecture and modules. The SC: In this section we will review the components of the SC architecture. As can be seen from Figure 2, the architecture contains three abstract level components  X  Connectors, Input Handlers and Application Ser v ices  X  together with the Dialogue Manager and the Natural Language Understander (NLU).
 Figure 2: Senior Companion system architecture Connectors form a communication bridge b e-twe en the core system and external applications. The external application refers to any modules or systems which provide a specific set of functio n-alities that might be changed in the future. There is one connector for each external application. It hides the underlying complex communication protocol details and provides a ge n eral interface for the main system to use. This abstraction d e-couples the connection of external and internal modules and makes changing and adding new exte r nal modules easier. At this mom ent, there are two connectors in the system  X  Napier Inte r-face Connector and CrazyTalk Avatar Conne c-tor. Both of them are using network sockets to send/receive messages.
 Input Handlers are a set of modules for proces s-ing messages according to message type s. Each handler deals with a category of messages where categories are coarse -grained and could include one or more message types. The handlers sep a-rate the code ha n dling inputs into different places and make the code easier to locate and change. Three han dlers have been implemented in the Senior Companion system  X  Setup Handler, Dragon Events Handler and General Ha n dler. The Setup Handler is responsible for loading the photo annotations if any, performing face dete c-tion if no annotation file is associated with the photo and chec k ing the Knowledge Base in case the photo being processed has been discussed in earlier se s sions. Dragon Event Handler deals with dragon speech recognition co m mands sent from the interface while the General Handler pro c esses user utt erances and photo change events of the inte r face.
 Application Services are a group of internal modules which provide interfaces for the Di a-logue Action Forms (DAF) to use. It has an easy -to -use high -level interface for general DAF d e-signers to code assoc i ated tests and actions as well as a low level interface for advanced DAFs. It also provides the communication link between DAFs and the internal system and e n ables DAFs to access system functionalities. Follo w ing is a brief summary of modules grouped into Applic a-tion Services.
 News Feeders are a set of RSS Feeders for fetc h-ing news from the internet. Three different news feeders have been implemented for fetching news from BBC website Sports, Politics and Business channels. There is also a Jokes Feeder to fetch Jokes from internet in a similar way. During the conversation, the user can request news about particular topics and the SC si m ply reads the news downloaded through the feeds.
 The DAF Repository is a list of DAFs loaded from files generated by the D AF Editor. The Natural Language Generation (NLG) mo d-ule is responsible for randomly selecting a sy s-tem utterance from a template. An optional var i-able can be passed when calling methods on this module. The variable will be used to replace sp e-cial sy m bols in the text template if applicable. Session Knowledge is the place where global info r mation for a particular running session is stored. For example, the name of the user who is running the session, the list of photos being di s-cussed in this session and the list of user utte r-ance s etc.
 The Knowledge Base is the data store of persi s-tent knowledge. It is implemented as an RDF triplestore using a Jena implementation. The tr i-plestore API is a layer built upon a traditional rel a tional database. The appl i catio n can save/retrieve information as RDF triples rather than table r e cords. The structure of knowledge represented in RDF triples is discussed later. The Reasoner is used to perform inference on existing knowledge in the Knowledge Base (see e x ample in next section).
 The Output Manager deals with sending me s-sages to external applications. It has been i m-plemented in a pu b lisher/subscriber fashion. There are three different channels in the sys tem: the text cha n nel, the interface command channel and the avatar command channel. Those cha n-nels could be su b scribed to by any connectors and handled respe c tively. Every utterance is passed through the Natural La n guage Understanding (NLU) module for processing. This module uses a set of well -established natural language processing tools such as those found in the GATE (Cu n ningham, et al., 1997) system. The basic processes carried out by GATE are: tokenizing, sentence spli t ting, POS tagging, parsing and Named Entity Reco g-nition. Th ese components have been further e n-hanced for the SC system by adding 1) new and improved gazetteers including family relations and 2) accompanying extraction rules .The Named Entity (NE) re c ognizer is a key part of the NLU module and recognizes the signif i cant entities required to process dialogue in the photo d o main: PERSON NAMES, LOCATION NAMES, FAMILY R E LATIONS and DATES. Although GATE recognizes basic ent i ties, more complex ent i ties are not handled. Apart from the gazetteers mentioned earlier and the h undreds of e x traction rules already present in GATE, about 20 new extraction rules using the JAPE rule la n-guage were also deve l oped for the SC module. These included rules which ide n tify complex dates, family relationships, negations and other information related to the SC domain. The fo l-lowing is an example of a simple rule used to identify relationship in utterances such as  X  X ary is my sister X : Macro: RELATIONSHIP_IDENTIFIER ( ({T o-ken.category=="PRP$"}|{Token.category=="PR P"}|{Lookup.majorType=="person_f irst"}):pers on2 ({Token.string=="is"}) ({Token.string=="my"}):person1 ({Lookup.minorType=="Relationship"}):relation ship ) Using this rule with the example mentioned ea r-lier, the rule interprets person1 as referring to the speaker so, if the name of the use r speaking is John (which was known from previous convers a-tions), it is uti l ized. Person 2 is then the name of the person me n tioned, i.e. Mary. This name is recognised by using the gazetteers we have in the system (which contain about 40,000 first names). The relationship is once again identified using the almost 800 unique relatio n ships added to the gazetteer. With this information, the NLU mo d-ule identifies Information Extraction patterns in the dialogue that represent significant co n tent with respect to a user's life and photos.
 The information obtained (such as Mary=sister -of John) is passed to the Dialogue Manager (DM) and then stored in the knowledge base (KB). The DM filters what to include and e x-clude from the KB. Given, in the example above, that Mary is the sister of John, the NLU knows that sister is a relationship between two people and is a key relationship. However, the NLU also di s covers syntactical information such as the fact the both Mary and John are nouns. Even though this information i s important, it is too low level to be of any use by the SC with respect to the user, i.e. the user is not interested in the parts -of -speech of a word. Thus, this information is di s-carded by the DM and not stored in the KB. The NLU mo d ule also identifies a Dialogue Act Tag for each user utterance based on the DAMSL set of DA tags and prior work done jointly with the University of Albany (Webb et al., 2008).
 The KB is a long -term store of information which makes it possible for the SC to retrieve informatio n stored between different sessions. The i n formation can be accessed anytime it is needed by simply invo k ing the relevant calls. The stru c ture of the data in the database is an RDF triple, and the KB is more commonly r e-ferred to as a triple store . In mathe matical terms, a triple store is nothing more than a large dat a-base of interco n nected graphs. Each triple is made up of a su b ject, a predicate and an object. So , if we took the previous example, Mary sister -of John; Mary would be the subject, sister -of wou ld be the predicate and John would be the object. The inference engine is an important part of the sy s tem because it allows us to di s cover new facts beyond what is elicited from the co n-versation with the user. Uncle Inference Rule: (?a sisterOf ?b), ( ?x sonOf ?a), (?b gender male) -&gt; (?b uncleOf ?x) Triples: (Mary sisterOf John) (Tom sonOf Mary) Triples produced automatically by ANNIE (the s e mantic tagger): (John gender male) Inference: (Mary sisterOf John) (Tom sonOf Mary) (John g ender male) -&gt; (John uncleOf Tom) This kind of inference is already used by the SC and we have about 50 inference rules aimed at producing new data on the relationships domain. This combin a tion of triple store, inference engine and inference rules mak es a system which is weak but powerful enough to mimic human re a-soning in this domain and thus simulate basic intelligence in the SC. For our prot o type, we are using the JENA Semantic Web Fram e work for the inference engine together with a MySQL d a-tabase as the knowledge base. However, this sy s-tem of family relationships is not enough to cover all the possible topics which can crop up during a conversation and, in such circu m-stances, the DM switches to an open -world model and instructs the NLU to seek furthe r i n-formation online. When the DM requests further information on a pa r ticular topic, the NLU first checks with the KB whether the topic is about something known. At this stage, we have to keep in mind that any topic r e quested by the DM should be already in the KB since it was preprocessed by the NLU when it was me n tioned in the utterance. So, if the user informs the system that the photograph was taken in Paris, (in response to a system question asking where the photo was take n), the utterance is first processed by the NLU which discovers that  X  X aris X  is a location using its semantic ta g-ger ANNIE (A Nearly New Information Extra c-tion engine). The semantic tagger makes use of gazetteers and IE rules in order to accomplish this ta sk. It also goes through the KB and r e-trieves any triples related to  X  X aris X . Inference is then performed on this data and the new inform a-tion gene r ated by this process is stored back in the KB. Once the type of information is identified, the NLU can use various predefined strategies: In the case of LOCATIONS, one of the strategies used is to seek for information in Wiki -Travel or Virtual Tou r ists. The system already knows how to query these sites and interpret their output by using predefined wrappers. T his is then used to extract relevant information from the mentioned sites webpages by sending an online query to these sites and storing the information retrieved in the tr i ple -store. This information is then used by the DM to generate a reply. In the prev ious e x ample, the system manages to extract the best sightse e ing spots in Paris. The NLU would then store in the KB tr i ples such as [Paris, sight -seeing, Eiffel Tower] and the DM with the help of the NLG would ask the user  X  X  X  X e heard that the X is a very famous spot. Have you seen it while you were there? X  Obviously in this case, X would be r e placed by the  X  X iffel Tower X .
 On the other hand, if the topic requested by the DM is unknown , or the semantic tagger is not capable of u n derstanding the semantic ca tegory, the system uses a normal search engine (and this is what we call  X  X ybrid -world X : the move outside the world the system already knows) . A query containing the unknown term in context is sent to standard engines and the top pages are retrieved. These pages are then pro c essed using ANNIE and the ir tagged attributes are an a lyzed. The standard attributes returned by ANNIE i n clude inform a tion about Dialogue Acts, Polarity (i.e. whether a sentence has positive, negative or ne u-tral connotations), Named Ent i ties, Semantic Categories (such as dates and cu r rency), etc. The system then filters the inform a tion collected by using more generic patterns and ge n erates a reply from the resultant information. ANNIE X  X  polarity methods have been shown to be an adequate i m-pl e mentation of the general word -based polarity methods pi o neered by Wiebe and her colleagues (see e.g. A k kaya et al., 2009) . The notion of companionship is not yet one with any agreed evaluation strategy or metric, though develo p ing one is part of the main project itself. Again, there are established measures for the a s-sessment of di a logue programs but they have all been developed for standard task -based di a-logues and the SC is not of that type: there is no specific task either in rem i nisc ing conversations, nor in the elicitation of the co n tent of photos, that can be assessed in standard ways, since there is no clear point at which an informal di a logue need stop, having been completed. Conve n tional di a logue evaluations often use measures l ike  X  X tickiness X  to determine how much a user will stay with or stick with a dialogue system and not leave it, presumably because they are disa p-pointed or find it lacking in some feature. But it is hard to separate that feature out from a task rapidly and effectively completed, where stick i-ness would be low not high. Traum (Traum et al., 2004) has developed a methodology for di a logue evaluation based on  X  X ppropriateness X  of r e-spons es and the Companions project has deve l-oped a model of evaluation for the SC based on that ( Benyon et al., 20 08 ).

