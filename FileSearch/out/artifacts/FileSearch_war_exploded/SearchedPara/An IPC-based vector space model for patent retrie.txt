 1. Introduction
As the number of electronic documents like web pages, news releases, academic papers, patent documents continues to mation needs. Among these, patent documents, a collection of rich technical information related to intellectual property deal with these challenges.

The vector space model (VSM) is commonly used in the area of information retrieval (IR) for presenting and comparing gue information needs. Before constructing vectors for the documents in a document set, it is necessary to determine the document concerned. X  The basis of the document vectors is therefore named as  X  X  X ndexing vocabulary X . However, the tradi-tional approach of constructing indexing vocabulary in VSM may suffer from the following problems: (1) Different document sets have different characteristics and need different bases for document vectors for the best per-(2) Even when the document set remains the same, the resulting indexing vocabulary will differ if different algorithms are (3) The resulting indexing vocabulary can also differ if the parameters of the adopted algorithm are adjusted, even if the (4) Words or terms that are commonly used to illustrate a concept tend to change or be gradually replaced over time due
The above-mentioned problems reveal significant weakness in the traditional methods; the generated indexing vocabu-the retrieval performance of the document set currently on hand. Making the indexing vocabularies generated from different eration. The composing vectors of a newly coming document will be different if different indexing vocabularies are used to transform that single document to get its respective vectors. As a result, the indexing vocabularies generated using these traditional approaches cannot be applied across applications, across document sets, or stay unchanged over time.
In this study, our focus is searching patent data. Patent documents are where one encounters the previously mentioned pages of the USPTO website. IPC is published by the World Intellectual Property Organization (WIPO), with its 9th edition new terms generated from wording evolution.

IPC is adopted here to improve compatibility across applications and data sets. IPC codes become the indexing vocabulary tem for all patent documents. This IPC-code approach has certain advantages. First, the generated vectors are compatible. or the parameters. Second, since IPC codes change slowly and slightly over time, the generated vector withstands wording evolution.

Finally, conclusions are presented in Section 5 . 2. Literature review
Choosing the proper indexing vocabulary for a document set is vital to VSM. The first subsection surveys VSM-related section. 2.1. Vector space model and indexing vocabulary selection
IR is the study to retrieve and extract the information that satisfies the user information needs from a set of documents and document retrieval systems. All the documents and queries in VSM can be represented by vectors and can be simply ary format, and more advanced types use term weighting schemes (such as the TFIDF formula presented by Sparck Jones, 1972 and Salton et al., 1975 ) to improve performance.

The accuracy and performance of VSM is influenced by the selected indexing vocabulary. In order to build a more accurate plans to select features so as to filter out homogeneous attributes and keep heterogeneous and informative attributes.
According to Trappey and Trappey (2008) , there are numerous methods to select index terms for an indexing vocabulary the topic drift problem does not occur. However, when the document set changes, the indexing vocabulary generated for the original document set would be no longer suitable. It is even harder to map a new document to the ready-made indexing vocabulary as the document set evolves over time. It is an ongoing issue in IR to discover an independent, full-coverage, time-invariant, and precise indexing vocabulary for the continuously changing document set. That also explains why it is necessary to design an approach of forming an indexing vocabulary which is strong enough to be used across applications, across document sets, and across time. 2.2. Introduction of patent documents
A general document is simply a textual article containing many paragraphs, sentences, and words. A patent document is panies and individuals worldwide, and, as of February 2008, has granted over 7,950,000 patents ( Wikipedia, 2009 ). Online keyword query and search functions are also provided on the USPTO website.
 uments are temporarily treated as general documents. According to Kang, Na, Kim, and Lee (2007) , patent documents are, on average, 24 times longer than a newspaper article. This length makes it difficult to find documents most relevant to a query, and is also another reason why an IPC-based VSM is needed.

The IPC, also called the Current International Class, is the name of a field within patent documents and was first estab-classes, and approximately 70,000 groups ( WIPO, 2009 ). Each group can be further divided into main groups and subgroups, represents a subgroup.
 patent documents. The IPC codes can be viewed as a topic label regarding the contents of the patent document. Vector-ori-ented methods are the popular way to retrieve documents. The IPC codes are used here as attributes in the indexing vocab-ulary to enrich the vector-oriented method for retrieving patent documents. 2.3. Patent mining
The amount of digital documents (e.g., patent documents) continues to increase rapidly and the vast content often over-design a comprehensive architecture and methodology for finding and retrieving patent documents to meet the user infor-mation needs.

Patent mining is an emerging research topic that arises in recent years. So far, not much research has been done on this works regarding these three issues. Retrieving patent documents can be done through the cluster-based approach ( Kang patent documents ( Huang, Liu, Wang, Ke, &amp; Yang, 2004 ).
 Previous researches employed traditional text-mining approach to build vectors for patent document representation. our major focus is to propose a new method for generating indexing vocabulary, IPC-based vector space model, to represent patent documents and replace the indexing vocabulary built from traditional text-mining approach. The value of IPC-based changes happen in document set, indexing vocabulary selection algorithm or parameter settings. Due to its strength, this new method can be used as a new platform for patent mining researchers to develop advanced mining methods. 2.4. Brief summary of the literature review
VSM, a popular method in IR, is adopted here to present patent documents. When using traditional indexing vocabulary selection methods, however, the compatibility problems occur because document vectors with different indexing vocabular-indexing vocabulary to avoid the problem. This IPC-based indexing vocabulary creates a uniform representation scheme for all patent documents and ensures that all vectors are compatible. 3. Research design named the IPC-based vector space model, and can be applied not only to a specific application or sub-domain, but also to rapidly updated data or generic applications. At the end of the process, document category vectors are generated for all the patent documents, meaning every document is represented by a vector of category codes in the IPC taxonomy.
Before introducing each phase, Fig. 2 shows an example of a vector, an A B vector in visual form. An object of A is ex-binary value (0 or 1) or a decimal value (such as 0.125, 0.5, or 0.95).

The main concern is transforming the patent documents into vectors of category codes in the IPC taxonomy in the most scalable, robust, and extensible way. There are five phases in the designed model: (1) collect patent documents, (2) text preprocessing, (3) generate category term vector, (4) generate term category vector, and (5) generate document cate-gory vector. The phases are described and explained in greater detail below. 3.1. Phase 1: Collect patent documents
First, patent documents must be gathered from the target database. The target database in this research is the USPTO posed vector space model. For each group of the group-level labels, a certain number of patent documents are gathered for further analysis.

Let D ={ d 1 , d 2 , ... , d n } be the set of patent documents, where n is the total number of documents in D . Let c level category code (which are the main group in the IPC hierarchy) and C ={ c codes within the IPC hierarchy. The total number of category codes in the IPC hierarchy is m . For example, c 27 X  and c 3 could be  X  X  X 01L 31 X . In addition, the set of documents in a category code is described as D ( c the documents belonging to category code c k . For example, if category code c includes documents d 2 and d 3 , then D ( c 1 )={ d 1 } and D ( c the above-mentioned variables is shown in Fig. 3 below. 3.2. Phase 2: Text preprocessing
In the second phase, text preprocessing is conducted. The main purpose of this phase is to clean and preprocess patent documents. During preprocessing, the tasks of syntax tagging, word stemming, and stop-word elimination are executed. tences based on their syntactic or morphological features. A log-linear POS tagger (developed by the Natural Language Pro-noun and  X  X  X rashed X  is a past participle verb.

After POS tagging, only nouns (including singular or collective nouns, plural nouns, singular proper nouns, and plural person singular present and third person singular present verbs) are reserved. The post-processing results from the sample sentence in Fig. 4 are illustrated in Fig. 5 .
 tial inputs for the next phase, the generation of category term vectors. 3.3. Phase 3: Generate category term vectors
This research attempts to generate document category vectors for each document in the gathered document set. To (phase 4), and finally, create document category vectors (phase 5).

The distinctive terms from the previous phase are used to generate category term vectors for every category code in the egory term vector is constructed. Let T ={ t 1 , t 2 , ... , t sentence ( Fig. 5 ) are such terms. Terms contained in document d the frequency of term t i in document d j . For example, if the terms appearing in document d and t 4 , we have T ( d 1 )={ t 1 , t 2 , t 4 , t 5 , t 6 the set of terms belonging to the documents in category code c terms in category code c 3 can be described as T ( c 3 )={ t
Documents in traditional VSM are usually represented by vectors of terms. The score of every attribute in the vector are calculated by the TFIDF formula ( w ij = tf ij log( n / n the weight of term t i in document d j , tf ij is the occurrence of term t document set, and n i is the number of documents containing t
The TFIDF formula can be intuitively extended into the TF-ICF (term frequency-inverse category frequency) formula to in a document vector to present its discrimination. We may think that TF-ICF might also be appropriate for the same task.
TF-ICF is not appropriate for calculating discrimination for terms across categories. However, we have modified the TF-ICF (mTF-ICF) formula to overcome these issues.
 note the weight of term t i in category c k for the category term vector. The full mTF-ICF formula is defined as follows: max sure the normalized term frequency in category c k .| D ( c standardize the term-frequency value for avoiding the bias caused by different numbers of documents contained in a category. log( m / m i ) in this formula calculates the ICF value for term t the number of categories in which the percentage of documents containing term t infrequent terms as noise and ignore them.
 different numbers of documents contained in a category; and (3) it remedies the bias caused when a term appears in almost every category (which may happen when a category contains many documents).

After calculating the weights for each term-attribute, the category term vector can be generated. The process of gener-ating category term vectors is illustrated in Fig. 7 . Let ~ c
The terms in T ( c k ) are the attributes of category term vector ~ c mTF-ICF formula. The generated category term vectors for all categories are presented as a category-by-term matrix: process, terms with lower standard deviations, which indicate weaker discriminative ability among categories, are removed.
The standard deviation is used as the discrimination recognition method because it is a simple way to calculate variation among attributes. A term t i with a smaller standard deviation means weaker discriminative ability between categories, and vice versa. The distinctive term can be the index term in the indexing vocabulary. The standard deviation of a term among categories can be calculated with the following:
After filtering, the category term vector becomes more concise because the number of attributes in a vector decreases, while the ability to distinguish one category from another increases.

The fourth and fifth phases generate the term category vectors and document category vectors, respectively. It is pos-sible for one term to occur in different documents and categories. For example, term t
T ( c )={ t 1 , t 2 , t 4 , t 5 , t 6 , t 7 } and T ( c 3 )={ t different categories. That is also why document category vectors are constructed via term category vectors, which are transformed from category term vectors. In the next phase, the term category vector for each term is generated by con-verting and transposing the category term vector. 3.4. Phase 4: Generate term category vector
After forming the category term vector, a converting and transposing process is conducted to present each term t term category vector. The process is based on the concept of matrix transposition, and can be done by interchanging the rows and columns of a matrix. For instance, the transposition of matrix A =[ a = b y , x . Thus, the category term matrix ( A cat term  X  X  w c t egory vectors ~ t 1 , ~ t 2 , ~ t 3 , ~ t 4 , ~ t 5 , ~ t egory vector is defined as ~ t i  X  X  w t c i ; 1 ; w t c i ; 2 resents the vector of the i th term, and w t c i ; k denotes the weight of term t 3.5. Phase 5: Generate document category vector
The document category vectors for each document are generated in this phase. Two steps are performed. First, a doc-ument term vector is generated for each document using the traditional TFIDF formula. This can be simply done through a traditional IR approach. We then create a doc term matrix A tained using the TFIDF formula. Second, the document category matrix is obtained by multiplying the document term matrix and the term category matrix, as A doc cat  X  A doc term all documents can be obtained from the document category matrix. The following formula is used to compute the weight:
The variable w d c j ; k is the weight of category c k for document d phase.

Finally, a document category vector for every document has been created. Let d document d j . 4. Experiments and evaluation The main purpose of the experiments and evaluations is to demonstrate the performance of the IPC-based method.
Through the experiments, we want to show that its performance is not sacrificed for its high compatibility across applica-tions and document sets. Several experiments were, therefore, designed and conducted for this purpose. These experiments can be divided into two types based on their evaluation approaches. They are manual evaluation and automatic evaluation.
The details of these two types of evaluations will be explained in the following subsections. 4.1. Data collection and text preprocessing
The experimental data consisted of patent documents from the USPTO database. Since the abstract in a patent document holds a major portion of the information about that document, other data fields, such as the claim and description, were omitted. The text data were extracted from the title and abstract fields. The raw data used in the experiment (patent doc-uments) and the outcomes of the experiments (generated vectors) were directly stored in the form of text files. Since IPC-subclass, and group codes are entirely the same would be viewed as patents in the same category. For example, patent doc-uments in  X  X  X 04C3/02 X  and  X  X  X 04C3/30 X  are in the same category. On the other hand, patent documents in  X  X  X 04C3/02 X  and  X  X  X 04C5/00 X  are in different categories.

In the manual evaluation and the first part of automatic evaluation, 116 patent documents from 2007 to 2009 were ran-domly collected. This document set was named Doc set (I). These patent documents were drawn from 63 different group-tained 29 patent documents. In the second part of the automatic evaluation, another 116 patent documents from 2007 to (II) is used to examine the compatibility of IPC-based VSM across document sets and applications. ing, word stemming, and stop-word elimination. The outcomes were then treated as the input data for the next phase. 4.2. The comparing methods for vector generation
In order to assess the performance of the proposed method, two algorithms as comparing methods are used to compare their performance with that of IPC-based method. The IPC-based method and the two comparing methods were imple-mented to transform the patent documents into vectors. Thus, a single patent document would have three different types of vectors, an entropy-type vector, a chi-square-type vector, and an IPC-based vector. Besides the IPC-based method, which is introduced in Section 3 , the two comparing methods are presented as follows.

The first comparing method is used to convert every patent document into its corresponding entropy-type vector using the traditional entropy formula. The entropy formula: w  X  t  X  X  1  X  1 discrimination determinant. The computed discrimination w ( t ) of an index term t is used to decide whether the term in (patent document d ) is computed via the weight computation formula w  X  d ; t  X  X 
The second comparing method is used to convert every patent document into a corresponding chi-squares-type vector using the traditional chi-square formula. The discrimination X is calculated using the discrimination determinant formula X among all categories is calculated with X 2 a v g  X  P m j  X  1 the term will be. The top 70% of index terms with higher X formula for computing score for every attribute in a vector is the same as that used in the entropy-type vector. 4.3. Experimental results and evaluation
The performances of these methods are measured by two approaches, manual and automatic approaches. The manual approach compares the ranking results of different indexing vocabulary selection methods with the judgment of experts.
The main idea of this manual evaluation is to judge which method has more satisfactory result in finding similar-document tor than the latter pair. Then, we examine which indexing vocabulary selection method can rank the patents more correctly, code similarity.

In the manual evaluation, ten PhD students were invited to attend the user-evaluation experiment. This user-evaluation experiment consists of three sub-experiments. In each sub-experiment, we randomly select a target patent document from ument. The participants were asked to compare those three lists of similar documents in every sub-experiment and to rate get document, the score is higher, and vice versa. The result of the manual evaluation is presented in the table below.
As can be seen from Table 1 , the IPC-based method is significantly better than the entropy method and the chi-square method.

The automatic evaluation was conducted under the assumption that documents in the same branch of the IPC hierarchy would have higher similarity score than those in different branches. For example, documents with IPC codes  X  X  X 04C3/02 X  and  X  X  X 21B4/02 X  would be more similar than a pair of documents with IPC codes  X  X  X 04C3/02 X  and  X  X  X 02H9/00 X . Moreover, the dee-per their branch in the hierarchy, the higher the similarity score would be. For example, two documents with IPC codes  X  X  X 04C3/02 X  and  X  X  X 04C3/30 X  would be more similar than a pair of documents with IPC codes  X  X  X 04C3/02 X  and  X  X  X 21B4/02 X .
The indexing vocabulary created by the entropy method contained 1154 attributes (the top 70% of all index terms). The chi-square method also generated 1154 attributes in the indexing vocabulary. Vectors created using the IPC-based method included 7000 possible attributes and would always contain these same 7000 attributes. However, only 63 attributes in each
IPC-based vector actually had values bigger than zero since the documents covered 63 groups. Consequently, each IPC-based vector could also be viewed as a 63-attribute vector.

Based on the assumption, the contrast between the similarity score of pairwise similar documents in the same branch and evaluation. For each sub-evaluation, 10 patent documents from one branch and 10 others from another branch were ana-lyzed. The evaluation consisted of computing the similarity of every pair of documents, and the accuracy and performance similarity score for each pair of patent documents was computed using the traditional cosine similarity formula:
On the group level, the four sub-evaluations (sub-evaluations 1, 2, 3, and 4) compared documents with IPC codes from two different branches each. The first sub-evaluation calculated similarities between paired documents in  X  X  X 04C3 X  and between paired documents in  X  X  X 04C3 X  and  X  X  X 01L35 X , in  X  X  X 04B1 X  and  X  X  X 01L35 X , and in  X  X  X 04B1 X  and  X  X  X 01B1 X . The four sub-
These sub-evaluations were executed to estimate similarities between paired documents in  X  X  X 04C X  and  X  X  X 04B X , in  X  X  X 04C X  and  X  X  X 01L X , in  X  X  X 04B X  and  X  X  X 01L X , and in  X  X  X 04B X  and  X  X  X 01B X . The four class-level sub-evaluations (sub-evaluations 9, 10, 11, and 12) compared documents with IPC codes from two different branches. These sub-evaluations were performed to estimate similarities between paired documents in  X  X  X 04 X  and  X  X  X 04 X , in  X  X  X 04 X  and  X  X  X 01 X , in  X  X  X 04 X  and  X  X  X 01 X , and in  X  X  X 04 X  and  X  X  X 01 X . The four section-level sub-evaluations (sub-evaluations 13, 14, 15, and 16) compared documents with
IPC codes from two different branches. These sub-evaluations were executed to estimate similarities between paired docu-ments for section-level IPC codes  X  X  X  X  and  X  X  X  X ,  X  X  X  X  and  X  X  X  X ,  X  X  X  X  and  X  X  X  X , and  X  X  X  X  and  X  X  X  X .
As seen in Table 2 above, the IPC-based method X  X  performance was significantly better than the chi-square method or the py-type vector methods.

In the evaluation, a pair of vectors with a zero similarity score was viewed as null-similarity vectors and ignored in the comparison. The chi-square method obtained similarity score of zero for the last 20 X 30 pairs of patent documents. The en-set.
 y 100 percent of the first x document pairs are in the same branch.

For a perfect algorithm (represented by the ideal curve), all of the first 90 document pairs would be in the same branch ( C 2  X  C uously downward from point (90, 1) to point (190, 0.47), where 0.47 = 90/190. Therefore, this chart clearly indicates the overall performance of the entropy-type vector, chi-square-type vector, and IPC-based vector methods. The y-axis value of percentage values from sub-evaluations 1 X 16. For instance, the y value of x and 0.9). The IPC-based vector method performed better overall than either the entropy-type vector or chi-square-type vec-range were zero. This shows that the vectors created via the entropy method were weaker in distinguishing similar documents.

The results from the first part of the experiments indicate the superior accuracy and performance when using IPC-based veal the compatibility of the IPC-based method and the stability of the indexing vocabulary, are discussed below.
In the second part of the experiments, the patent documents in Doc set (II) were added to the original document set (Doc indexing vocabulary selection algorithms, the entropy method and the v shown below in Table 3 . For both the entropy and chi-square methods, no more than 80% and 70% of attributes were com-mon (overlapping) between D I and D I + 1/2 D II , and between D vocabulary generated via traditional methods is not stable when the document set changes. In contrast, the indexing vocab-ulary of the IPC-based method will always be the same, no matter how much the document set changes.
There were 819 attributes appeared in both indexing vocabularies created with the two traditional methods. Since the total number of discriminative attributes with respect to 70% discrimination threshold in both indexing vocabularies was 1154, only approximately 71% are common attributes. This is an indication of the second problem: the indexing vocabulary addition, the indexing vocabulary would differ when the parameter values of the two traditional algorithms were changed.
By setting different discrimination thresholds, the number of attributes that made up the indexing vocabulary would be changed dramatically. For example, when changing the discrimination threshold to 50% and 30%, the total numbers of attri-problem due to its fixed indexing vocabulary. 5. Conclusion
A novel method, IPC-based VSM, was proposed for generating vectors to represent patent documents. These vectors were uments (the IPC codes and hierarchy). The indexing vocabulary generated in IPC-based VSM was better at finding similar documents than either of the traditional methods (the entropy-type and chi-square-type vectors). This was demonstrated tiple applications involving searching for or retrieving patent documents.

For the future, we are considering building representative vectors for more diverse content fields in patent documents (e.g., description and claims). Furthermore, the compatibility of this IPC-based VSM model should be tested by applying it to other patent databases, such as TIPO and EPO. For practical usage, this model might be embedded in a document retrieval system to improve retrieval efficiency.
 References
