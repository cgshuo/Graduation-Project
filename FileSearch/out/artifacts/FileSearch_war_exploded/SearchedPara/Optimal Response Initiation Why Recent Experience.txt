 Institute of Cognitive Science Consider the task of naming the sum of two numbers, e.g., 14+8. Given sufficient time, individuals will presumably produce the correct answer. However, under speed pressure, mistakes occur. In most cognitive and motor tasks, speed-accuracy tradeoffs are observed: Individuals can respond accurately but slowly, or quickly but be prone to errors. Speed-accuracy tradeoffs are due to the fact that evidence supporting the correct response accumulates gradually over time (Rabbitt &amp; Vyas, 1970; Gold &amp; Shadlen, 2002). Responses initiated earlier in time will be based on lower-quality information, and hence less likely to be correct.
 On what basis do motor systems make the decision to initiate a response? Recent theories have cast response initiation in terms of optimality (Bogacz et al., 2006), where optimality might be defined as maximizing reward per unit time, or minimizing a linear combination of latency and error rate. Although optimality might be defined in various ways, all definitions require an estimate of the probability that each candidate response will be correct. We argue that this estimate in turn requires knowledge of the task difficulty , or specifically, the rate at which evidence supporting the correct response accumulates over time. If a task is performed repeatedly, task difficulty can be estimated over a series of trials, suggesting that optimal decision processes should show sequential effects , in which performance on one trial depends on the difficulty of recent trials. We describe an experimental paradigm that offers behavioral evidence of sequential effects in response initiation. Figure 1: An illustration of the MDM. Left panel: evidence accumulation for a 20-AFC task as a function of time, with  X  R  X  = . 04 ,  X  i 6 = R  X  = 0 ,  X  = . 15 . Middle panel: the posterior over responses, P ( R  X  | X ) , with a = . 04 and b = 0 , based on the diffusion trace in the left panel. Right panel: the posterior over responses, P (  X  R  X  | X ) , assuming  X  a = . 07 and  X  b = . 02 for the same diffusion trace. We summarize key phenomena from this paradigm, and show that these phenomena are predicted by a model of response initiation. Our work achieves two goals: (1) offering a better understanding of and a computational characterization of control processes involved in response initiation, and (2) offering a rational basis for sequential effects in simple stimulus-response tasks. Neurophysiological and psychological data (e.g., Gold &amp; Shadlen, 2002; Ratcliff, Cherian, &amp; Seg-raves, 2003) have provided converging evidence for a theory of cortical decision making, known as the diffusion decision model or DDM (see recent review by Ratcliff &amp; McKoon, 2007). The DDM is formulated for two-alternative forced choice (2AFC) decisions. A noisy neural integrator accumu-lates evidence over time; positive evidence supports one response, negative evidence the other. The model X  X  dynamics are represented by a differential equation, dx =  X dt + w , where x is the accumu-lated evidence over time t ,  X  is the relative rate of evidence supporting one response over the other (positive or negative, depending on the balance of evidence), and w is white noise, w  X  X  (0 , X  2 dt ) . The variables  X  and  X  are called the drift and diffusion rates. A response is initiated when the ac-cumulated evidence reaches a positive or negative threshold, i.e., x &gt;  X  + or x &lt;  X   X  . The DDM implements the optimal decision strategy under various criteria of optimality (Bogacz et al., 2006). Tasks involving n alternative responses ( n AFC) can be modeled by generalizing the DDM to have one integrator per possible response (Bogacz &amp; Gurney, 2007; Vickers, 1970). We refer to this generalized class of models as multiresponse diffusion models or MDM . Consider one example of an n AFC task: naming the color of a visually presented color patch. The visual system produces a trickle of evidence for the correct or target response, R  X  . This evidence supports the target re-{  X  i | i 6 = R  X  } , are zero. (We assume no similarity among the stimuli, e.g., an aqua patch pro-vides no evidence for the response  X  X lue X , although our model could be extended in this way.) The left panel of Figure 1 illustrates typical dynamics of the MDM. The abcissa represents processing time relative to the onset of the color patch, and each curve represents one integrator (color name). 2.1 A Decision Rule for the Multiresponse Diffusion Model Although the DDM decision rule is optimal, no unique optimal decision rule exists for the multiple-response case (Bogacz &amp; Gurney, 2007; Dragelin et al, 1999). Rules based on an evidence criterion X  X nalogous to the DDM decision rule X  X urn out to be inadequate. Instead, candidate served evidence up to the current time, P ( R  X  = r | X ) . In our notation, R  X  is the random variable denoting the target response, r is a candidate response among the n alternatives, and X = { x i ( j X  ) | i = 1 ...n,j = 0 ... T  X  } is a collection of discrete samples of the multivariate dif-fusion process observed up to the current time T . The simulations reported here use a decision rule that initiates responding when the accuracy of the response is above a threshold,  X  : This rule has been shown to minimize decision latency in the limit of  X   X  1 (Dragelin et al., 1999). However, our model X  X  predictions are not tied to this particular rule. We emphasize that any sensible rule requires estimation of P ( R  X  = r | X ) , and we focus on how the phenomena explained by our model derive from the properties of this posterior distribution.
 Baum and Veeravalli (1994; see also Bogacz &amp; Gurney, 2007) derive P ( R  X  = r | X ) for the case and  X  are known. (We introduce the  X  tgt and  X  nontgt notation to refer to these drift rates even in the absence of information about R  X  .) We extend the Baum and Veeravalli result to the case where  X  tgt is an unknown random variable that must be estimated by the observer. The diffusion rate of a random walk,  X  2 , can be determined with arbitrary precision from a single observed trajectory, but the drift rate cannot (see Supplementary Material  X  available at http://matt.colorado.edu/papers.htm). Therefore, estimating statistics of  X  tgt is critical to achieving optimal performance.
 Given a sequence of discrete observations from a diffusion process, x = { x ( j X  ) | j = 0 ... T  X  } , we can use the independence of increments to a diffusion process with known drift and diffusion rates, x ( t 2 )  X  x ( t 1 )  X  X  ( t 2  X  t 1 )  X , ( t 2  X  t 1 )  X  2 , to calculate the likelihood of x : where  X  x ( T ) = x ( T )  X  x (0) is a sufficient statistic for estimating  X  .
 Consider the case where the drift rate of the target is a random variable,  X  tgt  X  N ( a,b 2 ) , and the drift rate of all nontargets,  X  nontgt , is zero. Using Equation 2 and integrating out  X  tgt , the posterior over response alternatives can be determined (see Supplementary Material): The middle panel of Figure 1 shows P ( R  X  | X ,a,b ) , as a function of processing time for the diffusion trace in the left panel, when the true drift rate is known ( a =  X  tgt and b = 0 ). 2.2 Estimating Drift To recap, we have argued that optimal response initiation in n AFC tasks requires calculation of the posterior response distribution, which in turn depends on assumptions about the drift rate of the target response. We proposed a decision rule based on a probabilisitic framework (Equations 1 and 3) that permits uncertainty in the drift rate, but requires a characterization of the prior distribution of this variable.
 We assume that the parameters of this distribution, a and b , are unknown. Consequently, the observer When  X  tgt is not representative of the assumed distribution N ( X  a,  X  b 2 ) , performance of the model will be impaired, as illustrated by a comparison of the center and right panels of Figure 1. In the center panel,  X  tgt = . 04 is known; in the right panel,  X  tgt is not representative of the assumed distribution. The consequence of this mismatch is that X  X or the criterion indicated by the dashed horizontal line X  X he model chooses the wrong response.
 We turn now to the estimation of the model X  X  drift distribution parameters,  X  a and  X  b . Consider a sequence of trials, k = 1 ...K , in which the same decision task is performed with different stimuli, and the drift rate of the target response on trial k is  X  ( k ) . Following each trial, the drift rate can If the task environment changes slowly, the drift rates over trials will be autocorrelated, and the 1) } . The weighting of past history should be based on the strength of the autocorrelation. Using maximum likelihood estimation of a and b with an exponential weighting on past history, one obtains where k is an index over trials, and the { v i ( k ) } are moment statistics of the drift disribution, updated following each trial using an exponential weighting constant,  X   X  [0 , 1] : This update rule is an efficient approximation to full hierarchical Bayesian inference of a and b . When combined with Equations 1 and 3 it determines the model X  X  response on the current trial. The optimal decision framework we have proposed naturally leads to the prediction that performance on the current trial is influenced by drift rates observed on recent trials. Because drift rates determine the signal-to-noise ratio of the diffusion process, they reflect the difficulty of the task at hand. Thus, the framework predicts that an optimal decision maker should show sequential effects based on recent trial difficulty. We now turn to behavioral data consistent with this prediction. In any behavioral task, some items are intrinsically easier than others, e.g., 10+3 is easier than 5+8, whether due to practice or the number of cognitive operations required to determine the sum. By definition, individuals have faster response times (RTs) and lower error rates to easy items. However, the RTs and error rates are modulated by the composition of a trial block. Consider an experimental paradigm consisting of three blocks: just easy items ( pure easy ), just hard items ( pure hard ), and a mixture of both in random order ( mixed ). When presented in a mixed block, easy items slow down relative to a pure block and hard items speed up. This phenomenon, known as the blocking effect (not to be confused with blocking in associative learning), suggests that the response-initiation processes use information not only from the current stimulus, but also from the stimulus environment in which it is operating. Table 1 shows a typical blocking result for a word-reading task, where word frequency is used to manipulate difficulty. We summarize the central, robust phenomena of the blocking-effect literature (e.g., Kiger &amp; Glass, 1981; Lupker, Brown &amp; Columbo, 1997; Lupker, Kinoshita, Coltheart, &amp; Taylor, 2000; Taylor &amp; Lupker, 2001).
 P1. Blocking effects occur across diverse paradigms, including naming, arithmetic verification and calculation, target search, and lexical decision. They are obtained when stimulus or response characteristics alternate from trial to trial. Thus, the blocking effect is not associated with a specific stimulus or response pathway, but rather is a general phenomenon of response initiation. P2. A signature of the effect concerns the relative magnitudes of easy-item slowdown and hard-item speedup. Typically, slowdown and speedup are of equal magnitude. Significantly more speedup than slowdown is never observed. However, in some paradigms (e.g., lexical decision, priming) significantly more slowdown than speedup can be observed.
 P3. The RT difference bewteen easy and hard items does not fully disappear in mixed blocks. Thus, RT depends on both the stimulus type and the composition of the block.
 P4. Speed-accuracy tradeoffs are observed: A drop in error rate accompanies easy-item slowdown, and a rise in error rate accompanies hard-item speedup.
 P5. The effects of stimulus history are local, i.e., the variability in RT on trial k due to trial k  X  l decreases rapidly with l . Dependencies for l &gt; 2 are not statistically reliable (Taylor &amp; Lupker, 2001), although the experiments may not have had sufficient power to detect weak dependencies. P6. Overt responses are necessary for obtaining blocking effects, but overt errors are not. The blocking effect demonstrates that the response time depends not only on information accruing from the current stimulus, but also on recent stimuli in the trial history. Therefore, any explanation of the blocking effect must specify the manner by which response initiation processes are sensitive to the composition of a block. Various mechanisms of control adaptation have been proposed. Domain-specific mechanisms. Many of the proposed mechanisms are domain-specific. For example, Rastle and Coltheart (1999) describe a model with two routes to naming, one lexical and one non-lexical, and posit that the composition of a block affects the emphasis that is placed on the output of one route versus the other. Because of the ubiquity of blocking effects across tasks, domain-specific Table 1: RTs and Error Rates for Blocking study of Lupker, Brown, &amp; Columbo (1997, Expt. 3) accounts are not compelling. Parsimony is achieved only if the adaptation mechanism is localized to a stage of response initiation common across stimulus-response tasks.
 Rate of convergence. Kello and Plaut (2003) have proposed that control processes adjust a gain parameter on units in a dynamical connectionist model. Increasing the gain results in more rapid convergence, but also a higher error rate. Simulations of this model have explained the basic block-ing effect, but not the complete set of phenomena we listed previously. Of greater concern is the fact that the model predicts the time taken to utter the response (when the response mode is verbal) decreases with increased speed pressure, which does not appear to be true (Damian, 2003). Evidence criterion. A candidate mechanism with intuitive appeal is the trial-to-trial adjustment of an evidence criterion in the MDM, such that the easier the previous trials are, the lower the criterion is set. This strategy results in the lowest criterion in a pure-easy block, intermediate in a mixed block, and highest in a pure-hard block. Because a higher criterion produces slower RTs and lower error rates, this leads to slowdown of easy items and speedup of hard items in a mixed block. Nonetheless, there are four reasons for being skeptical about an account of the blocking effect based on adjustment of an evidence criterion. (1) From a purely computational perspective, the optimality X  X r even the behavioral robustness X  X f an MDM with an evidence criterion has not been established. (2) Taylor and Lupker (2001) illustrate that adaptation of an evidence criterion can X  X t least in some models X  yield incorrect predictions concerning the blocking effect. (3) Strayer and Kramer (1994) attempted to model the blocking effect for a 2AFC task using an adaptive response criterion in the DDM. Their account fit data, but had a critical shortcoming: They needed to allow different criteria for easy and hard items in a mixed block, which makes no sense because the trial type was not known in advance, and setting differential criteria depends on knowing the trial type. (4) On logical grounds, the relative importance of speed versus accuracy should be determined by task instructions and payoffs. Item difficulty is an independent and unrelated factor. Consistent with this logical argument is the finding that manipulating instructions to emphasize speed versus accuracy does not produce the same pattern of effects as altering the composition of a block (Dorfman &amp; Glanzer, 1988). Having argued that existing accounts of the blocking effect are inadequate, we return to our analysis of n AFC tasks, and show that it provides a parsimonious account of blocking effects. Our account is premised on the assumption that response initiation processes are in some sense optimal. Regardless specifically, the probability that a response will be correct conditioned on the evidence accumulated thus far, P ( R  X  = r | X ) . As we argue above, estimation of this probability requires knowledge of the difficulty (drift) of the correct response, and recent trial history can provide this information. The response posterior, P ( R  X  = r | X ) , under our generative model of the task environment (Equa-tion 3) predicts a blocking effect. To see this clearly, consider the special case where uncertainty in  X  tgt is negligible, i.e., b  X  0 , which simplifies Equation 3 to P ( R  X  = r | X )  X  exp a  X  x r ( T ) / X  2 . This expression is a Gibbs distribution with temperature  X  2 /a . As the temperature is lowered, the entropy drops, and the probabilities become more extreme. Thus, larger values of a lead to faster re-sponses, because the greater expected signal-to-noise ratio makes evidence more reliable. How does this fact relate to the blocking effect? Easy items have, by definition, a higher mean drift than hard items; therefore, the estimated drift in the easy condition will be greater than in the hard condition, With response times related to  X  a , an easy item will slow down in the mixed condition relative to the pure, and a hard item will speed up.
 Although we could fit behavioral data (e.g., Table 1) quantitatively, such fits add no support for the model beyond a qualitative fit. The reason lies in the mapping of model decision times to human response latencies. An affine transform must be allowed, scaling time in the model to real-world time, and also allowing for a fixed-duration stage of perceptual processing. A blocking effect of any magnitude in the model could therefore be transformed to fit any pattern of data that had the right qualitative features. We thus focus on qualitative performance of the model. Figure 2: Simulation of the blocking paradigm with random parameter settings. (a) Scatterplot of hard speedup vs. easy slowdown, where coloring of a cell reflects the log(frequency) with which a given simulation outcome is obtained. (b) Histogram of percentage reduction in the difference between easy and hard RTs as a result of intermixing. (c) Scatterplot of change in error rate between pure and mixed conditions for easy and hard items.
 The model has four internal parameters:  X  (diffusion rate),  X  (history decay),  X  (accuracy criterion), and n (number of response alternatives). In addition, to simulate the blocking effect, we must specify the true drift distributions for easy and hard items, i.e., a E , b E , a H , and b H . (We might also allow for nonzero drift rates for some or all of the distractor responses.) To explore the robustness of the model, we performed 1200 replications of a blocking simulation, each with randomly drawn values for the eight free parameters. Parameters were drawn as follows:  X   X  U ( . 05 ,. 25) ,  X   X  1  X  1 / (1 + U (1 , 20) (these values are uniform in the half-life of the exponential memory decay), a
H ) /U (3 , 10) , and b E = b H . Each replication involved simulating three conditions: pure easy, pure hard, and mixed. The pure conditions were run for 5000 trials and the mixed condition for 10000 trials. Each condition began with an additional 25 practice trials which were discarded from our analysis but were useful to eliminate the effects of initialization of  X  a and  X  b . The model parameters were not adapted following error trials. For each replication and each condition, the median response time (RT) and mean error rate were computed. We discarded from our analysis simulations in which the error rates were grossly unlike those obtained in experimental studies, specifically, where the mean error rate in any condition was above 20%, and where the error rates for easy and hard items differed by more than a factor of 10.
 Figure 2a shows a scatterplot comparing the speedup of hard items (from pure to mixed conditions) to the slowdown of easy items. Units are in simulation time steps. The dashed diagonal line indicates speedup comparable in magnitude to slowdown. Much of the scatter is due to sampling noise in the median RTs. The model obtains a remarkably symmetric effect: 41% of replications yield speedup &gt; slowdown, 40% yield slowdown &gt; speedup, and the remaining 19% yield exactly equal sized effects. The slope of the regression line through the origin is 0.97. Thus, the model shows a key signature of the behavioral data X  X ymmetric blocking effects (Phenomenon P2).
 Figure 2b shows a histogram of the percentage reduction in the difference between easy and hard RTs as a result of intermixing. This percentage is 100 if easy RTs slow down and hard RTs speed up to become equal; the percentage is 0 if there is no slowdown of easy RTs or speedup of hard RTs. The simulation runs show a 10 X 30% reduction as a result of the blocking manipulation. This percentage is unaffected by the affine transformation required to convert simulation RTs to human RTs, and is thus directly comparable. Behavioral studies (e.g., Table 1) typically show 20 X 60% effects. Thus, the model X  X ith random parameter settings X  X ends to underpredict human results. Nonetheless, the model shows the key property that easy RTs are still faster than hard RTs in the mixed condition (Phenomenon P3).
 Figure 2c shows a scatterplot of the change in error rate for easy items (from pure to mixed condi-tions) versus change in error rate for hard items. Consistent with the behavioral data (Phenomenon P4), a speed-accuracy trade off is observed: When easy items slow down in the mixed versus pure conditions, error rates drop; when hard items speed up, error rates rise. This trade off is expected, because block composition affects only the stopping point of the model and not the model dynam-ics. Thus, any speedup should yield a higher error rate, and vice versa. Interestingly, the accuracy Figure 3: Human (black) and sim-ulation (white) RTs for easy and hard items in a mixed block, con-ditional on the 0, 1, and 2 previ-ous items (Taylor &amp; Lupker, 2001).
 Last letter in the trial sequence in-dicates the current trial and trial or-der is left to right.
 criterion is fixed across conditions in the model; the differences in error rates arise because of a mis-match between the parameters a and b used to generate trials, and the parameters  X  a and  X  b estimated from the trial sequence. Thus, although the criterion does not change across conditions, and the criterion is expressed in terms of accuracy (Equation 1), the block composition nonetheless affects the speed-accuracy trade off.
 Although the blocking effect is typically characterized by comparing performance of an item type across blocks, sequential effects within a block have also been examined. Taylor and Lupker (2001, Experiment 1) instructed participants to name high-frequency words (easy items) and nonwords (hard items). Focusing on the mixed block, Taylor and Lupker analyzed RTs conditional on the context X  X he 0, 1, and 2 preceding items. The black bars in Figure 3 show the RTs conditional on the context. Trial k is most influenced by trial k  X  1 , but trial k  X  2 modulates RTs as well. This decreasing influence of previous trials (Phenomenon P5) is well characterized by the model via the exponential-decay parameter,  X  (Equation 5). To model the Taylor and Lupker data, we ran a simulation with generic parameters which were not tuned to the data: a E = . 05 , a H = . 04 , b E = b H = . 002 ,  X  = . 15 ,  X  = . 99 ,  X  = . 5 , and n = 5 . We then scaled simulation RTs to human RTs with an affine transform whose two free parameters were fit to the data. The result, shown by the white bars in Figure 3, captures the important properties of the data.
 We have addressed all of the key phenomena of the blocking effect except two. Phenomenon P1 concerns the fact that the effect occurs across a variety of tasks and difficulty manipulations. The ubiquity of the effect is completely consistent with our focus on general mechanisms of response initiation. The model does not make any claims about the specific domain or the cause of variation in drift rates. Phenomenon P6 states that overt responses are required to obtain the blocking effect. Although the model cannot lay claims to distinctions between overt and covert responses, it does to blocking effects. In turn,  X   X  tgt is determined at the point in the diffusion process when a response would be initiated. Thus, the model claims that selecting a response on trial k is key to influencing performance on trial k + 1 . We have argued that optimal response initiation in speeded choice tasks requires advance knowledge about the difficulty of the current decision. Difficulty corresponds to the expected rate of evidence accumulation for the target response relative to distractors. When difficulty is high, the signal-to-noise ratio of the evidence-accumulation process is low, and a rational observer will wait for more evidence before initiating a response.
 Our model assumes that difficulty in the current task environment is estimated from the difficulty of recent trials, under an assumption of temporal autocorrelation. This is consistent with the empiri-cally observed blocking effect, whereby responses are slower to easy items and faster to hard items when those items are interleaved, compared to when item types are presented in separate blocks. According to our model, mixed blocks induce estimates of local difficulty that are intermediate be-tween those in pure easy and pure hard blocks. The resultant overestimation of difficulty for easy items leads to increased decision times, while an opposite effect occurs for hard items. We formalize these ideas in a multiresponse diffusion model of decision making. Evidence for each response accrues in a random walk, with positive drift rate  X  tgt for the correct response and zero drift for distractors. Analytical derivations show that conversion of evidence to a posterior distribution over responses depends on  X  tgt , which acts as an inverse temperature in a Gibbs distribution. When this parameter is uncertain, with a prior estimated from recent context, error in the estimate leads to systematic bias in the response time. Underestimation of the drift rate, as with easy trials in a mixed block, leads to damping of the computed posterior and response slowdown. Overestimation, as with hard trials in a mixed block, leads to exaggeration of the posterior and response speedup. The model successfully explains the full range of phenomena associated with the blocking effect, including the effects on both RTs and errors, the patterns of slowdown of easy items and speedup of hard items, and the detailed sequential effects of recent trials. Moreover, the model is robust to parameter settings, as our random-replication simulation shows. The model is robust in other respects as well: Its qualitative behavior does not depend on the number of response alternatives (we have tried up to 1000), the decision rule (we have also tried a criterion based on the posterior ratio between the most and next most probable responses), the estimation algorithm for  X  a and  X  b (we have also tried a Kalman filter), and violations of assumptions of the generative model (e.g., nonzero drift rates for some of the distractors, reflecting the similarity structure of perceptual representations). The tradeoff between speed and accuracy in decision making is a paradigmatic problem of cognitive control. Theories in cognitive science often hand the problem of control to a homunculus. When control processes are specified, they generally involve explicit, active, and sophisticated mechanisms (e.g., conflict detection; A.D. Jones et al., 2002). Our model achieves sequential adaptation of control via a statistical mechanism that is passive and in a sense dumb; it essentially reestimates the statistical structure of the environment by updating an expectation of task difficulty. Our belief is that many aspects of cognitive control can be explained away by such passive statistical mechanisms, eventually eliminating the homunculus from cognitive science.
 Acknowledgments References
