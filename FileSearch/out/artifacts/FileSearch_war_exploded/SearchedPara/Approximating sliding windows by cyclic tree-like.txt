 1. Introduction analyses and statistics. This is the case of network monitoring, sensor networks, (1)  X  Return the size of the k -th packet of the data stream  X  one, assuming that recent information is more reliable and signi importance in the recent literature [2,7,13,23,38,60,61,64] .
 maintaining a good approximate representation of the data distribution is certainly relevant in the reduction is a key factor allowing query processing also in case of multiple scans on data. the reduction technique should support drill-down and roll-up operations. designed for a speci fi c kind of query for which they show a good behavior in terms of ef network load balancing.
 and satis fi es all the above properties. Our histogram, called representing range queries with less than 32 bits.
 summarization smoothes each data value by consulting the  X  shown to be small (and this is our case). 2. Contributions and organization of the paper
The second important issue faced in the paper is the ability of the proposed structure to ef sliding window size).

Then, we validate the method (from both the precision and the ef method demonstrates the signi fi cance of the proposal. A very large number of research results fall in the techniques proposed [45,48] , through an indirect experimental comparison. the case of small storage space is both realistic and signi sliding window), where our technique strongly outperforms the other ones.
The rest of the paper is organized as follows. A brief survey of the wide literature in the querying is given in the next section. In Section 4 , we give some preliminary de us to reduce the structure storage space and how to use C-TREE hierarchical structure of C-TREE enhances the advantages given from the bit-saving approach w.r.t. address in Section 7.1 how to set the parameter of C-TREE work. 3. Related work fi survey on the rest of the related literature.
 recent values. The main difference is that the former consists in a wavelets [63] some characteristics. Wavelets have been used in the of each transformation is a set of values, called wavelet coef data streams, the challenge is to update ef fi ciently the coef coef that try to reach this goal. [45,48] are, as our proposal, histogram-based methods. Histograms are the most commonly used method in the [55] , which divides the data into buckets of equal length. The strategy used to in such a way that  X  i =1 n SSE i is minimal, where SSE i relative error measures for estimating pre fi x range queries, that is,  X  x gain in terms of bucket number.
 [1,3,4,8,10,13,22,29,40,62,71] , which is in general very ef summaries of the data stream. This approach has been extended in [32,33] to ef aggregate SQL queries over a collection of input data streams. 4. Preliminaries
We use the followingnotations throughoutourpaper.Wemodela data stream D at the instant t asa integer values, where x i with 1  X  i  X  t is the value received at the instant i . Given an integer 1
D at the instant t is the sequence x t  X  w +1 , ... , x t
A range query Q ( q 1 , q 2 )on D at the instant t with 0 query is the sum of the 6 most recent elements. Finally, observe that in the rest of the paper the symbol ceil and Mod denotes the modulo operation. 5. The C-TREE approach
We start the description of our proposal by illustrating brie composed of three modules.
 stored is impossible. The available memory is typically signi At any instant, the query processor exploits the maintained synopses to return an estimate of the queries. second module of our architecture. It is a tree-like histogram, named Processor , is exploited to provide fast approximate answers to range queries. the problem of reducing the storage space required for representing the information included into compression technique based on a bit-saving approach. Finally, we show how range queries. 5.1. The C-TREE histogram
We describe C-TREE by starting from the initial con fi guration (i.e., the con origin of the data fl ow) and then by showing how C-TREE is updated after the arrival of new data.
In the initial con fi guration, C-TREE consists of: (1) A full binary tree with n levels, where 2  X  n  X  log 2 Algorithm 1 . Insert procedure
Require: D: the last value from the data stream; 1: B . e = B . e +1 2: B . s = B . s + D 3: if B . e = d  X  X  X  the buffer is full then 4: Node N=P 5:  X  = B . s  X  val ( N ) 6: for i :1 TO n do 7: val ( N )= val ( N )+  X   X  X  X  node updating 8: N =parent( N ) 9: end for 10: B . s =0  X  X  X  buffer emptying 11: B . e =0  X  X  X  buffer emptying 12: P =( P Mod 2 n  X  1 )+1  X  X  X  P points to the next leaf node 13: end if the buffer is less than d = w pointed by P and  X  be the difference between s and val ( N ) (i.e., the current value of N ). Then, to the path from N to the root of the binary tree (Lines 6 buffer.
 between the value of the parent node and the value of the sibling node. As a consequence, given a save only 2 n  X  1 nodes (instead of 2 n  X  1).
 Now we show an example of C-TREE building.

Example 5.1. Let h 35 ; 51 ; 40 ; 118 ; 132 ; 21 ; 15 ; 16 the sliding window size is 8. Initially, e =0, s =0, P =1 and the value of all nodes is 0. The stream is 51, thus e =2 and s =86. Since e = d , the leaf node pointed by P (that is, the belonging to the path from such a leaf node to the root are increased by the resulting C-TREE is reported. Therein (as well as in the other
Therefore, e =1 and s =18. At the next arrival, e =2 and s =47. Since e =2, the root are increased by  X  . Finally, P is updated to the value 2. The algorithm is O ( logw ).
 In the next section, we describe how it is possible to save storage space in the technique. 5.2. Bit-saving encoding representation. In particular: (2) The left-hand child node of the root is encoded by k b (3) All nodes belonging to the same level are represented by the same number of bits. estimation inside histogram buckets.
 different from v (due to scaling error introduced by the reduced scale). We denote (1) by v
We describe now how this reduced-scale representation is de stored in N is val  X  N  X  P c which corresponds to the value V = Round  X  scaling error) recovered from val  X  N  X  P c is value val ( N )=205. Suppose that we use 5 bits to encode the child node. Then, we have that Round  X  actually stored in this node using the binary encoding val  X  N  X  an approximate value of this node.
 b However, we do not adopt this assumption throughout the paper.

Concerning the storage space in bits required by C-TREE (having at least 2 levels), it is equal to: where d = w space required for the nodes of C-TREE . 5.3. Answering a range-sum query
In this section, we describe the algorithm used for evaluating the answer to a range query Q ( q denote by Q  X  q 1 ; q 2  X  the approximate answer to Q ( q the number of data stream elements per leaf.
 (recall that B includes all elements that are not yet inserted in latter only elements occurring in C-TREE leaves. Therefore, we have well de de fi ne the estimation of both types of queries.

Consider a query Q ( q 1 , q 2 ) of the fi rst type, i.e., such that q
Q  X  q 1 ; q 2  X  =  X  q 2  X  q 1 +1  X   X 
Consider now a query Q ( q 1 , q 2 ) of the second type, i.e., such that e belonging to leaves of C-TREE . Thus, the estimation may exploit the hierarchical aggregation given by contribution to the query estimation is given. We precisely de function that we have to call on the root node. In order to explain how this function works we have to de therein used:  X 
Given the two leaf nodes L 1 and L 2 with indices l 1 =  X  P de fi ne  X  as the set of all the leaf nodes lying in the range L
Algorithm 1 of Section 5.1 manages leaf nodes as a cyclic array). In words, involved in the range query.  X 
Given a non leaf node N , we denote by L ( N ) the set of leaf nodes descending from N .  X 
Given a leaf node N and a query Q ( q 1 , q 2 ), we de fi Algorithm 2 . Contribution function
Require : N: a node of C-TREE ; Q ( q 1 , q 2 ): a range query; 1: if N is a leaf then 2: return I ( N , Q ( q 1 , q 2 ))  X  X  X  the function ends 3: else 4: for each C N child of N do 5: if L( C N )  X  then  X  X  X  C N is completely inside Q ( q 1 6: return val ( C N ) 7: else if L( C N )  X   X   X  X  X  then  X  X  X  C N is partially inside Q ( q 8: return Contribution( C N , Q ( q 1 , q 2 )) 9: end if 10: end for 11: end if interpolation. No recursive call in this case occurs (Lines 1 either one of the following conditions holds: (1) C N is completely involved in the query (i.e., L ( C N (2) C N is partially involved in the query (i.e., L  X  C N (3) C N does not give any contribution because it is outside the range query (i.e., L ( C In case (1) the function returns val ( C N ) (Lines 5  X  6). In case (2) a recursive call on C corresponds to a null operation in the function.
 6. Advantages of the hierarchical approach approach w.r.t. fl at histograms. In order to demonstrate the above claim, we compare a n -level identi fi es over the sliding window 2 n buckets corresponding to the leaves. For both histograms we implement the bit-saving encoding. For node of the root of C-TREE (i.e., k ). Thus, the total number of bits required to encode the buckets of the (2 TREE , the number of bits necessary to encode its nodes, say SS Section 5.2 ). In Table 1 , we report the ratio between SS hierarchical structure of C-TREE results in a space reduction of about 75%. this bit encoding and by  X  v c the value that can be restored by window, which is at most R  X  w , (we recall that w is the size of the sliding window). We have that corresponding to V = Round  X  s i w  X  R  X   X  2 k  X  1  X  X  , whereas the restored value is encoding is F = j s i  X   X  s i k j , where | x | denotes the absolute value of x . It can be easily veri granularity of the used scale is R  X  w possible sum). As a consequence, the maximum scaling error is the half of the size of such intervals, which is precisely, the scale granularity is not exactly halved, since we move from 2 half of 1/2 (i.e., in general negligible w.r.t. 2 k  X  1 for suf k +1  X  2 2 , since the maximum allowed value is cannot state that the C-TREE error is the same as the fl at-histogram error, since the node increases. As a consequence, the maximum absolute error which we call accuracy gap , for several values of n and k and we in Section 7.1 we will introduce the requirement for C-TREE gap, which is less than 0.06% (see Table 2 ).

Therefore, as stated earlier, the hierarchical approach is advantageous w.r.t. the maximum scaling error we have a storage consumption of C-TREE 7. Experiments evaluate the performance of C-TREE with the purpose of comparing it with three selected techniques. The signi is motivated in Section 3 .

Besides C-TREE the examined techniques are (notations used throughout the section are reported in Table 3 ):  X  in order to demonstrate the superiority of our method w.r.t. [45,48] .  X  multi-resolution approximation scheme. This structure needs to store 3  X  relative error at most .
 1,000,000 and the range of data points is from 0 to 10 6 .In Figs. 3 default value in our experiments.
 set has been used also in [36,51,57,66] . The statistics of the most signi some cases where we compare the techniques for different sizes keeping equal the average accuracy. queries with size q ,with0.3  X  w  X  q  X  w . For each technique, we measure the error E  X  t  X  = queryset and e i rel is the relative error . e i rel is de 7.1. Setting the parameters of C-TREE Before presenting the experimental results, we discuss the problem of how to choose the value of the and the number of bits used to encode the left-hand child node of the root, respectively. that help us to set the value of the other parameters (i.e., n and k ). In the ( P ) varies. We note that the error is null until val ( P )reachesthevalue2 intheparentnodedoesnotaffecttherelativeerror.Moreover,wearguethattheparameter k directly in approximation.
 partially overlapping the query and the scaling approximation. For k quasi-constant value because the fi rst component depends only on n . off.
 to 11 (Line 1). This setting corresponds to the smallest C-TREE parameters. We check if there is still available storage space to increase by 1 the levels of that the size of C-TREE for n and k incompatible with the rules given above is not reported.
Algorithm 3 . Setting n and k 1: n =2, k =11  X  X  X  Initialization 2: while size( C-TREE n +1, k +1 )  X  storage space do 3: n = n +1, k = k +1  X  X  X  Add another level to the tree 4: end while 5: while size( C-TREE n , k +1 )  X  storage space do 6: k = k +1  X  X  X  Improve scaling approximation 7: end while In the following sections, we describe the results of the experimental comparison of we consider a C-TREE implementing the bit-saving encoding without the assumption of bounded value. Thus, b n and k are set according to Algorithm 3 . 7.2. Impact of data skew Section 7.7 .
 7.3. Impact of storage space w is 1024 elements and the storage space of SWAT is 3  X  log 18% for synthetic data and 7% for real-life data.
 estimation is, the interesting result of our experiments is that the methods behave differently, even in signi
Observing HIST, we have that increasing the number of buckets produces a great bene slowly. A similar trend, albeit less pronounced, is shown also by force the storage space beyond 200 words. The analysis here conducted concurs to validate our proposal, since very suitable to this case, where it strongly outperforms the other examined techniques. 7.4. Impact of window size
In this experiment, the synthetic data is a data streams of 1,000,000 elements produced by a Zip shown in Fig. 11 .
 error (less than 0.1%) for sliding windows larger than 2 19 than 2 19 . Moreover, the general trend is that the error decreases as the window size grows. This re the space consumption of SWAT is about four times greater than that of HIST and than that of HIST.
 accuracy of all techniques. Also in this experiment, C-TREE gap between C-TREE and the other methods becomes very wide for very large sliding windows. This con to work at very high compression ratios, as already argued thanks to the results of the previous section. 7.5. Impact of query size range query, the higher the number of buckets fully covering the query is. In this experiment, query sizes.
 Thanks to these experiments, we have veri fi ed that the behavior of involving only entire buckets), it happens that the query answer error is not biased. This basically re the
C-TREE histogram. 7.6. Running time results of this experiment.
 proven to be more accurate than [45,48] .
 Anyway, the results of the experiments highlight the good performance of previous sections, but also in terms of ef fi ciency.
 7.7. C-TREE versus Waves: are error bounds always effective? Under a critical perspective, one could argue that a technique like approximation error is given. This is of course true, since the theoretical analysis of guarantees given by Waves are really meaningful.

Besides the experiments described throughout the previous sections, we make here some speci study how much space is required by Waves in order to have the same accuracy as these experiments are reported in Fig. 13 .
 fi to guarantees about the error.
 8. Conclusion and future work value of our method, whose performances have been tested to be de able to give a good accuracy.

Our results open a number of interesting research directions. Our accurate and ef using a hierarchical structure, like the very recent Lattice Histogram [53] . Finally, the high capability of small space suggests us to study the effectiveness of its hardware implementation, which could be a pro fi saving encoding.
 Acknowledgment Engines).

References
