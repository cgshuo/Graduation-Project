 In the study of word embedding, words are mapped into a vector space such that semantically relevant words are placed near each other [ 1 , 16 , 17 ]. Word vectors are helpful for a wide range of NLP tasks by better capturing syntactic and semantic information than simple lexical features [ 8 , 14 , 23 ]. In this work, we explore to apply embedding methodology to model the intrinsic hidden semantic space of Web search. Figure 1 (a) gives an example to illustrate the intuition. The user has an information need in mind which can be represented as a 4-dimension vector, and each dimension indicates the relevance of his need with a particular semantic topic. Although the user intends to formulate queries conveying his need on the third dimension, the first two queries are not precise enough. Then the user issues the last query that well matches his need, and accordingly, the returned URLs satisfy him. To generalize, websites and query terms could also be involved and projected as vectors in the same space. Obviously, building such a space governing the search procedure could be useful for different tasks, such as query suggestion, result ranking, etc.
 We conduct the semantic space learning using search session data since a search session can be regarded as an instantiation of a particular information need. The learning task is cast as a vertex embedding problem on a set of graphs (built from sessions), where the elements in a session are represented as vertices and related vertices are connected by edges. The use of graph seems a suitable choice for session representation because it captures the semantic interactions among elements. Given user X  X  information need, represented as a semantic vector, the probability of obtaining a session is jointly determined by semantic meaning of involved elements, i.e., vertices of the session graph. Then we perform vec-tor learning for vertices via maximizing the log-likelihood of a training data of sessions.
 Our main contributions are: (1) a framework is proposed to learn a semantic space of Web search, and different elements (such as queries, URLs, and terms) are projected as vectors in this space. Vectors of different elements are directly comparable for semantic similarity calculation, and our model has good applica-bility to unseen data; (2) We use graph structure to represent session data and develop an approach for vertex vector learning on session graphs. Our model can capture fine-grained structure information in click-through data. It is flexible to incorporate other types of elements. (3) Our model is trained on a large query log data from a search engine. Extensive experiments are conducted to examine the efficacy of the constructed semantic space, and the results show that the learnt vectors are helpful for different tasks. Researchers had observed the potential of generating semantic vectors for search queries and Web pages [ 7 , 10 , 21 ]. Deep Structured Semantic Model (DSSM) [ 10 ] and Convolutional Latent Semantic Model (CLSM) [ 21 ] employ deep neural net-work to map the raw term vector of a query or a document to its latent semantic vector. Both of them use the full text of pages as input, and CLSM also captures the contextual information. The network architecture in our model is different from them and it can be trained more efficiently. Furthermore, our framework also learns vectors of terms and websites and can be easily extended to include other elements, e.g. users. The learnt term vectors enable our model to tackle unseen data. Some other studies attempted to learn binary vectors for queries or URLs and binary values show the relevance to semantic dimensions [ 18 ]. inative Projection Model (DPM) for query-document matching at the seman-tic level. More specifically, BLTM is a generative model and it requires that a query and its clicked documents share the same distribution over topics and contain similar factions of words assigned to each topic. DPM is learnt using the S2Net algorithm that follows the pairwise learning-to-rank paradigm. Pre-vious works also tried to learn query-document similarity from click-through data with implicit semantic representation, such as bipartite graph or transla-for query rewriting in sponsored search. Here our framework performs vector learning for a more comprehensive setting, i.e. including URLs, queries, terms, and websites.
 estimating neural network language model was proposed in [ 2 ]. Word2vec [ 16 ]is a development with a simple architecture for efficient training. A development of word2vec maps paragraphs into the same space of words [ 13 ], which shares sim-ilar architecture with our basic model. In comparison, our work focuses on mod-eling session graph data, and the session vector is incorporated in the networks to model users X  information need. More importantly, our tailor-made enhanced model elegantly projects terms into the same semantic space of search elements. Some other works employed neural networks to learn concept vectors of input text objects for similarity calculation under a supervised setting [ 25 ]. Given a set of search sessions S = { s i } n i =1 as training data, we aim at finding a semantic space to model Web search scenario so that the probability of observing the sessions in S is maximized. Let  X  denote the parameters of the space (i.e., the semantic vectors of elements in sessions). The log-likelihood objective is defined as follows: where P ( s i ;  X  ) is the probability of observing s i in the space. C ( e j ) denote the context elements of e j in s i .Let v ( e e ,and v ( s i ), having the same dimensionality, denote the information need of the user corresponding to s i . v ( s i ) is also called session vector. We assume that the probability of e j only depends on C ( e j )and v ( s P ( e ; C ( e j ) , v ( s i )). Therefore, P ( s i ;  X  ) is calculated as: P ( e ; C ( e j ) , v ( s i )) is calculated with the element vectors of C ( e (described later). To summarize, our task is to learn vectors for elements in search sessions so that the objective in Eq. 1 is maximized. To do so, we should transform each session into training instances of the form ( e e in s i . For better capturing the structure information in click-through data, we introduce a graph representation of session data. Then we develop two models for our learning task by extending an algorithm of word2vec [ 16 ]. 4.1 Session Graph and Training Instances In a search session, there are several types of elements. A user first issues a query, and some URLs are clicked in the result list. To obtain better results, she may issue more queries. During browsing a clicked page, the user may also browse other pages in the same website. Thus, the website is also involved as an element of the session.
 Session Graph. A search session graph G = { V, E } is defined as an undirected graph. The vertex set V includes search query, clicked URL, and website. The edges are added between (1) two successive queries; (2) a clicked page and the corresponding query; (3) a website and pages from it; (4) a website and a query that results in pages of this website clicked.
 An example is given in Fig. 1 (b). With a query q 1 , the user clicked two URLs, u and u 2 . Thus, the edges ( q 1 ,u 1 ) and ( q 1 ,u 2 ) are added. The websites h h of u 1 and u 2 are involved. Accordingly, we have the edges ( u ( u ,h 2 ), and ( q 1 ,h 2 ). After browsing u 1 and u 2 , the user issued q clicked more URLs. C ( e j ) is defined as adjacent elements of e we have C ( q 1 )= { q 2 ,u 1 ,u 2 ,h 1 ,h 2 } . Each training instance ( e that the target e j comes from session s i with context C ( e 4.2 Basic Learning Model The objective of our basic model can be written as follows: The network, called session2vec (s2v for short), for calculating P ( e v ( s i )) is given in Fig. 2 (a), which basically introduces an auxiliary vector into CBOW model [ 16 ], as previously did in [ 13 , 17 ]. The input layer takes the element the element vectors 2 is summed with v ( s i )toget x j . The output layer contains a Huffman tree with each distinct element in training sessions as a leaf. The more frequent an element is, the shorter its Huffman code is.
 of p .Let v p 1: L denote the vertices on p and we have v sequence of binary codewords on p .Let  X  1: L  X  1 denote the vectors associated with the inner vertices v p 1: L  X  1 on p , each of them has the same dimensionality along p (going through L  X  1 binary selections). Specifically, at vertex v select the branch having the codeword c l with probability P ( c defined with the sigmoid function  X  : P ( e j ; C ( e j ) , v ( s i )) is calculated as: work in Fig. 2 (a). We use the SGD algorithm to learn the vectors of elements, inner nodes of Huffman tree, and sessions. During learning, each instance generated in Sect. 4.1 is fed into the network and its related parameters are updated. The learning procedure is performed by scanning all training instances one or a few times depending on efficiency requirement. With session2vec, each element (i.e., query, URL, and website) in training data is projected as a vector. However, s2v cannot deal with unseen elements in new data. To solve this problem, we propose an enhanced learning model, ses-sion2vec+ (s2v+), as depicted in Fig. 2 (b). The upper part of s2v+ is the same as s2v. The lower part, having the same architecture, incorporates the term-based training instances in the form of ( t k ,C ( t k ) ,s session vector is shared by two parts as a bridge to align the dimensions of ele-ment vectors and term vectors, learnt by the upper and lower parts, respectively. Thus, terms and elements are embedded in the same space, and term vectors can be utilized to build vectors for new elements such as unseen queries. Another advantage of s2v+ is that these term vectors can help solve the sparsity issue in s2v, since the vectors of sparse elements learnt in s2v might be unreliable. 5.1 Training Instances for Term Vector Learning We build term-based training instances by post-processing element-based formed into a set of term-based instances. Let t k denote a term in query e the URL title of e j .Each t k corresponds to one term-based instance ( t where C ( t k ) is the context of t k containing all terms of queries or URL titles in C ( e j ). Noun phrase chunking is done and a single term here may refer to a phrase, e.g.  X  X ew York Times X . Because t k could also come from URL titles, our model is augmented to handle unseen query terms with title terms. 5.2 Enhanced Learning Model For s2v+, we define a new objective function as follows: where P ( s i ;  X  ) is the probability of s i calculated with the term-based instances: where P ( t k ; C ( t k ) , v ( s i )) is the probability of t (  X  ; S )= where superscripts e and t indicate the calculations with element instances and term instances respectively. 3 types of training instances from one session are processed separately in each iteration. We first proceed with ( e j ,C ( e j ) ,s i ) and let ( j, l ) = log P ( c After combined with Eq. 4 , ( j, l ) is written as: With some derivations, the partial derivatives with respect to x follows: where  X  is the learning rate. x e j is an intermediate vector Our aim is to learn v ( e )for e  X  C ( e j ), to do so, v ( e ) is updated with the partial derivative of x log P ( c t l ;  X  t l , x e k ), and update formulae are: where t  X  C ( t k ). When updating the session vector v ( s are considered: The learning procedure for s2v can be easily derived by simplifying that of s2v+. 6.1 Training Data We employ a query log data set from Baidu search engine, including 10,413,491 unique queries, 13,126,252 URLs, 1,006,352 websites, and 3,965,539 terms (com-ing from queries and URL titles). Session boundaries are detected with a hybrid method of time-gap-based detection and task-based detection [ 3 , 12 ]: the interval of two consecutive queries is no more than 15 min; and the similarity between two consecutive queries is no less than a threshold. To calculate this similar-ity, we employ term vectors trained in a baseline system (CBOW of word2vec, described later) to represent query terms and the sum of them is used as query vector. The cosine similarity threshold is 0.5. In total, we collected 23,676,669 sessions, each session contains 2.1 queries and 2.3 clicks on average. 6.2 Case Study Semantic Dimensions. We show salient elements and terms of three dimen-sions (manually entitled  X  X tar X ,  X  X ovie resource X  and  X  X oftware resource X ), generated by s2v+, in Table 1 . These terms and elements have the largest val-ues in these dimensions, meanwhile the frequency is singers/actors from mainland China and Hong Kong are output as salient terms. The queries mainly search for the personal information of stars. For websites, the entertainment homepages of five top websites are listed. In  X  X ovie resource X , popular movie titles are output as salient terms and the queries are about movies X  showtime and scheme song. Interestingly, although  X  X tar X  and  X  X ovie resource X  are related, our model generates different salient term sets and query sets for them, focusing on different aspects. Presumably, it is because searching stars and searching movies are two different information needs. The element-based and term-based training instances are generated from individual sessions, thus the two information needs are well identified in learning. The websites involved in these two needs are also different and can help differentiate them to some extent.
 Learnt Vectors. The term vector  X  (Peking University) X  and the query vector  X  X eking University X  learnt by s2v+ are given in Fig. 3 . The two vectors are generally correlated well (cosine similarity is 0.591). Thus, we can reasonably derive the vector of an unseen query with term vectors. The two vec-tors also show some differences. The reason is that  X  X eking University X  appears in queries or URL titles with diverse meanings, such as  X  X MBA program in Peking University X  and  X  X eking University Health Science Center X . For query  X  X eking University X , the dominant information need is to find the university X  X  homepage or encyclopedia page (Fig. 3 ).
 7.1 Settings Variants of Our Framework. S2v+ can generate vectors of elements and terms (from queries and URL titles). According to how to use these vectors, we have three variants: S2v+.A directly uses element vectors; S2v+.B interpolates an element vector and the term vectors from this element. For instance, for query q , we first calculate the sum of its term vectors, then the sum is summed with v ( q ), and the result is used as the final vector of q ; S2v+.C uses the sum of term vectors of an element as its vector, and it is applicable for both existing elements in the training data and new elements. Comparison Systems. We employ the CBOW algorithm of word2vec for short) as a baseline and run it on a corpus containing 1 billion Chinese Web pages (much larger than the training data used in our model), and a vector is generated for each term. PLSA [ 9 ] is another baseline, and we run it on a pseudo-document corpus generated from our training data. Each pseudo-document is composed of queries and URL titles of a training session, and topic vectors of terms are learnt. 7.2 Results for Query Similarity Prediction We analyze our framework with a similar query ranking task to illustrate the behaviors of its variants. NDCG [ 11 ] is employed as the metric and 100 dimen-sions are used for all systems.
 Task Description and Evaluation Data. Each testing query has 5 candidate queries, and the task is to rank the candidates according to their similarity with the testing query. Cosine similarity is calculated with the learnt vectors. We employ an annotated data set containing 500 testing queries, each of which has 5 candidate queries. A Likert scale with three levels is employed to assess the candidates. Specifically, 3 means strongly relevant (e.g.  X  X ill Gates X  and  X  X ounder of Microsoft X ), 2 means relevant (e.g.  X  X ill Gates X  and  X  X teve Jobs X ), and 1 means irrelevant, (e.g.  X  X ill Gates X  and  X  X pider-Man X ). Each candidate is assessed by 3 assessors and the average score is rounded to the nearest relevance level. On average, each testing query has 1.7 strongly relevant candidates and 1.2 relevant candidates. These 500 testing queries are divided into observed part ( Q obs ) and unobserved part ( Q unobs ). Q obs has 129 testing queries, each testing query and its candidate queries are observed in our training data. Q unobs has 371 testing queries.
 Analysis of S2v Results on Q obs. For s2v, query vectors are directly learnt, and for the baselines, the vector of a query is obtained by summing its term vectors. The results of different methods are given in the left part of Table 2 . S2v can outperform the baselines. Specifically, on NDCG@1, s2v outperforms PLSA and w2v by about 8 % (significant with P&lt; 0 . 01 in paired t-test) and 2 % ( P&lt; 0 . 05), respectively. The reasons might be: (1) our training instances are generated from session graphs. In each graph, the elements have similar semantic meanings so that the contextual elements and the target element (i.e., e training instance are semantically more cohesive. Such training instances bring in less noise; (2) PLSA and w2v generate query vectors by summing the term vectors, however, their term vectors are learnt without considering query and session semantics and cannot well derive query vector. In contrast, s2v directly generates query vectors; (3) s2v maintains a session vector, and the semantic of a session is normally less ambiguous than a query. Thus, the session vector is helpful to guide vector learning for queries by deriving more precise information need. W2v also performs well, and its large training corpus helps deal with sparse queries more effectively.
 Analysis of S2v+ Results. Sparsity will hinder the effectiveness of learnt embeddings by s2v. In addition, if a query was not observed in the training data, s2v cannot learn a vector for it. S2v+ conducts vector learning for terms in a unified model. The learnt term vectors can be used in different variants as described in Sect. 7.1 .
 Results on Q obs. To examine the effectiveness of s2v+, we first compare its variants with s2v on Q obs and the results are given in the right part of Table 2 . S2v+.A outperforms s2v by 1 % on NDCG@1 ( P&lt; 0 . 05). This shows that the unified learning in s2v+ generates better vector representation for queries. It is because the lower part of the network in Fig. 2 (b) for term vector learning can help overcome the sparsity problem to some extent. Specifically, with the term-based learning part, the derived session vectors are more accurate since the sparsity problem of terms is less severe. As a result, accurate session vectors will help learn better query vectors. S2v+.B slightly outperforms s2v+.A, which shows using term vectors to interpolate the query vector can further solve the sparsity problem.
 generated by s2v+ can better derive the query vector. It is probably because the unified learning in s2v+ can better align the semantic meanings of queries and terms with the session vector as bridge. The term vectors from the baselines are not as effective as ours for deriving query vectors. S2v+.C performs better than s2v+.A and s2v+.B. The reason is that s2v+.A and s2v+.B use query vectors, but the sparsity problem affects the reliability of vectors of low-frequency queries. To have a closer look at the sparsity problem, we divide Q obs into 5 equal buckets, A, B, C, D, and E, according to the descending order of frequency. Similarly, candidates queries are also divided into 5 buckets, A X , B X , C X , D X , and E X . We evaluate the variants in different intervals and the results are shown in Table 3 . In each cell, the results of s2v+.A, s2v+.B, and s2v+.C are given in the upper, middle, and lower positions. The largest value is underscored, in bold and green, the smallest value is in italic and red. As shown in the upper left of Table 3 , S2v+.A and s2v+.B perform better for more frequent queries, When the queries become less frequent, moving toward the lower right corner, the performance of s2v+.A and s2v+.B declines. Meanwhile, s2v+.C is not affected much and outperforms the other two.
 Results on Q unobs. We also examine the performance of s2v+.C on Q unobs and compare it with w2v and PLSA baselines. The results are given in Table 4 . S2v+.C achieves 8 % and 4 % improvements ( P&lt; 0 . 05) on NDCG@1 compared with PLSA and w2v, respectively. This demonstrates term vectors generated with our model are more effective due to the unified learning and introducing the session vector. Combining the results in Tables 2 and 4 , s2v+.C is the most effective system. 7.3 Results for URL Ranking Setup. Here we examine the performance of our model in the task of URL ranking. The relevance between a query and its candidate URLs is computed as cosine similarity of their vectors. Still, a query vector is obtained by summing the vectors of its terms. For each URL, its vector is obtained by summing the vectors of terms in its title. We introduce another baseline BM25 [ 19 ] which is a ranking function commonly used to rank documents according to their relevance to a search query. Specifically, our BM25 baseline is a revision of the original BM25 formula to conduct normalization of term frequency according to [ 22 ]and revise inverse document frequency according to [ 5 ]. As discussed above, s2v+.C is the most effective variant and it also has better adaptability for unseen data. In addition, URL vectors also face the sparsity problem. Therefore, we conduct the comparison between s2v+.C and baselines.
 Evaluation Data. This data set has 1,000 queries of various length and popu-larity. On average, each query has 19.8 marked URLs retrieved by the query. A Likert scale with five levels is employed to assess the relevance of each URL. Results. The results are given in Table 5 . All vector-based methods can out-perform BM25. Our model achieves the best results in all cases. Specifically, it outperforms the baselines by about 4 % to 9 % on NDCG@1 ( P&lt; 0 . 01). Recall that we train s2v+ with term-based training instances (together with element-based) from both URL titles and queries. Presumably, such mixed instances make the learnt term vectors more capable for capturing the similarity between queries and URLs. Another reason might be that s2v+ jointly considers different types of elements (such as queries and URLs) in learning, thus the learnt term vectors can implicitly encode the semantic similarity among these elements to some extent.
 7.4 Results for Website Similarity Prediction Setup. In this task, the vectors from different systems are employed to calculate website similarity. For PLSA and w2v, the vector of a website is obtained by summing the terms vectors of its homepage title. Our model has three variants, namely, s2v.S, s2v+.S, and s2v+.T. S2v.S and s2v+.S use the learnt website vectors directly. S2v+.T uses website vectors by summing term vectors, as is done for baselines.
 Evaluation Data. This data set contains 500 testing websites with different popularity. Each testing website has 5 candidate websites. A Likert scale with three levels is employed to assess the candidate websites. Specifically, 3 means strongly relevant (e.g.  X  X ports.sina.com.cn X  and  X  X ports. qq.com X ), 2 means rele-vant (e.g.  X  X ports.sina.com.cn X  and  X  X ww.sina.com.cn X ), and 1 means irrelevant, (e.g.  X  X ports. sina.com.cn X  and  X  X il.qq.com X ). On average, each testing website has 1.6 strongly relevant candidates, and 1.4 relevant candidates. All the testing and candidate websites are covered by our training data set.
 Results. The results are given in Table 6 . The variants of our model outperform the baselines. Specifically, s2v+.S achieves 3 % to 10 % improvements ( P&lt; 0 . 05) on NDCG@1 compared with baselines. Among the variants, s2v+.S and s2v.S perform better than s2v+.T. It shows that the directly learnt website vectors are more effective than summing term vectors of titles for similarity prediction. This observation is different from that of queries. One reason might be that the sparsity problem for websites is not severe in training data. Another possible reason is that homepage titles, such as  X  X he best car website in China X , contain irrelevant terms.
 In this paper, we proposed a framework to uncover a semantic space for Web search. We develop two neural-network-based models, i.e. session2vec and ses-sion2vec+, to learn vectors for elements and terms. Compared with previous studies, our framework can perform hidden semantic learning for different types of elements. Moreover, our models enable the learning of vector representation on graph data. Experimental results indicate that the learnt vectors are helpful for a few tasks in Web search. For the future work, one direction is to extend our framework to model the interest profile of users. Another direction is to enhance the session graph with the information of click order and dwell time. A third direction is to derive the real-time information need with the partial information of the current session.

