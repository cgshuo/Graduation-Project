 Jesse Davis jesse.davis@cs.kuleuven.be KU Leuven, Celestijnenlaan 200a, Heverlee 3001, Belgium V  X  X tor Santos Costa vsc@dcc.fc.up.pt Peggy Peissig, Michael Caldwell { peissig.peggy,caldwell.michael Marshfield Clinic, 1000 N Oak Ave, Marshfield, WI 54449 USA Elizabeth Berg, David Page { berg,page } @biostat.wisc.edu Statistical relational learning (SRL) (Getoor &amp; Taskar, 2007) focuses on developing learning and reasoning for-malisms that combine the benefits of relational repre-sentations, such as relational databases or first-order logic, with those of probabilistic, graphical models for handling uncertainty. SRL is especially applicable to domains where it is important to incorporate infor-mation from multiple different relations in a learned model and explicitly model uncertainty. One emerg-ing application that meets both criteria is analyzing electronic medical records (EMR). An EMR is a re-lational database that stores a patient X  X  clinical his-tory: disease diagnoses, procedures, prescriptions, lab results, etc. Using EMRs it is possible to build models to address important medical problems such as pre-dicting which patients are most at risk for having an adverse response to a certain drug. However, EMRs pose challenges due to their relational schemas (i.e., the database contains separate relational tables for di-agnoses, prescriptions, labs, etc.), longitudinal nature (e.g., time of diagnosis may be important), and be-cause different patients may have dramatically differ-ent numbers of entries in any given table, such as diag-noses or vitals. Furthermore, it is important to model the uncertain, non-deterministic relationships between patients X  clinical histories and current and future pre-dictions about their health status.
 Latent structure poses a substantial challenge for using machine learning to analyze EMR data. A patient X  X  clinical history records information about specific pre-scribed medications (e.g., name, dosage, duration) or specific disease diagnoses. It does not explicitly men-tion important connections between different medica-tions or diagnoses, such as which other medications could be prescribed to treat an illness. This informa-tion may be necessary to build accurate models. Med-ical resources provide some relevant information. For example, the ICD9 diagnoses codes are a tree struc-tured hierarchy over a vocabulary of more than 14,000 concepts. Yet, it is impossible for a single, pre-defined hierarchy to capture all the medically-relevant group-ings of diseases or medications for a particular predic-tion task. For example, suppose we are using machine learning to detect if certain antibiotics carry a risk of liver damage, which is a known effect. For any one of these antibiotics, the number of people taking it may be small enough that the association is too weak to meet an interestingness threshold, such as the sup-port threshold in association rule mining. Yet if the algorithm examines all antibiotics, or all antibiotics grouped by their mechanism of action, most drugs in the class do not exhibit the association. Detecting the assocation with the adverse event requires discovering the right grouping of antibiotics , and that grouping is unlikely to appear in existing heterarchies.
 Addressing this problem requires automatically de-tecting which diseases or medicines are informative for a specific prediction task and grouping them to-gether. While most state-of-the-art SRL systems are unable to effectively cope with the challenge of latent structure, a few approaches address this problem via a relational clustering of objects and/or relations in a domain (Kemp et al., 2006; Kok &amp; Domingos, 2007; 2008; Sutskever et al., 2010). Intuitively, objects are clustered together if they occur in similar contexts (i.e., participate in the same relations). Some of these approaches aim at discovering relevant structure in the data as opposed to addressing a specific predic-tion task. Furthermore, a top-down, divisive search is computationally infeasible for complex domains such as EMRs which contain large numbers of objects (e.g., diseases, drugs) (Kemp et al., 2006; Kok &amp; Domingos, 2007). SNE (Kok &amp; Domingos, 2008) is a scalable pre-clustering approach that searches for latent rela-tionships among all objects in a domain. Thus it may miss subtle interactions relevant to the task at hand. This paper proposes LUCID (L atent U nderlying C oncept I nvention on-D emand), a novel approach that automatically discovers clusters of objects in a rela-tional domain and makes use of the invented clusters in the final learned model. Rather than ignoring the target task and simply pre-clustering objects, LUCID dynamically clusters objects , possibly hierarchically, in a demand-driven fashion. If it identifies a useful but low coverage regularity in the data, LUCID tries to strengthen it by selecting an object in the regularity and grouping it together with other objects and/or ex-isting groups to expand its coverage. It evaluates if the proposed grouping strengthens the regularity and re-sults in a more accurate learned model. LUCID allows each object to participate in multiple different group-ings, as an object may appear in multiple contexts. For example, a drug could be in different groupings related to its mechanism, indications, contraindications, etc. We motivate and evaluate our proposed approach on the specific task of predicting adverse drug reactions (ADRs) from EMR data. ADRs are the fourth-leading cause of death in the United States and represent a ma-jor risk to health, quality-of-life and the economy. The pain reliever Vioxx TM alone was earning US$2.5 billion per year before it was found to double the risk of heart attack and was pulled from the market while other similar drugs remain on the market. Additionally, ac-curate predictive models for ADRs are actionable. If a model is found to be accurate in a prospective trial, it could be used to avoid giving a drug to those at high-est risk of an ADR. Using three real-world ADR tasks, we demonstrate that the proposed approach produces a more accurate model than using pre-defined medical hierarchies and several other machine learning based approaches. Furthermore, our algorithm uncovered la-tent structure that a doctor with expertise in our tasks deemed to be interesting and relevant. LUCID dynamically constructs clusters that capture latent relationships between different objects in a do-main. It does so in the context of the SRL algorithm VISTA (Davis et al., 2007), which combines automated feature construction and model learning into a sin-gle process. VISTA uses first-order definite clauses, which can capture relational information, to define (bi-nary) features. These features then become nodes in a Bayesian network. 2.1. Datalog VISTA defines features using the non-recursive Dat-alog subset of first-order logic. 1 The alphabet con-sists of three types of symbols: constants, variables, and predicates. Constants (e.g., the drug name Propranolol ), which start with an upper case let-ter, denote specific objects in the domain. Variable symbols (e.g., disease ), denoted by lower case letters, range over objects in the domain. Predicate symbols P /n , where n refers to the arity of the predicate and n  X  0, represent relations among objects. An atom able. A literal is an atom or its negation. A clause is a disjunction over a finite set of literals. A definite clause is a clause that contains exactly one positive literal. Definite clauses are often written as an impli-cation B =  X  H , where B is a conjunction of literals called the body and H is a single literal called the head. All variables in a definite clause are assumed to be universally quantified. 2.2. VISTA VISTA uses definite clauses to define features for the statistical model. Each definite clause becomes a bi-nary feature in the underlying statistical model. The feature receives a value of one for an example if the data about the example satisfies (i.e., proves) the clause and it receives a value of zero otherwise. VISTA starts by learning a model M over an empty feature set F S . This corresponds to a model that predicts the prior probability of the target predicate. Then it repeatedly searches for new features for a fixed number of iterations. In each iteration, VISTA first selects a random seed example and then performs a general-to-specific, breadth-first search through the space of candidate clauses. To guide the search pro-cess, it constructs the bottom clause by finding all facts that are relevant to the seed example (Muggleton, 1995). VISTA constructs a rule containing just the target attribute, such as ADR ( pid ), on the right-hand side of the implication. This means that the feature matches all examples. It creates candidate features by adding literals that appear in the bottom clause to the left-hand side of the rule, which makes the feature more specific (i.e., it matches fewer examples). Re-stricting the candidate literals to those that appear in the bottom clause helps limit the search space while guaranteeing that each generated refinement matches at least one example.
 VISTA converts each candidate clause into a feature, f , and evaluates f by learning a new model (e.g., the structure of a Bayesian network) that incorporates f . In principle, any structure learner could be used, but VISTA typically uses a tree-augmented Naive Bayes model (Friedman et al., 1997). VISTA evaluates each f by comparing the generalization ability of the cur-rent model F S versus a model learned over a feature set extended with f . VISTA does this by calculating the area under the precision-recall curve (AUC-PR) on a tuning set. AUC-PR is used because relational domains typically have many more negative examples than positive examples, and the AUC-PR ignores the potentially large number of true negative examples. 2 In each iteration, VISTA adds the feature f 0 to F S that results in the largest improvement in the score of the model. In order to be included in the model, f 0 must improve the score by a certain percentage-based threshold. This helps control overfitting by pruning relatively weak features that only improve the model score slightly. If no feature improves the model X  X  score, then it simply proceeds to the next iteration. At a high-level, the key innovation of LUCID occurs when constructing feature definitions. Here, the al-gorithm has the ability to invent hierarchical clusters that pertain to a subset of the objects (i.e., constants) in the domain. Intuitively, constants that appear in the same grouping share some latent relationship. Dis-covering and exploiting the latent structure in the fea-ture definitions provides several benefits. First, it al-lows for more compact feature definitions. Second, by aggregating across groups of objects, it helps identify important features that may not otherwise be deemed relevant by the learning algorithm.
 To illustrate the intuition behind LUCID, we use a running example about ADRs to the medication Warfarin TM , which is a blood thinner commonly pre-scribed to patients at risk of having a stroke. However, Warfarin is known to increase the risk of internal bleed-ing for some patients. Consider the following feature definition: Drug ( pid , date1 , Terconazole )  X  This rule applies only to those patients who satisfy all the conditions on the left hand side of rule. Con-ditioning on whether a patient has been prescribed Terconazole limits the applicability of this rule. Ter-conazole is an enzyme inducer, which is a type of medication known to elevate a patient X  X  sensitivity to Warfarin. However, many other drugs in the en-zyme inducer class (e.g., Rifampicin and Ketocona-zolegive) are frequently prescribed instead of Tercona-zole, which makes this feature overly specific. A po-tentially stronger feature would replace Terconazole with an invented concept such as enzyme inducer or Warfarin elevator .
 Yet, these concepts are not explicitly encoded in clin-ical data. By grouping together related objects, LU-CID captures latent structure and is able to learn more general features. For example, we could generalize the previous rule as follows: Cluster1 ( did )  X  Drug ( pid , date1 , did )  X  The definition for Cluster1 , shown in Cluster defi-nition 3 below, represents latent structure among a group of medicines. Rule (2) is more general than Rule (1), as it is true of any patient that has taken any of the medications assigned to Cluster1 . Rule (1) is more restrictive because it is only true of patients that have taken Terconazole.
 The three key elements of LUCID introduced in the next subsections are: (i) how to represent latent struc-ture, (ii) how to learn the latent structure, and (iii) how the overall algorithm functions. 3.1. Representing Latent Structure LUCID X  X  goal is to capture hierarchical latent struc-ture about specific objects in the domain. Conceptu-ally, clusterings represent the latent structure. LUCID introduces one unary predicate, such as Cluster1 / 1 , for each cluster it invents. The predicate is true of any object that is assigned to the cluster it represents. Once the definition has been learned, it can appear in learned rules such as Rule (2). LUCID can assign objects to clusters in two ways.
 First, LUCID can assign individual objects to a clus-ter. This captures that specific constants are inter-changeable in some cases. For example, Terconazole, Rifampicin and Ketoconazole are all enzyme inducers, and a doctor could reasonably prescribe any of them. Thus LUCID could invent a new cluster, generically called Cluster1 , as follows: These statements simply assign these drugs to Cluster1 . There is no limit on the number of objects that can be assigned to each invented cluster. Second, LUCID can reuse previously discovered con-cepts to represent more high-level, hierarchical struc-ture. It can do so in the following manner: Just as before, the first two statements assign spe-cific drugs to Cluster2 . The key step is the third statement, where all the constants that have been assigned to Cluster1 are assigned to Cluster2 as well. Once a proposed grouping has been used in a feature that has been included in the model, it is available for future reuse during the learning proce-dure. Reusing previously discovered concepts allows the algorithm to automatically explore tradeoffs be-tween fine-grained grouping (e.g., enzyme inducers) and more high-level groupings (e.g., Warfarin eleva-tors) that may be present in the data. Furthermore, it allows the algorithm to build progressively more com-plex concepts over time. 3.2. Learning Latent Structure The key step in the algorithm is discovering the latent structure. Given a feature definition (e.g., Rule (1)) and a constant to replace with a cluster (e.g., Ter-conazole), latent structure is learned according to a two-step process. The first step rewrites a feature def-inition so that it applies to a set of objects, that is an invented cluster, instead of a single, specific object. The second step decides which objects to assign to the newly invented cluster.
 Feature Redefinition LUCID rewrites the feature definition by replacing the reference to the specific con-stant with a variable and conjoining an invented latent structure predicate to the end of the rule, as shown in Algorithm 1. For example, Rule (1) would be trans-formed into Rule (2), where Rule (2) has the variable did instead of the constant Terconazole , and the fea-ture definition has been extended with the invented predicate Cluster1 ( did ).
 Algorithm 1 RewriteRule(Feature f , Object Const , Feature Set F S , Data D )) Let B be the body of f
Let H be the head of f /*Replace Const with newVar in B */ Substitute( B, Const , newVar ) B 0 = C i ( newVar )  X  B
LearnCluster( B 0 =  X  H , Const , F S, D ) return: B 0 =  X  H Assigning Objects to the Cluster In order to learn a definition for the invented latent predicate, such as Cluster1 in Rule (2), LUCID needs to decide which objects to include in the cluster. LUCID em-ploys a bottom-up, data-driven approach for assigning objects to the cluster. The cluster initially contains a single constant and LUCID greedily adds additional constants of the same type to it.
 LUCID creates the initial cluster by assigning the replaced constant to it. In the running ex-ample, this corresponds to following statement: Cluster1 ( Terconazole ). Next, it tries to identify a set of candidate constants of the same type that could be added to the cluster. Ideally, the candidate set Algorithm 2 LearnCluster(Feature f , Object Const , Feature Set F S , Data D ) C i = { Const }
Cand =ConstNearMiss( f )  X  X  C j | cluster C j , j &lt; i } /*Score the extended feature set*/ score =AUCPR( F S  X  f, D ) repeat until No addition to C i improves score would include each object of the same type as well as every previously invented cluster about the type. This is often computationally infeasible due to the large number of objects. For example, when predicting ad-verse reactions, the data contains information about thousands of drugs and diseases. The central challenge is to identify a small but promising set of candidates to include in a grouping. LUCID restricts its candidate set to objects from  X  X ear miss X  examples. To illustrate this idea, consider the following two rules: Weight ( pid , date1 , w )  X  w &lt; 120  X  ADR ( pid ) (5) Drug ( pid , date1 , Terconazole )  X  The second rule, by adding the condition Drug ( pid , date1 , Terconazole ), applies to fewer patients. Some patients may match Rule (5), but not the more specific Rule (6) because they took a similar, but not identical medication. In a sense, Rule (5) provides a context where a drug like Terconazole may be prescribed. Thus, focusing on the medications prescribed to the set of patients that match Rule (5) but not Rule (6) can potentially identify which medications can be prescribed in place of Terconazole. Only considering objects from  X  X ear miss X  examples has two desirable properties. First, it only adds objects to a cluster that improve a rule X  X  positive minus negative coverage score, meaning the addition is guaranteed to increase recall without harming precision, at least on the training set. Second, all objects with this property are considered, giving the heuristic a completeness property. The candidate set thus includes (i) all previously invented clusters about the same type, and (ii) all constants that appear in examples covered by a rules X  immediate predecessor (i.e., Rule (5)) but not the rule itself (i.e., Rule (6)). Given the candidate set, LUCID tries to extend the definition of the cluster under construction. It adds each candidate, in turn, to the cluster. The benefit of the modified cluster is measured by seeing if the score of the retrained model, which includes the fea-ture that makes use of the extended cluster definition, improves. LUCID greedily selects the single constant that results in the largest improvement in the model X  X  score. This procedure iterates until no addition im-proves the model X  X  performance or the set of candidate constants is empty. The end result is a cluster defini-tion as illustrated by either Cluster definition (3) or Cluster definition (4). 3.3. Overall Algorithmic Structure Algorithm 3.3 provides an overview of LUCID. It uses the same procedure as VISTA to construct an initial set of candidate features. Next, LUCID considers aug-menting each feature definition with an extra, invented predicate by calling the procedure outlined in Subsec-tion 3.2. This is the key difference with VISTA as this results in a larger and much more expressive set of can-didate features. However, due to the large number of candidate features, it is prohibitively expensive to con-sider inventing and incorporating a learned cluster into each feature definition. Therefore, LUCID restricts it-self to inventing a latent concepts only for features that meet the following two conditions: Condition 1: The rule under consideration im-proves the score of the model. This provides ini-tial evidence that the rule is useful, but the algo-rithm may be able to improve its quality by model-ing latent structure. Discarding rules that initially exhibit no improvement dramatically improves the algorithm X  X  efficiency.
 Condition 2: The rule must contain a constant of a type that the user identified as a candidate for hav-ing latent structure. This helps reduce the search space as not all types of constants will exhibit la-tent structure.
 For each candidate feature that meets these two crite-ria, LUCID attempts to discover latent structure. It invokes the procedure outlined in Subsection 3.2 and adds the feature it constructs, which contains an in-vented latent predicate, to the set of candidate fea-tures. From the expanded candidate feature set, LU-CID picks the highest scoring feature f best and adds it to the feature set. If f best contains an invented cluster, then that cluster is made available for reuse in subse-quent iterations. If no feature improves the model X  X  score, then LUCID goes to the next iteration. The procedure terminates after running for a fixed number of iterations.
 Algorithm 3 LUCID(Data D , Maximum Iteration m )
F S = { X  X  repeat until Reaching iteration m return: F S In this section, we evaluate our proposed approach on three real-world data sets. In all tasks, we are given patients that take a certain medication and the goal is to model the patients that have a related ADR. We compare the following algorithms.
 VISTA This is the basic VISTA algorithm (Davis et al., 2007). It does not have the ability to learn clusters that capture latent structure.
 Expert+VISTA In this setting, we augmented each data set with hand-crafted hierarchies for both di-agnoses and medications. For diagnoses, we used all the levels of the ICD9 hierarchy. For medications, we use a hierarchy developed by our medical col-laborators. We then run VISTA on the augmented data set. Thus, instead of being limited to the spe-cific disease diagnoses or medications recorded for a patient, EXPERT+VISTA can learn rules that ex-ploit information about diseases or medications that appear higher up in the expert defined hierarchies. SNE+VISTA This approach uses the SNE sys-tem (Kok &amp; Domingos, 2008) as a pre-clustering step to identify latent structure. SNE is an unsu-pervised algorithm for automatically clustering to-Pos. examples 160 144 102 Neg. examples 2,134 1,440 1,020 Unique drugs 2,590 2,316 2,044 Unique diagnoses 7,912 8,389 7,286 Drug facts 3,518,467 603,503 335,065
Diagnoses facts 3,653,487 691,591 436,934 gether objects that are related to each other. First,
SNE analyzes the training data and produces a clus-tering of the objects in the domain. To exploit
SNE X  X  clusters in VISTA, we create one unary pred-icate for each clustering that is true of every object assigned to that cluster. Second, VISTA is run on the data set which has been augmented with SNE X  X  learned clustering. Thus the learned rules can in-corporate the clusters discovered by SNE.
 LUCID This is the approach proposed in this paper. Expert+LUCID This gives the proposed approach access to the expert defined hierarchies.
 We first describe the data sets we use. Then we present and discuss our experimental results. 4.1. Task Descriptions Our data comes from a large multispecialty clinic that has been using electronic medical records since 1985 and has electronic data back to the early 1960 X  X . We have received institutional review board approval to undertake these studies. For all tasks, we have access to information about observations (e.g., vital signs, family history, etc.), lab test results, disease diagnoses and medications. We only use patient data up to one week before that patient X  X  first prescription of the drug under consideration. This ensures that we are build-ing predictive models only from data generated before a patient is prescribed that drug.
 Characteristics of each task can be found in Table 1. We now briefly describe each task. Selective Cox-2 inhibitors (e.g., Vioxx TM ) are a class of pain relief drugs that were found to increase a patients risk of having a a myocardial infarction (MI) (i.e., a heart attack). Angiotensin-converting enzyme inhibitors (ACEi) are a class of drugs commonly prescribed to treat high blood-pressure and congestive heart failure. It is known that in some people, ACEi may result in angioedema (a swelling beneath the skin). Warfarin is a commonly prescribed blood-thinner that is known to increase the risk of internal bleeding for some in-dividuals. On each task the goal is to distinguish be-tween patients who take the medicine and have an ad-verse event (i.e., positive examples) and those who do not (i.e., the negative examples). 4.2. Methodology and Results We performed stratified, ten-fold cross-validation for each task. For SNE, we used the default parameter settings. We sub-divided the training data and used five folds for training the model structure and param-eters and four folds for tuning. We require that a can-didate feature result in at least a 2% improvement to the AUC-PR in order to be considered for acceptance. We set all parameters to be identical for all approaches. The only difference between VISTA and LUCID based approaches is that LUCID can introduce latent struc-ture. Without this ability, the algorithms would con-struct and evaluate identical candidate feature sets. Table 2 reports the average AUC-PRs for each of the tasks. LUCID alone outperforms all the non-LUCID approaches on all three tasks. In two of the three, the addition of the ICD9 codes further improves LUCID X  X  performance, while in the other one it degrades LU-CID X  X  performance. On the Selective Cox-2 and War-farin domains, LUCID results in relatively large im-provements in AUC-PR, of 12% and 41%, respectively when compared to VISTA. On these two domains, LU-CID improves the AUC-PR by 25% and 23% com-pared to SNE+VISTA. LUCID offers improvements of between 2% and 14% compared to using the ex-pert provided heterarchies. These improvements come with little run-time cost. Across all three tasks, the average run time per fold was approximately 1 hour for VISTA, 8 hours for SNE+VISTA, 1.7 hours for VISTA+Expert, 1.1 hours for LUCID and 1.6 hours for LUCID+Expert. SNE+VISTA is slow because running SNE took between 1 and 16 hours per fold. There is clearly a benefit to incorporating the latent information about the relationships between medicines and between diseases. In particular, it is beneficial to include the data-driven latent structure and the ex-pert provided heterarchies. Interestingly, the learned structure is always more valuable than the expert heterarchies in terms of building an accurate model. This indicates that these resources either lack the rel-evant groupings of terms or their groupings are not at the right granularity for these prediction tasks. Ex-pert+VISTA achieves the best non-LUCID based re-sult on two of three tasks. Combining LUCID with the expert knowledge is not always useful. The most likely explanation is that this approach has the largest search space and it falls into a local optimum. The utility of pre-clustering prior to learning, represented by SNE+VISTA, is less clear. This approach improves on the baseline on two tasks, but it only does better than the hand-crafted heterarchy on one task. A visual inspection of SNE X  X  learned clustering show that it dis-covers reasonable concepts from a medical perspective. However, it tends to discover more high-level concepts that are perhaps less useful to the prediction task at hand. In constrast, LUCID X  X  discovery is more task directed and it can also leverage partial feature defi-nitions to detect correlations among objects that arise in the context of a specific rule. 4.3. Learned Groupings Another important evaluation measure is whether LU-CID invents interesting and relevant concepts. We pre-sented several invented clusters to a medical doctor with expertise in circulatory diseases. We focus our discussion on structures from the Selective Cox-2 do-main. The expert noted a cluster containing the drugs diltiazem, a calcium-channel blocker, and clopidogrel (Plavix TM ), an antiplatelet agent. These two cardiac drugs are frequently used in acute coronary syndrome, especially after angioplasty. In terms of diseases, the expert highlighted a cluster describing cardiac catheter and coronary angioplasty, which are consistent with acute coronary syndrome and means that a patient is at a high risk of having a MI. Another cluster of in-terest involved cholecystectomy, a procedure that re-moves the gall blader, as in females the diagnosis of MI is often confused with gall bladder pain. Finally, the expert remarked on a cluster containing hearing loss as a finding that deserves further investigation. SRL lies at the intersection of relational learning and graphical model learning. Thus methods for discov-ering latent structure build on predicate invention in relational learning (e.g., (Muggleton &amp; Buntine, 1988)) and latent variable discovery in propositional graphi-cal models (e.g., (Elidan et al., 2000)). Our approach is closely related to Dietterich and Michalski X  X  (1983) relational learning work on internal disjunction. This operation replaces a constant with a disjunction of sev-eral constants. We go beyond this work by allowing re-use of an internal disjunction and most importantly, by explicitly modeling and reasoning about uncertainty in the data and the invented predicates.
 Our work is not the first to combine ideas from la-tent variable discovery and predicate invention to per-form cluster-based concept discovery in uncertain, re-lational domains (Kemp et al., 2006; Kok &amp; Domin-gos, 2007; 2008; Sutskever et al., 2010; Xu et al., 2006; Popescul &amp; Ungar, 2004). Popescul and Ungar (2004) use a pre-processing step that learns clusterings and then treats cluster membership as an invented feature during learning. In contrast, LUCID uses the learning process to guide cluster construction and it also allows reuse of clusters as part of new clusters. Sutskever et al. (2010) focus only on binary relations, whereas our domains have higher arity relations. Empirically, the SNE system (Kok &amp; Domingos, 2008), which we com-pare to, outperformed the IRM (Kemp et al., 2006) and MRC (Kok &amp; Domingos, 2007) on a domain of similar complexity and size to those we considered. We presented LUCID, a novel algorithm that discovers latent structure through a dynamic, demand-driven procedure. During learning, it can invent clusters about objects in the domain and include them in the learned model. We evaluated LUCID by learning mod-els from electronic medical record (EMR) data to pre-dict which patients are most at risk to suffer a given adverse drug reaction (ADR). On all three tasks we in-vestigated, LUCID resulted in improved performance compared to a standard SRL baseline, a pre-clustering based latent structure discovery algorithm, and using expert-constructed medical heterarchies. Additionally, it produced meaningful latent structure. Important directions for further research include applications to other ADRs, other tasks in learning from EMRs, and other types of relational databases.
 We thank Daniel Lowd, Maurice Bruynooghe and the reviewers for their helpful feedback. JD is par-tially supported by the Research Fund K.U.Leuven (CREA/11/015 and OT/11/051), EU FP7 Marie Curie Career Integration Grant (#294068) and FWO-Vlaanderen (G.0356.12). VSC is funded by ERDF through Programme COMPETE and by the Portuguese Government through FCT Foundation for Science and Technology projects LEAP (PTDC/EIA-CCO/112158/2009) and ADE (PTDC/EIA-EIA/121686/2010). MC, PP, EB and DP gratefully acknowledge the support of NIGMS grant R01GM097618-01.

