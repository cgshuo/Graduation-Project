 How can we optimize the topology of a networked system to bring a flu under control, propel a video to popularity, or stifle a network malware in its infancy? Previous work on information diffusion has focused on modeling the diffusion dynamics and selecting nodes to maximize/minimize influ-ence. Only a paucity of recent studies have attempted to address the network modification problems, where the goal is to either facilitate desirable spreads or curtail undesirable ones by adding or deleting a small subset of network nodes or edges. In this paper, we focus on the widely studied linear threshold diffusion model , and prove, for the first time, that the network modification problems under this model have supermodular objective functions. This surprising property allows us to design efficient data structures and scalable al-gorithms with provable approximation guarantees, despite the hardness of the problems in question. Both the time and space complexities of our algorithms are linear in the size of the network, which allows us to experiment with millions of nodes and edges. We show that our algorithms outperform an array of heuristics in terms of their effectiveness in con-trolling diffusion processes, often beating the next best by a significant margin.
 Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications  X  Data Mining General Terms: Algorithms, Theory, Experimentation Keywords: diffusion networks; network optimization; su-permodularity; approximation
The diffusion of physical, conceptual or digital substances over networks has been studied in many domains such as epidemiology [10], social media [16], and computer and mo-bile [19] networks. These studies have resulted in an array of models aiming to capture the diffusion dynamics, among which the most well-known are the linear threshold (LT) model, the independent cascade (IC) model, and the Sus-ceptible Infected Recovered (SIR) model. Starting with the work of Domingos and Richardson on viral marketing [6], a lot of research has concentrated on how one can pick a small set of source nodes, whose initial adoption of a given sub-stance would trigger maximal spread in the network. The seminal work of Kempe et al. [12] showed that source node selection for influence maximization is a submodular maxi-mization problem under the IC and LT diffusion models, and therefore admits a simple greedy algorithm with approxima-tion guarantees. Their result was followed by a whole line of research on source node selection in various related infor-mation diffusion contexts [4, 7, 9].

In contrast to these previous works where the diffusion networks remain unchanged , we are rather interested in prob-lems of modifying the topology of a diffusion network to ei-ther facilitate the spread of desirable substances, or curtail the spread of undesirable ones. One can consider deleting edges or nodes to minimize possible undesirable spread, such as that of a virus, disease or rumor, or one can consider adding edges or nodes to facilitate, for example, the spread of information or dispersal of endangered species. For in-stance, in disease control, authorities may consider disallow-ing travel between certain pairs of cities to curb the spread of a flu epidemic. On the other hand, social media websites can recommend to users additional information outlets to follow to increase the spread of ideas and memes. The mod-ification setting is particularly relevant when the agent op-timizing the topology does not have control over the sources of the spread, but is able to change some subset of the edges or nodes that he has access to. Hence, our setting is most relevant when the agent in question is looking to strategically design the topology, as opposed to reacting to a particular event. Thus, we will later assume that the set of nodes that are likely to be sources of diffusion are known, but which ones among them are the sources of a particular diffusion event follows some probability distribution (e.g. uniform). For example, in an information network, we may know which popular news sites are typically the sources of viral news, but are uncertain as to which of these sites will be the source of a particular piece of news. Despite the broad practical relevance of the diffusion network modification problems, existing results are very limited, and lack in either formal optimality guarantees or in algorithmic efficiency.

Related work. Under the SIR model, some positive net-work optimization results exist: Tong et al. [22] address the edge deletion (addition) problem by approximately minimiz-ing (maximizing) the eigenvalue of the adjacency matrix. In addition, methods have been designed to optimize sur-rogates for diffusion spread under SIR [8, 20]. Instead of maximizing/minimizing the spread of substances directly, these methods typically optimize a static property of the network, in the hope of optimizing diffusion. For instance, Schneider et al. [20] proposed  X  X etweenness centrality X  as a heuristic for immunizing nodes or removing edges under the SIR model, while  X  X egree centrality X  was adopted in [8] to protect against virus propagation in email networks.
Under the IC model, existing results are negative: Sheldon et al.[21] study the problem of node addition to maximize spread, and provide a counter-example showing that the ob-jective function is not submodular. Thus, they resort to a principled but expensive approach based on sample aver-age approximation and mixed integer programming, which provides provable optimality guarantees but cannot scale to large networks. Bogunovic [1] addresses the node deletion problem. For the edge deletion problem under the IC model, Kimura et al.[14] apply the greedy algorithm used by Kempe et al. [12] for source node selection, but do not provide any approximation guarantees. We note that the edge deletion objective that we consider is not supermodular under IC; a simple counter-example is provided in the extended version of this paper.

Network optimization under the LT model is still largely unexplored, and this paper seeks to fill that gap. The greedy approach has been used in [13] to delete edges under the LT model, albeit without any analysis of the supermodularity of the objective, nor formal approximation guarantees. More recently, Kuhlman et al. [15] propose heuristic algorithms for edge removal under a simpler deterministic variant of the LT model. In contrast, we describe principled algorithms for edge deletion and addition by exploiting supermodularity of the objectives under the more general stochastic LT model. Most related are [3, 9], where node deletion under the  X  X om-petitive X  LT model (a variant of stochastic LT) is addressed using supermodularity. The node deletion problem can be considered a special case of the  X  X nfluence blocking maxi-mization X  problem described in [3, 9]. However, the super-modularity results in those works are limited to node dele-tion, whereas our theoretical framework leads to supermod-ularity results for edge deletion and addition, node deletion and addition.

Our contributions. In this paper, we will address net-work topology optimization for diffusion under the linear threshold model . We will focus on two network modifica-tion problems involving the deletion of edges for minimizing spread and the addition of edges for maximizing spread 1 : Proof techniques used in the source node selection litera-ture are inadequate for our more complex network modi-fication problems. Instead, we propose a novel theoretical framework (Section 3) that yields surprising results, namely that the objective function in both problems is supermodu-lar , a property that has positive algorithmic implications. In particular, minimization of a supermodular function under cardinality constraints, although typically an NP-hard prob-lem, admits a greedy algorithm with approximation guaran-tees [18]. Similarly, cardinality-constrained supermodular
One can also consider the analogous node deletion and ad-dition problems, and our theoretical and algorithmic results on the finer-scale edge problems can be extended trivially. maximization has recently been shown to admit a simple modular approximation scheme [11]. Our finding, combined with these combinatorial optimization results allows, for the first time, the design of efficient diffusion-aware algorithms with approximation guarantees for the network modification problems under the LT model, filling a gap in the existence research literature on this topic.

We address several challenges in transforming the two gen-eral supermodular approximation algorithms into efficient and practical approaches for our setting. Directly imple-menting the supermodular optimization algorithms is im-practical, since evaluating the objective function given a set of source nodes is #P-hard in general [4]. We exploit the correspondence between the LT model and the  X  X ive-edge graph X  construction [12], and estimate the objective func-tion using a sample of random live-edge graphs. Neverthe-less, a naive application of the supermodular approximation schemes to the sample of random live-edge graphs will re-sult in runtime quadratic in the network size, an approach that does not scale to modern problems with millions of nodes and edges. To tackle this issue, we design two data structures, the descendant-count trees for the edge deletion problem, and the neighbor-counting graphs for the edge ad-dition problem, in order to support approximate evaluation of the objective function. These data structures can be con-structed in time linear in the network size , and queried in constant time , allowing us to scale the supermodular opti-mization algorithms to networks with millions of nodes.
Finally, we evaluate our algorithms on both synthetic and real-world diffusion networks and compare the quality of the solutions to scalable alternative approaches, based on opti-mizing structural properties of the networks. Our algorithms can lead to as large as 10-20% additional efficacy for edge deletion, and up to 100% for edge addition, compared to the other approaches. In terms of scalability, our algorithms can scale to large networks with millions of nodes and edges.
In this section, we will provide background on the linear threshold (LT) model for diffusion processes [12], which will be at the center of this study. This model is well-suited for representing threshold behavior, where entities in a network have a  X  X ipping point X  in terms of the fraction of neighboring nodes that have to adopt the diffusing substance, beyond which they would adopt it themselves. For instance, in a social setting, an individual may refrain from voicing his opinion, until a significant fraction (e.g. half) of his friends have voiced a similar opinion. Underlying the LT model is a weighted directed graph G = ( V,E,w ), called the influence graph , where V is a set of n nodes and E is a set of m directed edges, and w : V  X  V  X  [0 , 1] is a weight function. For edges ( u,v ) /  X  E we ignore the value of w ( u,v ). We further require that P u :( u,v )  X  E w ( u,v )  X  1 for each node v . Starting from a source node (or an initially activated node) S 0 = { a } , a cas-cade then proceeds in discrete time steps t = 0 , 1 , 2 ,... as follows: (1) at t = 0, every node v first independently se-lects a threshold  X  v uniformly at random in the range [0 , 1], reflecting the uncertainty as to users X  true thresholds; (2) subsequently, an inactive node v becomes activated at time nodes activated up to time t ; (3) finally, the process termi-nates if no more activations are possible.
Given an influence graph G = ( V,E,w ), the influence function  X  ( a,G ) of a source node a  X  V is defined as the expected number of active nodes at the end of the diffusion process,  X  ( a,G ) = E  X  v [ | S  X  | ], where the expectation is taken with respect to the randomness of the node thresholds  X  v
Kempe et al. [12] showed that the influence function can be computed in an alternative way using what is referred to as  X  X ive-edge graphs X , a construction that is more amenable to mathematical analysis. More specifically, a random live-edge graph X is generated as follows: Independently for each node v  X  V , at most one of its incoming edges is selected with probability w ( u,v ), and no edge is selected with prob-ability 1  X  P u :( u,v )  X  E w ( u,v ). Note that the set of nodes of X is equal to V , the set of  X  X ive X  (or sampled) edges E X X is a subset of E , i.e. , E X  X  E , and these edges are un-weighted. Then, the influence function can be alternatively computed as  X  ( a,G ) = E X [ r ( a,X )] = X where X G is the space of all possible live-edge graphs based on G , Pr[ X | G ] is the probability of sampling a particular live-edge graph X , and r ( a,X ) is the set of all reachable nodes in X from source a . If we define function p ( v,X,G ) := w ( u,v ) , if  X  u : ( u,v )  X  E X 1  X  P which is the probability of the configuration of incoming edges for node v in X ; then, the probability of a particular live-edge graph X is
We will show that the objective functions of the edge dele-tion and addition problems are supermodular in the next section. However, the proofs require some properties beyond those used in [12]. Thus, we will first give some intuition as to why these properties are needed. We will denote the mod-ification of an influence graph G by deleting or adding a set of edges S respectively by Consider the monotonicity of the influence function as de-fined in Eq. (1), with respect to the set of source nodes A :  X  ( A  X  a,G )  X   X  ( A,G ) is a sum over X G , and so proving that Pr[ X | G ]  X  r ( A  X  a,X )  X  Pr[ X | G ]  X  r ( A,X )  X  0 for the single live-edge graph X  X  X G suffices to prove monotonic-ity, in this case. In contrast, consider the monotonicity of the influence function, with respect to the set of edges in the graph:  X  ( a,G \ S )  X   X  ( a,G \ ( S  X  X  e } )). The issue here lies in that the former function sums over X G \ S , whereas the latter sums over X G \ ( S  X  X  e } ) : since the set of live-edge graphs and the associated probabilities involved in the computation of the influence function will change as edges are deleted, it is not obvious that this function is monotone at all. Similar difficulties apply to proving supermodularity.

In this section, we will prove four properties related to the space of live-edge graphs, which will form the basis of our later analysis. More specifically, we are concerned with
Deleting a set S from E will result in a new influence graph G \ S , which will generate a new space of live-edge graphs, X G \ S , and the associated live-edge graph probabil-ities, Pr[ X | G \ S ]. Furthermore, we will divide the space X
G \ S , according to the edge e , into three disjoint partitions (see Fig. 1(left)):
Note that the probabilities of a live-edge graph X common to both X G and X G \{ e } may or may not change. Specifically, if node v has another incoming edge g = ( u 0 ,v ) in X , then Otherwise, if node v has no incoming edge in X , then
Pr[ X | G ]  X  Pr[ X | G \{ e } ] =  X  w ( u,v ) Y concerning nodes v 0 6 = v are exactly the same, and We establish the following four relations between the spaces of live-edge graphs, and defer their proofs to the appendix. See Fig. 1 for illustrations.
Our first result establishes a one-to-one mapping between the elements in partition X e G \ S and X  X  G \ S .

Proposition 1. For every live-edge graph X  X  X  X  G \ S there exists a corresponding live-edge graph e X  X  X  e G \ S vice versa. If X = ( V,E X ) , then e X = ( V,E X  X  X  e } ) .
Our second result relates partitions X  X  e G \ S and X from the influence graph G \ ( S  X  X  e } ) with an additional edge e deleted from G \ S . This result also shows that the X
Our third result further partitions X  X  G \ S into a collec-tion of sets {  X  i } , and establishes a one-to-one mapping be-g = ( u 0 ,v 0 ) is an edge in E \ S with v 0 6 = v . partitioned into t sets {  X  i } t i =1 such that, for every  X  exists a corresponding X i  X  X   X  G \ ( S  X  X  g } ) , and vice versa. Our fourth result relates the probability of the partition  X  i  X  X   X  G \ S to the probability of the corresponding live-edge graph X i  X  X   X  G \ ( S  X  X  g } ) . This result is a sequel to the across space mapping property in the last section. Essentially, we show that the sum of the probabilities of the elements in  X  is equal to the probability of X i .
 Proposition 4. For every  X  i  X  X   X  G \ S and its associated X
In this section, we will prove a set of results for the LT model, namely that the objective functions are supermodular in both the edge deletion and the edge addition problems. These results will form the basis for our algorithm design.
A set function f : 2 E 7 X  R defined over the power set 2 E of a set E is called supermodular iff  X  S  X  T  X  E,  X  e  X  E \ T Intuitively, for a monotone increasing supermodular func-tion f , the marginal gain of adding a new element e to a set T is greater than the gain of adding e to any subset S of T . This property is referred to as the increasing differences property, as opposed to diminishing returns in the case of a submodular function. If f is a monotone decreasing func-tion (as will be the case when we consider deleting edges or nodes), then the marginal loss in adding e to T would be smaller than that of adding e to S .

We define the susceptibility of an influence graph G to a set of potential sources A as P a  X  A  X  ( a,G ), which is the sum of the influence function for each node a . Intuitively, one can think of each node a  X  A as having equal probability of be-ing the source, and the susceptibility of G as the expected value of the influence function with respect to the random-ness of picking an a from A . Our definition of susceptibility can also be generalized to the case where each node a has a different probability of being the source. In this case, all our subsequent theorems would still hold. Furthermore, we as-sume that the size of the source set is only poly-logarithmic in the total number of nodes in the network, i.e. , | A || V | .
In this problem, given an influence graph G = ( V,E,w ) and a set of sources A , we want to delete a set of edges S of size k from G such that the susceptibility of the resulting influence graph is minimized. That is where the objective function is a set function over the edges S to be deleted. We will show that each  X  ( a,G \ S ) is a monotonically decreasing and supermodular function of S , and hence their positive sum, P a  X  A  X  ( a,G \ S ), also is.
Monotonicity. In this section, we prove that  X  ( a,G \ S ) is a monotonically decreasing function of S . We will use the within space mapping property in Prop. 1 and the space inclusion property in Prop. 2 to prove the following result:
Theorem 5.  X  ( a,G \ S ) is a monotonically decreasing function of the set of edges S to be deleted.

Proof. Given the influence graph G = ( V,E,w ), we need to show that for any set S  X  E and e = ( u,v )  X  E \ S :
Using the fact that the space X G \ S is partitioned into is partitioned into two sets X  X  e G \ S and X  X  G \ S (space inclusion property in Prop. 2), we can write the difference as  X  ( a,G \ S )  X   X  ( a,G \ ( S  X  X  e } )) (6) = X + X + X Recall that e = ( u,v ). We will simplify the last two sum-mands in the above equation using the following two facts: Then Eq. (6) simplifies to P X  X  X  e any e X  X  X e G \ S has probability Pr[ e X | G \ S ] = w ( u,v )  X  Q to X  X  X   X  G \ S , we have that Eq. (6) is equal to Since the live-edge graph e X has one more edge than X , clearly r ( a, e X )  X  r ( a,X ) &gt; 0, which completes the proof.
Supermodularity. We will use the across space map-ping property in Prop. 3 (also Prop. 4) and the probability mapping property in Prop. 1 to prove the following result:
Theorem 6. The function  X  ( a,G \ S ) is a supermodular function of the set of edges S to be deleted.

Proof. Let t = |X  X  G \ ( S  X  X  g } ) | , then using the across space mapping property in Prop. 3, we can partition X  X  G \ S into t sets {  X  i } t i =1 and rewrite Eq. (7) in the proof of Thm. 5 as: Using similar reasoning to that in Eq. (7) in the proof of Thm. 5 for G \ ( S  X  X  g } ), we have  X  ( a,G \ ( S  X  X  g } ))  X   X  ( a,G \ ( S  X  X  g,e } ) (9) = X Then we need only compare Eq. (9) and (8) term by term for each X i  X  X  X  G \ ( S  X  X  g } ) ,i = 1 ,...,t . Clearly, when  X  { X i } , the terms from the two equations are equal. When  X  i = { X i ,X 0 i } , we need to show
Pr[ e X i | G \ S ]  X  r ( a, e X i )  X  r ( a,X i ) Based on the probability mapping property in Prop. 4, we have Pr[ e X i | G \ ( S  X  X  g } )] = Pr[ e X i | G \ S ] + Pr[ Then to establish Eq. (10), it suffices to show that Recall that X 0 i = ( V,E X i  X  X  g } ). Since live-edge graphs are constructed in a way that each node has at most one in-coming edge, each reachable node y has a unique path from the source node a to node y . Furthermore: (1) a reacha-bility path in e X i is clearly also present in e X 0 i , hence if re-moving edge e = ( u,v ) from e X i results in unreachability of some nodes in X i then those same nodes become unreach-able when removing e from e X 0 i ; (2) removing edge e from may disconnect some additional nodes whose paths from the source a include edge g . Therefore the reduction in reach-able nodes when removing edge e from e X 0 i is the same or larger than the reduction when removing edge e from This completes the proof.
In this section, given a partial influence graph G 0 ( V,E and a larger potential influence graph G = ( V,E,w ) with E 0  X  E , we want to add to G 0 a set of edges S  X  of size k from E \ E 0 such that the resulting susceptibility is maximized: where the objective function is a set function over the edges S 0 to be added. We will show that each  X  ( a,G 0  X  S monotone and supermodular, and hence their positive com-bination,  X  ( A,G 0  X  S 0 ), is also monotone and supermodular.
Theorem 7. The function  X  ( a,G 0  X  S 0 ) is a monotone and supermodular function of the set of S 0 edges to be added.
Proof. We will prove the results by relating the objec-tive function to that in the edge deletion problem and then apply the results from the edge deletion problem. More specifically, let S 0  X  T 0 and e  X  E \ T 0 . If we define S = E \ ( S 0  X  E 0  X  X  e } ), then since G 0  X  ( S 0  X  X  e } ) = G \ S and G 0  X  S 0 = G \ ( S  X  X  e } ). Similarly, if we define T = E \ ( T 0  X  E 0  X  X  e } ), then Note that S 0  X  T 0 implies that T  X  S . Then we apply the supermodularity of  X  ( a,G \ S ) as a function of the edges S to be deleted in Thm. 6, and obtain which completes the proof.
Given that the edge deletion and addition problems are supermodular, we can, in principle, solve the network topol-ogy optimization problems using the state-of-the-art super-modular optimization algorithms. However, there remain great challenges in scaling these algorithms up to diffusion networks with millions of nodes. First, supermodular op-timization requires evaluating the influence function many times. The problem of computing the influence function  X  ( a,G ) exactly has been shown to be #P-Hard [4]. Thus there is a need to design methods to approximately com-pute the influence function in near-linear time. To tackle this problem, we will estimate  X  ( a,G ) using empirical aver-aging (EA) over a fixed set of live-edge graphs, pre-sampled using the LT live-edge graph generation process described in section 2.2. That is where L = { X i } 1  X  i  X  l is the set of sampled live-edge graphs from G . Recall T a X i is the tree rooted at a induced from X
Second, typically, the marginal change of the influence function for each candidate edge needs to be computed. This imposes the additional requirement that each marginal change computation has to be nearly constant-time to han-dle the large number of candidate edges. To address these challenges, we will design an efficient descendant-counting tree data structure for the edge deletion problem, and use it as part of a greedy algorithm to minimize the supermod-ular objective function. For the edge addition problem, we will employ an efficient randomized neighbor-counting graph data structure, and use it inside a modular approximation algorithm to maximize the supermodular objective function. Fig. 3 illustrates the data structures. In both cases, time and space complexities are linear in the network size.
It is easy to see that the empirical average influence func-tion b  X  ( a,G \ S ) under edge deletion is also supermodular and monotonically decreasing. To solve the problem at hand, we adopt a simple greedy approach: at each iteration, given the current solution S t , add to the solution the element e with the largest marginal loss  X ( e | S t ) defined using Eq. (12) where T a X i \ S t means deleting edges S t from tree T a on this expansion, we notice that the edge with largest marginal loss is the edge whose deletion results in the largest decrease in the average number of descendants over all source nodes and the set of induced live-edge trees T a X . Note that we use the terminology  X  X arginal loss X  rather than  X  X arginal gain X  because our objective function is monotone decreasing , hence  X ( e | S t ) measures the marginal loss resulting from removing e after edges S t have been removed.

Na  X   X vely applying the greedy algorithm is computation-ally intensive and will not scale to networks with millions of nodes. Basically, at iteration t , for every edge e  X  E \ S and every T a X , we need to compute  X ( e | S t ) by performing a Breadth-First-Search (BFS) traversal from the source a , and count the number of nodes reachable in T a X i T lead to an O ( | V | 2 + | V || E | ) complexity algorithm: BFS is O ( | V | + | E | ) and we need to check O ( | E | ) edges in E \ S Such quadratic dependence on the network size motivates us to design a more efficient solution.

Scaling Up. Can we avoid the many BFS traversals? To answer this question, we first make the following observation
Observation 1. Given an edge e = ( u,v ) to be deleted where v is reachable from the source a , the marginal loss  X ( e | S t ) can be computed as r ( a,T a X \ S t )  X  r ( a,T a X \ ( S t  X  X  e } )) = r ( v,T This observation implies that, if we can compute r ( v,T for all v  X  V in the original live-edge tree T a X , we can then compute the marginal gain of each edge e efficiently.
Can we compute the number of descendant, r ( v,T a X ), ef-ficiently, for all v  X  V ? Fortunately, since we are dealing with trees of at most | V | edges each, this can be done in time O ( | V | ) using a single BFS traversal. More specifically, after initializing r ( v,T a X ) = 0 ,  X  v  X  V , 1. Perform a BFS starting from the source a of T a X , adding 2. While stack H is not empty, pop edge e = ( u,v ) and The correctness of the above procedure is easy to verify: the number of descendants of a node is equal to the sum of the number of descendants of its children, plus the number of children it has, which is exactly what we are computing.
Suppose we have already maintained the descendant counts r ( v,T a X \ S t ) for all node v  X  V . Then after deleting edge e = ( u,v ), there are two types of nodes for which need to up-date the descendant counts: the ancestors u 0 of node v , and the nodes that have become unreachable. For the former, we update their descendant counts by subtracting out the number of descendants of node v plus 1. Similar to Eq. (14), r ( u 0 ,T a X \ ( S t  X  X  e } )) = r ( u 0 ,T a X \ S t )  X  r ( v,T For the latter, we simply set their descendant counts to loss of each edge can also be updated according to Eq. (14). Overall Algorithm: GreedyCutting is summarized in Algorithm 1. It first samples live-edge graphs and obtains the corresponding live-edge trees for the input sources A . Lines 4 X 12 compute the initial descendant counts variables r ( u,T a X ) for each node u and each T a X , and the edge marginal loss variables  X ( e ) for all edges in E . For each iteration, line 15 adds to the solution set the edge with largest marginal loss, and lines 16 X 27 locally update the descendant count variables for nodes, and marginal loss variables for edges. Finally, the solution set S  X  is returned.

If we assume the number of source nodes to be poly-logarithmic in | V | , then Algorithm 1 has computational com-plexity O ( k |L|| V | ), which is linear (up to poly-logarithmic factors) in the size of the network. As for space complex-ity, our main data structures store the node descendant counts for each induced live-edge tree on one hand, and the marginal losses of the edges on the other, requiring space of complexity O ( | E | + | V ||L| ), linear in the network size. and h ( S ) = P a  X  A  X  ( a,G )  X   X  ( a,G \ S ) , the reduction in influence when S is deleted from E . Let  X  be the approxi-mation factor for influence estimation by EA. The solution b S returned by GreedyCutting satisfies Proof. Straightforward based on [18].
 Algorithm 1: GreedyCutting Input : Influence Graph G ( V,E,w ), Sources A , k
Output : Edges S  X  1 Sample a set of live-edge graphs L = { X } from G 2 Obtain the set of induced live-edge trees { T a X } from L 3 Initialize  X ( e ) = 0 for all e  X  E , r ( u,T a X ) = 0 for all u  X  V and T a X 4 for each T a X do 5 Initialize queue Q, stack H , Q.enqueue ( a ), 6 while Q is not empty do 7 s = Q.dequeue () 8 for u  X  V and ( s,u ) is an edge in T a X do 9 if u /  X  visited then 10 visited = visited  X  X  u } , Q.enqueue ( u ), 11 while H is not empty do 12 ( u,v ) = H.pop (), r ( u,T a X ) += r ( v,T a X ) + 1, 13 S  X  =  X  14 for t=1 to k do 15 e t = ( u t ,v t ) = argmax e  X  E \ S  X   X ( e ), S  X  = S 16 for each T a X do 17 if e t is an edge in T a X then 18 s = u t 19 while s is not the source a do 20 r ( s,T a X )  X  = r ( v t ,T a X ) + 1, 21 Initialize queue Q , Q.enqueue ( u t ), 22 while Q is not empty do 23 s = Q.dequeue () 24 for u  X  V and ( s,u ) is an edge in T a X do 25 if u /  X  visited then 26 visited = visited  X  X  u } , 27 return S  X 
We now turn to our algorithmic framework for solving the problem of adding edges. Recently, Iyer et al. [11] proposed a simple approach for constrained submodular minimization with approximation guarantees, which we will adapt for our (analog) supermodular maximization problem. Recall that given a partial influence graph G 0 ( V,E 0 ,w ) and a larger po-tential influence graph G = ( V,E,w ) with E 0  X  E , we want to add to G 0 a set of edges S  X  of size k from E \ E 0 such that the resulting susceptibility is maximized (Eq. (11)). The algorithm constructs a modular lower bound (MLB) of the objective function, and then adds edges that maximize this lower bound, instead of the original objective. That is, 1 |L| where L = { X i } 1  X  i  X  l is the set of sampled live-edge graphs from G 0 , and T a X i is the tree rooted at a induced from X Then, T a X i  X  S refers to the live-edge tree resulting from adding new edges S to T a X i . Note that the resulting tree may allow the source a to reach some nodes originally not reachable in T a X i .

The MLB approach has several nice properties. First, the modular lower bound function is simple, essentially requiring us to compute the reachability score r ( a,T a X i  X  X  e } ) for each candidate edge to be added. Second, maximizing the MLB for a budget k reduces to simply finding the top k edges which lead to the largest function value
However, na  X   X vely applying the MLB algorithm is compu-tationally intensive and can not be scaled up to networks with millions of nodes. Basically, for every candidate edge e to be added and for every T a X , we need to compute the reachability r ( a,T a X i  X  X  e } ) by performing a BFS traversal from the source a , and count the number of nodes reachable in T a X i  X  X  e } . It is easy to see that such an approach will lead to an O ( | V || E | ) complexity algorithm: BFS is O ( | V | ) (since trees T a X have at most | V | edges), and we need to check O ( | E | ) edges in E \ E 0 . Again, we are motivated to design a more efficient solution.

Scaling Up. Can we avoid the many BFS traversals? To answer this question, we first make the following observation
Observation 2. Given an edge e = ( u,v ) to be added, where node v is originally not reachable from the source a , but becomes reachable with the addition of e , the reachability of a can be updated as where T a X is the complement of T a X containing those nodes and edges not reachable from a .
 We note that the term r ( v, T a X ) + 1 is multiplied by the weight w ( e ) of edge e to account for the probability of that edge being actually picked by node v in the live-edge gener-ation process of the new influence graph G 0  X  X  e } . Further-more, note that T a X may contain cycles.

Can we compute the number of reachable nodes, r ( v, T a X efficiently, for all v in T a X ? Fortunately, this problem has been extensively studied in the theoretical computer science literature as the neighborhood size-estimation problem [5], and was recently applied in the context of influence estima-tion for a continuous-time diffusion model [7]. We will adapt a linear-time algorithm by Cohen [5] for our problem.
We apply the algorithm to T a X as follows: first, we assign to each node u a label l ( u ) drawn from the exponential dis-tribution with parameter (mean) 1. Then, we exploit the fact that the minimum l  X  ( v ) of the set of exponential ran-dom labels { l ( u ) } for nodes u reachable from v will itself be an exponential random variable, with its parameter equal to r ( v, T a X ). If we repeat the random labeling q times and size is estimated as
Can we find the least labels efficiently for all nodes v given each random labeling? In fact, this can be done using a modified BFS traversal which requires time only linear in the network size. More specifically, For a given labeling, we start from the node v with the smallest label, and perform a BFS traversal in the reverse direction of the graph edges. For each node u encountered in the BFS, we set l  X  ( u ) = l ( v ). Once a node has been encountered in a BFS and its least label has been set, it is marked as visited , not only for this particular BFS, but across all subsequent BFS runs. After the BFS traversal from node v is complete, we move to the unvisited node with the next smallest label, and repeat the procedure iteratively until all nodes have been marked as visited. It is easy to see why this algorithm correctly assigns the appropriate least label l  X  ( v ) to each node v : since we order the BFS runs by minimum labels, and traverse the edges in reversed direction, then once a node u has been visited, we are guaranteed that the l  X  ( u ) we assign to it is the smallest, and any subsequent BFS that can reach u will have a label larger than l  X  ( u ).

Overall Algorithm: ModularAdding is summarized in Algorithm 2: we first generate the live-edge graphs, in-duce the live-edge trees, and draw q labels for each node v  X  V from the exponential distribution with mean 1 (lines 1-5). Then, for each source node a  X  A , we iterate over the induced live-edge trees T a X , collecting the estimated neigh-borhood size of each node v in the complement T a X of each such tree, by applying Cohen X  X  algorithm (lines 7-20). After iterating over the live-edge trees, we compute the final score for each edge e  X  X  in the candidate set C as the sum over v  X  X  neighborhood size estimates, weighted by the edge X  X  diffu-sion probability w ( e ) (lines 21-22). Finally we sort the scores vector in descending order, and return the top k edges.
We assume the number of sources | A | is poly-logarithmic in | V | and hence ignored in the complexity analysis. Then Algorithm 2 has computational complexity O ( q |L|| V | ) and space complexity O ( q | V | ). This is because the Cohen X  X  algo-rithm has complexity O ( q | V | ), and is invoked O ( |L| ) times. The final sorting of the scores can be done in O ( | E \ E As for space, we only require data structures of sizes linear in the number of nodes O ( q | V | ) to hold the least labels. S ) , and g ( S ) = P a  X  A  X  ( a,G )  X   X  ( a,G 0  X  S 0 ) , the difference between the influence in the potential graph G and the influ-ence when S is added to E 0 . Let  X  g be the curvature [11] of g , and  X  be the approximation factor of our two estimation subroutines (1) EA and (2) Cohen X  X  algorithm. The solution b S returned by ModularAdding satisfies
Proof. Straightforward based on Thm. 5.4 in [11].
We now present our experimental setting and results.
Synthetic networks. We generate three types of net-works using the Kronecker graph model 2 [17], known to http://snap.stanford.edu/data/ Algorithm 2: ModularAdding Input : G 0 ( V,E 0 ,w ) ,k, Sources A, Candidates C
Output : Edges S  X  1 Sample a set of live-edge graphs L = { X } from G 0 2 Obtain the set of induced live-edge trees { T a X } from L 3 for each v  X  V do 4 for each i = 1 ,...,q do 5 l i ( v )  X  exp (  X  x ) 6 for each a  X  A do 7 for each T a X do 8 for each i = 1 ,...,q do 9 visited =  X  10 for nodes v in T a X ordered according to 11 if v /  X  visited then 12 visited = visited  X  X  v } 13 Initialize Q , Q.enqueue ( v ) 14 while Q is not empty do 15 u = Q.dequeue (), l  X  i ( u ) = l ( v ) 16 visited = visited  X  X  u } 17 for each parent s of u in T a X do 18 Q.enqueue ( s ) 19 for each node v in T a X do 20 r ( v, T a X ) = q  X  1 P q 21 for each e = ( u,v )  X  X  do 22 score ( e ) += w ( e )  X  P X 23 S  X  = argsort ( score ,k, descending) 24 return S  X  Dataset #Nodes #Edges Kronecker CorePeriphery ErdosRenyi [.5 .5; .5 .5] Hierarchical [.9 .1; .1 .9] HepPH 35K 420K Epinions 75K 509K MemeTracker 1.8K 5K generalize a number of realistic graph models: (1) CorePe-riphery , (2) ErdosRenyi and (3) Hierarchical . These three graph models have very different structural properties, allowing us to test for sensitivity to network structure.
Real-world networks. We choose three publicly avail-able real-world datasets 2 that are amenable to diffusion pro-cesses and hence suitable for our problems: (1) HepPH : a whom-cites-whom citation network based on the Arxiv High-energy Physics papers over the period 1993-2003; (2) Epin-ions : a who-trusts-whom online social network of the con-sumer review site Epinions.com; (3) MemeTracker : a who-copies-from-whom network of news media sites and blogs. The statistics of the datasets are summarized in Table 1.
Assigning probabilities. Given a network G ( V,E ), we populate the weight vector representing the probabilities on the edges E according to the LT model, as follows: for a given node v  X  V , we draw a probability value e w ( u,v ) for each edge e = ( u,v )  X  E that is incoming into v , uniformly at random from the interval [0 , 1]. In addition, we draw from the same interval a probability value w v representing no infection, i.e the probability that v  X  X  infected parents fail Problem | A | |L opt | |L eval | k q Edge Deletion 100 1 , 000 5 , 000 [0 ,t ]  X 
Edge Addition [0 , 2000] 20 to activate it. Since the probabilities on the edges plus the probability of no infection must sum to 1, we then normalize each probability over the sum of all the probabilities, i.e. , we obtain w ( u,v ) = e w ( u,v ) / ( P u  X  V e w ( u,v ) + w this method for all datasets except for MemeTracker .
For MemeTracker , we make use of the median transmis-sion time, also provided as part of the dataset. Let e t ( u,v ) be the median transmission time between two nodes u and v , then we set w ( u,v )  X  e t ( u,v )  X  1 , rewarding smaller transmis-sion times with higher diffusion probabilities, and vice versa. We assign a probability of w v = 0 . 2 ,  X  v  X  V , and normalize the weights for all nodes v such that P u  X  V w ( u,v )+ w
Competing heuristics. To evaluate the efficacy of the solutions provided by our algorithms, we compare against other heuristic measures that are not based on the dynam-ics entailed by the LT diffusion model. These heuristic strategies can be described as follows: (1) Random : select k edges uniformly at random from the input set of edges, (2) Weights : select the k edges with highest diffusion probabil-ity (weight) w ( u,v ), (3) Betweenness : select k edges with highest edge betweenness centrality [2, 20], (4) Eigen : select the k edges that cause the maximum decrease (increase) in the leading eigenvalue of the network when removed from it, or added to it [22], (5) Degree : select the k edges whose destination nodes have the highest out-degrees [8].
We carry out each experiment as follows: given an in-fluence graph G ( V,E,w ), a set of source nodes A chosen uniformly at random from V , and a budget k of edges to delete, we run GreedyCutting and the five heuristics and obtain a set of edges from each. Then, for each algorithm or heuristic, we simulate the LT diffusion process by generating a set of live-edge graphs L eval based on G , and then delet-ing the proposed set of edges S  X  from all live-edge graphs in L eval . The efficacy of each proposed set of edges is mea-sured by I k , the average number of infected nodes over L These parameters are summarized in Table 2. The budget k is increased until diffusion is no longer possible, i.e. , the source nodes are completely isolated.

Synthetic networks. The results are shown in Fig. 4 (a-c). First, we observe that our algorithm clearly outper-forms all five other heuristics: for any budget k of edges to delete, our algorithm minimizes the graph susceptibility ra-tio ( I k /I 0 ) better than any of the heuristics for all three syn-thetic network types, implying that it produces good solu-tions independently of the structural properties of the input network. On the other hand, the considered heuristics per-form arbitrarily good or bad, as we vary the type of synthetic network. At last, we observe that even for |L opt | = 1 , 000, a quantity much smaller than the typical 10 , 000 used in the literature, the green and red lines are almost indistin-guishable, meaning our solution generalizes well to the larger evaluation set of 5 , 000 live-edge graphs.
Real-world networks. We observe similar performance for real-world networks (Fig. 4 (d-f)). For instance, for the Epinions dataset (Fig. 4(e)), our method has decreased the graph susceptibility to 40% of its original value at k = 200, whereas the best performing heuristic at the same k is Weights with 60% (here, lower is better).
The experimental procedure for evaluating our Modu-larAdding algorithm and other heuristics is analogous to that described in 6.2 for edge deletion. We compare our al-gorithm to all previously described heuristics, for the excep-tion of the Betweenness heuristic, as it is not obvious how meaningful it would be to compute this metric for edges that do not initially exist in the network. Results are in Fig. 5.
Synthetic networks. Our algorithm is almost always twice as effective as the next best heuristic, be it Weights or Degree . This efficacy gap is consistent across all three types of networks, confirming yet again the robustness of the so-lutions we find to varying structural properties of networks.
Real-world networks. Similarly to the synthetic set-ting, our algorithm significantly outperforms all four heuris-tics in the real-world setting, for all three datasets. For instance, for the HepPH dataset in Fig. 5(d), the Degree heuristic requires adding 2 , 000 edges to the set A of 100 sources in order to increase the graph susceptibility by twice its initial value ( i.e. , at k = 0), whereas our algorithm increases the graph susceptibility by the same amount for k = 200 edges, a small fraction of 2000. This superior per-formance implies that our algorithm is more amenable to real-world applications, where the budget is typically very small relative to the number of nodes, possibly representing humans in a social network, blogs on the web, etc.
Scalability is a major concern in the industrial setting. We experimentally verify the scalability of both our edge dele-tion and addition algorithms. All experiments were executed on a laptop with a 2.7GHz quad-core i7 CPU and 16Gb RAM. The results presented in Fig. 6 measure the runtime of our algorithms on synthetic CorePeriphery networks of increasing number of nodes, and fixed average degree of 2. We vary the number of nodes, starting at 2 7 = 128 nodes, and up to 2 23 = 8 , 388 , 608 nodes (16 , 777 , 216 edges). The experimental results show that our algorithms scale linearly in the size of the network. As expected, ModularAdding , while also having a linear scaling, is more time-consuming than GreedyCutting , due to the repeated linear-time al-gorithm for building the neighbor-counting graph. This research was supported in part by NSF/NIH BIG-DATA 1R01GM108341-01, NSF IIS1116886, NSF CAREER IIS1350983 and a Raytheon faculty fellowship to L. Song. [1] I. Bogunovic. Robust protection of networks against [2] U. Brandes. A faster algorithm for betweenness cen-[3] W. Chen, L. V. Lakshmanan, and C. Castillo. Infor-[4] W. Chen, Y. Yuan, and L. Zhang. Scalable influ-[5] E. Cohen. Size-estimation framework with applications [6] P. Domingos and M. Richardson. Mining the network [7] N. Du, L. Song, H. Zha, and M. Gomez Rodriguez. [8] C. Gao, J. Liu, and N. Zhong. Network immunization [9] X. He, G. Song, W. Chen, and Q. Jiang. Influence [10] H. W. Hethcote. The mathematics of infectious dis-[11] R. Iyer, S. Jegelka, and J. Bilmes. Fast semidifferential-[12] D. Kempe, J. Kleinberg, and  X  E. Tardos. Maximizing [13] M. Kimura, K. Saito, and H. Motoda. Solving the con-[14] M. Kimura, K. Saito, and H. Motoda. Blocking links [15] C. J. Kuhlman, G. Tuli, S. Swarup, M. V. Marathe, [16] J. Leskovec, L. Backstrom, and J. Kleinberg. Meme-[17] J. Leskovec, D. Chakrabarti, J. Kleinberg, C. Faloutsos, [18] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis [19] S. Peng, S. Yu, and A. Yang. Smartphone malware and [20] C. M. Schneider, T. Mihaljev, S. Havlin, and H. J. Her-[21] D. Sheldon, B. Dilkina, A. N. Elmachtoub, R. Finseth, [22] H. Tong, B. A. Prakash, T. Eliassi-Rad, M. Faloutsos,
Proof of Prop. 1. Since edge e /  X  S , we can always find two live-edge graphs within X G \ S which differ by the edge e . The first live-edge graph X does not contain e , and the second live-edge graph X 0 contains the additional edge e .
Proof of Prop. 2. Since S  X  S  X  { e } , the influence graph G \ ( S  X  X  e } ) has one less edge than G \ S , while other parameters of the two graphs remain the same. This implies that any live-edge graph X generated from the former in-fluence graph can always be generated from the latter one, which establishes the first part of the proposition. Further-more, X G \ ( S  X  X  e } ) contains those live-edge graphs without edge e , which is essentially the union of X  X  e G \ S and X definition.
 Proof of Prop. 3. We will explicitly construct a set  X  i  X  X
G \ S for each element X i  X  X respectively as follows: (1) If node v 0 has an incoming edge in X i , then  X  i = { X i } .  X  i is contained in X X inclusion property. (2) Otherwise,  X  i = { X i ,X 0 i X i = ( V,E X i  X  X  g } ) is obtained by extending X i with edge g .  X  i is also contained in X  X  G \ S since g /  X  S and hence X is a valid live-edge graph in X  X  G \ S . It is easy to see that the  X  s are pairwise disjoint and form a partition of the space X Proof of Prop. 4. We will consider two cases. When  X  i = { X i } is a singleton, Pr[ X i | G \ ( S  X  X  g } )] = Pr[ X and hence the statement holds true trivially. When  X  { X i ,X 0 i } , the difference Pr[ X i | G \ ( S  X  X  g } )]  X  P S ] is proportional to p ( v 0 ,X i ,G \ ( S  X  X  g } ))  X  p ( v S )  X  p ( v 0 ,X 0 i ,G \ S ), where we only need to consider the con-tribution of the terminal node v 0 of edge g = ( u 0 ,v 0 all other nodes contribute the same amount to the probabil-ity of each live-edge graph involved. Based on Eq. (3), the difference between the first two terms, w ( u 0 ,v 0 ), cancels out with the third term, w ( u 0 ,v 0 ), which shows that the differ-ence Pr[ X i | G \ ( S  X  X  g } )]  X  P H  X   X  completes the proof.
