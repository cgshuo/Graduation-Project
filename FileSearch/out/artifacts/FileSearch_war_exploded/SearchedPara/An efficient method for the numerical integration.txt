 fl ine measured states. The rationale behind the proposed method is 1. Introduction
In the area of chemical and biochemical engineering the list of quantities that can be measured increased signi fi cantly in the last decade ( Schuegerl, 2001 ). This development gave rise to the applica-tion of data-driven techniques for process modeling. In particular Neural Networks (NNs) have found wide application, since they can easily be applied for fast nonlinear process model development. Most (bio)chemical processes are dynamic, wherefore the standard, rather static, concept of NNs has been extended in many different ways in order to yield a dynamic model ( Sinha et al., 2000 ). One peculiar wayismodelingthetimevaryingfunctionsofOrdinaryDifferential Equations (ODEs) by NNs, resulting in dynamic neural networks (DNN) ( Petre et al., 2010 ). This approach preserves some structural resemblance to the modeling of dynamic systems by fi rst-principles, i.e. a set of ODEs. To an even bigger extend hybrid semi-parametric modeling exploits the available fi rst-principles knowledge, repre-sented in from of parametric models, by combining it with nonpara-metric models that are identi fi ed from data ( Thompson and Kramer, 1994, von Stosch et al., 2014 ).Ingeneral,themodelstructureofDNNs or dynamic hybrid semi-parametric models can be expressed as a set of Ordinary Differential Equations (ODEs), i.e., dx dt  X  f  X  x ; z ; t ; w  X  ; x  X  t o  X  X  x o ;  X  1  X  where x is a vector of state variables, z is a vector of measured variables, t is the time, w represents all model parameters and f is a vector of rate functions describing how the states change along with time. In case of the DNN models, these functions, f ,aremodeledby
NNs. In case of hybrid semi-parametric models, these functions are combinations of NNs with fundamental knowledge, as e.g. presented in Oliveira (2004) .

Depending on the arguments of f , the model structure can either be a one-step ahead predictor, namely if measured variables, z ,are incorporated or a multi-step ahead predictor if f  X  f  X  x case, Eq. (1) needs to be integrated to obtain the state estimations x , which is usually done numerically. Whereas in the case of multi-step ahead predictors traditional numerical integration schemas can readily be applied (e.g. the ode45 of the MATLAB toolbox), this is not the case for one-step ahead prediction st ructures, since the value of the z might notbemeasured/availableatthetimeinstancesatwhich f is evaluated by the traditional schemas. Thus, for their integration either a step size schema, such as the well known Euler or Heun is adopted, fi tting the step size to the sampling frequency of z ,orsomeapproach is adapted to represent z as a function of time, e.g. spline or polynomial approaches, and then standard adaptive integration schema is applied, as for multi-step ahead predictors. Both approaches are computation-ally inef fi cient. Fixed step size methods allocate the function evalua-tions on a rigid grid, completely disregarding f 's curvature. Inter-polation becomes computational expensive when repetitively carried out as e.g. for network structure disc rimination and network training.
Moreover for other types of measured variables, such as those obtained from spectroscopic devices (e.g. Near InfraRed (NIR)), the application of interpolation techniques might not even be appropriate, since the error introduced by the interpolation technique can be great. nonparametric model, i.e. parameter identi fi cation, will compen-sate for the numerical error introduced due to an inappropriate step-size. While it can generally be expected that the overall error will decrease due to the compensation, the function that is sought to be modeled is distorted.
 that provides the solution within user speci fi ed tolerances at the desired time instances by varying the step size, but that only t z at which measured variables z are available. The proposed methodology is (1) analyzed using a simulation case study and (2) evaluated in comparison to fi xed step size methods on an experimental case study. In addition the mutual interference between step size, parameter identi fi cation, learning of the neural network and model performance is assessed. 2. Methodology 2.1. Condition 1 (C1) ment, Eq. (1) needs to be solved at those time instances at which state measurements were made. Most numerical integration meth-ods are capable of this. The methods usually either integrate from time instance to time instance or they integrate over the whole time interval and interpolate thereafter ( Shampine, 1987 ), the post-interpolation usually being computationally less expensive. 2.2. Condition 2 (C2)
For the numerical integration of Eq. (1) , the measured variables, z , needs to be provided at those time instances t z at which the with high frequency (implied through its choice as input) it might or smoothing spline interpolation can be applied for some types of measured variables, but during the network structure discrimina-tion, the network training or process optimization the repetitive interpolation becomes computationally expensive. For other types of measured variables, such as those obtained from spectroscopic devices (e.g. Near InfraRed (NIR)), the application of interpolation techniques might not even be appropriate, because (i) the error introduced by the interpolation technique can be large; and (ii) the number of measured variables is large, wherefore interpolations come with a signi fi cant time and computational burden. In order to avoid (repetitive) interpolations, fi xed step size methodologies fi nd application in which the integration step-size is determined by the sampling frequency of the measured variables z ( Schubert et al., 1994; van Can et al., 1996; von Stosch et al., 2012 ). However, it is well known that fi xed step size methodologies are, likewise, not computationally ef fi cient.

The sampling rate of online measured variables, z , is in most (bio) chemical processes both time constant and frequent. In contrast, the proportions of the divisions made for each step in most standard numerical integration schema, such as Runge  X  Kutta Fehlberg (4
Dormand  X  Price (4  X  5) ( Gladwell et al., 2003, Ashino and Vaillancourt, 2009 ) are irregular. Therefore their direct application along with the frequently sampled online measurements is hindered. In the follow-ing the intermeshing use of four integration methods, all of which having different but regular step pro portions, is proposed. Since their application comes with different r equirements on two consecutive steps, the time interval of the integration is subdivided into different sections, as explained in the following. For each of these sections a different integration schema is a pplied. A schema for the control of the integration error is proposed, in which the adaptation of the step size is carried out with respect to the given sampling time instances of the measurements. 2.3. Time instance analysis and classi fi cation of equal property sections
The proposed numerical integration method has to obey to two timelines, (1) the timeline at which the solution of the ODE is desired, t Xmes ,i.e.thetimeinstancesatwhichinfrequentof fl measurements have been obtained and at which the solution of the
ODE is compared to the measuremen ts (e.g. for parameter identi tion see Section 3.1 ), see Fig. 1 A; and (2) the timeline of the frequent online measurements, t z , whose entries determine the minimal possible step sizes that can be chosen, see Fig. 1 B. The sampling frequency of z  X  t z  X  is typically constant throughout the experiment, such that the increments between the time instances contained in t do all have the same size. However, online measurements might not existatthetimeinstancesoftheof fl ine measurements at which the solutionisdesired,i.e.thetimeinstanceelementsof t Xmes do not have to be contained in t z ,see Fig. 1 . In order to obey to these given conditions, it is proposed to divide the timeline into distinct sections such that for the numerical integration of each section a different methodology can be applied. In particular, the time vector t (which contains all the sampling times of t Xmes &amp; t z the following categories, which are represented in Fig. 1 :
S1) Sections with (at least) two equal sequential steps; (equal in S2) Sections in which (at least) two sequential steps are not S3) Steps for which no online measurements are available at the
For each section different numerical integration methods can be used, as described in the following. 2.4. The integration methods for sections with more than two equal sequential steps (S1)
For sections of the integration interval with more than two equal sequential steps, a Runge  X  Kutta method of order 4 is applied, named here RK4. We reformulated the classic Runge  X  Kutta method of order 4 in such way that it does not require the calculation of the ODEs at the middle of each step, h , but instead two sequential steps are performed at once, i.e. using the relation h  X  2 U h 1 .TheRK4schema then reads k 3  X  2 U h 1 U f  X  t n  X  h 1 ; x n  X  k 2 ; z  X  t n  X  h 1 k  X  2 U h 1 U f  X  t n  X  2 U h 1 ; x n  X  k 3 ; z  X  t n  X  2 U x n  X  1  X  x n  X  1 = 6 U  X  2 U k 1  X  4 U k 2  X  2 U k 3  X  k 4 where h 1 is the step size, n is the current time instance and k are the incremental coef fi cients.

For the estimation of the local truncation error associated with the solution of the RK4 schema, a Runge  X  Kutta method of third order (called here RK3) was adopted, since only one additional function evaluation per step is required. Utilizing the same step size relation h  X  2 U h 1 , the equation of the obtained local trunca-tion error estimate (LEE) reads where k a 3  X  2 U h 1 U f  X  t n  X  2 U h 1 ; x n 2 U k 1  X  4 2.5. The integration method for sections with two unequal sequential steps (S2) In case that two sequential steps do not have equal lengths, the RK4methodcannotbeapplied.Insteaditisproposedtoemploythe Heun numerical integration method ( Ashino and Vaillancourt, 2009 ), also known as the Euler modi fi ed method, since the proportions of two sequential steps have no relevance for this method and since the method is of second order. The local truncation error of the Heun scheme is approximated by the calculation of a LEE utilizing the Euler forward method, resulting in LEE where k 1 and k 2 are the incremental coef fi cients, which are identical to the ones of the RK4 method, see eq. (2) .

Since the Heun method makes two function evaluations per step (thus for two sequential steps four function evaluations are performed) the number of function evaluations for two consecu-tive steps are the same for the Heun and the RK4 method. Thus the question arises whether the solution after two consecutive steps is generally better using the RK4 or the Heun method. All in all it can be expected that higher order methods (RK4) provide a solution with a lower integration error than lower order methods (Heun or
Euler forward), but since for the considered scenario the smallest step size that can be used by the RK4 method is two times the smallest possible step size of the Heun method, this expectation will in limit not hold true. Hence, the solutions obtained with the
RK4 method were compared to those of the Heun method study-ing different fi xed step size values for h 1 . 2.6. Steps for which no online measurements are available at the end of the step (S3)
In case that the function evaluation of k 2 cannot be accomplished because no online measured data are available at the respective time instance, an Euler forward method is adopted for this step. Since the error which is due to the numerical integration can be assumed to be greater for the Euler forward method than the one obtained with other methods, the solution is not used to continue the numerical integration but instead the numerical integration is continued using the starting point of this step and the endpoint of the following step.
ALEEisnotcalculatedinthiscase. 2.7. Restricted step size control
The integration can be expedited by augmentation of the step size in areas in which the time slope is relatively constant, i.e. the curvature is low. Typically, LEEs are employed to control the step size, where the step-size is some function of the LEEs and some user-de fi ned tolerances ( Shampine, 2005 ), e.g.: j X  LEE method  X j r max  X  RelTol j X  x n  X  1  X  t n  X  1  X  X j ; AbsTol  X  where AbsTol is an user given scalar absolute tolerance value, RelTol is an user given vector of relative tolerance values and signi element wise multiplication. It has been shown that by using such an approach for step-size control, the numerical integration is typically stable ( Lapidus and Seinfeld , 1971 ).
 augmented or shortened since it has to comply with the given time instances. The time instances divide the timeline into time increments.
Thus instead of adapting the step size h 1 arbitrarily, h varying the number of time increments,  X  h (the relation between h and  X  h is presented in Fig. 2 a for an example). By nature the smallest possible  X  h is one, while the largest  X  h canbechosenbytheuser (10 in this study). The schema displayed in Fig. 2 b is applied to control the step-size h 1 when the steps comprised by  X  h are not of same size.
At any given step, the LEE is calculated and compared to the speci tolerances. If the value of the LEE is lower than the tolerances then the step-sizeofthisstepisaccepted,i.e.theODEisintegratedwiththe
Heun method, and for the subsequent step the step-size is enlarged. In casethatthestepshavethesamesizetheschemapresentedin Fig. 2 c is applied to control the step-size h 1 . At any given step, the LEEs for both methods are calculated with the same step-size h 1 and then has been introduced to reduce the numerical integration error when the smallest possible step size (de fi ned by the sampling frequency of the online data) is used and it is a result of the observation made in Sections 2.6 .and 4.1.1 .Ifthe LEE RK 4 ; RK 3 lower, then the following routine is similar to the one described aboveexceptthattheintegrationiscarriedoutwiththeRK4 method. In case the LEE RK 4 ; RK 3 is greater, the step-size is reduced asfaraspossibleandtheLEEsarecalculatedforthenewstep-size. If the lowest possible step-size is reached, the integration is carried out with the Heun metho d and the routine described in Fig. 2 b is applied.

 X  h is reduced in such a way as to provide the solution at the boarder of the sections. In case that the smallest possible step size is reached and that the LEE exceeds the user de fi ned tolerances, a warning message is printed suggesting the user to lower the sampling frequency in upcoming experiments. Note that for the Euler forward schema  X  h  X  1. 2.8. Stability and truncation errors
Per se, the employed Runge Kutta, Heun and Euler forward integration methods are stable provided that the step-size is suf fi ciently small ( Lapidus and Seinfeld , 1971 ). The step-size is, as described in the section before, controlled by keeping the values of the LEEs below those of the absolute and relative tolerances, as normally done ( Lapidus and Seinfeld, 1971; Shampine, 2005 ).
Stability is such indirectly controlled by the user through the choice of absolute and relative tolerance values. However, in the method proposed here the step-size has to comply with the timeline also given by the user, i.e. t mix , as described before. The step-size can therefore not be lower than the difference between two neighbor-ing time instances. This restriction might result in the exceeding of the tolerance values and subsequently into a loss of stability. As mentioned before, the user is informed if the tolerance values are exceeded due to the step-size restrictions.

To better understand the impact of the step-size on the stability and integration error, the linear ODE dy = dt  X   X  U y is used. This linear system can be adequate to analyze also the stability of nonlinear systems, given that the k i 's converge to some constant values as the step-size decreases ( Lapidus and Seinfeld, 1971 ). For one step with the step size h 1 (i.e. the total length of the step is 2 method yields y whereas two steps are needed with the Heun method to reach the same point, i.e. y where t 0 isthestartingtimepointoftheintegration.Absolute stability of the methods is given when the absolute value of the terms in the brackets of Eqs. (6 )and (7) , i.e. the characteristic root, are smaller than one. For different combinations of  X  U h stability is displayed in Fig. 3 A and B. The impact of the system of ODEs on the stability is given by  X  . It can be seen that the Heun method for two steps (with step-size h 1 ) or one step with step size h is stable for a wider range of  X  U h 1 values than the RK4 method for one step with the same step size. This could be expected since lowest possiblestepsizeoftheHeunishalfthatoftheRK4method.Further, it can be observed that the values of the characteristic roots for positive  X  U h 1 values increase faster than in the case of negative values. This is because ODEs in which the real part of the eigenvalues is smaller than zero are inherently stable ( Lapidus and Seinfeld, 1971 ).

The integration error can be obtained subtracting Eqs. (6) and (7) from the analytic solution, y  X  t 0  X  2 U h 1  X  X  y  X  t yields in case of the RK4 method for one step in case of the Heun method for two steps E and in case of the Heun method for one step E
The integration error is thus ampli fi ed or damped by the value of y  X  t 0  X  . The differences for different values of  X  U Fig. 3 C. It can be seen that for positive  X  U h 1 values the RK4 method produces lower integration errors, whereas in the case of negative values from approximately 0.93 on the Heun method produces lower integration errors. These errors are approximated by the respective LEE methods, shown in Fig. 3 D. It can be seen that the LEEs are upper bounds for the local truncation errors in the region where the integration methods are stable. The truncation error and the LEE values of the Heun method are for small step-size values always above those of the RK4 method. It can further be seen that for positive  X  U h 1 values, which are in the stable range, the RK4 method produces lower truncation errors and LEEs as the Heun method. In case, the  X  U h 1 values are lower than 0.93, the truncation error and LEE of the Heun method are lower than those of the RK4 method. Thus, given the case that the step-size cannot be reduced further and that the LEE of the Heun methods is lower than that of the RK4 method, then the integration with the Heun method produces lower truncation errors. Therefore, in this case the integration should be carried out with the Heun method, as proposed in the schema shown in Fig. 2 . 2.9. Evaluation criteria
The solutions obtained through t he numerical integration meth-odologies are compared using the following criteria, which address the accuracy and the related computational cost.

The True Local Error (TLE) can be calculated when the analy-tical solution of the studied ODEs system is known where the index i refers to each state and analytical/numerical speci fi es how the solution was obtained. In order to have a straight-forward criteria for tabular comparison, a scalar True Global Error (TGE) can be calculated given the analytical solution of the studied ODEs system is known
TGE
Similarly, a straightforward criteria for tabular comparison of the estimated numerical integration error is provided through the
Global Error Estimation (GEE) which is calculated applying a sum respectively, resulting in the following error criteria:
GEE
The second criteria type, accounting for the computational cost, re fl ects how ef fi cient a method is. Maybe the most accurate manner to evaluate the computational cost of an integration is through the number of function evaluations/function calls that a scheme made during the integration ( Krogh, 1973 ), because the number of function calls is independent of the used computer and eventual parallel process which might run on the machine. 3. DNN/hybrid modeling structure, parameter identi fi cation and model discrimination methods
The set of ODEs, Eq. (1) , describes the general form of dynamic hybrid semi-parametric models, where f is a vector of rate functions.
Incasethatnoknowledgeabouttheratefunctionsisavailable,the functions f can be modeled using Neural Networks and in this particular case the hybrid model st ructure is identical to structure of the DNN model described by Rovithakis and Christodoulou (1995) and Petre et al. (2010) . Whenever knowledge about the rate func-tionsisavailable,thisknowledgecanbeincorporatedandonlythe remaining unknown variables are estimated by the NN as e.g. described in detail in Oliveira (2004) .Inordertotraintheneural network and to discriminate the best performing network topology the procedure described in the following can be applied. 3.1. Training  X  parameter identi fi cation
For the training/ parameter identi fi cation the available data are split into two sets, a training and a validation set. Using the training set the weight values are identi fi ed minimizing a weighted least square function of the residual between the simulated of fl measured state variables x mes and the model estimates weighted by the respective variance  X  X ,i.e., min
E fg X  min for all n instances measured. A gradient based method is used for the identi fi cation, namely a Levenberg  X  Marquardt method, i.e. the lsqnonlin function of the Matlab Optimization toolbox was used. The gradients are derived using the sensitivities approach ( Oliveira, 2004; von Stosch et al., 2011 ), i.e. d dt
U dx dw  X  where z and t are independent of w . Since also x 0 is independent of w , dx 0 = dw  X  0. Eq. (15) is integrated along with Eq. (1) . The training is stopped when the weighted least square error calcu-lated for the validation set starts to increase, i.e. early-stopping is used to avoid over-fi tting ( Simutis and Luebbert, 1997 ). In order to escape from local minima during the identi fi cation, several random weight initializations (10 in the cases presented below) are performed and the best parameters a re chosen using cross-validation ( Simutis and Luebbert, 1997, Oliveira, 2004, von Stosch et al., 2011 ). 3.2. Model discrimination number of nodes in the hidden layer of the neural network, as well as the node transfer functions and, if necessary, the number of hidden layers. If available, the performance of the different model are compared based on their performance for the training and validation set. The performance of the different model structures is typically evaluated employing evaluation criteria. In the cases pre-sented in the following, the best performing model structure was chosen using the Bayesian informat ion criteria (BIC), which balances the fi t against the complexity of the model ( Peres et al., 2008 ). This criteria is calculated for the training and validation set. 4. Results and discussion 4.1. Case study I  X  a simulated system chosen because its analytical solution is known, wherefore the numerical solution can be assessed in comparison to the analytical one. This system of linear fi rst order ODEs, has been proposed by Lapidus and Seinfeld (1971) dy dt  X  where 0 o t o 2 and y 0  X  X  2 ; 1 ; 2 T . For a generic initial condition y y  X  t  X  X  4.1.1. Analysis of the fi xed step-size integration methods and local/ global error estimations
The integration methods Eul er forward, Heun and RK4 were separately analyzed (in  X  fi xed step size mode  X  ) in order to assess the properties of the proposed numerical integration methodology in relation to different values of h 1 .In Tables 1  X  4 the estimated errors (GEE) and the true errors (TGE) are presented for different values of h .Itcanbeobserved( Tables and 2 )thatforsuf fi ciently small step sizes ( h  X  10 3 or h  X  10 4 ) the RK4 performs better than the Heun method,eventhoughthestepsizeoftheRK4istwotimesthestep size of the Heun method. This could be expected because the RK4 method is of 4th order, producing local truncation errors of the 5th order ( O  X  h 5  X  ), while the Heun method is of order two (local trunca-tion errors of order O  X  h 3  X  ). Thus, if the step size is suf then the RK4 method is preferable since with the same number of function evaluations the solution is corrupted with a much lower numerical integration error, see e.g. Section 2.6 .However,when increasing the step size ( Tables 1  X  3 )itcanbeobservedthatthe differences between the errors of the RK4 and of the Heun method diminish. For h 1  X  10 2 , it can even be observed that for the third state, y 3 , lower associated GEE values are obtained for the Heun method than for the RK4, see Table 3 .Thisobservationisvisually con fi rmed when looking at Fig. 4 , wherein the time courses of the local errors ( TLE and LEE )areplottedfor y 3 . Therefore it is concluded that the RK4 method performs poorer than the Heun method when a certain threshold step size value is reached, which is in accordance with the fi ndings made in section 2.6 . Hence the proposed numerical methodology, switches the numerical integration schema in case that the step size cannot be further lowered and that the error estimate of the Heun method is better than the one of the RK4. In case that a too largestepsizeischosenbothmethodsarenolongerstable( Table 4 ), as expected ( Lapidus and Seinfeld, 1971 ). 4.1.2. The DNN/hybrid model structure
Hybrid models in general fi nd application if the system of ODEs is not completely known. Such a scenario is simulated by choosing a very simple structured hybrid model, which as a matter of fact is identical to a DNN model structure ( Rovithakis and Christodoulou, 1995; Petre et al., 2010 ), i.e. dy dt  X  wherein r 1 , r 2 and r 3 are all functions of the inputs y simulate online measurements of the state variables (Note that the vector that contains the functions r 1 , r 2 and r 3 is represented simply by f  X  U  X  in Eq. (1) ). Since it is assumed that the underlying system is unknown, r 1 , r 2 and r 3 are represented by Arti fi cial Neural Networks (ANNs) wherein the parameters w represent the weights of the connections between the three layers of the ANN. For the identi tion of the weights, Eq. (18) is integrated with the proposed step size  X  method and the parameter identi fi cation methodology described above was employed. The training and validation data were generated with the analytical solution, Eq. (17) , by (i) varying the values of y 0 by 5%; (ii) recording simulated of fl ine measured state variables, y offline ; mes , using a constant sampling frequency of 10 and (iii) recording simulated online measured variables y using three constant sampling frequencies (10 1 ,10 2 and 10 An additional test data set is generated with y 0 using the same sample performance can be analyzed with respect to the observations made before. The best performing model structure was discriminated with the above described methodology. The three nodes of the input and output layer have linear transfer functions and for the hidden layer a single hyperbolic tangential transfer function node was chosen. 4.1.3. Results obtained for the integration of the DNN/hybrid model
In Tables 5  X  7 global errors are presented for the test data, which were obtained integrating Eq. (18) using the proposed integration method (relative tolerance 10 5 and absolute tolerance 10 the different underlying online sampling frequencies 10 1 and 10 3 respectively. In case of the lowest sampling frequency ( Table 5 ), which is identical to the lowest step size studied before ( Table 4 ), the results in terms of TGE obtained for the integrated hybrid model ODE system ( Table 5 ) do not show the same loss of stability. What is the reason? Obviously, the ODEs are different, i.e. Eq. 18 differs from Eq. 16 . However, ultimately the ODE system should approximate the original system with desired accuracy within certain bounds. To approximate the system, the model weights, w , are changed such that the residual between the experimental value and the model estimate is minimized, Eq. (14) . The residual depends on the model estimations x  X  t mes ; i obtained by integrating Eq. (18) with the proposed method. A loss in stability caused by too great step-sizes results in oscillating/or increasing values of x  X  t mes ; i  X  and thus great residual values. The residual is used to identify the parameter values, and thus the parameters are identi fi ed such that they can account for unsuitable great step-sizes. On one hand this means that the numerical integration error can partially be accounted for by the ANN, but on the other hand the underlying  X  true  X  ODE system, i.e. Eq. (16) ,is no longer mimicked by Eq. (18) . The parameter identi fi cation is also the reason why the TGE values obtained for a sampling frequency of 10 1 are lower than those obtained for a sampling frequency of 10 . Even with a suf fi ciently small sampling frequency (10
Table 7 ) it can be observed that the TGE values are signi higher than the GEE values, which is contrary to the observations made in Section 4.1.1 . The trend that would be expected can be observedfortheGEE,forwhichthevaluesarelowerforadecreasing sampling frequency ( Tables 5  X  7 ). The GEE provide an upper bound to the error resulting from the numerical integration, wherefore the remaining error must stem from th e parameter/model mismatch.
Thus, it follows that the error which is due to the model mismatch, in case that the sampling frequency is suf fi ciently small, is greater than the error which is due to the numerical integration.

A fact that was expected but also strikes, is that the number of function evaluations for the proposed method is only lower than the number of function evaluations for the Heun fi xed step size method when the sampling frequency is suf fi ciently small (see headers of Tables 5  X  7 ). Obviously the number of function evalua-tions in case of the proposed method depends on many factors, but as a rule of thumb it might be stated that the sampling frequency is suf fi ciently small if the number of function evalua-tions with a Heun fi xed step size method is signi fi cantly greater than the number obtained with the proposed method (in which case the error due to the numerical integration is much lower than the error due to model parameter or structural mismatch).
However, a suf fi ciently small sampling frequency in this sense does not guarantee that the user speci fi ed integration tolerances are met. For instance it can be seen in Fig. 5 , that both error tolerances are violated around a time of 0.1, since the step size cannot be reduced below the sampling frequency of 10 3 . The user must be/is warned about this circumstance, so that he can take action if desired. Else it can be seen that the step size is reduced when the curvature is large and when approaching the time events at which the solution has to be provided (for comparison with the of measured states). At sections where the curvature is low, the step size is successfully enlarged. 4.2. Case study II  X  batch fermentations of Bordetella pertussis methodology reduces the number o f function evaluations, when applied for the development of DNNs/hybrid models using typical experimental bioreactor data. The experimental study published by
Soons et al. (2008) provides the bases. Eight cultivations were carried out in batch mode and variations to the process conditions, such as in pH, temperature and dissolved oxygen were applied, as reported in
Soons et al. (2008) . The process data consist of infrequent, sparse measured concentrations of lactate ( Lac mes ), glutamate ( Glu biomass ( Lac ) and frequent online measurements, namely pH ( pH ), temperature ( Temp ) and dissolved oxygen concentration ( DO ). The online measurements were fi ltered and resampled using a cubic spline method, such that time difference between the measurements is equidistant, i.e.: 0.01 h. 4.2.1. The DNN/hybrid model structure hybrid semi-parametric model. The model equation reads d dt where Lac DNN , Glu DNN and X DNN are the concentrations of lactate, network (Note that the vector that contains the functions r is represented simply by f  X  U  X  in Eq. (1) ). The inputs of the neural network comprise the estimated concentrations and the online mea-sured variables, i.e.: r i  X  r i  X  Lac DNN ; Glu DNN ; X DNN 1 ;::; 3. The model estimates are obtained by integrating Eq. (19) either with the proposed  X  variable step size  X  method or the traditional step-size method. The parameter identi fi cation and model discrimina-tion was carried out as described in Section 3 above. The required sets of training and validation data consist of data of 5 and 2 batches, respectively. A test set that comprised data of 1 batch was used in addition to assess the generalization properties of the models. Network structures with one to three nodes in the hidden layer were studied.
The best performing model comprised a network with one node and the transfer functions of the nodes in the hidden layer were tangential hyperbolic. 4.2.2. Results
Asigni fi cant decrease of the number of function evaluations when integrating Eq. (19) with the proposed integration method can be observed, see Table 8 . On average the number of function evaluations is 48% lower than the number of fi xed-step size evalua-tions. During the identi fi cation of the network weights the sensitiv-ities equations are integrated along with the model equations, and a decrease in the number of function evaluations due to the proposed integration method is not always observable, see e.g. Fig. 6 . Therein it can be seen that the number of function evaluations during the fi rst iterations shows a sharp peak, whereupon it drops below the number required for a fi xed step-size Euler forward integration. Then again it rises and stabilizes around 3300 function evaluation per iteration, which is about 1000 evaluations more than in the case of the fi xed step-size Euler forward method. The greater number of function evaluations in case of the proposed method is owed to the sensitivity of the sensitivities equations with respect to changes in the step-size length and the strict integration tolerances (for greater tolerance limits the number of function evaluations generally decreases during the fi nal stage). Nevertheless, it is remarkable that the number of function evaluations is still signi fi cantly lower as when applying a method to ensure similar numerical integration errors, such as e.g. a step-size Heun method (4600 functi on evaluations per iteration). The pro fi le of the number of function evaluations over the iterations is due to the parameter identi fi cation (gradient based), during which the parameters change the most in the initial stage of the identi followed by small parameter changes close to a minimum. 5. Conclusions
An adaptive step size method for the integration of measured variable dependent ODEs systems was proposed, which avoids the computational expensive repetitive interpolation of measure-ments. Using a fi rst case study, the properties of the method are rigorously analyzed and the method is applied in combination with a hybrid semi-parametric model that in this particular case is identical to a dynamic neural network. In a second experimental case study the performance of the method was assessed for the development of a hybrid model with typical bioreactor experiment data. The following can be concluded: i) For suf fi ciently small step sizes the Heun method produces ii) When increasing the step size, the differences between the iii) In case the proposed integration method is applied with the iv) The error due to the numerical integration can partially be v) In case of model simulation the proposed integration method can signi fi cantly reduce the number of function evaluations as in comparison to a fi xed step-size method, by adapting the step size according to the curvature while adhering to the sampling frequency of the incorporated measurements. In the worst case, the proposed method will perform similar to an equivalent fi xed-step size method, but the user is informed by the method if the desired error tolerances are exceeded. In the best case, a several fold speed up for the integration can be yielded (here about 10 times depending on the greatest number of  X  h ). The proposed method also avoids the repeti-tive interpolation of the online measurements, which would be required if traditional adaptive step-size methods would be used. This is of increasing importance the greater the number of repetitive interpolations and/or the greater the number of comprised online measured variables that need to interpolated. vi) In case of parameter identi fi cation the number of function evaluationsishigherthanforasimple fi xed-step Euler forward method, because (1) the sensitivities equations are integrated along with the model equations and so the curvature at least for a subset of equations is high and (2) because both of the combined methods, Heun and RK4, require twice as many evaluations for the same step as the forward method. vii) Since the sampling frequency determines the smallest possi-ble step size, the error tolerances can only be ensured to the degree where the smallest possible steps equal the sampling frequency. viii) The sampling frequency is not required to be constant, but in general a constant frequency allows the application of the RK4 method, which obtains a signi fi cantly reduced integration error with the same number of function evaluations as the Heun method.
 Acknowledgments The author MVS acknowledges fi nancial support through the
Funda X  X o para a Ci X ncia e a Tecnologia (SFRH/BPD/84573/2012 and SFRH/BD/36990/2007). The authors thank Zita I.T.A Soons,
Mathieu Stree fl and and the Netherlands Vaccine Institute for providing the data.
 References
