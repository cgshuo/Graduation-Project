 document X  X  content. Keywords provide rich semantic information for many text min-ing applications, for example: document classification, document clustering, docu-ment retrieval, topic s earch, and document analysis. have keywords assigned. In order to enjoy the benefit of keywords, it is necessary to paper. 
Existing methods on keyword extraction have been done mainly by using a prede-fined controlled-vocabulary, which cannot process the unknown words/phrases. In natural language processing, base Noun Phrase (baseNP) finding and key-term recog-nition have been studied. But the extracted baseNPs are not necessary to be keywords of the document. Recently, several methods are proposed to extract keywords by limited. In the research community, no previous study has so far sufficiently investi-also the  X  X ocal context information X , to the best of our knowledge. 
Three questions arise for keyword extraction: (1) how to formalize the problem the problem in a principled approach, and (3) how to make an implementation. (1) We formalize keyword extraction as a classification problem, in which the  X  X ndifferent keyword X , and  X  X ad keyword X . We give a specification of keyword in this paper. (2) We propose to conduct keyword extraction by a classification approach. In the approach, we select the candidate keywords by tri-grams, and then define the features by both  X  X lobal context information X  and  X  X ocal context information X . We then accom-plish the keyword extraction by a classification model that is trained in advance. port Vector Machines (SVMs). 
We tried to collect data from as many sources as possible for experiments. Our ex-perimental results indicate that the proposed SVM based method performs signifi-method to document classification. Experimental results indicate that our method can indeed enhance the accuracy of document classification. We observed improvements ranging from 7.79% to 22.12% on document classification in terms of F1-Measure. work. In section 3, we formalize the problem of keyword extraction. In section 4, we plementation. Section 6 gives our experimental results. We make concluding remarks in section 7. 2.1 Keyword Extraction Keyword extraction is the task of selecting a small set of words/phrases from a docu-mining [Hulth2004]. 
For example, Turney has developed a system, called GenEx, for keyword extrac-training documents. on Na X ve Bayes machine learning approach [Frank1999, Witten1999]. They have by utilizing the global context information, i.e. term frequency and first occurrence of the word/phrase. text X  features. See also [Azcarraga2002, Hulth2004, Matsuo2004, Zhu2003]. 
Our method exploits both global context and local context information. We trans-SVM algorithm as the classifier. 2.2 Keyword Assignment Keyword assignment is aimed to assign keywords from a predefined controlled-vocabulary to documents. 
For example, Dumaisn et al propose a method for finding a mapping from docu-ments to the categories that are defined as keywords in a controlled-vocabulary [Du-mais1998]. They make use of machine learning method to learn classifiers from a set known words/phrases. 2.3 Key-Term Recognition documents [Xun2000]. The extracted terms can be used as features of documents for document mining applications such as docum ent categorization and document cluster-aimed to extract the most meaningful words/phrases that can be used to describe the documents. In this way, a keyword can be a base NP; however, a base NP is not nec-cantly different. Keywords extracted from a document should be as few as possible if term extraction can extract many words/phrases. See also [Brill1999]. 2.4 Text Summarization Text summarization is another type of similar work to keyword extraction. Infor-tracted content by text summarization can be paragraph(s) or sentences(s). Therefore, text summarization differs in nature from keyword extraction. 
Zha, for instance, proposes a summarization method by first clustering sentences of a document (or a set of documents) into topical groups and then, within each topical See also [Berger2000, DUC, Mani1999]. Keywords extracted from a document play an important role in describing the mean-that keywords indeed improve the accuracy of document classification. Now we formally define the keyword extraction problem that we are solving. keywords. Here, the word is the smallest language unit in our problem, and a keyword words extracted should occur in the document. we can still provide relatively objective guidelines for judgment. We call it the speci-extraction. 
In the specification, we create three categories for keywords which represent their goodness as keywords:  X  X ood keyword X ,  X  X ndifferent keyword X  and  X  X ad keyword X . 
A good keyword must contain the general notion of the document, and several im-basic meaning of the document. Furthermore, a good keyword should be easily the user to distinguish between documents with similar contents. A bad keyword neither describes the general notion nor properties of the document. document by reading a bad keyword. 
An indifferent keyword is one that between good and bad keyword. We formalize keyword extraction as a classification problem. We take  X  X ood key-can be automatically accomplished by predicting the class of each test example. 
We perform keyword extraction in two passes of processing: learning, and keyword extraction. 
In learning, we construct the classification model that can predict the class of each For each example, we define a set of features and assign a label. The label represents whether the word/phrase is a  X  X ood keyword X ,  X  X ndifferent keyword X , or  X  X ad key-word X . We use the labeled data to train the classification models in advance. 
In keyword extraction, the input is a document. We extract a bag of words/phrases  X  X ood keywords X  as keywords. However, to determine whether a word/phrase is  X  X ood keyword X ,  X  X ndifferent key-word X , or  X  X ad keyword X  is still one of our near future work. We consider one implementation of our approach. We make use of SVM (Support Vector Machines) as the classification model [Vapnik1995]. y denotes a classification label. In learning, one attempts to find an optimal separating hyper-plane that maximally separates the two classes of training examples SVM can be further extended into non-linear SVMs by using kernel functions such as Gaussian and polynomial kernels. 
We use SVM-light, which is available at http://svmlight.joachims.org/. We choose best for our current task. We use the default values for the parameters in SVM-light. approach, i.e., take one class as positive and the other classes as negative. 5.1 Process steps. (1) Preprocessing. For a document, we conduct the sentence split, word tokeniza-tion and POS (part-of-speech) tagging by using GATE [Cunningham 2002]. We next employ Linker [Sleator1991] to analyze the dependency relationships between words in each sentence. After that, we employ tri-gram to create candidate phrases, and then using WordNet [Miller1990]. Specifically, we only stem the plural noun, gerund, and passive infinitive by their dictionary form. Finally, we obtain a set of  X  X eyword candi-date X  for the later processing. word/phrase in a document to define its features (see following section for a detailed sponds to a word/phrase. (3) Learning. The input is a collection of feature vector by step (2). We construct a word/phrase as an example, the words/phrases labeled with  X  X eyword X  as positive examples, and the other words/phrases as negative examples. We use the labeled data to train the SVM model in advance. (4) Extraction. The input is a document. We employ the preprocessing and the fea-output is the extracted keywords for that document. 
The key issue here is how to define features for effectively performing the extrac-tion task. 5.2 Features in the Model context features and the document global context features. (1) Global Context Features TFIDF Feature. The feature is calculated by TF*IDF, where TF is the Term Fre-n is the number of documents in which the current word/phrase occurs. ment. Its value ranges between 0 and 1. there exists). The words/phrases occurring in the document title, abstract and section title have higher probabilities of being keywords. (2) Local Context Features Local context features have not been investigated previously for the task of keyword extraction. POS Feature. The feature represents the POS of the current word. A keyword usually is a noun word/phrase. For phrase, we define a unified POS:  X  X HRASE X . words are recognized. We give two linkage definitions: Linkage Authority and Link-age Hub. Linkage Authority denotes how many words that modify the word. The more the word is modified by, the higher authority it has. Linkage Hub denotes how hub it has. 
The two linkages are defined as follows: 
Where: spectively. freq w  X  in the global corpora. N is the size of the global corpora. 
The value probability that this word appears in any document of the corpora. Contextual TFIDF Feature. Contextual TFIDF is the sum of the TFIDF of words in the  X  X ontext X  of the current word/phrase, which represents the contextual TFIDF. We view words in the same sentence as the current word as its contextual words. Data Sets and Evaluation Measures text collection ( http://www.research.att.com/~lewis/ reuters21578.html ). Web Doc is downloaded arbitrarily from the Internet. data set, its description and the number of documents in it. 
Among the four datasets, some research papers already have author assigned key-section 3). Moreover, the other documents do not have keywords. Human annotators conducted annotation on all the documents. Keywords of research papers were up-labeled. Specifically, five graduates in our laboratory were asked to conduct the anno-tation for all the documents. The number of annotated keywords ranges from 4 to 10. The average of annotated keywords is 9.69 per document. Finally, for each document, keywords. In this way, each document has six  X  X orrect X  keywords averagely. Evaluation Measures. In all the experiments on extraction, we conducted evaluations in terms of precision, recall and F1-Measure. The evaluation measures are defined as follows: Precision: P = A / ( A + B ) Recall: R = A / ( A + C ) F1-Measure: F 1 = 2 PR / ( P + R ) where A, B, C and D denote number of instances. method can extract the target, we say that it makes a correct decision; otherwise, we basis of the result. for a document, we selected six words/phrases with the higher TFIDF as keywords. extraction. We downloaded the KEA algorithm from http://www.nzdl.org/Kea/ index.html#download , and applied it to the four datasets. the features we defined in our model (inc luding global and local features). We carried out the comparison of the results by our methods with the two kinds of features. Keyword Extraction Experiment. We evaluated the performances of our keyword extraction methods on the four data sets. 
We performed comparisons with the baseline methods and the KEA algorithm. We also evaluated our method with only the global context features and with all the fea-tures we defined. 
Because the average number of keywords annotated manually is six, we select six words as keywords that are classified as positive examples by the SVM model. tures. The second column indicates the average number of keywords extracted. tures also outperforms that by using only global context features. We conducted sign improvements are statistically significant. Discussions (1) Improvements over baseline method. The TFIDF based extraction method re-sults in a poor performance (only 12.90% in terms of F1 -Measure). When using only global context features, we can obtain greatly improvement +40.09% in terms of F1-features, we can again obtain improvement +47.00% in terms of F1-Measure. (2) Improvements over KEA algorithm. When using only global context features, we can obtain greatly improvement +22.47% in terms of F1-Measure over KEA algo-tures, we can again obtain improvement +29.25% in terms of F1-Measure. features and local context feature outperforms that using only global context features (+6.51% in terms of F1-Measure). In the latter method more keywords were assigned ments. (4) Error analysis. We conducted error analysis on the results.  X  X eyword X . 20% of the errors were due to the  X  X mbiguity X  of the extracted keywords. document. But it is difficult to classify them to  X  X eyword X  or not. Maybe they should correspond to the  X  X ndifferent keyword X  in our specification. 
For the method combining both global and local context features, 25% of the errors word X . This was due to the effect of local context features. 75% of the errors were due to the  X  X mbiguity X  of the extracted keywords. (5) No free lunch. As the proverb says,  X  X very coin has its two sides X . Although the computation costs are heavy, especially on linker analysis. The linker analysis on the four data sets cost nearly 22 hours. (6) Difficult task. It is difficult to accurately extract keywords from documents. That is because in some cases judging whether a word/phrase is keyword or not is difficult, even for human. Document Classification Experiment. In order to evaluate the effectiveness of our keyword extraction method, which we aim to assign documents of a corpus to a fixed set of categories. We chose Na X ve Bayes as the classification method. For each document, the extracted keywords are viewed as features and are assigned with higher weights. CMU Text Learning Group Data Archives ( http://www-2.cs.cmu.edu/afs/cs.cmu. edu/project/theo-20/www/data/news20.html ). Among the collection, ten categories ture extraction. We carried out the experiments as follows. In the first experiment, we used all the BOW features to evaluate the classification performance. In the other experiment, we of the extracted keywords. Bayes classification on the original data and on the data with extracted keywords. 
From table 4, we see that by using keyword extraction, a significant improvement can be obtained on the task of document classification (ranging from 7.79% to 22.12% in terms of F1-Measure). We observed improvements on precision (+13.27%), recall (+4.65%), and F1-Measure (+12.86%) on average. The results indi-cate that our method of keyword extraction is effective. The results are also consistent with the result obtained in the experiment of keyword extraction. 
We also applied the extracted keywords to document classification by using SVM result on the task of document classification. fined the problem as that of extracting words/phrases in the document. We have pro-posed a classification approach to the task . Using Support Vector Machines, we have been able to make an implementation of the approach. Experimental results show that When applying it to document classificat ion, we observed a significant improvement on extraction accuracy. 
As future work, we plan to make further improvement on the accuracy. We also want to apply the keyword extraction method to other text mining applications. 
