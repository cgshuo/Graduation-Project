 Online learning is used in a wide range of real applications, e.g., predicting ad click-through rates (CTR) and personal-ized recommendations. Based on the analysis of users X  be-haviors in Video-On-Demand (VoD) recommender system-s, we discover that the most recent users X  actions can bet-ter reflect users X  current intentions and preferences. Under this observation, we thereby propose a novel time-decaying online learning algorithm derived from the state-of-the-art FTRL-proximal algorithm, called Time-Decaying Adaptive Prediction ( TDAP ) algorithm.

To scale Big Data, we further parallelize our algorithm following the data parallel scheme under both BSP and SSP consistency model. We experimentally evaluate our TDAP algorithm on real IPTV VoD datasets using two state-of-the-art distributed computing platforms, i.e., Spark and Petu-um. TDAP achieves good accuracy: it improves at least 5.6% in terms of prediction accuracy, compared to FTRL-proximal algorithm; and TDAP scales well: it runs 4 times faster when the number of machines increases from 2 to 10. In our real running business cases, TDAP significantly in-creases the degree of user activity, which brings more rev-enue than existing ones for our customers.
Online learning techniques [3, 9, 19, 24, 26, 30, 32] are powerful tools for a wide range of emerging applications, from online advertising [25] and personalized recommen-dation [2, 28], to unusual events detection [35] and suspi-cious URLs identification [23]. For example, in an online IPTV Video-On-Demand (VoD) recommender system for one of our customers, a giant Telcom company from Main-land China, the accuracy of prediction ( e.g., AUC) can be significantly improved at least 4% using online learning tech-niques compared to traditional batch (offline) learning tech-niques [12, 18, 37].
 Figure 1: The fast changing users X  watching counts on To date, people and devices (from smart phones, to VR Boxes, to coffee machines and cars) generate large volume of data every day, which are with fast-varying (or fast-changing ) nature ( a.k.a. concept drifting [11]). However, existing online learning techniques may not be a good fit for such fast-changing data, which are usually in form of exam-ples with features and labels in practice. Let X  X  first illustrate one of such data taken from a real-world application, Example 1: Figure 1 shows features about users X  watching counts on three different types of videos (Film, TV play and Animation) during the time period from 2015-06-01 to 2015-06-07 on an online IPTV VoD recommender system in a Telcom company from Mainland China.

From Figure 1, we observe that the watching counts on different types of videos vary a lot under different time pe-riod. In particular, in weekdays (from 2015-06-02 to 2015-06-05), the watching counts of TV play at working hours (08:00-18:00) on average are larger than those of the other two types of videos ( i.e., Animation and Film); Animation views are the most from 18:00 to 20:00; and the number of TV play increases again after 20:00. Besides, Animation views from 08:00 to 18:00 on weekends (from 2015-06-06 to 2015-06-07) and Children X  X  day (2015-06-01) are larger than those of the other two, which typically differ from the case in weekdays (as above).

In short, from the above observation, we note that the varying of users X  watching counts on different types of videos between day and night, or between weekdays and holidays, typically implies that the users X  watching preferences are changing rapidly along the time series, which in fact brings a big challenge to the design of the online learning algorithm for the recommender system. 2
The above example raises one crucial concern to the ex-isting online learning algorithm design: how to fit and scale those big and fast-changing online data efficiently and prac-tically ? To answer the question, a scalable time-decaying on-line learning algorithm is in need. However, two challenges need to be addressed.

The first challenge is that the time-decaying algorithm re-quires to fit the fast-changing online data . Unfortunately, up to date, previous works [19, 24, 25, 30, 32] have not addressed it well. On one hand, previous time-decaying algorithms ei-ther weight data (or examples) by time-decaying functions ( e.g., [16, 17]) or just discard outdated examples ( e.g., [3]), which require full memory or keep only recent examples, respectively. On the other hand, existing online learning al-gorithms ( e.g., mirror descent (MD) algorithm like TGD [19] and FOBOS [30], and follow-the-regularized-leader (FTRL) algorithm like RDA [32] and FTRL-proximal [24,25]), which do not take the changes of the data into account, may not respond the changes correctly. And worse still, the target model generated from the existing online learning algorithms may no longer be suitable for current data distribution, since older history of models are equally weighted as the recent ones in the learning procedure, which may decrease its ( i.e., the target model X  X ) effectiveness.

For the second challenge, the time-decaying algorithm needs to scale the big fast-changing online data . To the best of our knowledge, previous works [34, 36, 37] only study the parallelism of MD-like algorithms. And the parallelism of FTRL-like algorithms are mentioned in [25] only, no detailed solution is provided.
 Contributions . This paper addresses scalable online learn-ing problem with fast-changing data. The contributions are characterized as below. (1) We define a problem called time-decaying online con-vex optimization TOCO problem (Section 2), where the tar-get model approaches to the most recent models while older history of the models are deemphasized, following a user-defined time-decaying function. (2) We propose a time-decaying adaptive prediction TDAP algorithm to solve TOCO problem (Section 3), which incor-porates with both the state-of-the-art FTRL-proximal al-gorithm and an exponential time-decaying mechanism over model update. Recursive closed forms of the model up-date functions are proposed for computational efficiency and memory saving. (3) To scale big data, we first parallelize the TDAP algo-rithm following the data parallel scheme [14] under bulk syn-chronous parallel (BSP) [6] consistency model (Section 4), in which recursive update methods considering time-decaying factors are proposed, and detailed implementations are pro-vided. To avoid the unnecessary costs due to the synchro-nization policy ( X  X locking X  of stragglers) of BSP, we further parallelize the algorithm under stale synchronous parallel (SSP) model, with accuracy guarantees from [13]. (4) Under real-world datasets, we experimentally evaluate our algorithm on top of two well-known platforms (Sec-tion 5): (a) general big data analytic platform Spark [27] under BSP model; and (b) specific machine learning plat-form Petuum [33] under SSP model. It is worth highlight-ing that TDAP achieves good accuracy: it improves 5.6% prediction accuracy, compared to FTRL-proximal algorith-m, on both platforms; and TDAP scales well: it runs 4x speedup when the number of machines increases from 2 to 10. We further observe that TDAP on Petuum runs faster than that on Spark, and the former enjoys better scalability with more machines.

In our production IPTV VoD service, when we switched from FTRL-proximal to TDAP , we observed 5% more users engaging on our service, and 10% longer engagement time per user, approximately. We also observed that TDAP on Petuum can process approximately one order of magnitude more users than Spark, with the same cluster setup. While both TDAP on Petuum and Spark are viable, we found that deployment was easier and more efficient using Petuum. Organization . This paper is organized as below: In Sec-tion 2, we review some related work and formulate our TOCO problem; We propose our TDAP algorithm to solve the problem in Section 3; Section 4 then parallelize the TDAP algorithm under both BSP and SSP consistency mod-el; We experimentally verify our algorithm in Section 5 and conclude this paper in Section 6.
In this section, we first introduce the related work. We then give some details of the FTRL-proximal algorithm since our algorithm are derived from the FTRL-proximal algorith-m due to its superior performance. We end this section by formulating our problem. We characterize related work as follows.
 Algorithms with time-decaying property . Numbers of time-decaying algorithms are proposed to address the con-cept drifting [11] problem. On one hand, for gradual concept drifting, full memory based approaches ( e.g., [16] and [17]) use exponential or linear time-decaying functions to weight data (or examples), i.e., the older the example, the small-er the impact. For abrupt ones, on the other hand, partial memory based methods ( e.g., [3]) are proposed by discarding examples outside a pre-defined window, only recent exam-ples in the window are taken into account.

In contrast, we differ from the above as: (a) unlike full memory based methods, we do not require to store all exam-ples, which saves memory; (b) We consider all examples in model training, such that information in previous examples are not discarded; and (c) Our algorithms are able to tack-le both gradual and abrupt concept drifting problems, with tuning the time-decaying factor (to be seen in Section 3). Online convex learning algorithms . Various online learning algorithms are proposed to solve the online convex optimization problem. We characterize it as the following two types: (a) Mirror descent (MD) algorithms like truncat-ed gradient descent [19] and FOBOS [30]; and (b) Follow-the-regularized-leader (FTRL) algorithms like RDA [32] and FTRL-proximal [26]. Moreover, [24] proves the equivalence between the mirror descent algorithms and the FTRL algo-rithms, and in particular, FTRL-proximal outperforms the others in terms of accuracy and sparsity [25], and are wide-ly used in industry, e.g., recommender system [2, 28] and Advertisement system [25].
However, our algorithms differ from the previous ones in the followings: (a) The effects of the older history of the models on target model are scaled down with an exponen-tial time-decaying function, while existing methods do not ; and (b) The time-decaying factors are embedded into the recursive closed form of model update functions, similar to the FTRL-proximal algorithm in [25].
 Parallelism of online learning algorithm . In the litera-ture, there are various existing works on parallelized machine learning algorithm [10, 12, 18]. Meanwhile, lots of machine learning platforms are proposed [1, 8, 22]. Among others, relate to online learning context, techniques for paralleliz-ing mirror descent (MD) algorithms, in particular, stochas-tic gradient descent (SGD) algorithm have been intensively studied. [36] proves that parallelized SGD converges well with decayed updates. [37] presents the first parallelized SGD including a detailed analysis and experimental evi-dence. [34] proposes a user-friendly programming interface for parallelizing SGD. [25] also mentions the parallelism of the FTRL-like algorithms, but no detailed solution is given.
However, in contrast to previous works, we (a) pro-pose recursive model parameters update functions embed-ded with exponential time-decaying factors in distributed (multi-machines) setting; (b) provide practical implementa-tions of our algorithm (FTRL-like algorithm) for parallelism on both BSP [6] and SSP [13] consistency model in online learning scenario; and (c) compare the performance on two well-known platforms: (i) general big data analytic platform ( i.e., Spark [27]) for BSP model; and (ii) specific machine learning platform ( i.e., Petuum [33]) for SSP model. We conclude some interesting results in the experiments and hope that all practitioners get enlightened from it.
In this subsection, we give the details of the FTRL-proximal algorithm. We start with the optimization prob-lem that the algorithm is proposed for. We first establish some notations to be used in the following. We denote a vector g ( t )  X  R d , where t indicates the t -th training exam-ples. The i -th entry in vector g ( t ) is defined as g g ably if the context is clear.
 Optimization problem . Given a time step T  X  1, a se-quence of training examples with features x ( t )  X  R labels y ( t ) , t  X  [1 ,T ], the optimization problem that FTRL-proximal algorithm solved takes the form of in particular, Model update function . To solve the optimization prob-lem in Equation 1, at each iteration t  X  [1 ,T ], the FTRL-proximal algorithm updates the model parameters iterative-ly, i.e., w ( t +1) takes the form of arg min where
As reported in [25], the update function in Equation 2 can be transformed into a recursive closed form, i.e., the value w ( t ) can be recursively computed from w ( t  X  1) . An efficient implementation with pseudocode is then provided based on the recursive form. And better still, FTRL-proximal algo-rithm outperforms the other classical online learning algo-rithms ( e.g., FOBOS and RDA) in terms of accuracy and sparsity, Therefore, in this paper, we derive our techniques from the FTRL-proximal algorithm. We consider a possible intuitive modification to FTRL-proximal, that lets it adapt faster to changes in data distribution.
As motivated in Sec. 1, we want to tackle the data with fast-changing nature for online learning scenario, which in-dicates that the target model approaches to the most recent model while older history of the model can be deemphasized. Thus, we state the time-decaying online convex optimization TOCO problem as below.
 Definition 1: Given a time step T  X  1, a sequence of train-ing examples with features x ( t ) and labels y ( t ) , t  X  [1 ,T ], the time-decaying online convex optimization, denoted as TOCO , is stated as w
The objective function in Equation 4 is similar to that of Equation 1, except that we introduce an additional term target model. More specifically, (a) F ( T ) ( t ) is a monotonic increasing time-decay function (to be defined shortly) with independent variable t , and (b) S ( w , w ( t ) ) is a smoothing term, i.e., 1 2 k w  X  w ( t ) k 2 2 .
The intuition here is that with the help of time-decaying function, the target model w ( T ) cannot differ too much com-pared to those recent model, while the effects from older history of the model can be decreased. Such corresponds to the objective of our problem.
In order to solve TOCO problem, in this section, we present the details of the proposed time-decaying adaptive prediction ( TDAP ) algorithm. We first introduce the time-decaying function. We then give a formal definition of the model update function with recursive closed form. Details of the algorithm are finally presented.
 Time-Decaying function . We note that there are num-bers of time-decaying function in the literature, such as poly-nomial decay and exponential decay [7]. In this paper, we use exponential decay function as F ( T ) ( t ) in Definition 1. The reasons are two folds: (a) it is widely used in both in-dustry [20, 31] and academia [5, 29]; and (b) the recursive closed form of the model update function (to be seen short-ly) can be derived under the exponential term 1 .

In particular, the exponential time-decaying function takes the form of where T  X  1 is current time step, and t is time step of the history model, t  X  [1 ,T ]. Note that F ( T ) ( t ) is a monoton-ic increasing function with independent variable t , i.e., the larger the t , the larger the returned value.
 Model update function . Based on the exponential decay function in Equation 5, we define the iterative model update function in each iteration t to solve TOCO , where w takes the form of arg min Note that  X  ( s,t ) =  X  ( s )  X  F ( t ) ( s ), which can be extended on per-coordinate base as  X  i =  X  Here,  X  &gt; 0 is a decay rate, and the bigger the  X  , the faster decaying of the history model. It is easy to see that in case of lim  X   X  +  X   X  = 0, Equation 6 is equivalent to that of FTRL-proximal algorithm in Equation 2.

It is worth highlighting that the update function for TDAP algorithm differs from that of the FTRL-proximal algorithm as we introduce the time-decaying factor to the smoothing term, i.e., the quadratic term 1 2 P t s =1  X  ( s,t ) k w  X  w Closed form . Similar to FTRL-proximal algorithm, we next derive a recursive closed form of the update function in Equation 6 following the flow in [25].
In this work, we take the first step to study the TOCO prob-lem with exponential decay, other time-decaying functions ( e.g., polynomial decay) are refered to the future work.
We rewrite the Equation 6 w.r.t. the arg min over w as n w ( t +1) in a recursive closed form on a per-coordinate base as follows, ( From Equation 9, in iteration t , we are required to store P update both values in t -th iteration with only the values of ( t  X  1)-th iteration? Next, we focus on the recursive form in a recursive form: a recursive form
Thus, the recursive form of z ( t ) i becomes Detailed algorithm . Putting all together, in iteration t , from Equation 10 and 12, we note that our algorithm is coordinate base only . We show the pseudocode of TDAP algorithm using the example of logistic regression in Fig-ure 2. The algorithm first initializes the parameters in Line 1. Then, upon receiving the features (Lines 2-3) for each iteration, TDAP updates the model parameters and does the prediction (Lines 4-6). It then updates the param-eters for further usage by observing the labels (Lines 7-15). Advantages . It is worth remarking that (a) the effects of older history models on target model are scaled down with the help of time-decaying function, which leads to adapt fast changes (gradual or abrupt) of data; (b) all examples are used for model training while there is no need to record them, which significantly saves the memory; and (c) it is efficient to update the models due to the recursive closed form, as shown in Section 5.
In this section, we show the parallelism of TDAP algo-rithm. We first introduce the data model and the system model. We then present the parallel TDAP under data par-allel scheme with bulk synchronized parallel (BSP) consisten-cy model, as TDAP BSP . We end this section by showing how we can extend the TDAP BSP to stale synchronized parallel (SSP) model, as TDAP SSP . Data model . We follow the data parallel [14] model in online learning scenario. In particular, the data (examples with features and labels) take the form of stream, which is divided into a sequence of mini-batch D ( t ) in each iteration t  X  [1 ,T ], | D ( t ) |  X  1. The mini-batch D ( t ) is then parti-tioned and assigned to computational workers indexed by p for further computations (to be seen shortly).
 System model . The system model follows the state-of-the-art parameter server paradigm e.g., [8, 13, 22], which are widely used to tackle the large scale iterative machine learn-ing problem [15, 18, 37]. It comprises of the following three major components: Driver . The driver is to initiate the algorithm and control the parameters updates via parameter consistency controller for each iteration t  X  [1 ,T ] under the bulk synchronized parallel (BSP) or stale synchronized parallel (SSP). Parameter servers . The parameter servers (PS) provide a global access to model parameters via a parameter synchro-nization interface like that of table-based or key-value stores. Note that in practice, the PS can also be the driver. Workers . Let P be all workers. For each iteration t , each worker p  X  P receives the model parameters from PS via the parameter synchronization interface ( i.e., pull ()), and up-dates the model locally in parallel using the received exam-ples D ( t ) p partitioned by mini-batch D ( t ) , i.e., D Figure 3: Data model, system model and working flow Note that each example in D ( t ) is allocated to one worker only . After the update is done, the worker p then synchro-nizes the newly updated model parameters to the PS via the synchronization interface push (). The driver (or PS) then generates future decisions.
 Example 2: Figure 3 depicts an example of the data model and system model. Three parties of the system, i.e., driver, PS and workers are shown. For simplicity, here, the PS also represents the driver. The examples coming to the system take the form of a stream of mini-batch D ( t ) in each iteration t . Collections of examples D ( t ) p  X  D ( t ) are then sent to the worker p for later computations. 2 Data structure . We first introduce three types of data structures that facilitate TDAP BSP .
 Global parameters on PS . The global parameters are stored in PS, which keep track of the global model states. In par-ticular, in iteration t , the global parameters to be saved are ( u learning-rate schedule and model parameter) with i -th co-ordinate in t -th iteration computed under example d  X  D ( t ) decaying factor, which are different to h ( t ) i and  X  ( t ) Local parameters at workers . Each worker p stores its lo-cal parameters, which can be derived from global pa-rameters on PS. Specifically, in iteration t , the local parameters to be saved at worker p take the form of ( u where It is worth highlighting that h ( t  X  1) i 0 is recorded in order to compute P Local delta parameters . Intuitively, for each worker p , it computes the local delta parameters which is to incremen-tally update the global parameters on PS. More specifical-ly, the local delta parameters for work p in iteration t are TDAP BSP algorithm . We show the details of TDAP BSP us-ing the logistic regression, which is controlled by a driv-er function Driver BSP . Driver BSP initiates the TDAP BSP triggers Eval p BSP (Figure 4) and Eval PS BSP (Figure 5) functions in each iteration between workers and PS. All parameters are updated iteratively under BSP model, no need to com-pute from scratch.

In particular, all global parameters and local (delta) pa-rameters are initiated as zero. Then given a collection of examples in iteration t , each worker p computes the local (delta) parameters by Eval p BSP , in parallel , based on the glob-al parameters computed in previous iteration. The global parameters are then updated by Eval PS BSP at PS using the newly computed local delta parameters. Driver BSP termi-nates the whole procedure manually, or until there is no data coming.
 Eval p BSP . Given a collection of examples D ( t ) p  X  D iteration at worker p , Eval p BSP first receives all global param-eters from PS by pull () function (Line 1). It then updates the local parameters and computes local delta parameters iteratively, based on the parameters in ( t  X  1)-th iteration (Lines 2-7). The model parameters w ( t ) are then construct-ed using the newly updated local parameters, and the pre-diction are conducted (Lines 8-11). Eval p BSP finally computes the local delta parameters (Lines 12-17) and sends them to PS by push () function for incrementally updating the global parameters (Line 18).
 Eval PS BSP . Upon receiving all local delta parameters from each worker p in iteration t , Eval PS BSP increments global parameters by summing up all those received local delta parameters. The updated global parameters are used for next iteration (Lines 1-6).
 Example 3: Figure 3 illustrates the working flow of TDAP BSP algorithm in t -th iteration given a mini-batch D All local and global parameters are recored in PS and work-ers, respectively, which are initialized as zero.

Upon receiving a collection of examples D ( t ) p  X  D ( t ) worker p invokes Eval p BSP . It pulls the global parameters from PS, and updates the local (delta) parameters accordingly. The prediction are conducted based on the newly computed model parameters. After the computations, Eval p BSP pushes the local delta parameters to the PS.

Based on the local delta parameters received from al-l workers (required by BSP consistency model), the PS then invokes Eval PS BSP to augment the global parameters accord-ingly. Afterwards, the PS ( a.k.a. the Driver) then invokes next iteration of the computation, or abort. 2
The performance of TDAP BSP may be significantly ham-pered by the stragglers in each iteration that may hold up the process, such costs are inherent to the synchronization policy of BSP. To reduce the costs, one possible solution is to use asynchronous parallel strategy , however, no performance guarantee is provided [33] in terms of correctness.
In this subsection, we introduce TDAP under SSP con-sistency model [33], denoted as TDAP SSP , whose accuracy can be theoretically preserved by [13]. Since TDAP an extension from TDAP BSP , for presentation simplicity, we avoid repeating the same details, but highlight the major differences between two.
 Data structure . We first present the difference on data structure. The local delta parameters for TDAP SSP are the same to those of TDAP BSP , while local and global parameters involve more components, as described below.
 Global parameters on PS . Besides the global parameters used in TDAP BSP , TDAP SSP introduces two more types of global parameters on PS: (a) The time step t p for each work-er p , which encodes the latest time step that worker p syn-chronizes (via push interface) its local delta parameters to the PS; and (b) The minimum time step t PS for all workers p , i.e., t PS = min { t p | X  p  X  P } .
 Local parameters at workers . At worker p , except for those parameters in TDAP BSP , TDAP SSP requires to record (a) the latest time step t p that the local parameters been updated; and (b) the latest time step t ( p,PS ) that worker p synchro-nizes global parameters (via pull interface) from PS. TDAP SSP algorithm . Based on the newly introduced pa-rameters, we are ready to show the algorithm. Similar to TDAP BSP , TDAP SSP is also controlled by a driver Driver which is for initialization and triggering Eval p SSP and Eval functions under the SSP consistency model. In particular, compared to BSP, workers may compute advance ahead of each other up to s iterations apart, where s is called stale-ness threshold (in short stale), under SSP. Workers that go too far away ( s iterations faster than the slowest one) are forced to wait, until slower workers catch up. Note that SSP is equivalent to BSP when s = 0.
 Eval p SSP . Given a collection of examples D ( t ) checks whether the local parameters are delayed or stale, by evaluating the value of ( t p  X  t p,PS ). (a) If ( t p  X  t ( i.e., local parameters at worker p are delayed at least s iter-ations), Eval p SSP yields to synchronize global parameters from PS via pull interface (like Line 1 in Figure 4) and conducts the procedures that are the same to Lines 2-17. The time step t p,PS is then updated as t PS , i.e., t p,PS = t PS t
PS is within those returned global parameters; (b) Other-wise, no need to update the local parameters, Eval p SSP computes the local delta parameters, the same to Lines 12-17 in Figure 4.

Note that the time step t p for worker p is incremented by 1 after the above procedure, and all local delta parameters are then sent to PS via push interface, as Line 18 in Figure 4. ceiving (a) the local delta parameters, or (b) a pull request for global parameters, from a worker p .
In this section, we experimentally study the perfor-mance between FTRL-Proximal and TDAP using real-world datasets. In short, we evaluate (a) the accuracy of TDAP ; (b) the scalability of TDAP ; and (c) the efficiency between TDAP Spark and TDAP Petuum . The results exhibit the algorith-m with good accuracy, scalability and efficiency. Datasets . We benchmarked 8 real-world datasets in total, which can be classified into the following categories. Some detailed statistics of the datasets are illustrated in Table 1. Public non-time series datasets . We used 6 datasets with-out time series, namely Books, DVD, Electronics, Kitchen, RCV1 and News. Among them, Books, Dvd, Electronics and Kitchen are first used in [4], representing Amazon prod-uct reviews of four different product types. RCV1 and News are scaled versions of rcv1.binary [21] and news20.binary [15] datasets for binomial classification, respectively. Public time series dataset . We used a public dataset with time series on suspicious URLs detection, called URLs which is available from [23]. It is an anonymized 120-day subsets with around 2 . 4 million URLs detection records. Each day contains about 6 , 580 positives and 13 , 223 negatives exam-ples on average.
 IPTV VoD time series dataset . We collected a dataset with 7-day IPTV VoD (Video On Demand) program ( e.g., movies and TV plays) views, named as IPTV, from a giant Telecom company in Mainland China. It involves 72 , 350 , 479 view records from 4 , 446 , 247 users.

To generate the examples, we construct a feature label pair ( x ( t ) , y ( t ) ) for each VoD program view record at time t . In particular, x ( t ) is a sparse feature vector, with size of 1 , 321 , 393 (as shown in Table 1), encoding the characteris-tics of both program and user, e.g., program information, us-er properties, user behaviors and time stamp of user X  X  view. The label y ( t ) is 1 if the program was viewed by the user at least 20 minutes or half of the total length of the program; and 0 otherwise.
 Algorithm settings . We implemented the following al-gorithms: (a) Algorithms on Spark 1 . 5 . 1 under BSP mod-el: (i) FTRLProx Spark , the FTRL-Proximal algorithm [25], where  X  ,  X  1 and  X  2 are all set as 0 . 1 2 ; and (ii) TDAP of Sec. 3, where the settings for  X  ,  X  1 ,  X  2 are taken from FTRLProx Spark . The parameter  X  is carefully chosen for dif-ferent datasets (to been seen shortly); and (b) Algorithms on
We have varied  X  ,  X  1 and  X  2 from 0 . 0001 to 1 on all the above datasets, and 0 . 1 brings the best accuracy on average.
Dataset # of fea-Books 332,439 2,264 2,201 DVD 282,899 1,807 1,779 Electronics 235,796 2,857 2,824 Kitchen 205,664 2,954 2,991 RCV1 47,236 355,460 321,939 News 1,355,192 9,999 9,997 URLs 3,231,961 786,182 1,593,948 IPTV 1,321,393 32,869,901 39,480,578 Petuum 1 . 1 under SSP model 3 (i) FTRLProx Petuum ; and (ii) TDAP Petuum , the stale is set to 2 (as recommended in [33]), other parameter settings are the same to those on Spark (BSP).
 Evaluation framework . We conducted the evaluation of the algorithms using three different frameworks in terms of different datasets, where the accuracy metrics used include AUC (Area Under the ROC Curve) and AER [23] (Accu-mulative Error Rate). Details are as below.
 Framework for public non-time series datasets . The frame-work is designed for public non-time series datasets, where the size of mini-batch is set as one, i.e., once coming one example, the framework conducts prediction and trains the model. The metric, AUC, is calculated after all examples have been traversed.
 Framework for URLs dataset . We follow the evaluation framework for URLs as [23], where each mini-batch consists of one example, similar to the above framework. However, the AUC for both FTRL-Proximal algorithm and TDAP are very close, which approach to 0 . 999 (0 . 999214 for TDAP and 0 . 999057 for FTRL-Proximal), we thereby use AER instead. The AER is then aggregated and reported in terms of days. Framework for IPTV dataset . This framework, on the other hand, performs prediction and updates the model on IPTV over each mini-batch formed by time slot with 15 minutes, which follows our business requirements. And still, the AUC is then aggregated and compared in terms of days.
 Distributed settings . To evaluate the accuracy of the al-gorithms, we deployed all algorithms on a mini cluster with p = 3 machines, each of which has 24 cores, 96GB mem-ory and 18TB disk. To further study the scalability, we deployed a cluster with p = 10 machines, where each is with 8 cores, 64GB memory and 500GB disk. Each experiment is repeated 10 times and the average is reported. Parameter Choosing for TDAP . We first study the ac-curacy of TDAP by varying the parameter  X  , in order to choose good  X  for each dataset. We fix the parameters  X  ,  X  1 and  X  2 as mentioned above, for fair comparison.
 Figure 6 shows the AUC on Kitchen dataset using TDAP Spark . The x -axis is  X  and y -axis represents the AUC. In particular, by varying  X  from 0 . 1 to 0 . 000001, the AUC of TDAP becomes stable (approaching 94%) once  X  &gt; 0 . 0005, and similar for TDAP Petuum . Hence, we determine  X  = 0 . 0005
We use Petuum for the implementation of SSP as it is not known how to realize it under Spark. for Kitchen. Note that we conducted the same sets of exper-iments to determine the value of  X  for other datasets (not shown), which are used in later evaluations.
 Figure 6: The AUC of TDAP by varying parameter  X  on Accuracy Comparison Between FTRL-Proximal and TDAP . After determining  X  of TDAP for each dataset, we are ready to compare its accuracy to FTRL-Proximal. As the comparison between FTRLProx Petuum and TDAP Petuum shows similar results, for space constraints, we only report the results on FTRLProx Spark and TDAP Spark .
 Accuracy on public non-time series datasets . Table 2 re-ports the AUC comparison between FTRLProx Spark and TDAP Spark on public non-time series datasets. We note that TDAP Spark performs nearly the same as FTRLProx Spark Books, Dvd, Electronics, Kitchen and RCV1. However, for News, TDAP Spark improves the accuracy by at most 12%. The hypothesis held by FTRL-Proximal is that the effects of all historical models are equivalent. Although this might be suitable for most non-time series datasets, we still be-lieve that, according to  X  X o free lunch X  theorem, treating historical models differently can lead to better performance in some datasets, e.g., News in our experiments.
 Table 2: The AUC of TDAP Spark and FTRLProx Spark on all public non-time series datasets. The best value for each dataset is in bold.
 Accuracy on URLs dataset . Figure 7 shows the AER, i.e., the percentage of misclassified examples for all URLs en-countered up to date, for TDAP Spark and FTRLProx Spark on URLs. The x -axis is the number of days and y -axis is the AER. From the figure, we find out that the AER of TDAP Spark approaches 1 . 4%, which outperforms FTRLProx Spark (AER with 1 . 6%) by 12 . 5% on average. It is worth remarking that the AUC for both algorithms are very close, both approach 0 . 999, and the value of TDAP Spark increases 0 . 016% compared to that of FTRLProx Spark . Hence, we only report the AER in this part.
 Accuracy on IPTV dataset . Figure 8 shows the AUC on IPTV time series dataset. Not surprisingly, the results show that TDAP Spark outperforms FTRLProx Spark by around 5 . 6% on average. Such indicates that our strategy to deempha-size the effects of historical models in model training can definitely improve the accuracy, when the data are changing fast as motivated in Figure 1.
 In our running production service, when we switched from FTRL-Proximal to TDAP , TDAP significantly increased the degree of user activity, i.e., there were approximately 5% more users engaged and each user took 10% more time than ever, due to the accuracy improvement compared to the for-mer one. Such accordingly brought more revenue than the existing one (using FTRL-Proximal) for our customers. Scalability of TDAP . As TDAP shows good accuracy, we next verify its scalability. We conducted the experiments on IPTV dataset by varying p  X  [2 , 10] using TDAP Spark and TDAP Petuum , the results are shown in Figure 9.

As expected, TDAP Petuum shows an excellent scalability, which achieves 4x speedup when p increases from 2 to 10. However, TDAP Spark can only achieve 3x speedup, no matter how we increase the machines, i.e., TDAP Petuum enjoys better scalability with more machines than TDAP Spark . The ma-jor reasons are two folds: (a) SSP avoids the  X  X locking X  of stragglers in each BSP round, by setting the staleness (as revealed in [13]); (b) Petuum uses fine-grained caching s-trategies and distributed shared memory to further reduce the costs of network communication [33], whereas Spark X  X  RDD system performs caching at a coarser granularity [27] and thus requires more communication.
 Efficiency Comparison between TDAP Spark and TDAP Petuum . We next focus on the efficiency comparison between TDAP Spark and TDAP Petuum . Figure 10 shows the training time of both algorithms under the same setting (us-ing p = 3 machines). We highlight that the training time of TDAP Petuum is at least 1 / 20 of that of TDAP Spark , which is also exhibited in [33] due to the same reasons explained above.

Still in our production service, we observed that Petu-um can process approximately one order of magnitude more users than Spark, with the same cluster setup, i.e., the throughput of Petuum was at least 10 times larger than that of Spark. Hence, TDAP on Spark was possible, but the deployment was easier and more efficient using Petuum. Summary . We find the followings: (a) TDAP gives better accuracy than FTRL-Proximal: TDAP improves 5 . 6% pre-diction accuracy on average over our datasets; (b) TDAP has good scalability: TDAP Petuum (resp. TDAP Spark ) is 4 (re-sp. 3) times faster when p increases from 2 to 10; and (c) TDAP Petuum outperforms TDAP Spark in terms of efficiency: TDAP Petuum runs at least 20 times faster than TDAP Spark Conclusions . In this paper, we have defined time-decaying online convex optimization TOCO problem, where the tar-get model approaches to the most recent models while older history of the models are deemphasized, to tackle the fast-changing data. We have proposed a time-decaying adap-tive prediction TDAP algorithm to solve TOCO problem, where recursive closed forms of the model update functions have been designed. To scale big data, we have parallelized the TDAP algorithm under both BSP and SSP consistency model. Using real-world datasets, we have experimentally verified that TDAP achieves good accuracy, scalability and efficiency, on both models. We further observe that TDAP on Spark is possible, but it is easier and more efficient for deployment on Petuum in practice.
 Discussion . We note that the proof of regret bounds for TDAP , as well as TDAP BSP and TDAP SSP , are not the focus of this paper. We refer these to the future work.
