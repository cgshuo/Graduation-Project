 Statistical topic models provide a general data-driven fra mework for automated discovery of high-level knowledge from large col-lections of text documents. While topic models can potentia lly dis-cover a broad range of themes in a data set, the interpretabil ity of the learned topics is not always ideal. Human-defined concep ts, on the other hand, tend to be semantically richer due to caref ul selection of words to define concepts but they tend not to cove r the themes in a data set exhaustively. In this paper, we propo se a probabilistic framework to combine a hierarchy of human-de fined semantic concepts with statistical topic models to seek the best of both worlds. Experimental results using two different sour ces of concept hierarchies and two collections of text documents i ndicate that this combination leads to systematic improvements in t he qual-ity of the associated language models as well as enabling new tech-niques for inferring and visualizing the semantics of a docu ment. Categories and Subject Descriptors: H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing X  indexing methods, thesauri ; I.2.6 [Artificial Intelligence]: Learning; I.2.7 [Artific ial Intelligence]: Natural Language Processing General Terms: Algorithms, Experimentation, Human Factors. Keywords: statistical topic models, unsupervised learning, ontolo-gies, semantic concepts.
Latent Dirichlet analysis [2], also referred to as statisti cal topic modeling [7], is a general framework for automatically summ ariz-ing the thematic content of a set of documents. The basic conc ept underlying statistical topic modeling is that each documen t is com-posed of a probability distribution over topics, where each topic is represented as a multinomial probability distribution ove r words. The document-topic and topic-word distributions are learn ed au-tomatically from the data in an unsupervised manner. The und er-lying statistical framework of topic modeling enables a var iety of extensions to be developed in a systematic manner (e.g. [10, 1, 9]). An entirely different approach to representing thematic kn owledge is to manually define semantic concepts using human knowledg e and judgement  X  this is typically the case with the construct ion of ontologies and thesauri where a small set of important words are associated with each concept based on prior knowledge. Conc ept names and sets of relations among concepts (for ontologies) are also often provided.
 Concepts (as defined by humans) and topics (as learned from data) represent similar information but in different ways. Human-defined concepts are likely to be more interpretable than top ics and can be broader in coverage. Topics on the other hand have the advantage of being tuned to the themes in the particular corp us they are trained on. In addition, the probabilistic model th at un-derlies the topic model allows one to automatically tag each word in a document with the topic most likely to have generated it. In terms of related work, the models proposed in [8, 3] use topic s with prior knowledge for classification and word-sense disambig uation respectively. Chemudugunta et. al. [4] proposed the concep t-topic model for combining data-driven topics and semantic concep ts to automatically annotate documents. In this paper, we extend the framework in [4] to the hierarchical concept-topic model to take advantage of known hierarchical structure among concepts.
Concepts are often arranged in a tree-structured hierarchy . Here, we describe the hierarchical concept-topic model (HCTM), t hat ex-tends the concept-topic model (CTM) in [4] to incorporate th e hier-archical structure of the concept set. Similar to the CTM, th ere are T topics and C concepts in HCTM. For each document d , we in-troduce a  X  X witch" distribution p ( x | d ) which determines if a word should be generated via the topic route or the concept route. Ev-ery word token in the corpus is associated with a binary switc h variable x . If x = 0, the standard topic model (TM) mechanism is used to generate the word. That is, we first select a topic a document-specific mixture of topics p ( t | d ) and generate a word from the word distribution associated with topic t . If generate the word from one of the C concepts in the concept tree. To do that, we associate with each concept node c in the concept tree a document-specific multinomial distribution with dim ension-ality equal to N c + 1, where N c is the number of children of the concept node c . This distribution allows us to traverse the concept tree and exit at any of the C nodes in the tree  X  given that we are at a concept node c , there are N c child concepts to choose from and an additional option to choose an  X  X xit" child to exit the con cept tree. We start our walk through the concept tree at the root no de and select a child node from one of its children. We repeat thi s pro-cess until we reach an exit node and the word is generated from the parent of the exit node. Note that for a concept tree with there are exactly C distinct ways to select a path and exit the tree  X  one for each concept.

HCTM represents a document as a weighted combination of mix-tures of T topics and C paths through the concept tree: flexible and can handle any directed-acyclic concept graph. The word generation mechanism via the concept route in HCTM is re -lated to the Hierarchical Pachinko Allocation model 2 as des cribed in [9]. There is additional machinery in our model to incorpo rate T data-driven topics (in addition to the hierarchy of concept s) and a switching mechanism to choose the word generation process via the concept route or the topic route. Additional details abo ut the generative process and inference techniques are given in [6 ].
We use documents from the science and social studies genres of the Touchstone Applied Science Associates (TASA) corpus and concept sets from Cambridge Advanced Learners Dictionary ( CALD) and Open Directory Project (ODP) with approximately 2,000 a nd 10,000 concepts respectively in our experiments. We assess the predictive performance of TM, CTM and HCTM by comparing their perplexity on unseen words in test documents using con cepts from CALD and ODP. Perplexity is a quantitative measure to co m-pare language models and is widely used to compare the predic tive performance of topic models (e.g. [2, 7, 5]). In the experime nts below, we randomly split documents from the science and soci al studies genres of the TASA corpus into disjoint train and tes t sets with 90% of the documents included in the train set and the rem ain-ing 10% in the test set. For each test document, we use a random 50% of words of the document to estimate document specific dis -tributions and measure perplexity on the remaining 50% of wo rds using the estimated distributions.

For the models using concepts, we indicate the concept set us ed by appending the name of the concept set to the model name, e.g . HCTM-CALD to indicate that HCTM was trained using concepts from the CALD concept set. Figure 1 shows the perplexity of TM , CTM and HCTM using training documents from the science genre in TASA and testing on documents from the science (left) and s o-cial studies (right) genres in TASA respectively as a functi on of number of data-driven topics T . The point T = 0 indicates that there are no topics used in the model. The results clearly indicate that in-corporating concepts and modeling the concept-hierarchy g reatly improves the perplexity of the models. The performance diff er-ence is even more significant when the models are trained on on e genre of documents and tested on documents from a different g enre (e.g. see the right plot of Figure 1), indicating that the mod els using concepts are robust and can handle noise. TM, on the other han d, is completely data-driven and does not use any human knowled ge, so it is not as robust. One important point to note is that this im-proved performance by the concept models is not due to the hig h number of effective topics ( T + C ). In fact, even with topics TM does not improve its perplexity and even shows sign s of deterioration in quality in some cases. The correspondin g plots for models using training documents from social studies gen re in TASA and testing on documents from the social studies (left) and science (right) genres in TASA respectively are shown in Fig ure 2 with similar qualitative results as in Figure 1. Figures 1 an d 2 also allow us to compare the advantages of modeling the hierarchy of the concept sets. In both these figures when T = 0 , the perfor-mance of HCTM is always better than the performance of CTM for all cases and for both concept sets. This effect can be attrib uted to modeling the correlations of the child concept nodes. Mor e de-tails on the models, the experimental results and the data se ts are provided in [6].
We have proposed a probabilistic framework for combining da ta-driven topics and a hierarchy of semantically-rich human-d efined concepts. Experimental results, using two document collec tions and two concept sets, indicate that using the semantic conce pts and modeling the hierarchy of the concept-sets significantly im proves the quality of the resulting language models. This improvem ent is more pronounced when the training documents and test docume nts belong to different genres. We view the current set of models as a starting point for exploring more expressive generative m odels that can potentially have wide-ranging applications, part icularly in areas of document modeling and tagging, ontology modeling a nd refining, information retrieval, and so forth.
 The work of the authors was supported in part by NSF Award Num-ber IIS-0083489 as part of the KDD program. In addition the wo rk of author PS was supported in part by a Google Research Award.
