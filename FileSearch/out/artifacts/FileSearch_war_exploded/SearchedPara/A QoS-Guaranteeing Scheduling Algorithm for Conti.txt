 environmental monitoring in chemical reactions and so on. Most of these applications unbounded, high-volume and time-varying data streams. The uncertainty of best-effort services probably return outdated an swers or task failures, which may leads to low performance or even catastrophic results, and therefore is not adequate for many constraint, those responses exceeding delay cons traint would probably lead to the fire happening without alarm. However, most stream processing techniques provide best-QoS, such as average response delay, overall throughput, etc . Therefore, deterministic stream-based applications. 
QoS for data stream processing can be defined in a variety of ways and includes a security, etc. All these service requirements are important aspects of a comprehensive performance-centric view of data stream processing and focus primarily on the issues in providing time-related and space-related performance guarantee. In this paper, we processing based on the theory of Network Calculus [4,5] . Network Calculus provides a delays and backlog in a network. It has played an important role in the development contributions we made in this paper are as follows:  X  A QoS model for stream processing is proposed, including QoS-aware task  X  A task scheduling strategy, named QED, is provided to guarantee the QoS  X  Extensions of batch scheduling and window task preempting are suggested to QoS model for the stream processing. Our QoS-guaranteeing scheduling algorithm is discussed in Section 3. Then the algorithm is deployment over our proposed architecture in Section 4. Thereafter, experimental results are presented in Section 5. Related work is described in Section 6 before ending with conclusions in Section 7. numbered 0,1,2... 2.1 QoS-Aware Stream Processing Model Take a stream processing system as a blackbox with several continuous queries registered inside, as illustrated in Fig.1. The blackbox deals with the incoming data and thus, produces permanent results for each query on the fly. For a continuous query, cumulative functions are used to describe the amount of data that the query has received and processed. Terminologically, let:  X  interval [0, t ]. By convention, we take R (0)=0;  X 
R * ( t ) denotes the number of tuples that have been served (processed) by the query during [0, t ]. 
Note that R * ( t ) is measured in the number of tuples processed by the query rather engine acts as a service provider, and the re gistered queries are service consumers. In requirements. Here, the terms of arrival curve and service curve in Network Calculus respectively. Arrival curve defines a constraint on input burstiness as follows. Definition 1 (Arrival Curve). Given a wide-sense increasing function  X  , we say that is called an arrival curve for the stream, and the stream is also called  X  -smooth. curve  X  if and only if  X  is wide sense increasing,  X  (0)=0 and  X   X   X  R R * 1 . bounds the amount of data that has been processed by a DSMS within some specific service curve for the query is defined as 0, 0 curve of a continuous query are given, the input queue size and the response delay are bounded. Therefore, any QoS requirements re lated to time and space is deterministic. 2.2 QoS-Aware Tasks In a DSMS, data continuously arrive in the input queue to be processed by the corresponding queries. According to how the queries are processed, two scenar ios are considered to catalog the scheduling tasks for data stream processing:  X  SPJ query: SPJ is a fairly common class of queries in Definition 3 (Basic Task). The processing of a tuple by a query is defined as a basic task. Definition 4 (Window Task). The processing of a window by a continuous query is called a window task. each query has exactly one related stream. In the real DSMS, data sharing techniques could be applied to a stream participating multiple queries, and each query is related to a logic stream. And for those queries with multi-input, input streams are combined each other. By the way, some of the notations used in the paper are listed in Table 1. In this section, we first talk about the main idea of our QoS-Guaranteeing scheduling. Then the key techniques used in the scheduling strategy are developed one by one. 3.1 QED Overview the overall QoS expected. Since all the QoS requirements are abstracted in the form of efficient strategy to guarantee the respective service curve for each continuous query. Motivated by the service curve allocation method in Network Calculus, named task, and tasks are scheduled in EDF (Earliest Deadline First) strategy. Therefore, the scheduling algorithm is named as QED (QoS Earliest Deadline). If the deadlines are requirements and the system capability. 
Considering the respective properties of basic task and window task, optimizations picks up tasks in its task queue as much as possible into running, on the premise that running is costly, new arrived tasks with more urgent deadline have to wait a relative longer time. In order to guarantee QoS, each query is allocated a larger service curve, which would lead to much resource reserva tion. Therefore, a preemptive adaptation is suggested for window task scheduling, with QoS satisfaction not violated. 3.2 Deadline Allocation In network calculus, SCED policy defines output deadline to each packet according to l is because packets are transmitted non-preemptively in EDF strategy. data of flow i is defined by: where measured in a uniform comparable measurement rather than the number of tuples that have been served by each query. Therefore, the computation resource is standardized as follows. Assume that the query engine has the ability to perform C basic operations the costs can be known in advance by permanently monitoring the stream processing i = 1,...,N . Theorem 1 tells how the deadlines are allocated to tasks in a DSMS. allocated to query Q i as: where  X  max =max{  X  i }. d
Thus, 
Due to the expression of  X  i * , we have: 
According to the definition of service curve,  X  i is guaranteed to query Q i . guaranteed, then () n t R n so that () D known to be optimal for any independent process scheduling algorithms upon required service curves. In other words, if the EDF strategy with deadline allocated by the SCED in network calculus is introduced in our QoS-guaranteeing scheduling. 3.3 Schedulability Verification deadlines, the desired service curve is guaranteed to each query. Theorem 2 (Schedulability Condition in DSMS). In a DSMS, query Q i requires  X  i query Q i , i = 1 ,..., N, if Equation (3) is satisfied: Proof: Only if the overall required computation capability is always not greater than the capability that the DSMS could provide, the service curves could be guaranteed to each query. According to Theorem 1, in order to guarantee service curve  X  i to query Q following equation is satisfied: 
Thus, we get the schedulability condition for a DSMS as given in Equation (3). 3.4 Batch Size Decision To introduce batch scheduling for QoS-guaranteeing stream processing, the following aspects should be taken into consideration: 1. The introduce of batch should not disturb the property of QoS guaranteeing; 2. The involved computation cost due to batch scheduling could not be too heavy to affect the QoS guaranteeing; 3. The batch size should be as large as possible. 
To obey the above rules, the main idea of our batch size decision is as follows. On according to the improved service cu rve and the backlog at that time. improved to the extreme condition in which the system is just schedulable. Therefore, the improved service curve could be obtained from Equation (4): T as the guaranteed service curve for query Q i . T to the tasks that should be output before scheduling T k l . offline part and online part. Offline Part. As for the decision of batch size suggested above, it is not necessary to get the expression of the improved service curve for each query. In Equation (5), only  X   X   X  not a trivial work, it could be performed offline before system running. Therefore, the computation incurred by batch scheduling does not aggravate the runtime cost. modified. Therefore, the computation complexity of online part is quite trivial. 3.5 Preemptive Adaptation for Window Tasks The scheduling algorithm proposed above works in a non-preemptive fashion. During lower real time property of task processing. On the other hand, aiming at guaranteeing would lead to much resource reservation in the system. So, we try to break down the window tasks and suggest a preemptive scheduling extension as follows. 
When a window task is being scheduled, if a new task with higher priority arrives, the window task is interrupted, and the new arrived task is scheduled. The intermediate of t he window task are preserved, replaced into the task queue as a new window task with the same deadline as befor e. Since the task X  X  deadline is not changed, the window sub-tasks with the same deadline.
 schedulable in a preemptive fashion. Schedulability Verifier , Task Receiver , Task Trigger and Batch Organizer . admitted to the system, with their QoS requirements satisfied. Once the schedulability condition is obeyed, The QED Scheduler begins to trigger tasks into processing. 
In order to work in EDF fashion, Priority Order List maintains the priority of each tasks is preempted, the intermediate results are kept in State Manager . The scheduling procedures of each component in QED scheduler are listed in following Table 2. 
Offline: 5.1 Experimental Test Bed The experiments are based on the following Example 1. For ease of experimentation, cost is randomly generated obeying normal distributions. To illustrate the significance of extensions of batch and preempting, the two extensions are added to the algorithm QED, and the version with both extensions are named P-QED. Moreover, we make comparisons. The software environment for the following experiments is Windows XP using Java, and the hardware environment is PC with 1.73GHz PentiumM processor and 512M of memory. The machine is isolated from other tasks except the three continuous queries. follows: 
The schedulability verification is discussed for B-QED and P-QED as follow.  X  B-QED: Q E D i s u n s c h e d u l a b l e i n t h i s e x a m p l e . B u t f r o m l o n g p o i n t o f v i e w , 3 * t h a t i s , t h e s y s t e m resource is much sufficient than that needed. It is not strange since the unschedulablity is caused by non-preemption.  X  P-QED: three Query X  X  QoS can be satisfied. 5.2 Experimental Results  X  Schedulable Situation schedulable in this process. As it is illustrated in Fig.3, P-QED can totally guarantees least, so it is always scheduled with high priorities.  X  Unschedulable Situation Fig.4. We increase the peak rate of Q 2 . The system can be verified schedulable if the less than 0.55, the P-QED algorithm can still provide QoS guaranteeing service. This Q situation, our algorithm is quite fair but not excellent for QoS guaranteeing. Scheduling problem over data streams has motivated a considerable research recently memory requirement. The Aurora project employs a two-level scheduling approach : the first level handles the scheduling of superboxes that are a set of operators, and preemptive rate-based scheduling policy that handles the asynchronous nature of tuple above scheduling strategies try their best to gain better processing efficiency, and the deterministic behavior regarding the processing times relies on the real-time operating processing. This paper has investigated scheduling algorithms for stream data processing in order proposed based on the theory of network calculus, and an algo rithm accordin g to EDF strategy is proposed to guarantee QoS requirements. Then we optimize the algorithm processing efficiency. At last we obtain a preemptive QoS-guaranteeing batch our algorithms to address operator-level scheduling problem. In addition, some probability model could be imported in order to reduce system resource reservation. usually called continuous query and the trigger fashion is called tuple-driven. Besides, the fashion that results are output over a period is called time-driven. Presently, some representative DSMSs [1][2][3][4] have been designed and realized in this manner. 
However, with expanding of application requirements over data stream, some accident on a segment, we want to detect the speed change of those cars on the same model and classification methods to solve event-relative problems over data streams. Section 3 presents event semantics and an event-driven model EQM over data stream. query processing problems. Section 5 shows our model and algorithm are efficient by examples and experimental analysis. The last section concludes the paper. At present, most of the existing data stream models are extensions of relation algebra included [1][2] . In these models, query trigger manner mainly includes tuple-driven and model. Also, the query processing is similar to that in traditional database in which a query plan is a net of operators connected by queues and correct results are output by communication and synchronization methods. There are also some particular methods in the processing of increment maintenance, such as direct maintenance methods and negative tuple method [5][6] . STREAM [1] proposed by Standford is a DBMS which can describe models and query processing mentioned above well and especially CQL [7] is a representative powerful query language over data stream, but it can X  X  support query processing over complicated events well. studied event models and semantics in depth. However, ECA mainly focuses on static data set and pays less attention to dynamic and real-time characters over data stream which is irrelative with our devotion about event-driven model. events and time sequence composite events separately, which can help express Model) is proposed. 3.1 Basic Events Defi nition over Data Stream In our model, basic events include Time Event and Content Event . Definition 1: TE ( Time Event ). Suppose that the time domain T of data stream system occurring at t i is denoted as () divide CE into three categories further.  X 
Arrival Event(CE arr ). If d ij .t= t now , a CE arr occurs.  X  occurs. m denotes a threshold or tuple value over other data streams. For example, when temperature exceeds 50 degree, a CE trans occurs.  X  example, when temperature increases by 30 degree, a RE occurs. This situation is quite hard to describe by using relational algebra. 
Due to the time feature owned by stream data, TE and CE have relations between and necessary event information. A TE ( t ) can be considered as an tuple-arrival event whose attributes are set null except the timestamp attribute. 3.2 Semantic Composite Events In order to express semantics better, in our model, stream events are further classified over data stream and semantic granularity.  X  occurs.  X 
Beginning Event denoted as B , and IE ( t 2 ) is an Ending Event denoted as E .  X 
PE ( Periodic Event ). A group of IEs that occur periodically and express the same paper, we only consider it. 3.3 Time Sequence Composite Events make composites further according to time sequence relation between events in order to express more complicated semantics. @ denotes time sequence-composite operation.  X   X  sequence-composite event LE ( IE ( t 1 ) ,IE ( t 2 )) @IE ( t 3 ).  X 
LE@LE . It expresses that one lasting event occurs during another lasting event. If  X  3.4 Event-Driven Models over Data Stream stream separately. Furthermore, driven models over event-driven stream are classified in EQM as follows.  X  AEC (Arrival Event Continuous) Model and TEC (Time Event Continuous) Model. various application requirements in a more general manner. In a time-driven window query, Hop can be used to express the frequency of window sliding.  X  queries related with the values at the current time point or during the current time room temperature or the average temperature over previous 5 seconds is queried.  X  determined by a LE , a one-time query is run. For example, during the interval that somebody enters and leaves a room, the average room temperature is queried.  X  determined by a LE , a continuous query is run. Also Sliding Window and Hop can be added to this kind of query. For example, during the interval that a soldier stops moving and don X  X  begin to move again, for every 10 seconds, heartbeat times over the recent 30 seconds are queried. 
Based on EQM , we also propose a query language named as EQL with the function concrete EQL definition and illustration will not be given further in this paper. proposed. We adopt event interruption manner to trigger evaluation over query stream rather than join operation, which will improve average processing time. Due to space application. IES and LEC query problems can be analyzed in a similar way. For LES , data sharing is very common and a ke y problem to be considered. All the sharing relation  X  R , if () shared and incremental manner in each SLER . Fig.1 illustrates the data structure and aggregation value up to now. fashion. Based on the feature, improved method SLES * Algorithm is given in Table 2. some merged interval values. 
No available algorithm over data stream can solve the applications based on common LES . But in CQL , DWM ( delayed window method ) can be used to solve only TLES , which depends on Istream Operation to delay the occurrence of each B i and use window , LEL and MIL . We begin with a description of application example and our simulation framework in section 5.1. Experiments results and analysis are presented in section 5.2. 5.1 Experiment Setup the queries based on events as our example. The query is described as follows: when intensity over this period. Table 3 shows the descriptions for the application in EQL . Corresponding CQL based on DWM can be directly found in Query Repository [11] . 
Compared to CQL , EQL is simple and pellucid. Further more, we will compare the environment is that PentiumIV2.4GHz, 512MDDRAM and Windows XP and exponential distribution. Equation(4) to simulate () P  X  . Original experiments Parameters are listed in Table 4. 5.2 Experiment Results and memory cost by adjusting original experimental parameters. (a) () P  X  effects on memory cost (b) D effects on memory cost
Experiment 1-2 test the response delay of the three approaches by adjusting D and 
P  X  . From the corresponding experiment results shown in Fig. 2, we can find SLES respond nearly without any delay. 
P  X  . From the corresponding experiment results shown in Fig. 3, we can find SLES and SLES * have obvious advantage in memory cost beyond DWM and SLES * is even better. 
As experiments show, because SLES and SLES * make improvements in trigger for other LES queries. Finally, a DSMS to support complicated event application is in the plan. 
