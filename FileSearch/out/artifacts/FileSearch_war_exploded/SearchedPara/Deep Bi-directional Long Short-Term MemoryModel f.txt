 Intelligent transportation system (ITS) is an important part of smart city. Short-term traffic flow prediction is a core technology in ITS. The aim of short-term traffic flow prediction is to predict the number of vehicles within a given time interval on the basis of the historical traffic information. The time intervals are usually in the range of 5 to 30 minutes. The study of short-term traffic flow prediction has an important significance in real-time route guidance and reliable traffic control strategies [1]. Great efforts have been made to cope with the short-term traffic flow prediction problem in the past decades.
 approaches. In [2], [3], [4], time series methods, such as the autoregressive inte-grated moving average (ARIMA), were employed to forecast short-term traffic flow. Sun et al. [5] proposed a Bayesian network approach to predict short-term traffic flow. Yu et al. [6] used Markov chain model for short-term traffic flow pre-diction. Due to the stochasticity and nonlinearity of the traffic flow, parametric approaches cannot describe traffic flow precisely.
 term traffic flow prediction, for nonparametric approaches can capture the com-plicated nonlinearity of the traffic flow and take the uncertainty into considera-tion. Castro Neto et al. [7] employed support vector regression (SVR) to predict short-term traffic flow under typical and atypical traffic conditions. In [8], a local-ly weighted learning (LWL) method was proposed. Neural network (NN) models were reported in [9]. Owing to the ability of dealing with high-dimensional data, flexible model structure, strong generalization and learning ability of deep learn-ing methods, many deep learning models and structures were applied for traffic flow prediction. Huang et al. [1] incorporated multitask learning (MTL) into deep belief networks (DBN) for traffic flow prediction. Lv et al. [10] proposed a stacked auto-encoder (SAE) model. Tian et al. [11] used long short-term memory (LSTM) recurrent neural network to forecast short-term traffic flow prediction, which could automatically determine the optimal time lags. The limitations of the current deep learning models are the shallow structure unable to mine deep features and the weak sensitivity to time-aware traffic flow data.
 flow prediction in this paper. For unsupervised feature learning, we propose a deep bi-directional long short-term memory (DBL) by introducing long short-term memory (LSTM) recurrent neural network, residual connections, deeply hierarchical networks and bi-directional traffic flow. A regression layer is used above the DBL for supervised prediction. Additionally, we adopt dropout train-ing method to avoid overfitting problem. In other words, our model is able to mine the deep features of traffic flow and take full advantage of time-aware traffic flow data.
 lem of traffic flow prediction and introduces long short-term memory (LSTM) recurrent neural network model. In Section 3, we present the traffic flow predic-tion architecture. Section 4 shows the experimental settings and the experimen-tal results. In Section 5, we discuss the key components of our model. Finally, Section 6 is the conclusion. 2.1 Short-term Traffic Flow Prediction Traffic flow prediction is a typical temporal and spatial process. The traffic flow prediction problem can be stated as follows. The traffic flow of the i th observation point (road, segment or station) at the t th time interval is denoted as f i,t . At time t 0 , the prediction task is to forecast the traffic flow f i,t 0 +1 at time t 0 + 1, the past. O is the full set of observation points. The prediction time interval is the interval between time t and t + 1, which is denoted as  X  X  . According to the length of the prediction time interval, the traffic flow prediction can be divided into three types: long-term, mid-term and short-term traffic flow prediction. Short-term traffic flow prediction has a significant meaning in real-time route guidance and reliable traffic control strategies. 15-min is recommended as short-term prediction interval by the Highway Capacity Manual [13]. 2.2 Long Short-Term Memory Network Long Short-Term Memory (LSTM) [13] is an effective approach to predict short-term traffic flow, which takes advantage of the three multiplicative units in the memory block to determine the optimal time lags dynamically. The structure of LSTM prediction model with one memory block is shown in Fig. 1. The nota-tions are illustrated in Table 1. The LSTM prediction structure is composed of one input layer, one recurrent hidden layer whose basic unit is memory block, and one output layer. Memory blocks are a set of recurrently connected subnets. The memory block consists of one or more self-connected memory cells and three multiplicative units: the input gate, output gate and forget gate. The multiplica-tive gates allow LSTM memory cells to keep the information for long periods of time. The following equations mathematically abstract the process [11]. To capture the deep features of traffic flow and take full advantage of time-aware traffic flow data, we propose a deep bi-directional long short-term memory (D-BL) model in this paper. Additionally, we introduce the DBL model, regression layer and dropout training method into a traffic flow prediction architecture. In Section 3.1, we will show the details of the DBL model. And the traffic flow prediction architecture will be explained in Section 3.2.
Fig. 2: The structure of deep bi-directional long short-term memory model 3.1 Deep Bi-directional Long Short-Term Memory Model The structure of deep bi-directional long short-term memory model is shown in Fig. 2. The input n-length historical traffic flow sequence is denoted as x 0 = time interval. x i ( i = 1 , 2 ,...,m ) is the output of the i th layer. BiLSTM is the bi-directional long short-term memory network, where sequence from the start to the end and biLSTM has been successfully applied in natural language processing and image processing [14], [15]. By using biLSTM, the traffic flow information of both directions can be taken into consideration.
 results in the gradient vanishing problem. To achieve the idea of modeling d-ifferences between an intermediate layers output and the targets, we introduce residual connections among the DBL layers in a stack (the red line shown in Fig. 2). Residual connections performed well in the past [16], [17]. With residual connections in the DBL model, the equations are as follows. t th time interval for the i th layer, respectively; x i t is the input at the t th time interval for the i th layer;  X  i is the set of parameters of biLSTM i for the i th layer. 3.2 The Traffic Flow Prediction Architecture the embedding layer, the DBL, the mean pooling layer and the logistic regression and each x ( i )( i = 0 , 1 ,...,n  X  1) is a piece of traffic flow data at a time interval encoded by one-hot representation. The traffic flow data is mapped into a space of same dimension, which is a 64-dimensional vector space. After the DBL encodes the time-aware traffic flow information, a sequence { h (0) ,h (1) ,...,h ( n  X  1) } is produced. Then, the mean pooling layer extracts mean values of the sequence over time intervals. Besides, the mean pooling layer makes the features encoded into a vector h . The vector h is fed into the logistic regression layer at the top of the prediction architecture.
 of the model, we adopt the dropout method [19], [20] in the embedding layer. The key idea of the dropout method is to randomly drop units (along with their connections) from the neural network during training, which can prevent units from co-adapting too much. During training, dropout samples from numerous different thinned networks. When testing, it becomes easy to approximate the effect of averaging the predictions of all these thinned networks and it can be achieved by a single unthinned network with smaller weights. 4.1 Experimental Settings There are mainly two types of traffic flow data in the real world [1]. The first type is the loop detector data, which is collected by sensors on each road, such as inductive loops. The second type is the entrance-exit station data, which is collected at the entrance and exit of a road segment. The prediction task for the first type of data is to forecast the traffic flow on each road or segment, while the prediction task for another type is to forecast the traffic flow in each station, particularly the exit station.
 dataset from Caltrans Performance Measurement System (PeMS) [21]. PeMS is the most widely used dataset in traffic flow prediction. PeMS constantly collects loop detector data in real time for more than 8100 freeway locations throughout the State of California. Thus, the PeMS dataset is a typical dataset of the loop detector data and the prediction task for PeMS is to forecast the traffic flow on each road or segment. We use the data of five months (from July to November) in 2016 as the training set and the later one month (December) as the testing set.
  X  SVM: support vector machine [7];  X  DBN: deep belief network at the bottom and a multitask regression layer  X  SAE: stacked auto-encoder [10];  X  LSTM: long short-term memory recurrent neural network [11];  X  BiLSTM: we remove the deep hierarchy from the proposed architecture;  X  DBL: the proposed prediction architecture. 4.2 Experimental Results To evaluate the effectiveness of the traffic flow prediction models, we use two performance indexes, which are the Mean Absolute Percentage Error (MAPE) and the Root Mean Square Error (RMSE). According to them, we can evaluate the relative error and the absolute error. They are defined as follows. where f is the observation (real) value of traffic flow, and  X  f is the prediction value of traffic flow. 4.2.1 The Prediction Accuracy Comparison Number of vehicles in 15 mins Fig. 4: The comparison between real traffic flow and prediction of traffic flow dict 15-min interval traffic flow of a whole day (December 1, 2016) using the data collected from No.311974 observation road on D03-5 freeway in California. performance of the DBL model is quiet good during most of the day. Besides, there are mainly three fluctuating periods, which are around 7:00, 12:00 and 18:00 respectively. Those fluctuating periods are all peak traffic periods during which the performance of the DBL model is not as stable as other periods. The MAPE of DBL is 4.83% and the RMSE of DBL is 46.01, which manifests that DBL obtains a high prediction accuracy.
 Table 2. As shown in Table 2, both MAPE and RMSE of DBL are lowest among the prediction models. We can notice that bi-directional traffic flow improves the performance of LSTM, while the deep hierarchy enhances the prediction ability of biLSTM. 4.2.2 The Effect of Deep Hierarchy To verify the effectiveness of the deep hierarchy, we use biLSTM and DBL to predict 15-min interval traffic flow of a whole day on different roads. Due to the incompleteness of the data, only 876 observation roads of 1278 observation roads on D03-5 freeway in California have complete data. We randomly choose seven roads from the 876 roads for the evaluation. The MAPE comparison be-tween biLSTM and DBL is shown in Fig. 5, and the RMSE comparison between biLSTM and DBL is displayed in Fig. 6. In our experiment, we notice that for the prediction model to obtain a high accuracy, the prediction network struc-ture should be deep enough to capture deep features from the historical traffic information, which is similar to previous observations that for neural machine translation systems, the deep encoder and decoder RNNs significantly outper-form shallow encoder and decoder RNNs [16]. According to the results, we can find that the MAPE and the RMSE of DBL are both lower than those of biL-STM, which means that the deep hierarchy is an effective part to improve the prediction accuracy.
 4.2.3 The Generalization Capability of DBL cy of short-term traffic flow. Thus, the generalization capability of traffic flow prediction models can be evaluated by predicting traffic flow with different time intervals. The time intervals of short-term traffic flow prediction are usually no more than 30 minutes. We use 15-min, 20-min, 25-min and 30-min time inter-vals to verify the generalization capability of those prediction models and the results are shown in Table 3. As we can see from Table 3, the MAPE and RMSE of DBL are all lowest among the models with different time intervals, which demonstrates that DBL generalizes well. Compared with parametric models, neural network methods can capture the complicated nonlinearity of the traffic flow and take the uncertainty into consid-eration.
 ory ( LSTM ) recurrent neural network can automatically determine the optimal time lags when predicting traffic flow. Besides, the multiplicative gates allow LSTM memory cells to keep the traffic flow information for long periods of time. to extract, but our prediction architecture can mine them with the deeply hi-erarchical neuron networks; bi-directional traffic flow helps mine time-aware traffic information from forward and backward directions; residual connec-tions can improve the gradient flows and help avoid gradient vanishing with a highly deep neuron networks.
 function of the input, which helps to avoid the overfitting problem and make the model generalize well.
 obtain a higher accuracy and the experiments have proved their effectiveness and efficiency. In addition to the traffic flow prediction, our proposed deep prediction architecture has potential applications in other fields such as traffic prediction in wireless networks, the study of shifting meaning of words, the analysis of changes in people X  X  spending habits and etc. In this paper, we propose a deep bi-directional long short-term memory (DBL) advantage of time-aware traffic flow data. Additionally, we introduce the DBL, regression layer and dropout training method into a traffic flow prediction archi-tecture. To verify the performance of the DBL model, the dataset from PeMS is used in the proposed model and other four comparison models (SVM, DBN, SAE, LSTM). In the exprimental results, DBL obtains high accuracy. Besides, both the MAPE and RMSE of DBL are lowest among the comparison models with different prediction intervals, which demonstrates that DBL is effective and generalizes well.
 the size of vehicle, into consideration for a much higher accuracy. And the whole model and its optimization strategy will be evaluated by the third party like KDD Cup 2017.

