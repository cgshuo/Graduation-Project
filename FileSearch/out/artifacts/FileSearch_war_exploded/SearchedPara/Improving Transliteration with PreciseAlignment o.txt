 Automatic transliteration of foreign names, e.g. names of people, places, organi-zations, etc., is recognized as an important issue in many cross language appli-cations. Cross-lingual information retrieval involves query keyword translation from the source to target language and document translation in the opposite di-rection. For similar reasons, machine translation and spoken language processing, such as cross-lingual spoken document retrieval and spoken language translation, also encounters the same problem of translating proper names. Contemporary lexicon-based translation is ineffective as proper name dictionaries can never be comprehensive. New names appear almost daily and become unregistered vocab-ulary in the lexicon. This is known as the Out-Of-Vocabulary (OOV) problem. The lack of translation for OOV names can impact the performance of applica-tions adversely and sometimes seriously.
 appropriately transliterated, into target languages, which were originally hand-coded with rules of thumb by human translators. De facto standard has been established, but is often inconsistently used. The rules are subjected to the inter-pretation of individual producers. In Mandarin Chinese, for instance, the name of  X  X in Laden X  can be translated as /ben la deng/ 1 , /bin la deng/, /ben la dan/ and /bin la dan/. Sometimes dialectical features can further ambiguate the standard. For these reasons, rule-based transliteration approach has been undermined in English-to-Chinese machine translation applications. Thus, an effective data-driven transliteration model is required.
 transliteration of foreign names from English to Chinese. Grapheme-to-phoneme transformation and Pinyin-to-Hanzi conversion applied in the phoneme-based methods are extensively studied areas. We focus on the intermediate tasks for transliterating phoneme pairs. The rest of the paper is organized as follows: Section 2 summarizes related work; Section 3 explains the drawbacks of source-channel model in our task; Section 4 illustrates our methods in detail; Section 5 presents and analyses experimental results; Section 6 concludes this paper. Several approaches have been proposed for automatic name transliteration be-tween various language pairs. Based on the source-channel framework, [7] de-scribed a generative model, in which they adopted finite state transducers and a channel decoder to transform transliterated names in Japanese back to their origins in English. The source-channel model was later on applied or extended by a number of other tasks: backward transliteration from Arabic to English in [12], forward transliteration from English to Korean in [8], and forward transliteration from English to Chinese in [13].
 from the IBM statistical machine translation (SMT) model proposed by [2]: where E = e | E | 1 denotes a | E | -phoneme English word as the observation on channel output, and C = c | C | 1 represents E  X  X  | C | -phoneme Chinese translation by pinyin as the source of channel input. As shown in Fig. 1, the channel de-coder reverses the direction to find the most probable input pinyin sequence  X  C givenanobservation E . The posterior probability p ( C | E ) is indirectly maxi-mized by optimizing the combination of the transliteration model p ( E | C )and the language model p ( C ). p ( E | C ) was trained from name pairs represented by International Phonetic Alphabet (IPA) symbols for English names (obtained from a speech synthesis engine) and pinyin notations for their Chinese counter-parts (obtained from a Hanzi-Pinyin dictionary). It proceeded by Expectation-Maximization ( EM ) iterations of standard IBM SMT model training method by using GIZA++ toolkit, bootstrapping from Model-1 through Model-4 [13]. Language model p ( C ) was trained by using pinyin symbol trigrams and applying Good-Turing smoothing with Katz back-off in CMU-Cambridge language mod-eling toolkits [3]. Search was done by use of USC-ISI ReWrite Decoder [5]. The method demonstrates pinyin error rates in edit distance of around 50% [13]. When the IBM SMT model is applied in our task, i.e. English-to-Chinese translit-eration, it has several limitations: 1. p ( E | C ) is approximated by the Markov chains [11] under Markov assumption 2. Because of the inverted conditional probability p ( E | C ), only a target lan-3. Due to smoothing, the language model may not assign zero probability to Instead of source-channel, we aim to estimate the posterior probability directly. We rectify the angle of observation to avoid the use of the reversed conditional probability. Figure 3 shows the application of the alignment scheme of our ap-proach to the previous example in Fig. 2, where we look possible combinations of pinyin symbols as initial-final clusters converted from single English phonemes. The condition of the probability to be estimated thus turns out to be E instead of C . The distribution can be approximated directly by Maximum Entropy ( Max-Ent ) approach [1]. Under MaxEnt model, the language model can be considered as an optional feature [9]. Its absence could be compensated if other cutting edge features could be chosen. 4.1 Baseline of Direct Model We introduce the pinyin mapping units of each e i denoted by cmu i ,whichcan be individual pinyin symbols or clusters of initial and final. In an alignment, each English phoneme aligns to only one cmu . Thus, the transliteration model p ( C | E ) can be approximated by: The unknown cmu s (clusters) can be discovered on the fly during E M training for computing the Viterbi alignments and symbol-mapping probabilities by using GIZA++, where we can make the source and target consistent with the actual transliteration direction, i.e. from English to Chinese.
 From our perspective, the transliteration is to classify each phoneme of a given English name into its most probable cmu according to the frames of various features. We then yield a better approximation: where h i denotes the history or context of e i , which is described as follows: History of an English phoneme is defined as its left-two and right-two neighboring phonemes plus the two cmu s at pinyin side, to which its left-two phonemes align. conditional transliteration probability to produce the cmu with respect to its contextual history h can be computed by: where  X  is the set of all cmu s mapped from e and observed in the training data, and p ( h ,cmu ) is the joint probability distribution of observing h and cmu simultaneously, which can be trained using maximum likelihood estimation. We use the MaxEnt model to solve the joint probability distribution [10]: where  X  is a normalization constant, {  X ,  X  1 , X  2 ,..., X  k } are the model param-eters and { f 1 ,f 2 ,...,f k } are features which are all binary. Each parameter  X  j corresponds to a feature f j . A feature takes the following form: f 1 ( h i ,cmu i )= or f 2 ( h i ,cmu i )= The general feature templates we used in experiments are listed in Table 1, where X , Y and Z can be any individual English phoneme or Chinese pinyin cmu ,and |V E | and |V C | are the number of elements in the respective sound vocabulary of English and Chinese. 4.2 Improving the Baseline Model Deficiencies of the Baseline Model. There are two critical problems in the baseline model that can be improved: 1. The search space for finding the Viterbi alignment from all possible align-2. Because of compound pinyin finals, two consecutive English phonemes may Precise Alignment of Phoneme Chunks. We introduce alignment indica-tors between a pair of sound sequences of E and C . Within 39 English phonemes (24 consonants, 15 vowels) and 58 pinyin symbols (23 initials and 35 finals), there are always some indicative elements for alignment, i.e. indicators. For E ,they are all the consonants, the vowel at the first position and the second vowel of two contiguous vowels; for C correspondingly, they are all the initials, the fi-nal at the first position and the second final of two contiguous finals. Also, we define the following variables:  X  ( S ) is defined as # of indicators in sequence S in E and C .
 possible positions ahead of its indicators.  X  is practically an indicator defined for alignment. This ensures that both sequences end up with the same number of indicators. The t chunks separated by indicators in E should align to the corresponding t chunks in C in the same order. They are called alignment chunks. There are A = with respect to different positions of  X  .
 Thus, in a pair of aligned chunks, only three mapping layouts between phoneme elements are possible: 3. e 1 e 2 -to-c : By adding an additional  X  at C side, the alignment at phoneme EM Training for Symbol-Mappings. We then applied EM algorithm [4, 7] to find the Viterbi alignment for each training pair as follows: 1. Initialization: For each English-Chinese pair, assign equal weights to all 2. Expectation Step: For each of the 39 English phonemes, count the instances 3. Maximization Step: Re-compute the alignment scores. Each alignment is 4. Repeat step 2-3 until the symbol-mapping probabilities converge, meaning Thus, the EM training becomes more precise and produces significantly fewer possible alignments compared to the baseline. 5.1 Data Set We obtained the beta release v.1.0 of LDC X  X  Chinese-English bi-directional named entity list compiled from Xinhua X  X  database, from which we chose the English-to-Chinese proper name list of people as raw data. The list contains 572,213 foreign people X  X  names and their Chinese transliterations. Note that although the list is in English, it contains names originated from different languages (e.g. Rus-sian, German, Spanish, Arabic, Japanese, Korean, etc.). One assumption is that the Chinese translations were produced based on their English pronunciations directly. The exceptions are Japanese and Korean names, which are generally translated in terms of meaning as opposed to pronunciation, and we consider them as noise. We resorted to CMU X  X  pronunciation dictionary and LDC X  X  Chi-nese character table with pinyin to convert the names into a parallel corpus of sequences of English phonemes and pinyin symbols. We ended up with 46,305 pairs, which were then used as our experimental data pool. 5.2 Performance Measurement There is no standard for measuring machine transliteration. Some tests require human judgment. The performance was evaluated with two levels of accuracy, i.e. character-level accuracy ( C.A. ) and word level accuracy ( W.A. ) in [6]: In (7), L is the length of the standard transliteration of a given foreign name, and i , d ,and s are the number of insertion, deletion and substitution respectively, i.e. edit distance between machine-generated transliteration and the standard. If L&lt; ( i + d + s ), we set C.A. = 0. Equation (8) is the percentage of the number of transliterations identical to the standards in all the tested names. A name often has acceptable transliteration alternatives. Hence, we will also measure how the percentage of the number of transliterations distributes over different character-level accuracy ranges, which is referred to as C.A. Distribution ( C.A.D. ): where [ r 1 ,r 2 ) (denotes r 1  X  C.A.&lt;r 2 ) is the bound of a C.A. range. We set up six C.A. ranges: [0%, 20%), [20%, 40%), [40%, 60%), [60%, 80%), [80%, 100%) and [100%]. We are especially interested in the names within the ranges [0%, 20%) and [80%, 100%) since the former could be considered as  X  X ompletely incorrect X  and the latter  X  X cceptable X . 5.3 Experiments and Results In each trial of our experiments, individual translation name pairs, hereafter referred to as instances, were randomly selected from the data pool to build 10 subsets. Each respectively accounts for 10% to 100% (step=10%) of the total instances in the entire pool. In each subset, we used 90% of the instances for training and the remaining 10% for open test. Also the same number of instances (10%) were randomly selected from the training data for close test.
 Experiments. The baseline model was trained and tested as follows: 1. Using EM iterations in GIZA++ to obtain Viterbi alignment of each pair of 2. Aligned training instances were then passed to GIS (Generalized Iterative 3. Tests were conducted on the trained MaxEnt models.  X  X eam search X  [10] tings except that the tailored alignment scheme and the EM training (see Sect. 4.2) were applied in the step 1.
 was applied to the 10 subsets with different data sizes as described previously. And the performance of the model was measured by the average accuracy ( C.A. and W.A. )of50trialsoftheexperiments. C.A.D. was measured with average distributions of 50 trials on 100% data size only.
 Results and Discussions. Figure4showstheaverage C.A. and W.A. of the baseline model (BL) and the improved model (IM) over different data sizes. IM significantly outperforms BL on all tests. In open tests with 100% data, for example, IM demonstrates improvements on C.A. by 8.56% and on W.A. by 11.84%. Recall that in the IM model, we chopped longer pinyin symbols, e.g. compound finals, into smaller sound units, i.e. basic finals, and aligned chunks of English phonemes with corresponding chunks of pinyin symbols, prohibiting alignments across chunk borders. This could produce: 1. more precise mappings between English phonemes and cmu s; 2. less possible cmu s for each English phoneme, reducing uncertainties; 3. less cum s forming illegal pinyin syllables, leading to more legitimate pinyin sequences. The figure also shows that with enough instances, the models could achieve almost equal performance in open tests to closed ones.
 tributed over their C.A. values (on all data). For C.A. ranging from 0% to 80%, BL produced more transliterations throughout the four ranges than IM. In the remaining C.A. ranges, IM produced more high-quality transliterations (see C.A.  X  80%) and considerably more correct transliterations (see C.A. = 100%) than BL. 5.4 Comparisons with Source-Channel System We compared our work with the source-channel (SC) system described in [13]. Their method (the first translation system) was replicated with the only excep-tion that we obtained phoneme sequences of foreign names via a lookup of CMU X  X  pronunciation dictionary, whereas they adopted the Festival text-to-speech sys-tem for English pronunciations. Then we tested the SC system, our BL system and IM system using the entire data pool with 41,674 instances for training and the remaining 4,631 for testing. The language model of SC system was trained on the 41,674 pinyin sequences in the training portion, similarly using trigram by CMU-Cambridge toolkits as [13]. The results are shown in Table 2. Our BL and IM system outperformed the source-channel approach by about 3% and 10% respectively in all tests using the same data set.
 We modeled English-to-Chinese transliteration as direct phonetic mapping from English phonemes to a set of basic pinyin symbols plus dynamically discovered mapping units from training. Contextual features of each phoneme are taken into consideration in the model. An effective algorithm for precise alignment of phoneme chunks was presented, which demonstrated improvements on per-formance. Comparisons show that our approaches significantly outperforms tra-ditional source-channel model. Future work will include incorporating different features, such as additional contexts, target language model, or even the com-position of direct and inverted transliteration model under MaxEnt framework. The work described in this paper is partially supported by CUHK under the Strategic Grant initiative (Project Account No.: 4410001). We are especially grateful to Prof. Helen Meng for her support and help on obtaining LDC corpora.
