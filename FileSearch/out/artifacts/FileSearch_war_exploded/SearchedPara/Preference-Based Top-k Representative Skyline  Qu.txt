 Extracting a few interesting data objects from a potentially huge database to support multi-criteria decision making is challenging for the database community. There is an increasing number of real-world applications where the end-users need to make their over the objects X  dimensions are available, a subset of the most interesting objects can recent years. 
In the literature, there are a number of ranking tools that have been studied exten-sively in order to assist users in ranking processes. Top-k and skyline queries are two est scores that are based on some user-defined scoring functions. However, in multi-formulate a proper scoring function to best describe the trade-offs offered by different ranking criteria, e.g. room price and quality of hotels [1]. A skyline query is an alter-only a few criteria involved. 
To overcome the deficiencies of these two ranking techniques, a number of va-riants of ranking approaches have been propos ed recently to identify the truly interest-ing objects. Yiu and Mamouslis [2,3] propose top-k dominating queries which return ranking approach is unstable since the final results can be affected by the addition of processing [8]. Motivation and Challenges domains due to various factors, including data randomness and incompleteness, limi-tations of measuring equipment, delay or loss of data updates, etc. Since the number of such application domains is rapidly increasing, developing advanced data analysis tools over uncertain data has become more crucial. 
As aforementioned, skyline, top-k and top-k dominating queries have been widely studied in uncertain environments. However, these ranking approaches have their own deficiencies as analyzed above. By contrast, top-k representative queries play an im-portant role as they provide a novel ranking mechanism for applications where multi-in uncertain databases. Dealing with imprecise data in the ranking processes is much more complex and challenging since there are many factors that need to be taken into for each instance, the uncertainty of the results, and the exponential number of possi-ble instance combinations, and so on. Our Principal Contributions Can be Summarized as Follows:  X  We propose two efficient algorithms based on the R-Tree indexing struc- X  We present a detailed performance evaluation of our proposed algorithms Organization of the Paper: The rest of this paper is organized as follows. Section 2 novels algorithms for answering top-k representative queries in uncertain databases. A number of pruning conditions to enhance the efficiency of our methods are also pro-demonstrates the performance of the proposed algorithms through extensive experi-ments. Finally, section 6 concludes this research and briefly discusses future work. 2.1 Data Model and related concepts regarding ranking queries on uncertain databases. 
Let  X   X  be a set of n uncertain data objects in an m -dimensional space  X  X   X ,  X   X ,...,  X   X  , where each dimension has a domain  X  X  X   X   X  tional number. In our data model, each uncertain object mutually exclusive alternatives (or instances)  X   X   X  X  X  X  instance  X   X  may appear with non-zero probability  X  X   X   X  As a result, the existing probability of each uncertain object is presented by the prob-ability distribution over its instance set. 
Generally, we consider each instance of an uncertain object as an m-dimensional point. The j -th dimensional coordinate value of an instance Without loss of generality, we assume that  X  X   X   X  :  X   X  X 
Given a set of uncertain objects  X   X  , a possible world stances where each instance represents an uncertain object uniquely. The probability of the appearance of possible world W , denoted by  X  X  X  X  X  X  the dataset. Let  X  be the set of all possible worlds, and then use  X  X  X  X  X  X  X  to denote the skyline set of possible world  X  . C). Each uncertain object has a number of its instances and each instance is associated 0.2 as the total probability of its three instances is 0.8 X 1 2.2 Problem Definition research areas, such as Information Retrieval Systems [9,10] and Recommender Sys-the volume of data presented to the user is an efficient strategy when explicit scoring functions are not available. rences on the priority of the individual dimensions. In fact, a user may be interested in only a subset of dimensions or may prefer one specific dimension which is more im-portant than the others. Motivated by this, we complement existing work by exploit-uncertain databases. User Preference The formal definition of the user-specified preferences is defined as an ordered subset of dimensions in  X   X  .
 Definition 1 (User Preference). Given a set of all dimensions  X   X   X   X   X   X   X ,...,  X   X   X   X  X  X 1  X  is an ordered subset of that  X , X  X   X   X  X  X  X  X  X 1 X   X   X  :  X   X ,  X   X  X   X  , then  X   X   X  X   X  Definition 2 (Personalized Dominance Relationship). Given two instances and a user preference  X   X   X   X   X   X   X ,...,  X   X  (  X , X  X  X 1 based on  X   X  , denoted by  X   X   X   X   X  , if and only if all  X  X  X  , we have  X  X  X   X   X  X  X  X  X  X   X   X  . Based on the personalized dominance relationship against two instances, we now can compute the personalized skyline probability of an instance as follows. jects  X   X   X   X   X   X   X ,  X   X ,...,  X   X  and a user preference  X   X   X   X   X  the personalized skyline probability of an instance by  X  X  instance of other uncertain objects dominating  X   X  exists.  X  X   X  X  X  X  The personalized skyline probability of an object  X  X  X  is defined as:  X  X   X  X  X  X  Theorem 1. Given a possible world  X  and X   X  X   X  |  X  |  X 0  X   X   X   X   X   X ,...,  X   X  (  X , X  X  X 1  X   X  X   X  ), there is an unique order among instances in Let  X  X  X   X  instance exists in  X  X  X   X   X   X   X   X  , |  X  X  X   X   X   X   X   X  | X 1 .
 Lemma 1. Given a set of uncertain objects  X   X   X   X   X  rence  X   X   X   X   X   X   X ,...,  X   X  (  X , X  X  X 1  X   X  X   X  ), let |  X   X  and  X   X  be the set of all instances in  X   X  where  X   X   X  X   X  lized skyline probabilities of all instances in  X   X  equals to 1.  X  X   X  Due to the space limitation, the proof of the correctness of Theorem 1 and Lemma 1 tions which may cause difficulty for the user in defining an appropriate threshold. To size. The odds ratio is one of the important statistics which is commonly used in in-formation retrieval [13] and data mining [14]. Specifically, we define the odds of an instance as follows.
 Definition 4 (Odds Ratio of an Instance): The odds of an instance by skyline set to its existing probability.  X   X   X   X   X  Definition 5 (Preference-Based Top-k Representative Skyline Query) : Given a set of uncertain objects  X   X   X   X   X   X   X ,  X   X ,...,  X   X  , a user preference ( stances belonging to k different objects. We define the odds ratio of a skyline instance based on intuition: the larger the odds ratio of an instance, the more interesting the instance. Significance of Using Odds Ratio sentative skyline query, namely as scale invariance and stability , which are proposed important as it can avoid the scenario where malicious users manipulate databases to reach their objective by simply adding non-skyline (unimportant) instance. The Na X ve approach for the problem of top-k representative skyline queries is to first calculate the skyline probabilities for each instance by conducting dominance checks against instances of other objects. Then, we compute the odds ratio of each instance method is inefficient as the total number of instances may be too large and performing pair-wise dominance checks between instances is too costly. Motivated by this limita-tion, we now present two algorithms, namely Sweep-Based Algorithm and Bounding CPU time and number of objects pruned, especially with high dimensional datasets. 3.1 Pruning Techniques which allow us to reduce the number of dominance checks by eliminating redundant instances or objects. Hence, the computational cost will be significantly reduced. Eliminating Redundant Instances and Objects The instances/objects having personalized skyline probabilities equal to 0 are defined as redundant instances/objects. We exploit an important technique using the minimum bounding box of each uncertain object to el iminate redundant instances/objects. Let be an uncertain object having  X  instances,  X  X  X  X  X   X   X ,..., user-defined preference. We denote  X   X  X  X  X  and  X  the lower-left corner of the minimum bounding box (MBB for short) of the uncertain object  X  respectively. Pruning Rule 1 (Eliminate Redundant Instances): Let  X  be an uncertain object that has  X  intances and  X  is an instance such that  X  X  X  If  X   X  X  X  X   X   X   X   X  and  X   X  X   X   X   X   X   X 1  X  Pruning Rule 2 (Eliminate Redundant Objects): Let  X  be an uncertain object that has  X  intances and  X  is another uncertain object such that 3.2 Sweep-Based Algorithm instances are lexicographically sorted based on  X   X  and it is named as the input list We also maintain a SKY list which is a maximal heap based on the odds ratio to store the processed instances having non-zero odds ratios. 
Suppose we are processing instance  X   X   X  X  in  X  and we denote be instances of object  X  with position before  X   X  . Then, we define the an instance as follows: us to terminate the searching process as ear ly as possible since it guarantees that the rest of the instances in the list  X  are redundant. In our example given in Figure 1, we can terminate the iteration after processing instance  X   X  after  X   X  in  X  have zero personalized skyline probabilities. Algorithm 1 illustrates the  X  returned. Algorithm 1. Sweep-Based Algorithm 3.3 Bounding Probabilities of Instances pruned.
 Pruning Rule 3: Let  X   X  be the current processing instance and bound probability. If  X  X  X  X   X   X  X  X  X  X   X  then  X   X  is pruned where follows: in instances that have been processed so far. The numerator of the above equation acts as  X  wants to be inserted into  X  X  X  , its odds value has to be greater than Specifically, the minimum corners of MBBs of all uncertain objects in calculation of the personalized skyline probability of an object window query on the R-tree with the origin and  X   X  X  X  X  as the opposite corners. Specif-ically, the minimum corners of MBBs of all uncertain objects in a heap. The top instance of the heap is itera tively processed. We also create a minimal that need to be processed. When the heap top cannot be pruned, its personalized sky-line probability and odds ratio are computed. If there is another instance of the same  X  X  X  X  X   X  X  X  X   X  X  and  X  are updated when there is an addition or replacement performed in the SKY heap accordingly. Once the instance of an object is processed, the existing probability of the next instance of the object is compared with the upper bound before algorithms, only a small portion of instances are involved in the searching processes. Therefore, it is clear that our proposed algorithms have good scalability on large data sets. Algorithm 2. Bounding Probability Algorithm data (also known as probabilistic skyline queries) is much more complicated and chal-lenging since each uncertain object takes a probability of not being dominated by any other objects. In addition, returning the full skyline set would be impractical and may [18] and [19] aimed to return k uncertain objects that have the highest skyline proba-tioned methods have one of the following limitations: (1) they totally ignore the user about the dataset; (3) the final result sets are unstable since they can be controlled by the addition of unimportant (non-skyline) points. 
Motivated by these identified weaknesses, top-k representative skyline queries are nearest representative skyline point. Paper [22] explored the queries under the set-ting of distributed data. However, these aforementioned methods focus on traditional this is the first study of top-k representative skyline queries in uncertain databases. studies to evaluate the efficiency, effectiveness and scalability of our proposed algo-were conducted on a PC computer with a Core-2 Duo CPU running Windows 7 with issues of efficiency, effectiveness and scalability. www.basketball-reference.com as the real data set. The real data set contains 260,599 probabilities are randomly assigned to instances of the same object such that the total the hyper-rectangle region of each object where the instances of the object appear. 5.1 Evaluating Efficiency and Scalability rithms by conducting extensive experiments regarding to the response time over vary-ing parameters. 
We evaluate the efficiency of our proposed algorithms over varying dimensionality serve that the response time on the anti-correlated dataset increases more sharply than the relative performance on the independent dataset. This is because when the dimen-sive. In addition, the average edge length of the objects X  minimum bounding rectan-gle is another factor that can directly affect the response time. The larger the average sibling nodes in R-tree). The smaller the average edge length of the objects X  minimum bounding rectangles, the more effective the pruning processes. 5.2 Evaluating Effectiveness not only redundant objects/instances but also non-promising objects/instances by using the upper bound on the probability. In this paper, we are the first to study the problem of top-k representative queries on uncertain databases. One of the main drawbacks of previous work is that their ranking threshold as it may be inconvenient for an end-user. We also investigated the efficien-cy, effectiveness and scalability of our proposed algorithms by conducting extensive work is to consider the problem in a streamed or distributed setting, offering addition-al scalability, especially for massive big data. References 
