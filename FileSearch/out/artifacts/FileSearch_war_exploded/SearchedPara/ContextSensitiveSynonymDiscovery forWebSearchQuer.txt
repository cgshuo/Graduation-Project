 We prop ose a simple yet e ectiv e approac h to con text sen-sitiv e synon ym disco very for Web searc h queries based on co-clic k analysis; i.e., analyzing queries leading to clic king same documen ts. In addition to deriving word based syn-onyms, we also deriv e concept based synon yms with the help of query segmen tation. Evaluation results sho w that this ap-proac h dramatically outp erforms the thesaurus based syn-onym replacemen t metho d in keeping searc h inten t, from accuracy of 40% to above 80%.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retriev al]: Information Searc h and Re-triev al General Terms: Algorithms, Exp erimen tation Keyw ords: Synon ym disco very, query reform ulation
Synon yms are words or expressions of the same language that have the same or nearly the same meaning in some or all senses 1 . Automatically disco vering synon yms from text has been activ e topics in a variet y of language pro cess-ing tasks [3, 7, 1, 2, 4]. Most existing work is to create a general purp ose synon ym thesaurus without targeted appli-cations [5]. However, it is unclear how general synon yms can help a particular application. In the con text of Web searc h, we want to nd synon yms that can express the same searc h inten t of users. Disco vering synon yms for Web searc h have at least the follo wing challenges: 1. synon ym disco very is con text sensitiv e. Although there 1 according to the de nition by www.merriam-w ebster.com 2. con text can not only limit the use of synon yms as 3. there are man y new synon yms dev elop ed from the Web
In summary , synon ym disco very for Web searc h is di er-ent from traditional thesaurus mining; it needs to be con text sensitiv e to keep the same searc h inten t, and is time sensi-tive so we need to update the dictionary timely . To address these problems, we conduct con text based synon ym disco v-ery from co-clic ked queries, i.e., queries that share similar documen t clic k distribution. The intuition of disco vering synon yms from co-clic ked data is that queries with similar clic ked URLs tend to be related and carry similar inten ts, whic h are often form ulated with synon yms. Synon yms dis-covered from co-clic ked documen ts is con text sensitiv e; as we aggregate over man y queries, the distribution of clic ked documen ts re ects prett y well the searc h inten t. We can obtain searc h queries on a daily basis, thus the synon yms mined from searc h queries re ects most recen t synon yms.
Clustering has been extensiv ely studied in man y applica-tions, including query clustering [8]. One of the most suc-cessful techniques for clustering is based on distributional clustering [3, 4]. We adopt a similar approac h to our co-clic ked query clustering. Eac h query is asso ciated with a set of clic ked documen ts, asso ciated with the num ber of views and clic ks. We then compute the distance between a pair of queries by calculating the Jensen-Shannon(JS) div ergence between their clic ked URL distributions. We start with that every query is a separate cluster, and merge clusters greed-ily. After clusters are generated, pairs of queries within the same cluster can be considered as co-clic ked/related queries with a similarit y score computed from their JS div ergence.
Synon yms disco vered from co-clic ked queries have two as-pects of word meaning: (1) general meaning in the language (2) speci c meaning in the query . These two asp ects are re-lated. For example, if the two words are more likely to carry the same meaning in general, then they are more likely to carry the same meaning in speci c queries; on the con trary , if two words often carry the same meaning in a variet y of speci c queries, then we tend to believ e that the two words are synon yms in general language.
 We dev elop our mo del based on the above two asp ects. First, we try to get the general meaning of two words from their meanings in all speci c queries. As we describ ed above, the assumption here is that if the two words carry the same meaning in man y speci c queries, then they are likely to be synon yms for asp ect (1). We consider all the co-clic ked queries with the word and sum over, as in Eq. 1 where sim k ( w i ! w j ) represen ts the similarit y score of a query q k that aligns w i to w j . So intuitiv ely, we aggregate scores all query pairs that align w i to w j , and normalize it to a probabilit y ( P ( w j j w i )) over the vocabulary .
Then, the query is tak en into consideration to catc h the speci c meaning in asp ect (2). We de ne the probabilit y of reform ulating w i with w j for query q k to be the similarit y score as in Eq. 2
Last, we com bine the above two steps. We have two sets of estimations for the synon ym probabilit y, whic h is to refor-mulate w i with w j . One set of values are based on general language information and another set of values are based on speci c queries. We applied linear com bination in log scale to com bine the two probabilities as in Eq. 3
The simple word alignmen t strategy we used can only get the synon ym mapping from single term to single term. But there are a lot of phrase-to-phrase, term-to-phrase, or phrase-to-term synon ym mappings in language, suc h as \bab e in arms" and \infan t", \nyc" and "new york city". We perform query segmen tation on queries to iden tify concepts from queries based on an unsup ervised segmen tation mo del [6]. Query segmen tation not only gives concept based alignmen t, but also can impro ve the precision of alignmen t. For exam-ple, \bab y clothing stores" will not be aligned with \bab y fa-vorite stores" after segmen tation even they con tain the same num ber of words.
Because we are more interested in the application of re-form ulating Web searc h queries, our guideline to the edito-rial judgmen t focus on the query inten t change and con text-based synon yms. For example, \transp orters" and \mo vers" are good synon yms in the con text of \boat" because \boat transp orters" and \boat movers" keeps the same searc h in-ten t, but \ocean" is not a good synon yms to \sea" in the query of \sea boss boats" because \sea boss" is a brand name and \ocean boss" does not refer to the same brand. Results are measured with accuracy by num ber of disco vered syn-onyms (whic h re ects coverage). And accuracy are de ned as where n cor rect is the num ber of correctly disco vered syn-onyms, and N is the num ber of all disco vered synon yms.
We target on higher accuracy and larger coverage, but generally , disco vering more synon yms would lead to more errors, whic h means lower accuracy .
A perio d of Web searc h query log with clic ked URLs are used to generate co-clic ked query set. After word alignmen t, whic h extract the co-clic ked query pairs with same length and only one di eren t unit, we have around 12.1M unseg-men ted query pairs and 11.9M segmen ted query pairs.
We randomly sampled 42K queries from two weeks of query log, and evaluate the e ectiv eness of our synon ym disco very mo del with these queries. To test the synon ym disco very mo del built on the segmen ted data, we segmen ted the queries rst before sending the data as the evaluation set.
In this section we presen t WordNet thesaurus based query synon ym disco very, co-clic ked based term-to-term query syn-onym disco very, and co-clic k concept based query synon ym disco very.
The WordNet thesaurus-based synon ym replacemen t is a baseline of our approac h. For any word that has synon yms in the thesaurus, thesaurus-based synon ym replacemen t will rewrite the word with synon yms from the thesaurus.
Thesaurus-based synon ym replacemen t su ers from miss-ing of con text. Although thesaurus can pro vide clean in-formation, it has only kno wledge for single words. The con text plays an imp ortan t role in synon ym disco very, and thesaurus-based synon ym replacemen t without considering con text often brings too much errors and noise. Our ex-perimen ts sho w that only less than 46% of the disco vered synon yms are correct synon yms in query . Although 27k syn-onyms were disco vered from the test set, whic h are much more than the num ber of synon yms our approac h disco v-ered (see Section 4.3.2 and Section 4.3.3), the accuracy is too low to be used for Web searc h queries.
Figure 1 demonstrates how accuracy changes with the num ber of synon yms. Y axis represen ts the percen tage of correctly disco vered synon yms; X axis represen ts the num-ber of disco vered synon yms, including both of correct ones and wrong ones. The three di eren t lines represen ts three di eren t parameter settings of mixture weigh ts( in Eq. 3, whic h is 0.2, 0.3, or 0.4 in the gure) selected by exp erience. The gure sho ws accuracy drops by raising the num ber of synon yms. More synon ym pairs tend to imply lower accu-racy . From Figure 1 we can see: 1. the e ectiv eness of synon ym disco very is not very sen-2. the e ectiv eness of synon ym disco very is sensitiv e to Figure 1: Accuracy versus number of synon yms.
 Mixture weight =0.2, 0.3, or 0.4.
We presen t results from our mo del based on segmen ted co-clic ked query data in this section. The mo deling part is the same as the one for Section 4.3.2, and the only di erence is that the data were segmen ted.

Figure 2 sho ws the accuracy of synon yms by num ber of disco vered synon yms. As in Section 4.3.2, by applying dif-feren t thresholds as cut-o lines to Eq. 3, we get di eren t num bers of synon yms from the same test set, and a looser threshold gives us more synon ym pairs with lower accuracy . Y axis in Figure 2 represen ts the percen tage of correctly disco vered synon yms and X axis represen ts the num ber of disco vered synon yms. We have sho wn in Section 4.3.2 that the mixture weigh t is not an in uen tial factor within reason-able range, so we presen t only the result with one mixture weigh t in Figure 2.

Same as in Section 4.3.2, the gure sho ws that the ac-curacy of synon ym disco very is sensitiv e to the threshold. Loosing the threshold to get more synon yms decreases the accuracy . Again, it con rms that our mo del is e ectiv e and setting threshold to Eq. 3 is a feasible and sound way to disco ver not only single term synon yms but also phrase syn-onyms.
 Figure 2: Accuracy versus number of synon yms.
 Mixture weight =0.3.

Table 1 sho ws represen tativ e examples of query synon yms with the thesaurus-based synon ym replacemen t, con text sen-sitiv e synon ym disco very, and concept based con text sen-sitiv e synon ym disco very. The upp er part of eac h section sho ws positiv e examples (query inten ts remain the same af-ter synon ym replacemen t) and the lower part sho ws negativ e examples (query inten ts change after synon ym replacemen t).
From Table 1, we can see that our mo del can catc h not only traditional synon yms, whic h are the synon yms that can be found in man ually-built thesaurus, but also con text-based synon yms, whic h may not be treated as synon yms in dictio-naries or thesaurus.

However, the clic k data themselv es con tain huge amoun t of noise. Although they can re ect the users' inten ts in big picture, in man y speci c cases synon yms disco vered from co-clic ked data are biased by the clic k noise. In our application { Web searc h query reform ulation with synon yms, accuracy is the most imp ortan t thing and thus we are interested in error analysis. The errors that our mo del made in synon ym disco very are mainly caused by the follo wing reasons: 1. popular conc epts: There are some concepts that are well accepted suc h as \cnn" means \news" and \am trak" means \train" . And users searc hing for \news" tend to clic k CNN web site; users searc hing for \train" tend to clic k Am trak web site. With our mo del, \cnn" and \news" , \am trak" and \train" are disco vered to be synon yms, but this may hurt the searc h of \news" or \train" in general meaning. 2. same clicks by di er ent intents: Di eren t inten ts/meanings could results in same or similar clic ks. Query \an tique style wedding rings" and \an tique style engagemen t rings" carry di eren t inten ts, but very usually , these two di eren t inten ts can lead to the clic ks on the same store web sites. Other examples include \booster seats" and \car seats" , \brigh ton handbags" and \brigh ton sho es". For these examples, clic ks on Web URLs are not precise enough to re ect the detailed di erence of language concepts. 3. dominant user intents: Most people searc hing for \air-line travel restrictions" are looking for \airline baggage re-strictions" . So these two queries have similar clic ked-URLs. But \tra vel" and \baggage" are not synon yms in language. In these cases, popular user inten ts dominate and biased the meaning of language, whic h cause problems. 4. antonyms: Man y con text-based synon ym disco very metho ds su er from the anton ym problem, because anton yms can have very similar con texts. In our mo del, the problem has been reduced by integrating clic ked-URLs. But still, there are some examples, suc h as \sp yware" and \an tisp y-ware" , resulting in similar clic ks. To learn how to \protect a web site" , the user will often need to learn what are the main metho ds to \attac k a web site" , these di eren t-in ten t pairs lead to same clic ks because di eren t inten ts do not have to mean di eren t interests in speci c cases.

For future work, we are investigating using these syn-onyms in impro ving searc h relev ance. Our preliminary re-sults sho w this is promising. [1] M. Baroni and S. Bisi. Using Cooccurrence Statistics [2] C. Fellbaum, editor. Wor dNet: An Electronic Lexic al [3] D. Lin. Automatic retriev al and clustering of similar [4] F. Pereira, N. Tish by, and L. Lee. Distributional [5] R. Sno w, D. Jurafsky , and A. Y. Ng. Seman tic [6] B. Tan and F. Peng. Unsup ervised Query Segmen tation [7] P. Turney . Mining the Web for synon yms: PMI-IR [8] J.R. Wen, J.Y. Nie, and H.J. Zhang. Query Clustering
