 Multi-view clustering is an important problem in informa-tion retrieval due to the abundance of data offering many perspectives and generating multi-view representations. We investigate in this short note a late fusion approach for multi-view clustering based on the latent modeling of cluster-cluster relationships. We derive a probabilistic multi-view clustering model outperforming an early-fusion approach based on multi-view feature correlation analysis.
 H.3.3 [ Information Search and Retrieval ]: Clustering; I.5.1 [ Models ]: Statistical Algorithms Multi-view clustering, data fusion, latent models
Information retrieval has to deal with data presenting many perspectives and usually characterized by various het-erogeneous sources of information. Web pages, Web commu-nities, multimedia documents, user profiles are examples of data that can be organized into multi-graphs or decomposed onto multi-modal signals. Statistical analysis of those data collections has to deal efficiently with the various available views to infer internal relationships, structures and cate-gories. Consequently, multi-view clustering approaches have been recently developed to derive convenient mining tools handling these complex representations. Two families of algorithms might be identified: the first aims at doing an early fusion of the multi-view information while the second is based on the late fusion of clusters estimated indepen-dently in each view. For early fusion approaches, we can cite [6, 8] who propose to build a convex combination of multi-view similarities, where mixing parameters and clusters are jointly estimated to minimize a given penalty error. Late fusion consists of first taking a decision in each view sepa-rately and then fusing all decisions arising from all views in a global model. The global model tends to define a consensus clustering by determining cluster agreements/disagreements [1, 2]. Following this idea, we investigate a latent model framework to explicit cluster-cluster relationships in term of global multi-view clustering model.
We suppose that M views on N documents are avail-able. Each view m = 1 . . . M gives rise to k m clusters { c 1 , . . . , c m k m } obtained through some clustering methods. The clustering might be represented as a k m  X  N cluster-document matrix C m , where the binary entry C m kn indicates whether the document d n is in the cluster c m k . The M in-dependent clusterings C m are concatenated into a K  X  N matrix C , where K = P m k m is the total number of clus-ters over all views. The empirical joint cluster-document probability is simply obtained with a proper normalization
The inter-cluster analysis we propose relies on the co-occurrence relationships among multiple clusters and views. Exploiting cluster agreement and disagreement, the aim is to derive a multi-view clustering providing a consensus among all information initially available. The cluster agreement is evaluated through the joint cluster-cluster probability de-rived from (1) by noticing the conditional independence of observing simultaneously c k and c k 0 given d n The joint probability P ( c k , c k 0 ) is defined as the fraction of documents falling simultaneously in clusters c k and c k 0 definition the probability is 0 if the two clusters are from the same view). We will see in section 3 and 4 how a multi-view global clustering might be derived from this empirical joint distribution.
The Probabilistic Latent Semantic Analysis (PLSA), pro-posed in [4] and originally designed for term-document ma-trix analysis, states the existence of binary latent variables z , i = 1 , . . . L in the generative process of P ( c moreover assumes the conditional independence of the co-occurrence of c k and c k 0 given z i PLSA establishes a generative relationship between instances of clusters observed in various views and discrete variables z and thus makes explicit the absolute data distribution in a homogeneous latent space. Practically, as the latent model is estimated from the observations, it effectively fuses the sources of information.

The multi-view clustering of the data is given by assign-ing to every document d n the variable z i maximizing the posterior probability
Expectation-Maximization algorithm (EM) is tradition-ally used to estimate the latent model of equation (3). From initial random probabilities, EM iteratively maximizes the log-likelihood of the model knowing the empirical distribu-tion P ( c k , c k 0 ). Please refer to [4] for the complete estima-tion procedure.

Non-negative Matrix Factorization (NMF) [7] is an alter-native solution to get estimation of the PLSA parameters [3]. NMF seeks for the factorization of the empirical distribution matrix P kk 0 = P ( c k , c k 0 ) into two nonnegative matrices W and H such that P  X  W H . As detailed in [3], P ( c | z ) and P ( z ) can be easily recovered from W and H . We use the NMF implementation minimizing the Frobenius norm be-tween the matrix and its factorization. Again, please refer to [7] for the NMF implementation.

EM and NMF are both considered and compared in our experiments to operate the probabilistic latent clustering.
The experiments have been conducted on three data sets offering a multi-view description: Base clusterings { c m 1 , . . . , c m k m } are computed for each view using a standard k -means with k corresponding to the right number of categories in the data set (3, 9 and 30 respec-tively). The number of latent variables in equation (3) is set to the same number of k (3, 9 and 30 respectively).

For comparison purpose, a baseline Mahalanobis k -means is applied over the concatenated features, with again k equals to 3, 9 and 30. Similarly to the probabilistic latent cluster-ing which analyzes cluster co-occurrences, the Mahalanobis clustering estimates feature correlations to infer a suitable fusion model. This approach is representative of a multi-view early fusion clustering.

Clustering accuracy, evaluated with the F 1 measure, is given in table 1. At the light of these results, it appears that the latent clustering outperforms the early fusion approach. The result is particularly clear for the easy Wine data set, but also for the difficult Corel collection. This tends to in-dicate that base clustering operates a pre-filtering of the data and provides a more appropriate information than the  X  X pherized X  multi-view features. As far as the latent model estimation algorithms are concerned, NMF and EM perform comparably over the three data sets.
This communication has presented a latent clustering ap-proach based on the latent modeling of cluster-cluster rela-tionships. A nice feature of this model is the fact that its estimation relies on a very compact coding of the complete database (the cluster-cluster contingency table), and there-fore is particularly suited for large scale multi-view cluster-ing. Beside clustering, new multi-view similarity measures based on P ( d n , d n 0 ) may be also estimated from the same compact representation.
This work is funded by the Swiss National Center of Com-petence in Research (NCCR) on Interactive Multi-modal In-formation Management (IM2).
