 algorithm for mining frequent closed itemsets. Our approach consists of constructing a prefix graph structure and decomposing the database to variable length bit vectors, which are assigned to nodes of the graph. The main advantage of this representation is that the bit vectors at each node are relatively shorter than those produced by existing vertical mining methods. This facilitates fast frequency counting of itemsets via intersection operations. We also devise several int er-node and intra-node pruning strategies to substanti ally reduce the combinatorial search space. Unlike other existing approaches, we do not need to store in mem ory the entire set of closed itemsets that have been mi ned so far in order to check whether a candidate itemset i s closed. This dramatically reduces the memory usage of our algorithm, especially for low support threshold s. Our experiments using synthetic and real-world data sets show that PGMiner outperforms existing mining algorithms by as much as an order of magnitude and is scalable to very large databases. discovering frequent itemsets whose support counts are different than those of their supersets. Frequent c losed itemsets provide a compact yet lossless representat ion of the frequent itemsets; i.e., it is possible to deri ve the complete set of frequent itemsets along with their support counts from the closed itemsets alone. In particula r, the number of closed itemsets can be orders of magnitud e fewer than the number of frequent itemsets. The difference is even more pronounced for dense databa ses, where the frequent itemsets tend to be long and enumerating all of them is simply infeasible due to their exponential number. improve the efficiency of the closed itemset mining task [1, 2, 5, 7, 8, 9, 10, 12]. There are two typical s trategies adopted by these algorithms: (1) an effective pruni ng strategy to reduce the combinatorial search space o f candidate itemsets and (2) a compressed data representation to facilitate in-core processing of the itemsets. Item merging and sub-itemset pruning are two of the most commonly used strategies employed by current algorithms [10]. These strategies ensure th at many of the non-closed itemsets will not be examine d when searching for frequent closed itemsets, thereb y reducing the runtime of the algorithms. condensed representation of the database is also vi tal to achieve good efficiency. Existing algorithms such a s FPclose [2] and CLOSET+ [10] construct a frequent pattern tree (FP-tree) structure [3] to encode the relevant itemsets and frequency information. In this representation, each transaction in the database is represented as a path from the root of the FP-tree. Compression is achieved by merging prefix paths of transactions that share the same items. A vertical database representation is another popular strategy , in which each item is associated with a column of valu es indicating the transactions that contain the item. For example, algorithms such as CHARM [12] use vertical tid-lists as their data representation while MAFIA [1] and DCI-Close [5] use vertical bit vectors. Figure 1 shows the representation of the data, our analysis shows that there are situations where the storage requirements of th e tree may exceed even the database size, especially when the support threshold is low or when the database is ve ry sparse. This is because each tree node encodes not only the item label, but also the support count and poin ters to the parent, sibling, and child nodes. As shown in T able 1, the size of the initial FP-tree exceeds the databas e size for databases such as Chess and Kosarak . Algorithms that use the FP-tree structure must also recursivel y build smaller subtrees and traverse multiple branches of the trees to collect frequency information during the m ining process. The overhead of reconstructing and travers ing the FP-trees may degrade the overall performance of the algorithm [2]. storing vertical bit vectors are generally less tha n that for FP-tree and vertical tid-lists, with the exception of the Kosarak data set. Vertical bit vectors also allow for fast support counting using simple bitwise AND operation s. However, when the database is large and sparse, the handling of long bit-vectors is quite inefficient s ince there are lots of zeros in the vectors. itemset mining algorithms must compare the support of a candidate itemset against the support of its supers ets. To perform this task more efficiently, many algorithms such as CLOSET+ [10], FPclose [2] , and CHARM [12] store their intermediate result set, which contains all t he closed itemsets that have been mined so far, in another da ta structure (FP-Tree, hash table etc.). Such a storag e method is feasible as long as the number of closed itemsets is small. When the number of closed itemse ts is large, it will consume considerable memory to store and time to search the itemsets. In fact, our analysis shows that in some cases the amount of memory occupied by the result set is several orders of magnitude large r than the size of initial FP-tree or vertical database representation. For example, in the Chess database with 25% support threshold, storing the result set takes up to 102MB, even though the size of the initial FP-Tree is only 621Kb! The cost for searching the result set ( to determine whether a candidate itemset is closed) ca n also be very expensive. Our analysis on the Chess database shows that FPclose spends about 70% of its overall computation time searching the result-set. representations have their own strengths and limita tions. In this paper, we introduce a novel representation called PrefixGraph, which leverages some of the positive aspects of existing representations. From FP-tree, it borrows the idea of projecting a database onto diff erent nodes of a graph X  X ut without the extra cost of traversing multiple branches of the tree to collect frequency information. A PrefixGraph also uses bit vectors to encode the database projection at each n ode. However, the length of its bit vector is considerab ly shorter than that used by existing vertical bit vec tor representations. We will discuss in more details ho w the graph is constructed in Section 2. From Table 1, no te that the size of the prefix graph structure is mode rate compared to other representations. For the Kosarak data set, it yields the most compact representation. network flow analysis, a novel algorithm called PGMiner is developed. Our experimental results show that th e memory usage for PGMiner does not grow quite as rapidly as other algorithms during the mining proce ss. Furthermore, PGMiner outperforms FPclose [2], DCI-Close [5] and CHARM [12] , three state-of-the-art closed itemset mining algorithms, by an order of magnitude both in time and memory requirements. 2 introduces the PrefixGraph representation. Section 3 describes the PGMiner algorithm. Section 4 presents the experimental results while Section 5 concludes the paper. representation and show in detail its construction. itemset X is a non-empty subset of items; i.e. X  X  I . An itemset with k items is called a k-itemset . Items in a given itemset are assumed to be sorted according to some total order, p . We use the notation x p y to indicate x precedes y according to the total order. The support of an itemset X , denoted as  X  (X), is defined as the fraction of total transactions that contain X . An itemset is called frequent if its support is greater than or equal to a minimum support threshold  X  . An itemset X is closed if none of its proper supersets has exactly the same s upport count as X. Given a database D and a support threshold  X  , the problem of mining closed itemsets is to find al l closed itemsets that pass the support threshold. objects called vertices (or nodes) and E is a set of 2-element subsets of V called edges. A digraph G is a graph whose edge set E contains ordered pairs of distinct that u and v are adjacent in G . directed edges connecting pairs of nodes. Any item in the database that satisfies the support threshold is represented as a node in the PrefixGraph . Each node is also associated with a projected bit vector databas e (see Figure 3). Before illustrating the PrefixGraph structure further, we give some useful definitions. Definition 1 (Prefix 2-Item) At a node k , an item i is called its prefix 2-item if i p k and { i , k } is a frequent 2-itemset. Definition 2 (Prefix Itemset) Consider an itemset X = {i respect to node i j is defined as all the items {i 1 , i Definition 3 (Suffix Node) Let S be a set of nodes sorted based on frequency descending order. A suffix node with respect to node j is any node k  X  S such that j p k . Definition 4 (Suffix Link) A directed edge between node i and its suffix node k is called a suffix link. Definition 5 (Farthest-Node) Let S be a set of nodes sorted based on frequency descending order and T( j ) be subset of the suffix nodes such that  X  n  X  W( j ), jn is a suffix link in the PrefixGraph and { j , n} is a frequent 2-itemset. The Farthest-Node of node j is defined as the suffix node k , such that  X  n  X  W( j) , n p k . Example 1 : Consider the PrefixGraph shown in Figure 3 for the sample database in Table 2. The total order of the nodes are a p b p d p e p c. The prefix 2-item for node b is a , while the prefix 2-items for node c are a and b . The nodes d, e, and c are suffix nodes of b because b precedes these nodes. The edges bd , be and bc are examples of suffix links associated with node b . Finally, c is the Farthest-Node of b . using the transaction database given in Table 2 wit h support threshold  X  = 2. frequent items and their corresponding support coun ts. These frequent items form the nodes of the PrefixGraph . For the sample database, the list of frequent items are &lt;(a:4), (b:4), (c:3), (d:4), (e:4)&gt;, where (m:n) denotes an item m with support count n . on the descending order of support count as shown i n Figure 2(a). Next, we scan the database again to id entify the prefix 2-items for each node. For example, the frequent 2-itemsets for nodes a, b, d, e, and c are (ab, ad, ac, ae), (ba, bd, be, bc), (da, db, de), (ea, eb, e d), and (ca, cb), respectively. The prefix 2-items and their corresponding support counts for these nodes are {} , {a:3}, {a:3, b:2}, {a:2, b:2, d:3}, and {a:2, b:3} respectively. For each node, we store its set of pr efix 2-items in a header table as shown in Figure 2(b). the transactions as bits in the projected bit vecto r database of the nodes. We scan the database, and fo r each transaction, infrequent items are removed and the remaining items are sorted based on the frequency descending order. Let T be the resulting itemset. Now for each item k in T , we select the corresponding node k and compare its prefix 2-items against the prefix items et of T . If there is a match then these matching items are s tored as bits in the projected bit vector database of nod e k . sample database. After removing the infrequent item s, the remaining items are: T = {a, b, d, c}. Since the transaction has 4 frequent items we need to conside r the nodes a , b , d, and c . Node a has no prefix 2-items and therefore nothing is stored. For node b , item a of the transaction matches with its prefix 2-item (i.e. a) and therefore bit &lt;1&gt; is stored in its projected bit ve ctor DB. For node d , items {a, b} of T match with its prefix 2-items and therefore bits &lt;11&gt; are stored in the pro jected bit vector DB. Similarly for node c , the bits for items {a, b} of the transaction are stored in the projected b it vector DB. Figures 2(c) and 2(d) show the PrefixGraph after storing the first two transactions. When storing a transaction such as {d, e} at node e , we need to store bits &lt;001&gt; in node e , since only item d of the transaction matches with the prefix 2-items of node e . based on the transactions. For each item k in the transaction T , a suffix node m is selected such that m  X  T and  X  n  X  suffix nodes of k , m p n . A suffix link is then created from node k to node m . For example, consider the transaction {a, b, d, c}. For node b we select the suffix node d (out of d and c ) and add a suffix link from b to d . Figure 3 shows the complete PrefixGraph structure after storing all the transactions in the sample database. incorporated directly into the projected bit vector database. More specifically, we can group the bit v ectors of the transactions that have the same suffix link together and store them contiguously in the projected bit ve ctor database of the node. For this purpose, the project ed bit vector database of each node is partitioned into bi ns, and the set of bit vectors in each bin corresponds to a suffix link. For example, transactions {a, b, d, e} and {a , d, e} both have the same suffix link ( de ) at node d , and thus, can be stored together in a bin. If a transaction h as no suffix link beyond a given node, these transactions are stored in an additional bin called the terminating bin . For example, the transaction {a, d, e} is stored in the terminating bin of node e . All bins must be arranged contiguously, so that the intersection of bit vecto rs (item wise) can be done fast as a one large chunk of word s. Also, we need to keep track of the starting locatio n of each bin in order to identify the suffix links. procedure is given in Algorithm 1. Algorithm 1 ( PrefixGraph Construction) Input : A transaction database D and support threshold Output : PrefixGraph structure Method : three scans of the database. The first two scans ar e necessary to find frequent 1-itemset and 2-itemset, while the third scan is needed to construct the projected bit vector databases. Proposition 1 The size of the projected bit vector database of a node is bounded by the support count of the node times the number of prefix 2-items of that node. Proof . Let m be the number of prefix 2-items of a node k . Since the number of transactions that contain ite m k is equal to the support count  X  ( k ), the size of the projected bit vector database of node k must be equal to  X   X  8/) ( k m  X   X  bytes. But in a bit vector database, projected transactions starting with item k are not stored as bit vectors at that node. Therefore, the size of the projected bit vector database at node k is  X  PrefixGraph structure as we use bit vector intersections during mining. According to Proposition 1, the len gth of the bit vector is at most equal to the support coun t of the node. Since the support count of an item is usually much smaller than the database size, we will have shorte r bit vectors and accordingly faster bit vector intersect ions. node varies as shown in Figure 4 for the Chess and T40I10D100K databases with minimum support thresholds 30% and 0.10% respectively. Except for t he nodes in the middle, all other nodes have small pro jected bit vector databases, which facilitate faster minin g of itemsets. frequent closed itemsets from the PrefixGraph structure. The algorithm proceeds in two phases: first, we fin d the frequent closed itemsets for each node (these are k nown as local closed itemsets). We then check whether the local closed itemsets are also globally closed using various inter-node pruning techniques. Here we give the formal definitions of local and global closed items ets. Definition 6 (Local Closed itemset) An itemset X , derived under node n is defined as locally closed, if there is no itemset Y (  X  X ) derived under the same node n with  X  ( Y ) =  X  ( X ). Definition 7 (Global Closed itemset) An itemset X , derived under node n is defined as globally closed, if there is no itemset Y (  X  X ) derived under any node k, ( k  X  set of all n odes) with  X  ( Y ) =  X  ( X ). locally closed itemsets from the projected bit vect or database for each node. As shown in the next proposition, itemsets that are not locally closed a re guaranteed to be non-globally closed. Such itemsets can therefore be excluded from further consideration. Proposition 2: For any given itemset X, derived under node n, if X is not locally closed then it is not g lobally closed. Proof . Since X is not locally closed,  X  Y derived under Definition 7, X cannot be globally closed.  X  vectors of all distinct pairs of the itemsets are i ntersected and the cardinality of the resulting bit vector is checked. This is carried out recursively in a depth first ma nner until all the itemsets are enumerated. For example, in the itemset enumeration tree given in Figure 5, for ite mset {a}, we generate all its combinations ({ab},{ac},{a d}). Then starting from {ab}, ({abc},{abd}) are generate d. Similarly, itemsets {abcd}, {acd}, ({bc},{bd}), {bc d} and {cd} are enumerated in depth first manner. Note that any itemset {i 1 , i 2 , ...,i k } generated under a node n must have its node label appended as {i 1 , i 2 , ...,i k , n}. We have omitted item n from the set enumeration tree in Figure 5 for brevity. Similar to several past algorithms [1, 5, 8, 12], we use two additional pruning techniques to ra pidly identify the local closedness of the frequent items et once it is generated. Proposition 3: (sub-itemset pruning) For a frequent itemset X and an already found closed itemset Y, if X  X  Y and  X  (X)=  X  (Y), then X and all X X  X  descendent itemsets in the set enumeration tree are not closed. Proposition 4: (item merging) For a frequent itemset X and an already found frequent itemset Y, if the tid -set(X)  X  tid-set(Y) and Y  X  X, then X and all X X  X  descendent itemsets in the set enumeration tree are not closed. requires storing possibly a large set of closed ite msets and performing subset checking to determine whether an itemset is set-included in a superset. To reduce th ese overheads, we limit the applicability of this pruni ng strategy to itemsets between two successive levels of the depth first search space. For example, itemset {ab} at level-2 generates its level-3 itemsets ({abc}, {abd }). Based on Proposition 3, if {abc} and {ac} have iden tical support counts, we can prune {ac} and its sub-tree.
 an itemset X requires that we perform subset checking of X X  s bitmap with the bitmaps of all the processed (i.e . already mined) local itemsets of level-1 down to th e parent level of itemset X . For example, if the itemset is {b, c, d} we need to check whether its bitmap is a subset of the bitmap of a . If it is a subset of bitmap( a ), then {b, c, d} is not closed according to Proposition 4. In our vertical bit vector representation, such bitmap sub set checking can be performed very fast. that itemset generation and support counting are ve ry fast, since the projected database contains short b it vectors. Unlike FPclose and CLOSET+ , the information needed for support counting is locally available an d there is no need to traverse any other nodes. generate only the complete set of local closed item sets for that node. In the next section, we develop an e fficient flow based pruning strategy to verify whether the l ocal closed itemsets are also globally closed. we consider PrefixGraph structure as a network with transactions flowing through the nodes. Therefore, the problem of discovering a global closed itemset can be mapped to a network flow problem. PrefixGraph structure. For a node n in the PrefixGraph G , we define the out-neighborhood and in-neighborhoo d of n by N + ( n ) = { m  X  V(G) | ( n , m )  X  E(G)} and N { m  X  V(G) | ( m , n )  X  E(G)}, respectively (here V(G) and E(G) are the set of nodes and edges respectivel y). the flow along the edge and is considered as the se t of transactions that flows through the edge ( n , m ). Further more we have, 0  X  ) , ( m n f  X  X  ({nm}), where ) , ( m n f denotes the number of transactions. be defined as OutF ( n ) = ) , ( flow can be defined as InF ( n ) = ) , ( specifically, we denote ) , ( m n f X as all the transactions containing itemset X that flow from node n to m . Then, for a given itemset X derived under node n , the outgoing flow of X can be defined as OutF X ( n ) = ) , ( Similarly, the incoming flow of itemset X derived under node n can be defined as InF X ( n ) = ) , ( Here we give some properties of this flow based representation. Postulate 1: Given an itemset X derived under node n, where |X|  X  2, the following properties hold: II. InF X (n)  X  OutF X (n)
III.  X  m : OutF X (n)  X  InF Xm (m), where n p m and Xm Example 2 : Consider the PrefixGraph shown in Figure 6, for the database given in Table 2. The out-neighborhood of node b, N + (b) = {d, e, c} and the in-neighborhood of node d, N -(d) = {b, a}. Transaction flow along edges (b,d) and (d,e) are ) , ( d b f ={t 1 , t ID. The flows can also be defined with respect to a given itemset. For example, ) , ( flow for itemset {a, d, e} at node e, InF {a,d,e} ( e ) = {t and | InF {a,d,e} ( e )| =2 =  X  ( ade ). itemset can be defined as follows. Theorem 1: An itemset X derived under node n is globally closed if  X  m: InF X (n)  X  InF Xm (m), where n and Xm = X  X  {m}. Proof. This theorem is simply a re-statement of the definition of closed itemset that no supersets of X have the same support as X . Note that each immediate superset Xm must be generated at some node m in the PrefixGraph structure and  X  (Xm) = |InF Xm (m)| .  X  Corollary 1: The following conditions hold if X is not globally closed. II.  X  m : InF X ( n )  X  InF ( m ), where n p m . Proof. Condition I follows directly from the contra positive of Theorem 1. Condition II holds because InF Xm ( m )  X  InF ( m ) (from the definition of incoming flow).  X  several theorems that will assist us in identifying whether a given local closed itemset is globally closed. Theorem 2: For any itemset X derived under node n if, 
II.  X  X' s. t. X  X  X' and X' is known to be a globally then X must also be globally closed.
 Proof. To construct the proof, by contradiction, assume that X is not globally closed even though X X  is globally closed. By Corollary 1,  X  m : InF X ( n )  X  InF ( m ). Since X of subset relation, InF X X  ( n )  X  InF ( m ), which contradicts the previous statement that X X  is a globally closed itemset. Thus, X must be globally closed.  X  itemset derived under some node, then all locally c losed subsets of the itemset are also globally closed ( upward closure property). For example, in the search space given in Figure 5, suppose we found itemset {a, c, d} is globally closed; then all of the locally closed sub sets of {a, c, d} derived under node n are guaranteed to be globally closed. keeping all of the globally closed itemsets of a pa rticular node in memory for subset checking. To avoid this, we devise two optimization methods: First, when checki ng the global closedness of local closed itemsets, we start from the maximal closed itemset (leaf) of the enumeration tree. That way, if we determine the lea f itemset as globally closed (using other techniques described later), then all the local closed itemset s in its path (to the root) become globally closed. Second, based on our analysis, we found that there is temporal lo cality which can be exploited during the search, i.e., mos t local closed itemsets are subsets of the most recently fo und globally closed itemset. Therefore, each time we discovered a new globally closed itemset, we keep a copy of this itemset in memory. Then, when a new lo cal closed itemset is found we compare it against this copy. Theorem 3 : For any itemset X derived under node n if, 
II. |InF X ( n )| -| OutF X ( n )| &gt; 0 then X is a globally closed itemset.
 Proof. To construct the proof, by contradiction, assume that X is not globally closed but |InF X ( n )| &gt; | OutF By Corollary 1,  X  m : InF X ( n ) = InF Xm ( m ). From the third property of Proposition 1, | OutF X ( n )|  X  | InF Putting them together, it follows that | InF X | OutF X ( n )|, which contradicts our initial assumption. Thus, X must be globally closed.  X  closed itemset X , derived under node n , has at least one transaction that terminates at node n (i.e. those transactions do not flow to other nodes), then X is globally closed. In our PrefixGraph structure, all we need to do is to examine the bits in the terminating bin of the corresponding itemset X  X  bitmap. If at least one bit is  X 1 X  in the terminating bin of the itemset, then that itemset is globally closed. This is a very fast operation t hat requires checking the itemset X  X  own bit vector to determine the global closedness. Theorem 4 : For any itemset X derived under node n if, then X is not a globally closed itemset.
 Proof. Let InF X ( n ) = OutF X ( n ). Since X has exactly one suffix link to a node m , OutF X ( n ) = InF Xm ( m ). Putting them together, we obtain InF X ( n ) = InF Xm ( m ), which according to Corollary 1 means that X is not globally closed.  X  belong to itemset X flow to exactly one other node, then X is not closed. In the PrefixGraph representation, once an itemset is generated its links can be analyzed b y checking the bins of the bit vector. Based on the n umber of links, we can decide whether the itemset is not closed. previous theorems are inapplicable, we need to test whether they are globally closed. In order to deter mine the global closedness of a local closed itemset, we need to visit every suffix node and compare the support of its corresponding superset, which is a very expensive operation. The following theorem reduces the number of such nodes that need to be visited. Theorem 5 : Let X be any itemset derived under node n and let t be the Farthest-Node of n w. r .t. itemse t X. Then for any itemset X' s. t. X'  X  X derived under node m, n p m p t,  X  ( X' )  X   X  ( X ). Proof . Let adj X (n) = (n 1 , n 2 , ...,n m , t) be the possible set of nodes that itemset X can have a outgoing flow, with n for itemset X . Let X' be an itemset derived under any flow for any node  X  adj X (n) \{ t } then  X  ( X' ) =  X  InF X ( n ) is divided among the edges of nn 1 , nn 2 ,.., nn is the incoming flow of any X' derived under adj X i.e. possible node that can generate a superset itemset with identical support. So all of the nodes between the current node, where the itemset is generated, and the farth est node w.r.t. the itemset (excluding the farthest nod e itself) can be ignored. Using this theorem, we can identify the set of nodes that can possibly generate a superset itemset with an identical support for a given itemset X, derived under node n , as: GEN X ( n )= { m  X  set of nodes | Farthest-Node X ( n ) p m and  X  items j of X, j  X  prefix 2-items( m )}. Corollary 1 : Let X be an itemset, t be the farthest node of X and X' be the itemset derived under node t, s. t. X'  X  X. Then the next possible node t' that can generate a superset itemset with identical support to X is the node k = Farthest-Node X' (t) if k  X  GEN X (n). Otherwise t' is the immediate node that precede t and  X  GEN X (n). GEN X ( n ), it requires us to completely generate the bit vector for each local closed itemset under consider ation. In practice this is not very profitable. So, here w e design an efficient technique that will examine only the n odes in GEN X ( n ) and avoid complete regeneration of bit vectors at each node. itemset X , generated under node n , we visit each node in GEN X ( n ) until we determine its global closedness. Once we visit a node k  X  GEN X ( n ), we can generate the itemset Xk using its bit vector database and compare the supp ort count with X . Here we have used two observations in designing this technique: itemset X cannot have a superset itemset in a node k  X  GEN X ( n ) with an identical support. So, when checking the superset of the itemset X= {i 1 , i 2 , ...,i k node n under node k  X  GEN X ( n ), we first select item n and i 1 , and generate the bit vector by intersecting the corresponding bit vectors in node k . If  X  ( ni 1 ) &lt;  X  ( X ) then node k cannot generate itemset X and we stop processing that node immediately. Otherwise, we intersect each item  X  X in that order, until we determine whether itemset X can be generated by node k with an identical support count. employed here. We found temporal locality property that can be exploited during the subsequent generation o f itemsets in a node. In order to facilitate fast sub sequent itemset generation, we keep the bit vectors of the most common subsets of the itemset, once they have been generated under a node for reuse. Here we keep in memory a 2-bits wide bit vector for each node that needs to be checked. The first 1-bit wide vector always s aves the bit vector of itemset ( ni 1 ). In the second bit vector, we keep the bit vector of the most frequent items. For example, if the itemsets that come to a node k are { abcden }, { abdfn }, and { abcdgn }, we keep { abdn } in the second bit vector. So, if another itemset, say { abdmn }, needs to be checked under node k , we can directly use the bit vector of { abdn }. We found this technique to be very profitable. efficient because of the following reasons: first o ur bit vectors are shorter in length, so that intersection is fast. Second, we keep track of the bit vectors of most co mmon itemsets in memory, which avoids complete regenerat ion. Third and more importantly, after applying Theorems 2-4, the remaining percentage of itemsets that needs global closedness is much smaller. We have analyzed this i n Section 4. algorithm for frequent closed itemset mining. Algorithm 2 ( PGMiner ) Input : PrefixGraph structure G and support threshold Output : The complete set of frequent closed itemsets Method : Procedure MineNode ( n ) 3.3.1 Implementation Techniques . The input database format used by our algorithm is in horizontal representation, where database is arranged as a set of rows with each row representing a transaction in te rms of set of items. Internally we convert each transactio n to bit vectors and construct the bit vector DB for each no de as described earlier. need a fast method to count the support of an items et represented by the bit vector (i.e. number of 1 X  X ). We use a lookup table to store the number of 1 X  X  of each 1 6-bit value for all 2 16 possible 16-bit values. For example, 16 bit value of  X 5 X  has 2 ones,  X 25 X  has 3 ones and  X 1 0,000 X  has 5 ones. Also, when intersecting bit vectors we intersect word (32 bits in most architectures) by w ord. Once a word is intersected its support count is determined from the lookup table. 3.3.2 Memory Management. In this algorithm, we always start mining from the node with the highest support count i.e. node mining order is from left t o right. Once all the closed itemsets of a node is discovere d, we can safely remove the bit vector DB and reclaim mem ory space. As shown by Figure 4, bit vectors of middle nodes are in general wider and therefore take more memory space in subsequent mining. So reclaim of memory fr om the earlier nodes facilitates efficient memory util ization. environment used to execute our algorithms and the results obtained existing state of the art algorithms in each of the 3 data representation categories discussed in Section 1. I n the vertical TID-list category, we chose CHARM [12], which uses the DiffSet [11] technique to efficiently compress the database. In the vertical bit-vector category, we chose the DCI-Close [5] algorithm. In the FP-Tree category, we chose the FPclose [2] algorithm, which is a faster algorithm compared to CLOSET [9] and CLOSET + [10] under the same category. FPclose and DCI-Close implementations are obtained from FIMI repository  X  while CHARM implementation with DiffSets is obtained from its author. synthetic databases as shown in Table 3. The Medical database contains claims and diagnoses for patients and their prescribed medicine. All other real-world dat abases were obtained from FIMI repository. Synthetic databases were generated using the IBM Quest synthetic data generator [4]. Pentium 4 processor with 1 GB of memory running Linux . All recorded execution times refer to real time, which includes CPU time and I/O time. 4.2.1 Performance Comparisons . Execution time comparison of PGMiner against other algorithms is shown in Figure 7. When an algorithm took considera bly longer time compared to the rest, it was eventually terminated. (Also, run time of CHARM for WebDocs and kosarak datasets could not be recorded, as we had some runtime problems with CHARM ). databases tested, PGMiner shows the best runtime when compared to all other algorithms at low support thresholds. For the remaining two databases ( Chess , and Pumsb ), although PGMiner outperforms both FPclose and CHARM , DCI-Close shows better runtime. This is because their search space enumeration method seems better suited for these smaller databases. We found that in some cases all other algorithms fail to mine dat abases at low support thresholds, while PGMiner can still run for even smaller levels of support thresholds. performance because it has very low overhead due to the effectiveness of its flow based pruning strategies. Unlike other algorithms, PGMiner does not need to store the entire result set in memory. The PrefixGraph structure also has shorter bit vectors and this significantly reduces the bit vector intersection cost for large database s. Thus, PGMiner has better runtime and can scale to very lower levels of support thresholds. 4.2.2 Memory Usage . The memory usage for all the algorithms on several databases is shown in Figure 8. We found that PGMiner mines all of the databases with low memory usage when compared with the other algorithm s. In all these cases, FPclose shows higher memory consumption because of its storage based pruning strategy and the large FP-Tree structure it has to build for larger databases. However, DCI-Close shows better memory usage when compared with FPclose and CHARM . But in some cases (e.g. T40I10D100K ), its memory consumption gets suddenly high when the threshold is gradually lowered. Note that the memor y usage of PGMiner does not grow quite as rapidly as other algorithms during the mining process. 4.2.3 Scalability . We have also measured the execution time of all the algorithms by increasing the number of transactions gradually. We use the T50I10DxK data s et, where x is varied from 25,000 transactions (DB size 6.9MB) to 50 million transactions (DB size 13.9GB), with minimum support threshold 0.1%. When experimenting with these databases we used a server (2 GHz) with 4GB of memory, since these databases are of gigabyte size. Execution time for all of the algori thms is shown in Figure 9. The experimental results reveale d that CHARM , FPclose , and DCI-Close could not reach more than 1 million transactions (1000K) of this databas e set. FPclose and DCI-Close crashed for the T50I10D5000K dataset, and CHARM did not finish even after 2 hours. Analysis of memory usage for these algorithms revea led that they consume high memory space. In the 5000K dataset, the FPclose algorithm fails because it has consumed all the available memory space and it was killed by the system when trying to allocate more memory. See Figure 10. Memory consumption of DCI-Close is remarkably high even for the 1000K dataset, and it was also killed by the system when trying to all ocate a larger block in the 5000K case. Note that PGMiner was able to reach 50 million transactions easily showin g remarkably low memory usage. As shown in Figure 9, PGMiner shows impressive scalable performance when mining larger databases. 4.2.4 Effectiveness of the Flow Based Pruning. In our algorithm, when a local closed itemset is discovere d, we first apply Theorem 2 and then if it cannot discove r the closedness of the itemset, we apply Theorem 3. In T able 4 we have shown the percentage of itemsets discover ed by both these theorems. discover 94.1% of the total local closed itemsets a s either globally closed or not by using Theorem 2. From the remaining percentage (i.e. 5.9%), 85.4% of itemsets were discovered by Theorem 3. Table 4 clearly shows that both Theorem 2 and Theorem 3 are capable of detecti ng global closedness of many local closed itemsets of the database. Moreover, these two techniques can be eas ily implemented and it is one of the key factors to ach ieve faster performance in our algorithm. introduced by Agrawal et al. in [6]. Since then a n umber of efficient algorithms for mining frequent itemset s has been proposed [3, 14, 15]. A popular algorithm is t he Apriori algorithm [6]. However one of the major drawbacks of this algorithm is that it requires mak ing several passes over the database. As an alternative , tree projection algorithms [3, 13], where transactions i n the database are projected to a lexicographic tree, wer e proposed. FP-Tree [3] is one such algorithm, which creates a compact tree structure and applies partit ioned-based, divide &amp; conquer method for mining. address the issue of redundancy in frequent itemset s. The concept of frequent closed itemsets was introduced by Pasquier et al. [16]. A level wise algorithm called A-Close [16] was developed by Pasquier et al. which employs a breadth first strategy for mining frequen t closed itemsets. Since A-Close must scan the database several times, its performance is quite poor compar ed to other algorithms on large databases. Algorithms suc h as CLOSET [8] and CLOSET+ [10] are based on the FP-Tree structure. These algorithms use a mining techn ique based on recursive conditional projection of the FP -Trees. Non-closed itemsets are pruned using subset checking with the previously mined result set. Howe ver this requires all the closed itemsets previously di scovered to be present in memory. Hence the memory usage of these algorithms depends on the number of frequent closed itemsets. CLOSET + introduces a new duplicate itemset detection technique X  X pward checking that is suitable for handling sparse data sets more efficie ntly. FPclose [2] is another algorithm that is based on the FP-Tree structure and use arrays to efficiently traver se the FP-Tree structure, thereby gaining significant time savings compared to CLOSET and CLOSET +. FPclose also uses multiple conditional FP-trees for checkin g the closure of itemsets and achieves better speedup compared to CLOSET +, which uses a global tree structure for this task. in [12], uses a vertical TID representation. For de nse databases, it uses a dual itemset-tidlist search tr ee and adopts the Diffset technique [11] to store the itemset-tidlist at each node of the tree. Several alternati ve algorithms employ the vertical bit vector represent ation to store the database in a condensed manner. MAFIA [1], DCI-Close [5] are key algorithms in this category. Although they show good performance when mining smaller databases, the length of the bit vector is quite high for large databases. Also, for sparse database s the bit vectors contain mostly zeros and these algorith ms spend a lot of time intersecting these regions. To reduce these costs MAFIA uses compressed vertical bit map structures. Also, DCI-Close adopts many optimization techniques to reduce the number of bit wise interse ctions. DCI-Close use closure operation for generating closed itemsets. This technique completely enumerates clos ed itemsets without duplication and needs no previousl y mine closed itemsets. for mining frequent closed itemsets. The key advant age of our representation is that it leverages the posi tive aspects from both FP-tree and vertical bit vector representations. The size of the PrefixGraph structure is quite moderate and its memory requirements do not g row as rapidly as other algorithms. Our proposed algori thm called PGMiner employs several effective itemset pruning strategies derived from network flow analys is. These strategies can be adapted to other existing algorithms (such as CLOSET [8]) that use projected databases to prune their non-closed itemsets. to mine even larger databases measured in billions of transactions using the secondary memory. The PrefixGraph representation appears to be promising for this domain because it decomposes the overall probl em into multiple sub problems and has a compact bit-ve ctor structure. Implementing the inter-node pruning stra tegies in this domain without incurring substantial I/O ov erhead is one of the key challenges that needs to be addre ssed. providing the source code of the CHARM algorithm. Thanks also go to the authors of the FPclose and the DCI-Close algorithms for sharing their source codes with us. We are grateful to Michael Zaroukian and Henry Barry from the college of Human Medicine at MSU for providing us anonymized medical database. 
