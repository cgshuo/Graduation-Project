 Collaborative Filtering aims to predict user tastes, by min-imising the mean error produced when predicting hidden user ratings. The aim of a deployed recommender system is to iteratively predict users X  preferences over a dynamic, growing dataset, and system administrators are confronted with the problem of having to continuously tune the pa-rameters calibrating their CF algorithm. In this work, we formalise CF as a time-dependent, iterative prediction prob-lem. We then perform a temporal analysis of the Netflix dataset, and evaluate the temporal performance of two CF algorithms. We show that, due to the dynamic nature of the data, certain prediction methods that improve predic-tion accuracy on the Netflix probe set do not show similar improvements over a set of iterative train-test experiments with growing data. We then address the problem of parame-ter selection and update, and propose a method to automat-ically assign and update per-user neighbourhood sizes that (on the temporal scale) outperforms setting global parame-ters.
 Categories and Subject Descriptors: H.3.3 Information Search and Retrieval: Information Filtering General Terms: Algorithms Keywords: Temporal Collaborative Filtering.
Recommender Systems (RSs), based on Collaborative Fil-tering (CF), are becoming important portals via which users interact with online web sites. The core problem of CF is often reduced to one of prediction , and research in this field thus aims to optimise performance based on a mean error metric [1] -by testing on a partitioned dataset of user ratings. However, deployed implementations of these algo-rithms operate in a rather different setting. The dataset is dynamic: the user base and number of ratings grow over time, and the system will need to be iteratively updated. A growing dataset leads to changing features of the ratings; both global and user statistics derived from CF data (and often used to predict ratings) change over time. We illus-trate many of the changes that the Netflix data 1 is subject to over time in Figure 1. The top-left plot shows the nor-http://www.netflixprize.com Figure 1: The Netflix Data Changes Over Time: Growth of Number of Movies &amp; Users, and Changes in the Rating Mean, Variance, Mode malised near-linear growth of the number of movies over time, compared to the exponential growth of users. The remaining plots reflect how these changes influence the rat-ings: the global rating mean, variance, and mode vary as well. Consequently, static parameters may not always be optimal, and system administrators are required to contin-uously tune their algorithms for best performance. The aim of a recommender system is thus to continuously anticipate the behaviour of its users with a changing dataset; however, the algorithms applied in this context are not designed to adapt to meet the changes they will experience.

In this work, we extend CF evaluation to gain insight into the temporal performance of these algorithms as they are iteratively applied. We formalise CF as a time-dependent prediction problem and evaluate the bias model described by Potter [2] and the k -Nearest Neighbour algorithm [3] with a series of iterative experiments, to highlight the influence of changing data on prediction. Using this evaluation, we propose and evaluate adaptive temporal CF, a method of temporally adapting the size of user k NN neighbourhoods based on the performance measured up to the current time. Figure 2: Time-Averaged RMSE for k NN &amp; Bias Algorithm (left), Adaptive-k NN (right) We used 5 subsets of 60 , 000 users of the Netflix data. Starting at time = 500 days from the first rating in the dataset, the RS is updated at every  X  = 7 days. At each time t , based on all ratings input prior to t , we aim to predict any ratings that will be input before time ( t +  X  ). Time t is then incremented by  X  and the process is repeated; our data allows for 250 temporal updates. This set up implies that, due to the temporal structure of the data, both the number of historical ratings and ratings predicted in ( t +  X  ) will grow as t increases. We pruned each test set of any user-item pairs that have a history less than h = 1 (whether it be that the user has rated or the movie has been rated fewer than h times) in order to avoid testing extreme cold-start behaviour. This way, we aim to test CF algorithms on a wide range of dataset sizes and highlight the temporal performance of these algorithms.

We visualise the results using a time-averaged RMSE met-ric, or simply the RMSE achieved on all predictions made up to t . We plot the k NN and bias model cross-validated time-averaged RMSE results in Figure 2 (left). On the right hand part of the plot, the results (in descending order) are k = 20 , 35 , 50, and the bias model, which achieves the low-est RMSE. However, on the left hand side of the plot, the ordering of models is not the same: viewing the temporal results emphasises the difficulty of identifying one algorithm that consistently outperforms all others. For example, the bias model is the most accurate in two-thirds of the updates, while in the other cases the k NN model is more accurate. Temporal performance itself varies: after the 50 th update predictive accuracy wanes, highlighting the dependence that these methods have on the quality of the data they train on. From these results, k = 50 emerges as the most temporally accurate k NN parameter. However, we also explored how prediction error is distributed across a community of indi-viduals by splitting users into groups according to profile size and plotting the group X  X  5-fold cross-validated time-averaged performance. The k value performance in the group with fewer than 10 ratings is the opposite of what we observed when all groups were merged: larger neighbourhoods leads to less accurate results. In fact, there is often no consensus between the method that produces the best global perfor-mance and that which best suits each user .
The above experiments highlight how CF does not modify its behaviour based on how well it is performing over time, and, in particular, no single model will consistently outper-fom all others. However, switching between models may add intractable complexity to the scalability of CF, as it would require multiple independent models to be run on the data at each update. In this work, we therefore experiment with temporal-adaptivity that sets the k parameter for the next system update based on selecting, for each user, the parame-ter that would have most improved current performance. We select k from subset of potential values P = { 0 , 20 , 35 , 50 } . A k = 0 value disregards neighbourhoods completely; in this case we can either return a baseline item ( b i ) or user ( b u ) mean rating. We then proceed to set a value k u,t  X  P for each user u at time t . When new users enter the system, their k u,t value is bootstrapped to a pre-determined member of P . At each time step t , all users u have a corresponding error value e u,t denoting the time-averaged RMSE achieved on the predictions made to date on their profile . The idea is for each k u, ( t +  X  ) to be set to that which would have provided the steepest improvement on the users X  e u,t value in the last time step. We therefore aim to optimise the per-user k value by selecting the parameter that would have maximised the improvement on the current error: The time-averaged RMSE results are shown in the rightmost plot of Figure 2, compared to the results of the best global parameter setting ( k = 50). The results highlight a number of benefits of adaptive CF. The adaptive strategy at first ri-vals the performance of k = 50, but then improve the overall time-averaged RMSE without requiring any manual param-eter tuning. In particular, the user-adaptivity component of the strategy shows its effect since the results approximate or improves over simply selecting the best overall parameter. The improved accuracy of adaptive-k NN comes at little cost: computing predictions remains the same, since, for example, the computations for both the k = 20 and 35 predictions for a user-item pair are contained within those required to com-pute with k = 50.
This work departs from traditional CF research by extend-ing the analysis of prediction performance to incorporate a sequence of classification iterations that learn from a grow-ing set of ratings. We then implemented and evaluated a cheap method that automatically tunes parameters to pro-vide greater temporal accuracy. Due to limited space, we point the reader to [4] for full details 2 , results, and discus-sion of this work.
Available at http://www.cs.ucl.ac.uk/staff/n.lathia
