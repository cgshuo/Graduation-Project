 The abstraction of Markov random field (MRF) allows one to utilize graphical representation to capture inter-dependencybetween large number of random variables in a succinct manner. The MRF based models have been utilized successfully in the context of coding (e.g. the low density parity check code [15]), statistical physics (e.g. the Ising model [5]), natural language processing [13] and image processing in computer vision [11,12, 19]. In most applications, the primary inference question of interest is that of finding maximum a posteriori (MAP) solution  X  e.g. finding a most likely transmitted message based on the received signal.
 Related Work. Computing the exact MAP solution in general probabilistic models is an NP-hard problem. This had led researchers to resort of fast approximate algorithms. Various such algorith-mic approaches have been developed over more than the past three decades. In essence, all such approaches try to find a locally optimal solution of the problem through iterative procedure. These  X  X ocal update X  algorithms start from an initial solution and proceed by making a series of changes which lead to solutions having lower energy (or better likelihood), and hence are also called  X  X ove making algorithms X . At each step, the algorithms search the space of all possible local changes that can be made to the current solution (also called move space), and choose the one which leads to the solution having the highest probability or lowest energy.
 One such algorithm (which has been rediscovered multiple times) is called Iterated Conditional Modes or ICM for short. Its local update involves selecting (randomly or deterministically) a vari-able of the problem. Keeping the values of all other variables fixed, the value of the selected variable is chosen which results in a solution with the maximum probability. This process is repeated by se-lecting other variables until the probability cannot be increased further.
 The size of the move space is the defining characteristic of any such move making algorithm. A large move space means that more extensive changes to the current solution can be made. This makes the algorithm less prone to getting stuck in local minima and also results in a faster rate of convergence. Expansion and Swap are move making algorithms which search for the optimal move in a move space of size 2 n where n is the number of random variables. For energy functions composed of metric pairwise potentials, the optimal move can be found in polynomial time by minimizing a submodular quadratic pseudo-boolean function [3] (or solving an equivalent minimum cost st-cut problem).
 The last few years have seen a lot of interest in st-mincut based move algorithms for energy mini-mization. Komodakis et al. [9] recently gave an alternative interpretation of the expansion algorithm. They showed that expansion can be seen as solving the dual of a linear programming relaxation of the energy minimization problem. Researchers have also proposed a number of novel move en-coding strategies for solving particular forms of energy functions. Veksler [18] proposed a move algorithm in which variables can choose any label from a range of labels. They showed that this move space allowed them to obtain better minima of energy functions with truncated convex pair-wise terms. Kumar and Torr [10] have since shown that the range move algorithm achieves the same guarantees as the ones obtained by methods based on the standard linear programming relaxation. A related popular algorithmic approach is based on max-product belief propagation (cf. [14] and [22]). In a sense, it can be viewed as an iterative algorithm that makes local updates based optimizing based on the immediate graphical structure. There is a long list of literature on understanding the conditions under which max-product belief propagationalgorithm find correct solution. Specifically, in recent years a sequence of results suggest that there is an intimate relation between the max-product algorithm and a natural linear programming relaxation  X  for example, see [1,2,8,16,21]. We also note that Swendsen-Wang algorithm (SW) [17], a local flipping algorithm, has a philosophy similar to ours in that it repeats a process of randomly partitioning the graph, and computing an assignment. However, the graph partitioning of SW is fundamentally different from ours and there is no known guarantee for the error bound of SW.
 In summary, all the approaches thus far with provable guarantees for local update based algorithm are primarily for linear or more generally convex optimization setup.
 Our Contribution. As the main result of this paper, we propose a randomized iterative local al-gorithm that is based on simple local updates. The algorithm, starting with an arbitrary initial as-signment, updates it in each iteration by first picking a random node, then its (appropriate) random local neighborhood and optimizing over this local neighborhood. Somewhat surprisingly, we show that this algorithm finds near optimal assignment within n log 2 n iterations with high probability for graphs with geometry  X  i.e. graphs in which the neighborhood of each node within distance r grows no faster than a polynomial in r . Such graphs can have arbitrarily structure subject to this poly-nomial growth structure. We show that the approximation error depends gracefully on the average random radius of the local neighborhood and degree of polynomial growth of the graph. Overall, our algorithm can provide an  X   X  approximation MAP with C (  X  ) n log 2 n total computation with C (  X  ) depending only on  X  and the degree of polynomial growth. The crucial novel feature of our algo-rithm is the appropriate selection of random local neighborhood rather than deterministic in order to achieve provable performance guarantee.
 We note that near optimality of our algorithm does not depend on convexity property, or tree-like structure as many of the previous works; but only relies on geometry of the graphical structure which is present in many graphical models of interest such as those arising in image processing, wireless networks, etc.
 We use our algorithm to verify its performance in simulation scenario. Specifically, we apply our algorithm to two popular setting: (a) a grid graph based pairwise MRF with varying node and edge interaction strengths, and (b) a grid graph based MRF on the weighted independent set (or hardcore) model. We find that with very small radius (within 3), we find assignment which within 1% ( 0 . 99 factor) of the MAP for a large range of parameters and upto graph of 1000 nodes. Organization. We start by formally stating our problem statement and main theorem (Theorem 1) in Section 2. This is followed by a detailed description of the algorithm in Section 3. We present the sketch proof of the main result in Section 4. Finally, we provide a detailed simulation results in Section 5. We start with the formal problem description and useful definitions/notations followed by the state-ment of the main result about performance of the algorithm. The algorithm will be stated in the next section.
 Definitions &amp; Problem Statement. Our interest is in a pair-wise MRF defined next. We note that, formally all (non pair-wise) MRFs are equivalent to pair-wise MRFs  X  e.g. see [20].
 Definition 1 (Pair-wise MRF) . A pair-wise MRF based on graph G =( V, E ) with n = | V | vertices and edge set E is defined by associated a random variable X v with each vertex v  X  V taking value in finite alphabet set  X  ; the joint distribution of X =( X v ) v  X  V defined as where  X  v : X   X  R + and  X  uv : X  2  X  R + are called node and edge potential functions. 1 In this paper, the question of interest is to find the maximum a posteriori (MAP) assignment x  X   X   X  n , i.e. Equivalently, from the optimization point of view, we wish to find an optimal assignment of the problem where For completeness and simplicity of exposition, we assume that the function H is finite valued over  X  n . However, results of this paper extend for hard constrained problems such as the hardcore or independent set model.
 In this paper, we will design algorithms for finding approximate MAP problem. Specifically, we call an assignment x as an  X  -approximate MAP if Graphs with Geometry. We define notion of graphs with geometry here. To this end, a graph G =( V, E ) induces a natural  X  X raph metric X  on vertices V , denoted by d G : V  X  V  X  R + with d
G ( v, u ) as the length of the shortest path between u and v ; with it defined as  X  if there is no path between them.
 Definition 2 (Graph with Polynomial Growth) . We call a graph G with polynomial growth of degree (or growth rate)  X  , if for any v  X  V and r  X  N , where C&gt; 0 is a universal constant and B G ( v, r )= { w  X  V | d G ( w, v ) &lt;r } . A large class of graph model naturally fall into the graphs with polynomial growth. To begin with, the standard d -dimensional regular grid graphs have polynomial growth rate d  X  e.g. d =1 is the line graph. More generally, in recent years in the context of computational geometry and metric embedding, the graphs with finite doubling dimensions have become popular object of study [6,7]. It can be checked that a graph with doubling dimension  X  is also a graph with polynomial growth rate  X  . Finally, the popular geometric graph model where nodes are placed arbitrarily on a two dimensional surface with minimum distance separation and two nodes have an edge between them Statement of Main Result. The main result of this paper is a randomized iterative algorithm based on simple local updates. In essence the algorithm works as follows. It starts with an arbitrary initial assignment. In each iteration, it picks a node, say v from all n nodes of V , uniformly at random and picks a random radius Q (as per specific distribution). The algorithm re-assigns values to all nodes within distance Q of node v with respect to graph distance d G by finding the optimal assignment for this local neighborhood subject to keeping the assignment to all other nodes the same. The algorithm L OC -A LGO described in Section 3 repeats this process for n log 2 n many times. We show that L OC -A LGO finds near optimal solution with high probability as long as the graph has finite polynomial growth rate.
 Theorem 1. Given MRF based on graph G =( V, E ) of n = | V | nodes with polynomial growth rate  X  and approximation parameter  X   X  (0 , 1) , our algorithm L OC -A LGO with O (log(1 / X  ) n log n ) iterations produces a solution x such that And each iteration takes at most  X  (  X ,  X  ) computation, with where K (  X ,  X  ) is defined as In a nutshell, Theorem 1 say that the complexity of the algorithm for obtaining an  X  -approximation scales almost linearly in n , double exponentially in 1 / X  and  X  . On one hand, this result establishes that it is indeed possible to have polynomial (or almost linear) time approximation algorithm for arbitrary pair-wise MRF with polynomial growth. On the other hand, though theoretical bound on the pre-constant  X  (  X ,  X  ) as function of 1 / X  and  X  is not very exciting, our simulations suggest (see Section 5) that even for hard problem setup, the performance is much more optimistic than predicted by these theoretical bounds. Therefore, as a recommendation for a system designer, we suggest use of smaller  X  X adius X  distribution in algorithm described in Section 3 for obtaining good algorithm. In this section, we provide details of the algorithm intuitively described in the previous section. As chosen arbitrarily. Iteratively, at each step a vertex v  X  V is chosen uniformly at random along with a random radius Q that is chosen independently as per distribution Q . Then, select R X  V , the local Then while keeping the assignment of all nodes in V \R fixed as per x =( X  x v ) v  X  V , find MAP assignment x  X  , R restricted to nodes of R . And, update the assignment of nodes in v  X  X  as per x  X  , R . A caricature of an iteration is described in Figure 1. The precise description of the algorithm is given in Figure 2.
 In order to have good performance, it is essential to choose appropriate distribution Q for selection of random radius Q each time. Next, we define this distribution which is essentially a truncated Geometric distribution. Specifically, given parameters  X   X  (0 , 1) and the polynomial growth rate  X  (with constant C ) of the graph, define  X  =  X  5 C 2  X  , and Then, the distribution (or random variable) Q is defined over integers from 1 to K (  X ,  X  ) as L
OC -A LGO (  X , K ) In this section, we present proof of Theorem 1. To that end, we will prove the following Lemma. Lemma 1. If we run the L OC -A LGO with (2 n ln n ) iterations, with probability at least 1  X  1 /n ,we have From Lemma 1, we obtain Theorem 1 as follows. Define T = 2 log(1 / X  ) , and consider L OC -A
LGO with (2 Tn ln n ) iterations. From the fact that H ( x  X  )  X  H ( x )  X  0 , and by the Markov inequality applied to H ( x  X  )  X  H ( x ) with Lemma 1, we have that after (2 n ln n ) iterations, Note that (2) is true for any initial assignment of L OC -A LGO . Hence for each 1  X  t  X  T , after (2 tn ln n ) iterations, (2) holds independently with probability 1  X  1 /n . Also, note that H ( x ) is 1.
 For the total computation bound in Theorem 1, note that each iteration of L OC -A LGO involves dynamic programming over a local neighborhood of radius at most K = K (  X ,  X  ) around a node. This involves, due to the polynomial growth condition, at most CK  X  nodes. Each variable can takes at most |  X  | different values. Therefore, dynamic programming (or exhaustive search) can take at most |  X  | CK  X  operations as claimed.
 Proof of Lemma 1. First observe that by the standard argument in the classical coupon collector problem with n coupons (e.g. see [4]), it follows that after 2 n ln n iterations, with probability at least 1  X  1 /n , all the vertices of V will be chosen as  X  X all centers X  at least once. Error bound. Now we prove that if all the vertices of V are chosen as  X  X all centers X  at least once, the answer x generated by L OC -A LGO after 2 n ln n iterations, is indeed an  X  -approximationon average. To this end, we construct an imaginarily set of edges as follows. Imagine that the procedure (2) of L
OC -A LGO is done with an iteration parameter t  X  Z + . Then for each vertex v  X  V, we assign the largest iteration number t such that the chosen ball R at the iteration t contains w . That is, Now define an imaginary boundary set of L OC -A LGO as Now consider graph G =( V, E \B ) obtained by removing edges B from G . In this graph, nodes of the same connected component have same T (  X  ) value. Next, we state two Lemmas that will be crucial to the proof of the Theorem. Proof of Lemmas 2 and 3 are omitted.
 Lemma 2. Given two MRFs X 1 and X 2 on the same graph G =( V , E ) with identical edge po-Lemma 3. Given MRF X defined on G (as in (1) ), the algorithm L OC -A LGO produces output x such that where B is the (random) imaginary boundary set of L OC -A LGO ,  X  U ij max  X , X   X   X   X  ij (  X ,  X  ) , and  X  Now we obtain the following lemma that utilizes the fact that the distribution Q follows a geometric distribution with rate (1  X   X  )  X  its proof is omitted.
 Lemma 4. For any edge e  X  E of G , From Lemma 4, we obtain that Lemma 5. If G has maximum vertex degree d  X  , then Now recall that the maximum vertex degree d  X  of G is less than 2  X  C by the definition of poly-nomially growing graph. Therefore, by Lemma 3, (3), and Lemma 5, the output produced by the L
OC -A LGO algorithm is such that where recall that  X  =  X  5 C 2  X  . This completes the proof of Lemma 1. Our algorithm provides a provable approximation for any MRF on a polynomially growing graph. In this section, we present experimental evaluations of our algorithm for two popular models: (a) synthetic Ising model, and (b) hardcore (independent set) model. As a reader will notice, the ex-perimental results not only conform the qualitatively behavior proved by our theoretical result, but it also suggest that much tighter approximation guarantees should be expected in practice compared to what is guaranteed by theoretical results.
 Setup 1 2 Consider a binary (i.e.  X = { 0 , 1 } ) MRF on an n 1  X  n 2 grid G =( V, E ) : We consider the following scenario for choosing parameters (with the notation U [ a, b ] for the uni-form distribution over the interval [ a, b ] ): Figure 3: (A) plots the error of local update algorithm for a random Ising model in the grid graph of size 10  X  10 , and (B) plots the error in the grid of size 100  X  10 .
 To compare the effectiveness of our algorithm for each size of the local updates, in our simulation, we fix the square size as a constant instead of choosing it from a distribution. We run the simulation single vertex. We computed an exact MAP assignment x  X  by dynamic programming, and computed for n 1  X  n 2 grid graph. Then compare the error as follows: We run the simulation for 100 trials and compute the average error for each case. The Figure 3(A) plots the error for the grid of size 10  X  10 , while Figure 3(B) plots the error for the grid of size 100  X  10 . Remind that the approximation guarantee of Theorem 1 is an error bound for the worst case. As the simulation result suggests, for any graph and any range of  X  , the error of the local update algorithm decreases dramatically as r increases. Moreover, when r is comparably small as r =3 , the output of the local update algorithm achieves remarkably good approximation. Hence we observe that our algorithm performs well not only theoretically, but also practically.
 Setup 2. We consider the vertex weighted independent set model defined on a grid graph. To this end, we start by description of a weighted independent set problem as the MRF model. Specifically, consider a binary MRF on an n 1  X  n 2 grid G =( V, E ) : Here, the parameters are chosen as follows. For each graph, we computed the average error as in the Setup 1, over 100 trials. The result is shown in the following table. As the result shows, our local update algorithm achieves remarkably good approximation of the MAP or equivalently in this setup the maximum weight independent set, even with very small r values ! It is worth nothing that choosing  X  i from U [0 , X  ] for any  X &gt; 0 will give the same approximation result, since x  X  and x are both linear on  X  . We considered the question of designing simple, iterative algorithm with local updates for finding MAP in any pair-wise MRF. As the main result of this paper, we presented such a randomized, local iterative algorithm that can find  X  -approximate solution of MAP in any pair-wise MRF based on G within 2 n ln n iterations and the computation per iteration is constant C (  X ,  X  ) dependent on the accuracy parameter  X  as well as the growth rate  X  of the polynomially growing graph G . That is, ours is a local, iterative randomized PTAS for MAP problem in MRF with geometry. Our results are somewhat surprising given that thus far the known theoretical justification for such local algorithms strongly dependended on some form of convexity of the  X  X nergy X  function. In contrast, our results do not require any such condition, but only the geometry of the underlying MRF. We believe that MRF based modeling and inference in practice have the underlying graphical structure possessing some form of geometry naturally. [1] M. Bayati, D. Shah, and M. Sharma. Maximum weight matching via max-product belief [2] M. Bayati, D. Shah, and M. Sharma. Max-Product for Maximum Weight Matching: Conver-[3] Y. Boykov, O. Veksler, and R. Zabih. Fast approximate energy minimization via graph cuts. [4] William Feller. An Introduction to Probability Theory and Its Applications . Wiley, 1957. [5] Hans-Otto Georgii. Gibbs measures and phase transitions . Walter de Gruyter, 1988. [6] A. Gupta, R. Krauthgamer, and J.R. Lee. Bounded geometries, fractals, and low-distortion [7] S. Har-Peled and M. Mendel. Fast construction of nets in low dimensional metrics, and their [8] B. Huang and T. Jebara. Loopy belief propagation for bipartite maximum weight b-matching. [9] N. Komodakis and G. Tziritas. A new framework for approximate labeling via graph cuts. In [10] M. Pawan K umar and Philip H. S. Torr. Improved moves for truncated convex models. In [11] Stan Z. Li. Markov Random Field Modeling in Image Analysis . Springer, 2001. [12] M. Malfait and D. Roose. Wavelet-based image denoising using a markov random field a priori [13] Christopher D. Manning and Hinrich Schutze. Foundations of Statistical Natural Language [14] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference . San [15] Thomas Richardson and Ruediger Ubanke. Modern Coding Theory . Cambridge University [16] S. Sanghavi, D. Shah, and A. Willsky. Message-passing for Maximum Weight Independent [17] R. Swendsen and J. Wang. Nonuniversal critical dynamics in monte carlo simulations. Phys. [18] O. Veksler. Graph cut based optimization for mrfs with truncated convex priors. In CVPR , [19] Paul Viola and Michael J. Jones. Robust real-time face detection. International Journal of [20] M. Wainwright and M. Jordan. Graphical models, exponential families, and variational infer-[21] M. J. Wainwright, T. Jaakkola, and A. S. Willsky. Map estimation via agreement on (hy-[22] J. Yedidia, W. Freeman, and Y. Weiss. Generalized belief propagation. Mitsubishi Elect. Res.
