 In [19], Niesler used the distance between two words acting as a trigger-target pair to model the occurrence correlations within a word-category based language model. In this paper, we use  X  heuristic importance  X  X odepicttheimportanceof one page to attract visitors t o access another page. The  X  heuristic importance  X  is measured by computing the distance of their access positions in usage sessions.
The methods to reconstruct sessions are classified into five different stan-dards[15, 6, 21, 10, 11]. These five standards show the difference views on the binary relations of two accessed pages in reconstructing usage sessions. Web us-age patterns are mostly defined on the association rules, sequential patterns and tree structure[2, 5, 6, 12]. Detailed defini tions of different actions performed by visitors are given in [8, 9]. The binary r elationship between every two pages in usage patterns are modelled on the co-occurrence happenings[2], time sequen-tial[2, 5, 6] and structural characteristics [9, 12]. Clustering and classification of users are investigated in [1, 3, 21, 13, 18]. The binary relations between every two pages are computed on conditional possibilities or Markov chains [17], or on the content attributes[7]. We name the required terms in section 2 and give the general clustering method and web site modelling in section 3. We explain the evaluation measurements in section 4 an d discuss our experiments in section 5. Section 6 is a short summary. A page pair is named as Pair ( p trigger ,p target ). The heuristic importance is named as Hr ( p trigger ,p target ). For a page p in a given session s ,weuse Pos p to name the position of this page p in this session.

We improve this distance used in [19] to model the heuristic impor-tance from trigger page to target page. Within a session s ,themutualre- X  Over the session set S , the heuristic importance from p trigger to p target in where S X  is the sub set of S but includes all the sessions in which p trigger was accessed before p target .
 Here we also give the definitions of other methods to model page pairs.
Method 1 (SUP): A page pair is symbolized as two adjacently accessed pages in sessions. Given a session set S, L(S ) represents the corresponding binary page relation set, and I(S) the set reducing all the repeat happenings of the same bi-nary relations in L(S) . The support of the page pair PA = Pair ( p trigger ,p target ) support as the heuristic importance of p trigger to p target .Thismeasurementis widely used in web usage mining [1, 2, 5, 6, 8, 12].

Method 2 (IS): A page pair is symbolized as two adjacently accessed pages in heuristic importance of page p trigger to page p target . This model is also used in computing the mutual information of in model natural language [14].

Method 3 (CS): The heuristic importance is characterized by the conditional named as confidence in data mining and n-Markov chain is widely used in per-sonalized recommendation and adaptive web sites [17]. The clustering method that finds the related page communities from page pairs is introduced in this section. An overview of the algorithm is given in follows: Input: web server usage logs
Output: page clusters 1.Recover sessions from web usage logs, 2.Scan the recovered sessions and build 3.Create the graph from page pairs and find the cliques.

The method to recover sessions for different users has been detailed discussed in [11, 21], individual accessing behaviours are also recovered in this step for further interesting usage pattern mining [9]. In [13], clustering mining method was introduced in the PageGather system.
Web has been modelled by many ways, most of which is based on the graph theory. PageRank[7] and HIT[4] are the two famous methods. Besides the graph model, role-based model was used in [6] and n-Markov was used in many per-sonalized recommendations[17, 21].

We improved the method from HIT[4] to model the page relations within a web site. In this model, a web site is ded icated to several particular topics, and its semantic space can be formed based all the concepts related to these particular topics, and all the concepts are organized as a concept hierarchy. Each page within a web site is given a conc rete numerical definition represented the corresponding sub set of concepts, a nd this numerical weight is computed by weight propagation step by step from the home page, which represents the whole concept set. We call the page that disperse its concept as  X  host  X , and the page that inherits concepts from  X  host  X  as  X  X eceiver X . The weight of one concept w p c from a  X  host  X  is equally divided by all the  X  receives  X  that inherit this concept, and on the other hand, different concepts for a  X  receiver  X  is inherited from different  X  host  X .

Given a page p, its weight wp is computed as: w p = i =1 k p.w c i and p.w c i = n ,where k is the number of different concepts for p , q is the host of p for concept c i , and n is the number of receivers that inherit concept c i from q.
During computing w p for every page, the weight of a concept for a page is reduced with the weight propagation from the home page, so w p represents the importance of its corresponding semantic value from the point web designer. The distribution and propagation of concept weights like our definition are universally observed in the frame work designing of many web sites. We illustrate this model on the content main frame of www.hpi.uni-potsdam.de. There are 67 different pages for the main frame, and they are organized as a tree structure. With the help of automated interface design, among these 67 pages, every two pages are directly connected. This hel ps greatly to reduce the affect of navigation hyperlink for pair analysis. The table 1 shows the weight for some pages. The number of clusters and their average size are the two important measurable criteria for the success of a clustering method, and distinctiveness and coverage are the other two criteria for the quality of clusters. Given a set of M which is built by based on one clustering method, distinctiveness is given by the following equation: Distinctiveness ( M )= | P | k one clusters, and P i is the pages used in i-th cluster, if there is k clusters in M .And coverage is given as: Coverage ( M )= | P | | P | ,where P is the set of pages appearing at least in one cluster, and P is the pages that need to be clustered.

In our scenario, we add another two criteria: semantic dependence and popular-ity . Semantic dependence is defined as: Semantic  X  dependence ( M )= | C | k In the above formula, C is the set of content categories that a web site belongs to, C i is content categories that the i  X  th cluster has, if there is k clusters in M .Weuse the average support of the page pairs appearing in at least one cluster to name the popularity of the clustering model, the popularity of a model M is: Popularity ( M ) in M ,and Pr ( PA i ) is the possibility of page pair PA i over the usage record set.
In [18], Gold standard is named as the expert criter ion in general evaluation method that is used to find  X  X deal solution X  to a problem. The methods to reduce the subjective bias from experts is trying to get as more suitable experts as possible. In web usage mining, the ideal evaluation for a content improving schema is the direct feedback from client sides. But in web applications such direct feedback is uncontrollable. We are pushed to raise three measurements to evaluate usage models: 1. If similar patterns happen in different models, 2. If similar patterns happen in different periods of time, 3. If a model reflects the changes of the content reorganization, We take the content frame from www.hpi.uni-potsdam.de as the improving tar-get, which includes 67 different pages with different URLs. We take two pieces of web logs for clustering page pairs, one is from 01.03.2005 to 31.03.2005, and the other is from 01.04.2005 to 30.04.2005. By fetching the related usage infor-mation of 67 target frame pages, we get 16314 sessions from March, and 18546 from April.
 Here we show the validity of our method by one case study: These three pages have the same semantic importance comput ed as in section 4, because they are linked from the same source page as /lehre.html . This means that these three pages have no bias on the web designer X  X  side. But based on page pairs modeled from usage data, these three pages have some clear bias on heuristic importance.
In the above tow figures, we discriminate the different directions of heuris-tic importance within a page pair by using different lines: the bold line means a higher heuristic importance and the dashed line means a lower heuristic im-portance within the same page pair. From the four page clusters in these two figures, we find P 5 has a higher heuristic importance to P 3 and P 4 than those from P 3 and P 4 to P 5 , which happens in two different period of logs based on two different models. Based on task-orient ed evaluating measur ements in section 6, we can naturally conclude that P 3 &lt;  X  P 5  X  &gt;P 4 is a very useful page cluster and helps for improving content organization. In this paper, we investigate the problem of building content clusters based on modeling page pairs by computing the position distance between source page and target page. Some questions are still open for further investigation, for example, measuring the difference between usage patterns and original web organization.
