 An accurate and comprehensive user modeling technique is crucial for the quality of recommender systems. Tradition-ally, we model user preferences using only actions from the target site and may suffer from cold-start problem. As nowa-days people normally engage in multiple online sites for var-ious needs, we consider leveraging the cross-site actions to improve the user modeling accuracy. Specifically, in this paper we aim at achieving a more comprehensive and ac-curate user modeling by modeling user X  X  actions in multiple aligned heterogeneous sites simultaneously. To do so, we propose a modularized probabilistic graphical model frame-work JUMA. We further integrate topic model and matrix factorization into JUMA for joint user modeling over text-based and item-based sites. We assemble and publish large-scale dataset for comprehensive analyzing and evaluation. Experimental results show that our framework JUMA out performs traditional within-site user modeling techniques, especially for cold-start scenarios. For cold-start users, we achieve relative improvements of 9.3% and 12.8% compar-ing to existing within-site approaches for recommendation in item-based and text-based sites respectively. Thus we draw the conclusion that aligning heterogeneous sites and mod-eling users jointly do help to improve the quality of online recommender systems.
 User Modeling, Recommender System, Graphical Model
To improve user experience and to stimulate user actions, a great portion of online services include a native recom-mender system. Such recommender systems have brought great benefits for both users and service providers. There-fore, there exist plenty research works focusing on this topic. Experiments as well as online applications both prove the success of such systems.

An accurate and comprehensive user modeling technique is crucial for the quality of recommender systems. Tradition-ally, we model user X  X  preferences using actions from the tar-get site. For example, recommending movies based on one X  X  previous movie rating logs. Although the performances of such approaches are satisfying, there are still problems and limitations with these approaches.

A major problem is that existing approaches may fail when dealing with new users due to insufficient historical data. This problem is referred to as the cold-start prob-lem [26]. It widely exists and severely jeopardizes the user X  X  first impression when exposed to the recommender systems. Several works aim at alleviating this problem using side-information [6, 33] or interview processes [8]. However, such approaches require extra efforts from users thus still jeopar-dize the users X  first experiences.

Another limitation of existing techniques is the lack of comprehensiveness. When participating in specialized on-line services, users normally reveal only parts of his prefer-ences. As traditional user models focus only on user actions in the target site, they can only capture the most revealed parts of the user preferences. Although these are the most important parts for future recommendations in the same site, we cannot claim other aspects are irrelevant. For exam-ple, it is hard to mine one X  X  political preferences using only movie rating histories, but such preferences would be helpful when recommending political movies or documentaries.
On the other hand, as the usage of Internet develops, most people now engage in multiple sites for various needs. For example, we have Facebook for maintaining social relations, Twitter for microblogging, and IMDb for movie reviews. By aligning these sites and aggregating user X  X  online actions, we can directly aim at modeling user X  X  underlying general pref-erences instead of site-specific preferences. Following this di-rection, we can achieve comprehensive user preference mod-eling and actually solve the cold-start problem (users only encounter the cold-start problem once when joining his first online site).

The intuition behind this direction is: although the pur-poses and action types vary from site to site, the user X  X  un-derlying preferences remains the same. Every natural per-son has an underlying general preferences that depend on his/her personality, hobbies and personal taste. Such pref-erences do not change with the site the user currently en-gages. We refer such preferences as user X  X  universal prefer-ences in the following of this paper. When participating in a specific site, the user conducts actions based on parts of his universal preferences. Existing works aim at capturing the revealed parts of preferences in that specific site. By aligning the sites together and jointly model the users pref-erences in these sites simultaneously, we can directly capture the user X  X  comprehensive universal preferences. When deal-ing with cold-start scenario where user has only few actions, the preferences learned from other aligned sites can also help to alleviate the problem.

Therefore, in this paper we target at joint user model-ing over multiple aligned sites with heterogeneous actions. Extending within-site user modeling to cross-site joint mod-eling is not a trival task. The major challenge is the het-erogeneity of actions from different sites. To tackle this, we propose a modularized probabilistic graphical model frame-work JUMA. The benefit of modularization is that we can easily plug the state-of-the-art techniques for different types of actions into the framework. The framework achieves great generality and expendability by integrating corresponding modules for different kinds of sites. We discuss how to de-ploy JUMA for modeling text-based and item-based sites in this paper. We target at these types because most online services can be categorized into these two, thus we can cover most use scenarios.

Note that this approach requires the sites to be fully or partially aligned, i.e. alignment between accounts indicating that they belong to the same natural person is known. For-tunately, now most sites allow users to login with cross-site accounts (  X  X ogin with Facebook Account X  ). Researchers also work on how to recover the alignment by analyzing user X  X  profile, social relationship and user generated contents [20, 28]. The state-of-the-art approach achieves an accuracy over 80%. Therefore, the accessibility of such alignment should not be concerned.

The rest of the paper is organized as follows. We first dis-cuss the related works in Section 2. We present the dataset as well as the preliminary analysis in Section 3. We propose out framework JUMA in Section 4, and then report the ex-perimental results in Section 5. Finally, we draw conclusions and propose future works in Section 6.
User modeling is the core of recommender systems. There exist plenty research works in this direction. As the user generated contents (UGC) vary from site to site, researchers propose different user modeling techniques accordingly. Ma-trix factorization technique [15, 22] is widely used for this task, especially for item-based sites such as e-commercial and movie/music rating sites [13, 17]. Zhang et al. proposed an efficient bayesian hierarchical user modeling in [32]. Topic models, such as Latent Dirichlet Allocation [2], are employed for capturing user X  X  topic distributions in text-based sites such as Twitter and Tumblr [7]. There are also works try to leverage social relationships in online social network for improving the quality of user modeling [12, 18].

However, most of existing works tackle each application separately, thus might suffer from cold-start problem and lack of comprehensive user preference due to data insuffi-ciency. Therefore, in this paper we propose joint user mod-eling that model the user over multiple sites simultaneously and targets at improving the modeling precision as well as comprehensiveness.
The cold-start problem is that when giving recommenda-tions to new users who have no or only few historic actions, his/her preferences are not yet revealed to the recommender system. Therefore, the quality of recommendations in these scenarios might be rather poor.

Such problem exists in almost all recommender systems, therefore is of great importance. Researchers propose vari-ous solutions to alleviate this problem [9, 16, 26]. One di-rection is to leverage additional side information to com-pensate the user/item X  X  novelty. Gao et al. address the problem in location-based recommendation using social net-work as the side information [6]. Social tags are employed by Zhang et al. in [33]. Those approaches require specific types of side information for the given user, which may not be always available. Another direction is adding an inter-view process immediately after registration. This is the most widely adopted approach in commercial applications. The fundamental task in this direction is the form of the inter-view process and the questions asked during it. Golbandi et al. use decision trees to adaptively selecting the ques-tions [8]. Functional matrix factorization is also employed for generating interview questions [35]. Nevertheless, these approaches do need the users to manually answer the ques-tions or go through other types of interview process, thus have a negative impact on the user experiences.
The motivation of this paper is to some extent similar with cross-domain recommendation, which is improving user modeling by leveraging historic actions from other sources [5]. However, existing cross-domain approaches mainly focus on homogeneous data. For example, transferring between movies and books [27]. There is also a good fraction of papers target at synthetic multi-domain data generated by subdividing a single-domain dataset [1, 25]. For those sce-narios, different  X  X omains X  actually share a lot in common (action type, user preference, behavior pattern, etc.).
Instead, we aim at user modeling across sites with het-erogeneous actions, which is more challenging and general. There are also works aiming at heterogeneous data. McAuley et al. aim at understanding product ratings with review text in [21]. However, these approaches require aligned actions which is unavailable in the general setting. Also, such ap-proaches can not directly extend to more than two sites.
Although a large portion of online applications now enable users to login or associate with cross-site accounts (Face-book, Twitter, Google+, etc.), there still exist plenty un-aligned users and isolated networks. Therefore, automati-cally aligning the fragmented online social networks is pro-posed as a new topic in recent years. Researchers pro-pose various approaches to tackle this task by mining differ-ent kinds of information. Most works focus on mining the personal identifiable information in profile pages, including username, location, avatar etc. [19, 23, 24]. There are also works leveraging specific types of user generated contents in certain types of networks, for example social tags in tag-ging systems [10]. Liu et al. tackle the task by modeling users X  heterogenous behaviors [20] and achieve a accuracy over 80%.

There are also works aiming at improving existing tasks using aligned networks. For example, Zhang et al. em-ploy the aligned networks to improve the link prediction task [31].
In this section we first explain the data set used in this paper, and then conduct preliminary analysis for better un-derstanding of the user preferences consistency across the aligned heterogeneous sites.
We collect and publish a large-scale data set for analy-sis and evaluation. For data sources we use Douban 1 and Weibo 2 , one of China X  X  largest movie rating sites and mi-croblogging sites respectively. We collect 141,614 randomly selected users who participate in both Weibo and Douban. The account alignments are retrieved from explicit informa-tion in Douban X  X  profile pages. For item-based site Douban, we collect the rating histories for each user. On average each user has 123.49 rating logs. For text-based site Weibo, we collect up to 20 pages of microblogs (both original and re-tweet) for each user. On average each user has 343.78 microblogs. We also publish the dataset online for the re-search community 3 . Ideas and suggestions to extend the dataset are highly welcomed.
The underlying assumption of joint user modeling is that user X  X  preferences are to some extent consistent across sites. Despite its intuitiveness, we analyze on real data to support the assumption.

As user preferences are not explicitly expressed, we can not directly measure the preferences consistency. Fortu-nately, user X  X  action histories serve as explicit indicators of his preferences. Therefore, we show the user action similar-ity consistency instead.

Specifically, we analyze whether users with similar actions in one site are still tend to be similar in the other. We randomly select 5 million pairs of users and evaluate their pairwise similarity in the two sites according to their action histories. To model user similarity in text-based site Weibo, we first employ Latent Dirichlet Allocation (LDA [2]) to model the topic distribution of each user and then use L 1 distance to measure the dissimilarity between users. And for item-based site Douban, we use Jaccard similarity coefficient http://www.douban.com/ http://www.weibo.com/ http://dataset.apexlab.org/juma upon the set of rated movies. Formally: where  X  i  X  is the topic distribution of user i and W i is the set of movies rated by user i . Then we group the pairs with close similarity in the source network (Weibo) to capture the general trend. We report the averaged similarity in the target network (Douban) and show the results in Figure 1. The results indicate that users with similar actions in Weibo also tend to be similar in Douban on average, which support the assumption and indicate the existence of user preference consistency.

To gain further insight of preference consistency across sites, we employ multi-modal topic model to directly capture the relation between topics in Weibo and movies in Douban. Specifically, we consider movies as another set of  X  X ords X  and plug them into the original model. When user watches a movie, he/she first selects a topic according to his/her topic distribution and then chooses the movie according to the topic-movie distribution (corresponding to the topic-word dictionary  X  in traditional model). We depict the graphical model for the multi-modal topic model in Figure 2.
We show the resulting word-dictionary (  X  w ) and movie-dictionary (  X  m ) for some example topics in Table 1. From the results we can notice the hidden correlation between movies and topics in these two sites. For example, first topic indicates users who tweet about pets are more likely to en-joy comedies, cartoons, and the second topic indicates ones interested in political news tend to prefer movies with depth or background stories.
In this section we propose JUMA, a probabilistic graphical model for joint user modeling over multiple aligned sites. We first describe the design of the model in general setting, and then discuss the design details for text-based and item-based sites. Finally we propose a hybrid learning process for the parameter learning.
Probabilistic graphical model is a widely used technique for modeling user actions. For example, topic modeling [2], user preferences [29], social network modeling [11] and etc. The reason behind its popularity is its similarity towards the generation of user actions in real-world and its easiness for interpretation. Therefore, we employ probabilistic graphical model for the joint user modeling task.

The design of the general model mostly follows the as-sumption that user reveals part of his/her universal pref-erences when participating each specific site. We show the general graphical model in Figure 3 (a), which can be inter-preted as follows: Each user i has an universal preference U preference U i based on site-specific transferring model T Finally, user conduct actions A q i base on site-specific pref-erence P q i and site-specific item models {  X  q k } .  X , X  hyper-parameters for the prior.  X  q is the parameter that controls the coupling strength between the site-specific pref-erences and the universal preferences.

We design the universal preference U i to have a multivari-ate Gaussian prior with mean 0 and variance  X  . For the site-specific variables, the model need to be designed accordingly. The item set varies from site to site, e.g. words for text-based sites and music/movie/product for item-based sites. Besides, the plate containing user actions A q i also varies ac-cording to different action types. Therefore, to plug a spe-cific site into JUMA, we need to design the followings in details:
Now we discuss the implementation details of JUMA in the context of modeling item-based and text-based sites. We depict the detailed graphical model of the extended version in Figure 3 (b), where we have two plates for the two sites respectively. We explain the notations we used in Table 2.
To model user actions in the item-based site Douban, we employ Matrix Factorization (MF) technique [15], the most widely used technique for modeling the item rating actions. It captures user preferences and item characteristics with latent factors. Specifically, we can formally define the MF modular for JUMA by:
For text-based site Weibo, we use Latent Dirichlet alloca-tion (LDA) [2] to model the user X  X  topic distribution when writing or retweeting microblogs.
 We first quickly go through the settings of traditional LDA model. For each user, we draw his topic distribu-tion from a Dirichlet distribution with parameter  X  as the non-informative prior (  X  i  X  Dir (  X  )). For each word, we first draw the hidden topic z ij from user X  X  topic distribution ( z ij  X  Multi (  X  i )), and then select the word w ij according to topic-word dictionary  X  z ij . The topic-word dictionary  X  also follows Dirichlet distribution with non-informative prior  X  .

When integrating LDA with JUMA, instead of using non-informative prior for the user X  X  topic distribution, we can now borrow user X  X  universal preference. To keep the conju-gate prior, we have: where  X  w is a scale parameter for tuning the coupling strength (prior strength). Item modeling as well as user action mod-eling are kept the same with LDA.  X  k  X  Dir (  X  w ) , z ij  X  Multi ( P w i ) , A w ij  X  Multi (  X 
In this section we discuss the learning of JUMA. We pro-pose a hybrid learning process to estimate the parameters. The learning is mainly based on Gibbs sampling technique [30], a Markov chain Monte Carlo algorithm for approximat-ing multivariate probability distribution.

Specifically, we partition the graphical model into two sub-modules: user preferences module and site-specific ac-tion module (separated by dashed line in Figure 3 (a)). As showed in the figure, the two sub-modules are linked only through site-specific user preferences P q i . Viewing each mod-ule as a hyper parameter and applying Gibbs sampling over the modules, we can learn the model by iteratively updat-ing the modules separately. In the following subsections we discuss how we update the parameters in each modules.
Viewing from site X  X  action module, the difference with original models is the distribution of user preferences. Such change can be viewed as a change of prior knowledge. In traditional models we use non-informative prior distribution for user preferences. Instead, when integrating with JUMA, we take advantage of the informative prior transferred from universal preference.

Text-Based Sites. The topic distribution P w i now has a prior distribution of Dir (  X  w T w U i ) instead of Dir (  X  ). As we design the model by following the conjugate distribu-tions as in traditional design, only the parameter is shifted while the form of the distribution is kept the same as in the original model. Therefore, the inferences of the param-eters are mostly the same as in original model thus we skip the details here. By plugging the new prior parameter, the posterior distribution of the latent topic variable z ij is: where n ik is the number of times topic k being assigned to user i (# z i  X  = k ) and m kj is the number of times word j being assigned to topic k . For simplicity, we abbreviate the conditioned variables by  X   X   X . After sufficient sampling iterations, the parameters P w , X  w can be estimated by the following:
Item-Based Sites. User preference P d i now has a prior of N ( T d U i , X  d ) instead of N (0 , X  d ). Still, only parameters are shifted. The loss function is now:
L ( P d , X  d | U,T d ,  X  ) = Y We employ gradient descend technique, a widely used method for matrix factorization, to maximize the log likelihood. The partial gradient for user X  X  site-specific preferences P the movie X  X  latent factor  X  d k are as follows: As the gradient calculation is rather straight forward and is similar with the original MF, thus we omit the details here.
In this module, we need to update users X  universal prefer-ences { U i } as well as the preference transferring parameters T ,T w . We still follow Gibbs sampling and update them individually according to their posterior distribution condi-tioned on the others. The posterior distribution of user X  X  universal preferences U i according to the general model is:
P ( U i | T,P,U  X  i ,  X  )  X  X  ( U i | 0 , X  )  X  Y where P ( P q i | U i ,T q , X  q ) indicates probability of user having P i as preference in site q under prior transferred from U and T q . When applying to text-based and item-based sites as stated in previous section, we have:
The posterior distribution for preference transfer model X  X  parameter T q for general scenario is: where P ( T q |  X  q ) is the non-informative prior for T ting for text-based and item-based sites (normal distribution prior for T w ,T d and the corresponding P ( P q i | U we have:
P ( T d | U,P,  X  )  X  X  ( T d | 0 , X  d )  X  Y
P ( T w | U,P,  X  )  X  X  ( T w | 0 , X  w )  X  Y Based on these posterior distribution, Gibbs sampling with Metropolis-Hasting [4] or gradient descend technique can be applied for the learning. For simplicity of inference in text-based sites cases, when updating user preference modules we may assume the site-specific preference P q i follows mul-tivariate normal distribution with same mean and variance of the original distribution.
We conduct the experiments using real data over 148,470 aligned users from Weibo and Douban, with microblog retweet-ing histories and movie rating histories as user actions in the two sites respectively. Details are discussed in Section 3.1.
As there is no ground truth for user preferences, we can only evaluate the quality of user modeling by the perfor-mance of recommender systems.

We design experiments for both text-based site and item-based site to show that joint user modeling can transfer the user preferences and improve the performances in both direc-tions. Specifically, we implement microblog and movie rec-ommender systems for Weibo and Douban respectively using both JUMA and the existing state-of-the-art user modeling techniques as the underlying user preferences modeling.
For ground truth, we consider the user is interested in the movie if he/she rates it, and similar for microblogs. We use a portion (40% to 90%) of the user actions for training the model and the rest for testing. The recommender system ranks the potential movies/microblogs (the ones that user has no action with in the training data) according to the estimated user preferences. Then we employ Area Under the Curve (AUC) as the metric to evaluate the resulted rank.
For the text-based site Weibo, we compare the followings:
Note that LDA and JUMA use only the textual informa-tion while CTR and JUMA + also employ side information. For fair comparison, we should compare them accordingly.
For the item-based site Douban, we compare:
For all approaches, latent factor dimension for user pref-erences is set to 10 and number of topic is 20. All hyper-parameters are set to 1. The results are conducted over 5-fold cross validation.

There is no suitable cross-domain recommendation tech-niques to compare with under this experiment setting. As we discussed in Section 2, most existing cross-domain works focus on transferring user preferences between homogeneous user actions, thus can not apply for our setting between microblogging site and movie rating site. There are works modeling between text-based and item-based actions [21], however they require aligned actions for the model learning. For ComSoc in [34], although it also leverages multiple plat-form for joint user modeling, it focuses on borrowing the social relations instead of user generated contents thus also not suitable for comparing.
We first evaluate in the general scenario. We vary the training ratio from 40% to 90% and show the corresponding results in Table 3.

For the text-based site Weibo, our approach JUMA achieve relative improvements of 3 . 8% and 4 . 7% comparing to LDA when training ratio is 90% and 40% respectively. The re-sults indicate JUMA out-performs comparing method and is more robust to training size. For advanced and realistic scenario where side information is available, JUMA + out competes TM + .

For the item-based site Douban, JUMA achieves better performance comparing to both within-site approachs (PMF and SVD++) and joint modeling extended from existing ap-proaches (TMF and mmTM). Also note that topic-based matrix factorization (TMF) has only slight improvement over traditional MF. By detailed analysis we find that topic-related feature X  X  impact does not emerge in tMF because the signals coming from topic distributions are not as strong as the action histories within the same site.

By these experiments, we show that topic model and ma-trix factorization both can achieve better performance when integrating with JUMA. For other unevaluated techniques, we believe that similar improvement can also be achieved.
Recall that cold-start problem is the potential failure of recommender system when dealing with new users with few or even no actions. We simulate cold-start scenarios by lim-iting the number of historic actions used for training. We depict the relative AUC improvements over users with dif-ferent number of training actions (different cold-start level) in Figure 4. Results in both sites show that the perfor-mance improvement is much higher when dealing with cold users comparing to non-cold users. We achieve a relative improvement of 12.8% for the users with no historic actions in Weibo and 9.3% in Douban, indicating that JUMA suc-cessfully leverages cross-site action histories to alleviate the cold-start problem without special treatment.
Now we focus on opposite direction of cold-start where users have more actions than average. We show the results in Table 4, indicating JUMA still outperforms comparing al-gorithms. For those users, the traditional approaches should be able to precisely model user X  X  preference in the target site. The advantage of JUMA is comprehensiveness. For exam-ple, it is hard to model one X  X  political preferences based on his movie histories, but is rather simple based on his mi-croblogs. Such information might be helpful when recom-mending political related movies/documentaries.
 TARGET ALGS USER HISTORY COUNT 100 150 200 300
Text-Based (Weibo)
Item-Based (Douban)
In this paper, we aim at improving comprehensiveness and accuracy of user modeling by joint user modeling, i.e. simul-taneously modeling user actions in multiple aligned hetero-geneous sites. We make the assumption that user X  X  under-lying preferences are consistent across-sites and further con-duct analysis on real data to support it. We propose a mod-ularized probabilistic graphical model framework JUMA for joint user modeling over aligned sites, which can integrate state-of-the-art site-specific approaches for a united user mod-eling. We also collect and publish a large scale data set from Weibo and Douban. Based on the data set, we conduct extensive experiments to evaluate JUMA X  X  performance in various scenarios. Results show that JUMA out performs existing works and can alleviate cold-start problem with-out special treatment. For future works, we may consider integrating social relations into JUMA, and developing in-terpretation or visualization for user X  X  underlying universal preferences. [1] S. Berkovsky, T. Kuflik, and F. Ricci. Cross-domain [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [3] K. Chen, T. Chen, G. Zheng, O. Jin, E. Yao, and [4] S. Chib and E. Greenberg. Understanding the [5] I. Fern  X andez-Tob  X  X as, I. Cantador, M. Kaminskas, and [6] H. Gao, J. Tang, and H. Liu. Addressing the [7] F. Godin, V. Slavkovikj, W. De Neve, B. Schrauwen, [8] N. Golbandi, Y. Koren, and R. Lempel. Adaptive [9] F. Hu and Y. Yu. Interview process learning for top-n [10] T. Iofciu, P. Fankhauser, F. Abel, and K. Bischoff. [11] M. Jamali and M. Ester. A matrix factorization [12] H. Kautz, B. Selman, and M. Shah. Referral web: [13] N. Koenigstein, G. Dror, and Y. Koren. Yahoo! music [14] Y. Koren. Factorization meets the neighborhood: a [15] Y. Koren, R. Bell, and C. Volinsky. Matrix [16] X. N. Lam, T. Vu, T. D. Le, and A. D. Duong.
 [17] G. Linden, B. Smith, and J. York. Amazon. com [18] H. Liu and P. Maes. Interestmap: Harvesting social [19] J. Liu, F. Zhang, X. Song, Y.-I. Song, C.-Y. Lin, and [20] S. Liu, S. Wang, F. Zhu, J. Zhang, and R. Krishnan. [21] J. McAuley and J. Leskovec. Hidden factors and [22] A. Mnih and R. Salakhutdinov. Probabilistic matrix [23] A. Narayanan and V. Shmatikov. De-anonymizing [24] A. Narayanan and V. Shmatikov. Myths and fallacies [25] S. Sahebi and P. Brusilovsky. Cross-domain [26] A. I. Schein, A. Popescul, L. H. Ungar, and D. M. [27] S. Tan, J. Bu, X. Qin, C. Chen, and D. Cai. Cross [28] S. Tan, Z. Guan, D. Cai, X. Qin, J. Bu, and C. Chen. [29] J. Tang, S. Wu, J. Sun, and H. Su. Cross-domain [30] M. J. Wainwright and M. I. Jordan. Graphical models, [31] J. Zhang, X. Kong, and P. S. Yu. Predicting social [32] Y. Zhang and J. Koren. Efficient bayesian hierarchical [33] Z.-K. Zhang, C. Liu, Y.-C. Zhang, and T. Zhou. [34] E. Zhong, W. Fan, J. Wang, L. Xiao, and Y. Li. [35] K. Zhou, S.-H. Yang, and H. Zha. Functional matrix
