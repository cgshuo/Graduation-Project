 1. Introduction have been successful on the internet. CQA portals such as Yahoo! Answers
Wenwen, 207,469,570 questions have been resolved until October 30, 2012.  X  ( Horowitz &amp; Kamvar, 2010 ).
 Plataniotis, &amp; Venetsanopoulos, 2011 ) as shown in the right side of Fig. 1 . one. Such useful information can be used to improve the ranking of answerers. lem mentioned above can be treated as answerer ranking problem.
 two real-world datasets.
 of model parameters. Finally, we draw conclusions and discuss the future work in Section 6 . 2. Related work
Community Question Answering (CQA) portals such as Yahoo! Answers and Tencent Wenwen have collected plenty of and global features. Then the model predicted yes/no for each potential answerers for new questions. CQA.
 ways. the best and other answerers. extensively on this dataset. 3. Problem formalization and answerers. We define the set of all askers as U  X f u i define the set of all these ternary relations as S # I J M . For each question q , we use u asker. For convenience in the following statements, we define some functions as below, to answer q . Given a predictor b Y , this means that we should predict a score ^ y N highest scoring answerers for question q can be calculated as follows: where the superscript N represents the number of answerers to be predicted. 4. The proposed framework for ranking answerers 4.1. Latent topics of questions the topics of documents. The details are introduced in ( Blei et al., 2003 ). topic with the question. We define the set of all topics as T  X f t
P  X  q  X  X f p  X  t k j q  X g K k  X  1 of each question q has been learned. 4.2. Asker-topic-answerer model with tensor factorization among u ; q and a , since  X  u ; t k ; a  X  reveals that a has answered the question of u in topic t set of all different  X  u ; t  X 2 S is denoted as O S . Now, ^ y  X  u ; t  X  .

The remaining problem is how to calculate ^ z u ; t ; a . In this paper, we estimate where core tensor b C and feature matrices b U , b T and b tiply a matrix on dimension x with a tensor. These parameters are denoted as b
Then given ^ h ; ^ z u ; t ; a can be calculated as below: 4.3. Ranking constraints
Before learning model parameters ^ h , we propose two partial pairwise ranking constraints of predictor where A  X  is the set of positive answerers and A is the set of negative answerers which are defined as below: have not answered the questions.
 where A b  X  is the set of the best-positive answerers and A below: following formula.
 where represents orthogonal union. 4.4. Optimization objective
In this paper, we adopt an optimization criterion to learn model parameters instance ( Ferri, Hern X ndez-Orallo, &amp; Salido, 2003 ).
 should rank higher than negative answerer A and the best-positive answerer A &amp; Till, 2001 ), we use a multi-class generalization of AUC as shown in Eq. (4) : where C is number of classes and AUC c i ; c j is the area under two-class ROC curve involving classes c
Then optimizing objective is described as Eq. (5) : Function W  X  ^ h ; u ; t  X  is defined as below:
AUC b  X  ;  X  ^ h ; u ; t  X  ; AUC b  X  ;  X  ^ h ; u ; t  X  and AUC where H 0 : 5  X  x  X  is the Heaviside function: 4.4.1. Regularization where c is the regularization parameter. jjjj 2 F is Frobenius norm. 4.5. Learning model parameters
Now we need to learn model parameters ^ h by maximizing W  X 
W  X  ^ h ; u ; t  X  can be rewritten as where
As AUC function is not differentiable because of Heaviside function, we replace H s-shaped logistic function s  X  X  :
Hence, the derivative of core tensor features is: where
Next, for feature asker and topic the derivatives are as follows:
Then we use the gradient descent algorithm ( Herschtal &amp; Raskutti, 2004 ) to learn 4.6. Ranking answerers
P  X  q new  X  of q new , i.e. P  X  q new  X  X f p  X  t k j q new  X  ; j k  X  1 ; ... ; K g . Then, for each topic t use /  X  X  to normalize f ^ z u ; t k ; a g ; k  X  1 ; ... ; K as follows: where j  X  ^ z u ; t ; a  X  returns the reciprocal value of the ^ z score ^ y u ; q ; a of  X  u ; q ; a  X  is calculated as Eq. (2) . Now we get a ranking list r
At last, we choose the set of answerers with Top-N highest scoring ^ y q . The details of the proposed framework for learning the optimal answerer ranking are shown in Algorithm 1 . 4.7. Runtime complexity analysis
Algorithm 1. The proposed method for optimal answerer ranking 4.7.1. Predicting based on ^ z u ; t ; a . ^ z u ; t ; a is computed as Eq. (3) . We have ~ a can be computed in O  X  k U k T k A  X  for all ~ a , then the complexity of calculate ^ z of all candidate answerers. Then the runtime complexity for given new question q is O  X  X  K complexity of LDA inference, K q is the topic number of q . Since parameters k diction can be performed effectively via the trained model. 4.7.2. Training Section 4.4 . Similar to the predicting part, the complexity of updating gradient for each dimension is O  X  k
Then the complexity of the training procedure is O  X  iter j S j K learning procedure and j S j is the number of training samples. 5. Experimental evaluation and state-of-the-art approaches.

Our experiments are designed to address the following questions: 1. How well is the proposed method compared with other published approaches? 2. How is the effect after the introduction of asker dimension? Does it really work? 3. How does the number of topics K affect the performance of our method? 4. How does the parameter K q affect the performance? 5. How do the parameters k u ; k t , and k a affect the performance? 5.1. Dataset dataset that is in Chinese we should perform Chinese word segmentation firstly. teristic of social media.
 5.2. Evaluation setup 5.2.1. Evaluation methodology Terveen, &amp; Riedl, 2004 ).
 The compared approaches are described as follows: baseline in our experiments.
 answerers ( Liu et al., 2010 ).
 model ( Liu et al., 2010 ).
 BQ : Li presented an approach which considers the answering quality of users ( Li &amp; King, 2010 ). SQ : This method is an improved version of BQ, and the details are introduced in ( Li &amp; King, 2010 ). CQLL : Li et al. add the information of categories to improve the model performance ( Li et al., 2011 ).
MATA : The proposed method in this paper with multi-class AUC maximization. 5.2.2. Evaluation scenario u in dataset S , we select the latest question posted by u to compose the test set S have answered these questions. Furthermore, the training set S corresponding answerers with their answers. Consequently, we train the proposed model on S potential answerers for each question in S test . 5.2.3. Evaluation criterion The answerers who rank higher are more likely to answer the questions.
The groundtruth is the set of answerers who gave the best answer of the questions in S more likely to give the best answer of the question. 5.3. Experimental parameters
At the first stage of the proposed framework, we need to learn the topic distribution of questions by LDA. and k dim = 256. The other hyper-parameters are: learning rate d  X  0 : 1; regularization c  X  10 set to 5. The experiments were carried out on a desktop computer with 4 core CPU (2.53 GHz) and 16 GB memory. 5.4. Results and discussion 5.4.1. Topics of questions discovered by LDA 5.4.2. Performance comparison of methods In this section, we show the performance comparison of methods on YA and TW dataset respectively. 2010 ). Besides this, SQ is better than BQ which is also concluded in ( Li &amp; King, 2010 ). significant improvement under best-answerer criterion.
 The reason may be that the categories in our YA dataset are not very similar with each other.
Besides the previous evaluation, we have additionally evaluated F
QLDA is similar to BQ and these methods all outperform QLL. 5.4.3. Impact of the asker dimension information of askers and treats them as anonymous askers. We ran this Anonymous variant with K = 500 and k evaluation. 5.4.4. Impact of the number of topics In order to investigate the impact of the topics K used in LDA model, we ran the proposed method with 5.4.5. Impact of the K q parameter are shown in Table 10 . The results show that there is unobvious relationship between K
Table 10 , K q  X  5 achieves the best performance in metrics of MMVRR and MAP, while K in the metrics of Precision and Recall. The number of K q increases, it will cost more time in the training procedure. 5.4.6. Impact of tensor dimension k U ; k T and k A parameters k U ; k T and k A . We ran the proposed method with k dataset respectively. From Fig. 7 , we can see that as k dim we have to spend more time (about k 3 dim ) in training the corresponding model as k best when k dim  X  1024, we need to consider the factor of time cost to make a tradeoff in practice. 6. Conclusions and future work process.
 massive users.
 Acknowledgements authors also thank Jianjiang Feng and Peng Sun for proofreading the manuscript. References
