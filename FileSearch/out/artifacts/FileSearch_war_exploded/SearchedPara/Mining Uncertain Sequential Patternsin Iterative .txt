 Sequential pattern mining (SPM) is an important data mining application. It a relation see(t, aId, tId) , which denotes that the RFID tag event that Alice and Bob meet at time 100 happens with probability 0.4. basic framework can not directly be used in SPM because it does not support the iterative computing model which is required by most SPM algorithms. In this paper, we propose a sequential pattern mining algorithm in itera-summarized as follows: and analyze the naturally correlated possible worlds. (2) We design a vertical format of uncertain sequence databases in which we time complexity. rithm in parallel. datasets, which prove the efficiency and scalability of our algorithm. semantics and propose their complimentary uncertain SPM algorithm UPrefixS-and cannot be directly extended to MapReduce framework. A dynamic pro-ever, dynamic programming also cannot be directly extended to MapReduce. Jeong et al. propose a MapReduce framework for mining sequential patterns where unlimited number of items are allowed; Chen et al. extend the classic SPAM algorithm to its MapReduce version SPAMC [ 7 ]. However, SPAMC relies SPM problems. 3.1 Uncertain Model by e = sid, eid, I, p e . Here sid is the sequence id and eid is the event id. sid, eid identifies a unique event. I is an itemset that describes event sequence database. Here, for instance, the uncertain event indicates that the itemset { AB } occurs in e 11 with probability 0.8. we can compute the existential probability of a possible world Where d i  X  w is a sequence in w and e ij  X  d i is an event in possible world w 1 by P ( w 1 )=(0 . 8  X  0 . 2)  X  (1  X  0 . supporting a pattern, because each event in w 1 is also present in 3.2 Uncertain SPM Problem A sequential pattern  X  = X 1  X  X  X  X n is supported by a sequence denoted by  X   X  , if and only if there exists integers 1  X  k frequent if and only if it satisfies sup ( s )  X  t s , where computed by Equation ( 2 ). Where w is a possible world in which s is frequent and P ( probability of w .
 Then the uncertain sequential pattern mining problem is defined as follows. Given an uncertain sequence database D , a minimal support threshold sequential pattern s in D which has P ( sup ( s )  X  t s ) 4.1 Approximation of Frequentness Probability Suppose D = { d 1 ,...,d n } is an uncertain database and s in
D , denoted by sup ( s ), can be computed by Equation ( 3 ). computation of P ( s d i ) in section 4.2 .
 sum of n independent but non-identical Bernoulli random variables. And can be modeled by its probability mass function (pmf), denoted by { sup ( s ) | 0: p bution when n goes to infinity. Therefore, in the large scale database approximate the distribution of sup ( s ) by Equation ( 4 ). Here we approximate sup ( s ) by the Gaussian distribution the approximated frequentness probability P ( sup ( s )  X  t linear time. 4.2 Support Probability to possible world semantics.
 probability. However, suppose each item in a k -length pattern s in practice.
 ity efficiently. Let l be the last item of sequential pattern d , suppose there are q possible occurrences of l in events the possible worlds that may support s can be divided into ( g item of s )isin e k i , then it can be computed by Equation ( 6 ). ing to possible world semantics, there are three possible worlds of support s : w 1 = { BC 1 } , w 2 = { BC 2 } and w 3 = { BC into two disjoint groups by the latest occurrence of item as g 1 = { w 1 } and g 2 = { w 2 ,w 3 } . We first compute P ( g pattern. P ( s d | g i )in( 7 ) can be computed by ( 8 ).
P ( s d | g i )= occurrence of the last item of s in the event e k j .And  X  item of s occurs before the last item of s ; otherwise,  X  computation from exponential to O ( p  X  q ). 4.3 Vertical Data Structure patterns. The schema of D k is sid, c, tid, P c ,P i , where tain sequence d , c is a candidate pattern and tid, P c ,P of c in d . Suppose i is the last item of c and e is the event identified by ( which the latest occurrence of item i locates in event e .And the existential probability of i in e .
 We transform the original sequence database into its vertical format which vertical data format D k . Here D is the original database, and from
D . For example, let s = A , then we have two groups g rences of s in sequence d 1 . We compute P c 1 ( s )=1  X  P and support probabilities P ( s d 1 )=0 . 65 and P ( s d 2 )=0 minsup =1and minprob =0 . 5, then A and B are two frequent pat-terns, and their occurrences are saved in D 2 . For example, let P ( s d d , we first compute P ( g 1 )=0 . 8  X  0 . 3=0 . 24 and P ( P ( s )=0 . 4  X  0 . 24 = 0 . 096 and P c 2 ( s )=0 . 4  X  0 . 7=0 support probability P ( s d 2 )=0 . 376.
 And
D k is usually in a much smaller size than the original database because it only contains occurrences of potential frequent candidate patterns. 4.4 Uncertain SPM in Iterative MapReduce job to search k -length frequent patterns on a cluster of computers. k th ( k&gt; 1) iteration, the input data of a mapper is a chunk of patterns are distributed to mappers, which is denote by C (1) Mapper Function: The mapper function is shown in Algorithm 1 .Itfirst constructs d k from d k  X  1 and C k , where d k  X  1  X  D k  X  ( pattern c , the mapper computes the support probability p the newly updated data structure and outputs a key-value pair p the Bernoulli random variable sup ( c | d k ). Thereafter, file system (DFS) to be used in the next iteration. (2) Combiner Function: We design a combiner function in Algorithm 2 to help improve the performance. Suppose a mapper function emits n c,  X  i , X  2 i ( i =1 ,...,n ) which are associated with the identical pattern reduce the total bandwidth cost of data shuffling. value pair of the reducer is in the form of c,  X  i , X  2 i to approximate the distribution of overall support sup ( c and minprob = t p , the reducer outputs the probabilistic frequent sequential patterns to the file, if P ( sup ( c )  X  t s )  X  t p ; otherwise, frequent and is discarded by the reducer.
 join k -length frequent patterns to generate ( k + 1)-length candidate patterns discovered.
 duce, denoted by IMRSPM , and evaluate its performance using both synthetic and real world datasets in a 10-node Hadoop cluster.
 5.1 Synthetic Dataset Generation The IBM market-basket data generator [ 3 ] uses the following parameters to per transaction per sequence; (4) I : number of different items. t  X  N (  X ,  X  2 ), where  X  is randomly drawn from range [0 drawn from range [1 / 21 , 1 / 12]. Then we draw a value from a dataset T4L10I10C10 indicates T =4, L = 10, I =10  X  1000 and 5.2 Scalability erated by different parameters. Here we set minsup =0 . 2% and Fig. 5(a) shows the running time variations of IMRSPM when ning time variations of IMRSPM when T varies from 5 to 25, where L =4, I = 10 000. Fig. 5(c) shows the running time variations of IMRSPM when L running time variations of IMRSPM when I varies from 2 000 to 32 000, where C = 100 000, T =4, L =4.
 proves the effectiveness of our incremental temporal uncertainty management demonstrates the advantage of using iterative MapReduce framework. (2) The running time increase with the increment of C , T parameters generates larger scale datasets. Furthermore, when ing the efficiency especially in such cases. (3) The running time slightly drops with the increment of I are randomly selected from a fixed set of items. 5.3 Mining Customer Behavior Patterns from Amazon Reviews We apply our IMRSPM algorithm in Amazon review dataset[ 12 ]todiscover customer behavior patterns. The Amazon review dataset includes 34 686 770 reviews of 2 441 053 products from 6 643 669 customers between June 1995 to subjective satisfaction. Suppose a customer gives a score believe that the probability that this customer likes this product is B in the future.
 For example, given minsup =0 . 005% and minprob =0 . 7, we have discovered the sequential pattern B000TZ19TC  X  B000GL8UMI . Here B000TZ19TC is the Amazon Standard Identification Number (ASIN) of the book Fahrenheit uct B000TZ19TC may also like B000GL8UMI in the future, which is a newer patterns as B000MZWXNA  X  B000PBZH6Q , where B000MZWXNA is asso-ciated with the book The Martian Way and ASIN B000PBZH6Q identifies the book Foundation .
 Figure 6 and Figure 7 show the effect of user-defined parameters and minprob in Amazon dataset. We initially set minprob =0 . 7and 0 . 04%. In Figure 6(a) and 7(a) , we vary the value of minsup 0 . Figure 6 and Figure 7 , we observe that: are mined when minsup is larger, which can be proved by Figure 7(a) . (2) The performance remains relatively stable to the variation of of other distributed platforms in solving uncertain SPM problems.
