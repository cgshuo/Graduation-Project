 1. Introduction variety of applications with great success. Their first main advantage is that they do not require a user-specified problem solving algo-rithm (as is the case with classic programming) but instead they  X  X  X earn X  X  from examples, much like human beings. Their second main advantage is that they possess inherent generalization ability. This means that they can identify and respond to patterns which are similar but not identical to the ones with which they have been trained ( Vosniakos and Benardos, 2007 ). ANN is one of the most important data mining techniques. I t is used for both supervised and unsupervised learning ( Yaghini et al., in press ). Training ANN is a complex task of great importance in problems of supervised learn-ing. Most of ANN training algorithms make use of gradient-based search. These methods have the advantage of the directed search in which weights are always updated in such a way that minimizes the error called ANN learning process. However, there are several negative aspects with these algorithms such as dependency on a learning rate parameter, networ k paralysis, slowing down by an order of magnitude for every extra (hidden) layer added and complex and multi-modal error space. Therefore, these algorithms most likely are trapped in local minima; making them entirely dependent on initial (weights), settings which make the algorithms not to guarantee their universal usefulness ( Kiranyaz et al., 2009 ).
Metaheuristic global search strategy enables them to avoid being trapped into secondary peak of performance and can therefore provide effective and robust solution to the problem of ANN and training ( Castellani and Rowlands, 2009 ). They have the advantage of being applicable to any type of ANN, feedforward or not, with any activation function, differentiable or not ( Kiranyaz et al., 2009 ). They provide acceptable solutions in a reasonable time for solving hard and complex problems. They are particularly useful for dealing with large complex problems, which generate many local optima. They are less likely to be trapped in local minima than traditional gradient-based search algorithms. They do not depend on gradient information and thus are quite suitable for problems where such information is unavailable or very costly to obtain or estimate ( Talbi, 2009 ). Learning algorithm is an important aspect of ANN based model.
In this article, a literature review and categorization for ANN learning algorithms are presented. Then, a method for training
ANN is proposed. The proposed method combines global search strategy of improved opposition based particle swarm optimiza-tion (PSO) with the local search ability of the traditional back-propagation algorithm (BPA) with the momentum term. The opposition based and random perturbation methods are two diversification components of the algorithm. Time-varying social and cognitive components improve the search ability of the algorithm and constriction factor is another parameter that guar-antees convergence of particles. During training a prediction ANN model, overfitting, i.e., learning more than adequate specification of training data is one of the common problems especially with the large data sets ( Prechelt, 1994 ). This problem has an off-putting effect on prediction model to forecast new pattern and causes incorrect or lowerthanexpectedprediction( Yaghini et al., in press ). Several approaches have been proposed to solve the problem none of which consider multimodality of the weight space. Therefore, a new cross validation method is proposed.

The organization of this paper is as follows. Section 2 presents a literature review about the previous research. In Section 3 , the components of the proposed algorithm, criterion for accuracy evaluation, the proposed cross validation method, and the steps of the algorithm are explained. In Section 4 , the experimental results for the benchmark problems are presented. In Section 5 , conclu-sions and some hints for the future research are given. 2. Literature review
Metaheuristic algorithms for training ANN models could be divided into single-solution based and population-based algo-rithms ( S -Metaheuristics and P -Metaheuristics).

In training ANN with S -Metaheuristics ( Battiti and Tecchiolli, 1995 ; Sexton et al., 1998 ), Tabu Search (TS) ( Treadgold and Gedeon, 1998 ; Chalup and Maire, 1999 ) and Simulated Annealing (SA) are utilized.

Using P -Metaheuristics, one could divide ANN training into evolutionary algorithms (EA) and swarm intelligence (SI) algo-rithms. Learning and evolution are two fundamental forms of adaptation. There has been a great interest in combining learning and evolution with ANN, and combining ANN and EA can lead to significantly better intelligent systems than relying on ANN or EA alone ( Yao, 1999 ). In training ANN with EA, Porto et al. (1995) and Mandischer (2002) make a comparison among EAs and gradient-based algorithms. Sexton and Dorsey (2000) compare BPA with the genetic algorithm (GA) for ANN training over a collection of 10 benchmark real world data sets. Cantu-Paz and Kamath (2005) present an empirical evaluation of eight combinations of GA and ANN on 15 public-domain and artificial data sets to identify the methods that consistently produce accurate classifiers that gen-eralize well. They utilize a predefined parameter setting for GA and indicate that the GA is not dependent on the initial random weights for finding superior solutions. Alba and Chicano (2004) and Malinak and Jaksa (2007) combine EA with gradient-based local search algorithm to obtain better result. Another class of P -Metaheuristic, which is used as training algorithm, is SI. They originate from the social behavior of those species that have a common target (for example, compete for foods) ( Talbi, 2009 ). Among SI algorithms, PSO is one of the most successful one. Unlike GA, PSO has no complicated evolutionary operators such as crossover, selection and mutation, and it is highly dependent on stochastic processes ( Kiranyaz et al., 2009 ). Kennedy and Eberhart (1995) introduced the PSO for the first time. Engelbrecht and Bergh (2000) propose a method to employ PSO in a cooperative configuration achieved by splitting the input vector into several sub-vectors, each of which is optimized cooperatively in its own swarm. Mendes et al. (2002) and Gudise and Venayagamoorthy (2003) make use of PSO to train ANN. In their research, authors use a very simple problem that does not reveal outperformance of their method. Zaho et al. (2005) present a modified PSO, which adjust the trajectories (positions and velocities) of the particle based on the best positions visited earlier by them and other particles, and incorporates population diversity method to avoid premature convergence. Carvalho and Ludermir (2007) have made use of a methodology entirely based on the PSO and apply it to benchmark classification problems of the medical field. The results obtained by this methodology are situated between the results presented by other well-studied techniques such as GA or SA. Carvalho and Ludermir (2006) analyze the use of the PSO algorithm and two variants with a local search operator for neural network training, and for evaluating these algorithms; they apply 3 medical field benchmark classification problems. Al-Kazemi and
Mohan (2002) use multi-phase PSO algorithm (MPPSO) which simultaneously evolves multiple groups of particles that change their search criterion when changing the phases, and incorporates hill-climbing.

In addition to the modifications made to basic PSO algorithm, other PSO variations have also been developed. Among these variations, those that incorporate opposition-based learning into
PSO are capable of delivering better performance as compared to the standard PSO. Opposition-based learning is first introduced by
Tizhoosh (2005) and later it is applied to PSO. Opposition-based learning is based on the concept of opposite points and opposite numbers. Han and He (2007) propose a modified PSO algorithm for noisy problems, which utilizes opposition-based learning. Wu et al. (2008) propose an opposition-based comprehensive learning
PSO which utilizes opposition-based learning for swarm initializa-tion and exemplar selection. Omran (2009) presents the improved PSO, which applies a simplified form of opposition-based learning.
In this approach, the particle havi ng worst fitness is replaced by its opposite particles. Opposition-based learning is only applied to one particle instead of the whole swarm and is not used at the time initialization. Hybrid Improved Opposition-based Particle swarm optimization and genetic algorithm (HIOPGA) method is a new
ANN training algorithm that combines ability of two populations based algorithms ( Yaghini et al., 2011 ). In the beginning, the algorithm starts training with a population of particles and during iteration of the algorithm when some ANNs (or particle position) in the d -dimensional space cannot be improved through the PSO, a sub-population is established and sent to the GA. By utilizing the GA crossover and mutation operators, the sub-population of the trapped particles is evolved. This process is repeated until the algorithm meets the termination condition. The authors compare their pro-posed method with back propagation algorithm on several bench-mark problems.

Apart from PSO, researchers employ the other SI algorithms, none of which is successful as PSO. Blum and Socha (2005) present a continuous version of Ant Colony Optimization (ACO R )algorithm.
Chen et al. (2008) propose a new hybrid algorithm based on artificial fish swarm algorithm and PSO. They compare their proposed algorithms with specialized gradient-based algorithm for ANN training. Karaboga et al. (2007) proposed An Artificial Bee Colony (ABC) algorithm for classification purposes. The performance of the algorithm has been compared with the traditional BPA and the GA. 3. The proposed algorithm
In this section, the proposed hyb rid algorithm to optimize the weights of ANN prediction models is explained. It is a combination of local search and global search algorithms. In the ANN prediction models, fully connected layered feedforward networks are employed.
Except of input units, each unit in the network has a bias. 3.1. The proposed particles
A good, detailed, basic version of PSO algorithm can be seen in Yu et al. (2008) . The proposed algorithm combines PSO and BPA ( Fig. 1 ).
For simplification in this figure, an ANN with one hidden layer, three input units, one hidden unit and two output units is considered. 3.2. Criterion for accuracy evaluation
For classification problems as shown in Eqs. (1) and (2), Classi-fication Error Percentage (CEP) is utilized to evaluate the accuracy. o !  X  o p 1 , ::: , o pn and t ! p  X  t p 1 , ::: , t pn where n is the number of
ANN output units and o pi and t pi are predicted and target values of output unit i , p !  X  p 1 , ::: , p k is input pattern which k is number of
ANN inputs, and P is the number of patterns. c  X  p !  X  X  1 if o CEP  X  100
Error (NRMSE) is employed as shown in Eqs. (3) and (4), where N is number of the output units, P is number of pattern, and o t pi are predicted and target values of i th output unit for pattern p .
RMSE  X 
NRMSE  X  100 RMSE P P 3.3. The improved PSO significantly fast rate, its ability to fine-tune the optimum solu-tion is comparatively weak mainly due to the lack of diversity at the end of the evolutionary process. To improve the search ability of standard PSO, time-varying parameter is utilized. Suppose that t and m are current and final iteration numbers, and C 1 ( t ), C
C 1 ( m ) and C 2 ( m ) are cognitive and social components of current and final iterations. In the first version of PSO, a single weight, c  X  c 1  X  c 2 , called acceleration constant, is used instead of the two distinct weights in this paper. However, the latter offered better control on the algorithm, leading to its predominance over the first version ( Parsopoulos and Vrahatis, 2010 ). Then, time-varying parameter is calculated using Eqs. (5) and (6). If each of parameter reaches to final values, it is set to initial value again. Using the time-varying parameter, one can implement large cognitive component and small social component at the beginning of the search to guarantee particles moving around the search space and to avoid particles moving toward the best population position.
However, a small cognitive component and a large social compo-nent allow the particles to converge to the global optima in the search ( Ratnaweera et al., 2004 ). K is another parameter that is utilized along with these parameters and is called constriction coefficient with the hope that it can insure a PSO to converge ( Clerc and Kennedy, 2002 ). K is calculated using Eq. (7), where f t  X  X  X  C 1 t  X  X  X  C 2 t  X  X  and f t  X  X  Z 4.

C  X  t  X  1  X  X  X  t = m  X  X  C 1 m C 1  X  t  X  X  X  C 1  X  t  X  X  5  X 
C  X  t  X  1  X  X  X  t = m  X  X  C 2 m C 2  X  t  X  X  X  C 2  X  t  X  X  6  X 
K  X  t  X  X  2 2 f  X  t  X  3.4. The opposition-based learning components
The proposed algorithm implements the opposition-based learn-ing components in two different way s. First, after population initi-alization, to start with a better population, the algorithm calculates the opposite position and velocity of each particle; then, for each particle the better one (current particle or its opposite) is inserted into the population. Second, during the iteration, when the algorithm finds a new velocity and position for a particle, the opposite position and velocity of each particle are calculated, and the better one is inserted into the current generation. When creating opposite parti-cles, an important question arises as to what the velocity of these particles should be? One can either have the same velocity as that of the original particle, or one can randomly reinitialize the velocity.
Alternatively, the opposite of the velocity of the original particle can be calculated. The velocity of the original particle can not be used because it was calculated using the current position of the original particle which would be invalid for the opposite particle. Reinitializ-ing the opposite particles velocity randomly is not such an inviting option because advantage of the experience gained by original particle would not be taken. Other researchers have not investigated this question and use random initialization of velocity. It is decided here to use the opposite velocity of the original particle, since it is believed that by using opposite velocity, better performance could be achieved, as we do with utilizing opposite positions. The opposite velocity is calculated in exactly the same way as the opposite particles calculation. The pseudocode of opposite particle calculation position (initial weight of ANN), and [ v min , v max ]isthevelocity interval. The positions and velocity of i th particle at iteration t are
X ( t )  X  ( x i1 ( t ), y , x id ( t )) and V i ( t )  X  ( v 3.5. Random perturbation
PSO can quickly find a good solution but sometimes suffers from stagnation without an improvement ( Ratnaweera et al., 2004 ). There-fore, to avoid this drawback of basic PSO, the velocity of particles is reset in order to enable them to have a new momentum. Under this new strategy, when the global best position is not improving with the increasing number of generations, each particle i will be selected by a predefined probability (0.5 in this study) from the population, and then, a random perturbation is added to each dimension v id by a predefined probability 0.5 in this study) of the velocity vector v of the selected particle i . The velocity resetting is presented in Fig. 3 , where r 1 , r 2 and r 3 are separately generated using uniformly dis-tributed random numbers in range (0, 1), and v max is the maximum magnitude of the random perturbation to each dimension of the selected particle. 3.6. The proposed cross validation method
The training error of an ANN may decrease as the training process progresses. However, at some points, usually in the later stages of training, the ANN may start to take advantage of idiosyncrasies in the training data. Consequently, its gen eralization performance may start to deteriorate even though the training error continues to decrease ( Islam et al., 2009 ). Early stopping in cross validation ( Prechelt, 1998 ) is one common approach to avoid o verfitting. In this method, the training data is divided into training and validation sets. The training process will not terminate when the training error is minimized; instead, it stops when the validation error starts to increase. This termination criterion is deceptive because the validation set may contain several local minima. In the proposed algorithm, to decrease negative effect of multimodal validation space on model general-ization ability, a simple criterion that terminates the training process oftheANNisused.Attheendofeach L training iterations, the validation error is evaluated. If validation error have increased for T successive times in comparison to first L training iterations (inde-pendent of how large the increases ac tually are), training process is terminated. The idea behind the termination criterion is to stop the training process of the ANN when its validation error increases not just once but during T consecutive times. It can be assumed that such increases indicate the beginning of the final overfitting, not just the intermittent one. Fig. 4 represents the pseudocode of the proposed cross validation method. 3.7. Termination criterion
The algorithm simultaneously uses three criteria as termination condition. First, termination condition is based on training error. In this approach, at the end of each iteration t if the error on the training pattern is less than e , the training process will terminate (for the classification problems e  X  10 2 , for the approximation problems  X  10 6 ). Second, if the number of iteration becomes greater than a predefined number, the training process will be terminated.
Third, according to the proposed cross validation method, if the algorithm meets the over training condition, the training process will be terminated. 3.8. The overall structure of the proposed hybrid algorithm
The steps of hybrid improved opposition based particle swarm optimization (IOPSO) and BPA for artificial neural network train-ing are explained as follows:
Step 1) Specify starting position and velocity of particles according to initial value of parameters. Set iteration counter to zero ( iter  X  0), and set the counter that calculates number of no improvement after BPA training on gbest to zero ( gbest CounterAfterBpTrain  X  0).

Step 2) To establish a better population, calculate opposite position and velocity of particles, and insert better particle into population (Pseudocode in Fig. 2 ).

Step 3) For each particle, specify the best personal position and calculate the number of no improvements in it ( pbest i and pbest i Counter ). In addition, specify the best global position and calculate the number of no improvements in it ( gbest and gbsetCounter ).
 Step 4) If E train ( gbest ( iter )) o e , go to Step 23; otherwise, go to Step 5.

Step 5) Calculate the best global position of particle validation error (E val ( gbest ( iter )).

Step 6) According to Eqs. (4) X (6), calculate C 1 ( iter  X  1), C and K ( iter  X  1).

Step 7) Calculate new position and velocity of particles (training by PSO).

Step 8) For each particle, specify the best personal position and calculate the number of no improvements in it ( pbest pbest i Counter ). Moreover, specify the best global position and calculate the number of no improvements in it ( gbest and gbsetCounter ).
 Step 9) If E t rain ( gbest ( iter )) o e , go to Step 23, otherwise, go to Step 10.
 Step 10) Perform the proposed cross validation.

Step 11) If the number of no improvements in the best global position is greater than maximum allowed number ( gbset-
Counter 4 Maxgbest ), go to Step 12 (backpropagation training 4. Experimental results 4.1. Benchmark problems proposed algorithm and three other algorithms on several well-known benchmark problems are presented. Table 1 constitutes a summary of problems specification in which a considerable variety in the number of patterns, attributes and classes are illustrated. The detailed explanation of these problems can be acquired from the University of California, Irvine, Machine Learn-ing Repository ( UCI Repository of machine learning databases (2011) ).
 sets: a training set, a validation set and a testing set. The number of patterns in these sets is demonstrated in Table 1 . The training set is utilized to weight modification for ANN training. The validation set is used for stopping the training process of ANNs, while the testing set is utilized for judging the prediction ability of a trained ANN. These partitions were inspired by suggestion in benchmarking methodologies ( Prechelt, 1995 ; Prechelt, 1996 ).
For each benchmark problem, entropy is calculated according to Eq. (8), where P ( C i ) is the probability of class C determined by dividing the number of pattern of class C i total number of pattern in data set. Entropy of a data set is the average amount of information needed to identify the class label of a pattern in data set. In fact, entropy explores class distribution information in its calculation and shows impurity of data set. It can be considered as a criterion for difficulty of the problems. E  X 
For instance, in Gene data set, there are three different class labels. Number of all pattern is 3175 with 762 patterns belonging to the class 1, 756 patterns to class 2 and 1648 patterns belonging to the class 3. Class probabilities are 0.24, 0.24 and 0.52, respectively.
According to Eq. (8), entropy for Gene data set is calculated as follows.
 E  X  4.2. Comparison with implemented methods
The algorithms are implemente d with Java programming lan-guage and a personal computer with Intel( R )Pentium( R )CPU 2.66 GHz 2.68 GHz, 32 Bits Windows 7 Ultimate operating system, and 4.0 GB installed memory (RAM) is used to achieve all the results.
To reduce the effect of random parameter initialization on the prediction ability of the models, each model is independently run 40 times. The average and standard deviation of results are presented in Table 2 . The BPA needs much more time and iterations to converge, but less disperses solutions. The random essence of the metaheuristic algorithms cause much more disperse solutions e.g., in Gene problem the test error standard deviation for BPA is 0.71, for combination of two metaheuristic algorithms (IOPSO_GA) is 8.01, for combination of a local and global search in the proposed method is 2.49, respectively.

According to Fig. 5 and Table 1 , the proposed algorithm has sensitivity to the number of input attributes, problem size and entropy. For example in the benchmark problems, Gene problem has greatest number input attributes it is also a large-scale problem with almost great entropy. As illustrated in Table 2 , the proposed algorithm has not shown generalization ability for this problem. This also satisfies the conditions for Horse and Diabetes problems.
Fig. 6 (a) X (h) represents CPU time-tes ting error for the best-so-far network from the beginning of the algorithms. As these figures reveal, the combination of the global search ability of the improved opposition base PSO and local search ability of BPA with the momentum term has the best result. As Table 2 discloses, mean and standard deviation over 40 independent runs of algorithms for each of eight benchmark problems are calculated. Small value of standarddeviationforIOPSO_BPAincomparisonwithotherthree algorithms reveals robustness of the proposed method. For example, the pair (test error S.D value, CPU time S.D value) for Thyroids problem in the proposed method is (0.33, 3.72), for IOPSOGA (1.02, 5.89), for IOPSO (0.61, 4.45) and for the BPA is (0.37, 10.96), show that IOPSO_BPA produces less disperse solution, so it is more stable in variable starting condition and can find promising solution in a reasonable time.

To do a fair comparison of the models, Fig. 7 is presented. It reveals the rank in the time and the rank in the error for the problems. This figure illustrates the results of different solution methods for various benchmark problems. Accordingly, IOPSO_BPA has substantial dominance over other methods regarding to the CPU time and generalization ability.

According to Table 2 and Fig. 6 (a) X (h), in comparison with other three algorithms for ANN weight optimization, the combi-nation of the global search ability of IOPSO and local search ability of BPA with momentum term is preferred in both CPU time and testing error. In addition, with respect to the variation in solu-tions, Table 2 reveals its superiority in comparison with IOPSO and combination of IOPSO and BPA over 40 independent runs. It has good variation with regard to the BPA with momentum term.
For most problems, the combination of IOPSO and GA can find good solution in a reasonable time, but variation in the solutions in this hybrid algorithm is high. Therefore, IOPSO_GA has not adequate stability for the prediction. 4.3. Comparison with promising methods in the literature
There are a number of algorithms for ANN training that can be compared with the proposed algorithm. Different algorithms employ different exper imental methodologies; therefore, in this paper a straight comparison with other algorithms using statistical tests is not practical. Furthermore, the required results of indepen-dent runs for statistical tests are generally not obtainable. As a result, it is impossible to compare different algorithms reasonably, unless one implements all algorit hms under the same experimental setup again. Since the aim of experimental comparison here is to understand the strengths and weaknesses of IOPSO_BPA, in this section a comparison between IOPSO_BPA and other competing methods on the eight classification problems is presented in Table 3 .
An error rate in the table refers to the CEP over the test data set. It is straightforward to see that the best classification performance is achieved with the proposed techni que over Cancer, Card, Diabetes, Heart, Horse and Iris data sets. In this study, in order to examine IOPSO_BPA with other experimented data mining techniques for prediction, Table 4 compares results of IOPSO_BPA against those of five prediction methods tested by Friedman (1997) . The accuracy rate in the table refers to CEP on the testing set. It is clear that
IOPSO_BPA outperforms other algorithms on major data sets. Note that the training time could not be the subject of this section because these algorithms are imple mented with different program-ming languages and computers with different specifications. 5. Conclusions
Learning algorithm is an important aspect of ANN based models. In this article, a literature review and categorization of the ANN learning algorithms were presented. Most of the learning algorithms are based on the gradient decent methods which are greedy and are potentially trapped in local optima of the weight space. Moreover, metaheuristic algorithms have global search strat-egy; it enables them to keep away from local optima, so the ability of both of them is combined and a superior hybrid algorithm is presented. The proposed algorithm combined the global ability of metaheuristics and the local greedy gradient based algorithm result-ing in a superior hybrid method. The training time and accuracy of the proposed algorithm on eight benchmark problems are compared with three other famous ANN training algorithms. The results prove the dominance of the proposed algorithm.

In this article, a comparison in terms of the testing accuracy rate between the proposed method and other challenging meth-ods and some data mining techniques for prediction over all data sets, is presented. The evaluation of the results showed super-iority of the proposed algorithm.

Presenting a satisfactory and efficient ANN training algorithm has always been a challenging subject especially for problems that may need handling a very large amount of data. Therefore, reducing the training time and increasing the model accuracy is a subject with great importance. To do so, future research need to be undertaken in following direction. Local search for global particle training either can be a faster gradient based algorithm such as the quick propagation,
Levenberg Marquardt algorithm, or single-solution metaheuristics such as tabu search or simulated annealing algorithms.
 References
