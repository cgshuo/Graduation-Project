 Globally, 30% of women fifteen and older have ex-perienced physical and/or sexual intimate partner violence at some point in their life (Devries et al., 2013). While domestic abuse tends to have greater prevalence in low-income and non-western coun-tries, it is still endemic in regions like North Amer-ica and Western Europe. In the United States, by an intimate partner, 9.4% of women have been raped, 16.9% of women and 8% of men have expe-rienced sexual violence other than rape, and 24.3% of women and 13.8% of men have experienced se-vere physical violence (Black et al., 2011). This translates to an estimated economic cost of $5.8 billion for direct medical and mental health care services, along with lost productivity and reduced lifetime earnings (Craft, 2003). Economic costs are calculable and provide concrete metrics for policy makers, but the physical and psychologi-cal effects felt by victims of domestic abuse are the true costs. Domestic abuse is the 12 th leading cause of years of life lost (Murray et al., 2013), and it contributes to health issues including fre-quent headaches, chronic pain, difficulty sleeping, anxiety, and depression (Black et al., 2011).
The data used to calculate such statistics are often derived from costly and time-consuming population-based surveys that primarily seek to obtain insight into the prevalence and conse-quences of domestic abuse. Due to safety con-cerns for victims and researchers, these surveys follow strict guidelines set by the World Health Organization (Garcia-Moreno et al., 2001). Great care must be taken by the researchers to ensure the safety of the participants, and therefore the num-ber of participants is often quite small (Burge et al., 2014). One way to avoid the cost of wide scale surveys while still maintaining appropriate research conditions is to leverage the abundance of data publicly available on the web. Of particular interest are moderated forums that allow discourse between users.
 source of data for this paper. This site has a wide range of forums dedicated to various topics, called subreddits , each of which are moderated by community volunteers. For subreddits dedicated to sensitive topics such as depression, domestic abuse, and suicide, the moderators tend to ensure that the anonymous submitter has access to local help hotlines if a life-threatening situation is de-scribed. They also enforce respectful behavior and ensure that the submissions are on topic by delet-ing disrespectful or off-topic posts. Finally, they ensure that site rules are followed, including the strict disallowal of doxing , the practice of using submission details to reveal user identities.
Reddit allows lengthy submissions, unlike Twit-ter, and therefore the use of standard English is more common. This allows natural language pro-cessing tools like semantic role labelers trained on standard English to function better. Finally, Red-dit allows users to comment on submissions, pro-viding them with the ability to ask questions, give advice, and provide support. This makes its data ideal for sensitive subjects not typically discussed in social media.

This work makes two contributions: classifiers for identifying texts discussing domestic abuse and an analysis of discussions of domestic abuse in several subreddits. Social media sites are an emerging source of data for public health studies, such as mental health, bullying, and disease tracking. These sites provide less intimidating and more accessible channels for reporting, collectively processing, and making sense of traumatic and stigmatizing experiences (Homan et al., 2014; Walther, 1996). Many re-searchers have focused on Twitter data, due to its prominent presence, accessibility, and the charac-teristics of tweets. For instance, De Choudhury et al. (2013) predicted the onset of depression from user tweets, while other studies have modeled dis-tress (Homan et al., 2014; Lehrman et al., 2012). Most relevantly, Schrading et al. (2015) used the #WhyIStayed trend to predict whether a tweet was about staying in an abusive relationship or leaving, analyzing the lexical structures victims of abuse give for staying or leaving.

Reddit has been studied less in this area, with work mainly focusing on mental health. In Pavalanathan and De Choudhury (2015), a large number of subreddits on the topic of mental health were identified and used to determine the differ-lar accounts. They observed almost 6 times more throwaway submissions in mental health subred-dits over control subreddits, and found that throw-away accounts exhibit considerable disinhibition in discussing sensitive aspects of the self. This motivates our work in analyzing Reddit submis-sions on domestic abuse, which can be assumed to have similar levels of throwaway accounts and discussion. Additionally, Balani and De Choud-hury (2015) used standard ngram features, along with submission and author attributes to classify a submission as high or low self-disclosure. 3 Dataset 3 and Data Analysis Following the procedure in Balani and De Choud-hury (2015) for subreddit discovery, we identified several subreddits that focus on domestic abuse. Additionally, we determined subreddits unrelated to domestic abuse, to be used as a control set. Ta-ble 1 shows the subreddits, the total number of unique posts (called submissions 4 ), and total num-ber of replies to those submissions (called com-ments ) collected.
 Table 1: The domestic abuse subreddits and con-trol subreddits with the total number of submis-sions and comments collected.

The anger and anxiety subreddits were chosen as control subreddits in order to help the classi-fier discriminate between the dynamics of abusive relationships and the potential effects of abuse on victims. For example, anxiety and anger may be affect caused by domestic abuse, but they are also caused by a wide variety of other factors. By in-cluding these subreddits in the control set, a classi-fier should utilize the situations, causes, and stake-holders in abusive relationships as features, not the affect particularly associated with abusive rela-tionships. Similarly, the advice subreddit was cho-sen as a way to help the classifier understand that advice-seeking behavior is not indicative of abuse. The casualconversation subreddit allows discus-sion of anything, providing an excellent sample of general written discourse. The domestic abuse subreddits have far fewer active users, submis-sions, and comments in total. 3.1 Preprocessing All experiments used the same preprocessing steps. From the collected subreddits, only sub-missions with at least one comment were chosen to be included for study. We then ran the sub-mission text through the Illinois Curator (Clarke et al., 2012) to provide semantic role labeling (SRL) (Punyakanok et al., 2008). A total of 552 domestic abuse submissions were parsed, and we randomly chose an even distribution of the control subred-dits (138 each), yielding a total sample size of 1104. All submissions were normalized by low-ercasing, lemmatizing, and stoplisting. External links and URLs were replaced with url and refer-ences to subreddits, e.g. /r/domesticviolence , were replaced with subreddit link . 3.2 Descriptive Statistics We present basic descriptive statistics on the set of 552 abuse submissions and 552 non-abuse sub-missions in Table 2.
 Table 2: Basic descriptive statistics. The score is provided by users voting on submis-sions/comments they feel are informative. The depth of a comment indicates where in a reply chain it falls. A depth of 0 means it is in reply to the submission, a depth of 1 means it is in re-ply to a depth 0 comment, etc. The  X  values are standard deviation metrics.

In general, the non-abuse subreddits have more discourse between commenters, as indicated by a larger comment depth, however, the abuse subred-dits tend to have longer submissions and replies. The abuse subreddits perhaps also have a smaller more tight-knit, community as indicated by fewer numbers of unique submitters and commenters. 3.3 Ngram Attributes To get a sense of the language used between the two sets of subreddits, the most frequent 1-, 2-, and 3-grams were examined. While there are many common and overlapping ngrams in the two sets, each set does have distinct ngrams. In the abuse set, distinct ngrams include the obvi-ous abuse (1595 occurences), domestic violence (202), and abusive relationship (166). Addition-ally, unique 3-grams related to the agents and situ-ations in abusive relationships like local dv agency (12) and make feel bad (11) appear. Also included are unique empathetic and helping discourse from comments, including let know (121), and feel free improve classification results, as support and em-pathy may be more prevalent in the abuse set than in the control set. 3.4 Semantic Role Attributes From the SRL tool, our dataset was tagged with various arguments of predicates. This data is par-ticularly useful in our study, as we are interested in examining the semantic actions and stakehold-ers within an abusive relationship. By perform-ing a lookup in Proposition Bank (Martha et al., 2005) with a given argument number, predicate, and sense, we retrieved unique role labels for each argument.

We determined the top 100 most frequent roles and predicates in the two sets, and took only the unique roles and predicates within each set to see what frequently occurring but unique roles and predicates exist within the abuse and control group.
 Table 3: Top 10 unique roles and predicates with their frequency for the abuse data. An exclamation point on a predicate indicates negation.

Table 3 contains roles and predicates that are powerful indicators of an abusive relationship, in-cluding a caller , hitter , thing hit , abuser , and entity experiencing hurt/damage . Importantly, several predicates that appear in this data also appear in a study on discussions of domestic abuse in Twitter data, including believe and realize , which indicate cognitive manipulation in the victims of domestic abuse (Schrading et al., 2015). In order to discover the semantic and lexical fea-tures salient to abusive relationships, we designed several classifiers. The subreddit category to which a submission was posted was used as the gold standard label of abuse or non-abuse . The la-bels were validated by examining the top ngrams, roles, and predicates in Section 3, and taking into account that these subreddits are moderated for on-topic content. We ran several experiments to study classifiers, the impact of features, and the effect of comments on prediction performance. 4.1 Combinations of Features We used the 1-, 2-, and 3-grams in the submis-sion text, the predicates, and the semantic role Perceptron, na  X   X ve Bayes, logistic regression, ran-dom forest, radial basis function SVM, and lin-ear SVM classifiers were parameter optimized us-ing 10-fold cross validation. Table 4 contains the results for the best classifier. The best features are the ngrams, achieving the highest accuracies alone. Predicates and semantic roles perform ad-mirably, but bring the classifier accuracies down slightly when added to ngrams. To determine the top features for prediction, we examined the weights of the top performing classifier, Scikit-learn X  X  (Pedregosa et al., 2011) Linear SVM with C=0.1, as in Guyon et al. (2002). These, along with their weights, are shown in Table 5. 4.2 Comment Data Only We experimented with only comment data to pre-dict if they were posted in an abuse or non-abuse subreddit. Because ngram features performed best in the previous experiment, a larger set of sub-missions (1336 per class) was used. A final held out testset was created from 10% of these submis-sions, giving 1202 submissions per class for the devset and 134 per class for the testset. Taking the comments from these submissions yielded 4712 abuse and 19349 non-abuse comments for the de-vset and 642 abuse and 2264 non-abuse comments Table 5: Top 10 features based on Linear SVM weights using only ngrams from submissions. The classifier may be relying heavily on the anxi-ety and anger subreddits to discriminate between abuse and non-abuse, as indicated by the sharp drop in SVM weight from anger to job . Abuse word weights are more evenly distributed. for the testset. 10-fold cross-validation was used on the devset to tune the classifier. Using a Linear SVM with C=1 achieved an F1 score of 0 . 70  X  . 02 on the devset. On the held out testset, it achieved a precision of 0.68, recall of 0.62, and F1 score of 0.65. Examining its weights gives features similar to those in Table 5, with additional empathetic dis-course like thank , hug , and safe in the abuse class. 4.3 Comment and Submission Text Concatenating the comments to their respective submissions may improve results, but because comments can be completely off-topic or in re-ply to other comments, we experimented with only the top-scoring comments and those most simi-lar to the submission text. To compute similar-ity we used a sum of the word vector representa-tions from Levy and Goldberg (2014) as included in spaCy (Honnibal, 2015) and used cosine simi-larity. Taking only the top 90 th percentile in user voting score and text similarity, we had 2688 abuse comments and 7852 non-abuse comments con-catenated to the 1336 submissions of their class. This method achieves extremely high accuracy of 94%  X  2% on the devset and 92% on the testset us-ing a Linear SVM with C=1. A classifier trained only on the submission text data from the same devset/testset split obtains the lower accuracies of 90%  X  2% on the devset and 86% on the testset, in-dicating that comments can add predictive power. The top features are similar to those in Table 5. 4.4 Uneven Set of Submissions Using the method in Section 4.3 to train the clas-sifier, a larger, uneven set of data was examined (still using only ngrams). This set contained 1336 abuse and 17020 non-abuse instances. From this set, 15% were held out for final examination as a testset and the rest was used as a devset with 5-fold cross-validation. On the devset, an F1 score of 0 . 81  X  0 . 01 was achieved while on the testset it had a precision of 0.84, recall of 0.74, and F1 score of 0.79. The best classifier was a Linear SVM with C=100. The confusion matrix of the testset is in Table 4.4.
 Actual Class Table 6: Confusion matrix on the testset of the Abuse/Non-Abuse classifier.

This classifier has good precision for the abuse class, and decent recall, meaning that there can be confidence that submissions flagged as abuse are indeed about abuse . By applying this classifier to a large held out set of data, these results suggest that many potentially relevant submissions would be flagged for examination, and they would mostly be about abuse . 4.5 Testing on Completely Held Out To get a sense of efficacy in the wild in detecting submissions about abuse, the best classifier from Section 4.4 was taken (trained on the devset data) and run on a large set of submissions from the relationships and relationship advice subreddits. These subreddits are general forums for discussion and advice on any relationship (not necessarily in-timate). Their submissions tend to be long, de-scriptive, and extremely personal.

After running the abuse classifier on the submis-sions from these subreddits with at least 1 com-ment (13623 in total, with their 90 th percentile comments concatenated), 423 submissions were flagged as being about abuse. 101 of these 423 were annotated by 3 annotators (co-authors), us-ing the labels A (the submission discusses an abu-sive relationship), M (off-hand mention of abuse), N (not about abuse), and O (off-topic submission or other).

From the three annotators X  annotations, on av-erage 59% are A , 16% are M , 23% are N , and 2% are O . The percentage of overall agreement was 72% and Randolph X  X  free-marginal multirater kappa (Warrens, 2010) score was 0.63. Annota-tors occasionally had a hard time distinguishing between A and M , as context may have been miss-ing. Combining the two by considering all M as A , the average percent of A increases to 75%, the percentage of overall agreement improves to 86% and the kappa score improves to 0.79. Taking the statistic that on average 75% of the flagged sub-missions in the annotated subset are about abuse or have a mention of abuse indicates that this clas-sifier should hopefully have a precision of around 0.75 on unseen Reddit data at large. Understand-ably, the precision drops by about .1 compared to its use on the subreddits it was trained and tested on. A precision of 0.75 on this set of data would mean that any statistics from this set may include some noise, but overall, the trends should reveal important results about abuse. This work provides an analysis of domestic abuse using the online social site Reddit. Language anal-ysis reveals interesting patterns used in discussing abuse, as well as initial data about the semantic actions and stakeholders involved in abusive rela-tionships. Multiple classifiers were implemented to determine the top semantic and linguistic fea-tures in detecting abusive relationships. Simpler features such as ngrams performed above the more complex predicate and role labels extracted from a semantic role labeler, though the more complex structures contribute to interesting insights in data analysis. Future work could use a larger training set from multiple online sites to analyze the pat-terns of online abuse discourse across varied fo-rums.
 This work was supported in part by a GCCIS Kodak Endowed Chair Fund Health Information Technology Strategic Initiative Grant and NSF Award #SES-1111016.
