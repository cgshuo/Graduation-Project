 We study the problem of building the classification model for a target class in the absence of any labeled training ex-ample for that class. To address this difficult learning prob-lem, we extend the idea of transfer learning by assuming that the following side information is available: (i) a coll ec-tion of labeled examples belonging to other classes in the problem domain, called the auxiliary classes; (ii) the clas s information including the prior of the target class and the correlation between the target class and the auxiliary clas ses. Our goal is to construct the classification model for the tar-get class by leveraging the above data and information. We refer to this learning problem as unsupervised transfer classification . Our framework is based on the generalized maximum entropy model that is effective in transferring the label information of the auxiliary classes to the target cla ss. A theoretical analysis shows that under certain assumption , the classification model obtained by the proposed approach converges to the optimal model when it is learned from the labeled examples for the target class. Empirical study on text categorization over four different data sets verifies th e effectiveness of the proposed approach.
 I.5 [ Pattern Recognition ]: Design Methodology X  Classi-fier design and evaluation ; H.1 [ Models and Principles ]: Miscellaneous Algorithms, Experimentation Unsupervised Transfer Classification, Text Categorizatio n, Generalized Maximum Entropy
Semi-supervised learning is designed to reduce the num-ber of labeled examples for building accurate classificatio n model by utilizing unlabeled data. Many semi-supervised learning techniques ([31] and references therein) have bee n developed and successfully applied to text categorization . In this work, we examine the problem of learning the classifica-tion model for a given class, called the target class, withou t a single labeled training example for that class. This can be viewed as an extreme case of semi-supervised learning. In order to address this difficult learning problem, we extend the idea of transfer learning by assuming that the following side information is available Our goal is to construct the classification model for the tar-get class by effectively transferring the label information of the auxiliary classes to the target class. We refer to the above problem as unsupervised transfer classification in order to distinguish from most studies in transfer learni ng for classification where some labeled examples are availabl e for the target class.

Unsupervised transfer classification is particularly usef ul when the target class does not have any labeled example. This scenario is encountered in many applications. For in-stance, in automatic image annotation [12], given the lim-ited size of the vocabulary that is used for training, we ofte n encounter the problem of how to annotate images with a keyword outside the training vocabulary. A similar problem arises in social tagging [14] when some of the tags are so rare that it becomes difficult to collect any useful example for these tags. The unsupervised transfer classification ca n be applied to these problems by automatically learning an annotation model for the new keyword (or rare tag) even if it does not have a single labeled example.

We address the problem of unsupervised transfer classifi-cation by effectively transferring the label information of the auxiliary classes to the target class. We propose a framewor k based on the generalized maximum entropy model that effec-tively leverages the class information as well as the traini ng examples for the auxiliary classes. Our analysis shows that under certain assumption, the classification model found by the proposed approach will converge to the optimal model when it is learned from the labeled examples for the target class. An empirical study on text categorization over four different data sets verifies the efficacy of the proposed ap-proach. The contributions of this paper are summarized as follows:
The remainder of this paper is organized as follows. In sec-tion 2, we review some related work. In section 3, we present the framework for unsupervised transfer classification. We present experimental results in section 4, and finally con-clude in section 5.
Our work is related to transfer learning, multi-label learn -ing, and maximum entropy learning.

Transfer Learning The objective of transfer learning is to transfer the knowledge from the source domain to the target domain. The transferred knowledge can take various forms, such as knowledge about training examples [7, 11, 17] , knowledge of feature representation [2, 3, 8], and knowledg e of model parameters [16, 4, 27] and many others [21]. Since the objective of our work is to transfer the label informatio n of the auxiliary classes to the target class, it is closely re -lated to the study of transfer learning. Unlike most studies in transfer learning for classification that require labele d ex-amples for the target class, we assume no labeled example is available for the target class, making it a more challenging and realistic problem in many applications.

Multi-label Learning Several multi-label learning algo-rithms [26, 29, 30, 13, 10] have been designed to exploit the correlation between classes for constructing classific a-tion models. [26] proposes a generative model for multi-lab el learning to incorporate the pairwise class correlation inf or-mation; [29] exploits the class correlation by introducing a common prior shared by all classes; Zhu et al. [30] propose a maximum entropy model for multi-label learning that ex-ploits the class correlation information. [13] explores th e class correlation in a label propagation framework. In [10] , a common subspace is assumed to be shared by all the labels. Our work is related to these studies in exploring the class correlation for classification, but differs from these studi es in that while they are focused on supervised learning, the ob-jective of this work is to build a classification model withou t a single labeled example for the target class.

Maximum Entropy Learning Maximum entropy prin-ciple has been successfully applied to natural language pro -cessing [6, 24, 23] and text categorization [20, 30, 18]. The proposed maximum entropy model generalizes the tradi-tional model by introducing (i) inequality constraints int o the model to replace the original equality constraints, and (ii) different ways for estimating the sufficient statistics. Note that the proposed generalized maximum entropy model is closely related to [1] in which inequality constraints ar e introduced into the framework of divergence minimization. Our generalized maximum entropy model differs from [1] in that we introduce a regularization term for the errors re-lated to the inequality constraints. The regularization te rm is particularly important for maximum entropy model since the dual problem of maximum entropy model is in general not strongly convex. Additionally, we want to point out that the generalized maximum entropy model is also pre-sented in the work of Yang et al. [28], but we emphasize that this work differs from [28] in that we solve the problem of unsupervised transfer classification rather than learni ng from noisy side information.

Finally, our work is also closely related to [15, 22]. Simila r to our problem, the label information is not given explicitl y in these studies, and the goal is to build classification mod-els from multiple sets of unlabeled data for which only the class proportion information is available. Unlike these tw o studies, in our work, the class information is utilized to as -sist the transfer of label information of the auxiliary clas ses to the target class.
In this section, we first present the problem of unsuper-vised transfer classification. We then present a generalize d maximum entropy model, and a framework for unsupervised transfer classification based on the generalized maximum entropy model. The optimization algorithm and the con-sistency analysis of the proposed method are also presented . The issues of how to obtain the class information and the specific assumption made by the proposed framework are addressed at the end of this section.
Let D = { x i  X  X  , i = 1 , . . . , n } be a set of training examples that are assigned to the auxiliary classes C = { c 1 , . . . , c K } , where K is the number of the auxiliary classes. of class c k to example x i . Note that each example can be assigned to multiple classes. By using a standard supervise d learning method (e.g., logistic regression model), we can learn a binary prediction function, denoted by p ( y k = 1 | x ), that outputs the likelihood of assigning x to class c k . Our objective however is to learn a binary prediction function p ( y t | x ) for a target class c t /  X  X  that does not have a sin-gle labeled example. In order to learn p ( y t | x ) for the target class c t , we need to transfer the label information from the auxiliary classes in C to the target class. To this end, we assume the following class information is available: (i) th e ditional probabilities between the target class and the aux -refer to this learning problem as unsupervised transfer classification .

A straightforward approach for this problem is to con-struct the prediction function p ( y t | x ) by a weighted combi-nation of the prediction functions for the auxiliary classe s, i.e., Figure 1: An illustrative example showing the limi-tation of the combination approach in (1).
 We refer to the method in (1) as the combination of classi-fication models, or cModel for short.

The major shortcoming of the combination approach is that it imposes a strong constraint in constructing the pre-diction function for the target class c t . In particular, if a training example is not a support vector 1 for any of the auxiliary classes in C , it will never be a support vector for the target class c t , leading to a serious limitation in building classification model for c t .

To illustrate this limitation, consider the problem in Fig-ure 1, in which we have four auxiliary classes c 1 , c 2 , c that are highlighted by four shaded octagons. The decision boundaries that distinguish each class from the other three classes are highlighted by four solid lines. Assume SVM is used to learn the individual classifiers. Note that since the training examples in the four small solid circles are not the closest to any of the decision boundaries, they will not be the support vectors for the four auxiliary classes. Suppose the target class c t is essentially a combination of c 1 and c whose decision boundary is highlighted by the horizonal dashed line. In the case of supervised learning, since the ex -amples in the small solid circles are the closest to the dashe d line, they should be support vectors for c t . Unfortunately, in the prediction function generated by the combination ap-proach, none of these examples will be support vectors for c , leading to a suboptimal model for c t .
Before we present the generalized maximum entropy model, we first motivate the proposed approach by explaining why maximum entropy could be an attractive approach for unsu-pervised transfer classification. The formulation of the tr a-ditional maximum entropy model for classification is given as follows: where f j ( ) is the j th  X  X  1 , , d } feature function defined on X and  X  ( y i , y ) is the Kronecker delta function that out-Here, we slightly abuse the terminology of support vectors. For a non-SVM classifier, support vector is referred to any training example that is heavily weighted by the classifier. puts 1 if y i = y and zero, otherwise. It is important to note that in order to train a maximum entropy model, we only need to know the quantity the sufficient statistics), not the class assignments of in-dividual examples. In fact, if we have means to approx-imately compute without knowing the class label of each example, we can modify the maximum entropy model in (2) by replacing P i =1  X  ( y i , y ) f j ( x i ) /n with The key idea of the proposed approach is to estimate b f j using the class information, which will be elaborated later .
Although it appears intuitively correct, the formulation suggested in (3) could be problematic. First, for an arbi-trarily approximate estimate b f j ( y ), the problem in (3) may not even be feasible. For instance, in the case of binary classification, i.e., y  X  X  0 , 1 } , by adding the constraints for b f ( y = 1) and b f j ( y = 0), we will have the following implicit constraint If two arbitrary estimates b f j ( y = 0) and b f j ( y = 1) do not satisfy the constraint in (4), they will lead to an infeasibl e optimization problem for (3). More importantly, using the equality constraints in the maximum entropy model in (2) is by itself problematic. Note that both sides of the equalit y constraint in (2) can be interpreted as empirical estimates following theorem, the two quantities are identical only wh en the number of examples n goes to infinity, and could be significantly different when n is small.
 Theorem 1. Concentration of MaxEnt X  X  Constraint Assume ( x i , y i ) are i.i.d. samples from an unknown distri-bution P ( X, Y ) . The equality constraint in (2) for any j and y holds with probability 1 when the number of examples n approaches infinity. However, with finite n , the following inequality holds for any  X  &gt; 0 where R j = max The proof for the theorem can be found in Appendix A. Based on the above discussion, we relax the equality con-straint in the maximum entropy model into inequality con-straint, max  X  1 tor  X  y . Note that in the above formulation, to account for the difference between the two estimates, we introduce dummy variables  X  yj . In addition, we introduce a regularization term k  X  k 2 / (2  X  ) into the objective for these dummy variables so that they can be determined automatically.  X  is a regular-ization parameter that will be determined empirically. We refer to the formulation in (5) as the Generalized Maxi-mum Entropy Model . It includes two distinguished fea-tures compared to the traditional maximum entropy model: (i) it allows different ways for estimating E X,Y [  X  ( Y, y ) f (i.e., b f j ( y )) that could potentially avoid the requirement of knowing the class assignments of all training examples, and (ii) it uses the inequality constraint to allow the mismatch between data and the prediction function p ( y | x ). With the inequality constraint, we essentially have where  X  y = 1  X  y and the upper bound is derived from the following implicit constraint The following proposition shows the relationship between the generalized maximum entropy model in (5) and the reg-ularized logistic regression model.
 Proposition 1. When b f j ( y ) = kk = kk 2 , the dual problem of (5) is equivalent to the reg-ularized logistic regression model, i.e., min where  X  y i = 1 if y i = 1 and  X  y =  X  1 if y i = 0 . Proposition 1 follows directly the result in (10) that will b e presented later.
In order to build a classification model for the target class c , we will apply the generalized maximum entropy model in (5). The key question is how to compute b f j ( y t ), an estimate c , using the class information.

First, notice that using the class prior information p ( y we could write the expectation of feature functions as Thus, b f j ( y t ) can be computed as examples. Therefore, our goal is to compute u x | y t [ f
Second, note that for all the auxiliary classes c k  X  X  , u x | y k [ f j ( x )] can be simply computed as approach is to approximate it by a linear combination of its counterparts for the auxiliary classes. As a result, we need to establish the relationship between u x | y t [ f j { u lowing assumption
Assumption 1 ( A1 ). The following relationship holds for Pr( X | Y k = y k ) for any auxiliary class c k Note that assumption A1 essentially assumes that X is con-ditionally independent of Y k given Y t , i.e. Pr( X | Y t Pr( X | Y t ), which may not be true in real-world applications. Later on we will discuss how to relax this assumption. Given the assumption A1 , we have the following relations for the conditional expectation E X | Y = y [ f j ( X )]: which leads to the following regression relations for u x | y k where  X  is the error term. By putting the regression relations for all the auxiliary classes into the matrix form, we have th e following regression system: where W and U x | y t and b A are defined as follows By solving the regression system in (8) under the implicit lowing solution for U x | y t where
Using the method described in the previous subsection, we will be able to compute b f j ( y t ) using the class information. In this section, we present the optimization algorithm and consistency analysis.
Maximum entropy model is usually solved via its dual problem. Here we show the dual problem for (5) in (10). The derivation is skipped due to space limitations. max where The dual problem can be solved efficiently by using Nesterov method [19] with details given in Algorithm 1. One of the key steps in running the Nesterov method in Algorithm 1 is to solve the constrained optimization problem in (11). It is easy to verify that the optimal solution to (11) is vector into the positive orthant. The convergence rate of th e Nesterov method is O 1 of iterations. The time complexity of the optimization al-gorithm is O ( N ( n + d )). With the computed dual variables  X  1 and  X  0 , the prediction function for the target class c given by
Next, we present the consistency analysis and show that under assumption A1 the solution obtained by the proposed approach will converge to the optimal one trained by the la-beled examples for the target class. Since our approach de-pends on u x | y t [ f j ( x )], which is an estimate for E in the first step of consistency analysis, we bound the differ-ence between these two quantities via the following theorem .
Theorem 2. Assume bounded feature function f j ( x ) , i.e. | f ( x ) | X  R, j = 1 , . . . , d , and the prior for all the auxiliary classes are significantly large, i.e., there exists some pos itive constant  X  &gt; 0 such that p ( y k = 1)  X   X , k = 1 , . . . , K . Under the assumption A1 , for any  X  &gt; 10 Kd exp(  X  n X  2 with probability at least 1  X   X  , we have 4  X  where  X  max ,  X  min are the maximum and minimum eigenvalue of W  X  W , and  X  =  X  max / X  min .
 The proof can be found in Appendix B. As revealed by Theorem 2, the difference between the estimate U x | y t and E
X | Y t [ f ( X )] will essentially diminish when the number of examples n goes to infinity. In the next theorem, we show how the difference in the estimates b f j ( y ) will affect the so-lution to the dual problem in (10).
 Algorithm 1 Solving the dual problem in (10) 1. Input the number of iterations or convergence rate 2. Initialize the approximate solution b 1  X  R 2 d , search 3. In the i th ( i  X  1) step, given b i , a i  X  1 , q i  X  1 4. repeat Step 3 until the input number of iterations is 5. Output (  X  1 ;  X  0 ) = b
Theorem 3. Assume  X  2 norm is in the generalized maxi-mum entropy model, i.e., kk = kk 2 . Let  X   X   X  = (  X   X  1  X  be the solution to the optimization problem in (10) with b f b f = b f o 1 , b f o 0  X  . We have The proof can be found in Appendix C. Combining the re-sults in Theorems 2 and 3, we have the following consistency result for the solution obtained by the proposed approach, which verifies the model obtained by the proposed approach converges to the optimal model learned in the presence of labeled examples for the target class.

Theorem 4. Assume (i)  X  2 norm is used in the general-for any x , and (iii) p ( y k = 1)  X   X , k = 1 , . . . , K for some  X  &gt; 0 . As the number of training examples goes to infi-nite, under the assumption A1 , the optimal solution  X   X  = (  X  1 ,  X   X  0 ) to (10) with b f j ( y t ) = p ( y t ) u x | y t verge to  X   X   X  = (  X   X  1  X  ,  X   X  0  X  ) with probability 1 , where  X  optimal solution to (10) with b f  X  j ( y t ) = p ( y t )E
In this section, we discuss two issues: (i) how to obtain the class information in real-world applications, and (ii) how to relax the assumption A1 .

Obtaining Class Information The class information includes p ( y t = 1 | y k = 1) and p ( y t = 1). One approach is to derive the class information from a different domain that shares the same set of classes as the target domain. For example, in the case of text categorization of language a , we could derive the class information from the labeled documents that are in a different language b . The class in-formation can also be obtained by querying external sources such as a web search engine or a particular web site. For in-stance, to classify research articles into predefined topic s, we can measure the correlation between two research topics by simply counting the number of returned URLs after querying a search engine with the conjunction of the two topics. Evi-dently, these methods may not obtain an accurate estimate of the class information. However, as will be shown in our empirical study, even with such possibly inaccurate estima te of the class information, the proposed approach could still yield reasonably accurate prediction for text categorizat ion.
Relaxing Assumption A1 As we discussed before, as-sumption A1 is equivalent to having the independence be-tween X and Y k given Y t , i.e. Pr( X | Y t , Y k ) = Pr( X | Y which may not be true for real-world applications. We can relax this assumption by approximating Pr( X | Y t , Y k ) with a linear combination of Pr( X | Y t ) and Pr( X | Y k ). For in-stance, we could have the following approximations for the probability Pr( X | Y t , Y k ): Pr( X | Y t = 1 , Y k = 0) = Pr( X | Y t = 1) Pr( X | Y t = 0 , Y k = 1) = Pr( X | Y k = 1) Pr( X | Y t = y, Y k = y ) = 1 With the above approximations, a similar result can be de-rived using the procedure described in Section 3.3.
We verify the efficacy of the proposed algorithm for unsu-pervised transfer classification on the problem of text cate -gorization. Four text data sets are used for evaluation: (i)  X  X mc2007 X  [5] data set is used in 2007 SIAM text mining workshop for text mining competition, (ii)  X  X nron X  2 data set includes email messages from about 150 users, mostly senior management of Enron, (iii)  X  X ibtex X  data set, pro-cessed by Katakis et al. [14], contains the metadata for the bibtex items such as title and authors of papers and (iv)  X  X elicious X  [25] data set extracted from the delicious soci al bookmarking site on April 7 2007; it contains textual de-scription of each web page along with its annotated tags. In our study, we follow the default partition of training data and testing data specified by the authors of the data sets. The statistics of the four data sets are summarized in Ta-ble 1. The last column gives the percentage of the training examples. To preprocess the documents, we normalize the attributes of a document by first dividing them by the sum http://bailando.sims.berkeley.edu/enron_email name #examples #attributes #class %training tmc2007 28596 49060 22 75% enron 1702 1001 53 67% bibtex 7395 1836 159 67% delicious 16105 500 983 80% of all attributes of the document and then taking the square root of the ratios [9]. Each normalized attribute is used as a different feature function f j ( x ).

To test the capability of the proposed algorithm in build-ing the classification model for a target class without a sing le labeled example, we follow the paradigm of  X  X eave one class out X  X ross validation by choosing one class as the target cla ss and using the remaining classes as the auxiliary classes. Th e proposed algorithm is applied to learn a classification mode l for the target class when we only have (i) the assignments of training documents to the auxiliary classes and (ii) the class information. We evaluated the proposed algorithm on both training data 3 and testing data. We repeat the same procedure for every class in each data set, and the result averaged over all the classes in the data set is reported in this study. The Area under ROC curve (AUC) is used as the evaluation metric in our study. Compared to the other evaluation metrics (such as F 1 ), AUC is advantageous in that it does not require the classifier to make explicit binar y decisions and therefore avoids the bias in evaluation cause d by the choice of the threshold. For all the experiments, the regularization parameter  X  is set to  X  = 0 . 01 /n , where n is size of the training set. This choice of  X  usually yields good classification performance.

Besides the combination approach in (1) (i.e., cModel ), we introduce the following two baseline approaches in our study. These two baselines use the same generalized maxi-mum entropy model as the proposed approach. They differ from the proposed approach in how to compute b f j ( y ). In the nation of u x | y k [ f ( x )], i.e., and compute b f j ( y ) using (6) and (4). In the second ap-proach, we first predict the assignments of the target class c for the training examples by a weighted combination of the auxiliary classes in C , i.e., b y = I where I ( z ) is an indicator function that outputs 1 if z is true and zero, otherwise. We then compute b f j ( y ) based on the predictions b y t i , i = 1 , . . . , n , i.e., We refer to the first approach as the generalized maximum entropy model that estimates the expectation by average, or
Note that we do not have the assignments of the training documents to the target class GME-avg for short, and the second one as the combination of class labels, or cLabel for short. Since these two baselines differ from the proposed approach only in computing b f j a comparison to these two baselines will show if the proposed approach for computing b f j ( y ) is effective for unsupervised transfer classification. Finally, we refer to our method as the generalized maximum entropy model that estimates the expectation by regression, or GME-Reg for short.
We compare our method with the three baseline meth-ods. The class information, i.e. the conditional probabili -mated from the training data. Table 2 summarizes the result of AUC for training data, testing data, and for all the data that includes both training data and testing data. Note that since we only have the assignments of the auxiliary classes for the training data, it is therefore valuable to evaluate t he classification accuracy of the target class for the training data. It is not surprising to observe that for all methods in comparison, their performance for training data is in gen-eral better than that for testing data. We also observe that for all the cases, the proposed method GME-Reg outper-forms the baseline methods significantly (student-t test at 95% significance level) except for cLabel on  X  X ibtex X . Our result also reveals that the proposed algorithm is computa-tionally efficient: on a 2.0GHz CPU, 2.0GB memory linux server, the averaged running time of the optimization algo-rithm is 23 seconds for  X  X mc X , 0 . 97 seconds for  X  X nron X , 11 seconds for  X  X ibtex X , and 15 seconds for  X  X elicious X  when th e convergence accuracy is set as 10  X  4 .
In this experiment, we compare the unsupervised trans-fer classification to the supervised classification using the generalized maximum entropy model. The objective of this comparison is to measure the amount of label information transferred from the auxiliary classes to the target class. In particular, to find the number of labeled examples that are needed to achieve the same performance as the unsu-pervised transfer classification, we increase the number of labeled examples for the target class in supervised classifi -cation. Figure 2 shows the result of AUC for all data (i.e., training data + testing data) for both the supervised and the unsupervised classification approaches. To ensure the robustness of our result, for supervised classification, we re-peat each experiment five times and report AUC averaged over five runs. We observe that the label information trans-ferred from the auxiliary classes is indeed significant: for data sets  X  X mc2007 X  and  X  X nron X , the amount of information transferred from the auxiliary classes is equivalent to a fe w hundred labeled examples; for  X  X ibtex X  and  X  X elicious X , it is more valuable and is equivalent to a few thousand labeled examples. Figure 2: Comparison of unsupervised transfer clas-sification to supervised classification with increasing number of labeled training examples
In this experiment, we evaluate the proposed approach with the class information estimated from external sources . We choose  X  X ibtex X  and  X  X elicious X  data sets for evaluation since the class names are given in these two data sets. By re-moving the classes in these data sets that are not meaningful , such as  X 2005 X ,  X 2006 X ,  X  X nd X ,  X  X f X  ,  X ? X ,  X ?? X  etc, we finally obtain a total of 123 classes in  X  X ibtex X  and 920 classes in  X  X elicious X . Two external sources are used for obtaining th e class information for data set  X  X ibtex X : (i) the social book -mark and publication sharing web site bibsonomy 4 , referred to as bib.org for short, and (ii) ACM digital library 5 , re-ferred to as acm.org for short. The external source for ob-taining class information for  X  X elicious X  data set is the de li-cious social bookmarking 6 web site, referred to as deli.com for short. We obtain the class information by sending querie s to the external sources that consist of the class name(s), and computing the class information based on the number of returned entities. The conditional probability is com-puted as p ( y t = 1 | y k = 1) = # ENT ( c t , c k ) / # ENT ( c where # ENT ( c t , c k ) is the number of entities tagged by http://www.bibsonomy.org/tags/ http://portal.acm.org/ http://delicious.com/tag/ Table 3: Classification Accuracy(AUC) using exter-nal class information for  X  X ibtex X  and  X  X elicious X  both class c t and c k and # ENT ( c k ) is the number of en-tities tagged by c k . The class prior p ( y t = 1) is estimated as # ENT ( c t ) / # ENT , where # ENT is the total number of entities in the external source. However, since the total number of entities is unavailable for bib.org and deli.com, we replace # ENT with the sum of entities in all the classes, i.e., # ENT ( c t )+ ing+testing) examples is shown in Table 3. For the conve-nience of comparison, we also include in Table 3 the AUC results using the class information estimated from the data set itself. We observe that the proposed approach still yiel ds reasonably accurate prediction even using class informati on estimated from the external sources. It is not surprising that using the class information estimated from bib.org, th e proposed approach yields better performance on  X  X ibtex X  than using the class information estimated from acm.org because  X  X ibtex X  is actually collected from bib.org. By com -paring to the result of supervised classification in Figure 3 , we find that for  X  X ibtex X , the amount of information trans-ferred from the auxiliary classes is equivalent to 600 label ed examples when using the class information estimated from bib.org, and 100 labeled examples when using the class infor -mation estimated from acm.org. For  X  X elicious X , the equiv-alent number of labeled examples is over 1 , 000 when using deli.com as the external source to estimate the class inform a-tion. These results further confirm the value of unsupervise d transfer classification even with rough estimates of the cla ss information from external sources. Figure 3: Comparison of unsupervised transfer clas-sification to supervised classification with increasing number of labeled training examples
We have considered the challenging problem of unsuper-vised transfer classification whose goal is to build the clas si-fication model for a target class not by its labeled examples but by leveraging the label information of auxiliary classe s. We propose a framework based on the generalized maximum entropy model that effectively transfers the label informa-tion of the auxiliary classes to the target class. We present efficient algorithm for solving the related optimization pro b-lem and consistency analysis for the solution obtained by th e proposed approach. Extensive empirical studies show the promising performance of the framework for unsupervised transfer classification. In the future, we plan to investiga te the performance of the proposed approach on different tasks such as image annotation and with different means of esti-mating the class information such as using the WordNet. This work was supported in part by National Science Foun-dation (IIS-0643494), Office of Naval Research ( N00014-09-1-0663), and Army Research Office (W911NF-09-1-0421). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of NSF, ONR and ARO. Part of this research was supported by WCU(World Class University) program through the National Research Founda-tion of Korea funded by the Ministry of Education, Science and Technology(R31-2008-000-10008-0) to Korea Universit y. We would like to thank the reviewers for their valuable com-ments and thank Ying Liu for her valuable discussion. [1] Y. Altun and A. J. Smola. Unifying divergence [2] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task [3] A. Argyriou, C. A. Micchelli, M. Pontil, and Y. Ying. [4] E. Bonilla, K. M. Chai, and C. Williams. Multi-task [5] V. Chandola, A. Banerjee, and V. Kumar. Anomaly [6] S. F. Chen and R. Rosenfeld. A gaussian prior for [7] W. Dai, Q. Yang, G.-R. Xue, and Y. Yu. Boosting for [8] W. Dai, Q. Yang, G.-R. Xue, and Y. Yu. Self-taught [9] T. Jebara, R. Kondor, A. Howard, K. Bennett, and [10] S. Ji, L. Tang, S. Yu, and J. Ye. Extracting shared [11] J. Jiang and C. Zhai. Instance weighting for domain [12] Y. Jin, L. Khan, L. Wang, and M. Awad. Image [13] F. Kang, R. Jin, and R. Sukthankar. Correlated label [14] I. Katakis, G. Tsoumakas, and I. Vlahavas. Multilabel [15] H. K  X uck and N. de Freitas. Learning about individuals [16] N. D. Lawrence and J. C. Platt. Learning to learn [17] X. Liao, Y. Xue, and L. Carin. Logistic regression [18] A. Mikheev and R. Mooney. Feature lattices and [19] A. Nemirovski. Efficient methods in convex [20] K. Nigam, J. Lafferty, and A. Mccallum. Using [21] S. J. Pan and Q. Yang. A survey on transfer learning. [22] N. Quadrianto, A. J. Smola, T. S. Caetano, and Q. V. [23] A. Ratnaparkhi, J. Reynar, and S. Roukos. A [24] R. Rosenfeld. A maximum entropy approach to [25] G. Tsoumakas, I. Katakis, and I. Vlahavas. Effective [26] N. Ueda and K. Saito. Parametric mixture models for [27] Q. Yang, Y. Chen, G. Xue, W. Dai, and Y. Yu.
 [28] T. Yang, R. Jin, and A. K. Jain. Learning from noisy [29] K. Yu, S. Yu, and V. Tresp. Multi-label informed [30] S. Zhu, X. Ji, W. Xu, and Y. Gong. Multi-labelled [31] X. Zhu. Semi-supervised learning literature survey,
Proof. The theorem can be proved by using McDiarmid X  X  pectation of the quantity is equal to So we can see that 1 are the empirical estimates of above expectations, and unde r i.i.d. assumption we have Following McDiarmid X  X  inequality, we have which imply
Pr 1 n Replacing  X  with 1 Due to limited space, we sketch the proof for theorem 2. u of estimates in b A , as stated in the following lemma.
Lemma 1. Under assumption A1 , we have  X 
Proof. First under assumption A1 , we have similar so-lution for E X | Y t [ f ( X )] Then we have k E ( W  X  W )  X  1 p t (E X [ f ( X )]  X  u x [ f ( x )]) + ( W  X  W )  X  1 ( I  X  p t p  X   X  + = where we use the fact k p t k 2 2  X   X  1 max  X k p t ( W  X  W ) k p
Lemma 2. Assume bounded feature function f j ( x ) , i.e., | f have This lemma can be proved by McDiarmid X  X  inequality and union bound.

Lemma 3. Assume bounded feature function f j ( x ) , i.e., | f ( x ) | X  R, j = 1 , . . . , d , and the prior for all auxiliary classes are significantly large, i.e. there exists some posi tive we have
Proof. To prove this lemma, we first show the bound for We can bound both the numerator denoted by d k uE and the denominator in the above equation with McDiarmid X  X  in-equality, Then with union bound, we have  X  1  X  5 exp(  X   X  2 n ) Since p ( y k = 1)  X   X  , with  X   X   X / 2, we have Again applying the union bound, we have
Pr k  X  A  X  b A k 2 F  X  Kd 4 R X   X  Let  X  = 5 Kd exp(  X   X  2 n ), then with probability 1  X   X  , we have the lemma 3.

Combining the above lemmas together, we complete the proof for theorem 2.
 Let where  X  =  X  1  X  of  X  , which is convex in  X  . Assume  X   X  is the optimal solution to minimizing L (  X  ),  X  o is the optimal solution to minimizing L (  X  ) with where we use the fact that L ( ) is a c r -strongly convex func-tion, and the optimality criterion that  X  L (  X   X  )  X  (  X  0. Then L (  X  o ) = g (  X  o )  X   X  o  X  Coming the above two bounds together, we have i.e.,
