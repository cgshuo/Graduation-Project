 i = j , and 0 otherwise. h w ( x ) = sgn( wx ).
 quadratic risk is given by P 4 i =1 p i ( y i  X  wx i ) 2 .
 equivalently by with p 3 = / 2 and y 3 =  X  1. Let x 4 =  X  1 / with p 4 = / 2 and y 4 = +1. goes to zero.
 However, with this distribution This gives (those with positive w ) having a 0 / 1 risk of .
 Proof. First, note that Let us now compute the expectation according to the posterior Q W , X  of these three terms.  X  E  X  For E  X  For E From all that precedes, we then obtain: and we are done.
 Proof. Let us now prove Equation (6), which is given by right-hand side of Equation (20) and by taking the limit when goes to zero. Now, let Performing the change of variables U = V  X  W gives Now, let ~ A be the vector of H Y defined as and let us denote by A l , the l th component of the vector ~ A . Then This implies that 9.1. An analysis of the argument of the exponential function of the integral I Let In the following, A l denotes the l th component of the vector ~ A . Then, Let us now define the matrix N of dimension N X  X  N Y as Now, let Recall that, w.l.o.g., x i is different from 0 and that  X &gt; 0 . This new change of variables gives CLAIM 1 : For any l = 1 ,..,N Y , let Then, Proof of the claim. From the definition of B l , we have that Note also that Hence, The penultimate equality comes from Equation (27). Thus, Claim 1 is proved. 9.2. Let us transform our integral I into a Gaussian integral Definition 7.  X  Let the operator ? : { 1 ,..,N Y } X { 1 ,..,N X } X  X  X { 1 ,..,N Y N X } be defined as  X  Let ~z be the vector of dimension N Y N X defined as  X  Let ~ X  be the vector of dimension N Y N X defined as  X  Let M be the matrix of dimension ( N Y N X )  X  ( N Y N X ) defined as Note that in what follows, the reader should interpret  X  l as l ? i and  X  m as m ? j . From the definitions above, we have Substituing this expression for Q into the integral I given by Equation (22) gives one of the statements of the following claim.
 CLAIM 2 : Matrix M is positive definite and Before proving Claim 2, let us show that it implies the result. To finish the proof, let us now prove Claim 2.
 Now, from the definition of M , and basic determinant X  X  properties, we have determinant X  X  property, and from the fact that det( X ) = Q N X i =1 x i . ( N [ i ; j ] x i x j ) i ; j (but with a multiplicity augmented by a factor of N Y ). eigenvalue of N . Indeed, because of Equation (34), we have that This, in turn, implies that if N is positive definite, so is M . Hence, to prove Claim 2, we only have to show that N is positive definite and Now, note that Proof. From equation (9) we have it X  X  j -th column.
 Because { u i v | j } ( i,j )  X  X  constitutes an orthonormal basis of R m 2 we have Equation (14) then becomes
