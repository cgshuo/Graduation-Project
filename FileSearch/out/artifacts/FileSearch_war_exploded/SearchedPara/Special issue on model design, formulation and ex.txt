 1. Introduction
Since the inception of the first formal model for Information Retrieval (IR) well documented in ( Salton, 1968 ), a number of different IR models (for example, vector space, probabilistic, fuzzy, logical, inference, language, etc.) have appeared and gained separate mathematical formulations ( Baeza-Yates &amp; Ribeiro-
Neto, 1999 ; Belew, 2000 ; Lalmas, 1998 ; Meadow, Boyce, &amp; Kraft, 1999 ; Salton &amp; McGill, 1983 ; van Rijs-bergen, 1979 ), which, on the one hand, helped in spreading IR into higher education worldwide, and, on the other hand, helped in designing experiments and developing applications.

At the end of 1990s the usage of mathematical and formal methods, and of their associated apparatus in experimental IR, reached a point where the need for a systematic and methodical review was recognised.
This was so that concepts could be clarify, as well as their use within mathematical techniques for IR, and so that new tools could be created for enhancing their applicability in practice. Many new results have stemmed from such a need. For example, it was shown that basic IR models (Boolean, vector space, prob-abilistic, associative) can be formulated in a unified and axiomatic way, and thus mathematical foundations for IR were laid down ( Dominich, 2001 ). More recently, it is argued that basic IR concepts (document, user, query, retrieval) may be viewed as geometrical entities similar to those used in classical Quantum The-ory ( van Rijsbergen, 2004 ).

The series of five consecutive ACM SIGIR workshops in Mathematical/Formal Methods in IR (the first held in Athens, Greece, 2000; and then: New Orleans, 2001, USA; Tampere, 2002, Finland; Toronto, 2002, Canada; Sheffield, 2004, UK) demonstrate that this topic, the usage of mathematical and formal methods in
IR, has since become a standalone research discipline within IR. This special issue includes three significant papers that were presented at the fourth workshop (held in Toronto, 2003). All three papers have been ex-tended and thoroughly reviewed.

The first two papers of this special issue are along the line of a unified mathematical treatment of IR models. In the first paper, Ro  X  lleke, Tsikrika and Kazai propose an ingenious and elegant general mathe-matical framework based on matrix computation. This framework can be used to derive basic IR models, and it can be useful to IR system designers to construct such systems in a more effective way. In the second paper, Zhai and Lafferty propose a general mathematical framework based on function minimisation using
Bayesian decision theory. In addition to deriving a number of basic IR models, it is shown how the pro-posed framework can be used to formulate new IR models, e.g., for subtopic retrieval.
The third paper is a very good example of how mathematical techniques can be used to clarify why a model works effectively. Kontostathis and Pottenger offer a mathematical argument, and support it by extensive experiments, to show how higher order term co-occurrences influence the effectiveness of retrieval using Latent Semantic Indexing. 2. Papers in this issue
Thomas Ro  X  lleke, Theodora Tsikrika, and Gabriella Kazai: A general matrix framework for modelling information retrieval . The paper proposes a framework for IR based on matrix representation. Three spaces, called matrix spaces, are considered: collection, document and query spaces. Each space has two dimensions, and is represented as a matrix. The collection space has a document dimension and a term dimension, and is represented by a binary document-by-term matrix. The document space is based on a binary location-by-term matrix (where locations are entities defined within documents). The query space is represented by two matrices containing relevance assessments made by assessors. The authors then show how key IR concepts (term weighting, such as term frequency and inverse document frequency; evaluation measures, such as precision an recall; ranking) can be modelled formally, as matrix operations, in the pro-posed framework. It is shown how different IR models, namely the vector space, logical, probabilistic infer-ence, language, and probability of relevance models, can be derived within the proposed framework. It is interesting to see, on the one hand, the formulas for the different Retrieval Status Values (RSV) expressed in a unified style, and on the other hand the formulation of the PageRank algorithm within this framework.
The authors argue that the matrix-based framework proposed in their paper can help IR system designers in constructing more efficient applications.

ChengXiang Zhai, and John Lafferty: A risk minimization framework for information retrieval . The pa-per is concerned with formulating a probabilistic IR model as a statistical decision problem. After a brief re-capitalion of the vector space, probabilistic relevance, and probabilistic inference models, a new model, called risk minimization model, is proposed. Retrieval is conceived as a decision process: the system needs to choose a set of documents and present them to the user, who may re-formulate the query, and re-issue it to the system. A query is viewed as the result of some probabilistic process of the user, a document as the output of a probabilistic process associated with a source, while the query is generated using some model. Thus the retrieval process is viewed as a compound decision action: selecting and presenting doc-uments. This process is modelled using Bayesian decision theory as one in which the associated loss or risk should be minimized. By particularizing or quantifying the loss, different models can be formulated: set-based retrieval (the loss does not depend on the presentation strategy), rank-based retrieval (the loss depends on ranking). For the latter case, different particular forms of the loss function are discussed mathematically. The authors also show how subtopic retrieval is also modelled as a risk minimization problem.

April Kontostathis, and William M. Pottenger: A framework for understanding Latent Semantic Indexing (LSI) performance . Latent Semantic Indexing (LSI) is well-known in IR; it is based on a technique called
Singular Value Decomposition (SVD). The paper is concerned with understanding the performance in effec-tiveness of the LSI method. After a description of the LSI algorithm, the authors, using examples, remark that co-occurring terms receive positive cosine similarity values. Thus, an experimental study X  X  X sing the
MED, CRAN, CISI, CACM, NPL and LISA test collections X  X  X f the relation between co-occurring terms and their similarity values is presented: the order of term co-occurrence and the distribution of the similar-ity values. The highest order of co-occurrence observed was five. Second and third order co-occurrences reduce the sparcity of the matrix significantly. The methods used as well the experimental results are described in details. Based on these results, the authors conclude that the higher the order X  X  X nd especially second order X  X  X o-occurrences, the higher the performance of the LSI method. After the experimental part, the authors present a formal mathematical proof that the LSI method encapsulates term co-occurrence information. 3. Conclusion
These papers show explicitly how sophisticated mathematical and formal methods can be exploited to increase our understanding of retrieval models. It is also clear that much fruitful theoretical research re-mains to be done.
 References
