 Sentiment analysis or opinion mining aims to use automated tools to detect subjective information such as opinions, at -titudes, and feelings expressed in text. This paper pro-poses a novel probabilistic modeling framework based on La-tent Dirichlet Allocation (LDA), called joint sentiment/t opic model (JST), which detects sentiment and topic simultane-ously from text. Unlike other machine learning approaches to sentiment classification which often require labeled cor -pora for classifier training, the proposed JST model is fully unsupervised. The model has been evaluated on the movie review dataset to classify the review sentiment polarity an d minimum prior information have also been explored to fur-ther improve the sentiment classification accuracy. Prelim i-nary experiments have shown promising results achieved by JST.
 I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing X  Text analysis Algorithms, Experimentation Sentiment analysis, Opinion mining, Latent Dirichlet Allo -cation, Joint sentiment/topic model
As propelled by the rapid growth of text data, text mining has been applied to discover hidden knowledge from text in many applications and domains. In business sectors, great efforts have been made to find out customers X  sentiments and opinions, often expressed in free text, towards companies X  products and services. However, discovering sentiments an d opinions through manual analysis of a large volume of tex-tual data is extremely difficult. Hence, in recent years, ther e have been much interests in the natural language processing community to develop novel text mining techniques with the capability of accurately extracting customers X  opinions f rom large volumes of unstructured text data.

Among various opinion mining tasks, one of them is senti-ment classification, i.e. whether the semantic orientation of a text is positive, negative or neutral. When applying ma-chine learning to sentiment classification, most existing a p-proaches rely on supervised learning models trained from la -beled corpora where each document has been labeled as pos-itive or negative prior to training. Such labeled corpora ar e not always easily obtained in practical applications. Also , sentiment classification models trained on one domain might not work at all when moving to another domain. Further-more, in a more fine-grained sentiment classification prob-lem (e.g. finding users X  opinions for a particular product feature), topic/feature detection and sentiment classific ation are often performed in a two-stage pipeline process, by first detecting a topic/feature and later assigning a sentiment l a-bel to that particular topic.

Intuitively, sentiment polarities are dependent on topics or domains. Therefore, detecting both topic and sentiment simultaneously should serve a critical function in helping users in terms of opinion mining and summarization. For instance, though the adjective  X  X npredictable X  in a phrase such as  X  X npredictable steering X  may have negative orien-tation in an automobile review, it could also have positive orientation in a phrase like  X  X npredictable plot X  in a movie review [5].

Although much work has been done in detecting topics [2, 6, 20], these lines of work mainly focused on discover-ing and analyzing topics of documents alone, without any analysis of sentiment in the text, which limit the usefulnes s of the mining results. Other work [16, 22, 11, 15, 4, 3, 25] addressed the problem of sentiment detection in various levels (i.e. from word/phrase level, to sentence and docu-ment level). However, none of them can model mixture of topics alongside with sentiment classification, which agai n makes the results less informative to users. Some of the recent work [14, 19] has been aware of this limitation and tried to capture sentiments and mixture of topics simulta-neously. However, Mei et al. [14] does not model sentiment directly and requires post-processing to calculate the pos i-tive/negative coverage in a document in order to identify it s polarity. Titov and McDonald [19] requires some kind of su-pervised settings that the customer reviews should contain ratings for the aspects/features discussed in the text and thus it lacks of the flexibility to adapt to other domains.
In this paper, we focus on document level sentiment clas-sification based on the proposed unsupervised joint senti-ment/topic (JST) model. This model extends the state-of-the-art topic model, Latent Dirichlet Allocation (LDA) , by adding a sentiment layer. Our model distinguishes from other models in that: (1) JST is fully unsupervised; (2) JST can detect sentiment and topic simultaneously. To the best of our knowledge, no other existing approaches present the same merits as our model. We have also explored var-ious approaches for obtaining prior information in order to improve the sentiment detection accuracy. Although the proposed JST model can be easily extended to detect po-larity of text at various granularity levels, in this paper w e mainly focus on reporting our preliminary results on the document-level sentiment classification and briefly presen t the sentiment analysis results on some extracted topics as an example illustration.

The rest of the paper is organized as follows. Section 2 introduces the related work. Section 3 presents the Joint Sentiment/Topic (JST) model. We show the experimental setup in Section 4 and discuss the results based on the movie review dataset 1 in Section 5. Finally, Section 6 concludes the paper and outlines the future work.
Great bulk of work has been focused on the problem of sentiment classification at various levels using machine le arn-ing techniques. Turney and Littman [22] applied an un-supervised learning algorithm to classify the semantic ori -entation in the word/phrase level, based on mutual infor-mation between document phrases and a small set of posi-tive/negative paradigm words like  X  X ood X  and  X  X ad X . Choi et al. [4] dealt with opinion analysis by combining condi-tional random fields (CRFs) and a variation of Autoslog. In the sentence level, a semi-supervised machine learning alg o-rithm was proposed by Pang and Lee [15], which employs a subjectivity detector and minimum cuts in graphs. Another system by Kim and Hovy [11] judges the sentiment of a given sentence by combining the individual word-level sentiment . Eguchi and Lavrenko [5] proposed a generative model that jointly models sentiment words, topic words and sentiment polarity in a sentence as a triple. In more recent work [25], the authors tackled this problem utilizing CRFs and con-sidered both contextual dependency and label redundancy in sentence sentiment classification. Another line of work i s in the document level, where one tries to evaluate the over-all sentiment of a document. The representative work at the early stage can be found in [21, 16], where the former used unsupervised learning and mutual information, which is similar to the approach proposed in [22]; while the latter classified the polarity of movie reviews with the traditiona l supervised text categorization methods. Following this wa y, lots of other approaches have been proposed. For example, McDonald et al. [13] investigated a global structured model that learns to predict sentiment of different levels of granu -larity in text. Blitzer et al. [3] focused on domain adaption for sentiment classifiers with respect to different types of products X  online reviews.

However, as can be easily pointed out, all the aforemen-
Polarity dataset v2.0 URL: http://www.cs.cornell.edu/people/pabo/movie-review-data/ tioned work shares some similar limitations: (1) they only f o-cus on sentiment classification without considering the mix -ture of topics in the text, which is less informative to users and may limit the usefulness of the results; (2) most of the approaches [16, 15, 4, 3, 13, 25] are favored in supervised learning, which require a labeled corpus for training and potentially restrain their applicability to other domains of interest.

Motivated by these observations, we construct an unsu-pervised hierarchical Bayesian model which can classify do c-ument level sentiment and extract mixture of topics simul-taneously. To the best of our knowledge, not much work has been done regarding this particular problem. However, there are indeed several lines of work which are quite close to our vision [14, 20, 19].
 One of the most closely related work is the Topic-Sentiment Model (TSM) [14], which jointly models the mixture of top-ics and sentiment predictions for the entire document. How-ever, there are several intrinsical differences between JST and TSM. First of all, TSM is essentially based on the Prob-abilistic Latent Semantic Indexing (pLSI) [8] model with an extra background component and two additional senti-ment subtopics, and thus suffers from the problems of infer-encing on new document and overfitting the data, both of which are known as the deficits of pLSI. JST overcomes these shortcomings as it is based on LDA with a better statisti-cal foundation. Regarding topic extraction, TSM samples a word either from the background component model or topi-cal themes where the latter are further categorized into thr ee sub-categories, i.e. neutral, positive and negative senti ment models. In contrast, in JST one draws a word from the dis-tribution over words jointly defined by topic and sentiment label that chosen in the first place. Thirdly, for sentiment detection, TSM requires postprocessing to calculate the se n-timent coverage of a document, while in JST the document sentiment can be directly obtained from the probability dis -tribution of sentiment label given document.

Other models by Titov and McDonald [20, 19] are also closely related to ours, since they are all based on the state -of-the-art topic model LDA. First proposed in [20], the Mult i-Grain Latent Dirichlet Allocation model (MG-LDA) is ar-gued to be more appropriate to build topics that are rep-resentative of ratable aspects of objects from online user reviews, by allowing terms being generated from either a global topic or a local topic. Being aware of the limitation that MG-LDA is still purely topic based without consid-ering the associations between topics and sentiments, Tito v and McDonald further proposed the Multi-Aspect Sentiment model (MAS) [19] by extending the MG-LDA framework. The major improvement of MAS is that it can aggregate sentiment texts for the sentiment summary of each rating aspect extracted from the MG-LDA. Our model differs from MAS in several aspects: MAS works on a supervised setting as it requires that every aspect is rated at least in some docu -ments, which is practically infeasible in real life applica tions, while our JST model is fully unsupervised with only min-imum prior information being incorporated, which in turn has more flexibilities; MAS focuses on extracting text for sentiment summaries of each aspect ratings while we pre-dict the sentiment orientation in the document level.
The Latent Dirichlet Allocation (LDA) model, as shown in Figure 1(a), is one of the most popular topic models based upon the assumption that documents are mixture of topics, where a topic is a probability distribution over words [2, 18]. The LDA model is effectively a generative model from which a new document can be generated in a predefined probabilistic procedure. Compared to another commonly used generative model Probabilistic Latent Semantic Index -ing (pLSI) [8], LDA has a better statistical foundation by defining the topic-document distribution  X  , which allows in-ferencing on new document based on previously estimated model and avoids the problem of overfitting, where both are known as the deficits of pLSI. Generally, the procedure of generating each word in a document under LDA can be bro-ken down into two stages. One firstly chooses a distribution over a mixture of K topics. Following that, one picks up a topic randomly from the topic distribution, and draws a word from that topic according to the topic X  X  word proba-bility distribution.

The existing framework of LDA has three hierarchical lay-ers, where topics are associated with documents, and words are associated with topics. In order to model document sen-timents, we propose a joint sentiment/topic (JST) model by adding an additional sentiment layer between the docu-ment and the topic layer. Hence, JST is effectively a four-layer model, where sentiment labels are associated with doc -uments, under which topics are associated with sentiment labels and words are associated with both sentiment labels and topics. A graphical model of JST is represented in Fig-ure 1(b).

Assume that we have a corpus with a collection of D documents denoted by C = { d 1 , d 2 , ..., d D } ; each docu-ment in the corpus is a sequence of N d words denoted by d = ( w 1 , w 2 , ..., w N d ), and each word in the document is an item from a vocabulary index with V distinct terms de-noted by { 1 , 2 , ..., V } . Also, let S be the number of distinct sentiment labels, and T be the total number of topics. The procedure of generating a word w i in document d boils down to three stages. Firstly, one chooses a sentiment label l from the document specific sentiment distribution  X  d . Following that, one chooses a topic randomly from the topic distri-bution  X  l,d , where  X  l,d is chosen conditioned on the senti-ment label l . It is worth noting at this point that the topic-document distribution of JST is different from the one of LDA. In LDA, there is only one topic-document distribution  X  for each individual document. In contrast, each document in JST is associated with S (number of sentiment labels) topic-document distributions, each of which corresponds t o a sentiment label l with the same number of topics. This feature essentially provides means for the JST model to mea-sure the sentiment of topics. Finally, one draws a word from distribution over words defined by the topic and sentiment label, which is again different from LDA that a word is sam-pled from the word distribution only defined by topic.
The formal definition of the generative process which cor-responds to the hierarchical Bayesian model shown in Fig-ure 1(b) is as follows:
The hyperparameters  X  and  X  in JST can be treated as the prior observation counts for the number of times topic j associated with sentiment label l sampled from a docu-ment and the number of times words sampled from topic j associated with sentiment label l respectively, before hav-ing observed any actual words. Similarly, the hyperparame-ter  X  can be interpreted as the prior observation counts for the number of times sentiment label l sampled from docu-ment before any words from the corpus is observed. In JST, there are three sets of latent variables that we need to infer , including: the joint sentiment/topic-document distribut ion  X  , the joint sentiment/topic-word distribution  X  , and the sentiment-document distribution  X  . We will see later in the paper that the sentiment-document distribution  X  plays an important role in determining the document polarity.
In order to obtain the distributions of  X  ,  X  and  X  , we firstly estimate the posterior distribution over z , i.e the as-signment of word tokens to topics and sentiment labels. The sampling distribution for a word given the remaining topics and sentiment labels is P ( z t = j, l t = k | w , z  X  t , l where z  X  t and l  X  t are vector of assignments of topics and labels for all the words in the collection except for the word at position t in document d .

The joint probability of the topic/sentiment label assign-ments and the words can be factored into the following three terms: For the first term, by integrating out  X  , we obtain: where V is the size of the vocabulary, T is the total number of topics, S is the total number of sentiment labels, N i,j,k is the number of times word i appeared in topic j and with sentiment label k . N j,k is the number of times words as-signed to topic j and sentiment label k , and  X  is the gamma function.
 For the second term, by integrating out  X  , we obtain: where S is the total number of sentiment labels, D is the total number of documents in the collection, N j,k,d is the number of times a word from document d has been associ-ated with topic j and sentiment label k . N k,d is the number of times sentiment label k has been assigned to some word tokens in document d .
 For the third term, by integrating out  X  , we obtain: where D is the total number of documents in the collection, N k,d is the number of times sentiment label k has been as-signed to some word tokens in document d . N d is the total number of words in the document collection.

Gibbs sampling will sequentially sample each variable of interest, z t and l t here, from the distribution over that vari-able given the current values of all other variables and the data. Letting the subscript  X  t denote a quantity that ex-cludes data from t th position, the conditional posterior for z and l t is:
Equation 5 is the conditional probability derived by margin al-izing out the random variables  X  ,  X  , and  X  . A sample ob-tained from the Markov chain can be used to approximate the distribution of words in topics and sentiment labels:
The approximated predictive distribution over topics for sentiment label is:
Finally, the approximated predictive distribution over se n-timent label for document is:
The pseudo code for the Gibbs sampling procedure of JST is shown in Figure 2.
A variation of JST model is presented in Figure 1(c), namely tying-JST model. The major difference between tying-JST and JST model falls into that, in order to sample a word in a document during the generative process, one has to choose a topic-document distribution  X  d for every docu-ment under the JST model, whereas in tying-JST there is only one topic-document distribution  X  which accounts for all the documents in the corpus. Therefore, during the Gibbs sampling procedure, rather than having a  X  matrix with di-mension T  X  S  X  D as for JST, the  X  matrix of tying-JST has only T  X  S dimension. As a result, the approximated predic-tive distribution over topics for sentiment label is differe nt from Equation 7 and should be reformulated as: where T is the total number of topics, N j,k is the total num-ber of times topic j is associated with sentiment label k , and N k is total number of times that a word is associated with sentiment label k .

Experimental results will be presented in Section 5 to com-pare the performance of the JST and the tying-JST model.
In this section, we present the experimental setup of doc-ument polarity classification and topic extraction based on the movie review dataset. This dataset consists of two cat-egories of free format movie review texts, with their overal l sentiment polarity labeled either positive or negative. Ho w-ever, one should note that we do not use any of the polarity label information of the dataset in our experiments but only for evaluating the performance of the JST model, as our model is fully unsupervised.
Preprocessing was performed on the movie review data before the subsequent experiments. Firstly, punctuation, numbers and other non-alphabet characters were removed. Secondly, for the purpose of reducing the vocabulary size and addressing the issue of data sparseness, stemming was performed using the Porter X  X  stemmer algorithm [17]. Stop words were also removed based on a stop word list 2 . Af-ter preprocessing, the corpus contains 2000 documents and 627,317 words with 25,166 distinct terms.
As has been pointed out by Pang et al. [16], the sen-timent classification problem is somehow more challenging than the traditional topic-based classification, since sen ti-ment can be expressed in a more subtle manner while topics can be identified more easily according to the co-occurrence of keywords. One of the directions for improving the senti-ment detection accuracy is to incorporate prior informatio n or subjectivity lexicon (i.e., words bearing positive or ne ga-tive polarity), which can be obtained in many different ways. Some approach annotates polarity to words based on man-ually constructed Appraisal Groups [24]. Other approach generates subjectivity lexicons in a semi-automatic manne r [1]. More recently, Kaji and Kitsuregawa [9] proposed a method which can build polarity-tagged corpus from HTML documents fully automatically. While subjectivity lexico n generation is beyond the scope of this paper, here in our experiments, we investigated incorporating prior informa -tion obtained in four different ways into the JST and the tying-JST model, and explored how the prior information can improve the sentiment classification accuracy. Paradigm word list The paradigm word list consists of a set of positive and negative words, e.g. excellent and rubbish . These lexicon words can be simply treated as the paradigms for defining the positive and negative semantic orientation , rather than for the purpose of training the algorithm [22].
The majority of the words were derived from the word lists used by Pang et al. [16] for their baseline result tests, with punctuation like  X ? X  and  X ! X  removed. However, we did notice the difference that the movie review data used by Pang et al. [16] is an older version with only 700 positive and 700 negative movie reviews, compared to the newer version we used that contains 1000 positive and 1000 negative doc-uments. Hence, we added some additional paradigm words to the original list by reexamining a small portion of the corpus based on a very preliminary check of word frequency counts. Finally, the resulting paradigm word list contains 21 positive and 21 negative paradigm words respectively, as shown in Table 1.
 Mutual information (MI) In statistical language mod-eling, mutual information is a criterion widely used for cal -culating the semantic association between words. Here we use mutual information to select the words that have strong http://ir.dcs.gla.ac.uk/resources/linguistic utils/stop words/ association with positive or negative sentiment classes. T he top 20 words within each individual sentiment class were selected based on their MI scores and incorporated as prior information for our models.
 Full subjectivity lexicon We also explored using the publicly available subjectivity word list with establishe d po-sists of 2718 positive and 4911 negative words 4 . By match-ing the words in the MPQA subjectivity lexicon with the vocabulary (with 25,166 distinct terms) of the movie review dataset, we finally obtained a subset of 1335 positive, 2214 negative words.
 Filtered subjectivity lexicon The filtered subjectivity lexicon was obtained by removing from the full subjectiv-ity lexicon the words occurred less than 50 times in the movie review dataset. The words whose polarity changed after stemming were also removed automatically. Finally, the filtered subjectivity lexicon contains 374 positive and 675 negative words.

Although one may argue that the paradigm word list and the MI extracted words seem requiring certain supervision information from the corpus itself, the subjectivity lexic on used here is fully domain-independent and does not bear any supervision information specifically to the movie revie w dataset. In fact, the JST model with the filtered subjectivit y lexicon achieved better performance than the ones using the prior information obtained from paradigm word list or MI extracted words as can be seen later in Section 5. While it is well-known that sentiment classifiers trained on one domain often fail to produce satisfactory results in another domai n, we speculate that the unsupervised nature of our JST model makes it highly portable to other domains.
We modified Phan X  X  GibbsLDA++ package 5 for the JST and tying-JST model implementation. In the experiments, the prior information was only utilized during the initiali za-tion of posterior distribution z , i.e. assignment of word token to sentiment label and topic. We chose a total number of 3 sentiment labels representing positive, negative and neut ral, considering the fact that the sentiment of any word can be categorized into one of these three classes. The initializa tion starts by comparing each word token in the corpus against the words in the sentiment word list as described in Sec-tion 4.2. If there is a match, the word token is assigned with the corresponding sentiment label. Otherwise, a sentiment label is randomly sampled for a word token.
In this section, we will present and discuss the experi-mental results of both document sentiment classification an d topic extraction, based on the movie review dataset.
The document sentiment is classified based on P ( l | d ), the probability of sentiment label given document, which is ap-proximated using Equation 8 in the implementation. In our ity lexicon since the number of neutral words is small and many of the neutral words have multiple polarities, e.g. bot h neutral and positive. http://gibbslda.sourceforge.net/ Prior information (pos./neg.) pos. neg. overall pos. neg. overall Without prior information 0/0 63 56.6 59.8 59.2 53.8 56.5 Paradigm words 21/21 70.8 77.5 74.2 74.2 71.3 73.1 Paradigm words + MI 41/41 76.6 82.3 79.5 78 73.1 75.6 Full subjectivity lexicon 1335/2214 74.1 66.7 70.4 77.6 69 73.3 Filtered subjectivity lexicon 374/675 84.2 81.5 82.8 84.6 73.1 78.9 Pang et al. (2002) [16] N/A Classifier used: SVMs Best accuracy: 82.9% experiments, we only consider the probability of positive a nd negative label given document, with the neutral label prob-ability being ignored. There are two main reasons. Firstly, movie review sentiment classification in our case is effec-tively a binary classification problem, i.e. documents are being classified either as positive or negative, without the alternative of neutral. Secondly, the prior information we incorporated merely contributes to the positive and negati ve words, and consequently there will be much more influence on the probability distribution of positive and negative la bel given document, rather than the distribution of neutral la-bel given document. Therefore, we define that a document d is classified as a positive-sentiment document if its proba-bility of positive sentiment label given document P ( l pos is greater than its probability of negative sentiment label given document P ( l neg | d ), and vice versa.

In this section, we show how prior information improves the sentiment classification accuracy of the JST and tying-JST models and how topic mixtures affect the performance of our models.
Table 2 shows the sentiment classification accuracy at doc-ument level by incorporating various prior information. Th e number of polarity (positive and negative) words in various subjectivity word list is also listed. In all of the results showed in the table,  X  is set to 50 # topics ,  X  is set to 0.01. It should be noted that while LDA can produce reasonable re-sults with a simple uniform Dirichlet prior for its hyperpa-rameters, asymmetric prior  X  for sentiment-document dis-tribution should be used since it captures different corre-lations among sentiment labels. In our experiments,  X  is set to 0.01 for positive sentiment label and 5 for negative sentiment label. The setting for  X  was determined empir-ically. It is worth pointing out that hyperparameters can be learned from data directly by maximum likelihood or maximum a posteriori estimation [23]. Alternatively, an ap -proximation approach such as moment matching could also be used to avoid iterative methods for the sake of simplic-ity and speed [12]. We leave the estimation of  X  in a more principled way as future work.

It can be observed from Table 2 that without incorporat-ing any prior information, JST only achieved around 60% overall accuracy. By incorporating merely 21 positive and 21 negative paradigm words, a significant performance im-provement is observed with JST and tying-JST giving an overall of 74.2% and 73.1% accuracy respectively. We also experimented the combination of paradigm words and mu-tual information and evaluated how mutual information can help to improve the sentiment classification accuracy. We extracted the top 20 positive/negative words based on the MI value calculated from the 40 randomly selected labeled documents from the movie review dataset with equal num-ber of positive and negative documents. Plus the paradigm words listed in Table 1, the total number of positive and negative words is 41 each. It can be observed that there is a considerable improvement in classification accuracy afte r incorporating the MI-extracted words, with 5.3% and 2.5% improvement for JST and tying-JST respectively.

Subjectivity lexicons have attracted increasing focus in previous work [1]. Intuitively, one might expect that with a larger subjectivity lexicon and hence an increasing num-ber of polarity words, sentiment classification performanc e would be improved since an overall polarity of a text can be inferred from the aggregated polarity of its individual words. However, the results shown in Table 2 reveal that incorporating the full subjectivity lexicon with 1335 posi -tive and 2214 negative words in fact hurts the performance of both JST and tying-JST, with a relatively poor overall accuracy of 70.4% and 73.3% being achieved respectively. In contrast, with the filtered subjectivity lexicon by remov -ing the infrequent polarity words, the performance of both models improves. Thus, the full subjectivity lexicon actua lly introduces more noise into the models and hence resulted in poorer performance. Also, the yielding results (82.8% for JST and 78.9% for tying-JST) are actually better than the performance by incorporating any aforementioned prior in-formation.

We also observe that tying-JST performed consistently worse than the JST model except for the case of incorporat-ing full subjectivity lexicon as prior information. Theref ore, JST seems to be a more reasonable model design in terms of sentiment classification.
In another set of experiments, we followed the approach in [15] and performed subjectivity detection (with sentenc es that do not express any opinions removed) prior to sentiment classification. Subjective sentences were extracted from t he original movie review dataset using the LingPipe package 6 First, we trained the subjectivity classifier based on the Su b-http://alias-i.com/lingpipe/demos/tutorial/sentimen t/read-me.html jectivity v1.0 dataset 7 which contains 5000 subjective and 5000 objective sentences. The trained classifier was then used to extract the subjective sentences from the movie re-view dataset, which reduces each single document to 5 to 25 sentences. After subjectivity detection and data preproce ss-ing as described in Section 4.1, the dataset, which we named as X  X ubjective MR X , still contains 2000 documents but with a total of 334,336 words and 18,013 distinct terms (c.f. 25,16 6 distinct terms without subjectivity detection).

It can be seen from Table 2 that the best performance for both JST and tying-JST is obtained on the subjective MR dataset with the prior sentiment label information ob-tained from the filtered subjectivity lexicon, where an over all accuracy of 84.6% and 82% was achieved by JST and tying-JST respectively. This is a clear improvement over 82.8% and 78.9% when no subjectivity detection was performed. It suggests that though the subjective MR dataset is in a much compressed form, it is more effective than the full dataset as it retains comparable polarity information in a much cleane r way [15].
For comparison, document-level sentiment classification results on the movie review dataset from four previous stud-ies are also listed in the last four rows of Table 2. The best result reported in [16] is 82.9%, which is attained by sup-port vector machines (SVMs) using bag-of-unigram features . The performance was later further improved to 87.2% [15] by applying SVMs on the subjective portions of the movie reviews which were extracted using a subjectivity detector as described in Section 5.1.2. Whitelaw et al. [24] used SVMs to train on the combination of different types of appraisal group features and the bag-of-words features for sentiment analysis. The reported best accuracy is 90.2% using 1,597 appraisal groups with each possible combination of Attitud e and Orientation plus 48,314 bag-of-words features. Their http://www.cs.cornell.edu/People/pabo/movie-review-data/ appraisal groups were constructed semi-automatically and comprise of a total of 41,082 appraising groups. This is much more complicated than the subjectivity lexicon used in this paper. Kennedy and Inkpen [10] combined two main sources, General Inquirer 8 and Choose the Right Word [7], to obtain a total of 1,955 positive and 2,398 negative terms. They then trained two classifiers, one was based on count-ing the number of positive and negative terms contained in movie reviews and augmented with contextual valence shifters, while the other was based on SVMs trained from the combination of unigrams and valence shifter bigrams. These two classifiers were finally combined to give the best classification accuracy which is 86.2%.
 In our experiment, the best overall accuracy achieved by JST is 84.6%, based on the filtered subjectivity lexicon and the subjective MR dataset. It outperforms the best result reported in [16] and is only 2.6% and 1.6% lower than the results reported in [15] and [10]. Even for the state-of-the -art result reported in [24], the best accuracy achieved by JST is only 5.6% lower. While all the previous studies men-tioned here relied on the labeled movie review data to train sentiment classifiers, our proposed JST model is fully un-supervised. In addition, the previous reported results [15 , 24, 10] were all based on 10-fold cross validation in a test se t comprising of 200 documents only 9 , our experimental results reported here are based on the whole movie review dataset with a total of 2000 documents. We also evaluated the mixture of topics and sentiments. Figure 3 shows the sentiment classification accuracy of the JST model incorporating prior information obtained in dif-ferent ways with the number of topics set to 1, 50 and 100. When the topic number is set to 1, the JST model is es-http://www.wjh.harvard.edu/  X  inquirer/ [16] used an early version of the movie review data which consists of 700 positive and 700 negative documents and the results were based on 3-fold cross validation. sentially transformed to a simple LDA model with only S topics, each of which corresponds to a sentiment label. Con-sequently, it ignores the correlation between sentiment la bels and topics. It can be observed from Figure 3 that, JST per-forms worse with single topic compared to 50 and 100 topics, except for the case of full subjectivity lexicon as shown in Figure 3(d) where the single topic performance is almost the same as the one with 100 topics. For paradigm words + MI, filtered subjectivity lexicon and filter subjectivity le xi-con (subjective MR) (Figures 3(c), 3(e), and 3(f)), the resu lt with 100 topics outperforms the ones with other topic num-ber settings. For the case when no prior information is ap-plied as well as paradigm words as shown in Figure 3(a) and Figure 3(b), the results with 50 topics are almost the same as the ones achieved with 100 topics and both are higher than that of the single topic setting. It can be also easily seen that the results with filtered subjectivity lexicon in Figur e 3(e) give the most balanced classification accuracy on both positive and negative documents. From the above, we can conclude that topic information indeed helps in sentiment classification as the JST model with the mixture of topics consistently outperforms a simple LDA model ignoring the mixture of topics. This justifies the proposal of our JST model. Also, the empirical results reveal that the optimum number of topics for the movie review dataset is 100.
The second goal of JST is to extract topics from the movie review dataset (without subjectivity detection) and evalu ate the effectiveness of topic sentiment captured by the model. In the experiment, the distribution of words given topic and sentiment label was estimated using Equation (6). Unlike the LDA model that a word is drawn from the topic-word distribution, in JST one draws a word from the distribution over words conditioned on both topics and sentiment labels. Therefore, we analyze the extracted topics under two differ-ent sentiment labels (positive and negative). Six example topics extracted from the movie review dataset under posi-tive and negative sentiment labels are shown in Table 3.
The three topics on the left columns of Table 3 were gen-erated under the positive sentiment label and the remaining topics were generated under the negative sentiment label, each of which is represented by the top 20 topic words. As can be seen from the table that the six extracted topics are quite informative and coherent, where each of them tried to capture the underlying theme of a movie or the relevant comments from a movie reviewer. For example, under the positive sentiment label category, topic 1 is likely to be ve ry positive review comments for a movie; topic 2 is apparently about the movie  X  X ou X  X e got a mail X  by Tom Hanks and Meg Ryan; topic 3 is closely related to the very popular romantic movie  X  X itanic X  directed by James Cameron and casted by Leonardo DiCaprio and Kate Winslet. For the topics un-der the negative sentiment category, topic 1 is probably the criticism made by a movie reviewer, while topic 2 is about movies related to sex/porn issues and topic 3 is likely to be the movie  X  X reen Mile X  by Tom Hanks.

In terms of topic sentiment, by examining each of the topics in Table 3, it is quite evident that topic 1 under the positive sentiment label and topic 1 under the negative la-bel indeed bear positive and negative sentiment respective ly. For topic 2 and topic 3 under the negative sentiment label, it is still fairly easy to recognize that some of their topic words convey negative sentiments though not as strong as the ones in topic 1. Topic 2 and topic 3 under the positive sentiment label mainly describe movie plots with less words carrying positive sentiment compared to topic 1 under the same category. Manually examining the data reveals that the terms that seem not conveying sentiments under these two topics in fact appear in the context expressing positive sentiments. The above analysis illustrates the effectivene ss of JST in extracting mixture of topics from a corpus.
In this paper, we have presented a joint sentiment/topic (JST) model which can detect document level sentiment and extract mixture of topics from text simultaneously. In con-trast to most of the existing approaches in sentiment classi -fication which rely on supervised learning, the proposed JST model is fully unsupervised, thus provides more flexibiliti es and can be easier adapted to other applications. Experi-ments have been conducted to evaluate the performance of JST based on the movie review dataset. The preliminary results demonstrated that our model is able to give compet-itive performance in document level sentiment classificati on compared with the results generated by other existing su-pervised approaches and the discovered topics are indeed coherent and informative.

One of the limitations of our model is that it represents each document as a bag of words and thus ignores the word ordering. It will probably predict the sentiment of X  X ot goo d movie X  being positive and the sentiment of  X  X ot bad movie X  being negative. Thus, in future work, we will extend the model to include higher order information (bigrams or tri-grams). Another promising future step is to extend JST to detect the polarity of text at various granularity levels, e .g. detecting sentiment labels for more fine-grained topics. We also intend to carry out a large scale of experiments and evaluate the model performance on datasets from different domains.
We thank Rui Wang and Naihui He for processing part of the prior information and Lei Wang for providing computing resources. [1] A. Abbasi, H. Chen, and A. Salem. Sentiment analysis [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [3] J. Blitzer, M. Dredze, and F. Pereira. Biographies, [4] Y. Choi, C. Cardie, E. Riloff, and S. Patwardhan. [5] K. Eguchi and V. Lavrenko. Sentiment retrieval using [6] T. Griffiths and M. Steyvers. Finding scientific topics. [7] S. Hayakawa and E. Ehrlich. Choose the right word: A [8] T. Hofmann. Probabilistic latent semantic indexing. In [9] N. Kaji and M. Kitsuregawa. Automatic construction [10] A. Kennedy and D. Inkpen. Sentiment classification of [11] S.-M. Kim and E. Hovy. Determining the sentiment of [12] W. Li and A. McCallum. Pachinko allocation: [13] R. McDonald, K. Hannan, T. Neylon, M. Wells, and [14] Q. Mei, X. Ling, M. Wondra, H. Su, and C. Zhai. [15] B. Pang and L. Lee. A sentimental education: [16] B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up?: [17] M. F. Porter. An algorithm for suffix stripping. pages [18] M. Steyvers and T. Griffiths. Probabilistic Topic [19] I. Titov and R. McDonald. A joint model of text and [20] I. Titov and R. McDonald. Modeling online reviews [21] P. D. Turney. Thumbs up or thumbs down?: semantic [22] P. D. Turney and M. L. Littman. Unsupervised [23] H. M. Wallach. Topic modeling: beyond bag-of-words. [24] C. Whitelaw, N. Garg, and S. Argamon. Using [25] J. Zhao, K. Liu, and G. Wang. Adding redundant
