 A multivariate time series (MTS) can be cons idered as made up of a collection of data classifying of such data can be applied into various problem domains. For example, in monitored for a patient over a period of time for such relationship or interrelationship to be discovered. In financial analysis, as another example, the performance of a stock in terms of such variables as highs and lows, opening and closing prices, trading vo-interrelationship to be understood. also brings some new challenges to the data mining and machine learning community [1]. A number of different approaches have been proposed for univariate time series classification in the literature [6]. Artificial Neural Network (ANN), is used to classify the feature vectors [14-16]. The as a vector of features, but there are no explicit features in sequence data. ii) The di-one variable is broken into MTS or each processed separately. Finally, the MTS can be of different lengths that cannot be extracted features by traditional method easily. strategy, called as M ultivariate T ime S eries C lassifier (MTSC). The algorithmic con-applied to different problems on MTS data. possible directions for future work. A multivariate time series (MTS) can be defined as a sequence of vectors, which may into a pre-defined set of classes [8]. To summary the existing algorithms of classifica-feature extraction method as pre-processing for MTS data, and classify feature vectors using classifier. 
Feature extraction greatly affects the desi gn and performance of the classifier and dimensional feature space, map useful information contained by original features to a classical feature extraction methods are based on statistical analysis. As the represent-ative, there are some classical methods such as Principal Component Analysis (PCA), addition, for improving the performance of classification MTS data, some new feature Singular Value Decomposition (SVD), to reduce the different length of data to feature vectors, and then apply SVM on the feature vectors to classify MTS data. Weng et al. [6] project original MTS into PCA subspace by throwing away the smallest principal components firstly, and then MTS samples in the PCA subspace are projected into a However, the above existing extraction method may lose the dependency relationship information among different univariate time series. patterns) at different time points, and combine the degree value of all patterns as fea-ture vector. 
After extracting features from original MTS data, a classifier, such as Support Vec-separating hyper-plane [20]. Considering the input vector is a m kernel function to the original input data. ANN is composed of interconnecting artifi-cial neurons that can compute values from inputs. Multi-Layer Perceptron (MLP) and distributed approach [21]. catch the dependency relationship between different variables, and classify MTS data based on feature vectors. Combining the proposed feature extraction method and clas-(MTSC). 
The task of the proposed algorithm is to uncover the temporal relationship or inter-relationships between different variables. These temporal relationship or interrelation-level value using Equal Frequency; 2) extract features from MTS data which contains nent time series within each MTS; 2.3) combine the value of degree of patterns disco-using SVM with RBF-kernel function or MLP ANN. The structure of our proposed algorithm is shown in Figure 1. The definitions and notations are given in the Section 3.1, and then Section 3.2 specifies the proposed algorithm in detail. 3.1 The Problem Definition and Notations Let S represent a set of MTS with the following characteristics: 1. S consists of m MTS represented as S  X  X  X  X   X   X ,  X   X ,...,  X   X  (variables) that can be represented as  X   X   X  , j=1, ....,n , so that and  X   X   X  represent the j th univariate time series in i th MTS. 3. The values in the vector  X   X   X  , j =1, ...., n, takes on the time instants of 4. The domains of the value of variable,  X   X  , X ,..., X 1 X , [  X  bound of the values that  X   X  can take on. 
Given a set of MTS, S , with characteristics as described above, they are pre-classified into k classes, where,  X   X  = {  X   X   X   X   X   X   X ,  X   X  =  X  X  to  X  . 3.2 The Proposed Algorithm 3.2.1 Discretization tion is a frequently used technique to partition the value space of a continuous varia-[23, 24]. Equal Width and Equal Frequency are two simplest discretization methods. Width can hardly handle this situation. Hence, in our case, we transform original nu-ing Equal Frequency [17] algorithm. And we set the number of bins is three, that is to dium, low}). 3.2.2 Discover Intra-/Inter-Temporal Patterns temporally interrelated, the value that a particular variable take on at any time instant can be related to the variable X  X  previous values or to the previous values of other va-terns in one MTS. We use the proposed significant discrepancy measures to evaluate gree that describes dependency patterns can be treated as Feature Vectors. Two main sub-steps are specified as following. Step One: Discovering Intra-Temporal Patterns.
 series in i th MTS, the magnitude of the difference between the conditional probability Pr(  X   X , X   X  |  X   X , X  X  X  X   X  ), 1  X   X  X  X   X  X  X  X   X  X  , and the a priori probability Pr( follows: where  X  X  X  X  X  X   X , X   X   X ,  X , X  X  X  X   X   X  is the number of instants of the value,  X   X   X  that appear in  X  conditional probability  X  X  X  X   X , X   X   X  X   X , X  X  X  X   X   X  and the apriori probability ities are normalized using (3) [23]. 
The significance of the temporal relationship depends on the magnitude of norma-lized difference,  X   X , X   X  [23] which can be either  X  0 or or absence of  X   X , X  X  X  X   X  would likely imply that at univariate time series will or will not take on the value tude of the normalized differences in conditional captures the strength of the temporal relationships [23] and they constitute the intra-temporal patterns for two values within the same variable. Step Two: Discovering Inter-Channels Temporal Patterns.
 temporal patterns are defined between two different variables say, earlier time instant,  X  , 1  X   X  X  X   X  X  X  X   X  X  . These temporal relationships or interrelation-ships can be determined as follows. Algorithm 1. The Proposed Feature Extraction Method 
Given a value, say,  X   X , X   X  , and another value, say, ferences can be determined by first estimating the two probabilities Pr ( larly, the differences in the two probabilities,  X   X  X  X   X  , X   X  shown in Algorithm 1. 3.2.3 Classification Using SVM or ANN Once all the temporal patterns are discovered, for MTS, we get a set of intra-temporal patterns measure  X   X , X   X  , ( i = 1, 2, ..., m , j = 1, 2, ..., n, and variables, 1  X   X  X  X   X  X  X  X  and i = 1, 2, ..., m . In addition, each classification algorithm has been specified in Section 2. To evaluate the performance of MTSC, a number of different experiments were car-ried out using both synthetic and real world data. In order to prove the proposed algo-data sets included EMG: Physical Action data set and ECG data set. For the purpose of performance evaluation, the test samples are compared with the known class labels lowing, we describe the data set in section 4.1; and then the experimental results using tween the proposed algorithm and traditiona l methods are given in section 4.3. 4.1 Data Set Description 4.1.1 Discrete Data Se t: Synthetic Data Set The synthetic data set is a discrete dataset that consists of 45 MTS generated random-ly. Each of these MTS consists, in turn, of 5 variables, i= 1,2,...5. There are total of 500 data values are generated for each variable to make all 5 univariate time series consists of 500 time points. Hence the synthetic data set is a 45 (MTS)  X  5 (variables)  X  500 (time points) dimensions data set. Classes Rules 
The different rules that belong to three classes are shown in Table 1. For example, in Class 1, we generate v  X  to v  X  randomly that takes on the value of i = 1,2,...5 firstly. The Rule 2 in Class 1 means, we insert patterns into take on  X   X   X   X  at every interval of 2 time units, and 1hen Variable 4 takes on value of  X   X   X , v  X  is generated to be  X   X   X   X  at next time point. Similarly, Rule 3 means, if value of v is not equal to  X   X   X   X , the value of v  X  is generated as  X  stant 50% or  X   X   X   X  at the next time instant 50% of the time. Hence, for Class 1 v are noise data since they are totally random. 4.1.2 Numerical Real-World Data Set 1: EMG Physical Action Dataset rienced aggression in scenarios such as physical fighting, took part in the experiment. (time points) with sampling frequency of 200Hz. Hence the EMG data is a 80 (MTS)  X  8 (channels)  X  ~10000 (time points) dimensions data set. 4.1.3 Numerical Real-World Data Set 2: ECG Dataset The other real-world dataset is ECG data set [13]. This data set comprises a collection orded with two electrodes by one electrode during one heartbeat. Each heartbeat has an assigned classification of normal or abnormal. It contains 200 data sets where 133 were identified as normal and 67 were identi fied as abnormal. Hence, in this dataset, mension of this data set is 200 (MTS)  X  2 (electrodes) 4.2 Experiment Process and Evaluation pose of performance evaluation, 80% data are selected randomly as training data and Classification Accuracy (CA). mean of precision and recall [14] that can be defined as below. Let be a class after classification using MTSC and C previous known, (k is the number of classes), so the F-measure is defined for C as equal (4) shows [14].  X  X  X  X  X  X   X   X ,  X   X  represents the number of MTS with the cluster label ered cluster,  X   X  ,  X  X  X  X  X  X   X   X  is the number of records with class label  X  X  X  X  X  X   X   X  , is the number of records in the predicted class label rate MTSC is and the definition of CA is shown in equation (5) 4.3 Experimental Result for the Proposed Algorithm ent variables only between the previous time point and next one time point ( use the proposed feature extraction to process the MTS data firstly and then use SVM dataset using different classifier. The result table shows the value of Mean Acc. (the average of classification accuracy), Highest Acc. (the highest classification accuracy) and F-measure (the average value of F-measure). When MTSC is applied for ANN more than 75% with F-measure is 0.72 for SVM classifier. Hence, in this experiment, SVM. within one variable or between different variables may not only in one time interval, we set  X  =1 to 5 for intra-/inter-temporal patterns. Table 3 and Table 4 show the result for the two real data sets using MTSC with SVM or ANN classification algorithm for different time intervals. 
In summary, ANN can get higher classification accuracy and F-measure than SVM for the most of classification result. In EMG dataset, when F-measure being 0.89 for SVM classifier, and accuracy of 91.78% with the average F-tween variables are the most significant for classification in 5 time intervals. In ECG same variable and between different variables can distinguish different samples best. 4.4 Comparison Experimental Result For performance benchmarking, we compare the proposed MTSC algorithm with 1) (No FE), 2) SVM or ANN classification with PCA for MTS data. The Principle Com-ponent Analysis (PCA) method can reduce high dimensions of MTS data and trans-classify feature vectors. Table 5 and Table 6 summarize the comparison result in clas-sification accuracy and F-measure. 
For synthetic dataset, when no feature extraction method is applied, the classifica-tion accuracy is 50.46% and 68% with F-measure of 0.46 and 0.69 for SVM classifier and ANN classifier respectively. PCA+SVM can only achieve an accuracy of 67.2% with average F-measure of 0.41, and PCA+ANN can achieve a higher accuracy of MTSC can get higher both classification accuracy and F-measure than two other tra-ditional methods. We can conclude from the result table, the value of the average of classification accuracy using MTSC is higher than the result using PCA with SVM or ANN for all data sets. 
Besides the classification performance comparison, the complexity analysis is used, the classifier has to process for mnt dimensions data. When some feature extrac-and the run-time of complexity of our proposed algorithm could be Generally, the MTS contains very high dimensions of time points with less variables, so in this case, the advantage of MTSC just need to count once for the value of each time points. This paper has presented a classification strategy that combining the proposed feature extraction method and classifier for classifying MTS data. Unlike many existing me-nuous or discrete data or both. As the proposed feature extraction method can perform its tasks without requiring any special assumption about data models, it is generic and handle time series of different length. For performance evaluation, FEMTS was tested rithm for multivariate time series classification. The future work could be investigated into the possibility of improving the current work in three aspects: 1) after discovering how the algorithm can be more generally applicable. 
