 Modeling the response time of search engines is an impor-tant task for many applications such as resource selection in federated text search. Limited research has been con-ducted to address this task. Prior research calculated the search response time of all queries in the same way either with the average response time of several sample queries or with a single probability distribution, which is irrelevan t to the characteristics of queries. However, the search respon se time may vary a lot for different types of queries. This pa-per proposes a novel query-specific and source-specific ap-proach to model search response time. Some training data is acquired by measuring the search response time of some sample queries from a search engine. Then, a query-specific model is estimated with the training data and their corre-sponding response times by utilizing Ridge Regression. The obtained model can be used to predict search response times for new queries. A set of empirical studies are conducted to show the effectiveness of the proposed method.
 H3.3 [ Information Search and Retrieval ] Performance, Experimentation, Theory.
 Source Selection, Response Time, Ridge Regression.
The rapid growth of online searchable information sources on local area networks and the Internet creates a problem of finding the relevant information that may be distributed among many information sources [1][7].

Much literature has studied issues related to source selec-tion and results merging. In source selection [2][3][5][6] , we need to determine the search engines that should be queried, especially under the circumstance when it is time consum-ing or expensive to query every data source due to some resource constraints. Once the results are retrieved from different search engines, a results merging method is often used to integrate the individual ranked lists into a single l ist [5].

Searching response time is a very important component in source selection [2][5] [6]. However, the related resear ch is still limited. In [2], [5] and [6], the authors assume that the response times for the different queries should be the same or follow a specific distribution that is independent of the queries. In fact, the search response time may vary sig-nificantly for different kinds of queries with different query lengths and common or rare query terms in different databases . the response time would be much longer than that of  X  X 53 X , which is the name of a gene that causes cancer, because, in this database,  X  X ancer X  is much more common than  X  X 53 X .
In this paper, we propose a new method to model the relationship between the query and the corresponding re-sponse time. Our method predicts the time delay of different queries by: i) sending some training queries to a search en-gine and measuring the corresponding response times; and ii) modeling the response times given the training queries, and predicting response times for new queries sent by the users. This is accomplished by formalizing the response tim e predication procedure as an optimization problem and pre-dict the response time of new queries by this optimization result.
Our method is characterized by its ability to model the relationship between the response times and queries. To achieve this goal, we first need to extract features for queri es.
Suppose we have a training query set { q 1 , q 2 , . . . , q l is the total number of training queries. We map each train-ing query q i to a feature vector x i , which is calculated on a set of background databases with diverse topics. For the training query q i , we use the sum of its corresponding idf features for its query terms to represent its map on the j -th background database. And we use this value as its j th feature in x i . More specifically, the j -th component in the feature vector x i is determined by: Here, N j is the total number of documents in the j th back-ground database, q ik is the k -th query term in the query q , and df j ( q ik ) is the total number of documents, in the j th 1 http : //crisp.cit.nih.gov/crisp/crisp query.generate screen background database, that contains this particular term q We add this number by 1 to avoid the denominator being zero.

After the training feature vectors X = { x i , i = 1 , . . . , l } are acquired, we build a linear model based on these vec-tors and their corresponding response times in a specific search engine, i.e., T = { t i , i = 1 , . . . , l } . This model can be represented by a function f such that: f : X X  X  and f ( x ) = w T x + b , where w is the weight vector and b is the bias. To obtain the w and b in this model, we use the Ridge Regression method [4]. The optimization formulation of Ridge Regression can be described as: where  X  is a parameter that controls the trade-off between the complexity of the model and the square loss. After solv-ing this optimization problem, we can predict the response time for any query sent to this search engine by: i) first mapping this query to a feature vector x by Eq.(1). ii) esti-mating its response time by  X  t = f ( x ) = w T x + b .
Experiments are conducted on 8 different randomly se-lected academic search engines, including the IEEE explore r, the NIH AWARD Search Engine, the accessscience search engine, etc.

We have a set of 120 queries, whose topics mainly focus on computer science, biology, economics, etc. These querie s are sent to the 8 academic search engines beforehand and we can acquire their corresponding response times in these search engines. The feature vectors of these 120 queries are calculated on 22 background databases. 20 of them are from the 20 newsgroup database and the remaining 2 are from the trec wt10g and the OHSUMED databases, respectively.
For the proposed method, the parameter  X  in Eq.(2) is determined by 5-fold cross validation.We also compare the proposed method with some query independent methods, i.e., the  X  X verage X  method, which uses the mean of the re-sponse times on the training set as the predicted response time for the testing queries; the  X  X in X  method, which uses the minimal response time of the training queries as the pre-diction for the testing queries, and the X  X ax X  X ethod, which uses the maximal response time of the training queries as the estimation for testing queries. For all of these methods, on each search engine, the final results are averaged over 30 in-dependent trials. During each trial, 50 queries are randoml y selected as training queries, while the others are left as th e testing set E . The following criterion is used to measure the loss on E : where  X  T i and T i denote the estimated and actual response time of the i th query on the testing set E , respectively. | E | represents the number of queries in E . The loss compari-son results are shown in Table 1. From these experimental results, we can see that the proposed method is superior.
Response time is a very important component in source selection. However, previous research only calculated the search response time of all queries in the same way either with the average response time of several sample queries or with a single probability distribution, which is query inde -pendent and can not reflect the characteristics of the querie s. In this paper, we show, by modeling the relationship between queries and the corresponding response times, we can pre-dict the response time for new queries more precisely. It is true that this model may be affected by some unknown factors, such as the network congestion and web caching. In the future, we plan to design new methods to make the prediction model more robust to these situations. [1] J. Callan. Distributed information retrieval. Advances [2] D. Dreilinger and A. Howe. Experiences with selecting [3] J. French, A. Powell, and J. Callan. Effective and [4] A. Hoerl and R. Kennard. Ridge Regression: Biased [5] K. Hosanagar. A utility theoretic approach to [6] A. Montgomery, K. Hosanagar, R. Krishnan, and [7] C. Yu, K. Liu, W. Meng, Z. Wu, and N. Rishe. A
