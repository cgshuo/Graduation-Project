 1. Introduction
With the assistance of Internet, the surveillance system makes a big progress to let surveillance users monitor distant events by a simple browser. Thus the remote live events can easily be seized at anywhere the users access Internet. If the monitoring application can be extended to a handheld device such as a cellular phone, surveillance users can acquire remote events at anytime and any-where via any available mobile wireless network, such as the General Packet Radio Service (GPRS), Wireless Fidelity (Wi-Fi), and
Universal Mobile Telecommunications System (UMTS) to the imple-menting Worldwide Interoperability for Microwave Access (WiMAX) or 3rd Generation Partnership Project Long Term Evolu-tion (3GPP-LTE). Thanks to the wireless technology revolution, a wireless user can access Internet ser vices via ubiquitous networks by a multi-mode device. J2ME is a typical mobile based develop-ment technologies ( Read and Maurer, 2003 ; Kochnev and Terekhov, 2003 ). A J2ME based wireless intelligent video surveillance system was implemented to make a useful supplement of a traditional monitoring system with its good mobility ( Xu et al., 2008 ). In such a mobile surveillance system, capt ured frames are normally obtained through a higher speed network in a building and then delivered to the remote mobile users through a lower speed network outside the building. The mismatch of transmission capabilities in different networks which cameras and viewers are attached to would affect the viewing continuity and pla yback liveness. The unmatched bandwidth at both ends located in different network environments may incur a deferred playback at the viewer site so that the transmitted frame rates should be adapted to the heterogeneous network conditions. Capturing and sending too many frames which cannot be viewed on time by the viewer not only cause frame delay between cameras and viewers but also waste too much power for capturing frames at the camera site. A simple and intuitive way, this issue is adjusting the capturing period by an adaptive pause time control mechanism at the video input end. Hence, this paper proposed a frame synchronizatio n scheme by adaptively pausing some time at the camera side based on the network transmission condition to make the remote viewers obtain the captured frames with more synchronous event information.
 illustrates some related works about surveillance systems.
Section 3 illustrates the surveillance system model in a hetero-geneous network environment and the proposed adaptive frame synchronization scheme. In Section 4 , we theoretically analyze the asynchronization effect of video communication in a hetero-geneous network environment and show some simulation results to prove the effectiveness of the proposed mechanism. Conclud-ing remarks are finally drawn in Section 5 .
 2. Related work
A typical surveillance system model is sending the captured frames from cameras to viewers for being played back. In a heterogeneous network environment, the quality of frame syn-chronization is largely affected by various network characteris-tics, such as a limited channel bandwidth and a variant transmission rate. Therefore, frame synchronization may encoun-ter a frame lag issue while the frame transmission spans across different networks. Many adaptive solutions are proposed for users X  dynamic variations in network access capability. Proxy cache based mechanisms are designed for adaptively playing streaming media ( Yu et al., 2003 ; Cha et al., 2006 ) and reducing the maximum bandwidth requirement subject to QoS-guaranteed video playback ( Chang et al., 2007 ). Some adaption strategies are based on feedbacks from users, such as the packet dispersion feedback ( Jammeh et al., 2009 ), the specific subset of packets that should be delivered ( Magharei and Rejaie, 2006 ), or user specified relevance-distortion policy ( Ozcelebi et al., 2007 ).
In a traditional surveillance system ( Foresti, 1998 ; Esteve et al., 2007 ), many fixed cameras are pinned at fixed locations to capture events. Users then keep a close watch on the videos sent from these cameras via a monitor at a fixed location. Application for surveillance system such as vehicle classification by road lane detection and model fitting using a surveillance camera is shown in Shin et al. (2006 ). Tracking human facial expression within a video image has many useful applications, such as surveillance and teleconferencing. Using the Active Appearance Model to recognize human facial expression in a video image ( Jo and Kim, 2010 ) is proposed. Internet indeed facilitates the remote mon-itoring but it still lacks some flexibility. In the past, many efforts are put on improving the inflexibility in a traditional surveillance system. A web-based surveillance system in Imai et al. (2008 ) was proposed for surveillance viewers to perform monitoring and controlling remotely by cellular phones. However, if the both sides  X  cameras and monitors can become movable, the monitor-ing area can become wider and the viewer can obtain the events remotely anytime and anywhere.

A network camera equipped on a mobile robot ( Leu et al., 2011 ) can help capture events in wider and more dynamic angles.
As hardware costs are coming down dramatically and capabilities of robot are increasing fast, robotics is becoming more important in everyday life. A robotic dual-camera vision system ( Tonet et al., 2008 ) is built by composing a telephoto camera whose field of view can be moved within a larger view field of a wide-angle camera. Meanwhile, movable robots can be a good facility to broaden the monitoring vision by carrying the event capturing camera. An autonomous mobile robotic system ( Paola et al., 2010 ) developed on a multisensory mobile platform can autonomously navigate in the environment and perform surveillance activities.
With the integration of current wireless network technology, a robotic surveillance system can extend the security sensing within a home or building environment. Meanwhile, Handover between different wireless networks is also an issue in autono-mous mobile robotic system. An enhanced technique for vertical handover of multimedia traffic between WLAN and EVDO ( Javed et al., 2010 ) is proposed. To maintain the connectivity of an established multimedia traffic between two different networks using mobility management, the authors propose an efficient algorithm which maintains the real time connection as well as preventing the data loss during transition from WLAN to Evolu-tion-Data Optimized (EVDO).

On the other hand, the unmatched bandwidth at both ends which are located in different network environments may incur a deferred playback at the viewer side, the transmitted frame rates should be adapted to the heterogeneous network conditions. Adaptive Wireless Multi-level ECN (AWMECN) in Karimi and Fathy (2010 ) is proposed to conduct rate adaptation and quality adaptation in the application layer for a better Quality of Service (QoS) on delivering multimedia over heterogeneous wireless networks. Owing to the next generation of mobile wireless systems targets to obtain ubiquitous connectivity services for mobile users through heterogeneous wireless networks (HWNs), which integrate cellular network, WLAN, WiMAX, and MANET. In Xie et al. (2010 ), the authors discuss the security characteristics unique to HWNs. For reducing the computational time, Sathappan et al. (2011 ) address the problem of task scheduling in hetero-geneous distributed systems with the goal of maximizing the system reliability and decreasing the makespan. On the other hand, when a user wishes to minimize the energy consumption for an application running on a handheld device, the user may choose to set the processor speed to its slowest level. An energy conservation DVFS algorithm ( Liang et al., 2010 ) is proposed to maximize energy saving. A more simple and intuitive way for the rate adaptation is adjusting the capturing period by a adaptive pause time control mechanism at the video input end. Following the above design issues, our work presented in this paper aims to design a recognition assisted dynamic surveillance system by fully integrating wireless, robotics, image processing, and mobile phone techniques. 3. System model and proposed scheme
A generic surveillance system architecture in a heterogeneous network is illustrated as Fig. 1 shows. Two parties  X  Viewer and Camera in the surveillance system are bridged by a Proxy gateway and are normally located in different networks with different access capabilities and access rates. Without losing the generality, we assume that the network transmission rate under the network which the camera is attached to is higher than the one under the network which the viewer is attached to. For example, the camera may access the Internet via a Wi-Fi network with a higher access rate while the mobile viewer may access the Internet via a cellular network with a less access rate. Synchronous and asynchronous modes between Viewer and Camera are two common frame transmission schemes. The related process flows are shown below: 3.1. Synchronous mode
The synchronous mode uses a request and response to carry out the viewing function on Viewer. Viewer would sequentially request each frame toward Proxy and then the request is forwarded from Proxy to Camera. After Camera captures and sends the image frame to Proxy. If needed, the captured frame would be scaled by Proxy to fit the screen size of Viewer and then delivered to Viewer. The related process flow is shown in Fig. 2 .
In such a manner, Camera may be idle when Proxy is sending a frame to Viewer and Viewer may be idle when Proxy is waiting for Camera to deliver a following frame. The synchronous mode is suitable for the condition in which the viewer may not demand high-frequently updated frames or the network transmission rate is low.

The algorithm of the synchronous mode is illustrated as follows: (1) At Viewer side: While Begin
While End (2) At Proxy side: Receive a command from Viewer; If (Command  X  X   X  X  X ideoFrameRequesting X  X ) 3.2. Asynchronous mode frame is captured by Camera after the surveillance service is activated. After Proxy gets the captured frame, it may invoke some image process procedures including frame quality adjust-ing, object contouring, and face detecting if needed. Then Proxy delivers the processed frame to Viewer. Furthermore, in the asynchronous mode there are two independent threads on Proxy.
One thread is responsible for requesting a frame toward Camera and the other one is for delivering the captured frame from
Camera to Viewer. On a fire-and-forget basis, Viewer does not need to repeatedly check if a new captured frame arrives. Ideally, every frame captured by Camera is viewed by Viewer right after a constant time interval without considering the captured frames are transmitted through different kinds of networks. Fig. 3 shows the ideal relationship between captured and viewed frames. The asynchronous mode is suitable for the condition in which the viewer may demand high-frequently updated frames or the net-work transmission rate is high.
 ities in the Camera-to-Proxy and Proxy-to-Viewer links which may be located in heterogeneous networks, the frames received by Viewer may gradually get desynchronized with the ones captured by Camera. The scene a remote reviewer views may lag far behind the live event. The desynchronization effect would get worse cumulatively as the execution time gets longer. Fig. 4 shows the desynchronization effect between captured and viewed frames in a real network environment. 3.3. Asynchronous mode  X  pause time control:
A fire-and-forget based asynchronous mode may get frames between Camera and Viewer desynchronized cumulatively as the execution time gets longer. Therefore, we add a pause time control on Proxy to cancel this annoying effect caused by the asynchronous viewing mode on Viewer. That means Proxy is forced to wait for a certain time to requesting Camera to send the following frame. Fig. 5 shows the pause time control mechanism can relieve the desynchronized effect between captured and viewed frames. Such an improvement can make Viewer obtain the frame consistent with the live scene.

Its detailed operation algorithm is illustrated as follows: (1) At Viewer side: Initializes a reviewing request toward Proxy; While Begin
While End (2) At Proxy Receives a command from Viewer; While Begin
While End (3) At Camera side: Receives a command from Proxy; If (Command  X  X   X  X  X ideoFrameRequesting X  X ) End If
However, how to choose a proper pause time is a trade-off issue. The asynchronization effect would still exist if the pause time is set too short, while the captured frame cannot be viewed timely at the viewer site if the pause time is set too long. We propose an adaptive pause time mechanism based on the condition of the previous frame delivery. The adaptive pause time is set as follows T  X  n  X  1  X  X  T RV  X  n  X  T CC  X  n  X  T CP  X  n  X  T proc  X  n  X  X  1  X  where T p  X  n  X  1  X  : the pause time for requesting the ( n  X  1)-th Viewer, T CC ( n ): the n -th frame X  X  capturing time at Camera, T the n -th frame X  X  receiving time from Camera to Proxy, T proc n -th frame X  X  processing time at Proxy if any. 4. Theoretical analysis and system evaluation 4.1. Theoretical analysis
We try to theoretically conduct the time delay analysis for frame transmission in a heterogeneous network environment and the data lost analysis under a synchronized playback require-ment. Based on these analyses, the proposed adaptive pause time mechanism can be a solution to relieve the asynchronization effect in the unmatched transmission rate situation. We deduct the quantitative comparison result by referring to the following notations. f : data size of a frame l : the average network transmission rate in the Camera-to-
Proxy link Viewer link Proxy by Camera from Proxy by Viewer
Without losing the generosity, we assume l m . 4.1.1. Time delay analysis for frame transmission
Since l 4 m , D t s  X  f = l o f = m  X  D t r . It means a frame captured by Camera would take more time to be delivered to Viewer to be played back. As the sent frames are increased, the frame delay condition would be accumulated so that the asynchronization effect between captured and viewed frames would get more serious. 4.1.2. Data lost analysis for the synchronized playback:
If the video transmission service is asked to be synchronized played back with a constant playback delay between Camera and
Viewer, Viewer may not have enough time to process the data sent from Camera. During the transmission time t 1 to t 2 cause ( l m )( t 2 t 1 ) data lost due to l 4 m . 4.2. System evaluation
Our evaluation focuses the performance for different captur-ing-viewing modes ( X  X  X synchronous X  X  and  X  X  X synchronous with an adaptive pause time control mechanism X  X ) based on the different evaluation metrics (the time delay for frames sent from Camera to
Viewer and the needed frame capturing rate at Camera via different wireless networks (Wi-Fi, 3G)). Some key parameters for the evaluation are shown in Table 1 . 4.2.1. The time delay for Frames sent from camera to viewer:
The time delay for receiving frames would affect the synchro-nization or liveness status between the captured frames from
Camera and the received frames at the Viewer site. We put a timestamp showing the time when each frame is captured by
Camera. The timestamp would be compared to the time when the frame is received at the Viewer site. The time difference in-between can make us realize the synchronization or liveness status between the captured and viewed frames through different networks with different transmission rates. Hence, the smaller the time delay for receiving frames, the better the frames synchronization between Camera and Viewer. Fig. 6 shows that the  X  X  X synchronous with an adaptive pause time control mechan-ism X  X  mode can have a less average frame delay compared to the  X  X  X synchronous X  X  mode. 4.2.2. The needed frame capturing rate at the camera site: capturing rate at Camera is independent of the one at the Viewer site. However, since the network transmission capabilities of the
Camera-to-Proxy and Proxy-to-Viewer links may differ, the frames received by Viewer may gradually be out of synchroniza-tion with the frames captured by Camera without considering the mismatch of transmission rates. That means if the video commu-nication system wants to keep good synchronization between the live scene and the viewed scene, it should adaptively control the frame capturing rate to prevent Camera from capturing too many frames which would not be received and viewed by Viewer. In other words, the frame capturing rate should be adaptively tuned according to the transmission rate in the Proxy-to-Viewer link.
Hence, the smaller the needed frame capturing rate at Camera, the less the wasted frames captured by Camera. Fig. 7 shows that the  X  X  X synchronous with an adaptive pause time control mechan-ism X  X  mode can have a less needed frame capturing rate compared to the  X  X  X synchronous X  X  mode. 5. Conclusion
The camera and viewer ends in the modern surveillance system are separately attached to different networks. The mis-match of transmission capabilities in the heterogeneous networks would affect the viewing continuity and playback liveness. Hence, adaptively pausing some time to capture frames based on the network quality can make the viewer end obtain more frames consistent with the live scene. In this article, we propose an adaptive frame synchronization mechanism to efficiently improve the frame consistency between captured and viewed frames at the camera and viewer ends in a heterogeneous network. The proposed frame synchronization scheme by adaptively pausing some time at the camera side is based on the network transmis-sion condition to make the remote viewers obtain the captured frames with more synchronous event information. The evaluation results show that the proposed scheme can achieve a shorter time delay between the captured frames at the camera site and the viewer site.
 References
