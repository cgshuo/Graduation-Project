 This paper presents a background and overview for task 1 (of 2 tasks) of the KDD Challenge Cup 2002, a competition held in conjunction with the ACM SIGKDD International Con-ference on Knowledge Discovery and Data Mining (KDD), July 23-26, 2002. Task 1 dealt with detecting which pa-pers, in a set of fruit fly genetics papers (texts), contained experimental results about gene products (transcripts and proteins), and also within each paper, which genes had ex-perimental results about their products mentioned. 1 KDD Cup, competition, biology, genomics, text mining This paper presents a background and overview for task 1 (of 2 tasks) of the KDD Challenge Cup 2002, a competition held in conjunction with the ACM SIGKDD International Con-ference on Knowledge Discovery and Data Mining (KDD), July 23-26, 2002. Task 1 dealt with text data-mining to pro-vide semi-automated aids for biological database curation. Alexander Yeh was the co-chair for task 1.
 Biomedical information exists in both the research liter-ature and various semi-structured databases. The litera-ture is a rich source of information. Abstracts of much of the published literature are easily accessible via PubMED; full text articles have more limited availability, but con-tain critical information not available in the abstracts. Bi-ological databases serve as repositories and distillations of what is described in the literature. Such databases exist for genes and proteins in general, and also for more specific areas, such as the genome of a specific organism. These databases typically have fields that contain structured en-tries, e.g., genetic or protein sequences, measurements, or gene or protein or tissue names (in a controlled vocabulary). However, these databases also contain significant amounts of semi-structured information, including summaries, com-ments, and short descriptive phrases. In addition, biological databases are generally accompanied by rich resources, in-cluding nomenclatures or ontologies that specify allowable entries for the database fields. c  X  2002 The MITRE Corporation. All rights reserved. SIGKDD Explorations. Volume 4, Issue 2 -page 87 For each paper, a system needed to return three things: 1. A ranked list of articles in order of probability of the 2. A yes/no decision on whether to curate each article; 3. For each gene in each article, a yes/no decision about Appendix A provides more details.
 The KDD Challenge Cup schedule included a 6 week period when the training data was made available, followed by a two week period to complete the running of the test material. The training set consisted of 862  X  X leaned X  full text articles, of which 283 had been judged to need curation. Each article came to the Harvard curators with a list of the genes (in a standardized nomenclature) mentioned in the paper. Along with its standardized nomenclature, the FlyBase database provides synonym lists for each gene. These resources, along with the set (in an evidence file) of relevant database entries for each article, were provided as part of the training data. The test set consisted of another 213 articles, together with the genes mentioned in each article. The task presented to the contestants is only a part of what the FlyBase Harvard curators do. But even just this part is of real importance to the curators, because most of the papers (for example, 2/3 of our training papers) given to them contain no results of interest, and filtering out such papers is useful. Following KDD Cup in July, other database curation groups have asked us about our interest in using their databases as test cases for a similar evaluation, because they need these kinds of tools in their daily work. Even this one  X  X imple X  task provides plenty of challenges for the contestants. One challenge is that FlyBase is only inter-ested in gene expression results that are applicable to  X  X egu-lar X  flies found in the wild (wild-type), and not in expression results that just apply to laboratory induced mutations. Another challenge are the multiple names (synonyms) of many genes. This challenge carries over to gene products because the texts usually reference the products via their associated gene. As mentioned above, the contestants were provided with a list of synonyms for the genes. However, the list was probably not complete (there are many typograph-ical variants of names), and an additional complication is that some names can refer to more than one gene. An ex-ample is Clk , which is both a symbol for the Clock gene and also is a synonym for the period gene.
 A third set of challenges comes from a mismatch between natural language processing (NLP) systems and the training data as provided by the FlyBase database. NLP systems are mainly designed to find/extract explicit mentions of infor-mation in the text (text strings), with perhaps some limited normalization or stemming involved. FlyBase stores what results of interest were found in a paper, but SIGKDD Explorations. Volume 4, Issue 2 -page 88 This paper reports on work done in part at the MITRE Corporation under the support of the MITRE Sponsored Research Program. In addition, many people at FlyBase worked to make this KDD Cup task possible, especially William Gelbart, Beverly Matthews, Leyla Bayraktaroglu, David Emmert and Don Gilbert.
 For each paper, we provide the text of the paper in which parts of the paper that are beyond plain English text (su-perscripts, italics, Greek letters, etc.) have been converted into a representation in plain English text. We also pro-vide a template in XML for each paper, which both lists the genes mentioned in that paper and also indicates the yes/no decisions to be made. The template for the paper from the Section 1 immunolocalization example is shown here (actu-ally, only 4 of the 12 listed genes are shown here): &lt;article file="R171" pubmedid="9006979"&gt; &lt;curate&gt;?&lt;/curate&gt; ... ... &lt;/article&gt; This view of the template indicates some mention of the l(2)05006 , Ecol\lacZ , Phm and Thiolase genes in the pa-per.
 The contestants give their yes/no ( Y / N ) answers by return-ing these templates with the ?  X  X  replaced by Y or N as ap-propriate. For each gene, returning &lt;pp&gt;Y&lt;/pp&gt; means that a system found experimental evidence of interest in the pa-per for some polypeptide/protein of that gene. Returning &lt;pp&gt;N&lt;/pp&gt; means that a system did not find such evidence. findings for that gene X  X  transcripts. An example of such evidence is the passage in that immunolocalization exam-ple, which mentions experimental evidence for some Phm polypeptide(s). This passage describes an assay which finds where Phm polypeptide(s) are present in a fruit fly. Lethal (e.g., l(2)05006 ), foreign (e.g., Ecol\lacZ ) and anony-mous genes are particularly hard to handle, so the contes-tants did not have to answer Y / N for those genes X  products. We indicate this by having an X where an ? would normally be found in a template.
 The overall decision on whether a paper had experimental evidence for a product of any gene ( including lethal, foreign and anonymous genes) is indicated by changing the ? in &lt;curate&gt;?&lt;/curate&gt; into a Y for yes and N for no.
