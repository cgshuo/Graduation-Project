 luecke@fias.uni-frankfurt.de
Gatsby Computational Neuroscience Unit, UCL A long-standing goal of unsupervised learning on images is t o be able to learn the shape and form of objects from unlabelled scenes. Individual images usually contain only a small subset of all possible objects. This observation has motivated the construction o f algorithms X  X uch as sparse coding (SC; [1]) or non-negative matrix factorization (NMF; [2]) and it s sparse variants X  X ased on learning in motivation, these algorithms make severe approximations. Perhaps the most crucial is that in the underlying latent variable models, objects or parts thereo f, combine linearly to form the image. In real images the combination of individual objects depends o n their relative distance from the camera the hidden causes non-linearly compete to determine the pix el values in the region of overlap. In this paper we extend multiple-causes models such as SC or N MF to handle occlusion. The idea of using many hidden  X  X ause X  variables to control the presen ce or absence of objects is retained, but these variables are augmented by another set of latent va riables which determine the relative depth of the objects, much as in the z-buffer employed by comp uter graphics. In turn, this enables the simplistic linear combination rule to be replaced by one in which nearby objects occlude those that are more distant. One of the consequences of moving to a r icher, more complex model is that inference and learning become correspondingly harder. One of the main contributions of this paper is to show how to overcome these difficulties.
 tic approaches [3, 4] assign pixels in multiple images taken from the same scene to a fixed number of image layers. The approach is most frequently applied to a utomatically remove foreground and background objects. Those models are in many aspects more ge neral than the approach discussed here. However, they model, in contrast to our approach, data in which objects maintain a fixed position in depth relative to the other objects. The occlusion model contains three important elements. The first is a set of variables which controls is the combination rule which describes how closer active ob jects occlude more distant ones. To model the presence or absence of an object we use H binary hidden variables s assume that the presence of one object is independent of the p resence of the others and assume, for simplicity, equal probabilities  X  for objects to be present: which of two overlapping objects occludes the other. The dep th-ordering is captured in the model functions  X   X  : { 1 , . . . , | ~s |}  X  { 1 , . . . , | ~s |} , with | ~s | = P given ~s is defined by: distinct choices of  X   X  would have resulted in different images. The final stage of the generative model describes how to produ ce the image given a selection of active causes and an ordering in relative depth of these caus es. One approach would be to choose the this would mean that every image generated from the model wou ld comprise just one object; the closest. What is missing from this description is a notion of t he extent of an object and the fact contains two sets of parameters. One set of parameters, W  X  R H  X  D , describes what contribution an object makes to each pixel ( D is the number of pixels). The vector ( W vector ~ T case). Fig. 1A illustrates the combination of masks and feat ures, and Fig. 1B shows the graphical model of the generation process.
 Let us formalize how an image is generated given the paramete rs  X  = ( W, T ) and given the hidden image ~ T ( S,  X ) to be given by:
T d ( S,  X ) = W h where h In (3) the order in depth is represented by the mapping  X  whose specific form will facilitate later Fig. 2. Let us assume that the mask values W for continuous values). As depicted in Fig. 1A an object h with s with W ~ T causes h with s combination rule (3) simply states that of all objects with W variables Y = ( ~y usual choice for component extraction systems): Equations (1) to (4) represent a generative model for occlus ion. One approach to learning the parameters  X  = ( W, T ) of this model from data Y = { Y ( n ) } is to use Maximum Likelihood learning, that is, However, as there is usually a large number of objects that ca n potentially be present in the train-ing images, and as the likelihood involves summing over all c ombinations of objects and associ-computable, optimization of the likelihood is made problem atic by an analytical intractability aris-ing from the fact that the occlusion non-linearity is non-di fferentiable. The following section de-scribes how to side-step the computational intractability within the standard Expectation Maximi-sation (EM) formalism for maximum likelihood learning, usi ng a truncated expansion of sums for the sufficient statistics. Furthermore, as the M-Step of EM r equires gradients to be computed, the model X  X  non-linearity.
 introduce the free-energy function F ( X  , q ) which is a function of  X  and an unknown distribution Approximations introduced later on can be interpreted as ch oosing specific functions q , although (for brevity) we will not make this relation explicit. In the model described above, in which each image is drawn independently and identically, q ( S (1) , . . . , S ( N ) ) = Q where the function H ( q ) =  X  P pendent of  X  . Note that P E-step (while the parameters,  X  , are kept fixed) and with respect to parameters,  X  , in the M-step (while q is kept fixed). It can be shown that an EM iteration increases t he likelihood or leaves it unchanged. In practical applications EM is found to increas e the likelihood to likelihood maxima, although these can be local.
 M-Step. The M-Step of EM, in which the free-energy, F , is optimized with respect to the parame-this standard procedure is not directly applicable because of the non-linear nature of occlusion as reflected by the combination rule (3). However, it is possibl e to approximate the combination rule by the differentiable function, Note that for  X   X   X  the function ~ T  X  differentiable w.r.t. the parameters W where ~e proximations on the left-hand-side above become equalitie s for  X   X   X  ). We can now compute approximations to the derivatives of F ( X  , q ) . For large values of  X  the following holds: conditions for a maximum of the free energy that hold in the li mit  X   X  X  X  : Note that equations (11) are not straight-forward update ru les. However, we can use them in the fixed-point sense and approximate the parameters which appe ar on the right-hand-side of the equa-tions using the values from the previous iteration.
 Equations (11), together with the exact posterior q likelihood based learning algorithm for the generative mod el (1) to (4). Note, however, that due to the multiplication of the weights and the mask, W given h the combination ~ T with  X  6 = 0 . To remove the degeneracy we set after each iteration: For reasons that will briefly be discussed later, the use of W is advantageous for some data, although for many other types of data W max E-Step. The crucial entities that have to be computed for update equa tions (11) are the sufficient statistics hA hA hA id ( S, W ) i q That is, in order to approximate (13), the problematic sums i n the numerator and denominator have been truncated. We only sum over states ~s with less or equal  X  non-zero entries. Approximation (13) replaces the intractable exact E-step by one whose computat ional cost scales only polynomially with H (roughly cubically for  X  = 3 ). As for other approximate EM approaches, there is no guaran tee were generated by a small number of causes on average we can, h owever, expect the approximation to match an exact E-step with increasing accuracy the closer we get to the optimum. For reasons highlighted earlier, such data will be typical in image mode lling. A truncation approach similar to (13) has successfully been used in the context of the maximal causes generative model in [8]. Also in the case of occlusion we will later see that in numerical ex periments using approximation (13) the true generating causes are indeed recovered. In order to evaluate the algorithm it has been applied to arti ficial data, where its performance can be compared to ground truth, and to more realistic visual dat a. In all the experiments we use image pixels as input variables ~y vector, ~y the feature parameters T c Learning and annealing. The free-energy landscape traversed by EM algorithms is oft en multi-alleviated using deterministic annealing as described in [ 9, 10]. For the model under consideration (11). For the sufficient statistics hA (8) instead of A during learning with  X  = 1 experiments we used 100 EM iterations and decreased  X  T linearly except for 10 initial iterations at  X  features, W zero during the last 20 iterations of each trial.
 The colored bars test. The component extraction capabilities of the model were tes ted using the colored bars test. This test is a generalization of the class ical bars test [11] which has become a popular benchmark task for non-linear component extractio n. In the standard bars test with H = 8 bars the input data are 16-dimensional vectors, representi ng a 4  X  4 grid of pixels, i.e., D = 16 . have colors ~ T gen Once chosen, they remain fixed for the generation of the data s et. For each image a bar appears independently with a probability  X  = 2 chosen from the permutation group. The color of each pixel is determined by the least distant bar and is black if the pixel is occupied by no bar. N = 500 images were generated for learning and Fig. 3A shows a random selection of 13 examples. The learning algorithms were applied to the colored bars test with H = 8 hidden units and D = 16 input units. The observation noise was set Figure 3: Application to the colored bars test. A Selection of 13 of the N = 500 data points used for learning. B Changes of the parameters W and T for the algorithm with H = 8 hidden units. Each row shows W and T for the specified EM iteration. C Feature vectors at the iterations in B HSV color space). Crosses are the real generating values, bl ack circles the current model values ~ T and grey circles those of the previous iterations. to  X  = 0 . 05 and learning was initialized with  X  T init = 1 2 D . The inferred approximate maximum-likelihood parameters converged to values close to the gene rating parameters in 44 of 50 trials. In 6 Fig. 3B shows the time-course of a typical trial during learn ing. As can be observed, the mask value W and the feature values T converged to values close to the generating ones. For data wi th added 48 of 50 trials (96% reliability). A higher average number of causes per input reduced reliability. A maximum of three causes (on average) were used for the noise less bars test. This is considered a difficult task in the standard bars test. With otherwise the same parameters our algorithm had a algorithm when we increased the accuracy of (13) by setting  X  = 4 (instead of  X  = 3 ). Reliability seemed much more affected by changes to parameters for annea ling and parameter noise, i.e., by changes to those parameters that affect the additional mech anisms to avoid local optima. The standard bars test. Instead of choosing the bar colors randomly as above, they ca n also be set modification. When the generating parameters were as above (e ight bars, probability of a bar to be a bars test with ten bars, D = 5  X  5 , a probability of 2 data points, the algorithm with model parameters as above ex tracted all bars in 43 of 50 trials (86% the number of training images. For N = 1000 instead of 500 reliability increased to 94% (50 trials; mean number of extracted bars 9.9). The bars test with ten bar s is probably the one most frequently found in the literature. Linear and non-linear component ex traction approaches are compared, e.g., in [12, 8] and usually achieve lower reliability values than the presented algorithm. Classical ICA and PCA algorithms investigated in [13] never succeeded in e xtracting all bars. Relatively recent approaches can achieve reliability values higher than 90% but often only by introducing additional constraints (compare R-MCA [8], or constrained forms of NMF [14]).
 More realistic input. One possible criticism of the bars tests above is that the bar s are relatively simple objects. The purpose of this section is, therefore, t o demonstrate the performance of the algorithm when images contain more complicated objects. Si zed objects were taken from the COIL-degree rotation). The images were scaled down to 15  X  15 pixels and randomly placed on a black background image of 25  X  25 pixels. Downscaling introduced blurred object edges and to remove this effect dark pixels were set to black. The training image s were generated with each object being Figure 4: Application to images of cluttered objects. A Selection of 14 of the N = 500 data points. B Parameter change displayed as in Fig. 3. C Change of feature vectors displayed as in Fig. 3. images 1 are given in Fig. 4A. We applied the learning algorithm with H = 6 , an initial temperature for annealing of  X  T init = 1 of parameter values during learning. As can be observed, the mask values converged to represent Note that the model is not matched to the dataset as each objec t has a fixed distribution of color values which is a poor match to a Gaussian distribution with a constant color mean. The model reacted by assigning part of the real color distribution to t he mask values which are responsible for the 3-dimensional appearance of the masks (see Fig. 4B). Note that the normalization (12) was motivated by this observation because it can better tolerat e high mask value variances. We ran 50 trials using different sets of N = 500 images generated as above. In 42 of the trials (84%) the algorithm converged to values representing all six objects together with appropriate values for their mean colors. In seven trials the algorithm converged to a loc al optima (average number of extracted an algorithm with same parameters but H = 8 extracted all objects in 40 of the trials (reliability 80%, average number of extracted objects 7 . 7 ). We have studied learning in the generative model of occlusio n (1) to (4). Parameters can be op-timized given a collection of N images in which different sets of causes are present at diffe rent positions in depth. As briefly discussed earlier, the proble m of occlusion has been addressed by small number of foreground objects (usually one or two) on a s tatic or slowly changing background. Typical applications of the approach are figure-ground sepa ration and the automatic removal of the background or foreground objects. The approach using sprit es is in many aspects more general than importantly, addresses the problem of invariance by modeli ng object transformations. Regarding the modelling of object arrangements, our approach is, however , more general. The additional hidden variable used for object arrangements allows our model to be applied to images of cluttered scenes. The approach in [3, 4] assumes a fixed object arrangement, i.e ., it assumes that each object has the same depth position in all training images. Our approach the refore addresses an aspect of visual data that is complementary to the aspects modeled in [3, 4]. M odels that combine the advantages of both approaches thus promise interesting advancements, e. g., towards systems that can learn from video data in which objects change their positions in depth.
 Another interesting aspect of the model presented in this wo rk is its close connection to component extraction methods. Algorithms such as SC, NMF or maximal ca uses analysis (MCA; [8]) use super-positions of elementary components to explain the data. ICA and SC have prominently been applied to explain neural response properties, and NMF is a popular a pproach to learn components for visual object recognition [e.g. 14, 16]. Our model follows these mu ltiple-causes methods by assuming the data to consist of independently generated components. It d istinguishes itself, however, by the way in which these components are assumed to combine. ICA, SC, NM F and many other models assume linear superposition, MCA uses a max -function instead of the sum, and other systems use noisy-or combinations. In the class of multiple-causes approaches o ur model is the first to generalize the combination rule to one that models occlusion explicitly. T his required an additional variable for multiple-causes models, masks have recently been introduc ed in conjunction with ICA [17] in order to model local contrast correlation in image patches. For ou r model, the combination of masks and vectorial feature parameters allow for applications to mor e general sets of data than those used for classical component extraction. In numerical experiments we have used color images for instance. However, we can apply our algorithm also to grey-level data s uch as used for other algorithms. This allows for a direct quantitative comparison of the novel alg orithm with state-of-the-art component extraction approaches. The reported results for the standa rd bars test show the competitiveness of method used is its assumption of relatively sparsely active hidden causes. This limitation is to some extent shared, e.g., with SC or sparse versions of NMF. Exper iments with higher  X  values in (13) indicate, however, that the performance of the algorithm is not so much limited by the accuracy of the E-step, but rather by the more challenging likelihood la ndscape for less sparse data. therein), SWIFT features [19], or vectors using combination s of color and texture [e.g. 6]. Depend-ing on the choice of feature vectors and the application doma in, it might be necessary to generalize the model. It is, for instance, straight-forward to introdu ce more complex feature vectors. Although other applications also make sense to use multiple feature v ectors per cause. In the extreme case as many feature vectors as pixels could be used, i.e., ~ T features would proceed along the same lines as the derivatio ns for single features ~ T individual prior parameters for the frequency of object app earances could be introduced. Such pa-rameters could be trained with an approach similar to the one in [8]. Additional parameters could in depth in order to model a background. Finally, the most int eresting, but also most challenging model has, in common with state-of-the-art component extra ction algorithms, the assumption that the component locations are fixed. Especially for images of o bjects, changes in planar component positions have to be addressed in general. Possible approac hes that have been used in the literature NMF, and in [18] in the context of object recognition. Potent ial future application domains for our approach would, however, also include data sets for which co mponent positions are fixed. E.g., in many benchmark databases for face recognition, faces are al ready in a normalized position. For component extraction, faces can be regarded as combination s of a background faces  X  X ccluded X  by mouth, nose, and eye textures which can themselves be occlud ed by beards, sunglasses, or hats. In summary, the studied occlusion model advances generativ e modeling approaches to visual data by explicitly modeling object arrangements in depth. The ap proach complements established ap-proaches of occlusion modeling in the literature by general izing standard approaches to multiple-causes component extraction.
 Acknowledgements. We gratefully acknowledge funding by the German Federal Min istry of Ed-ucation and Research (BMBF) in the project 01GQ0840 (Bernst ein Focus Neurotechnology Frank-furt), the Gatsby Charitable Foundation, and the Honda Rese arch Institute Europe GmbH. [1] B. A. Olshausen and D. J. Field. Emergence of simple-cell receptive field properties by learning [2] D. D. Lee and H. S. Seung. Learning the parts of objects by n on-negative matrix factorization. [3] N. Jojic and B. Frey. Learning flexible sprites in video la yers. Conf. on Computer Vision and [4] C. K. I. Williams and M. K. Titsias. Greedy learning of mul tiple objects in images using robust [5] K. Fukushima. Restoring partly occluded patterns: a neu ral network model. Neural Networks , [6] C. Eckes, J. Triesch, and C. von der Malsburg. Analysis of cluttered scenes using an elastic [7] R. M. Neal and G. E. Hinton. A view of the EM algorithm that j ustifies incremental, sparse, [8] J. L  X  ucke and M. Sahani. Maximal causes for non-linear component extraction. Journal of [9] N. Ueda and R. Nakano. Deterministic annealing EM algori thm. Neural Networks , 11(2):271 X  [10] M. Sahani. Latent variable models for neural data analy sis, 1999. PhD Thesis, Caltech. [12] M. W. Spratling. Learning image components for object r ecognition. Journal of Machine [13] S. Hochreiter and J. Schmidhuber. Feature extraction t hrough LOCOCODE. Neural Compu-[14] P. O. Hoyer. Non-negative matrix factorization with sp arseness constraints. Journal of Machine [15] S. A. Nene, S. K. Nayar, and H. Murase. Columbia object im age library (COIL-100). Technical [18] P. Wolfrum, C. Wolff, J. L  X  ucke, and C. von der Malsburg. A recurrent dynamic model for [19] D. G. Lowe. Distinctive image features from scale-inva riant keypoints. International Journal [20] J. Eggert, H. Wersing, and E. K  X  orner. Transformation-invariant representation and NMF. In
