 Medical coding or classification is the process of transforming in-formation contained in patient medical records into standard prede-fined medical codes. There are several worldwide accepted medical coding conventions associated with diagnoses and medical proce-dures; however, in the United States the Ninth Revision of ICD (ICD-9) provides the standard for coding clinical records. Accu-rate medical coding is important since it is used by hospitals for insurance billing purposes. Since after discharge a patient can be assigned or classified to several ICD-9 codes, the coding problem can be seen as a multi-label classification problem. In this paper, we introduce a multi-label large-margin classifier that automatically learns the underlying inter-code structure and allows the controlled incorporation of prior knowledge about medical code relationships. In addition to refining and learning the code relationships, our clas-sifier can also utilize this shared information to improve its per-formance. Experiments on a publicly available dataset containing clinical free text and their associated medical codes showed that our proposed multi-label classifier outperforms related multi-label models in this problem.
 I.2.6 [ Computing Methodologies ]: ARTIFICIAL INTELLIGENCE X  Learning Algorithms Medical data mining, multi-label classification, medical coding, large margin, classification, L1 regularization
Hospitals and in general healthcare providers rely on medical coding to record medical services (procedures) and associated causes or conditions (diagnoses). These procedure and diagnosis codes are key elements in the financial transactions processed by insur-ance companies or other medical reimbursement-processing orga-nizations. Thus, healthcare providers are largely required to use medical codes to classify the present conditions/diseases and pro-cedures performed on basically all patients. In addition to this de facto usage, medical codes have many additional uses in automated decision support in medicine, medical quality or guideline adher-ence, and disease surveillance, among many areas.

The most commonly used diagnosis coding systems are based on the International Statistical Classification of Diseases and Related Health Problems (commonly abbreviated ICD). ICD-9 was created by the World Health Organization (WHO) in 1977 (later extended to ICD-9 CM, where CM stands for Clinical Modification) and is used primarily in the United States. ICD-10 is used in most of the rest of the world, albeit with certain regional modifications. The codes include, in general, classifications for signs, symptoms, ab-normal findings, complaints, social circumstances, and causes of injury or disease. In the United States, ICD-9 codes play a key role in reporting medical statistics to government organizations such as the Joint Commission on Accreditation of Healthcare Organi-zations (JCAHO) and the Center for Medicate and Medicaid Ser-vices (CMS). Importantly, ICD-9 codes are used to track certain diseases, such as the flu (ICD-9 code 486), that may have public health implications.

In the considered scenario, when a patient receives a medical ser-vice, an ICD-9 code is assigned. The code depends on the reasons for the patient visit. This is normally done manually, by skilled personnel. The codes may be assigned immediately, but in most cases, especially for patients requiring hospitalization, codes are assigned retrospectively after an expert reviews medical documen-tation (doctor notes, lab reports, etc.) created during the patient visit. That is, an expert coder reads the documentation and, based on medical knowledge, guidelines, regulations, and experience, as-signs one or more ICD-9 codes to the patient visit.

Given the large number of codes and their level of specificity for certain (not all) diagnoses, this is a very time consuming process. It is also error prone; it is estimated that only 60% to 80% codes truly reflect the patient diagnosis [1]. There are a large num-ber of reasons why more efficiency and more accuracy are highly needed in ICD-9 code assignment. These include, the imperative to reduce healthcare costs; the clear need to keep accurate statistics of diseases, specially those important for public health; the need to increase cost transparency in the healthcare system; and the large potential that a correctly maintained and recorded coding system can have in patient treatment and in general decision support.
In this paper, we address the ICD-9 code assignment problem de-scribed above based on the natural language text employed to doc-ument the patient hospital visit. This includes text from documents such as doctor notes, lab reports, history and physical, nursing as-sessments, etc.

ICD-9 coding has several interesting properties from a data min-ing and statistical modeling point of view. The codes are based on a hierarchy where general categories and several sub-categories are defined. For example, the code 440 is assigned to Atherosclero-sis, but more specific codes such as 440.1 and 440.2 are assigned to Atherosclerosis of Renal Artery and Arteries of the Extremities respectively. A key characteristic of this coding system is that as-signed codes are often correlated, for example the occurrence of Chest Pain (786.5) is common with the occurrence of Congestive Heart Failure (428.0) for the same patient visit. This co-occurrence of diagnoses is to some degree known by experts and thus this prior domain knowledge should be utilized whenever possible in the de-sign of automated coding algorithms. In addition, the problem is multi-label; one patient visit gets associated with multiple codes. Finally, the data is sparse, some codes are very common while oth-ers are very rare. Thus, the data support for the different classes (codes) varies enormously.

Given the specific challenges presented by this problem and ap-plication, we developed and analyzed a method for building a multi-label (multi-class) classifier that can estimate the class structure of the data together with the individual classifiers. Given the lack of data for some classes, the method also allows the incorporation of prior knowledge about the structure automatically, adjusting the de-gree upon which this prior knowledge should be used. We demon-strate experimentally that the approach can be used to solve large problems with a performance similar or superior to related state-of-the-art approaches.

A large number of daily tasks in healthcare are based on man-ual review of information, specially documents, written in natural language. While approaches on natural language processing have grown rapidly in the past years in many areas (primarily in Web mining and language translation), the area of automated medical coding has been explored in a limited way. Most deployed sys-tems use rule-based approaches [7, 15], while others have used ba-sic learning methods such as k-nearest neighbors or naive Bayes classifiers [9]. Sometimes the approach is semi-automated [11]. The most recent approach we are aware of uses a Gaussian Process (GP) based classifier to learn to assign ICD-9 codes to records [10]. However, related approaches have one or several limitations in that they either do not take advantage of prior domain knowledge effi-ciently, are not explicitly designed for multi-label data (thus, they usually cannot exploit the class structure), or do not explicitly un-cover the underlying class (code) relationships. In this paper we propose a method to address these limitations in a new and simple formulation.
This paper presents a solution to the code assignment problem above based on a multi-label, large-margin classification model. In multi-class classification, each point (patient visit) x may be la-beled with a number of distinct classes (codes). A key property of multi-label problems is that class labels are often not mutually inde-pendent given a data point; the existence of this class/label structure is a fundamental factor in this paper.

It is possible to approach this multi-label problem using a combi-nation of standard binary (or even multi-class) classifiers; however, this would not exploit the underlying class structure. If the labels are correlated, we could try to represent combinations of labels as new, compound labels. This is often inappropriate due to the com-binatorial number of compound classes required and the lack of sufficient data to create meaningful estimates [2]).

We can focus on building a function f : X X Y X  that can be used to produce properly ranked labels [13]. Various other strate-gies are possible. If a Hamming loss is used to build the function f basically to reduce the number of label corrections needed to classify the given points, a standard binary classification approach would be sufficient. If the fraction of unordered labels is used as a loss function, this is equivalent to the rank -SVM approach [5], one of the state-of-the-art methods. A related non-parametric approach to achieve this is to learn prototype vectors for each class and rank the labels of the given test point according to its inner product with the prototype vectors [3]. A related method, named the multi-label KNN algorithm (ML-KNN) [18], consists on finding the k nearest examples to the data point to be classified and formulating a pre-diction based on the number of elements of the given class falling in the neighborhood.

The presented approach can represent class relationships where, for example, data points with a particular medical code (class) may be very likely to have a related code but very unlikely to have an un-related code. These type of relationships very often exist in multi-label problems. A standard classifier will ignore or (at best) not explicitly model this potentially rich structure, even though it is present in the data. In this paper, we focus on explicitly uncover-ing this structure for ICD classifications since this would be highly valuable for medical interpretability.

In this problem, there exists prior medical knowledge that can help with incorporating this structure into the classifier. This may resemble the notion of a prior p ( y ) in probabilistic modeling ap-proaches; however, for the purposes of this paper we may not use the term prior knowledge in an equivalent manner 1 . The avail-ability of prior domain knowledge is clearly another motivation for explicitly representing the class structure. However, in practice it is difficult to determine the degree of accuracy of this prior knowl-edge. In this paper we do not make a strong assumption about how reliable this knowledge is, instead we automatically determine the level on which it should be taken into account in order to maximize our classification criterion.
Before introducing formally the proposed method, we first de-fine our notation. Suppose we have D data samples (medical doc-ument), and each of them is in dimension K , where each data sam-ple component (feature) is a binary value that represents whether or not each one of the K considered words is present in the doc-ument. We represent them as D row vectors: x i  X  X  ; here X denotes the domain of instances. Each data point shares an asso-ciate L dimensional row label vector y i , which is formulated from the data in question. In this paper we do not make this restriction about prior knowledge . Y l document does not belong to the code i ). In order to simplify our notation, we will denote all the data samples as a D  X  K matrix: X =[ x 1 x 2  X  X  X  x D ] , and similarly, all the labels as a Y =[ y 1 y 2  X  X  X  y D ] , so individually, each row of X corresponds to one data sample, and its label vector is the corresponding row in Y . Vector e represents a column vector of ones of proper dimen-sionality, and diag( v ) represents a diagonal matrix whose diagonal components are the elements of the vector v .
Consider the following optimization problem: min where
W stands for a K  X  L matrix, and each column w i of W is a hyperplane classifier predicting the i th label. Therefore, since each data point has L labels, we have in total L columns. M can be de-fined as a between-labels relation matrix, of size L  X  L . the appropriate hyperplane shift from the origin (or threshold) for prediction  X  y i given by x i WM . The parameter  X  controls the trade-off between classification accuracy and regularization.  X  notes the matrix Frobenius norm, and  X  1 denotes a matrix L1 norm defined as: this is, the summation of the absolute values of all the elements of the matrix. In supervised learning, it is often the case that even though the total number of input features is large, only a small frac-tion of these features suffices to build a model with (at least) com-parable performance. Furthermore, it is a well-known fact that fea-ture selection can help prevent overfitting in problems with many input features relative to the amount/variability of the data (see [6, 16]). This is generally the case with problems related to text pro-cessing where the number of available features corresponds to a large number of available words that are present in the set of docu-ments.

As mentioned before, M is a matrix that captures the relations between the labels according to prior knowledge and available data.  X  M sim is an initial prior knowledge matrix that contains informa-tion about the labels. This prior knowledge can be provided by the user based on experts X  domain knowledge or it can be simply empirically estimated from available data. The parameter  X  trols how much the matrix M will stay close to the prior knowl-edge  X  M sim vs. the optimization of M to minimize empirical error based on the training data.

Note that from the definition of  X  y i in formulation (1), prediction of label l depends not only on the corresponding classifier w column of W ) but also on the remaining L  X  1 classifiers corre-sponding to the other L  X  1 labels. This dependence is controlled by the matrix M , so defining  X  M sim that encodes prior knowledge about the relation among the expected output of the classifiers, in-tuitively, is a good choice of an initial point for our algorithm.
For empirical estimation of the similarity matrix  X  M sim very general choice that is also employed in our experiments is as follows:
In order to interpret equation (3) it is useful to note the following: Different representations are possible depending on the particular problem at hand.

It is important to note that even when formulation (1) is not convex, it is a box-constrained bi-convex optimization problem for which optimization algorithms with fast convergence rates can be applied as explained below.

Another interesting characteristic of formulation (1) is that strictly speaking, W 1 is not differentiable (around the origin). However, a simple and effective way to overcome this difficulty is the use of differentiable close approximations to the L 1 norm.

We will use the smooth approximation to the L1 penalty pro-posed in [14] that based on the following: (i) | x | =( x ) + +(  X  x ) + , where the plus function is defined as (ii) The plus function can be approximated (smoothly), by the Combining these facts, we arrive to the following smooth approxi-mation for the absolute value function consisting of the sum of the integral of two sigmoid functions (Fig. 1 plots this approximation near 0 for different values of  X  ):
In practice,  X  =10 5 yields results that are within some small tol-erance of the results produced by (optimal) constrained optimiza-tion methods. As opposed to the L1-penalty, this approximation is amenable to standard unconstrained optimization methods since it is twice-differentiable: Figure 1: Approximation for | x | near x =0 using the function | x |  X  for different settings of the parameter  X  This approximation can be used in conjunction with any general likelihood or loss functions. It has been shown in [14] that for optimization problems derived from learning methods with L1 reg-ularization, the solutions of the smooth approximated problems ap-proach the solution to the original problems when  X  approaches infinity.

When dealing with large data sets, it is not computationally fea-sible to update the complete W and M at one single time, both of the two live in a large-dimensional space. Instead, we implemented a computationally inexpensive algorithm that updates W and one column at a time respectively.

In order to understand our large-scale algorithm, it is useful to rewrite W in the form of combinations of column vectors, such that W =[ w 1 , w 2 ,  X  X  X  , w L ] . Similarly M is written as combinations of row vectors M =[ m r 1 m r 2  X  X  X  m r L ] . Using these definitions, we could simplify formulation (1) as: The gradient and Hessian of the objective function of (5) with re-spect to each column vector w j can be written as follows: where  X  is a K  X  K matrix and  X  (  X  ) is the characteristic function. Similarly, using the same idea on M ,we can rewrite it as the com-bination of column vectors: M =[ m 1 , m 2 ,  X  X  X  , m L ] . Then, the gradient and the Hessian of the objective function of formulation (5) with respect to each column vector m j is: G
XY and  X  M trices. By using equations (6-11) with box constraints on can derive an effective implementation that is ideal for large scale problems. We used Quasi-Newton techniques in our implementa-tion, helping our algorithm converge fast to a local minimum, in practice.

Without loss of generality, we set m x and m y to be 0 , which could be achieved by preprocessing the data, so the optimal zero given by  X  opt = m y  X  m x WM . Algorithm 1 box shows the large-scale inexpensive SVM-sim algorithm. In this algorithm, we set the initial W randomly, but one may also choose W from the result of one-vs-rest SVMs in order to expect faster convergence, and threshold usually depends on the scale of matrix W and thus depends on the scale of the multi-label problems themselves. A typical value for is 10  X  4 . This setting provided satisfactory re-sults in most situations.
 Algorithm 1 Large Scale SVM-sim Algorithm input:  X  ,  X  , ,  X  M sim , W initial end while return W and M
Note that we used two publicly available optimization methods as part of our proposed algorithm: 1. For updating W , we used a solver based on the standard 2. For updating M , we used the standard  X  X rust-region-reflective X 
In this section, we describe our data in more detail, provide the pre-processing steps we performed to prepare our data, present our experimental set-up, report our results, and discuss these results.
Each document sample in the ICD-9 Data represents a recording of the events that occurs in a patient X  X  hospital visit. The text in these documents are free-form notes regarding examinations, treat-ments, procedures, evaluations (examples include radiology notes, 2 http://www.cs.ubc.ca/  X  schmidtm/Software/minFunc.html personal physician notes, lab tests, etc.). These documents are au-thored by different people with different qualifications (e.g., physi-cian, nurse, radiologist, etc.). There are a total of 978 this database. We apply a unigram feature representation, with each feature indicating the presence (represented as +1 ) or absence ( of a word. As commonly done in text processing, we first removed stop words and applied stemming, resulting in a 1931 -word dictio-nary. We then retained only words that occurred in at least the data samples, which leaves us with 1155 words. We centered our data to have zero-mean and normalized each feature to have variance of one. There are 140 different symptom or disease codes (classes) in this database. Due that the majority of the classes have very few training examples, in this study we only worked with the codes (classes) that occurred in at least 5% of the samples, corre-sponding to a total of 20 codes.
In our experiments we investigate whether or not taking advan-tage of the relationships among classes can improve the classifi-cation of ICD-9 codes over the standard one-vs-rest SVM, which learns the classifiers for each binary label separately. We also com-pare our technique ( SVM-sim ) with three other different types of multi-label algorithms: an SVM-based algorithm ( rank -SVM [5]), a k -nearest-neighbor-based method (ML-KNN [18]), and a neural-network-based method (BP-MLL [17]). Besides checking for per-formance based on accuracy, another advantage of our approach is that it can learn the relationship among the classes. We also present the similarity matrices that SVM-sim discovers. We report our accu-racies based on a five-fold cross-validation. Within the training set of each fold, we separate 10% for tuning. We tuned our parameters (  X  and  X  ) for all the methods over 11 values ranging from 10 10 5 . For the nearest neighbor algorithm, we tried k =1 , 2 , 4 , 8 , 16 and reported the results from the best k together with the used. For rank -SVM, we tuned the cost parameter over eight val-ues from 10  X  5 to 10 2 . For BP-MLL, we set the number of neurons and number of hidden layers, learning rate and number of train-ing epochs as suggested by the authors [17]. All results from the SVM-based classifiers here are with a linear kernel.
Table 1 reports the five-fold cross-validated accuracies for all five methods. In the table, we highlighted the best performing method for each code class in bold and in red. The higher the accuracies, the better. In Figure 2, we also present the accuracies (as shown on the ( left ) subfigure) for each class in ascending order for all the methods, and their corresponding standard deviations (as shown on the ( right ) subfigure). Note that our method, SVM-sim , performed the best in almost all of the classes and came in close second for the other cases. In all cases, our approach had the lowest variance in accuracies among the different folds. Note, too, how taking advan-tage of the relationship among classes drastically improved the re-sults over one-vs-rest. This data set is a difficult classification task with only about 60%  X  80% accuracy when manually labeled [1]; however, by taking advantage of relationships and data from the other classes helped improve our performance, where we reached accuracies between 95% to 99% .

In Figure 3, we also display the receiver operating characteris-tic (ROC) curves for all the methods and their corresponding area under the curve (AUC). We cannot show all of the 20 ROC plots; instead, we provide the average of the ROC plots for the 20 Observe that our approach, SVM-sim still performed the best. In Ta-ble 2, we report the five-fold cross-validated area under the curve (AUC) results for all five methods on the ICD-9 data for all classes (codes), with the best results highlighted in bold and in red. Note that our approach is the best in all cases except for class We take a closer look at this worst case by plotting the ROC curves on class 18 as shown in Figure 5. Even though our approach is the worst in terms of AUC on class 18 , it performed the best in terms of true positive detection at low false positive ratios (below
The results reveal that the multi-label classification of ICD-9 codes benefits from the sharing of information among the classes. The codes represent different symptoms/diseases, many of which are highly correlated to each other. For example, patients that suf-fer from a particular pain belongs to a subset of symptoms/diseases. The elements in that subset share many common words and are sometimes even just different descriptions of the same disease. Let us say, a patient has vesicoureteral problems ( C 5 : vesicoureteral reflux). It is highly probable that this patient is suffering disorders of the urinary system type ( C 2 ). Inversely, symptoms that are lo-cated at the urinary system would have no correlation with asthma.
In contrast to all the other multi-label methods, we also learn the relationships among classes.  X  M sim and M in equation (3) are the prior and similarity matrices learned by SVM-sim . To high-light the relationship among the classes, we permute the rows and columns of this similarity matrix using co-clustering [4]. The co-clustering algorithm we implemented basically alternates k-means clustering of the rows and k-means clustering of the columns until convergence. After permutation, we obtain the matrix M . Note that the relationship matrix does not have to be symmetric. We can interpret the relationship from this matrix as a directed graph (showing only the strongest 10% relations). Figures 7 and Figure 8 display directed graphs showing the prior code relations  X  M and the learnt relations M respectively. These figures show that our approach besides improving our classification performance also provides us with information regarding the relationship among the classes (codes). For instance, Figure 7 (the graph for prior  X  M reveals that C 13 (which stands for  X  X ever and other physiologic disturbances of temperature regulation X ) and C 18 ( X  X ung field: Coin lesion lung, shadow lung X ) can help predict patients as hav-ing C 15 ( X  X ymptoms involving respiratory system and other chest symptoms X ), which makes sense.

Comparing Figures 7 and 8, we find that the topology of rela-tions changed during the learning process. The graph in Figure 8 (the graph for final M ) shows that fever ( C 13 ), chest pain ( and respiratory abnormalities ( C 14 ) can cause respiratory symp-toms ( C 15 ). The graph also shows that urinary tract infection ( and chest pain ( C 16 ) are associated with fever ( C 13 ). Note that the graph from the final M matrix makes more sense than the prior graph. In the prior relation graph, it indicates that bladder disor-ders ( C 8 ) is predictive of asthma ( C 2 ), which does not seem right. However, after the learning process, the graph from the final shows that chest pain ( C 16 ), lung field ( C 18 ) and pulmonary col-lapse ( C 3 ) can be predictive of asthma ( C 2 ).

Besides learning the class code relations, our approach also learns the features that are important for each code (class) through the L1 norm regularization in our formulation. We consider each column of
W as a baseline classifier (the classifier before structure sharing by matrix M ). Because of the L1 norm regularization on W coefficients for each classifier will be sparse. In Figure 4, we re-port the number of features selected for each class. We considered a feature as being selected for class j if the absolute value of its classes selected different numbers of features and that we achieved substantial amount of reduction from the original 1155 features. In Table 3, we also list the selected words (features) for each class. We limit the list here to the top 5 words (in terms of absolute weight) per class. From the table, we observe that different classifiers do find different key words for the different classes and that the key words selected made sense and are associated to the class. We also noticed that class 13 &amp; 15 use the largest amount of words ( words for the 13 th class, and 172 words for the 15 th class), corre-sponding to fever and cough classes respectively. These two classes are symptoms that commonly occur in many diseases and are more general than other symptom/disease codes; thus, they need more words compared to other more specific symptom/disease codes.
Finally, we investigate how our prior class relationship structure,  X  M sim , affects the performance of our classifier. The first  X  M as what we suggested in Equation 3. Let us call this the similarity prior. We compare this against two other priors: (1) identity and (2) random. Identity assumes no correlation among the classes and serves as our baseline. The other prior assumes a random L matrix, where each element is sampled from a uniform distribution in the set of [  X  1 , +1] . This prior assumes an arbitrary set of re-lations between the different classes. The average ROC results for the 20 classes are shown in Figure 6. We observe that the similarity prior outperforms the other two priors. This shows that knowing a good prior improves the performance of our classification. The figure also shows that even when we start with a bad prior, like ran-dom, we still obtain ROC results that are comparable with the other competing multi-label classifiers (see results on Figure 3). Figure 3: Results for ICD9 Text Data: Average ROC curves for the different methods from 20 codes.
Hospitals and healthcare providers rely on medical coding to record medical services and associated causes and conditions dur-ing a patient X  X  visit. This coding is normally done manually. Given the large number of codes and their level of specificity for certain diagnosis, this is a very time consuming process and is error prone Table 3: A list of words whose absolute weight value is larger than 0 . 05 for each medical code (class). Note that we only limit the list to up to five words per class. methods for each of the 20 codes. Figure 4: The number of features (words) selected by SVM-sim for each class out of the original 1155 words. with an estimated accuracies of around only 60% to 80% . In this study, we have developed a multi-label classifier to automate the process of classifying ICD-9 codes from text recordings. We cast the medical coding problem as a multi-label classification problem Figure 5: The ROC curves for Class 18 , the worst AUC result for SVM-sim . because each text document can be classified to one or more codes (classes). The number of codes/classes is high and the occurrence of these codes may be few in a training set. Moreover, codes (which are associated with symptoms and/or diseases) are correlated. This Figure 6: ROC results for three different initial prior class re-lationship matrix,  X  M sim : similarity, identity, and random. motivated us to take advantage of code/class relations to help build better classifiers for classes with few training samples. In this pa-per, we have introduced a multi-label large-margin formulation that explicitly represents the medical code/class structure and simulta-neously learns the classifier and the code/class structure from the data. Moreover, our formulation enables the incorporation of prior knowledge about the structure automatically into the classifier. We found that sharing the code/class structure among the classifiers help improve the performance of each binary classification. Our experiments demonstrated the ability of our approach in discover-ing medical code relations. Furthermore, our results reveal that in-corporation of prior domain knowledge helped SVM-sim to obtain classification performance superior to other multi-label approaches for classifying ICD-9 medical codes, where we reached accuracies between 95% to 99% .
 This work is supported by NSF IIS-0915910. [1] C. Benesch, D. W. Jr, A. Wilder, P. Duncan, G. Samsa, and [2] M. Boutell, J. Luo, X. Shen, and C. Brown. Learning [3] K. Crammer and Y. Singer. A new family of online [4] I. S. Dhillon. Co-clustering documents and words using [5] A. Elisseeff and J. Weston. A kernel method for [6] I. Guyon and A. Elisseeff. An introduction to variable and [7] http://www.icd9coding.com/. [8] R. B. Jean, J. Charles, and G. J. Nocedal. A trust region [9] L. Larkey and W. B. Croft. Automatic assignment of ICD9 [10] L. Lita, S. Yu, S. Niculescu, and J. Bi. Large scale diagnostic [11] C. Lovis, P. Michel, R. Baud, and J. Scherrer. Use of a [12] J. Nocedal and S. Wright. Numerical Optimization (2nd ed.) . [13] R. E. Schapire and Y. Singer. Boostexter: A boosting-based [14] M. Schmidt, G. Fung, and R. Rosales. Fast optimization [15] A. Sonel, C. Good, H. Rao, A. Macioce, L. Wall, [16] J. Weston, A. Elisseeff, B. Scholkopf, and M. Tipping. Use [17] M.-L. Zhang. Multilabel neural networks with applications [18] M.-L. Zhang and Z.-H. Zhou. A k-nearest neighbor based
