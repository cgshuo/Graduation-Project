 Recommender systems are increasingly being employed to person-alize services, such as on the web, but also in electronics devices, such as personal video recorders. These recommenders learn a user prole, based on rating feedback from the user on, e.g., books, songs, or TV programs, and use machine learning techniques to infer the ratings of new items.

The techniques commonly used are collaborative ltering and naive Bayesian classication, and they are known to have several problems, in particular the cold-start problem and its slow adaptiv-ity to changing user preferences. These problems can be mitigated by allowing the user to set up or manipulate his prole.

In this paper, we propose an extension to the naive Bayesian clas-sier that enhances user control. We do this by maintaining and exibly integrating two proles for a user, one learned by rating feedback, and one created by the user. We in particular show how the cold-start problem is mitigated.
 G.3 [ Probability and Statistics ]: Probabilistic algorithms (includ-ing Monte Carlo); H.3.3 [ Information Search and Retrieval ]: In-formation ltering Algorithms classication, machine learning, naive Bayes, recommender, user prole, user control, multi-valued features Copyright 2007 ACM 978-1-59593-730-8/07/0010 ... $ 5.00.
The use of recommender technology is steadily being introduced into the market. Web sites such as Yahoo! Movies and MovieLens offer a recommender to aid users in nding the movies they like, and personal video recorders like the Tivo box use a recommender for automatic recording of the user's favorite movies.

A recommender learns the taste of a user, based on ratings that the user supplies on items, such as movies. These ratings are typi-cally a positive negative classication, indicating like and dislike, respectively, or a more elaborate classication into a range of like-degrees . As such, this is the interface by which the user teaches the recommender about his taste. This learning process is inherently slow in the sense that the user has to rate a considerable number of items before the recommender can make sensible suggestions. This leads to the well-known cold-start problem and to a slow adaptabil-ity of the recommender to changing user preferences. The former problem pertains to the situation that the user has only rated a few items.

Although the cold-start problem can be mitigated by setting up a rating session wherein the user rates a sufcient number of items, the burden this places upon the user is generally considered unac-ceptable. Furthermore, this is not an elegant way to deal with a sudden change of interest. For example, if the user discovers that he likes a particular actor or director, having to rate many movies before the recommender has learned this clearly indicates that this rating interface is inappropriate to deal with such situations. The user should have more direct control over the recommender to be able to resolve these situations.

Naive Bayesian classication (NBC) lends itself well to this type of user control because often, the prole it uses is quite intuitive. A movie is described by a number of feature-value pairs, such as (channel, Hallmark Movie Channel), (actor, Clint Eastwood), or (start time, 20:00), and the prole consists of positive and negative counts for individual feature-value pairs. From these gures, like-degrees can be computed, at the level of feature-value pairs rather than at the level of individual movies. The user can similarly create a prole by dening like-degrees for feature-value pairs, so that these proles can be combined.

We propose to extend NBC by incorporating a user-dened pro-le and exibly combining it with the learned prole. This exibil-ity is such that, initially, the recommender operates based solely on the user -dened prole and, as the recommender learns, the learned prole gradually replaces the user -dened prole. Ho we ver, when the user adapts his prole, the adapted part temporarily tak es over again.

The remainder of this paper is organized as follo ws. After briey describing related work in Section 2, we revisit nai ve Bayesian classication in Section 3. Then, in Section 4, we explain how to incorporate a user -dened prole into the classier . In Section 5 we generalize this to multi-v alued features, where a feature can at-tain a number of values simultaneously . We report on performance results, pro viding a proof of concept for the recommender , in Sec-tion 6. We mak e some concluding remarks in Section 7.
Several approaches have been proposed in the literature to miti-gate the cold-start problem. In [6], the authors propose to use pre-computed ster eotypes from which a user can choose some to jump-start a recommender . A stereotype is a possibly lar ge set of items, TV programs in their paper , that are similar to each other , where similarity is dened using the modied value-dif ference metric (see [2], [10]). The precomputation uses rating histories of a number of users and uses a standard clustering algorithm.

An alternati ve approach is to combine a user -dened recom-mender with a learning recommender by combining their outputs. These are called hybrid recommender systems. in [12], the authors propose to use a neural netw ork for fusing the outputs. User con-trol beyond incorporating a user -dened recommender is, howe ver, lacking.
 In [9], the author suggests an alternati ve to Mo vieLens, called DynamicLens, to aid the user in pro viding a recommender system with user -dened ratings to a meta-recommender system. The in-terf ace is in particular geared towards enhancing user control in hybrid recommender systems.

The aim of this paper is to inte grate a user -dened prole and a learned prole into a single recommender , rather than using multi-ple recommenders, offering direct user control over recommended items. We next describe NBC in detail, starting with some notation. An instance x is described by f feature values x i 2 D i , for each i = 1 ; 2 ; : : : ; f , where D i is the domain of feature i . Its class is denoted by c ( x ) 2 C , where C is the set of classes. For the moment, we do not consider missing features, but return to this shortly .
Given is a non-empty set X of training instances and for each instance x 2 X its class c x = c ( x ) . Let y be an instance to be clas-sied. The approach in NBC is that we express Pr ( c ( y ) = each j 2 C , in terms of the training data.

Let x be a random variable on the domain U of instances. Us-ing Bayes' rule and assuming conditional independence of feature values for a given class, we can rephrase Pr ( c ( y ) = j
Pr ( c ( y ) = j ) = Pr ( c ( x ) = j j x = y ) As the denominator can alternati vely be written as the sum over all j of the numerator , it serv es as a normalization constant. When comparing probabilities, this constant can be omitted.
 The factors Pr ( c ( x ) = j ) are called prior probabilities , the factors Pr ( x i = y i j c ( x ) = j ) conditional probabilities , and the expressions Pr ( c ( y ) = j ) are called the posterior probabilities .

The general approach in NBC is that the prior and conditional probabilities are estimated using the training data to obtain esti-mates of the posterior probabilities. We dene the learned prole as follo ws. For each feature i , each value v 2 D i , and each class j , where j S j denotes the cardinality of a set S . By assuming, with-out loss of generality , that for each j , N ( j ) &gt; 0, we estimate the probabilities as By substituting these estimates into Equation 1 we obtain an es-timate of the probability that y belongs to class j in terms of the training data.

In case N ( i ; y i ; j ) = 0 in Equation 4, a technique called Laplace corr ection , see [1], is used to pre vent the conditional probability estimate and corresponding posterior probability estimate to be-come 0. For now, we will assume that we do not have any so-called zero counts.

The nai ve Bayes' classication  X  c ( y ) of y is dened as the value of j that maximizes the estimate. Ties are brok en arbitrarily . For-mally ,  X  c ( y ) is dened as cation error rate E , or error rate for short, is dened as and is a measure for the performance of the classier . Here, x is again a randomly chosen instance. The classication accurac y is dened as 1 E . The denition of error rate can be rened by considering class-conditional error rates. Given a class j , we dene as the class-j error rate. The class-conditional classication accu-rac y is given by 1 E j .

This summarizes the classical approach towards nai ve Bayesian classication, see also [7]. Some remarks, howe ver, are worth mak-ing. First, Equations 3 and 4 can indeed be used as estimates of the prior and conditional probabilities, respecti vely , if the training set consists of instances chosen randomly on the instance space U . In practice, this may not be the case. For example, if the prior prob-abilities are hea vily skewed, then this would require a relati vely lar ge training set to obtain a suf cient number of class-j instances in the training set, for those values of j for which the prior proba-bilities are relati vely small, to obtain suf ciently reliable estimates for the conditional probabilities. It seems therefore reasonable to keep the values of N ( j ) approximately equal. In this case, howe ver, Equation 3 does not generally hold, and proper values for the prior probabilities should be obtained in a dif ferent way. Also in other cases, such as in a recommender system, where it may be lar gely up to the user which instances end up in the training set, Equation 3 may be invalid.
For a two-class recommender , [5] suggests to set the prior prob-abilities so as to balance the class-conditional error rates, an ap-proach that is essentially the same a suggested in [4], where the author uses a cost-based approach towards classication. We adopt the same approach, in that the priors are set to predened values p for each j 2 C , based on criteria related to the class-conditional error rates.

The second remark pertains to missing features and features with multiple values. We will return to the latter in Section 5. When-ever a feature is missing in an instance to be classied, we omit the corresponding factor from Equation 5. To deal with missing fea-tures in instances from the training set, we adapt the estimate of the conditional probability , given in Equation 4 to where N ( i ; j ) =  X  v 2 D the number of instances in the training set that do have a value for feature i .

The denition of  X  c in Equation 5 is thus replaced by
The goal in this section is to inte grate a user -dened prole with the learned prole, given by Equation 2. We do this by dening lik e-de grees for indi vidual feature values.

We assume that there are two classes, i.e., positi ve ( + ative ( ). We also simplify notation by omitting, where possible, explicit reference to the random variable x . In particular , we ab-predened prior probabilities p + and p , we deri ve that Corresponding to the denition of  X  c in Equation 8, if the estimate of the right-hand side of this equation is lar ger than 1, y is classied as positi ve, if it is smaller than 1, y is classied as negative, and if it equals one, a random choice is made.

We next dene as the skewing factor for feature-v alue pair ( i ; v ) . As sho wn by Equation 11, it indicates the relati ve skew that v causes for feature i in the prior probabilities. Using Equation 10, Equation 9 can be rephrased as The involv ed skewing factors are thus multiplied together . Note that a non-zero skewing factor r is canceled by its inverse 1
Where r ( i ; v ) ranges from 0 to  X  , the deri ved quantity l dened as ranges from 0 to 1, 1 itself excluded. This l ( i ; v ) can be interpreted as a like-de gree for feature-v alue pair ( i ; v ) , where 0.5 corresponds to neutral, as it leads to the neutral skewing factor of 1. Further -more, two non-zero lik e-de grees l and 1 l lead to the skewing factors of l = ( 1 l ) and ( 1 l ) = l , respecti vely , which cancel each other when multiplied together .

This forms the basis for the incorporation of a user -dened pro-le l u . On the one hand, the lik e-de gree l l ( i ; v ) training set using the learned skewing factor r l ( i ; v which estimates the skewing factor given by Equation 10. On the other hand, for each feature-v alue pair ( i ; v ) , there is a user -dened can set this lik e-de gree to any value in the range [ 0 ; def ault value enables the user to easily create a prole by only set-ting a few lik e-de grees.

The user -dened and learned lik e-de grees are inte grated as fol-lows. We dene the inte grated lik e-de gree l int ( i ; v sponding inte grated skewing factor r int ( i ; v ) using the inverse func-tion x = ( 1 x ) of x = ( 1 + x ) , which is used in Equation 13. This skewing factor replaces r ( i ; v ) in Equation 12.

To generate a recommender that starts off as one based on a user -dened prole and gradually turns into a learning recommender based only on the learned prole, this a should preferably be made dependent on the size of the training set. The thick, solid line in Figure 1 illustrates a possible denition, where the horizontal axis denotes the training set size.
 Figur e 1: Possible dependency of a on the training set size S (thick, solid line) and a possible trajectory of a when an update at S 0 in the user -dened prole and tw o pruning actions are perf ormed (thin, grey lines).

Initially , that is, until the training set size has a specic size K , the user -dened prole should be acti ve only to allo w the learned prole to mature some what. Otherwise, the user -dened prole would immediately be contaminated with unreliable data. Then, the learned prole gradually tak es over as the training set size in-creases, until it is suf ciently lar ge, indicated by the limit L , at which point the learned prole has completely tak en over. There is, of course, ample freedom in choosing how a depends on S . The linear relationship is chosen here for simplicity .

This can be rened by making a dependent on i , the feature un-der consideration in Equation 15. In particular , N min ( as pro vides a measure for the size of the training data pertaining to feature i . Using this feature-dependent measure is especially rel-evant for features that are often not assigned a value, resulting in relati vely unreliable estimates of the conditional probabilities.
Hence, we propose to dene a i as follo ws. where for an expression E , ( E ) + stands for max ( 0 ; E inition corresponds to the thick, solid line in Figure 1, whereby S = N min ( i ) .
As the training set size increases, the role of the user -dened prole generally decreases. Hence, if the user updates his prole, say the lik e-de gree of feature-v alue pair ( i ; v ) , while the learned prole has nearly or completely tak en over, then this does not resort in much effect, if any.

A possible solution to this problem is to prune the rating history such that N min ( i ) decreases, but this is a rather drastic approach. It is instead more ele gant to incorporate an offset D ( i N min ( i ) is decreased. Instead of using a i , we use a iv No w, when the user updates the lik e-de gree of feature-v alue pair ( i ; v ) , the corresponding offset is set to, e.g., N min ( i so that, for this pair , the recommender starts off using only the user -dened prole again. Once a iv has become 0 again, D ( i ; v reset to 0 as well. See Figure 1 for a possible trajectory of a
To retain exibility in the learned prole to adapt to user prefer -ences that change slo wly over time, the rating history should reg-ularly be pruned, e.g., by disre garding the oldest ratings. This is complicated by the presence of non-zero offsets D ( i ; v
There are various ways to deal with this, but an obvious and simple solution is to try and keep a iv constant, until the size of the training set becomes so small that an increase in a iv sary . This results in the follo wing update for D ( i ; changes from N to N 0 &lt; N .
 The thin, gre y lines in Figure 1 illustrates a possible trajectory , in-dicated by the arro wheads, of the value of a after an update in the user -dened prole at S = S 0 and two pruning actions.
It is not uncommon that features may have multiple values, such as the cast of a mo vie or a list of genres describing a mo vie in general terms. A possible approach is to consider a list of values as independent and to incorporate them as such in the computation of the posterior probabilities. In particular , if a feature i has a set of values V , then all feature-v alue pairs ( i ; v ) , with v as separate features, each contrib uting a factor in the product in Equation 8. Especially when the values in V are dependent, such as with a x ed cast, this approach results in an over-representation of this feature.

We pro vide an alternati ve to this approach, based on [11], where the author considers probabilistic feature values: The value of a feature i is given by a probability distrib ution on its domain D
Let y be an instance with probabilistic feature values, i.e., for each i = 1 ; 2 ; : : : ; f , y i is randomly distrib uted on D probability distrib ution p y ( i ; v ) . Let V y ( i ) D possible values of y i . In the case that j V y ( i ) j = a deterministic value. Let the set V y = f v j v i 2 V y ( denote the set of values that y can attain. We assume that for each v 2 V y This independence assumption is similar to the usual conditional independence assumption.

We are again interested in Pr ( c ( y ) = j ) for each class j . Let x be a random instance, uniformly distrib uted on the instance space. We proceed along the same lines as in Section 3 and partially follo w St  X  orr . Note that we use short-hand notation, i.e., we abbre viate ` c ( function.

Pr ( c ( y ) = j ) space.

As before, the right-hand side of Equation 18 can be estimated using the training data, which may also contain instances with prob-abilistic feature values. To this end, we generalize the denition of the user prole N ( i ; v ; j ) as follo ws.

For an instance y , the classication  X  c ( y ) is generalized to Multi-v alued features are modeled as uniformly distrib uted prob-abilistic features, i.e., for each i , all values v 2 V y p ( i ; v ) can be omitted from the formula abo ve, as is easily veri-ed. Equation 19 can in this case be interpreted as if each instance with a multi-v alued feature i , say with m values, is subdi vided into m sub-instances, one corresponding to each value, each of which is counted 1 = m times. Figur e 2: Graphical views of the integration steps: (a) without and (b) with multi-v alued featur es.

No w that we have generalized nai ve Bayesian classication to deal with multi-v alued features, we next explain how to incorporate a user -dened prole. Analogously to Equation 9, we deri ve, based on Equation 18, Using Equation 10, we can rephrase this as from which it is easily seen that, for each feature i , a weighted average of the involv ed skewing factors is calculated, the weights depending on the conditional probabilities of the involv ed values v . As these weights are not available in the user -dened prole, we suggest replacing the weights by 1 = j V y ( i ) j to calculate the ordi-nary average.

Both average skewing factors must next be translated to lik e-degrees to tak e a con vex combination of these lik e-de grees. The nal issue to resolv e now is how to tak e a con vex combination lik e in Equation 15, where the lik e-de grees have been replaced by the translation of an average of skewing factors. An obvious solution is to use the maximum of a iv over v 2 V y ( i ) , as this results in a con-trib ution from the user -dened prole corresponding to a value for which the contrib ution is maximal. In this way, whene ver the lik e-degree for a value is updated by the user , its role will maximally permeate the results. The procedure is illustrated in Figure 2b. For the learning part of the recommender , we estimate the weighted average of the learned skewing factors in Equation 20 using the training data, resulting in a single learned skewing factor , which is translated to a learned lik e-de gree. For the user -dened part, we tak e the ordinary average of the involv ed user -dened skewing factors, based on the user -dened lik e-de grees, resulting in a user -dened skewing factor , which is translated back to a user -dened lik e-de gree. Then, these two lik e-de grees are combined as in Equa-tion 15, but with an alternati ve value a 0 for a as explained abo ve, and translated back to an inte grated skewing factor .
 Figur e 3: Subdi vision of part of the rating history of a user into a user -dened-pr ole, training, and test part.
This section consists of three parts. We describe the simulation setup in the rst part. In the second, we report on initial results while experimenting with an actual implementation, resulting in a number of impro vements. In the third part, we pro vide a proof of concept by using a specially prepared user -dened prole.
For a thorough assessment of the performance of the recom-mender , it is necessary to inte grate the recommender into an ap-plication or system, such as a personal video recorder , to involv e users, and to dene appropriate performance measures. In particu-lar , when the recommender is used to guide the automatic recording of broadcast mo vies on a hard disk, the total average value to the user of the content on disk would be an appropriate measure. An-other issue that is of rele vance especially in the current conte xt is user satisf action pertaining to the possibility to control the recom-mender . A user may initially set and tune a simple prole, based on immediate feedback in terms of recommended items. We cur -rently circumv ent these comple x assessments and instead focus on a proof of concept, wherein we will sho w that, given an appro-priately chosen user -dened prole, the proposed solution indeed mitig ates the cold-start problem. For reasons of space, we will not investig ate sudden changes of interest by users, so that the offsets D ( i ; v ) do not play a role and the a i , dened in Equation 17 can be used, which is independent of the feature values.

We consider the rating histories of seven users A, . . . , G that we collected. For each user , we use part of his rating history to create an appropriate user -dened prole. Ho w this is done will shortly be explained. We use another part of the rating history to train the recommender and to obtain values for the prior probabilities. We use yet another part to test it. Figure 3 and Table 1 illustrate the details. The complete rating history of size S hi is sho wn as a line that loosely corresponds to a time line. It alternatingly contains positi vely and negatively rated programs. On this line are indicated the data used for the user -dened prole, S ud in size, the training set of size S tr , and the test set of size S te . The variable S indicates the starting position of the three adjacent parts and this variable runs over the rating history to collect suf cient statistics.
Referring to the table, the parameters K and L pertain to the def-inition of a i in Equation 17. The y were chosen, based on some experience with the recommender . Note that a value of 50 for L implies that a rating history of at least 100 programs is required for the recommender to become completely based on the learned pro-le. The parameter d is used in the construction of the user -dened prole, and is discussed belo w. For each value of S tr , which runs from 0 to 100 with a step size of 5, the variable j , which controls S , runs from 0 to j max , where j max is the lar gest inte ger satisfying the inequality ( j max + 1 ) S ud + S tr + S te S hi . This choice causes almost the entire rating history to be used for each value of S time with an independent, user -dened prole. These j max + sults are averaged to compute an error rate.

The user -dened prole is constructed as follo ws. Using the designated history part, skewing factors are dened for all feature-value pairs, according to Equation 14, using Laplace correction if necessary . These are next con verted to lik e-de grees and rounded to the nearest of a limited number of lik e-de grees l k , k dened as A value of d = 7 for d seems reasonable. Hence, we mimic a user who has meticulously dened a prole that closely matches a learned prole based on 50 ratings, but is restrained to only a limited number of equidistant lik e-de grees. Although this is not realistic in practice, it does pro vide proper input for a proof of con-cept.

As already mentioned, the training set is also used to generate values for the prior probabilities. This is done as follo ws. Using the lea ve-one-out cross-v alidation method, see [7], positi ve poste-rior probability estimates are calculated for all training instances, using uniform priors. Ne xt, a decision threshold in the interv al ( 0 ; 1 ) is determined that results in a minimal dif ference between the positi ve and negative classication error rate on the classied instances. The decision threshold determines which instances are classied as positi ve and which ones as negative, based on a com-parison with the positi ve posterior probability estimates. The deci-sion threshold can be translated to prior probabilities. In particular , it can be sho wn that, if uniform priors are used initially , then for a decision threshold g , the positi ve prior probability should set to 1 g . Once the priors have been set, the arg-max operator can be used, effecti vely resulting in using a decision threshold of 0.5.
In practice, a user will not generally set a lar ge number of lik e-degrees, so that the user -dened prole will contain a lot of neutral values of 0.5, and thus skewing factors equal to 1. These neutral values have a detrimental effect on the classication accurac y. To mitig ate this, the approach we tak e is that the ordinary average over the user -dened skewing factors is tak en only over those unequal to 1. If there are no such skewing factors, the average is set to 1. This change correspondingly inuences the denition of a 0 in the general case that the offsets may be unequal 0. The maximum is only tak en over those values whose user -dened skewing factors are unequal to 1. If there are no such skewing factors, all a -values for the multi-v alued feature are the same, and this value should be chosen. For the latter it is required that the offset D ( reset to 0 whene ver the user resets the corresponding lik e-de gree to neutral. This, howe ver, is of no concern for the current simulations.
Although it is tempting not to use small training sets to generate the priors, it has a detrimental effect on the classication accurac y. Hence, unless there is no training data in either class, in which case the priors are set to 0.5, the training set is used to generate the priors.

The sometimes necessary Laplace correction needs the domain sizes of the features. For some features, this domain is very lar ge, such as for actors, and in general these are not kno wn. We instead use as the domain size for feature i the number of feature-v alue pairs ( i ; v ) that exist in the training set, with a lower bound of 1 to pre vent domains of size 0.

In the used rating histories, some features are often not present, leading to relati vely small values of N min ( i ) , dened in Equation 16 for lar ge training sets. This consequently leads to a slo w tak e-o ver by the learning recommender . And besides this, the features that are often not present generally do not contrib ute signicantly to the classication accurac y. Hence, all features that were lar gely absent in the rating histories were discarded. For simplicity , we also discarded the feature `description'.
The performance measure of interest we use is the classication error rate. Figures 4 10 compare the classication error rates of the inte grated recommender with that of a learning recommender for each of the users.

For each of the users, the results sho w that the cold-start prob-lem has been signicantly reduced. Depending on the user , the inte grated recommender has an adv antage over the learning recom-mender for a longer or shorter period of time. For each user , the curv es con verge quite fast to a dif ference of less than 0.05. This may be explained by the fact that the tastes of the users are obvi-ously not that dif cult to learn.

Apparently , choosing priors, based on a small training set, and using an ordinary average instead of a weighted average as ex-plained in Section 5 do not have a devastating effect.
In this paper , we have proposed to seamlessly inte grate a user -dened and a learned prole into a recommender based on nai ve Bayesian classication in order to mitig ate the cold-start problem and to enhance user control.

The results reported upon pro vide a proof of concept using a limited amount of ground-truth data. The experiments could be extended with more data, using, for instance, the Duine data set, see [3]. In addition to these experiments, user tests should be per -formed to assess the use and usefulness of the proposed solution, including sudden changes of interest of the user . To test sudden changes of interest, a possible approach is to combine the rating histories of two users and append one to the other . Upon the change from the rst to the second rating history , a user -dened prole is built and incorporated using some data from the second rating his-tory in a similar way as described in the paper .

The inte gration of a user -dened prole with a learned prole also allo ws the user -dened prole to come from another source, or even various sources. For example, using the learned prole from another user can be used to jump-start the learning recommender , thereby still allo wing ample freedom to change this prole.
The proposed solution may be rened by incorporating the re-sults from Pronk, Gutta, and Verhae gh (2005), who extend the nai ve Bayesian classier by adding condence levels to the pos-terior probability estimates. These condence levels can pro vide additional control pertaining to how fast the learned prole could tak e over the user -dened prole. This is a topic for further re-search.

A further renement is to utilize feature-selection algorithms to optimize the performance of the recommender by excluding certain features. An additional issue here is that the user might still want to exert control on the recommender using one of the excluded fea-tures. Also this is a topic for further research. [1] Cestnik, B. [1990]. Estimating probabilities: a crucial task in [2] Cost, S., &amp; Salzber g, S. [1993]. A weighted nearest neighbor [3] Duine [2004]. Duine Project , http://www .telin.nl/project/ [4] Elkan, C. [2001]. The foundations of cost-sensiti ve learning, [5] G  X  artner , T., Wu, S., &amp; Flach, P.A. [2001]. Data mining on the [6] Kurapati, K., &amp; Gutta S. [2002]. Instant personalization via [7] Mitchell, T.M. [1997]. Mac hine Learning . McGra w-Hill. [8] Pronk, V., Gutta, S.V .R., &amp; Verhae gh, W.F.J. [2005]. [9] Schafer , J.B. [2005]. DynamicLens: A dynamic user [10] Stanll, C., &amp; Waltz, D. [1986]. Toward memory-based [11] St  X  orr , H.-P . [2002]. A compact fuzzy extension of the nai ve [12] Zimmerman, J., Kurapati, K., Buczak, A.L., Schaf fer , D.,
