 Abstract How to understand intents behind user queries is crucial towards improving the performance of Web search systems. NTCIR-11 IMine task focuses on this problem. In this paper, we address the NTCIR-11 IMine task with two phases referred to as Query Intent Mining ( QIM ) and Query Intent Ranking ( QIR ). (I) QIM is intended to mine users X  potential intents by clustering short text fragments related to the given query. (II) QIR focuses on ranking those mined intents in a proper way. Two challenges exist in handling these tasks. (II) How to precisely estimate the intent similarity between user queries which only consist of a few words. (2) How to properly rank intents in terms of multiple factors, e.g. relevance, diversity, intent drift and so on. For the first challenge, we first investigate two interesting phenomena by analyzing query logs and document datasets, namely  X  X  Same-Intent-Co-Click  X  X  ( SICC ) and  X  X  Same-Intent-Similar-Rank  X  X  ( SISR ). SICC means that when users issue different queries, these queries represent the same intent if they click on the same URL. SISR means that if two queries denote the same intent, we should get similar search results when issuing them to a search engine. Then, we propose similarity functions for QIM based on the two phenomena. For the second challenge, we propose a novel intent ranking model which considers multiple factors as a whole. We perform extensive experiments and an interesting case study on the Chinese dataset of NTCIR-11 IMine task. Experimental results demonstrate the effectiveness of our proposed approaches in terms of both QIM and QIR . Keywords Information retrieval Query understanding Intent mining Intent ranking NTCIR-11 IMine task Most queries are short, ambiguous and multifaceted. For example, the query  X  X  X aguar X  X  may refer to the animal, the car or the software. Actually people frequently issue queries with more than one unspecified intent (Hu et al. 2012 ; Sakai et al. 2013 ; Qian et al. 2013 ). Besides, users X  information needs are multifaceted, exploratory, and a same query may imply different information needs of users. For the query  X  X  X wine flu X  X , doctors may be interested in the pathogenesis and treatment solutions, while patients may look for the transmissions and preventive measures.

Recently understanding the intents behind users X  queries has attracted significant attention in information retrieval (IR) (Dou et al. 2011a ; Dang and Croft 2012 , 2013 ). It is one of the most fundamental problems in IR systems. For desktop users, it can help to diversify the search results to cover as many intents as possible in the first page in order to satisfy most users X  information needs. For mobile users, it can help to infer a user X  X  exact intent to personalize the search results in the limited screen (Beg and Ahmad 2007 ; Jiang and Tan 2009 ). Besides, it is also a crucial issue in many IR problems such as query suggestion and expansion (Hu et al. 2012 ; Qian et al. 2013 ; Liao et al. 2011 ; Biancalana et al. 2013 ).

In this study, we focus on the NTCIR-11 IMine task. Our efforts are made in two phases: (I) Query Intent Mining ( QIM ) and (II) Query Intent Ranking ( QIR ). For a given query, QIM tries to discover a two-level intent hierarchy with a clustering process from candidate text fragments 1 of the query. QIR tries to rank each layer of the two-level intent hierarchy in terms of relevance, diversity and intent drift.

In particular, in Phase (I), we first investigate two interesting phenomena by analyzing query logs and document datasets, namely  X  X  Same-Intent-Co-Click  X  X  ( SICC ) and  X  X  Same-Intent-Similar-Rank  X  X  ( SISR ). SICC means that when users issue different queries, these queries may represent the same intent if they click on the same URL. SISR means that if two strings denote the same intent, we should get similar search results when issuing them to a search engine. Then we define similarity functions based on the two phenomena as well as syntactic and semantic characteristics. After that, we obtain an integrated similarity function with a supervised learning approach. Finally, we propose an affinity propagation-based clustering algorithm (Frey and Dueck 2007 ) for discovery of the intents and con-struction of the two-level intent hierarchy to interpret a query. In Phase (II), we propose ranking models for each layer of the two-level intent hierarchy by considering multiple factors, e.g. relevance, diversity, novelty, time. We further prove that our ranking model is a monotone and submodular function, and thus we can get an approximation of  X  1 1 e  X  with a greedy algorithm (ALGORITHM 2) (Cornuejols et al. 1977 ; Nemhauser et al. 1978 ). We perform extensive experiments and an interesting case study on the dataset of NTCIR-11 IMine task. 2 Experimental results demonstrate the effectiveness of our pro-posed approaches in terms of both intent mining and ranking.

To sum up, our main contributions are listed as follows.  X  We investigate two significant phenomena by analyzing user behavior data in depth,  X  We propose a supervised learning approach rather than traditional heuristic approaches  X  We present ranking models to order the two-level intent hierarchy considering multiple  X  We prove that our ranking model is a monotone and submodular function, and thus we The rest of this paper is organized as follows. Section 2 surveys the related work. Section 3 formulates the intent mining and intent ranking problems. Sections 4 and 5 present the clustering-based intent mining approach and intent ranking models respec-tively. Section 6 reports the experimental results and a case study. Section 7 concludes the paper and discusses our future work. 2.1 Query intent mining Existing literature about query intent mining can be classified into two categories: Clus-tering/Classifying Search Results or URLs and Clustering/Classifying Query Related Terms . We will discuss them respectively.
 Clustering/Classifying Search Results or URLs.
 Given a query, this category of approaches consider each intent behind the query as a set of search results or URLs, which can be straightforwardly discovered with clustering or classification algorithms.

Chen and Dumais classified search results into predefined hierarchical categories such as Yahoo! or LookSmart X  X  Web directory (Chen and Dumais 2000 ). Wen et al. clustered similar queries according to their contents and user logs. They proposed a similarity function based on query and search results content to compare two queries (Wen et al. 2001 ). Carlos Cobos et al. introduced a new description-centric algorithm for the clustering of web results, called WDC-CSK, which is based on the cuckoo search meta-heuristic algorithm, k-means algorithm, Balanced Bayesian Information Criterion, split and merge methods on clusters, and frequent phrases approach for cluster labeling (Cobos et al. 2014 ). Zeng et al. ( 2004 ) clustered search results into different groups with highly readable names. Given a query and the ranked list of titles and snippets, they first extracted salient phrases as candidate cluster names with a regression model learned from human labeled training data. Then, the documents were assigned to relevant salient phrases to form candidate clusters. Wang and Zhai first learned a given query X  X  aspects from users X  query logs with the star clustering algorithm. Then they categorized and organized the search results according to the learned aspects (Wang and Zhai 2007 ).

Beeferman and Berger first built a bipartite graph with the click through data consisting of user queries and clicked URLs. Then, they applied an agglomerative clustering to the graph to group related queries and URLs (Beeferman and Berger 2000 ). Hu et al. ( 2012 ) first found two interesting phenomena from user behavior: One Subtopic Per Search and Subtopic Clarification By Keyword. The former means that if a user clicks multiple URLs in one query, then the clicked URLs tend to represent the same facet. The latter means that users often add additional keywords to expand the query in order to clarify their search intent. Based on the two phenomena, they clustered all the clicked URLs and corre-sponding queries, where each cluster represents an intent. Qian et al. ( 2013 ) first classified query intents into two types according to their variation over time line: constant and bursty. Then they regarded query logs as a constantly data stream and divided it into variable-length partitions. Finally, they clustered each partition into different groups of URLs which represent intents. Cao et al. ( 2008 ) summarized similar queries into concepts by clustering the click-through bipartite of queries and URLs recorded from query logs. Fujita et al. ( 2010 ) used a random walk approach on query-URL bipartite graph to discover facet attributes of queries. Radlinski et al. ( 2010 ) discovered intents of queries using query logs. For a given query, they first identified a set of possibly related queries, and then used the random walk similarities algorithm to find intent clusters. Sadikov et al. ( 2010 ) clustered the refinements of user queries to mine underlying user intents. They modeled user behavior as a Markov graph combining document click and session co-occurrence infor-mation. And then they performed multiple random walks on the graph to get clusters. Clustering/Classifying Query Related Terms.
 Existing work belonging to this direction considers the intent of a query as a set of candidate sub-intents, i.e. query related terms (Xue et al. 2011 ). These candidate sub-intents may come from many sources such as query suggestions from search engines, related search queries from user query logs and so on. Currently, this domain is one of the hot topics in query intent mining (Aiello et al. 2011 ).

Moreno et al. ( 2014 ) proposed an algorithm called Dual C-Means to cluster search similar queries as candidates for a given query from query logs. Then they used a click-through bipartite graph to refine these similar queries. Finally they grouped the candidates into the same clusters. Dang et al. ( 2011 ) generated reformulations which represent pos-sible intents of a query by clustering reformulated queries generated from publicly available resources as candidates, e.g., anchor text. Wang et al. ( 2013 ) suggested using surrounding text of query terms in top retrieved documents to mine intents and rank them. They first extracted text fragments containing query terms from different parts of docu-ments as candidates. Then they grouped similar candidates into clusters and generate a zooming in on individual words as possible indicators of user intent. They provided a taxonomy of intent words derived through rigorous manual analysis of large query logs.
Recently, this problem has been stressed by NTCIR, 3 which has a task for intent mining and ranking [INTENT-1 of NTCIR-9, 4 INTENT-2 of NTCIR-10, 5 IMine of NRCIR-11 (see footnote 2)]. The task consists of two phases: intent mining and ranking. Participants of the task propose many methods (Sakai et al. 2013 ). Xue et al. ( 2011 ) proposed a method which achieves the best performance in English data in terms of D#-nDCG . They first extracted candidate sub-intents from query recommendation, Wikipedia and the click through data. Then they evaluated the similarity of every two sub-intents based on the click through data. If the similarity is larger than a predefined threshold, the two sub-intents are judged to belong to the same intent. Yu and Ren ( 2013 ) presented a method which gets the best performance in Chinese data in terms of D#-nDCG . Specifically, they first classified intents into two types: role-explicit topic and role-implicit topic. For the role-explicit topics, they constructed a modifier graph based on the set of co-kernel-object strings. Then, the modifier graph was decomposed into clusters with strong intra-cluster interaction and relatively weak inter-cluster interaction. Each modifier cluster intuitively reveals a possible intent. For the role-implicit topics which generally express single information needs, they directly used the extracted sub-intents as intents. 2.2 Intent ranking Related work on intent ranking coexists with intent mining and is mainly included in INTENT/IMine task of NTCIR (see footnote 3).
 Wang et al. ranked queries X  sub-intents by optimizing both their relevance and diversity. They first estimated a relevance score for a sub-intent considering three aspects: (1) the relevance of sub-intents to the given query; (2) the importance of sub-intents, which partially reflects popularity; and (3) the readability of sub-intents. Then they ranked sub-intents by balancing relevance and diversity. They tried to achieve the goal that major sub-intents were ranked higher and top sub-intents could cover as many different intents as possible (Wang et al. 2013 ). Xue et al. ( 2011 ) extracted and ranked sub-intents at NTCIR-9 INTENT-1 Task. When sub-intents were extracted from the query recommendation of search engines, they ranked them according to the number of search engines which rec-ommend the sub-intents. When sub-intents were selected from the bipartite graph of query logs, they ranked them according to the number of common clicked URLs when user search the query and its sub-intents. Finally they re-ranked these sub-intents by their term frequencies in the clicked titles and snippets. Yu and Ren ( 2013 ) classified intents into two explicit topic, they defined a quality function of the list with top-k sub-intents which consists of three parts: popularity of topic, probability distribution of modifiers, and effectiveness of a sub-intent string expressing a sub-intent. For the ranking of sub-intents in role-implicit topics, they directly generated the ranked list through semantic similarities leveraging on lexical ontologies.

In summary, although there is a growth in researches investigating users X  intents of queries recently, there are still some issues to resolve. Firstly, most of current similarity from query logs only or from documents collections only. In addition, the combination of different similarity functions from multiple resources are usually defined heuristically. This can not precisely estimate the similarity between sub-intents because of their short text characteristics. Secondly, existing approaches consider query intent mining and ranking from a static viewpoint. They ignore the issue of intent drift that some new intents might emerge and some old intent might become unpopular. Besides, diversity and redundancy issues are not carefully studied in sub-intent ranking with respect to the coverage of the intents. 3.1 NTCIR-11 IMine task In the NTCIR-11 IMine Task (see footnote 2), participants are expected to generate a two-level hierarchy of underlying intents by analysis into the provided document collection, intents, a ranking list of all first-level intents and a separate ranking list of all second-level intents should also be returned for each query.

A list of query suggestions/completions collected from popular commercial search engines are provided as possible intent candidates, including query suggestions collected from Bing, Google, Sogou, Yahoo! and Baidu, 6 query dimensions generated by (Dou et al. 2011b ) from search engine result page, 7 related Web search queries generated by (Liu et al. 2011 ) from Sogou log data. 8 3.2 Task reformulation In this section, we reformulate the NTCIR-11 IMine task with a more general formalization.

A candidate Text Fragment can be any text fragment related to the query. Candidate sub-intent s represent the text fragments from which the intents of a query are mined. An example is shown in the upper part of Fig. 1 . Intent Hierarchy represents the tree structure of a given query X  X  intents. An two-level intent hierarchy example is shown in the lower part of Fig. 1 . The first-layer of intent hierarchy consists of Intents and the second-layer consists of Sub-intents .

Based on above terminologies, the two main tasks of our work can be formulated as follows.
 Task 1 (Query intent mining (QIM)) Given a query q associated with a set of Candidate Sub-intents ( text fragments related to q ) C X f SI 1 ; SI 2 ; ... ; SI n g , QIM task attempts to generate a two-level intent hierarchy, expressed as I q  X f I 1 ; I 2 ; ... g . Each node of the first is a Sub-intent SI i .

After QIM , each query can be interpreted as a two-level intent hierarchy. An instance of a two-level intent hierarchy is shown in Fig. 1 , which is composed of two levels: the intent level and the sub-intent level. The intents represent specific objects or events of the query, where four intents (objects) of the Chinese query  X  X  (Prophet) X  X  are listed:  X  X  (Prophets in religion) X  X ,  X  X  (The Chinese name of an actor in Dota game) X  X ,  X  X  (Prophet electronic dog) X  X  and  X  X  (Movies about prophets) X  X . Each intent can be described as a set of sub-intents. The sub-intents indicate the properties of the objects or events. For example, users may be interested in specific  X  X  X rophets in religion X  X  like  X  X  X esus Christ X  X  or  X  X  X braham X  X , or they may look for some properties of the movie  X  X  X nowing X  X  like  X  X  X ctor Nicolas Cage X  X  and  X  X  X irector Alex Proyas X  X .
In our study, it should be noted that: (1) Not all candidate sub-intents are assigned to intents (or become sub-intents), i.e., S X  belong to any two different intents, i.e., I l \ I m  X   X  for I l ; I m 2I q and l 6  X  m .
Similar to other clustering tasks, for QIM , the central problem is to design an effective similarity function to measure the similarity between each pair of candidate sub-intents. Task 2 (Query intent ranking (QIR)) Given a query q and its two-level intent hierarchy I I q and (2) all of the sub-intents S  X 
According to our definition, QIR task involves two ranking sub-tasks: rankings at the intent level and at the sub-intent level. Furthermore, ranking at the intent level should be handled firstly, as the ranking of the sub-intents depends on their intents: (1) A sub-intent could be important if its intent is important; (2) The sub-intents ranked in top positions should be diversified over intents. As discussed previously, designing an effective similarity function is the central problem in the QIM task. In this session, we measure the similarity between each pair of candidate sub-intents with consideration of three feature classes: Click Through-based Similarity, Search Result-based Similarity, and Query-based Similarity. 4.1 Click through-based similarity Many text fragments are queries issued by users, and thus their similarity can be reflected from their users X  click-through behaviors. Specially, the queries are likely to share a same intent if same URLs associated with these queries are clicked. In this study, we refer to such phenomenon as  X  X  Same-Intent-Co-Click ( SICC ) X  X  as shown in Fig. 2 . The SICC phenomenon can be interpreted as: most documents usually focus on a main topic. Thus different queries submitted by multiple users reflect the same intent if most users click on the same URL to look for a same topic.
 We experimentally validate the assumption of the SICC phenomenon based on the SogouQ dataset. 9 SogouQ is a dataset of 1-month Chinese query logs collected from the Chinese commercial search engine Sogou 10 in June 2012. It is officially offered by NTCIR INTENT-1, INTENT-2 and IMine task as a part of the Chinese dataset. Because it contains user queries that are not a part of the NTCIR-11 IMine task, we firstly filtered out 4270 queries (each query is a superset of the corresponding query of IMine) and 17232 URLs. Then, we manually labeled intents of these queries. 11 Finally, we analyzed the number of intents and the number of different queries for per URL, as shown in Fig. 3 .

Figure 3 a shows the distribution of the number of intents (vertical axis) with respect to the number of different queries (horizontal axis) that users click the same URL. We can see that there is a quite low positive correlation between them: the number of intents for one URL does not increase obviously with the growth of the number of different queries. That is, though different users use different queries when clicking a same URL, but the average number of intents for the clicked URL is less than 3. Figure 3 b shows the percentage of URLs (vertical axis) with respect to the number of different queries (horizontal axis) per URL. We can see that, for more than 92.7 % URLs, users issue less than seven different queries when clicking the same URL. Combining Fig. 3 a, b, we can conclude that, for more than 92.7 % URLs, the average number of intents behind user queries is less than 1.5, which is a strong statistical support for SICC phenomenon.

Our first similarity function is based on SICC phenomenon. Let SI i and SI j be any pair of candidate sub-intents. Let U D t SI time D t respectively. Each of them is composed of a vector of URLs that users clicked with the text fragments as queries. Thus the similarity between SI i and SI j can be measured as the similarity between U D t SI where  X  X  &gt;  X  X  is the transpose operator for a given vector or matrix, and  X  X  jjjj  X  X  is the 2-norm and SI j belong to a same intent.
 We also adopt the approach proposed by Craswell and Szummer as another similarity W First, we build the Query-URL bipartite graph and transition probability matrix. Then, we extend it by adding self-transitions to the nodes. Finally, we perform the random walk and use the convergent transition probability between SI i and SI j as the similarity. 4.2 Search result-based similarity The next three similarity functions are based on another common phenomenon that different queries associated with similar search results may imply the same intent. In this study, we refer to such phenomenon as  X  X  Same-Intent-Similar-Rank ( SISR ) X  X  as shown in Fig. 4 .
We also conducted experimental analysis on SogouQ (see footnote 9) for this phe-nomenon. First, we labeled intents of the corresponding queries in the Sogou logs and submitted them to the Google Search Engine. 12 Then for each pair of queries, we count the number of common documents among their top-N search results, where N varies from 5 to 100, as shown in Fig. 5 . From the figure we can see that queries belonging to the same intent tend to have much more common documents in the search results than those belonging to different intents.

Given a query (a candidate sub-intent), its search results generally involve two aspects: (1) the contents of retrieved documents, and (2) the ranking of retrieved documents. Correspondingly, we define three search result-based similarity functions, of which the first two similarity functions are defined based on the content of retrieved documents, and the last one is based on the ranking of the documents.

Similarity based on the contents of retrieved documents For a pair of queries (candidate constraint D t . In our experiments, we just used the snapshots of the top-N documents in the Google Search Engine (see footnote 12) instead of the full list of the documents for simplification.

Vector Space Model (VSM) and Language Model (LM) are two well-known repre-sentations of the documents. VSM regards each document as a bag of words and thus the document can be represented as a vector of word occurrences. Then, the similarity between two documents is evaluated with the Cosine metric. VSM performs well on tasks that involve measuring the similarity between words, phrases, and documents (Pantel and Lin 2002 ; Rapp 2003 ; Turney et al. 2003 ; Manning et al. 2008 ). LM recognizes each document as a sequence of words and assigns a probability to each permutation of the words. LM is also frequently used to evaluating the similarity between texts (Metzler et al. 2007 ; Erkan 2006 ; Kurland 2006 ). But different from VSM, LM evaluates the similarity of two doc-uments from the perspective of probability distributions, i.e., the similarity or distance of two documents X  language models.

From the perspective of VSM, the sets of the retrieved documents D D t i and D D t j during time D t of SI i and SI j can be represented as vectors of words W D t D and the similarity between SI i and SI j can be measured as the similarity between W D t D W D j , which can be calculated with the cosine metric:
From the perspective of LM, through considering the common documents D D t i \ D D t j , the similarity between SI i and SI j can be measured by the cross entropy between their probability distributions P  X  d j SI i  X  and P  X  d j SI j  X  .
 where P  X  d j SI  X  can be calculated with the language model (Manning et al. 2008 ).
Similarity based on the ranking of retrieved documents Given a pair of candidate sub-and let p D t i and p D t j be the rankings on their common document set D D t i \ D D t j . From the angle of the document ranking, the similarity between SI i and SI j can be measured as the similarity between p D t i and p D t j , which is generally calculated based on the Kendall X  X  s rank correlation coefficient (Kendall 1938 ; Marden 1996 )on D D t i \ D D t j .
 p i and p respectively, and N  X j D D t i \ D D t j j X  N c  X  N d is the cardinality of the common document set D p i \ p D t j  X ; or p D t i is a reverse ranking of p W  X  SI i ; SI j ; D t  X  X  1if p D t i is the same as p D t j and thus N c  X  1 2 N  X  N 1  X  and N d  X  0. 4.3 Query-based similarity We further explore more similarity functions which directly measure the similarity of two text fragments (candidate sub-intents).

Syntactic similarity Syntactic similarity describes the string match between two sub-intents. W 6 is such metric that takes exact term match and term sequence into account. where where SI p i represents the term at position p of sub-intent SI i .If SI j contains the term SI p i , Pos  X  SI j ; SI p i  X  is null, then j p p 0 j is null too.

W 7 is another syntactic similarity that computes the cosine similarity of the term vectors of the sub-intents. Different from W 6 , it ignores term sequence. where W SI is the term vector of the sub-intent SI .

Semantic similarity While the sub-intents may not have direct term overlap, they may be similar semantically. To address this, we also define some semantic similarities. Different from measuring the semantic similarity of two documents, Language Model-like metrics are not suitable for the short text characteristics. The first similarity function we defined is based on the experience that words of the same intent are more frequently co-occur than that of different intents.
 where cooccur  X  w 1 ; w 2  X  is the frequency when w 1 and w 2 co-occur in the same sentence of search result snapshots or same queries in the search logs.

The next two similarity functions are based on HowNet. 13 HowNet is a Chinese lexical database similar to WordNet. 14 A variety of semantic similarities are implemented based on information found in the lexical database. The following two similarities are adopted in this paper, of which SIM Liu  X  w m ; w n  X  and SIM Xia  X  w m ; w n  X  are based on algorithms proposed by Liu (Liu and Li 2002 ) and Xia (Xia 2007 ) respectively.
 4.4 Learning-based similarity integration Among above ten similarity functions, the first click-through-based and three search result-based functions are time-dependent, while the other functions are time-independent. D t may refer to different time granularity such as  X  X ay X ,  X  X eek X ,  X  X onth X ,  X  X ear X  or time intervals automatically segmented according to events period detection (Qian et al. 2013 ). All of the similarity functions have a same scope of values from 0 to 1. With the proposed ten similarity functions, the final similarity function can be straightforwardly obtained in a linear integration. Generally, most existing work utilized heuristic methods to design the coefficients of the functions, because they usually use less than three functions for inte-gration, which is relatively easy to decide the best values heuristically (Wen et al. 2001 ; Xue et al. 2011 ; Hu et al. 2012 ; Qian et al. 2013 ). In our study, we consider ten similarity functions, which is much more difficult to optimize coefficients heuristically.

We propose a learning-based integration method. Specially, given two candidate sub-Thus the linearly integrated similarity metric can be defined as follows: where h  X  X  # 1 ; ... ;# 10 &gt; is the coefficient vector, 0 # 1 ; ... ;# 10 1 and hold. Since 0 w m  X  SI i ; SI j ; D t  X  1 for m  X  1 ; ... ; 10, the integrated similarity 0 SIM  X  SI i ; SI j ; D t  X  1.

Let Q be the training dataset, which is comprised of a set of queries. Each query q 2 Q learning-based integration method, given a query q , we try to maximize the similarity between the sub-intents in same intents while minimize the similarity between the sub-intents in different intents. Thus the loss function can be defined as follows: where We use the Lagrange multiplier method to solve the constrained optimization problem. Let Then we can straightforwardly solve it with the gradient descent method (Calamai and More  X  1987 ). The gradient of the L  X  h ; k  X  with respect to h and k is as follows: where 1 10 is a 10-dimensional vector of which all of the elements are 1. Thus the update formula of h and k are as follows:
Note that we have another constraint # m 0 for m  X  1 ; 2 ; ... ; 10. Thus, in each itera-values of h . 4.5 Clustering algorithm With the integrated similarity function, we generate a two-level intent hierarchy for a given query with an affinity propagation(Frey and Dueck 2007 )-based clustering method. We choose this clustering approach because affinity propagation does not need to predefine the number of clusters and it recently has received tremendous attentions from different areas, including image (Wang et al. 2013 ), text (Sun and Guo 2014 ), stream (Zhang et al. 2014 ), and hierarchical (Kazantseva and Szpakowicz 2014 ) clustering tasks for its effectiveness. The intent mining algorithm is shown in Algorithm 1, where the parameter  X  0 : 5 (which is the best performance setting in our QIM experiments). Each cluster represents one intent of the query. Given a query associated with a set of intents and sub-intents, it is crucial to order them properly, so that search engines are able to adjust the search results or make query sug-gestion/expansion for fulfillment of users X  information needs. In this section, we present ranking models for the intent and sub-intent levels respectively. 5.1 Intent ranking In intent ranking, the main challenge is the intent drift problem, that the importance of the intents is time-sensitive and evolves over time. Some new intents emerge and receive great attentions while some old ones become unpopular. However, existing studies mostly focus on understanding user intents from a static viewpoint.

In this study, we construct a time-sensitive importance function s  X  I l ; q ; D t  X  : I q ! R to calculate the ranking scores of the intents for the given query q at D t .

Intent ranking objective function The importance of the intents involves two issues: cluster quality and intent relevance, as follows: relevance metric of intent I l to the query q at D t .

Clustering quality of intents Since each intent is actually a cluster of sub-intents, the quality of an intent can be measured with the metric of the clustering algorithms, i.e., the more close the sub-intents in the intent are, the higher the intent quality is. Specially, given is defined as follows: where Z Q is a normalization factor which normalizes the value of the intent quality into the scale from 0 to 1.

Temporal relevance of intents We define the temporal relevance of the intents from the perspectives of the TF-IDF model and the language model respectively.

TF-IDF model (Manning et al. 2008 ) is a standard weighting scheme for weighting the relevance of the terms in information retrieval, which is calculated as product of the term frequency and the inverse document frequency. The term frequency tf ( w , d ) of word w in document d is defined as (the logarithm of) the number of times that w occurs in d .It positively contributes to the relevance of d to w . The inverse document frequency idf ( w , D ) of word w in corpus D measures the rarity of w in D , which is defined as (the logarithm of) the inverse of the document frequency df ( w , D ), i.e., the number of docu-ments that w occurs in the corpus D .If w is rare, then the documents containing w are more relevant to w .

Given a query q and an intent I l , let W l be the set of words in I l , and D  X  q ; D t  X  be the set of the documents retrieved by q with time constraint D t . In our experiments, we just used the snapshots of the top-N documents in the Google Search Engine (see footnote 12). Thus from the perspective of the TF-IDF model, the temporal relevance of the intents r  X  q ; I l ; D t  X  can be calculated as the average TF-IDF weighting scores of the words in I l and the corpus D  X  q ; D t  X  . Formally, (Manning et al. 2008 ). 5.2 Sub-intent ranking Sub-intents represent users X  detailed information needs, such as the properties of the objects and events. Thus discovery of top-k important sub-intents is a central problem for many applications in information retrieval, e.g. query suggestion and search diversification.
Sub-intent ranking objective function Given a query q , all of its intents I q and sub-intents S X  according to their importance at D t with consideration of temporal issues and diversity issues. The objective function is defined as follows: evaluates the extent to which the ranking list p covers intent I l . Thus, the explanation for our objective (Formula 16 ) is, we try to maximize the coverage of intents in terms of their importance in top -k sub-intents ranking list p . U  X  p ; I l ; q ; D t  X  is defined as follows: P  X  SI i ; p ; I l ; q ; D t  X  is the probability that sub-intent SI i covers intent I l at D t . independence assumption of Na X   X  ve Bayes, probability that all sub-intents in p fail to cover I l . Then, 1 is the probability that at least one sub-intent in p covers intent I l .

Temporal relevance of sub-intents In Formula 18 , imp  X  SI i ; I l ; q ; D t  X  is the temporal relevance of SI i at D t , which involves two aspects: the temporal importance of SI i for its intent I l , and the relevance of SI i for the query q . Formally, evaluated using term frequency of SI i in the set of retrieved documents D  X  q ; D t  X  by q at D t . Similar to previous settings, we used the snapshots of the top-N documents in the Google Search Engine (see footnote 12). Formally, between SI i and its intent I l , i.e., the average similarity between SI i and each sub-intent in I : I .

Novelty of sub-intents nov  X  SI i ; p ; D t  X  in Formula 18 is to measure the novelty of choosing SI i into p , which is defined as the difference between SI i and the other sub-intents in p . Formally, where f is a very small positive number to make sure that the minimal value of f  X  1 E 4 .

The intuition of nov  X  SI i ; p ; D t  X  is that p should cover as many intents as possible and simultaneously not contain similar sub-intents. For example, if p already includes the sub-intent  X  X  ( X  X nowing X  starring Nicolas Cage) X  X , it should not contain the similar sub-intents like  X  X 
Optimization As shown in Theorem 1, we prove that our objective function 16 is non-negative, monotone and sub-modular.
 Theorem 1 L  X  p ; I q ; q ; D t  X  is a non-negative, monotone and sub-modular function . sub-intents related by p 1 p 2 . Let SI be a sub-intent satisfying p 2  X  p 1 [f SI g . L  X  p 2 ; I q ; q ; D t  X  L  X  p 1 ; I q ; q ; D t  X  which means L  X  p ; I q ; q ; D t  X  is monotone.
Let p 3 be any arbitrary list of sub-intents satisfying p 1 p 3 . Let SI 0 be a sub-intent not in p 3 . Denote p 1 [f SI 0 g with p 1 0 and similarly p 3 [f SI 0 g with p 3 0 .
Similarly, we can establish Note that V  X  SI i  X 2 X  0 ; 1 and p 1 p 3 , we have Q submodular. h The value of Theorem 1 reflects in two aspects. First, according to the work done by Cornuejols et al. ( 1977 ) and Nemhauser et al. ( 1978 ), if an objective function is proved to be non-negative , monotone and sub-modular (which Theorem 1 does), then we can make a conclusion that the Greedy algorithm will achieve at least a  X  1 1 e  X  approximation of the Greedy algorithm, they will not influence above conclusion. The Greedy algorithm is shown in Algorithm 2. Initially the ranking p is empty, and iteratively select a sub-intent SI i from Sn p that maximizes the Formula 16 at step i , and set its ranking position as i . Second, the practical running time of Greedy for this problem can be alleviated by CELF (Leskovec et al. 2007 ) and CELF ?? (Goyal et al. 2011 ). For details of the two algo-rithms, we refer the readers to the papers (Leskovec et al. 2007 ; Goyal et al. 2011 ). 6.1 Experimental setup Data sets To evaluate the performance of our method, we used the Chinese dataset of NTCIR-11 IMine (see footnote 2). We choose this dataset because this is the only available dataset with real query logs, to the best of our knowledge . The official dataset contains: (1) 50 Chinese queries. (2) Query logs SogouQ (see footnote 9). (3) The candidate sub-intents: Query suggestions collected from Sogou (see footnote 10), Google (see footnote 12), Yahoo!, 15 Bing 16 and Baidu; 17 Query dimensions generated by (Dou et al. 2011b ) from search engine result pages; Related queries generated by (Liu et al. 2011 ) from SogouQ (see footnote 9).

For each candidate sub-intent, we collected Google search results belonging to the time span from January 2004 to July 2013. Specially, for each month, we issued each candidate sub-intent to Google Search with the condition of time range, and collected the top 500 results in the ranking list. For example,  X  X  X dobe X  X  was submitted with the time condition  X  X 1 Jan, 2004 X 31 Jan, 2004 X  X  which can be specified in  X  X  X oogle Search Tools X  X . The number of snapshots in the document dataset used in the experiment is about 8.5 million.

Evaluation measures Average accuracy is used to measure the quality of the hierar-chical structure by whether the sub-intent is correctly assigned to the appropriate intent. relevant to the query (annotated manually), then Correct  X  I l  X  should be 0.

D#-nDCG , a frequently-used measure for ranking diversification, is used to evaluate the quality of the intent/sub-intent ranking list by judging whether all important intents/sub-intents are found and ranked correctly (Sakai and Song 2011 ).
 where q is set to 0.5 in this paper. I -rec @ k is the intent recall at top k , i.e. percentage of intents found (for intent ranking) or covered by sub-intents (for sub-intent ranking). D -nDCG @ k is computed by replacing the raw gain of nDCG with the global gain: where g r  X  I l  X  is the gain value of intent/sub-intent at position r for intent I l (ground truth).
H -measure 2 (Liu et al. 2014 ) is used to evaluate the performance of intent mining, intent ranking as well as sub-intent ranking.
 where D # -nDCG @ I is the D#-nDCG of all intents in the ranking list, similarly, D # -nDCG @ SI is the D#-nDCG of all sub-intents in the ranking list, and s is set to 0.5.
Baseline Our first baseline is TUTA 1 (Yu and Ren 2013 ), which is the best Chinese run in NTCIR-10 INTENT-2 task. We implement the approach according to their paper and apply it to the NTCIR-11 IMine dataset. In order to find out whether the proposed SICC and SISR features are actually useful, we use another baseline, namely CONTENT-BASED , which uses Cosine of the queries as the similarity and the proposed clustering approach in this paper. As for sub-intent ranking, we use IA-Select (Agrawal et al. 2009 ) and PM2 (Dang and Croft 2012 ) as baselines. We also choose the official results of IMine for comparison which includes 11 baselines (Liu et al. 2014 ). Note that our work is the first considering intent drift issue in intent and sub-intent ranking, to the best of our knowledge. However, we can not measure our study due to the lack of available data, baseline methods and evaluation measures. So we have to set D t to full time (from Jan. 2004 to Dec. 2013 in this paper) in order to compare our methods with the baseline. Additionally, we make an interesting case study with intent drift in Sect. 6.3 to demonstrate the effectiveness of our study.

Parameter setting Fivefold cross validation is adopted to train the parameters of our approach with INTENT-1 18 and INTENT-2 19 data. Cross-validation is widely used in learning approaches to choose the values of parameters (Tibshirani and Tibshirani 2009 ). First, we randomly split the data into five pieces. Then, the parameters were estimated using fivefold cross-validation. Finally, the parameters were computed as the median of the five estimations (Chapelle et al. 2002 ). The final coefficient vector h for these ten similarity equally in the experiment. 6.2 Experiment results The experiment results are shown in Tables 1 , 2 , 3 and 4 . The first three tables compare our methods with TUTA 1, and the last table compares our methods with the other baselines. OurMethod 1 represents our method with heuristical h ; OurMethod 2 represents our method with learned h .

The intent mining result in Table 1 shows that both OurMethod 1 and OurMethod 2 outperform TUTA 1, and OurMethod 2 achieves the best performance. There are three reasons for the improvement: (1) Our methods consider three feature classes: click through-based similarity, search result-based similarity, and query-based similarity, while TUTA 1 mainly utilizes query-based features. (2) Our methods define ten similarity func-tions while TUTA 1 only defines four. (3) OurMethod 2 learns h from data for the integration of the 10 similarity functions while TUTA 1 assigns the same weight to their similarity functions. Besides, because CONTENT-BASED uses the same clustering approach as OurMethod , the comparison with CONTENT-BASED indicates that the proposed SICC and SISR features are actually useful.
 The intent ranking result in terms of D#-nDCG in Table 2 indicates that both OurMethod 1 and OurMethod 2 surpass TUTA 1. This is because TUTA 1 only considers frequency of words to model the popularity of each intent, while we also consider the intent quality and the intent relevance with respect to the query. Word frequency of intents only reflects the popularity of the intent to some extent. However, a popular intent might not be accurately clustered and is not necessarily very relevant to the given query. In another word, a popular but non-relevant or not well clustered intent should not be ranked in the top results. This issue is ignored by TUTA 1.

The sub-intent ranking results are shown in Table 3 . TUTA 1 quantifies the quality of the list with the top k sub-intents R using definitions inspired by the metric D#-nDCG , i.e. where N ( R ) denotes the number of distinct clusters (intents) to which the current sub-intents R belong. N  X  R  X  = I q is used to approximate I -rec in D#-nDCG . I  X  SI i  X  is the intent that the sub-intent SI i belongs to. pop  X  I  X  SI i  X  X  is the metric used to rank intents as talked above, which is estimated using word frequency of the intent.
  X  r  X  1  X  X  aims at ranking sub-intents indicating major intents in higher positions, which is used to approximate D -nDCG in D#-nDCG .

Both our methods outperform TUTA 1 for three reasons. First, we achieve better intent mining results, which is fundamental for sub-intent ranking both in TUTA 1 and our work. Second, TUTA 1 simply defines the gain value of a sub-intent at rank r as the importance of clustering results, the sub-intents in the same cluster are not necessarily the same impor-tant. Third, redundancy is not considered in TUTA 1 which results in many redundant sub-intents. E.g., for the two sub-intents  X  X  X rophet movie X  X  and  X  X  X ovie about prophet X  X , our method will only rank one of them at the top and filter out the other one. However, TUTA 1 ranks both of them at the top. Finally, the learned h helps improve the results significantly, which confirms our arguments in Sect. 4.4 . As for the ranking, we also compare our sub-intent ranking approach with IA-Select and PM2 . The results indicate that our approach outperforms IA-Select and PM2 , which means that our proposed sub-intent ranking algo-rithm is effective.
 The comparison of our methods with NTCIR-11 IMine official results is shown in Table 4 . The bold face indicates the best performance for each evaluation measure and underline indicates the second best performance for each evaluation measure. As we can see, the performance of our intent mining approach is only a little worse than CNU-S-C and our intent ranking approach is only a little worse than FRDC-S-C and KLE-S-C . 20 How-ever, our approaches achieve the best performance in terms of H-measure with a 1.58 % improvement compared with the second best approach. 6.3 A case study of intents drift understanding
Unfortunately, no existing dataset and evaluation metrics are fit for measuring the circumstances (Berberich and Bedathur 2013 ; Hu et al. 2012 ; Jones and Diaz 2007 ). Figure 6 shows the intents evolution over a timeline of the Chinese query  X  X   X  X  mined by our approach. The vertical axis shows the relative popularity of four intents at that time computed with the Function 13 . Table 5 shows the top five sub-intents at different time units. The results in Fig. 6 are consistent with actual facts and reflect users X  intents drift. Two most popular intents  X  X  X ame X  X  and  X  X  X ovie X  X  are more popular than the other two intents over almost all the time. Before the year 2010, the movie  X  X  X nowing X  X  starring Nicolas Cage was the most popular intent. Then,  X  X  X ota Game X  X  became the most popular intent which is reasonable because  X  X  X ota X  X  became popular and many people searched the information about the  X  X  X rophet Hero (an actor in the Dota game) X  X . The results in Table 5 are satisfactory since the ranking changes with time to satisfy the evolving intents. Before the famous movie  X  X  X nowing X  X  was on in 2009,  X  X  X rophet electronic dog X  X  is ranked as the first. When the movie was popular in 2009,  X  X  X ovies about prophet X  X  is ranked as the first. After  X  X  X ota X  X  became popular,  X  X  X laying tips of Dota prophet X  X  is ranked as the first. Besides, the top results are diversified with different intents. In this paper, we have studied the problem of query intent mining and ranking. We implemented our approaches and baseline methods, and experimentally verified that sig-nificant improvements were achieved by our approach in terms of three popular evaluation metrics. We also demonstrated how our work helps understand user intents drift through an interesting case study.
There are several issues we want to further explore to enhance our current work. First, we plan to investigate the use of other similarity functions to further improve the accuracy. Second, we would like to study how to integrate the similarity functions nonlinearly. Finally, we also plan to consider more factors when ranking the intents and sub-intents to further improve the ranking results.

