 Relation extraction refers to the task of predicting semantic relations between entities expressed in text, e.g. to detect an /business/company/founders relation between the company WhatsApp and the person Jan Koum from the following text: WhatsApp Inc. was founded in 2009 by Americans Brian Acton and Jan Koum (also the CEO), both former employees of Yahoo . Most approaches to relation extraction use supervised paradigm, which achieve high precision and recall [1, 20, 22]. Unfortunately, fully supervised methods are limited by the avail-ability of training data and cannot satisfy the demands of extracting thousands of relations with explosion of Web text.
 knowledge bases exist, such as DBpedia 1 , YAGO 2 and Freebase 3 . To address the issue of lacking a large amount of labeled data, a particularly attractive approach to relation extraction is based on distant supervision [12]. The distant supervision assumes that if two entities participate in a relation of a known knowledge base, all of the sentences that mention these two entities express that relation in some way. Thus, distant supervision heuristically align the given knowledge base to free text and consider the alignment as labeled data. An example accounting for the training instances generated through distant supervision is illustrated in Figure 1. The entity pairs  X  Apple, SteveJobs  X  participate in a known Freebase relation. The relation mentions 1 and 2 are selected as training instances. In succession, we usually extract diverse lexical and syntactic features from all of the mentions and combine them into a richer feature vector [12], which subsequently fed to a classifier. This procedure is effective to get training examlpes. However, it is confronted with noise features. For instance, the mention 2 does not express the corresponding relation, but selected as an training instances as well in Figure 1. Therefore, features extracted from this mention are noisy. This analogous case is widespread in relation extraction based on distant supervision .
 ture problem mentioned above. The rationale of this method is that if sufficient training samples are available from each class, it will be possible to represent the test samples as a linear combination of just those training samples from the same class [18]. In relation extraction, given a new test feature vector, we first compute its sparse representation of all the features extracted from train-ing samples. It may not be possible to express the test instance exactly as a sparse superposition of the training samples due to the noise features. To re-duce the influence of noise feature, a noise term is adopted in the procedure of finding the sparse solution. Then, the residuals to each class are computed. Finally, we classify the test sample by assigning it to the object class that has apply this technique on relation extraction based on distant supervision . It is not at all clear that the sparse representation should have relevance to the noise features. Nevertheless, our experiments demonstrate that the sparse representa-tion can be quite effective to alleviate the noise feature problem. Moreover, our noise-tolerant approaches significantly outperform the state-of-the-art methods. works in the area of relation extraction. Section 3 gives a detailed description of relation extraction via sparse representation. The experimental results are presented in Section 4. Finally, there is a conclusion in Section 5. Relation extraction is an important topics in Natural Language Processing (NLP). Many approaches have been explored for relation extraction, such as bootstrap-ping, unsupervised relation discovery and supervised method. Researchers have proposed various features to identify the relations between two entities by using different methods.
 The Distributional Hypothesis [6] theory indicates that words occur in the same context tend to have similar meanings. Accordingly, it is assumed that the entity pairs occurring in similar context tend to have similar relations. Hasegawa et al. [7] adopted a hierarchical clustering method to cluster the contexts of entity pairs and simply selected the most frequent words in the contexts to represent the relation that held between the entities. Chen et al. [3] proposed a novel unsupervised method based on model order selection and discriminative label identification to deal with this problem.
 ti classification problem and researchers concentrate on extracting more complex features. Generally, these methods can be categorized into two types: feature-based and kernel-based. In feature-based methods, a diverse set of strategies have been exploited to convert the classification clues in structures such as sequences, parse trees into feature vectors [11, 15]. Feature-based methods suffer from the problem of selecting a suitable feature-set when converting the structured repre-sentation into feature vectors. Kernel methods provide a natural alternative to exploit rich representation of the input classification clues like syntactic parse trees, etc. Kernel methods allow the usage of a large set of features without explicitly extracting them. So far, various kernels have been proposed to solve relation extraction, such as convolution tree kernel [13], subsequence kernel [1] and dependency tree kernel [2].
 amount of labeled data for training. To address this problem, Mintz et al. [12] adopted Freebase, a large-scale knowledge base which contains billions of rela-tion instances, to distantly supervise Wikipedia corpus. The distant supervision paradigm selected the sentences that matched the facts in knowledge base as positive examples. As mentioned in section 1, this training data generating al-gorithm sometimes exposed to wrong label problem and brought noise labeled data. To address the shortcoming, Riedel et al. [14] and Hoffmann et al. [8] cast the relaxed distant supervision assumption as multi-instance learning. In addi-tion, Surdeanu et al. [16] proposed a novel approach to multi-instance multi-label learning for relation extraction, which can model all of the sentences in texts and all of the labels in knowledge bases. Takamatsu et al. [17] pointed out the re-laxed assumption would fail and proposed a novel generative model to model the heuristic labeling process in order to reduce the wrong labels. Zhang et al. [21] analyzed some critical factors in distant supervision which have great impact on the accuracy to improve the performance. These previous studies mainly pay attention to errors generated in the procedure of distant supervision . In con-trast, our work alternatively resolves the noise features and exploit the sparse representation to solve the problem. In this paper, we apply sparse representation with convex optimization for dis-tant supervision relation extraction. Sparse representations are representations that account for most or all of the information of a signal with a linear combina-tion of a small number of elementary signals called atoms [9]. Often, the atoms are chosen from an over-complete dictionary. This technology has been success-fully applied on many active research areas, such as computer vision [19] and speech signal processing [10]. Our models for relation extraction are based on the theoretic framework proposed by Wright et al. [19], which reveals that occlu-sion and corruption in face recognition can be handled uniformly and robustly within the sparse representation classification framework. In distant supervision relation extraction, the noise features are analogous to the occlusion and corrup-tion in face recognition. The feature vectors of all the train instances are selected as the dictionary and the classifier enhances the robustness to noise feature by adopting noise term in the procedure of finding the sparse solution. 3.1 Problem Statement The problem in distant supervision relation extraction is to use labeled training samples from k distinct classes to correctly determine the class to which a new test sample belongs. The distant supervision assumption is that if two entities participate in a relation, all of the sentences that mention these two entities might express that relation. To leverage the information from different mentions, the features for identical tuples from different sentences are usually combined, creating a richer feature vector [12]. Let v  X  R m denote the richer feature vector. The given n i training samples from the i th class can be represented as the set is denoted as the concatenation of the n training samples of all k classes: A = [ A 1 , A 2 ,  X  X  X  , A k ]  X  R m  X  n ( n = extraction is formulated as given matrix A to determine the class to which the richer feature vector y  X  R m of a test sample belongs.
 3.2 Sparse Linear Combination So far, a variety of statistical, generative and discriminative methods have been proposed for exploiting the structure of the matrix A for classification. One particularly simple and effective method is to consider the samples from a single class as a linear combination of the subspace. In relation extraction, we select the training examples as the subspace. Given sufficient training samples of the represented as follows: where w i,j  X  R is the weight for the j -th training sample v i,j associated with class i .
 Therefore, we select the matrix A of all the training samples as a dictionary and the test sample is further represented as a sparse linear combination of matrix A . the training samples and the entries are zero except for those associated with the i -th class.
 relation extraction is converted to get optimal w in equation (2) when given y and A . Obviously, this equation is overdetermined when m &gt; n and we can get its unique solution. In relation extraction, various syntactic and semantic features are usually exploited and the feature dimension is very high. In addition, y = Aw may not be perfectly satisfied in the presence of noise features. Thus, equation is underdetermined and the solution w is not unique. At first glance, it seems impossible to get the solution of w in this case. However, we can get the following observations: a valid test sample y can be represented using only the training samples from the same class. This representation is naturally sparse if the number of the relation classes is reasonably large. Thus, to get the optimal w , we transform the problem to find the sparsest solution to y = Aw , solving the following optimization problem: where k X k denotes the ` 0 -norm, which means to find the solution vector that has zero entries as much as possible. However, this ` 0 -minimization problem is NP-hard and difficult even to get an approximate solution. Recent work in the sparse representation prove that if the solution w is sparse enough, ` 0 -norm can be replaced by ` 1 -norm [5]. We further transform the problem to ` 1 -minimization problem: by standard linear programming methods [4]. 3.3 Dealing with Noise Features In the above section, we assumed that the test feature vectors are exactly rep-resented as a sparse linear combination of all the training feature vectors. Since the features are noisy in distant supervision , the exact representation is not reasonable and we cannot assume that Aw is known with arbitrary precision. the procedure of finding the sparse solution and the equation (2) is modified to explicitly model the noise as follows: where e  X  R m is the added noise term. There are mainly two approach to solve the feature noise in equation (5). On the one hand, e is considered as a term with bounded energy k e k 2 &lt;  X  . This model is called N oise T erm as B ounded E nergy( NTBE ). Therefore, the sparse solution w is then approximately recov-ered by solving the following convex optimization problem: Similarly, this convex optimization problem can be efficiently solved. The optimal solution subjects to the constraint that the energy of the reconstruction error of y is no bigger than  X  .
 are nonzero. This model is called N oise T erm as E rror V ector ( NTEV ). The noise features may affect any entry of the feature vector and may be arbitrarily large in magnitude. In this model, the noise features are represented as a linear combination of error basis and handled uniformly through sparse representation. Then, equation (5) is replaced as: where the matrix A and sparse weight w are respectively extended to A 0 = this method can explicitly model the location of feature corruption. The nonzero entries of e indicate corrupted dimensions of the feature vector. Apparently, equation (8) is underdetermined and does not have a unique solution for w 0 . Similarly to equation (4), we attempt to get the the sparsest solution w 0 from solving the following extended constrained ` 1 minimization problem: 3.4 Relation Classification This section introduces how to get class label of test samples based on the results of sparse representation. Given a new test sample vector y , we first compute its sparse representation  X w via equation (6) or (8). Ideally, the entries in the estimate  X w will be zero except for the entries that associated with the target class. However, the feature noise and modeling error may lead to small nonzero entries for multiple classes. To resovle this problem, it usually classifies y based on how well the coefficients associated with all of the training samples of each class reproduce  X y i . The test sample is classified according to the reconstruction error between y and its approximations.
 entries in w that are associated with class i . We can approximately reproduce y in class i as  X y i = A  X  i (  X w ). Then the classifier assign y to the class that minimizes the residual between y and  X y i . If we use NTBE to model the noise, we can predict the relation class as follows: sents the estimated noise of the test sample feature vector y and y  X   X e recovers the clean feature vector. To get the class label, we slightly modify the residual r ( y ) and compute as follows: plying a softmax operation: To evaluate the performance of our proposed approach, we conduct three sets of experiments. The first is to test NTBE with different noise term  X  , to gain some understanding of how the choice of noise term impacts upon the performance. In the second set of experiments, we make comparison of the performance among our method and other three kinds of landmark methods [12, 8, 16] using held-out evaluation. As the held-out evaluation is confronted with false negative problem, the goal of the third one is to evaluate the extracted results manually. 4.1 Dataset and Experiment Settings Dataset: We select a real world dataset 4 , NYT X 10, to evaluate our method. The dataset was developed by Riedel et al. [14] and also used by Hoffmann et al. [8]. In the dataset, Freebase was used as the distant supervision source and the New York Times (NYT) was selected as the text corpus. Four categories of Freebase relations are used, including  X  X eople X ,  X  X usiness X ,  X  X erson X  and  X  X ocation X . The NYT data contains over 1.8 million articles written and published between Jan-uary 1, 1987 and June 19, 2007. The Freebase relations were divided into two parts, one for training and one for testing. The former is aligned to the years 2005-2006 of the NYT corpus, the latter to the year 2007. As we need nega-tive examples for training, this dataset generally pick 10% of the entity pairs that appear in the same sentence but are not related according to Freebase. Moreover, three kinds of features, namely, lexical, syntactic and named entity tag features, were extracted from relation mentions. The statistics about the dataset is presented in Table 1. There are 51 relationships and an NA class. we randomly choose 1% NA training examples as the negative examples in the following experiments. Table 1 presents that the number of features exceeds feature vector and data sparsity. To control the feature sparsity degree, Surdeanu et al. [16] released the source code 5 to reproduce their experiments and use a threshold  X  to filter the features that appears less than  X  times. They set  X  = 5 in the original code by default. To guarantee the fair comparison for all of the methods, we follow their settings and adopt the same way to filter the features in our experiments. In the sparse representation-based relation extraction, the main problem is to solve the ` 1 -minimization problem. In this paper, we use SPGL1 6 to solve this problem and set the parameters as default. 4.2 The Effect of Noise Term In the NTBE model, an extra input parameter  X  is needed. This parameter determines the tolerance to the noise features. The optimal value of  X  varies with different datasets. In this part, we experimentally study the effect of the noise term  X  in our proposed method. Since there is no development dataset in NYT X 10, we tuned the noise term  X  by trying different value via five-fold cross-validation. Figure 2 illustrates the curves of F1 score for each fold.  X  = 0 means that the test feature vector are exactly represent as a sparse linear combination of all the training feature vectors. From Figure 2, we can observe a phenomenon that the performance gradually increases as the error energy  X  increases before reaching the optimum. However, it sharply decreases if we continue increasing the optimal error energy. We get the optimal results when  X  = 0 . 3. An intuitive explanation can be accounted for this phenomenon: The feature vector contains much noise when the error energy is very small and the model tends to be overfitting. Whereas the feature vector is likely to lose principal information and the model tends to be underfitting when the error energy is excessively large. 4.3 Held-out Evaluation In the held-out evaluation, half of the Freebase relations were divided for test-ing. The relation instances discovered from testing articles were automatically compared with those in Freebase. Held-out evaluation gives a rough measure of precision without requiring expensive human evaluation. To get the final perfor-mance of our proposed method, we select three approaches as competitors to be compared with our method in Figure 3. Mintz represents the baseline distant supervision model for relation extraction proposed by Mintz et al. [12]. Mul-tiR is a state-of-the-art multi instance learning system proposed by Hoffmann et al. [8]. MIML indicates the multi-instance multi-label learning system [16], of their labels. We compare these three approached with our proposed sparse representation based methods. In NTBE , the error energy is set to the optimal value  X  = 0 . 3. For MultiR and MIML , we used the authors X  implementation. We re-implemented Mintz X  X  algorithm.
 state-of-the-art over the whole precision-recall curve. NTEV achieves the best results except that the recall is between 0.12 and 0.17. The precision-recall curve of NTEV has a sharp decline when the recall is about 0.12. The reason for this phenomenon is that the number of NA testing examples is far more than the number of testing examples. By analyzing the results, we find that a large number of the NA testing examples have conditional probabilities greater than the testing examples. The precision will declines gradually while the recall rate remains unchange. Therefore, there has been a sharp decline in the precision-recall curve. The similar phenomenon can be observed in MultiR when the recall rate is about 0.03. In the held out evaluation, we compare newly discovered relation instances to the held out Freebase. As the incompleteness of Freebase, held out evaluation suffers from false negatives and the precision is underestimated. We address this problem through manual evaluation in the next section. 4.4 Manual Evaluation participating entity is not in Freebase. Since the number of the relation instances expressed in the test data is unknown, we cannot calculate recall in this case. Al-ternatively, we calculate the precision of the Top-N extracted relation instances. Table 2 presents the manually evaluated precisions for the Top-100, Top-200, Top-500, from which we can see that both of our methods outperform all of the compared methods. NTEV achieves the best performance. We also perform one-tailed t-test ( p 6 0 . 05) which demonstrates that our method significantly outperforms all of the baselines. The distant supervision assumes that every sentence that mentions two related entities in a knowledge base express the corresponding relation. The distant su-pervision assumption can fail, which results in noise feature problem and causes poor extraction performance. In this paper, we exploit sparse representation for distant supervision relation extraction. To tolerance the noise features, a noise term is adopted in our model. Two models, NTBE and NTEV , are adopted to model the noise. Experiment results demonstrate that the sparse representation is quite effective to alleviate the noise feature problem.
 This work was supported by the National Natural Science Foundation of Chi-na (No.61202329, 61272332, 61333018), CCF-Tencent Open Research Fund and the Opening Project of Beijing Key Laboratory of Internet Culture and Digital Dissemination Research(ICDD201301). We thank the anonymous reviewers for their insightful comments.

