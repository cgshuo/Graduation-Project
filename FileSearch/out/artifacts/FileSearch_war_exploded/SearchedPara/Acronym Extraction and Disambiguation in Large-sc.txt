 In this paper, we focus on the automatic extraction and disambiguation of acronyms in large-scale organizational web pages, which is important but difficult due to the diversity of acronyms and the scale of organi zational web pages. We propose two novel algorithms to address the key problems in acronym extraction and disambiguation: (1) An unsupervised ranking algorithm to automatically filter out the incorrect acronym-expansion pairs. Different from the existing approaches, our method does not require any hand-crafted rules; (2) A graph-based algorithm to disambigua te ambiguous acronyms, which leverages the hyperlinks of pages to facilitate the acronym disambiguation. We evaluate th e proposed approaches using two large-scale, real-world datasets in two different domains. Our experimental results show th at our approach is domain independent, and achieves higher precision and recall than the existing methods. H.3.3 [ Information Storage and Retrieval ]: Information Storage and Retrieval -Information filtering Algorithms, Performance Acronym extraction and disambigua tion, Pattern/Instance ranking, Graph-based disambiguation, Under-sampling Many organizations (i.e., a la rge company or university) have a large number of web pages, such as news, blogs, and electronic mail archives. Acronyms are widely used in these pages as a succinct way to refer to important concepts or named entities. However, acronyms are often cite d without explicit expansion, which cause serious difficulty fo r understanding the web pages in which they appear. To accurately understand thes e web pages, for each ambiguous acronym, we need to automatically identify its correct expansion. To achieve this goal, two tasks, acronym extraction and acronym disambiguation, are involved. The first task attempts to extract all explicit acronym-expansion pairs from a set of web pages, and is generally divided into three steps: candidate acronyms recognition, expansions extraction and the ra nking and filtering of acronym-expansion pairs. The last step is most critical and it determines the performance of the acronym extraction algorithm. Many approaches [1, 2, 3, 6] have been proposed for acronym extraction. According to the difference in the ranking strategy in the third step above, we distingui sh these approaches into two types: rule-based and supervised learning based . Rule-based approaches [1, 2, 6] attempt to rank the candidate pairs using some hand-crafted scoring rules. In supervised learning approaches [3], each hand-crafted scoring rule is encoded by a feature vector, which in turn is used to design a classifier. The classifier is trained on a manually labeled dataset and then used to determine whether an acronym-e xpansion pair should be kept. The main disadvantage of these approaches is that they require manually creating the scoring rule s, which is a time-consuming and tedious task . To overcome this drawback, we propose an unsupervised method to automatically rank and filter out the incorrect acronym-expansion pairs. Consequently, our method does not require any hand-crafted rules. A lot of studies [7] have be en reported for the second task, acronym disambiguation, and are all based on supervised classification. However, this supervised classification based approach does not work well on large-scale organizational web pages for the following two reasons: (i) The link structures of the organizational web pages are not used in this approach, but our experiments show that they are critical for acronym disambiguation. In many cases, the context of an acronym does not provide enough information for disambiguation, but the link structures do. (ii) The distribution of automatically obtained training data [7] is extremely imbalanced. This extremely skewed training data the reported works assume that the amount of training data for each expansion is approximately equal. Aiming at the special characteristics of the large-scale organizational web pages, we propose a novel graph-based acronym disambiguation approach . First, our method utilizes under-sampling [4] to balance the sk ewed training data to improve the content-based classification. Then, the prediction results are propagated in a graph to facilita te the acronym disambiguation. Similar to existing work [1, 2, 3, 6], we also apply some heuristic rules to extract candidate acronyms. Specifically, we consider a phrase as a candidate acronym if it satisfies three conditions: (1) Its length is greater than 1 and less than 11. (2) It includes at least 2 capital letters and its first char acter is alphabetic or numeric. (3) In addition to alphabetic or numeric characters, it can only include four special characters: " /", "-", "." and "&amp; ". An exception is that if a phr ase is embedded in one of the two pairs, it X  X  recognized as a candidate acronym without any constraints. In our datasets, some one-character and lower-case acronyms, such as M ( Megabyte ) and pdf ( portable document format ) are extracted by this exception. Once a candidate acronym is recognized, its associated expansion can be extracted from its context. The size (in term of the word number) of the context is the number of characters in the candidate acronym plus 5 words. In our study, each web page is processed twice to get as many acronyms as possible. First, a HTML parser is used to parse the page content and build a DOM tree. Then a page is transforme d to plain text by removing all HTML tags. Finally, the extraction results of these two passes are merged. In this paper, we leverage the algorithm in [6] to extract the candidate expansion for a given acronym from its context. We process each page twice because each of the single pass has some weakness. For the first pass, to guarantee the precision of the extraction, we limit the search scope of the context within a text node. Hence, if an acron ym and its candidate expansion locates in different text nodes of a DOM tree, this pair cannot be correctly extracted, which in turn reduces the recall of the extraction. For the second pass, the text boundary defined by HTML tags are removed after th e tags are removed, and many incorrect acronym-expansion pairs are extracted across the boundary. In this step, we attempt to extract candidate acronym-expansion pair as many as possibl e. Then, we apply the candidate acronym-expansion ranking algorithm (see next section) to filter out the incorrect ones. To filter out the incorrect pa irs, we propose a novel unsupervised method to rank all the pairs so that the incorrect pairs are ranked lower than the correct ones. This method first automatically learns and ranks the patterns that are hidden in the context of the acronym-expansion pairs, and then leverages these patterns to rank the pairs. We define a pattern as a six-tuple: ( order, prefix , e-pattern, acronym and its expansion in the context. If the expansion is before the acronym, the value of order is 1. Otherwise, it X  X  0. The middle is the characters between th e acronym and its expansion. The prefix and the suffix are the characters surrounding an acronym and its expansion. The e-pattern and a-pattern denote the pattern of an expansion and an acronym, respectively. For a given acronym, its a-pattern is generated in this way: Each alphabetic and numeric characte r is mapped to "c" and "n", respectively. For a gi ven expansion, its e-pattern is generated in a similar way: Each continuous al phabetic and numeric character sequence is mapped to "c " and "n", respectively. To simplify terminology, we use the term instance to refer to an acronym-expansion pair from now on. Intuitively, the reliability of a given pattern/instance is determined by the following three factors: (i) The association between an instance and a pattern. Pointwise Mutual Information (PMI) [5] is commonly used to measure the strength of association between two events. (ii) The authority of an instance/pattern. We measure the authority using the summation of the PageRank values of the web pages from which an instance/pattern is extracted. The intuition behind this factor is that the PageRank value is an indicator of the quality of a page, which in turn can be used to decide the quality of an instance/pattern extracted from this page. (iii) The popularity of an instance/pattern. We measure the popularity using the number of th e unique domains from which an instance/pattern is extracted. The intuition here is that if an instance/pattern appears in many different domains within an organization, it should have a high reliability. 
Combining all of the above factor s, the reliability of a pattern p (1) and formula (2): pmi(i, p) , pr(i, p) and p(i, p) are the normalized association, authority and popularity of p and i . I is the set of the instances that match instance i.
 An iterative process is involved to compute r(p) and r(i). At the beginning, each r(i) is set to 1. Then, the computation of the two formulas is repeated until the reliabilities of patterns and instances are converged. The intuition behind the formula (1) and (2) is that a reliable pattern can match many reliable instances and a reliable instance, in turn, is extracted from many re liable patterns. This algorithm is similar to the Espresso algorithm, but has two advantages: (i) Starting from a set of manually created seed instances, Espresso requires a number of rounds of iterations to find new instances. Comparatively, our algorithm only needs one round because all instances are known at the beginning of the iteration. (ii) Besides the association between an instance and a pattern, two important factors, the authority and popularity, are also taken into account in our algorithm to measure the reliability. Once each instance is assigned a score, we can use a pre-defined threshold to filter out the instances with lower score. The threshold can be determined experimentally. Aiming at the special characteristics of large-scale organizational web pages, we propose a novel two-stage graph-based acronym disambiguation approach. At the first stage, a content-based classifier is trained to predict the probability of each candidate expansion to be the correct expa nsion of an ambiguous acronym. We apply the similar idea in [7] to automatically obtain training data and train the content-based classifiers. We utilize the under-sampling strategy [4] to balance the extremely skewed training data. In this paper, we reduce the ratio between the major classes and the minor classes to approx imate 10:1 by randomly sampling the major classes. At the second stage, the predicted probabilities are propagated in the graph created for each acronym. We first create a link struct ure graph using all organizational web pages with their hyperlinks . Then, we create an acronym graph for each acronym with multiple expansions based on this graph. In an acronym graph, each node represents an occurrence of an acronym in a page. If this acronym is ambiguous, we first use a content-based classifier to predict the probability of each candidate expansion to be the correct expansion. We use a vector v to record these probabilities. For example, if a given acronym has three expansions, E 1 , E 2 and E 3 , and after content-based classification, the probability of E 1 , E 2 and E 3 is 0.5, 0.3, and 0.2, acronym is unambiguous, its expansi on is explicitly defined, e.g., E . Then, its v p is denoted as &lt; 0, 1, 0 &gt;. If two web pages contain same acronym and are connected in one or more hops in the link structure graph, an edge is created between these two acronyms in the corresponding acronym graph. We use |d| to denote the minimum hop number of the shortest paths between these two web pages in the link structure graph. Then, the weight of this edge is 1/|d|. Similar to existing studies [7], we assume one sense per discourse . Hence, the occurrence is 1 even if an acronym is present in the same page more than one time. For a given acronym, its neighbors are the acronyms that are connected to it in the acronym graph. Once an acronym graph is created, we can utilize it to propagate the content-based classification results to improve the content-based acronym disambiguation. For a given acronym i , we use the following formula to propagate its content-based prediction results v i . between i and its neighbors ( N ): Where j is a neighbor of i and its topic vector is V distance between i and j . 0  X  X  X  X  1. The motivation of our gra ph-based disambig uation method is that, in a large organization, an acronym often has the same expansion within one department of the organization. The web pages in one department are usuall y close together, so the distance among them is small. Therefore, multiple occurrences of the same acronyms within a neighborhood of the link structure graph usually have the same expansion. Two datasets, HP dataset and St anford dataset, are used in our experiments, which contain 3,168,827 and 911,053 web pages, respectively. In this section, we evaluate the performance of our acronym-expansion ranking and filtering a pproach, and compare it with three important approaches, a rule-based [1], a supervised learning based [3] and a semi-supervised learning based, Espresso [5], which are reported with better performance. To perform the evaluation and comparison, we manually create two test datasets. For HP datase t, we randomly select 200 web pages from more than 1 million web pages which contain at least one candidate acronym-expansion pa ir. A total of 427 real pairs are manually annotated in these web pages. Similarly, for the Stanford dataset, we also ra ndomly select 200 web pages from more than 130, 000 pages and get 328 real pairs. To compare our method with the supervised method [3], we first train a Multinomial Na X ve Bayes classifier using Weka ( http://www.cs.waikato.ac.nz/ml/weka/ ). Then, we use 10-fold cross-validate measure to estimate the performance of [3] using the manually labeled datasets. For the rule based method [1], semi-supervised method [5] and our method, we first utilize each method to rank the candidate pairs and sort them by their scores. Then, for the result set of each method, we repeatedly remove the pair with the lowest score, and calculate the precision, recall and F 1 on the left dataset. After that, we select the best F 1 as the best performance of the method. Table 1. Comparison between our method and baselines for Table 2. Comparison between our method and baselines for The performances of the four approaches are illustrated in Table 1 and Table 2. We can see that in both datasets, our approach has the highest recall and F 1 , and the rule-based approach [1] has the worst performance. In [1], four simple scoring rules are used to rank the candidate acronym-expansion pairs, but many complex acronym -expansion matching patterns cannot be covered by these 4 rule s, which results in the worst performance. We can also see that the supervised-based approach [3] has the highest precision in the two datase ts. In [3], 17 carefully defined rules are encoded into 17 feature vectors and used to design a classifier. These well-defined rules and the manually labeled dataset guarantee the precision of the extraction. However, its recall is lower than ours because that the 17 carefully defined rules still cannot cover all the complex matching patterns. We can also see that both Espresso and our method archive better results, this is because they propagate the reliability between the patterns and instances. After the propagation, the score of an instance is determined by the all patterns it matched. Moreover, we can see that our method outperform the Espresso method. That X  X  because that our approach takes two import factors, the authority and popularity of acronym-expansion pairs, which generates the better ranking results. For the HP dataset, we randomly select 60 acronyms from the 9,216 acronyms with multiple expansions. The web pages containing both these acronyms a nd their expansions are gathered as training data, and the web pa ges only contain these acronym are collected as the testing data. Then, we randomly select 5 testing pages for each acronym in average and obtain 300 testing pages; Similarly, for the Stanford dataset, we also randomly select 60 acronyms from the 4,780 acronyms that have multiple expansions. Finally, al l of these testing data are manually labeled. We first train a Multinomial Na X ve Bayes classifier using Weka for each acronym. Then, the trained classifiers are used to disambiguate the testing data. Finally, the classification results are propagated on the created acronym graphs. In this step, the parameters, such as  X  and |d|, are also tuned by the labeled testing data. In our experiments, we choose 0.3 and 2 as the value of  X  and |d|, respectively. After that, we first comput e the precision, recall and F each acronym. Then, we use the average value of these metrics to compare the baseline method with ours. Table 3 and 4 illustrate the experimental results. 
Table 3. Comparison between the content-based method and 
Table 4. Comparison between the content-based method and In both datasets, our graph-based approach outperforms the content-based method. That X  X  because in many cases, the surrounding context cannot give e nough cues for disambiguation, and the content-based approach cannot work well. Moreover, in a large organization, an acronym often has the same expansion within the same department. The web pages in one department are usually close together in the link structure graph, so the distance among them is small. As a resu lt, multiple occu rrences of the same acronyms within a neighborhood of the link structure graph usually have the same expansio n, which makes our graph-based method archive better results. We can also see that our graph-based method achieves more improvement on the HP dataset than the Stanford dataset. However, the performance of our method on the HP dataset is not as good as that on the Stanford dataset. We analyze the experimental results and find that acronyms are arbitrarily used in the HP dataset. In many cases , the context of an ambiguous acronym is not closely relative, which causes the content-based classification cannot work well . In many other cases, some ambiguous acronyms are part of anc hor text of a hyperlinks, and its correct expansion is defined in the pointed page. Hence, the graph-based method can improve the performance of content-based classification. Comparably, in the Stanford dataset, acronyms are cited in more formal format, and their contexts are usually related and cause better results. disambiguation approach for large-scale organizational web pages. Our main contributions include: (i) A novel unsupervised algorithm to automatically select genuine acronym-expansion pairs. (ii) A novel graph-based acronym disambiguation algorithm to facilitate the acronym disambiguation. The proposed approaches are evaluated on two large-scale, real-world datasets in two different domains, and the experimental results show that our approaches are domain indepe ndent, and could achieve higher precision and recall than existing methods. [1] E. Adar. SaRAD: A simple and robust abbreviation [2] L. S. Larkey, P. Ogilvie, M. A. Price, and B. Tamilio. [3] D. Nadeau and P. Turney. Supervised learning approach to [4] M. A. Maloof. Learning when data sets are imbalanced and [5] P. Pantel and M. Pe nnacchiotti. Espresso : leveraging generic [6] A. Schwartz, and M. Hear st. A simple algorithm for [7] H. Yu, W. Kim, V. hatziva ssiloglou, and W.J. Wilbur. A 
