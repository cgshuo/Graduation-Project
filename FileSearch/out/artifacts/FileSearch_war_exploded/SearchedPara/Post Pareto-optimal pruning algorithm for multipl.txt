 fi cant effort has been devoted to exploring Multi-Objective Evolutionary 1. Introduction Many real-life problems involve several con fl icting objectives. Such problems require multi-objective optimization. The con ing objectives means that a solution that is extreme with respect to one objective requires a compromise in another objective. A classic example of multi-objective optimization problem is the car buying problem. The solution can be expressed in terms of a trade-off between cost and comfort (a two-objective problem). The optimization goal is to fi nd a single best solution out of all of the trade-off solutions, with respect to all objectives.
Typically there is no one best solution to a multi-objective optimization problem, since all solutions involve a compromise between objectives. Instead a single solution, there is a set of trade-off solutions called non-dominated solutions (i.e., no solu-tion dominates or is better than the other solutions in the set). Non-dominated solutions are also called Pareto-optimal solutions. All solutions that are Pareto-optimal constitute the Pareto Set. The objective values of the Pareto set in the objective space constitute the Pareto frontier or Pareto front.

Multi-objective optimization problems can be solved by mathematical modeling approaches that are also effective in fi nding non-dominated solutions. However, these approaches con-sume huge computing resources and do not generate multiple solutions in single simulation run. Multi-Objective Evolutionary Algo-rithms (MOEAs) overcome this limitation. These algorithms imitate natural genetic evolution and apply optimization to a population of solutions. MOEAs can solve multi-objective problems in a reasonable time, and generate multiple solutions that can approximate the entire Pareto-optimal solution in a single run ( Barrionuevo, 2011 ). Typically, MOEAs have two primary goals: converging to the Pareto-optimal frontier and maintaining a well-spread set of solutions to obtain a good approximation of Pareto-optimal solu-tions. Most MOEAs try to generate solutions that approximate the entire Pareto-optimal solution front ( Adra and Fleming, 2011 ). However, as indicated by many researchers, this does not help much in choosing a fi nal solution. Consequently, a third goal of converging to the regions that are appealing to the decision maker (DM) has been considered recently. The literature ( Branke et al., 2001; Bechikh et al., 2011; Sindhya et al., 2011; Sinha et al., 2013; Soylu and Ulusoy, 2011 ) stresses the importance of and examines the methods for converging to the interesting portions of the Pareto front, where  X  interesting  X  is de fi ned in terms of the DM's preferences.
 In real-world applications, the DM is not interested in the whole Pareto front since often the fi nal decision is just a single solution.
The main goal of MOEAs is to assist the DM in selecting the alternative which satis fi es most or all of his/her preferences. To simplify the decision making task, the DM can incorporate his/her preferences into the search process. These preferences are used to guide the search towards the preferred parts of the Pareto front from the DM's perspective ( Xiong et al., 2012 ). These parts are called the region of interest (ROI). Several strategies have been developed to model the DM's preference information including weight preference ( Basseur et al., 2012 ), solution ranking ( Deb et al., 2010 )andsoon.
Some strategies have been developed in order to perform this in the post Pareto-optimal phase such as those presented in Kulturel-Konak et al. (2008) and Wattanapongsakorn and Leesutthipornchai (2013) . the fi nal best solution. In addition, most of the preference strategies require some level of background knowledge from the DM. Consider-ing these issues, in this paper we propose a new pruning mechanism that can fi lter out undesired solutions and provide solutions to the DM that match his or her expressed preferences.

The contributions of our research can be summarized as follows: 1. We propose a new pruning algorithm which can be used in post-Pareto optimal phase. 2. The algorithm has speci fi c bias parameters that allow the DM to prioritize each objective according to his/her preferences. 3. We offer the possibility of pruning more solutions inside and outside the region of interest, which is identi fi ed by the DM. 2. Multiple objective optimization
Real-world problems commonly require the simultaneous consideration of multiple performance measures. Most often, the multiple objectives are in con fl ict and compete with each other.
The DM has to choose an individual solution based on certain preferences or priorities for different objectives. In its general form, a multi-objective optimization problem can be formulated as follows:  X  Minimize  X  z  X  fx  X  X 
Subject to x A X where,  X  f ( x )  X  ( f 1 ( x ), ... , f i ( x ), ... , f p ( x )) T  X  x  X  ( x 1 , ... , x n ) T is decision vector.  X  X
D R n is feasible decision space.  X  z  X  f ( x ) is objective vector and Z  X  f ( X ) is solution space. n T  X  Transpose
Asolution x that satis fi es all constraints and variable bounds is a ( f 2.1. Pareto-optimality
Inmulti-objectiveproblems,theconceptof  X  dominance  X  is used to determine if one solution is better than others. A solution x is said to dominate a solution y if the following two conditions are true: least one objective. In this case y is said to be  X  dominated the concept of dominance in a two-objective minimization problem.
Since both functions are to be minimized, the following dominance relationships can be observed: solution 2 dominates solutions1, 3 and 5; solution 3 dominates only solution 5 and solution 4 dominates only solution 5. Furthermore, solutions 2 and 4 are non-dominated because there is no solution that dominates them.

Note that even if solution 2 is equal in one objective to solutions 1 and 3, it still dominates them, given the de fi nition of dominance.
The non-dominance relationship determines the concept of Pareto by any other solution. In other words, a Pareto-optimal solution cannot be improved in one objective without losing quality in another one. In the example, solutions 2 and 4 are Pareto-optimal solutions .Thesetof all solutions that are Pareto-optimal constitute the Pareto set. The objective values of the Pareto set in the objective space constitute the
Pareto front. 2.2. Multi-objective Optimization with Evolutionary Algorithms (MOEAs)
The term evolutionary algorithm (EA) stands for a class of stochastic optimization methods that simulate the process of natural evolution. The origins of EAs can be traced back to late 1950s ( Goldberg, 1989 ). Since then, many evolutionary algorithms have been developed. The EA approaches operate on a set of candidate solutions. This set is modi fi ed by the two principles of selection and variation. Selection imitates the competition for reproduction and resources among living beings. The other prin-ciple, variation, imitates the natural capability of creating new living being by means of recombination and mutation. Early attempts to use EA in multi-objective optimization problems focused on classical approaches (e.g., weighted-sum or  X  -con-strained). Soon, however, researchers started to develop novel algorithms that exploited the powerful concepts behind EA. The
Vector Evaluated Genetic Algorithm (VEGA) developed in 1984 is considered the fi rst MOEA. After VEGA, the next decisive milestone was proposed by Goldberg ( Goldberg, 1989 ) with the use of Pareto optimality as the fi tness criterion. In this approach, the population is ranked in terms of fronts (Pareto ranking). The non-dominated solutions obtain the highest rank (associated with highest The next front is given the second highest rank and so on. Recently, many MOEAs have been introduced such as: MOCell ( Nebro et al., 2009 ): a cellular based MOEA AbYSS ( Nebro et al., 2008 ): multi-objective scatter search MOPSO ( Durillo et al., 2009 ): a particle swarm based MOEA
Hybrid MOEA ( Sindhya et al, 2013 ): multi-algorithm based MOEA MOEA/D-M2M ( Liu et al., 2014 ): an aggregation based MOEA In addition, in Wang et al. (2013), the authors categorized
MOEAs based on their fi tness schemes including Pareto dominance based MOEAs, aggregation (or weight) based MOEAs, epsilon 2.2.1. Multi-objective Genetic Algorithms (MOGAs)
Goldberg's theoretical background served as the basis for several MOEAs developed in later years. Genetic algorithms (GAs) are mostly used to design MOEAs since they have been proved effectively in avoiding local optima. Most MOEAs are GA-based MOEAs. These are considered the fi rst generation of MOEAs including the Multi-objective Genetic Algorithm (MOGA), pro-posed in1993, and the Non-dominated Sorting Genetic algorithm (NSGA), proposed in1994. The Strength Pareto Evolutionary Algo-rithm (SPEA) was proposed by Zitzler et al. (1999), who started the second generation of MOEA research. A year later, revised versions of SPEA and NSGA were proposed, named SPEA-2 (Ziztler et al., 2001) and NSGA-II ( Deb et al., 2002 ) respectively. These methods have gained wide spread attention and have begun to be applied to a wide range of practical problems. The criterion de fi second generation of algorithms is the incorporation of a techni-que to preserve the best members of the obtained population in each iteration, called  X  elitism  X  . Elitism addresses the problem of losing good solutions during the optimization process due to random effects. One way to deal with this problem is to combine the previous population and their offspring, i.e., the mating pool after variation, and to apply a deterministic selection procedure. 2.2.2. Incorporation of preference articulation in MOGAs and pruning mechanisms
The incorporation of preference articulation has been developed for several reasons. This section reviews some well-known techni-ques that have been incorporated into the multi-objective opti-mization problem solving process. Much research in evolutionary multi-objective optimization att empts to approximate the complete Pareto-optimal frontier by a set of well-distributed representatives of Pareto-optimal solutions. On the other hand, in most practical applications, the DM is fi nally interested in obtaining a single solution. The role of the DM is illustrated in Fig. 2 .
Branke et al. (2001) proposed a method for utilizing the decision maker's preferences for guiding the search towards the regions of interest. The method asks the DM to specify his/her trade-offs between each pair of objectives. After that, it constructs the minimal and maximal utility functions. These utility functions are used for modifying the dominance scheme to re fl ect the decision maker's preferences. The authors also suggested the Guided Multi-Objective Evolutionary Algorithm (G-MOEA) that uses this method. They showed that their algorithm is able to converge to the desired regions are of interest to the DM.
Fig. 3 (a) shows regular dominance, while the guided dominance concept is illustrated in Fig. 3 (b). The G-MOEA can be implemented by a simple transformation of the objective functions.
 objectives and use these together with the standard dominance principle. The extended dominance can be calculated as follows: x ! y 3  X  X  f 1  X  x  X  X  m 12 f 2 x  X  X  X  r  X  f 1  X  y  X  X  m 12 f 2 In Eq. ( 2.1 ), the parameters m 12 and m 21 denote correspondingly the maximum acceptable amounts of degradation for objectives 1 and 2 which are compensated by a single unit of improvement in objectives 2 and 1, respectively.

Deb and Kumar (2007) suggested a method that seeks to fi nd a set of solutions where the DM expresses his/her preference as two points in the objective-space, the Aspiration Point (AP) and the Reservation while RP is the worst acceptable value of each objective. The search direction is guided by the AP toward RP in objective space. The result is located in the middle point on the Pareto optimal front. Heidi and Coit (2007) proposed a clustering method to prune Pareto-optimal solutions. The method sequentially combines MOEA with data clustering by a k-means algorithm, in order to create a set of desirable solutions that is smaller and more manageable. The cluster-ing approach was applied in the post-Pareto optimal phase on the redundancy allocation problem (RAP), a well-known reliability opti-mization problem. A multiple stage process was performed to identify promising solutions. The Pareto-o ptimal set was initially obtained using NSGA-II algorithm. The dec ision-making stage was then per-formed with the aid of data clustering techniques to prune the size of the Pareto-optimal set and obtain a smaller representation of the multi-objective design space.

Kulturel-Konak et al. (2008) proposed a new methodology to solve different versions of multi-objective system redundancy allocation problems with prioritized objectives. The process begins by obtaining Pareto optimal solutions using t he MTS (Multinomial Tabu Search) algorithm. The objective functions are then normalized and ranked according to decision maker's preferences. The decision maker ranks the objectives as the most important, second important and so on, and then random sets of weight assignments ( w i ) are repeatedly generated and selected.

Wattanapongsakorn and Leesutthipornchai (2013) proposed a new rationale for pruning Pareto-optimal solutions to help the DM choosing fi nal best solution without preferences from the user. Pareto-optimal solutions are fi rst generated by general-purpose MOEAs (user-preferred), then a pruning mechanism called adap-tive angle based pruning algorithm (ADA) is applied. The extended dominance is measured by calculating the angle between each pair of solutions and comparing to a delta angle which represents a maximum threshold angle as shown in Fig. 4 . The delta was calculated adaptively using a crowding estimator technique. In this approach, no preferences from the DM are needed. The contribu-tions of ADA are based on following assumptions: the DM does not prioritize multiple objective functions, and the algorithm empha-sizes the fi nal solutions that balance in all objective values.
In summary, a variety of preference-based MOEAs and pruning methods have been previously developed. Most preference-based MOEAs are modi fi ed versions of general-purpose MOEAs. Different parts of MOEAs can be modi fi ed in order to direct the search towards the preferred part(s) of the Pareto front. With regard to pruning mechanisms, the approaches are usually applied in the post Pareto-optimal phase. Existing approaches can be divided into weight allocation methods and extended dominance methods. 2.3. Performance evaluation in multi-objective optimization
To understand the strengths and weakness of an algorithm, it is important to have a strong understanding of the problem at hand. Many multi-objective test problems have been analyzed in order to draw accurate conclusions about the strengths and weakness of the algorithms tested on them. In this section, multi-objective optimization test problems and their relevant performance metrics are brie fl y reviewed. 2.3.1. Test problems
The problems that are commonly used in multi-objective optimization research can be divided into constrained and uncon-strained problems. Constrained problems come with restrictions on the value of variables in objective functions, expressed with constraint function(s). Unconstrained problems have no constraint function; only objective functions have to be considered. In fact, since variables in unconstrained problems are bounded, unconstrained problems are also sometimes known as  X  bound constrained  X 
Well-known benchmarking problems such as Schaffer, Fonseca and Flemming, and Kursawe belong to the unconstrained category, 2009 ) which are probably the most used test problems in the
MOEA literature. The ZDT set consists of six bi-objective problems, which have been designed to test the ability of a multi-objective optimization method to handle different types of the dif fi with Multi-Objective Optimization Problems(MOOPs). ZDT pro-blems have the bene fi t that they are purely synthetic and their exact solutions are known. They are also easy to implement and they test several basic properties of MOEAs. However, they have several defects, which reduce their utility. In particular, these problems have only two objectives and are not directly scalable to many objectives. 2.3.1.1. Scalable test problems. The Deb  X  Thiele  X  Laumanns (DTLZ) test problems have become popular in recent years. DTLZ are scalable to any number of objectives, although 3-objective versions are mostly used. As with the ZTD problem set, DTLZ problems are synthetic and their solutions are known. De fi for nine different DTLZ problems are given in Deb et al. (2001) .
Similar to ZDT problems, DTLZ problems address a variety of different problem characteristics. However, DTLZ problems have some limitations because all the problems are separable ( Huband et al., 2006 ). Separability implies that all nonlinear functions could be written in form of a summation of functions which depends only on one variable, while non-separable problem is characterized by parameter dependencies. Non-separable problem is more dif fi cult than separable problem and more representative to real-world problem.

The Walking Fish Group (WFG) test problem toolkit ( Huband et al., 2006 ) was proposed to increase the dif fi culty and variability of the test problems. It provides tools for test problem generation, as well as a set of nine different test problems. 2.3.2. Performance evaluation metrics
This section gives an overview of some widely used metric for evaluating MOEAs. For assessing the performance of the algorithms on the test problems, two different issues are normally taken into account: to minimize the distance from the Pareto front generated by the algorithm to the true Pareto front (convergence), and to maximize the spread of solutions (diversity). Various quality indicators have been proposed to be used in comparative studies of MOEAs Chaudhuri and Deb (2010) . They can be classi fi ed into those measuring convergence, diversity and both.
The major classi fi cations of metrics can be divided into cardinality-based metrics, distance-based metrics, and volume-based metrics. 2.3.2.1. Cardinality-based metrics. Cardinality-based metrics measure the performance of various algorithms by counting the total number of non-dominated solutions found by each algorithm ( Zitzler et al., 2003 ). Most cardinality-based metrics rely on a reference set and measure the contribution from each algorithm with respect to this reference set. The best-known cardinality-based metric is Convergence Difference of two sets. The major drawback of this metric is that it is not ef fi cient when comparing more than two algorithms. In addition, it becomes increasingly inaccurate as number of objectives increases. 2.3.2.2. Distance-based metrics. Generational Distance (GD) is a metric used widely to measure the convergence of evolutionary multi-objective algorithms. It gives an accurate measure for the convergence because GD is calculated based on the Pareto-optimal front. The GD works by calculating the average closest distances of all obtained solutions to the Pareto front. However, GD does not measure the diversity and spread of the solutions on the Pareto front, and it cannot be applied without prior knowledge of the true Pareto front. An improved version of GD known as Inverted Generational Distance (IGD) takes both diversity and convergence of solution into consideration. IGD calculates the average closest distance of sample points on the true Pareto-optimal front to the solutions obtained by MOEA. 2.3.2.3. Volume-based metrics. Hypervolume (HV) is a metric which measures the volume de fi ned by all obtained solutions and a nadir point, which is a vector of the worse objective values obtained by the solution set. Higher HV values indicate a better convergence and diversity of obtained solutions. A prominent advantage of HV is that it does not depend on the knowledge of the Pareto-optimal front. 2.3.3. Performance metrics for preference-based methods
Zitzler et al. (2008) noted that the preference information must be considered when designing performance metrics for MOEAs. For general-purpose MOEAs, if we have two solutions set A and B, solution set A can be claimed strictly better than solution set B when all aspects (e.g. convergence and diversity) are evaluated. However, for a preference-based approach, solution set A cannot be claimed to be strictly better than solution set B, because each preference-based method was introduced with a different ratio-nale. In order to evaluate the performance of a preference-based method, we must measure the aspect of performance that is most appropriate to the goals of the preference mechanism.

Branke (2008) concluded that none of the preference-based methods can be claimed to be superior to the others in every aspect. When selecting a solution method, the speci fi cfeaturesofthe problem to be solved must be taken into consideration. The opinions and abilities of the DM are important. Since our pruning algorithm is considered to be a preference-based method, we will concentrate our quality evaluation on the degr ee of convergence. Metrics that measure diversity are not really relevant for us. The Generational Distance (GD) performance metric is considered as the standard convergence metric in the multi-objective optimization research community. Hence we use the GD metric in this work. 2.3.3.1. Generational Distance (GD)
This indicator was introduced for measuring how far the elements in the set of non-dominated vectors (or solutions after pruning) are from those in the true Pareto front ( Nebro et al., 2009 ). The GD is formulated as follows: GD  X  where n is the number of vectors in the set of non-dominated (measured in objective space) between each solution found and nearest member of the true Pareto front. It is clear that a value of GD  X  0 means that all the generated elements are in the Pareto front. 3. Pareto solution pruning using extended angle dominance
A previous angle-based pruning algorithm called ADA was men-tioned in Section 2 . The idea behind ADA is a variant of the guided dominance technique proposed in Branke et al., 2001 .InADA,a A threshold angle of each objective is introduced in order to approximate the portion of desirable solutions. The pruning rationale is to increase the dominated area for the purpose of removing solutions that only marginally improve in some objectives while being the regular dominated area. The expanded area covers some discarded solutions that have marginal improvement. Only signi improved solutions are selected to be in the non-dominated set.
As explained in Section 2.2.2 (see Fig. 4 ), in multi-objective optimization problems solution A is determined to be better than solution B if and only if solution A has all objective values (i.e., f and f 2 ) less than (in minimization context) solution B. If one or more solutions exist in the shaded area, those solutions are dominated by (worse than) solution A. The shaded area is called the  X  dominated area  X  . If solution A is not in the dominated area of any solution, the solution A is called  X  non-dominated solution For the two-objective minimization context, the dominated area has boundary lines that form a right (90 1 ) angle, with each line parallel to one objective axis. The shaded area in Fig. 4 shows the dominated area for regular dominance. When there are more than two objectives, there is an analogous interpretation.

Our approach creates an extended dominated area by specifying an adjustable angle to de fi ne the dominance boundary. If the extended angle is 0 1 ,wehaveregulardominance.Asthesizeofangleis increased to be greater than 0 degrees, the dominated area expands. 3.1. ASA algorithm
This section explains our approach in detail. The process can be divided into two independent phases, a phase for determining Pareto-optimal solutions and a pruning phase. Our approach is called A ngle based with S peci fi c bias parameter pruning A lgorithm (ASA). It can be integrated with any MOEA for solution selection.
Our ASA is a further development of ADA. ADA has several limitations such as no way to incorporate user preference, com-putational expensive, treats all objective equally and etc. Our new pruning algorithm overcomes all ADA limitations. The pruning method begins by calculating the angle between a pair of solutions by using a simple geometric function that is an inverse tangent function as presented in ADA. However, we implement the thresh-old angle more simply and ef fi ciently than ADA. The angle between two non-dominated solutions is calculated using Eq. ( 3.1 ). The geometric angle is denoted by  X  n where n is the n th objective. For the minimizing objective context,  X  n is given by  X   X  tan 1 where N denotes the number of objective functions and n denotes the n th objective function.

 X  f n denotes the difference between the n th objective values of two non-dominated solutions.

For example, considering multi-objective optimization with two objective functions f 1 and f 2 , the angle of the extended dominated area for solution A is shown in Fig. 5 .  X   X  tan 1
We de fi ne the dominance condition as follows: i ! j 3  X  N
In Eq. ( 3.2 ), i ! j means solution i dominates solution j. For example, a two-objective optimization has a multi-objective criteria such that  X  i ! j  X  3  X  X  f 1 i  X  X  r f 1 j  X  X  4  X j  X  1 i ; j  X  X j r j  X  1 j X   X  f 2 i  X  X  r f 2 j  X  X  4  X j  X  2 i ; j  X  X j r j  X  2 j X  4 0  X  3 :
Solution i is better than solution j if and only if at least one of the two expressions in the disjunction above is true. The disjunc-tion indicates that the dominated solution is usually located in only one side of the extended area, that is, extension from f geometric angle or f 2 geometric angle. 3.1.1. Determination of threshold angle
Threshold angle (  X  ) is a reference angle which is compared to the calculated geometric angle between pair of solutions ( smaller than the threshold angle, solution j will be discarded, and the algorithm will keep only solution i . The process to determine the threshold angle can be elaborated as follows: 1. All non-dominated solutions are sorted in ascending order for each objective. 2. The Inter-quartile range of sorted data for each objective is calculated, denoted by IQSn . 3. The inter-quartile range of average distance of n th objective value between two consecutive non-dominated solutions is calculated, denoted by IQn.

The threshold angle (  X  n ) of each objective value can be calculated as follows:  X   X  tan 1 IQS n IQ where n is objective number. Note the incorporation of a new parameter,  X  .  X  is the bias intensity of each objective, ranging from 0.00 to 1.00 The purpose of  X  is to incorporate DM preferences into the pruning process.
 Considering the solutions in Fig. 7 , both solutions D and G are
Pareto optimal. However, neither is an attractive solution when considering alternatives that can offer improvement in one of the objective functions without sacri fi cing too much in the other. Both solutions D and G would be pruned as non-promising solutions using ASA because their geometric angles are less than the threshold angle. Alternatively, considering solution B (in compar-ison to solution C), the geometric angle is greater than the threshold angle, and the solution would not be pruned. 3.1.1.1. Speci fi c-bias intensity parameter. In multi-criteria decision making community, one of the interesting research directions is to fi nd an alternative way for the DM to incorporate his/her preferences into the optimization process. Our method allows the
DM to tune the  X  value independently for each objective as shown in Fig. 8 . We call the distinct  X  values for each objective the speci bias intensity (because they are speci fi c to a particular objective).
Fig. 7 illustrates tuning with the speci fi c-bias parameters. Because we now have multiple bias parameters, one for each objective, a new equation for the threshold angle is needed.

We introduce the speci fi c bias intensity parameter as shown in following equation:  X   X  tan 1 IQS n IQ where n is objective number and  X  n is bias intensity of each objective, ranging from 0.00 to 1.00. A stronger bias (higher value) indicates a less preferred objective. Fig. 8 shows the effect of each bias intensity parameter in controlling the size of threshold angle. Note that the experiments, we typically specify  X   X  0.50 for most preferred objec-tive(s), and  X   X  0.90 for less preferred objective(s). 3.2. Incorporating Region of Interest into MOEA and pruning ROI
In some circumstances, the DM has an explicit preferred region of interest. He/she only needs to fi lter out the Pareto-optimal solutions in speci fi c region. A reference point-based strategy is commonly used in DM's preference modeling as a goal to be achieved. The user-supplied reference points are used to guide the search towards the preferred parts of the Pareto front as shown in Fig. 9 (a). In this section, we propose a technique to incorporate user-preference to identify ROI using reference point to MOEA/D algorithm. Our new preference-based MOEA/D algorithm is called Preference-MOEA/D or PR-MOEA/D. 3.2.1. Preference-MOEA/D algorithm (PR-MOEAD)
MOEA/D algorithm is a weighted-based multi-objective optimiza-tion algorithm. An appropriate weight vector is generated to cover the entire Pareto-optimal front. Because of this property, we have an opportunity to tune its weight vector. Initially, we adopted the concept of incorporating preference articulation by using reference points as presented in Mohammadi et al. (2012) . Then we generated a smaller set of weight vectors to fi nd a number of solutions that are close to user-supplied reference point(s). This differs from the original MOEA/ D, where the set of weight vectors of the whole Pareto-optimal front is generated to approximate representative Pareto-optimal solutions. In contrast, PR-MOEA/D is a combination of reference point technique and MOEA/D algorithm.
 Pseudo code of modi fi ed-MOEA/D (PR-MOEA/D):
Input : Modi fi ed-MOEA/D algorithm Output: External Note that z is the reference point used in a weighted Tchebycheff approach. z is not the user-supplied reference point that is used for identifying preferred solution(s). Since MOEA/D is a weight-based algorithm, in particular, it is a population based plus an aggrega-tion (weight)-based algorithm. A prede fi ned weight is needed before optimization process can be started. For instance, a multi-objective optimization problem Fx  X  X  X  X  f 1 x  X  X  ; ... ; f solved by a population-based MOE Aalone.However,inMOEA/D,a prede fi ned weight vector such as weight Tchebycheff is needed in order to work together with population of solutions. In Tchebycheff approach, the scalar optimization problem can be written in the form: minimize g te x j z  X  X  X  max z  X  min f i x  X  X j x  X  X g for each i  X  1, ... , m .Thus,  X  is a prede weight vector for each Pareto optimal solution, i.e. 100 population need 100 prede fi ned weight vector (  X  i ). MOEA/D decomposes a multi-objective optimization problem into a number of scalar optimization sub-problems and optimizes them simultaneously. (e.g. 100 initial population, 100 weight vectors are needed, and 100 sub-problems are created based on Eq. ( 3.6 ). All sub-problems are optimized simultaneously in one generation). Our modi fi ed version of MOEA/D does not use a neighborhood assignment for each individual solution. We can eliminate many Euclidean distance calculations because we just need to fi nd a limited set of solutions located close to user-supplied refer ence point(s). For that reason, our Modi fi ed-MOEA/D is faster and the convergence is better than the original MOEA/D. Since this research is focused on the pruning mechanism, we leave a further study of the performance of Mod-i fi ed-MOEA/D (in terms of convergen ce speed and accuracy) for future work. First, a subset of Pareto-optimal solutions is identi supplied reference point. This is called fi rst-level pruning strategy. Then the ASA is applied to the subset of Pareto-optimal solutions obtained from the fi rst-level pruning strategy (reference point method). The process of applying ASA represents a second-level pruning strategy as presented in Fig. 9 (b). 4. Experiments This section describes in detail our experiments incorporating DM preferences via ASA into the post-Pareto decision making process. Our method fi rst prepared sets of Pareto-optimal solu-tions to be fed as input data to the pruning mechanism, using MOEA/D. Once the Pareto-optimal solutions had been approxi-mated by MOEA/D, the pruning algorithm (ASA or ASA  X  ROI) was applied. 4.1. Experiments overview
We tested the algorithm by using several test problems as follows: (1) ZDT, (2) DTLZ, and(3)WFG test suit. As discussed in Section 2.3.1 , ZDT and DTLZ are commonly used benchmark problems, while WFG introduces variance and complexity. When considering variations in the shape of Pareto fronts, they can be divided into concave, convex, discrete and continuous. We chose problems that produced all these variations. We used a typical MOEA/D algorithm for fi nding Pareto-optimal solutions. We also modi fi ed the algorithm to include the user preference identi terms of a reference point. The modi fi ed MOEA/D is called Preference-MOEA/D. MOEA/D and Preference-MOEA/D algorithms are used to observe variations in the performance of our pruning algorithm when applies to different types of Pareto-optimal sets.
We divided the example problems into three sections to demonstrate how our ASA algorithm works. Each section contains a two-objective problem and a three-objective problem. Section 4.3 discusses ASA algorithm with equal  X  values on all objectives, Section 4.4 discusses ASA algorithm with speci fi c bias parameter (
Section 4.5 discusses ASA algorithm when applying to region of interest (ROI). 4.2. Generation of Pareto-optimal solutions
This section describes the process of Pareto-optimal solutions approximation. It should be noted that this process is performed independently from the pruning algorithm in order to determine the Pareto-optimal solutions.

There are many ways to generate Pareto-optimal solutions; evolutionary algorithms are mostly used since they have been proved effectively in avoiding local optima. We prepared Pareto-optimal solutions using MOEA/D algorithm. 4.2.1. Input data and experimental setting (for Pareto-optimal solutions approximation process)
The experimental setting for each benchmark problem is as follows. 1. Populations of 300 solutions are considered for two-objective problems. 2. Populations of 500 solutions are considered for three-objective problems.

The experiment is set up as follows. (1) Approximate the Pareto-optimal solutions of selected bench-mark problems by MOEAs.

MOEA/D and PR-MOEA/D parameters:  X  Maximum evaluation  X  150,000  X  Crossover probability  X  1.0  X  Mutation probability  X  0.1  X  Scaling factor for mutation  X  0.5 (used in mutation  X  Distribution Index  X  20 (2) Apply our pruning algorithm on each Pareto-optimal set. (3) Tune bias intensity  X  i for each objective function i ,1 (4) Examine the result.

The parameter setting values were suggested based on pre-vious literature ( Zitzler et al., 2001; Deb et al., 2002; Zhang and Li, 2007; Durillo and Nebro, 2011 ).
 The experimental setting for pruning ROI:
The experiment is set up as follows: (1) Pareto-optimal solutions are approximated by PR-MOEA/D with user supplied reference point(s).
 (2) Apply the pruning algorithm with prioritizing region of (3) Specify the tuning bias intensity,  X  . (4) Examine the result. 4.2.2. Input data and experimental setting (for pruning algorithm-ASA) 300 Pareto-optimal solutions are considered for two-objective problems, and 500 Pareto-optimal solutions are considered for three-objective problems.
 Bias intensity parameter (  X  ):
Real number between 0.00 and 1.00, to control the number of pruned Pareto-optimal solutions.
 Pareto Front: For each optimization problem, 500 solutions from referenced Pareto front are considered. 4.3. Post-Pareto pruning using ASA (single bias intensity)
This experiment demonstrates ASA approach when all bias intensity values are tuned equally. We show ZDT3 for two-objective problem and DTLZ7 for three-objective problem.
ZDT3 Problem : Fig. 10 shows results for ZDT3 problem after applying MOEA/D algorithm and then our ASA pruning, with tuning parameters of 0.50, 0.85 and 0.90, respectively. After pruning, in all cases, the solutions fall into multiple knee regions (concave bulge) as expected. Higher values of tuning parameter result in stronger pruning, one knee region is pruned (removed) with tuning parameter of 0.90, shown in part (d).

DTLZ7 Problem: Fig. 11 shows result of DTLZ7 problem after applying MOEA/D algorithm and then our ASA pruning, with tuning parameters of 0.50, 0.85, and 0.95 respectively. After pruning, in all cases, the solutions fall into multiple disjoint regions as expected. The results are shown in parts (b) and (c). In part (d), two disjoint regions were almost completely eliminated. 4.4. Post-Pareto pruning using ASA with speci fi c bias intensity (different  X  values for each objective)
In this experiment, we allow the decision maker (DM) to choose his/her preferred objectives. The bias parameter  X  speci fi cally for each objective by the DM. To observe the result effectively, two different forms of benchmark problems are con-sidered in this experiment, where each problem has unique characteristics and complexity. ZDT4 and WFG2 problems are chosen for observation. We observe the results as follows: ZDT4Problem : Fig. 12 shows result for the ZDT4 problem. Part (a) shows the full Pareto front, which consists of a continuous, convex curve. Parts (b), (c) and (d) show results after applying MOEA/D algorithm and then our ASA pruning, with speci fi c tuning parameter of (  X  1  X  0.50,  X  2  X  0.99), (  X  1  X  0.99,  X  (  X   X  0.99,  X  2  X  0.99) respectively. After pruning, in all cases, it can be observed that the solutions are crowded favoring objective 1 when objective 2 has a higher bias value while objective 1 has a lower bias (lower bias results in more preferred objective) as shown in part (b). The solutions are crowded to favor objective 2 when biasing objective 1 with higher value while lowering the bias in objective 2 as shown in part (c). More solutions are pruned when a stronger bias is applied to both objectives and the solutions approach knee regions as shown in part (d).
 WFG2 Problem: For this problem, we de fi ned three objectives.
In order to observe the result effectively for speci fi c bias parameter in a three-objective problem, we divided the objective priority into two options. Option 1 gives the priority to one objective while option 2 gives the priority to two objectives (out of the three) equally as shown in Table 1 .
 Fig. 13 shows results for WFG2 problem. Part (a) shows the full
Pareto front in 3D space. Parts (b), (c), (d), (e), (g) and (h) show results after applying MOEA/D al gorithm and then our ASA pruning, with speci fi c tuning parameters of (  X  1  X  0.50,  X  2  X  0.90, (  X   X  0.90,  X  2  X  0.50,  X  3  X  0.90), (  X  1  X  0.90,  X  2  X  0.90, 0.50,  X  2  X  0.50,  X  3  X  0.90), (  X  1  X  0.50,  X  2  X  0.90,  X  3  X  0.50), ( 0.50, pruning, in option 1, it can be observed that the solutions are crowded favoring the preferred objective for each case as shown in part (d) (preferred objective  X  3).Inoption2,thesolutionsare crowded to favor both preferred objectives as shown in part (e) (preferred objectives  X  1 and 2), part (f) (preferred objectives  X  1and 3) and part (g) (preferred objectives  X  2and3).Moresolutionsare pruned when stronger tuning parameters are applied to all objec-tives, and the solutions are crowded to favor objectives 1 and 2 as shown in part (h).
 4.5. Incorporating ROI into generation of Pareto optimal solutions
In this experiment, we assume that the DM has a preferred region of interest (ROI). He/she wants to fi lter out the non-dominated solutions in speci fi c regions which are close to a user-supplied reference point. To include the user preference in term of reference point, the Preference-MOEA/D (PR-MOEA/D) is used instead of MOEA/D. ZDT1 and DTLZ4 problems are visualized for observation.

ZDT1 Problem : Fig. 14 shows results for ZDT1 problem. Part (a) shows the full Pareto front, which consists of a continuous curve.
Part (b) shows the result after applying PR-MOEA/D algorithm with a reference point of (0.2, 0.2), where solutions closest to the reference point speci fi ed by the DM are retained. Part, (c) shows the result after applying our ASA pruning, with tuning parameter of 0.99. The result still preserves diversity in the speci desired.

DTLZ4 Problem : Fig. 15 shows results for DTLZ4 problem. Part (a) shows the full Pareto front, which consists of a continuous curve, and has solutions distributed non-uniformly, such that the edge of the front holds more solutions. Part (b) shows the result after applying PR-MOEA/D algorithm with the reference point of (0.2, 0.2, 0.2). Parts (c) and (d) show results when applying our ASA pruning, with tuning parameter of 0.90 and 0.99, respectively, where the results fall into the extreme area as expected. 5. Performance evaluation
We have shown in the previous section that our algorithms have the expected effects on the fi nal set of solutions. The bias intensity parameters operate as desired, focus ing the solutions remaining after pruning toward the preferred objec tives. In this section we attempt to evaluate the quality of the solutions retained.

It is important to recognize that different preference/pruning mechanisms should be performed f or different reasons, depending on what the DM prefers. It is not always meaningful to compare the results directly between two different pruning algorithms. For example, the objective with k-means pruning is to maintain diversity while preference-based method tends to focus on the most desirable region for a particular DM. There fore, volume based performance metrics such as Hypervolume will always give better values for a k-means approach but that should not be interpreted as universally better performance. Section 2.3.2 discusses in detail how to choose appropriate performance metrics for preference-based pruning methods. The GD performan ce metric discussed in Section 2.3.2 appears to be most useful for measuring the effectiveness of our algorithm in terms of convergenc e. Most preference-based MOEAs ( Karahan and Koksalan., 2010; Bechikh et al., 2011; Mohammadi et al. 2012; Wattanapongsakorn and Leesutthipornchai., 2013 )haveused GD to measure the accuracy of their algorithms since GD considers only the convergence aspect of performance. 5.1. Result discussion Tables 2 and 3 show GD values for NSGA-II, MOEA/D and MOEA/ D  X  ASA algorithms. NSGA-II and MOEA/D are considered as baseline algorithms (general purpose MOEAs), while MOEA/D  X  ASA is a combination of MOEA/D algorithm and our ASA pruning approach. We applied our ASA pruning algorithm to the solution set that was approximated by MOEA/D instead of NSGA-II because MOEA/D provides better GD values for most test problems. Three well-known test suites are considered in our experiment including ZDT, DTLZ and WFG test problems. The bolded values represent the best GD values among the three methods
For our ASA pruning approach, we use the bias parameter of 0.85 for every test problem because we want to measure the performance of our ASA pruning in terms of maximizing conver-gence. Higher bias will result in more solutions being pruned away. We would like to show that even with the higher bias value (0.85 in this case), and thus fewer solutions, the results still provide better GD values when compared to NSGA-II and MOEA/ D baseline algorithms. Table 4 shows GD values for the two-level pruning strategy. Only one baseline algorithm is shown in Table 4 which is MOEA/D algorithm. PR-MOEA/D is considered as fi rst level-pruning method. In fact, PR-MOEA/D was designed to be a preference-based MOEA by using reference point technique. The reference point of (0.2,0.2) is used for fi rst level pruning method. Once the result from fi rst level pruning strategy was obtained, ASA pruning approach was applied to the result from fi rst level. 5.2. Statistical analysis
In this work, we are dealing with stochastic algorithms and presenting the means of multiple independent runs to get stable values. For each test problem, we carried out 10 independent runs.
Tables 2 through 4 provide the mean  X  x  X  and the standard deviation  X   X   X  of the results in each experimental condition.

We analyzed the results to determine whether apparent differ-ences in the mean GD for different conditions are statistically signi fi cant or whether they might be due to chance. The null hypothesis (H0)  X  the means are equal across conditions and the alternative hypothesis (H1)  X  means for our algorithm are lower.
First, we inspected measures of skew and kurtosis to check whether the distributions of the results are approximately normal distribu-tion. If the distribution is normal, we perform a one-dimensional
Analysis of Variance (ANOVA).Otherwise a non-parametric Kruskal
Wallis test is performed. We use a 95% con fi dence level in the statistical tests for this work ( p -value under 0.05). 5.3. Signi fi cance characterization We performed a Shapiro-Wilk's test ( Shapiro and Wilk., 1965; Razali and Wah., 2011 ), and an inspection of the skewness and kurtosis measures, standard errors ( Cramer, 1998; Cramer and Howitt, 2004; Doane and Seward, 2011 ), plus visual inspection of the histograms, normal Q  X  Q plot and boxplots of the data in Tables 2 through4 .Thesetestscon fi rmed that the data were not approximately normally distributed. Hence a non-parametric Kruskal  X  Wallis test was performed to verify the equality of means in the samples. Data in Tables 2 through 4 show statistically signi ant differences among three algorithms (NSGA-II, MOEA/D and ASA  X  MOEA/D) for all problems ( p -value under 0.05). We use the symbol  X   X   X  following Durrillo et al. (2008) and Nebro et al. (2009) in last column of Tables 2  X  4 to indicate that the differences among the mean values of the three algorithms for a given problem are statistically signi fi cant ( p -o 0.05). Thus, we reject null hypothesis (H0) and accept the alternative hypothesis (H1).

The results in Tables 2  X  4 demonstrate the quality of the solutions produced by our algorithm. We can get better GD values if  X  is smaller and pruning is more extensive. For instance, in the WFG2 ( Table 2 ) problem, the best GD value belongs to MOEA/D but if we reduce  X  in our algorithm to 0.60, then the GD is decreased to 2.38982106E-4 which is better than the other conditions. The results also indicate that even with the stronger bias (  X  is 0.85 in our experiments), our algorithm still outperforms other algorithms in terms of convergence. In summary, our pruning algorithm can effectively fi lter out less accurate solutions and keep more accurate and robust solutions.

However, as pointed out by Branke (2008) , no indicator can demonstrate the superiority of a preference/pruning method in every aspect. Each algorithm is introduced for different reasons. The preference and abilities of the DM must be taken into consideration in order to choose the appropriate preference/pruning method. 6. Conclusion
There are two primary reasons to prune Pareto-optimal solu-tions as follows: (1) to reduce the number of Pareto-optimal solutions while maintaining diversity and (2) to reduce the overall set of Pareto-optimal solutions to a subset that re fl ects preferences from the decision maker (DM). MOEAs always give general view of particular problem to the DM. However, the process of choosing the fi nal best solution for the DM is still dif fi cult, because the Pareto-optimal solutions are distributed and cover all regions of the Pareto front. The DM still needs some background knowledge of the problem in order to choose the fi nal best solution that pleases him/her at most. We propose a new algorithm to guide the DM in order to arrive at few preferred solutions. For future work, we plan to integrate our pruning algorithm with MOEAs in order to perform the ASA pruning algorithm during the course of optimization.
 Acknowledgment This work was supported by King Mongkut's University of Technology Thonburi (KMUTT), the Higher Education Research Promotion and National Research University Project of Thailand, Of fi ce of the Higher Education Commission.
 References
