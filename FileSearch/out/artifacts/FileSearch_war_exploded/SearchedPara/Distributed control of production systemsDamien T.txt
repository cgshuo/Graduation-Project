 1. Introduction
This editorial introduces the special issue of the Elsevier journal, Engineering Application of Artificial Intelligence ,on Dis-tributed control of production systems . The current technology in communication and embedded systems allows products and production resources to play a more active role in the production process. This new active capacity will generate major changes in organizations and information systems (e.g., Enterprise Resource Planning (ERP) and Manufacturing Execution Systems (MES)).
New approaches are now required for modelling, testing and assessing the features made possible by the decisional and informational capabilities of these new active entities. One among the many possibilities is to use agents and holons, since agent-and holon-based approaches assume interaction between intelli-gent entities to facilitate the emergence of a global behavior. This special issue thus focuses on the possible applications of distributed approaches for the design, evaluation and implemen-tation of new control architectures for production systems. Both fundamental and applied research papers are presented.
This editorial is structured as follows. The concepts of control and distributed control of production systems are first presented.
Then, the evolution of industrial needs is introduced, highlighting the expected advantages of distributed control systems but also presenting the challenges that are addressed in each of the papers in this special issue. The last section offers conclusions about the direction that future advances will take. 2. Control and distributed control of production systems
In this paper, the term  X  X  X ontrol X  X  includes what is generally accepted as the whole loop that allows a process or a system to be controlled, from sensors to actuators. As a result, a closed loop can then be defined as something that exists between a system that controls and a system that is controlled ( Wiener, 1948 ). In this context, Baker (1998) proposed a block-diagram model of manufacturing control ( Fig. 1 ).

Due to the difficulty of a single central factory controller to deal with production system complexity (e.g., data management complexity, uncertainty related to demand and resource avail-ability, the lag between events and relevant information proces-sing) while at the same time considering real-time constraints (i.e., reactivity), one widely used solution has been to distribute decisional capabilities to decisional entities, leading to non-centralized control systems. In this special issue, it is assumed that distribution of control means the division of a global control process based on a splitting criterion (e.g., geographical, func-tional) into several decisional sub-activities that are assigned to sub-systems, called decisional entities. These decisional entities are systems that are able to support a decision process, which is composed of a triggering activity, problem formulation, problem solving and application of the resulting decisions through the system actuators. The triggering activity can be based on an estimation of the distance between the desired goal and the state detected by sensors. Decentralized control is thus a form of distribution in which the decisional activities that are assigned can be seen as local control activities (e.g., local control of a resource).

In the early 1970s, the first kind of control distribution was fully hierarchical and based on the Computer Integrated Manu-facturing (CIM) paradigm. Splitting the global control problem into hierarchically dependent sub-problems with decreasing time ranges (i.e., strategic, tactic and operational, such as planning, scheduling and supervising) assigned to hierarchically dependent decisional entities allowed sufficient long-term optimization to be maintained (i.e., global optimality), while supporting less short-term optimization (e.g., agility, reactivity). This approach has led to the well-known Manufacturing Resources Planning (MRP2) and more recently, to Enterprise Resource Planning.

This traditional CIM-based approach is known to provide near-optimal solutions when some hard assumptions are met, for example, the long-term availability and reliability of the supply and demand, the optimal behavior and high reliability of production systems, low product diversity, and the observability and controllability of all the possible internal variables. One of the theoretical foundations for this traditional approach was pub-lished by Mesarovic  X  et al. (1980) . The term  X  X  X istributed X  X  is sometimes used in this context, not explicitly to refer to the distribution of control but rather to the distribution of resources, for example, to describe company sites that are not located at the same place. The papers by Jiao et al. (2009) , and by Chung et al. (2009) address this topic. Jiao et al. (2009) focus on the coordination mechanisms within the supply chain of a multi-national company. The control architecture is fully hierarchical, which means that there is no heterarchical relationship among decisional entities that must be coordinated, despite the fact that this control architecture is applied to a supply chain, which can be seen as a set of physically distributed resources. The authors formulate the product, process and supply chain coordination as a factory loading allocation problem using a constraint satisfaction approach. A decision propagation structure is extended from the constraint heuristic search to facilitate solution space exploration.
In such a model, the search for static optimality is feasible if a global criterion can be expressed. Chung et al. (2009) propose a supervisory genetic algorithm approach to deal with distributed production scheduling that takes maintenance tasks into account.
The aim of their approach is to minimize the makespan of the jobs. They analyze the influence of the relationship between the maintenance repair time and machine age on the performance of maintenance scheduling.

Since the 1990s, other kinds of distribution, especially based upon the distribution of control decision have also been considered. These approaches were adopted due to the emerging need for local reactivity. The main argument was that, in hierarchical control, the time spent to inform the correct controller within the hierarchy (bottom-up), and then to decide and to apply the decision (top-down) generates lags and instabilities. The idea was to permit the decisional entities to work together so as to react quickly instead of requesting control decisions from upper decisional levels, which was generating response time lags. In this new approach to distribution, interaction processes other than coordination appear, mainly, negotiation and cooperation ( Mar  X   X   X  k and Lazansky, 2007 ). How-ever, negotiation and cooperation led to new problems, for example, the need to prove deadlock avoidance mechanisms and more generally, the need to prove that sufficient level of performance can be attained.

In the first studies of this approach to distribution, upper-level decisional control was forbidden. In fact, the relationship among such cooperating decisional entities can been qualified as  X  X  X ully heterarchical X  X . Heterarchy can be formalized using graph theory.
A directed graph composed of nodes representing decisional entities and arcs representing the master X  X lave interaction of a decisional entity (master) with another entity (slave) is called  X  X  X nfluence graph X  X . If each node can be considered as both a master and a slave, no hierarchy can be identified, and thus the graph is considered to be strongly connected. This strong connection defines a heterarchy. This formalization is consistent with the initial heterarchy concept developed by McCulloch (1945) . Fig. 2 illustrates the difference between hierarchy and heterarchy.
Graphically, hierarchy can be seen as a kind of  X  X  X ertical X  X  distribution of control, while heterarchy is a kind of  X  X  X orizontal X  X  distribution of control.

In fully heterarchical control systems (one-level heterarchy, as shown in Fig. 2 ), long-term optimization is hard to obtain and to verify due to the difficulty of proving that a sufficient level of performance can be attained, while short-term optimization is easy to achieve. Multi-agent systems have been widely used to model such fully heterarchical control systems. Since the end of 1990s, a new paradigm has emerged: the holonic paradigm. The desire to integrate both hierarchical and heterarchical mechan-isms into a distributed control system can be seen as an essential feature of the holonic paradigm, allowing users to benefit from the advantages of both approaches. Of course, it does not negate the pertinent drawbacks.

Fig. 3 summarizes the different ways to distribute control decisions from centralized control systems to design non-centralized control systems based upon two fundamental design choices: the choice of using hierarchical relationships and the choice of using heterarchical relationships. Given the different ways of distributing control decisions, it is possible to construct an architecture typology that is inspired by Dilts et al. (1991) .
Indeed, the desire to use hierarchical relationships when designing a control architecture led to Class I control architectures, and the desire to use heterarchical relationships led to Class III control architectures. Class II control architectures, being semi-heterarchical, fall somewhere in the middle, integrating both hierarchical or heterarchical relationships. A control architecture is Class II if its whole influence graph is not strongly connected (not a Class III) while at least one sub-graph is strongly connected (not a Class I). A typical Class II control architecture is a Class III control system with a supervisory level.
This special issue focuses on distributed systems that contain heterarchical relationships, with or without hierarchical ones.
With exception of Jiao et al. X  X  (2009) and Chung et al. X  X  (2009) , which deal with a Class I control system, the different control systems proposed range from fully heterarchical to semi-heter-archical (Classes II and III). For reasons of simplicity, in the rest of this paper, the control systems proposed are called  X  X  X istributed X  X .
This is obviously a restriction of the definition proposed in the beginning of this paper, since the vertical distribution is also
Market information materials possible, though it would lead to a Class I control system.
According to Bousbia and Trentesaux (2002), control architectures supporting heterarchy mainly use three kinds of modelling approaches: bionic and bio-inspired, as proposed by Okino (1993), Ueda et al. (2001) or Sallez et al. (2009); multi-agent, as proposed by Maione and Naso (2003); and holonic, as proposed by
Van Brussel et al. (1998) . In this special issue, primarily multi-agent and holonic architectures are considered. 3. Evolution of industrial requirements
The evolution of industrial requirements towards more heterarchy has mainly been caused by industry X  X  need to move from static optimization to dynamic optimization and agility (Gunasekaran, 1999 ) and to be more reactive to environmental changes (e.g., reduced product life cycle, unpredictable customer behavior). A recent study highlighted that, for European factory equipment suppliers, the priority among 10 major concerns was the need for  X  X  X ntelligent products X  X , including self-optimizing systems ( Schreiber (2007) cited in Sauer (2008)). Industrial requirements have evolved from the usual traditional perfor-mance criteria, described in terms of static optimality or near optimality, towards new performance criteria, described in terms of reactivity, adaptability and robustness. A growing number of industrialists now want control systems that provide satisfactory, adaptable and robust solutions rather than optimal solutions that require meeting several hard assumptions. Of course, this is not true for all industries. However, there is one common denomi-nator that holds true for those that are concerned with high tech and mass customization, including the automotive, computer, phone and communication systems industries. They all want satisfactory, adaptable and robust solutions, which distributed control approaches can help to provide.
 HETERARCHY HIERARCHY Low Class I Fully hierarchical control system 
Several papers in this special issue point out the advantage of distributed control to support agility. Agility is becoming one of the key objectives that justifies designing heterarchical relation-ships among decisional entities. This does not mean that hierarchical relations disappear; they are just complementary to the heterarchical relationships. Heterarchy does, however, gen-erate new problems, some of which are addressed in this special issue. According to Gunasekaran (1999) ,  X  X  X gility can be defined as the capability of surviving and prospering in a competitive environment of continuous and unpredictable change by reacting quickly and effectively to changing markets, driven by customer-designed products and services X  X .

In production and manufacturing, there are two types of agility: business agility and technical agility. Business agility focuses on adapting the whole set of production means to evolving financial and economic target objectives and mainly involves the strategic level: networked enterprises, virtual enterprises or supply chains, for example ( Cagliano et al., 2004 ).
Technical agility, on the other hand, can be described in terms of efficiency and effectiveness ( Bousbia et al., 2005 ).
Efficiency involves making sure the means are used suffi-ciently, given the obtained results. The efficiency dimension of agility concerns:
Supporting product diversity, batch size reduction and mass customization ( Yang and Li, 2002 ).

Adapting systems to new technologies (e.g., resource up-grades).

Modifying production systems to deal with new product versions and shortening product life cycles, which leads to redesigning production resources to meet evolving customer needs.

Production costs and resource use optimization are some of the key parameters (e.g., activity costing and inventory level mea-surements). For example, adaptive dimensioning of production lines (e.g., line balancing) is relevant to the efficiency dimension of agility. It is widely studied both in the scientific community and in industry, especially the automotive industry, with the  X  X  X ean manufacturing X  X  concept and its associated methods, such as the Value Stream Mapping and the Demand Flow Technology s .
Effectiveness involves making sure that the results obtained match the target objectives for a given set of means. The effectiveness dimension of agility concerns: new production methods (e.g., the concept of just-in-time, the
Kaizen/continuous improvement strategy and the associated methods: Kanban control, overall equipment effectiveness, quick response quality control. the robustness, re-configurability, maintainability, proactivity and reactivity in the face of scheduling or planning perturba-tions (e.g., modification, insertion or cancellation of orders, supply delays or errors, batch quality control warnings, breakdowns).

This effectiveness dimension of technical agility is widely studied in both the industrial and scientific communities ( Leita  X  o and Restivo, 2008 ).

Ideally, a firm should of course develop tools and methods that will simultaneously support both business and technical agility, in all their dimensions. The link between technical and business agilities is crucial since the relevant models, assumptions and approaches are usually very different in the technical and business worlds, which makes interoperability hard to achieve (Morel et al., 2007 ). In addition, the different dimensions of agility are not really compatible. For example, JIT production methods seeking effectiveness lead to a reduced resource use rate, implying reduced efficiency ( X  X  X t is sometimes important not to produce X  X ).
This incompatibility is a challenge when trying to simultaneously manage both dimensions of technical agility.

In general, the concept of agility should be extended to integrate the life cycle of production systems more extensively.
In the context of product life cycle management, this is linked to the whole product and process life cycles. The manufacturing phase is not the only phase that may potentially be concerned with distribution of control. For example, distributed cooperation between the product design system and the manufacturing system could possibly improve the feasibility of designed products and shorten the time needed to adapt the product manufacturing processes to the evolving product specifications. 4. Distributed control systems and agility
As mentioned above, heterarchical distribution of control (Class II and III control systems) is one way to make systems more agile. Moving decisions closer to the point where they will be applied should shorten reaction delays, thus reducing long-term instability (e.g., bullwhip effect in supply chains), make it easier to manage re-initialisation and reconfiguration procedures after shut downs or breakdowns (effectiveness dimension of technical agility), leading for example to plug-and-play systems ( Mar  X   X   X  k et al., 2005 ), increase product traceability and allow products to be more active throughout their entire life cycle, especially during the manufacturing phase, but also in distribution/logistics, inven-tory and future generation product design (effectiveness dimension of technical agility), allow the control system to evolve more easily according to unexpected changes in the external or internal environment, which would increase the return on long-term investments over the ones generated by more centralized architectures (efficiency dimension of technical agility) and facilitate supply chain collaboration mechanisms, as well as collaboration in virtual and networked enterprises or compa-nies (business agility). This would also be true in domains other than production, for example, in services, especially in hospitals, where several hierarchies (e.g., clinical, adminis-trative, technical) may co-exist and co-operate without any central supervision.
 But these improvements have not really been proven, with the exception of some rare and well-known industrial validations, such as the one published by Bussmann and Schild (2001) . (The interested reader can also consult Mar  X   X   X  k and Lazansky (2007) .)
Still, some distributed control systems have been completely implemented on small manufacturing systems, as two of the papers in this special issue illustrate. First, Covanich and
McFarlane (2009) compare the ease of reconfiguration of holonic vs. conventional manufacturing control systems by evaluating the effort required to introduce a new machine into these two control systems. Based on a real case study, their article shows that the holonic approach with a conventional hardware may offer little advantage over the conventional approach, while the holonic approach with an  X  X  X deal X  X  hardware appears to have significant advantage over the conventional approach. The second study is proposed by Borangiu et al. (2009), who studied the implementa-tion of a complete holonic control system designed to control an assembly cell.

However, despite their advantages, distributed control archi-tectures have several drawbacks, which limit their application in real industrial cases ( Mar  X   X   X  k and Lazansky, 2007 ). The challenge is to manage these drawbacks. The issues raised by these drawbacks are addressed in the following section. 5. Challenges for designing distributed control systems
The following issues prevent the concept of distributed control from being sufficiently mature to be accepted by industrials, even though the expected advantages from increased agility are the ones they want for their systems. While these issues remain, no industrial manager will deploy distributed control systems, or even spend time and money to test, compare and verify the behavior of such systems, as emphases the paper of Leita  X  o (2009) .
The minimal level of trust that the future user, the production manager, may have in the concept of distributed control is an additional problem for the use of such systems. 5.1. Guaranteed near-optimal or satisfactory performances
The challenge of performance guarantees is widely addressed in the literature, as well as in this special issue. This challenge not only involves proving efficiency or effectiveness or finding a satisfying compromise between the two, but also involves proving other major properties, such as safety, fault-tolerance and dead-lock avoidance ( Bongaerts et al., 2000 ; Duffie and Prabhu, 1996 ; Cantamessa, 1997 ).

The dynamic behavior of loosely linked autonomous decisional entities, such as those found in holonic and multi-agent systems, makes it hard to obtain performance guarantees. This difficulty is mainly due to the  X  X  X yopic behavior X  X  of distributed control systems. In fact, this myopic behavior is one of the major obstacles to using such systems. The analogy with myopia is justified since this condition causes lack of visual acuity and can be extended to the lack of discernment and long-range perspec-tives in such activities as thinking or planning. Distributed control myopia is related to the uncertainty of knowledge about the future states of both the control system and the controlled system, uncertainty that increases rapidly over time.

Of course, such  X  X  X yopic X  X  behavior can be seen as systematic in all types of control when the environment is stochastic and can be extended to another kind of myopia,  X  X  X patial myopia X  X , when considering local decision criteria instead of more global ones, such as in scheduling. The paper of Leita  X  o emphasizes the fact that this is particularly true for distributed control systems, even when the environment remains fully deterministic. Indeed, in such systems, the decisional entities are often loosely linked, which is not the case in centralized or hierarchized architectures.
Several promising research areas can be identified in the context of myopic behavior. One solution would be to use pro-active simulations in real-time environment to ensure the best short-term decisions, as illustrated by Cardin and Castagna (2009) . To manage the myopic behavior, the authors address the observability of the system state using a holonic PROSA-oriented approach. Since decisions and information are distributed among the holons, it is hard to evaluate the global state of the system.
But, without knowing this global state, it is impossible to extrapolate the system behavior in the near future. Their approach consists of enhancing the staff holon with on-line simulation capabilities to create a comprehensive system observer. Myopic behavior management is then facilitated by allowing possible future simulation studies (e.g., what-if? scenarii) based on reliable information about the real state of the system. A similar approach is also proposed in the paper proposed by Pujo et al. (2009) .
In order to maintain a certain performance level, it is frequently necessary to deal with myopic behavior by defining a kind of  X  X  X lobal optimizing mechanism X  X  (GOM) ( Sallez et al., 2009 ), without which performances are often very poor. There are several ways to integrate GOM into distributed control systems. One common solution is to ensure that local decisions are made in consideration of global criteria; another is to impose global constraints within which decisions must be made, thus guaran-teeing a minimal global performance level. Each distributed control study must provide a GOM to provide satisfactory performances. A number of papers in this special issue deal with the issue of how to provide satisfying performances. They are presented below, as well as the GOM used.

M. Wang et al. (2009) address the integration of both the effectiveness and efficiency dimensions of technical agility, proposing a multi-agent model able to work from the strategic level dynamic supply chain generation) to the operational level (dynamic production process), despite perturbations. In their multi-agent model, agents negotiate by refinement, using con-straint propagation to find the most efficient and effective supply chain configuration that will satisfy customer requirements. The GOM is then managed by searching for a guarantee at a higher level (i.e., the strategic level) than operational solutions that satisfy the customer requirements.

Seilonen et al. (2009) propose a multi-agent system based upon the belief X  X esire X  X ntention model dedicated to the initial control of continuous processes, including both continuous and discrete control operations. In such processes, safety and reliability are hard constraints to fulfill. Their paper focuses specifically on agent negotiation to coordinate (re)configuration after a failure and addresses the effectiveness dimension of technical agility. The GOM is implemented through agent cooperation and considers local configurations to manage local faults, which facilitates the global remediation of these faults.
Lim et al. (2009) propose a multi-agent system that exploits the effectiveness dimension of technical agility, with a particular focus on the responsiveness of production schedules that encounter perturbations. Their idea is to use an iterative bidding procedure, driven by a simulated annealing (SA) optimization mechanism, until total production costs are minimized. The GOM is then supported by the SA algorithms.

Sabar et al. (2009) propose a multi-agent approach to personnel scheduling problems, which they apply in the context of a paced multi-product assembly center. The aim is to generate daily assignments of employees to workstations according to activity requirements, taking into account the human factors (e.g., competencies, mobility and preferences) for each employee, in order to provide efficient personnel scheduling. The idea is to define coalitions in which agents tend to reach equilibrium, by seeking for more and more satisfying activities through coopera-tion. The effectiveness dimension of technical agility is addressed in this approach. Experimental results show that this multi-agent approach produces high-quality, effective solutions in short computational times, potentially leading to a real-time use of this distributed control system. The GOM is managed through the search for equilibrium in coalition formation process, which means that when the equilibrium is reached, the near optima are also reached.

Pujo et al. (2009) propose a flat holonic system, whose objective is to increase FMS reactivity and productivity. Reactivity is insured through decentralized task generation. The idea is to enhance the classic PROSA reference architecture ( Van Brussel et al., 1998 ) with a Simulation Holon to identify and evaluate the prospects for production system evolution over time. (This approach is similar to the one proposed by Cardin and Castagna, 2009 ). The reactive behavior of the control of a flexible turning cell is highlighted. This paper addresses the effectiveness dimen-sion of technical agility; the GOM is supported by a contract-net protocol and on-line simulations are used to determine the best decision.

Borangiu et al. (2009) propose a Class II holonic control architecture and deal with the subsequent implementation issues.
They apply their architecture to an assembly job shop with networked intelligent robots, which make decisions based on dynamic simulations of material processing and transportation.
Their completely deployed holonic control structure produced significant experimental results. The dimension of technical agility addressed is the effectiveness dimension. Like in the article by Pujo et al. (2009), the GOM is supported by a contract-net protocol.

Many works are related to problems in production scheduling, which is one of the most often addressed subjects in the literature.
However, other kinds of scheduling problems may arise. One increasingly important industrial concern is the need to integrate maintenance tasks into the production schedule, as Chung et al. (2009) have proposed. The following papers focus on this concern.
Aissani et al. (2009) propose a multi-agent approach for dynamic maintenance task scheduling and apply it to a petroleum industry production system. Their approach allows agents to simultaneously insure effective maintenance scheduling and continuous improvement of the solution quality by means of reinforcement learning. Their experiments have shown that their approach cannot only generate satisfactory scheduling solutions for predictive and corrective maintenance tasks on-line but can also improve solution quality. This paper clearly addresses the effectiveness dimension of technical agility. The GOM is managed through contract-net negotiation and the continuous improve-ment mechanisms due to reinforcement learning.

The last paper dealing with satisfactory performance levels in this special issue is by Tamani et al. (2009), who propose an intelligent distributed supervised control approach for high volume production systems in which the parts flow can be approximated by a continuous fluid model. The distributed local controller is synthesized by using Takagi X  X ugeno fuzzy systems.
At a higher level, a supervisory controller (i.e., the GOM) works to improve the overall system performance.

Table 1 summarizes the features presented in all these papers. 5.2. Design methodology and engineering in distributed control system
Even if the model performances are proved and are character-ized according to several parameters, there remains the issue of the design methodology and the engineering of the distributed control system, given the specifications of the end user (e.g., a production site manager). This issue can be summarized as follows:  X  X  X rom the local behaviors of single decision-making unit, a global behavior of the system [must] emerge coherently with requested characteristics (e.g., reactivity) X  X  ( Cavalieri et al., 2000 ).
In this special issue, Hsieh (2009) makes an original contribu-tion to the domain of design methodology for distributed control systems using formal properties of holarchies. The author proposes a generic method to facilitate the design of appropriate dynamic HMS holarchies, which takes time constraints and costs into account. Both the effectiveness and efficiency dimensions of technical agility are addressed. The author uses the contract-net protocol and Petri nets to model the time constraints. The conditions needed for the holarchy to support these constraints are formalized, allowing an optimized dynamic holarchy to be designed under these conditions.

L. Wang et al. (2009) propose a framework for distributed process planning using function blocks. The proposed methods integrate dynamic scheduling functions into a distributed envir-onment. The idea is to use function blocks to handle dynamic changes while generating and executing the process plan. The authors propose a function block designer that is able to encapsulate generic process plans in function blocks for runtime execution. These function blocks are able to identify environ-mental changes; thus the process plan can be adapted dynami-cally. This paper also illustrates the interoperability of a distributed production control with product specification man-agement tools and CAD systems.

Currently, no global design methodology exists; only a few specific and encouraging contributions, like the two mentioned above, can be identified. A necessary condition for the appearance of a global design methodology might be the development of  X  X  X mergence engineering X  X . This type of engineering deals with how to control emergent phenomena to make systems evolve in the desired way. This concept of emergence engineering presents a new challenge for researchers working on deployment methods for distributed production control. 5.3. Interoperability and deployment norms
To support the future deployment of a distributed control system, interoperability and norms are required. Currently, studies about the interoperability of distributed control systems with existing organizational and information systems (e.g., ERP,
MES and design tools) are lacking. Indeed, most of these software tools assume total decisional control of production control sy stems, which is inappropriate when considering, for example, a distributed control system in which the entities make decisions through negotiation. All the development specifications for such major software tools, as well as for subsequent software development, must be revised to support interoperability with distributed control systems to make these software tools able to benefit from the advantages of heterarchical architectures.
To meet this challenge, norms for distributed systems should be, of course, designed and used. Too few are currently available, for example: the International Standard IEC61499 for Distributed
Systems; the Foundation for Intelligent Physical Agents FIPA, and the IEEE Computer Society standards organization that promotes agent-based technology and the interoperability of its standards with other technologies. But these few examples are insufficient to support the whole process, from designing distributed control architectures to their deployment and interoperable use with other well-established industrial software. The STEP-NC and ISO (ISO 14649-1) standards are also potentially useful. For example,
Seilonen et al. (2009) use the FIPA standard to facilitate the deployment of their design method. 5.4. Development, scalability and costs
The issues of development, scalability and costs are involved in the development and the real deployment of a model based on engineering considerations. Leita  X  o presents in his paper a state of the art in intelligent distributed manufacturing control systems using emerging paradigms, such as multi-agent and holonic manufacturing systems. The paper proposes a complete survey of the applications of agent-based manufacturing control systems, including the real implementations in industry. Assuming for the moment the existence of a design methodology, Leita  X  o highlights the issue of scalability in prototype development for real industrial cases. Indeed, most research developments stop at the prototype phase; there are rare real implementations on small test beds, but no large-scale real-world implementations. Since no information is available (i.e., no lessons learnt process), it is hard to prove the real agility of a distributed control system. Mean-while, some efforts are currently being made in, as highlighted by the papers of Borangiu et al. (2009) and Covanich and McFarlane (2009) . For example, there is a growing number of application-oriented publications, especially in the context of  X  X  X ntelligent X  X  products and resources; see for example, Mar  X   X   X  k and Lazansky (2007) , Zaeh and Ostgathe (2008), Pannequin et al., (2009) and Sallez et al. (2009).

Indeed, it is important to note that the current technological possibilities (e.g., embedded infotronics, distributed controllers, mechatronics, intelligent actuators, RFID and auto-ID technolo-gies) now allow the definition of  X  X  X mbient intelligence X  X  environ-ments where a growing amount of information can be embedded, thus increasing the decision-making capability of static and/or mobile entities, either products or resources. Deployment costs should thus be drastically reduced, and the design of methodol-ogies for deployment facilitated. 5.5. The final challenge: human factors, manager trust and investment returns
This last challenge is a kind of  X  X  X uest for the Holy Grail X  X . In centralized or hierarchical control, trust in the system is naturally high, since these approaches are well established and frequently used. This is not the case for distributed approaches, in which the complexity of the interactions is hard to understand, support and manage. Trust in such systems is thus drastically reduced.
Managers will not trust a system if they do not have a global understanding of it, if they cannot easily extrapolate possible behaviors from it (linked with the  X  X  X yopic X  X  behavior), and if they cannot even evaluate the time needed for a return on their investment (i.e., when they will earn money using the system they paid for). The lack of consideration of the human factors in system design and the lack of manager commitment to distributed approaches is clear in the literature. A new generation of decision-support systems that take these human factors into account will thus have to be designed ( Trentesaux et al., 1998 ). But this final challenge will not be resolved until all the challenges mentioned above have been resolved. 6. Conclusion
Resolving the problems and challenges described above is not insurmountable. This is illustrated at a low level by the wide-spread use of the Kanban system, which can be seen as distributed production control system ( Takahashi and Nakamura, 2002 ) and at the higher level by the use of heterarchical control architecture for describing and managing supply chains and extended and networked enterprises ( Tomiyama, 1997 ). Several of the identified disadvantages have been addressed by the papers presented in this special issue about the  X  X  X istributed control of production systems X  X . This special issue was planned to illustrate a large number of possible application contexts for distributed control and the impact of using distributed control on the different kinds of agility. Both highly theoretical and highly practical approaches have been presented in the papers. In addition, the usual  X  X  X roduction levels X  X , from operational to strategic, have also been considered. Moreover, the various kinds of control (e.g., process control, reconfiguration, production scheduling and maintenance scheduling) were all addressed, mainly during the production phase but also in the design phase.

To conclude, it could be argued that the continuously increasing capabilities provided by computer power will counter-balance the continuous structural reduction of the decisional contexts and make it ineffective to use distributed approaches. For example, increasing computer power and the emergence of grid computing will reduce calculation times, making it easier to obtain real-time behavior with the static scheduling algorithms of the past. In this case, centralized approaches would be more and more competitive for supporting agility (e.g., advanced planning systems). On the other hand, the increasing capabilities of embedded systems and high-speed communication networks will make it easier to manage production control distributively. In this case, globally optimized performance will be easier to realize, making it ineffective to use centralized approaches. We think that the continuous volatile evolution of designer choices  X  from centralized to distributed approaches and vice versa  X  is guided by industrial needs and technological evolution. Consequently, future production control systems may include centralized mechanisms (i.e., powerful static optimization mechanisms) coupled with distributed ones (i.e., powerful reactive mechanisms). In this respect,  X  X  X olonic systems X  X ,  X  X  X mbient intelligence X  X  and  X  X  X m-bedded intelligence X  X  seem to be major key words in the near future, impacting not only production phase but also the whole life cycle of products, from their designing phase to their recycling phase.
 Acknowledgement
More than 30 papers from all around the world were submitted for publication in this special issue, which allowed a rigorous and incisive analysis of all the contributions in the field of distributed control systems. The guest editor would like to thank all the authors for their contributions and the numerous reviewers for their consistent and helpful comments. The guest editor also acknowledges his debt to the reviewers, Bernard Grabot, EAAI Deputy Editor, and Rob Vingerhoeds, EAAI Editor-in-
Chief, for their confidence in this project and their availability during the whole publication process.
 References List of the 15 papers composing this special issue
