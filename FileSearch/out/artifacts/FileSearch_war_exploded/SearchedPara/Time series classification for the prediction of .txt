 1. Introduction
Time series are a special kind of input data to machine learning problems. Most modeling techniques have been designed with a static data model in mind and are not suitable for coping with the dynamicnatureoftimeseries.Mostdynamicdatamodelsarevery complex in both design and training algorithms. Examples of such models based on artificial neural networks are the hidden control neural network ( Levin, 1993 ), the neural prediction model ( Iso and
Watanabe, 1991 ), the linked predictive neural network ( Tebelskis et al., 1990 ) and the adaptive time-delay neural network ( Xie et al., 2006 ). Recurrent neural networks (RNNs) are often used ( Robinson, 1994 ) since this type of artificial neural network can represent high-dimensional non-linear temporal data. Hidden Markov models ( Rabiner, 1989 ) and neural network-hidden Markov model hybrids ( Graves and Schmidhuber, 2005 ; Trentin and Gori, 2003 ) are also used to model time series data. An obstacle when using RNNs is that only a few training algorithms exist which are complex and often yield poor results ( Haykin, 1994 ; Jaeger, 2002b ).
More recently, three approaches to simplify the training process of RNNs were independently developed. These approaches are liquid state machines (LSM) ( Maass et al., 2002 ), echo state networks (ESN) ( Jaeger, 2001 ), and backpropagation decorrelation (BPDC) ( Steil, 2006 ). The underlying idea of these three methods is similar and nowadays they are referred to as reservoir computing ( Verstraeten et al., 2007 ). Reservoir computing has become a vivid research field and recently a special issue of  X  X  neural networks  X  X  was dedicated to it ( Jaeger et al., 2007 ).

The key idea in reservoir computing is that the dynamic system producing the time series data is modeled in a reservoir consisting of a RNN. The reservoir is then read by a linear readout function, which is illustrated in Fig. 1 . The output of this readout function can then be used to make several kinds of predictions. The training algorithm only affects the linear readout function. For training linear functions many algorithms exist such as linear regression ( Fisher, 1925 ).

The goal of this study is to verify whether the use of reservoir computing methods is an added value in classification problems in the intensive care unit (ICU) when the input data consists of time series. We select a case study that is easily characterized by medical experts. This medical classification problem is then handled using reservoir computing, which can directly cope with time series data, and the performance is compared to more traditional machine learning approaches, which cannot directly cope with this high-dimensional temporal data and thus need to be combined with feature extraction (FE) and selection (FS) to process the time series.

LSMs and ESNs are the two pioneering reservoir computing methods. However, the two methods have a very different back-ground ( Jaeger et al., 2007 ). The initial ESN publications were framed in settings of machine learning and non-linear signal processing applications ( Jaeger, 2001 , 2002a , b , 2003 ; Jaeger and Haas, 2004 ). In contrast, LSMs were developed from a computa-tional neuroscience background, aiming at elucidating principal computational properties of microcircuits ( Maass et al., 2002 , 2003 , 2004 ; Natschl  X  ager et al., 2002 ).

This difference in background also explains the main differ-ence between LSMs and ESNs ( Luko  X  sevic  X  ius and Jaeger, 2009 ). ESNs standardly use simple sigmoid neurons or leaky integrator neuron models, while LSMs use more sophisticated and biologi-cally realistic models built from a spiking neuron model called the leaky integrate and fire (LIF) neuron ( Maass and Bishop, 2001 ) and dynamic synaptic connection models ( Gerstner and Kistler, 2002 ) in the reservoir. Since the model of both the connections and the neurons themselves in LSMs is quite sophisticated, it has a large number of free parameters to be set, which is done manually, guided by biologically observed parameter ranges. The parameters of ESNs, e.g., the warm-up drop and the leak rate, are more intuitive and can easily be set by using rules of thumb or performing parameter sweeps. Moreover, LSMs require pulse trains as input data. Translating continuous data, of which the training data of the medical problem under study in this research consists, to pulse trains is a complex problem. Consequently,
LSMs are usually more difficult to implement, to correctly set up and tune, and typically more expensive to emulate on digital computers than simple ESN-type  X  X  X eighted sum and non-linearity X  X 
RNNs. Thus LSMs are less widespread for engineering applications of RNNs than ESNs. This makes ESNs the better choice for  X  X  X imple X  X  engineering tasks, such as the medical classification problem under study in this research.

The idea of separation between a reservoir and a readout function has also been arrived at from the point of view of optimizing the performance of the RNN training algorithms that use error back-propagation. It was found that the A tiya-Parlos recurrent learning (APRL) rule ( Schiller and Steil, 2005 ) restricts the adaptation of the weights to the output layer, effectively splitting the RNN into a reservoir and a readout layer. The o utput weights are trained and the internal weights are only globally scaled up or down a bit ( Schrauwen et al., 2007 ). This lead to a learning rule for RNNs called BPDC. Here too, sigmoidal neurons are used, but a significant difference between
BPDC reservoirs and ESNs is the fact that feedback connections from the readout layer into the reservoir and into the readout layer itself are used, whereas in practice this is hardly ever the case for ESNs ( Verstraeten et al., 2007 ). As for the medical classification task under scrutiny these feedback connections are not needed, ESNs were used instead of BPDC in this research.

More information about the different reservoir computing methods and their various properties and application domains can be found in Verstraeten et al. (2007) , Jaeger et al. (2007) , and Luko  X  sevic  X  ius and Jaeger (2009) .

Thus, the ESN was selected as reservoir computing method to handle the medical classification problem studied in this research.
The medical time series are also classified using support vector machines (SVMs) and the naive Bayes (NB) classifier. This way, we can compare the performance of two traditional classifiers  X  a sophisticated and a simple one  X  and the recent classifier based on ESN.

Although medical data are often time series, little medical applications of ESN have been studied yet. To our knowledge, apart from this study, of which a preliminary report has been published which focusses on the clinical aspect of the study ( Verplancke et al., 2010 ), ESNs have been applied to two other medical use cases. An abstract reported the classification of autistic and normal children ( Noris et al., 2008 ) and a study described the detection of epileptic seizures on rat data using reservoir computing ( Buteneers et al., 2008 , 2011 ).
In time-oriented medical studies, longitudinal data analysis is a popular approach. However, this is only suitable for relatively short time series  X  typically up to 10 measurements per input parameter  X  since longitudinal data analysis focuses on the correlation of mea-surements within a time series, which diminishes when the time series grows and measurements lie further apart in time ( Zeger et al., 2006 ). Another approach is repeatedl y performing data analysis only in a very small interval or individual points in time. However, this neglects the temporal nature of the data almost completely.
The remainder of this paper is structured as follows. The application data is described in Section 2 .In Section 3 the classification, feature extraction and selection, and performance evaluation methods used in this study are briefly introduced.
Section 4 then summarizes the experimental setup, after which the results are presented in Section 5 . These are discussed in
Section 6 after which a conclusion is formulated in Section 7 . 2. Application data
Since we want to explore the advantages of the use of echo state networks in this study, a simple problem is selected. That is, a problem that is easily solved by an expert in the field. This way, we are sure that the required information to solve the problem is contained in the data and that the acquired result is the outcome of the used method, not the used data.
 In collaboration with the ICU department of the Ghent
University we selected the problem of predicting whether or not a patient will need dialysis between five and 10 days after admission in the ICU. The prediction is made at hour 72 after submission, so only the diuresis and creatinine values of the first three days after ICU admission were retrieved from the ICU database for each patient included in the study. The study population consisted of an observational cohort of 916 patients admitted consecutively to the ICU between May 31, 2003 and
November 17, 2007. These patients were selected from a total of 9752 medical and surgical ICU (MICU/SICU) patients admitted in this period after application of inclusion/exclusion criteria.
Namely, 8725 patients with a length of stay in the ICU of less than 10 days and 111 patients who received dialysis in the first five days of ICU admission were excluded from the analysis.
Diuresis is measured in 2 h intervals, while creatinine is measured one, two or exceptionally three times a day. These measurements are performed by hand, so there exists some variance in the intervals between succeeding measurements. Also the interval between creatinine measurements is larger than the one between diuresis measurements. However, the input time series needs to contain measurements over regular time intervals and these intervals must be the same for both input parameters.
Therefore linear interpolation of the data is the very first preprocessing step.

The availability of both diuresis and creatinine measurements does not fully overlap. Measurements not within the overlapping interval are excluded from the data. Patients who do not have an overlapping interval of minimal 40 measurements are excluded from the study. After pre-processing, 830 patients are available with 60 interpolated measurements for both creatinine and diuresis. Fig. 2 visualizes these interpolated creatinine and diuresis measurements, expressed as milliliter/hour (ml/h), for two patients. The patient in Fig. 2 a needed dialysis between five and 10 days after ICU admission and the patient in Fig. 2 b did not.
The interval between these measurements is 1 h, so the data consists of a 60 h period somewhere in the first three days of the patient X  X  stay in the ICU. Sixty two percent of the patients were male and the mean age of the study population was 58.6 years.
The selected population had a total mortality rate of 17% and the mean Simplified Acute Physiology Score (SAPS) II score was 37.2.
The 82/830 (9.9%) patients needed dialysis between the fifth and tenth day after admission, while the remaining 748/830 (90.1%) patients did not need dialysis during that period. 3. Classifiers
In this section we discuss the feature extraction and selection methods and the classifiers under study. The time series are classified using support vector machines, the naive Bayes classifier and echo state networks. Prior to the use of SVM and the NB classifier, feature extraction and selection is required to reduce the number of input features and thus alleviate the effect of curse of dimensionality ( Bowden et al., 2005 ). This way, we can compare the performance of two traditional classifiers  X  a sophisticated and a simple one  X  and the recent classifier based on ESN. 3.1. Feature extraction and selection
Classical classification techniques, such as the SVM and NB classifier, have been designed with a static data model in mind and are not suitable for coping with the dynamic nature of time series. The performance of the SVM and NB classifiers suffers from a large number of features if not all the features are of the same type and of equal importance ( Bowden et al., 2005 ). This is the case in the medical problem addressed in this research as it consists of two types of features, namely diuresis and creatinine values. Sixty interpolated measurements for both diuresis and creatinine are used as features. Not all these measurements are equally important as expert opinion reveals that the tails of the time series, i.e., later measurements, contain more information than the start of the series.

An inclusion of a large number of features in the SVM and NB classifiers leads to  X  X  X he curse of dimensionality X  X  ( Bowden et al., 2005 ; Muttil and Chau, 2007 ), which is associated with the following shortcomings:
As the input dimensionality increases, the computational complexity and memory requirements of the model increase, which in turn increases the time to build the models.

As the input variables increase, the number of training samples required also increase.

Misconvergence and poor model accuracy may result from the inclusion of irrelevant inputs due to an increase in the number of local minima present in the error surface.

Interpreting complex models is more difficult than interpret-ing simple models that give comparable results.

Feature extraction, which generates additional features from the time series, and feature selection, which selects the most appropriate features and thus reduces the amount of input features, helps to improve the performance of learning models by ( Guyon and Elisseeff, 2003 ): alleviating the effect of the curse of dimensionality; enhancing generalization capability; speeding up the learning process and improving model interpretability.

To make sure that all the information contained in the time series is captured, extensive feature extraction is applied for the SVM and the NB classifier. Features are therefore extracted that capture the overall properties of the time series and the correla-tion between the different measurements in the time series. For each time series the minimum, maximum, mean, median, 25th percentile, 75th percentile, standard deviation (stdev), the linear regression  X  y  X  ax  X  b  X  coefficients a and b and the area under the curve (AUC) are calculated. This results in 10 features per time series.

As mentioned previously, expert opinion reveals that the tails of the time series contain more information than the start of the series. We therefore repeat the feature extraction multiple times for reduced time series. The 10 features are extracted for the full time series, the 59 last values of the time series, the 58 last values of the time series, y ,and the two last values of the time series. This results in 59 n 10  X  590 extracted features per input para-meter, or 1180 extracted features in total. Finally we add the measurements themselves to the extracted feature set as well, which results in 1180  X  2 n 60  X  1300 features.

Feature selection needs to be performed on these 1300 features to select the most useful ones for the NB and SVM classifiers. Ideally, a brute-force search is performed in which the classifica-tion performance of each possible combination of features is tested and the best combination is selected. Brute-force feature selection is however very resource-intensive. As the number of possible feature combinations for 1300 features is nearly endless, namely  X  2 1300 1  X  possible combinations, the required computa-tion time would be virtually infinite.

To boost the performance, a greedy feature selection algorithm is used which iteratively adds the feature that improves predic-tion the best out of a set of features that show little multi-collinearity with the already selected set of features. This approach is similar to the one used by Langley and Sage (1994) , but in each iteration we filter the set of candidates so that it contains only features that are not collinear with the already selected set. This drastically reduces the size of the set of candidate features in each iteration and therefore speeds up the feature selection process. Detection of multicollinearity is done using the common rule of thumb: variance inflation factor 4 5 ( Kutner et al., 2004 ). The classifier used in this hybrid filter-wrapper method ( Guyon and Elisseeff, 2003 ) is the NB classifier.
All data is globally scaled to the [ 0.9, 0.9] interval. Scaling features to a fixed interval is necessary to avoid favoring a feature only because it has the largest scale. The bounds 0.9 and 0.9 are chosen instead of 1 and 1 to avoid excessive weight saturation in the recurrent artificial neural network. 3.2. Support vector machines
As first discussed by Cortes and Vapnik (1995) , a SVM tries to separate positive and negative examples in a multi-dimensional space by a hyperplane.
 y A f 1 , 1 g , x i A R d . The points x that lie on the hyperplane satisfy the equation w x  X  b  X  0, where w is normal to the hyperplane. d and d are the shortest distances from the separating hyper-plane to the closest positive and negative examples. The margin of the separating hyperplane is then defined as d  X   X  d .
The SVM discussed by Cortes and Vapnik (1995) was a linear classifier. For the linearly separable case, the SVM searches for the hyperplane that separates the data from the two classes with maximal margin ( Vapnik, 1995 ). This search can be formulated as an optimization problem, where
X is maximized, subject to
X y i  X  0 for a i Z 0  X  2  X  with a i being the Lagrangian multipliers for each training exam-ple. Given the a i , the solution is given by w  X 
X
The examples for which a i 4 0 are called support vectors. All other examples have a i  X  0.

When the positive and negative examples are not linearly separable, an additional condition needs to be added: 0 r a i r C  X  4  X  This gives the a i an upper bound of C .

Switching to the non-linear case can be done by using the kernel-trick ( Aizerman et al., 1964 ). Notice that the data appears in the training problems, see Eq. (1), only in the form of dot products x i x j . If the data is mapped to some other Euclidian space H , using a mapping F : R d / H , the training problem can be be used in the training algorithm and it never needs to be explicitly known what F is. An example of such a kernel function and the one which was used in this study is the radial basis function (RBF) kernel function. R  X  uping (2001) showed that the
RBF kernel performs very well on different types of time series and learning tasks. The RBF kernel function has the following definition:
K  X  x , x j  X  X  exp  X  g J x i x j J 2  X  X  5  X 
This results in a training algorithm with only two parameters, namely C and g . For a more detailed introduction to SVMs, we refer to Burges (1998) . SVMs have been successfully applied to perform time series prediction and prediction on real problems in different engineering fields ( Lin et al., 2006 ; R  X  uping, 2001 ; Kampouraki et al., 2009 ; Zhang et al., 2010 ).

The libSVM ( Chang and Lin, 2012 ) support vector machine implementation is used in this study. The C and g parameters were optimized using parameter sweeps during each experiment, as is further detailed in Section 4 . 3.3. Naive Bayes classifier
The naive Bayes classifier is based on the application of Bayes X  theorem, which relates the conditional and marginal probabilities of events A and B :
P  X  A 9
B  X  X  P  X  B where P ( A ) is the prior probability of A , P ( B ) is the prior probability of B , P  X  A 9 B  X  is the posterior probability of A and
P  X  B 9 A  X  is the posterior probability B .

A custom Java implementation of the naive Bayes classifier is used in this study. This naive Bayes classifier estimates the prior probability of class A as
When a previously unseen example X is presented to the classifier, the likelihood of class A is estimated as
Li  X  A  X  # items of class A in the training set in the neighborhood of X
Assuming that each feature is conditionally independent of every other feature, the posterior probability that a previously unseen example X belongs to class A can be estimated as P  X  X  X  A  X  P  X  A  X  Li  X  A  X  X  9  X 
The number of examples in the training set that constitute the neighborhood of a previously unseen sample X , denoted by parameter k , is the only configurable parameter of the used naive
Bayes implementation. Parameter sweeps were performed to determine the optimal value for k per experiment, as is further detailed in Section 4 .

It can be noted that the naive Bayes classifier is based on applying Bayes X  theorem with strong independence assumptions.
However, empirical results show that it performs surprisingly well in many domains containing clear feature dependencies ( Domingos and Pazzani, 1997 ). Zhang (2004) shows that the feature dependence distribution plays a crucial role in the explanation of this behavior and that sufficient and necessary conditions for the optimality of naive Bayes can be formulated. 3.4. Echo state networks
The key idea in reservoir computing ( Verstraeten et al., 2007 )is to feed time series to a reservoir, thereby modeling the dynamics of the system which generates the time series. The reservoir is then read by a readout function in order to make predictions using the constructed model. When training the model, only the readout function is modified, the complex dynamic modeling behavior of the reservoir is left unchanged.

In ESN ( Jaeger, 2001 ), the reservoir consists of a recurrent artificial neural network with sigmoid activation functions and the echo state property which ensures good modeling abilities.
A recurrent artificial neural network is said to have the echo state property when its state is uniquely determined by the input time series. This implies the state forgetting property : the initial state of the reservoir has no impact on the state after feeding a  X  possibly infinite  X  time series. Although it is not yet clearly understood how it exactly works, the reservoir acts as a short-term fading memory ( Jaeger, 2002a ), which means in practical applications that the most recent input of the network has the largest impact on the prediction outcome. The readout function used in ESN is a linear classifier.

The general layout of an ESN is illustrated in Fig. 1 . It consists of k input nodes, n reservoir nodes, and l output nodes. Each node is a perceptron with a sigmoid activation function. The state of each node at a given time is the weighted sum of the last fed inputs, namely x  X  t  X  1  X  X  1 m  X  x  X  t  X  m f  X  Wx  X  t  X  W in u  X  t  X   X  10  X  where x  X  t denotes the network state at time t and u is the input matrix. Leaky integrator neurons are used to optimize the leak rate m of the reservoir so that it can perfectly match the timescale of the input data. For every sample, x  X  0 is initialized as 0. The weights in the ESN are represented in weight matrices. The k n matrix W in contains the weights between the input and reservoir nodes and the n n matrix W contains the recurrent weights between the reservoir nodes. The spectral radius l max is defined as the largest absolute eigenvalue of the matrix W . It has been shown that reservoirs whose spectral radius is larger than one  X  9 l max 9 4 1  X  do not have the echo state property, but in practice the spectral radius is chosen close to one to achieve a suitable dynamic response ( Jaeger, 2001 ). Zero weights are the equivalent of the absence of connections. Feedback connections from output nodes to reservoir nodes and connections from input nodes directly to output nodes are optional.

By using Eq. (10) the echo state network can be recursively simulated using the training data D train . After each sample of the training data is simulated, the 9 D train 9 reservoir state matrices are concatenated in a large state matrix A . Because an ESN is a dynamical system, it takes some time before the full effects of the input are visible in the reservoir states. Therefore, the initial states containing the transient effects are discarded which is known as warm-up drop. The number of states that is discarded is determined by the warm-up drop parameter a .

Different methods can then be used to train the linear readout function, and thus to determine the elements of the  X  k  X  n  X  l  X  l output weight matrix W out , which contains the weights between the reservoir nodes and the output nodes. A complete overview and discussion of the different available techniques reported in the literature for training the readout function of the reservoir can be found in Luko  X  sevic  X  ius and Jaeger (2009) . As the medical problem under study does not require on-line adaptation of the model, batch learning can be performed. In batch mode, the most recommended and used method is ridge or Tikhonov regression ( Wyffels et al., 2008 ), as it has the lowest computational cost, while still allowing to perform regularization. Ridge regression introduces a regularization parameter l . In addition to improving the numerical stability, the regularization in effect reduces the magnitudes of entries in W out , thus mitigating sensitivity to noise and overfitting. However, because Fisher weighting is also used in this study to deal with the unbalanced data set, as further explained in the last two paragraphs of this section, ridge regression could not be used as this combination is not imple-mented in the Reservoir Computing Toolbox (RCToolbox) ( Verstraeten and Wardermann, 2012 ). In this study, the RCTool-box is used to run the ESN experiments. However, using ridge regression is equivalent with using least squares regression ( Bj  X  orck, 1996 ) with noise. So, in this study, W out performing least squares regression on the matrix A , using the desired output matrix y as the right-hand side. Thus, the matrix
W out is computed that satisfies the equation:
W out  X  min W J A W y J 2 :  X  11  X 
In practice, this equation can be computed in a single step by using the Moore X  X enrose generalized matrix inverse, or pseudo-inverse, of the matrix A ( Penrose, 1955 ). This provides least squares regression with a similar numerical stability as ridge regression. Gaussian noise is added to the matrix A in order to control the trade-off between model complexity and general-ization capability (avoid overfitting). This guarantees that the model is complex enough to accurately model the underlying system, but not too complex such that it becomes sensitive to the noise in the samples. Similar to ridge regression, the amount of noise is determined by a regularization parameter l .

Other methods that are sometimes used in the literature to train the linear readout function are weighted regression and evolutionary search ( Jiang et al., 2008 ). The first uses weights to emphasize some time steps t over others. As this study wanted to evaluate how well the ESN performed on the time series without using domain expert knowledge, this method was not used. State-of-art evolutionary methods are able to achieve the same level of precision for supervised tasks as with the best application of linear regression. However, their computational cost is much higher.

Finally, the output of the reservoir can be computed as follows: ^ y  X  k  X  W out x  X  k  X  12  X  where ^ y is the actual output of the reservoir system.
As mentioned previously, the RCToolbox is used to run the ESN experiments. As the original time series, and thus not the extracted features, are used as input for the ESN, a reservoir with k  X  2 input nodes and l  X  1 output nodes is initialized. Theelementsoftheinputweightmatrix W in are drawn from the discrete set f 0 : 1 , 0 : 1 g with equal probabilities. The density of the input weight matrix is 10%, which means that 10% of the weights are non-zero. The elements of the reservoir weight matrix W are drawn from a Gaussian distribution. The density D of the reservoir weight matrix is chosen as d  X  20%. The optimal value for the regularization parameter l is determined by performing a brute-force grid search of the parameter space with cross-validation.
Output-to-output connections are not used. Input-to-output connections are used to enable a dir ect linear mapping of the input.
The RCToolbox allows performing parameter sweeps to find the optimal values for the various parameters of an ESN, namely the leak rate m , the number of reservoir nodes n , the spectral radius l max and the warm-up drop parameter a . These optimal values are found by performing a sensitivity analysis for each parameter. This means that the values for this parameter are varied while all other parameter settings of the ESN are left unchanged. The parameter value which results in the best average performance of the ESN is chosen.
 The sensitivity analysis of the leak rate m is visualized in Fig. 3 . This figure shows the observed average performance and its standard deviation in 30 runs for leak rate values between  X  0 : 01 and m  X  1. Higher performance values are better. For a more detailed explanation of the performance measure, see Section 3.5 . Different runs with the same settings result in different performance results because the data is randomly divided among the folds and the reservoir is randomly initialized. In theory, performance should not depend on these random circumstances. In practice, the dependence should be minimized. For example because of the limited amount of available data, there will always be a certain amount of dependence on how exactly the data is divided among the folds. In this problem setting, the best average performance and the smallest deviation in performance is aimed at. From Fig. 3 it is clear that adjusting the leak rate does not boost the performance of the ESN significantly. Likely this is due to the fact that in this case, the optimal parameters of the ESN are outside the usual range: for the high total input to the reservoir used here, the reservoir acts more like a static kernel rather than a dynamical system. As a consequence, the leak rate is chosen to be the value m  X  0 : 01. This is the default value for the leak rate in the RCToolbox. This means that the reservoir will work very slowly, implementing a low-pass filter.

The sensitivity analyses of the number of reservoir nodes n and the spectral radius l max are shown in Figs. 4 and 5 . These figures show the observed average performance and its standard devia-tion in 30 runs for number of reservoir nodes between n  X  10 and n  X  300 and for spectral radius values between l max  X  0 : 1 and l max  X  1 : 5. From Figs. 4 and 5 it can be derived that adjusting the number of reservoir nodes n or the spectral radius l max also had minimal effects on the performance of the ESN. As mentioned previously, a spectral radius close to one should be chosen to achieve a suitable dynamic response and to guarantee that the echo state property holds. Therefore, the spectral radius is chosen to be the value l max  X  0 : 99. The weights are rescaled so that the spectral radius l max is set to this value. The number of reservoir nodes was chosen to be n  X  70, as this was the parameter value with the highest average AUC across all the runs.

Finally, the warm-up drop parameter a is optimized by perform-ing a sensitivity analysis. The observed average performance and its standard deviation in 30 runs for warm-up drop values between  X  0 (no warm-up drop) and a  X  59 (only the last time point remains) are plotted in Fig. 6 .From Fig. 6 it is clear that adjusting the warm-up drop parameter significantly boosts the performance of the ESN. A warm-up drop of a  X  56 first time steps of the time series 1 leads to the best performance results. This corresponds with the opinion of the domain experts that the tail of the time series contains more information than the start of the series. As can be noted from Section 2 , the data set is unbalanced.
There are a lot more examples of patients who did not receive dialysis between the fifth and tenth day after admission than there are patients that did (748 versus 82 of the 830 patients). This unbalance will have an effect on the generalization capabilities of the classifiers. Since the readout is trained using regression, the separating hyperplane will shift towards the class centers that are most present in the data set (the threshold will not be zero). This is undesirable as one wants the hyperplane to lie in the middle between the two classes (threshold equal to zero). To achieve this, Fisher labeling is applied ( Duda et al., 2001 ).

Assume that the positive class has n 1 examples and the negative class has n 2 examples, then Fisher labeling relabels these classes from the usual  X  1 , 1 for positive and negative examples respectively to  X  X  n 1  X  n 2  X  = n 1 ,  X  n 1  X  n 2  X  = n 2 labels reflect the unbalance of the number of examples in each class. This guarantees that the shifting of the hyperplane is undone. Thus for this data set, the Fisher labeling relabels the classes to [830/82, 830/748]. 3.5. Performance evaluation Each of the three used methods outputs a prediction score. The
SVM and the NB output a prediction score per sample. The ESN, on the other hand, outputs a prediction score per time point in the time series. As the warm-up drop parameter a is set to 56, only four time points remain and thus four prediction scores are outputted by the ESN per sample. These are summarized to one prediction score per sample by taking the mean of these four values. In contrast with a categorical prediction  X  class A versus class B  X  a prediction score is a value x A R in the interval 1 ,  X 1 X  . The sign of x corresponds to a class while the magnitude of x reflects the estimated probability of actually belonging to that class. By varying the prediction threshold, different classifiers can be constructed. These classifiers vary from one that classifies all patients into one class to one that classifies all patients into the other class.

The correctness of a classification can be evaluated by comput-ing the number of true positives ( TP , positive examples classified as positive), true negatives ( TN , negative examples classified as nega-tive), false positives ( FP , negative examples classified as positive), and false negatives ( FN , positive example classified as negative) respectively. The most often used measures for binary classification based on these values are Accuracy, Precision, Sensitivity (Recall), Specificity, F-Score and the area under the ROC curve ( AUC ) ( Sokolova and Lapalme, 2009 ). These measures differ in their ability to preserve their value under a change of the number TP , TN , FP , and/or FN . A measure is invariant if its value does not change when one or more of the TP , TN , FP ,or FN values change. This inability can be beneficial or adverse, depending on the goal of the classification task. More information about the different performance measures for classification can be found in Sokolova and Lapalme (2009) .
For the medical problem under scrutiny, we are interested in the overall performance of the classifier, i.e., interested in the performance of the classifier on both identifying and correctly classifying positive and negative examples. In other words, it is equally important to correctly identify whether a patient will receive dialysis or not between five and 10 days after admission in the ICU. Precision, Recall and F-Score are invariant to changes in the number of TN . These measures thus do not acknowledge the ability of the classifiers to correctly identify negative examples. In contrast, Specificity is invariant to changes in the number of TP . This measure thus does not acknowledge the ability of the classifiers to correctly identify positive examples. Consequently, two measures remain that are non-invariant to changes to the number of TN and TP , namely AUC and accuracy. However, the accuracy is invariant to the distribution of classification results because it does not distinguish TP from TN and FN from FP . This measure is thus not trustworthy when using unbalanced data sets. The AUC is non-invariant to the distribution of classification results, which makes it a good measure for comparing classifiers on unbalanced data sets, such as the one used in this study.
The AUC is calculated based on the Specificity and Sensitivity performance measures of the classifier. Sensitivity measures the proportion of actual positive examples, i.e., patients needing dialysis, which are correctly identified by the classifier as follows: Sensitivity  X  TP TP  X  FN  X  13  X  In contrast, Specificity measures the proportion of actual negative examples, which are correctly identified by the classifier as follows: Specificity  X  TN TN  X  FP  X  14  X  Plotting Sensitivity versus  X  1 Specificity  X  for all these classifiers, results in the so-called receiver operating characteristic (ROC) curve ( Zweig and Campbell, 1993 ). The area under this ROC curve ( AUC ) is an estimation of the probability that a positive patient receives a higher prediction score than a negative patient by the classification method under study. An AUC value of 1.0 indi-cates a classifier that perfectly separates positives from negatives, while a classifier that randomly classifies patients as positive or negative corresponds to AUC  X  0.5. All other classifiers will result in 0 : 5 o AUC o 1 : 0.

A two-sample t -test is used to determine whether an observed difference in AUC is random or real. A p -value expresses the probability of having a test statistic at least as extreme as the one that was actually observed, assuming that the null-hypothesis is true. The lower the p -value, the less likely the result, and consequently the more statistically significant the result is. A result is statistically significant if it is unlikely that it occurred by chance. Generally, the null hypothesis is rejected if the p -value is smaller than or equal to the significance level, a .

In this paper, the test statistics are the average AUC s across the 30 runs for each classifier. The null-hypothesis in these tests is that both average AUC s are equal. The significance level a is chosen to be 0.05, which expresses that results that are only 5% likely or less are deemed extraordinary, given that the null hypothesis is true.

Since we test three average AUC s for equality, the significance level a must be corrected for multiple testing. This can be done by applying Dunn X   X  Sida  X  k correction ( Abdi, 2007 ), that is  X  1  X  1 a  X  1 = C  X  15  X  where a is the chosen significance level, a cor is the corrected a -value, and C is the number of tests. The null-hypothesis in this test is that both average AUC s are equal. Thus the corrected significance level, with whom the p -values are compared, is  X  1  X  1 0 : 05  X  1 = 3  X  0 : 016952  X  16  X 
When choosing a prediction threshold, we can select the value where the balanced accuracy of the classifier is the highest. We define balanced accuracy as follows: balanced accuracy  X  Sensitivity  X  Specificity 2  X  17  X 
Using maximum balanced accuracy prevents favoring a classifier that always outputs the majority class in the case of heavily unbalanced data sets such as the one used in this study. If the classifier performs equally well on either class, this term reduces to the conventional accuracy, i.e., the number of correct predic-tions divided by the total number of predictions. In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the maximum balanced accuracy will drop to chance.

As can be seen, the AUC gives us a global view on the quality of the constructed classifiers, while the maximum balanced accu-racy is an indication of the best prediction accuracy we can expect. Moreover, the AUC is well-known and much used perfor-mance measure of binary classification tasks within the medical domain ( Sokolova et al., 2006 ). Both the AUC and maximum balanced accuracy are invariant to a uniform change of positive and negative examples in the data set. This means that these measures are stable with respect to the uniform increase of the data size. As in our medical problem, the proportion of represen-tatives for the positive and negative class will remain stable across different data sizes, these measures are a good choice. We will also look at the required execution time, which is a measure for the computational complexity of the methods under study. 4. Problem setting
To summarize, we compare the classification performance of three methods on the given problem. The performance measures are AUC and maximum balanced accuracy, which are determined for each of the methods using cross-validation. The computational complexity of the methods is compared through their required execution times. All these tests were performed on the same machine  X  Advanced Micro Devices (AMD) Athlon 64 2 Dual
Core Processor, 3000 megahertz (MHz) Central Processing Unit (CPU), 2 Gigabyte (GB) of Random-Access Memory (RAM)  X  under exactly the same conditions.

The input data consists of two time series per patient. Each time series consists of 60 linear interpolated values, which are constructed out of the original patient data. For the ESN method, no further preprocessing of the data is necessary. Prior to the use of SVM and the NB classifier, feature extraction and selection and global rescaling of the data is required.

Several parts of the algorithms under study have a stochastic nature. Examples are the random division of the available data into folds and the random initialization of the reservoir weights in the ESN. To avoid faulty interpretation of results that origin from a coincidental odd configuration, the experiments are repeated 30 times, each time using another random initialization.

The pre-processing phase of the SVM and NB classifier, con-sisting of the feature extraction and selection process and global rescaling of the data, is also subject to random factors, for example, the random division of the available data into folds.
Moreover, there are several multicollinear features. In each iteration of the feature selection, the set of candidates is filtered so that it contains only features that are not collinear with the already selected set. Which of the multicollinear features thus ends up in the selected set is also subject to the random initialization of the feature selection. Therefore, this pre-processing phase is also repeated for each run of the SVM and NB classifier.
 Consequently, the data set that is used as input for the NB and
SVM classifiers is different in every run. To determine the optimal values for the parameter k of the NB classifier and parameters C and g of the SVM classifier parameter sweeps thus need to be performed for each of the 30 runs. For each parameter, the value is selected that achieves the highest performance for the classifier in that run. Consequently, different parameter values are obtained for the NB and SVM classifiers in each run. The optimal value of the parameter k of the NB classifier across the 30 runs ranges from k  X  29 to k  X  47 and is on average k  X  40. The optimal value of the parameters C and g of the SVM classifier across the 30 runs range from C  X  4 : 12 to C  X  23.65 and g  X  22 : 05 to g  X  10 : 57 and are on average C  X  17.66 and g  X  17 : 58. 5. Results
Tables 1 and 2 show respectively the observed AUC and maximum balanced accuracy performance measures. The best maximum balanced accuracy and best AUC achieved across the 30 runs for each classification method are shown as well as the average value and its accompanying standard deviation (stdev) and confidence intervals (CI) at 95% and 99%. The performance measures for the ESN classifier are shown for both the configura-tion for which all the parameter values of the ESN were optimized through parameter sweeps and the default configuration which uses the default settings of the RCToolbox for the ESN. The default settings are a reservoir size n  X  100, a leak rate m  X  0 : 01, a scale factor l max  X  0 : 9 and a warm-up drop a  X  0. Table 3 contains the p -values that are obtained while testing the average AUC s for equality.
 Fig. 7 shows the obtained ROC curves in run 1. The obtained ROC curves in the other runs are very similar.

As Table 4 shows, the pre-processing phase preceding the support vector machines and naive Bayes classifier approach, which includes the loading and interpolating the data and performing feature extraction and selection, requires on average 3 hours (h) 59 minutes (m) 55 seconds (s) and 245.93 milli-seconds (ms) of computation time. The pre-processing phase for the recurrent reservoir, which only includes loading and inter-polating the data as no feature extraction and selection is needed, requires on average only 253.87 ms of computation time.
Table 5 shows the computation time needed to train the three classifiers. The reported train time includes finding the optimal value for the size of the neighborhood k , see Eq. (8) , for the NB classifier, for the C and g parameters, see Eqs. (4) and (5) , of the SVM classifier and the regularization parameter l of the ESN classifier with default configuration. To reach the performance results of the optimized ESN classifier, parameter sweeps need to be performed. The train time for performing one parameter sweep of the reservoir size, leak rate, scale factor or warm-up drop parameters of the ESN are also reported. Performing one sweep means that this parameter is set to 1 value (e.g., reservoir size  X  300) and the ESN is trained. In practice, mainly the warm-up drop parameter needed to be sweeped to obtain the improved performance results of the optimized ESN classifier.

Finally, Table 6 visualizes the computation time needed to test the three classifiers with data about one patient. 6. Discussion
The p -values comparing the naive Bayes (NB) classifier com-bined with feature extraction (FE) and selection (FS), the support vector machine (SVM) combined with FE and FS and the echo state network (ESN) classifier are smaller than the Dunn X  corrected significance level a  X  0 : 016952, see Eq. (16) . We there-fore conclude that there is a significant difference between the average AUC s of the used methods observed at the 5% level. This means that the SVM  X  FE  X  FS, with an average
AUC of 0.838, is the worst classifier. The NB  X  FE  X  FS has an average AUC of 0.874 and is thus the best classifier. The ESN classifier lies somewhere in the middle with an average AUC of 0.849. Inspection of Fig. 7 , which shows the ROC curves, and
Table 2 , which shows the observed maximum balanced accuracy, see Eq. (17) , confirms this conclusion. However, the results of the
NB classifier combined with FE and FS are biased as the feature selection method is a hybrid filter-wrapper method which also uses a NB classifier as classifier. Consequently, features selected by this hybrid filter-wrapper method are optimal for and best recognized by the NB classifier used in this feature selection method. If we then again apply a NB classifier on the selected features, the achieved results are slightly biased towards the NB classifier, since the selected feature set favors this type of classifier.

Based on the observed values of the performance measures we cannot definitely favor the ESN classifier. The picture changes when we look at the procedure followed for each method. The
SVM and the NB classifier are designed for data sets where the data resides in an n -dimensional space as such. The longitudinal correlation along the different dimensions/parameters is not taken into account in any way. Therefore SVM and NB perform rather poorly when time series data is used unprocessed. To get satisfying results, we first must extract useful features based on the time series. This can be done in an automated way or by using domain knowledge of the problem at hand. Extracting features in an automated way often results in missing important character-istics of the data, while acquiring domain knowledge is a time consuming and often cumbersome activity. In this study we used a combined approach, exploiting the time saving properties of automated feature extraction and limiting the domain knowledge gathering to acquiring general properties of the data. The latter allows to steer the automated procedure, which avoids exploring useless regions in the search space. This approach still results in an enormous amount of candidate features, which makes a feature selection phase necessary as well. Furthermore, both feature extraction and feature selection phases combined require a considerable amount of computation time, namely on average approximately 4 h (see Table 4 ).
 In the ESN approach, no feature extraction and selection is needed.
The reservoir stores features from the input data and actually adds features to it, as we go from an input space from k  X  2dimensionstoa reservoir space of n  X  70 dimensions. Thus, by putting a reservoir between the input data and the readout, a lot more features are available to build the estimation on. The ESN consequently succeeds nicely in modeling the information contained in the time series data.
It therefore needs on average less than a second of pre-processing time (see Table 4 ) and no domain knowledge. Additionally, the reservoir algorithms are easy to implement, and existing rules of thumb suffice for acquiring a good performing configuration of the reservoir, as can be noted from the performance of the ESN with default configuration in Table 1 . Moreover, a simple linear regression classification suffices for determining the final classification results, where complex non-linear methods are required in the traditional approach.

Note that expert opinion states that in the data used the required information is mostly contained in the tail of the time series. This was explicitly taken into account during the pre-processing phase of the SVM and NB classifiers by extr acting features from an increas-ingly shorter time series. Namely, the 10 features were extracted for the full time series, the 59 last values of the time series, the 58 last values of the time series, y , and the two last values of the time series.Ifwestudythefeatures, which were selected during the feature selection phase, we see that mainly features of the shorter time series and linear regression coefficients were selected. How-ever, for the ESN classifier this domain knowledge does not need to be taken explicitly into account. The ESN classifier takes it implicitly into account because of the fading short-term memory ( Jaeger, 2002a ) characteristic of the ESN. This means that the most recent input of the network has the largest impact on the prediction outcome, which matches the domain knowledge that the most important information is contained in the tail of the time series. This explains the successful results.

The computation time for training the ESN classifier is also better than the other classifiers, as shown in Table 6 . However, additional time is needed to optimize the values of the various parameters of the ESN classifier through parameter sweeps.
Optimizing the value of the warm-up drop parameter resulted in significant performance improvements. In practice, about five sweeps would have to be performed to obtain the optimal value for the warm-up drop parameter. Therefore, the train time for the different classifiers is comparable.
 As can be derived from Table 6 , the test time of the SVM and
ESN is also comparable. The computation time for testing the NB classifier is slightly higher on average, because the NB classifier takes into account each training sample when calculating the neighborhood of the testing sample. Since the data set used in this study is relatively small, the difference in test time between the NB classifier and the SVM and ESN classifiers is still negligible.
Since the ESN allows complex non-linear modeling in a simpler and computationally much more efficient way compared to the traditional approach while yielding a comparable classifi-cation performance, the authors believe that the ESN will play an important role in future analysis of medical time series data. 7. Conclusion
Medical data often consists of time series. This kind of data should be analyzed by specialized methods. The echo state net-work (ESN) is a recent method that was optimized to handle time series data. ESNs are easy to implement and to use, and do not require that feature extraction and selection is performed on the time series data before using it as input. We show the usefulness of ESN by using it to predict the need for dialysis between the fifth and tenth day after admission in ICU patients, and comparing the results to those acquired by using support vector machines (SVM) and the naive Bayes (NB) classifier combined with feature extraction (FE) and selection (FS). A hybrid filter-wrapper feature selection method is used with an NB classifier as classifier.
Performance is measured by the area under the ROC curve and the maximum balanced accuracy.

Limitations of this study are that no extensive comparative study was performed between different feature selection methods that could be combined with the SVM and NB classifiers and the lack of comparison of the ESN to other classification methods which can directly process time series. Future work will further investigate these limitations by studying if the choice of the feature selection method significantly improves the performance of the SVM and NB classifiers on this medical classification task.
Moreover, the performance of the ESN will be compared to other reservoir computing methods, such as liquid state machines and backpropagation decorrelation.

The results of this study showed statistically significant difference at the 5% level between the performance of ESN and the other two methods. The SVM  X  FE  X  FS had the worst perfor-mance, the NB classifier  X  FE  X  FS the best and the performance of the ESN lies in the middle. However, the results of the NB classifier  X  FE  X  FS are biased as the feature selection method is a hybrid filter-wrapper method which also uses a NB classifier.
Moreover, its simplicity in usage, its ability to model and extract features without the need of domain knowledge, and its limited usage of computing time, make ESN the most suitable method for predicting the need for dialysis when using measured time series as input.

Future work will focus on applying the reservoir computing methods on a medical classification task which is not trivial for the medical experts, namely detecting whether a patient who has been admitted to the ICU has sepsis. Sepsis is the number one cause of death in the ICU.
 Acknowledgments
Femke Ongenae would like to thank the IWT, Institute for the promotion of Innovation through Science and Technology in Flanders, for supporting this work through her PhD grant. References
