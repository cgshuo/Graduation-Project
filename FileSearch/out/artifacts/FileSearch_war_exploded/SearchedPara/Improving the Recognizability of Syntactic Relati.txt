 The ability to search over grammatical relation-ships between words is useful in many non-scientific fields. For example, a social scientist trying to characterize different perspectives on im-migration might ask how adjectives applying to  X  X mmigrant X  have changed in the last 30 years. A scholar interested in gender might search a col-lection to find out whether different nouns enter into possessive relationships with  X  X is X  and  X  X er X  (Muralidharan and Hearst, 2013). In other fields, grammatical queries can be used to develop pat-terns for recognizing entities in text, such as med-ical terms (Hirschman et al., 2005; MacLean and Heer, 2013), and products and organizations (Cu-lotta and McCallum, 2005), and for coding quali-tative data such as survey results.

Most existing interfaces for syntactic search (querying over grammatical and syntactic struc-tures) require structured query syntax. For exam-ple, the popular Stanford Parser includes Tregex, which allows for sophisticated regular expression search over syntactic tree structures (Levy and An-drew, 2006). The Finite Structure Query tool for querying syntactically annotated corpora requires its queries to be stated in first order logic (Kepser, 2003). In the Corpus Query Language (Jakubicek et al., 2010), a query is a pattern of attribute-value pairs, where values can include regular ex-pressions containing parse tree nodes and words. Several approaches have adopted XML represen-tations and the associated query language families of XPATH and SPARQL. For example, LPath aug-ments XPath with additional tree operators to give it further expressiveness (Lai and Bird, 2010).
However, most potential users do not have pro-gramming expertise, and are not likely to be at ease composing rigidly-structured queries. One survey found that even though linguists wished to make very technical linguistic queries, 55% of them did not know how to program (Soehn et al., 2008). In another (Gibbs and Owens, 2012), humanities scholars and social scientists are fre-quently skeptical of digital tools, because they are often difficult to use. This reduces the likelihood that existing structured-query tools for syntactic search will be usable by non-programmers (Ogden and Brooks, 1983).

A related approach is the query-by-example work seen in the past in interfaces to database sys-tems (Androutsopoulos et al., 1995). For instance, the Linguist X  X  Search Engine (Resnik et al., 2005) uses a query-by-example strategy in which a user types in an initial sentence in English, and the sys-tem produces a graphical view of a parse tree as output, which the user can alter. The user can ei-ther click on the tree or modify the LISP expres-sion to generalize the query. SPLICR also contains a graphical tree editor tool (Rehm et al., 2009). According to Shneiderman and Plaisant (2010), query-by-example has largely fallen out of favor as a user interface design approach. A downside of QBE is that the user must manipulate an exam-ple to arrive at the desired generalization.
More recently auto-suggest, a faster technique that does not require the manipulation of query by example, has become a widely-used approach in search user interfaces with strong support in terms of its usability (Anick and Kantamneni, 2008; Ward et al., 2012; Jagadish et al., 2007). A list of selectable options is shown under the search bar, filtered to be relevant as the searcher types. Searchers can recognize and select the option that matches their information need, without having to generate the query themselves.

The success of auto-suggest depends upon showing users options they can recognize. How-ever, we know of no prior work on how to dis-play grammatical relations so that they can be easily recognized. One current presentation (not used with auto-suggest) is to name the relation and show blanks where the words that satisfy it would appear as in X is the subject of Y (Muralid-haran and Hearst, 2013); we used this as the base-line presentation in our experiments because it em-ploys the relation definitions found in the Stan-ford Dependency Parser X  X  manual (De Marneffe et al., 2006). Following the principle of recognition over recall, we hypothesized that showing contex-tualized usage examples would make the relations more recognizable.

Our results confirm that showing examples in the form of words or phrases significantly im-proves the accuracy with which grammatical re-lationships are recognized over the standard base-line of showing the relation name with blanks. Our findings also showed that clausal relationships, which span longer distances in sentences, bene-fited significantly more from example phrases than either of the other treatments.

These findings suggest that a query interface in which a user enters a word of interest and the sys-tem shows candidate grammatical relations aug-mented with examples from the text will be more successful than the baseline of simply naming the relation and showing gaps where the participating words appear. We gave participants a series of identification tasks. In each task, they were shown a list of sen-tences containing a particular syntactic relation-ship between highlighted words. They were asked to identify the relationship type from a list of four options. We presented the options in three differ-ent ways, and compared the accuracy.

We chose Amazon X  X  Mechanical Turk (MTurk) crowdsourcing platform as a source of study par-ticipants. The wide range of backgrounds pro-vided by MTurk is desirable because our goal is to find a representation that is understandable to most people, not just linguistic experts or programmers. This platform has become widely used for both obtaining language judgements and for usability studies (Kittur et al., 2008; Snow et al., 2008). Our hypothesis was:
To test it, participants were given a series of identification tasks. In each task, they were shown a list of 8 sentences, each containing a particu-lar relationship between highlighted words. They were asked to identify the relationship from a list of 4 choices. Additionally, one word was chosen as a focus word that was present in all the sen-tences, to make the relationship more recognizable ( X  X ife X  in Figure 1).

The choices were displayed in 3 different ways (Figure 1). The baseline presentation (Figure 1a) named the linguistic relation and showed a blank space with a pink background for the varying word in the relationship, the focus word highlighted in yellow and underlined, and any necessary addi-tional words necessary to convey the relationship (such as  X  X f X  for the prepositional relationship  X  X f X , the third option).

The words presentation showed the baseline de-sign, and in addition beneath was the word  X  X xam-ples: X  followed by a list of 4 example words that could fill in the pink blank slot (Figure 1b). The phrases presentation again showed the baseline design, beneath which was the phrase  X  X atterns like: X  and a list of 4 example phrases in which fragments of text including both the pink and the yellow highlighted portions of the relationship ap-peared (Figure 1c). Method: We used a between-subjects design.
 The task order and the choice order were not var-ied: the only variation between participants was the presentation of the choices. To avoid the pos-sibility of guessing the right answer by pattern-matching, we ensured that there was no overlap between the list of sentences shown, and the ex-amples shown in the choices as words or phrases. Tasks: The tasks were generated using the Stanford Dependency Parser (De Marneffe et al., 2006) on the text of Moby Dick by Herman Melville. We tested the 12 most common gram-matical relationships in the novel in order to cover the most content and to be able to provide as many real examples as possible. These relationships fell into two categories, listed below with examples.
Clausal or long-distance relations:  X  Adverbial clause: I walk while talking  X  Open clausal complement: I love to sing  X  Clausal complement: he saw us leave  X  Relative clause modifier: the letter I wrote
Non-clausal relations:  X  Subject of verb: he threw the ball  X  Object of verb: he threw the ball  X  Adjective modifier red ball  X  Preposition (in): a hole in a bucket  X  Preposition (of): the piece of cheese  X  Conjunction (and) mind and body  X  Adverb modifier: we walk slowly  X  Noun compound: Mr. Brown
We tested each of these 12 relations with 4 dif-ferent focus words, 2 in each role. For example, the Subject of Verb relation was tested in the fol-lowing forms:  X  (Ahab, ) : the sentences each contained  X  (captain, )  X  ( , said) : the sentences each contained  X  ( , stood)
To maximize coverage, yet keep the total task time reasonable (average 6.8 minutes), we divided the relations above into 4 task sets, each testing recognition of 3 different relations. Each of rela-tions was tested with 4 different words, making a total of 12 tasks per participant.

Participants: 400 participants completed the study distributed randomly over the 4 task sets and the 3 presentations. Participants were paid 50c (U.S.) for completing the study, with an additional 50c bonus if they correctly identified 10 or more of the 12 relationships. They were informed of the possibility of the bonus before starting.

To gauge their syntactic familiarity, we also asked them to rate how familiar they were with the terms  X  X djective X  (88% claimed they could de-fine it),  X  X nfinitive X  (43%), and  X  X lausal comple-ment X  (18%). To help ensure the quality of effort, we included a multiple-choice screening question,  X  X hat is the third word of this sentence? X  The 27 participants (out of 410) who answered incorrectly were eliminated.

Results: The results (Figure 2) confirm our hy-pothesis. Participants in conditions that showed examples ( phrases and words ) were significantly more accurate at identifying the relations than participants in the baseline condition. We used the Wilcoxson signed-rank test, an alternative to the standard T-test that does not assume sam-ples are normally distributed. The average suc-cess rate in the baseline condition was 41%, which is significantly less accurate than words : 52%, (p=0.00019, W=6136), and phrases : 55%, (p=0.00014, W=5546.5).

Clausal relations operate over longer distances in sentences, and so it is to be expected that show-ing longer stretches of context would perform bet-Figure 2: Recognition rates for different types of relations under the 3 experiment conditions, with 95% confidence intervals. ter in these cases; that is indeed what the re-sults showed. Phrases significantly outperformed words and baseline for clausal relations. The av-erage success rate was 48% for phrases , which is significantly more than words : 38%, (p=0.017 W=6976.5) and baseline : 24%, (p=1.9  X  10  X  9 W=4399.0), which was indistinguishable from random guessing (25%). This is a strong improve-ment, given that only 18% of participants reported being able to define  X  X lausal complement X .

For the non-clausal relations, there was no sig-nificant difference between phrases and words , although they were both overall significantly bet-ter than the baseline (words: p=0.0063 W=6740, phrases: p=0.023 W=6418.5). Among these rela-tions, adverb modifiers stood out (Figure 2), be-cause evidence suggested that words (63% suc-cess) made the relation more recognizable than phrases (47% success, p=0.056, W=574.0)  X  but the difference was only almost significant, due to the smaller sample size (only 96 participants en-countered this relation). This may be because the words are the most salient piece of information in an adverbial relation  X  adverbs usually end in  X  X y X   X  and in the phrases condition the additional infor-mation distracts from recognition of this pattern. The results imply that user interfaces for syntactic search should show candidate relationships aug-mented with a list of phrases in which they occur. A list of phrases is the most recognizable presenta-tion for clausal relationships (34% better than the baseline), and is as good as a list of words for the other types of relations, except adverb modifiers. For adverb modifiers, the list of words is the most recognizable presentation. This is likely because Enlglish adverbs usually end in  X -ly X  are therefore a distinctive set of words.

The list of candidates can be ordered by fre-quency of occurrence in the collection, or by an interestingness measure given the search word. As the user becomes more familiar with a given re-lation, it may be expedient to shorten the cues shown, and then re-introduce them if a relation has not been selected after some period of time has elapsed. If phrases are used, there is a tradeoff between recognizability and the space required to display the examples of usage. However, it is im-portant to keep in mind that because the sugges-tions are populated with items from the collection itself, they are informative.

The best strategy, phrases , had an overall suc-cess rate of only 55%, although the intended user base may have more familiarity with grammatical relations than the participants did, and therefore may perform better in practice. Nonetheless, there is room for improvement in scores, and it may be that additional visual cues, such as some kind of bracketing, will improve results. Furthermore, the current study did not test three-word relationships or more complex combinations of structures, and those may require improvements to the design. We thank Bj  X  orn Hartmann for his helpful com-ments. This work is supported by National En-dowment for the Humanities grant HK-50011.

