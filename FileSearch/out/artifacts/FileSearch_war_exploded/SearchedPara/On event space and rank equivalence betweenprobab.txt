 Robert W. P. Luk Abstract This paper discusses various issues about the rank equivalence of Lafferty and Zhai between the log-odds ratio and the query likelihood of probabilistic retrieval models. It highlights that Robertson X  X  concerns about this equivalence may arise when multiple probability distributions are assumed to be uniformly distributed, after assuming that the marginal probability logically follows from Kolmogorov X  X  probability axioms. It also clarifies that there are two types of rank equivalence relations between probabilistic models, namely strict and weak rank equivalence. This paper focuses on the strict rank equivalence which requires the event spaces of the participating probabilistic models to be identical. It is possible that two probabilistic models are strict rank equivalent when they use different probability estimation methods. This paper shows that the query likelihood, applying assumptions 1 and 2 of Lafferty and Zhai. In addition, some statistical component language model may be strict rank equivalent to the log-odds ratio, and that some statistical component model using the log-odds ratio may be strict rank equivalent to the query likelihood. Finally, we suggest adding a random variable for the user information need to the probabilistic retrieval models for clarification when these models deal with multiple requests.
 Keywords Probabilistic models Event space Information retrieval 1 Introduction Robertson X  X  ( 2005 ) instructive paper cautions some of the mathematical derivations of language models for information retrieval using marginal probabilities (in Eq. 1 of Rob-ertson 2005 ) because the event space of these probabilities is different from the event space of the conditional probability. He further questions the event spaces of the earlier language model by Ponte and Croft ( 1998 ) and by Lafferty and Zhai ( 2003 ). To answer these questions, Roelleke and Wang ( 2006 ) show how event spaces of the different retrieval models are related via parallel derivations with a novel language model that uses a query likelihood ratio for ranking. In this paper, we believe that Robertson X  X  assumption about develop our understanding on the basis of Kolmogorov X  X  probability axioms and revisit the rank equivalence of Lafferty and Zhai ( 2003 ) in this perspective.

The rest of this paper is organized as follows. Section 2 derives the marginal probability based on Kolmogorov X  X  probability axioms and highlights the necessary condition that needs to be true for the marginal probability calculation to be correct. Section 3 clarifies Robertson X  X  example of stars and planets. We provide an interpretation of how the mar-ginal probabilities can be obtained from random sampling tuples in a cross-product event space. In addition, this section clarifies the rank equivalence of Lafferty and Zhai ( 2003 ). Section 4 discusses rank equivalence between two retrieval models, clarifies that there are discusses the impact of using different probability estimations on rank equivalence. Section 5 shows that the language model by Ponte and Croft ( 1998 ) and the language model by Lafferty and Zhai ( 2003 ) will be (strict) rank equivalent if assumptions 1 and 2 of Lafferty and Zhai ( 2003 ) are true. Section 6 discusses these assumptions. It shows that some statistical component language models are strict rank equivalent to the log-odds ratio, and some statistical component models are strict rank equivalent to the query likelihood. Section 7 introduces the topic random variable in the probabilistic retrieval models for clarification and for (pseudo) relevance feedback. Finally, Sect. 8 summarizes this paper. 2 Marginal probability derivation In this paper, probabilities are defined according to Kolmogorov X  X  axioms, namely: (a) Normalization axiom : p  X  K  X  X  1 where K is the event space and; (b) Non-negativity axiom : p  X  e 2 }  X  K  X  X 2 [0,1] where e is an event and } ( ) is the (c) Finite additivity axiom : p  X  a [ b  X  X  p  X  a  X  X  p  X  b  X  for all a , b in }  X  K  X  such that
For ease of discussion, we assume that all probabilities are discrete in this paper. We use uppercase letters to denote a set and lowercase letters to denote an element or an event. We further place a suffix after p to indicate the event space K of the probability p as follows p  X  X  : If K  X  D Q ; where 9 is the Cartesian product, then p K  X  X  will be the same as p
D Q  X  X  : Since the Cartesian product is commutative, p D Q  X  X  and p Q D  X  X  are probabilities marginal probability of d in D because this probability does not specify a particular query q follows that any event e in K C has zero probability (i.e., p K  X  e  X  X  0). Therefore, we can write an alternative probability of events that are defined in C as p C ( a ) where a is an event in C . This shows that it is possible to equate probabilities of different event spaces pro-vided one event space is a subset of the other. The event space K and event subspace C can be denoted by two random variables, say R 1 and R 2, that take values in those event spaces where one event space is a subset of the other. However, Bayes X  theorem rests on the marginal probability calculation which is shown to be derived from the probability axioms as follows.

By the normalization axiom, we have p X ( X ) = 1, and p Y ( t ) = p X ( X ) 9 p Y ( t ). Since the occurrence of X is independent of t (because X always occurs independent of t as p ( X ) = 1), p X ( X ) 9 p Y ( t ) is the joint probability p X Y  X  X ; t  X  of t and X , i.e., Using the finite additivity axiom, the (marginal) probability p Y ( t ) of event t can be expressed as: Based on Eq. 1, the marginal probability calculation does not depend on any uniform probability distribution assumption. Instead, Eq. 1 depends on the following necessary condition to be true: Necessary condition 1 For any two different events, s 1 and s 2 in X (that is exhaustively partitioned), s 1 \ s 2  X ; where X is used as in Eq. 1.

Equation 1 always holds for any event space X that cross-products with the event space Y provided that p X ( X ) = 1, which is always true by the normalization axiom. Hence, the only condition of concern is necessary condition 1 when developing retrieval models using Eq. 1.
From the point of view of probabilistic modeling (Robertson 2003 ), it is possible that some hidden variable (say R 1 ) is unaccounted for in the current model. The event space X of this hidden variable can combine with the event space Y of the current probabilistic model in order to form a new probabilistic model that is defined over the event space X 9 Y . The probabilities f p X Y  X  X g of the existing model become the marginal probabilities of the new probabilistic model. Robertson ( 2005 ) found that if the (marginal) probabilities of the current and the new models are uniformly distributed (subject to some structural constraint), then inconsistencies arise when using Eq. 1 to obtain the marginal probabili-ties, compared with assigning uniform marginal probabilities. However, as we explain later, assigning uniform probabilities is not a logical necessity where as event spaces can always be structured as lists of tuples or equivalently as trees. Therefore, we believe that the problem occurs because multiple probability distributions are assumed to be uniform and not solely because of different event spaces.

It should be noted that the concern of possible problematic ranking caused by the uniform probability distribution assumption as discussed in (Robertson 2005 ) is not unjustified because some past language models do assume that prior probabilities are uniformly distributed. For example, Berger and Lafferty ( 1999 ) considered p D Q  X  d  X  as the prior probabilities which were thought to be uniform. However, they also indicated that this probability might vary depending on document length. Therefore, p D Q  X  d  X  is not necessarily uniform for some language models. Similarly, one version of the relevance language model by Lavrenko and Croft ( 2001 ) also assumed that a prior for the document models is uniform (i.e., Method 2: conditional sampling). However, the other version of the relevance language model does not make such a uniform prior assumption (i.e., Method 1: independent and identically distributed sampling). Therefore, there is a need to investigate this issue in a more thorough manner.
 3 Clarification This section clarifies the issues related to the event space (Robertson 2005 ) and the rank equivalence of Lafferty and Zhai ( 2003 ). 3.1 Event space Robertson ( 2005 ) argues that the event space Y of p Y ( t ) is not the same as the event space Therefore, he cautioned those who worked in developing language models for information retrieval. However, it should be noted that both the event space Y for p Y ( t ) and the event This observation enables us to obtain the marginal probability p Y ( t ) from the more detailed tuple events in both X and Y as follows.

We provide an interpretation of the marginal probability based on random sampling similar to that of Robertson ( 2005 ), but we do not require the marginal probabilities to be evenly distributed (although sometimes they can be). Using Robertson X  X  example, let an stars and Y is a set of planets. In this paper, we ignore the magnetic field in (Robertson 2005 ) because if we know the particular star/planet, then we know whether the star/planet has or has not a magnetic field. Let us randomly pick event tuples from an urn U that tuples are equally likely to be randomly selected. The marginal probabilities for events in Y the tuples from U and ignoring their first elements (i.e., X ,or s 1 and s 2 ) of the selected selected tuples. Therefore, we may obtain the marginal probabilities based on randomly sampling tuples over the cross product space of X and Y , without the need to sample the subspace X first and then Y , or vice versa (although we can do so).

As in Robertson ( 2005 ), the previous example shows that the probability p X Y  X  t  X  X  1 = 3 is based on randomly picking a tuple of star and planet with equal likelihood. However, Robertson ( 2005 ) indicated that this probability calculated using the marginal probability will not be 1/3 if we assume that randomly picking a star is equally likely, and if randomly calculation is based on Kolmogorov X  X  axioms, and we assume that necessary condition 1 holds, the calculation must be accepted as ground truth. The only possibility to reconcile p
X Y  X  t  X  and its marginal probability calculation using Eq. 1 is not to assume that randomly picking a star is equally likely nor randomly picking a planet given a star is necessarily equally likely. In fact, there is no logical necessity that probability distributions are uni-form. Language models typically leave some of the probability distributions unspecified and later estimate the probability distributions rather than assuming the distributions are uniform. While many language models are Bayesian probabilistic models, the Bayesian prior probabilities (of these language models) are not necessarily uniformly distributed.
We summarize our discussion using probability generation trees as in Fig. 1 that shows three different examples. Figure 1 a is Robertson X  X  example where p X Y  X  t  X  is not the same as calculating it based on the marginal probability using Eq. 1. Figure 1 b is our example that is consistent with the marginal probability calculation using Eq. 1, but the probability of picking a star randomly is not uniformly distributed (as explained earlier). Figure 1 cis our other example that is consistent with the marginal probability calculation using Eq. 1, but the probability of picking a planet randomly is not uniformly distributed. This shows that by not requiring that all probability distributions be uniformly distributed, the problem raised by Robertson may not occur. In fact, there is no logical necessity that the probability distributions are uniformly distributed.

Apart from assuming probabilities are uniformly distributed, there is a possibility that asserting assumptions may lead to data inconsistencies for some probability distributions (but not necessarily for all possible probability distributions). If we take Robertson X  X  example (i.e., planets and stars), it is possible that estimating the probabilities resulted in uniform probability distributions and data inconsistencies can arise. The underlying problem seems to be the assumptions made as indicated earlier by Cooper ( 1995 ), instead of the event space as Robertson suggested, because the corollary, lemma and theorem derived from the probability axioms are true once the axioms are accepted while the assumptions can be invalid. For example, if our model assumes that p X Y  X  s  X  X  1 = 2 and p frequency estimate of p X Y  X  t  X  is 1/3, then there are data inconsistencies between the predicted and actual values. We believe that the problem of data inconsistencies is our different event spaces. In summary, it seems more appealing to question whether the assumptions asserted lead to inconsistencies for some probability distributions. Let us start by revisiting the rank equivalence claimed by Laffery and Zhai ( 2003 ). 3.2 Rank equivalence of Lafferty and Zhai Figure 2 depicts the claim by Lafferty and Zhai ( 2003 ) on the rank equivalence between the query likelihood and the log-odds ratio (i.e., between Box 1 and 2 in Fig. 2 ). Sepa-rately, these probabilistic ranking functions derive the corresponding operational ranking functions of their statistical component models, so they belong to the probabilistic models at a level higher (or more general) than the statistical component model. These probabi-listic models are more general in the sense that they have fewer details (e.g., assumptions and component specifications) than the statistical component models. Also, they may be related to the probability ranking principle (Robertson 1977 ) that forms the unified basis for ranking documents [even for interactive retrieval (Fuhr 2008 )] and for modeling the evaluation of ranked lists (Wu et al. 2007 ).

Lafferty and Zhai ( 2003 ) claimed that the statistical component models of the log-odds ratio are not rank equivalent to the statistical component language model (i.e., between Box 3 and 4) because their probabilities are estimated differently. Apart from the issues about probability estimation for establishing rank equivalence, the derivations and rank equivalence relation assert different sets of assumptions. The impact of asserting multiple sets of assumptions is important because the rank equivalence claimed by Lafferty and Zhai ( 2003 ) will be purely theoretical if there does not exist a statistical component model that is rank equivalent to both the log-odds ratio and the query likelihood. In other words, if Box 1, 2 and 4 are not rank equivalent), or vice versa (i.e., Box 2, 1 and 3 are not rank equivalent), then the rank equivalence for the higher probabilistic models has no direct practical significance. This practical issue about rank equivalence is discussed in Sect. 6. 4 Rank equivalence Showing two retrieval models are rank equivalence is an important theoretical task as it may avoid the use of Eq. 1 without the need to assert necessary condition 1. Its practical significance may imply that (a) there is no need to compare such models for better retrieval effectiveness, and that (b) the model that may be carried out by a more time-space efficient algorithm is preferred over slower ones. In this section, we discuss a motivating example of rank equivalence, identify different types of rank equivalence relations, and discuss the impact of different probability estimation methods on them. This discussion differs from the equivalence of BIM and the novel language model by Roelleke and Wang ( 2006 ) because (1) the BIM and their language model use the same probability estimation method (i.e., relative frequency), (2) their language model ranks documents by a ratio of two query assert assumptions of Lafferty and Zhai, and (4) their equivalence relation makes an assumption that the contribution to the retrieval status value from relevant documents is constant.
 4.1 Motivating example Lafferty and Zhai ( 2003 ) use rank equivalence to reconcile different probabilistic models. For example, the two sides of the probabilities in the following equation are related by the definition of conditional probability, where X  X  D Q R (as in Wu et al. 2007 ), D is a set of documents, Q is a set of queries, r is the relevance value, r is the non-relevance value, R  X f r ; r g ; d is a document in D , and evaluation model (Wu et al. 2007 ) for the probability ranking principle (PRP as in Rob-et al., 1999 ), and (3) this rank equivalence illustrates that assumptions 1 and 2 of Lafferty reconciling two different probabilistic retrieval models.
 ingly, p X  X  d j q ; r  X  is rank equivalent (Wu et al. 2007 ) to the log-odds ratio of the RSJ model some language models because p X  X  d ; q  X  of these language models is not a constant. Otherwise, p X  X  q j d  X  becomes problematic for ranking as it is independent of q . This rank equivalence instead of the equality as follows.

Suppose that the probability p X  X  d j q ; r  X  on the left hand side (LHS) of Eq. 2 is estimated by one model with a set S 1 of assumptions and the probability on the right hand side (RHS) of Eq. 2 is estimated by another model with another set S 2 of assumptions. While the two probabilistic models may not assign uniform probability distributions, it is possible that, for some data set, the probability distributions estimated by the two retrieval models can lead to inconsistencies as suggested by Robertson ( 2005 ). In general, assuming a certain probabilistic relationship holds can lead to the exclusion of certain data distributions. In other words, some data distributions contradict with the assumptions asserted. This problem does not appear in the derivation by Lafferty and Zhai ( 2003 ) because the log-odds ratio is equivalent to query likelihood of the language model on the basis of producing the same ranking output, i.e., the orderings of the probabilities/similarities on both sides of the equation are the same. Instead of Eq. 2 in the previous instructive example, we consider an alternative type of rank equivalence between the evaluation model (Wu et al. 2007 ) for PRP and the language model where X is the event space as in (Wu et al. 2007 ), H is the event space of a language 2003 ). Because these are two different event spaces, the RHS of the previous relation may relate to the PRP because only the evaluation model assumes that p X  X  d ; q  X  is a constant, and not the language model on the RHS. We call such rank equivalence between two different probabilistic models defined over two different event spaces weak rank equiva-lence. Weak rank equivalence can be identified by observing that the event spaces on its two sides are different.
 For illustration, Table 1 shows an example of rank equivalence between Model A and Model B. Here, we suppose that Model A and Model B use different methods to estimate documents. In this example, the probabilities of Model A for ranking are different from the corresponding probabilities of Model B for ranking, but the assigned ranks of the documents are the same for both Model A and B. For Model B, p H  X  q ; r  X  is not necessary for ranking, but it is included here for clarity of presentation. For claiming that Model A is rank equivalent to Model B, the ranking using Model A should be the same as that methods that lead to rank equivalence between Model A and B, for all queries and for all collections.

One possible approach that may guarantee two probabilistic models are rank equivalent for all queries and for all collections assumes that the probabilities on both sides of a rank equivalence relation are derived from a single event space of an underlying (random) experiment as suggested by Robertson ( 2005 ). We call this type of rank equivalence strict rank equivalence which can be identified easily because the probabilistic models partici-pating in the rank equivalence relation have the same event space. Even when the probabilistic models are strict rank equivalent, there may be an additional problem that these models estimate probabilities differently from the same random experiment as these different probabilistic models operating with the same event space, will these probabilistic models not necessarily be rank equivalent? 4.2 Problem with different probability estimation methods To answer the previous question, one method to show that these models are strict rank equivalent is to prove such equivalence mathematically by finding how the probability probability that is estimated by additive smoothing (e.g., Lidstone 1920 ) is denoted by the superscript a . In Eq. 2, suppose that the probability on the LHS is estimated by relative frequency and the probabilities on the RHS are estimated by additive smoothing. Since these probabilities estimated differently are not expected to be the same, they are not expected to be strict rank equivalent. However, when we want to claim that the language model is rank equivalent to the evaluation model (Wu et al. 2007 ), they are required to be strict rank equivalent by demanding The probabilities estimated by additive smoothing (e.g., Lidstone 1920 ) are linearly related to their relative frequency estimates: where f ( x ) is the occurrence frequency of x , N is the total frequency, V is the vocabulary g = d /( N + d V ). The RHS of relation 3 can be rewritten as p  X  d ; r  X  is not rank equivalent to p f X  X  d j q ; r  X  in general. However, for some special case, relation 3 holds. If p f X  X  d ; r  X  is a constant, then Here, we want to show that even different estimation methods may lead to strict rank a constant) does not invoke the assumptions of Lafferty and Zhai, and it may not be realistic in practice. While it is obvious that two different estimation methods may lead to different ranking, it might be possible for some (unknown) probabilistic models estimated using different estimation methods to be strict rank equivalent. Given this possibility, there may be a reason other than the use of different probability estimation methods, which explains why the statistical component language model is not strict rank equivalent to the statistical component model of the log-odds ratio. 4.3 Equivalence between probabilistic and statistical component models When a statistical component model is derived from a probabilistic model at a higher level, such a statistical component model may have data inconsistencies (e.g., Cooper 1995 ). For example, p X  X  d j q ; r  X  can be rewritten in terms of its components where a document is rewritten as a set of n attributes from A d 1 to A dn . If we assume that attributes are conditionally independent, then While we assumed identity 4 holds, it may not hold in practice. We clarify this problem using a schematic diagram as shown in Fig. 3 . More specifically, probabilistic model A and its statistical component version B in Fig. 3 correspond to the LHS and the RHS of identity 4, respectively. Suppose model A directly measures p X  X  d j q ; r  X  by relative frequency counting, and suppose method 1 of model A assigns this measured probability as the probability on the LHS of identity 4. Suppose model B measures p X  X  A di j q ; r  X  by relative cases, the following does not hold: This is partly because A common remedy is to use Bayes X  theorem (as done for language models, e.g., Hiemstra 2002 ): However, this assumes that necessary condition 1 holds for different documents. An alternative without assuming that such a condition holds uses strict rank equivalence to link these probabilities: Despite that we use the same probability estimation method, and we use a probabilistic model and its derived statistical component version, there will still be no guarantee that the probabilities on its LHS and calculate the derived probability ratio using measured prob-abilities on its RHS. To avoid the inconsistency between the probabilistic model and its statistical component model, the probability of the former probabilistic model is assigned with the probability derived from its latter statistical component model. For our previous example, the probability on the LHS of identity 4 is not estimated from the event space even though it can be done. Instead, this probability is assigned with the calculated probabilities that are derived from the measured probabilities on the RHS of identity 4. In certain event will happen. This option to avoid inconsistencies by probability assignment is not available when two statistical component models are strict rank equivalent. This is because the two statistical component models need to estimate their probabilities from the same event space. This suggests that even if the same probability estimation method is used for both statistical component models, these models may not be strict rank equivalent. 4.4 Equivalence between statistical component models Let us discuss an instructive example to appreciate the difficulty of making two statistical component models rank equivalent. Suppose we have two such models for the LHS and RHS of Eq. 2: where A qi is the i -th attribute of the query q . The probabilities on the LHS of the above strict rank equivalence relations are the probabilities of the probabilistic models without any specified probability estimation methods. The probabilities on the RHS of the above strict rank equivalence relations are the measured probabilities that are estimated by the relative frequency method f . When these probabilities are substituted into equation 2, and the equality is changed to strict rank equivalence, i.e., it becomes difficult to prove the above relation is true for all queries and for all collections. The reason is not because different estimation methods are used. Actually, these estimation attribute but of different objects. Even if we make the same attributes of different objects to these two probabilities will be different. For the conditional probabilities on the LHS, we count the frequencies for a single query q , where as we count the frequencies of a single document d for the conditional probabilities on the RHS. Consequently, it is difficult to collections. This discussion will be inconsistent with the remark by Laffery and Zhai ( 2003 ) about  X  X  X he component models (that are) estimated quite differently X  X  (added our estimation methods used (e.g., additive smoothing (Lidstone 1920 ) or absolute discounting differently X  X  means getting different probability values because of the use of different measured probabilities and/or different probability estimation methods.

Roelleke and Wang ( 2006 ) show that it is possible to create a novel statistical component language model using query likelihood ratio that is rank equivalent to the BIM without using the rank equivalence of Lafferty and Zhai ( 2003 ). This is done using models that employ the same probability estimation methods. Is it possible that two different statistical component models will be strict rank equivalent to each other if they use different probability estimation methods? To illustrate this possibility, suppose we are given that is there a probability estimation method b such that Suppose the probability estimation method, b , is related to its corresponding relative frequency estimation method F : where c is a normalization constant and k is a parameter of this estimation method. If k [ 1, then smaller relative frequency probability estimates will be even smaller. This reduces the effect of over-estimation by the relative frequency estimation method (i.e., the maximum likelihood estimator) when the frequency count is small. When the frequency count is zero, this method maintains that the probability is zero. To avoid zero probabil-ities, 0.5 is added to the frequency counts and the total frequency as in the binary independence model (BIM of Robertson and Spa  X  rck 1976 ), i.e., Taking the logarithm, the probabilities estimated by these two methods are related: Using this equality, the query likelihood estimated by method b is rank equivalent to the query likelihood estimated by relative frequency, i.e., In general, we derive This illustrates that it is possible that two statistical component models are rank equivalent even though the probability estimation methods are different. Therefore, different proba-bility estimations do not necessarily lead to different ranking.
Strict rank equivalence is related to weak rank equivalence under some special cir-cumstances. Suppose we have two retrieval models, A and B . They rank documents by the space X : The following obvious remark can be observed:
For H X ; p H ; B  X  y  X  is a marginal probability since y is in X and so it specifies only a under specific conditions. 5 Combining other models In this section, we show that the language model by Ponte and Croft ( 1998 ) is rank equivalent to the language model in Lafferty and Zhai ( 2003 ) using their assumptions 1 and 2. This enables us to deal with both types of language models together in subsequent sections. In addition, we show that the log-odds ratio is rank equivalent to minus the probability of non-relevance (Wu et al. in press ) that relates to the TF-IDF term weights.
As Lafferty and Zhai ( 2003 ) have already shown, both the log-odds of the RSJ model and the query likelihood of language models can be thought of as estimating and/or ranking on the basis of the log-odds ratio, O X  X  r j q ; d  X  (Fuhr 1992 ), that is defined over the event space X : Lafferty and Zhai ( 2003 ) further show that where  X  rank denotes the rank equivalence relation. Equation 6 assumes that the following two statistical (conditional) independence assumptions (Lafferty and Zhai 2003 ) hold without asserting any assumption of uniform probability distributions: Assumption 1 p X  X  d ; q j r  X  X  p X  X  d j r  X  p X  X  q j r  X  : Assumption 2 p X  X  d ; r  X  X  p X  X  d  X  p X  X  r  X  :
For binary relevance, the following holds: Together with assumption 2, the previous condition logically implies p X  X  d ; r  X  X  p X  X  d  X  p  X  r  X  ; because, from Eq. 7, we have: Hence, Eq. 8 is a consequence of assumption 2 in Lafferty and Zhai ( 2003 ).

The query likelihood function (Lafferty and Zhai 2003 ) is defined as p X  X  q j d ; r  X  : This has been used as the basis of ranking by a number of language models (e.g., Miller et al. 1999 ). Alternatively, another ranking function, is also commonly found in a variety of language models (e.g., Ponte and Croft 1998 ; Hiemstra 1998 ; Berger and Lafferty 1999 ; Song and Croft 1999 ; Hiemstra 2000 ; Spa  X  rck et al. 2003 ; Zhai and Lafferty 2004 ; Gao et al. 2004 ) for information retrieval. We will show that these two ranking functions of language models are rank equivalent to each other if assumptions 1 and 2 are true. Given that: we rewrite the query likelihood: Applying Eq. 8, the previous equation is simplified to Since the second term on the RHS of the previous equation only depends on the query q , we simplify the previous equation further using strict rank equivalence, Since logarithm is an order-preserving transformation, it follows that the Lafferty and Zhai model ( 2003 ) and Ponte and Croft model ( 1998 ) are strict rank equivalent with the log-odds ratio: provided that assumptions 1 and 2 hold (an alternative derivation is shown in Appendix I), and Eq. 9 holds. Even though the relevance random variable does not appear in the Ponte and Croft ( 1988 ) model, the information in the relevance random variable might be embedded in the implicit assumptions of the model.

Recently, Wu et al. ( in press ) showed that the TF-IDF term weight is derived from the strict rank equivalent to the log-odds ratio: given that p X  X  r j d ; q  X  X  p X  X  r j d ; q  X  X  1 (Eq. 1.1. in Laffery and Zhai 2003 ). 6 Tackling the assumptions Assumptions 1 and 2 bring the work by Lafferty and Zhai ( 2003 ) and by Ponte and Croft ( 1998 ) on the same ground of the log-odds ratio and it is time to question whether these assumptions are reasonable. Intuitively, assumption 2 is reasonable since one does not expect that documents and relevance are statistically dependent without specifying the marginal probabilities, p X  X  d  X  and p X  X  r  X  : Note that assumption 2 does not state the like-lihood of retrieving a document is uniformly distributed. For example, documents that have more terms are more likely to be matched and therefore retrieved (but whether these documents are relevant or not are unknown). Although assumption 2 implies that p marginal probability that is aggregated for all queries given a document d , so this prob-ability has no relationship with a particular query q . It should not be confused with p ( L | d ) of the BIM (Spa  X  rck et al. 2000 ) where L maps to relevance. This is because BIM is defined probability p X  X  r j d  X  X  : Assumption 1 is specified by conditional independence that is more complex to justify. First, we note that many probabilistic retrieval models have asserted assumption 1 to hold (e.g., Yu and Salton 1976 ; Robertson et al. 1982a , b ), including the binary independence assumptions 1 and 2 together does not fall into the data inconsistency problem discussed by Cooper ( 1995 ) and discovered by Robertson ( 1974 ) because the conditional probability in assumption 2 here only assumed the independence between documents and relevance, instead of documents and queries (as in Cooper, 1995 ). Second, if the following assumption holds: Assumption 3 p X  X  d ; q ; r  X  p X  X  r  X  X  p X  X  d ; r  X  p X  X  q ; r  X  then we can derive assumption 1 instead of asserting it. This is obtained by dividing p  X  r  X  2 on both sides of assumption 3, which does not need to assume that p R  X  r  X  [ 0 : For the probabilistic models at a higher level (Fig. 2 ), we show that Sufficient condition 1 Assumptions 1 and 2 of Lafferty and Zhai are sufficient condi-tions for the rank equivalence between the log-odds ratio and the query likelihood.
Since the rank equivalence between the log-odds ratio and the query likelihood is already established by Lafferty and Zhai the remaining task is to show that these assumptions are not necessary conditions. This is done by establishing the strict rank equivalence using a different set of assumptions (that are mentioned as uniform distribu-tion by Robertson 2005 ): Assumption 4 p X  X  d ; q  X  is a constant (i.e., uniformly distributed).
 Assumption 5 p X  X  d ; r  X  is a constant (i.e., uniformly distributed).
 relation is applicable to a special form of the hidden Markov language model (HMLM) of However, these two assumptions are not applicable to language models (e.g., Ponte and Croft 1998 ) which rank documents by p X  X  q j d  X  : This is because assumption 4 implies that Eq. 10 does not hold as the document ranking is problematic (i.e., it assigns the same value for document ranking across different queries) for such language models. For BIM, this assumption does not cause any problems, because p X  X  d ; q  X  is a marginal probability combining the probability of relevance and the probability of non-relevance.

Lafferty and Zhai ( 2003 ) have claimed that while probabilistically the log-odds is rank equivalent to the query likelihood, statistical component models of the log-odds ratio and the query likelihood are not rank equivalent. In their words, ... the two approaches (based on the log-odds or the query likelihood) are not equivalent from a statistical point of view, since the component models are estimated quite differently. (page 2, Lafferty and Zhai 2003 ) (added our bracketed text in the above quotation). Lafferty and Zhai ( 2003 ) do not mention whether the statistical component language model (e.g., Berger and Lafferty 1999 ) can be derived from the log-odds ratio at a higher probabilistic modeling level (i.e., Box 1, 2 and 4 in Fig. 2 ). Such derivations are important for claiming that the statistical component mention whether the statistical component model (e.g., BIM [Robertson and Spa  X  rck 1976 ]) modeling level (i.e., Box 2, 1 and 3 in Fig. 2 ). Such derivations are important for claiming that the statistical component models of the log-odds ratio are strict rank equivalent to the query likelihood. These derivations require the assumptions by Lafferty and Zhai ( 2003 )to be asserted with the assumptions of the related statistical component models.

Let us focus on the strict rank equivalence between the log-odds ratio at the higher probabilistic level and the statistical component language models. We identify at least three possible claims about such a strict rank equivalence relation: Claim 1 If assumptions 1 and 2 by Laffery and Zhai ( 2003 ) are true, then no statistical component language models are strict rank equivalent to the log-odds ratio that is at the higher probabilistic level.
 Claim 2 If assumptions 1 and 2 by Laffery and Zhai ( 2003 ) are true, then all statistical component language models are strict rank equivalent to the log-odds ratio that is at the higher probabilistic level.
 Claim 3 If assumptions 1 and 2 by Laffery and Zhai ( 2003 ) are true, then some statistical higher probabilistic level.

We argue for claim 3 by showing that claims 1 and 2 are not tenable. First, we assert that claim 1 is true and disprove it by a counter example. For ranking using the language model by Lafferty and Zhai ( 2003 ), we estimate the probability p X  X  q j d ; r  X  and assume their assumptions 1 and 2 hold so that the language model corresponds to the log-odds ratio. Since calculation using Eq. 1, i.e., Since only p X  X  q ; d ; r  X  is estimated from data and the others are derived from it based on the assumptions, there are no problematic rankings (unlike the planet and star example of Robertson). If we further simplify the above (see Appendix I) and replace the above ranking function by the one in (Ponte and Croft 1998 ) (i.e., log p X  X  q j d  X  X  ; then we need to simply estimate p X  X  q ; d  X  from the data and derive the marginal probability p X  X  d  X  using Eq. 1 based on the estimated joint probabilities f p X  X  q ; d  X g ; i.e., p X  X  d  X  X  assuming that necessary condition 1 holds in this case.

Similarly, to show that claim 2 is not tenable, we assert that it is true, and find a counter equivalent to the query likelihood given assumptions 1, 2 and 5 hold as follows. By Eqs. 10, 11 and assumption 5, we deduce that The previous relation is rewritten as Since p X  X  r ; d ; q  X  X  p X  X  d ; r ; q  X  ; we deduce that where p X  X  q  X  is a marginal probability. By the above relation and by Eq. 10 that asserts assumptions 1 and 2 of Lafferty and Zhai hold, we obtain
This ranking is problematic because it is only dependent on the document and inde-pendent of the query (i.e., assigning the same rank to a document for all queries). If this special form of the HMLM is strict rank equivalent to the log-odds ratio via assumptions 1 and 2 of Lafferty and Zhai, then the resultant ranking will be problematic as the ranking is query independent. This shows that claim 2 does not hold. Since both claim 1 and 2 do not hold, claim 3 holds.

When deriving the strict rank equivalence between the statistical component models of the log-odds ratio and the query likelihood, assumptions 1 and 2 by Lafferty and Zhai are asserted with the model-specific assumptions of these statistical component models. Again, there are three possible claims: Claim 4 If assumptions 1 and 2 by Laffery and Zhai ( 2003 ) are true, then no statistical component models of the log-odds ratio are strict rank equivalent to the query likelihood that is at the higher probabilistic level.
 Claim 5 If assumptions 1 and 2 by Laffery and Zhai ( 2003 ) are true, then all statistical component models of the log-odds ratio are strict rank equivalent to the query likelihood that is at the higher probabilistic level.
 Claim 6 If assumptions 1 and 2 by Laffery and Zhai ( 2003 ) are true, then some statistical component model of the log-odds ratio is strict rank equivalent to the query likelihood that is at the higher probabilistic level.

When all statistical component models (like the BIM) of the log-odds ratio are defined for single queries, such models are making the following singleton query assumption in the event space, X : Assumption 6 Q = { q }.
 result, the log-odds ratio becomes:
Therefore, claim 5 does not hold. Claim 4 will hold if the statistical component models of the log-odds ratio are defined for single queries. However, claim 4 will not hold if we extend the statistical component models (e.g., the BIM) of the log-odds ratio for multiple queries as in Lafferty and Zhai ( 2003 ). In the case of the BIM, we use a group of such BIMs for the set of queries such that each query is assigned with a BIM. Since both claim 4 and claim 5 do not hold, claim 6 holds. In summary, we conclude that the rank equivalence claimed by Lafferty and Zhai ( 2003 ) has immediate practical significance because some statistical component language model is rank equivalent to the log-odds ratio, and some statistical component model of the log-odds ratio is rank equivalent to the query likelihood. 7 Topic variable In Sect. 2, we have shown that it is possible to enlarge the event space by performing a cross-product with other event spaces. This enlargement of the event space is the same as the problem of missing (hidden) variables. For probabilistic information retrieval, one variable that seemed to be missing is the  X  X  X onceptual X  X  user information need. When we information need. It is possible that many different queries are referring to the same user information need (e.g., Robertson 2005 ; Zhai and Lafferty 2006 ). For instance, the TREC user information need (called a topic) in ad hoc retrieval is specified by multiple types of queries (e.g., title queries, concept queries and narrative queries). We believe that the user information need is an important hidden variable because it can clarify the confusion between query text and the identification of the user information need.
 Many of the probabilistic retrieval models deal with a single user information need (e.g., BIM) and it does not seem to be necessary to model it explicitly because the query representing it is already unique. This becomes important when reconciling different retrieval models when one model deals with a single request and another model deals with multiple requests. From the perspective of probabilistic modeling, if the probabilistic retrieval model needs the marginal probabilities without query dependence (e.g., p X  X  d ; r  X  X  ; these marginal probabilities are calculated using Eq. 1 that requires necessary condition 1 to hold. This condition is satisfied by making each query text to be distinct from each other. This is done by adding an identifier for the user information need to the query. Apart from modeling, a web query may contain different kinds of information (like session identifiers, user profiles, etc.). In this case, the distinction between a topic and a query may be helpful because many different queries may be generated for the same user information need, and because different user information need may generate the same query (i.e., when the query text is ambiguous). Furthermore, documents are considered to be relevant to the user information need and not on the basis of being relevant to a piece of query text. Based on this, we show later that the introduction of the user information need into the probabilistic model enables language models to perform (pseudo) relevance feedback which has been identified to be difficult before (Robertson 2005 ).

For presentation clarity, we treat the user information needs as topics and we propose to add a topic set T so that the event space is: Equation 10 is considered as a notation convenience of Eq. 12: by taking away the particular topic t and the topic set T in Eq. 12. For Eq. 12 to hold, we need to assert assumption 2 and we need to modify assumption 3 to assumption 7: Assumption 7 p W  X  d ; q ; r ; t  X  p W  X  r  X  X  p W  X  d ; r  X  p W  X  q ; r ; t  X  :
The above assumption does not imply that any of the above probability distributions are uniform. Details of the derivations to obtain Eq. 12 are in Appendix II.

The topic variable bridges the difference in representing the query by the RSJ model and the language models as follows. According to Robertson ( 2005 ), the query in the RSJ model is supposed to be a topic identifier that uniquely identifies the topic (although not explicitly written down) where as the query in the language model is a feature vector or a text string. We reconcile these differences by adding the topic in the language models and the tuple ( q , t ), which is a combination of the query q and the topic t in Eq. 12. This combination provides a unique value to identify the particular topic as required by the RSJ model. This unique value for each query ensures that the necessary condition 1 for calculating marginal probabilities holds. For example, this is needed for estim ating the marginal probability, p W  X  d  X  X  P model by Ponte and Croft ( 1998 ).

Based on Eq. 12, (pseudo) relevance feedback for language models is the same as the usual (pseudo) relevance feedback based on the vector space model. The language model ranks on the basis of the expanded query q 0 by reformulating the initial query q using the t , the same set of relevance is used for both query q and query q 0 . This facilitates a single topic to associate with any number of pieces of query text. Conversely, a piece of query text can associate with any number of topics since a piece of query text can be ambiguous. In practice, the topic variable is already used in open IR evaluation workshops (e.g., TREC, INEX and NTCIR). A query text string is the concatenation of the topic identifier with the sequence of query terms. When this query text string is processed into a vector, the appear in any documents, it does not match with any documents and it does not affect document ranking. In practice, most query processing modules in IR systems filter the topic identifiers.

For notation convenience, it is possible to drop T in the probabilistic retrieval models as in the past because it is clear that the probabilities are defined for a particular topic, and that relevance is defined in terms of the topic and not in terms of the query. With the advent of more sophisticated web query processing, the topic random variable appears to be probabilistic retrieval models. 8 Summary It seems that if we accept Kolmogorov X  X  probability axioms and if necessary condition 1 holds, then the marginal probability will follow immediately. However, Robertson ( 2005 ) highlights the significance of the event space when reconciling different probabilistic models by rank equivalence (Lafferty and Zhai 2003 ). In this paper, we highlight that, models need to be questioned as well. Apart from looking at event spaces, it seems that it is appealing to question whether multiple probability distributions can be assumed to be uniformly distributed simultaneously without causing the probabilistic models to produce problematic ranking. We have also shown that the probability of relevance (Robertson 1977 ) can be considered as the common ground (as in Eq. 10) of the earlier language model by Lafferty and Zhai ( 2003 ), as well as the earlier language model by Ponte and Croft ( 1998 ) that requires assumptions 1 and 2 to hold (provided that suitable probabilities assumptions of Laffery and Zhai are true) the relevance random variable may be implicit in the ranking formula. Assumption 1 is mentioned in previous retrieval model design (e.g., Robertson et al. 1982b ) and it can be replaced by assumption 3 that does not require any additional condition to hold. Assumption 2 seems intuitively plausible when its proba-bilities are marginal probabilities. We show that the rank equivalence claimed by Lafferty and Zhai ( 2003 ) has practical significance because some statistical component language model is strict rank equivalent to the log-odds ratio, and some statistical component model of the log-odds ratio is strict rank equivalent to the query likelihood. In this case, assumptions 1 and 2 are the sufficient conditions for the rank equivalence between the log-odds ratio and the query likelihood. While some of the earlier probabilistic models do not include the user information need (called the topic) as a random variable for notation convenience, we suggest adding the topic random variable in the probabilistic retrieval models for notation clarity when these models deal with multiple requests.
 Appendix I: Alternative derivation According to the Lafferty and Zhai ( 2003 ) model, the ranking formula (i.e., Eq. 1.18 in Lafferty and Zhai 2003 ) is: Appendix II: Derivations with the topic variable Starting with the log-odds ratio, we have: We assume that assumption 2 and 4 holds. Next, we derive similar to Lafferty and Zhai ( 2003 ): To derive the Ponte and Croft model ( 1998 ), we have: References
