 1. Introduction
Many companies, in order to meet the requirements of their clients and to provide them with adequate products, implement two key processes:  X  the  X  X  X roduct design X  X  process, which aims at defining precisely the components and the structure of the product,  X  the  X  X  X roject design X  X  process which aims at specifying how the product will be realized (sequence of tasks, used resources y ).

These two processes are often implemented sequentially: first the product is designed then the realization project is elaborated. For example, when a client wants to build a house, the architect designs at first a plan of the house, then the corresponding realization project is developed and launched. Since the project constraints (for example resources availability) are not explicitly taken into account in the product design, this can lead to additional iterations between  X  X  X roduct design X  X  and  X  X  X roject design X  X  processes. A better integration (or coupling) of both processes is therefore a way to improve the global performance of companies.

An in-depth study of several mechanisms that can facilitate this integration has been launched in a project called ATLAS, funded by the French National Research Agency and involving academic laboratories, industrialists and the competitiveness cluster Aerospace Valley. The work presented in this paper takes place in the context of the ATLAS project.

In this section, a simplified product/project integration model is proposed. Indeed, in both environments (product and project), design processes are generally achieved according to a hierarchical decomposition (see Fig. 1 ) in order to encompass complexity:  X  products are recursively decomposed into smaller sub-products ( X  X  X ND X  X  connectors), e.g. product P 1 is made of P 11 and P  X  accordingly, projects are recursively decomposed into sub-projects: in order to realize P 1 one has to realize P 11
P 12 and to assemble P 11 and P 12 ,  X  alternatives ( X  X  X OR X  X  connectors) can be defined in products (e.g. choice between components P 11 is composed of P 0 11 XOR R 00 7 to achieve task T 7 ).

Definition 1. an integrated model, called project graph , is used in order to represent simultaneously the links between the product and project hierarchies. This model consists in an oriented graph without cycles in which nodes are: tasks of the project,  X  X  X ND X  X  connectors and  X  X  X OR X  X  connectors. The oriented arcs represent the precedence constraints between tasks. Fig. 2 represents such a model for the example of decomposition given in Fig. 1 .Sucha graph permits to capitalize that is called  X  X  X tructural knowledge X  X  in the rest of the article. It concerns XOR nodes that correspond to the possible choices of products X  structure. Making a product choice corresponding to a XOR node imply to inhibit a set of downstream connected nodes. Those product XOR are represented by a circular node whereas project XOR, which do not involve inhibition of other XOR node, are represented by dotted circle.

Definition 2. a scenario corresponds to a graph in which all the choices are made (i.e. with no more XOR nodes). An example of scenario, corresponding to the model in Fig. 2 , is illustrated in
Fig. 3 . 1.1. Mathematical description of the addressed problem: optimal scenario among all the possible ones within the simple directed graph project. The project graph G =( a , b ) is defined by: the three different node types (XOR, AND, Task): corresponding to XOR nodes X  X f x i = a i A XOR g X  1  X  identifiers of the direct successor nodes of the XOR node i . Dx i  X f j = a j A a ; b ij A b ; a i A XOR g X  2  X  scenario s corresponds to the instantiation of the variable x defined by x s k  X  j with j A Dx k  X  3  X  T''7
Let X s , the vector of instantiations of all the variables corresponding to the scenario s
X  X f x s k = a k A XOR g X  4  X 
Let G s ( X s ) the directed graph obtained by instantiation of all the variables and corresponding to the scenario s (e.g. see scenario s and b s , the set of edges. G s depends on the variables instantiation X s .

Let f m ( x s ), the value of the criteria m for the scenario s that depends on the variables instantiation X s . This value is computed from the graph G s ( X s ) and depends on the considered criteria m . of all the elementary task costs. If the criteria m is the delay, it is necessary to find the longest path in the graph G s and then, f represents the final delay of the scenario. Therefore, considering a scenario s , each criteria m is evaluated in a specific manner using an appropriate algorithm to apply to the graph G s .

Let f m ( X ), the objective function to optimize corresponding to the criteria m and depending on the variables X . Considering that there is P objective functions to optimize, the multi-valuated optimization function f is defined by min f  X  X  X  X  min  X  f 1  X  X  X  ; f 2  X  X  X  ;:::; f P  X  X  X  X   X  5  X 
This problem can be considered as an extended product configuration optimization problem. The existing literature on the subject is mainly dedicated to finding a feasible configuration according to constraints and knowledge on the domain. However, as mentioned in Li et al. (2006 ) it is very difficult to optimize the resulting configured product since a problem of combinatorial explosion appears especially when the problem is loosely constrained. In this case, using an optimization approach can help to focus on good solutions. In Baron et al. (2004 ) a search method, based on a classical multi-objective evolutionary algo-rithm, was proposed for the problem of scenario selection with promising results.

The method proposed in Baron et al. (2004 ) is improved by taking into account the knowledge that can be capitalized from previous optimizations (learning from experience). Another important issue is to make the capitalized knowledge explicitly available to the decision maker and, therefore, to help him understand the proposed solutions. This enables to avoid the black-box effect of a combined simulation-optimization approach without knowledge acquisition. The main idea developed in this paper is to guide the search process with the available knowledge and, reciprocally, to improve the knowledge by learning from the most interesting solutions obtained during search.

The background of this work, with respect to existing approaches that mix learning and search, is given in Section 2.
Then, the proposed approach, based on a hybridization between bayesian networks (for knowledge acquisition) and evolutionary algorithms (for search) is described in Section 3. Finally, the results obtained on the target problem are discussed in Section 4. 2. Background
The method proposed in this paper relates to a recent family of algorithms called  X  X  X ntelligent evolutionary optimization X  X  (IEO) (Huyet and Paris, 2004 , Michalski et al., 2006 ). As stated above, these algorithms are based on the interaction between a search process and a knowledge acquisition process achieved through learning. The goal is to benefit of the advantages of both approaches. The search process aims at improving a set of solutions by pseudo-random selection and combination opera-tions. The goal of the learning process is to extract, to capitalize some knowledge contained into the solutions in order to guide the search process. Indeed, Michalski et al. (2006 ) shows that fixing some interesting solutions properties is generally enough for the search method to focus very quickly on some solutions close to the optimal. So the learning process has only to give some orientations to the search process with respect to a given context. This section presents works which relate to the scenario selection problem for each process (search or learning optimization methods) then an overview of existing hybrid approaches. 2.1. Search process
The model defined in the previous section represents a highly combinatorial (multiple XOR disjunctions in the graph) multi-objective problem. The multi-objective aspect invites to provide the decision maker with a panel of good solutions which represents various compromises between identified objectives (Pareto front). This kind of problem is often addressed using metaheuristic optimization methods (see Rochet and Baron, 2006 and Chelouah et al., 2009 ) for studies of different metaheuristic applied to the scenarios selection problem). Among those, this study relies on evolutionary algorithms (EA) ( Holland, 1975 ), as illustrated on the left part of Fig. 4 . EA is indeed well suited for multi-criteria optimization and can provide the learning algorithm with a set of individuals that  X  X  X epresent X  X  the global search space.

This kind of method indirectly reuses knowledge related to the problem via the evaluation of the generated solutions. Here, knowledge on the problem corresponds to a connection between a given instantiation of genes (a scheme) and an interesting area of the objective space. Holland (1975) showed that the improve-ment of individuals in the evolutionary algorithms is ensured by the indirect selection of the schemes with good performance (according to the schemata theorem). Nevertheless in classical EA, unguided evolutionary operators handle genes in a random way. Some techniques try to identify and preserve combinations with good performances thanks to specific search operators and solution encoding, such as messy genetic algorithm (mGA) ( Goldberg et al., 1989) and linkage evolving genetic operator (LEGO) ( Smith and Fogarty, 1996 ). The evolutionary search process concerns thus both individual improvement and links between genes. The coupling of classical EA with a learning process makes it possible:
As detailed in Section 3, the acquired knowledge can be used simply in order to give orientations to the EA by introducing some bias into the classical evolutionary operators (initialisation, mutation and crossover operators). 2.2. Learning process
Among the different optimization methods based on a learning process, this section focuses on approaches using a probabilistic model such as population-based incremental learning (PBIL) ( Baluja, 1994) and extended compact genetic algorithm (ECGA) (Harik et al., 2006). Indeed, such model can provide guidance with approximate information directly usable in order to give orientations to search operators. Bayesian optimization algorithms (BOA) ( Pelikan et al., 1998)usesBayesiannetworks(BN)asamodelofknowledge (Fig. 4 ). In this method, the MoK is learned from a sample set containing selected individuals from the previous generation (according to their fitness or performance). Then, a sampling procedure is used to generate, directly from the MoK, the new population of individuals without using modification or combina-tion operators. One of the main characteristic of the learning process lies in the construction of the sample data set. A substantial set of individuals, distributed in the promising areas is essential to obtain a relevant model. When the individuals used as a learning set are selected, the induction of the probability model, especially parameters interaction (i.e. de finition of the Bayesian network structure), constitutes the harde st task to perform automatically (Baluja, 2002 ). Therefore, classical BOA learning process focuses on the study of most influent parameters interaction.

Another way to address this difficult problem is to use a prior knowledge in order to improve the learning procedure. The use of prior knowledge allows either to speed up algorithm convergence by introducing some high-quality or partial available solutions (Schwarz and Ocenasek, 2000), or to improve the learning procedure using an available structural knowledge (prior prob-abilities of networks structure) ( Schwarz and Ocenasek, 2000 ;
Baluja, 2002 ; Hauschild et al., 2008 ). The learning model proposed in this paper (Section 3) relies on the acquisition, from experts, of  X  X  X  priori X  X  knowledge about the structure of the network. There-fore, during the optimization process, the learning is achieved only through probability updates. This method makes it possible to concentrate the learning effort to the probabilities estimation.
In the proposed approach, the diffe rent objectives are considered separately in the MoK (non-aggre gative approach). That makes it possibletodissociatetheknowledgerelatedtothedifferentpartsof the surface of compromise between objectives and then to propose a specific guidance towards each zone of the search space. 2.3. Integration of search and learning
In the two previous types of methods, the computing time is used either for evolutionary search process or for learning process. The choice between both approaches depends on the evaluation cost of individuals (time), the number of genes and the complexity of interactions between genes. On one hand, if the evaluation cost of an individual is very important, the traditional
EA is less powerful. On the other hand, for a model containing a great number of variables or complex interactions, the knowledge learning cost may be prohibitive for the learning algorithms. The coupling of both approaches allows restricting the search process to the areas with good performances and allows the manipulation of complex configurations of genes by means of biased evolu-tionary operators.
 (search and learning) have few interactions during execution, especially for the crossover operator. Most of them, such as the learnable evolution model (LEM) ( Michalski, 1998 ) or intelligent optimization method ( Huyet and Paris, 2004 ), alternate between: the learning process also provides rules to characterize effective crossover or mutation (crossover or mutation rate, type of operators: uniform crossover, N-point crossover, etc.). achieved indirectly. This generates a black-box effect incompa-tible with an expert utilisation of the knowledge model. Knowl-edge can be represented by means of operator classes ( Sebag and
Schoenauer, 1994 ), intervals ( Michalski et al., 2006 ), assumptions on the parameters values or by the attributes about good solutions ( Chung, 1997 ). Huyet and Paris (2004) propose to model directly the knowledge using classes of parameters. They provide a hierarchy of parameters according to their impact on the fitness improvement. Furthermore, no model enables to dissociate objectives in order to have a representation of the influence of decisions on each of them. Objectives are aggregated (Jourdan et al., 2005 ) and then, partial knowledge is impossible to reuse. The proposed approach aims at delivering to the decision maker, in addition to the best solutions obtained, a MoK characterizing efficient individuals. The model proposed in the next section gives some answers to the issues listed above. 3. Proposed framework and algorithm 3.1. General architecture evolutionary algorithm for the multi-objective search process and a model of knowledge (MoK) able to provide orientations adapted to the treated case ( Fig. 5 ). The Bayesian network (BN) formalism is used to represent the MoK. Two sources of knowledge are used to elaborate the MoK: on one hand, a selection of individuals (solutions) provided by the EA and, on the other hand, expert knowledge mainly used in order to define the structure of the BN.
The resulting BN can be used by the EA as orientations for its search process. These orientations are taken into account directly by means of the evolutionary operators. Using a selection of individuals obtained during search, a learning step enables the BN to be updated by means of an inference learning algorithm. 3.2. The model of knowledge
The aim of the model of knowledge (MoK) is to formalize links between three spaces: the decision space, the evaluation space and the context space. The decision space relates to all the decisions that can be taken by decision makers, whether design or project choices (see Section 1). The evaluation space concerns the objectives to reach by the search method and, more precisely, the performance of the solutions with respect to these objectives. To be able to reuse knowledge from previous experiences (here previous project/product), the context of each experience (e.g. project/product) has to be described using supplementary para-meters. All the external parameters that can influence the search process are gathered into the context space. For example, an external parameter can be the supplier capacities which influ-ences decision related to the choice between various suppliers for a task. The modification of these external parameters is considered as an input of the model and their influence on the two other spaces has to be taken into account.

The formalism used for building the MoK is Bayesian networks (BN) ( Pearl, 1988) because of their learning capacities and practical decision aiding abilities. A BN is a probabilistic model that represents a set of variables (nodes) and their conditional dependencies (edges between nodes) in a directed acyclic graph.
It allows the inference of the conditional probability of each state of a node according to the state of others nodes. Conditional probabilities are gathered into a conditional probabilities table (CPT) linked to each node. An interesting characteristic of a BN is the graphical representation (e.g. see the BN of Fig. 6 ) very suitable for an aided decision perspective. As illustrated in Fig. 6 , the MoK contains four kinds of nodes: objective, decision, concept and environment nodes. The decision nodes correspond to the
XOR connectors of the project graph. The objective nodes represent the different objectives used for multi-objective optimization. The concepts nodes are used by experts to express which characteristics of the domain are important and can influence one or several objectives. Environment nodes enable to contextualize the knowledge contained into concept nodes.
Each node of the MoK is discrete, i.e. it contains only a finite set of possible states for the modelled entity. A decision node can take into account all the possible choices (or states) for this decision. An objective node takes into account one of the objectives to optimize (in our experiments, two objectives are considered: minimisation of cost and delay) and is represented by discrete states (e.g. low , medium , important ). This characteristic is used in order to define different objective classes (see Section 3.2.2). States of an environment node represent the different discrete possibilities of the context that can influence the objectives. Concept nodes have two distinct roles in the MoK: (1) to reduce complexity and (2) to model expert knowledge. Under the hypothesis that the concept nodes are not necessary, it is possible to draw some arcs directly between decision nodes and objective nodes, with respect to the different influences known by the experts. The obtained model may be sufficient to capitalize expert knowledge and to guide the evolutionary algorithm. However, the complexity of such a model will be very important because it is directly proportional to the dimension of the table of conditional probabilities of the objective nodes which depends on the number of parent nodes and the number of states of those parent nodes. In order to limit the complexity, concept nodes enable to build progressively the links between decisions and objectives. In such way, the number of parents of each node is reduced, as well as the global complexity of the model. So, introducing concept nodes enables to take into account the particular influences of a limited number of decisions on sub-criteria. For instance, during a project, a great number of decisions about sub-contracting or not can be linked to one sub-criterion called  X  X  X ub-contracting X  X , represented by a concept node. This concept node can be linked to objective nodes according to expert knowledge (e.g. sub-contracting can influence the cost and the delay but not the weight of the product).

Without learning process, the probabilities of states for each decision node of the BN are uniform (i.e. the search space is considered as uniformly interesting). These probabilities can be updated by a learning procedure performed on a selection of solutions provided by the EA or by knowledge provided by the experts. 3.2.1. Structural knowledge within the MoK
The structure of the MoK is given by the nodes and the arcs between nodes. The majority of the arcs starts from decision nodes and go to objective nodes, via concept nodes. Considering the project graph ( Fig. 2 ), some choices about design can inhibit other choices. That is taken into account in the MoK by means of arcs between decision nodes and a particular state called  X  X  X nhibited X  X  that indicates the inhibition of a decision by an upstream decision.

For instance, the simple BN represented in Fig. 7 represent three possible linked decisions (three nodes linked by two arcs). The first decision to take during this project, represented by the Selection Population i Population i+1 Evolutionary algorithm Model of Knowledge node  X  X  X ecision 1 X  X , can be  X  X  X tate 1 X  X  or  X  X  X tate 2 X  X . If the decision  X  X  X tate 2 X  X  is taken, then the decision represented by the node  X  X  X ecision 2 X  X  is inhibited and its state  X  X  X nhibited X  X  has a probability of 1. On the other hand, if the decision  X  X  X tate 1 X  X  is taken, then the node  X  X  X ecision 3 X  X  is inhibited (states  X  X  X tate 5 X  X  and  X  X  X tate 6 X  X  have a probability of 0 and the state Inhibited has a probability of 1).
The tables of conditional probabilities of nodes called  X  X  X ecision 2 X  X  and  X  X  X ecision 3 X  X  enable to represent the different probabilities to have a particular state for a decision with respect to the states of its parent. 3.2.2. Objective classes within the MoK
In order to be able to guide the evolutionary search process, the MoK has to be representative of different objective classes.
The number of classes is obtained from the number of discrete states of the objectives. In fact, only particular zones of the objective space are interesting in order to guide the evolutionary algorithm. Fig. 8 represents a MoK and the associated objective space with two objectives and three discrete states by objective (there are two environment nodes (suppliers and workshop capacities) and no concept nodes). Nine areas are defined but only five of them are interesting (C 0 to C 4 ). In a multi-objective optimization process, the method has to provide decision makers with a set of solutions belonging to the Pareto front. A good quality of this set is obtained when all the objective classes corresponding to the Pareto front have at least one solution. So, the proposed method enables to guide the EA to reach, at each generation, an ideal Pareto front or, more exactly, interesting zones of search space represented by the different classes of objectives ( Fig. 8 ).
 necessary to compute probabilities linked to the different objective classes. Therefore, in the BN, fixing probabilities of some objective states to 1 enables to obtain probability of each state s of a decision d with respect to the objective class c (noted P c , d , s ). This operation consists in setting some evidence s in the objective nodes (setting probabilities to 1) in order to obtain the probability of each state in each decision to reach the zone of the objective space defined by its cost and a  X  X  X ow X  X  delay are considered as certain and probabilities are set to 1 (see Fig. 8 ).
 inhibited state of the decision d ,ifitexistsinthenode).If P then P c , d , s is set to 1 for each s A { s 1 d , s 2 d indicates that the decision d is inhibited for the class c . 3.3. The evolutionary algorithm oriented by knowledge (EAOK) method (strength Pareto evolutionary algorithm, illustrated on left side of Fig. 9 ) proposed by Zitzler and Thiele (1999) .Themodified
SPEA proposed in this paper is based on this traditional EA with classical steps: initialisation, ev aluation/archiving, selection and genetics crossover and mutation operators. The evaluation, archiving and selection operations have not been modified.

SPEA ensures the multi-objective evaluation of individuals according to two steps: (i) the cost of solution is computed for each criterion (e.g. global cost and delay); (ii) then, the multi-criteria evaluation is achieved by means of a Pareto front to compare and classify the solutions. The probability of selection of an individual is proportional to its performance (called  X  X  X itness X  X ).
An individual X  X  fitness depends on its position in the search space compared to the Pareto front. The fitness of an individual i is given by formula (6) ( Zitzler and Thiele 1999 ) according to the strength ( S ) of individuals j that dominate i (an individual j that dominates i is noted j 4 i , and correspond to the fact that for each criterion, the performance of the individual j is equivalent or better than the performance of the individual i ). The strength of an individual S given by formula (7) where n is the number of dominated solutions and 9 Pop 9 is the population size. f  X  s  X  9
Pop 9  X  1 :  X  7  X  3.3.1. Solution encoding
In order to define the new EA, an encoding of a solution (a scenario) is needed. The model proposed by Baron et al. (2004) is well suited for the representation of a project scenario.
Therefore, it is used in the proposed EA. A project graph and an individual corresponding to one scenario are represented in Fig. 10 .

The chromosome of an individual gathers on the left side the genes corresponding to decisions derived from product decom-position (choices between components represented by XOR nodes in the project graph). Instantiations of the genes of this first part (selection of a particular state) can lead to the inhibition of some other genes in the chromosome. On the right side of the chromosome, genes represent decisions derived from project decomposition (choices to achieve tasks on the graph, represented by dotted circles on Fig. 10 ). A gene g represents a decision d .A value of a gene g represents a choice (state) s for a decision d . All the possible choices are always represented even if several of them are inactive since they are inhibited by choices made on genes of the left side of the chromosome. This encoding ensures a constant viability of the solutions. This aspect of inhibited variables has been previously studied by Paris et al. (2001) . But in this study, the authors traduce it by a specific coding (individuals represented by trees) and specific evolutionary operators that allow handling this tree representation.
During the execution of the EAOK, two strategies can be used:  X  X  X tructural knowledge utilisation X  X  and  X  X  X iploid knowledge pre-servation X  X . These two strategies are presented below. 3.3.2. Structural knowledge utilisation
During the execution of the EAOK, if a gene is inhibited by a previous gene instantiation, the values of the corresponding probabilities associated to the objective class ( P c , d , s indicating its inhibition. In Fig. 11 , the fact that P 2,1,1 the inhibition of third gene, then the inhibition of this gene also leads to the inhibition of others depending genes (here, genes 6 X 9). This inhibition mechanism corresponds to the mode called  X  X  X tructural knowledge utilisation X  X . It can be applied all along the algorithm or not applied, according to the strategy chosen for the algorithm (see Sections 3.3.5 and 3.3.6). 3.3.3. Diploid knowledge preservation
During the execution of the EAOK, different operators can modify the genes of the chromosomes. A mode called  X  X  X iploid knowledge preservation X  X  permits to preserve inactive genes which can represent interesting characteristics in other areas of the search space and that can be re-activated during other cycles of the EAOK. This biological concept was already used successfully for optimization in dynamic environment by Holland (1975) . During optimization process, if  X  X  X iploid knowledge preservation X  X  mode is activated, inactive genes are not modified (see Sections 3.3.5 and 3.3.6). 3.3.4. Initialisation oriented by knowledge
The first step of the EAOK is the initialisation of individuals of the population according to the probabilities P c , d , s with respect to each objective class. The initial population is built according to the objective classes in order to start the search procedure with a priori good orientations. The initial population (the constant size N of the population is a parameter of the EAOK) is created with individuals uniformly distributed to the different objective classes (individuals are randomly assigned to objective classes). After assignation to objective classes, the values of the individual genes are fixed using the probabilities of individual classes in order to give a priori good orientations. As illustrated in
Fig. 12 , the probability to select a value g 0 (model of state s )ofa gene g (model of decision d ) belonging to an individual i associated to a class c is given by: P c , d , s . Therefore, values of genes are selected by a roulette wheel selection (RWS) mechanism. If P c , d , s is equal to 1, then the choice of the gene value is not important and a random selection is done. 3.3.5. Mutation oriented by knowledge
First, the mutation operator selects an individual randomly among the population according to the probability of mutation
P mut (input parameter of the EAOK). Then, as illustrated by Fig. 13 , the probabilities of the individuals X  objective class are used to fix the value of genes. For a gene g , two cases are taken into account: genes are inhibited by mutation of previous genes, the associated values of the objective class are set to 1. 3.3.6. Crossover oriented by knowledge randomly among the population according to the probability of crossover P cross (parameter of the EAOK). The second individual ( i 2 ) is chosen according to the crossover strategy: exploratory or intensification strategy. The exploratory strategy consists in choosing the second parent associated to another objective class (firstly in the classes closest to the class of individual i intensification strategy consists in choosing a second parent associated to the same objective class. Once parent selection is done, probabilities of their classes are used to determine the points of crossover (an example of crossover operation is illustrated on Fig. 14 ). The crossover is performed in a specific manner for each individual (unilateral crossover).
 belonging to the selected parent i 1 associated to the class c , the crossover is performed according to the probability (1 P c , d , s called pertinence of the active state) if P c , d , s a 1. The crossover consists in copying the corresponding value of the gene of parent i 2 into the current gene of the parent i 1 .
 exchange, favourable genes of each individual. When the value linked to a gene in the corresponding objective class is 1 (inhibited gene), a unilateral crossover is done with a probability of 0.5 if the  X  X  X iploid knowledge preservation X  X  mode is inactive (uniform crossover of inhibited genes). If the  X  X  X iploid knowledge preservation X  X  mode is active, inhibited genes are preserved from the evolutionary process. 3.3.7. Test of evolution best solutions of the Pareto front are improved at each cycle. If the search process does not evolve, two reasons are possible: (1) the global optimum is reached or (2) a local minimum has been found. For the second possibility, the main cause can be erroneous, unsuitable or incomplete probabilities in the MoK. Therefore, if there is no evolution after a predefined number of cycles of the
EAOK, then the MoK is updated by means of: (1) a probability smoothing procedure, (2) a learning procedure from a selection of individuals. Both permit to make evolving the MoK for a better orientation of the EAOK and are described in the next sections. 3.3.8. Probability smoothing
In order to modify the MoK, the probability smoothing process is used at first. It consists to change the probabilities of the BN according to the formula (8) below
P 0  X  P  X  1 smooth _ degree  X  X  8  X  where P is a probability before smoothing and smooth_ degree is a parameter that permits to control the smoothing process. P 0 is the probability after smoothing. The smoothing degree is included into the interval [0, 1]. If smooth_degree is equal to 1 the operators are not oriented by knowledge (EAOK degenerates as a classical EA). If smooth_degree is equal to 0, there is no probability smoothing. 3.3.9. Learning procedure
Probabilities of the BN are learned from representative cases using EM algorithm (expectation X  X aximization) ( Dempster et al., 1977 Tanner, 1996 ). The EM algorithm can be used in BN for finding maximum likelihood estimates of parameters. The model can depend on unobserved latent variables. So, it is interesting for the learning process because cases can be incomplete (notably for a partial knowledge reuse). A case represents an individual with the values of concepts, criteria, decisions and associated objec-tives. EM algorithm stops the learning process following two criteria: the number of iterations E X  X  or the improvement of the
BN likelihood compared to the previous learning cycle (network quality indicator with respect to the set of learning examples). 3.3.10. Affectation of the individual to objective classes
Individuals created by means of crossover and mutation operators have to be affected to objective classes in order to start a new cycle. An individual is affected to its closest objective class. In the objective space, for each objective class, a central individual is defined ( Fig. 15 ). Its role is to represent the objective class tending to attract new individuals. Central individuals belong to the current Pareto front. 3.4. Computational complexity of EAOK
The proposed algorithm is a modified SPEA complemented by a BN guidance (that involve learning and inference algorithm). The computational complexity of the traditional SPEA method is O ( KN 3 )(Zitzler and Thiele, 1999 ), where K is the number of objectives and N the size of population. The modified genetics operators added to the classical SPEA method (evaluation and KO -operators) have a bounded complexity proportional to the number of decision variables of the problem. The BN guidance, beforehand computed ( X  X  X  priori X  X  orientations) then updated after every learning phase or probabilities smoothing phase, is obtained by a learning algorithm (EM algorithm) on the set of selected individuals. The learning phase has a polynomial time complexity which depends on the number of learning cases (individuals), the selected stopping criterion and the BN shape (especially the number of un-instantiated nodes  X  decision and concept nodes), the number of states of those nodes and their relationships (number and size of clique in the BN) ( Dempster et al., 1977 ). Finally, the inference algorithm used to exploit the learned model (classes acquisition) is the junction tree algorithm. It is done for each objective class on the learned model. Its time complexity also depends on network shape (see Cowell et al., 1999) for more details on inference and learning algorithm). So the complexity of the whole algorithm is thus polynomial. 4. Experimentation and results
The main contribution of this study consists in the hybridation of an evolutionary algorithm with a dedicated model of knowledge. This knowledgetakesthreedistinctforms:(1)aconceptualdependency structure between para meters expressed by a Bayesian network, (2) probabilities extracted from analysis of previous optimizations and, (3) explicit structural knowledge (inhibitions between genes). To evaluate the use of each type of knowledge, the behaviour of three algorithms is studied in this section: 0.3 0.7
Chromosom before mutation
Chromosom after mutation
Individual assigned class
The EAOK init algorithm enables to check the impact of using all the available knowledge (structure and probabilities) while the
EAOK X only uses the minimal necessary knowledge (BN structure given by an expert). The analysis of the three algorithms should allow choosing a control strategy according to the available knowledge and its relevance.

The algorithms have been studied by means of an ad hoc platform developed in C++. Experimentation has been planned in two steps. In the first step, the algorithms are evaluated on limited size problems (different graph shapes with 35 to 90 task nodes and 10 to 40 XOR nodes using a test graph random generator, see next section). This first step allows checking the general behaviour of the algorithm as well as tuning of several parameters (evolutionary parameters, crossover strategies, learn-ing parameters, y ). In a second phase, the behaviour of the algorithms is studied on a larger project (approximately hundred
XOR nodes and three hundred task nodes in the project graph). 4.1. Test graph random generator
The main principles of the graph generator used in order to build the test graphs are described in this section.
 algorithm which treats graph by subsets in which the objects to assign (tasks, XOR, AND nodes) are distributed. It allows obtaining a nearly balanced graph with a similar number of nodes in every subset. We also use, for the first test phase, some particular graph shapes (linear or tree shape).
 introducing underlying knowledge into data. This allows to simulate a coherent knowledge represent ationthatcanbespottedbythe learning algorithm. Therefore, some  X  X  X oncepts X  X  are attached to each
XOR node, which modulate the perfor mance of associated tasks (tasks located on the branches of the XOR node) for each criterion. 4.2. Global evaluation of the strategies small projects (35 task nodes randomly generated, 12 XOR nodes for Fig. 16 and Table 1 for example). The curves at the top of
Fig. 16 show the average performance of the population of individuals obtained with the strategies EA, EAOK init , EAOK
EAOK 5 . The curves at the bottom of Fig. 16 show the average performance of the individuals of the Pareto front. Each curve represents average values obtained after one hundred executions. fitness F (noted fitness below). F corresponds to the sum of normalised objective values. For each criterion, the minimum and the maximum experimental values permit to obtain a normalised objective value in order to be added to the other ones. duals of the population are 25% better than those obtained with
EA. These results come from different combination of others parameters detailed in Sections 4.2 X 4.5 (crossover strategies, knowledge use, etc.). This explains the important standard deviation but, for a given setting, the performance ratio between
EA and EAOK init is stable. The initial gap between EA and EAOK corresponds to the direct impact of knowledge injection at the initialisation step. This gap varies according to the MoK quality.
The population generated by the guided EAOK is always improved in comparison with classical EA, because the used MoK leads to a concentration of the population within good performance areas.
The final Pareto-optimal individuals mean fitness is improved of 4.82% at the twentieth generation. EA performance meets EAOK ones very progressively, according to the problem complexity (number of parameters and complexity of injected knowledge) and according to evolutionary parameters setting.

They are equivalent to EA at the beginning of optimization process (uniform probabilities distribution). They deviate from EA after every learning phase. He learning effect is particularly visible in mode EAOK 5 with three zones where the difference with EA is 1 0 0 1 0 increased (generations 5, 10 and 15). At the beginning of the process, EAOK 1 has better performance than EAOK 5 but, the difference is progressively reduced and finally EAOK 5 gives better results. This can be explained as follows: EAOK 5 leaves degrees of freedom to the search process in order to improve individuals between each learning phase, whereas, for EAOK 1 , individuals selected for learning are not enough diversified and the guided search remains in a restricted area of the search space. EAOK better takes advantage of search and guiding combined effects. 4.3. Crossover strategies evaluation The average values for one hundred executions of EA and
EAOK init with two crossover strategies (exploration and intensi-fication strategies respectively noted C explo and C int ) on the same project are represented in Table 2 .

During optimization, the performances of EA, whatever the selected crossover strategy, are similar. With the exploration strategy, individuals have a good distribution on the Pareto front. However, they give individually worse performances. On the contrary, when using the intensification strategy the individuals are gathered and their performances are better. Let us point out that at the end of the optimization process the strategy of intensification is globally more powerful than exploration (average values of every mode). However, the EA with an intensification strategy alone gives worse performance than the EA with an exploration strategy only. This can be explained by the lack of diversity of the population using a strategy of intensification during all the process. With respect to the relative standard deviation (RSD), the intensification strategy always achieves better results with, for example for the best individual of EAOK init ,aRSDvalueof0.6%.

The most visible effect of the choice of crossover strategy affects the average improvement given by the oriented crossover operator. EAOK init with a strategy of intensification presents a significant initial peak, corresponding to the fast improvement in all the known good performances areas. The average performance of the crossing for the first generation is 233 for EAOK init ,whileEA improvement reaches only 29.5 in exploration mode. The indivi-duals are thus correctly crossed, by respecting the integrity of relevant knowledge of each class, and then produce individuals mixing good features of both parents. For the whole process, the crossover improves of 41 the global fitness of the solutions for the strategy of exploration whereas the improvement in intensification strategy is 18.2. During the following tests, an exploratory strategy has been used during the optimization process, notably in order to provide a set of diversified solutions to the learning process in mode EAOK X . The intensification strategy is used only at the end of the search process in order to refine obtained solutions. 4.4. Learning parameters setting
For the tuning of the learning algorithm parameters, two important characteristics must be taken into account: the quality of the examples used for learning and the stopping criterion of the learning algorithm. Both parameters are studied in the following sections. 4.4.1. Influence of the set of examples used for learning
Table 3 presents results obtained for the five following strategies on a small size project (50 task nodes): important characteristic in order to obtain a relevant model. The first observation is that strategies sel 1 and sel 4 lead to poor performances.
Indeed, they select individuals from the entire search space including individuals of poor performance. The others strategies focus on good individuals which permits to avoid a saturation of the learning capabilities of the MoK with poor individuals.
 better results: (i) it better selects individuals whatever the shape of the Pareto front (concave or convex front); (ii) it allows having a constant number of learning examples, which makes it possible to control precisely the processing time of the EM algorithm by defining the size of the sets of selected individual. This strategy ( sel 3 ) was finally complemented by additional set ( sel better learn the zones of compromise between objectives. This last strategy leads to the best results and has been selected for the remaining experimentations. 4.4.2. Influence of stopping criterion
Table 4 presentstestsrealizedonthesamegraphthaninsection 4.3.1 (50 task nodes) for the other p arameter of learning algorithm: the stopping criterion. As previousl y presented, two kinds of criteria are experimented: a fixed number of EM iterations (ten iterations has been tested) or the minimal improvement of log-likelihood of BN compared to the previous EM step (three different values investi-gated: a minimal improvement of 0.1%, 0.01%, and 0.001% to continue the learning process). The first one allows to control the computing time needed for the learning algorithm but the quality of probabilities estimation is not guaranteed. The values presented in Table 4 have been obtained with the final individual selection ( sel f crossover strategy (except the two last lines of the table, see details below). As shown in this table, the best strategy seems to be the less restrictive one (0.1% of minimal log-likelihood improvement). Indeed, a fast learning is sufficient to make emerging the main properties of the search space and thus to obtain a global guidance, whereas a longer learning brings to an over-guidance of the search towards the existing individuals. The same conclusion can be drawn when the number of examples per class of objec tivesistoorestri cted (presented results obtained with various individual selection strategies). The phenomenon of  X  X  X ver-learning X  X  induces stagnation of search around the already found individuals, with a risk of stagnation in local minima. This interpretation has been confirmed by the use of a progressive smoothing (see Secti on 3.3.8) of the MoK, presented by the two last lines of Table 4 . The progressive smoothing can be used and provides two functions: (i) it makes it possible to limit  X  X  X ver-learning X  X  when cases provided to the learning are too similar; (ii) it constitutes a mean for gradually giving degrees of freedom to the search process, i.e., to limit the guidance by the MoK (phenomenon of  X  X  X ver-guidance X  X ). If smoothing gives good results on reduced size projects, it nevertheless requires more computing time, in particular for bigger ones. Thus, it should not be systematically used but only as a last resort when the optimization stagnates. 4.5. Structural knowledge and diploid preservation mode setting
Every combination 1 of structural knowledge (SK) and diploid knowledge preservation (DKP) modes has been evaluated. The results are presented in Table 5 and concern one hundred executions of each strategy: EAOK init , EA and EAOK 10 on a project of 50 task nodes. Structural knowledge can be used to indirectly manage the knowledge contained in the individuals. If it allows an initial improvement of the AE, it also involves a reduction of the genetic diversity by reducing exchanges between the individuals. On the other hand, the use of structural knowledge with a MoK learned online allows using only individual specific information among knowledge contained in class. The diploid knowledge preservation mode gives good results only when the individuals have already a good level of performance, by preserving the inactive combinations which can be re-used when the corre-sponding genes are re-activated. On the contrary, the best strategy with reliable information (EAOK init ) is to use neither structural knowledge, nor diploid knowledge preservation. Gui-dance by the model is then complete, but this strategy must not to be maintained because of stagnation risks (strict guiding towards existing individuals). 4.6. Large size problem experimentation
Finally, the proposed method has been tested on a problem of larger size (350 tasks nodes and more than 100 XOR nodes). An exact algorithm is not suitable for such large project. Individuals used for the construction of the  X  X  X  priori X  X  model (EAOK init ) are collected during one execution of the EAOK 10 (390 individuals). Table 6 presents the average of 20 execution of our algorithm (30 generations of 50 individuals, P
The EAOK 10 algorithm shows an interesting behaviour. The population is overall improved by guiding as well as individuals of the Pareto front. At the last generation, the variation between EA and EAOK 10 , respectively, reaches 54% (population), 15% (Pareto front) and 11% (better individual) in favour of the EAOK 10 Moreover, these performances are more regular than those of the traditional EA. The learning improves the results, especially the precision and reliability of optimization. It also seems that the performances obtained strongly depend on the quality of search before the first learning. An interesting prospect is to use an adjustment of the EA supporting the diversity of individuals, in order to improve the quality of individuals provided to the learning algorithm. However, in its version of the platform, the time of inference needed to update the probabilities classes remains important. The EAOK 10 requires indeed approximately 300 seconds to reach the thirtieth generation with two learning phase, so approximately 27% of additional time required compared to the EA. 5. Conclusion
This paper is focused on the description and evaluation of a new evolutionary algorithm for the selection of project scenarios in the early phases of a system design. The underlying problem is highly combinatorial especially when decisions on the product and on the project are integrated in a single model, called project graph. In order to benefit from expert knowledge and from past optimizations, a hybridation between a learning algorithm and a search algorithm is proposed. A model of knowledge, used to capitalize the knowledge that links decisions, environment, objectives and concepts, is defined using the Bayesian network formalism. This model is obtained from experts and from a learning process using some solutions generated by the EA. This model is used in order to give orientations to the EA to reach a priori interesting zones of the multi-objective space. In a decision aided perspective, the guided search process has to give some solutions well distributed on the Pareto front. The proposed method is based on the hybridation of a classical strength Pareto evolutionary algorithm in order to guide the search process by means of the model of knowledge. New operators of initialisation, crossover and mutation are defined. Their behaviour is oriented by probabilities contained into the MoK. Since the MoK can be incomplete or erroneous, a MoK updating process based on in-line learning permits to make it evolve during optimization.
Obtained results show the interest of the different levels of knowledge reuse for orientation of an evolutionary algorithm.
When the knowledge contained in the model of knowledge is reliable, the proposed method allows a significant improvement of performance. When the MoK is erroneous or incomplete, the tests realised on learning algorithm enabled us to study the learning process abilities with the suggested method. To validate our approach completely, it still remains to confront it with standard problems ( X  X  X enchmarks X  X ).

However, tests carried out show the high performances of the evolutionary algorithm oriented by knowledge compared to a traditional EA. Moreover, the advantages of the proposed model relate not only to a well guided and more efficient optimization than with classical EA, but also to the possibility to capitalize knowledge about previously planned projects according to their context, and to provide decision makers with the MoK used during optimization in addition to the optimized solutions. It is indeed useful for decision makers to use the Bayesian network, thanks to the tools offered by this formalism, and to directly evaluate the influence of his decision on the objectives. References
