 Categories and Subject Descriptors: H.3.3 Information filtering: Information Search and Retrieval General Terms: Experimentation.
 Keywords: Financial news filtering, world knowledge, NLP, machine learning.
Document retrieval is a well-understood problem, as a consequence search technology has been able to support growth and innovation in scientific and industrial domains. As the Web evolves new types of content emerge: blogs and other types of communities, often based on multimedia con-tent sharing, feeds for information browsing and delivery, vertical domains for shopping and performing other trans-actions, Web advertising. New types of content are chal-lenging for traditional IR approaches based on the idea that the unit of information is a full  X  X ocument X , whose content can be reasonably approximated with a bag-of-words repre-sentation, and whose ranking or matching can be assessed in isolation, within the vector space model paradigm.
News filtering tasks involve monitoring a stream of news to identify stories belonging to a predefined set of categories. In the context of opinion mining we define five categories which capture the  X  X olarity X  of the story, a graded posi-tive/negative opinion, with respect to a company. Financial news services are an important component of major Internet content providers (e.g., Google Finance, Yahoo! Finance). Financial news and stock prices tend to be correlated, and opinions and trends of financial stories can be modeled to a certain extent [2, 3, 7]. Tools for automated monitoring of such news could be valuable to users, financial analysts or small investors. Previous work has focused on clues for polarity such as selected keywords (plunge, surge, etc.), in-stead we consider the task of classifying all news stories that are relevant to a set of companies, coming through a stream.
We present an exploratory study on the problem of clas-sifying financial news stories streamed through RSS feeds. In particular, we focus on news stories titles . The reason for this is threefold. First, processing titles is faster than full documents and allows monitoring of larger numbers of sources efficiently. Secondly, and more interestingly, humans seems to be capable of performing such a task effortlessly on the basis of the little information provided by the title, even with no specific domain expertise. Furthermore, processing titles, e.g., short sentences, is a kind of short text process-ing and retrieval task, an area of research which is becoming increasingly relevant [4]. We implement a system for classi-fying news titles based on traditional document representa-tion concepts and machine learning. We analyze the output of the system to identify the causes of its limitations and discuss desirable properties of more advanced systems. We conclude that to improve accuracy in broad-coverage set-tings a substantial amount of world knowledge is necessary.
Over a month period, October-November 2006, we moni-tored the RSS feeds from Yahoo! Finance (36 sources) rela-tive to the top 50 company symbols in the Standard &amp; Poors index. The first author, a senior student in economics, an-notated the titles of 7,382 stories using the following five categories, the same as [7]:  X  X ad X  (B),  X  X lmost bad X  (b),  X  X ncertain X  (U),  X  X lmost good X  (g), and  X  X ood X  (G). Our data collection method differs from [7] in that we do not automatically assign to category  X  X ncertain X  all news which do not mention explicitly the company name. Also, we do not limit our attention to news which contain predefined trigger words, but consider all news stories in the stream. The motivation for this is valuable recall: the most frequent trigger words are relatively infrequent; e.g.,  X  X ain X  occurs in 2.2% of the titles,  X  X rop X  in the 0.9%,  X  X rowth X  and  X  X ain X  in the 0.8%,  X  X urge X  in the 0.3%, etc. The following table illustrates a few example titles: C Title Co.

B  X  X IG units subpoenaed by DOJ and SEC X  AIG b  X  X hinese SUV maker aims to prove itself X  F
U  X  X ndonesia seeking $ 12 Billion in capital X  IBM g  X  X &amp;G sees better operating environment X  PG G  X  X alero energy 3Q profit surges X  VLO As an illustration, the first title mentions a legal action against the company (B), while the second (b), although not explicitly negative, implies the possibility of more com-petition on a strategic market for an auto manufacturer, etc.
We partition the stories in train, development and test sets. The development set contains 1,050 titles collected in October 2006, the training set consists of 4,513 titles from the first 14 days of November 2006, and the test portion contains 1,819 news from November 15 (752 titles), 16 (811) and 17 (256). Splitting by day is necessary since the same news can appear several time in one day for different compa-nies, or for the same company from different sources. As a classifier we used a regularized multiclass perceptron of our implementation based on the algorithm introduced in [1], we set the free parameters of the algorithm on the development set. We tried three different types of binary feature encod-ings: bag of unigrams (Uni), bag of unigrams and bigrams (+Big), the latter plus a feature for the company stock sym-bol (+Co.). Considering all 7,382 titles, 3,589 of them fall into the category  X  X ncertain X . Thus the simplest baselines which chooses the majority vote category would be correct roughly 48.6% of the time. The following table summarizes the results of our experiments:
Uni +Big +Co. P-2 P-3 +15Nov +16Nov 54.6 56.9 58.4 58.2 56.5 59.7 60.5
The Uni model has an accuracy of 54.6%, the best model is obtained adding bigrams and the company symbol (58.4%). Richer feature representations in the dual space with poly-nomial kernel functions of degree two (58.2%) and three (56.5%), were not useful. To estimate the impact of more training data we added to the linear model one day of stories (November 15, 752 titles), and two days of stories (15 and 16, 1566 titles) and testing on the remaining day(s). This amounts to adding respectively 16% and 35% more training data, but results improved only slightly (59.7% and 60.5%).
While the model outperforms the baseline, its accuracy is poor. By comparison, the same classifier with similar fea-tures achieves accuracies above 91% in classifying a TREC question classification data-set in 6 categories. Possibly, with higher quality data, e.g., larger in size and produced by several annotators, results might improve. However, it is known that classifying documents by opinion is a harder problem than classifying by topic, typically because the un-structured bag of words representation is not expressive eno-ugh a task which can involve sophisticated inferences [6].
To identify peculiar features of this task we analyzed the errors made by the system in the last experiment, compris-ing 256 news from November 17. The systems makes 101 errors which we inspected and classified according to the nature of the story with respect to the company. We pro-pose that there are six main patterns which emerge from the mistakes, listed below: The most frequent mistakes concern news about products or properties of a company ( X  X ROD X ); e.g., X  X eromexico chooses GEnx engines X  (GE), to classify this correctly it might be necessary to know that GEnx engines are prod-ucts of GE and that  X  X eing chosen X  is a positive event. The category  X  X NT X  concerns issues internal to the com-pany about lawsuits, scandals or company X  X  components; e.g.,  X  X ELL wrestles with its accounting X , here some knowl-edge of a company X  X  structure and internal dynamics could help.  X  X ND X  concerns remarks about the company X  X  indus-try sector; e.g.,  X  X nergy sector shrugs off crude weakness X .  X  X OMP X  news involve the company X  X  competitors; e.g.,  X  X P poised to unseat IBM X  (DELL),  X  X ong lines greet PlaySta-tion 3 debut X  (MSFT); these are typically very polarized stories. Some misclassified stories concern the general econ-omy news ( X  X CO X ); e.g.,  X  X en off low after Japan data X . A few mistakes ( X  X ROF X ) concern explicit mentions of profit or loss for the company ( X  X irst Solar rises after IPO X )
This analysis suggests that this type of task, in a broad-coverage setting, involves a significant amount of, partly domain-independent, world-knowledge which needs to be available to the system. Companies are not independent from each other: complex dependency structures are defined by relations such as competitor, allied, customer, sellers. Probably a structured learning approach would be benefi-cial. More NLP, e.g., syntactic analysis and detailed tree comparison [5], might be needed to capture the role of en-tities involved in a story; e.g., the same story  X  X  sues B over X X  can be good news for A (the subject) and bad for B (the object). We noticed also that several stories repeats in more or less the same form for different companies or from different sources or both. The classification of such stories might be best modeled as an ensemble and not in isolation since their classification mutually affect each other. More world knowledge needs to be used, to improve the represen-tation and uncover structure in the data. Such knowledge should be automatically generated in order to have enough coverage and be up-to-date.

There is valuable information to be gained in broad cov-erage settings. Less than 50% of the stories mention the full name or an abbreviation of the company the story refers to, the rest do not mention the company name or refer to related entities. Stories in the category uncertain have a considerable amount of cases with no explicit mention of the company. However almost 40% of the stories do not mention the company although they express polarized information. Finally, we suggest that the title polarity task, because it re-lies on rather transparent world knowledge-grounded infer-ences, could serve as a benchmark to evaluate the capability of systems to integrate and use world-knowledge. [1] K. Crammer and Y. Singer. Ultraconservative online [2] S. R. Das and M. Y. Chen. Yahoo! for Amazon: [3] V. Lavrenko, M. Schmill, D. Lawrie, P. Ogilvie, [4] D. Metzler, S. Dumais, and C. Meek. Similarity [5] A. Moschitti. Efficient convolution kernels for [6] B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up? [7] Y.-W. Seo, J. A. Giampapa, and K. P. Sycara. Text
