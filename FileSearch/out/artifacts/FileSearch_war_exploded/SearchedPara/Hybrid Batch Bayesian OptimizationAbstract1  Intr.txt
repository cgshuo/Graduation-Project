 Oregon State University, Corvallis, OR, 97330 USA UT Austin, 1 University Station C0806, Austin, TX, 78712 USA Oregon State University, Corvallis, OR, 97330 USA Bayesian optimization tries to optimize an unknown func-tion f (  X  ) by requesting a set of experiments where f (  X  ) is costly to evaluate (Jones, 2001; Brochu et al., 2009). In this work, we are interested in finding a point x  X   X  X d such that: where X d is a d -dimensional compact input space and f (  X  ) is the non-concave underlying function that has multiple lo-cal optima. The function f (  X  ) might be the performance of a black box device characterized by input x . For example, in our motivating application we try to optimize the power output of nano-enhanced Microbial Fuel Cells (MFCs). MFCs (Bond &amp; Lovley, 2003) use micro-organisms to gen-erate electricity. It has been shown that the power genera-tion efficiency of an MFC significantly depends on the sur-face properties of the anode (Park &amp; Zeikus, 2003). Our problem involves optimizing the surface properties of the anodes in order to maximize the output power. The goal is to develop an efficient BO algorithm for this application since running an experiment is very expensive and time consuming.
 Focusing on the task of function maximization, each run of BO consists of two main steps: estimating the values of the unknown function f (  X  ) via a probabilistic model such as GP, and selecting the best next experiment(s) according to the probabilistic model via some selection criterion. The selected experiments are then run and the results are added to update the probabilistic model. This cycle is repeated until we meet a stopping criterion.
 Most of the proposed selection criteria in BO are sequen-tial , where only one experiment is selected at each iteration (Moore &amp; Schneider, 1995; Jones, 2001; Sacks et al., 1989; Locatelli, 1997). Sequential policies usually perform very well in practice, since they optimize the experiment selec-tion at each iteration by using the maximum available in-formation for each experiment. However, they are not time efficient in many applications where running an experiment takes a long time, and we have the capability to run multiple experiments in parallel. This motivates batch algorithms that select more than one experiment at each iteration. Recently, Azimi et al. (2010) introduced a batch BO ap-proach that selects a batch of k experiments at each iter-ation that approximates the behavior of a given sequen-tial heuristic. Ginsbourger et al. (2010) introduced a con-stant liar heuristic algorithm to select a batch of experi-ments based on the Expected Improvement (EI) (Locatelli, 1997) policy. Specifically, after selecting an experiment by EI, the output of the selected point is set to a con-stant value. This experiment is then added to the prior and the procedure is repeated until k experiments are selected. Although these two batch algorithms (Azimi et al., 2010; Ginsbourger et al., 2010) can speedup the experiment se-lection by a factor of k , their results show that batch se-lection in general performs worse than the sequential EI policy, especially when the total number of experiments is small. This observation motivates us to introduce a Hybrid BO approach that dynamically alternates between sequen-tial and batch selection to achieve improved time efficiency over sequential without degrading the performance. In this paper, we focus on a class of batch policies that is based on simulating a sequential policy and provide a sys-tematic approach to analyze such batch BO policies. We analytically connect the mismatch between the BO X  X  prob-abilistic model and the underlying true function to the per-formance of the batch policy. We provide full characteriza-tion of simulated-based batch policies when the batch size is 2 . For the purpose of illustration, consider a batch policy that selects 2 experiments. The first experiment matches the sequential policy. The choice of the second experiment, however, will depend on what is the simulated outcome of the first experiment. We show that the distance between the second experiment picked by a simulation-based batch pol-icy (without the knowledge of the output of the first experi-ment) and the one picked by the sequential policy (with the knowledge of the output of the first experiment) is upper-bounded by a quantity that is proportional to the square root of the estimation error.
 This analysis naturally gives rise to our hybrid batch/sequential algorithm. Our algorithm works as follows: At each step, given any sequential policy (EI in this paper), find the best next single experiment and estimate its possible outcome via BO X  X  probabilistic model (GP in this paper). Then, update the prior with that point and choose the next best single experiment and so on. We analytically show that this process can be continued until certain stopping criterion is met. This stopping criterion measures how much a simulated experiment is going to bias our probabilistic model (mainly because of inaccuracy in estimation of the outcomes of the first experiment). If the bias is small, we continue to add more examples to our batch; and if it is large, we stop.
 The proposed algorithm has the appealing property that it behaves more like a sequential policy in early stages when the number of observed experiments is small, and naturally transits to batch mode in later stages when more experi-ments are available. This is because the stopping criterion tends to be more stringent in early stages because the bias of the prior can be potentially large, forcing the algorithm to act sequentially. The beauty of this algorithm is that it evolves from a sequential algorithm to a batch algorithm in an optimal manner characterized by our theoretical results. Experimental results show that the proposed algorithm can achieve up to 78% speedup over the sequential policy with-out degrading the performance even with a very small num-ber of experiments.
 The paper is organized as follows. We introduce the Gaus-sian Process which is used as our model in Section 2. The proposed dynamic batch algorithm is described in Section 3. Section 4 presents the experimental results and the paper is concluded in Section 5. A BO algorithm has two main ingredients: a probabilistic model for the unknown function, and, a selection criterion for choosing next best experiment(s) based on the model. We select GP (Rasmussen &amp; Williams, 2006) as our proba-bilistic model and EI (Locatelli, 1997) as our selection cri-terion. We study the properties of GP in this section and postpone the analysis of EI to the next section.
 We use GP to build the posterior over the outcome val-ues given our observation set O = ( x O , y O ) , where, x O = { x 1 ,x 2 ,...,x n } is the set of inputs and y { y 1 ,y 2 ,...,y n } is the set of outcomes (of the experiment) such that y j = f ( x j ) and f (  X  ) is the underlying function. For a new input point x i , GP models the un-known output y i = f ( x i ) as a normal random variable y i  X  N (  X  x k ( x i , x O ) k ( x O , x O )  X  1 y O and  X  2 x bitrary kernel function .
 Definition 1. Let x = { x 1 ,x 2 ,...,x m }  X  X \ x O be any unobserved set of points. Let be our estimate of their outputs based on GP considering y |O  X  N (  X  x { x
O  X  x } , let y z |O  X  X  (  X  z |O , X  2 z |O ) and y z |O , ( x , N ( Under the GP model, the variance of a point z depends only on the location of the observed points and is independent of their outputs, i.e., update the variance of any point z after finalizing our new query set x without the knowledge of their true outputs y = f ( x ) . The following theorem characterizes the change in the variance of z if we query x .
 Theorem 1. Assuming  X (  X  z ) :=  X  2 z |O  X   X  2 z |O , x , we have  X (  X  z ) = CA  X  1 B T  X  k ( z, x ) D CA  X  1 B T  X  k ( z, x ) From a practical point of view, this theorem enables us to update the variance of z via computing the  X (  X  z ) and add it to the previous value. This is much faster than recalcu-lating the variance of z directly. The computational bottle-neck of this update is only the matrix inversion in D with complexity O ( m 3 ) , considering the fact that k ( x O , x has been computed before, while the complexity of the di-rect variance computation is O ( n + m ) 3 .
 The actual expected value  X  z |O , x heavily depends on the true outputs y = f ( x ) , which are not available. Without the knowledge of the true outputs, we make an estimation b  X  z |O , x based on the GP-suggested output values b y . We bound this estimation error in the next theorem.
 Theorem 2. Let  X  z = ( k ( z, x )  X  CA  X  1 B T ) D Here, k X k 2 is vector 2-norm. This theorem tells us that our estimation error at point z is proportional to the parameter  X  , which is known to us without the knowledge of y . In-tuitively, if  X  z is small, we would think that our estimation b  X  z |O , x is accurate and hence, we can make our decision about the point z without knowing y , i.e., before the result of experiment on x returns. This tells us that it is possible to do batch BO without a big loss in performance.
 Remark: If we want to minimize our estimation error of b  X  z |O , x in expectation, we should set b y =  X  x |O . This is in some sense trivial and even counter intuitive. One might claim that if the unknown function is upper-bounded by M , then the best choice for expected value around the optimal point in the GP model. However, this theorem shows that this choice is overly op-timistic.
 The previous theorem provides a performance bound based on our estimation error on point of view, that bound cannot be computed since we do not know the exact values of y . As a practical measure, we would like to focus on the expected value of the estimation error as opposed to the error itself. Next corollary provides an upper-bound on the expected error, by simply taking expectation from the result of theorem 2.
 Corollary 1. Let  X  x := q P m i =1  X  2 x Moreover, Remark 1: We focus on the second bound in this corollary, which has two terms. The first term (  X  z  X  x ) measures  X  X ow close X  the point z is to x . The second term captures the bias of our estimator best choice for Remark 2: This corollary entails that if for some small value of , we have then, we are guaranteed that Since  X  z and  X  x are both computable without the knowl-edge of y , this observation motivates us to use this as a stopping criterion for our algorithm to determine if the cur-rent estimation bias is too large to continue selecting more examples in the batch. In the nutshell, when we want to query a batch of samples, if this criterion is met, we are sure that our estimation of y is accurate and hence, we do not need to wait for the label of the selected examples be-fore making the next selection. In a sequential approach, we query for only one experi-ment at a time using a selection criterion (policy), mainly because the selection criterion requires the output of the previous query to find the next best one. Suppose we have the capability of running n b experiments in parallel, and we are limited by the total number of possible experiments n . At each iteration, the question is whether or not we can query more than one sample to speed up the experimental procedure without losing performance comparing to the se-quential approach. We use Expected Improvement (EI) as our base sequential selection criterion. Below we provide the formal definition for EI.
 Definition 2. EI(Locatelli, 1997) at point x with associated GP prediction y |O  X  X  (  X  x |O , X  2 x |O ) is defined to be where, u = ( y max  X   X  x |O ) / X  x |O and y max = max Also,  X (  X  ) and  X  (  X  ) represent standard Gaussian distribu-tion and density functions respectively.
 Our proposed algorithm selects a batch (possibly one) of samples at each iteration based on the EI policy, where the batch size is dynamically determined at each step. In par-ticular, the algorithm will continue to select more experi-ments if the condition in (3) is satisfied for the point z . To explain the algorithm, suppose we are at the beginning of the first round of the algorithm. Thus far, we have ob-served y O = f ( x O ) at some randomly chosen sample points x O . To form our batch query, we start from an empty set of samples and gradually add the next best sample one at a time. The first sample we pick ( x 1 ) is identical to the first sample that sequential EI picks ( x  X  1 ), simply because both maximize the same objective, i.e., x 1 = x  X  1 . To pick our second sample, we estimate y  X  1 = f ( x  X  1 ) by some value  X  y . This estimation, changes the EI function of all unob-served points to some c EI function formulated as where, the true EI function: c EI might not lead to the optimum of the true EI . However, the next lemma shows that these two functions are close to each other for a good estimation  X  y 1 .
 Lemma 1. At any point z , we have In the light of this lemma, there is hope that x arg max c EI (a potential batch sample from our algorithm) is close to x  X  2 = arg max EI (the optimal sample picked by sequential policy). The next theorem bounds the error of our algorithm in terms of the second selected point in comparison to the sequential EI.
 Theorem 3. Let  X  min be the minimum singular value of the Hessian matrix d 2 c EI dx 2 ( x ) on the line intersecting x x . Then, Here x 2 is the second point selected by our simulation based batch method without knowing the outcome of x 1 , whereas x  X  2 is the second point selected by the sequential EI method after knowing the outcome of x 1 .
 Remark 1: The parameter  X  min captures the curvature of the c EI function around its optimal point x 2 . This curvature cannot be zero unless x  X  2 is very far from x 2 , which is very unlikely due to the closeness of their expected values (see Corollary 1).
 Remark 2: This theorem shows that the sample estimation error is proportional to the square root of the estimation error of y  X  1 . This means that the sample estimation is more sensitive to the output estimation error for functions taking value in [0 , 1] .
 This line of analysis can be extended to next samples. These results show that an algorithm based on the es-timation can be successful. In practice, after we opti-mized c EI for x 2 , then, we check the condition (3) (i.e.,  X  isfied, we add x 2 to our batch query and move on to x 3 and so on. Algorithm 1 summarizes our proposed method for hybrid batch Bayesian optimization.
 Algorithm 1 Hybrid Batch Expected Improvement Input: Total budget of experiments ( n l ), maximum batch size In early stages, this algorithm behaves more like a sequen-tial policy since the criterion for building up a batch is very hard to satisfy, mainly because  X  x is large when we have only a few samples in O . After collecting enough samples, the term  X  x starts decreasing and as it gets closer and closer to zero, we can select larger and larger batch sizes. Thus, the algorithm gradually transits into a batch policy while maintaining a close match to the performance to the pure sequential policy. Benchmarks. We consider 6 well-known synthetic bench-mark functions: Cosines and Rosenbrock (Anderson et al., 2000; Brunato et al., 2006) over [0 , 1] 2 , Hartman(3) (Dixon &amp; Szeg, 1978) over [0 , 1] 3 , Hartman(6) (Dixon &amp; Szeg, 1978) over [0 , 1] 6 , Shekel (Dixon &amp; Szeg, 1978) over [3 , 6] and Michalewicz (Michalewicz, 1994) over [0 , X  ] 5 . The an-alytic expression for these functions are shown in Table 1. The other two real benchmarks are Fuel Cell and Hydro-gen . In Fuel Cell, the goal is to maximize the generated electricity from microbial fuel cells with by changing the nano structure properties of the anodes. We fit a regression model on the data to build our function f (  X  ) for evaluation. In Hydrogen benchmark, the data has been collected as part of a study on Hydrogen production from a particular bacte-ria where the goal is to maximize the amount of Hydrogen production by optimizing the PH and Nitrogen levels of growth medium. Both Fuel cell and Hydrogen data are in [0 , 1] 2 . Their contour plots are shown in Figure 1. Setting. We use a GP using a zero-mean prior and Gaussian kernel function k ( x,y ) = exp (  X  1 l k x  X  y k 2 ) , with kernel width l = 0 . 01 X  d i =1 l i , where, l i is the length of the i th dimension (Azimi et al., 2010). For this kernel function, we can directly drive the next two corollaries from theorems 1, 2.
 Corollary 2. For all points z  X  X \{O ,x  X  1 } , and kernel This corollary entails that after selecting the first ex-periment x  X  1 , the set of points z such that  X (  X  z are located inside a hyper sphere centered at x  X  1 other words, the variance of those inside the hyper sphere are affected significantly (more than ) when x  X  1 is selected. Corollary 3. Under the assumption of Corollary 2, we Similar to corollary 2, the corollary 3 represents a hyper sphere centered at x  X  1 and the points which are inside the hyper sphere are those whose expected values are affected more than when x  X  1 is selected.
 We run our algorithm on each benchmark for 100 inde-pendent times and the average simple regret is reported as the result. The simple regret is the difference between the maximum value of f (  X  ) , denoted by M , and y after finishing the experimental procedure. In each run, the algorithm starts with 2 initial random points for 2 , 3 -dimensional benchmarks and 5 initial random points for higher dimensional benchmarks. The total number of ex-periments n l is set to 15 for 2 , 3 -dimensional and 30 for the higher dimensional benchmarks. The maximum batch size at each iteration, n b , is set to 5 . The parameter is set to 0 . 02 for 2 , 3 -dimensional and 0 . 2 for higher dimensional benchmarks. Note that, our experimental setup is designed to match typical scenarios encountered in real applications, where we typically start with a very small number of ran-dom experiments, and are restricted with a total budget. Results. Our algorithm requires us to select a specific es-timation for  X  y . Recall that our theoretical analysis from Theorem 2 suggests that to minimize the estimation error of b  X  z |O , x in expectation, we should use we hope to confirm this by comparing different possible es-timations for  X  y . In particular, we consider 6 different esti-mations of  X  y including: 1)  X  y = M , which means we expect to observe the best possible output for each experiment se-lected by EI; 2)  X  y = y max , where y max = max y i  X  y is our current best observation; 3)  X  y = (1 +  X  ) y max , which means each step of EI algorithm is expected to improve the best current observation by margin  X  , we set the value of  X  to 0 . 1 in our experiment; 4)  X  y = set the value of  X  y to be the expected output at that point; minimum observed output; and 6)  X  y = random , which set  X  y to a uniform random value drawn in [ y min ,y max ] . To demonstrate the effectiveness of our algorithm, we con-sider two state-of-the-art batch BO algorithms in the lit-erature: 1) simulation matching (Matching) (Azimi et al., 2010) and 2) the constant liar approach in which the output of the selected samples in the batch is set to their mean in order to select the next experiment (CL(  X   X  )) (Ginsbourger et al., 2010). For both methods, we set the batch size to k = 5 . We have also reported the performance of the se-quential EI and pure random selection policies.
 The speedup of our proposed approach is calculated as the percentage of the samples in the whole experiment that are selected in batch mode. More specifically, if we finish n samples in T steps, the speedup is calculated as 1  X  T n Clearly, the maximum speedup in our setting is %80 , that can be only achieved if we select 5 experiments at each time steps. For example, the speedup of proposed baseline batch approaches, Matching and CL(  X   X  ), are %80 . Table 2 shows the result.
 Interestingly, all of the 6 considered estimators achieved similar performance (comparable to EI) in terms of their regrets. The key difference between the different estima-tors is the level of speedup they achieve. In particular, we observe that the most speedup is achieved by  X  y = for which we are able to produce over 70% speedup (very close to fully batch) for the three high dimensional func-tions Michalewicz, Shekel and Hartman 6.
 Further inspection of the speedup rates reveal that setting  X  y to a large value, for example M , y max , and (1 +  X  ) y max generally leads to less speedup than the other choices. This can be explained by noting that a large value of  X  y will lead to higher chance of violating the condition required for making the next experiment selection in Algorithm 1, which is stated in Equation 3. In particular, for a large  X  y , the next point selected by EI will most likely be very close to x , since the mean of the points close to x are high. This will lead to a large  X  z . Further, the quantity k is likely very large. Consequently, it is easy to violate this condition thus stop the selection process early on. In con-trast, if  X  y = y min , although k  X  z to be small because the next point z selected by EI will likely to be far away from x since the mean and variance of the points close to x are very small. Considering the two terms jointly, we expect to achieve a higher speedup by setting  X  y = y min comparing to setting  X  y to a large value, which is exactly what we observe in our experiments. Fi-nally, by setting  X  y to  X  x |O , we have k the stopping criterion only depends on  X  z  X  x . Thus we ex-pect to achieve the maximum speedup among the different choices we consider for  X  y .
 Our experimental investigation shows that the size of the batch generally increases as the experiment goes forward. This is consistent with our theoretical results in which the value of  X  z  X  x + k decreases. Note that, sampling at any arbitrary point when the number of observations is small would change the vari-ance of the input space significantly comparing to the case where there are a lot of observation points. Therefore, the stopping criteria of Algorithm 1 is less likely to be met in the early stages of the experimental procedure where there are a few observation points.
 The  X  -Constant Batch Approach. This part of the ex-periments is motivated by our theoretical analysis and the goal is to shed some lights on a batch method recently pro-posed by Ginsbourger et al. (2010), which selects a batch of experiments that jointly maximize the EI objective. They show that finding such a batch of experiments is practi-cally intractable. Therefore, they introduced a heuristic approach called Constant liar to select a batch of k ex-periments. After selecting the first experiment, Constant liar sets the output of the selected experiment as a constant value c . That experiment is then added to the set of observa-tions and the next experiment is selected. This procedure is repeated until k experiments are selected. They introduced several possible ways for setting c , including c = M , c = and c = y min . They empirically demonstrated that setting c = M provided them a good result for their particular test functions. However, there is no theoretical justification or guidance toward what is the best c .
 Our theoretical analysis, in particular Corollary 1, indicates that by setting c (  X  y in this paper) to for continued experiment selection can be easily met com-paring to other settings, i.e.,  X  z  X  x  X  . Thus, a batch of k  X  1 experiments are requested at most iterations with-out degrading the performance. This theoretical result also justifies the choice of setting c = approach. We call this approach  X  -Constant Batch. We run this algorithm on proposed 8 benchmarks for different batch sizes 5 and 10 . Figures 2 and 3 show the performance of  X  -Constant along with 5 competitive approaches: 1) Se-quential EI; 2) Constant liar with  X  y = M ; 3) Constant liar with  X  y = y max ; 4) Constant liar with  X  y = y min ; and 5) Matching, which is a recently proposed approach by Azimi et al. (2010). For this set of experiments, we use the same experimental setup as used in Table 2.
 The results show that the  X  -constant batch approach per-forms very competitively compared to the Matching ap-proach, which is one of the best existing batch Bayesian optimization approach in the literature. In addition, it is more practical than the Matching approach for high dimen-sional applications since its computational complexity is significantly less than the Matching algorithm. Note that the performance of  X  -Constant is also shown in Table 2 as CL(  X   X  ). It is worth emphasizing that while  X  -Constant achieves highly competitive batch performance, it is con-sistently worse than sequential EI and the proposed Hy-brid Batch EI algorithm. This result suggests that the stop-ping criterion used in Algorithm 1 is in fact effective to-ward identifying the condition under which we must stop increasing the batch size to avoid significant performance degradation compared to the sequential EI. In the Bayesian optimization framework, we investigated the problem of batch query selection with the goal of main-taining the performance of a sequential policy which using fewer iterations. Although our results are for general BO problems, for the sake of clarity, we focused on the task of maximizing an unknown non-convex/concave function. There are two main contributions in this paper.
 Firstly, we introduce a systematic way to analyze the per-formance and limits of simulation-based batch BO methods by a) proving universal bounds on the bias caused by the simulation error; and b) analyzing the selection of the sec-ond experiment when we have an estimate of the outcome of the first experiment. In all cases, we provide theoreti-cal bounds on the error, relating the simulation error to the prediction error of the next best experiment.
 Secondly, based on the analysis above, we proposed an al-gorithm that behaves optimally in expectation. This algo-rithm at each step decides whether or not to pick another query to add to the current batch, and as such dynamically determines the appropriate batch size at each step. In early iterations, our algorithm behaves more similar to the se-quential policy and gradually moves toward a batch policy with variable batch sizes.
 The empirical evaluation over both synthetic and real data shows substantial speedup (up to 78% ) compared to the corresponding sequential policy, with little to nothing loss in the optimization performance. Our theoretical results also shed some interesting light on the Constant-liar ap-proach, a recently proposed batch selection method based on the EI objective.
 The authors acknowledge the support of the NSF under grants IIS-1055113.
 Anderson, Brigham S., Moore, Andrew, and Cohn, David.
A nonparametric approach to noisy and costly optimiza-tion. In ICML , 2000.
 Azimi, Javad, Fern, Alan, and Fern, Xiaoli. Batch bayesian optimization via simulation matching. In NIPS , 2010. Bond, D. and Lovley, D. Electricity production by geobac-ter sulfurreducens attached to electrodes. Applications of Environmental Microbiology , pp. 1548 X 1555, 2003. Brochu, Eric, Cora, Vlad M., and de Freitas, Nando. A tu-torial on Bayesian optimization of expensive cost func-tions, with application to active user modeling and hier-archical reinforcement learning. Technical Report TR-2009-23, 2009.
 Brunato, Mauro, Battiti, Roberto, and Pasupuleti, Srini-vas. A memory-based rash optimizer. In AAAI-06 Work-shop on Heuristic Search, Memory Based Heuristics and Their applications , 2006.
 Dixon, L.C.W. and Szeg, G.P. The Global Optimization
Problem: An Introduction Toward Global Optimization . 1978.
 Ginsbourger, David, Riche, Rodolphe Le, and Carraro,
Laurent. Kriging is well-suited to parallelize optimiza-tion. Computational Intelligence In Expensive Optimiza-tion Problems , pp. 131 X 162, 2010.
 Jones, D. A taxonomy of global optimization methods based on response surfaces. Journal of Global Optimiza-tion , 21:345 X 383, 2001.
 Locatelli, M. Bayesian algorithms for one-dimensional globaloptimization. J. of Global Optimization , 1997. Michalewicz, Zbigniew. Genetic algorithms + data struc-tures = evolution programs (2nd, extended ed.) . 1994. Moore, Andrew and Schneider, Jeff. Memory-based stochastic optimization. In NIPS , 1995.
 Park, D. and Zeikus, J. Improved fuel cell and electrode designs for producing electricity from microbial degra-dation. Biotechnol.Bioeng. , pp. 348 X 355, 2003.
 Rasmussen, Carl Edward and Williams, Christopher K. I. Gaussian Processes for Machine Learning . MIT, 2006. Sacks, Jerome, Welch, William J., Mitchell, Toby J., and
Wynn, Henry P. Design and analysis of computer exper-
