 1. Introduction
Model Predictive Control (MPC) ( Maciejowski, 2002 )isan optimal control technique, in which the controller uses an internal process model to predict the process output over a certain number of sample steps (called the prediction horizon) to calculate optimal control moves for the system. One of the main advantages of this control technique is the systematic and intuitive manner in which constraints are incorporated into the control system and the fact that delays are naturally catered for. It is a mature technology at this stage, with stability and robustness analysis well established.

However, for large systems such as the electricity grid, it is often impractical to implement MPC from a central controller, due to computational constraints. Likewise it is often desirable or necessary to use a number of separate controllers, referred to as agents, to control subsystems, e.g., in a deregulated power market several controllers may be responsible for the control of different sections of the power grid. Likewise, when power systems span several countries, then each country will typically have separate controllers for their own sections of the grid.

There has been much research interest in recent years in distributed MPC ( Scattolini, 2009 ), in which several agents com-municate and cooperate with each other to approximate the behaviour of a centralised MPC agent. In non-iterative distributed MPC techniques such as those proposed in Liu et al. (2010 , 2009 ) ;
Camponogara et al. (2002) agents only communicate with each other once per sample step. In iterative distributed MPC techni-ques, agents communicate with each other a number of times at each sample step. There are a wide variety of iterative distributed
MPC techniques in the literature. In Sanchez et al. (2011) the distributed MPC problem is framed as an iterative game that seeks out Pareto or Nash equilibria. In Venkat (2006) a Jacobian decomposition of the original centralised MPC problem is used to distribute the centralised problem over a number of agents who perform a number of optimisations in parallel until the input variables converge. A number of dual decomposition methods have also been used to distribute the MPC problem. These problems are iterative due to the alternating minimisations of the primal problem and updating of the Lagrange multipliers, which repeat until the Lagrange multipliers converge. In Scheu and Marquardt (2011) agents optimise in parallel and a sensitivity based approach is used in order to distribute the control. In this case the Lagrange multipliers are used to handle equality and inequality constraints. In Necoara et al. (2008) a proximal center based dual decomposition method is proposed for distributing the control. Agents optimise in parallel and Lagrange multipliers are used to handle equality constraints, which agents use when seek-ing to form consensus. In Giselsson and Rantzer (2010) equality constraints are placed on interconnecting variables between agents to form consensus and control is distributed using dual decomposition. Agents optimise in parallel and a distributed stopping criterion is proposed based on relaxed dynamic pro-gramming. In Negenborn et al. (2008) a parallel and a serial distributed MPC method are proposed. Equality constraints between interconnecting variables are again applied in order to obtain consensus between agents. These equality constraints are incorporated into the cost function using an augmented Lagran-gian formulation. First, the control was distributed in a parallel fashion using the Auxiliary Problem Principle. Then, a second method distributed the control in a serial fashion, using the
Alternating Direction Method of Multipliers. While connected agents must optimise here in a serial fashion non-connected agents can optimise in parallel.
 of the various goals contained in the MPC cost function during optimization. By tuning the weights appropriately, MPC perfor-mance can be improved, given a specific performance criterion.
The equivalent in classical control would be the tuning of PID parameters to achieve desired performance. In classical control scenarios, stochastic search techniques such as Simulated Anneal-ing ( Kwok and Sheng, 1994 ), Genetic Algorithms (GA) ( Jones and
De Moura Oliveira, 1995 ), and Particle Swarm Optimisation (PSO) ( Gaing, 2004 ) have proven to be efficient ways of finding optimal values for PID gains.
 PID gains ( Fabijanski and Lagoda, 2008 ; Jones and De Moura
Oliveira, 1995 ; Lin and Liu, 2010 ). However, recently the advan-tages of using PSO over GA for the optimisation of PID gains have been demonstrated, in terms of both the quality of and the efficiency with which a final solution can be found. The reason for this is that PSO performs better than GA when optimising epistatic functions, i.e., functions where there is a high level of correlation between the parameters being optimised ( Gaing, 2004 ).
 literature for tuning weights ( Di Cairano and Bemporad, 2010 ; Lee and Yu, 1994 ; Rowe and Maciejowski, 2000 ). PSO has been used in Suzuki et al. (2007) for this purpose, with promising results.
PSO is attractive for tuning for a number of reasons. Its capability to optimise on a wide range of surfaces, which may be convex, non-convex, discontinuous, or multi-modal ( Trelea, 2003 ; Liang et al., 2006 ), means that PSO is flexible in terms of what criterion can be used to determine the fitness of given weights. Also no special knowledge is needed about the MPC algorithm being used and so it is user friendly for industrial practitioners. PSO is preferrable in comparison with GA for weight optimisation due to the level of correlation between weights when optimising in an MPC setting.
 ques have yet been proposed for distributed MPC. While typically in centralised MPC one is concerned with tuning weights so as to distributed MPC algorithms it is typically desirable to choose weights so as to achieve a good trade off between setpoint tracking and the communication overhead. In these algorithms, agents must communicate at each iteration with adjacent agents.
The level of communication needed depends largely on the number of iterations needed for agents to form a consensus on inputs and interconnecting variables.
 longer sample times (e.g., chemical plants), high levels of com-munication may not be important, as agents have sufficient time to communicate with each other before applying control inputs to the plant. However, in large networks with fast dynamics, such as power networks, it is necessary that the number of such iterations is small, as the short sample times constrain the time allowed for communication. Therefore, it is important that iterative distributed MPC systems could be tuned to minimise the number of iterations needed for the algorithm to reach convergence at each sample step, while maintaining a desirable closed loop performance. Given the large number of tunable parameters in iterative distributed MPC, it is non-trivial to attain the desired closed loop performance while maintaining a low level of iterations needed to achieve convergence through manual tuning. Thus it is useful to develop an automated process for tuning these parameters.

In this paper, a novel PSO based weight optimisation algorithm is proposed for iterative distributed MPC. This weight tuning algorithm simultaneously optimises both the closed loop perfor-mance of the system and the communication overhead. The communication overhead is reduced by using an iteration deter-rent that penalises increases in the maximum number of itera-tions needed for convergence of the distributed MPC algorithm.
The authors are not aware of an attempt to minimise iterations through parameter tuning before or for that matter of a tuning technique in which minimisation of the iterations is considered. A stochastic search technique is necessary here as the surface being optimised is non-convex and the use of the iteration deterrent results in discontinuities in the surface. PSO is suitable for use on non-convex and discontinuous surfaces and has also previously been shown to outperform other stochastic search algorithms when tuning controller gains, as was stated previously. To the authors X  knowledge the use of PSO to reduce the number of iterations needed for a distributed controller to achieve desired control is novel to the AI community.

In this paper the weight tuning technique for iterative distributed MPC will be evaluated on two different multi-agent
Load Frequency Control (LFC) case studies. The first system is a discrete-time 20 area LFC problem, which has a large number of tunable parameters, thus making it difficult to tune. The second system is a smaller scale, continuous-time multiple High Voltage
Direct Current (HVDC) link problem. While there are less tunable parameters in this problem, a large number of iterations may be needed to achieve convergence of the distributed MPC problem at each sample step. It is difficult in this problem to find a set of weights to yield a desirable trade off between disturbance rejection and the communication overhead. The distributed MPC algorithm used in this paper to illustrate the potential of the PSO tuning algorithm is Negenborn et al. (2008) . This algorithm is suitable for use in deregulated and large scale power networks where agents are typically only capable of exchanging informa-tion related to interconnecting variables with other agents. In each of the applications, distributed MPC weights are also optimised based only on the closed loop performance and a comparison is made between this case and the case in which the iteration deterrent is also used.

This paper is organised as follows: In Section 2 the iterative distributed MPC used in this paper will be presented briefly.
Section 3 will introduce the PSO algorithm in detail. In Section 4 the novel PSO based iterative distributed MPC tuning algorithm is presented. It will then be seen, in Section 5 , how this weight optimisation affects the performance of two multi-agent power networks. Conclusions will be given in Section 6 . 2. Iterative distributed model predictive control
Model Predictive Control ( Maciejowski, 2002 ) is an advanced control technique that utilises real-time optimisation. It uses pre-dictions, based on a suitable mod el, in order to provide optimal control inputs to a system. One of its main advantages over other control techniques is its ability to incorporate constraints into its stability, and robustness proofs well established ( Rawlings and Mayne, 2009 ). 2.1. Definition of an agent
For clarity the definition of an agent, as understood in this paper, will now be provided. An agent is defined here as an entity responsible for the control of a system or subsystem, with access to the current state of the system or subsystem it controls. The agent X  X  local states are accessed by direct measurement or estimation. Agents have access to a model of the local system or subsystem and in the distributed case, each agent is able to communicate with all other agents who share a common variable with that agent. Agents compute values for their control inputs at discrete time steps based on the information available to them. 2.2. Description and state X  X pace prediction
In MPC a control agent uses a discrete-time system model that predicts the system X  X  future trajectory over a prediction horizon in order to calculate the optimal inputs over this horizon. Only the input for the first time step is applied. At the next time step a new action is determined. MPC is often called Receding Horizon Control due to the prediction horizon moving forward each time step.

A system consisting of n subsystems is considered, where each subsystem consists of a set of nodes (a node being an individual point in a network that can be described using a combination of variables and equations) and the interconnections between these nodes. Subsystems are assumed to be non-overlapping, i.e., nodes do not appear in 2 different subsystems. A discrete-time, linear, time-invariant state X  X pace model is used to model the subsystem dynamics. This is given as follows: x  X  k  X  1  X  X  A a x a  X  k  X  X  B a u a  X  k  X  X  D a d a  X  k  X  X  V y  X  k  X  X  C a x a  X  k  X  ,  X  2  X  subsystem inputs, d a  X  k  X  are known disturbances, y a  X  k  X  are subsystem outputs, v a  X  k  X  are external inputs from other subsys-tems that influence subsystem a at sample step k , and A a V , and C a are the state X  X pace matrices.

To simplify notation, the prediction vector, over a horizon N is first introduced. For a general vector z , its prediction vector is ~ z over the prediction horizon are then determined using recursive substitution on (1) as follows: ~ x  X  k  X  1  X  X  A f a x a  X  k  X  X  B f a ~ u a  X  k  X  X  D f a ~ d a derivation of these matrices is well established in the literature ( Maciejowski, 2002 ). 2.3. Iterative distributed MPC formulation
In a system of n subsystems, with agents 1 , ... , n , assume initially that agent a has access to x a  X  k  X  , ~ d a  X  k  X  , and following optimisation problem is then solved at each time step: ~ u  X  k  X  X  arg min subject to constraints where I and E are two finite sets of indices, and c i , for i for a
A I , are the equality and inequality constraints of the problem, respectively, and x  X  k  X  X  X  x T 1  X  k  X  , ... , x  X  k  X 
T , d  X  X  d T 1  X  k  X  , ... , d T n  X  k  X  T , and v  X  X  v T cost of subsystem a at sample time k is (henceforth,
J  X  x a  X  k  X  , ~ u a  X  k  X  , ~ d a  X  k  X  , ~ v a  X  k  X  X  is denoted as J
J  X  k  X  X  horizon for subsystem a at sample step k , typically defined as the following quadratic cost function:
J  X  k , p  X  X  e T a  X  k  X  p  X  1  X  Q a e a  X  k  X  p  X  1  X  of the prediction horizon, at sample time k . The error is given by e setpoints of agent a . It is assumed here that the pair  X  A observable.

The weighting matrices Q a and R a have only non-negative diagonal elements. These matrices determine the relative impor-tance of the minimisation of the error and the control effort from sample to sample during optimisation, respectively. The tuning of these parameters significantly influences the behaviour of the control system.

Let there be a set of agents, with indices j A N a , that are connected to agent a through its external input vector v a interconnecting input vector, w in ja , is defined as the vector of inputs to control problem a from agent j and the interconnecting output vector w out ja is defined as the vector of outputs to control problem j from agent a . When many subsystems are intercon-nected, then knowledge of ~ w in ja  X  k  X  cannot be assumed, as is actually dependent on the dynamics of other subsystems.
Hence, subsystems must reach a consensus on values for these interconnecting variables.

In distributed MPC systems, inter-agent communication is used in order to coordinate system control actions. In Negenborn et al. (2008) a serial method is proposed where agents solve their local problems, and consensus on interconnecting variables is ensured by placing equality constraints on corresponding interconnecting inputs and outputs over the full prediction horizon. These equality constraints are handled using an augmented Lagrangian formulation and the Alternating Direction Method of Multipliers ( Bertsekas and
Tsitsikilis, 1989 ; Tosserams et al., 2008 ) is used to distribute the control over the agents.

Under this scheme the optimisation problem of agent a , for iteration l of the distributed MPC cycle, at time step k is:
J  X  k , l  X  X  and J ja  X  k , l  X  is the cost associated with the inter-agent coordina-tion with agent j given by
J  X  k , l  X  X  associated with the interconnecting constraints ~ w in ja at iteration l ,andtimestep k .
 nicating the interconnecting variables with its neighbours. The performed an optimisation. When the optimisation cycle is finished, the Lagrange multipliers are updated as follows: ~ k in ja  X  k , l  X  1  X  X  ~ k in ja  X  k , l  X  X  c  X  ~ w in ja Iterations continue until:
J ~ k where E is a specified tolerance and J : J 1 denotes the infinity norm.
 gives to achieving consensus with other connected agents versus parameters of the distributed MPC, and the Q a and R a parameters on the closed loop performance of the system and on the amount of communication used by the distributed MPC scheme to achieve this control. Therefore, it is of interest to develop methods that can be used to tune these parameters so as to give the desired control performance. So far, there are no structured methods capable of doing this tuning. 3. Particle Swarm Optimisation technique based on the social behaviour of swarms of flocking animals ( Kennedy and Eberhart, 1995 ). It is suitable for the optimisation of convex or non-convex, continuous or discontinuous surfaces. It works by initialising a number of candidate solutions, called particles, in the parameter space being searched, and then updating their positions over a number of iterations, in such a way so as to converge to a final (ideally global) optimal solution. cost function f ) is as follows: 1. Initialise a population of P particles in d dimensions, within vectors with entries uniformly distributed in the interval [0,1], the positive scalar o is the inertial weight which controls the exploration and exploitation in the search space, and c 1 are acceleration constants called the cognition and social components, respectively.

Applied particle velocities are bounded by v q min r v q app where v q min and v q max are the lower and upper bounds on particle velocities, respectively, and v q app is the applied particle velocity. If v q  X  i  X  1  X  exceeds the aforementioned velocity bounds, the applied velocity, v q app , is taken at the upper or lower bound, i.e., if v q o v q min , let v q app  X  v q min algorithm is then updated for the next iteration as follows: x q  X  i  X  1  X  X  x q  X  i  X  X  T v q app  X  i  X  1  X  ,  X  13  X  where time step T  X  1. 3. Evaluate the cost function values at each of the P particles X  positions. 4. If for particle q , f q  X  i  X  1  X  o f b q  X  i  X  , then let x f q  X  i  X  1  X  o f g  X  i  X  , let x g  X  i  X  1  X  X  x q  X  i  X  1  X  .If f iteration i . 5. Repeat steps (2) X (4) until termination criteria are met, e.g., a maximum amount of iterations has been reached, x g  X  i  X  has not changed for a given number of iterations, etc. 4. PSO weight optimisation for distributed MPC
In this section a novel PSO based weight optimisation algorithm for iterative distributed MPC is proposed that minimises inter-agent communication while maintaining a desirable closed loop perfor-mance. Inter-agent communication is minimised through the pena-lisation of the maximum number of iterations needed for the iterative distributed MPC to converge for a given worst case scenario.

The vector C  X  X  Q 1 ... Q n , R 1 ... R n , c , E T contains n weights, consisting of the distributed MPC disturbance rejection performance related weights associated with each agent X  X  local problem,givenin(20),andthe c and E weights that are associated with achieving consensus between agents. For each of the P particles in the PSO, of dimension d  X  n c , a distributed MPC simulation is scenario that excites each of the subsystems controlled by the distributed MPC agents sufficiently, to prepare the system for the worst contingencies that might arise. The j th agent X  X  local fitness the overall disturbance rejection fitness, for the q th particle X  X  simulation run at PSO iteration i . When a system is optimised for disturbance rejection only (henceforth referred to as the DR only case), the fitness of particle q in the swarm is given by f  X  i  X  X  where f q  X  i  X  is the fitness of particle q at iteration i of the PSO algorithm.

In order to minimise the number of iterations used in a given simulation, an iteration suppressing cost r  X  q , i  X  is used where  X  q , i  X  X  max  X  l  X  q , i  X  X  ,  X  15  X  where l  X  q , i  X  is a vector of the number of distributed MPC iterations used at each sample step during the q th particle X  X  simulation run at PSO iteration i . When using this iteration deterrent (henceforth, referred to as the DRID case) the fitness of particle q at iteration i becomes: f  X  i  X  X  u r r  X  q , i  X  X  where u r is a positive constant used to determine the relative importance of the iteration deterrent cost to the disturbance rejection cost during optimisation.

The PSO weight optimization algorithm is as follows: 1. A random population of P particles is initialised in d dimen-sions, with x min r x q r x max , where x min Z 0 and x max Z the upper and lower bounds on particle q  X  X  position x q . If good initial estimates are known in advance, some particles can be initialized with these values instead. evaluated. 3. Based on these fitnesses the PSO algorithm updates each particle q  X  X  personal best position x b q  X  i  X  and fitnesses corre-sponding to these positions, f b q  X  i  X  , for q  X  1 ... P , and x global best position, and its associated fitness f g  X  i  X  and then calculates the next positions in the fitness function based on (12) and (13). Then with these P particles, the algorithm repeats from step (2). 4. The algorithm terminates when a termination criterion is satisfied; in this paper this happens when f g  X  i  X  has not changed by more than a small specified tolerance for a given number of PSO iterations.
 The choice of PSO parameters and u r can be problem dependent and would typically be chosen by the practitioner depending on the application. However, it is significantly more intuitive for the practitioner to pick suitable PSO parameters and values for u order to achieve a desired control system performance than it is to try and achieve this performance through the manual tuning of the distributed MPC parameters. 5. Simulation experiments
In this section, PSO weight optimisation is applied to the distributed MPC control of two complex, highly interconnected power systems performing Load Frequency Control (LFC). In LFC it is desired to maintain the frequency of a power system as close to 50 Hz (or 1 per unit (pu) frequency, which is the normalised frequency) as possible at all times. This is done by ensuring that the supplied power matches the demanded power at all times in the network. Agents must be capable of returning the frequency in the area they control to the 1 pu setpoint after disturbances such as load disturbances and line faults. The agents X  individual problems are coupled due to power flowing between subsystems through AC or DC line connections. First a discrete-time power network consisting of 20 subsystems is considered, and in the second experiment a continuous-time multiple link HVDC system, consisting of 4 highly interconnected subsystems is considered.

In both cases the weights are first optimised based only on the disturbance rejection performance, and then optimised again incorporating the iteration deterrent, as in (16). The disturbance rejection criterion for the j th agent in the simulation, run by particle q in the swarm, at PSO iteration i , used in both cases presented here is the discrete-time equivalent of the Integral of the Square of Time by the Squared Error (ISTSE) ( Gambier, 2007 ), which is used to place greater emphasis on long term errors over short term errors that occur immediately after disturbances It is given by f  X  q , i  X  X  error at sample time k is the difference between the measured and 1 pu frequencies, and q and i are the PSO particle and iteration, respectively. As the tuning is based on simulation runs, as in Fig. 1 , it is not practical to run simulations for an infinite number of samples and so simulations are run for a finite number of sample steps k f that is large enough to adequately capture the systems dynamics.
 The PSO routines are carried out using the PSO Toolbox for
Matlab ( Birge, 2003 ). In Trelea (2003) it was shown that good convergence properties could be obtained for the PSO, using the meter values were selected for this work. Other parameters used in the PSO toolbox are given in Appendix A . 5.1. System 1: 20 area discrete-time LFC problem
The 20 area discrete time LFC problem is shown in Fig. 2 . The continuous-time dynamics of subsystem a are described by the following second-order system ( Negenborn et al., 2008 ): d dt
D d a  X  t  X  X  2 p D f a  X  t  X  , d dt
D f a  X  t  X  X  y  X  t  X  X  the frequency of generator a , D P gen a  X  t  X  the power generation of these variables denotes a deviation from the original equilibrium position. Here y a represents the measured output states, while the purposes of the simulations output measurements y a are assumed to be noise free.

In discrete time, the local control input is u a  X  k  X  X  D P x are v subnetworks connected to subnetwork a ,and N in a f i g is the i th member of the subset of agents connected to agent a . Discretizing the continuous time model using an Euler approximation (with step size t  X  0 : 2 s), the model can be written as in (1) with:
A a  X 
V a  X  with a sample time of 0.2s. The parameters of all subnetworks are identical and are given as follows: K p a  X  120, T P a  X  20, K 5.1.1. Controller description system so as to ensure integral action. The augmented state for agent a at sample k is defined as x aug a  X  k  X  X  X  D x a  X  k  X  , x
D x a  X  k  X  X  x a  X  k  X  x a  X  k 1  X  , and incremental values of u used with their associated state X  X pace models 3 for the control of the system. A prediction horizon of N  X  10 was used to adequately take into account each subnetwork X  X  dynamic response. distributed MPC:
J stage a  X  k , p  X  X  Q a D f 2 a  X  k  X  p  X  1  X  X  R a D u 2 where Q a , R a are the scalar weights in the cost functions for the variables f a  X  k  X  p  X  and D u a  X  k  X  p  X  respectively. Q the same value for all stages of the prediction horizon. Using this stage cost, J local a  X  k  X  is formed as in (5).
 j A N a and the interconnecting output is D d a . The following gives the interconnection cost agent a experiences due to its connection to agent j : for each j A N a , where in each of the k and w vectors above there is one entry for each step of the prediction horizon, i.e., for each agent j that agent a is connected to, there are k in ja and w in over the full prediction horizon to determine what D d in agent a would like to receive, and also there are k out ja terms for each step of the prediction horizon based on the D d terms that agent a would like to send to other agents.
The overall cost function for each agent is formed using (20) and (21), as in (7). Constraints on the inputs and states are as follows: u a r u a  X  k  X  l  X  r u max a , x a r x a  X  k  X  l  X  r x max a , for l  X  0 , ... , N 1, and u min a  X  0 : 3, u max a  X  0 : 3, x a  X  X  10 ; 10 T . 5.1.2. PSO optimisation of the distributed MPC weights
PSO is now used to optimise the weights and parameters of the distributed MPC system for the 20 area LFC system. Given the large number of agents in the system, it is non-trivial to find a combination of weights that give both good disturbance rejection performance and a low communications overhead.

The weights determine the relative importance of the goals of the distributed MPC system; c is set equal to 1 and the other weights are then optimised using PSO. The vector of weights that are to be optimised here is C  X  X  Q 1 ... Q 20 E T . The R were not optimised and were given a value of 10 3 . However, these could be optimised if the practitioner so desired. The constraints for the variables in the PSO optimisation are as follows: 0 : 1 r Q a r 100, for agents a  X  1 ... 20, and 10
For the PSO optimisations involving the iteration deterrent, u  X  2 : 5.

To save on the overall PSO simulation time an upper limit of 50 distributed MPC iterations is allowed in each simulation run of the power system. If this is exceeded at any stage a fitness of 1000 is allocated to the particle at that position and the simulation of the next particle begins. While this upper limit on distributed
MPC iterations could be reduced, it allows the information from a wider range of particles to be used in the PSO optimisation.
The PSO particle fitness is based on a network simulation run lasting k f  X  25 discrete time steps, with t  X  0 : 2 s, i.e., a total simulation time of 5 s. This simulation involves disturbances of equal magnitude of 0.2 pu being applied at t  X  0 s to all subsys-tems except subsystem 17, where a larger disturbance of 0.23 pu is applied, these disturbances being the largest that can be expected to occur in each area, so this is a serious fault scenario for this system. Simulations were run on a computer with an Intel s Core TM 2 6400 operating at 2.13 GHz and with 3 GB of
RAM in Matlab 7.6.0 (2008a). All distributed MPC optimisations are done using quadprog. The PSO terminates when f g does not improve by more than 2 : 5 10 4 for 7 consecutive iterations.
Finding a set a weights to control this system for this scenario is non-trivial. The best performance the authors could achieve before optimisation, by manually tuning parameters, was with  X  Q 1 ... Q 20 c E T  X  X  10 ... 10 1 10 2 T . Fig. 3 shows the results of the experiment. Unacceptable disturbance rejection is achieved with area 14 becoming unstable towards the end of the simula-tion as a result of the disturbance, as can be seen in Fig. 3 (b). The
ISTSE for this performance is 131. Up to 11 distributed MPC iterations were needed to achieve this control, as can be seen in Fig. 3 (d).

The frequencies in areas 7, 14, and 17 (used as sample illustrations of the effect of the weight optimisations) can be seen in Figs. 3 (a), (b), and (c), respectively. These results include the initial manual tuning, the PSO tuning based only on disturbance rejection (DR only), and the PSO tuning based on disturbance rejection with an iteration deterrent (DRID). The number of distributed MPC iterations needed over time, for each of the aforementioned tunings, is given in Fig. 3 (d), and f plotted for each of the PSO iterations in the DR only and DRID cases in Figs. 3 (e) and (f).

The final optimised weights for the DR only case are as follows:  X  Q number of distributed MPC iterations needed to achieve this is 3 as can be seen in Fig. 3 (e).

The final optimised weights for the DRID case are as follows:  X  Q iteration cost of 2.5 and an ISTSE of 2.8975. Note that the maximum number of iterations needed to achieve this control is only 1.

Looking at both PSO optimisations it can be seen that weight optimisation significantly improves not only the disturbance rejection cost of the system, but also the number of iterations needed to converge to the final solution, in both tuning cases. Comparing the ISTSEs of each of the optimisations it can be seen that the DR only case trades off an increased number of iterations for a better disturbance rejection performance whereas the DRID case trades off a slightly worse disturbance rejection performance for a decrease in the number of iterations needed for the distributed MPC to converge. However, the disturbance rejection performance in the DRID case is still satisfactory, and a significant improvement on the disturbance rejection performance achieved with the original tuning.

The overall PSO optimisation time for the DR only case was 5 hours and the DRID case was 5.58 hours (measured using cputime in Matlab which measures the total time in each cpu core spent over the whole simulation. The actual time taken is usually roughly equal to the cputime divided by the number of cores on the computer, i.e., on a dual core computer the real time would be roughly half the cputime). It can be seen in Figs. 3 (e) and (f) that in both cases after 8 iterations PSO does not significantly improve, and is quite near the final optimal value for the weights. 5.2. System 2: continuous-time multiple HVDC link system
The system used in this section, based on the multiple HVDC link system between Denmark, Norway, and Sweden, is depicted in Fig. 4 ( Erikkson, 2008 ). It consists of 4 buses with their own generation and loads. Both Alternating Current (AC) and HVDC  X 0.25  X 0.2  X 0.15  X 0.1  X 0.05 0.05 0.1
 X  f (pu) 10 12
Iterations 5.5 6.5 PSO fitness links connect the buses. The HVDC links are of the Line Commu-tated Converter type ( Pai et al., 1981 ). Large amounts of power are transferred from bus 2, which has the largest generation capacity, to bus 4, which has the largest power load. Generation capacities and loads are kept constant in this paper. A simplification in this paper is to assume no line losses, which means that the amount of power in the system is constant at all times, and so the modula-tion of the HVDC line powers alone is enough to stabilise the system after line faults.
 agents problems this is quite a challenging distributed MPC problem. Finding a good combination of weights that balances both desirable closed loop performance and a low communication overhead is non-trivial and so this problem is also a suitable testbed on which to evaluate weight tuning algorithms. The classical swing equations for a generator a are ( Kundur, 1994 ): d d t d r a  X  t  X  X  o 0 D o r a  X  t  X  ,  X  22  X  d d t o r a  X  t  X  X  o r a  X  t  X  is the rotor speed (pu), D o r a  X  t  X  X  o r a deviation (pu), o 0 is the base rotor speed (rad/s), P m a are the mechanical and generated power (pu), respectively, and D a is the damping factor (pu).
 tion, which gives the system X  X  generator currents in terms of the system X  X  voltages and HVDC line currents ( Mc Namara et al., 2011 ), the following swing equation for generator a can be found: d where E q a is the magnitude of the internal voltage of generator a , voltage E q a to generator current l in the system, and g coefficient of the contribution of the power injections from HVDC link j at bus a (details of how each of these are derived are given in Mc Namara et al. (2011) ).

It can be seen that this equation gives a relationship between the rotor acceleration of generator a , the rotor positions of each of the generators in the network, and the HVDC line powers. From this it can be seen that there is high level of interconnectivity between each of the subsystems X  individual distributed MPC problems and a large communications overhead can be expected when agents need to coordinate their actions. The multiple HVDC link system para-meters used in the simulation are given in Appendix B . 5.2.1. Controller description
At each sample the state equations for each generator are linearised about the current operating point as follows: d d t "# where in the above equation f r a  X  d r a , o r a , P DC 1 defined in (24), and op indicates the linearisation of the relevant variable, vector, or function about the current operating point.
The states of agent a are taken as x a  X  X  d r a o r a T , the inputs u  X  X  P DC 1 P DC 2 T , and the interconnecting input v a  X  d system model is discretised using a zero-order hold with a sample time t  X  0 : 01 s, providing the discrete-time state X  X pace equations for the distributed MPC system. Predictions are formed using incremental state X  X pace models so as to ensure integral action, and incremental interconnecting inputs D v a and their associated state X  X pace models are used for predictions and optimisations. A prediction horizon of N  X  50 is used so as to accurately represent the system dynamics in the optimisation.
 One agent is assigned per generator to control its frequency.
Each agent has access to its relevant state X  X pace model, the constraints on its variables, and can communicate with agents to which it is connected by an AC or HVDC link.

The stage cost for the a th agent (there is one agent for each generator, so for convenience the subscript a is used to index given as follows:
J a  X  k , p  X  X  Q a  X  o r a  X  k  X  p  X  1  X  1  X  2  X  D u a  X  k  X  p  X  where Q a is the weight corresponding to o r a , and R a is a diagonal weight matrix corresponding to each of the inputs in D u a cost function. This cost function penalises deviations of the frequency from the base frequency and the control effort.
The interconnection cost for the distributed MPC case at sample step k and iteration l of the control cycle, J inter the following form
J inputs, w u a , next denotes the vector w u j when agent j is the next the last agent to optimise, and distributed MPC iteration l and the sample step k are dropped for compactness.

After agent a has completed its optimisation, it sends the relevant updated values of the variables to the agents that are connected to it, for use in their distributed MPC optimisations. The total cost function for agent a is given by (7).
 These constraints are applied over the full prediction horizon. In a centralised MPC case, the optimal values calculated for P the distributed MPC system calculate slightly different values for the HVDC powers to each other, as these powers only have to match to a degree, determined by the distributed MPC parameters c and E . 3 respectively, are the control inputs that are applied (these were chosen as the vast majority of pow er transfer is from subsystems 2 and 3 to subsystems 1 and 4, and so it is assumed their agents insist on having the final say on what power is transferred). 5.2.2. PSO optimisation of the distributed MPC weights
PSO was used to optimise the weights and parameters of the distributed MPC system for the multiple HVDC link system. Due to the high level of coupling between the subsystems it can be difficult to manually tune the system weights to achieve good disturbance rejection in a small number of iterations.
As previously stated, the weights determine the relative importance of the goals of the distributed MPC system. Therefore one weight is set equal to 1 and the rest of the weights are then optimised relative to this weight using PSO. The weight of agent 1, Q 1 is set equal to 1 and the vector of PSO weights is then C  X  X  Q 2 Q 3 Q 4 c E T . The R a weights are not optimised and are simply set to a small positive constant, where R a diag  X  10 3 , 10 3  X  . However, as in the previous example these weights could be optimised, if desired by the practitioner. The constraints for the variables in the PSO optimisation were as follows: 0 : 1 r Q a r 100, for a  X  2 ... 4, 0 : 01 10 4 r E r 1. The PSO terminates when f g does not improve by more than 0.1 for 7 consecutive iterations.

An upper limit of 120 distributed MPC iterations is allowed for each control cycle to save on simulation time in each simulation of this could be set lower but it allows the information from a wider range of particles to be useful in the PSO optimisation.
The tuning scenario used involves three-phase to ground faults being simultaneously applied to lines 1 and 3 in the system for a duration of 200 ms and then returning the system to its non-fault state. Manual tuning for this scenario is quite difficult and in fact a number of initial tuning attempts did not stabilise the system. Manually tuning the distributed MPC, the best performance the authors could attain was using  X  Q 1 Q 2 Q 3 Q 4 c E T  X  10 30 10 10 1 10 3 T . While this guess is stabilising, there is still an offset towards the end of the simulation and up to 40 distributed MPC iterations are needed for one of the control cycles to converge. It was decided not to initialise the PSO with this guess to see how long it would take to converge on the final solution with random initial guesses. For the simulations invol-ving the iteration deterrent, u  X  100. 5.2.3. Results Simulations are run on a 2211.412 MHz Quad-Core AMD Opteron TM Processor 2354 with a 512 KB cache size and 8 GB of RAM in Matlab version 7.11.0.584 (R2010b). Simulink is used to simulate the nonlinear, continuou s-time power system simulations, using the Dormand X  X rince (ode45 in Matlab) continuous-time algo-rithm, with a maximum step size of 2 ms and a relative tolerance of 0.001. Linearisations of the nonlinear equations (22) and (24), are used to derive the discrete-time state X  X pace models that are used in the distributed MPC controllers. These inputs were calculated and applied at fixed time steps of 10ms using Matlab and the calculated inputs were passed to the continuous-time Simulink simulations. All
MPC optimisations are performed using the CPLEX v10 Barrier QP solver, through the TOMLAB v7.4 interface in Matlab.

The final output of the disturbance rejection only PSO weight optimisation (DR only) set  X  Q 1 Q 2 Q 3 Q 4 c E T  X  X  122 : 8 100
PSO optimisation based on disturbance rejection with the itera-tion deterrent (DRID) gave  X  Q 1 Q 2 Q 3 Q 4 c E  X  X  159 : 6 100 90 : 11 : 06 0 : 13 T , with the final f g  X  693. The f g consisted of a disturbance rejection cost of 93 and an iteration deterrent cost of 600.

The fitness at each iteration of the PSO algorithm can be seen in Figs. 5 (g) and (h) for the DR only and DRID cases, respectively.
The other plots in Fig. 5 show the frequencies in each area plotted against time for the initial set of weights, the DR only weights, and the DRID weights. The plots of the distributed MPC iterations needed over the course of the simulation to achieve the control for each of the aforementioned weight scenarios are also shown.
It can be seen that in both cases the maximum number of distributed MPC iterations needed for convergence during the simulation run is significantly reduced in comparison with the original case, and that the disturbance rejection significantly improves. This illustrates that weight optimisation can simulta-neously improve both the disturbance rejection and communica-tion overhead, at least in certain situations.

While the DR only case results in a smaller overall amount of iterations than the DRID case, both the DR only and DRID cases converge on the same maximum number of iterations for the simulation run, but the DR only case ends up with a smaller overall communication overhead. In fact the DR only case also has the smaller disturbance rejection cost of the two. This could be simply because the PSO simply did not come across this solution while searching in the DRID case. However, it must also be considered that the discontinuities in the cost function caused by the iteration deterrent prevented this better result being found in the DRID case. From a practical point of view, though, both results are considerably better in terms of both disturbance rejec-tion and communication performance than with the original case.
It is noted that there is a significant amount of computational overhead associated with finding these weights. DRID took approxi-mately 4 weeks and the duration for the DR only simulation took approximately 8.5 weeks. The length of time needed for the optimisation was due to the long time the multiple HVDC link simulation took to run. On average simulation runs of these simulations took between 10 and 20 min at a time due to the fact that the sample time needed for simulation was quite small and the fact that a very long simulation time was needed due to the long settling times in multiple HVDC link system. Also, a prediction horizon of 50 steps is needed in this system, and so each of the distributed MPC problems are quite large. Much time was also spent in the exploitation stage, of the PSO algorithm, finding the final the PSO has almost converged to the final result. 5.3. Discussion of overall results
In both of the PSO weight optimisation experiments in this section it can be seen that the optimised weight values give simultaneously both improved disturbance rejection performance and a reduced number of distributed MPC iterations. Also it can be seen that the iteration deterrent has the potential to further minimise the max-imum number of distributed MPC ite rations needed in a simulation. where it is desirable to minimise the number of iterations needed for convergence of the distributed MPC algorithm while seeking to simultaneously improve disturbance rejection performance. a near optimal result in the early stage of optimisation. However, the exploitation stage of the algorithm takes a significant number of iterations and so can be wasteful in terms of the overall computational overhead. Another criterion, based on the perfor-mance being within satisfactory bounds, could be used in cases where the system simulations take quite a long time to run, in order to terminate the PSO optimisation at an earlier stage.
The duration of the PSO weight optimisation is significantly influenced by the time taken to run the individual power system simulations used to evaluate PSO particle fitnesses. While the PSO the simulation scenarios. It is for this reason that the multiple HVDC link weight optimisation experiment took significantly longer than the 20 area LFC weight case. It is worth carefully considering the length of time the system simulations run for during each fitness evaluation, how efficient simulation runs are, and what termination criteria should be used to terminate the PSO, in order to reduce the 0.999 1.001 1.002 1.003 1.004 1.005 1.006 1.007 1.008  X  (pu) 0.996 0.998 1.002 1.004 1.006  X  (pu)
Iterations 1000 1100 1200 1300 1400 PSO fitness overall PSO weight optimisation time. For computationally intensive simulations, such as the multiple HVDC link system in this paper, overall times for PSO optimisation could also potentially be reduced computers. 6. Conclusions and future work
An automatic PSO-based weight optimisation algorithm is proposed here for iterative distributed Model Predictive Control (MPC). This tuning algorithm simultaneously optimises both the closed loop performance of the system and minimises the amount of inter-agent communication needed to achieve this closed loop performance. This communication overhead is minimised by penalising the maximum number of iterations needed to achieve convergence of the distributed MPC algorithm over the course of a serious fault scenario simulation. The results achieved optimising the weights using this iteration deterrent were also compared to the results achieved when only the closed loop performance of the system was considered.

As a general strategy for tuning distributed MPC systems, PSO is advantageous as it can effectively find optima on a range of convex, non-convex, continuous and discontinuous functions, and so is quite flexible in terms of what fitness criteria can be used to tune the system. Also, practitioners do not need any in depth knowledge of the distributed MPC algorithm they are tuning in order to tune the weights, using PSO as described in the paper. Using an iteration deterrent for the weight optimisation, it is possible to tune the control system to achieve a desirable trade off between the closed loop performance and the communication overhead needed to achieve this control.

Two power systems examples are used to evaluate this weight optimisation technique. In both cases the weight optimisation results in an improvement in both the disturbance rejection overhead and the communication overhead. However, it was possible to further reduce the communications overhead using the disturbance rejection and iteration deterrent criterion.
There is a number of ways the work presented here could be further developed. The technique presented in this paper could be used to optimise the prediction horizon, which would further reduce the communication overhead. It could also be evaluated when used on other iterative distributed control techniques and in applications outside the domain of power systems.
 Acknowledgements This work was funded by the Irish Research Council for Science, Engineering and Technology (IRCSET) and supported the VENI project  X  X  X ntelligent multi-agent control for flexible coordination of transport hubs X  X  (project 11210) of the Dutch Technology Foundation STW and the European Union Seventh Framework Programme [FP7/2007-2013] under grant agreement no. 257462 HYCON2 Network of Excellence.
 Appendix A. PSO Toolbox parameters Parameters used for the PSO Toolbox are given as follows:
Parameter Description p Number of particles 35 mvden Maximum velocity divisor 2 epoch Maximum number of iterations 300
Appendix B. Power system parameters used in the multiple link HVDC simulation
S base  X  100 10 6 VA, U base  X  100 10 3 V, f base  X  50 Hz, w 2 p f base rad = s.
 Line 1 2 3 4 X pu 0.6 0.6 0.1 0.1 X pu 0.1 0.1 0.1 0.1
Generator 1 2 3 4 pu 0.09 0.06 0.12 0.12 H (s) 2 4 2 2 D pu 1111 P  X  P m pu 0.1 0.6 0.1 0.1 d rad 5.9874 0.2871 5.585 5.03
E pu 0.4454 0.513 0.6807 1.0622 Bus 1 2 3 4 Load pu 0.1  X  0.05i 0.1  X  0.05i 0.1  X  0.05i 0.6  X  0.2759i
U pu 0.1097 0.2426 0.256 0.2219 y rad 0.4809 6.2768 5.5161 1.3042 HVDC link a  X  12 P a , 0 pu 0.3573 0.1427 q a 0.8952 0.9037 References
