 With the ever-increasing growth of the World-Wide Web, the number of casual search engines users has grown rapidly. However user queries are usually too short to de-scribe the accurate information they need. T he analysis [1] shows that the average query length is 1.7 terms for popular queries and 2.2 terms over all queries. In order to ad-dress this problem, query expansion has b een receiving much attention in a long time [2,3,4,5,6,7,8]. Among all the query expansion methods, pseudo-relevance feedback (PRF) [9,10] is nearly the most attractive one because it does not require any user in-put. PRF assumes that top ranked documents are relevant. Many approaches have been presented to extract useful terms from those pseudo-relevant documents. Serval criteria have also been proposed to select expansion terms based on term distributions, such as idf , tf ,  X  2 statistic, web resource (e.g Wikipedia), linguistic feature, ontology and so on. More recently, supervised learning me thods have also been studied[5,11].

However, previous research efforts have m ainly focused on extracting terms sepa-rately without considering the impacts of relationships among terms and their combina-tions. Selection of terms is typically performed in a greedy manner using some type of score or rank. As a result, the performances of current models are usually unstable and the improvements are limited. Several experiments in Section 3 show that term combi-nations can highly impact the final results. This in turn leads to a natural question: how can we select aset of expansion terms from pseudo-feedback documents?
To address the above question, we propose to seek a set of terms by requiring that: 1) the terms are related to the query and use ful for Information Retrieval (IR) accord-ing to their distributions, linguistic features, and so on; 2) redundancy of the terms is minimum, in other words, t he terms should be maximally dissimilar to each other. In this paper, we use non-negative matrix factorization method to cluster the terms and capture their pairwise correlations. Then a novel expansion term selection algorithm is used to extract a set of terms. We compare the proposed algorithm with the tradi-tional approaches on five TREC test collections. The experimental results show that our proposed term selection method achieves good performance and is able to improve the retrieval effectiveness significantly.

The contributions of our work can be summarized as follows: 1) We thoroughly eval-uate impacts of relationships among terms and their combinations for pseudo relevance feedback. 2) We propose a novel maximum relevance and minimum redundancy crite-ria to select expansion terms. In contrast to existing work, expansion terms are selected as a set, and the relationships among them are considered.

The remaining of the paper is organized as follows: In Section 2, we review a number of related work and the state-of-the-art approaches in query expansion. Section 3 pro-vides experimental examinations of the hypothesis about term combinations and shows that it does hold in practice. In Section 4, we present our expansion criteria. Experi-mental results on five TREC test collections are shown in Section 5. Finally, Section 6 concludes and suggests some future work. The approach presented in this paper is related to previous work on pseudo-relevance feedback and Non-negative Matrix Factorization.

The problem of how to automatically extract useful terms from the top rank initial retrieval set is a long-studied task. Since no user input is required, pseudo-relevance feedback (PRF) has received considerable attentions. Statistical based query expan-sion is one of the classical methods. Okapi [12] addes the 20 top ranking terms, which is scored by BM 25 weight, for query expansion. Carpineto et al.[8] introduced an information-theoretic method, including Rocchio X  X  weights, Robertson Selection Value (RSV), CHI-squared, and Kullback-Leibler distance, for query expansion.

Many approaches have been proposed to improve the effectiveness of PRF with external resources, such as Wordnet[13], dependency relations[14], and so on. Xu et al.[2] explored the utilization of wikipedia in PRF. They categorized the TREC topics into three types based on wikipedia and proposed different methods for term selection with wikipedia entity pages. Collins-Thompson and Callan [15] described a Markov chain model that combines multiple sources of knowledge on term associations, and al-lows chaining of multiple inference steps with different link types to perform  X  X emantic smoothing X  on language models, and app lied this model to query expansion.
Recently, there has been work focused on s electing better documents for pseudo-relevance feedback. Sakai et al. [16] proposed an approach to skip documents in the initial ranked documents to look for mor e  X  X ovel X  pseudo-relevant documents. They used cluster method to collect novel doc uments rather than separating relevant documents from non-relevant ones. However, their experiments on NTCIR collections did no show significant improvements. Lee et al.[3] proposed an approach to resample the top-ranked documents using clusters. They assumed that document that appears in multiple highly-ranked clusters would contribute more to the query terms than other documents.

Huang and Croft [17] proposed a framework to expand queries with a small number of opinion words. A number of sentiment expansion approaches were used to find the most appropriate query-independent or query -dependent opinion words. However, the query expansion method they used is query independent. It only forces on the opinion retreval domain.
 Supervised learning methods have also been proposed to classify expansion terms. Zhang et al. [11] proposed a method to automatically evaluate the retrieval effectiveness of terms. Then SVM is used to select terms directly based on statistical features. Cao et al. [5] re-examined the assumption of pseudo-relevance feedback and used the similar idea to select expansion terms.
 The most similar work to our proposal is the method proposed by Udupa et al. [18]. They claimed that the effect of including a term into an expansion set depended on the rest of the terms in the expansion set . They proposed to use spectral partitioning of term-term interaction matrix to takes into account term interactions. Different from their approach, we propose to use maximum relevance and minimum redundancy cri-teria to select terms as a whole. The redundancy is captured by term clusters, which is obtained by constrained non-negative matrix factorization method. Term distributions and linguistic features are used to measure the relevance. As we mentioned in Section 1, our approach selects expansion terms as a whole set. The general assumption behind it is that the relationships among terms and their com-binations can impact the final retrieval result. To evaluate this assumption, we consider all the  X  X ood X  expansion terms and their combinations.
 Suppose MAP ( q ) represents the mean-average-precision of the original query q and MAP ( q t i ) represents the MAP of the expanded query(original query with term t i ). Following the formula proposed in [5], the performance change due to t i is measured bigger than 0.05 1 .

Since the size of vocabulary is too big and the evaluation is a time consuming task, we use the following score function to select top 200 words as candidate terms: where N is the total number of documents, R is the number of relevant documents, the number of documents and relevant documents containing term t i are respectively represented by n i and r i [19]. The top 20 documents 2 are regarded as relevant in our experiments. Then, good expansion terms are measured and selected by chg ( t ) from the candidate terms.
 Through the above steps, we can obtain a set of good expansion terms for each topic. In order to evaluate the impact of their combinations, C 5 | G erated where | G k | represents the count of good expansion terms in topic k and C 5 | G is the number of 5-combinations from the good expansion terms. In our examination, the maximum size of | G k | is set to 20. Each expanded query contains both the original query and five additional terms, which are selected by chg ( t i ) . We use Lemur toolkit 3 to conduct the experiments in this paper.

Five TREC collections are used to examine the assumption and their description can be found in Section 6.1. in TREC 7 (from topic 351 to C 5 | G mary results in different collections. The fourth column  X  X op 5 X  represents the result of combining initial query with five additional terms whose chg ( t i ) are the highest among all the candidate terms.

As we can see, pseudo-relevance feedback is effective when good expansion set is selected. In TREC 7, the relative improvement of the best expansion set over the initial result is 108.9%. However, although every single term can improve the retrieval result, their combinations may deteriorate the perfo rmance. In all collections, the worst results with query expansions of some topics are even much lower than the result of the initial query without any expansion terms. We also note from the Table 1 that the best expan-sion set achieves better result than the To p 5 . In other words, although each single term can only improve the result slightly, the ir combination can be more effective. Figure 1 shows the overview of our proposed query expansion methods. First of all the system returns an initial set of retrieval results with the given query. Then the unigram language model is applied to generate term-document matrix. After that non-negative matrix factorization methods are used on term-document matrix. Upon convergence of the matrix factorization algorithm, term-c luster and document-cluster matrices are obtained. Given the two matrices, query expansion set can be generated by different query expansion methods, which will be detailedly described in the following parts. 4.1 Coverage Criterion for Query Expansion From analyzing clustering result of the top-ranked documents, we observe that those documents usually correspond to several differe nt topics. Different clusters usually con-tain different concepts. Buckley et al.[20] also mentioned the observation. Since the intention of the query cannot be easily detected, including all major topics should be useful for the expansion queries.

In order to improve the coverage of expansion queries, one of the straightforward method is to select terms from each clusters. S ince clusters have different size, a bal-anced way to select terms from the multiple clusters should be considered. We assume that clusters with more documents are more important. Based on this assumption, the number of terms extracted from cluster C i is set to | C i | N ,where N is the total num-ber of documents and | C i | represents the number of doc uments in the cluster. In each cluster, terms are ranked by Eq.(1). 4.2 Maximum Relevance and Minimum Redundancy Criterion for Query Ding and Peng [21] proposed minimal-redundancy-maximal-relevance (mRMR) frame-work to select promising features. Inspired by their work on feature selection, we re-define the maximal relevance constraint and minimal redundancy constraint for text retrieval, and combine them as mRMR-QE criterion for query expansion.
 The maximal relevance condition is to search a set of terms T satisfying Eq.(2). documents in cluster c i . max c i  X  C Score c i ( t i ,q ) represents the maximum relevance score of the term to a cluster. The relevance between T and q is measured by the sum of individual term t i and query q. However, it is likely that the redundancy among the terms selected according to the maximal relevance criterion could be rich. More over, from the analysis of Section 3, we observe that the including terms whi ch are highly dependent on each other may degrade the result. Therefore, the following minimal redundancy criterion can be used to select mutually exclusive terms. where I ( x i ,x j ) represents the mutual information between term t i and t j .
Combing the maximal relevance and minimal redundancy creation, the maximum relevance and minimum redundancy Criteri on for query expansion (mRMR-QE) is de-fined by the Eq.(4). Following the method proposed in [22], an incremental search method is used in prac-tice. Suppose we already have T m  X  1 , which contains m  X  1 terms. Then Eq.(5) is used to select the mth term from the remaining set { W  X  T m  X  1 } . 5.1 Collections We evaluate our methods with three TREC corpus Disk4&amp;5, WT10g and BLOGS06. Five test collections, TREC 7, TREC 8, TREC 10 Web, TREC Blog 2006, and TREC Blog 2007, are used in the experiments. We implement our expansion methods based on Lemur 4.10 4 . Okapi BM25 ranking function is used as the retrieval model. All test collections and corpus were stemmed using the Porter stemmer provided as part of Lemur. As for performance measures, the mean average precision (MAP) for top 1000 documents is the primary evaluation metric in all the test collections. Other metrics include precision at five documents (P@5), precision at ten documents (P@10), R-precision (R-prec), and binary Preference (bPref). We also conduct  X  -test to determine where the improvement on performance statistically significant. 5.2 Coverage Criterion Evaluation Table 2 contains the results of experiments in all test collections using Okapi BM25 ranking function and pseudo relevance feedb ack with coverage criterion. The left col-umn in the table shows the test collections. Each row in the table represents the results of different performance metrics. The column  X  X AP-P X  represents results of the Okapi BM25 ranking function with traditional pseudo relevance feedback. For all four col-lections, 20 terms are sorted by Eq. 1 and extracted with coverage criterion from 5 top-ranked documents.

From the table we can observe that the coverage criterion achieve better results than the original pseudo relevance feedback method in all four collections. In TREC 8 collec-tion, the criterion achieves significant improvement. The results we obtained in TREC 7 and TREC 8 are the state-of-the-art performance. Compared to  X  X M25+PRF  X , not only the MAP but also most of the other eval uation metrics achieve better results among the collections. Those results can also demonstrate the observation we mentioned in the previous sections. 5.3 mRMR-QE Evaluation In this experiment, we also use the TREC corpus Disk4&amp;5, WT10g, and BLOGS06 to test the performances. In the same way as previous experiments, five test collections, TREC 7, TREC 8, TREC 10 Web, TREC Blog 2006, and TREC Blog 2007, are eval-uated. Table 3 summaries the results of experiments in all test collections using Okapi BM25 ranking function and pseudo relevance feedback with mRMR-QE criterion. The same parameters are used in this experiment.

From the Table 3, we observe that expansion terms extracted by pseudo relevance feedback with maximum relevance and minimum redundancy criterion can signifi-cantly improve the retrieval effectiveness. In all the collections, mRMR-QE criterion achieves better results than coverage criterion in most performance metrics. Figure 2 shows the performance comparisons of different expansion methods. Those results show that mRMR-QE criterion can capture the good expansion terms more effectively than pervious approaches. This is consistent with the observations we studied in the Section 3. We also note from the retrieval result that more than 69.2% of expansion queries give positive impact over the original queries, which is also more robust than coverage criterion. In this paper, we studied the impacts of the relationships among terms and their com-binations. Through several empirical experiments, we show that retrieval performance would significantly impacted by the combinations of expansion terms. In all five test collections, the best expansion can significantly improve the retrieval result.
In order to address this problem, we presented a novel clustering based method to select expansion terms as a set. The main idea is to first simultaneously cluster terms and documents, and then use Maximum Relevance and Minimum Redundancy criteria to select terms based on their clusters, term di stributions, and other features. We evaluated the results with five different TREC collections. We also discussed the factors in our proposed method, including the number of expansion terms and the number of pseudo relevance documents.
 The author wishes to thank the anonymous reviewers for their helpful comments. This work was partially funded by 973 Program (2010CB327906), The National High Technology Research and Development Program of China (2009AA01A346), Shang-hai Leading Academic Discipline Project (B114), Doctoral Fund of Ministry of Ed-ucation of China (200802460066), National Natural Science Funds for Distinguished Young Scholar of China (61003092), and Shanghai Science and Technology Develop-ment Funds (08511500302).

