 Indexing is an important Information Retrieval (IR) op-eration, which must be parallelised to support large-scale document corpora. We propose a novel adaptation of the state-of-the-art single-pass indexing algorithm in terms of the MapReduce programming model. We then experiment with this adaptation, in the context of the Hadoop MapRe-duce implementation. In particular, we explore the scale of improvements that can be achieved when using firstly more processing hardware and secondly larger corpora. Our re-sults show that indexing speed increases in a close to linear fashion when scaling corpus size or number of processing machines. This suggests that the proposed indexing imple-mentation is viable to support upcoming large-scale corpora. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage &amp; Retrieval]: Information Search &amp; Retrieval General Terms: Performance, Experimentation Keywords: Indexing, MapReduce
With the ever-growing test corpora being developed for researchers, scalable implementations of common IR opera-tions have become a necessity. Indeed, TREC in 2009 in-creased the size of its largest collection by almost 12 times. As MapReduce has gained popularity in commercial set-tings, with implementations by Google [3], Yahoo! [2] and Microsoft [5], it seems likely to be a viable tool for large-scale data processing. To investigate this, we propose develop-ment of a state-of-the-art indexing operation, in the context of MapReduce. While the original MapReduce paper [3] shows the scalability of MapReduce in general, it does not give an in-depth explanation of how efficient indexing should be performed within such a model.
 In Section 2, we develop a novel indexing strategy in MapReduce, inspired by the single-pass indexing of Heinz &amp; Zobel [4]. In particular, we employ Hadoop [2] -the only freely available MapReduce implementation, developed by Yahoo!. Section 3, presents experiments using our MapRe-duce indexing strategy, to assess its scalability, in terms of hardware and input data. The main contributions of this work are three-fold: we show how the MapReduce paradigm can be successfully applied to an existing IR system and provide a working implementation to the community; we provide a working example of MapReduce of significantly greater complexity than the commonly-used MapReduce wo-duce task, the posting lists for each term are merged by map number and flush number, to ensure that the posting lists for each term are in a globally correct doc-id ordering. The reduce function takes each term in turn and merges the posting lists for that term into a full posting list. Figure 1 presents an example for a distributed setting MapReduce indexing paradigm of 200 documents. Note that the num-ber of reduce tasks therefore determines the final number of inverted index shards created.
To determine the extent to which MapReduce is a suitable framework for efficiently processing large IR corpora, we in-vestigate two research questions: does our Hadoop MapRe-duce implementation attain linear speedup with machines allocated (i.e. doubling machines would ideally half index-ing time); and how does corpora size affect performance? Our indexer uses the Hadoop MapReduce implementation (v. 0.18.2) and we evaluate using four standard TREC cor-pora of varying size, namely WT2G, WT10G, .GOV and .GOV2. Of these, .GOV2 is the largest at 25M documents, comprising 425GB when uncompressed.

Firstly, we test to determine if the distributed (MapRe-duce) indexing will complete the same indexing process in a shorter time as we increase the processing power available. To show this, we measure the mean indexing time of .GOV2 (5 repetitions), running on 1-8 machines, when using a sin-gle reduce task. From the single reducer curve in Figure 2, we observe that indexing time decreases as more machines are added (i.e. speedup increases). However, by examining the trends observed as the number of machines increases, we see that linear speedup is not achieved, as indexing time speedups level off after approximately 6 machines.
On further analysis, we suggest that this is due to the use of a single reduce task, with this becoming the bottleneck of the indexing job, i.e. the (sequential) single reduce task lim-its the speedup achievable as described in Amdahl X  X  law [1]. To test this, we then experimented indexing when using 24 reducers. The results are presented in the multiple reducer curve in Figure 2. Indeed, this shows that by using multi-ple reduce tasks we achieve marked performance improve-ments beyond 6 machines. As an illustration to this success, we note that the single-pass (single-threaded) indexing took over a day (1605 minutes) to index .GOV2. However, when running the multi-threaded MapReduce implementation on a single three-core machine, indexing completed in less than 8 hours (472 minutes), while for 8 machines this is reduced to just over an hour (73 minutes). This represents a 6.5 times speedup for the MapReduce implementation between 1 and 8 machines.

However, as this is still sub-linear scaling, we further sug-gest that this can be explained in terms of a lack of file local-ity to the machines doing the work. As of v. 0.18.2, Hadoop ignored file locality when assigning multiple files to each map task 1 . To investigate the impact of this, we increased the availability of .GOV2 until all machines had their own copy -thereby eliminating the need to transfer files. The results are also presented in Figure 2, which clearly shows scaling close to linear in nature. We can therefore conclude that our MapReduce indexing implementation scales with processing power in a fashion which is appropriate for efficient compu-tation. Moreover, linear speedup can be achieved through maximisation of file locality.
