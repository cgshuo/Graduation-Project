 These days many applications deal with large amounts of transaction data, i.e. network traffic data, sensor network data and web usage data [3]. Such data, also referred to as data streams in the rest of the paper, often present skewed distributions, i.e. some classes are not sufficiently represented while instances of other classes are over-represented.

Class imbalance exists in a large number of real-world domains and, hence, learning on the static imbalanced data ha s received great focus [4,6]. Existing solutions can be divided into the following four categories: (i) under-sampling the majority class, so that its size matches that of the minority class(es); (ii) over-sampling the minority class so as to match the size of the other class(es); (iii) internally biasing the learning process so as to compensate for class imbalance; (iv) multi-experts systems. Despite such efforts, most of these methods, while increase the accuracy on the minority c lass, decrease the g lobal accuracy in comparison with traditional learning algorithms.

Turning our attention to data streams cl assification, recent research has been directed towards the topic o f data streams classification [7,15,8,16]. Few methods, however, have been designed to classify skewed data streams [9].

Therefore, skewed data streams classific ation deserves more attention. In this respect, we propose here a classification method for skewed data streams, pre-senting the following contributions: (i) we discuss the pros and cons of metrics for performance evaluation under class skew; (ii) we present a review of the lit-erature concerning classification methods for both static and streaming skewed datasets; (iii) we propose a new approach for skewed data streams classification. Comparing with existing methods, our proposed method improves not only the accuracy on each class but also the globa l recognition accuracy, as confirmed by experiments carried out on three public datasets.

The rest of the paper is organized as follows: we present background and motivations in section 2, where we also review related work. In section 3, we introduce our approach in detail. In section 4, we report the experimental results. Finally, we conclude the paper in section 5. In this paper, we consider two-classes ske wed data classification problems, where the minority and majority instances belong to the positive and negative classes respectively, and the positive class is largely under-represented in comparison to the negative one. The skewness of a dataset denotes the degree of data imbalance, and its value is equal to the a priori probability of an instance belonging to the majority class. 2.1 Performance Metrics For a two-classes classification task, table 1 shows the corresponding confusion matrix which is usually used to assess the performance of a recognition system. We denote n  X  = FP + TN and n + = TP + FN as the numbers of samples in the negative and positive classes, respectively.

The global recognition accuracy, referred to as acc , is a traditional measure for evaluating the performance of a classifier. For a two-classes classification task, acc =( TP + TN ) / ( n  X  + n + ). It is notable that such a measure is sensitive to class skew because it considers values reported in all columns of the confusion matrix. As an example, consider the Credit Card dataset with a skewness of 97 . 79% (see also subsection 4.1). A classification system would achieve an accuracy as high as acc =97 . 79% if it arbitrarily labels all test samples as negative. However, it would fail to recognize all positive cases, so it cannot meet the need of skewed data classification applications.

As a complementary metric for acc on skewed data, we introduce the geomet-ric mean of accuracies ( gacc ) for class-imbalance learning, which is a performance measure used in the literature [12]: gacc = berofelementsofclass i correctly labeled and n + i is the number of samples belonging to class i . Hence, n ii /n + i represents the accuracy for each class. It is clear that gacc ranges in [0 , 1]. For two-classes skewed data classification tasks, we further introduce the following two metrics which specialize in measuring the performance of a classifier on the two different classes:  X  True Positive Rate or Recall , which is defined as TP rate = acc + = TP TP + FN ;  X  True Negative Rate , which is defined as TN rate = acc  X  = TN TN + FP ; From above definitions, for two classes recognition problem, we obtain gacc =  X  acc +  X  acc  X  . On one side, to get a large value of gacc , both accuracies should be large. On the other side, gacc will be low if either accuracy value is low. Hence, gacc is a balance of acc + and acc  X  . Nevertheless, if we only use the gacc value to evaluate a classifier X  X  perform ance, we can not distinguish its separate performance on the two different classes. As an example, consider the classifier for the Credit Card mentioned above. Its acc  X  value is 100% but, since its acc + is 0%, the gacc value for this classifier is 0%. This example confirms that neither acc nor gacc on its own is enough to reflect the overall performance of the classifier on skewed data, motivating the use of acc + and acc  X  .

As a short summary, the metrics of acc , gacc , acc + (or acc  X  ) should be used together as a joint measure to evaluate classification performance on skewed data streams. Indeed, on the one hand, acc measures the global recognition rate and, on the other hand, gacc reflects how much classifier p erformance is balanced. In addition, acc + (or acc  X  ) reports separate classification performance on the two different classes. 2.2 Classification Methods for Skewed Data Researches for the learning of static imbalanced data can be classified into the following four categories: 1. Under-sampling the majority class by resizing the training sets ( TS ), makes 2. Over-sampling the minority class so as to match the size of the majority one. 3. Internally biasing the discrimination-based process to compensate class im-4. Multi-experts systems ( MES ). In MES, each composing classifier C i is 2.3 Classification Methods for Streaming Data Very fast decision tree learner (VFDT) is an early work for data stream clas-sification [7]. It builds a decision tree incrementally using constant memory. It starts with a single leaf, decides which attribute is the best for splitting the tree, and selects via Hoeffding bound a small subset of examples passing through the nodes. VFDTc [8] is an improvement over VFDT that can handle continuous data, incorporate new information online and classify the samples with a single scan of the data.

MES is also applied to data streams building separate classifiers on sequential batches [15]. The performance of existi ng classifiers are tested using the new batch of data. As a constant number of classifiers is kept, the extra classifiers with worst classification accuracies will be eliminated. The final predication is made by combining the outputs of remaining classifiers through majority voting. In the following, we refer to this method as SEA .

Gao et. al. proposed a classification method for skewed data streams [9], which is referred to as SDM07 in the rest of the paper. To make the class distributions of the TS balanced, they (1) collect mino rity samples that have appeared over in the new batch and all the past batches, (2) use only the majority instances randomly sampled in the new batch. Samples from steps (1) and (2) are then merged into a new TS used to build a classi fier. Moreover, to make more accurate classifications, they generate several such TSs at each new batch by running step (2) several times. The outputs of the set a re then combined by majority voting. 2.4 Motivations The review of the literature reporte d so far shows that recent research has focused, on the one hand, on class-imbalance learning on static data and, on the other hand, on classifying non-skewe d data streams. However, conventional methods for non-skewed data streams usually do not give enough attention to skewed streams, whereas static class-im balance learning methods often harm the accuracy on majority class, although th ey increase the recognition accuracy on the minority class.

To better illustrate such motivations, columns 2-9 of Table 2 compare the classification performance ac hieved by two methods, namely SDM07 [9] and SEA [15], on the Credit Card dataset with skewness of 97 . 79%. In Table 2, we observe that data streams classification method designed for training under class skew, i.e. SDM07 , achieves more balanced performance measured in terms of gacc than a conventional classifier adopting learning method tailored for non-skewed data, i.e. SEA , due to the fact that the minority class classification accuracy ( acc + )of SDM07 is larger than SEA . However, although acc + is improved, we observe that acc values returned by SDM07 is always smaller than those provided by SEA , confirming our observation that global a ccuracy decreases for existing methods handling skewed data streams.

Thus, we are motivated to develop a new skewed data streams classification method that can increase both the global recognition accuracy and the accuracy on minority class. As reported in section 2.4, we have noti ced that balancing the accuracies for each class has the side effect of decrea sing the global recognition accuracy ( acc ). Therefore, we present in the following a method aiming at achieving larger acc while still improving acc + or gacc . 3.1 Framework of the Method Since it is very difficult for a class-imbala nce learner to achieve high performance on both acc and gacc , we decide not to pursue perfect performance on both measures separately, but to develop a classification method that can balance them simultaneously, harming the globa l accuracy less than previous methods.
So, how can we balance acc with gacc ? We utilize a multi-objective optimiza-tion technique selecting the final output of the classification system between the output of a classifier trained according to a learning method addressing the course of class imbalance, and the output of a classifier adopting a training method for non-skewed data [14]. This choice is driven by a parameter, referred to as threshold t  X  in the following, whose value maximizes two objective func-tions, i.e. the global accuracy ( acc ) and the geometric mean accuracies ( gacc ), on a validation set.

The framework of our method, shown in Fig. 1 (left), is based on two en-sembles of classifiers. They are referred to as non-skewed ensemble of classifiers ( NEC ), and skewed ensemble of classifiers ( SEC ). The former is trained on the original skewed distribution, whereas the latter is trained on an artificially balanced training set, applying MES scheme suited for imbalanced data. In our implementation, we use SEA [15] for NEC ,and SDM07 [9] for SEC .Thisframe-work is adapted to data streams by means of dividing the training streams into batches, and each batch is further divided into training and validation sets.
Givenaninstance x belonging to test set, the final label O ( x ) is determined as follows:
When the reliability  X  ( x )providedby NEC is larger than the threshold t  X  ,the final label corresponds to the label returned by NEC because it is reasonable to assume that NEC is likely to provide a correct classification. But, when  X  ( x )is below t  X  , O ( x ) is equal to the label assigned by SEC , i.e. a classification method tailored specially for skewed data. Indeed, in this case, the value of the reliability suggests that the decision returned by NEC may not be safe. We will explain the rationale of reliability estimation in subsection 3.3. 3.2 Multi-objective Optimization According to our proposal, we will first train NEC and SEC on the training set of a given batch. Next, both of them are used to classify instances belonging to the validation set of the batch to determine the best value of t  X  to be used with the test data. Finally for test data, we apply equation 1 to set the final classification. As reported above, th e choice between the outputs of NEC and SEC is driven by t  X  .Since t  X  is an important threshold parameter, how do we set this parameter? In order to an swer this question, recall that gacc measures how much the accuracies on two classes are balanced, whereas acc estimates the global performance of the classification system. Let us represent gacc and acc on the X and Y axes respectively, and vary a threshold t to generate a set of points that can be used to plot a curve using samples belonging to validation set. The curve extrema at t =0and t =1correspondto NEC and SEC performance, respectively. In this plot, the ideal point is C =(1 , 1); hence, the nearer the curve to this point, the better the performance obtained. Therefore, the value t values measured on the valid ation set when the threshold t is used.

Fig. 1 (right) shows two examples of this curve, corresponding to two different situations that may occur. The first situation is represented by the continuous line in the figure. In this case, the proposed method selects a value of t  X  that permits to improve both gacc and acc in comparison to individual performance of NEC and SEC , i.e. points marked with t =0and t = 1. The second situation is represented by the dashed curve. In th is case, the proposed method selects a value of t  X  that improves gacc with respect to both NEC and SEC , while it reduces slightly the value of acc in comparison to NEC . We deem that such a reduction can be accepted since final p erformance are m ore balanced than individual ones returned by NEC and SEC .
 Algorithm 1 shows the algorithm implementing our proposal presented so far. The training stream is divided into sequential batches (line 1), and each batch is further divided into training and validation sets (line 3-(a)). Using the training set, we train NEC and SEC (line 3-(b)). Next we compute t  X  using a validation set and applying the method given in subsection 3.2, (line3-(c)). As NEC and SEC are both ensemble of classifiers, we collect the member classifiers in line 3-(d). To classify test instances, we appl y step 3-(e) according to equation 1. 3.3 Reliability Estimation This subsection answers to the following question: what is the reliability and why is it useful in the proposed method?
Utilizing information derived from classifier outputs allows for estimating the reliability of each classification act. Reliability takes into account many issues that influence the achievement of a correct classification, such as the noise affect-ing the samples domain, and the differe nces between the objects to be recognized and those used for training the classifiers.

Let  X  ( x ) denote the reliability of a classification act on any instance x ,and the value range within [0 , 1]. For two-class classifiers,  X  ( x ) is computed using Algorithm 1. Algorithm of the proposed method the difference of predictions on the two different classes. A low value of  X  ( x ) will suggest that the classification decision made on instance x is not safe since, for instance, it may be a borderline ins tance or it can be affected by noise in the feature space; while a large value of  X  ( x ) would suggest that the classifier is more likely to have provided a correct classification [10].

In order to explain the rationale of using the reliability for skewed data clas-sification, let us consider Fig. 2, where we report the experimentally measured distributions of reliability values for test samples labeled by a classifier (i.e. NEC ) trained on a skewed distribution. On the one hand, when we apply NEC ,the minority class samples are more likely to receive low reliability values (see the left part of Fig. 2). On the other hand, although low reliability values can also be found for true negative instances, instances with high reliability values are more likely to belong to the majority (negative) class (see the right part of Fig. 2).
In short, there are two main reasons for using reliability estimations on skewed data stream classifiers: (1) applying NEC , samples with high reliability values are more likely to belong to negative (majority) class. Hence, we can use reli-ability values to distinguish between positive and negative instances; (2) SEC is trained on artificially balanced training sets, so it should recognize not only positive instances, but also negative ones. Therefore, although instances with low reliability values can contain negative (majority) instances, SEC should be able to correctly classify most of them. In this section, we first describe the dat asets used for the experiments. Second, we introduce the experimental protocol and, third, we report the experimental results. 4.1 Datasets We use the three datasets shown in table 3. These datasets vary in both num-ber of features and skewness. The prediction task for the Adult dataset is to determine whether a person makes over 50K income a year. We only use two classes of the Forest Cover dataset: Ponderosa and Lodgepole Pine. The task of the Forest Cover dataset is to predict the forest cover type. The Credit Card dataset was provided by the 2009 UCSD/FICO data mining contest 1 and used for predicting whether a transaction is an anomaly or not.
 4.2 Experimental Protocol We test our approach on the above mentioned datasets. For each dataset, we divide the data into batches, and the last two batches are left for testing only. We vary the size of the batches in our tests: each batch in the Credit Card data contains 10,000 transactions, the size of a batch in the Forest Cover dataset is 20,000, and it is 5,000 for the Adult data. As there are few methods for skewed data stream classification, we implement SDM07 [9] for SEC and we apply SEA [15] for NEC . These two methods were chosen because both of them are well rec ognized methods for classifying skewed or non-skewed data streams. Since both NEC and SEC are classifier ensembles, we use C4.5, Na  X   X ve Bayes and Logistic Regression as the base learners in our experiments. Performance are estimated measuring acc , gacc , acc + ,and acc  X  . 4.3 Results Tables 2, 4 and 5 report the results of the tests we performed on the Credit Card dataset. Tables 6 and 7 show a portion of the test results on both Adult and Forest Cover datasets. It is worth noting that SEA usually achieves the largest acc value but has the smallest gacc value. The case is reversed for SDM07 , with the largest value for gacc but the smallest value for acc . Our proposed method, however, achieves a balanced performance between the two above methods. As discussed in section 2, this occurs because SEA is a learning method that usually ignores the minority class in skewed data. SDM07 , on the other hand, is biased toward the minority class but harms the recognition accuracy on majority class. Unlike the other two methods, our proposed approach balances acc and gacc simultaneously.

We now provide a deeper analysis of the results achieved on the Credit Card dataset (Tables 2, 4 and 5). We notice that: (i) SEA usually achieves the best values of acc , while SDM07 often has the best values of both acc + and gacc ; (ii) Sometimes the gacc values of our method are as large as or even larger than SDM07 ; (iii) Our method increases the values of the acc + of SEA by up to 70%. Our method also outperforms SEA in terms of gacc by 25%; (iv) Our method does not outperform SEA in terms of acc . With respect to SEA ,ourmethod decreases acc by approximately 4 %, but the decrease in acc is usually 13% in the case of SDM07 .

In summary, the above observations show that the proposed method takes into account minority class instances without harming the global accuracy as much as existing methods. We owe this fact to both the double-ensemble framework and the multi-objective optimization technique embedded in the learning algorithm, which dynamically adapts its threshold to variation in data distribution. Similar results were also found in the experiments with the other two datasets. The results are shown in Table 6 and Table 7.

Finally, we report the elapsed time during training and test phases of each method. The running time increases with the batch size. Using C4.5 as the base learner on Credit Card data, the proposed method takes 353 seconds, whereas SDM07 spends 280 seconds. In the case of the Adult data, the proposed method and SDM07 use 274 and 234 seconds, respectivel y. These results are reasonable, because the proposed method trains tw o ensembles of classifiers. Hence, the training time is slight longer than that of SDM07 .
 In this paper, we have presented a classi fication method for skewed data streams. This method is based on two classifier ensembles suited for learning with and without class skew. While still improving the accuracy on each class, the pro-posed method does not decrease the g lobal recognition accuracy as much as existing methods. Future work will be directed towards extending our study to multi-class data streams.

