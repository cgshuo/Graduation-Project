 Liu Yang liuy@cs.cmu.edu Machine Learning Department, Carnegie Mellon University Steve Hanneke steve.hanneke@gmail.com In many machine learning applications, there is an abundance of cheap unlabeled data, while obtaining enough labels for supervised learning requires signif-icantly more time, effort, or other costs. It is there-fore important to try to reduce the total number of labels needed for supervised learning. One of the most appealing approaches to this problem is active learn-ing , a protocol in which the learning algorithm itself selects which of the unlabeled data points should be labeled, in an interactive (sequential) fashion. There is now a well-established literature full of compelling theoretical and empirical evidence indicating that ac-tive learning can significantly reduce the number of la-bels required for learning, compared to learning from randomly selected points (passive learning). However, there remain a number of fundamental open questions regarding how strong the theoretical advantages of ac-tive learning over passive learning truly are, particu-larly when faced with the challenge of noisy labels. At present, there is already a vast literature on the de-sign and analysis of passive learning algorithms, built up over several decades by a substantial number of researchers. In approaching the problem of designing effective active learning algorithms, we might hope to circumvent the need for a commensurate amount of ef-fort, by directly building upon the existing tried-and-true passive learning methods. By leveraging the in-creased power afforded by the active learning protocol, we may hope to further reduce the number of labels required to learn with these same methods.
 Toward this end, (Hanneke, 2009; 2012) recently pro-posed a framework called activized learning , in which a passive learning algorithm is provided as a subroutine to an active meta-algorithm, which constructs data sets to feed into the passive subroutine, and uses the returned classifiers to inform the active learning pro-cess. The objective is to design this meta-algorithm in such a way as to guarantee that the number of label requests required to learn to a desired accuracy will al-ways be significantly reduced compared to the number of random labeled examples the given passive learning algorithm would require to obtain a similar accuracy; in this case, we say the active meta-algorithm activizes the given passive algorithm. This reduction-based framework captures the typical approach to the de-sign of active learning algorithms in practice (see e.g., (Tong and Koller, 2001; Baldridge and Palmer, 2009; Settles, 2010)), and is appealing because it may in-herit the tried-and-true properties (e.g., learning bias) of the given passive learning algorithm, while further reducing the number of labels required for learning. If an active meta-algorithm activizes every passive learning algorithm, under some stated conditions, then it is called a universal activizer under those conditions. In the original analysis, (Hanneke, 2009) proved that such universal activizers do exist under the condition that the target concept resides in a known space of fi-nite VC dimension and that there is no label noise (the so-called realizable case ). (Hanneke, 2012) also proved that there exist classification noise models under which there typically do not exist universal activizers, even with the Bayes optimal classifier in a known space of finite VC dimension. Thus, there is a question of what types of noise admit the existence of universal activiz-ers for a given type of concept space.
 In this work, we study the classic uniform classifica-tion noise model of (Angluin and Laird, 1988). In this model, there is a target concept residing in a known concept space of finite VC dimension, and the labels in the training data are corrupted by independent and identically distributed noise variables. The probability that a given label in the training set differs from that of the target concept is referred to as the noise rate , and is always strictly less than 1 / 2 so that the tar-get concept is also the unique Bayes optimal classifier. Below, we find that there do exist universal activiz-ers for any VC classes under the uniform classification noise model. This represents the first general result es-tablishing the existence of universal activizers for VC classes in the presence of classification noise. Our proof of this result builds upon the established methods of (Hanneke, 2012), but requires several novel technical contributions in addition, including a rather interest-ing technique for handling the problem of adapting to the value of the noise rate.
 The paper is structured as follows. In Section 2, we formalize the setting and objective. This is followed in Section 3 with a description of a helpful method and result of (Hanneke, 2012). We then proceed to construct two useful subroutines in Section 4, proving a relevant guarantee for each. Finally, in Section 5, we present our meta-algorithm and prove the main result: that the proposed meta-algorithm is indeed a universal activizer for VC classes under the uniform classification noise model. We are interested in a statistical learning setting for binary classification, in which there is some joint dis-tribution D XY on X  X { X  1 , +1 } , and we denote by D the marginal distribution of D XY on X . For any classifier h : X  X  { X  1 , +1 } , denote by er( h ) = D
XY ( { ( x, y ) : h ( x ) 6 = y } ) the error rate of h . There is additionally a set C of classifiers, called the con-cept space , and we denote by d the VC dimension of C (Vapnik and Chervonenkis, 1971; Vapnik, 1982); throughout this work, we will suppose d &lt;  X  , in which case C is called a VC class . We will be interested in the set of distributions satisfying the uniform classification noise assumption of (Angluin and Laird, 1988), which supposes there is an element h  X  D the Y values are simply the h  X  D corrupted by independently flipping each Y to equal Definition 1. For a given concept space C , de-fine the set of uniform classification noise distri-butions UniformNoise( C ) = {D XY :  X  h  X  D C ,  X  ( D XY )  X  [0 , 1 / 2) such that for ( X, Y )  X  D XY P ( Y 6 = h  X  D For D XY  X  UniformNoise( C ), the classifier h  X  D called the target function , and  X  ( D XY ) is referred to as the noise rate ; note that we have  X  ( D XY ) = er( h  X  D In the learning problem, there is a sequence Z = D
XY -distributed; we denote by Z m = { ( X i , Y i ) } m i =1 The { X i }  X  i =1 sequence is referred to as the unlabeled data sequence, while the Y i values are referred to as the labels . An active learning algorithm has direct ac-cess to the X i values, but must request to observe the labels Y i one at a time. In the specific active learning protocol we study here, the active learning algorithm is given as input a budget n  X  N , and is allowed to request the values of at most n labels; based on the X i values, the algorithm selects an index i 1  X  N , receives the value Y i the value Y i after which the algorithm returns a classifier. Definition 2. An active learning algorithm A achieves label complexity  X  a ( , ) if, for any joint distribution D XY ,  X   X  &gt; 0 ,  X  n  X   X  a (  X , D XY ) , E [er( A ( n ))]  X   X  .
 Since some D XY have no classifiers h with er( h )  X   X  for small  X  &gt; 0, we will be interested in analyzing the quantity  X  a (  X  ( D XY ) +  X , D XY ), the number of labels sufficient to achieve expected error rate within  X  of the best possible error rate.
 In the present context, we define a passive learning algorithm as any function A p ( ) mapping any finite sequence of labeled examples to a classifier. Definition 3. A passive learning algorithm A p achieves label complexity  X  p ( , ) if, for any joint distribution D XY ,  X   X  &gt; 0 ,  X  n  X   X  p (  X , D XY ) , E [er( A p ( Z n ))]  X   X  .
 For any m  X  N and sequence L X  ( X X { X  1 , +1 } ) m , we additionally define the empirical error rate of a clas-define V [( x, y )] = { h  X  V : h ( x ) = y } for any V  X  C . Following (Hanneke, 2009; 2012), we now formally de-fine what it means to activize a passive algorithm. An active meta-algorithm is a procedure A a taking as input two arguments, namely a passive learning al-gorithm A p and a label budget n  X  N , and return-ing a classifier  X  h = A a ( A p , n ), such that A a ( A is an active learning algorithm. Define the class of functions Polylog(1 / X  ) as those g s.t.  X  k  X  [0 ,  X  ), g (  X  ) = O log k (1 / X  ) . Here, and in all contexts below, the asymptotics are always considered as  X   X  0 (from above) when considering a function of  X  , and as n  X  X  X  when considering a function of n ; all other quanti-ties are considered constants in these asymptotics. In particular, we write g 1 (  X  ) = o ( g 2 (  X  )) (or equivalently g For a label complexity  X  p , we will consider any D XY for which  X  p ( , D XY ) is relatively small as being triv-ial , indicating that we need not concern ourselves with improving the label complexity for that D XY since it is already very small; for our purposes,  X  X el-atively small X  means polylog. Furthermore, keeping with the reduction style of the framework, we will only require our active learning methods to be effec-tive when the given passive algorithm has  X  X eason-able X  behavior. Formally, define the set Nontrivial( X  p ) as those D XY for which, letting  X  = min h er( h ),  X  (  X  +  X , D XY ) =  X  ( g (  X  )). Finally, define an activizer under uniform classification noise as follows. Definition 4. (Hanneke, 2009; 2012) We say an active meta-algorithm A a activizes a passive algo-rithm A p for C under UniformNoise( C ) if the fol-lowing condition holds. For any label complexity  X  p achieved by A p , the active learning algorithm A a ( A p achieves a label complexity  X  a such that  X D XY  X  UniformNoise( C )  X  Nontrivial( X  p ) ,  X  c  X  [1 ,  X  ) s.t. (letting  X  =  X  ( D XY ) ) In this case, A a is called an activizer for A p with respect to C under UniformNoise( C ) , and the active learning algorithm A a ( A p , ) is called the A a -activized A p . If A a activizes every passive algorithm for C un-der UniformNoise( C ) , we say A a is a universal ac-tivizer for C under UniformNoise( C ) .
 This definition says that, for all nontrivial distribu-tions satisfying the uniform classification noise model, the activized A p algorithm has a label complexity with a strictly slower rate of growth compared to that of the original A p algorithm. For instance, if the origi-nal label complexity of A p was  X (1 / X  ), then a label complexity of O (log(1 / X  )) for the activized A p algo-rithm would suffice to satisfy this condition (as would, for instance, O (1 / X  1 / 2 )). The two slight twists on this interpretation are the restriction to nontrivial distri-butions and the factor of c loss in the  X  argument. As noted by (Hanneke, 2012), the restriction to some no-tion of  X  X ontrivial X  D XY is necessary, since we clearly cannot hope to improve over passive in certain triv-ial scenarios, such as when D has support on a sin-gle point; passive learning can have O (log(1 / X  )) label complexity in this case. The implication of this defi-nition is that the activized algorithm X  X  label complex-ity is superior to any nontrivial upper bound on the passive method X  X  label complexity. It is not known whether the loss in the  X  argument, by a constant c , is really necessary in general (even for the realizable case). However, this only really makes a difference for rather strange passive learning methods; in most cases,  X  p (  X  +  X  ; D XY ) = poly(1 / X  ), in which case we can set c = 1 by increasing the leading constant on  X  a . Our analysis below reveals we can set this c arbitrarily close to 1, or even to a certain (1 + o (1)) function of  X  . 2.1. Summary of Results In this work, we construct an active meta-algorithm, referred to as Meta-Algorithm 1 below, and prove that it is a universal activizer for C under UniformNoise( C ). This applies to any VC class C . The significance of this result is primarily a deeper understanding of the ad-vantages of active learning over passive learning. This first step beyond the realizable case in activized learn-ing is particularly interesting in light of established negative results indicating that there exist noise mod-els under which there do not exist universal activizers for certain VC classes (Hanneke, 2012).
 The proof is structured as follows. We first review a technique of (Hanneke, 2012) for active learning based on shatterable sets, represented by Subroutine 1 be-low. For our purposes, the important property of this technique is that it produces a set of labeled exam-ples, where each example has either its true (noisy) label, or else has the label of the target function it-self (i.e., the de-noised label). It also has the desirable property that the number of examples in this set is significantly larger than the number of label requests used to produce it. These properties, originally proved by (Hanneke, 2012), are summarized in Lemma 1. We may then hope that if we feed this labeled sample into the given passive learning algorithm, then as long as this sample is larger than the label complexity of that algorithm, it will produce a good classifier; since we used a much smaller number of label requests com-pared to the size of this sample, we would therefore have the desired improvements in label complexity. Unfortunately, it is not always so simple. The fact that some of the examples are de-noised turns out to be a problem, as there are passive algorithms whose perfor-mance may be highly dependent on the uniformity of the noise, and their performance can actually degrade from denoising select data points. For instance, there are several algorithms in the literature on efficiently learning linear separators under uniform classification noise, which may produce worse classifiers if given a partially-denoised set of examples instead of the orig-inal noisy examples. Even common methods such as logistic regression can be made to perform worse by denoising select instances. So our next step is to alter this sample to appear more like a typical sample from D
XY ; that is, oddly enough, we need to re-noise the de-noised examples.
 The difficulty in re-noising the sample is that we do not know the value of  X  ( D XY ). Furthermore, estimat-ing  X  ( D XY ) to the required precision would require too many labeled examples to obtain the desired per-formance gains. So we devise a means of getting what we need, by a combination of coarse estimation and a kind of brute-force search. With this approximate noise rate in hand, we simply flip each de-noised la-bel with probability  X   X  ( D XY ), so that the sample now appears to be a typical sample for D XY . This method for re-noising the sample is referred to as Sub-routine 2 below, and its effectiveness is described in Lemma 2. Feeding this sample to the passive algo-rithm then achieves the desired result.
 However, before we can conclude, there is some clean-up needed, as the above techniques generate a variety of by-products that we must sort through to find this re-noised de-noised labeled sample. Specifically, in ad-dition to the large partially de-noised labeled sample, Subroutine 1 also generates several spurious labeled data sets, with no detectable way to determine which one is the sample we are interested in. Furthermore, in addition to the re-noised data set resulting from adding noise at rate  X   X  ( D XY ), Subroutine 2 also gen-erates several samples re-noised with noise rates differ-ing significantly from  X  ( D XY ). As such, our approach is to take all of the sets produced by Subroutine 1, run each through Subroutine 2, and then run the passive algorithm with each of the resulting samples. This re-sults in a large collection of classifiers, at least one of which has the required error rate. To identify a good classifier among these, we perform a kind of tourna-ment, comparing pairs of classifiers by querying for the labels of points where they disagree, and taking as the winner the one making fewer mistakes. After sev-eral rounds of this, we emerge with an overall winner, which we then return. This technique is referred to as Subroutine 3 below, and the guarantee on the quality of the classifier it selects is given in Lemma 3. The sections below include the details of these meth-ods, with rigorous analyses of their behaviors. This section describes an approach to active learning investigated by (Hanneke, 2009; 2012). Recall that we say a set of classifiers V shatters { x 1 , . . . , x m } X  X   X  y 1 , . . . , y m  X  { X  1 , +1 } ,  X  h  X  V s.t.  X  i  X  m, h ( x y . To simplify notation, define X 0 = {  X  } , and say V shatters  X  iff V 6 = {} ; also suppose P ( X 0 ) = 1. Now consider the definition of Subroutine 1 below, based on a similar method of (Hanneke, 2012). For our purposes, for m  X  N , the value  X  U m (  X  ) is defined as follows, based on a uniform concentration inequality of (Vapnik and Chervonenkis, 1971). The results below would also hold for certain other choices of  X  U m (  X  ), which may sometimes yield smaller label complexity guarantees; see (Hanneke, 2012) for one such alternative. The quantities  X  P ( ) in Sub-routine 1 are estimators for their respective analogous quantities P ( ), based only on unlabeled examples. Their specific definitions are not particularly relevant to the present discussion, but for completeness are in-cluded in an appendix available online.
 Subroutine 1 operates as follows. We first request a number of labels for random points, and use these to prune away any classifiers making a relatively large number of mistakes, leaving a subset V of classifiers from C with relatively small empirical error rates. We then proceed to construct d +1 different pairs ( L k , Q k of labeled data sets. For each k , each data point X m in the sequence will be inserted into either L k or Q k , along with a corresponding label. If it is determined (in Step 6) that, for most sequences S  X  X  k  X  1 that V shatters, V also shatters S  X  X  X m } , then we request the label Y m and add the pair ( X m , Y m ) to Q k . For each S  X  X k  X  1 shattered by V for which V does not shatter S  X  X  X m } , there is some y  X  X  X  1 , +1 } and some classification of S such that every h  X  V that classifies S in that way has h ( X m ) = y ; we let  X  y denote the value of y for which this happens on a larger fraction of sequences S of this type; if X m was not already inserted into Q k , then we insert the pair ( X m ,  X  y ) into L . Thus, Q k is the set of examples we requested the labels of, while L k is the set of examples we did not request the labels of, along with a kind of inferred label. The motivation for this technique comes from the work of (Hanneke, 2012), where it is shown that, for appropriate values of k , with high probability this  X  y will agree with h  X  D processed in this way (specified in Step 5) is chosen to , Q ) , . . . , ( L d +1 , Q d +1 )  X  U  X   X  Q k  X  X  ( X m , Y m ) } and t  X  t + 1 ,  X  y )] does not shatter S V shatters S be small enough so that, with high probability, the  X  t &lt; n  X  condition in Step 6 is redundant, and so that |L k | X  n 33 / 32 (for technical reasons arising below). The following result was essentially proven by (Hanneke, 2012) (more precisely, it can easily be estab-lished following the techniques of (Hanneke, 2012)); for completeness, we include a full proof in an appendix available on the web.
 Lemma 1. (Hanneke, 2012) For any VC class C and D XY  X  UniformNoise( C ) , there exist constants k  X   X  { 1 , . . . , d + 1 } , c, c  X   X  (1 ,  X  ) , and a monotone sequence  X  1 ( n ) =  X  ( n ) such that,  X  n  X  N , with prob-ability at least 1  X  c exp { X  c  X  n 1 / 3 } , running Subrou-tine 1 with label budget  X  n/ 2  X  and confidence param-eter  X  n = exp { X  and er L In other words, the set L k  X   X  Q k  X  has size  X  n , and every ( x, y )  X  X  k  X  has y = h  X  D Re-noising the Sample At first glance, it might seem Lemma 1 almost solves the problem already, aside from identifying an appropriate k . For k = k  X  , the sample L k  X  Q k represents a partially de-noised collection of labeled examples, which might intuitively seem even better to feed into the passive algorithm than a sample with noisy labels. However, this reason-ing is na  X  X ve, since we are seeking a universal activizer for C , applicable to any passive learning algorithm. In particular, there are many passive learning algorithms that actually use the properties of the noise to their advantage in the learning process, so that altering the noise distribution of the sample may alter the behav-ior of the passive algorithm to ill effects: that is, its performance can be made worse by de-noising select examples from a given sample. For instance, this is the case for certain algorithms in the computational learn-ing theory literature on efficiently learning linear sepa-rators under uniform classification noise. It is also true for many methods based on statistical models, such as logistic regression. Another idea might be to simply feed one of the Q k sets to the passive learning algo-rithm. However, this suffers from a similar problem, as there are many passive learning algorithms designed for specific distributions over X , which simply do not work when the data has a different distribution. For instance, this is the case for many algorithms in the computational learning theory literature, which are of-ten designed specifically for certain highly-symmetric distributions (e.g., so that one has concentration guar-antees on the coefficients in a high-dimensional repre-sentation of the target, such as in Fourier analysis). Therefore, to design an active learning algorithm with label complexity improvements over passive learning methods such as these, we cannot simply use the de-noised labels, nor can we use only the subset of labels actually requested, as input to the passive algorithm. Thus, we are tasked with the somewhat unusual prob-lem of re-noising the de-noised labels, so that the la-beled sample appears to be a typical iid sample with distribution roughly D XY . Of course, if we knew  X  ( D XY ), we could simply corrupt each of the de-noised labels independently with probability  X  ( D XY ). In the } , let R j = L ( j )  X  Q absence of such direct information, one might try sub-stituting an estimate of  X  ( D XY ). However, it happens one would need too many labeled samples to estimate  X  ( D XY ) to the precision needed to re-noise the sample similarly enough to the D XY distribution to work well when we feed it into the passive algorithm. Instead, we employ a combination of estimation and search, which turns out to be sufficient for our purposes. Specifi-cally, consider Subroutine 2 above. The algorithm first produces a confidence interval for  X  ( D XY ) of width 2 n  X  5 / 16 , and then picks a sequence of evenly-spaced values  X  j in this range, at increments of 2 n  X  17 / 16 ; for each of these  X  j values, it flips the label of each sam-ple in L independently with probability  X  j , and merges these corrupted samples with the set Q to produce a labeled data set R j . 1 We have the following lemma. Lemma 2. Suppose D XY  X  UniformNoise( C ) ,  X  ( n ) =  X  ( n ) , Q X  X  { X 1 , . . . , X m } , and L X = { X 1 , . . . , X m }\ Q X . Further suppose Q = { ( X i , Y X i  X  Q X } , L = { ( X i , h  X  D XY ( X i )) : X i  X  L X } , n 33 / 32  X  |L|  X   X  2 ( n ) , and A p is a passive learning algorithm. Then  X  q 1 ( n ) = o (1) s.t., if { R i } n 3 / 4 sequence of data sets returned by Subroutine 2 when provided n and ( L , Q ) as inputs, then
E min Proof. If  X  ( D XY ) = 0, then R 0 = Z m , so that the re-sult clearly holds with q 1 ( n ) = 0. For the remainder of the proof, suppose  X  ( D XY ) &gt; 0, and let  X  =  X  ( D XY Let N 1 = min { n  X   X  N : min m&gt;n  X   X  2 ( m )  X  n } ; this exists because  X  2 ( n ) =  X  ( n ). Since |L|  X   X  2 ( n ), if n &gt; N 1 we must have s = n . If this is the case, then by Hoeffding X  X  inequality, with probabil-ity 1  X  exp  X  n 1 / 4 , |  X   X   X   X  ( D XY ) |  X  c 1 n  X  3 / 8 some (universal) constant c 1  X  (0 ,  X  ). Thus, on this event, letting N 2 = max { N 1 , c 16 1 } , if n &gt; N ticular, this means j  X  = argmin j |  X  j  X   X  ( D XY ) | has |  X  Now for any sequence of labels y 1 , . . . , y m  X  X  X  1 , +1 } s.t. X i  X  Q X =  X  y i = Y i , we have  X  max  X  max This final quantity approaches 1 as n  X   X  , and we therefore define, for any n &gt; N 2 , In particular, when the above inequalities hold,
E h er ( A p ( R j  X  ))  X   X  { X i } m i =1 , Q, j  X  i Since we have established that this holds with proba-bility at least 1  X  exp  X  n 1 / 4 when n &gt; N 2 , we have, , h , . . . , h N ) 6 = h 2 i ( X i ) (if they exist) by the law of total expectation, and since we always have er( A p ( R j  X  ))  X   X   X  [0 , 1], if n &gt; N 2 ,
E [er ( A p ( R j  X  ))  X   X  ]  X  (1 + q 1 ( n )) E [er ( A p ( Z m ))  X   X  ] + exp n  X  n 1 / 4 For completeness, we may define q 1 ( n ) = exp n N 1 / 4 for any n  X  N 2 , and the inequality in the lemma state-ment then trivially holds for these small n values. A Tournament for Classifier Selection Lem-mas 1 and 2 together indicate that, if we feed each ( L k , Q k ) pair into Subroutine 2 (using an appropri-ate fraction of the overall label budget for each call), then we need only find a way to select from among the returned labeled samples R j , or equivalently from among the set of classifiers h j = A p ( R j ), so that the selected  X  j has er( h  X  j )  X   X  ( D XY ) not too much larger than er( h j  X  )  X   X  ( D XY ), for j  X  as above. Here we de-velop such a procedure, based on a tournament among these classifiers by pairwise comparisons. Specifically, consider Subroutine 3 above. This algorithm groups the classifiers into pairs, and for each pair it requests a number of labels for points on which the two classifiers disagree; it then discards whichever of these classifiers makes more mistakes, and makes a recursive call on the set of surviving classifiers (the number of which is smaller than the original set by a factor of 2). This procedure admits the following lemma.
 Lemma 3. Suppose D XY  X  UniformNoise( C ) . Then there exists a constant c  X  (0 ,  X  ) and a func-tion q 2 ( n ) = o (1) such that, for any n  X  N and any sequence of classifiers h 1 , h 2 , . . . , h N with 1  X  N  X  ( d + 1)(1 + (4 n ) 3 / 4 ) , with probability at least 1  X  exp  X  cn 1 / 12 , the classifier h  X  j returned from calling Subroutine 3 with label budget n and classi-fiers h 1 , h 2 , . . . , h N satisfies er( h  X  j )  X   X  ( D q ( n )) min j (er( h j )  X   X  ( D XY )) .
 Proof. Let  X  =  X  ( D XY ). We proceed inductively (it is clear for N = 1). Suppose some i  X  { 1 , . . . ,  X  N/ 2  X  X  has P ( h j ( X ) 6 = h  X  D h = Denoting by p 1 this latter quantity, and letting  X  1 =
P (er S iN ( h k ) &gt; 1 / 2) = P (er S iN ( h k ) &gt; (1 +  X  for an appropriate choice of constant c 1  X  (0 ,  X  ). Simplifying this last expression, we find that it is at most exp  X  c 2 n 1 / 12 for an appropriate constant c 2  X  (0 ,  X  ). A union bound then implies that with probability at least 1  X  ( N/ 2) exp  X  c 1 n 1 / 12 , for each i  X  { 1 , . . . ,  X  N/ 2  X  X  , we have P ( h  X  i ( X ) 6 = h Note that, although both n and N are reduced in the recursive calls, they will still satisfy the constraint on the size of N (i.e., 1  X  N  X  ( d + 1)(1 + (4 n ) 3 / 4 )), and the sample sizes | S | =  X  n/N  X  remain essentially constant over recursive calls, so that this result can be applied to the recursive calls as well (tweaking the constant in the exponent can compensate for the vari-ability due to the floor function). Thus, applying this argument inductively, combined with a union bound over the O (log N ) recursive calls, we have that there exists a constant c 2  X  (0 ,  X  ) s.t. with probability  X  1  X  ( N log 2 N ) exp  X  c 2 n 1 / 12  X  1  X  exp  X  cn 1 / 12 (for an appropriate c &gt; 0), the returned classifier h  X  satisfies (for an appropriate constant c 3  X  (0 ,  X  )) P h  X  j ( X ) 6 = h  X  D Since  X  h , er( h )  X   X  = (1  X  2  X  ) P ( h ( X ) 6 = h  X  D approaches 1 as n  X   X  , defining q 2 ( n ) = exp c 3 n  X  1 / 12 log n  X  1 suffices for the result. We are now finally ready for our main result, establish-ing the existence of universal activizers for VC classes under uniform classification noise. Specifically, con-sider Meta-Algorithm 1 above, which combines the above arguments (setting appropriate label budgets for each subroutine). We have the following result. Theorem 1. For any VC class C , Meta-Algorithm 1 is a universal activizer for C under UniformNoise( C ) . Proof. Lemma 1 implies that with probability 1  X  exp { X   X ( n 1 / 3 ) } , some pair ( L k , Q k ) will satisfy the conditions of Lemma 2; more precisely, on this event, and conditioned on |L k  X  Q k | , the pair ( L k , Q k ) will be distributionally equivalent to a pair ( L , Q ) that satisfies these conditions. Thus, combining Lemmas 1 and 2, and the law of total expectation, combined with the fact that er( h )  X   X  ( D XY )  X  [0 , 1] for D XY UniformNoise( C ), we have that (letting  X  =  X  ( D XY ))
E min Finally, combining this with Lemma 3 implies that E h er(  X  h )  X   X  i  X  (1 + o (1)) sup For an n =  X (log 12 (1 / X  )), the second term on the right hand side of (1) is &lt;  X  . For the first term, note that if A p achieves label complexity  X  p , then in order to take n large enough so that  X  1 ( n )  X   X  p (  X  +  X  ; D XY Thus, since  X  1 ( n ) =  X  ( n ), for D XY  X  Nontrivial( X  p the smallest N 2  X   X  N such that every n  X  N 2  X  has satisfies N 2  X  = o ( X  p (  X  +  X , D XY )). Therefore, since any O (log 12 (1 / X  )) function is also o ( X  p (  X  +  X , D for D XY  X  Nontrivial( X  p ), we see that applying Meta-Algorithm 1 to A p results in an active learning algo-rithm achieving a label compleity  X  a s.t., for D XY  X  UniformNoise( C )  X  Nontrivial( X  p ),  X  a (3  X  +  X , D XY )  X  max N 2  X  , O (log 12 (1 / X  )) = o ( X  p (  X  +  X , D XY )). We established the existence of universal activizers for arbitrary VC classes in the presence of uniform classi-fication noise. This is the first result of this generality regarding the advantages active learning over passive learning in the presence of noise.
 Previously, (Hanneke, 2009; 2012) has argued that even seemingly benign noise models typically do not permit the existence of universal activizers for arbi-trary VC classes. Thus, in an investigation of the existence of universal activizers for VC classes, the key question going forward is whether there are more general noise models, nontrivially subsuming uniform classification noise, under which universal activizers for VC classes still exist.
 Angluin, D. and Laird, P. Learning from noisy exam-ples. Machine Learning , 2:343 X 370, 1988.
 Baldridge, J. and Palmer, A. How well does active learning actually work? Time-based evaluation of cost-reduction strategies for language documenta-tion. In Proceedings of the Conference on Empirical Methods in Natural Language Processing , 2009. Hanneke, S. Theoretical Foundations of Active Learn-ing . PhD thesis, Machine Learning Department,
School of Computer Science, Carnegie Mellon Uni-versity, 2009.
 Hanneke, S. Activized learning: Transforming passive to active with improved label complexity. Journal of Machine Learning Research , 13(5):1469 X 1587, 2012. Settles, B. Active learning literature survey. http://active-learning.net , 2010.
 Tong, S. and Koller, D. Support vector machine ac-tive learning with applications to text classification. Journal of Machine Learning Research , 2, 2001. Vapnik, V. Estimation of Dependencies Based on Em-pirical Data . Springer-Verlag, New York, 1982. Vapnik, V. and Chervonenkis, A. On the uniform con-vergence of relative frequencies of events to their probabilities. Theory of Probability and its Applica-
