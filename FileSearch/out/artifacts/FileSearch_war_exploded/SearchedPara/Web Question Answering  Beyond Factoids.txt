
Automatic question answering is a central topic in in-formation retrieval. Web search engines have made great progress at answering factoid queries, such as  X  X ow many people live in Australia? X . These can provide a succinct an-swer, up to a few words in length, and sometimes offer ad-ditional information such as related facts or entities. How-ever, for deeper questions which could benefit from a longer response (e.g.,  X  X istory of Australia X ), current search engine resort to returning a link to a detailed web document. Alter-natively, such a question might be posted on a Community Question Answering (CQA) site ( X  X isiting Australia in May, what should I see? X ), hoping to get a human authored and detailed response.

In this workshop we aim to explore the boundaries of Web question answering to better understand the spectrum of ap-proaches and possible responses that are more detailed than a short fact, yet are more useful than a full document re-sult. Is it possible to automatically answer diverse questions ranging from advice on fixing a broken sink to requests for opinions on the best basketball player of all time. In addi-tion, questions submitted on the Web can be either short and ambiguous (such as Web queries to a search engine), or long and detailed (such as CQA questions). This work-shop is particularly timely for two additional reasons: (1) there still exist many disagreements regarding the goals and nature of Web question answering services, mostly relating to the questions of  X  X uestion intent X  (what kind of queries benefit from question answering compared to other meth-ods); and (2) leading search engines are eager to provide
