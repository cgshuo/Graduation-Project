
Universidad Central  X  X arta Abreu X  de Las Villas, Villa Clara, Cuba Hasselt University, Hasselt, Belgium 1. Introduction
The FCM theory [2] was introduced by B. Kosko as a knowledge-based methodology for modeling and simulating dynamical systems. These structures combine the reasoning strength of the connectionist approach with some elements of fuzzy logic, which are normally considered during the knowledge-engineering phase [3]. Using this methodology, a system can be modeled in terms of concepts (e.g. variables, objects or states which are equivalent to neurons in connectionist models) and causal relations among such entities. In a few words, from the structural point of view, a simple FCM may be denoted as directed graphs allowing feedback, consisting on neurons and weighted arcs.

In a simple FCM, each link takes value in the range [  X  1 , 1] . It denotes the causality degree between two nodes as a result of the quantification of a fuzzy linguistic variable [6]. The activation value of concepts is also fuzzy in nature and regularly takes values in the range [0 , 1] . Hence, the higher the activation value, the stronger the influence of the concept over the investigated system. In other words, FCM establish the forward and backward propagation of causality [5], admitting the knowledge base to increase when concepts and links between them are increased.

In the past decade, FCM based models have gained considerable research interest among researches, being widely used for solving several real-world problems. Some practical examples include [11]: decision-making tasks, risk analysis, prediction, text categorization, pattern recognition, management, and classification. However, estimating parameters that characterize the whole system (e.g. the causal weight matrix) may be tedious for humans, leading to inefficient models. In order to increase the reli-ability of FCM-based models several learning algorithms for tuning such parameters have been intro-duced [10], although most of them are focused on computing causal relations between map concepts.
On the other hand, existing approaches suppose that FCM are closed systems and they do not con-sider external influences, while other factors such as the FCM stability are frequently ignored. As far as known, there is no existence of any learning method for enhancing the system stability once the system causality is established. For example, let us suppose a FCM resulting from experts where causal connec-tions may be partially modified (e.g. we know the direction of causalities and an approximation of their values that should be preserved). Can we expect lineal stability in the final map? If not, how to improve the stability of the system without affecting causal connections estimated by experts? In the literature a few researches concerning FCM convergence have been proposed. For instance, Kosko [4] developed an analytic method based on Liapounov functions for reaching stable solutions on Feedback Standard Additive Models (SAM  X  which share several of the FCM characteristics). Unfor-tunately, Kosko concluded that such conditions cannot be extended to FCM due to the large number of feedback links involved in FCM-based models. More recently, other analytical methods were intro-duced (see Section 3), but we believe that such approaches are mostly useful for stabilizing FCM used in modeling tasks.

Being more specific, this paper attempts explaining why most analytical models ensuring the existence and uniqueness of a fixed-point attractor cannot be successfully used for solving prediction problems. Besides, we formalize an approximate algorithm based on Swarm Intelligence which learning goal is the system stability. Briefly, the basic idea here is to find an appropriate threshold function for each map neuron, instead of using the same function for all concepts. It attempts enhancing the map stability once the estimation of the causal weight matrix is done, without affecting the inference capability of the original system. In practice this scheme leads to a Sigmoid FCM-based model that uses excitable neurons, that is, concepts that could be influenced by external factors.

It is pertinent to remark that authors will be focused on Sigmoid FCM, instead of discrete (e.g. binary o trivalent) ones. This remark is motivated by the benchmarking study discussed in [27] where results showed that the sigmoid function outperformed the other functions, by using the same decision model. Besides, since FCM are deterministic models, a discrete map will always find a previously visited state vector (although the path length to reach this point could be exponential).
 The rest of the paper is organized as follows: the second section provides mathematical details about FCM. In the third section we review the most relevant studies on FCM convergence and their drawbacks, whereas in the Section 4 we describe a new learning method for handling stability issues in Sigmoid FCM. After that, Section 5 introduces the experimental framework concerning HIV-1 drug resistance, and provides details about simulations. Finally, conclusions are given in Section 6. 2. A brief background on Fuzzy Cognitive Maps
Mathematically speaking, a simple FCM can be defined using a 4-tuple ( C, W, A, f ) where C = { C 1 ,C 2 ,C 3 ,...,C M } is a set of M graph nodes or neurons, W :( C i ,C j )  X  w ij is a function which as-from historical data. Likewise, A :( C i )  X  A i associates an activation degree A i  X  R to each concept C i at the moment t ( t =1 , 2 ,...,T ) . Finally, a threshold or transformation function f : R  X  [0 , 1] is used to keep the activation value of neurons in the allowed range.

Following Eq. (1) shows how to update the activation vector (i.e. the activation value of neurons) using the state vector A 0 as the initial configuration. In the same way to other recurrent models  X  such as the well-known Hopfield network  X  this information propagation mechanism is iteratively repeated until a hidden pattern [5] is observed (which is an ideal outcome), or a maximal number of iterations T is reached. In this scheme the most commonly used threshold functions are: the bivalent function, the trivalent function, and the sigmoid variants.
 The effect on the selection of a specific function over the stability and inference capabilities of the FCM was explored in [1]. From this work some important remarks were concluded:  X  Discrete FCM never show chaotic behavior. It means that always a fixed-point attractor or a limit  X  Continuous FCM may additionally exhibit chaotic states, where the FCM model continues to pro-During the simulation phase on a Sigmoid FCM, the activation value of each map neuron is influenced by the values of the connected concepts with the appropriate weights [15]. It shows the causal effect of changes on the neurons X  activation value on the whole system. More specifically, once the system reaches a fixed-point attractor, decision-makers use this information to make decisions leading to the desired solution [25]. That is why FCM theory is a very convenient approach for performing modeling and simulation tasks. However, when the system reaches a limit cycle or a chaotic behavior, decision-making is practically impossible [30]. In the following Section 3 we review some theoretical results that attempts to provide better stability features on FCM-based models. 3. Stability on non-discrete Fuzzy Cognitive Maps
As far as known, in the literature few researches concerning stability on continuous FCM have been proposed. In this section we revise the most relevant contributions in this field, and after that we try to explain why these approaches are not adequate for stabilizing Sigmoid FCM used on prediction tasks. Note that the main goal of a FCM-based classifier is the mapping of an input set (initial excitation of input neurons) to a desired output vector (system response), according to the representation of the knowledge stored inside the classifier X  X  structure.
 In reference [31] the authors proved that when the weight matrix fulfills certain conditions, then the FCM will converge to a unique fixed-point attractor. For example, if the map has not input neurons (they influence but are not influenced by the other nodes) then the map will converge to a single attractor regardless the exact values of th e initial concept values (see Theorem 1). Likewise, they introduce an adaptive weight-estimation method that employs appropriate weight projection criteria to assure that the uniqueness of the solution is not compromised.
 This result is mainly useful for modeling problems and cannot be applied to FCM-based classifiers. In order to comprehend implicit limitations of this theorem, let us suppose a perfectly balanced clas-sification problem having three decision classes (e.g. Low, Middle and High). According to Theorem 1, and supposing that convergence conditions are met, then the map will always converge to the same fixed-point attractor, which means that 2/3 of all instances will be erroneously classified. Theorem 1 . There is one and only one solution for any concept value A i of any FCM (using a sigmoid transformation function), if: It does not consider FCM with input concepts; although results discussed above are still valid (see The-orem 2). In such cases the equilibrium point does not depend solely on the weight set, as in the case of FCMs with no input nodes, but also depends on the values of the input neurons. Hence, different excitation values will drive the Sigmoid FCM to different fixed-points. It means that, for each equilib-rium point, we need to compute different weights ensuring the desired response, leading to ambiguous understanding of the same investigated system.
 Theorem 2 . For a Sigmoid FCM with m input nodes, there is one and only one solution for any concept value A i if: In reference [7] a slightly different theorem concerning the steepness  X  of sigmoid threshold function is presented (see next Theorem 3). It is based on the assumption that if there were two stable fixed points then a slight change in the initial conditions (which cannot be exactly quantified) may result in a totally different outcome, making the value of the map hard to justify. Though, following the same reasoning explained above it is clear that this approach seriously limits the simulation ability of Sigmoid FCM when solving classification or prediction problems.
 Theorem 3 . The number of solutions of Eq. (1) depends on the size of  X  :  X  If  X &gt; 0 is small enough then there is a unique solution. This fixed point of the Sigmoidal FCM, is  X  If  X &gt; 0 is large enough there can be multiple solutions, where many of these fixed points may be For better understanding of the above affirmation let us consider a FCM concerning travel behavior analysis [24]. This model involves three kinds of variables which are denoted as map concepts, and three further nodes for each transport alternative (bus, bike or car). When the FCM inference process is activated, a decision node called  X  X tility X  is examined. It has evidence related to the expert preferences with respect to each transport mode for an initial cond ition. Nevertheless, according to Theorem 3 and supposing that  X &gt; 0 is small enough, the map will converge to the same solution independently the initial scenario, so the system will not be able to distinguish between two different decisions.
Summarizing, although some researches [21] ensure that FCM cannot be used in classification tasks, recent studies [9,19,20,22] showed that FCM are in turn promising classifiers. However, FCM-based classifiers do not regularly consider the system stability in their learning phase, and some of most rel-evant analytical methods seem to be inadequate to overcome this serious drawback. In the following section we describe a population-based learning methodology that attempts improving the global sta-bility on previously adjusted Sigmoid FCM (i.e. once the phase concerning the estimation of the causal weight matrix is complete). 4. Improving stability on sigmoid FCM
In the literature several supervised and unsupervised learning algorithms have been proposed, mainly focused on the transformation of the causal weight matrix. As a brief categorization, they could be gathered in three large groups [15]: Hebbian-type, population-based and hybrid methods. However, sev-eral of these learning methods cannot explicitly guarantee the system stability (e.g. population-based algorithms). In this section we describe a non-direct learning algorithm for enhancing the convergence features of Sigmoid FCM, once the estimation of the causal links is done. It attempts to reduce the variability on the map responses over the time, but always preserving the overall system accuracy.
Being more specific, Tsadiras [1] demonstrated that the inference ability of FCM-based models may be strongly influenced by the selection of the concepts X  transformation function. On the other hand, Theorem 2 proved that the steepness  X  could be associated to the system stability. Based on these ob-servations, in reference [16] several empirical simulations were performed with the goal of studying the effects of using several sigmoid transformation functions, over the global stability of the system re-sponse, as next Eq. (4) suggests. It should be stated that such experiments are equivalent to use a custom is the real impact of this variation over the system behavior? From empirical simulations the authors concluded that small changes on  X  i lead to some variations on the map stability. Consequently, it seems to be reas onable to suppose that a l earning algorithm could help to improve the map convergence, by solving the related real-parameter optimization problem. It is relevant to remark that normally FCM are considered as closed systems where external factors affecting the concepts are omitted. But in many real world problems this perception will be inadequate and may affect the global accuracy or the system stability.

For example, it is well-known that biological behavior on proteins not only depends on the amino acids interaction, but also is conditioned by external factors such as the chemical processes influencing the catalytic responses [16]. Such external factors may be modeled using a threshold function f i for each  X 
The global effect of this artificial factor may be computed at each cycle as the difference between the map response using the same function for all nodes (i.e.  X  1 =  X  2 = ... =  X  n ), and the system output using a proper family of sigmoid functions. What is more, this scheme is equivalent to introduce a factor 0  X  i 1 to intensify or reduce the activation value of each map neuron C i . From these considerations convergence without modifying the system causality.

More explicitly, the learning aim of this method is focused on computing a family of sigmoid func-function will be used for updating the activation value of the i th concept. In practice, it implies to adjust duced a novel method based on Swarm Intelligence principles [23]. This procedure exploits a swarm of particles to solve the related real-parameter optimization problem.

Particle Swarm Optimization (PSO) is an approximate search method for solving challenging continu-ous problems [26]. In the standard PSO each particle (i.e. swarm agent) denotes a M -dimensional point in the solution space (where M is the total number of map neurons). The i th dimension of each particle represents the steepness  X  i associated to the i th threshold function. During the search, swarm agents adjust their position by using a combination of an attraction to the best positions that they individually have found, and an attraction to the best solutions that any particle has found, imitating those who have a better performance.

PSO-based methods have proven to be quite competent for solving real-parameter optimization tasks [32]. Nevertheless, the swarm is frequently attracted to local optima, causing premature conver-gence states. For this reason, the authors adopted a variant called PSO with Random Sampling in Vari-able Neighborhoods (RSVN) which is able to notably outperform the constricted PSO algorithm [13]. Equation (5) formalizes the objective function that should be minimized during the search steps. In the above function, K is the available number of instances, M denotes the number of neurons, T is the maximal number of times, whereas A k it is the activation value of the i th concept for the current time t ,usingthe k th instance as initial condition. In this scheme an instance is a sequence of values codifying an initial condition, and its corresponding response. In brief, the learning algorithm attempts to reduce the global variability of the system responses for each instance over the time.

On the other hand, a particle (solution) will be considered as no feasible if the prediction ability of the investigated system is negatively affected, which preserves the map accuracy. Observe that causal weights are not modified during this optimization procedure since this method is oriented to compute more stable maps over adjusted Sigmoid FCM.

It should be highlighted that the main goal of our research is to describe a methodology for improving the system stability, therefore we could use any continuous metaheuristic (e.g. Evolutionary Algorithms) for solving the related optimization task. What is more, during simulations we prefer to adopt an approx-imate approach since population-based metaheuristics are capable to find near-optimal solutions in a reasonable execution time, ignoring analytical properties of the objective function (e.g. continuity, con-vexity, differentiability or grad ient information) which are frequently unknown in advanced. However, exact algorithms such as mathematical programming techniques could be used as well.

It is fair to mention that the idea of using  X  X xcitable X  neurons on FCM-based models is not a contri-bution of this work. For example, Stylios and Groumpos [8] introduced a new FCM model where each concept has an external output (bias), which influences each node with a weight and it is taken into ac-count at the calculation rule. The reader may easily perceive the similarity between the Stylios X  proposal and the approach discussed in this section, since both models are oriented to simulate influences over the neurons. In next Section 5 we conduct several experiments that allow studying the effects of the proposed learning algorithm over the stability of six Sigmoid FCM concerning drug resistance analysis. 5. Performance analysis
In order to validate the method discussed in the above section we use six adjusted FCM taken from [18]. Such maps describe the behavior of some HIV-1 mutations related to their resistance to existing antiviral drugs. More precisely, the authors modeled the HIV protease protein as a FCM where each sequence pos ition is tak en as a neuron, while anothe r node for the resistance target is also defined. The protease sequence is defined by 99 amino acids, and its main function is related to the maturation of released viral particles by cleaving precursor proteins [14]. With the goal of reducing the number of concepts involved in the final modeling, they use those sequence sites associated with drug resistance. In this topology neurons are fully connected; whereas a causal connection between each sequence position and the resistance is established.

It is important to mention that each map denotes the protein behavior for a specific drug: Amprenavir (APV), Indinavir (IDV), Saquinavir (SQV), Nelfinavir (NFV), Ritonavir (RTV) and Atazanavir (ATV). Each drug has associated a high-quality filtered datasets taken from [29] consisting in reported mutations and their resistance value. Despite the prediction abilities of this model [22], the authors cannot ensure the system stability. Following we conduct experiments studying the effects of the algorithm described before over the stability of these maps.

In all the experiments performed in this section we use a constricted PSO Type 1 where  X  =0 . 7298 and c 1 = c 2  X  1 . 496 . The parameter settings of the PSO-RSVN algorithm adopted as optimizer is fixed as follows: 40 particles as swarm size, 80 generations, 10 variable neighborhoods, while the allowed number of generations without progress is set to 20. It should be mentioned that parameters concerning the PSO-RSVN algorithm were tuned as reference [17] suggests, since such values proved to be a proper configuration for several problems. Last of all, the number of times used during the inference phase is T = 100 , whereas the activation degree of each map node is calculated as the normalized contact energy [28] of the corresponding amino acid in the input sequence.

As a first analysis, the stability of the resistance neuron for each inhibitor (using a randomly selected mutation) is measured. Figures 1 X 3 show the activation degree of the resistance concept ( x axis) over the time ( y axis) for two situations: the dashed line represents the response using the same function for all neurons, whereas the solid line denotes the output using the family of sigmoid functions found by the algorithm.

From these simulations we can conclude that the algorithm improves the convergence property of each map. In this simulation, only the resistance node was monitored since it is the decision neuron, allowing predicting whether a new unclassified mutation observed in a patient infected by the virus will be susceptible to the target inhibitor or not.

The reader may observe that the system response changes for next drugs: IDV, RTV and ATV. In such cases the classification rate does not suffer any change since the resistance target for a drug is measured in a certain range instead of using a single value. This range is computed by adopting a pre-defined biological cut-off which allows classifying a new mutation in susceptible or resistant. However, we noticed that some FCM achieved better accuracy, which is an unexpected positive result. For better understanding of this issue let us analyze the behavior of the selected mutation  X  X KLD-VFMIIVVSVTVNML X  for the map IDV. This sequence has high level of resistance for the drug IDV, which means that the higher the activation value of the resistance neuron, the better the accuracy of the model for this instance. But after applying the learning algorithm (see Fig. 1(a)) the FCM is able of computing higher resistance value for the decision concept. As partial remarks, four behaviors were observed: (Figs 1(a) and (b)) the convergence feature of stable maps was improved, (Figs 2(a) and (b)) cyclic patterns were removed, (Fig. 3(a)) the variability response on chaotic systems was reduced, although the final system remains chaotic, and finally (Fig. 3(b)) the chaotic behavior was corrected, leading to a perfectly stable system which is the most desirable outcome.

To generalize these results we introduce a second experiment which tries to answer the next question: are the stability improvements statistically significant? By doing so, we calculate for each instance the difference between the original system response, and the average system response after applying the described learning algorithms 10 times. In practice this measure is equivalent to compute the evalua-tion Eq. (4) for each mutation individually ( K =1 ). Table 1 summarizes the p -value resulting from the Wilcoxon signed rank test [12] associated to each inhibitor, and also the behavior of the objective function for all mutations (taking into account the original system, and the best sample solution after ap-plying the proposed learning methodology). This test suggests rejecting the null hypothesis H 0 ( p -value &lt; 0.05) in all cases, confirming that there exist significant improvements on the systems stability.
Why it is desirable more stable systems? To answer this question let us analyze the inference pro-cess for the map SQV regarding the selected mutation  X  X KLDVFMIGVPVISTVNML X . This sequence has high level of resistance to inhibitor SQV. When the same function is used for all the neurons, the activation level of the decision neuron has lower degree of resistance towards the end (iteration 82), and hence the sequence may be erroneously classified as susceptible. But using the family of sigmoid functions found by the learning algorithm the final neuron is more stable, although the biological system remains chaotic. Actually, the variability that shows this map towards the end will not affect the system response, because in this case the final class value (susceptible or resistant) will be determined using a range instead of a single value.

Figures 4 and 5 show the swarm diversity behavior for all inhibitors, during the search phase. The x axis denotes the current generation, whereas the y axis represents the average distance among particles, normalized in the range [0,1]. Observe that the PSO-RSVN algorithm performed identical to the stan-dard constricted PSO model for drugs IDV and RTV, since the swarm reorganization strategy remained inactive. However, for inhibitors ATV, APV, NFV and SQV the algorithm detected potential stagnation or premature convergence states, so the swarm reorganization method was activated, therefore improving the population diversity.

To conclude, we present another experiment illustrating why theoretical results concerning FCM sta-bility (discussed in the Section 3) cannot be used in prediction tasks. With this goal in mind, we estimate the causal matrix of each map by using the weights adaptation procedure discussed in reference [31]. Observe that Theorem 2 is not applicable to the FCM described before because they have not input neurons, so all concepts are updated during the inference procedure. Similarly, we use Theorem 3 for stabilizing FCM-based systems as reference [18] suggests.

Once six maps have been stabilized, all available mutations are classified to evaluate the prediction ac-curacies. Table 2 shows the confusion matrix achieved for each inhibitor. Based on these simulations we can conclude that, after applying such theoretical results, all FCM are able to converge to a stable fixed-point attractor. However, since this attractor is the same regardless the initial stimulus (i.e. mutation) that they attempt to predict, the classification quality is considerable affected.
 6. Conclusions Stability on Sigmoid FCM-based systems plays an important role during the decision-making process. As discussed, stability means to ensure the existence of fixed-points attractors. However, many learning algorithms do not consider this issue in their weights estimation scheme, leading to systems exhibiting cyclic or chaotic patterns. To deal with this drawback some analytical methods have been developed, but they are not adequate for handling FCM used in pattern classification problems. More exactly, these methods are focused on determining analytical conditions ensuring the existence and uniqueness of an attractor point, but in most cases this equilibrium state is the same for all input sequences.
In this paper an approximate algorithm for enhancing the global stability properties of Sigmoid FCM was discussed. The main proposition of this procedure is to estimate, using a Swarm Intelligence ap-proach, a custom sigmoid function for each node instead of using the same transformation function for all neurons. It attempts to efficiently simulate the effects of external factors over the neurons, where the learning goal is the system stability. In order to validate the proposal we used six FCM concerning the Bioinformatics field. From simulations we can conclude that, after applying the learning method-ology, adjusted FCM exhibit better stability without varying the system causality. The future work will be focused on studying the convergence on Sigmoid FCM, but now from perspective of the causal links characterizing the neurons X  interaction.
 References
