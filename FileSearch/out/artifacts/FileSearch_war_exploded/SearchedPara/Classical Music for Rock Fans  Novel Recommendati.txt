 Most recommender algorithms produce types similar to those the active user has accessed before. This is because they measure user similarity only from the co-rating behaviors against items and compute recommendations by analyzing the items possessed by the users most similar to the active user. In this paper, we define item novelty as the small-est distance from the class the user accessed before to the class that includes target items over the taxonomy. Then, we try to accurately recommend highly novel items to the user. First, our method measures user similarity by employ-ing items rated by users and a taxonomy of items. It can accurately identify many items that may suit the user. Sec-ond, it creates a graph whose nodes are users; weighted edges are set between users according to their similarity. It ana-lyzes the user graph and extracts users that are related on the graph though the similarity between the active user and each of those users is not high. The users so extracted are likely to have highly novel items for the active user. An eval-uation conducted on several datasets finds that our method accurately identifies items with higher novelty than previous methods.
 I.2.6 [ Artificial Intelligence ]: Learning X  Knowledge Ac-quisition ; H3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Algorithms, Experimentation, Theory Collaborative filtering, Novelty Detection Recommender systems are widely used by content providers to increase their chance of commercial success. Many con-tent providers adopt methods based on collaborative filter-ing (CF), which is a broad term for the process of recom-mending items to an active user, the one who is receiving the recommendation, based on the intuition that users who access the same items with the user tend to have similar in-terests to the user. Basic CF methods measure the similarity of users only from the co-rating behaviors against items, and compute recommendations for the active user by analyzing the items possessed by the users most similar to the user. As a result, they are apt to recommend the types of items that have already been accessed by the user. For example, if the user highly rates a horror movie (as an item), the typical CF methods recommend items that were made by the same director, performed by the same actors, or included in the same genre, horror. The user, however, may have variety of interests other than horror movie items and often needs recommendations of other types of items[25].

Against this problem, Ziegler and McNee proposed an al-gorithm that increases the diversity of recommendation list entries[25]. The list includes items in several classes defined by a taxonomy. This can raise user satisfaction but the accuracy of item prediction is degraded. Their recommen-dations consider only the items possessed by the users most similar to the user and so include the same types of items that the user has accessed before; they do, however, present a greater number of classes than traditional CF techniques. Their method also fails to analyze or measure item novelty, a critical omission since novel recommendations are essential to widening the user X  X  range of interests. We assess novelty in terms of the distance from the present interests of the user to the item recommended according to the taxonomy of items. This metric is useful in two ways. First, it presents, in an easy to understand manner, the relationship between the user X  X  present interests and the target item. That is, the user can understand why the presented items are different from those that the user has accessed before. Second, the user can boost the novelty threshold if she wants items that are completely unknown to her.

In this paper, we propose a method that accurately iden-tifies items that are highly novel for the active user. We define item novelty as the smallest distance from the class the user accessed before to the class that includes a target item. The metric of accuracy measures the performance of the recommender algorithm by comparing the algorithm X  X  prediction against a user X  X  rating of an item. This metric is also important because users more strongly trust accurate recommendation results and tend to use such services[12, 16]. By accurately identifying items that are highly novel to the user, and recommending those to him, he may become interested in them. For example, if the recommender sys-tem can recommend many good Classical music items to a user who has been listening to only Rock music items, the user may widen his interests by accessing the recommended items. The content providers also can promote more of their items to users even if the users previously accessed only lim-ited sets of items.

The main contributions of the paper are the following.
We evaluated the accuracy and novelty of our method comprehensively by using four large datasets of various item domains with many parameter settings. Furthermore, we extend the taxonomy of items in one item provider by ap-plying the metadata of items gathered from another item provider, and evaluated how the enhanced taxonomy influ-enced the performance of our method. From the many eval-uation results so gained, we confirm that our method iden-tifies many more items that offer higher novelty and does so more accurately than previous similarity schemes including the taxonomy-based method proposed by Ziegler et al.[24, 25].

The paper is organized as follows: we describe related works in the next section. Section 3 explains the background of our study. Section 4 introduces how to measure the simi-larity of users following the taxonomy of items and identify items with higher novelty from a user graph created based on the similarity of users. Section 5 evaluates our method using several datasets, and finally, section 6 concludes the paper.
In this section, we briefly review related works, which can be categorized into three parts: novel item recommenda-tion, accurate item recommendation, and cross-domain rec-ommendation.

Novel Item Recommendation. The notion of novelty is defined in different ways in several papers. To the best of our knowledge, most papers refer to the definition provided in [4]. They define novel items as items that are unknown to the user but interesting for the user. They also describe that novel items and serendipitous items are different in that the former is more easily found by the user than the latter. However, this definition is very abstract, which makes it difficult to evaluate item novelty in detail and thus apply it. We consider that highly novel items, based on our definition, are those that cannot be easily discovered by the user. For example, the user who, up to now, has demonstrated an interest only in music items in Rock, is unable to easily discover interesting items in Classical music by himself.
Onuma et al. proposed a method that identifies novel items as items (they call  X  X urprising X ) that are accessed by users similar to the active user but also accessed by users not so similar to the active user[15]. Their idea is to envi-sion the problem of identifying novel items as node selection on a graph. They give high scores to nodes that are well connected to the older choices, and at the same time well connected to unrelated choices. Their evaluation example shows that their method generates more diverse recommen-dation results such as recommending  X  X urprising X  items in comedy, horror, and science fiction movie items to the user who has shown an interest in only comedy movies. We con-sider that the score of novelty in our paper is more a natural definition because it allows item taxonomy to be used in ex-plaining to the active user why the items were recommended as novel.

The authors in [19, 20] define novelty as  X  X he degree to which a recommendation is non-obvious X . They propose the measurement of novelty that involves computing the number of correct recommendations made by the algorithm that are not present in the recommendations made by a related algo-rithm. Their evaluation shows that their proposed method can identify items that can not be identified by the method that only ranks items by their popularity. We however con-sider such a metric reflects only popularity and is not suit-able for evaluating novelty.

As explained above, we consider that the definitions of novelty given by previous works are not useful in helping the active user to understand why the recommended items were determined to be novel and to understand how novel they are .

Different from the above papers, our previous work ex-amined user satisfaction when recommending novel items to the user[14]. We proposed a taxonomy-based algorithm to find novel items that we defined as items that are included in classes that the active user has not accessed before. An online evaluation showed that user clicks tend to concentrate on the novel items thus found. Our previous work, however, only focused on user interest analysis from the descriptions submitted to blogs and the application of novel item recom-mendation for blog community activation. It also considered only the items possessed by the users most similar to the user and so its recommendations are apt to include a few items with high novelty.

Accurate Item Recommendation. In most CF stud-ies, the researchers focus on improving the accuracy of the prediction results. Here, we explain some of those works such as those using the matrix factorization technique, taxo-nomy-based technique, and graph mining technique.
Yehuda et al. proposed a method that uses matrix fac-torization. It characterizes both items and users by vectors of factors inferred from item rating patterns[7, 8]. High cor-respondence between item and user factors leads to a rec-ommendation. This approach has become popular in recent years since it offers good scalability with predictive accuracy. However, their method does not aim to suggest novel items for the user. Furthermore, the matrix factorization tech-nique usually analyzes latent factors inferred from item rat-ing patterns, thus it is not easy for a user to understand why the identified items are being recommended to the user. We consider that presenting semantic reasons to the user is im-portant, especially when recommending novel items. Thus, we use the taxonomy of items in explaining the reasoning behind the recommendations.

Some researchers use item taxonomies to raise the accu-racy of prediction results[24]. This approach was shown to be useful when the transaction data of users is sparse. How-ever, in measuring user similarity, this type of method fo-cuses only on classes that include items rated by both users and their super classes. As a result, this method naively assumes that users who share many items are highly sim-ilar to the user; those users may have many good as well as many not so good items for the user. Our method is different from existing taxonomy-based methods because it assesses how many subclasses are shared and not shared in each class in the taxonomy.

The authors in [19, 20] assign a-priori scores to the classes in the taxonomy of items, and compute the relationships be-tween scores assigned to different classes. They then prop-agate those scores for a specific user to predict each user X  X  preference. Their method was shown to be useful when the transaction data of users was sparse. Their method lies out-side the scope of CF methods (they call their approach on-tology filtering) because they do not compute user similari-ties. Unfortunately, their method is not suitable for realizing highly novel items identification because the score of user in-terests assigned to one class is rarely propagated to the class that is far from the original class over the taxonomy. Some researchers have started to use random walks or RWR on a graph to compute recommendations[23, 3, 6, 2, 15]. Yildirim and Krishnamoorthy perform random walks on the item graph whose nodes on the graph are items and whose weighted edges are set between item nodes accord-ing to item similarity; they confirmed that their approach overcame the sparsity problem, which decreases prediction accuracy when the transaction dataset is sparse. However, to the best of our knowledge, no study has identified items with higher novelty using random walks on the user graph.
Cross-domain Recommendation. Related to the stud-ies of novel item identification, a few recent works have tar-geted cross-domain recommendation[9, 13], i.e. the predic-tion of items that are located in the domains that the active user explicitly did not show an interest in before. Bin and his co-workers analyzed users who took similar rating be-haviors against items across several item domains[9]. Their method shares the knowledge that is learned by using the rating datasets from multiple item domains even when the users and items of these datasets do not overlap.
Nakatsuji et al. also proposed cross-domain recommen-dation based on the observation that users who share simi-lar items or who share social connections, can provide rec-ommendation chains (sequences of transitively associated edges) to items in other domains[13]. We consider, how-ever, that novel item identification within a domain is still important because users who access items in a domain have already expressed an interest in that domain. Thus, it is nat-ural to present novel items within the domain to expand the user X  X  interests, by analyzing user interests in detail using a domain-specific taxonomy.
Our method extends CF and uses RWR to identify items with high novelty.
CF methods can be classified into two approaches: memory-based CF and model-based CF. Memory-based CF assumes that each user belongs to a larger group of users with similar behavior. Indeed this method is referred to as user-oriented memory-based CF; an analogous method which builds item similarity groups using co-purchase history is known as item-oriented CF[18]. On the other hand, model-based CF gen-erates the predictions by using a model that is optimized against training data. Clustering[5, 22] and Bayesian net-work models are examples of the model-based approach[6, 23].

In computing user similarity, basic CF methods often use the Pearson correlation approach[17] or the cosine-based ap-proach[1].

If we define a as the active user, who is to receive the rec-ommendation, and M as the set of items rated by users a the average value of item ratings given by a , the Pearson cor-relation coefficient measures the similarity S ( a, u ) between a and u as indicated by equation (1). as zero in equation (1). The advantage of the Pearson cor-relation approach is that it takes into account that different users might have different rating schemes.

If we assume N is the set of users that are most similar to a , the predicted rating of a on item I i , p a,I i is obtained by the following equation (2).
A graph is a natural representation of data objects that have some inherent relational structure. In a graph, ob-jects and their relationships can be represented as nodes and weighted edges respectively, where weights denote the strength of a relationship. Measuring the relatedness of two nodes in the graph can be achieved by using RWR the-ory[10]. Starting from node a , a RWR is performed by fol-lowing a randomly selected link to another node at each step. Additionally, at every step there is a probability,  X  , that the walk restarts at a . Let p ( t ) be a column vector step t proceeds from node u . q is a column vector whose elements are set to zero; only the element corresponding to a is set to one, i.e. q ( a ) = 1. Also let A be the column-normalized adjacency matrix of the graph. In other words, A is the transition probability table where element A ( u, v ) gives the probability of v being the next node given that the current node is u . The stationary probabilities for each node can be obtained by recursively applying equation (3) until convergence; they give us the long-term visit rate of each node biased towards the starting node.
Therefore, p ( l ) a , where l is the status after convergence, can be considered as a measure of relatedness between nodes a and u .
In this section, we detail the proposed method. First, we define the problem. We then introduce our method; it models user interests and measures user similarity according to the taxonomy of items. Next, we show how novel item identification can be realized by performing RWR on the user similarity graph. Table 1 gives the main symbols used in this paper.
We first define the novelty of an item for the active user using the taxonomy of items. We consider that it presents, in an easy to understand manner, the relationship between the user X  X  present interests and the target item. Let the distance from class C i to C j over the taxonomy be dis ( C i ,C j ) and I i ( a ) be the item set in class C i that user a has rated. Then, our formal definition of the score of novelty N ( a, I j ) against It e ms
Figure 1: An explanation of the score of novelty. item I j in C j for user a , who has already has expressed interest in I i in C i , as follows; We assess the distance as the hops from class C i to class have novelty scores of two for a because there are two classes We define the problem tackled in the paper as follows: Problem (Recommending Highly Novel Items).

Given: A taxonomy of items and ratings of users against
Find: Highly novel items for the user, while guarantee-
Taxonomies are becoming more readily available; exam-ples include the taxonomies of music, movies, and game content generated by All Media Guide 1 and ListenJapan 2 . http://www.allmediaguide.com/ http://listen.jp/ Algorithm 1 Building user interests.
 Input: A taxonomy of items and ratings of users against Output: Interests of u . 1: //Measuring rating of u against each class C i . 2: for each class C i do 4: end for 5: //Reflecting ratings of subclasses to that of the super 6: for k =1to H  X  1 do 7: for each class C j in L ( H  X  k ) do 8: for each class C l in C j ( u ) do 10: end for 11: end for 12: end for Tabelog 3 has created a deep taxonomy for restaurants in Japan. We consider that modeling user interests according to these taxonomies is reasonable because content providers make significant efforts to optimize the granularity and branch-ing factors of classes so that their customers can readily ac-cess the items according to the customers X  interests. For example, the music taxonomy of ListenJapan has, on aver-age, four hierarchies and 432 classes to classify items, while the restaurant taxonomy of Tabelog has, on average, four hierarchies and 318 classes to classify items.

Our approach is based on the observation that users who are interested in some items are also interested in classes that include those items. Thus, we reflect the rating values of the items to that of the class that includes those items. In the same way, we reflect the rating values of the classes to the super class that includes those classes. The rating value for an item is implicitly assigned according to the frequency of a user X  X  access to the item, or explicitly assigned by the user.

The algorithm for building user interests is shown in Algo-rithm 1. We rate the class from the ratings of items in the puted as I i  X  X  i ( u ) r u,I i (line 3). For example in Fig.2, if user u assigns the rating value of 4.0 to I 31 and 4.5 to I 32 , the rating value of class C 3 for u is 8 . 5. The rating values of the super class are computed in the same way; a key point is that we use the rating to each class, instead of the rating to each item, and compute the rating values of the classes in the order of the depth of hierarchy level in the taxonomy (lines 6 -12). In Algorithm 1, integer H is the maximum value of hierarchy level of the taxonomy, and L ( k ) is a func-tion that returns class set in the k th hierarchy level in the taxonomy. Here, we set the root class in the first hierarchy level in the taxonomy.
Next, we explain the similarity measurement between users a and u according to the taxonomy of items. We first explain the approach of our method and then present an example. Please refer to Algorithm 2 also. In the approach described http://tabelog.com/: Tabelog is one of the most famous online restaurant guides in Japan. The word  X  X abe X  means  X  X ating X  in Japanese. Figure 2: Measuring similarity of user a and u .
 Algorithm 2 Measuring user similarity Input: Interests of users.
 Output: Similarity scores between a and u . 1: for each user u do 2: for each class C j in {C i ( a )  X  X  i ( u ) } do 3: compute S ( a, u, C j ); 4: end for 5: Compute similarity scores S C ( a, u ); 6: Compute similarity scores S I ( a, u ); 7: Normalize S C ( a, u ) and S I ( a, u ); 8: Compute S ( a, u )as S C ( a, u )+ S I ( a, u ); 9: end for below, we use C i ( u ) as the subclass set of class C i that user u rates.
The proposed method checks how many interests shared and not shared in each class in the taxonomy as well as offset the difference in the rating schemes of users. It is a natural approach and achieves high accuracy as demonstrated in our evaluation.
We explain our algorithm by using the example in Fig.2. is computed as min (0 . 0 , 8 . 5) = 0 . 0 (2) S C ( a, u ) is computed as (2 . 0 / 2) + 0 . 0=1 . 0. (3) Next, S I ( a, u ) is computed as by combining the two above similarity scores, S C ( a, u ) and S I ( a, u ). Algorithm 3 Predicting Items via Novelty Scores.
 Input: A taxonomy of items and similarity scores between Output: Prediction results with scores of novelty. 1: //Creating a column-normalized adjacency matrix A . 2: for each user u do 3: Sum ( u )=0; 4: for each user v do 5: Sum ( u )+ = S ( u, v ); 6: end for 7: A ( u, v )= S ( u, v ) /Sum ( u ); 8: end for 9: Perform RWR on the graph determined by A in finite 10: Compute prediction values of items for a by applying 11: // Compute scores of novelty for all identified items. 12: for each item I j predicted to a do 13: Compute N ( a, I j ); 14: end for
We now explain how to combine RWR and similarity mea-surement results to identify highly novel items for users. Please refer to Algorithm 3.

Our method first builds a user graph whose nodes are users; the weighted edges between node u and v correspond to the similarity score S ( u, v ), see the previous subsection. In other words, we use S ( u, v ) to build column-normalized adjacency matrix A in equation (3) by linearly scaling up each row of values such that the maximum of each row cor-responds to 1 and the minimum of each row corresponds to 0 (lines 1 -8).

Next, it executes RWR on the graph (line 9). By per-forming RWR on the graph, we obtain the probability that a walk from active user a will pass through user u on the graph; RWR, equation (3), is iterated until convergence is realized. Finally, we obtain the relatedness between active user node a and other users on the graph. In equation (3), as  X  is decreased, the walk passes through more neighbors that diverge more strongly from active user a . We discuss the effect of this parameter in our evaluations.

By using relatedness instead of similarity between users a and u , we compute the prediction values of items for user a using equation (2) (line 10). Since our method incorporates items possessed by users who are not similar to user a , but who are related to a on the graph, it can recommend items with high novelty to a ; this means that such users share less items or less classes with the active user.

Then, we assign a score of novelty to each identified item following equation (4) (lines 11 -14).
We now evaluate our method for investigating the accu-racy and item novelty yielded by our method.
Our experiment used the following datasets.
We used data from MovieLens 4 , an online movie recom-mendation system, to evaluate the performance of the pro-posed method. This data set contains 212,586 ratings of 943 anonymous MovieLens users on 1,682 movies. The av-erage number of ratings assigned to each item is 59.4. Many online content providers do not have such a lot of number of ratings assigned to each item. For example, the aver-age number of ratings assigned to each item is 4.64 in the dataset of Tabelog. The taxonomy of movie items is simple; it has only 19 genres as classes, and has only two hierar-chies; the root class,  X  X ovie X  and subclasses. This dataset is much more dense than the music datasets explained later. Different from the implicit ratings extracted from blogs, a low item rating indicates a negative interest in that item. Because the number of classes is only 19 and the users rate many items in this dataset, thus this dataset is unsuitable for evaluating novel item identification. However, we can use this dataset to evaluate the accuracy of our method, even if the taxonomy is very simple and item ratings are dense.
The evaluation also uses the MovieLens dataset with an extended taxonomy enriched by the metadata of movie items provided by an another movie information provider, goo movie 5 .
This dataset includes 48,695 implicit ratings of 3,545 users according to a taxonomy extracted in the experiment of
Available at http://www.grouplens.org/node/73 http://movie.goo.ne.jp/ Nakatsuji et al.[14] from the blog portal Doblog 6 and the taxonomy of non-Japanese music artists provided by Listen-Japan. The taxonomy contains 279 genres as classes and 21,214 artists as items 7 . Nakatsuji et al. created rating values for each item of a user by analyzing the descrip-tion frequency of each item among the user X  X  blog entries. The average number of ratings assigned to each item is 6.3. We linearly scaled up each rating value such that the maxi-mum user rating corresponded to 5 and the minimum corre-sponded to 1 following the range of ratings in the MovieLens dataset. The class hierarchy in this taxonomy is deep; it has, on average, four hierarchies, and sometimes has a fifth hier-archy under the root class  X  X usic X  with detailed end classes such as  X  X pace rock X  and  X  X cid jazz X . This represents de-tailed expert knowledge that can be used to measure the similarity of users accurately. The greatest value in the score of novelty is six. Such large scores are assigned to recom-mended items if the items are under  X  X lassic X  class and the active user is interested in the class under  X  X ock X  though he did not access  X  X lassic X  items before.
We also used 58,104 implicit ratings of 2,800 users ex-tracted from blog entries in Doblog using a Japanese taxon-omy provided by ListenJapan in the same way as Nakatsuji et al. did for the non-Japanese taxonomy. The Japanese taxonomy contains 153 genres as classes and 7,421 artists as items. The class hierarchy in this taxonomy is as deep as that in the non-Japanese taxonomy. The average number of ratings assigned to each item is 10.8.
We randomly divided dataset D into two datasets: train-ing dataset T and predicted dataset P . Thus, we could acquire users who had items whose classes are in P though they are not included in T . We then used T to measure the similarity between users, and created a user graph to measure the relatedness between users on the graph. We http://www.doblog.com/;Unfortunately, Doblog termi-nated services on May 2009.
The music taxonomies in our evaluation can be accessed via ListenJapan home page: http://listen.jp/ examined four ratios of T to D , T D : 0.1, 0.3, 0.5, and 0.7. When T D is small, the dataset of user ratings is sparse.
Following the standard evaluation methodology for CF, we predicted the user ratings only on the withheld ratings in T and computed Mean Absolute Error (MAE), which penalizes each miss by the distance to the actual rating. This measure is written below, where n is the number of entries in P , and P i and R i are the predicted and actual ratings of the i th entry, respectively.

We also check the prediction coverage, that is the ratio between the items that are predicted by the method and the items that are included in P [4]. The prediction coverage can be written as follows:
We investigate the prediction coverage according to the novelty score in detail. Note that the accuracy and item novelty are different metrics and must be measured and/or optimized separately.
We compared our similarity measurement method to the following similarity measures.
We first estimated the number of users, N , similar to the user, and determined the MAE. As a result, we set N to 40 against the music datasets and N to 30 against the movie dataset because MAE worsens if N is large.

Next, we evaluated the accuracy of our method by chang-ing the ratio of training data, T D and the restart parame-ter  X  . Results against the movie dataset, those against the non-Japanese music dataset, and those against the Japanese music dataset are shown in Table 2, Table 3, and Table 4, respectively. Here,  X  X on X  in each table indicates the results when RWR was not performed.

For the movie dataset, our method, T(J&amp;P) and T(J) , achieved better accuracy than the other methods when the dataset was sparse, however, method Pearson achieved higher accuracy than our methods when the dataset was not sparse. The movie dataset is much more dense than the music dataset, and the taxonomy of movie items is much simpler than that of the music dataset. When we use the music dataset, most of the results of our method, T(J&amp;P) and T(J) , are better than those of the other methods. Thus, we can understand that our methods work better when the dataset is sparse and the taxonomy is detailed. We will enrich the taxonomy of movie dataset by adding additional movie metadata such as actors and directors, and evaluate the movie dataset again in the section 5.6.

Interestingly, T(J&amp;P) achieved the highest accuracy against the non-Japanese music dataset. However, when we used the other datasets, T(J) tends to achieve higher accuracy. This is because the non-Japanese taxonomy is more detailed than the other taxonomies, and this situation well suits our as-sumption that users who like an item also like classes that include that item. Furthermore, when the dataset is not sparse, users tend to have many items in each class. In such situations, the end class of the taxonomy can be classified into more detailed classes, and T(J) works better because it checks how many instances shared and not shared by users in each class in the taxonomy. For example, T(J) considers that the interest of a and that of a user who likes items, similar users who like items I 21 and I 22 , from users who like items I 21 , I 22 , and I 23 .

We also investigated the impact of restart parameter  X  , and found that most results are improved if we decrease  X  to a certain point. In particular, when we used not so dense datasets such as the music datasets, the prediction accuracy is often improved if we decrease  X  . When the data is sparse, the user profile is not so well constructed, and thus similarity measurements do not perform so well. In such a case, the Table 5: Prediction coverage versus item novelty against non-Japanese music dataset.
 Table 6: Prediction coverage versus item novelty against Japanese music dataset.
 accuracy is improved by incorporating the items accessed by users who are related to the active user a on the graph though the similarity between a and each of those users is small.

From above results, we consider that our method can iden-tify items accurately when the taxonomy is constructed in detail and the rating dataset is sparser.
We also investigated the prediction coverage of the meth-ods according to the novelty of items and parameter  X  .Ta-ble 5 and Table 6 show the results for the non-Japanese mu-sic dataset with T D = 0.7 and those for the Japanese music dataset with T D = 0.7, respectively.

Those results show that our methods (even without RWR) have better prediction coverage than the other methods be-cause they can measure the similarity of users even if they do not share the same items. However, when RWR is not performed, the results indicate that the items with higher novelty are difficult to identify because users who are very similar to each other tend to share items with low novelty.
We next show what happens when  X  is reduced. We found that our taxonomy-based methods offer high prediction cov-Figure 3: Example of extended taxonomy of Movie-Lens items.
 Table 7: MAE against movie dataset with extended taxonomy.
 erage against items with higher novelty. Furthermore, as we demonstrated above, the accuracy does not fall significantly if we decrease parameter  X  .

From those results, we consider that our methods can identify items with higher novelty and more accurately than any other methods. Typical recommendations based on pre-vious CF methods present types of items that are similar to those the active user highly rated. Our graph-based method allows the active user to discover items that are located in the class he did not know well through the items accessed by the users who are not directly similar to the active user.
As the reader can naturally imagine, those results also suggest that our method increases the diversity of the rec-ommendation results. We, however, consider that our score of novelty is superior to the notion of diversity. The score of novelty gives the semantic relationships between the present interests of the active user and the item recommended to him. For example, by altering the desired minimum novelty score, the user can winnow the recommendation results to increase user satisfaction.
We extended the MovieLens item taxonomy by matching items in the MovieLens dataset with those provided by one of the Japanese movie information provider, goo movie. This was done by checking the title name of items. If the name of a MovieLens item matched the name of an item provided in goo movie, we extended the item taxonomy by creating classes that have the properties of genres attached by Movie-Lens and those of metadata attached by goo movie such as release date, actors, directors, writer, and musician. Fig. 3 presents an example. The item  X  X he Godfather X  is originally classified in  X  X ction X  class in the MovieLens dataset. We ex-tend it by using the metadata provided by goo movie, and create a new class  X  X ction (1970-79) X  and we also create a class  X  X rancis Ford Coppola X  under the class  X  X ction (1970-79) X . Then, we classified  X  X he Godfather X  to  X  X rancis Ford Coppola X . This yields automatic enrichment of the taxon-omy in the MovieLens Dataset. As a result, we acquired a taxonomy with 8,889 classes and 922 items. The number of items is less than the original dataset because some items had no match in the goo movie item name set. The num-ber of users, 943, was the same as the original MovieLens dataset.

Next, we evaluated the accuracy of our method by using the MovieLens dataset with extended taxonomy. Results are shown in Table 7. The extension allowed our method to achieve higher accuracy than all compared methods. Thus, we conclude that deeper taxonomies are good for predicting user interests. Note that the results are not so good as the results using the original taxonomy shown in Table 2. This is because there are fewer items to be learned which decreases accuracy.
For completeness, we evaluated our method by applying it to restaurant ratings.

We used a dataset from Tabelog to evaluate the perfor-mance of the proposed method. We focused on restaurants in Tokyo among all restaurants known to Tabelog. The tested dataset contained 401,584 ratings of 7,403 anonymous Tabelog users on 133,432 restaurants. The average number of ratings assigned to each item was 4.64. The taxonomy of Tabelog is quite deep; it has 318 genres as classes, and has three or four hierarchy levels. For example, the end classes of this taxonomy have genres such as  X  X ine bar X  and  X  X eer garden X . The maximum user rating was 5 and the minimum rating was 0. Like the MovieLens dataset, a low item rating indicates a negative interest in that item.

The taxonomy of Tabelog is quite deep, so we apply our method of T(J&amp;P) to this dataset according to the results discussed in section 5.4. We also apply our method to this dataset while changing the ratio of T to D , T D = 0.5 and 0.7, i.e. the dataset is not sparse.

We first estimated the number of users, N , similar to the user, and determined the MAE. As a result, we set N to 40 against this dataset.

Results against MAE are shown in Table 8. Our method achieves the highest accuracy among all compared methods. We also investigated the prediction coverage of the methods according to the novelty of items and parameter  X  . Table 9 shows the results with T D = 0.7. They show that our meth-ods have better prediction coverage than the other meth-ods even if RWR is not used. Furthermore, we found that our taxonomy-based methods offer high prediction coverage against items with higher novelty when parameter  X  is low.
It is clear from the above that our method can be well applied to item domains other than movies and music. Table 9: Prediction coverage versus item novelty against restaurant dataset.

This paper introduced a method that can identify, for the active user, items with high novelty. To measure the sim-ilarity of users, our method uses items rated by users as well as the taxonomy of items. It then builds a user graph whose nodes are users, and sets weighted edges between user nodes according to the similarity of users. It performs Ran-dom Walk with Restarts over the graph, and extracts users who are not similar to the active user but whose nodes are arrived at frequently. By incorporating the items accessed by those extracted users, our method identifies items with high novelty for the active user. Evaluations show that our method can identify items with higher novelty and more accurately than existing methods. The time spent in per-forming RWR on the graph is one problem in identifying items with high novelty, however a fast RWR computation technique was proposed by Tong et al.[21]. The definition of novelty given here may be too rigid and better performance might be achieved by allowing items in classes the user has accessed before (but very infrequently) to be recommended to the user as being novel. [1] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [2] F. Fouss, A. Pirotte, J. michel Renders, and [3] M. Gori and A. Pucci. Itemrank: A random-walk [4] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and [5] A. Kohrs and B. Merialdo. Clustering for collaborative [6] I. Konstas, V. Stathopoulos, and J. M. Jose. On social [7] Y. Koren. Collaborative filtering with temporal [8] Y. Koren, R. Bell, and C. Volinsky. Matrix [9] B. Li, Q. Yang, and X. Xue. Transfer learning for [10] L. Lovazs. Random Walks on Graphs: A Survey , [11] C. D. Manning and H. Schtze. Foundations of [12] S. M. McNee, J. Riedl, and J. A. Konstan. Being [13] M. Nakatsuji, Y. Fujiwara, A. Tanaka, T. Uchiyama, [14] M. Nakatsuji, M. Yoshida, and T. Ishida. Detecting [15] K. Onuma, H. Tong, and C. Faloutsos. Tangent: a [16] A. M. Rashid, I. Albert, D. Cosley, S. K. Lam, S. M. [17] P. Resnick, N. Iacovou, M. Suchak, P. Bergstorm, and [18] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [19] V. Schickel-Zuber and B. Faltings. Inferring user X  X  [20] V. Schickel-Zuber and B. Faltings. Oss: A semantic [21] H. Tong, C. Faloutsos, and J.-Y. Pan. Fast random [22] L. Ungar and D. Foster. Clustering methods for [23] H. Yildirim and M. S. Krishnamoorthy. A random [24] C. N. Ziegler, G. Lausen, and L. S. Thieme.
 [25] C. N. Ziegler and S. M. McNee. Improving
