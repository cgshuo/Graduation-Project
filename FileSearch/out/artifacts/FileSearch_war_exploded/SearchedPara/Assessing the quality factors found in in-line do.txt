 1. Introduction  X  incorporating multiple software repositories [3].
 2. Background documentation on software maintenance. 2.1. Source code comments and their impact on software maintenance in-line documentation currently available is through performing time-consuming manual code checks. 2.2. In-line documentation and Javadoc between the source code and documentation, a specific documentation or programming syntax has to be used. used.
 documentation in Fig. 2 . 2.3. How to write Javadoc comments documentation into a variety of output formats, such as HTML, L comments that influence the format of the documentation produced or the way documentation pages are linked. bodies), enabling the comment within the stub to explain what future plans hold for the created identifiers. the tool is being used effectively. 2 These specifications include details such as:  X 
Class/interface/field descriptions can omit the subject and simply state the object.  X 
Method descriptions need to begin with verb phrases.  X 
Use third person, declarative, rather than second person, prescriptive.  X 
Do not include any abbreviations when writing source code comments. 3. NLP corpus generation from source code representation format suitable for automated NLP analysis. 3.1. Javadoc Doclets as a result of the static source code analysis.
 limited to pre-defined tags such as b p&gt; or b head&gt; structure that encloses information using the pre-defined tags, such as is possible by developing a custom Doclet that uses the Javadoc library. 3.2. Marking up source code able to model both the syntactic and semantic information found in Java source code, such as:  X  parent/child relationships between generalized and specialized classes;  X  the package an interface or abstract class belongs to;  X  fields, constructors and methods of a class;  X  the types, modifiers (private, public, protected), and constant values of the fields; and  X  the return types, parameter list, and thrown exceptions of a method.
ArgoUML [13]. Fig. 4 shows how our Doclet represents the information found in the abstract class using the b parameter list of the  X  intialiseListener  X  method are modeled using the XML tag to the standard HTML output. For example, we now also know that the parent of the that the  X  listener  X  parameter of the  X  intialiseListener 3.3. Marking up source code comments line tag. Fig. 4 shows how the Javadoc comments are marked up using the using the Class_Comment and Author XML tags.
 modeled. We eliminated the XML elements and attributes for readability purposes. interpreted as features of the annotation. 4. Improving software quality through automatic comment analysis: The JavadocMiner of giving users recommendations on how a Javadoc comment may be improved based on the source code segments. A summary of all heuristics is presented in Table 1 . 4.1. Internal (NL quality) comment analysis 4.1.1. Token, noun and verb count heuristic (TNVC) assessments, such as SPW and PWS, in order to detect the writing style of a comment. 4.1.2. Words per Javadoc comment heuristic (WPJC) by the total number of Javadoc comments within a class.
 4.1.3. Abbreviation count heuristic (ABB) annotated using features specifying that the string is an abbreviation. 4.1.4. Readability heuristics (FOG/FLESCH/KINCAID) A number of formulas were implemented that analyze the readability of text [14], for example: understand a block of text. It is defined as: where: ASL Average sentence length using number of words.
 HW Number of words with more than two syllables.
 range from 60 to 70. 4 It is defined as: where: ASL Average sentence length using number of words.

ASW Average number of syllables per word. level.
 Where: ASL Average sentence length using number of words.
 ASW Average number of syllables per word.
 and IRS (Internal Revenue Service), to analyze the readability of their documents [5]. 4.1.5. Second person writing style heuristic (SPW) where a present participle verb is followed by a determiner and finally a proper noun (e.g., are found, we compare the stem of the verb (e.g.,  X  get  X  n-gram. 4.1.6. Passive writing style heuristic (PWS) comment can be improved by identifying the passive verb group.
 4.2. Code/comment consistency analysis
The following heuristics analyze in-line documentation in relation to the source code being documented. 4.2.1. Documentable item ratio heuristic (DIR)  X  parseAssociationEnd method that is completely documented using the in-line tags. were: 4.2.2. Any Javadoc comment heuristic (ANYJ) metric [5].
 bug). 4.2.3. SYNC heuristics (RSYNC/PSYNC/ESYNC) longer valid  X  for example, due to changes in the code not being reflected in the documentation. 4.2.3.1. RSYNC. The return type of a method is documented using the the comment and the actual return type of the method. 4.2.3.2. PSYNC. When documenting the parameter list of a method, the indicated in the comment and the parameter name as it appears in the parameter list. 4.2.3.3. ESYNC. Documenting exceptions thrown by a method is done using the method.
 to RSYNC, PSYNC, and ESYNC because: (i) the parameter comment begins with the value return comment begins with the possible value being returned ( throws an exception that is not documented. 4.2.4. Added readability value heuristic (ARV) an n-gram comparison between the identifier (e.g.,  X  getsTheLabel the identifier name using regular expressions designed to process the Java naming convention [15] for a If the strings are an exact match then the JavadocMiner informs the user on the bad quality of the comment. does not add any readability value.
 extracted and what each heuristic returns as result of the analysis. 4.3. An ontology for source code comments subsequently be queried or linked with other knowledge sources [3].
 representation, ontologies provide a non-proprietary common language with open world assumption capabilities.
Racer [19], Pellet [20], or FaCT++ [21]. 4.3.1. Ontology design of the major concepts modeled in our Javadoc ontology.
 relationships found in the NLP ontology.

Not included in Tables 2 and 3 are the inverse properties, such as create additional inferences, providing additional ways of querying the ontology. for further queries on the results of the JavadocMiner. 4.3.2. Ontology population Hence, we need to automatically populate [23] the ontology based on the results of the NLP analysis. are exported to the Javadoc and NLP ontologies as OWL instances and relationships, as shown in Fig. 14 . 5. Implementation 5.1. Overall system architecture discussion of the GATE framework and its different components can be found in [24]. read by subsequent components. 5.2. The JavadocMiner NLP application pipeline.
 resources provided by GATE [24] and in green are the PRs implemented by us. 5.2.1. Preprocessing stage splitting, and part-of-speech (POS) tagging [24]. 5.2.2. JavadocMiner PR consistency analysis on Javadoc comments, such as SYNC and SPW .
 using the SSL Doclet. The heuristic starts by examining entities from the  X 
Parameter_Comment  X  is associated with a specific  X  Parameter assigns a value of  X  TRUE  X  to  X  PARAMSYNC  X  ; otherwise, comment consistency of return comments and exceptions.
 method items vs. the items that have actually been documented ( DIR metric). 5.2.3. ReadabilityMetrics PR a document needs to be measured. The ReadabilityMetrics PR makes use of an existing library the PWS heuristic.
 a suggestion for improvement is generated. 5.2.4. OwlExporter PR and relations of an existing NLP and domain-specific ontology on the other hand. shows an excerpt of a populated Javadoc ontology. 5.3. End-user interfaces further cross-linking with other software artifacts [3]. 5.3.1. The Semantic Assistants Eclipse plug-in requests to a Semantic Assistants [26] server ( Fig. 20 ).
 form of annotations.
 code editor, in exactly the same way as he works with source code errors and warnings. 5.3.2. Ontology application authors that created the Javadoc documentation for the class.
 with other software knowledge repositories, including versioning systems and bug databases [3]. 6. Evaluation quality of source code. 6.1. Data releases of theUML modelingtool ArgoUML 6 and theIDE Eclipse. 6.2. Experiments systems to determine the varying degrees of correlation between the individual heuristics and bug defects. 6.3. Results and analysis indicated the Low Level Module as being the most thoroughly documented module.  X 
Gets the ToolTipModule object  X  would yield a Kincaid reading grade level of 13, where bottom right). 6.3.1. Quality analysis framework that is extended using plug-ins that use the services provided by the PDE API module. modules ( Fig. 23 , top right).
 6.3.2. Comment  X  bug correlation how closely each metric correlated with the number of reported bug defects, we applied the Pearson product and therefore a difference in the degree of correlation between the two metrics is possible. metric, which we previously determined as being the least correlated. 7. Related work 7.1. Corpus generation from source code XML-Doclet , 8 Mavens XMLDoclet , 9 or the jeldoclet . 10
A Doclet that generates a schema that closely resembles the SSLDoclet is the Fig. 4 .
 as a corpus. None of the existing Doclets that we examined were capable of doing so. For example, since the negative impact on the amount of work needed by the language engineers to make use of the generated corpus. processing, which is an application scenario not targeted by existing efforts. 7.2. Quality analysis of in-line documentation source code they were explaining.
 major correlations made with other software engineering artifacts.
 7.3. Code/comment consistency analysis on four large open source software projects: Linux, Mozilla, Wine and Apache, and detected 60 comment new bugs and 27 bad comments.
 analyzer  X  used to estimate the length of software was implemented in [31]. The analyzer applies  X  to observe the evolution of a single software project, the
Name, Parameter Name and Comment Vocabularies. The work uses a combination of existing tools like identifiers introducing new terms, and finally what do the most frequent terms refer to. stakeholders, such as managers and conformance testers. 8. Conclusions and future work comments.
 Acknowledgments thank Bahar Sateli for implementing the Semantic Assistants Eclipse plug-in.
References
