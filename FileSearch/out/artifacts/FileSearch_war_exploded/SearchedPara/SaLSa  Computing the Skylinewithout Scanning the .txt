 Skyline queries compute the set of Pareto-optimal tuples in a relation, i.e., those tuples that are not dominated by any other tuple in the same relation. Although several algo-rithms have been proposed for efficiently evaluating skyline queries, they either require to extend the relational server with specialized access methods (which is not always fea-sible) or have to perform the dominance tests on all the tuples in order to determine the result. In this paper we introduce SaLSa ( Sort and Limit Skyline algorithm ), which exploits the sorting machinery of a relational engine to order tuples so that only a subset of them needs to be examined for computing the skyline result. This makes SaLSa particu-larly attractive when skyline queries are executed on top of systems that do not understand skyline semantics or when the skyline logic runs on clients with limited power and/or bandwidth.
 H.2.4 [ Database Management Systems ]: Query process-ing Algorithms, Performance Skyline, Monotone functions, Client/Server architecture
The skyline of a relation r is the set of Pareto-optimal, or undominated , tuples in r . According to the Pareto principle, a tuple p dominates another tuple p i if p is at least as good as p i on all the skyline attributes and strictly better than p on at least one attribute. This work is partially supported by the MIUR PRIN Project WISDOM (Web Intelligent Search based on DO-Main ontologies).
 Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00. Example 1 Consider the relation Hotels(Name ,Price,Rat-ing, Location) and the instance: A skyline query over the attributes Price (to be minimized), Rating (to be maximized), and Location, for which the most preferred value is  X  X ea X  whereas  X  X ity X  is the worst, will re-turn hotels Jolly, Rome, and Holiday, since Jolly dominates Continental (better price, same rating, better location) and both Rome and Holiday dominate Excelsior and Capri. Us-ing Preference SQL [11], this query can be expressed as: SELECT * FROM Hotels PREFERRING LOWEST(Price) AND HIGHEST(Rating) AND Location= X  X ea X  ELSE Location&lt;&gt; X  X ity X  Skyline queries are a specific, yet relevant, example of pref-erence queries [6, 10], and have been recognized as a useful and practical way to make database systems more flexible in supporting user requirements [5]. Consequently, there has been a growing interest in algorithms for efficiently evalu-ating skyline queries on large databases [4, 8, 13, 9]. With respect to such works, which concentrate on how to imple-menttheskylineoperator within a database system, in this paper we take a slightly different perspective on the prob-lem, by addressing the following important issue: how can skyline queries be efficiently computed if the underlying data server has no knowledge at all of the skyline logic? In other terms, how can an application, running on top of a standard database system, evaluate a skyline query? Note that this is precisely the problem that one has to face when using any currently available commercial database system. The same is true if one wants to provide skyline functionality on top of a web-accessible data source.

In scenarios like these the only currently available alter-native is to run a skyline algorithm on the client side, and compute the result by requesting to the underlying data source all the data in the target relation. For instance, computing the skyline query in Example 1 would require the client to fetch from the server holding the Hotels rela-tion all its (presumably many) hotels. It should be observed that, no matter how smart the skyline algorithm is designed, this strategy will pay an excessive communication overhead, which might nullify any effort spent in the implementation of the skyline algorithm. This is particularly true for clients with a limited bandwidth connection, as the following ex-ample illustrates.
 Example 2 Consider a skyline query issued by a wireless client (e.g., a PDA) on a 802.11b network. If the relation has 20,000 tuples, each of 100 bytes, and the effective data transfer rate between the client and the server is 1 Mbps (1 Megabits per second), 1 then shipping all the tuples to the client will require about 15 seconds. On the other hand, state-of-the-art algorithms can compute a 6-dimensional sky-line on such relation in less than 1 second, i.e., 1 order of magnitude faster (see also our experiments in Section 5). Motivated by above observations, in this paper we introduce a novel algorithm, called SaLSa ( Sort and Limit Skyline al-gorithm ). SaLSa takes from the SFS ( Sort Filter Skyline ) algorithm by Chomicki et al. [8] the idea of pre-sorting the input relation before running the filter step in which domi-nance tests are executed. Thus, both SFS and SaLSa need to perform a topological sort of the input data, and as such both can progressively return undominated tuples as soon as they discover them. However, while for SFS a  X  X ood X  sorting function is one that puts in the first positions those tuples that are likely to dominate many other tuples, thus leading to reduce the number of dominance tests, sorting data in SaLSa is mainly used as a means to stop fetching tuples from the input stream, thus effectively limiting the number of tuples to be read. In other terms, SaLSa relies on sorting functions that can guarantee that all tuples be-yond a certain point in the input stream are dominated by some already seen tuple. As an example, SaLSa is able to determine the 10 tuples of a 3-dimensional skyline over the NBA dataset by reading only 3783 tuples out of 17791, thus saving 79% of the transfer cost (see Section 5 for description of datasets and details on experiments). With numbers as in Example 2, this would save about 11 seconds of transfer time.

The rest of the paper is organized as follows. In Section 2 we review the semantics of a skyline query and algorithms for its evaluation. Section 3 introduces the SaLSa algorithm. Section 4 provides details on some implementation issues. Section 5 presents experimental results on both real and synthetic datasets, and Section 6 concludes.
This section briefly reviews the definition of skyline and existing algorithms for its evaluation.

Let R ( A 1 ,...,A d ) be a relation schema, and let dom ( A be the domain of attribute A j . Further, let D = dom ( A ...  X  dom ( A d ). Let r be a relation over R , i.e., a set of tuples, or d -dimensional points ,from D . In the following, the terms tuple and point will be used interchangeably.
The skyline of r , S = S ( r ), is the subset of points in r that are Pareto-optimal. 2 Apoint p is Pareto-optimal, or
The nominal 802.11b bandwidth is 11Mbps, but this as-sumes no traffic at all in the network. An effective 1Mbps transfer rate is a realistic estimate for the case of moderate traffic.
For simplicity we consider that all attributes are involved in the skyline. Generalization to the case where R also includes non-skyline attributes is immediate. undominated , iff there is no other point p i  X  r that is not worse than p on all attributes (or coordinates )andstrictly better than p on at least one attribute. Assuming without loss of generality that on each attribute higher values are better, and writing p p i to mean that p dominates p i ,we have: where: and p [ j ]  X  p.A j is the value of p for attribute A j .Ex-tending the definition to the case of categorical attributes (e.g., Location) is an easy task, which will be discussed in Section 4.

Computing the skyline is equivalent to determine the max-ima of a set of vectors, a well-known problem in computa-tional geometry [14]. However, algorithms developed in that field cannot be directly applied in a database scenario, since they do not take into account main memory limitations. This was observed in [4], where a divide and conquer al-gorithm, D&amp;C , suitable for external memory was proposed. However, a recent analysis [9] shows that the average perfor-mance of D&amp;C deteriorates with increasing skyline dimen-sionality, d . In [4] another algorithm, called Block Nested Loops ( BNL ), is proposed. BNL allocates in main memory a window W , and sequentially scans the input relation. When apoint p is read, it is compared to points in W .If p is dom-inated by a point in W ,then p is discarded, otherwise p is inserted in W .If p dominates some points in W ,theseare removed from W . In case the window saturates, a tempo-rary file is used to store poin ts that cannot be placed in W . This file is used as the input to the next pass. Eventually the algorithm terminates, since at the end of each pass the size of the temporary file can only decrease.
 The SFS ( Sort Filter Skyline ) algorithm [8] improves over BNL by first sorting the input data according to decreasing values of a monotone function F . This guarantees that if F ( p )  X F ( p i ), then p i will not dominate p , written p In other terms, using a monotone function corresponds to perform a topological sort with respect to the Pareto dom-inance criterion. Similarly to BNL , SFS keeps in W the undominated points seen so far. However, the monotonicity of
F now guarantees that in the filter phase a new point p i will never dominate an already seen point p , thus a point will never be dropped from the window. This leads to three ma-jor improvements with respect to BNL : 1) the management of W largely simplifies, 2) points in the skyline can be pro-gressively returned without having to wait for all the input to be read, and 3) the number of passes of the filter phase is optimal, i.e., |S| / | W | . From the last observation it fol-lows that, even for moderately large skylines, SFS will likely complete in a single pass. Experimental results in [8] indeed show that SFS runs (much) faster than BNL ,andthatitex-ecutes less dominance tests. In particular, this is achieved by sorting data using their  X  X olume X  or, equivalently, their  X  X ntropy X  (see Section 3.1.2 for details).

LESS [9] is a recent improvement of SFS that integrates in the first step of a standard external sort-merge algorithm an elimination-filter window, so as to earlier discarding some dominated tuples. Further, LESS combines the last merge pass of the sorting algorithm with the first skyline-filter pass. Although results in [9] show that LESS consistently outper-forms SFS , LESS would not be applicable in scenarios in which one has no direct control on the data server (thus on the algorithm used to sort tuples). For the same reason, al-gorithms like NN [12] and BBS [13] that rely on the existence of specific access structures are not relevant here.
Even if not directly fitting the scenario considered in this paper, it is worth mentioning skyline algorithms based on a distributed access model [1, 3, 2]. Such algorithms work by querying d independent subsystems, each managing a specific skyline attribute and returning objects ordered ac-cording to the preference on that attribute (e.g., minimize the price). By iterating on the streams of incoming results, the skyline can be computed by just looking at those objects that are returned by at least one subsystem before a single object p is returned by all subsystems. To perform all the necessary dominance tests, thus to eventually determine the actual skyline, missing attribute values for all candidate ob-jects are then obtained through a series of random accesses , each having as input the object identifier for which attribute values are sought.

Although distributed skyline algorithms can indeed limit the number of tuples to be transmitted from a server to a client, applying them in a scenario where all skyline at-tributes are managed by a single server would unnecessarily incur a high overhead. First, the client should issue d inde-pendent sub-queries, for each of which the server should per-form a distinct sort of the input relation. Further, the client should waste resources to join the results arriving from the sub-queries. Finally, many other queries would be needed for performing the random accesses, i.e., to retrieve missing attribute values.

Considering all the above, and reminding that only algo-rithms that can be run on top of standard database systems are of interest in our scenario, it is evident that the best currently available alternative is indeed SFS . The algorithm we introduce, called SaLSa (for Sort and Limit Skyline algorithm ), builds on the basic idea that, if the input relation r is sorted according to a suitably chosen monotone function, then it is possible to determine the sky-line of r without applying the skyline filter to all the points . In general, this might drastically reduce the number of tu-ples to be read and, depending on the specific instance and sorting function, it might reduce the number of dominance tests as well. Since SaLSa shares with SFS the idea of pre-sorting the input relation, it also keeps all the SFS strengths: simplified management of the window, incremental delivery of results, and optimal number of passes of the filter phase.
We illustrate how SaLSa works when a single pass is suf-ficient to complete the evaluation. Extension to the case where skyline size exceeds the available main memory is managed as in SFS , and not reported here for brevity. SaLSa starts by initializing to r the set U of unread tuples . It also makes use of a stop point , p stop , which is used to ear-lier terminate reading tuples. Step 2 sorts U according to decreasing values of a monotone function F . Thisisactu-ally done by issuing the following standard, i.e., non-skyline, SQL query to the server: SELECT * FROM R ORDER BY F DESC
Each time a new point p is read from U , p is compared against the current skyline S . If none of the points in dominates p (i.e., S p ), p is inserted into S .Thismight possibly trigger the update of the stop point (step 5). At step 6 SaLSa checks if it has gained sufficient evidence to conclude that no further point in U can be part of the sky-line, i.e., all points in U are dominated by p stop ( p stop If this is so, the algorithm terminates.
 Algorithm 1 SaLSa 1: S X  X  X  , U X  r , stop  X  false , p stop  X  undefined 2: sort U according to F 3: while not stop  X U =  X  do 4: p  X  get next point from U , U X  X \{ p } 5: if S p then S X  X  X  X  p } ,update p stop 6: if p stop U then stop  X  true 7: return S
Two key factors ultimately d etermine the actual perfor-mance of SaLSa : the choice of the sorting function, which might severely influence the number of tuples to be read, and the strategy for choosing the stop point. Before analyzing both issues, we introduce some basic terminology.

Assume that during the execution of SaLSa the last point p read so far has value F ( p )= l .Wesaythat F is at level l after reading p , and denote with l ( F ,r ) the level at which SaLSa eventually halts, also called the stop level of F on r . Similarly, U ( F ,r ) denotes the value of U when the algorithm terminates.

When F is at level l , F ( p i )  X  l holds for each p i  X  X  safely stop the execution one should guarantee that p stop p for all unread points. This is done in SaLSa by considering the unread domain at level l , defined as: Therefore, when F is at level l it is U X  X  ( F ,l ). Note that D ( F ,l ), unlike U , does not depend on the specific relation r . Then, SaLSa can safely stop fetching tuples iff the following is true: The subset of the D domain that SaLSa has not explored when it halts is denoted D ( F ,r )  X D ( F ,l ( F ,r )). In principle, any monotone function can be used within SaLSa . However, it is useless to use a function F if F is not able to limit the tuples to be read. More precisely, we say that F limits a relation r when U ( F ,r ) =  X  and that F limiting if there exists at least a relation r for which U is not empty. Note that this is the same as saying that D (
F ,r ) is not always empty. Thus, only limiting sorting functions are worth considering for SaLSa .
It is not clear how one could analyze the whole space of limiting functions by looking for the  X  X est X  one to use. For instance, let d = 4, and functions F 1 = A 1  X  ( A 2 + A 3 and F 2 =( A 1 + A 2 )  X  ln A 3 + A 4 .Is F 1 better than Are they limiting? Can we provide an effective method to check if p stop D ( F i ,l )when F i is at level l ? Can the stop point be efficiently updated? Is there any principled reason why the attributes should be assigned different roles (e.g., A 1 and A 4 in F 1 )?
Being this the first work that addresses the problem of using a sorting function to limit the number of tuples to be read, we feel it is important to focus the attention on a well-defined class of functions, which exhibit a key property of symmetry .
 Definition 1 Afunction F on d variables is symmetric iff it is invariant under any permutation of the variables. Intuitively, a symmetric function F does not privilege any attribute over the others, i.e., all the attributes play the same role. This seems to be a ve ry natural requirements if one uses F for computing the skyline, since by definition all skyline attributes are equally important.
 In the following we will only consider symmetric functions. Further, in order to avoid unnecessary complications, we will consider that all attribute values are normalized in the [0 , 1] range, i.e.,  X  j : dom ( A j )=[0 , 1]. Section 3.2 briefly touches on the case of asymmetric functions, and Section 4 describes how relations with arbitrary domains can be dealt with.
A key factor affecting the performance of SaLSa is the choice of the stop point, p stop . Clearly, a good stop point should maximize the chance of stopping earlier the execu-tion. Although one might suspect that the choice of the stop point depends on the specific function used to sort the points, rather surprisingly this is not the case for symmetric functions. We first need the following result about symmet-ric monotone functions.
 Lemma 1 Let F be a symmetric monotone function and assume F is at level l . Further, let M be the maximum value such that l = F ( M, 0 , 0 ,..., 0) and assume M is finite. Then, there is no point p for which both the following hold: 1) F ( p )  X  l ,and2)  X  j : p [ j ] &gt;M .
 Proof. Assume that both 1) and 2) hold. Since F is sym-metric it is possible to arbitrarily choose the attribute A which p [ j ] &gt;M . Then, let j = 1. Consider the point p = ( p [1] , 0 , 0 ,..., 0), i.e., p [1] = p [1] and  X  j =1: p [ j ] Then, by monotonicity of F ,itis F ( p )  X F ( p )  X  l .This contradicts the hypothesis that M is the maximum value for which l = F ( M, 0 , 0 ,..., 0) holds.
 Theorem 1 Let F be any symmetric monotone function, and let S be the current set of skyline points. For each point p  X  X  ,let p i =min j { p i [ j ] } . The strategy that chooses the stop point according to the following MaxiMin rule: with ties that can be arbitrarily broken, is optimal, i.e., there is no other rule that on any relation can do better than the MaxiMin rule.
 Proof. Consider a rule that eventually chooses as stop point p bad  X  X  such that p bad &lt;p stop ,where p stop is as in Equa-tion 5. To prove the theorem we need to show that: 1) whenever SaLSa halts due to p bad , then so it does due to p stop , and 2) there exists at least a relation r for which using p stop can be stopped before than if using p bad . 1) Let p i be any point in the region, denoted as D ( F ,r )[ p 2) Immediate.
 The definition given by Equation 5 provide an efficient, O (1), method for incrementally updating the stop point. Let p stop be the current stop point. When a new point p is added to the skyline, the stop point either remains unchanged or it is set to p . This only depends on which among p and p stop maximum.
 Example 3 Suppose the current skyline S consists of points p are used in Example 4); then, it is p 1 =0 . 4 ,p 3 =0 . 3 ,p 0 . 05 ,thus p stop = p 1 .Ifpoint p 2 =( . 55 ,. 5) is added to then p 2 becomes the new stop point, since it is p 2 =0 . 5 &gt; 0 . 4= p 1 .
 Lemma 1 also provides an effective way to determine when SaLSa can be stopped.
 Theorem 2 Let p stop be the current stop point. Let F be any symmetric monotone function, and assume F is at level l . Further, let M be the maximum value such that l = F ( M, 0 , 0 ,..., 0) . If no such finite M exists, then set M =  X  .If M  X  p stop then SaLSa can be stopped. Strict inequal-ity is required only in the particular case that  X  j : p stop p Proof. From Lemma 1 we know that no point p such that F ( p )  X  l has an attribute value greater than M .Thisis sufficient to conclude that p is dominated by p stop .
Although Theorem 1 shows that the stop point can be cho-sen independently of the sorting function, this does not mean that all sorting functions will behave equally well. In the fol-lowing we consider some relevant cases of sorting functions, and argument about their applicability. To avoid making the problem trivial to solve, we exclude from the analysis those (unrealistic) instances that include the  X  X deal X  point 1 =(1 ,..., 1), and consider only skylines over at least 2 dimensions, i.e., d  X  2.
The first symmetric monotone function we consider is the one based on the  X  X olume X  of the points, as originally pro-posed by the authors of SFS in [7]: We will shortly explain why we denote the function as vol rather than simply as vol . The rationale of using vol which also justifies its name, is that if points are uniformly distributed over D ,then vol [0]( p ) is the volume of the region dominated by p . Then, fetching first points with higher volume increases the chance of early discarding many other points, thus reducing the overall number of comparisons. Since SFS is not concerned with the problem of limiting the number of points to be read, no analysis on the effectiveness of using vol [0] for this purpose was given in [7] and [8]. Observation 1 The vol [0] sorting function is not limiting. Intuitively, vol [0] is not limiting since, for any level l , includes points that are maximal on one or more attributes. Without loss of generality assume d =2. Let p 1 =(1 ,p 1 [2]) and p 2 =( p 2 [1] , 1). For any value of the current vol it is possible to choose values for p 1 [2] and p 2 [1] such that both p 1 and p 2 are in U . Then, the only point that can dominate both is the ideal point 1 . The arguments can be easily generalized to an arbitrary number of attributes d by considering d points, each one maximal on a different attribute.

Technically, to make the volume function limiting one has to exclude the 0 value from the domain. To this end, con-sider the function vol [1]( p )= d j =1 ( p [ j ]+1). 3 If we have, say, a 2-dimensional skyline, now there is a chance of halting SaLSa execution as soon as the level of vol [1] reaches a value l&lt; 2. This is because l&lt; 2 guarantees that no point with maximal values either on A 1 or on A 2 is still unread. Such arguments are generalized as follows.
 Observation 2 Consider the function Then l ( vol [ m ] ,r ) &lt; ( m +1) m d  X  1 for any relation r . Proof. (sketch) Each vertex v of the hypercube [0 , 1] d with coordinates (0 ,..., 0 , 1 , 0 ,..., 0), for which it is vol ( m +1) m d  X  1 , needs to be excluded from U , otherwise the arguments used for Observation 1 would apply here.
A detailed analysis of the effect of m on the limiting power of vol [ m ] is beyond the scope of this paper and is left as a subject for future work. However, it is instructive to have some intuition about  X  X ow much X , in geometrical terms, one can expect to limit. For this, consider the point p on the
SFS actually implements the entropy function, E ( p )= j =1 log( p [ j ] + 1), which also avoids to incur into overflow problems. In [7] it is asserted that E yields the same order as vol [0]. This is not true, since E produces the same order of vol [1], which in general is different from that induced by vol [0]. main diagonal of the hypercube for which it is vol [ m ]( p )= ( m +1) m d  X  1 = m d ( m +1) /m . For each attribute A j is p [ j ]= m ( d ( m +1) /m  X  1). Thus, even for moderately large values of d , p is already quite close to the worst possible point, i.e., (0 ,..., 0), yet vol [ m ] cannot discard it.
In the following we will only consider vol [1], and will de-note it as vol for simplicity.
An obvious alternative to vol is to sum (rather than to multiply) attribute values, that is: Observation 3 The sum sorting function is limiting and l ( sum ,r ) &lt; 1 .
 This immediately follows from Theorem 2. Assume that r has a point p stop with p stop = x ,0 &lt;x&lt; 1. Then, canbehaltedassoonasthecurrentlevel l  X  x ,sincefor any point p  X  X  ( sum ,x )itis  X  j : p [ j ]  X  x ,withatleastan inequality which is guaranteed to be strict.
Arguments used to show that sum is limiting can be used to show that many other functions are limiting as well. It is therefore natural to ask if there is an  X  X ptimal X  sorting function, i.e., a function that on any instance r can limit r more than any other function. The answer is affirmative, and such optimal function, max , is defined as: Therefore, max first sorts points considering for each of them the maximum coordinate value. Then, in case of ties, a sum on the skyline attributes is used. Note that this is needed only to guarantee the monotonicity of max , and that other monotone tie-breaking rules are possible here (e.g., vol ). Clearly, max is limiting, since when p stop = x ,0 &lt;x&lt; 1, SaLSa can be stopped as soon as it fetches a point for which it is l  X  x . 4 Theorem 3 For each relation r and any symmetric sorting function F different from max it is: D ( F ,r )  X  X  ( max ,r ) , thus U ( F ,r )  X  X  ( max ,r ) .
 Proof. (sketch) The optimality of max follows from simple geometric arguments and the observation that, due to The-orem 1, all symmetric limiting sorting function will eventu-ally limit r using the same stop point p stop ,with p stop 0 &lt;x&lt; 1. This is to say that maximal attribute val-ues in the unread domain D ( F ,r )areequalto x , indepen-dently of F .Let F = max .Since F is monotone, then D (
F ,r )  X  [0 ,x ] d  X D ( max ,r ). The second part of the theo-rem, U ( F ,r )  X  X  ( max ,r ), immediately follows. The equal-ity case has also to be considered here, since it is possible that r has no point in D ( max ,r ) \D ( F ,r ).

We conclude this section by observing that the limiting and the filtering power of a sorting function F , the latter
Strict inequality is required only in the particular case when  X  j : p stop [ j ]= x and duplicates are possible. referring to the impact F has on the effectiveness of the fil-ter phase in which dominance tests are executed, are not necessarily positively correlated. This is also to say that, given functions F 1 and F 2 , it might well be the case that U (
F 1 ,r )  X  X  ( F 2 ,r ), yet sorting data using F 1 leads to exe-cute less dominance tests than using F 2 .
 Example 4 As an example of how the different sorting func-tions operate, we show below the case of a 2-dimensional skyline over a relation with 8 points. The skyline consists of points p 1 ,p 2 ,p 3 ,and p 7 (markedwithanasteriskintheta-bles). The stop point is point p 2 =( . 55 ,. 5) ,with p 2 the left-most table we see that sorting by vol (actually vol cannot avoid reading all the points. Indeed, after reading p the level of vol is 1 . 54 = ( . 4+1)  X  ( . 1+1) .Fromthisone derives that the maximum possible value on either A 1 or A is . 54 &gt;. 5 , thus also the last point p 6 has to be read.
Sorting by sum allows halting the execution without read-ing point p 6 . After reading p 8 , the level of sum is l = . 5 , which is sufficient to conclude that all skyline points have been seen. Note that in this particular case sum and yield the same order.

Finally, sorting by max allows SaLSa to stop before reading p . Although p 8 is in the region dominated by the stop point, SaLSa cannot avoid reading it. Indeed, before reading p 8 level of max is . 55 , and from this one cannot exclude that a skyline point, say ( . 4 ,. 52) , exists.

As to dominance tests, it can be verified that both vol and max execute 11 comparisons, whereas sum performs only 10 tests to determine the skyline.
 p 1 (  X  ) .75 .4 p 3 (  X  ) .3 .8 p 2 (  X  ) .55 .5 p 4 .3 .7 p 7 (  X  ) .05 .9 p 5 .3 .35 p 8 .4 .1 p 6 .2 .25
In this section we try to shed some light on what the use of an asymmetric sorting function is going to change in the choice of the stop point and in the logic for halting the execution of SaLSa . We start with the well-known case of lexicographic sort .

A popular way to sort data is by first ordering them ac-cording to A 1 values, then breaking ties using A 2 ,andsoon. According to this lexicographic sort, each point is assigned the (vector) value: graphic order. Note that lexicographically sorting only on a proper subset of skyline attributes would not yield a mono-tone order in case of ties on the sorting attributes. This is to say that we could have p i p even if p has been read before than p i .

Since lex is not symmetric, arguments used in Section 3.1 do not apply here. In particular, the choice of the stop point cannot be based on the MaxiMin rule described in Theorem 1. Consider a point p =( p [1] ,...,p [ k ] , 1 ,..., 1), i.e., p is maximal on attributes k +1 ,...,d . Then, p can be used to stop the execution as soon as SaLSa reads a point p such that p i [ j ]=0,1  X  j&lt;k ,and p i [ k ]  X  p [ k ]. holds even when k = d , in which case one must wait to read to stop. The following result summarizes such observations. Theorem 4 Let S be the current set of skyline points. For each point p i  X  X  , consider its  X  X eversed X  version, ( p [ d ] ,...,p i [1]) . Then, the strategy that chooses the stop point according to the following ReverseLex rule: is optimal for lex .
 Rather surprisingly, above th eorem says that the best point to use for stopping the execution is indeed the one that is optimal when the priority of attributes is reversed with respect to the one adopted for sorting.

We now turn to consider the case when F is a generic asymmetric sorting function. For the sake of definiteness, assume F is real valued, F ( p )  X  . The basic observation is now that when F is asymmetric, it is no longer true that maximal values of points in the unread domain at level l , D (
F ,l ), are the same for all attributes, thus results in Sec-tion 3.1 need to be generalized. This can be done as follows.
For p oint p i define its j -th stop level as: and l i =min j { l i [ j ] } . Note that when the level of we have that, for each j , the maximal value of A j in D ( M j , is guaranteed to be not higher than p i [ j ], M j  X  p Then, we can generalize the MaxiMin rule of Theorem 1 by choosing as stop point: For instance, let F =1 . 2 A 1 + A 2 +2 A 3 and consider points p we conclude that the stop point is p 2 and that we must wait F to reach level l  X  . 4 before being able to stop.
In this section we briefly describe how some practical is-sues that arise when implementing SaLSa on top of a real DBMS can be dealt with.

In our discussion, we have assumed that all skyline at-tributes have the numerical domain [0 , 1]. This was only done with the aim to simplify the presentation of results. However, in real cases each attribute might likely have a different, specific, domain. For instance, in Example 1 the domain of the Price attribute is the set of real numbers, while the domain of Rating is the set of integers from 1 to 5. Further, the domain of Location is not even numeric.
The last should be a strict inequality only if p [ j ]=0, 1  X  j&lt;k .
For arbitrary numerical dom ains the problem can be eas-ily solved as follows. Given a skyline attribute A j , one first determines the maximum, max j , and minimum, min j ,val-ues of A j , after that it normalizes values in the [0 , 1] range by using in the function F in place of A j (or complementing to 1 the above if A j has to be minimized). The specific method used for determining max j and min j can vary depending on the specific scenario at hand. For instance, both values might be derivable from the semantics of the application, or they could be obtained from the server catalogs and then cached in the client to be reused in other queries.

Consider now the case of categorical attributes. The pref-erences we consider always induce a weak order over at-tribute values. This is to say that a preference on attribute A j implicitly defines a number n of  X  X evels X , L 1 ,...,L n the domain of A j . For instance, the preference over the Lo-cation attribute in Example 1 induces the order:  X  X ea X  { all other values but  X  X ity X  }  X  X ity X , which consists of n =3 levels. Note that a value at level L i is better than any value at level L j , j&gt;i .

Preferences of this kind cannot be directly embedded in an ORDER BY clause, since the SQL standard does not provide any means to order categorical attributes in an ar-bitrary way. The approach we take is to map the preference levels into n different numerical values, x 1 ,...,x n  X  [0 , 1], such that L i L j leads to x i &gt;x j . A basic way for doing this is to set x i =( n  X  i ) / ( n  X  1), thus the first level has value 1 and the worst has value 0.

In order to provide a numerical value that can be inserted into an ORDER BY clause, one can use CASE expressions, which are part of the SQL99 standard. Putting all together, the query in Example 1 would be transformed in the stan-dard SQL query (assuming to use sum as sorting function and that hotels X  prices range from 20 to 300 dollars): SELECT * FROM Hotels ORDER BY ((300-Price)/280 + (Rating-1)/4 + CASE Location WHEN  X  X ea X  THEN 1 WHEN  X  X ity X  THEN 0 ELSE 0.5 END) DESC
Finally, the max sorting function can be easily imple-mented within a DBMS as a user-defined function (UDF). In our experimental setup we followed this approach and imple-mented max as a binary C UDF within IBM DB2 UDB. The computation of max over 3 or more attributes was done by nesting the function calls (e.g., max ( A 1 , max ( A 2 ,A
We experimented with the SaLSa and the SFS algorithms using both synthetic and real datasets: Synthetic: We used the synthetic data generator provided Real: We downloaded from www.basketballreference.com All datasets were bulk-loaded into the DB2 Universal DataBase V8.1, running on a Pentium IV 3.4 GHz PC equipped with 512 MB of main memory and a 80GB Samsung SP0812C hard drive, under the Windows XP Professional operating system. SaLSa and SFS wereimplementedinJavaonaclient machine.

Since for all the experiments we performed the size of the skyline was sufficiently small (at most 29,295 100-bytes points) to be entirely contained in the client main memory, no temporary file was ever needed (i.e., both SaLSa and SFS always completed in a single pass).

In the first experiment we wanted to establish the perfor-mance of the vol , sum ,and max sorting functions in limiting the input relation. To this end, we consider the normalized Limiting Power ( nLP ), which measures how many useless points are pruned when using a given sorting function. nLP is defined as the number of unread tuples, |U| , divided by the number of points not in the skyline, | r | X  X S| : The range of nLP is [0,1], with higher values meaning better limiting performance.
 Values of nLP over the synthetic datasets are shown in Figure 1 as a function of the number of skyline attributes. Clearly, when increasing the number of attributes, finding the skyline becomes more difficult, thus nLP decreases. A remarkable exception is the behavior of max on the corre-lated dataset, in which nLP is almost independent on the number of attributes and always remains well above 99%. When comparing the different sorting functions, it is evi-dent that max obtains for all distributions much higher nLP values than sum , which in turn always limits more than vol The figures also include results for a mixed dataset, consist-ing of 500,000 tuples, half of which are anti-correlated and half of which are uniformly distributed in the [0 , 0 . 5] main. Thus, mixed simulates the case where the  X  X ront X  of the dataset is anti-correlated, after which several other tu-ples follow. Their actual distribution is indeed almost imma-terial, the relevant thing being that such tuples are all likely to be dominated by some other tuple in the front. We found this kind of mixed distribution more similar than any of the other three synthetically generated to what real data actu-ally look like, an example of which is given in Figure 4. This kind of distribution is the one on which both sum and vol exhibit their best limiting power, whereas max performance stays between that of uniform and anti-correlated datasets. In particular, with d = 6 attributes, max still prunes about 56% (  X  270,000) tuples. Figure 1: Normalized Limiting Power ( nLP )forthe sum (a), the max (b), and the vol (c) sorting functions as a function of the number of attributes.

While nLP measures the amount of work saved for re-trieving tuples from the data server, to express the amount of work saved by the client during the computation of the skylineweintroducethe normalized Filtering Power ( nF P ). We computed the number of actual dominance tests, dt , and normalized it by the maximum number of comparisons, which equals |S| 2 + |S| ( | r | X  X S| ). Then, nF P is just the complement to 1 of this quantity, i.e.:
Figure 2 shows that the max sorting function, which is the clear winner when limiting is considered, has a variable behavior in reducing the number of comparisons. In partic-ular this is true when increasing the number of attributes, in which case the function with the best filtering power is sum , followed by vol and then by max .

Figure 3 shows the percentage of dominance tests that each function leads to execute, when compared to SFS using the same function. Thus, with respect to Figure 2, now one can appreciate the actual effect that limiting the input has on the filtering phase. Clearly, for a given function, the relative Filtering Power : of SaLSa with respect to SFS is always  X  1, since SaLSa never executes more dominance tests than SFS . For all func-tions rF P tends to 1 as the number of attributes increases, with the exception of max over uniform and correlated datasets. However, the ratio of dominance tests tending to 1 does not mean that SaLSa and SFS execute the same number of com-parisons. For instance, with d = 6 attributes and using max SaLSa saves about 6 . 6  X  10 6 tests on the mixed and 10 7 on the anti-correlated datasets, respectively.

Then, we analyzed the performance of SFS and SaLSa on the NBA real dataset. For this set of experiments we considered only SFS using the vol function. The attributes were considered in the following order: gp , pts , reb , ast , fgm , and ftm . To provide a graphical intuition about the dataset, Figure 4 shows the projection of the 17,791 tuples over the reb and the ast attributes. As anticipated, it is hard to model this kind of distribution with one of the three  X  X asic X  synthetic datasets (uniform, correlated, and anti-correlated) that are commonly used to benchmark skyline algorithms. The mixed dataset we introduced indeed seems to provide a better fit of what one can expect in real situations. Figure 4: Visual analysis of correlation between reb/ast attributes in the NBA dataset.

Graphs in Figure 5 show, respectively, the number of fetched tuples and of comparisons for the four methods un-der analysis ( SFS with vol , SaLSa with vol , sum ,and max
Results in Figure 5 (a) demonstrate that SaLSa is in-deed highly effective in reducing the number of tuples to be fetched from the data server. For instance, even with 6 attributes SaLSa using max correctly computes the skyline without having to read about 5,500 tuples out of 17,791. Only slightly worse is the performance when either vol or sum is used, both pruning about 4,000 tuples. It is worth noting that the jump observed in the graphs of all SaLSa variants when d = 4 is mainly due to the insertion of the ast attribute, which has a very low correlation with reb (see Figure 4).

As to the number of comparisons (Figure 5 (b)), all solu-tions are somewhat comparable for a number of attributes d  X  4, whereas for 2 and 3 attributes max is clearly the most effective method. For instance, when d =2, max executes only 3,193 comparisons versus the 20,234 of SFS .
 Finally, we evaluated actual computation times for the SFS and the SaLSa algorithms on the NBA dataset. In par-ticular, we considered sorting times , i.e., the time needed by thedataservertosortthedata, filtering times , i.e., the time spent by the client in computing the skyline, and commu-nication times , i.e., the time needed to transmit data from the server to the client. The client used in the experiments was a PC with the same HW characteristics of the data server, whereas we simulated the use of a wireless 802.11b connection with a realistic actual transfer rate of 1Mbps (see Footnote 1). Figure 2: Normalized Filtering Power ( nF P )for SaLSa ,using sum (a), max (b), and vol (c) for sorting, as a function of the number of attributes. Figure 3: Relative Filtering Power ( rF P )of SaLSa wrt
SFS ,using sum (a), max (b), and vol (c) for sorting, as a function of the number of attributes.

Sorting and filtering costs are shown in Figure 6 (a) and (b), respectively. It can be observed that, albeit max is the best solution for both limiting and filtering points, its sorting time is the highest one. In particular, the sorting time grows linearly for max , whereas it stays almost constant when vol or sum is used. From this we conclude that when d =2we are just paying the overhead of invoking a user-defined func-tion in DB2, whereas the linear trend only depends on our binary implementation of max , which makes such overhead linearly dependent on d .

When communication costs are considered, the higher num-ber of tuples that SFS needs to fetch from the server has a major impact, and the limiting power becomes predominant in determining the overall performance. Thus, as Figure 6 (c) shows, SFS is the worst among the considered solutions, while the best limiting power of max wrt sum and vol makes sorting by the maximum coordinate value the cheapest al-ternative along the full range of considered dimensionalities.
To study the impact of different transfer rates on the total elapsed time, we considered computing the skyline over 4 at-tributes and varied the transfer rate between the data server and the client in the range [1,100] Mbps. Figure 7 shows to-tal computation times for the three SaLSa variants, normal-ized with respect to SFS costs: in the range of considered transfer rate values SaLSa always performs better than SFS (normalized costs are always less than 1), and only when communication is very fast (100 Mbps) the higher sorting costs of max outweigh the higher number of fetched tuples of sum and vol , making these two slightly better than max .
Finally,weobservethatintheaboveexperimentswehave considered a client with the same computing capabilities of the server. Had we experimented with a slower client, the net effect would have been a relative increase of filtering with respect to sorting times, thus a further increase in per-formance of SaLSa variants with respect to SFS .
In this paper we have introduced SaLSa , a novel algorithm for computing the skyline of a relation. With respect to pre-vious algorithms, SaLSa innovative feature is the ability of computing the correct result without having to apply domi-nance tests to all the objects in the relation. This is achieved by pre-sorting the data using a monotone limiting function, and then checking that unread data are all dominated by a so-called stop point . Experimental results show that this strategy is indeed effective, thus particularly attractive when one has no direct control on the data server or when the sky-line logic runs on a client with limited bandwidth connec-tion. Incidentally, the idea of limiting the amount of data to be read by exploiting the value of a monotone function is also used by the recent SUBSKY algorithm [15] for comput-ing skylines in subspaces. However, being SUBSKY based on a fixed ordering for each attribute, it cannot be used for arbitrary preference specifications (e.g., the one on Location in Example 1).

In this paper we have considered three specific symmetric sorting functions, namely volume ( vol ), sum of coordinates ( sum ), and maximum coordinate ( max ), and proved that the latter has an optimal limiting performance. In the future, we would like to better understand the interplay between the limiting power of a sorting function and its effectiveness in reducing the number of dominance tests. A further in-teresting issue would be to understand how information on data distribution could be exploited to dynamically choose the best, possibly asymmetric, sorting function to use. (b), and total (c). Figure 5: Number of fetched tuples (a) and of com-parisons (b) as a function of the number of attributes for the NBA dataset.

Finally, although SaLSa was conceived as a client-side al-gorithm, the idea of limiting the input could be applied to enhance the performance of server-side algorithms as well. Towards this direction we plan to integrate SaLSa with LESS which is nowadays the best server-side algorithm when no indices are available. Figure 7: Elapsed time on the NBA dataset as a function of the transfer rate, normalized wrt SFS (4 attributes: gp , pts , reb ,and ast ).
