 Recently, Web services have started to be a popular medium for data publishing and sharing on the Web. Modern enterpris es are moving towards service-oriented architectures for data sharing on the Web by developing Web service frontends on top of their databases, thereby provi ding a well-documented, interoperable method for interacting with their data [9,8,13,19]. We refer to this class of services as data services in the rest of the paper. Data services are software components that encapsulate a wide range of data-cen tric operations over  X  X usiness objects X  in underlying data sources. They abstract data consumers from the details of where data pieces are located and how th ey should be accessed and allow data providers to restrain the way their business objects are manipulated and enforce their own business rules and logic. The gro wing importance of data services in the movement toward a hosted-services world is evidenced by the number of contexts within which they have been utilized in recent years: data publishing [9,14], data exchange and integration [11], service-or iented architectures (SOA) [8], data as a service (DaaS) [19], and recen tly, cloud computing [5].

Most of the time data services are used t o access privacy-sensitive informa-tion. For example, in the healthcare domain, data services are widely used to access and manipulate the elect ronic healthcare records [11]. Given the sensitive nature of the accessed information and the social and legal implications for its disclosure [1], security and privacy are considered among the key challenging issues that still impede the widespread adoption of data services [4].
A considerable body of recent research works have been devoted to security and privacy in the area of Web services [10,12,20,18]. Their focus was on provid-ing mechanisms for ensuring that servi ces act only on the authorized requests and for ensuring SOAP message confidentiality and integrity. However, this is not sufficient as control over who can invoke which service is just one aspect of the security and the privacy problem for data services. A fine-grained con-trol over the information disclosed by d ata service calls is required, where the same service call, depending on the call issuer and the purpose of the invocation, can return more or less information to the caller. Portions of the information returned by a data service call can be enc rypted, substituted, or altogether re-moved from the call X  X  results. We explain the privacy and the security challenges for data services based on a concrete example. 1.1 Motivating Scenario Let us consider a healthcare scenario in which a nurse Alice needs to consult the personal information (e.g., name, date of birth, etc.) of patients admitted into her healthcare organization NetCare for some medical purposes (e.g., to ensure that patients receive the right me dical dosages corresponding to their ages, etc.). The NetCare organization involves many specialized departments (cardiology, nephrology, etc.) and laboratories, and follows a data service based approach [9,11,13] to overcome the heterogeneity of its data sources at their various locations; i.e. data services are created on top of heterogeneous data sources to mask their heterogeneity for data consumers. We assume that Alice works in the cardiology department, and that she issued the following query:  X  Q: return the names and dates of birth DoB for all patients  X . We also assume that she has the following service at her disposal: S 1 ($center, ?name, ?dob), where input parameters are preceded by  X $ X  and output parameters by  X ? X .

Obviously, the query Q can be resolved by simply invoking S 1 with the value center = NetCare . However, executing the service S 1 involves handling security and privacy concerns that could be asso ciated with the service X  X  accessed data. For example, nurses may be only allowe d to access the information of patients from their own departments (e.g., nurses working at the cardiology department are not allowed to access the informatio n about patients at the nephrology de-partment); physicians may be only allowe d to access the information of their own patients, etc. These are security concer ns that are typically defined in security policies. Furthermore, the patients should also be allowed to control who can access their data, for what purposes and under what conditions. For example, two patients Bob and Sue whose data are accessed by S 1 may have different preferences regarding the d isclosure of their ages to a nurse for medical treat-ment purposes. These are privacy concerns that relate to individuals and their requirements about their data. They are typically defined in privacy policies. 1.2 Challenges Based on our scenario, we identify the following two challenges which are ad-dressed in the paper. The first challenge is how to enable the service providers (e.g., NetCare) to handle the cited securi ty and privacy constraints. A common approach in the database field to handle such constraints is to push them to the underlying DBMS by rewriting the query to include these constraints [16]. However, this may not be applicable to data services as the same service may access a multitude of heterogeneous dat a sources that may not necessarily have a DBMS (e.g., XML files, flat files, silos of l egacy applications, external Web ser-vices, etc.). An alternative approach is to enforce privacy and security policies at the application level [7], by modifying, in our case, the source code of data services. However, this also may not always be applicable nor advisable as most of current data service creation platforms (e.g., AquaLogic [8]) provide data ser-vices as black boxes that cannot be modified; i.e., th eir internal data integration procedures and logics are not accessibl e. Even if the code was modifiable, this solution often leads to privacy leaks [16], as the dropped programming code may contain flaws; i.e., its correctness is hard to be proven (especially for complex queries), compared to declarative rew ritten queries in the first approach. The second challenge is how to specify and m odel the security and privacy concerns associated with data services. There is a need for a model that provides explicit description of these concerns to ensure the correct execution of services (e.g., to make sure that services are executed b y entitled bodies, etc.) and the proper usage of their returned data (e.g., if d ata were modified for some privacy con-cerns, the type of applied modification s needs to be declared so that users can interpret data correctly). 1.3 Contributions In this paper, we propose a secure, privacy-preserving execution model for data services allowing service providers to enforce their privacy and security policies without changing the implementation of their data services (i.e., data services are considered as black boxes). Our model is inspired by the database approach to enforce privacy and security policies. It relies on a declarative modeling of data services using RDF Views . When a data service is invoked, our model modifies the RDF view of the corresponding servic e to take into account pertaining secu-rity and privacy constraints. Our model uses the mature query rewriting tech-niques to rewrite the modified view in terms of calls to data services (including the initial one). Services are then execu ted, and the constraints are enforced on the returned results. Our contributions are summarized as follows:  X  We propose a semantic modeling for data services, privacy and security poli- X  We propose a secure and privacy-preserving execution model for data ser- X  We integrated our model in the architecture of the widely used Web services The rest of the paper is organized as fo llows. In Section 2, we present our secure and privacy-preserving execution model for data services. We present also our modeling to data services, security and privacy policies. We evaluate our model in Section 3, survey related works in S ection 4 and then conclude the paper in Section 5. In this section, we describe the propo sed model for data service execution. 2.1 Model Overview Our model is inspired by the database approach to  X  declaratively  X  handle the security and privacy concerns. Specific ally, our model relies on modeling data services as RDF Parameterized Views over domain ontologies to explicitly define their semantics. An RDF view captures the semantics of the service X  X  inputs and outputs (and their inter-relationships) using concepts and relations whose se-mantics are formally defined in domain ontologies. Views can be integrated into the service description files (e.g., WSDL) as annotations. Our model, as Figure 1 shows, enforces the privacy and the secu rity constraints associated with data services  X  declaratively  X  as follows. Upon the reception of a service invocation re-quest for a given service (e.g., S i ), it extracts the RDF view of the corresponding service from the service description file and the contextual information (e.g., the recipient of requested data, the purpose , the time and location, etc.) from the invocation request. Then, the RDF view is rewritten to include the security and privacy constraints that pertain to the data items referred in the view. These constraints are defined in the security and privacy policies and have the form of SPARQL expressions (which simplifies their inclusion in the RDF view). The generated extended view may include now additional data items necessary for the evaluation of the constraints (e.g., t he consent of patients, the departments of nurses, etc.) that are not covered by t he initial service. Therefore, the ex-tended view is rewritten in terms of calls to ( i ) the initial service S i and ( ii )the services covering the newly added data items. Finally, the obtained composition (i.e., the rewriting) is executed, and the constraints are evaluated and enforced on the obtained results. The obtained re sults now respect the different security and privacy concerns, and can be retur ned safely to the service consumer. We explain and illustrate these steps in details in subsequent sections. 2.2 Semantic Models for Data Services and Policies Semantic Model for Data Services : The semantics of data services should be explicitly defined to allow service consumers to correctly interpret and use the services X  returned data. In this work, we model data services as RDF Parameter-ized Views ( RPV s ) over domain ontologies  X  .RPVsuse concepts and relations from  X  to capture the semantic relationships between input and output sets of a data service.

Formally, a data service S i is described over a domain ontology  X  as a pred-icate: S i ($ X i , ? Y i ):  X  &lt;RPV i ( X i , Y i , Z i ) ,C i &gt; ,where:  X  X  X  RPV  X  C Figure 2 (Parts a and b ) shows respectively the RDF view of S 1 and its graphical representation. The blue ovals (e.g., Patient , Center ) are ontological concepts (ontological concepts and relations are prefixed by the ontology namespace  X  X : X ).
RDF views have the advantage of making the implicit assumptions made about the service X  X  provided data explicit . These assumptions may be disclosed implicitly to service consumers. For example, the names and DoBs returned by S 1 are for patients  X  who have diabetes  X ; i.e., the service consumer will know -implicitly-in addition to the received nam es that these patients have diabetes. Modeling and explicitly describing this implicit knowledge is the first step to han-dle this unwanted implicit information disclosure. Note that RDF views can be integrated to the service description files as annotations (e.g., using the WSDL-S approach (www.w3.org/Submission/WSDL-S/).
 Security and Privacy Policies : In this work, we suppose the accessed data are modeled using domain ontologies. We express therefore the security and privacy policies over these ontologies. We adopt the OrBAC [3] and its extension (a) (b) PrivOrBAC [6] to express the security an d the privacy policies respectively. In the Organization-Based Access Control mo del (OrBAC), privileges are expressed in terms of permissions . A permission is a predicate Permission(org, r, a, d, c) ; it is read as follows: the organization org grants permission to the role r to realize the activity a on the data item d and in the context c .Inthiswork, org and r refer to ontological concepts in the ontology, d refers to the properties defined in the ontology. The context c is used to specify fine-grained access control constraints (e.g., constraints on the working hours, emergency, etc.).

The security rules corresponding to the motivating example, i.e. nurses may be only allowed to access the information of patients admitted in the same de-partment , can be expressed in the OrBAC model as follows: where the  X  SameDepartment  X  context is defined against domain ontologies as a SPARQL expression. It can be expressed in the Datalog notation as follows ( X  X : X  denotes the ontology X  X  namespace): The PrivOrBAC model [6] extends the OrBAC model with the privacy require-ments specified by much of current privacy legislations [1,2]. These requirements are consent , data accuracy , provisional obligations and purposes . Consent is the user agreement for accessing and/or processing his/her data. It is required be-fore delivering personal data to third parties. Accuracy is the level of anonymity and/or level of accuracy of disclosed data. Provisional obligations refer to the actions to be taken by the requestors after the access. Purpose is the goal that motivates the access request. The propos ed model in this paper considers only the consent and the purpose requirements. Expressions in PrivOrBAC have the form Permission(org, r, p, a, d, c) ,where p denotes the purpose , the context c is used to represent the consent ; org , r , a and d have the same semantics as above. As the consents of data owners can be regarded as any other data items in underlying data sources, we model them in the underlying ontology and include them in the context part of the PrivOrBAC X  X  permissions.
 The privacy rules of our example are as follows: where the  X  Consent  X  context is defined against domain ontologies. Figure 3 shows the Consent expressed as a SPARQL expression as well as its graphical representation (we factored out the concepts and properties that are needed to model the consent in a specialized ontology denoted by the prefix  X  X : X ). 2.3 RDF Views Rewriting to Integrate Security and Privacy In this step, the proposed model extends the RDF view of the queried service with the applicable security and privacy rules (from the policies) as follows.
Our model extracts the RDF view of the invoked service from the service description file, and consults the associ ated security and privacy policies to de-termine the applicable rules for the given couple of (recipient, purpose). With respect to security policies, our model applies the access rules associated with each of the data items declared in the v iew to remove unauthorized data items. In some cases, the access to a given data item is granted only under certain con-ditions. For example, the security rule s in our example restrict the access to the patient X  X  personal information to the nurses working in the department where the patients are treated. These conditi ons (which have concretely the form of SPARQL expressions) are accommodated in the RDF view. The parts (a) and (b) of Figure 4 shows respectively the initial and the extended view; the added RDF triples are marked in red. Similarly, our algorithm rewrites the extended view to integrate the privacy rules. Returning to our example, the condition related to the patient X  X  consent are added to the view. Figure 4 (Part-c) shows the extended view, where the added RDF triples are marked in blue. 2.4 Rewriting the Extended View in Terms of Data Services The extended RDF view v extended may include additional data items (denoted by  X v = v extended  X  v original ) required to enforce security and privacy constraints. These data items may not be necessary co vered by the initial service. In our example (Figure 4, Part-c),  X v includes the RDF triples ensuring that the pa-tients and the nurse have the same departments, and the RDF triples querying the patient X  X  consent relative to the disclosure of his personal and medical data.
In this step, we find the data services covering  X v to prepare for the enforce-ment of privacy and security conditi ons (in a later step), and rewrites v extended in terms of these services along with the initial service. In this work, we assume the data items necessary for the evaluation of the security and privacy constraints (e.g., consent, time, loc ation, etc.) are also provided as data services. Our rewriting algorithm that implements this step has two phases: Phase 1: Finding the relevant services : In this phase, the algorithm com-pares v extended to the RDF views of available services and determines the parts of v extended that are covered by these views . We illustrate this phase based on our example. We assume the existence of a service S 2 returning the centers and the departments where a given patient is treated, and a service S 3 re-turning the privacy preference of a given patient regarding the disclosure of a given property (e.g., name, DoB, etc.) relative to a given couple of recipient and purpose. The RDF views of these services are shown in Figure 5. Table 1 shows our sample services and the parts they cover of v extended . The service S 2 covers the properties composedOf ( C, P )and treatedIn ( P,D )andthenode D ( const 2= X  cardiology  X ), and covers from the nodes P and C the functional properties (i.e., identifiers properties) hasName and dName that could be used to make the connection with the other parts of v extended that are not covered by S 2 . The service S 3 covers the identical sub graphs involving a node of a Preferences type (e.g., P 1 , P 2 , P 3 , P 4 ), a node of Target type (e.g., T 1 , T 2 , T , T 4 ) and the object properties hasPreferences and hasTarget , hence its insertions in the third, fourth, fifth and sixth rows of the Table 1. Phase 2: Combining the relevant services : In the second phase, the algo-rithm combines the different lines from the generated table (in the first phase) to cover v extended entirely . In our example we need to combine all of Table-1 X  X  lines to cover v extended . v extended is written in the Datalog notation as follows 2.5 Enforcing Security and Privacy Constraints The services selected in the previous ste p are orchestrated into a composition plan to be executed. The composition plan defines the execution order of services and includes filters to enforce privacy and security conditions. Figure 6 shows the execution plan of the running example. The service S 1 is first invoked with the name of the healthcare center ( x =  X  X etCARE X ); the patient names obtained (denoted by the variable y ) are then used to invoke the service S 3 which returns the patients X  preferences relative to th e disclosure of their properties (name, DoB, department, and disease). In parallel, the service S 2 is invoked to retrieve the departments where the patients are tre ated. The results of these services are then joined. Figure 7 gives the outputs of the join operator.

After the join operation has been reali zed, the obtained results are processed by a privacy filter that uses the values of the properties that were added to the initial view to evaluate the privacy constraints of the different properties that are subject to privacy constraints in the view. Null values will be returned for properties whose privacy constraints evaluate to False.

Privacy filters are added to the outputs of services returning privacy sensitive data. The semantics of a privacy filter is defined as follows: Definition 1. Let t (resp., t p ) be a tuple in the output table T (resp., T p )of a service S returning privacy sensitive data, let t [ i ] and t p [ i ] be the projected datatype properties that are subject to privacy constraints, and let constraint ( t [ i ]) be a boolean function that evaluates the privacy constraints associated with t [ i ] . Atuple t p is inserted in T p as follows: For each tuple t  X  T Discard all tuples that are null in all columns in T p Continuing with our running example, the added filter computes the values of y , z , const 1 (i.e, department) and const 2 (i.e, disease) as follows: y = y if w =  X  X es X , otherwise y =Null z = z if q =  X  X es X , otherwise z =Null const 1= const 1if u =  X  X es X , otherwise const 1= Null const 2= const 2if r =  X  X es X , otherwise const 2= Null
After applying the privacy filter, the composition execution plan applies the predicates of the extended view (e.g., dep = X  X ardiology X , and di = X  X iabetes X ) on the filter X  X  outputs. This operation is required for two reasons: ( i )toremove the tuples that the recipient is not allowed to access according to the security policy, and ( ii ) to remove the tuples that the recipient has access to, but whose disclosure would lead to a privacy breach.

Figure 7 shows the output of the Select ( dep =  X  X ardiology X ) operator. The tuples t 4 and t 5 have been removed. t 5 has been removed in compliance with the security policy which requires the patient and recipient to be in the same department -the patient Stacy is treated in the surger y department, whereas the recipient Alice works in the cardiology department). t 4 was removed despite the fact that the patient and the recipient are in the same department. Note that if t 4 were disclosed, then the recipient Alice would infer that the patient Andy is treated in the cardiology department which violates Andy  X  X  privacy preferences.
The Select ( di =  X  X iabetes X ) operator removes the tuple t 3 by comparing the value  X  X ull X  with the constant  X  X iabetes X . Note that if t 3 was disclosed, then the recipient Alice would infer that the patient Sue has Diabetes which violates Sue  X  X  privacy preferences. 3.1 Implementation In order to validate and evaluate our proposal, we exploited the extensibility support provided by Axis 2, specifically the ability to deploy user modules, to implement our privacy-preserving service invocation model. As shown in Fig-ure 8, we extended the AXIS 2.0 architecture with a privacy module consisting of two handlers: the Input and Output handlers , detailed as follows. Input Handler : This handler intercepts incoming SOAP messages and uses the AXIOM API ( http://ws.apache.org/axiom/ ) to extract context information and the request contents, which are then stored into an XML file. The context information of the request is extracted from the SOAP header and contains the recipient identity and the purpose of the invocation. The business service in then invoked by our Axis2 engine.
 Output Handler : The output handler intercepts the output SOAP response message before it is sent out of the service engine and makes sure that it com-plies with the applicable privacy and security policies. To do so, the RDF View Modification component parses the security and privacy policies associated with the invoked service using the DOM API and extracts the rules that apply to the accessed data items for the recipient and the purpose at hand. It rewrites the RDF view to take into account these extracted rules as explained in the previous sections. Then, the RDFViewRewritingcomponent decomposes the obtained extended view into a set of calls to data serv ices that retrieve the different data items requested by the extended view. The obtained composition is then exe-cuted. As a final step, the Result Filtering component enforces the privacy and the security constraints on the obtained results. The output SOAP message is built and the filtered results are sent to the service consumer. 3.2 Evaluation To evaluate the efficiency of our model, we applied it to the healthcare do-main. In the context of the PAIRSE Project (http://picoforge.int-evry.fr/cgi-bin/twiki/view/Pairse/), we were provided with a set of /411/ medical data services accessing synthetic medical info rmation (e.g., diseases, medical tests, allergies, etc) of more than /30,000/ patients. The access to these medical data was conditioned by a set of /47/ privacy and security rules. For each patient, we have randomly generated data disclosure preferences with regard to /10/ med-ical actors (e.g., researcher, physician, nurse, etc.) and different purposes (e.g., scientific research). These preferences are stored in an independent database and accessed via /10/ data services, each giving the preferences relative to a partic-ular type of medical data (e.g., ongoing tr eatments, allergies, etc.). We deployed all of these services on our extended AXIS server running on a machine with 2.2GHz of CPU and 8GB of memory.

We conducted a set of experiments to measure the cost incurred in the enforce-ment of security and privacy policies during the service invocation. Specifically, we evaluated: ( i )thecost c 1 incurred in computing the extended view and writ-ing it in terms of services, and the ( ii )thecost c 2 incurredinenforcingthe security and privacy constraints on retri eved data (i.e., the cost incurred in the filters). For that purpose, in the first set of experiments we executed the services to return the medical information about one given patient (e.g., the patient Bob). In the second set, we executed the same services to return the medical information for all patients. In the first set of experiments, as the services return the information of one patient only, c 2 can be neglected and remains only c 1 .In the second set, c 2 is amplified by the number of processed patients. The executed services in our experiments were select ed such that they have different sizes of RDF views (namely, /1/ class-node, /3/ class-nodes, and /5/class-nodes). The invocations were made by the same actor (a researcher) and for the same purpose (medical research). Figure 9 depicts the results obtained for the invocations in Sets 1 and 2. The results for Set 1 show that security and privacy handling adds only a slight increase in the service invocation time. This could be attributed to the following reasons: ( i ) the time needed to inject the security and privacy constraints in the service X  X  RDF view is almost negligible, ( ii ) rewriting the v extended in terms of services is not expensive, as most of v extended  X  X  graph is already covered by v original and the size of (  X v ) does not exceed generally 20% of the size of v original , and finally ( iii ) there is no network overhead incurred in invoking the additional services as they are already deployed on the server. The results for Set 2 show that c 2 is still relatively low if compared to the time required for executing the services with out addressing the security and privacy concerns. Most approaches in the area of Web service security have focused on providing mechanisms for ensuring that services act only on authorized requests as well as ensuring the confidentiality and the integrity of exchanged messages [10]. These works range from proposing new public-and private-key encryption mechanisms to protect exchanged SOAP messages [20], to proposing secure communication protocols and architectures [12]. We consider these works as complementary to our proposal as we focus on a different security aspect which is limiting the service X  X  disclosed information based on the identities of services X  consumers (i.e., the recipients), their purposes and the data queried at the service endpoint.
Some works have addressed the privacy of service consumers as they may release sensitive information (e.g., credit card numbers, etc.) when they inter-act with Web services. Hamadi et al. [15] proposed a formal technique to allow Web service providers descr ibe  X  X aithfully X  the way they use and store the data collected from service consumers. The desc ription is integrated into Web service standards using an extended state machine model, and could be used in the service selection process. Meziane et al. [18] proposed a system to monitor the compliance of service prov iders with the privacy agreements that define the con-sumers X  privacy rights. Malik et al. [17] proposed a reputation-based approach to enable interacting Web services to have a better understanding of their pri-vacy practices, to help them preserve use rs X  privacy when interacting with other services. In our work, the focus is on data subjects whose data are accessed by the data services rather than on service consumers. Therefore, our work comple-ments these works by addressing a new dimension of the privacy problem.
In addition, the main aspect that differentiates our contribution from existing work is the transparent integration and management of privacy and security concerns into existing arch itectures, without modifying either business services, protocols or query languages that give access to the services. Therefore, the integration of our contribution into existing business applications should require minimal changes, leaving the original business infrastructure unchanged. In this paper, we proposed a secure and privacy-preserving execution model for data services. Our model exploits the services X  semantics to allow service providers enforce locally their privacy and security policies without changing the implementation of their dat a services (i.e., data services are considered as black boxes). We integrated our model to the architecture of Axis 2.0 and evaluated its efficiency in the healthcare application domain. The obtained results are promising. As a future work, we plan to address data privacy concerns when composing autonomous data services with conflicting privacy policies. Acknowledgments. This research work is funded by the French National Re-search Agency under the grant number ANR-09-SEGI-008.

