 Panagiotis Papadakis n 1. Introduction
In parallel to common robotic applications where robots are designed to operate in indoor-structured environments, there is an increasing interest in advancing robot technology, both in hardware and software, to allow robots to be deployed in outdoor, off-road, natural, as well as unnatural environments. Robotic applications such as planetary exploration, search and rescue, forestry and mining are made feasible by designing robots with reconfigurable components that passively, or actively, adapt to the underlying terrain.

Mobile robots are now at the forefront of applications that range from terrestrial environments of severely hazardous human life conditions ( Guizzo et al., 2011 ) to pure research oriented applications as for example Mars exploration ( Carsten et al., 2009 ). Within such cluttered and diverse environments, the operation of robots can be made feasible by addressing a number of common problems, namely (i) assessment of the terrain traversability, (ii) planning optimal motion paths with respect to the given criteria and (iii) suitably adapting the kinematic configuration of articulated robots as a function of terrain traversability. In addressing these issues, their high interdependence should be taken into consideration together with the fact that solutions should be tailored to the constitu-ents of the application which, in turn, imposes constraints in the design of a robot and its perceptual capabilities.
In view of the complexity and plurality of challenges that are encountered in addressing each sub-problem, most research efforts have been dedicated into addressing these issues distinc-tively and occasionally, by imposing several oversimplifications in formulating the entire problem. In this survey, we review the state-of-the-art in 3D terrain traversability analysis for UGVs while in parallel elaborating on the relation of the various approaches to path-motion planning, in order to provide a spherical view of the problem while in parallel directing the attention towards more specific elements that are of key impor-tance. We gather and organize previous work into a taxonomy wherein the problem of terrain traversability analysis may be addressed through either external X  X istant (exteroceptive) sen-sing of the environment, namely, LIDAR and vision sensors, or by proprioceptive sensory data processing during the traversal of the terrain.

By reviewing the various directions that have been explored, the goal of this survey resides mainly into three objectives. In particular, to shed light on the advantages and disadvantages of the previously proposed methodologies, to serve as a valuable reference for the community in gathering the most influential works within the field, and finally, inspire research in addressing the open challenges. Under these perspectives, the present work constitutes the first large-scale effort in reviewing the field of terrain traversability analysis methodologies for motion planning of UGVs.

To facilitate the reading and comprehension of the material that is included in the survey, the remainder of the paper has been organized as follows. First, in Section 2 , we identify the major components of terrain traversability analysis methods and provide a generic top-down view of the domain through a high-level taxon-omy. Our description continues in Sections 3 X 6 ,wherewegather and categorize the previous appr oaches according to this taxonomy that is further refined to account for the key elements that characterize the individual domains. Finally, in Section 7 ,wediscuss and elaborate on the findings from the collected literature and in
Section 8 we conclude with a view toward the open challenges and future trends. 2. Terrain traversability analysis for UGVs
Terrain traversability analys ishasbeenusedasameansfor navigating a robotic ground vehicl e within environments of varying complexity, on the one hand ensuring safety in terms of collisions or reaching unrecoverable states and on the other hand achieving goals in an optimal mode of operation. Occasionally, this generic capability of a UGV has been termed using keywords such as: drivability, trafficability, navigability, coverability, terrainability, maneuverability, mobility and traversability.

Although the problem has been viewed from various perspectives, a formal and widely accepted defin ition has not yet been settled within the robotics community. In the recent work of Ugur and Sahin (2010) , robotic traversability was formalized in the context of the theory of affordances set by Gibson (1979) . Several experiments within Ugur and Sahin (2010) evaluate the prominent aspects of traversability when viewed as an affordance, namely, the extent to which it is a relative attribute, provides perceptual economy and allows for generalization when novel examples are encountered.
Despite the largely constrained experiments, it is evident that the notion of affordance fits adequately as a means to model traversa-bility in the robotics domain.

Though suitable, that formalization nevertheless is highly generic and in turn incomplete as it lacks a formalization for quantifying traversability and deriving a continuous measure rather than a discrete, binary assessment (i.e. traversable or non-traversable). Apparently, such a formalization is still an open problem as it decomposes to a plurality of constituents.
In this study, the term traversability has been identified as the most established within the community. More formally, and looking at the direction of quantifying traversability, we will appoint to the term traversability the following semantics.

Definition. The capability of a ground vehicle to reside over a terrain region under an admissible state wherein it is capable of entering given its current state, this capability being quantified by taking into account a terrain model, the robotic vehicle model, the kinematic constraints of the vehicle and a set of criteria based on which the optimality of an admissible state can be assessed.
This formulation should not be viewed as a strict definition, however, it should suffice to capture the main components of the problem. The terrain model amounts to the perception of the material that in turn prescribes its generic terramechanic proper-ties and its interaction with a traversing vehicle. Geometric characteristics are also appointed into the terrain model to account for the different forms that a material may be distributed.
The robot model minimally captures the basic physical properties of the vehicle such as inertia, mass, dimensions and 3D shape and the kinematic constraints describe the permissible states of motion of the vehicle under consideration.

Historically, terrain analysis through traversability estimation was initially addressed as a binary classification problem, i.e. distinguishing traversable from non-traversable terrain. Later on, the need for finer classification was recognized that either assigned a continuous traversability score or classified the terrain into the various classes that were commonly encountered within a particular application.

Despite the trend in deploying robots into environments of increasing complexity, binary terrain classification should not be viewed as redundant or trivial. The main reason is that the computational complexity of analysis increases together with terrain complexity, hence, binary classification can assist in performing a more elaborative analysis to those portions of the terrain that are of more interest. 2.1. Main streams of research
The predominant approach for measuring traversability concerned the analysis of 2D digital elevation maps (DEM) ( Kweon and Kanade, 1992 ) (alternatively known as Cartesian elevation maps ( Daily et al., 1988 ; Olin and Tseng, 1991 ), originating from occupancy grid maps ( Moravec and Elfes, 1985 ; Elfes, 1989 ), a representation of terrain whose establishment is accredited to Moravec. Grid-based terrain analysis enables the application of efficient graph search algorithms for the purpose of planning, that are currently still very popular and extensively used (see Kavraki et al., 1996 ; Pivtoraiko and Kelly, 2005 ; Melchior and Simmons, 2007 ; Howard et al., 2008 ; Jaillet et al., 2010 ).
This is the preferred choice especially when dense 3D point clouds can be acquired from LIDAR data. Alternatively, or in parallel, appearance-based (spectroscopic) traversability evaluation was per-formed within the images acquired from passive vision sensors and finally back-projected into the 3D world. From another perspective, methods that rely on training and/or classification during the traversal of a particular region from the UGV have also been considered through proprioception, by using sensors such as inertia measurement units (IMU), wheel slip sensors, collision bumpers or other domain-specific sensors.

On the basis of the type of sensory data processing that is employed, we may project the previously explored methodologies into a space that is characterized as follows: Proprioceptive sensory data processing.
 Exteroceptive sensory data processing: J Geometry-based.
 J Appearance-based.
 This distinction is sketched in Fig. 1 .

Although the majority of methods project to either one of these categories, there is a number of hybrid approaches that may further imply the use of additional sensor modalities other than LIDAR, cameras, or proprioceptive sensors (as detailed in Section 6 ).
In the following sections, we review the field of 3D terrain traversability analysis for the purpose of UGV motion planning, in further detail. A sufficiently extended review is provided that includes the seminal and most representative papers and covers the prominent directions that have been explored within the field.
In this effort, a number of relevant works were omitted from the current review in order to give emphasis to those parts of the previous work that have been deemed as maximally orthogonal to one another, and in turn, minimize the redundancy in the referenced material at the benefit of the reader. 3. Proprioceptive traversability analysis
Proprioceptive-based analysis methodologies are useful in learn-ing the best model that captures the difficulty encountered when a vehicle traverses a given terrain . The following compose a represen-tative set of previous approaches of this category ( Iagnemma et al., 2002 ; Wellington and Stentz, 2004 ; Ojeda et al., 2006 ; Angelova et al., 2007a ; Coyle and Collins, 2008 ; Leppanen et al., 2008 ; Bajracharya et al., 2009 ; Bermudez et al., 2012 ) wherein the vehicle learns the difficulty in traversing different types of terrain by analyzing various sensory inputs such as vibrations, wheel slips, bumper hits, etc.
Whenever on-board, proprioceptive sensing is further com-bined with long range perceptual modalities, then, traversability assessments can be further propagated to distant regions cap-tured by the exteroceptive sensory data after having previously determined their correlation to the proprioceptive features, as is characteristically performed by Howard et al. (2006) and Shneier et al. (2008) .

This approach, however, requires an underlying highly tolerant or dispensable vehicle platform in order to deal with failures that may occur, such as tipping over or crashes. Therefore, proprio-ceptive sensing has not generally been favored compared to exteroceptive sensing that serves as the basis in the obstacle negotiation process and allows for worst case traversability assessments that could later on be refined during the actual traversal.

As the content delivered within the survey will reveal, the attention had most often been focused on methodologies that assess the traversability characteristics before actually driving over the respective region. 4. Geometry-based traversability analysis
Objectively, the direction followed by the majority of terrain traversability analysis methodologies is based on geometric processing. In Table 1 , an overview of the previous work belong-ing to this category is provided where the various approaches are further grouped according to the targeted application scenario. In parallel, a set of common features that characterize traversability analysis methods are instantiated, namely, whether terrain prop-erties are taken into account (Ter), robotic attributes (Rob), robot stability constraints (Stab) and robot kinematic constraints (Kin), in corrobation to the definition of traversability given in the previous section.

In Fig. 2 we illustrate how the previous approaches are clustered on the basis of the criteria that are employed using a Venn diagram representation. Through a bottom-up view of the previous work it is straightforward to identify that the basis of all methodologies resides into building a terrain model and deriving a set of features from a given terrain according to this model. On top of such a model, more complex and higher level processing could be pursued by further taking into account a robot model as well as stability and kinematic constraints.

In building a terrain model and deriving a set of corresponding features, we can identify a set of common approaches that have been mostly explored, namely (i) signal processing on the terrain signal ( Section 4.1 ), (ii) convolution of the terrain signal with a kernel simulating the underlying vehicle ( Section 4.2 ) and (iii) statistical processing and extraction of moment-based features and certainty assessments ( Section 4.3 ). It should be noted that these prevalent directions are not mutually orthogonal and most previous works concerned mixtures of these approaches. We discuss methodologies that build and extend these directions by introducing vehicle-dependent variables in Section 4.4 . 4.1. Signal processing
Signal processing techniques have not been as popular as other approaches, nevertheless, a comprehensive summary can be decomposed into two major branches in signal processing, namely, single-scale space and multi-scale space analysis.

In the first domain, one of the earliest approaches in terrain traversability analysis, in general, concerns the work of Hoffman and Krotkov (1989) where a set of terrain roughness parameters was extracted by employing Fourier analysis. By treating the elevation map as the input signal, it was first filtered in order to obtain a subset of samples and localize the terrain roughness and then for each localized point, a plane was fit by least squares regression, discarding the inherent rotation and translation by normalization. Finally, roughness parameters were computed through Fourier analysis on the transformed signal, by computing the expected range of heights and slopes and the repeatability tendency of the signal.

In the domain of multi-scale space analysis, Pai and Reissell (1998) followed an approach based on wavelet decomposition that modeled terrain traversability in multiple resolution levels.
The core idea relied in assessing the terrain roughness by the rate of error decrease in approximating the original terrain map by coarser levels of the wavelet decomposition. On this basis, a local terrain roughness measure is computed for each grid cell that was used to derive optimal paths, where optimality was established by lexicographic comparison of the paths after sorting the respective cells in non-increasing order.

Multi-scale space terrain traversability analysis has also been explored in other works (described in the following subsections), but from another perspective, namely, by taking into account the sparsity in the sensed terrain surface as a result of distance. 4.2. Convolution with kernel
A trend that has drawn significant attention in terrain traversa-bility analysis corresponds to the simulation of the vehicle as a fixed-size 2D kernel and convolving this kernel with the 2D terrain map.
The term convolution here should not be taken equivalently to its formal definition in the context of signal processing. The motivation in using this term is based on the idea that the terrain map is iteratively processed by superimposition of a window (radial or rectangular) centred at the total s et of discretized positions and potentially at different orientations, in that way simulating the overlay of the vehicle on top of the terrain and computing the features that characterize the terrain at these positions. The under-lying idea is illustrated in Fig. 3 .

At any given position, the features that are extracted take into account either the 3D positions of the corresponding grid cells, or make direct use of the 3D points that reside within these cells that have been acquired either from LIDAR sensors or passive vision sensors. Regardless of the underlying data set that is used, a statistical processing stage is followed in the sequel where various features can be extracted among which the most notable can be denoted using the terms certainty , terrain orientation and roughness .

The previous constitute the main statistical features that have been employed, next to which extensions or more dedicated features have further been proposed. 4.3. Statistic processing
Statistic processing of the inherent 3D information of a terrain surface has been the most popular and extensively explored approach in building the terrain model and extracting traversability features.
It would not be exaggerating to say that the core ideas for geometry-based traversability ana lysis methods based on statistic processing had been mainly unfolded in the works of Langer et al. (1994) and Gennery (1999) . In detail, Langer et al. constructed 2D traversability grid maps by computing elevation statistics from the set of 3D points residing within eac h grid cell, namely, the maximum, minimum, variance of height and slope. These features were then checked by hard thresholds according to the vehicle capabilities. In the seminal work of Gennery, terrain traversability was captured by a cost function that aggregated the elevation, slope, roughness and data point accuracy, integrated with a path planning algorithm that took into account the distance traveled as well as the probability of traversability. The geometric features were computed for every grid cell by an iterative plane-fitting process that adaptively weighed the fitted points according to their accuracy, terrain roughness and distance from the center of the ce ll. Finally, the probability of traversability was derived as the probability product of having a permissible slope and roughness.

Other research efforts either augmented these basic ideas or introduced new features. In Joho et al. (2007) traversability was quantified into a global value that was derived as the product of pre-normalized measures of slope, roughness and obstacle presence. The cost was first assigned within each g rid cell by local least-square plane fitting and finally propagated to the entire map through convolutionwithaGaussiankernel.Anapproachmoretightly connected to path planning was presented in Ye (2007) ,wherethe slope of robot-sized terrain patc hes was computed by plane fitting through eigen-analysis and measuring the corresponding roughness through the residual of the fit, that gave a final traversability index (TI) as a linear combination of the two measures. TI was used to derive a vector field for each cell and a final traversability field histogram (TFH) was derived by accu mulating the cell traversal costs in the foreground of the robot that was discretized into sectors.
Instead of using LIDAR, Dubbelmanand et al. (2007) detected obsta-cles in the direction of image columns by using dense 3D terrain data reconstructed from stereo disparities. First, a disparity validity mea-sure was employed together with an image pyramid to produce reliable disparity estimates and in the sequel, the traversability was computed for each pixel of the disparity image by estimating the maximum vertical slope and using hy steresis thresholding that was driven by morphological opening and region filling. Traversability classification of road-type terrain was addressed in Andersen et al. (2006) , by using single 2D laser scans that were obtained by a laser tilted towards the ground. The features extracted corresponded to the height, roughness, step size, curvature, slope, width and data validity which were then fused into a global classifier. A notable characteristic in that approach was the grouping of consecutive traversable segments by clustering measurements into groups of locally homo-geneous geometrical descriptions. Finally, in Kuthirummal et al. (2011) , terrain traversability could be grounded by building a grid map wherein the cells accumulated elevation histograms from the acquired 3D point cloud. By individual inspection of the histograms, overhanging structures were detected, while by pairwise comparison between adjacent cells, the respec tive traversability was assessed. 4.3.1. Modeling uncertainty and error
Systems that worked deterministically often proved to be impractical due to the increased complexity and uncertainty that characterized the environment and the error induced in various measurements. To alleviate this problem, a number of approaches focused on modeling uncertainty in terrain perception mainly through probabilistic modeling. Landmarking perspectives as those described by Kavraki et al. (1996) for constrained environ-ments and Gennery (1999) for planetary rovers, set the founda-tions in this field.

A methodology that concretely modeled error and uncertainty is reflected in Singh et al. (2000) through the notions of terrain certainty and goodness that were combined in order to derive terrain traver-sability (stereomap). To determ ine the goodness of a cell, the minimum of the roll, pitch and roughness of planar rover-sized patches centered at each cell was taken, by fitting planes onto the stereo range data points and computing the residual of the planes. The certainty attributed to a grid cell depended on the number of points within the corresponding patch, their variance and its distance from the current position of the UGV. This essentially favored cells in the local neighborhood of the UGV when local path planning was employed (using Morphin Kelly, 1995 ) and aged cells that lied further away, hence, also biasing the global path planned using the Dynamic A n method ( Stentz, 1995 ). A correlated approach was proposed by Wettergreen et al. (2005) , where certainty in terrain perception was modeled as a function of the number of points and the uniformity of their distribution, that was eve ntually combined with the least favorable among the slope, roughness and point discontinuity within rover sized-patches around the robot. The problem of uncertainty in the detection of obstacles that was induced due to the non-uniform laser scan readings in 3D space was explicitly discussed in Montemerlo and Thrun (2004) , by modeling terrain navigability as a distance adaptive attribute. A pyra mid consisting of several layers of terrain maps of varying resolution was constructed and updated using the Bayes rule wherein navi gability was first locally assessed through the difference between the maximum and minimum eleva-tion. Finally, the terrain map was convolved with a radial kernel that modeled the robot in order to account for the distance from obstacles ( Ferguson et al., 2003 ).

A special reference should be made to the work of Thrun et al. (2006a) , where we find the description of the terrain analysis module of the vehicle Stanley Thrun et al. (2006b) that won the DARPA Grand challenge for autonomous driving in desert terrain. In that approach, traversability was formulated as a probabilistic feature wherein locally spaced elevation differences in the acquired 3D point cloud were verified or discarded, through an error probability estimate that designated whether a position corresponded to an obstacle, drivable space, or unknown. The probabilistic terrain analysis took into account errors occurring in the robot X  X  state estimation and the noise induced from the laser sensors and accumulated over time. 4.3.2. Extraction of shape features
Another approach for deriving the traversability of the terrain concerned the detection of basic shape features, such as edges , planar patches or clusters of scattered 3 D points (see Fig. 4 ).
The main concept is to employ 3D scene understanding algorithms and map the difficulty of a vehicle in traversing a terrain into distinct levels. In such a hierarchy, planar surfaces could correspond to traversable regions depending on their orientation, lines or edges signifying the transition between planar surfaces and finally surfaces that spread in all 3D direc-tions could be judged as the regions that are less likely to allow traversal.
 On this line of thought, in the work of Lalonde et al. (2006) 3D LIDAR data were classified based on their scatterness , surfaceness and linearness for natural terrain analysis. Through the use of ground truth data, Gaussian mixture models of these classes were learned by employing Expectation Maximization on a set of statistic features that were computed from the principal component analysis (PCA) decomposition of sets of neighbo ring points across the 3D scene.
Subsequent filtering on the classification results was performed to account for outliers, discard edges and discriminate the ground from other surfaces, while as a last ste p, region growing was employed for grouping classified points. Similarly in Heckman et al. (2007) , detection of potential negative obstacles was performed by initially performing ray-tracing for occlusion labeling and finally context-based labeling. Given a 3D voxel grid where cells were classified into linear , surface and scatter , ray-tracing was used to propagate the class of occupied voxels to the corresponding occluded voxels while context-based labeling was used to distinguish among four cases that could be the cause of data absence and eventually infer the presence of negative obstacles.
 By building upon fine terrain descriptions extracted from the
GESTALT system ( Goldberg et al., 2002 ), step , roughness , pitch and border hazards were perceived as described in Helmick et al. (2009) , by using the statistics within a goodness map that quantified traversability by locally fitting planar patches across the map. Terrain was classified into definitely traversable , definitely not traversable or unknown by thresholding the goodness value of each cell while traversability of the unknown terrain was pre-dicted by employing forward simulation of path following within the ROAMS environment ( Huntsberger et al., 2008 ) and calculat-ing the energy consumption along a path together with the amount of wheel slippage.

Perception of negative obstacle shapes : Perception of negative obstacles, such as gaps, downward inclined planes or descending steps which are characteristic examples of shapes that belong to this category (see Fig. 5 ), has occasionally been at the focus of scene understanding approaches. Perception of such shapes con-stitutes a big challenge when relying solely on sensors on-board a
UGV, since they are either occluded by positive obstacles or the ground plane and therefore their presence can be inferred through the absence of data.

This problem was addressed in the work of Larson et al. (2011) , wherein terrain traversability was determined by the presence of positive and negative obstacles, step edge obstacles, slope steepness and terrain roughness. Positive ob stacles were detected when the surface elevation variance exceeded a chosen threshold while step edges by measuring elevation differences among neighboring cells.Patchesofmissingrangedatathatexceededsomesizewere considered as potential negative obstacles and a consecutive filtering process determined whether they could be the result of shadowing from positive obstacles. The slope steepness and terrain roughness were computed through PCA analysis. In subsequent work ( Larson and Trivedi, 2011 ), the authors explored a long and short-range negative obstacle detection framework. Initially, potential negative obstacles were detected at a distance using the NODR classification approach and then further refined and filtered using support vector machines (SVM) when the UGV has sufficiently approached the surrounding area. NODR comprised a multi-pass detection process that first looked for steps and next for gaps whose characteristics could either be directly measured from the available range data, or inferred by using contextual cues, such as sudden negative or positive elevation drops. Eventually, using an SVM model trained on ground truth data, true and false positives of negative obstacles were distinguished once the UGV had sufficiently approached. Using stereo-based scene reconstruction and motion cues Murarka et al. (2008) distinguished five possible urb an terrain classes, namely, ground plane, above or below ground plane, drop-off edge and unknown . Drop-off (occluding) edges were detected by boundary extraction and matching in pairs of images of different frames and comparing the motion of features above and below the edges. If the ratio was above a threshold, then an occluding edge was detected.
The remaining four classes of terra in were assessed by measuring the total elevation of cells of the grid map.

To date, no previous work has gone further from binary traversa-bility assessments which implies that whenever a gap is detected it has always been considered as lethal, although it could be passable under certain conditions depending on the mobility capabilities of the UGV. 4.4. Incorporating robot dependent variables
Traversability analysis that is performed solely using character-istics of the terrain provides the basis for the development of more dedicated and detailed models that take as input vehicle dependent variables. Such schema allow for mo re accurate traversability assess-ments at the cost of increased computational complexity that may occasionally be less prioritized.

Among the first elaborative attempt to quantify terrain traversa-bility, at least implicitly, by taking into account the 3D terrain structure and its relation to a 3D vehicle model was presented by
Simeon (1991) . By modeling a vehicle using an arbitrary polyhedron with contact points corresponding to the supporting wheels and the terrain as a polygonal surface, a one-to-one mapping was established between the terrain and a given robot placement by geometric computations that designated a particular robot configuration as admissible, if it satisfied the collision-free and stability conditions.
Collisions arose in the event of negative ground clearance while stability was a function of the posi tion of the robot X  X  gravitational center when projected onto its support polygon. In the same context, more complex vehicle models and suitable configuration space representations were considered in subsequent work ( Simeon and Wright, 1993 ; Wright and Simeon, 1993 ).

Despite the fact that such approaches started to be explored quite early, probably the limited computing capabilities available at that time prevented this direction to foster since employing such complicated models was prohibitively time consuming.
In recent years however the interest was renewed due to the proliferation of dedicated software for running such models, such as simulation environments and physics engines together with the availability of efficient and affordable hardware.
While the field is still in its infancy yet progress can be attested by looking at a number of works where at least one step is taken beyond just simulating the vehicle as a symmetric kernel and convolving that kernel with the terrain. A distingu ishable framework was presented by Bonnafous et al. (2001) where the traversability properties of the terrain are collected into a danger attribute taking into account the robot configuration and stability constraints related to the pitch and roll angles of the articulated components and an uncertainty con-straint that accounted for the sparseness of information in the DEM as the proportion of unperceived cells in the vicinity of the robot surface contact point. The aggregated cost of a particular trajectory within the costmap was then computed by considering the individual danger within the cells as well as the cost induced by the changes in the robot configuration along the path execution. An alternative para-digm is presented in Kubota et al. (2001) where the traversability probability was formulated by estimating the roll, pitch and height criteria of a rectangular shaped robot superimposed on a DEM. In detail, the inclination in each pair of wheels was modeled at the respective perpendicular direction and the height of all grid cells occupied by the robot model as a Gaussian mixture model, that was parameterized by the prescribed position of the robot at a given cell and yaw direction. In Vandapel et al. (2006) , two kinds of terrain traversability maps were construct ed by processing aerial LIDAR data.
The first map quantified the presence of vegetation which encoded the confidence of terrain reconstruction that could be used to plan paths below canopy while the se condmapwasderivedbysuper-position of a robot model across different directions on the elevation map and estimating its roll, pitch and ground clearance. These estimates were then smoothly mapped into a fixed interval and the overall cost was taken as the least favorable of the three criteria.
Recently, Ishigami et al. (2011) formulated the dynamic mobility index , a measure that combined static factors such as stability and dynamic factorssuchaswheelslippage,t ime duration and energy consump-tion. The model assessed terrain roughness as the standard deviation of elevation across the robot footprint when projected onto the 2D grip map at varying yaw angle and wheel slippage by measuring the terrain inclination. Finally, the length of a path was considered in order to favor the shortest paths while energy consumption and time duration were evaluated by simul ating the traversal using paths extracted with varying weightings of the involved factors that finally produced a single path with minimal energy consumption.
In the domain of USAR, a pure geometric-processing approach that quantified the static 3D traversability of articulated, tracked UGVs was proposed in Papadakis and Pirri (2012) , wherein 3D reconstructed terrain from collapsed sites ( Kruijff et al., 2012 ) was used in order to learn and regress the mobility of the robot. By means of physics-based optimization, the robotic vehicle could assess its stable pose on top of a given terrain and in the sequel quantify the optimality of that pose through the computation of refined traversability costs, that accounted for the complete 3D model of the vehicle and the shape of the terrain surface. In a similar setting, Norouzi et al. (2012) employed physics-based prediction of contact support points of a given reconfigurable robot on top of a terrain and in the sequel quantified the traversability by further considering a criterion about the visibi-lity range of an arm-mounted camera. 5. Appearance-based traversability analysis
Terrain traversability analysis methods of this kind project the problem into the image-processing and classification realm ( Fig. 6 ). In this perspective, robotic systems that employ appearance-based traversability analysis usually assess a discrete set of terrain classes, rather than regressing traversability. An overview of previous work concerning appearance-based traversability analysis is provided in Table 2 .

Regressing terrain traversability based on vision features rather than performing terrain classification was recently pro-posed by Guo et al. (2011) . To achieve this, an SVM model was trained for distinguishing different degrees X  X lasses of traversa-bility by learning the standard deviation of the robot angular acceleration when traversing terrains of given type, mainly characterized by moments-based image features. For the applica-tion of robotic-based planetary exploration, Howard et al. (2001) and Howard and Seraji (2001) regressed the terrain traversability by measuring terrain roughness, slope, discontinuity and hard-ness. They measured roughness by computing the size, concen-tration and average separation distance of rocky regions within the observed area that were identified by comparing their visual signature against that of the ground. The slope of the terrain was predicted by using a neural network that had been trained to learn the relationship between slope and correlated pixels along the horizon while terrain discontinuity was used to model features such as cliffs and ravines by measuring the distance between roughly detected lines. Hardness was used to classify between different terrain materials (sand, gravel, etc.), as a measure of potential wheel slippage, by performing texture analysis.

Appearance-based terrain traversability analysis could be further refined from the point of view of the structure of the underlying raw feature space. From this perspective, through a hierarchy of classifiers that were designed to distinguish terrain classes of varying complexity, Angelova et al. (2007) performed appearance-based terrain classification on feature spaces of vary-ing resolution. Classification was performed in a top-down fash-ion, starting by fast and simple classifiers and advancing into finer and more complex classification by applying the minimum-cut algorithm in order to determine non-overlapping classification sub-spaces. By employing standard features based on color statistics and textons, terrain was classified into soil, sand, grave, asphalt, grass and woodchips. As a better alternative to the use of regularly spaced fixed-size image patches for visual primitives,
Dongshin et al. (2007) performed natural terrain classification by using super-pixels extracted by over-segmentation of an image.
These produced regions of homogeneous visual content are superior to rectangular image patches that are generally sensitive to the tessellation resolution and occlusions. As a proof of the superiority of super-pixels, standard image features were employed and Bayesian classification showing improved perfor-mance on a number of examples. Alternatively, Filitchkin and Byl (2012) proposed an adaptive sliding window technique within a 2D image in order to obtain terrain signatures of constant feature density. This was achieved by a simple gradient X  X escent based approach that iteratively increased the range radius of computed features at each consecutive pixel and finally extract-ing the corresponding visual word histogram. By employing SURF features Bay et al. (2008) and an SVM classifier, they distin-guished a predefined set of natural terrain classes that were subsequently coupled with appropriate gait behaviors for a quadruped robot. 6. Hybrid approaches
A mindful study of the previous work and the respective results would not favor an individual approach or particular sensor as being overall superior. An evident complementarity however exists between LIDAR and vision sensors which has been exploited within several works in order to extend the range of operating conditions and increase the overall robustness. We may generally refer to such approaches as hybrid to denote the cases where traversability analysis is being performed by fusion of the two main categories of sensory data and occasionally from other heterogeneous sources of data (see Fig. 7 ). Table 3 summarizes and groups previous work that concerns hybrid terrain traversability analysis methodologies through the fusion of various sensor modalities. 6.1. Fusion of geometry-based and appearance-based features
The main stream of research in hybrid traversability analysis methodologies concerns the fusion of geometry-based and appearance-based features, where visual features are computed on the human visible range of spectra. Previous work may have relied either on passive vision sensors where pixel data are registered to range estimates or through the additional use of
LIDAR sensors wherein data from one source are registered to data from the second source.

Instead of using a single representation of fused features, most often distinct roles are assigned to each sensory data type for assessing different kinds of terrain traversability. In Bellutta et al. (2000) for example, terrain perception was based on the combi-nation of geometric and visual features through a rule-base system. Terrain was geometrically classified into negative or positive obstacles by inspection of the height profile of elevation data while the terrain support was statistically learned through
Expectation Maximization within the color space. In Manduchi et al. (2005) , a hybrid classification scheme was proposed that acted upon the output of a positive obstacle detection process.
First, points in the stereo-disparity range image that corre-sponded to obstacles were detected in pairs by hard thresholding on the extracted slope and height and then grouped together by finding maximally connected sub-graphs within a point graph , that connected neighboring surface points. In the sequel, color-based terrain classification was performed by using the surface reflectivity spectra and learning a Gaussian mixture model for classes of rock / solid , green and dry vegetation. LIDAR data were also used to distinguish smooth against rough surfaces by analyzing the changes in the laser range histogram. A system of pervasive use of LIDAR sensors operating jointly with a single camera is presented in Crane III et al. (2006) where they describe the traversability grid data structure. A collection of smart sensors complied with a fixed underlying traversability assessment pro-tocol assigned traversability scores to each grid cell. Three LIDAR sensors were employed to distinctively assess terrain smoothness and the presence of positive and negative obstacles while a camera was used to segment the drivable area from the remain-ing scene by simple Bayes classification in color space.
A merging perspective of the LIDAR-based and visual-based terrain analysis approaches was explored in the work of Lu et al. (2009 , 2011) where a laser stripe-based structured light sensor was employed that comprised of a laser and camera. The hybrid sensor was used to perform terrain classification through texture features (contrast, correlation, energy and homogeneity) extracted from gray-scale image data, together with Fourier spectral analysis of 1D elevation profiles. Classification was performed by training a probabilistic neural network that was able to discriminate among asphalt, grass, gravel an d sand, suitably aligning the vehicle control parameters for the terrain to be traversed.
 The fusion of diverse, remote sensor modalities is explored in
Stentz et al. (2003) , where the terrain perception of a UGV was complemented by a UAV that registered terrain data acquired from high elevation into the environment as perceived from the sensors of the UGV. The robot team was equipped with co-registered passive and active sensing that were fused in order to assess the drivability , compressibility and penetrability of natural terrain. Color cues proved discriminative for evaluating the drivability over various vegetation and solid obstacles while the density of the reflected LIDAR rays was useful for determining space rigidity. The fusion of traversability costmaps derived from different sensors was addressed by time averaging over each sensor and considering the maximum cost overall for each map cell. Fusion of UAV acquired data for UGV motion planning is also discussed in Vandapel et al. (2006) although solely concerning LIDAR sensors.

In Happold et al. (2006) a framework of terrain traversability estimation was developed for prediction into the classes of low , intermediate , high and lethal traversability. The first stage con-cerned the acquisition of ground truth with respect to the stereo range data and extraction of geometric features that captured statistics on the elevation and the point cloud population accord-ing to the ground terrain plane. They trained a neural network that was subsequently fed with predicted geometric features using maximum likelihood estimation in color space and the final traversability cost was determined by accounting for a graded confidence of stereo range estimation in the lateral and forward direction as well as the elapsed measurement time. 6.2. Heterogeneous sensor fusion
Next to the prominent direction of fusing appearance-based with geometry-based features, a co nsiderable number of approaches concerns the fusion of additional heterogeneous sources of data.
Characteristically, a scene underst anding system that fused percep-tion capabilities from several diver se sensors in order to determine the traversability of the terrain was presented in Rosenblum and Gothard (2000) . Environmental sensing concerning temperature, precipitation and humidity were registered with depth information (stereo disparities) and image visual cues such as color and texture and shape features such as size and orientation, altogether covering an almost complete range of operating conditions. Using these features, a terrain classification system was trained that could be applied per pixel or image patch. An alternative approach in terms of perception for detection of negative obstacles during night was proposed in Matthies and Rankin (2003) , wherein range data were combined with thermal features of the terrain that highlighted cavities as potential negative obstacles. The method was based on the observation that negative obstacles retain more heat during night than planar surfaces.

Other notable works, mainly concerned the fusion of geometry-based and appearance-based feature s together with (near)-infrared imagery. In Dima et al. (2004) , feature and classifier fusion for obstacle detection and terrain traversability was presented. The basis features that were computed on incoming sensory data from various perceptual modalities, namely, LIDAR, color images and infrared, corresponded to the mean and variance of pixel values along a set of image patches spanning the image space. By combin-ing features that incorporate domain knowledge ( Lalonde et al., 2006 ), the authors evaluated classifier fusion strategies (experts, stacked generalization and AdaBoost) and showed improved classi-fication scores for road, human and negative obstacle detection, in comparison to single feature-based classifiers. The work of Silver et al. (2006) emphasized on fusing heterogeneous overhead data for terrain classification and mobility pr ediction. In detail, image-based features were extracted from the HSV space and Near-Infrared Imagery (NIR), together with eleva tion-based features and 3D point cloud features that described the density of the ground support region in combination to PCA-based features. A neural network was built on the aforementioned featur es, giving a traversal cost that was added to a vehicle mobility cost which was computed by assessing the roll, pitch and ground clearance of the robot at various locations, through convolution with a vehicle model. Kelly et al. (2006) described the design and operation of a human X  X obot team for off-road navigation, wherein terrain classification was based on geometry-based features combined with multi-spectral image-based features. PCA was applied in different resolutions of a 3D grid in order to distinguish terrain, vegetation, rocks and bushes. Vegetation, soil and sky detection in images was further aided by using NIR data. The robot support surface was detected by ray-tracing of the laser-beams and trai ning a neural network to assess the load-bearing surface while traversing over vegetated areas, whereas obstacles were inferred by the presence X  X bsence of laser hits in the direction perpendicular to the supporting surface. 6.3. Comparative studies and surveys
To complement our review, a number of previous studies that are insightful for specific aspects of the general problem are of relevance.

As far as discrimination ability is concerned between texture and keypoint descriptors for outdoor applications, a comparative study was recently presented in Khan et al. (2011) . In detail, the authors tested local binary, ternary and adaptive ternary patterns as well as SURF and Daisy descriptors for discriminating asphalt, gravel, grass and tiled surfaces. Among several classification approaches, random forests performed best overall, while key-point descriptors proved to be more discriminative at higher resolutions than the texture-based methods.

A study on rough terrain traversability metrics in the field of urban search and rescue (USAR) was presented by Molino et al. (2007) . Two complementary formulations of terrain coverability were proposed, providing a measure of the total terrain roughness for the task where the robot has to explore an entire area in order to detect the maximum number of victims. It is argued, that both alternative measures are needed and could prove useful depend-ing on the context, namely, depending on whether a discretized elevation map is available or not together with the cell connec-tivity. For the purpose of path planning, terrain crossability was defined as the accumulated cost of robot movements along a path within the rough terrain, that accounted for roughness, wheel X  track diameter and path length.

A useful study on fusion methodologies can be found in the work of Halatci et al. (2007) , where an indepth evaluation of features from different sensing modalities, fusion strategies and classification methodologies was presented. The application domain concerned planetary rovers and classification of terrain into rocky , sandy and mixed . Towards this goal, the author s employed appearance-based features derived by color intensities and texture wavelet-based signatures, geometry-based features derived from the surface orien-tation and step heights by employin g least-squares plane fitting and finally, proprioceptive features by spectral analysis of vibration signals during the traversal of a particular terrain. Two levels of classifiers (lower and higher) were combined hierarchically using
Gaussian mixtures or support vector machines at the lower level to train the classifiers that were fused into a high-level classification either through Bayes fusion or meta-classifier fusion.
An extended survey on vision-based approaches for navigation of mobile robots is provided in DeSouza and Avinash (2002) .Although that survey does not explicitly focus on the concept of quantifying traversability, it reviews a number of correlated aspects such as obstacle detection, measurements uncertainty and map building using vision sensors, that altogether contribute to the goal of allowing a robot to optimally navigate within an environment.
Finally, Chhaniyara et al. (2012) performed a survey on terrain trafficability analysis and the terramechanics of planetary soils.
They organize terrain characterization methods into a hierarchy using as criterion the sensing range of instruments, namely, spectroscopic, radar and in situ and elaborate on the advantages as well as limitations of the various types in the context of space vehicle missions. The results are summarized within an empirical study that spans the whole range of sensing approaches and which highlights the effectiveness X  X fficiency trade-off. 7. Discussion
Following the completion of the description of individual contributions in traversability analysis methodologies, we now shift the discussion onto a number of points that collectively help in deriving several insightful observations. 7.1. Geometry-based versus appearance-based approaches
As has probably been recognized already, the first question that naturally arises concerns the criteria for preferring either a geometry-based or appearance-based approach for analyzing the traversability of a given terrain. The answer to this question points directly toward the application and the environment that the UGV is designed and planned to operate. By summarizing the advantages and disadvantages of the different sensing modalities for particular environments and conditions, we next present a list of key differ-ences between the two predominant approaches, namely: Geometry-based approaches provide the shape of the surface.
As a result, they are invariant to lighting conditions, smoke, shadows or poor weather.

LIDARs are an active sensor that are generally expensive and consume more energy, in contrast to cameras that are more affordable and since they are passive sensors they consume less energy.

Cameras can focus on areas of interest and provide better resolution for finer classification tasks.

Appearance-based (spectroscopic) approaches are occasionally more suited in estimating the load bearing surface than geometry-based approaches.

As was already discussed in Section 6 , the strong complemen-tarity between geometric and appearance-based sensor modalities has often been exploited in order to increase the overall perfor-mance. However, the degree of complementarity under specific conditions has only started to be studied in depth within the last decade and calls for further research.

In the case where the 3D structure of the environment can be reliably recovered by using camera sensors ( Hartley and
Zisserman, 2004 ) either through structure from motion or use of stereo-disparities, hybrid traversability analysis schemes can be developed by registering visual information with the correspond-ing 3D spatial coordinates. Such schema require dense recon-structions of the surrounding environment in order to obtain reliable estimates which in turn usually implies the presence of a sufficiently high amount of characteristic keypoints within the acquired images.

In the domain of exteroceptive terrain analysis and in parti-cular remote sensing of the load-bearing surface, the key feature for estimating the degree to which a surface would bear the weight of a vehicle or not, relies on the identification of the type of material of the corresponding surface. In this context, a spectroscopic approach could be beneficial compared to a pure geometry-based approach, e.g. when the thermal inertia of the terrain can be estimated by analyzing multi-spectra of infrared images. Such sensors allow the measurement of sub-terrain features that are beyond the sensing capabilities of LIDAR (see
Chhaniyara et al., 2012 ). If the conditions within the environment accommodate such assumptions, then spectroscopic sensors may be more adept compared to LIDAR.

Within very specific applications and extreme cases, there exist examples that no sensor modality (spectroscopic or LIDAR) can address effectively in the assessment of traversability. Char-acteristically, we may think of a curb filled with liquid whose surface could be reflective, transparent or light-absorbing (being deceiving in all cases) and whose shape would be highly smooth to be considered as traversable by geometric processing. Such challenging scenarios are rarely addressed and beyond the scope of most contemporary applications. 7.2. Impact
Through a straightforward comparison of the amount of previous work between the two predominant approaches, we may objectively witness a stronger impact of geometry-based traversability analysis methods versus appearance-based. This can probably be explained by the fact that the false positive rate of geometry-based approaches is lower than that of appearance-based approaches. In other words, it is less likely that the shape of the surface will be judged as traversable although it is actually not, in contrast to the appearance of the surface that is usually more prone to this kind of erroneous assessments.

Undoubtedly, avoiding an unrecoverable state that could be due to a false positive is more crucial than false negative assessments that although may result in intimidating planning behaviors, they do not compromise the operation of the robot. The trade-off between safety and effectiveness has mostly favored the former in designing the operation of robots, mainly due to the fragility and high cost of the hardware that is employed. This stresses the need for designing robots that are more affordable and dispensable or alternatively, more robust to collisions and tipping over. In corroboration to this, some impressive steps toward this direction are already being made ( BostonDynamics ; iRobot ), mostly motivated by military applications. 7.3. Application focus
Although research interest was primarily directed toward planetary missions of UGVs, the major part of research overall concerns robots operating within natural environments (as can be extracted from Tables 1 X 3 ). The difference within the two domains as far as traversability analysis is concerned, mainly relies on the need to guarantee a higher degree of autonomy for planetary vehicles in view of the remoteness of their operation and the largely constrained energy resources that limit the speed of the vehicle. On the other hand, natural environments pose bigger challenges for traversability analysis methods than planetary surfaces, since they involve more varying lighting conditions, the presence of vegetation and dynamic events. Overall, this results to a larger and more diverse set of terrain categories that justifies the increased attention in this application.
In contrast, previous work on terrain traversability for struc-tured environments or search and rescue applications has been relatively limited. Structured environments concern urban areas, outdoor and indoor, that are mostly composed of planar surfaces of varying appearances. On the other hand, search and rescue environments probably correspond to the most challenging domain for traversability analysis. The terrain may or may not have a structure or it may be the result of a mixture of materials of diverse attributes ( Sheh et al., 2007 ). In this case, the definition of a terrain class category could be highly ambiguous, therefore impeding any further inference about traversability. 7.4. Criteria for traversability estimation
Recalling the general problem description at Section 2 ,we distinguished a set of criteria based on which traversability analysis methods are developed, namely, the terrain model, the robot physical model, robot kinematic constraints and robot stability constraints.

Through the elaborative description of the previous work as presented in Sections 3 X 6 , an interesting feature is revealed, namely, that the core of all methodologies resides in an under-lying terrain model in combination to which additional criteria may be considered. Analyzing traversability through the extrac-tion of a set of terrain features is beneficial in the following aspects:
Terrain model-based approaches are more generic extending their applicability into different robotic platforms.

They are computationally efficient and allow the seamless application of a plurality of standard computer vision algo-rithms and statistic modeling mechanisms.

They translate the traversability analysis problem into a conventional pattern recognition problem.

On the other hand, purely terrain model-based approaches usually oversimplify the problem as they do not take into account the actual physical interaction of the terrain with the UGV, either static or dynamic. Modeling the interaction between the terrain and the vehicle relies on complex physical models. Deriving a traversability cost that further accounts for the robot X  X  physical model, kinematic and stability constraints is not as straightfor-ward as different notions of optimality/stability may be applic-able that occasionally may be conflicting to one another. A detailed elaboration on the latter issue can be found in Freitas et al. (2010) .

An instructive set of robot optimality/stability measures that are the result of the interaction between the robotic vehicle and the terrain are the following:
Ground clearance : The minimum distance between the center of the robots coordinate frame to the terrain below.

Robot orientation : The roll/pitch of the robot frame with respect to the world frame.
 Zero moment point distance ( Vukobratovic and Borovac, 2004 ):
The point where the resultant of all the reaction forces is applied, i.e. the point about which the total moment of all the external forces is zero. The distance between the boundaries of the stable region and the ZMP is designated as the stability margin.
 Force-angle stability measure ( Papadopoulos and Rey, 1996 ):
The minimum angle required to tip over the vehicle, between the gravitational net force and a tip-over axis normal.
Distance stability margin ( McGhee and Frank, 1968 ): The minimum distance required to tip over the vehicle, between a support robot point and its projected center of mass.
Traction efficiency : Depends on the ratio of tangential to normal contact forces over all tracks or wheels.

Depending on the desired approximation resolution of the physical interaction between the terrain and the vehicle as well as the available sensors, the computation of these measures can be arbitrarily complex. This is reflected by the limited amount of previous work where not only generic terrain features are accounted for but further, an interaction model is constructed. Mapping optimality/stability assessments onto traversability cost assessments in order to guide motion planning is, nevertheless, a growing field. In this direction Roan et al. (2010) performed an evaluation of three state-of-the-art stability criteria comparing their effectiveness in accessing robot stability in real-world experiments wherein tipping over the robotic vehicle was purpo-sefully evoked. 8. Challenges and future trends
Terrain traversability analysis for robot motion planning is a field of active research with a broad range of applications. Mobile robots are slowly but steadily becoming an integral part in a plurality of domains where the presence of humans may be unfeasible, perilous or harmful. From early applications where the main pursuit was to deploy robotic vehicles on planetary surfaces, mobile robots were later on introduced to applications within natural environments and are currently being highly integrated into environments that involve human presence.
The present up-to-date survey has reported on several major advancements and breakthroughs that have mainly been achieved for robots operating in planetary surfaces and natural environments. Robotic vehicles such as the spirit X  X pportunity for Mars exploration ( NASA ) or Stanley ( Thrun et al., 2006b ) that won the DARPA Grand Challenge on 2006 are characteristic examples of complete, reliable and highly effective systems that demon-strate the level of advancement in the field of terrain traversa-bility analysis for robot motion planning in the respective environments. This is further in accordance to the research findings recently reported in the context of Thuer X  X  PhD thesis ( Thuer, 2009 ).

Interestingly, the research X  X  focus and in turn the progress in the field of structured (indoor and outdoor) and unstructured environments, namely, urban search and rescue, lacks behind in comparison to the previous fields. This can certainly be attributed to the difference in the time span that research has been dedicated to each domain, as applications of mobile robots in urban environments are only lately becoming popular. Moreover, urban environments pose bigger challenges as far as traversability analysis is concerned for robot motion planning, since environ-ments are synthesized by a wider variety of terrain classes and often mixtures of materials, while the robot missions often require more delicate operations. Further research toward this direction should be provisioned if mobile robots are to be fully integrated into such environments. A major boost towards this goal can certainly be attributed to the standardization of data structures, communication protocols, sensors and robotic plat-forms in international level, that is mainly fulfilled through the development of the robot operating system (ROS) ( Quigley et al., 2009 ).
 Acknowledgment
This survey has been partially supported by the EU FP7 ICT 247870 NIFTi project.
 References
