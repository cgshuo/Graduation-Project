 In many real-world applications, the samples/features ac-quired are in spatial or temporal order. In such cases, the magnitudes of adjacent samples/features are typically close to each other. Meanwhile, in the high-dimensional scenario, identifying the most relevant samples/features is also de-sired. In this paper, we consider a regularized model which can simultaneously identify important features and group similar features together. The model is based on a penalty called Absolute Fused Lasso (AFL). The AFL penalty en-courages sparsity in the coefficients as well as their succes-sive differences of absolute values X  X .e., local constancy of the coefficient components in absolute values. Due to the non-convexity of AFL, it is challenging to develop efficient algorithms to solve the optimization problem. To this end, we employ the Difference of Convex functions (DC) pro-gramming to optimize the proposed non-convex problem. At each DC iteration, we adopt the proximal algorithm to solve a convex regularized sub-problem. One of the major contri-butions of this paper is to develop a highly efficient algorithm to compute the proximal operator. Empirical studies on both synthetic and real-world data sets from Genome-Wide Association Studies demonstrate the efficiency and effective-ness of the proposed approach in simultaneous identifying important features and grouping similar features.
 Absolute Fused Lasso; Non-convex Optimization; Proximal Operator; GWAS
Regularized learning methods have recently attracted in-creasing attention in various applications. A common sce-nario that occurs in many studies is that the data sets we investigated are of some natural (e.g., spatial or temporal) order; examples include the comparative genomic hybridiza-tion data [18], prostate cancer data [17] and neuroimaging data [23]. For those classes of studies, it is often the case that the adjacent samples/features are similar and even identical. Moreover, in Genome-Wide Association Studies (GWAS), a causal single-nucleotide polymorphism (SNP) often exhibits high similarity with its nearby SNPs. It is thus desired to group nearby SNPs together. However, due to the ambigu-ity choice of reference allele during genotype coding [8], we should group adjacent SNPs if their absolute values are close to each other.

Previous works [22, 26, 1, 25, 20] indicate that utilizing the inherent structure information in the data can potentially be beneficial for model construction and interpretation. Thus if the data exhibits some sequential order, we can potentially incorporate such prior knowledge into the model to improve performance. Meanwhile, due to the curse of dimensionality in the high-dimensional scenario, identifying the most rele-vant features is of crucial importance. In such a case, the traditional Lasso [16] model is insufficient to produce desired results since it tends to select only one of those highly corre-lated features [29]. There are mainly two approaches in the literature to address the problem. One approach adopts the fused penalty (e.g., fused Lasso), which can yield a sparse solution in both the coefficients and their successive differ-ences [17, 18, 9]. However, it does not consider the case that adjacent features have high similarity but opposite signs. Another approach utilizes the graph structure among fea-tures (e.g., OSCAR) during model construction [3, 23, 28]. However, such an approach is too general and does not make full use of the specific structure of the genome data.
Generally, a GWA study focuses on investigating associ-ations between genotypes (SNPs) and disease phenotypes. Previous studies [8, 28] have shown that incorporating the linkage disequilibrium (LD) information [13] between adja-cent SNPs is beneficial in delineating association SNPs with smoothness and less randomness than individual SNP anal-ysis. The studies in [8] also argue that the fused Lasso is not effective due to the ambiguity choice of coding refer-ence. Thus, it is desired to penalize successive SNPs whose absolute values are close or identical.

In this paper, we consider a regularized model which uses a penalty called  X  X bsolute Fused Lasso X  (AFL) to solve such a problem. The AFL penalty encourages sparsity in the co-efficients as well as their successive differences of absolute values X  X .e., local constancy of the coefficient components in absolute value. With AFL, highly similar features can potentially be grouped together even when their signs are different. Since the AFL problems are non-convex, it is chal-lenging to develop efficient optimization algorithms. To this end, we employ the Difference of Convex functions (DC) programming to solve the non-convex problem. At each DC iteration, we adopt the proximal algorithm to efficiently solve the convex subproblem, which iteratively solves a prox-imal operator problem; we further use the Barzilai-Borwein (BB) rule for line search to accelerate convergence. One of the major contributions of this paper is to show that the proximal operator problem can be solved efficiently. Specif-ically, by exploiting the special structure of the regularizer, we first convert the computation of such proximal operator to an equivalent optimization problem via a Euclidean pro-jection onto a special polyhedron. We then develop a gradi-ent descent algorithm based on a novel restart technique by utilizing the optimality condition to efficiently solve the pro-jection problem. We have conducted empirical evaluations on both synthetic data and real data. Experimental results demonstrate that the proposed DC-Proximal approach can achieve up to 50x speedup over general DC-ADMM (alter-nating direction method of multipliers) method X  X t allows us to perform efficient AFL modeling on large-scale genome data that contains tens of thousands SNPs. In this paper, we consider the following Absolute Fused Lasso (AFL) regularization model: where loss( x ) is a convex empirical loss function (e.g., the least squares loss or the logistic loss) and the AFL penalty is defined as: where  X  1 and  X  2 are non-negative regularization parame-ters. The second term penalizes differences of successive co-efficients X  magnitudes and can be considered as a grouping penalty. By imposing both the l 1 and the grouping penal-ties, the AFL model can simultaneously identify important features as well as group similar (identical) features together.
Different from the fused Lasso that penalizes the l 1 -norm on successive differences of coefficients (i.e.,  X  2 P p  X  1 the AFL encourages the smoothness of adjacent coefficients whose absolute values are close or even identical. Thus, strong successive signals can be identified by Eq. (1) even when their signs are different. In general, adopting the AFL penalty is expected to be more effective than the fused Lasso (See an example in Fig. 1). Note that in GWAS, the SNPs data we obtain through genotype coding are strongly af-fected by the choice of reference allele. Thus it is insufficient to just penalize the successive differences without consider-ing the absolute values. In [8], the authors use the l 2 on the absolute difference, and apply coordinate descent to solve the proposed formulation. However, due to the use of l 2 -norm, the fused property, i.e., the absolute values of nearby terms tend to be identical, does not hold any more. Figure 1: Comparison of the solutions of the AFL and the fused Lasso on a simulated data. The AFL (red line) pro-vides better recovery of the original signals (green) than the fused Lasso (blue). See Supplement A for more details about this experiment.

In this paper, we propose to adopt the DC programming to solve the AFL problem (1) and apply the proximal algo-rithm to solve the sub-problem at each DC iteration. One of our main technical contributions is to develop an algo-rithm to efficiently solve the proximal operator problem by exploiting the special structure of the regularizer, which is a key building block of the proximal algorithm.
The AFL formulation in Eq. (1) is a non-convex optimiza-tion problem. We propose to use the Difference of Convex functions (DC) programming [15, 14] to solve it, where a key step is to decompose the objective function in Eq. (1) into the difference of two convex functions. By noting that || x i | X  X  x i +1 || = | x i + x i +1 | + | x i  X  x i +1 | X  ( | x we decompose the objective function in Eq. (1) into the dif-ference of the following two functions: f ( x ) = loss( x ) +  X  1 k x k 1 +  X  2
By linearization of f 2 ( x ), the per-iteration subproblem of the DC algorithm can be written as: where and sgn(  X  ) is the signum function (Detailed derivation is pro-vided in Supplement B). We summarize the DC program-ming in Algorithm 1. A key building block in this algorithm is how to efficiently solve the subproblem (3). Next, we show that (3) can be efficiently solved via a proximal algorithm. Algorithm 1 DC algorithm for solving the AFL Problem Input: data matrix A  X  R n  X  p , response vector y  X  R n  X  1 Output: x 1: Initialization: x 0  X  0 ,k = 0 2: while f ( x k )  X  f ( x k +1 ) &gt; do 3: Update c k according to Eq. (4). 4: Update x k +1 according to Eq. (3). 5: k  X  k + 1. 6: end while
In this paper, we adopt the proximal framework [21] to solve the sub-optimization problem (3) at each DC iteration. Problem (3) is equivalent to where
The proximal algorithm solves problem (3) by generating a sequence { x k } by solving: where t k &gt; 0 is chosen by some rule introduced below. It is easy to show that (6) is equivalent to the following proximal operator problem: where u k = x k  X   X  l ( x k ) /t k . Thus, it can be viewed as the gradient descent along the direction  X  X  X  l ( x k ) with the step size 1 /t k plus computing the proximal operator prob-lem (7). The pseudo codes of the algorithm are summarized in Algorithm 2.
 Algorithm 2 The Proximal Algorithm Input: A , y , X  1 , X  2 Output: x 1: Choose  X  &gt; 1, t max &gt; t min &gt; 0 2: Initialization: x 0 ,k = 0 3: while some stopping criterion is not satisfied do 4: Choose t k  X  [ t min ,t max ] 5: while line search criterion is not satisfied do 6: Update x k +1 according to Eq. (7). 7: t k  X   X t k . 8: end while 9: k  X  k + 1. 10: end while
To guarantee convergence, we use a line search criterion to choose an appropriate step size. Specifically, we accept the step size 1 /t k if the following inequality holds: where  X   X  (0 , 1) is a constant. To further accelerate the convergence speed of the proximal algorithm, as suggested by the studies in [21, 5], we adopt the Barzilai-Borwein (BB) rule to initialize the line search step size as 1 /t k, 0 with a k = x k  X  x k  X  1 and b k =  X  l ( x k )  X  X  X  l ( x k  X  1
Notice that a key step in the proximal algorithm is how to efficiently solve the proximal operator problem (7). In the next section, we introduce our efficient approach to solve (7) by exploiting the special structure of the regularizer.
For discussion convenience, we absorb t k into the regular-ization parameters  X  1 and  X  2 , and omit the superscript k in Eq. (7). Then the proximal operator problem (7) can be simplified as follows:
By applying the procedure discussed in [4], we have the following theorem: Theorem 1. For any  X  1 , X  2  X  0 , we have
Theorem 1 implies that we can solve problem (8) in two steps: first solve (8) with  X  1 = 0 and then applying (9) to obtain the final result. Let  X  = 2  X  2 and  X  1 = 0, Eq. (8) can be rewritten as: We propose to solve problem (10) efficiently by converting the proximal operator to a Euclidean projection onto a spe-cial polyhedron. To perform this transformation, we utilize some important properties of (10) as summarized in Lemma 1, where a detailed proof is provided in Supplement C. Lemma 1. Let x  X  =  X   X  ( u ) be the optimal solution to (10) .  X   X  &gt; 0 , we have: i) if u i  X  0 , then u i  X  x  X  i  X  0 , ii) if u i &lt; 0 , then u i  X  x  X  i  X  0 , iii)  X   X  ( u ) = sgn( u )  X   X  ( | u | ) , iv) if | u i | X | u i +1 | , then | x  X  i | X | x  X  i +1 | , v) if | u i | &lt; | u i +1 | , then | x  X  i | X | x  X  i +1
Assume u  X  0, we define a sparse matrix R  X  R ( p  X  1)  X  p follows: In addition, we denote a vector w  X  R p with the j -th entry defined as: With Lemma 1 and the above definitions of R and w , we next present the following theorem which converts the prox-imal operator problem to an equivalent Euclidean projection problem.
 Theorem 2. Let u  X  0 and  X  &gt; 0 . Let and Define the Euclidean projection of v onto P as: We have
The above theorem implies that, the proximal operator in (10) can be solved by solving the Euclidean projection problem in (15). To further simplify, our next theorem shows that, such a Euclidean projection problem can be solved by a simplified problem without the non-negative constraint. Theorem 3. Let u  X  0 ,  X  &gt; 0 , and We have
Detailed proofs of Theorem 2 and Theorem 3 are provided in Supplements D &amp; E. In the next section, we discuss a restart technique to efficiently solve the Euclidean projection problem (18).
Introducing the dual variable z  X  R p  X  1 for the inequal-ity constraints in (18), we can obtain the Lagrangian in Supp. (E-48). The dual problem of (18) is equivalent to
We propose to solve (18) by simultaneously using the in-formation of the primal and dual problems. The novelty convergence.
Our proposed restart technique is built on the introduc-tion of the support set . Specifically,  X  z  X  0 and denote g =  X  0 ( z ), we define the support set as follows:
The support set S ( z ) is motivated by the optimality of the problem (20), and shall be used for defining a nonlinear and discontinuous mapping from z to x .  X  z  X   X  0, it is a
From the optimality condition, we can build the relation-ship between the minimizer and its gradient, as summarized in the following lemma: Lemma 2. Let z  X  be the optimal solution to (20) and g  X  =  X  ( z  X  ) . We have: i) if z  X  i &gt; 0 then g  X  i = 0 , and ii) if g then z  X  i = 0 .

The matrix RR T is very special, and it can be shown that its eigenvalues are 2  X  2cos( i X /p ) ,i = 1 , 2 ,...,p  X  1, and thus it is positive definite. Note that RR T is the Hessian of  X  ( z ), which implies that the minimizer of (20) is unique. 5.2.2 A Nonlinear Mapping  X  (  X  ) from z to x
Let s 0 = 0 denote the smallest entry in S ( z ), and s | S | p denote the largest entry in S ( z ). In addition, we de-note the j -th largest entry in the set S  X  X  0 ,p } by s j 1 , 2 ,..., | S | X  2. It is clear that 1  X  s 1 and s | S | X  2 With s 0 ,s 1 ,...,s | S | X  1 , the indices in [1 : p ] can be divided into | S | X  1 non-overlapping groups:
Let e  X  R p be a vector composed of 1 X  X , and e G j and v G be the j -th group of e and v corresponding to the indices in G , respectively. For discussion convenience, assume z 0 z = 0, then we can define the nonlinear mapping x =  X  ( z ) based on the support set S as: x
With Lemma 2 and the definition of support set in (21), it is easy to show that the optimal solution to problem (18) can be exactly recovered by the support set S ( z  X  ), as stated in the following theorem.
 Theorem 4. Let z  X  be the minimizer of the dual prob-lem (20) , and x  X  be the minimizer of primal problem (18) . Then x  X  can be recovered by x  X  =  X  ( z  X  ) .
By introducing the support set S , Theorem 4 provides an alternative efficient way to computing x  X  from z  X  . Specif-ically, we can exactly obtain x  X  =  X  (  X  z ), where  X  z is an ap-propriate solution with S (  X  z ) = S ( z  X  ) even if  X  z 6 = z intuition is that, for a given appropriate solution  X  z 6 = z tion than  X  x = v  X  R T  X  z for the primal.

We then present a gradient projection algorithm based on the proposed restart technique, as summarized in Algo-rithm 3. Given an iterative solution z k , we do not perform the gradient projection at the point z = z k . Instead, we first compute x k =  X  ( z k ). Then, we compute a restart point z by x k = v  X  R T z k 0 , where z k 0 can be solved by an equivalent linear system RR T z k 0 = R v  X  R x k . Finally, we perform the gradient projection at the restart point z = z k 0 . Note that P ( x ) is an operator that projects x onto the non-negative orthant. Algorithm 3 Gradient Projection Algorithm with a Restart Technique Input: v , X ,R Output: z 1: Initialization: z 0  X  0 ,L = 2  X  2 cos(  X  ( p  X  1) /p ), k = 0; 2: Compute g 0 =  X  0 ( z 0 ) = RR T z 0  X  R v ; 3: while not converge do 4: Update the support set S ( z k ) according to (21); 5: Update x k =  X  ( z k ) according to (23); 6: Compute z k 0 as the solution to RR T z k 0 = R v  X  R x 7: Update z k +1 = P 0 ( z k 0 ), and set k  X  k + 1; 8: end while
To end this section, we summarize our methodology for solving the proximal operator problem (8) as follows. We first show that a minimizer of problem (8) can be obtained by applying a soft-thresholding (9) on the solution of an al-ternative optimization problem (10). By applying the prop-erties of (10) introduced in Lemma 1 and two variables R and w defined in (11) and (12), we show that the proxi-mal operator problem (10) can be convert to an equivalent problem (15). In the sequel, we present to optimize an al-ternative problem (18) without the non-negative constraint through (19). To solve problem (18), we develop a novel restart technique by introducing the support set (21) and a nonlinear mapping (22). We propose to use Algorithm 3 to solve (18) for efficient computation.
In this section, we evaluate the AFL model (with the least-squares loss) and the proposed algorithm on both synthetic and real-world data. We first evaluate the efficiency of our proposed algorithm in  X  6.1.1, and then compare the AFL with the fused Lasso in  X  6.1.2. Next, we evaluate the predic-tion performance of the AFL in two GWA studies in  X  6.2.1 and  X  6.2.2. Finally, we show the effectiveness of the AFL in identifying genetic risk factors in  X  6.2.2. For all experiments, we use the following two stopping criteria for our algorithm: 1) the relative difference of function values between two iter-ations is less than a tolerance of 10  X  5 , and 2) the algorithm exceeds the maximum iterations (1000 iterations).
We present the empirical studies on the efficiency of our proposed algorithm by comparing our method with the ap-proach that adopts the alternating direction method of mul-tipliers (ADMM) to solve the sub-problem at each DC it-eration. The experiments are carried out on a collection of randomly generated data sets A  X  R n  X  p and outcomes y  X  R n  X  1 . In addition, denote  X   X  = k A T y k  X  . We then conduct the evaluations in the following two scenarios:
Figure 2 summarizes the running time (in seconds) and speedup of AFL (proximal algorithm) over ADMM in the above two scenarios. From these figures, we have the follow-ing observations: (1) Our proposed algorithm is much more efficient than ADMM in both scenarios. (2) The speedup of AFL over ADMM increases as the feature size increases. This indicates that our proposed approach using DC pro-gramming and the proximal algorithm is capable of han-dling large-scale learning problems. (3) The speedup of AFL over ADMM increases as the regularized parameters become larger. Thus, our method is expected to be superior over ADMM in real-world applications, i.e., only a small num-ber of features are relevant X  X  relatively large regularized parameter value is preferred. Figure 2: Comparison of running times and speedups of AFL over ADMM. In this study, we compare the AFL model with the fused Lasso. Recall that the AFL is designed to encourage the smoothness of adjacent coefficients whose absolute values are close or even identical. Thus if the adjacent features exhibit different signs in the model, the AFL approach is expected to be more effective than the fused Lasso. We generate the synthetic data via the linear model y = A  X  x + , where the design matrix A  X  R 500  X  5000 and the noise term  X  R n are randomly generated from normal dis-tributions. The ground truth  X  x  X  R n contains 10% of the signals, which are evenly partitioned into 5 groups. Specif-ically, within each group, we first continuously assign the same value for all the signals; and then, we randomly pick { 0% , 1% , 2% , 5% , 10% } of the signals and change their signs to the opposite. The regularization parameters  X  1 and  X  2 validation for both the AFL and the fused Lasso. We then evaluate the models on a 100 i.i.d. samples testing set. The SLEP package [7, 9] is utilized to solve the fused Lasso prob-lem. We report the averaged prediction performance of 10 replications in Table 1.

We observe from Table 1 that the AFL approach provides better prediction performance than the fused Lasso in most cases. If the ground truth  X  x does not contain too many opposite adjacent signals, both AFL and the fused Lasso can recover the original signal accurately. However, when the number of opposite signals increases, AFL outperforms the fused Lasso significantly. The reason is that, with the AFL penalty, the model tends to select those highly similar adjacent features even if their signs are different. Therefore, the AFL approach is more robust than the fused Lasso in such cases.
 Table 1: Averaged prediction performance of AFL and fused Lasso on synthetic data (standard deviation is shown in the bracket). FL refers to the fused Lasso. MSE refers to the mean squared error. Corr X is the Pearson correlation be-tween the model x and the ground truth  X  x .

In this study, we evaluate the AFL approach on a real-world GWAS data called GLT1D1. The data set contain-ing 210 samples and 1,782 SNPs [28]. The major objec-tives in this study are predicting the gene expression level of GLT1D1 as well as identifying disease risk SNPs. To con-struct our predictive models, we randomly pick 2/3 of the samples to form the training set and use the same method in  X  6.1.2 to choose the best parameters. We compare the AFL model with the fused Lasso on the remaining 1/3 of the data. The averaged results of 10 replications are sum-marized in Table 2.

Table 2 shows that the AFL approach achieves better pre-diction performance in terms of MSE. In addition, our model selects a smaller number of SNPs, which demonstrates the need of considering the absolute values in GWAS due to the ambiguity choice of reference allele during genotype coding. Table 2: Averaged prediction performance of AFL and fused Lasso on GLT1D1 Data.  X # of nonzeros X  refers to the num-ber of nonzero regression coefficients.
 In this study, we evaluate the AFL model on the Alzheimer X  X  Disease Neuroimaging Initiative (ADNI) whole genome se-quence (WGS) data. Particularly, we investigate imaging ge-netics associations between imaging phenotypes and SNPs (within the 19th chromosome) using the regression model with the AFL penalty. We follow the procedure in [24] to process the SNP data and the data set contains 717 subjects and 131,670 SNPs. The baseline entorhinal cortex (EC) vol-ume and hippocampal (HIPP) volume are chosen to be the responses, as these are two major brain regions affected by the Alzheimer X  X  disease (AD).
 Comparison of Prediction Performance We first compare the predictive performance of the AFL model with the fused Lasso. We randomly pick 90% of the samples to form the training set and the remaining 10% of the samples to form the testing set. We perform five-fold cross-validation to choose the best regularization parame-squared error and the number of nonzero coefficients of 10 replications in Table 3.

Table 3 shows that both approaches achieve similar predic-tive performance in terms of MSE. Specifically, in EC task, AFL achieves a slightly lower MSE by selecting a smaller number of features. In HIPP task, AFL selects more features than the fused Lasso. We take a careful look at the SNPs identified by AFL. The AFL detects several SNPs located in three gene including PVRL2 (rs12972156, rs12972970, rs34342646), APOE (rs769449, rs769450, rs429358) and APOC1 (rs12721051, rs56131196, rs4420638) and assign them into correct groups. Note that the sign of the model coefficient of SNP rs769450 is different from its two adja-cent SNPs (i.e., rs769449 and rs429358); the fused Lasso approach fails to group those three SNPs appropriately. Table 3: Averaged prediction performance of AFL and fused Lasso on ADNI WGS Data.
 Detecting Risk Genetic Factors using AFL Inspired by the idea of interaction testing introduced in [2], we finally conduct a study on detecting AD risk genetic fac-tors with the AFL model. Specifically, on Chromosome 19, we first calculate the Pearson correlation between each coded SNP and the response phenotype vector. Then, we plug the correlation coefficients vector into our model (1). To iden-tify the most association SNPs, we vary the regularization parameters and record each model.

Figure 3 shows the study results of EC and HIPP. In the experiment, we can observe that the AFL model can successfully capture AD risk genes including PVRL2 [10], TOMM40 [12, 6, 11], APOE [10, 12, 11, 19] and APOC1 [27, 19]. Moreover, the AFL is capable of performing auto-matic feature grouping even when the signs are different, e.g., rs769449, rs769450 and rs429358 in APOE exhibit high similarity in absolute values. However, the fused Lasso fails to correctly group SNPs like rs769450 since their signals are Table 4: Statistical scores of selected SNPs on Chr.19. P-EC refers to the p-value associated with the EC task. P-HIPP refers to the p-value associated with the HIPP task. OR refers to the odds ratio associated with MCI&amp;AD. different. In Table 4, we further present some statistical scores of SNPs selected by the AFL model, including the p-value 1 (P) and odds ratio (OR) association score. We can observe that most of the selected SNPs achieve high statis-tical significance.
In this paper, we study a regularized learning model based on absolute fused Lasso penalty. The AFL penalty encour-ences of successive coefficients X  magnitudes. Due to the non-convexity of the proposed model, we propose to use the DC programming to solve it. At each DC iteration, we solve a convex regularized sub-problem via the proximal algorithm. The proximal algorithm iteratively solves a proximal oper-ator problem and adopts the Barzilai-Borwein rule for line search. One of our main technical contributions is to develop a highly efficient algorithm to solve the proximal operator problem via a Euclidean projection based on a novel restart technique. Experimental results on both synthetic and real-world data demonstrate the effectiveness and efficiency of the proposed algorithm. This work was supported in part by research grants from NIH (R01 LM010730 and RF1 AG051710) and NSF (IIS-0953662 and III-1421057).
 [1] F. Bach, R. Jenatton, J. Mairal, G. Obozinski, et al.
Those p-values are obtained from Pearson correlation anal-ysis between SNPs and the selected imaging phenotype. [2] J. Bien, N. Simon, R. Tibshirani, et al. Convex hier-[3] H. D. Bondell and B. J. Reich. Simultaneous regression [4] J. Friedman, T. Hastie, H. H  X  ofling, R. Tibshirani, et al. [5] P. Gong, C. Zhang, Z. Lu, J. Huang, and J. Ye. A [6] R. J. Guerreiro and J. Hardy. TOMM40 association [7] J. Liu, S. Ji, and J. Ye. SLEP: Sparse Learning with [8] J. Liu, K. Wang, S. Ma, and J. Huang. Regularized [9] J. Liu, L. Yuan, and J. Ye. An efficient algorithm for a [10] M. W. Logue et al. A comprehensive genetic associ-[11] D. M. Lyall et al. Alzheimer X  X  disease susceptibility [12] A. Maruszak et al. TOMM40 rs10524523 polymor-[13] D. E. Reich, M. Cargill, S. Bolk, J. Ireland, P. C. Sa-[14] P. D. Tao and L. T. H. An. Convex analysis approach to [15] P. D. Tao et al. Duality in dc (difference of convex func-[16] R. Tibshirani. Regression shrinkage and selection via [17] R. Tibshirani, M. Saunders, S. Rosset, J. Zhu, and [18] R. Tibshirani and P. Wang. Spatial smoothing and hot [19] B. Tycko et al. APOE and APOC1 promoter poly-SNPs. AD risk genes are marked in red. [20] Y. Wang, S. Wang, J. Tang, H. Liu, and B. Li. PPP: [21] S. Wright, R. Nowak, and M. Figueiredo. Sparse recon-[22] S. Yang, Z. Lu, X. Shen, P. Wonka, and J. Ye. Fused [23] S. Yang, L. Yuan, Y.-C. Lai, X. Shen, P. Wonka, and [24] T. Yang, J. Wang, Q. Sun, D. P. Hibar, N. Jahanshad, [25] T. Yang, X. Zhao, B. Lin, T. Zeng, S. Ji, and J. Ye. [26] J. Ye and J. Liu. Sparse methods for biomedical [27] Q. Zhou, F. Zhao, Z.-p. Lv, C.-g. Zheng, W.-d. Zheng, [28] Y. Zhu, X. Shen, and W. Pan. Simultaneous group-[29] H. Zou and T. Hastie. Regularization and variable selec-In this supplement, we present all of the details we men-tioned in the main text.

The synthetic data set is generated via y = Ax + , where the data matrix A  X  R 500  X  500 and the noise term are randomly generated from normal distributions. The ground truth x is designed as:
The AFL formulation in Eq. (1) is a non-convex optimiza-tion problem. We propose to use the DC programming to solve it. By noting that || x i | X  X  x i +1 || = | x i + x i +1 | + | x i  X  x i +1 | X  ( | x we decompose the objective function in Eq. (1) into the dif-ference of the following two functions: f ( x ) = loss( x ) +  X  1 k x k 1 +  X  2
Denote the affine minorization of f 2 ( x ) as f k 2 ( x ) = f Then the DC programming solves problem (1) by iteratively solving: Since  X  x k , X  X  2 ( x k )  X  is a constant, problem (24) is equivalent to: and let c k =  X  X  2 ( x k ), problem (24) can be rewritten as: Note that where d 1 = d p = 1 ,d i = 2 , 2  X  i  X  p  X  1; sgn(  X  ) is the signum function. In addition, since max ( | x i | , | x ( | x i + x i +1 | + | x i  X  x i +1 | ), problem (26) is equivalent to min Proof: We prove these properties of the proximal operator problem (10) as follows. i) If u i  X  0 and x  X  i &lt; 0, we can construct  X x  X  as follows: ii) This property can be proved in a similar way as i). iii) Let  X x  X  =  X   X  ( | u | ). We have iv) We only focus on the case u i  X  u i +1  X  0 in the proof v) This property can be proved in a similar way as iv). This ends the proof to Lemma 1.

Based on Lemma 1, we also have the following remark that summarizes the properties of w : Remark. w i = 2 indicates 1 &lt; i &lt; p,u i  X  1 &lt; u i w i = 1 holds in one of the following four cases: 1) i = 1 ,u 1  X  u 2 ; 2) i = p,u p  X  1 &lt; u p ; 3) 1 &lt; i &lt; p,u i  X  u i +1 ,u i  X  u i  X  1 ; 4) 1 &lt; i &lt; p,u i &lt; u i +1 ,u i &gt; u i  X  1 . w i = 0 holds in one of the following three cases: 1) i = 1 ,u 1 &lt; u 2 ; 3) 1 &lt; i &lt; p,u i &lt; u i +1 ,u i  X  u i  X  1 . In addition, it is easy to get that P p i =1 w i = p  X  1 . Proof: According to Lemma 1 i) and ii), we have that the optimal solution to (10) is non-negative, i.e., x  X   X  0. Incor-porating the definition of R in (11) and Lemma 1 iv) and v), we have R x  X   X  0. Therefore, we have x  X   X  P , where P is defined in (14). It is easy to verify that P is a closed convex and nonempty polyhedron. Thus x  X  =  X   X  ( u ) is the optimal solution to Making use of the definitions of R and w in (11) and (12),  X  x  X  P , we have Therefore, x  X  =  X   X  ( u ) is the optimal solution to the prob-lem: Incorporating (13), we can easily verify that,  X  P  X  optimal solution to(15) is also the optimal solution to (41). Thus, (16) holds.
 Proof: We prove (19) by the technique of KKT optimality conditions.

By introducing the dual variables w  X  R p for the inequal-ity x  X  0, and z  X  R p  X  1 for the inequality R x  X  0, we can write the Lagrangian of (15) as: The inequality constraint functions in (15) are affine, and thus Slater X  X  condition holds, which indicates strong duality. zero gap for (15). The KKT optimality conditions require the following necessary and sufficient conditions:
Following a similar analysis, we introduce the dual vari-able z  X  R p  X  1 for the inequality R x  X  0, and write the Lagrangian of (18) as: Let  X  x and  X  z be any primal and dual optimal points with zero gap for (18). The KKT optimality conditions requires the following necessary and sufficient conditions: Let
Next, we show that x  X  and ( w  X  , z  X  ) satisfy the KKT con-ditions (44)-(47). It is easy to verify the relationships in formulations (44), (46)-(47). R x  X   X  0 holds as: 1) R  X  x  X  0, 2) x  X  = max(  X  x , 0), and 3) each row of R only contains two entries 1 and -1. As the objectives of (15) and (18) are strictly convex,  X  x and  X  x are both unique. Therefore, it fol-lows from (53) that (19) holds.
