 Fl ash mem o r y has bee nwi de ly ad o pted in the p o rtab l ede vi ces such as PDA, d i g i ta l camera a n d MP3 as the durab l est o rage mater i a l due t oi ts o utsta n d in g character i st i cs :li ght w e i ght , p ow er sa vin ga n dsh o ck res i sta n t .A spr i ce dr o ps a n d vol ume in creases sharp ly e v er yy ear ,fl ash based st o rage de vi ces are e x-pected t o be app li ed t o data -in te n s iv es y stems in c l ud in g database ma n ageme n t s y stems .How e v er , as a n EE P RO M, fl ash mem o r y e x h i b i ts s o me t o ta lly d iff ere n t I Ofeaturesc o mpared wi th trad i t ion a l d i sk .How t ol e v erage these features b y rec on s i der in gthee xi st in gst o rage tech nolo g yi s on e o fthema in o bstac l es f o rthe p o pu l ar i zat ion o f fl ash .

D atabase ma n ageme n ts y stems res o rt t o mem o r y cache t o b oo st the I Oper -f o rma n ce as there are great speed gap bet w ee n the mem o r y a n dd i sk .How e v er , due t o c o st a n d capac i t y c on stra in ts ,only the h o tdatash o u l dbe lo aded in t o ma in mem o r y. W he ni t i sfu ll, s o me pages ha v et o be e vi cted fr o mmem o r y a n d the ke y pr o b l em f o rcacherep l aceme n tstrateg y. T he emerge n ce o f fl ash mem o r y d o es no t esse n t i a lly cha n ge the s i tuat ion ab ov eastherest ill e xi sts o b vio us speed gap bet w ee nfl ash a n dma in mem o r y. How e v er , ama in feature o f fl ash mem o r y i sas y mmetr i c speed o freada n d w r i te , that i s ,w r i t in g a page i sse v era l t i mes s low er tha n read in g . C on seque n t ly, e vi ct in gad i rt y page fr o mma in mem o r y will in cur s i g ni fica n t ly h i gher t i me c o st tha n ac l ea n page rep l aceme n tf o r fl ash mem -t oo pt i m i ze curre n td i sk -o r i e n ted cache rep l aceme n tschemef o r fl ash mem o r y.
Curre n t state -o f -the -art wo rks d ono tfu lly ut ili ze the read -w r i te c o st d iff er -e n ce . C FL R U[1] ma in ta in sa win d ow on L R U queue .T he c l ea n pages in the win d ow will be e vi cted first e v e ni fthe y are much h o tter tha n the d i rt yon es . T h i sma y deter io rate the ov era ll perf o rma n ce because s o me o bs ol ete d i rt y pages te n dt oo ccup y the prec io us ma in mem o r y res o urce f o ra lon gt i me .WS R [ 2 ] [3] (w r i te seque n t i a l re o rder ) based meth o ds i mpr ov ethee xi st in gd i sk -o r i e n ted cache rep l aceme n tmeth o ds b y g ivin ga no ther cha n ce t o the d i rt y pages w he n the y are se l ected as the vi ct i m .B ut actua lly, h ow ma ny  X  cha n ces  X  sh o u l dbe g iv e n t o the d i rt y pages i sdepe n ded on the o perat ion c o st .In esse n ce , these access l ate n c yo f fl ash i s only asma ll fract ion o fmag n et i cd i sk ,w hat dema n ds f o r low c o mp l e xi t y onlin erep l aceme n ta l g o r i thm .Un f o rtu n ate ly, as far as w e k now, non e o fe xi st in gse l f -tu nin g appr o aches i sO (1) in the wo rst case . In th i spaper ,w epr o p o se a nov e l cache rep l aceme n tstrateg y, n amed A dapt iv e C o st Aw are cache Rep l aceme n t (A C A R ), based on th i sread -w r i te c o st m o de l. A C A Rpr ovi des a n equa lo pp o rtu ni t y f o rc l ea n a n dd i rt y pages t o c o mpete wi th each o ther acc o rd in gt oo perat ion c o st .To ach i e v eth i s ,w ema in ta in t wo separate wi th the wo rk lo ad e vol ut ion a n d o perat ion c o st . Our a l g o r i thm has the f ollowin g mer i ts :1)Ano perat ion c o st a w are cache rep l aceme n tstrateg y, 2 )Dyn am i ca l ad j ust in g structure t o the wo rk lo ad ,3) O (1) t i me c o mp l e xi t y f o r each access in the wo rst case , a n d4 )An e x te n s ion t o supp o rt h o tdatarec o g ni t ion.
T he rest o fth i spaper i s o rga ni zed as f ollow s :S ect ion 2 in tr o duces backgr o u n d k nowl edge ab o ut fl ash mem o r y a n dre l ated wo rk .InS ect ion 3, a n e w cache rep l aceme n tmeth o d A C A Ra n d i ts e n ha n ceme n t A C A R + are prese n ted in deta il wi th a n a ly s i s . E x per i me n ta l resu l ts are rep o rted in S ect ion 4 , a n dfi n a lly w e c on c l ude the paper in S ect ion 5. 2.1 Flash Memory Fl ash mem o r yi sa n EE P RO MFl ash mem o r yw h i ch c o mes in t o t wo fl a vo rs N OR a n d NAND. NAND fl ash i s appr o pr i ate f o rdatast o rage w h il e N OR fl ash i sde -s i g n ed f o rc o de e x ecute -in-p l ace .H e n ce ,w ef o cus on NAND fl ash in th i spaper . T here are t wo k in ds o f NAND, SL C (Sin g l e -L e v e l Ce ll) a n d ML C (M u l t i-L e v e l Ce ll). ML Chas l arger capac i t y c o mpared wi th SL Catthee x pe n se o fh i gher access l ate n c y, m o re e n erg y c on sumpt ion a n d low er stab ili t y. T he read a n d w r i te u ni t o f NAND i s on e page ( t y p i ca lly 2 K). T he page wi th data ca nno tbere w r i tte n bef o re erased e v e ni f i t i spart i a lly used . Erase perf o rms in a on e -t i me -on e -b lo ck ma nn er ,w h i ch c on ta in s 6 4 o r 1 28 pages t y p i ca lly. F urtherm o re ,only seque n t i a l page usage i s supp o rted in ab lo ck .Li m i ted (10000-100000) t i mes o feraseca n be e n dured bef o re wo r no ut .T ab l e 1[ 4 ] ill ustrates the access l ate n c yo f SL Ca n d ML C wi th mag n et i cd i sk as c o mpar i s on. F r o mthetab l e , se v era lI O character i s -t i cs ca n be o bser v ed as f ollow s .
 Low access latency. A s a pure e l ectr i ca l de vi ce ,fl ash mem o r y ca n resp on dt o Asymmetry of IO. T he w r i te perf o rms se v era l t i mes s low er tha n read .In 2.2 Related Work T he cache rep l aceme n thasbee n ah o tt o p i cf o rse v era l decades in the database c o mmu ni t y as w e ll as in the c o mputer arch i tecture area .L R U(L east Rece n t ly U sed ) a n d LFU (L east F reque n t ly U sed ) are t wo c l ass i c appr o aches f o rcache ma n ageme n t .L R U f o cuses on rece n c yin f o rmat ion w h i ch reacts qu i ck ly t o the wo rk lo ad e vol ut ion w h il e LFU rec o rds freque n c yw h i ch ca n figure o ut the lon g -term patter no f access .A fter that , ma ny appr o aches tr y t o c o mb in ethemer i ts o f L R U a n d LFU [5] [6] [ 7 ][ 8 ]. 2Q [9] i s a breakthr o ugh in cache rep l aceme n t strateg y. M a ny f ollowin g  X  ad v a n ced  X  appr o aches are c on ducted as i mpr ov eme n ts based on 2Q . 2Q c on ta in st wo L R U queues , Q 1 a n dQ2 .T he pages accessed f o r the first t i me are he l d in Q 1; i fa ny page in Q 1i s refere n ced aga in, i t i s m ov ed in t o Q2 . E v er y e vi ct ion perf o rms on Q 1 first .In th i s w a y, 2Q ca n detect the h o t pages a n dh ol dthem in Q2 .LI R S [10], the a l g o r i thm in tegrated in t o MyS Q L, d ivi des pages in t oHI Ra n d LI Rc o rresp on d in gt o Q 1 a n dQ2 in 2Q . Diff ere n t ly, LI R S ad j usts the l e n gth o f HI R queue aut o mat i ca lly acc o rd in gt o the l east rece n t LI R .A RC [11] i sase l f -tu nin gstrateg ywi th o ut parameter .I t acc o mm o dates the l e n gth o fQ 1 a n dQ2 in 2Q d yn am i ca lly us in g in f o rmat ion o fa l read y e vi cted pages .T hese d i sk -o r i e n ted cache ma n ageme n tstrateg i es are des i g n ed t o ma xi m i ze the page h i trat io w h i ch ma yno tbesu i tab l ef o r fl ash -based s y stems wi th d iff ere n t I/ O character i st i cs , th o ugh the sk ill sthe y used are he l pfu l t o cache des i g nonfl ash mem o r y.

M a ny wo rks ha v ebee n d on e on de v e lo p in g fl ash -spec i fic cache ma n ageme n t schema .FAB[1 2 ] a n d BPL R U[13] are t wo b lo ck l e v e l cache ma n ageme n tstrate -g i es .How e v er , the y are b o th des i g n ed f o r fl ash de vi ce embedded cache . C FL R U [1] ma in ta in sa win d ow on the L R U e n d o f L R U Queue .In th i s win d ow, c l ea n pages are e vi cted first .Di rt y pages will be e vi cted u nl ess there d o es no te x-i st a ny c l ea n page in the win d ow. How e v er , s o me c ool d i rt y pages ma yo ccup y cache f o ra lon gt i me w h i ch decreases the e ff ect iv es i ze o fcache .Ani mpr ov eme n t o fC FL R Uwi th d yn am i c win d ow-s i ze i sa l s o me n t ion ed , but i td o es no ts olv e th i spr o b l em in esse n ce .F urtherm o re , the d yn am i c win d ow-s i ze C FL R Ui s no t O (1) in the wo rst case .LI R S-WS R [3] a n d L R U-WS R [ 2 ] are s i m il ar meth o ds based on LI R S a n d L R U separate ly. T he y g iv eh i gher pr io r i t y t o d i rt y pages b y pr ovi d in ga no ther cha n ce t o them on ce the y are se l ected as vi ct i m .B ut th i s meth o dacts in afi x ed ma nn er e v e nw he n ad o pted on ade vi ce wi th d iff ere n t o perat ion c o sts .In add i t ion, WS Rmeth o ds are no t wo rst -case O (1) a l g o r i thm e i ther .A c o st a w are a l g o r i thm i spr o p o sed based on C A R [1 4 ]in[15].How e v er , th i smeth o d i sdes i g n ed f o rm o b il e embedded s y stems a n dc on s i ders c o mpressed pages ma inly. In add i t ion, i tst o res o perat ion s w h i ch makes i ts low t o determ in e vi ct i m . C FD C [16] i mpr ov es C FL R U b y c l uster in gthed i rt y pages in the same b lo ck a n de vi cted them as a batch . Rece n t ly-E vi cted -Fi rst B u ff er Rep l aceme n t Poli c y[1 7 ] uses s i m il ar tech nolo g y t oi mpr ov es the ov era ll perf o rma n ce .B ut th i stech ni que i s o rth o g on a l t oo ur wo rk as the same meth o dca n be in tegrated in t oA C A Reas ily. Fl ashCache [1 8 ] emp loy s fl ash as a part o fma in mem o r y f o r e n erg y-sa vin g purp o se w h i ch i s no tthem o t iv at ion o f o urs . 3.1 General Idea T he ke yi dea o f A C A R i s v er i ficat ion a n dse l f -tu nin g .A C A Rca nl ear n the best p ool s i ze aut o mat i ca lly fr o mthe  X  m i stakes  X  caused b y pre vio us dec i s ion s .T here -f o re ,w eh ol dpre vio us dec i s ion sf o rm i stake detect ion. Al th o ugh the cache m i ss has a l read yo ccurred , th i se x per i e n ce ca n be ad o pted as a t i pf o r future dec i-s ion s .Wi th the assumpt ion o f access patter n stab ili t y, the k nowl edge l ear n tca n pre v e n tthesamek in d o fm i stake tak in gp l ace aga in.

To ach i e v eth i s ,A C A R o rga ni zes a ll the cache -res i de n t pages in t o t wo L R U queues n amed CR ( C l ea n Res i de n t ) a n d D R (Di rt y Res i de n t )w h i ch c on ta in c l ea n a n dd i rt y pages separate ly. B es i des , a no ther t wo c o rresp on d in g queues C N R ( C l ea nNon-Res i de n t ) a n d DN R (Di rt yNon-Res i de n t ) are used t o keep the non-res i de n t pages that are e vi cted fr o mCRa n d D R .In fact , the pages e vi cted act as the dec i s ion smadeb yA C A R .I fapre vio us ly e vi cted page in non-res i de n t queue i s refere n ced in the future ( th i s i sacachem i ss that w ed ono te x pect ), th i smea n sthe A C A Rsh o u l dha v epa i dm o re atte n t ion t o the c o rresp on d in g queue .H e n ce ,A C A Rperf o rms a n ad j ustme n tb y a llo cat in gm o re cache space t o th i s queue .Fo re x amp l e ,i fa n access t o a page p 1i sperf o rmed w h i ch i s in C N R queue , th i s i sdefi ni te ly am i ss as a ll the pages in C N Rare non-res i de n t .T hus , m o re space i sass i g n ed t o CR t o tr y t o pre v e n tthesameth in ghappe nin g aga in. T he c o sts o freada n d w r i te o perat ion sareusedt o dec i de h ow much space i s a llo cated t o the queue .

W e determ in ethespacea llo cated in each case b y a n a ly z in gthe lo ss caused b y the w r on ge vi ct ion. T here are f o ur cases in t o ta l. 1. Read on C N R .T h i s causes a page read .I f the page i sres i de n t , read ca n be 2 . Read on DN R .T h i s i sthesame wi th case 1. 3. W r i te on C N R .Sin ce a ll the read o perat ion sarec on s i dered in the t wo cases 4 .W r i te on DN R .I f the page i sres i de n tthe n, these t wo w r i te ca n be merged O n ce access patter n cha n ges , cache m i ss in g i s li ke ly t oin crease acc o rd in g ly. C on seque n t ly, ad j ustme n t o f A C A R i sc on t in u o us ly tr i ggered .T he l e n gths o f CR a n d D Rbec o me acc o mm o dated t o the n e wwo rk lo ad patter n gradua lly. T heref o re , the A C A R i sase l f -tu nin gstrateg y. 3.2 Implementation A s ill ustrated in figure 1, a ll the pages res i de n t in cache are reser v ed in CR a n d D R in the w a y that CR st o res the c l ea n pages w h il e D Rst o res the d i rt yon es . T hus ,w ea lw a y sha v e that the t o ta l s i ze o fCRa n d D R i s no t l arger tha n cache s i ze .Aw r i te on CR page will cause th i s page m ov ed t oD R .Bo th CR a n d D R act in L R U ma nn er .A C A Ra l s o ma in ta in st wo au xili ar yFIF O queues n amed C N Ra n d DN R .I f a page i se vi cted fr o mCR o r D R ,i ts ID i srec o rded in t o C N R o r DN Rc o rresp on d in g ly. How e v er , the c on te n t o f that page i s freed fr o mcache . Sin ce only page ID sarec on ta in ed in C N Ra n d DN R ,only a li tt l efract ion o f mem o r yi srequ i red a n dha v e li tt l ee ff ect on the ov era ll perf o rma n ce o fcache .
Av ar i ab l e n amed CR L E ( CR L e n gth E x pected )o f flo at t y pe i sma in ta in ed b yA C A R w h i ch in d i cates the pr o per e x pected l e n gth o fCR . O n ce e vi ct ion happe n s ,i factua ll e n gth o fCRe x ceeds CR L E , a page will be se l ected fr o mCR as the vi ct i mb yL R U ma nn er . Other wi se , a page in D R i sse l ected .No te that the t o ta ll e n gth o fCRa n d D Requa l scaches i ze w he n e vi ct in g , s o there i s no n eed t o keep D R L Ef o r D R queue .I fa ny page i sh i t on C N R o r DN R , s o me ad j ustme n t i sperf o rmed on CR L E .InA C A R ,w eassumethec o st o freadas 1, a n dthec o st o f w r i te i s no rma li zed as Ratio = writeCost/readCost . CR L E i s Algorithm 1 . Acquire free page procedure in creased b y1i fah i ttakesp l ace on C N R , decreased b y1on areadh i t on DN R , a n d decreased b y Rat io on a w r i te h i t on DN R .In th i s w a y, d iff ere n t o perat ion s are treated pr o per ly in A C A R .

A scachema n ageme n tmeth o ds usua lly d o, w e keep a hash tab l e o f pages in mem o r y t o acce l erate search in g .Poin ters t o queue e n tr i es o f the page as w e ll as ap oin ter t o the page data i ssa v ed in the hash tab l e .T he c on crete a l g o r i thms are g iv e nin a l g o r i thm 1 a n da l g o r i thm 2 .

W ed i scuss h ow t o ch oo se the queue l e n gths o fC N Ra n d DN Rhere .Alon ger s i ze wo u l d in cur ad j ust in g o fCR L Equ i ck ly t o he l p A C A Rt o be adapted t o wo rk lo ad cha n ge qu i ck ly but t oo lon g o fC N Ra n d DN R will ma in ta in ma ny o bs ol ete messages that m i s l ead the A C A R .T he l e n gth i satu nin g parameter in o ur strateg y, a n d w e will prese n te x per i me n ta l resu l ts on th i sfact o r .T he same s i ze i sass i g n ed f o rC N Ra n d DN R , because the w e i ghts o f w r i te a n dread o perat ion sha v ea l read y bee n re fl ected on Rat io.

T he t i me c o mp l e xi t yo f A C A R i sO (1) in the wo rst case , s oA C A R i s v er y su i tab l ef o r onlin epr o cess in g . 3.3 Algorithm Analysis T he v ar i ab l es used in th i s sect ion i s li sted in tab l e2 .
 Proposition 1. Under a stable IO pattern, when cache is full, increment of l cr will cause CRLE tends to decrease and vice versa.
 T he  X  stab l e I O patter n X  mea n s the access p o ss i b ili t yo f pages c on f o rm t o a stab l ed i str i but ion. No te that the decreme n t o fCR L Emea n s pages in CR are m o re eas ily t o be se l ected as vi ct i m .T h i s will l ead t o a decreme n t o f l cr w h i ch will cause in creme n t o fCR L E in tur n. Fo rapart i cu l ar I O patter n, these t wo phases ca n arr iv eataba l a n ce s i tuat ion as the f ollowin gpr o p o s i t ion sh ow s . Algorithm 2 . ACAR algorithm Proposition 2. Under a stable IO pattern, ACAR will come to a stable situa-tion which approximately has or either l wr or l cr is 0.Assume ACAR tends to evict the page with lower weight w.
 T h i spr o p o s i t ion sh ow s A C A Ruses w e i ghted freque n c y t o determ in e w h i ch page t o be e vi cted .F urtherm o re , the o perat ion c o st i sre fl ected in w e i ght .T he pr oo fs t o these pr o p o s i t ion sare o m i tted due t o the space li m i tat ion. 3.4 Enhanced ACAR with Hot Data Detection Awi se cache ma n ageme n tp oli c y sh o u l dd i st in gu i sh h o tdatafr o mc ol d .Fo r e x amp l e , sca nnin g o fa l arge fi l e will e vi ct f o rmer detected h o t pages o ut o fthe cache in L R U-based p oli c y. To s olv eth i spr o b l em , s o me e xi st in g fl ash -o r i e n ted strateg i es such as BPL R U[13] a n dC FD C [16] in tegrate sca n detect ion appr o ach . E n ha n ced A C A R n amed A C A R + adds a no ther queue S R (Sin g l e Li st ) t o dea l wi th th i spr o b l em .A sdem on strated in figure 2 , the page refere n ced f o r the first t i me i sst o red in the s in g l e li st .I f page in s in g l e li st i s accessed aga in, the ni t will be e l e v ated in t o trad i t ion a lA C A Rpart .In add i t ion, vi ct i mse l ect ion i s only perf o rmed on s in g l e li st .T hus ,on ce sca n takes p l ace ,only pages in s in g l e li st will be e vi cted .T he pages in A C A Rpartarepr o tected . In th i s sect ion, w ec on duct a trace -dr iv e n s i mu l at ion in c l ud in gart i fic i a l a n d rea l app li cat ion wo rk lo ads .W eusethet o ta lI Ot i me t o the fl ash in sec on ds i mp l eme n ted f o rc o mpar i s on. All e x per i me n ts are ru non a2 . 4G H z In te l Quad C PU wi th 2 G Bo fph y s i ca l mem o r y. T he o perat in gs y stem used i s Win d ow s7 , a n dthes i mu l at ion i sde v e lo ped in Vi sua lS tud io 2 00 8e nvi r on me n tus in gC #. 4.1 Stationary Reference Probability Distribution A s yn thet i c wo rk lo ad i sad o pted in th i s sect ion w h i ch has a l s o bee n used in [9,5]. W ege n erated ra n d o m refere n ces t o 1000 pages wi th a Z i pfia n d i str i but ion. T he parameter i sc on figured t o s i mu l ate 8 0-2 0 a n d4 5-2 0 d i str i but ion s separate ly. In T he n umber o fread i sab o ut 65% o fthet o ta l. Win d ow s i ze o fC FL R Ui sfi x ed t o 30% o fcaches i ze as rec o mme n ded in [1].

A tthebeg innin g ,w esetthe o perat ion c o sts as ML C in tab l e 1. T he resu l ts are g iv e nin figure 3. C FL R U a n d L R UWS Re x ceed L R U s in ce the y a llo cated h i gher pr io r i t y t o d i rt y pages .A C A Rperf o rms better tha n C FL R U a n d L R UWS Ras i tca n d yn am i ca lly ad j ust t o the wo rk lo ad a n d o perat ion c o st .Wi th the he l p o fh o t page detect ion, A C A R +o utperf o rms a ll the o ther strateg i es in 8 0-2 0 d i str i but ion. Sin ce the lo ca li t yin 4 5-2 0 d i str i but ion i s no tas o b vio us as 8 0-2 0 d i str i but ion, i t i shardert o pred i ct page accesses in 4 5-2 0 d i str i but ion. C on se -que n t ly, each strateg y perf o rms wo rse on 4 5-2 0 d i str i but ion.
 W erec on figure o perat ion c o sts t o s i mu l ate SL C .A s ill ustrated in figure 4 ( a ), A C A Rs a l s o e x ceed o ther strateg i es .I tca n be o bser v ed in figure 4 ( b ) that the n umber o f w r i te o perat ion s in SL C i s l ess tha n that in ML C .B ecause the w r i te o perat ion s in SL Care no ts o cr i t i ca l as that in ML C ,A C A Rad j usts the space a l-lo cated t o c l ea n a n dd i rt y pages t o ach i e v e better ov era ll perf o rma n ce .How e v er , C FL R U a n d L R UWS Rca nno tbea w are o fth i s o perat ion c o st cha n ges .

W e n e x t inv est i gate the e ff ects o f parameters o f o ur appr o ach .F r o m figure 5( a ), w eca n see that w he n the l e n gth o fC N Ra n d DN Raread j usted , there i s no s i g ni fica n tcha n ge on the ov era ll perf o rma n ce .T he A C A R i s in se n-s i t iv et ol e n gth o f N R queues .In the f ollowin ge x per i me n ts ,w ea lw a y s keep l e n gth o fC N Ra n d DN Rasha l f o fcaches i ze .Fi gure 5( b ) sh ow sthere l at ion bet w ee nS R l e n gth in A C A R + a n d i ts perf o rma n ce .To ta l c o st first ly decreases a n dthe nin creases wi th in creme n t o f S R .T h i sca n be eas ily u n derst oo ds in ce A C A R + perf o rms c lo ser t oL R Uwi th l arger S Ra n dperf o rms c lo ser t oA C A R wi th sma ll er S R .W eset S Rt o 10% o fcaches i ze in the f ollowin ge x per i me n ts . 4.2 Experiments on Real Trace Fo r o ur e x per i me n ts ,w ec oll ect traces o f TP C -Cbe n chmark ru nnin g on Po st -gre S Q L 8 .3.5 a n d Lin u x ker n e l c o mp il eus in gGCC4 .1, a n dthe n rep l a y the trace wi th o ur s i mu l at o r .T he data set o f TP C -C i s2G B, a n d page s i ze o f Po stgre S Q L i s8 KB. T he v ers ion o f Lin u x ker n e li s2 .6. 27 . Cache s i ze ra n ges fr o m 10000 t o 2 0000 in e x per i me n t on TP C -Ctrace .L R Ui s o m i tted as C FL R U a n d L R UWS R are i ts i mpr ov eme n ts a n dsh ow better perf o rma n ce in pre vio us stud y. W esetthe c o sts as SL C in th i spart ,w h il eresu l ts are s i m il ar t oML C .A sdem on strated in figure 6( a ), A C A R + perf o rms much better tha no ther a l g o r i thms .T h i s i sbe -cause the TP C -C i sm ix ed wi th read a n dupdate o f the data i tems , a n d A C A R meth o ds a llo cate pr o per w e i ght t o the c l ea n a n dd i rt y pages .In add i t ion, the A C A R + ca n d i st in gu i sh c ol d pages a n d has the best perf o rma n ce .

T he w r i te patter no f Lin u x ker n e l c o mp il e i sma inly seque n t i a l. In th i scase , keep in gd i rt y pages in cache i s no ta wi se dec i s ion because the y will no t li ke ly t o be w r i tte n aga in. T hat i s w h y C FL R U a n d L R UWS Rperf o rm wo rse .B ut A C A R + ca n dea lwi th th i spr o b l em eas ily s in ce a ll the seque n t i a l accesses will only o ccup y cache pages in S R queue .T he resu l t i s ill ustrated in figure 6( b ). T he n e w features o f fl ash mem o r y p o se great cha ll e n ges f o rcachema n ageme n t p oli c y. A s y mmetr i c I O speed requ i res a c o st a w are strateg y, a n d low access l a -te n c y sets c lo se restra in t on the c o mp l e xi t yo fthestrateg y. In th i spaper , a nov e l cache rep l aceme n tp oli c yn amed A C A R i spr o p o sed t o dea lwi th th i spr o b l em . A C A Rd ivi des the cache in t o t wo p ool sf o rc l ea n a n dd i rt y pages separate ly, a n d d yn am i ca lly ad j usts the s i ze o fthemacc o rd in gt o s y stem wo rk lo ad a n d o pera -t ion c o st .In add i t ion, A C A R i sa wo rst -case O (1) a l g o r i thm su i tab l ef o r on-lin e pr o cess in g .A C A R + further i mpr ov es the A C A Rb y add in ga no ther queue f o r h o t data detect ion.

N e x tstep ,w ec on s i der t oin tegrate s o me ad v a n ced d i sk -o r i e n ted cache rep l ace -me n tstrateg i es , e . g ., LI R S, wi th o ur A C A Rt o further b oo st the perf o rma n ce . W earea l s oin terested in wo rk in g on b lo ck -l e v e lA C A R w h i ch c l usters d i rt y pages in on eb lo ck t o gether t o acce l erate w r i te -back perf o rma n ce .
 T h i s research w as supp o rted b y the gra n ts o f N atura lS c i e n ce Fo u n dat ion o f Ch in a (No. 60 87 3063).

