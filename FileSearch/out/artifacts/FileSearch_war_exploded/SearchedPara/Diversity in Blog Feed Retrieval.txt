 Blog distillation (blog feed retrieval) is a task in blog re-trieval where the goal is to rank blogs according to their recurrent relevance to a query topic. One of the main prop-erties of blog feed retrieval is that the unit of retrieval is a collection of documents as opposed to a single document as in other IR tasks. This collection retrieval nature of blog distillation introduces new challenges and requires new in-vestigations specific to this problem.

Researchers have addressed this problem by considering a wide range of evidence and information resources. However, previous work has not studied the effect of on-topic diversity of blog posts in blog relevance. By on-topic diversity of blog posts we mean that those posts that are about the query topic need to have high diversity and cover different sub-topics of the query.

In this study, we investigate three types of on-topic di-versity and their effect on retrieval performance: topical di-versity, temporal diversity and hybrid diversity. Our exper-iments over different blog collections and different baseline methods show that on-topic diversity can improve the per-formance of the retrieval system. Among the three types of diversity, hybrid diversity, that considers both topical and temporal diversities, achieves the best performance. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Blog Retrieval, Diversity, Novelty
Amongst all the information resources, the web is becom-ing the main source for providing new and useful information to users. Everyday, people receive up-to-date information via web-based services such as news web sites, social net-works or blogs. User generated content, like blogs, plays an important role in this phenomenon. Millions of people write about their experiences and express their opinions in blogs providing a rich source of information.

Considering this huge amount of user-generated data and its specific properties, designing new retrieval methods is necessary to facilitate addressing the different types of in-formation needs that blog users may have. Studies show that one of the main categories of blog-related queries is about finding blogs that deal with a specific topic of interest [12]. These queries, which are called concept queries, are the focus of a blog distillation system [9]. The blog distillation task (also known as blog feed retrieval) 1 is concerned with ranking blogs according to their recurring central interest to the topic of a user X  X  query. In other words, our aim is to discover relevant blogs for each topic 2 that a user can add to his reader and refer to in the future [10].

A relevant blog is expected to regularly publish posts about the topic. When it comes to blog relevance estima-tion, the usual emphasis is on the number of topic-related posts that a blog publishes. Nevertheless, the amount of new information that each of these posts add to the blog is another influential factor. If a blog publishes repetitive information with low novelty, it would be less interesting for the user to follow. In our diversity-based methods, we leverage this property and penalize those blogs that have low diversity in their posts related to the topic.

There are different scenarios where considering the diver-sity might help the retrieval performance. Table 1 shows some real examples of blogs that were affected by one of our diversity-based methods. The examples are part of our experiments on two selected topics of TREC09 and are com-pared to the best performing baseline method. We can see that by penalizing those blogs that have low diversity, we can filter out non-relevant blogs such as spam blogs or blogs that publish similar posts multiple times. On the other hand, it can help us to retrieve those relevant blogs that have high diversity among their posts even though they might have low initial score for the query.

In this paper, we discuss how to add a measure of diversity to the existing blog retrieval methods and study the effect on retrieval performance. Our main aim is to answer the following questions::
We use words  X  X eed X  and  X  X log X  interchangeably
We use words  X  X opic X  and  X  X uery X  interchangeably Topic ID: 1107 Topic title: Mountain Climbing Example 1 Feed no: BLOG08-feed-1167752 Blog URL: http://hockeycrew.livejournal.com Blog title:  X  X  Smile Because I X  X  Confused X  them very similar.
 Its rank in the baseline method: 10 Its rank after applying diversity: above 100 (not retrieved) Example 2 Feed no: BLOG08-feed-1218342 Blog URL: http://playwintersports.blogspot.com Its rank in the baseline method: 61 Its rank after applying diversity: above 100 (not retrieved) Example 3 Feed no: BLOG08-feed-070681 Blog URL: http://himadventures.blogspot.com Blog title:  X  X rekking, Camping, Climbing And Traveling In Himalayas X  Its rank in the baseline method: above 100 (not retrieved) Its rank after applying diversity: 81 Topic ID: 1122 Topic title: Skiing Example 4 Feed no: BLOG08-feed-616929 Blog URL: http://justjetskis.blogspot.com Blog title:  X  X UST SKI RESOURCES X  with almost identical content.
 Its rank in the baseline method: 1
Its rank after applying diversity: above 100 (not retrieved)
The rest of the paper is organized as follows. In section 2 we review state of the art methods of blog retrieval. Section 3 describes the methods that rely on post level evidence ag-gregation for calculating blog relevance. Those methods are the baselines for our experiments and our diversity methods are developed based on them. Section 4 explains our pro-posed diversity-based methods. Experimental results over different data sets are discussed in section 5. Finally, we conclude the paper and describe future work in section 6.
Research in blog distillation started mostly after 2007, when the TREC organizers proposed the task as part of the blog track. Researchers have employed different approaches from related areas such as ad-hoc search, expert search, and resource selection in distributed information retrieval.
The simplest models use ad-hoc search methods for find-ing blog relevant to a specific topic. They treat each blog as one long document created by concatenating all of its posts [3, 4, 13]. These methods ignore any specific property of blogs and usually use standard IR techniques to rank blogs. Despite their simplicity, these methods perform fairly well in blog retrieval.

Some other approaches have been applied to blog retrieval based on expert search methods. Expert search is a task in the TREC Enterprise Track where systems are asked to rank candidate experts with respect to their predicted expertise about a query, using documentary evidence of the expertise found in the collection [14]. Based on the similarity between blog distillation and expert search, some researchers have adapted expert retrieval methods for blog retrieval [1, 9]. In these models, each post in a blog is seen as evidence of blog interest in the query topic. Balog et al. adapt two language modeling approaches of expert finding and show their effectiveness in blog distillation [1]. MacDonald et al. use data fusion models to combine post-based evidence to compute a final relevance score of the blog [9].

Other researchers have employed resource selection meth-ods from distributed information retrieval for blog retrieval. In distributed information retrieval, the cost of searching all servers for each query is considered prohibitively expensive, so server selection algorithms are used [5]. Queries are then routed only to servers that are likely to have many relevant documents for the query. Elsas et al. deal with blog dis-tillation as a resource selection problem [4]. They model each blog as a collection of posts and use a language mod-eling approach to select the best collection. Similar work is described by Seo et al. , which they call Pseudo Cluster Selection [13].

None of the previous work paid attention to the diversity of blog posts in their retrieval methods. Previously, the co-hesiveness of a blog was assumed to be a positive sign of blog relevance [4, 13, 9, 6]. However, diversity, as a neg-atively correlated measure to cohesiveness, has never been studied. In the following, we consider the diversity of blog posts, its effect on the retrieval systems, and its relation with the cohesiveness of the blog.
In general, most of the blog distillation methods can be seen as an aggregation of the post-level relevance evidence to calculate the blog-level relevance score. The following are the main existing aggregation methods that we use as baselines in our experiments:
All the mentioned methods have one parameter as the size of R ( q ) which we call n . This parameter defines the size of the initially retrieved set of posts for the query that will be inputs of the aggregation methods. The value of n is learnt using a training set which will be described in more detail later. The PCS method has two more parameters that are assigned as follows:
The relation between posts in each blog can give us use-ful information about the blog. Previous studies considered cohesiveness as a way to capture how posts in the blog are similar to the blog in general [4, 13, 9]. In these studies, a blog with higher cohesiveness and thus less diversity is considered a better blog to retrieve. Elsas et al. define the centrality of a post as its similarity to the blog as a whole. They assume that if the retrieved posts from a blog have high centrality, that blog is a better candidate for retrieval [4]. Seo and Croft penalize those blogs that have high di-versity among their posts [13]. Defining the goal of blog retrieval system to retrieve topic-centric blogs, they assume that blogs with high diversity are not topic-centric and thus should be penalized. MacDonald and Ounis define similar measures to retrieve blogs with focused interests [9]. They also consider temporal distribution of posts to retrieve blogs with recurring interests.

In contrast to previous work where all the posts of the blog are used for estimations, we focus only on those posts that are about the query topic. While diversity of a blog as a whole might be negative evidence for blog relevance, we assume that on-topic diversity is an asset. In other words, we assume that a relevant blog should have a high coverage over sub-topics and thus should have a high diversity among posts that it publishes about the topic.

We define three types of diversity over the posts and inves-tigate their effectiveness on performance of a blog retrieval system:
In the following we discuss each of the methods in more detail.
First we study topical diversity among the posts of each blog. Blog distillation queries tend to be more general than normal web queries and thus have a wider range of sub-topics [4]. We assume that posts that are retrieved from each blog for the query should have high diversity in order to cover different sub-topics. We want to investigate how this on-topic diversity of posts can affect the relevance of a blog to the query.

In order to test if the diversity of blog posts is an impor-tant factor in the relevance of blogs, we carry out preliminary experiments on the Blog08 collection. In these experiments, we assume that higher similarity of blog posts indicates less diversity among them. This assumption is consistent with previous work on diversification [2].

For each query, we first retrieve the top n posts using a traditional retrieval method. Then for each blog that has more than one post in the retrieved set, we calculate the average similarity between its retrieved posts, which we call On-topic Intra-feed Similarity (OIS):
The higher the OIS value, the less diverse is the feed with respect to the query. We use cosine similarity as the simi-larity measure between two posts.

Figure 1 shows the distribution of OIS for relevant and non-relevant blogs. It can be seen that non-relevant blogs are more likely to have high OIS values. The mean of OIS for relevant blogs is 0.43 compared to 0.50 for non-relevant blogs. Based on the Welch two sample t-test, the difference between the mean values is statistically significant with a p-values equal to 2.6e-16 . This shows the possibility of us-ing the diversity of posts for discriminating between relevant and non-relevant blogs and consequently having a better re-trieval system.

In figure 1, we use the top 2000 posts for each topic. Simi-lar behavior has been observed for a smaller number of posts. However, it is possible that with an increasing number of re-trieved posts, we retrieve more posts for each blog and we end up with less diverse relevant blogs or more diverse non-relevant blogs. In order to test this possibility, we run the same analysis with the top 15000 posts for each query. Fig-ure 2 shows the outcome of this experiment. The mean of OIS values for relevant blogs is 0.34 compared to 0.42 for non-relevant blogs. The difference between the mean values is statistically significant with the p-value less than 2.2e-16 .
As we can see, the OIS values decrease with increasing numbers of posts. However, the difference between relevant and non-relevant blogs still exists. This is quite surprising, since we expect that by retrieving more posts, we increase the chance that non-relevant blogs will have a more diverse set of retrieved posts.

The per-topic analysis in figure 3 shows the difference more clearly. This figure shows the average of OIS values Figure 1: Distribution of On-topic Intra-feed Similarity( OIS ) using top 2000 retrieved posts. for relevant and non-relevant blogs for each query topic. For clarity, topics are sorted by the average OIS of their non-relevant feeds. As can be seen for most topics, non-relevant feeds have higher similarity among their posts compared to the relevant ones.

To capture the diversity of blog posts, we adapt a variation of Maximal Marginal Relevance (MMR) [2]. The goal of MMR is to maximize diversity of retrieved set of documents. It selects documents that are more similar to the query and less similar to already retrieved documents: where R is an initial set of documents and S is the set of already retrieved documents.

Similar to the MMR method, our diversity detection method exploits the fact that similar documents are less diverse, thus it penalizes posts that are similar to other posts in the blog. In other words, only information of a post that does not appear in other blog posts can contribute to blog relevance: where score ini ( p i ,q ) is the initial score of post p query q . S is the set of posts that belong to the same blog and have higher scores than p i . This method assumes that based on its similarity to other posts. The parameter  X  con-trols the importance of the post novelty in its score, which can vary for different similarity methods or different queries. sim topical captures the content similarity between the two posts and can be replaced by any similarity measure. We use cosine similarity, since it always has a value in [0 , 1] and does not need an extra normalization step: where tf ( w,p ) is the term frequency of the term w in the post p . When there is no similarity between a post and other blog posts that have higher score, the maximum of similarities will be zero. In this case, the diversity score of the post will be the same as its initial score and therefore all the relevance evidence of the post can contribute to the blog relevance score. In contrast, if there is another post very similar to the current post, then the cosine similarity will be close to one. As a result, depending on the value of  X  , the diversity score of the post can be close to zero. Therefore, the blog will not gain any relevance from that post even if the post has high query likelihood.

After obtaining new scores for posts, any existing aggre-gation method can be used to aggregate the new scores and calculate the score of blogs. Applying the diversity-based scores introduces a new parameter  X  that needs to be esti-mated.
In addition to the content of blog posts, temporal infor-mation is another important source of information that can be used by the retrieval system [8, 9]. Analogous to topical diversity, we can assume that a relevant blog should have a high temporal diversity among its published posts for the query. In other words, we expect that blog posts have high coverage over the temporal space and not be concentrated on specific time windows.

We employ a similar approach to the topical diversity where we penalize the posts that have high temporal sim-ilarity to other posts. To this end, we define a temporal similarity function between two posts as an un-normalized Gaussian function: where t i is the time-stamp of p i given in days. We can see that the temporal similarity has a value between zero and one. If the two posts are published in the same day their similarity will be one and the similarity will decrease when the temporal distance increases. Finally, we penalize post scores based on their temporal similarity:
Using this method, if the post is published around the same date as some other posts, it will contribute less to the blog relevance than a post which is published at a distant time. In other words, this captures the property of whether the blog posts are published all over the temporal space or if they are mostly published in some specific small time windows.

The temporal similarity function adds a new parameter  X  to the model which is the standard deviation of the Gaussian function.
Finally, we can consider hybrid measure of diversity that takes both topical and temporal diversities into account. Two possible cases in which temporal and topical diversi-ties can complement each other can be described as follows:
To consider these cases in our method, we define an hybrid similarity function as follows: where sim topical and sim temporal are calculated using for-mula 6 and formula 7 respectively. Similar to topical and temporal diversity scores in formulas 5 and 8, we penalize those posts that have high hybrid similarity with other posts.
We can see that in this method, we mainly penalize those posts that are published around the same date as other posts and also have very similar content to them. Thus, in any of the two mentioned scenarios where one of the similarities is high and the other one is low, the post will not be highly penalized and can still contribute to the blog relevance. We conduct our experiments over four years worth of TREC blog track data from the blog distillation task, in-cluding TREC X 07, TREC X 08, TREC X 09 and TREC X 10 data sets. The TREC X 07 and TREC X 08 data sets include 45 and 50 queries respectively and use the Blog06 collection. The TREC X 09 and TREC X 10 data sets use Blog08, a new collec-tion of blogs, and have 39 and 46 queries respectively. We use only the title of the topics as the queries.

The Blogs06 collection is a crawl of about one hundred thousand blogs over an 11-week period [10], and includes blog posts (permalinks), feed, and homepage for each blog. Blog08 is a collection of about one million blogs crawled over a year with the same structure as the Blog06 collection [11]. In our experiments we only use the permalinks component of the collection, which consist of approximately 3.2 million documents for Blog06 and about 28.4 million documents for Blog08.

We use the Terrier Information Retrieval system 3 to index the collection with the default stemming and stop-words re-moval. In all the methods, the language modeling approach using the Dirichlet smoothing has been used to score the posts and retrieve top posts for each query. Without further tuning, the Dirichlet smoothing parameter is set to 5000 [16].
We use the three blog retrieval methods discussed in sec-tion 2 as our baseline methods. We apply each of these methods on the language model scores and also on the three diversified scores calculated by our proposed methods.
Since TREC X 07 and TREC X 08 query sets share the same collection, we use one to tune the parameters for the other. We do the same for the TREC X 09 and TREC X 10 query sets that share the Blog08 collection. By fixing the parameters k and  X  in the PCS method and the Dirichlet smoothing parameter across all the methods, the remaining parameters to be tuned are the following:
Tables 2, 3, 4 and 5 show the performance evaluation of the methods over TREC X 07, TREC X 08, TREC X 09 and TREC X 10 respectively. The first three rows in each table represent the performance of baseline methods. The second three rows show the performance of the corresponding meth-ods based on the topical diversity scores. The third three rows show the performance of the methods using the tempo-ral diversity scores followed by the last rows that show the performance of the hybrid diversity scores.
 Statistical significance tests are performed using the paired T-test at 0.05 level of significance. The symbol  X  indicates that a diversity method has a statistically significant im-provement over its corresponding baseline. The symbols M and N show that the hybrid diversity method has a statis-tically significant improvement over the temporal diversity and topical diversity methods respectively. The bold val-ues in each column indicate the best performance for the corresponding evaluation measure.

As we can see in the tables, diversity-based methods gen-erally improve their corresponding baseline methods. In most cases, these improvements are at a statistically sig-nificant level. The temporal diversity methods are not as ef-fective as their topical diversity counterpart. However, when combined together, the resulting hybrid diversity methods http://ir.dcs.gla.ac.uk/terrier/ Table 2: Evaluation results for the implemented mod-els over TREC X 07 data set.
 Model MAP P@10 Bpref CombSum 0.2259 0.3844 0.2721 PCS 0.2695 0.4378 0.3115 SDM 0.2867 0.4444 0.3439 CombSum-topical 0.2506  X  0.4244  X  0.2859  X  PCS-topical 0.2901  X  0.4422 0.3184  X  SDM-topical 0.3168  X  0.4756  X  0.3667  X  CombSum-temporal 0.2612  X  0.4267 0.2840  X  PCS-temporal 0.2844  X  0.4911  X  0.3134 SDM-temporal 0.3023  X  0.4756  X  0.3539 CombSum-hybrid 0.2466  X  0.4333  X  0.2866  X  M PCS-hybrid 0.2961  X  M 0.4622 0.3197  X  M SDM-hybrid 0.3191  X  M 0.5156  X  MN 0.3622  X  M
Table 3: Evaluation results for the implemented mod-els over TREC X 08 data set.
 Table 4: Evaluation results for the implemented mod-els over TREC X 09 data set.
 Model MAP P@10 Bpref CombSum 0.1889 0.3154 0.2148 PCS 0.2093 0.3103 0.2279 SDM 0.2636 0.3821 0.2858 CombSum-topical 0.2180  X  0.3282 0.2297  X  PCS-topical 0.2196  X  0.3282 0.2374  X  SDM-topical 0.2888  X  0.4333  X  0.3091  X  CombSum-temporal 0.2087  X  0.3051 0.2187 PCS-temporal 0.2082 0.3103 0.2250 SDM-temporal 0.2759 0.3846 0.2909 CombSum-hybrid 0.2176  X  M 0.3282 M 0.2334  X  M PCS-hybrid 0.2224  X  M 0.3462  X  M 0.2387  X  M SDM-hybrid 0.2961  X  MN 0.4308  X  M 0.3125  X  M
Table 5: Evaluation results for the implemented mod-els over TREC X 10 data set.
 usually produce the best results. In some cases, combining temporal diversity with topical diversity results in a statis-tically significant improvement over each one of them.
An interesting observation is that the SDM method, as the strongest baseline, benefits the most from the diversi-fication. As a result, the SDM-hybrid method significantly outperforms the SDM method in most of the collections and evaluation metrics.

We previously mentioned that spam blogs are one cate-gory of non-relevant blogs that would be filtered using diversity-based methods. It is interesting to see what portion of blogs that are affected by diversity methods are in fact spam blogs. To this end, we manually checked non-relevant blogs that were initially retrieved by SDM and were removed from the ranked list after applying hybrid diversity measure. We chose ten random queries from the TREC X 09 query set and compared their ranked lists before and after considering di-versity. Among 106 non-relevant blogs that were removed from the ranked list, 27 of them (25%) were spam blogs and the rest were non-spam. This shows that considering diver-sity does not just filter out spam blogs, but also removes other non-relevant blogs from the ranked list. On the other hand, our examination shows that the method promotes rel-evant blogs in the ranking. For the examined queries, there were 30 new relevant blogs retrieved after applying diversity and only 6 relevant blogs were removed from the ranked list.
In order to test the robustness of proposed approaches, we analyze the sensitivity of their retrieval performance to the parameters. We analyze the results over the TREC X 09 query set, as an example of a large collection, and the TREC X 07 query set, as an example of a small collection. For simplicity, we only consider the SDM method and the corresponding diversity-based methods in this analysis. To study each of the parameters, we fix the other parameters with values that are learnt from the training set in the previous experiments.
Figures 4 and 7 show the effect of n , the number of initially retrieved posts, on the performance of retrieval systems. The diversity-based methods outperform the baselines at all the values of n . This confirms our analysis in section 4 that the difference between on-topic diversity of relevant blogs and non-relevant blogs does not change by increasing n . We can see that by increasing the number of posts, the performance increases and the difference of performances for values higher than 5000 are insignificant.

Figures 5 and 8 show the effect of  X  when we fix the val-ues of n and  X  . We can see that the performance of the hybrid and topical diversity methods generally increase by increasing  X  . In both collections, the best performance of these methods is achieved when  X  has a value close to one. This shows that the maximum penalty for those blogs that publish repetitive information produces the best results. On the other hand, temporal diversity is less robust and the per-formance decreases for  X  values higher than 0 . 5.

Finally, figures 6 and 9 show the effect of  X  on the perfor-Figure 4: Effect of the number of the top retrieved posts in the performance over TREC X 07 data set Figure 7: Effect of the number of the top retrieved posts in the performance over TREC X 09 data set mance of temporal and hybrid diversity methods. It can be seen that  X  is less influential on the performance and it has little negative effect when its value increases. It is interest-ing to see the relation between the size of the collection and the best value of  X  . While for the TREC X 07 collection the best performance is achieved when  X  is around 5, this value for the TREC X 09 collection is around 40.
So far, we showed that blog post diversity is a discrimina-tive feature in blog retrieval that can improve retrieval per-formance. In this section, we investigate a comparison be-tween blog post diversity and the previously proposed blog cohesiveness measures. The cohesiveness of a blog is as-sumed to show whether the blog focuses on a specific topic or not. While it is a reasonable assumption, the proposed methods in previous work did not show any positive effect on retrieval effectiveness:
For clarity of the paper we do not report this comparison here. Figure 10: Cohesiveness distribution of relevant and non-relevant blogs
All these works assumed cohesiveness to be a positive fea-ture of blog relevance and did not investigate if this is a valid assumption or not. In order to verify the validity of this assumption, we use the following cohesiveness measure to compare the relevant and non-relevant blogs: where V D ( b i ) is a virtual document created by concatenat-ing all the posts of b i . We use the cosine similarity measure for calculating sim ( p ji ,b i ), as the similarity between a post and a blog. This measure of cohesiveness compares the ini-tially retrieved posts of a blog to the blog as a whole. In other words, it captures the cohesiveness of the blog with respect to the topic. It is similar to those measures used in other works mentioned earlier [9, 4].

Figure 10 shows the distribution of cohesiveness values for relevant and non-relevant blogs in TREC X 09 data set. The value of n , the size of R ( q ), is set to 15000 for this analysis. The mean value of cohesiveness for relevant blogs is 0.56 and for non-relevant blogs, it is 0.55 . The difference be-tween the mean values is not statistically significant and the p-value of the Welch t-test is 0.66 . This shows that the co-hesiveness is not a strong discriminative feature and explains why adding cohesiveness did not improve the performance of the retrieval systems in the previous works.
 It is interesting to verify if cohesiveness is correlated with IOS , as defined in equation 4. If a blog has high cohesiveness, it is not surprising that it would also have high similarity among its posts and thus high IOS value. However if the top posts of a blog are very similar (high IOS ), one can not directly conclude that the blog has high cohesiveness. In order to examine such a correlation we calculate the Pearson correlation between the cohesiveness and the OIS values. The correlation is statistically significant with a value of 0.83 . The high correlation shows that blogs with high OIS are very likely to also have high cohesiveness.
In 2009, a more complex and refined version of the blog distillation task was introduced in TREC, named  X  X aceted Blog Distillation X  [11]. The new task, which was first intro-duced by Hearst et al. [7], aims to consider not only the blog relevance to the topic but also the  X  X uality aspects X  (facets) of the blog. For each query, a specific facet is determined and only blogs that satisfy that facet are considered to be relevant. In this section, we discuss the effect of diversity on the performance of the system for different facets. Different facets can be seen as different categories of blogs that users might search for. It is important to be able to decide for what type of information needs we can use diversity to get the maximum overall performance.

We use the introduced facets in the TREC X 09 and TREC X 10 data collections which include Opinionated vs. Factual, Per-sonal vs. Company and In-depth vs. Shallow facets [11]. Tables 6 and 7 compare the performance of the diversity method with the baseline method for each facet. Without further tuning, we use the same parameter values as the previous section.
 The statistically significant improvements are shown by  X  . Since each facet has very few queries, the statistical signifi-cance tests will be very sensitive and do not always show a difference. Thus we report also the percentage of improve-ment over the baseline method. The maximum improvement for each measure is shown in bold.

As we can see, diversity improves the performance of the system for almost all of the facets and evaluation measures. This shows that the effectiveness of diversity is not restricted to specific categories of topics. As a result, one can expect to have improvements by applying diversity for any type of information needs in blog search.

It is interesting to notice the improvement of P@10 for the in-depth queries which is the maximum among all the facets. For the in-depth queries, a relevant blog is expected to have in-depth thoughts and analyses about the topic [11]. As we previously saw in example 3 in table 1, one of the scenarios where diversity is effective is in retrieving blogs with such an in-depth property. The obtained improvements for in-depth queries confirm our previous observation. The results shows that a diversity-based method retrieves in-depth blogs at the top ranks and significantly improves the P@10 measure.
In this paper, we studied the effect of employing differ-ent diversity measures on blog retrieval. We showed that diversity is an important feature that can help in distin-guishing relevant blogs from non-relevant ones. We intro-duced three types of diversity and investigated their effect on the performance of the retrieval systems. Our experiments on standard blog retrieval collections showed improvements over different baseline methods.

We further showed that the common assumption of cohe-siveness is not an indicative feature of blog relevance and that is in fact the reason that there is no improvement ob-served in the previous work.

Finally, we investigated the effect of diversity on different types of queries and showed that diversity can be beneficial to all query types. Table 6: Effect of diversity on different facets over TREC X 09 data set.
 Facet Model MAP P@10 Bpref
Opinionated SDM 0.1153 0.1615 0.0998 SDM-hybrid 0.1236 0.1923 0.1132 (13 queries) (+7%) (+19%) (+13%)
Factual SDM 0.1749 0.1692 0.1570 SDM-hybrid 0.1788 0.1538 0.1661 (13 queries) (+2%) (-9%) (+5%)
Personal SDM 0.1840 0.2000 0.1384 SDM-hybrid 0.2201 0.2375 0.1756 (8 queries) (+19%)  X  (+18%) ( +26% )  X 
Official SDM 0.1876 0.1750 0.1537 SDM-hybrid 0.2319 0.1750 0.1819 (8 queries) ( +23% ) (0.0%) (+18%)
Indepth SDM 0.2723 0.2222 0.2624 SDM-hybrid 0.2872 0.2667 0.2526 (18 queries) (+5%) ( 20% )  X  (-3%)
Shallow SDM 0.1348 0.0889 0.1118 SDM-hybrid 0.1540 0.1056 0.1378 (18 queries) (+14%)  X  (+18%) (+23%) Table 7: Effect of diversity on different facets over TREC X 09 data set.
 Facet Model MAP P@10 Bpref
Opinionated SDM 0.1061 0.1800 0.1257 SDM-hybrid 0.1260 0.2000 0.1369 (15 queries) (+18%)  X  (+11%) (+8%)
Factual SDM 0.1028 0.1000 0.0820 SDM-hybrid 0.1190 0.1067 0.0985 (15 queries) (+15%) (+6%) ( +20% )
Personal SDM 0.1290 0.1533 0.1095 SDM-hybrid 0.1426 0.1467 0.1060 (15 queries) (+10%) (-4%) (-3%)
Official SDM 0.2057 0.1267 0.1697 SDM-hybrid 0.2274 0.1400 0.1928 (15 queries) (+10%) (+10%) (+13%)
Indepth SDM 0.2396 0.1250 0.2079 SDM-hybrid 0.2953 0.1625 0.2430 (16 queries) ( +23% )  X  ( +30% )  X  (+16%)
Shallow SDM 0.0833 0.1250 0.0818 SDM-hybrid 0.1003 0.1313 0.0838 (16 queries) (+20%) (+5%) (+2%)
One possible extension for future work is to apply the proposed approach to similar problems. It would be inter-esting to see if the diversity assumption holds for collection selection in distributed IR, expert search or user search in microblogs.

We are also interested in a more general framework for considering blog diversity that can be used in any existing blog retrieval method. So far, we have only applied diversity measures to the methods that are an aggregation of post-level scores. However, there are some methods that do not just aggregate post-level scores, such as the Blogger Model method [1] or two stage retrieval model [15]. It would be interesting to develop a framework to adapt diversity mea-sures for those methods as well.
This work was supported partly by the Center for Intelli-gent Information Retrieval and partly by the Swiss National Science Foundation. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the spon-sors.

We thank Jangwon Seo for his collaboration and com-ments while he was in CIIR. We also like to thank Armita Kaboli for her helpful discussions and comments. [1] K. Balog, M. de Rijke, and W. Weerkamp. Bloggers as [2] J. Carbonell and J. Goldstein. The use of mmr, [3] M. Efron, D. Turnbull, and C. Ovalle. University of [4] J. L. Elsas, J. Arguello, J. Callan, and J. G. Carbonell. [5] D. Hawking and P. Thomas. Server selection methods [6] J. He, W. Weerkamp, M. Larson, and M. de Rijke. An [7] M. A. Hearst, M. Hurst, and S. T. Dumais. What [8] M. Keikha, S. Gerani, and F. Crestani. Temper: A [9] C. Macdonald and I. Ounis. Key blog distillation: [10] C. Macdonald, I. Ounis, and I. Soboroff. Overview of [11] C. Macdonald, I. Ounis, and I. Soboroff. Overview of [12] G. Mishne and M. de Rijke. A study of blog search. In [13] J. Seo and W. B. Croft. Blog site search using [14] I. Soboroff, A. de Vries, and N. Craswell. Overview of [15] W. Weerkamp, K. Balog, and M. de Rijke. Blog feed [16] C. Zhai and J. Lafferty. A study of smoothing
 Blog distillation (blog feed retrieval) is a task in blog re-trieval where the goal is to rank blogs according to their recurrent relevance to a query topic. One of the main prop-erties of blog feed retrieval is that the unit of retrieval is a collection of documents as opposed to a single document as in other IR tasks. This collection retrieval nature of blog distillation introduces new challenges and requires new in-vestigations specific to this problem.

Researchers have addressed this problem by considering a wide range of evidence and information resources. However, previous work has not studied the effect of on-topic diversity of blog posts in blog relevance. By on-topic diversity of blog posts we mean that those posts that are about the query topic need to have high diversity and cover different sub-topics of the query.

In this study, we investigate three types of on-topic di-versity and their effect on retrieval performance: topical di-versity, temporal diversity and hybrid diversity. Our exper-iments over different blog collections and different baseline methods show that on-topic diversity can improve the per-formance of the retrieval system. Among the three types of diversity, hybrid diversity, that considers both topical and temporal diversities, achieves the best performance. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Blog Retrieval, Diversity, Novelty
Amongst all the information resources, the web is becom-ing the main source for providing new and useful information to users. Everyday, people receive up-to-date information via web-based services such as news web sites, social net-works or blogs. User generated content, like blogs, plays an important role in this phenomenon. Millions of people write about their experiences and express their opinions in blogs providing a rich source of information.

Considering this huge amount of user-generated data and its specific properties, designing new retrieval methods is necessary to facilitate addressing the different types of in-formation needs that blog users may have. Studies show that one of the main categories of blog-related queries is about finding blogs that deal with a specific topic of interest [12]. These queries, which are called concept queries, are the focus of a blog distillation system [9]. The blog distillation task (also known as blog feed retrieval) 1 is concerned with ranking blogs according to their recurring central interest to the topic of a user X  X  query. In other words, our aim is to discover relevant blogs for each topic 2 that a user can add to his reader and refer to in the future [10].

A relevant blog is expected to regularly publish posts about the topic. When it comes to blog relevance estima-tion, the usual emphasis is on the number of topic-related posts that a blog publishes. Nevertheless, the amount of new information that each of these posts add to the blog is another influential factor. If a blog publishes repetitive information with low novelty, it would be less interesting for the user to follow. In our diversity-based methods, we leverage this property and penalize those blogs that have low diversity in their posts related to the topic.

There are different scenarios where considering the diver-sity might help the retrieval performance. Table 1 shows some real examples of blogs that were affected by one of our diversity-based methods. The examples are part of our experiments on two selected topics of TREC09 and are com-pared to the best performing baseline method. We can see that by penalizing those blogs that have low diversity, we can filter out non-relevant blogs such as spam blogs or blogs that publish similar posts multiple times. On the other hand, it can help us to retrieve those relevant blogs that have high diversity among their posts even though they might have low initial score for the query.

In this paper, we discuss how to add a measure of diversity to the existing blog retrieval methods and study the effect on retrieval performance. Our main aim is to answer the following questions::
We use words  X  X eed X  and  X  X log X  interchangeably
We use words  X  X opic X  and  X  X uery X  interchangeably Topic ID: 1107 Topic title: Mountain Climbing Example 1 Feed no: BLOG08-feed-1167752 Blog URL: http://hockeycrew.livejournal.com Blog title:  X  X  Smile Because I X  X  Confused X  them very similar.
 Its rank in the baseline method: 10 Its rank after applying diversity: above 100 (not retrieved) Example 2 Feed no: BLOG08-feed-1218342 Blog URL: http://playwintersports.blogspot.com Its rank in the baseline method: 61 Its rank after applying diversity: above 100 (not retrieved) Example 3 Feed no: BLOG08-feed-070681 Blog URL: http://himadventures.blogspot.com Blog title:  X  X rekking, Camping, Climbing And Traveling In Himalayas X  Its rank in the baseline method: above 100 (not retrieved) Its rank after applying diversity: 81 Topic ID: 1122 Topic title: Skiing Example 4 Feed no: BLOG08-feed-616929 Blog URL: http://justjetskis.blogspot.com Blog title:  X  X UST SKI RESOURCES X  with almost identical content.
 Its rank in the baseline method: 1
Its rank after applying diversity: above 100 (not retrieved)
The rest of the paper is organized as follows. In section 2 we review state of the art methods of blog retrieval. Section 3 describes the methods that rely on post level evidence ag-gregation for calculating blog relevance. Those methods are the baselines for our experiments and our diversity methods are developed based on them. Section 4 explains our pro-posed diversity-based methods. Experimental results over different data sets are discussed in section 5. Finally, we conclude the paper and describe future work in section 6.
Research in blog distillation started mostly after 2007, when the TREC organizers proposed the task as part of the blog track. Researchers have employed different approaches from related areas such as ad-hoc search, expert search, and resource selection in distributed information retrieval.
The simplest models use ad-hoc search methods for find-ing blog relevant to a specific topic. They treat each blog as one long document created by concatenating all of its posts [3, 4, 13]. These methods ignore any specific property of blogs and usually use standard IR techniques to rank blogs. Despite their simplicity, these methods perform fairly well in blog retrieval.

Some other approaches have been applied to blog retrieval based on expert search methods. Expert search is a task in the TREC Enterprise Track where systems are asked to rank candidate experts with respect to their predicted expertise about a query, using documentary evidence of the expertise found in the collection [14]. Based on the similarity between blog distillation and expert search, some researchers have adapted expert retrieval methods for blog retrieval [1, 9]. In these models, each post in a blog is seen as evidence of blog interest in the query topic. Balog et al. adapt two language modeling approaches of expert finding and show their effectiveness in blog distillation [1]. MacDonald et al. use data fusion models to combine post-based evidence to compute a final relevance score of the blog [9].

Other researchers have employed resource selection meth-ods from distributed information retrieval for blog retrieval. In distributed information retrieval, the cost of searching all servers for each query is considered prohibitively expensive, so server selection algorithms are used [5]. Queries are then routed only to servers that are likely to have many relevant documents for the query. Elsas et al. deal with blog dis-tillation as a resource selection problem [4]. They model each blog as a collection of posts and use a language mod-eling approach to select the best collection. Similar work is described by Seo et al. , which they call Pseudo Cluster Selection [13].

None of the previous work paid attention to the diversity of blog posts in their retrieval methods. Previously, the co-hesiveness of a blog was assumed to be a positive sign of blog relevance [4, 13, 9, 6]. However, diversity, as a neg-atively correlated measure to cohesiveness, has never been studied. In the following, we consider the diversity of blog posts, its effect on the retrieval systems, and its relation with the cohesiveness of the blog.
In general, most of the blog distillation methods can be seen as an aggregation of the post-level relevance evidence to calculate the blog-level relevance score. The following are the main existing aggregation methods that we use as baselines in our experiments:
All the mentioned methods have one parameter as the size of R ( q ) which we call n . This parameter defines the size of the initially retrieved set of posts for the query that will be inputs of the aggregation methods. The value of n is learnt using a training set which will be described in more detail later. The PCS method has two more parameters that are assigned as follows:
The relation between posts in each blog can give us use-ful information about the blog. Previous studies considered cohesiveness as a way to capture how posts in the blog are similar to the blog in general [4, 13, 9]. In these studies, a blog with higher cohesiveness and thus less diversity is considered a better blog to retrieve. Elsas et al. define the centrality of a post as its similarity to the blog as a whole. They assume that if the retrieved posts from a blog have high centrality, that blog is a better candidate for retrieval [4]. Seo and Croft penalize those blogs that have high di-versity among their posts [13]. Defining the goal of blog retrieval system to retrieve topic-centric blogs, they assume that blogs with high diversity are not topic-centric and thus should be penalized. MacDonald and Ounis define similar measures to retrieve blogs with focused interests [9]. They also consider temporal distribution of posts to retrieve blogs with recurring interests.

In contrast to previous work where all the posts of the blog are used for estimations, we focus only on those posts that are about the query topic. While diversity of a blog as a whole might be negative evidence for blog relevance, we assume that on-topic diversity is an asset. In other words, we assume that a relevant blog should have a high coverage over sub-topics and thus should have a high diversity among posts that it publishes about the topic.

We define three types of diversity over the posts and inves-tigate their effectiveness on performance of a blog retrieval system:
In the following we discuss each of the methods in more detail.
First we study topical diversity among the posts of each blog. Blog distillation queries tend to be more general than normal web queries and thus have a wider range of sub-topics [4]. We assume that posts that are retrieved from each blog for the query should have high diversity in order to cover different sub-topics. We want to investigate how this on-topic diversity of posts can affect the relevance of a blog to the query.

In order to test if the diversity of blog posts is an impor-tant factor in the relevance of blogs, we carry out preliminary experiments on the Blog08 collection. In these experiments, we assume that higher similarity of blog posts indicates less diversity among them. This assumption is consistent with previous work on diversification [2].

For each query, we first retrieve the top n posts using a traditional retrieval method. Then for each blog that has more than one post in the retrieved set, we calculate the average similarity between its retrieved posts, which we call On-topic Intra-feed Similarity (OIS):
The higher the OIS value, the less diverse is the feed with respect to the query. We use cosine similarity as the simi-larity measure between two posts.

Figure 1 shows the distribution of OIS for relevant and non-relevant blogs. It can be seen that non-relevant blogs are more likely to have high OIS values. The mean of OIS for relevant blogs is 0.43 compared to 0.50 for non-relevant blogs. Based on the Welch two sample t-test, the difference between the mean values is statistically significant with a p-values equal to 2.6e-16 . This shows the possibility of us-ing the diversity of posts for discriminating between relevant and non-relevant blogs and consequently having a better re-trieval system.

In figure 1, we use the top 2000 posts for each topic. Simi-lar behavior has been observed for a smaller number of posts. However, it is possible that with an increasing number of re-trieved posts, we retrieve more posts for each blog and we end up with less diverse relevant blogs or more diverse non-relevant blogs. In order to test this possibility, we run the same analysis with the top 15000 posts for each query. Fig-ure 2 shows the outcome of this experiment. The mean of OIS values for relevant blogs is 0.34 compared to 0.42 for non-relevant blogs. The difference between the mean values is statistically significant with the p-value less than 2.2e-16 .
As we can see, the OIS values decrease with increasing numbers of posts. However, the difference between relevant and non-relevant blogs still exists. This is quite surprising, since we expect that by retrieving more posts, we increase the chance that non-relevant blogs will have a more diverse set of retrieved posts.

The per-topic analysis in figure 3 shows the difference more clearly. This figure shows the average of OIS values Figure 1: Distribution of On-topic Intra-feed Similarity( OIS ) using top 2000 retrieved posts. for relevant and non-relevant blogs for each query topic. For clarity, topics are sorted by the average OIS of their non-relevant feeds. As can be seen for most topics, non-relevant feeds have higher similarity among their posts compared to the relevant ones.

To capture the diversity of blog posts, we adapt a variation of Maximal Marginal Relevance (MMR) [2]. The goal of MMR is to maximize diversity of retrieved set of documents. It selects documents that are more similar to the query and less similar to already retrieved documents: where R is an initial set of documents and S is the set of already retrieved documents.

Similar to the MMR method, our diversity detection method exploits the fact that similar documents are less diverse, thus it penalizes posts that are similar to other posts in the blog. In other words, only information of a post that does not appear in other blog posts can contribute to blog relevance: where score ini ( p i ,q ) is the initial score of post p query q . S is the set of posts that belong to the same blog and have higher scores than p i . This method assumes that based on its similarity to other posts. The parameter  X  con-trols the importance of the post novelty in its score, which can vary for different similarity methods or different queries. sim topical captures the content similarity between the two posts and can be replaced by any similarity measure. We use cosine similarity, since it always has a value in [0 , 1] and does not need an extra normalization step: where tf ( w,p ) is the term frequency of the term w in the post p . When there is no similarity between a post and other blog posts that have higher score, the maximum of similarities will be zero. In this case, the diversity score of the post will be the same as its initial score and therefore all the relevance evidence of the post can contribute to the blog relevance score. In contrast, if there is another post very similar to the current post, then the cosine similarity will be close to one. As a result, depending on the value of  X  , the diversity score of the post can be close to zero. Therefore, the blog will not gain any relevance from that post even if the post has high query likelihood.

After obtaining new scores for posts, any existing aggre-gation method can be used to aggregate the new scores and calculate the score of blogs. Applying the diversity-based scores introduces a new parameter  X  that needs to be esti-mated.
In addition to the content of blog posts, temporal infor-mation is another important source of information that can be used by the retrieval system [8, 9]. Analogous to topical diversity, we can assume that a relevant blog should have a high temporal diversity among its published posts for the query. In other words, we expect that blog posts have high coverage over the temporal space and not be concentrated on specific time windows.

We employ a similar approach to the topical diversity where we penalize the posts that have high temporal sim-ilarity to other posts. To this end, we define a temporal similarity function between two posts as an un-normalized Gaussian function: where t i is the time-stamp of p i given in days. We can see that the temporal similarity has a value between zero and one. If the two posts are published in the same day their similarity will be one and the similarity will decrease when the temporal distance increases. Finally, we penalize post scores based on their temporal similarity:
Using this method, if the post is published around the same date as some other posts, it will contribute less to the blog relevance than a post which is published at a distant time. In other words, this captures the property of whether the blog posts are published all over the temporal space or if they are mostly published in some specific small time windows.

The temporal similarity function adds a new parameter  X  to the model which is the standard deviation of the Gaussian function.
Finally, we can consider hybrid measure of diversity that takes both topical and temporal diversities into account. Two possible cases in which temporal and topical diversi-ties can complement each other can be described as follows:
To consider these cases in our method, we define an hybrid similarity function as follows: where sim topical and sim temporal are calculated using for-mula 6 and formula 7 respectively. Similar to topical and temporal diversity scores in formulas 5 and 8, we penalize those posts that have high hybrid similarity with other posts.
We can see that in this method, we mainly penalize those posts that are published around the same date as other posts and also have very similar content to them. Thus, in any of the two mentioned scenarios where one of the similarities is high and the other one is low, the post will not be highly penalized and can still contribute to the blog relevance. We conduct our experiments over four years worth of TREC blog track data from the blog distillation task, in-cluding TREC X 07, TREC X 08, TREC X 09 and TREC X 10 data sets. The TREC X 07 and TREC X 08 data sets include 45 and 50 queries respectively and use the Blog06 collection. The TREC X 09 and TREC X 10 data sets use Blog08, a new collec-tion of blogs, and have 39 and 46 queries respectively. We use only the title of the topics as the queries.

The Blogs06 collection is a crawl of about one hundred thousand blogs over an 11-week period [10], and includes blog posts (permalinks), feed, and homepage for each blog. Blog08 is a collection of about one million blogs crawled over a year with the same structure as the Blog06 collection [11]. In our experiments we only use the permalinks component of the collection, which consist of approximately 3.2 million documents for Blog06 and about 28.4 million documents for Blog08.

We use the Terrier Information Retrieval system 3 to index the collection with the default stemming and stop-words re-moval. In all the methods, the language modeling approach using the Dirichlet smoothing has been used to score the posts and retrieve top posts for each query. Without further tuning, the Dirichlet smoothing parameter is set to 5000 [16].
We use the three blog retrieval methods discussed in sec-tion 2 as our baseline methods. We apply each of these methods on the language model scores and also on the three diversified scores calculated by our proposed methods.
Since TREC X 07 and TREC X 08 query sets share the same collection, we use one to tune the parameters for the other. We do the same for the TREC X 09 and TREC X 10 query sets that share the Blog08 collection. By fixing the parameters k and  X  in the PCS method and the Dirichlet smoothing parameter across all the methods, the remaining parameters to be tuned are the following:
Tables 2, 3, 4 and 5 show the performance evaluation of the methods over TREC X 07, TREC X 08, TREC X 09 and TREC X 10 respectively. The first three rows in each table represent the performance of baseline methods. The second three rows show the performance of the corresponding meth-ods based on the topical diversity scores. The third three rows show the performance of the methods using the tempo-ral diversity scores followed by the last rows that show the performance of the hybrid diversity scores.
 Statistical significance tests are performed using the paired T-test at 0.05 level of significance. The symbol  X  indicates that a diversity method has a statistically significant im-provement over its corresponding baseline. The symbols M and N show that the hybrid diversity method has a statis-tically significant improvement over the temporal diversity and topical diversity methods respectively. The bold val-ues in each column indicate the best performance for the corresponding evaluation measure.

As we can see in the tables, diversity-based methods gen-erally improve their corresponding baseline methods. In most cases, these improvements are at a statistically sig-nificant level. The temporal diversity methods are not as ef-fective as their topical diversity counterpart. However, when combined together, the resulting hybrid diversity methods http://ir.dcs.gla.ac.uk/terrier/ Table 2: Evaluation results for the implemented mod-els over TREC X 07 data set.
 Model MAP P@10 Bpref CombSum 0.2259 0.3844 0.2721 PCS 0.2695 0.4378 0.3115 SDM 0.2867 0.4444 0.3439 CombSum-topical 0.2506  X  0.4244  X  0.2859  X  PCS-topical 0.2901  X  0.4422 0.3184  X  SDM-topical 0.3168  X  0.4756  X  0.3667  X  CombSum-temporal 0.2612  X  0.4267 0.2840  X  PCS-temporal 0.2844  X  0.4911  X  0.3134 SDM-temporal 0.3023  X  0.4756  X  0.3539 CombSum-hybrid 0.2466  X  0.4333  X  0.2866  X  M PCS-hybrid 0.2961  X  M 0.4622 0.3197  X  M SDM-hybrid 0.3191  X  M 0.5156  X  MN 0.3622  X  M
Table 3: Evaluation results for the implemented mod-els over TREC X 08 data set.
 Table 4: Evaluation results for the implemented mod-els over TREC X 09 data set.
 Model MAP P@10 Bpref CombSum 0.1889 0.3154 0.2148 PCS 0.2093 0.3103 0.2279 SDM 0.2636 0.3821 0.2858 CombSum-topical 0.2180  X  0.3282 0.2297  X  PCS-topical 0.2196  X  0.3282 0.2374  X  SDM-topical 0.2888  X  0.4333  X  0.3091  X  CombSum-temporal 0.2087  X  0.3051 0.2187 PCS-temporal 0.2082 0.3103 0.2250 SDM-temporal 0.2759 0.3846 0.2909 CombSum-hybrid 0.2176  X  M 0.3282 M 0.2334  X  M PCS-hybrid 0.2224  X  M 0.3462  X  M 0.2387  X  M SDM-hybrid 0.2961  X  MN 0.4308  X  M 0.3125  X  M
Table 5: Evaluation results for the implemented mod-els over TREC X 10 data set.
 usually produce the best results. In some cases, combining temporal diversity with topical diversity results in a statis-tically significant improvement over each one of them.
An interesting observation is that the SDM method, as the strongest baseline, benefits the most from the diversi-fication. As a result, the SDM-hybrid method significantly outperforms the SDM method in most of the collections and evaluation metrics.

We previously mentioned that spam blogs are one cate-gory of non-relevant blogs that would be filtered using diversity-based methods. It is interesting to see what portion of blogs that are affected by diversity methods are in fact spam blogs. To this end, we manually checked non-relevant blogs that were initially retrieved by SDM and were removed from the ranked list after applying hybrid diversity measure. We chose ten random queries from the TREC X 09 query set and compared their ranked lists before and after considering di-versity. Among 106 non-relevant blogs that were removed from the ranked list, 27 of them (25%) were spam blogs and the rest were non-spam. This shows that considering diver-sity does not just filter out spam blogs, but also removes other non-relevant blogs from the ranked list. On the other hand, our examination shows that the method promotes rel-evant blogs in the ranking. For the examined queries, there were 30 new relevant blogs retrieved after applying diversity and only 6 relevant blogs were removed from the ranked list.
In order to test the robustness of proposed approaches, we analyze the sensitivity of their retrieval performance to the parameters. We analyze the results over the TREC X 09 query set, as an example of a large collection, and the TREC X 07 query set, as an example of a small collection. For simplicity, we only consider the SDM method and the corresponding diversity-based methods in this analysis. To study each of the parameters, we fix the other parameters with values that are learnt from the training set in the previous experiments.
Figures 4 and 7 show the effect of n , the number of initially retrieved posts, on the performance of retrieval systems. The diversity-based methods outperform the baselines at all the values of n . This confirms our analysis in section 4 that the difference between on-topic diversity of relevant blogs and non-relevant blogs does not change by increasing n . We can see that by increasing the number of posts, the performance increases and the difference of performances for values higher than 5000 are insignificant.

Figures 5 and 8 show the effect of  X  when we fix the val-ues of n and  X  . We can see that the performance of the hybrid and topical diversity methods generally increase by increasing  X  . In both collections, the best performance of these methods is achieved when  X  has a value close to one. This shows that the maximum penalty for those blogs that publish repetitive information produces the best results. On the other hand, temporal diversity is less robust and the per-formance decreases for  X  values higher than 0 . 5.

Finally, figures 6 and 9 show the effect of  X  on the perfor-Figure 4: Effect of the number of the top retrieved posts in the performance over TREC X 07 data set Figure 7: Effect of the number of the top retrieved posts in the performance over TREC X 09 data set mance of temporal and hybrid diversity methods. It can be seen that  X  is less influential on the performance and it has little negative effect when its value increases. It is interest-ing to see the relation between the size of the collection and the best value of  X  . While for the TREC X 07 collection the best performance is achieved when  X  is around 5, this value for the TREC X 09 collection is around 40.
So far, we showed that blog post diversity is a discrimina-tive feature in blog retrieval that can improve retrieval per-formance. In this section, we investigate a comparison be-tween blog post diversity and the previously proposed blog cohesiveness measures. The cohesiveness of a blog is as-sumed to show whether the blog focuses on a specific topic or not. While it is a reasonable assumption, the proposed methods in previous work did not show any positive effect on retrieval effectiveness:
For clarity of the paper we do not report this comparison here. Figure 10: Cohesiveness distribution of relevant and non-relevant blogs
All these works assumed cohesiveness to be a positive fea-ture of blog relevance and did not investigate if this is a valid assumption or not. In order to verify the validity of this assumption, we use the following cohesiveness measure to compare the relevant and non-relevant blogs: where V D ( b i ) is a virtual document created by concatenat-ing all the posts of b i . We use the cosine similarity measure for calculating sim ( p ji ,b i ), as the similarity between a post and a blog. This measure of cohesiveness compares the ini-tially retrieved posts of a blog to the blog as a whole. In other words, it captures the cohesiveness of the blog with respect to the topic. It is similar to those measures used in other works mentioned earlier [9, 4].

Figure 10 shows the distribution of cohesiveness values for relevant and non-relevant blogs in TREC X 09 data set. The value of n , the size of R ( q ), is set to 15000 for this analysis. The mean value of cohesiveness for relevant blogs is 0.56 and for non-relevant blogs, it is 0.55 . The difference be-tween the mean values is not statistically significant and the p-value of the Welch t-test is 0.66 . This shows that the co-hesiveness is not a strong discriminative feature and explains why adding cohesiveness did not improve the performance of the retrieval systems in the previous works.
 It is interesting to verify if cohesiveness is correlated with IOS , as defined in equation 4. If a blog has high cohesiveness, it is not surprising that it would also have high similarity among its posts and thus high IOS value. However if the top posts of a blog are very similar (high IOS ), one can not directly conclude that the blog has high cohesiveness. In order to examine such a correlation we calculate the Pearson correlation between the cohesiveness and the OIS values. The correlation is statistically significant with a value of 0.83 . The high correlation shows that blogs with high OIS are very likely to also have high cohesiveness.
In 2009, a more complex and refined version of the blog distillation task was introduced in TREC, named  X  X aceted Blog Distillation X  [11]. The new task, which was first intro-duced by Hearst et al. [7], aims to consider not only the blog relevance to the topic but also the  X  X uality aspects X  (facets) of the blog. For each query, a specific facet is determined and only blogs that satisfy that facet are considered to be relevant. In this section, we discuss the effect of diversity on the performance of the system for different facets. Different facets can be seen as different categories of blogs that users might search for. It is important to be able to decide for what type of information needs we can use diversity to get the maximum overall performance.

We use the introduced facets in the TREC X 09 and TREC X 10 data collections which include Opinionated vs. Factual, Per-sonal vs. Company and In-depth vs. Shallow facets [11]. Tables 6 and 7 compare the performance of the diversity method with the baseline method for each facet. Without further tuning, we use the same parameter values as the previous section.
 The statistically significant improvements are shown by  X  . Since each facet has very few queries, the statistical signifi-cance tests will be very sensitive and do not always show a difference. Thus we report also the percentage of improve-ment over the baseline method. The maximum improvement for each measure is shown in bold.

As we can see, diversity improves the performance of the system for almost all of the facets and evaluation measures. This shows that the effectiveness of diversity is not restricted to specific categories of topics. As a result, one can expect to have improvements by applying diversity for any type of information needs in blog search.

It is interesting to notice the improvement of P@10 for the in-depth queries which is the maximum among all the facets. For the in-depth queries, a relevant blog is expected to have in-depth thoughts and analyses about the topic [11]. As we previously saw in example 3 in table 1, one of the scenarios where diversity is effective is in retrieving blogs with such an in-depth property. The obtained improvements for in-depth queries confirm our previous observation. The results shows that a diversity-based method retrieves in-depth blogs at the top ranks and significantly improves the P@10 measure.
In this paper, we studied the effect of employing differ-ent diversity measures on blog retrieval. We showed that diversity is an important feature that can help in distin-guishing relevant blogs from non-relevant ones. We intro-duced three types of diversity and investigated their effect on the performance of the retrieval systems. Our experiments on standard blog retrieval collections showed improvements over different baseline methods.

We further showed that the common assumption of cohe-siveness is not an indicative feature of blog relevance and that is in fact the reason that there is no improvement ob-served in the previous work.

Finally, we investigated the effect of diversity on different types of queries and showed that diversity can be beneficial to all query types. Table 6: Effect of diversity on different facets over TREC X 09 data set.
 Facet Model MAP P@10 Bpref
Opinionated SDM 0.1153 0.1615 0.0998 SDM-hybrid 0.1236 0.1923 0.1132 (13 queries) (+7%) (+19%) (+13%)
Factual SDM 0.1749 0.1692 0.1570 SDM-hybrid 0.1788 0.1538 0.1661 (13 queries) (+2%) (-9%) (+5%)
Personal SDM 0.1840 0.2000 0.1384 SDM-hybrid 0.2201 0.2375 0.1756 (8 queries) (+19%)  X  (+18%) ( +26% )  X 
Official SDM 0.1876 0.1750 0.1537 SDM-hybrid 0.2319 0.1750 0.1819 (8 queries) ( +23% ) (0.0%) (+18%)
Indepth SDM 0.2723 0.2222 0.2624 SDM-hybrid 0.2872 0.2667 0.2526 (18 queries) (+5%) ( 20% )  X  (-3%)
Shallow SDM 0.1348 0.0889 0.1118 SDM-hybrid 0.1540 0.1056 0.1378 (18 queries) (+14%)  X  (+18%) (+23%) Table 7: Effect of diversity on different facets over TREC X 09 data set.
 Facet Model MAP P@10 Bpref
Opinionated SDM 0.1061 0.1800 0.1257 SDM-hybrid 0.1260 0.2000 0.1369 (15 queries) (+18%)  X  (+11%) (+8%)
Factual SDM 0.1028 0.1000 0.0820 SDM-hybrid 0.1190 0.1067 0.0985 (15 queries) (+15%) (+6%) ( +20% )
Personal SDM 0.1290 0.1533 0.1095 SDM-hybrid 0.1426 0.1467 0.1060 (15 queries) (+10%) (-4%) (-3%)
Official SDM 0.2057 0.1267 0.1697 SDM-hybrid 0.2274 0.1400 0.1928 (15 queries) (+10%) (+10%) (+13%)
Indepth SDM 0.2396 0.1250 0.2079 SDM-hybrid 0.2953 0.1625 0.2430 (16 queries) ( +23% )  X  ( +30% )  X  (+16%)
Shallow SDM 0.0833 0.1250 0.0818 SDM-hybrid 0.1003 0.1313 0.0838 (16 queries) (+20%) (+5%) (+2%)
One possible extension for future work is to apply the proposed approach to similar problems. It would be inter-esting to see if the diversity assumption holds for collection selection in distributed IR, expert search or user search in microblogs.

We are also interested in a more general framework for considering blog diversity that can be used in any existing blog retrieval method. So far, we have only applied diversity measures to the methods that are an aggregation of post-level scores. However, there are some methods that do not just aggregate post-level scores, such as the Blogger Model method [1] or two stage retrieval model [15]. It would be interesting to develop a framework to adapt diversity mea-sures for those methods as well.
This work was supported partly by the Center for Intelli-gent Information Retrieval and partly by the Swiss National Science Foundation. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the spon-sors.

We thank Jangwon Seo for his collaboration and com-ments while he was in CIIR. We also like to thank Armita Kaboli for her helpful discussions and comments. [1] K. Balog, M. de Rijke, and W. Weerkamp. Bloggers as [2] J. Carbonell and J. Goldstein. The use of mmr, [3] M. Efron, D. Turnbull, and C. Ovalle. University of [4] J. L. Elsas, J. Arguello, J. Callan, and J. G. Carbonell. [5] D. Hawking and P. Thomas. Server selection methods [6] J. He, W. Weerkamp, M. Larson, and M. de Rijke. An [7] M. A. Hearst, M. Hurst, and S. T. Dumais. What [8] M. Keikha, S. Gerani, and F. Crestani. Temper: A [9] C. Macdonald and I. Ounis. Key blog distillation: [10] C. Macdonald, I. Ounis, and I. Soboroff. Overview of [11] C. Macdonald, I. Ounis, and I. Soboroff. Overview of [12] G. Mishne and M. de Rijke. A study of blog search. In [13] J. Seo and W. B. Croft. Blog site search using [14] I. Soboroff, A. de Vries, and N. Craswell. Overview of [15] W. Weerkamp, K. Balog, and M. de Rijke. Blog feed [16] C. Zhai and J. Lafferty. A study of smoothing
