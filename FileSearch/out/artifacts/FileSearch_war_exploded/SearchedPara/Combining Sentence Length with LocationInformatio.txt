 Paraphrases are alternative ways to convey the same information [1]. And the paraphrase phenomenon is a common language phenomenon. The paraphrasing technology has been applied for various applications of natural language process-ing, such as question answering [2, 3, 4, 5, 6], information extraction [7], machine translation [8], information retrieval [9], multidocument [10], and it can improve the whole performance of these applications. There are many kinds of naturally occurred paraphrases resource. Barzilay extracted them from different transla-tions of the same masterpiece [1]. Shinyama extracted paraphrases from news articles [11]. But the language they processed most is English or Japanese, the Chinese paraphrases is seldom researched. And in this paper, we mainly referred to the Barzilay X  X  method to build a Chinese paraphrases corpus. The practical alignment technology is necessary for doing it.
 been a number of papers on aligning bilingual texts at the sentence level in the last century, e.g., [12, 13, 14, 15]. On clean inputs, such as the Canadian Hansards and the Hong Kang Hansards, these methods have been very successful. Church [16] and chen [17] proposed some methods to resolve the problem in noisy bilin-gual texts. Cognate information between Indo-European languages pairs are used to align noisy texts. But these methods are limited when aligning the languages pairs which are not in the same genre or have no cognate information. Fung [18] proposed a new algorithm to resolve this problem to some extent. The algorithm uses frequency, position and recency information as features for pattern match-ing. Wang [19] adapted the similar idea with Fung [18] to align special domain bilingual texts. Their algorithms need some high frequency word pairs as fea-tures. When processing the texts that include less high-frequency words, these methods will perform weakly and with less precision because of the scarcity of the data problem.
 They have the following characteristics as follows: allel text; lator X  X  individual idea; length. All these methods have limitations when facing the real monolingual parallel texts according to the characteristics mentioned above. We proposed a new alignment method based on the sentences length and location information. The basic idea is that the location of a sentence pair with certain length is distributed in the whole text similarly. The local and global location information of a sentence pair is fully combined together to determine the probability with which the sentence pair is a sentence bead.
 quent section reports the mathematical model of our alignment approach. Sec-tion 4 presents the process of anchors selection, algorithm implementation is shown in section 5. The experiment results and discussion are shown in section 6. In the final section, we conclude with a discussion of future work. It is necessary to clarify several concepts for understanding the alignment pro-cess. As shown below: anchors when he aligned Hansard corpus. He considered that anchors are some aligned sentence pairs which divided the whole texts into small fragments. aligned sentence pair a sentence bead. Sentence bead has some different styles, such as (0:1), (1:0), (1:1), (1:2), (1: more), (2:1), (2:2), (2: more), (more: 1), (more: 2), (more: more). construct a sentence pair. ment anchors. In this paper, all (1:1) sentence beads are categorized as candidate anchors. The alignment process has two steps: the first step is to integrate all the origin paragraphs into one large paragraph. This can eliminate the problem induced by the vague paragraph boundaries. The second step is the alignment process. After alignment, the monolingual parallel texts become sequences of aligned fragments. And the unit of a fragment can be one sentence, two sentences or several sentences.
 tending the concepts of bipartite graph and matching in graph theory. 3.1 Bipartite Graph Bipartite graph: Here, we assumed G to be an undirected graph, then it could be defined as G = &lt;V, E &gt; . The vertex set of V has two finite subsets: V 1 and V ,also V 1  X  V 2 = V , V 1  X  V 2 =  X . Let E be a collection of pairs, when e  X  E , V , E ,V 2 &gt; , called bipartite graph. In a bipartite graph G, if each vertex of V 1 is joined with each vertex of V 2 , or vice versa, here an edge represents a sentence called complete bipartite graph. We considered that: | V 1 | = m, | V 2 | = n ,where the parameters m and n are respectively the elements numbers of V 1 and V 2 . The complete bipartite graph was usually abbreviated as Km, n as shown in Figure 1. 3.2 Matching Matching: Assuming G = &lt;V 1 , E ,V 2 &gt; was a bipartite graph. A matching of G was defined as M, a subset of E with the property that no two edges of M have a common vertex. 3.3 Best Alignment Matching The procedure of alignment using sentence length and location information can be seen as a special matching. We defined this problem as  X  X est Alignment Matching X  (BAM).
 then E M must meet the following conditions: alignment threshold); at the same time, there are no edges sk, tr which made k &lt; iandr &gt; j, or k &gt; iandr &lt; j; of edge in collection E, until the weight of every edge d(si, tj) is equal or more than the alignment threshold D. Generally, the alignment threshold D is deter-mined according to experience. the text S or T can be denoted by S(s1, s2, s3, ... ,si,sj, ... , sm) or T(t1, t2, t3, ... ,ti,tj, ... , tn). Considering the form merely, each element in S combined with any element in T can create a complete bipartite graph. Thus the alignment task can be seen as the process of searching for the BAM in the complete bipartite graph. As shown in Figure 2, the edge e = { si, tj } belongs to E M ; this means that the i-th sentence in text S and the j-th sentence in text T can make an alignment anchor. Each edge is corresponding to an alignment value. In order to ensure the monolingual parallel texts are divided with the same fragment number, we default that the last sentence in the monolingual parallel texts is aligned. That is to say, { sm, tn } X  E M was correct, if | S | =m and | T | =n in the BAM mathematical model.
 tence pair is to be a candidate anchor. The smallest value of the sentence pair is found from the complete bipartite graph. That means the selected sentence pair is the most probable aligned (1:1) sentence bead. Alignment process is completed until the alignment anchors become saturated under alignment threshold value. chors. These anchors divide the whole texts into short aligned fragments. At the same time, these anchors themselves are extracted as correct sentence pairs independently. The definition of BAM ensures that the selected sentence pairs cannot produce cross-alignment errors, and some cases of (1:more) or (more:1) alignment fragments can be attained by the fragments pairs between two selected alignment anchors. All (1:1) sentence beads are extracted from different styles of monolingual par-allel texts. Their distribution states are similar as presented in Figure 3. The horizontal axis denotes the sentence number in one Chinese translation text, and the vertical axis denotes the sentence number in another Chinese transla-tion text. beads in monolingual parallel texts and their distributions obey an obvious law well. DeKai, Wu offered that (1:1) sentence beads occupied 89% in English-Chinese as well [15]. If we select these sentence beads as candidate anchors, the alignment method will be general on any languages pairs. Length and location information of sentence pair is used fully to calculate the alignment weight of each sentence pair. Finally, the sentence pair with high value will be filtered by the similarity of the two sentences in a sentence pair.
 rameters are defined: alignment threshold, where P[i,j] denotes the integrated alignment value between si and tj. We construct a formal alignment function on every sentence pair: of sentence pairs X  length and the weight of context lengths well. The longer the text is, the more insensitive the effect of the context length is. So  X   X  X  value should change in order to balance the whole proportion. The short text is vice versa. In this paper we define: through: Intersection(L 1 ,L 2 ) is the common length of the two sentences.
 of P[i, j] is, the more the probability of sentence pair si, tj being a (1:1) sentence bead is. In this paper, we adopt a greedy algorithm to select alignment anchors according to all the alignment function values of P[i, j] which are less than the alignment threshold. This procedure can be implemented with a time complexity of O(m*n). To obtain further improvement in alignment accuracy the similar-ity is used to filter the wrong sentence pairs independently. And calculation approach of the similarity is same with the method mentioned above.
 the alignment precision is improved greatly. Here, those candidate alignment anchors whose similarities exceed the similarity threshold will become the final alignment anchors. These final anchors divide the whole monolingual parallel texts into aligned fragments. According to the definition of BAM, the first selected anchor will divide the whole monolingual parallel texts into two parts. We stipulated that the sentences in the upper part of one translation text cannot match any sentence in the nether part of anther translation text. As shown in Figure 5. must be selected in the first quadrant or the third quadrant and exclusive from the boundary. It is obvious that the cross alignment error will happen if the candidate anchor exists in the second quadrant or fourth quadrant. For example, if the (i, j) is the first selected alignment anchor, and the (i-1, j+1) is the second selected alignment anchor, the cross alignment appears. We can limit the anchors selection field to prevent the cross-alignment errors.
 tence pair is not a (1:1) sentence bead, we use a virtual sentence length as the origin alignment sentence bead when we initialize the alignment process. The implementation of alignment algorithm is described as followed: function value; and the go to step 6), and if the smallest value is equal to or more than the threshold, then go to step 7); the sentence pair will become an alignment anchor and divide the monolingual parallel text into two parts respectively, then limit the search field of the next candidate anchors and go to the step 4); Because the translations of most of masterpiece are aligned in chapter and the sentence number of every chapter are less than 500, our algorithm works well on the monolingual parallel texts with the sentence number under 500. Part of translations in  X  X he Sorrows of Young Werther X  and  X  X ien A  X  nos de Soledad X  are selected as test set. The concrete information is shown in Table 1 and 2. ity filtering and without similarity filtering. The precision and recall are defined: of alignment sentence pairs in monolingual parallel texts sentence pairs in standard test texts a statistic on all the errors and find that most errors are partial alignment errors. Partial alignment means that the alignment location is correct, but a half pair of the alignment pair is not integrated. The result shows that similarity filtering can resolve the problem in some extent. The recall is so low because there are some correct aligned fragment pairs with more than one sentence which cannot match the correspondent sentence pair in the standard set.
 length-based sentence alignment method using dynamic programming. And com-bining the traditional alignment method with our method, the results are shown in Table 4.
 graph boundaries, the error extension phenomena happen easily in the length-based alignment method. Its alignment results are so weaker that it cannot be used. If we omit all of the origin paragraphs information and merge all the paragraphs in the monolingual parallel text into one larger paragraph respec-tively. The length-based alignment method rated the precision of 35.0%. This is mainly because different translators have different translation styles and differ-ent comprehension on the same foreign texts. But our method rated 160 (1:1) sentence pairs as alignment anchors which divide the monolingual parallel text into aligned fragments. Then the length-based classic method was applied to these aligned fragments and got a high precision.
 with all the (1:1) sentence beads. Their only difference is the sparse extent of the aligned pairs. We can make a conclusion that Our method performs very well to align the real monolingual parallel texts. This paper proposed a new method for fully aligning real monolingual parallel texts using sentence length and location information, described concretely in section 3 and 4. The model was motivated by the observation that the location of a sentence pair with certain length is distributed in the whole text similarly. It uses the (1:1) sentence beads instead of the high frequency words as the candidate anchors. Local and global location characteristics of sentence pairs are involved to determine the probability which the sentence pair is an alignment anchors. according to the formal alignment function. Then the process of BAM is per-formed to get the alignment anchors. This alignment method can restrain the errors extension effectively in comparison to the traditional length-based align-ment method. Furthermore, it has shown strong robustness, even if when it meets ill-quality texts that include incorrect sentences. To obtain further improvement in alignment accuracy sentence similarity filtering was performed. The algorithm need not segment the Chinese sentence require little cost to implement. cally to get high precision alignment anchors, for example, applying the first test set, even if we get only 107 (1:1) sentence beads but the precision is 98.13%. We found that this method can perform the function of paragraph alignment very well and ensure the alignment precision simultaneously.
 even extracted from the monolingual parallel text directly to build a large scale paraphrase corpus if the original monolingual parallel text is abundant. And the rest text can be used as spare resource. Now, we have obtained about 50,000 Chinese paraphrase pairs with high quality.
 and extend the method to align other languages pairs.
 This research was supported by National Natural Science Foundation (60203020) and Science Foundation of Harbin Institute of Technology (hit.2002.73).
