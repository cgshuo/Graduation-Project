 In this paper, we propose a method to cluster the spacial patterns of the visual eld in glaucoma patients to analyze the progression patterns of glaucoma. The degree of pro-gression in the visual eld of glaucoma patients can be di-vided into several regions by straight line boundaries, we call this speci c structure Direct Product Structure in this paper. Since we can observe the direct product structure in the visual elds, we propose a bottom-up hierarchical clus-tering method to embed this structure into the clustering structure. In our method, according to the minimum de-scription length (MDL) principle, we select the best cluster division so that the total code length required for encoding the data as well as the clustering structure is minimum. We can thereby select the clusters that are robust to the noise in the position of the direct product structure for clustering. We demonstrate the effectiveness of our method using an ar-ti cial dataset and a real glaucoma dataset. Our proposed method performed better than existing methods for both datasets. For the real glaucoma dataset in particular, our method discovered the characteristic progressive patterns of glaucoma as speci c features of clusters. These patterns Th e current address is Corporate Research &amp; Development Center, TOSHIBA Corporation.
 E-mail: shigeru1.maya@toshiba.co.jp.
 c  X  agree with clinical knowledge. Furthermore, we show that our clusters can be applied to improve the accuracy of pre-dicting glaucoma progression. Thus, our clusters contain rich information of glaucoma, and hence can contribute to further development in glaucoma research.
 H.2.8 [ Information Systems ]: Database Applications| Data mining ; J.3 [ Life and Medical Sciences ]: Medical information systems Experimentation, Performance, Algorithm Glaucoma, hierarchical clustering, normalized maximum like-lihood distribution, the minimum description length
Glaucoma is a chronic disease of eyes, which affects the eld of vision ( visual eld ). The mechanism of the progres-sion of glaucoma is based on an increase in uid pressure on the eye. As this pressure increases, the optical nerve is dam-aged which leads to visual eld loss. Glaucoma is one of the main causes of blindness worldwide. Patients are surgically treated, according to the progression speed and also the pat-tern of the disease, hence it is clinically useful to optimize the treatment using mined-knowledge regarding glaucoma.
A major eld requiring mined knowledge regarding glau-coma is the prediction of glaucoma progression [10, 12, 13]. In the relevant studies, predicting models embedded with (a) (b) (c) Fi gure 1: Visual elds of glaucoma. (a) 74 diagnosis points are shown as the white box. (b, c) Direct product structure of real visual eld data. Regions are divided by red straight lines. the characteristic features of glaucoma were constructed. Al-though these models performed well, many issues remain to be analyzed in order to improve the clinical setting.
Detecting characteristic progressive patterns on the visual elds of glaucoma patients is one of most challenging prob-lems in research on predicting glaucoma progression. Clin-ical knowledge shows that the progression of glaucoma is deeply correlated with the pattern of optical nerves [6], such as progression from the side of the ear and that from the side of the nose. If we can classify these progressive patterns, we may obtain useful knowledge from clinical data. Such knowledge might help clinicians in numerous ways, such as the visualization of implicit clinical knowledge, the detec-tion of novel progressive patterns, the addition of new in-formation to improve the accuracy of prediction, and the discovery of correlations between the progressive patterns and risk factors of glaucoma and so on. Therefore, we focus on clustering glaucoma visual eld data.

In this paper, we propose a clustering method to analyze the progression patterns of glaucoma by using a real glau-coma patient dataset which is given as Figure 1(a). We can observe a characteristic special feature on the visual eld of glaucoma eyes as shown in Figure 1(b), (c). The red straight boundaries divide progression areas in both gures. We call this characteristic structure Direct Product Structure in this paper. To effectively mine knowledge from the dataset, we embed this direct product structure into our model. Past studies on pattern clustering of glaucoma primarily used a Gaussian mixture model [21] and independent component analysis [3]. These methods could not embed spacial infor-mation into the analyses, and the number of clusters had to be given in advance. Therefore, we propose a novel cluster-ing method that embeds speci c features of glaucoma into the model, and can automatically choose the best number of clusters. To the best of our knowledge, this is the rst approach of its kind in glaucoma analyses.
 We focus on spatial information in glaucoma progression. We show two sets of visual eld data in Figure 1(b), (c). We can see that the red straight boundaries divide progression areas in both gures. However, these boundaries are similar but in slightly different positions. Therefore, a clustering technique is needed that classi es data with similar direct product structures together by tolerating slight differences in their spatial positions. We implemented this architecture by coding such features into our proposed technique. Un-der the minimum description length (MDL) principle [18], our proposed hierarchical clustering method obtains opti-mal clustering division where the total code length required for encoding the data as well as the clustering structure is minimum. We speci cally employ the normalized maximum likelihood coding (NML) [18] for the encoding of data.
Our method worked better than comparative methods in clustering an arti cial dataset. We further found progressive patterns in the real glaucoma dataset. Our method sensi-tively detects the difference of progression stages in glau-coma. Moreover, we applied our clustering method to the prediction of glaucoma progression. Liang et al. [10] re-cently proposed a framework for predicting glaucoma pro-gression on the basis of spatio-temporal pattern clustering. By using our clusters in the clustering part of Liang et al.'s framework, we were able to signi cantly improve the predic-tion accuracy with a few data points in previous works.
The novelty of our research can be summarized in the following: (1) A novel clustering method of visual eld data on glaucoma; (2) Mining deep knowledge in ophthalmology.
We rst propose a novel clustering method considering speci c features of glaucoma. Many past studies did not use the spatial information of the visual eld for clustering visual elds. The relevant spatial information constitutes important knowledge because the progression of glaucoma is deeply correlated with the spatial patterns of the optical nerves. Our proposed method embeds characteristic direct product features into our models and tolerates slight dif-ferences in boundary positions of divided ares in glaucoma (see Figure 1(b), (c)). Moreover, we employ bottom-up hi-erarchical clustering based on the MDL principle, which can automatically determine the number of clusters.

We obtained the following knowledge of glaucoma using this method. Firstly, we can divide visual eld data into clusters which correspond to damaged areas of visual eld. This was not achieved in previous works. Secondly, we nd that obtained clusters can re ect the time evolution of visual eld in glaucoma progression. This result agrees with the clinical knowledge. Finally, we nd that obtained clusters can contribute to the improvement of the prediction accu-racy by applying them into the previous prediction method.
Because numerous studies have been conducted in the eld of glaucoma progression prediction, we summarize here a few recent studies involving the embedding of glaucoma-speci c features into models. Liang et al. [10] proposed a prediction method based on spatio-temporal clustering. This method collects data regarding patients with similar progressive patterns to form a prediction target patient. Maya et al. [12] proposed a prediction method based on a multi-task learning algorithm. Their method does not ap-ply clustering to patient data for prediction, but instead uses a multi-task learning algorithm. Murata et al. [13] proposed a prediction method based on variational Bayesian learning. Their method involved embedding spatio-temporal patterns of glaucoma patients into their models. Hirasawa et al. [9] investigated the relationship between the inspection points and progression rates. Asaoka [2] clustered the inspection points to understand the feature of regions.

In past research involving the clustering of the progressive patterns of glaucoma, a Gaussian mixture model was used to show the correspondence of the clustering results and the existence of glaucoma [21]. Independent component analysis was employed to show the feature detection of the clusters [3 ]. However, these methods embed neither speci c feature of glaucoma nor the relevant spatial information into their models. The relationship between the local points of the visual eld and optical nerves has also been studied [6].
The visual eld data of glaucoma can be treated as image data. The scale-invariant feature transform (SIFT) algo-rithm [11] and the histogram of oriented gradients (HOG) feature descriptors [4] have been used in image processing. Although rotated patterns of glaucoma are different features because spatial positions are important, SIFT is consistent for rotating and scaling pictures, i.e., SIFT does not suit our setting. Thus, to apply these features quantities to cluster glaucoma progression patterns, HOG is better than SIFT.
With regard to past studies on clustering methods related to our work here, a method combining the Gaussian mixture model and Laplacian regularization was proposed [7]. Hirai and Yamanishi [8] proposed an automatic decision of the number of clusters using a normalized maximum likelihood distribution. Papadimitriou et al. [14] proposed a top-down hierarchical clustering method based on the MDL principle.
This paper is organized as follows: In Section 2, we intro-duce the glaucoma dataset. In Section 3, we show the frame-work of our proposed method based on the MDL principle. The code length of our model is introduced in Sections 4 and 5. In Section 6, we provide the details of our proposed algorithm. We show the experimental results for the arti -cial dataset in Section 7 and those for real glaucoma dataset in Section 8. We conclude our paper in Section 9.
The local points over the visual eld are shown in Fig-ure 1(a). The black parts are local points where diagnoses are not made. The number of local points is 74, and an integer called total deviation (TD), representing the loss of visual strength, is measured at each local point. The range of TD is approximately [-40, 0]. A small value of TD implies advanced damage of glaucoma at the relevant local point.
Glaucoma data are characterized by visual eld data that often have direct product structures. The positions of the boundaries to specify the direct structures on visual eld are not necessarily congruent (see Figure 1(b), (c)).
As shown in Figure 1(a), the visual eld data has a grid-like structure and many points do not correspond to values. We complement these values with neighboring values of TDs for analyses. See Figure 2 for this compliment procedure. Values of the six points on each corner are determined as the mean of the TD of the neighboring four points. Values of the two points (blind spots) located at the center-left are determined as the mean of the TD of neighboring three diagnosis points. Finally, we round these determined values because a value of the TD is an integer. As written above, many missing values in the original data shown as boxes with red line in Figure 2(a) are completed in Figure 2(b).
Our proposed clustering method divides a set of visual elds of glaucoma patients into several clusters. We employ a code length as a criterion to determine the optimal clus-tering division. Let us express the dataset with a series of codes f 0 ; 1 g , e.g. 010, according to a coding rule. Then, Fi gure 2: Complementing missing values (red boxes). (a) Original data. (b) Complemented data. Fi gure 3: A schematic gure of our proposed method. (a) A sketch of our proposed hierarchical clustering. Each Square is visual eld data. Sev-eral clusters are merged at each step. (b)-(e) Proce-dure to obtain the code length. (b) Obtain the code length of the rule of dividing clusters (RCcode). (c) Visual eld data belonging to one cluster. (d) Ob-tain the code length to represent the direct struc-ture (SCB). (e) Obtain the code length to produce elements in each region (SCR). the dataset can be converted into a series of codes. The code length is the length of this series of codes. Under the minimum description length ( MDL ) principle [18], the opti-mal selection is chosen when it achieves the minimum code length. The code length of our clustering model is composed of two parts: the code length of the rule of clustering divi-sions ( RCcode ) and the code length of each of the divided clusters ( DCcode ). Under the MDL principle, optimal clus-tering division is obtained by minimizing the code length of our clustering model. However, it is difficult to obtain opti-mal clustering division because of its large time complexity due to the large number of possible clustering divisions.
In this paper, we propose a bottom-up hierarchical cluster-ing method (BHCM) which clears up this large time com-plexity by merging several clusters for each step. Further-more, we embed characteristic spatial structures of the vi-sual elds of glaucoma patients, the direct product struc-ture (see Figure 1), into our model. This idea is effective in clustering glaucoma datasets. Its procedure is schematically shown in Figure 3. Our method obtains clustering divisions by minimizing code length, the sum of RCcode and DCcode. Before introducing the detailed architecture of BHCM, we provide details of RCcode in Section 4 and DCcode in Sec-ti on 5. The procedure to obtain the code length is schemat-ically illustrated in Figure 3 (b)-(e).
Let us divide data from N visual elds into M clusters where the size of each cluster is k m ( m = 1 ;:::;M ). Note that the number of possible assignments of the visual led data is M 2 := N ! = ( k 1 ! k 2 ! k M !).

We code the rule of clustering division by considering the information necessary to describe the implementation of the division. In this case, we need M + 2 natural numbers M , f k m g , and M 2 . Note that we can record the realized assign-ments of visual eld data using M 2 if we set a counting rule, e.g., the ascending order. The code length of any natural number m is log m := log(2 : 865) + log m + log log m [16]. Hence, the code length RCcode is given as RCcode = log M +
DCcode is the sum of the code lengths of all clusters. We focus hereafter on the code length of a single cluster. As in Section 2, the glaucoma visual pattern has direct product structures. We describe embedding this characteristic into our model in Section 5.1. The code length of our model is given as a stochastic complexity ( SC ) in Sections 5.2, 5.3, and 5.4. We optimize the code length in Section 5.5. We embed the direct product structure into our model. We assume that a visual eld data is an S T matrix. We divide this matrix into G H region s with boundaries being normal to the axes. Figure 4(a) is an example. Note that S;T;G; and H are common to all visual eld data.

We denote variables as follows: the number of visual eld data is n , the i th visual eld data is x i 2 R S T ( i = and vertical boundary positions on the i th visual eld data
Our proposed method allows different positions of bound-aries in visual eld data belonging to the same cluster. This is important to eliminate inessential difference in data. Al-though visual eld data showing similar progressive patterns should be combined in the same cluster, slight differences between two sets of patterns might occur, as shown in Fig-ure 4(a). Our proposed method combines these similar data patterns into the same cluster by using code length as a criterion because the code length decreases if the clustered visual eld data are similar.
Stochastic complexity (SC) is the code length of a dataset given a normalized maximum likelihood distribution P NML ( ) [17]. When a data item x is generated from P ( X j ), the maximum likelihood estimator ^ is obtained. P NML ( ) is then de ned as P NML ( X ) := ( P ( X j ^ )) = ( der this probabilistic distribution, the code length of x SC is described as log P ( x j ^ ) + log Fi gure 4: Examples of visual eld data. (a) Regions and boundaries are ( n;S;T;G;H ) = (2 ; 5 ; 5 ; 2 ; 2) and y f 0 ; 2 ; 5 g . (b) Parameters corresponding to regions. is often difficult to directly obtain SC, Rissanen [15] showed the approximation of SC under certain conditions as follows:
SC( x ) = log P ( x j ^ ) + k where I ( ) is the Fisher information matrix , x is the size of x , and k is the number of parameters. We employed the normal distribution as P ( ), i.e., represents mean and variance ( k = 2). When we restrict the integral intervals of the Fisher information matrix in Eq. (2) to 2 2 2 2 an d 2 2 2 [8], SC( x ) is given as log P ( x j ^ ; ^ 2 ) + log( x= (2 )) + 1 : 5 + + = 2.
We assume that the boundaries of the data for the i th pa-tient belonging to a cluster are generated by P ( y ( i ) ters. The SC of the g th vertical boundary SCBR( g ) and the h th horizontal boundary SCBC( h ) are then derived as Thus, the code length of the boundaries, de ned as SCB, is given as Note that we omit the boundaries g = 1 and h = 1 because they do not affect the division. In this section, we derive the SC of the divided regions. The number of cells f ( g;h ) within the ( g;h )th region is ob-tained as f ( g;h ) = y Th en, the SC of the ( g;h )th region SCRE( g;h ) is derived as We assume that visual eld data belonging to the ( g;h ) re-( g;h ) is the parameter of the ( g;h )th region. Thus, the code length of all the regions SCR is given as
In this section, we describe the optimization of the bound-clusters SCC. From Eqs. (5) and (7), SCC is derived as SCC = SCB + SCR. We note that SCB and SCR are functions of the boundaries. In the optimization procedure, procedures A-step and B-step are alternatively repeated ve times. In A-step, we update the positions of the boundaries under the condition that the parameters ( g;h ) , row ( g ) , and xed. In B-step, we update the parameters ( g;h ) , row ( g ) ( h ) under the condition that the positions of the boundaries are xed. Following the repetitions, we run an additional B-step to obtain maximum likelihood estimators ^ ( g;h ) , ^ row and ^ col ( h ) . Finally, we determine SCC using these estimated parameters. Note that while this architecture provides a lo-cal optimal SCC, our experiments indicate that our method is effective. The algorithm is summarized in Alg. 1. The ob-tained SCC is the criterion for clustering decision described in later Section 6.
In A-step, we update the positions of the dividing bound-aries using dynamical programming ( DP ). In particular, we extend Dynamic Time Warping [19] to apply to our model. We rst modify the code length of a cluster by obtaining the upper bound of SCC, and approximate it as follows:  X  + k + k +  X  +  X  Here, we use displacement from equally divided points of row f Sg=G g ( g = 1 ;:::;G 1) and column f Th=H g ( h = 1 ;:::;H 1). We de ne the displacement of the bound-aries from these points as part ( i ) row ( g ) := Sg=G y terms that did not correspond to the position of the divid-ing boundaries were omitted in Eq. (8). The derivation of Eq. (8) is omitted due to the space limitation.

A crucial modi cation in Eq. (8) from the original form of the SCC is that we can now separately analyze each patient's visual data. Recall that f ( g;h ) is the number of cells be-longing to the ( g;h )th regions of all visual eld data within a cluster. Even if a boundary of a visual eld data item changes, several values of f ( g;h ) change. This change affects all visual eld data. To overcome this problem, we introduce the displacement of boundaries from equally divided points f
Sg=G g and f Th=H g . This idea enables the enhancement of the size of visual eld data during DP. Moreover, this allows us to separately calculate the optimizing problem for each patient by modifying the summation of the i th visual eld data. Therefore, we can solve an optimization problem for each data item. Hereafter, we use the value obtained from Eq. (8) instead of the original code length.

We now introduce our use of DP. Our goal is to obtain the optimal value of Eq. (8) for the i th visual eld ( S T ) with G H regions, which is de ned as CDP [ S;T;G;H ]. A sub-problem then is to obtain the optimal value of Eq. (8) for the i th visual eld ( s t ) with g h regions, i.e., CDP [ s;t;g;h ]. Note that 1 s S; 1 t T; 1 g G; 1 h H .

In DP, a sub-problem for the i th visual eld ( s t ) with g h regions is generated by adding a new row or column to a smaller sub-problem where the visual elds are ( s 1) t or s ( t 1), respectively. This means that the visual eld ( s 1) t enhances to the visual eld s t by adding a new row and that s ( t 1) to that s t by a new column. Moreover, an option exists whether a new boundary arises or not in the new added row or column. Therefore, a sub-problem originates in four smaller sub-problems, and its CDP[ s;t;g;h ] is obtained from those of the smaller sub-problems.

Under this procedure, CDP[ s;t;g;h ] satis es the following formula as CDP[ s;t;g;h ] = min f E 1 ;E 2 ;E 3 ;E 4 g , where
E 1 = CDP[ s 1 ;t;g;h ] +
E 2 = CDP[ s 1 ;t;g 1 ;h ] log( P ( y ( i ) row ( g + 1) j row
E 3 = CDP[ s;t 1 ;g;h ] +
E 4 = CDP[ s;t 1 ;g;h 1] log( P ( y ( i ) col ( h + 1) j col where ( i;u;v ) indicates the divided region ( g;h ) to which x ( u;v ) belongs. Note that we exclude a pass whereby the denominators of Eqs. (9) and (10) are not positive candi-dates from CDP [ s;t;g;h ]. The initial condition is set at CDP [ u;v; 1 ; 1] with u 2 [1 : S ] and v 2 [1 : T ], where [ a : b ] := f x 2 Z j a x b g . Note that CDP [ u;v; 1 ; 1] are A lgorithm 1 The code length of visual eld data. I NPUT: Visual eld data x i 2 R S T ( i = 1 ;:::;n ) and structures of divided regions G H .
 OUTPUT: Code length of n visual eld data within a cluster (SCC). 1: Initialize the boundary positions of n visual eld data. 2: for l = 1 ! # of iterations (here, ve times) do 4: for i = 1 ! n do 5: Run A-step: we update the boundaries of the i th 6: end for 7: end for 8: Run B-step again. 9: We obtain SCC using the boundaries of all visual eld so lely obtained because the visual eld is undivided. When we nally obtain CDP [ S;T;G;H ], we can also obtain the boundaries by checking cases where a new boundary arises. The complexity of this DP is O ( STGH ) because we need to obtain a table with S T G H cells in DP. For n visual elds, the complexity is O ( nSTGH ). imum likelihood estimation using the data x ( f ( g;h )) . In the rst B-step, we set the initial conditions of the boundaries to y ( i ) row ( j ) = round(( j 1) S=G ) (2 j G ) and y ( i ) round(( j 1) T=H ) (2 j H ), where round( r ) gives r rounded to the nearest number. We note that only the rst terms in Eqs. (3), (4), and (6) correspond to the parameters.
We introduce the detailed algorithm of our proposed bottom-up hierarchical clustering method (BHCM). An initial con-dition of BHCM is that the visual eld of each glaucoma eye is considered to be one cluster, i.e., the number of clusters is the same as that of visual elds in the dataset. We merge these clusters based on the MDL principle, i.e., we merge some clusters into others to achieve minimum code length. Note that our BHCM tolerates slight differences in the po-sitions of the boundaries between clusters. We realized this by modeling the boundary positions using probabilistic dis-tributions. If some boundaries are similar and should be merged into the same cluster, the code length of our model will be shorter when these boundaries are generated by the same distribution than when they are generated by different distributions. On the contrary, for different boundaries, the code length of our model is longer when both boundaries have been generated by the same distribution than when they have been generated by different distributions.
First, we choose a cluster C 1 with minimum value of SCC from a set of size-one clusters. Note that clusters previously chosen are never chosen again. Second, we obtain SCC as CS 1 . Third, we obtain SCC as CS 2 for the case where C 1 and another cluster, C 2 , are merged. If CS 2 is shorter than CS we merge C 2 into C 1 in the fourth step. All clusters except C 1 are checked through this process. Fourth, we merge C 1 and the clusters selected in the third step. We repeat this procedure until no cluster can be selected. We choose the cluster with the minimum code length because such a cluster strongly expresses direct product structures, and thus is a reasonable selection as representative of the nal cluster.
A bene t of our proposed method is its small time com-plexity. This is effected by merging clusters all at once in the fourth step. For ordinal bottom-up hierarchical cluster-ing methods, a cluster is merged to only one other cluster. This is the key to applying bottom-up hierarchical clustering to analyses of glaucoma datasets.
In this section, we compare the performance of our pro-posed method with several other methods for using three progressive patterns of arti cial data. We generated arti -cial data with three patterns: direct product pattern, tree pattern, and step pattern (see Figure 5).
We show how to generate the arti cial data. The data structure is constructed as similar to glaucoma data, i.e., the arti cial data has direct product structure and is divided into several regions. Based on this condition, Our manner of generating each arti cial progressive pattern data item was as follows. We rst initiated the data as R 10 10 , i.e., S = T = 10. We then generated boundaries dividing the regions on the spatial data. We nally generated values of elements within each region from the normal distribution of which parameters are given based on corresponding regions.
We divided the spacial data into 3 3 regions with bound-aries. The boundary positions were denoted by y ( i ) row Z 4 of the i th data. They were set to y ( i ) row (1) = 0 ;y min f Z 1 ;Z 2 g ;y ( i ) row (3) = max f Z 1 ;Z 2 g , and y where Z 1 and Z 2 were given as Z 1 =  X  (3 + Z )  X  and Z 2  X  (6 + Z )  X  . Note that Z was drawn from the normal dis-tribution, with mean 0 and standard deviation 2, and  X  a  X  indicates the integer part of a . If Z 1 = Z 2 , we redraw them. The same procedure was repeated in the case of columns.
Generated data has three types of progressive patterns: direct product pattern, tree pattern, and step pattern. Note that tree and step patterns were generated by merging some regions (see Figure 5(b), (c)). Values of data were given by the normal distribution. Its means were de ned for each region as Figure 5 and SDs were all set to 1. We prepared 40 spacial data with the same condition and considered them as a cluster. For each pattern, we generated three clusters, i.e., we had 120 spacial data for each progressive pattern.
We introduce comparative methods in this section. A comparative method is de ned as a pair of a clustering method and data inputted to the clustering method.

We prepared three types of inputted data as raw data (RAW), smoothing data (SMO), and HOG[4]. When we input the data without change, we call it RAW. In SMO, each element of spacial data is exchanged for the averaged values of the ve points: the point itself and the neighboring four points, i.e. SMO gives local space information. HOG is a feature mainly used in image processing, and is useful for 4 3 : 24 10 4 4 : 05 10 4 3 : 88 10 4 4 : 37 10 4 4 3 : 03 10 5 3 : 58 10 4 3 : 48 10 4 4 : 19 10 4 4 3 : 40 10 5 3 : 36 10 4 3 : 37 10 4 3 : 54 10 4 Fi gure 5: Three spatial patterns. The mean param-eters of the normal distribution are shown in each region. (a) Direct product pattern. (b) Tree pat-tern. (c) Step pattern. detecting shapes of objects. In HOG, the size of cells and blocks are set at 2 and its dimension was reduced to 100 with principal component analysis due to its high dimension.
For clustering methods, we used Gaussian mixture models with Laplacian regularization (LAP) [7], Gaussian mixture models (GMM), and k -means clustering. We rst introduce LAP. Let x i 2 R d denotes the i th spacial data, where d = S T = 100. Then, the similarity matrix S 2 R N N among spacial data is S ( i;j ) = exp where D ( u;v ) = 1 = (dist( u;v )+1) : Note that dist( u;v ) is the Euclidean distance between the u th point and v th point. We set the hyperparameter to 10 d as in [7]. For these three clustering methods, we set the number of clusters to three which is the true number of clusters. Note that our proposed method automatically determined the number of clusters.
The eight comparative methods are summarized as fol-lows: (RAW + k -means), (RAW + GMM), (RAW + LAP), (SMO + k -means), (SMO + GMM), (SMO + LAP), (HOG + k -means), and (HOG + GMM).
Four evaluation indices of clustering are introduced in this section. We denote a set of spacial data correctly belonging to the i th cluster by L i , a set of those belonging to the j th cluster by C j , and N is the number of data items ( N = 120). We de ne Prec( L i ;C j ) := j L i \ C j j j C
L i j . Then, Purity is de ned as and InversePurity as measure is de ned as F-measure = where F ( L i ;C j ) = 2Prec( L i ;C j )Rec( L i ;C j ) = (Prec( L Rec( L i ;C j )) [5]. Then, Normalized mutual information (NMI) Fi gure 6: Results using arti cial data. (a) Result for direct product pattern. (b) Result for tree pattern. (c) Result for Step pattern. [20] is de ned as indices were within the range [0 ; 1], which indicates that the cluster was precise with high values.
In our method, we employed the normal distribution as described in Eqs. (3), (4), and (6). We set ( ; ) to (8 ; 8) in Eqs. (3) and (4), and (10 ; 8) in Eq. (6). The size of regions ( G H ) was chosen as that giving the shortest code length As a result, we chose ( G;H ) as (3 ; 3) for direct product pat-4 : 96 10 5 5 : 03 10 5 4 : 99 10 5 5 : 25 10 5 te rn, and (3 ; 2) for tree and step patterns. The code lengths of ( G;H ) is shown in Table 1. For each comparative method, we repeated 100 trials by changing initial conditions.
The medians of the evaluation indices of clustering are shown in Figure 6. Our method outperformed all methods in direct product and tree patterns but does not in step pat-tern. This showed that our method suits the direct product structure like glaucoma special pattern. On the contrary, for the step pattern, they are quite different from the direct product structure, therefore, our method did not work well.
The glaucoma dataset used in this paper was provided by the Department of Ophthalmology, The University of Tokyo. The dataset was composed of diagnoses of 1,086 eyes. Al-though each eye was diagnosed several times, we selected the visual eld data from the initial diagnosis. Therefore, we clustered 1,086 visual eld data items.
We employed the normal distribution and determined ( G;H ) in Eqs. (3) and (4), and (12 ; 8) in Eq. (6). The code length with ( G;H ) is summarized in Table 2.
 Our method determined the number of clusters as seven. The progressive patterns of these clusters and sizes of clus-ters are shown in Figure 7. The progressive patterns are gen-erated by weighted averaging visual eld data within each cluster. We omit the details due to the space limitation. Note that we show the values of only 74 local points on the visual eld which corresponds to actual diagnosis points (see Fig. 1(a)). We also note that the size of cluster # 7 was only one, therefore, we should consider it as an outlier. We present the results of the comparative method SMO+GMM. As the comparative method, we employed SMO as input data and GMM for clustering method because this combi-nation performed well on arti cial data. We set the num-ber of clusters in GMM to six in keeping with the number of meaningful clusters in our method. The progressive pat-terns and the sizes of clusters of the comparative method are shown in Figure 8. Each progressive pattern was generated by averaging the visual eld data within a cluster. Here, we show the comparison result of our method and SMO+GMM. Table 3 is a cross-table: The ( i;j )th element of this table represents the number of visual eld data items belonging to the i th cluster in our proposed method and the j th cluster in SMO+GMM. We can nd the signi cance information in the following four points.

First, our method clearly divides a complex cluster gen-erated by SMO+GMM into two simple clusters. As shown in Table 3, members of the cluster # 5 in SMO+GMM are divided into the clusters # 5 and # 6 in our method. For the clusters # 5 and # 6 in our method, damages of the Fi gure 7: Characteristic features of clusters in our proposed method. (a) The size of the cluster #1 was 569. (b) #2 277. (c) #3 96. (d)#4 49. (e)#5 48. (f) #6 46. (g) #7 1. Fi gure 8: Characteristic features of clusters in SMO+GMM. (a) The size of cluster #1 was 448. (b) #2 221. (c) #3 151. (d)#4 144. (e)#5 63. (f) #6 59. progressive patterns are on upper and lower area, respec-tively (Figure 7(e),(f)). On the contrary, for the clusters # 5 in SMO+GMM, damages entirely spread on the visual eld. This difference indicates that our proposed method can capture the two different progressive patterns.
Second, our method can sensitively detect the difference of progression stage. As similar to the rst point, mem-bers of the cluster # 2 in SMO+GMM are divided into the clusters # 1 and # 2 in our method. For the cluster # 2 in SMO+GMM, damages of the progressive pattern are un-clear (Figure 8(b)). In our method, however, damages of T able 3: Cross-table between our proposed and the comparative method.
 th e progressive patterns of the cluster # 2 is heavier than that of # 1 (Figure 7(a), (b)). This implies that our method sensitively detects the difference of progression stage.
Third, our method detects the progressive patterns spread-ing the lower area. For the cluster # 6 in our method (Fig-ure 7(f)), the damages on the visual eld clearly shown in the lower area. On the contrary, for the cluster # 3 in SMO+GMM (Figure 8(c)), the damages within the lower area are not so clear. This suggests that our method gath-ered visual eld damaged in the lower area more correctly.
Fourth, our method shows the progressive patterns which agrees with the clinical knowledge. Glaucomatous visual eld defect usually starts with nasal step (Figure 7(a)) and/or Bjerrum scotoma. Nasal step and Bjerrum scotoma are the names of areas in the visual eld. As the disease progresses these defects expand and can be merged to each other (Fig-ure 7(b), (d), (f)). With the further advancement, hemi eld loss in superior or inferior visual eld can be observed (Fig-ure 7(c)) sometimes excluding points which are adjacent to a horizontal line (Figure 7(e)). Thus, we see the time evolu-tion of progressive patterns. On the contrary, it is hard to nd such time evolution for the clusters of SMO+GMM.
In this section, we apply our clustering method to the prediction problem of future progression of glaucoma. It is known that damages caused by glaucoma do not recover, therefore, initial treatments to alleviate the progression of glaucoma are seriously important. From this viewpoint, ac-curate prediction using a few measurements is strongly de-sired and investigated by many studies [10, 12, 13].
We introduce Liang et al.'s work [10] to use it as an ex-ample for the applications of our clustering results into the prediction problem. Recently, Liang et al. [10] proposed a clustering-based prediction method. This method gathers patients who are similar to the target patient using spatio-temporal clustering, and generates a predictor by tting them to a linear function of time. Thus, by exchanging their clusters for our clusters, we can evaluate the effects of our clustering results on the prediction problem of glaucoma.
Here, we show the settings of our comparison. As the com-parative method, we employed the uv -em clustering method and the temporal-shift linear regression (TSLR) because this combination performed well [10]. The number of clusters of uv -em was set to 40 based on [10]. The performance of pre-diction is measured by the root mean squared error (RMSE) de ned as dicted and actual TD on the i th local point on the visual RMSE Fi gure 9: RMSE for the number of known measure-ments Q . Centers show the median of RMSE and the upper and lower ends show quantiles.
 Table 4: The number of wins of proposed and com-parative methods.

Q # of Prop. # of uv -em # of total p -v alue 2 6 00 4 86 1 086 6 : 00 10 4 3 5 85 5 01 1 086 0 : 0118 4 5 51 5 35 1 086 0 : 649 5 5 55 5 13 1 068 0 : 210 6 5 47 5 07 1 054 0 : 230 7 5 27 5 05 1 032 0 : 513 8 4 72 5 09 9 81 0 : 250 9 4 29 4 45 8 74 0 : 612 el d at the nal data point, respectively. The number of data points used for the learning is denoted by Q . We note that our clusters were generated using only rst diagnosis data without use of time information.

We compared RMSE of both methods varying Q 2 [2 : 9] through 10-fold cross-validation. As shown in Figure 9, our clustering results gave more accurate prediction than the comparative method in the sense of median for Q = 2 and 3. Moreover, we counted the number of wins of our method as summarized in Table 4. For Q = 2 and 3, our method was signi cantly better than the comparative method with p &lt; 0 : 05. To check the signi cance of this result, we conducted a binomial test with a null hypotheses that predictive abilities are equal for both methods. For Q 4, the null hypotheses cannot be rejected. This results imply that our clustering contains helpful information for prediction problem.
In this paper, we proposed a bottom-up hierarchical clus-tering method to embed speci c features of the visual eld data from glaucoma patients into a model. Our method classi es the visual eld data into several clusters based on the code length of the dataset. Under the MDL principle, optimal clusters are selected.

Our proposed method has performed well for an arti cial dataset. In the cases involving the arti cial dataset with direct product and tree patterns, our method has exhibited the best performance in comparative experiments. However, in case of datasets with step pattern, our method was infe-rior. This result re ects the architecture of direct product in our proposed method.

Using a real dataset of glaucoma, our method detected the characteristic progressive patterns. This result agrees with clinical knowledge of glaucoma progression. Moreover, we entered our clustering results into a prediction method based on spatio-temporal clustering, and found that pre-diction performance improved when our clusters were used. This implies that our clusters contain not only characteris-tic patterns, but also richer information that can extend our method to treat general problems in glaucoma.

In future research, we will investigate the capabilities of our method to provide more information for glaucoma treat-ment. With a larger patient dataset, we think that our method can provide more detailed features of the progressive patterns of glaucoma. This is supported by the automatic decision regarding the number of clusters in our method. Re-gardless of the size of the dataset, our method generates suit-ably sized clusters. Furthermore, our clustering results may be able to contribute to providing classi cation of glaucoma patients. By combining clustering results in large datasets with other information, such as risk factors, we may obtain deeper knowledge of glaucoma. This will contribute to the treatment of the glaucoma.
The authors thank for Mr. Fujino and Ms. Taketani of the Department of Ophthalmology, The University of Tokyo for providing us useful comments. This work is partially supported by JST-CREST. [1] J. Artiles, J. Gonzalo, and S. Sekine, \The [2] R. Asaoka, \Mapping glaucoma patients' 30-2 and 10-2 [3] R. Choudrey and S. Roberts, \Variational mixture of [4] N. Dalal and B. Triggs, \Histograms of oriented [5] B. Fung, K. Wang, and M. Este, \Hierarchical [6] D. F. Garway-Heath, D. Poinoosawmy, F. W. Fitzke, [7] X. He, D. Cai, Y. Shao, H. Bao, and J. Han, \Laplacian [8] S. Hirai and K. Yamanishi, \Efficient computation of [9] K. Hirasawa, H.Murata, H. Hirasawa, C. Mayama, and [10] Z. Liang, R. Tomioka, H. Murata, R. Asaoka, and K. [11] D. G. Lowe, \Object recognition from local [12] S. Maya, K, Morino, and K. Yamanishi, \Predicting [13] H. Murata, M. Araie, and R. Asaoka, \A new [14] S. Papadimitriou, J. Sun, C. Faloutsos, and P. S. Yu, [15] J. Rissanen, \Fisher information and stochastic [16] J. Rissanen. Stochastic Complexity in Statistical [17] J. Rissanen, \Stochastic Complexity in Learning," [18] J. Rissanen. Information and complexity in statistical [19] H. Sakoe and S. Chiba, \Dynamic programming [20] A. Strehl and J. Ghosh, \Cluster ensembles|a [21] S. Youse , M. Goldbaum, M. Balasubramanian, F.
