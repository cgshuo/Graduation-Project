 1. Introduction
The new human X  X omputer interaction technologies offer increasingly natural ways to operate and communicate with machines. Ranging from voice to vision, all these interaction technologies are helping to drastically change the way people operate computers. Within all these interaction methods, gesture recognition plays an important role due to the universal use of signs and gestures for human communication ( Stokoe, 1972 ). This fact increases the relevance of sign recognition, pointing it as a growing research area with countless application fields. Even so, sign recognition raises new technical challenges.
Classification, segmentation, training and sensor noise processing are only a few of the issues that must be tackled in this kind of system. To this end a wide range of architectures and algorithms are being posed, 1 although the complexity of each of the tasks makes it difficult to develop a complete system.

The research presented here is based on the real time recognition of the Fingerspelling Alphabet, an alphabet used by the deaf. The use of data gloves and accelerometers has been selected for this work from the different technologies available for gesture and sign recognition, specifically a 5 DT Data Glove 14
Ultra , 2 a glove typically used for motion capture in computer animation, and a MTx , 3 an accelerometer providing information about acceleration, angular velocity and orientation.

The machine learning ( Mitchell, 1997; Russell and Norvig, 1995 ) field offers a wide range of algorithms capable of extracting rules and patterns from the available data. This feature makes the use of these algorithms suitable for the problem of sign recognition. Even so, the real time nature of gesture recognition brings to light new issues not present in other kinds of classification problems.

On account of the problems related to the real time application of machine learning algorithms, this paper presents a two-tier architecture for sign recognition. In the first stage, the glove and accelerometer signals are processed for segmentation purposes, identifying the different signs performed over time. In the second stage, different classifiers are used to recognize the signs identified in the segmentation phase, taking advantage of the features of hierarchical classifiers and signal processing to obtain a higher recognition rate. Some experiments are also carried out to test the accuracy of the proposed architecture. The results obtained from this two-tier approach are promising.
 The rest of the article is structured in the following manner:
Section 2 gives information about previous research activities related to this paper. Section 3 describes the Fingerspelling Alphabet used in this research. In Section 4, the data glove and the accelerometer used in the experiments are described. Section 5 presents the proposed architectur e for gesture recognition and the experiments done to validate it. In Section 6 the proposed architecture for movement recognit ion is presented, including the validation process applied. Section 7 describes the system imple-mentation process carried out, incl uding the new functionalities, the complete architecture and a final validation. Finally Section 8 presents the conclusions obtain ed and the future work to be done. 2. Related work
Gesture recognition opens a new research area with multiple application domains. The different technologies available nowa-days make it possible to address the recognition task from many perspectives. Ranging from cameras to sensors, many different approaches to the posed problem can be suggested, each of them with its specific features and difficulties.

The use of cameras is common practice in sign and gesture recognition. Several approaches have been presented in an attempt to overcome the specific problems of vision-based recognition. Dadgostar (2005) proposed a three-tier system for gesture recognition. The first two tiers were devoted to skin detection and object tracking, respectively, trying to find the areas of interest and the movement to classify. In the third-tier, the gesture recognition task was performed by means of Neural
Networks. Hasanuzzaman et al. (2007) , on the other hand, presented a knowledge-based gesture recognition platform using a multi-cluster based learning method. In this approach static and dynamic gesture images were analyzed and classified using a hierarchical database of labelled images. Brashear et al. (2003) proposed a combined approach, incorporating an accelerometer to increase the recognition rates of the vision-based sign recognition. Data provided from both a hat-mounted camera and an accelerometer is processed by hidden Markov models (HMM) to recognize gestures from a restricted sign language.
In the same way, several works based on the use of data gloves could also be found. Due to the wide range of application domains of data gloves, it is possible to find articles tackling issues such as the analysis of different classification systems to identify objects ( Heumer et al., 2007; Ibarguren et al., 2006 ) or the use of the gloves for cooperation and interaction with robots ( Dillmann, 2003 ).
Concentrating on sign recognition through data gloves, diverse literature can also be found. Kadous (1996) has worked on the recognition of some AUSLAN signs (Australian Sign Language) by means of Decision Trees and Instan ce-Based Learning. The proposed approach initially extracts differe nt features from the information provided by the glove (features such as distance, energy and time), in an effort to characterize the gesture. This information is used afterwards for classification p urposes by means of Decision Trees and Instance-Based Learning. In the same way, Fels and Hinton (1993) have developed a system that relates hand gestures to speech through an adaptive interface. To this end three different Neural
Networks are used to process the information provided by the glove, dividing the classification task into different stages.
Classifier combination ( Gunesetal.,2003;Hoetal.,1994;Lu, 1996 ) is one of the most interesting research fields within machine learning because it makes possibl e an increase in the recognition rates of the basic classifiers by their combination. Even so, the ways of combining and selecting the classifiers is still an open research topic due to the wide range of possibilities which exist. One of the main ways to combine the classifiers is by creating hierarchies, although there are countless ways in which this can be done. Jordan and Jacobs (1993) proposed the use of the Expectation-Maximiza-tion (EM) algorithm for adjusting the parameters of a tree-structured architecture. In the same way, Mart X   X  nez-Otzeta et al. (2006) propose the use of genetic algorithms for the creation of the hierarchy and the election of the different basic classifiers. These different approaches show the complexity of the task and the variety of methods used to tackle it.

Finally feature subset selection (FSS) ( Liu and Motoda, 1998; Inza et al., 2000; Peng et al., 2005 ) offers a useful tool to increase the recognition rates of classifiers as well as uncover the significance of the different variables available. Among the different techniques for feature selection, genetic algorithms ( Goldberg, 1989; B  X  ack, 1996 ) are being increasingly used for this task ( Yang and Honavar, 1998 ) due to their capacity to escape fro m local minimums/maximums. Previous experiments around data gloves ( Ibarguren et al., 2006 ) have shown the suitability of using this kind of Evolutionary Algorithms in recognition problems. 3. Sign language
The Fingerspelling Alphabet used in this experiment is formed of 30 signs describing the different letters of the Spanish alphabet (English alphabet plus ch , ll , ~ n and rr ). Those signs are performed combining both hand gestures and hand movements. Based on the sensors chosen for this research, the first group of signs (hand gestures) will be tracked by means of data gloves while for the second group (hand movements) the previously presented accelerometer will be used. 3.1. Hand gesture
Focusing on sign recognition using only data gloves, 12 of the 30 signs have been removed as in their case, it was necessary to know the hand position (upwards or downwards) or the hand movement of the speaker after performing the sign. This has reduced the number of signs to be recognized to 18, resulting in an alphabet
Besides the signs constituting the Fingerspelling Alphabet, two more classes have been introduced related to the real time recognition:
Hand at rest : This class describes the hand while performing no sign, represented by an open hand. This  X  X  X ign X  X  is used when starting or finishing the spelling or to separate the different words of the sentences. Due to its significance in the spelling process, this class is treated as a new  X  X  X ign X  X  during the experiment.
Hand in transition : This class describes the hand in motion while changing from one sign to another. It is not strictly a hand gesture (countless gestures are produced while changing signs). This class just denotes that the user X  X  hand is in movement, something which significantly increases the diffi-culty in its detection and justifies the special treatment of this class during the experiment.

With these additions, the total number of classes rises to 20 in this recognition problem: the 18 signs, the hand at rest and the hand in transition. 3.2. Hand movement
To be able to represent the other 12 letters removed previously, the Spanish Fingerspelling Alphabet uses six hand movements that are combined with hand gestures, movements shown in Fig. 2 . Those six movements require one to (I) represent a J with the hand, (II) move the hand left-and-right twice, (III) flex the hand downwards, (IV) represent a circle with the hand, (V) move the hand up-and-down twice and (VI) represent a Z with the hand. Combining those movements with the aforementioned gestures the interlocutor is able to represent the 30 letters constituting the Fingerspelling Alphabet. 4. System requirements 4.1. Data glove
The already mentioned 5 DT Data Glove 14 Ultra , see Fig. 3 , has been used for this experiment: a glove that provides information about finger flexure and abduction between fingers, typically used for motion capture in computer animation. The glove is composed of 14 sensors, two sensors to measure the flexure of each finger and one to measure each abduction. Each sensor provides a real value between 0 and 1 with a frequency up to 60Hz. 4.2. Accelerometer For movement recognition purposes the already mentioned
MTx , see Figs. 4 and 5 , has been used. This accelerometer provides information about 3D acceleration, angular velocity and orientation in the right handed Cartesian co-ordinate system with a frequency up to 512Hz. 5. Proposed approach for gesture recognition
Real time gesture recognition reveals new issues not present in off-line classification problems. The 14 continuous signals re-ceived from the glove make preliminary signal processing necessary before data can be classified, to try to separate and identify the different signs performed by the system user. The proposed approach poses a two-layer architecture for gesture recognition, a segmentation layer and a classification layer, as can be seen in Fig. 6 .

Segmentation layer : In the first stage, the signals provided by the glove are collected and analyzed, in an effort to identify the moments in which the user is performing a sign or in which the hand is at rest. The idea is to distinguish the transitions from sign to sign as a first step in the classification problem. To this end, a time window structure is used to store the last glove data received and analyze it dynamically. Once those moments where the signs are performed (or the hand is at rest) are identified, one glove reading is collected (14 real values) and sent to the second classification layer for the signs to be recognized.

Classification layer : In this classification layer a distance-based hierarchical classifier has been proposed, to make use of the features of hierarchical classifiers. Based on a glove reading (14 real values between 0 and 1) provided by the segmentation layer, this classification layer returns the sign related to the analyzed data. In an attempt to simplify system training, the classifier has been created using only one case of each class (the 18 signs plus the hand at rest). The main reason for this decision is to simplify as far as possible data acquisition and the system initialization, making it more user-friendly. In the same way, this decision makes necessary a careful information processing procedure for the classifier creation due to the scant information available. 5.1. Segmentation layer
As previously described, the continuous signals provided by the Data Glove are processed initially by means of the segmenta-tion layer. The main reason to include this layer is the difficulty in determining statically (by means of a single glove reading) when the user is performing a sign or is in transition (with the hand in movement while changing from one sign to other). Previous experiments ( Ibarguren et al., 2007 ) showed the real problem of transition detection by means of single readings. This fact makes it necessary to create a segmentation layer to process dynamically the signals provided by the Data Glove.

Fig. 7 (a) shows the signals collected while performing some signs over a period of time. It can be seen that the signals are quite stationary while representing the signs. On the other hand signals change drastically in the transition periods. This feature is used for segmentation purposes, detecting those stationary zones in the collected signals.

The proposed segmentation layer works using a time window of 15 glove readings, a buffer with the last 15 readings of the 14 sensors of the glove. Over this time window the produced signal variation is calculated using the formula (1), where Val represents the value of sensor j in time i . In this way the signal variation over the time window is calculated and characterized. Fig. 7 (b) shows the variation values obtained from the signals shown in Fig. 7 (a).
Once the signal variation is calculated, it is necessary to detect the local minimums (the minimum of the valleys), as they represent the moments where the hand is stationary while performing a sign, as shown in Fig. 7 (c). This is done using another buffer where those variation values are stored. This buffer is analyzed to determine whether the central value is the minimum of that valley. To avoid errors in the local minimum detection, maximums detection and thresholds are introduced in
Once the local minimums are detected, the moments in which the user is performing a sign, the corresponding glove reading is sent to the classification layer to be classified (14 real values that characterize the hand gesture). 5.2. Classification layer
In this second layer the segmented readings from the glove signals are classified with the purpose of recognizing the performed sign. As stated before, the idea behind this approach is to classify those new readings using only one training case per class. The main reason for this decision is to simplify as far as possible the data acquisition phase, making system initialization easier.

Previous experiments ( Ibarguren et al., 2007 ) pointed to distance-based classifiers as one of the best algorithms for this kind of sign recognition problem, due to their capacity to avoid the problems related to sensor noise and their ability to make good predictions based on very few training cases. Even so, several problems have been detected when trying to recognize very similar signs. This explains the need for a multi-classifier method to distinguish between those similar signs, trying to raise recognition rates with the help of the algorithm combination. The proposed approach poses the combination of the above-mentioned ideas, creating a distance-based hierarchical multi-classifier.

As stated before, the classifier has been created using only 19 cases (18 signs and the hand at rest), each of them composed of 14 real values between 0 and 1. Once the database had been established, a centroid-based hierarchical clustering was applied using the Euclidean distance as a unit of measurement. Fig. 8 shows the resulting dendrogram. A detailed analysis of the dendrogram shows that the most similar signs (a/e, f/o, g/l and r/u) form clusters in the lowest levels of the hierarchy. This means it is possible to work in a more accurate way when trying to recognize the similar signs in the lowest levels of the tree.
Based on the information obtained from the clustering process, the system generates automatically a dichotomic tree structure, as shown in Fig. 9 , where in each of the nodes and leaves a 1-NN classifier is posed (a K-NN classifier where K  X  1). Starting from the initial node, the new case to be classified is compared with the different signs of the node, searching for the closest case. Once the most similar sign is identified, the new case to be classified is sent to the inferior node that contains the most similar sign. This process is repeated until a leaf is reached.

To overcome the problem of distinguishing between the similar cases (a/e, f/o, g/l and r/u), the system takes advantage of the tree structure, performing a specific classification in the lowest level nodes. In those nodes only some of the sensors X  information is taken into account for classification purposes, that which differentiates one sign from another, as shown in Fig. 10 .In this way, only the most relevant information is analyzed by the 1-NN classifier, leaving out the information that could cause variations in the prediction. The idea behind the proposed approach is to analyse in greater depth the details of the new gesture as the lowest level nodes are reached, trying to leave out the information that could add noise and disturbances to the classification.

To this end, a weighted 1-NN algorithm is applied in the a/e, f/o, g/l and u/r leaves. The idea is to measure the distance between two signs taking into account only some of the sensors. Initially four masks were created (2), (3), (4) and (5), each of them representing the sensors that measure the differences between the two signs. The masks are formed by 14 values (0 or 1) that represent whether the sensor i is relevant (value 1) for the classification or not (value 0).
 Mask ae  X f 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 g X  2  X  Mask fo  X f 1 , 1 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 g X  3  X  Mask gl  X f 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 g X  4  X  Mask ur  X f 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 , 0 , 0 , 0 , 0 , 0 g X  5  X  The masks are used to apply a weighted 1-NN in those leaves.
The Euclidean distance of only the relevant sensors is calculated using formula (6) for measuring the similarities between the signs. Once the distance to the two signs is calculated, the new case is labelled with the class related to the nearest sign. Dist  X  A , B  X  X 
To sum up, the new case to be classified is hierarchically analyzed. In each step a 1-NN classifier is used, searching for the most similar sign and once identified, the new case is sent to the lower cluster which contains the sign. This process is repeated until a leaf is reached, where the new case is labelled. If the nodes with similar signs (a/e, f/o, g/l or u/r) are reached, the weighted 1-NN algorithm is applied to classify the new case. 5.3. Experimental set-up and results
To test the efficiency of the proposed approach, five sentences were spelled and classified by the two-layer architecture. During the data acquisition process, the 12 r emoved signs were omitted from the spelling, leaving only the letters included in our 18 sign alphabet. The hand at rest  X  X  X ign X  X  was also represented at the beginning and at the end of the sentences (to start and end the spelling with a neutral sign) and to symbolize the spaces between the words. Every sentence was spelt by the same person during separate sessions. Readings were captured in a continuous form, creating different files with sequences of chronologically ordered readings. A total number of 633 letters were written and a total number of 60336 readings were collected during the spelling process. This validation was done for the two layers of the proposed architecture, the segmentation layer and the classification layer.

Segmentation layer validation : This experiment tries to measure the correct segmentation rate, following the proposed approach. To this end, the five files containing the spelled sentences are sent to the classifier to be analyzed. Each sentence is a sequence of signs and spaces between words ( hand at rest ) that must be segmented. The validation measures how many gestures (signs and hand at rest ) are properly segmented. There are three types of errors: (a) letter or space disappearance, (b) letter repetition and (c) letter not performed.

Classification layer validation : This experiment measures the recognition rate of the classification layer. The readings provided by the segmentation layer are classified and labelled by the distance-based hierarchical classifier as a sign or the hand at rest . The recognition rate reveals the percentage of correctly classified cases. The only error type in this validation process is where a case is labelled incorrectly.

The results obtained can be seen in Table 1 . The second column of the table shows the number of signs in the sentence, hand at rest included, and the number of characters in brackets. The third and fourth columns show the errors (missing characters and character repetitions) and success rates of the segmentation layer. The last two columns give information about the errors and the success rates of the sign classification.

The proposed segmentation layer obtained good results, reaching a 100% success rate in some of the sentences. Even so, there are still problems concerning segmentation when there is a small finger change between two signs or the sign is not performed properly (i.e. performed in two stages or with rectifications). In those cases it was necessary to apply thresholds in the minimum and maximum detection, although this did not help to eradicate the problem completely.

The classification layer also obtained good results, reaching recognition rates up to 94%. The distance-based hierarchical approach allows high recognition rates based on only one training case for each of the classes. Thanks to the hierarchical structure it is possible to analyze in greater depth the differences between the signs as the lowest levels of the tree structure are reached. Even so, although most of the gestures were properly recognized there are still difficulties when classifying cases which belong to signs with similar gestures.

Finally, the proposed architecture is able to recognize the 18 well as the hand at rest and the hand in transition. Even so, considering the purpose of this research, it is necessary to recognize the whole Fingerspelling Alphabet to build a real sign recognition system. As described above, the analyzed sign language uses both hand gestures and hand movements to represent all the letters. Taking this into account and after observing the good results of the proposed approach for gesture recognition, the next step of this research has to tackle the movement recognition issue. The next chapter describes the proposed approach for movement recognition as well as the experiments carried out to validate it. 6. Proposed approach for movement recognition
Real time movement recognition reveals new issues not present in off-line classification problems nor in gesture recogni-tion problems. Although movement recognition also raises the question of segmentation, the classification task reveals the dynamic nature of the movement recognition. Movements are not static actions that can be characterized with a single reading of a sensor but an action that happens during a period of time.
Therefore this time, after the segmentation phase, the system needs to deal with a set of accelerometer readings received during a period of time and not only a single reading as in the gesture recognition problem. The proposed approach poses a two-layer architecture for movement recognition, a segmentation layer and a classification layer, both of them dealing with time series, as illustrated in Fig. 11 .

Segmentation layer : In the first stage, the nine signals provided by the accelerometer (accelerations, angular velocities and orientations) are collected and analyzed, trying to identify the moments in which the user is performing a movement or in which the hand is static. To this end, a time window structure is used to store the last accelerometer data received and analyze it dynamically. Once those time periods of movement are identified, the set of accelerometer readings related to those periods (N readings of the accelerometer) are sent to the second layer to be classified.

Classification layer : In this second layer a classification process is started, trying to determine to which of the six movements the group of N readings provided by the segmentation layer belongs.
The main problem of this stage of the recognition is the dynamic nature of the movements; this time the system has not a unique accelerometer reading for the classification but a set of N readings. And in the same way the size of this set of readings may vary due to the dynamic nature of the action. Because of that it is necessary to address this classification process from a signal processing point of view and not only as a regular classification problem. In an attempt to simplify system training, the different classifiers have also been created using only one case per class, as occurred in the gesture recognition problem. As pointed out in the gesture recognition chapter, one of the main characteristics of the proposed architecture is its capacity to simplify as far as possible the system initialization, making the system as user friendly as possible. 6.1. Segmentation layer
As stated previously, the continuous signals received from the accelerometer are stored and analyzed initially by means of the segmentation layer. The main reason to include this segmentation layer in the proposed architecture is the difficulty in identifying the different movement periods by means of a single acceler-ometer reading. It would be easy to notice if the hand is in movement analysing the different values of a single reading provided by the accelerometer but the identification and extrac-tion of the different movement periods need a deeper signal analysis. To this end a segmentation layer has been created, trying to identify and extract the time series related to the different movements performed.

Fig. 12 (a) shows the acceleration signals received while performing some movements over a period of time. It can be observed that the signals are stationary while no movement is drastically during periods of movement. This feature is used for segmentation purposes, extracting those changing zones from the received signals.

This segmentation layer works using a time window of 10 accelerometer readings, a buffer with the last 10 readings of accelerations, angular velocities and orientations. A previous data analysis showed that the acceleration signals are the most significant ones, characterizing the movement in a effective way. Based on this fact, over this time window the combined signal energy of the accelerations is calculated using the formula (7), where Acc represents the value of acceleration on axis X / Y / Z in time i . In this way the combined signal energy is calculated.
Fig. 12 (b) shows the combined signal energy values obtained from the accelerations shown in Fig. 12 (a).

E
Once the combined acceleration energy is calculated, it is necessary to detect the increases in the energy signal to identify the periods of movement, as illustrated in Fig. 12 (c). Specifically it is necessary to identify those peaks located between the arrows as they represent the periods of high signal energy and consequently the periods of movement. To this end a threshold value has been applied, a threshold able to detect the different periods of movement as it cuts the energy signal, separating the peaks from the valleys.
Once those periods of movement are detected, the set of readings related to those periods is stored and sent to the classification layer to be classified (a set of N accelerometer readings including accelerations, angular velocities and orienta-tions in axis X / Y / Z ). 6.2. Classification layer
In this second layer the segmented set of accelerometer readings are classified with the purpose of recognizing the performed movement. The main problem of this classification process is the variability of the length of the time series. Due to the dynamic nature of the action to be detected, the different periods of movement will have a different length. This will make the classification task more difficult, making it impossible to apply a direct classification due to the variability in the number of attributes of each case. Trying to avoid the aforementioned problem, this approach proposes a pre-process o f the provided data, extracting a number of features from the diffe rent accelerometer signals. This way, each time series will be converted into an array of M values or characteristics, independent of the length of the time series. Over those arrays of M values, the classifiers will be created. 6.2.1. Signal pre-processing
Having decided the application of a pre-processing phase, it was necessary to identify the signal characteristics that allow the description of the different movements in a suitable way. To this end, a number of signal parameters were defined initially. In this stage of the recognition task the orientation data was eliminated due to the variation in its values as the hand can easily change its position and orientation while using the sign language. Over the acceleration and angular velocity signals in axis X / Y / Z the next parameters were defined:
Number of readings: This parameter, which characterizes the whole set of readings, represents the number of readings included in the time series.

Signal energy: By means of the signal energy, calculated with formula (8), it is possible to characterize the movements distinguishing signals with higher amplitude from the lower ones. E  X 
Positive signal energy: In this case the signal energy is calculated but taking into account only the positive values of the signal, as illustrated in formula (9). This time the calculated energy will be related to one of the sides of the coordinate axis.
This way it will be possible to characterize the movement if it is not equilibrated and tends to deviate to one of the sides of the axis.

Negative signal energy: This time the signal energy is calculated but considering only the negative values of the signal, formula (10). This way the information of the positive signal energy will be complemented as illustrated in formula (11).
 E  X  E pos  X  E neg  X  11  X 
Number of peaks: Signal energy is able to characterize the movement although is some cases the number of peaks of the signal could be enough. For this reason it was decided to introduce the number of peaks, both positives and negatives, as a parameter for classification.

Number of positive peaks: As occurred in the case of the signal energy, it was decided to count the number of positive peaks. This way it will be possible to characterize irregular movements.

Number of negative peaks: This time the number of negative peaks of the signal have also been taken into account, complementing in this way the information about the number of peaks, formula (12).
 Peaks  X  Peaks pos  X  Peaks neg  X  12  X 
Once those seven parameters had been defined, one generic and another six related to each of the six signals provided by the accelerometer (acceleration and angular velocity in axis X / Y / Z ), it is possible to extract a total number of 37 characteristics. Using those 37 attributes the classification problem will be posed. 6.2.2. Experimental set-up
As stated in the gesture recognition section, one of the most important characteristics of a recognition system should be the simplicity of the initialization and training phase. Trying to apply this idea in the proposed architecture this time the classifiers will also be created using only one case per class.

Initially a database of 60 cases was created, performing each of the six movements 10 times. Once those 60 movements were extracted from the accelerometer signal and pre-processed, a complete database of 60 cases and 37 attributes was created. Applying the idea of using just one case per class for training purposes, this complete database was divided into 10 folds each of them containing one case per class, as illustrated in Fig. 13 .

Once those 10 folds were created and to obtain an accurate recognition rate of the proposed classifiers, a validation process was designed taking into account the simplification of the training phase. To this end, one of the 10 folds (six cases) is used iteratively as training database and the induced classifier is tested with rest of the folds (54 cases), see Fig. 14 . This process is repeated 10 times, training the classifier with each of the folds.
The final recognition rate is estimated by calculating the mean of the rates obtained in each operation. This validation method makes it possible to get reliable recognition rates based on classifiers induced using only one case per class. 6.2.3. Initial test
In an effort to obtain some reference recognition rates, an initial classification process was set up using three basic classifiers for this purpose. The selected classifiers were C4.5, K-
NN and Na X   X ve -Bayes. Based on these three algorithms, the idea is to analyze which type of classifier best fits in this movement recognition problem.

In the same time to test the efficiency of the proposed pre-processing method, three different training databases were used for each classifier:
Signal energy of accelerations: In this first training set only the signal energy of accelerations ( X / Y / Z ) and the number of readings were included, a total number of 10 attributes.
Signal energy of accelerations and angular velocities: This training set includes the signal energies of both accelerations and angular velocities plus the number of readings, a total number of 19 values.

Energies and number of peaks: In this final training set, all the information presented in the pre-processing section was included (signal energies and number of peaks of accelerations and angular velocities and the number of readings). This increases the number of attributes up to 37.

Based on those algorithms and training sets, Table 2 presents the obtained recognition rates after the validation process. It can be seen that the best results are obtained by the algorithms 1-NN and Na X   X  ve-Bayes. And in the same way, it is worth pointing out that the use of the whole training set for the creation of the classifiers does not improve the recognition rates in all cases. This last fact might point to the need for applying a process of attribute selection to identify the most significant ones. 6.2.4. Data discretization
In an attempt to improve the recognition rates obtained in the initial tests it was decided to apply another data pre-processing step before classification. Due to the nature of the attributes managed in this recognition problem, real numbers in a wide range of values [0 X 1000], a data discretization was applied over the previously presented databases. The main reason for this decision is the need to homogenize the managed data, decreasing the range of values to deal with.

To this end the MDL ( Fayyad and Irani, 1992 ) discretization method was applied. This algorithm allows data discretization, deciding on its own the number of nominal values and their range of values. After the application of the data discretization a new validation process was started, Table 3 presents the results obtained.

The discretization process has raised the recognition rates, by up to 97% in three of the cases. This time the best results are also obtained with the algorithms K-NN and Na X   X  ve-Bayes and using only information about the signal energy. Specifically the best result is obtained by the algorithm K-NN and using only the information about the signal energy of the accelerations. This allows a reliable movement recognition based on little informa-tion, a desired feature in this kind of system. 6.3. Genetic algorithms for feature subset selection
As a last step in the movement recognition task it was decided to apply a feature subset selection (FSS) ( Liu and Motoda, 1998 ) process. There are two main reasons for this decision. First, try to increase the recognition rates of the above mentioned three algorithms. Second, extract information about the most important attributes of the databases. Previous experiments did not show a clear relation between the different training databases and the recognition rates so it would be interesting to extract information about the most important signals from the accelerometer and the different features obtained from those signals. This information could help in further research activity around movement recognition.

The next lines offer information about the designed genetic algorithm and its different parameters:
Individuals : The purpose of this process is to select the best subset of the 37 attributes available. Taking it into account the individuals of the designed algorithm are represented as a binary array of 37 values, see Fig. 16 . Each value represents if the attribute n is in the selected subset (value 1) or not (value 0).
Fitness function : The aim of this optimization process is to increase the precision of the classifiers. To this end the recognition rate was selected as fitness function. This time the recognition rate is also calculated dividing the database in 10 folds and creating the classifiers using only one case per class, as done previously in the movement recognition task. If two individuals get the same recognition rate the one with less attributes selected will be considered better.

Population : The selected size for the population is 10 individuals, not allowing to have more than two individuals with the same representation. The initial population is created randomly in each algorithm execution.

Individual selection : The roulette wheel selection method is the used one in the designed algorithm. It allows a random selection but proportional to the fitness function, something that will help to escape from the local maximums.

Crossover : Due to the simplicity of the individuals X  representa-tion, the selected crossover method of the algorithm is the one-point crossover . The crossover is applied with a probability of the 90%. If the crossover is not applied a copy of both parents will be sent to the next steps of the algorithm.

Mutation : The mutation is performed selecting randomly one of the 37 values of the array and changing its value (from 0 to 1 or from 1 to 0). The probability to apply the mutation to each of the  X  X  X hild X  X  solutions is set in a 10%.

Once defined the different parts and parameters of the genetic algorithm, it was applied to the different machine learning paradigms used in the previous experiments. Those experiments showed different behaviours of the classifiers under the same training sets. Therefore it was decide to apply separated executions for each of the classifiers (C4.5, 1-NN and Na X   X ve -Bayes).

Fig. 15 illustrates the progression of the best individual and the mean recognition rate along the three executions of the genetic algorithm. Table 4 presents the final recognition rates obtained after the whole movement recognition process.

The execution of the genetic algorithms has raised the recognition rates, reaching a 98 X 99% for the algorithms 1-NN and Na X   X ve -Bayes. C4.5 has reached a recognition rate of 49%, still far from the other two paradigms. Those rates have been reached using between 11 and 14 attributes from the initial 37. This important reduction in the number of used attributes will help in the same way to reduce the computational weight of the data pre-processing, a desired feature due to the real time nature of the posed problem. A deeper analysis of the selected attributes points to the energies of the accelerations and angular velocities in axis X / Y as the most relevant signals for movement recognition purposes.

Once finalized the feature subset selection process by means of genetic algorithms, there are two main conclusions that could be extracted. First of all, the attribute selection process has raised the recognition rates of the classifiers as well as highlighted the importance of some accelerometer signals. This last information could be useful in future research activity around movement recognition. And in the same way, this attribute reduction will decrease the computational weight of the algorithm execution.
Those two conclusions point to genetic algorithms as a suitable method for feature subset selection aside the most common greedy methods. 6.3.1. Summary
To sum up, the proposed approach poses initial data pre-processing to homogenize the received time series and transform and reduce those sets of accelerometer readings in arrays of M values. In a next step, this array is discretized with the purpose of improving movement recognition. Once data is pre-processed, a
Na X   X ve -Bayes or 1-NN classifier is used to determine which of the six movements of the sign language has been performed. 7. System implementation
Once the architecture for both gesture and movement recognition has been defined, in a next step it is necessary to implement the above presented approach to verify its suitability.
This implementation exercise seems to be necessary as real utilization of the proposed architecture will inevitably reveal issues not taken into account in the different experiments. And in the same way, it is necessary to create a whole architecture able to combine both gesture and movement information.

The next lines will relate the process followed in this implementation exercise. 7.1. New functionalities
As cited above, the implementation of the whole recognition system has revealed some issues not present in off-line experi-ments. Those issues, enumerated below, make it necessary to add new functionalities and features to the recognition system.
Visualization : One of the main needs of this kind of system is the creation of a visualization tool. The visualization of the spelling process improves user experience as it helps to control the process and ensures the correct spelling of the sentences. To this end a graphical interface has been created, an interface that shows the spelled letters as soon as they are detected. Fig. 17 shows the developed graphical interface.

Error processing : The use of a recognition system will inevitably cause the appearance of errors in the spelling process, errors from both the recognition system and the user. Taking this into account it is necessary to introduce some kind of correction tool to erase those errors. To this end a new sign has been added, sign showed in Fig. 18 . This gesture allows the last letter shown in the graphical interface to be erased, making it possible to make corrections. The inclusion of this new sign, very different from the 18 gestures of the Fingerspelling Alphabet, does not affect the classifiers X  performance.

Spaces and sentences : The recognition system should offer the chance to write both words and sentences, making it necessary to introduce spaces between words. For this purpose, as specified in the gesture recognition section, the hand at rest is used to represent the spaces between words. When the hand at rest is detected a space will be introduced in the character array shown in the screen. In the case of the end of the sentences, it was decided to introduce no sign to keep the classification task as simple as possible after the introduction of the delete sign. This way a timer has been introduced, a timer that indicates that the sentence is over. This method allows a convenient way to end the sentences without adding any more gesture or movement.
Sign reproduction : In an effort to complete the sign recognition system, the proposed application requires a way to reproduce the spelled words and sentences. The visualization tool allows a visual reproduction of the process but it requires constant attention. To avoid this, it was decided to introduce a final module in the architecture to reproduce orally the spelled words and sentences. This task was performed by means of a text to speech (TTS) application, an application able to reproduce orally any written text.

With the addition of those new functionalities it is possible to offer a whole sign recognition system, allowing a convenient spelling experience by means of the different elements introduced. 7.2. Architecture
Once the different modules and functionalities of the sign recognition system have been defined, it is necessary to design an architecture including all of them. After considering the necessities of the system it was decided to create a two layer architecture as shown in Fig. 19 .

Initially, both gesture and movement recognition modules process the signals received by the sensors. Both modules work exactly as described in the gesture recognition and movement recognition sections, segmenting the signals first and classifying those sets of readings afterwards.

Once the low level recognition has been performed, the upper layer combines this information. Firstly, (a) the gesture informa-tion is collected, forming the different words and sentences.
Secondly, (b) the movement information is used to change the meaning of the different letters written. Taking into account that each movement changes only the meaning of certain letters, this layer also verifies that the change of meaning is performed correctly (the last received movement really changes the meaning of the last gesture). Talking about the new functionalities, this layer also (c) allows the visualization of the process, showing the different words and sentences by means of the visual interface. Finally (d) it also sends the different words and sentences to the
TTS module to be orally reproduced, once the end of the sentences are detected.

The architecture described here allows all the signs to be recognized, including the possibility of visualising the process, correct errors and reproduce the sentences. The proposed architecture deals with all the needs of this kind of system. 7.3. Classifier creation
Trying to separate the classifiers from the sign recognition architecture, it was decided to initialize the gesture and move-ment classifiers at the beginning of the execution. This decision allows the reconfiguration of the classifiers, something necessary for a system with multiple users.

To this end some initialization files were created, containing the training cases, time window size, threshold values and so on.
Those values are then used in the system initialization phase to create the different classifiers and structures that will be used in the recognition.

This separation between system architecture and classifiers allows an easy way to reconfigure the recognition system, making it possible to have different users without changing any source codes of the recognition application. 7.4. System validation
As a last step in this implementation exercise a validation process was initiated. In this case, this time two of the aforementioned sentences were spelled by the same person. Both hand gestures and hand movements were combined, allowing all the letters in the Fingerspelling Alphabet to be represented. And in the same way, due to the delete sign, it was possible to spell correctly all the letters deleting and re-writing the errors. Table 5 presents the results of the spelling process. The second and third columns show the number of hand gestures and hand movements to be represented in the sentence. Finally the number of deleted signs during the spelling process is shown in the fourth column.
In both sentences a total number of 19 and 18 signs were deleted and re-written due to recognition errors, less than 10% of the gestures/movements. The majority of those recognition errors were related to pairs of similar signs although this problem could be solved by the addition of the delete sign. However, it is worth mentioning that this error rate decreased as the user got used to its utilization and practiced with the Fingerspelling Alphabet. 8. Conclusions and future work This paper presents a layered approach for sign recognition. The sign recognition is divided into two tasks, gesture recognition and movement recognition. The proposed approach poses a layered architecture for both recognition tasks. In both cases an initial segmentation layer analyzes the received signals, searching for the different gestures and movements performed. The second layer classifies the information obtained from the first layer, using different classifiers for this purpose.

Focusing on gesture recognition, a validation process has been carried out using a selection of spelled-out sentences. The results suggest that the proposed two-layer architecture is able to deal with the real time nature of the gesture recognition problem. The segmentation layer allows detection of the signs from the received continuous signals, measuring signal changes over time for this purpose. The K-NN based hierarchical architecture then allows a reliable classification based on one case only per class, a feature that makes the proposed approach user-friendly.
In the case of movement recognition the results suggest that the proposed two-layer architecture fits the problem posed. The first segmentation layer allows the movement extraction by means of the signal energy of the accelerations. In the second layer the extracted time series are pre-processed before the classification phase, allowing data homogenization. Once data has been pre-processed, the K-NN algorithm allows a reliable classification based on one case per class, as used in gesture recognition.

Even so, it is worth mentioning the problems encountered during both phases, the segmentation and classification. There are still problems while segmenting signs when there is a small hand movement between two signs or the sign has been performed in two stages or with corrections. In the classification layer, although a hierarchical architecture or data pre-processing has been used to solve the problem, it is still difficult to distinguish very similar signs, due to problems such as glove calibration or sensor noise. The creation of more complex classifiers seems to be one the best choices to improve recognition rates.

As a future work path in the sign recognition field, the research team is studying the combination of vision-based approaches with the presented solution as well as the creation of new architectures able to combine the gesture and movement information in the most suitable way. And at the same time, the research team is also working on the application of the proposed layered architecture in new environments such as activity recognition, specifically in the recognition of industrial activities such as machine maintenance. Although there are huge differ-ences between sign recognition and activity recognition, the idea of applying a layered architecture seems to be applicable to the activity recognition field.
 References
