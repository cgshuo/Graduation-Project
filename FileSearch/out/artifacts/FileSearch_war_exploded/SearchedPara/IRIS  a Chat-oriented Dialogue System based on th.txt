 Dialogue systems have been gaining popularity re-cently as the demand for such kind of applications have increased in many different areas. Addition-ally, recent advances in other related language technologies such as speech recognition, discourse analysis and natural language understanding have made possible for dialogue systems to find practi-cal applications that are commercially exploitable (Pieraccini et al. , 2009; Griol et al. , 2010). 
From the application point of view, dialogue systems can be categorized into two major classes: task-oriented and chat-oriented. In the case of task-oriented dialogue systems, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific infor-mation from a service facility, etc. (Busemann et al. , 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participa-ting in a game, or just for chitchat or entertain-ment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al. , 2003, Wallis, 2010). 
In this paper, we introduce IRIS (Informal Res-ponse Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al. , 1975; van Rijsbergen, 2005). From the operational point of view, IRIS belongs to the category of example-based dialogue systems (Murao et al. , 2003). Its dialogue strategy is supported by a large database of dialogues that is used to provide candidate responses to a given user input. The search for candidate responses is per-formed by computing the cosine similarity metric into the vector space model representation, in which each utterance in the dialogue database is represented by a vector. 
Different from example-based question answer-ing systems (Vicedo, 2002; Xue et al. , 2008), IRIS uses a dual search strategy. In addition to the cur-rent user input, which is compared with all existent utterances in the database, a vector representation of the current dialogue history is also compared with vector representations of full dialogues in the database. Such a dual search strategy allows for in-corporating information about the dialogue context into the response selection process. The rest of the paper is structured as follows. Section 2 presents the architecture of IRIS as well as provides a general description of the dataset that has been used for its implementation. Section 3 presents some illustrative examples of dialogues generated by IRIS, and Section 4 presents the main conclusions of this work. In this section we first provide a detailed descrip-tion of the IRIS architecture along with the most relevant issues behind its implementation. Then, we describe the specific dialogue dataset that sup-ports the IRIS implementation. 2.1 Architecture As already mentioned, IRIS architecture is heavily based on a vector space model framework, which includes a standard similarity search module from vector-based information retrieval systems (Salton and McGill, 1983). However, it also implements some additional modules that provide the system with capabilities for automatic chatting. 
Figure 1 depicts a block diagram that illustrates the main modules in the IRIS architecture. As seen from the picture, the whole system comprises se-ven processing modules and three repositories. 
The main operation of IRIS can be described as follows. When a new dialogue starts, the control of the dialogue is passed from the dialogue manage-ment module to the initiation/ending module. This module implements a two-state dialogue strategy which main objectives are: first, to greet the user and self-introduce IRIS and, second, to collect the name of the user. This module uses a basic parsing algorithm that is responsible for extracting the user X  X  name from the provided input. The name is the first vocabulary term learned by IRIS, which is stored in the vocabulary learning repository. 
Once the dialogue initiation has been concluded the dialogue management system gains back the control of the dialogue and initializes the current history vector. Two types of vector initializations are possible here. If the user is already know by IRIS, it will load the last stored dialogue history for that user; otherwise, IRIS will randomly select one dialogue history vector from the dialogue data-base. After this initialization, IRIS prompts the user for what he desires to do. From this moment, the example-based chat strategy starts. 
For each new input from the user, the dialogue management module makes a series of actions that, after a decision process, can lead to different types of responses. In the first action, the dynamic repla-cement module searches for possible matches bet-ween the terms within the vocabulary learning repository and the input string. In a new dialogue, the only two terms know by IRIS are its own name and the user name. If any of this two terms are identified, they are automatically replaced by the placeholders &lt;self-name&gt; and &lt;other-name&gt; , res-pectively. 
In the case of a mature dialogue, when there are more terms into the vocabulary learning repository, every term matched in the input is replaced by its corresponding definition stored in the vocabulary learning database. 
Just after the dynamic replacement is conducted, tokenization and vectorization of the user input is carried out. During tokenization, an additional checking is conducted by the dialogue manager. It looks for any adaptation command that could be possibly inserted at the beginning of the user input. More details on adaptation commands will be given when describing the style/manner adaptation module. Immediately after tokenization, unknown vocabulary terms (OOVs) are identified. IRIS will consider as OOV any term that is not contained in either the dialogue or vocabulary learning data-bases. In case an OOV is identified, a set of heuris-tics (aiming at avoiding confusing misspellings with OOVs) are applied to decide whether IRIS should ask the user for the meaning of such a term. 
If IRIS decides to ask for the meaning of the term, the control of the dialogue is passed to the vocabulary learning module which is responsible for collecting the meaning of the given term from the user or, alternatively, from an external source of information. Once the definition is collected and validated, it is stored along with the OOV term into the vocabulary learning repository. After comple-ting a learning cycle, IRIS acknowledges the user about having  X  X nderstood X  the meaning of the term and control is passed back to the dialogue manage-ment module, which waits for a new user input. If IRIS decides not to ask for the meaning of the OOV term, or if no OOV term has been identified, vectorization of the user input is completed by the vector similarity modules and similarity scores are computed for retrieving best matches from the dialogue database. Two different similarity scores are actually used by IRIS. The first score is applied at the utterance level. It computes the cosine similarities between the current user input vector and all single utterances stored in the database. This score is used for retrieving a large amount of candidate utterances from the dialogue database, generally between 50 and 100, depending on the absolute value of the associated scores. 
The second score is computed over history vectors. The current dialogue history, which is available from the current history repository, inclu-des all utterances interchanged by the current user and IRIS. In other to facilitate possible topic chan-ges along the dialogue evolution, a damping or  X  X orgetting X  factor is used for giving more impor-tance to the most recent utterances in the dialogue history. A single vector representation is then com-puted for the currently updated dialogue history after applying the damping factor. The cosine similarity between this vector and the vector repre-sentations for each full dialogue stored in the dia-logue database are computed and used along with the utterance-level score for generating a final rank of candidate utterances. A log-linear combination scheme is used for combining the two scores. The dialogue management module randomly selects one of the top ranked utterances and prompts back to the user the corresponding reply (from the dia-logue database) to the wining utterance. 
Just immediately before prompting back the res-ponse to the user, the dynamic replacement module performs an inverse operation for replacing the two placeholders &lt;self-name&gt; and &lt;other-name&gt; , in case they occur in the response, by their actual values. 
The final action taken by IRIS is related to the style/manner adaptation module. For this action to take place the user has to include one of three pos-sible adaptations commands at the beginning of her/his new turn. The three adaptation commands recognized by IRIS are: ban (*), reinforce (+), and discourage ( X ). By using any of these three charac-ters as the first character in the new turn, the user is requesting IRIS to modify the vector space repre-sentation of the previous selected response as follows:  X  Ban (*): IRIS will mark its last response as a  X  Reinforce (+): IRIS will pull the vector space  X  Discourage ( X ): IRIS will push the vector 2.2 Dialogue Data Collection For the current implementation of IRIS, a subset of the Movie-DiC dialogue data collection has been used (Banchs, 2012). Movie-DiC is a dialogue corpus that has been extracted from movie scripts which are freely available at The Internet Movie Script Data Collection ( http://www.imsdb.com/ ). In this subsection, we present a brief description on the specific data subset used for the implementa-tion of IRIS, as well as we briefly review the process followed for collecting the data and ex-tracting the dialogues. 
First of all, dialogues have to be identified and parsed from the collected html files. Three basic elements are extracted from the scripts: speakers, utterances and context. The speaker and utterance elements contain information about the characters who speak and what they said at each dialogue turn. On the other hand, context elements contain all the additional information (explanations and descriptions) appearing in the scripts. 
The extracted dialogues are stored into a data structure such that the information about turn se-quences within the dialogues and dialogue sequen-ces within the scripts are preserved. 
Some post-processing is also necessary to filter out and/or repair the most common parsing errors occurring during the dialogue extraction phase. Some of these errors include: bad script formatting, same-speaker turn continuations, explanatory notes inserted within the turns, misspelling of names in the speaker headers, changes in the encoding for-mat, etc. 
The final dialogue collection used in the IRIS implementation consists of dialogues from 153 movie scripts, mainly belonging to the comedy, action and family genres. Table 1 summarizes the main statistics of the resulting dataset. 
For each turn in the dialogue collection, a vector space model representation was constructed. For this, the standard bag-of-words weighting scheme known as TF-IDF was used (Spark, 1972; Salton and Buckley, 1988). 
Before performing the vectorization, word toke-nization was conducted. In this step, all punctua-tion marks were removed, with the exception of the question  X ? X  and exclamation  X ! X  marks. Simi-larly, all other non-alphanumeric characters occur-ring in the utterances were removed as well. Also during the tokenization phase, all self-references to current speaker names in the utterances were re-placed by the &lt;self-name&gt; placeholder, as well as all references to the names of other speakers participating in the same dialogue were replaced by the &lt;other-name&gt; place-holder. 
Finally, a vector space model representation was also computed for each full dialogue in the collec-tion. For this bag-of-words model at the dialogue level, both utterance and context information were taken into account. Again, the TF-IDF weighting scheme was used. In this section we show some real examples of interactions between IRIS and human users. First, we present some interesting examples of good per-formance, as well as illustrate some of the learning capabilities of IRIS. Then, we present some of the common failures which identify specific points of attention for further improvements. 3.1 Good Performance Examples Our first example illustrates the beginning of a typical chat session between IRIS and a new user. This example is depicted in Table 2. 
Table 2: Beginning of a chat session between IRIS 
For the dialogue depicted in Table 2, turn num-bers 1, 2 and 3 are processed by the dialogue intia-tion/ending module. The example-based dialogue management strategy starts from turn 4 onwards. Notice that as far as this is a new user, not previous dialogue history exists, so in this case a random history vector has been selected and instead of focusing in the sports topic suggested by the user, IRIS  X  X akes the initiative X  of asking for a date. In our second example, which is presented in Table 3, we illustrate the beginning of a typical chat session between IRIS and a returning user. For this particular user, her last interaction with IRIS was about sports. 
Similar to the previous example, turn 1 is pro-cessed by the dialogue intiation/ending module and the example-based dialogue management strategy starts from turn 2 onwards. In this particular case, IRIS is much more centered on the sports topic as this context information has been already provided by the stored dialogue history of the previous chat session with this particular user. Table 3: Beginning of a chat session between IRIS In our third example, which is presented in Table 4, we illustrate the learning of a new vocabu-lary word by IRIS. In this example, when the un-known term paella is detected, the control of the dialogue is passed to the vocabulary learning mo-dule, which takes care of turns 7, 8, 9 and 10. 
Table 4: Chat segment in which IRIS learns the 
Notice that when the user asks IRIS about having some paella today, IRIS is already able to associate it with seafood as it was stated in the user X  X  provided definition. The process actually occurs as follows: after tokenization, but before vectorization of the user input in turn 11, the dynamic replacement module substitutes the term paella by its definition, which has been previously stored in the vocabulary learning repository when turn 9 was processed. The actual user input that is finally vectorized in turn 11 is the following one: so do you want some it is a spanish food yellow rice with some seafood on it today ? , which is the utterance used by IRIS to retrieve and select the response it provides in turn 12. 3.2 Common Failure Examples In this subsection we focus our attention in the most common failures exhibited by IRIS. Some of these failures put in evidence specific points of attention that should be taken into account for further improvements of the system. 
Our first example illustrates the problem of IRIS lack of consistency in issues for which consistent answers are required. Two specific chat segments in which IRIS provides inconsistent responses are presented in Table 5. 
The first example presented in Table 5 constitu-tes a serious consistency problem. In this case IRIS has reported two different ages in the same chat session. The second case, although not so serious as the previous one, also constitutes a consistency failure. In this case IRIS states Football is my life just two turns after saying I hate sports . 
Our second example, which is presented in Ta-ble 6, illustrates a problem derived from the noise that is still present in the dataset. Table 6: Example of noise in the dialogue dataset 
In the particular example illustrated in Table 6, as seen from turn 3, a context element has been mistakenly stored in the data collection as an utterance during the dataset preparation phase. Several problems similar to this one, which are related to noise in the database, have been detected already. To tackle this problem we need to refine the parsing and post-processing algorithms used during the dialogue dataset construction phase. In this paper, we have presented IRIS (Informal Response Interactive System), a chat-oriented dia-logue system that is based on the vector space model framework. The system belongs to the class of example-based dialogue systems and builds its chat capabilities on a dual search strategy over a large collection of movie dialogues. 
Additional strategies allowing for system adap-tation and learning have been also implemented over the same vector space model framework. More specifically, IRIS is capable of learning new vocabulary terms and semantically relating them to previous knowledge, as well as adapting its dia-logue decisions to some stated user preferences. 
We have also described the main characteristics of the architecture of IRIS and the most important functions performed by each of its constituent modules. Finally, we have provided some exam-ples of good chat performance and some examples of the common failures exhibited by IRIS. 
As future work, we intend to improve IRIS per-formance by addressing some of the already identi-fied common failures. Similarly, we intend to aug-ment IRIS chatting capabilities by extending the size of the current dialogue database and integra-ting a strategy for group chatting. The authors would like to thank the Institute for Infocomm Research for its support and permission to publish this work. 
