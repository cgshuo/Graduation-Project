 This special section emphasizes a high-level notion of trust, such as arises in collab-orations among intelligent, socially adept agents. Agents can be thought of as the elementary units of open computational environments or multiagent systems. In par-ticular, agents can adapt their behavior and interactions, thus potentially realizing rich emergent social phenomena.

Increasingly, researchers recognize trustworthiness as a relation between a trusted party and a trusting party that arises in a context of interaction. Trustworthiness thus inherently reflects the purpose for which one party may trust another. This con-trasts not only with security, which deals with encryption and digital signatures, but also with the more common notion of trust in distributed computing, which emphasizes authentication. Ultimately, no matter what security techniques are used or authentica-tions obtained, one party must decide whether to place its plans in the hands of another party. This decision may involve sharing (private) information, granting authorizations or privileges, or negotiating contracts or collaborative service engagements.
How can an agent make a decision about whether to place its plans in the hands of another? And how can an agent use its own trustworthiness as relational capital in a multiagent system? The autonomy and adaptivity of the agents offers both a challenge and an opportunity. An agent X  X  decision to trust another would potentially consider rich models of other agents, including cognitive, organizational, social, emotional, economic, and evidential factors as well as the controls (social, economic, or legal) in place in the given environment.

It is little surprise that trust has long been studied in the agents community, al-though quite often in a two-party X  X ather than a true multiagent X  X etting. The articles included in this special section emphasize the multiagent nature of trust and involve explicit interactions among multiple agents.
 The first two articles demonstrate the benefits of explicit social modeling for trust. Zhang and Cohen consider the time-honored trust research setting of electronic com-merce. They model a procurement auction in which a buyer chooses sellers and buyers can share information regarding sellers. Zhang and Cohen model advisor agents, who help prospective trustees, and show how to address the potential dishonesty of sellers. They rely on the buyers forming a social network to improve their effectiveness in selecting good sellers.

Erriquez et al. consider the well-known trust-evaluation testbed called ART. They select two of the many agents developed for ART competitions and add a layer of social modeling to those agents X  X nterestingly, previous agents did not incorporate such social modeling. Erriquez et al. show that their socially modified agents are able to fulfill more transactions than the original agents. In addition, the modified agents obtain a much larger fraction of wins in the same settings as before, thereby demonstrating the potential value of social modeling for trust.
 The next two articles extend agent modeling to incorporate richer representations. Burnett et al. motivate the notion of stereotypes as a basis for trust. Stereotypes are known to play an important function in fast forming and changing human organiza-tions. Burnett et al. show how to model stereotypes using a probabilistic representa-tion based on Dempster-Shafer theory and consider ways in which stereotypes might be induced from interactions as ways to capture the observable features of the parties involved that are relevant for trust.

Falcone et al. study the challenge of dealing with categories such as those people use to assess trust in others. These categories represent both the explicit (Manifesta) and the implicit (Krypta) qualities of an agent and provide a basis for assessing trust in a manner that theoretically precedes conventional approaches based on direct experience and referrals. Falcone et al. show how categorial reasoning enables an agent to establish fruitful interactions with agents that it has not previously encountered. This aspect has an important ramification in connection with open systems as characterized by heterogeneous societies of self-interested agents.

TIST received 17 submissions for this special section, of which four were selected for inclusion after one or two rounds of peer reviews. We note in passing that reviewing for the article by Falcone et al. was handled not by the guest editors but by the editor-in-chief directly.

