
Searching for images of people is an essential task for image and video search engines. However, current search engines have limited capabilities f or this task since they rely on text associated with images and video, and such text is likely to return many irrelevant results. We propose a method for retrieving relevant faces of one person by learn-ing the visual consistency among results retrieved from text-correlation-based search engines. The method consists of two steps. In the first step, each candidate face obtained from a text-based search engine is ranked with a score that measures the distribution of visual similarities among the faces. Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list, respectively. The sec-ond step improves this ranking by treating this problem as a classification problem in which input faces are classified as  X  X erson-X  X  or  X  X on-person-X  X ; and the faces are re-ranked according to their relevant score inferred from the classi-fier X  X  probability output. To train this classifier, we use a bagging-based framework to combine results from multiple weak classifiers trained using different subsets. These train-ing subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step. In this way, the accuracy of the ranked list increases after a number of iterations. Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each it-eration, with the final performance being higher than those of the existing algorithms.
With the rapid growth of digital technology, large image and video databases have become more available than ever to users. This trend has shown the need for effective and ef-ficient tools for indexing and retrieving based on visual con-tent. A typical application is s earching for a specific person by providing his or her name. Most current search engines use the text associated with images and video as significant clues for returning results. However, other un-queried faces and names may appear with the queried ones (Figure 1), and this significantly lowers the r etrieval performance. One way to improve the retrieval performance is to take into account visual information present in the retrieved faces. This task is challenging for the following reasons:  X  Large variations in facial appearance due to pose  X  The fact that the retrieved face set consists of faces of The main idea is to assume that there is visual consistency among the results returned from text-based search engines and this visual consistency is then learned through an in-teractive process. This method consists of two stages. In the first stage, we explore the local density of faces to iden-tify potential candidates for relevant faces 1 and irrelevant faces 2 . This stage reflects the fact that the facial images of the queried person tend to form dense clusters, whereas ir-relevant facial images are sparse since they look different from each other. For each face, we define a score to mea-sure the density of its neighbor set. This score is used to form a ranked list, in which faces with high-density scores are considered relevant and are put at the top.
 have no guarantee of c ontaining relevant faces. Therefore, a second stage is necessary to improve this ranked list. We model this problem as a classification problem in which in-put faces are classified as person-X (the queried person) or non-person-X (the un-queried person). The faces are ranked according to a relevanc y score that is inferred from the classifier X  X  probability output. Since annotation data is not available, the rank list from the previous step is used to assign labels for a subset of faces. This subset is then used to train a classifier using supervised methods such as sup-port vector machines (SVM). The trained classifier is used to re-rank faces in the original input set. This step is re-peated a number of times to get the final ranked list. Since automatically assigning labels from the ranked list is not re-liable, the trained classifiers are weak. To obtain the final strong classifier, we use the idea of ensemble learning [6] in which weak classifiers trained on different subsets are com-bined to improve the stability and classification accuracy of single classifiers. The learned classifier can be further used for recognizing new facial images of the queried person. tion performance for the following reasons:  X  Supervised learning methods, such as SVM, provide
Figure 2. Large variations in facial expres-sions, poses, illumination conditions and oc-clusions making face recognition difficult.

Best viewed in color.  X  The bagging framework helps to leverage noises in the
Our contribution is two-fold:  X  We propose a general framework to boost the face re- X  We demonstrate its feasibility with a practical web
There are several approaches for re-ranking and learn-ing models from web images. Their underlying assump-tion is that text-based search engines return a large frac-tion of relevant images. The challenge is how to model what is common in the relevant images. One approach is to model this problem in a probabilistic framework in which the returned images are used to learn the parame-ters of the model. For examples, as described by Fergus et al. [12], objects retrieved usin g an image search engine are re-ranked by extending the constellation model. Another proposal, described in [15], uses a non-parametric graphi-cal model and an interactive framework to simultaneously learn object class models and c ollect object class datasets. The main contribution of these approaches is probabilistic models that can be learned with a small number of training images. However, these models are complicated since they require several hundred parameters for learning and are sus-ceptible to over-fitting. Furthermore, to obtain robust mod-els, a small amount of supervision is required to select seed images.

Another study [4, 3] proposed a clustering-based method for associating names and faces in news photos. To solve the problem of ambiguity between several names and one face, a modified k -means clustering process was used in which faces are assigned to the closest cluster (each clus-ter corresponding to one name) after a number of iterations. Although the result was impressive, it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment when a news photo only has one face and its caption only has one name. Furthermore, a large number of irrelevant faces (more than 12%) have to be manually eliminated before clustering.
 A graph-based approach was proposed by Ozkan and Duygulu [16], in which a graph is formed from faces as nodes, and the weights of edges linked between nodes are the similarity of faces, is closely related to our problem. Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces, this problem is considered equal to the problem of finding the densest subgraph of a full graph; and can therefore be solved by taking an available solution [9]. Although, exper-imental results showed the effectiveness of this method, it is still questionable whether the densest subgraph intuitively describes most of the relevant faces of the queried person and it is easy to extend for the ranking problem. Further-more, choosing an optimal threshold to convert the initial graph into a binary one is difficult and rather ad hoc due to the curse of dimensionality.

An advantage of the methods [4, 3, 16] is they are fully unsupervised. However, a disadvantage is that no model is learned for predicting new images of the same category. Furthermore, they are used for performing hard categoriza-tion on input images that are in applicable for re-ranking. The balance of recall and precision was not addressed. Typ-ically, these approaches tend to ignore the recall to obtain high precision. This leads to the reduction in the number of collected images.

Our approach combines a number of advances over the existing approaches. Specifi cally, we learn a model for each query from the returned images for purposes such as re-ranking and predicting new images. However, we used an unsupervised method to select training samples automati-cally, which is different from the methods proposed by Fer-gus et al. and Li et al. [12, 15]. This unsupervised method is different from the one by Ozkan and Duygulu [16] in the modeling of the distribution of relevant images. We use density-based estimation rather than the densest graph.
Given a set of images returned by any text-based search engine for a queried person (e.g.  X  X eorge Bush X ), we per-form a ranking process and learning of person X  X  X  model as follows:  X  Step 1: Detect faces and eye positions, and then per- X  Step 2: Compute an eigenface space and project the  X  Step 3: Estimate the ranked list of these faces using  X  Step 4: Improve this ranked list using Rank-By-
Steps 1 and 2 are typical for any face processing system, and they are described in section 4.2. The algorithms used in Steps 3 and 4 are described i n section 3.1 and section 3.2, respectively. Figure 3 illustrates the proposed framework.
Figure 4. An example of faces retrieved for person-Donald Rumsfeld. Irrelevant faces are marked with a star. Irrelevant faces might form several clusters, but the relevant faces form the largest cluster.

Among the faces retrieved by text-based search engines for a query of person-X , as shown in Figure 4, relevant faces usually look similar and form the largest cluster. One approach of re-ranking these faces is to cluster based on vi-sual similarity. However, to obtain ideal clustering results is impossible since these faces ar e high dimensional data and the clusters are in different shapes, sizes, and densities. In-stead, a graph-based approach was proposed by Ozkan and Duygulu [16] in which the node s are faces and edge weights are the similarities between two faces. With the observation that the nodes (faces) of the queried person are similar to each other and different from other nodes in the graph, the densest component of the full graph the set of highly con-nected nodes in the graph will correspond to the face of the queried person. The main drawback of this approach is it needs a threshold to convert the initial weighted graph to a binary graph. Choosing this threshold in high dimensional spaces is difficult since different persons might have differ-ent optimal thresholds.
 Ester et al. and Breunig et al. [11, 7] to solve this problem. Specifically, we define the local density score (LDS) of a point p (i.e. a face) as the average distance to its k-nearest neighbors.
 where R ( p, k ) is the set of k -neighbors of p ,and distance ( p, q ) is the similarity between p and q . space, and face clusters might have different sizes, shapes, and densities, we do not directly use the Euclidean distance between two points in this feature space for distance ( p, q Instead, we use another similarity measure defined by the number of shared neighbors between two points. The effi-ciency of this similarity measure for density-based cluster-ing methods was described in [10]. between p and its neighbors. Therefore, we can use this local density score to rank faces. Faces with higher scores are considered to be potential candidates that are relevant to person-X , while faces with lower scores are considered as outliers and thus are potential candidates for non-person-X . Algorithm 1 describes these steps.
 Algorithm 1: Rank-By-Local-Density-Score
Step 1: For each face p , compute LDS ( p, k ) , where k is the number of neighbors of p and is the input of the ranking process.

Step 2: Rank these faces using LDS ( p, k ) (The higher the score the more relevant).
One limitation of the local density score based ranking is it cannot handle faces of anot her person strongly associ-ated in the k -neighbor set (for example, many duplicates). Therefore, another step is proposed for handling this case. As a result, we have a model that can be used for both re-ranking current faces and predicting new incoming faces.
The main idea is to use a probabilistic model to measure the relevancy of a face to person-X , P ( person  X  X | face Since the labels are not available for training, we use the input rank list found from the previous step to extract a sub-set of faces lying at the top and bottom of the ranked list to form the training set. After that, we use SVM with prob-abilistic output [17] implemented in LibSVM [8] to learn the person-X model. This model is applied to faces of the original set, and the output probabilistic scores are used to re-rank these faces. Since it is not guaranteed that faces ly-ing at two ends of the input rank list correctly correspond to the faces of person-X and faces of non person-X , we adopt the idea of a bagging framework [6] in which randomly se-lecting subsets to train weak cl assifiers, and then combining these classifiers help reduce the risk of using noisy training sets.
 The details of the Rank-By-Bagging-ProbSVM-InnerLoop method, improving an input rank list by combining weak classifiers trained from subsets annotated by that rank list are described in Algorithm 2 .
 Given an input ranked list, Rank-By-Bagging-ProbSVM-InnerLoop is used to improve this list. We repeat the process a number of times whereby the ranked list output from the previous step is used as the input ranked list of the next Algorithm 2: Rank-By-Bagging-ProbSVM-InnerLoop Step 1: Train a weak classifier, h i .

Step 1.1: Select a set S pos including p % of top ranked faces and then randomly select a subset S  X  pos from S pos . Label faces in S  X  pos as positive samples.

Step 1.2: Select a set S neg including p % of bottom ranked faces and then randomly select a subset S  X  neg from S neg Label faces in S  X  neg as negative samples.

Step 1.3: Use S  X  pos and S  X  neg to train a weak classifier, h j , using LibSVM [8] with probability outputs. Step 2: Compute ensemble classifier H i = i j =1 h j .
Step 3: Apply H i to the original face set and form the rank list, Rank i , using the output probabilistic scores.
Step 4: Repeat steps 1 to 3 until Dist 2 RankList ( Rank i  X  1 ,Rank i ) &lt; = . Step 5: Return H i = i j =1 h j .
 Algorithm 3: Rank-By-Bagging-ProbSVM-OuterLoop Step 1: Rank cur = Rank-By-Bagging-ProbSVM-InnerLoop( Rank prev ).
 Step 2: dist = Dist 2 RankList ( Rank prev ,Rank cur ) . Step 3: Rank final = Rank cur .
 Step 4: Rank prev = Rank cur .

Step 5: Repeat steps 1 to 4 until dist &lt; = .

Step 6: Return Rank final . step. In this way, the iterations significantly improve the final ranked list. The details are described in Algorithm 3 . By-Bagging-ProbSVM-InnerLoop and Rank-By-Bagging-ProbSVM-OuterLoop ,weusethe Kendall  X  tau dis-tance [13], which is a metric that counts the number of pair-wise disagreements between two lists. The larger the dis-tance, the more dissimilar the two lists are. The Kendall tau distance between two lists,  X  1 and  X  2 , is defined as fol-lows: in  X  1 and  X  2 . K i,j (  X  1 , X  2 )=0 if i and j are in the same order in  X  1 and  X  2 ,and K i,j (  X  1 , X  2 )=1 if i and j are in the opposite order in  X  1 and  X  2 .
 where N is the number of members of the list, the normal-ized Kendall tau distance can be written as follows: means that if the ranked list does not change significantly after a number of iterations, it is reasonable to stop.
We used the dataset described by Berg et al. [4] for our experiments. This dataset consists of approximately half a million news photos and captions from Yahoo News col-lected over a period of roughly two years. This dataset is better than datasets collect ed from image search engines such as Google that usually limit the total number of re-turned images to 1,000. Furthermore, it has annotations that are valuable for evaluation of methods. Note that these an-notations are used for evaluation purpose only. Our method is fully unsupervised, so it assumes the annotations are not available at running time.

Only frontal faces were considered since current frontal face detection systems [19] work in real time and have ac-curacies exceeding 95%. 44,773 faces were detected and normalized to the size of 86  X  86 pixels.
 We selected fifteen govern ment leaders, including George W. Bush (US), Vladimir Putin (Russia), Ziang Jemin (China), Tony Blair (UK), Junichiro Koizumi (Japan), Roh Moo-hyun (Korea), Abdullah Gul (Turkey), and other key individuals, such as John Paul II (the Former Pope) and Hans Blix (UN), because their images frequently appear in the dataset [16]. Variations in each person X  X  name were collected. For example, George W. Bush, President Bush, U.S. President, etc., all refer to the current U.S. pres-ident.

We performed simple string search in captions to check whether a caption contained one of these names. The faces extracted from the corresponding image associated with this caption were returned. The faces retrieved from the differ-ent name queries were merged into one set and used as input for ranking.

Figure 5 shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these fifteen individuals. I n total, 5,603 faces were re-trieved in which 3,374 faces were relevant. On average, the accuracy was 60.22%.
We used an eye detector to detect the positions of the eyes of the detected faces. The eye detector, built with the same approach as that of Viola and Jones [19], had an ac-curacy of more than 95%. If the eye positions were not detected, predefined eye locations were assigned. The eye positions were used to align faces to a predefined canonical pose.

To compensate for illumination effects, the subtraction of the bestfit brightness plane followed by histogram equal-ization was applied. This normalization process is shown in Figure 6.
 duce the number of dimensions of the feature vector for face representation. Eigenfaces were computed from the origi-nal face set returned using the text-based query method. The number of eigenfaces used to form the eigen space was se-lected so that 97% of the total energy was retained [5]. The number of dimensions of these feature spaces ranged from 80 to 500.
 that are commonly used in information retrieval, such as precision, recall, and average precision. Given a queried person and letting N ret be the total number of faces re-turned, N rel the number of relevant faces, and N hit the total number of relevant faces, recall and precision can be calcu-lated as follows:
Precision and recall are only used to evaluate the quality of an unordered set of retrieved faces. To evaluate ranked lists in which both recall and precision are taken into ac-count, average precision is usually used. The average pre-cision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0.0, 0.1, 0.2, ..., 1.0.

The interpolated precision p interp at a certain recall level r is defined as the highest precision found for any recall level q  X  r :
In addition, to evaluate the performance of multiple queries, we used mean average precision, which is the mean of average precisions computed from queries 3 .
The parameters of our method include:  X  p : the fraction of faces at the top and bottom of the  X  : the maximum Kendall tau distance K norm (  X  1 , X  2)  X  kernel : the kernel type is used for the SVM. The de-4.5.1 Performance Comparison with Existing Ap-We performed a comparison between our proposed method with other existing approaches.  X  Text Based Baseline (TBL): Once faces corresponding  X  Distance-Based Outlier (DBO): We adopted the idea  X  Densest Sub-Graph based Method (DSG): We r e - X  Local Density Score (LDS): This is the first stage of  X  Unsupervised Ensemble Learning Using Local Den- X  Supervised Learning (SVM-SUP): We randomly se-
Figure 7. Performance comparison of meth-ods. Due to different settings, performances are superimposed for better evaluation.

Figure 7 shows a performance comparison of these meth-ods. Our proposed methods (LDS and UEL-LDS) out-perform other unsupervised methods such as TBL, DBO and DSG. Furthermore, the performance of the DBO and DSG methods are sensitive to the distance threshold, while the performance of our proposed method is less sensitive. It confirms that the similarity measure using shared near-est neighbors is reliable for estimation of the local den-sity score. The performance of UEL-LDS is slightly bet-ter than LDS since the training sets labeled automatically from the ranked list are noisy. However, UEL-LDS im-proves significantly even when the performance of LDS is poor. These performances are worse than that of SVM-SUP using a small number of labeled samples.

Figure 8 shows an example of the top 50 faces ranked using the TBL, DBO, DSG and LDS methods. The perfor-mance of DBO is poor since a low threshold is used. This ranks irrelevant faces that are near duplicates (rows 2 and 3 in Figure 8(b)) higher than rel evant faces. This explains the same situation with DSG. 4.5.2 Performance of Ensemble Classifiers In Figure 9, we show the performance of five single clas-sifiers and that of five ensemble classifiers. The ensemble classifier k is formed by combining single classifiers from to k . It clearly indicates that the ensemble classifier is more stable than single weak classifiers. 4.5.3 New Face Annotation We conducted another experiment to show the effectiveness of our approach in which learned models are used to anno-tate new faces of other databases. We used each name in the list as a query to obtain the top 500 images from the Google Image Search Engine (GoogleSE). Next, these images were processed using the steps described in section 4.2: extract-ing faces, detecting eyes and doing normalization. We pro-jected these faces to the PCA subspace trained for that name and used the learned model to re-rank faces.
 faces detected as faces) detected from 7,500 returned im-ages. We manually labeled these faces and there were 2,342 relevant faces. On average, the accuracy of the GoogleSE is 57.08%.
 The performance of UEL-LDS was obtained by running the best system, which is shown as the peak of the UEL-LDS curve in Figure 7. The performances of SVM-SUP-05 and SVM-SUP-10 correspond to the supervised systems (cf. section 4.5.1) that used p =5% and p = 10% ofthedataset respectively. We evaluated the performance by calculating the precision at the top 20 returned faces, which is com-mon for image search engines and recall and precision on all detected faces of the test set. UEL-LDS achieved com-parable performance to the supervised methods and outper-formed the baseline GoogleSE. The precision at the top 20 of SVM-SUP-05 is poorer than that of UEL-LDS due to the small number of training samples. Figure 10 shows top 20 faces ranked using these two methods. where the main assumption that text-based search engines return a large fraction of relevant images is satisfied. Fig-ure 12 shows an example where this assumption is broken. Consequently, as shown in Figure 13, the model learned by this set performed poorly in recognizing new faces returned by GoogleSE. Our approach solely relies on the above as-sumption; therefore, it is not affected by the ranking of text-based search engines.

The iteration of bagging SVM classifiers does not guar-antee a significant improvement in performance. The aim of our future work is to study how to improve the quality of the training sets used in this iteration.
We presented a method for ranking faces retrieved us-ing text-based correlation methods in searches for a specific person. This method learns the visual consistency among faces in a two-stage process. In the first stage, a relative den-sity score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely to be relevant or ir-relevant faces, respectively. In the second stage, a bagging framework is used to combine weak classifiers trained on subsets labeled from the ranked list into a strong classifier. This strong classifier is then applied to the original set to re-rank faces on the basis of the output probabilistic scores. Experiments on various face sets showed the effectiveness of this method. Our approach is beneficial when there are several faces in a returned image, as shown in Figure 11. [7] M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander. LOF: [8] C.-C. Chang and C.-J. Lin. LIBSVM: a library for [9] M. Charikar. Greedy approximation algorithms for finding [10] L. Ertoz, M. Steinbach, and V. Kumar. Finding clusters of [11] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A density-[12] R. Fergus, P. Perona, and A. Zisserman. A visual category [13] M. Kendall. Rank Correlation Methods .CharlesGriffin [14] E. M. Knorr, R. T. Ng, and V. Tucakov. Distance-based out-[15] L.-J. Li, G. Wang, and L. Fei-Fei. Optimol: automatic on-[16] D. Ozkan and P. Duygu. A graph based approach for naming [17] J. Platt. Probabilistic out puts for support vector machines [18] M. Turk and A. Pentland. Face recognition using eigenfaces. [19] P. Viola and M. Jones. Rapid object detection using a [20] T.-F. Wu, C.-J. Lin, and R. C. Weng. Probability estimates [21] W. Zhao, R. Chellappa, P. J. Phillips, and A. Rosenfeld. Face Figure 8. Top 50 faces ranked by the methods
TBL, DBO, DSG and LDS. Irrelevant faces are marked with a star.
Figure 9. Performance of the ensemble clas-sifiers and single classifiers. Figure 10. Top 20 faces ranked by Google
Image Search Engine (a) and ranked using our learned model (b). Irrelevant faces are marked with a star.

Figure 11. Image returned by GoogleSE for query  X  X erhard Schroeder X . GoogleSE was unable to accurately identify who the queried person was, while the learned model of our approach accurately identified him.

Figure 12. Example in which portion of rel-evant faces is dominant, but it is difficult to group all these faces into one cluster due to large facial variations. In feature space, the largest cluster formed from relevant faces is not largest cluster among those formed from all returned faces. Irrelevant faces are marked with a star.

Figure 13. Many irrelevant faces annotated using the model learned from the data set shown in Figure 12. Irrelevant faces are marked with a star.
