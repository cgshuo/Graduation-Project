 In many online news services, users often write comments towards news in subjective emotions such as sadness, hap-piness or anger. Knowing such emotions can help under-stand the preferences and perspectives of individual user-s, and therefore may facilitate online publishers to provide more relevant services to users. Although building emotion classifiers is a practical task, it highly depends on sufficient training data that is not easy to be collected directly and the manually labeling work of comments can be quite labor intensive. Also, online news has different domains, which makes the problem even harder as different word distribu-tions of the domains require different classifiers with corre-sponding distinct training data.

This paper addresses the task of emotion tagging for com-ments of cross-domain online news. The cross-domain task is formulated as a transfer learning problem which utilizes a small amount of labeled data from a target news domain and abundant labeled data from a different source domain. This paper proposes a novel framework to transfer knowl-edge across different news domains. More specifically, differ-ent approaches have been proposed when the two domains share the same set of emotion categories or use different categories. An extensive set of experimental results on four datasets from popular online news services demonstrates the effectiveness of our proposed models in cross-domain emo-tion tagging for comments of online news in both the scenar-ios of sharing the same emotion categories or having different categories in the source and target domains.  X 
The authors contributed equally to this work.  X 
Part of this work was performed when the authors visited/ studied at Purdue University.
 H.3.3 [ Information Systems ]: Information Storage and Retrieval -Information Search and Retrieval Sentiment Tagging; Online News; Comments; Transfer Learn-ing; Cross-Domain; Cross-Category
With the explosion of social media over the past decade, more and more user-generated data is available on the Web for expressing users X  opinions and emotions. Among vari-ous types of social media, online news is an important form that attracts billions of users to read, respond, and active-ly interact with each other by making comments. Opinions and comments of individual users often have huge impact-s on other users and the community. Users often express subjective emotions such as sadness, surprise and anger in comments. Grasping such emotions can help understand the perspectives and preferences of individual users, and thus may facilitate online publishers to provide more personal-ized services or statistically study readers X  attitudes toward news events. Therefore, to better make use of user comments for quantitative analysis, a research problem of automatic e-motion tagging for comments of online news arises.

Emotion tagging for online news comments is an applica-tion of the research area of opinion mining and sentiment analysis, which has attracted much attention in information retrieval and natural language processing communities (e.g., [24]). In particular, the tagging problem is formulated as a sentiment classification problem, which focuses on detecting the polarity (e.g., positive or negative) or multiple emotion categories (e.g., happy, sad, angry, etc.) from user-generated contents including user reviews of products or services, post-s on blogs or social networks, and comments in forums or online news services.

Traditional supervised learning methods have been ap-plied to emotion tagging for comments of online news (e.g., [34]). The performances of these methods heavily rely on the availability of a relative large amount of manually tagged comments. The labeling work is often labor intensive for ob-taining sufficient training data. Moreover, online news has many domains such as politics, entertainment or sports, and if we directly apply the classifiers trained from one domain to comments from another domain, it usually leads to poor classification performances (e.g., [5][22]). The reason is that comments in different news domains talk about different sets of topics in different styles, which results in different term distributions.

This paper focuses on the task of cross-domain emotion tagging, which utilizes the model trained on one source news domain to help build the model for another target news do-main. More specifically, there are two different scenarios in the task of cross-domain emotion tagging for online news comments. The first scenario is that the two domains share the same set of emotion categories (e.g., both are emotion polarities). The second one is that the two domains use different emotion categories which lead to different label s-paces. For example, comments in the source domain are tagged with binary sentiment polarity whereas in the target domain we want to tag comments with multiple emotion cat-egories such as happiness, sadness, and anger. Taking the category differences into consideration, the problem turns to be cross-domain and cross-category emotion tagging.
This paper proposes novel transfer learning approaches for cross-domain and cross-category emotion tagging of online news comments. When abundant labeled data in the source domain are available, a relatively small amount of labeled data in the target domain can be sufficient for training an accurate classifier in the target domain by transferring use-ful knowledge from the source domain. In particular, when two domains share the same set of emotion categories, the joint probabilities of text features and emotion categories are used to model the relationship between data in the source and target domains. When the two domains utilize differen-t sets of categories, we propose two types of models which deal with the category differences either in a probabilistic way or in an explicit way: the probabilistic model infers the category correlations purely from data and the explicit mod-els borrow human prior knowledge and fix the matchings of categories.

An extensive set of experiments is conducted with four datasets from popular online news services in two groups. Our proposed models significantly outperform alternatives in the task of emotion tagging for comments in both cases when the source domain and target domain share the same emotion categories or use different categories.

To the best of our knowledge, this is the first piece of research that focuses on modeling cross-domain and cross-category emotion tagging for comments of online news. Our proposed models can also be generalized and applied on oth-er cross-domain and cross-category applications.

The rest of the paper is organized as follows. Section 2 reviews some related work. Section 3 proposes our ap-proaches for the two scenarios when the source domain and the target domain share the same emotion categories or use different categories. Datasets and experimental results are discussed in Section 4. The last section provides conclusions and points out possible future work.
Sentiment analysis has become an important subfield of information management. Previous work mostly focuses on product reviews [21], blogs [7][20][30] and news corpo-ra [2][8][19]. For a general survey, please refer to [24]. This paper focuses on emotion tagging for comments of online news.

Many machine learning techniques have been applied on sentiment classification, such as unsupervised learning tech-niques (e.g., [28]), supervised learning techniques (e.g., [25]) and semi-supervised learning techniques (e.g., [26]). For comments of online news, Zhang et al. [34] propose a clas-sification approach that exploits information from heteroge-neous information sources to predict emotions. The research work in [15] tries to predict upcoming comments X  polarity before comments are posted. Many existing works on sen-timent analysis make a strong assumption that the labeled training data and unlabeled testing data share the same fea-tures and category spaces. Thus to analyze comments from a new domain, the training data need to be recollected and models need to be rebuilt.

But the tasks and data distributions in those domains are not completely different, transfer learning techniques [23][29] can reuse data from an existing domain and thus require less labeled data from the new domain. Blitzer et al. [3][4] propose the structural correspondence learning (S-CL) algorithm to exploit domain adaptation techniques for sentiment classification. SCL is motivated by a multi-task learning method using alternating structural optimization (ASO) [1]. More recently, Li et al. [18] propose to transfer common lexical knowledge across domains via matrix fac-torization techniques. Zhang et al. [32] propose research on knowledge transfer in sentiment analysis with auxiliary data from related sources. Unlike SCL algorithm which uses source domain data to find some important pivot features, it models the underlying distribution differences explicitly. The work of Zhang et al. is designed for binary categories and can handle neither multiple categories nor the scenario when two domains use different category sets.
This section proposes a novel framework of cross-domain and cross-category emotion tagging for comments of online news by modeling the data differences between the source and target domains. First we provide a formal definition of the research problem, and then propose approaches for the two scenarios when the source and target domains share the same set of emotion categories or use different categories.
Given a specific news domain D , where an emotion cate-gory set is defined as E = { e i } ( i = 1 ,...,k ), the comment emotion tagging problem is to tag unlabeled comments with corresponding emotions in E utilizing a set of labeled com-ments D . A comment is described as a feature vector x and the label is defined as y = { y l } ( l = 1 ,...,K ), y l 1 if comment x is tagged with emotion e l or 0 otherwise, P l =1 y l = 1. Thus the labeled comments set D can be de-noted as { ( x 1 , y 1 ) , ( x 2 , y 2 ) ,..., ( x m , y number of labeled comments.

In our problem setting of cross-domain and cross-category emotion tagging, two news domains D S and D T are speci-fied, where D S is the source domain and D T is the target do-main. Two emotion category sets E S = { e S l } ( l = 1 ,...,K and E T = { e T k } ( k = 1 ,...,K T ) are defined on D S respectively. Notice that here E S and E T are not necessarily to be the same and it is the reason why our setting is de-scribed by  X  X ross-category X . We have a set of labeled data from the source domain as D S = { ( x S 1 , y S ( x S m , y S m ) } , where m is the size of source domain data. In addition, some labeled data from the target (the new) domain as D T = { ( x T 1 , y T also available and n is the size of labeled target domain data. x S i  X  X S and x T i  X  X T are drawn from the same feature space but under different distributions. In general, 0  X  n m as there are abundant labeled data in the source domain but limited labeled data in the target domain. The task of cross-domain and cross-category emotion tagging is to learn an emotion classifier to predict the emotion tags of unlabeled comments in the target domain D T based on the labeled data of both D S and D T .
This section focuses on the problem of cross-domain e-motion tagging with identical category sets in D S and D T Namely, E S is exactly the same as E T and we rewrite them as E S = E T = { e k } ( k = 1 ,...,K ).
Many probabilistic classification techniques in the liter-ature generally fall into two categories: generative models and discriminative models. Discriminative models have at-tractive theoretical properties [16] and their effectiveness has been demonstrated in the field of information retrieval for applications such as text classification [14][31] and learning to rank [13]. In most cases, discriminative models provide better accuracy than generative models.

This paper utilizes multinomial logistic regression, a dis-criminative model, to classify users X  comments into different emotion categories. Formally, in the target domain D T and given the i th comment, the conditional probability that the comment should be tagged with a predefined emotion cate-gory e k is expressed in terms of a soft-max function as the following normalized probabilistic value, Here x T i represents the feature vector of the i th comment,  X  k denotes the combination weight parameters of emotion category e k . The larger the value  X  T k x T i is, the more prob-able the comment shows particular emotion e k .

The error of the emotion tagging approach with multino-mial logistic regression is measured with the negative log-likelihood loss function. In particular, the loss of a partic-ular i th instance in the training data of the target domain, denoted by  X  T i , can be expressed as follows,
Since the training data from the target domain are in-sufficient for making accurate prediction, it is necessary to utilize the abundant training data from the source domain to improve the classification accuracy in the target domain. Although the feature spaces are the same (i.e., a vector s-pace of keywords in the vocabulary), the data distributions of the two domains are different as the comments in the source domain and the comments in the target domain fo-cus on different types of topics.

To incorporate the auxiliary training data from the source domain into the loss function of the target domain, the dif-ferences of training data distributions between different do-mains are modeled. We propose to adjust the weight of labeled data from the source domain to reflect their corre-sponding importance in the target domain. In particular, a unified objective loss function is defined as follows, taking data from both the source domain and the target domain into account: Where  X  S i is the loss value of each instance from the source domain, which is defined with respect to the weight param-eters  X  k as follows (i.e., in a similar manner to the loss func-tion in the target domain), In equation (3),  X  i models the data distribution differences between the source domain and the target domain, which enables the source domain instances to be naturally incorpo-rated into the objective function through appropriate reweight-ing. The estimating method of  X  i is introduced in the next subsection. R (  X  ) is the regularization penalty to prevent overfitting. In particular, we use the L2 (i.e., ridge) regular-ization method [12].  X  1 and  X  2 are two trade-off parameters that explore the relative importance of classification results in the source domain and the target domain.
As we have discussed, domain adaption can be achieved through reweighting instances from the source domain by modeling the probability differences between the distribu-tions of domains. The distribution differences between the source domain and the target domain lie not only in the text features (feature spaces) of comments but also in the emotion categories (label spaces). So we use the joint prob-abilities of the text features and the emotion categories to model the relationship between data in the source and tar-get domains. In particular,  X  i refers to Pr T ( x S i , y represents the ratio between the joint data distributions in the target domain and that in the source domain for the source domain instance x S i . The intuition is that the ra-tio of the joint probabilities can well capture how a data instance from the source domain should be reweighted to reflect its importance in the target domain.

To estimate  X  i , we adopt an approach based on kernel den-sity estimation (many other methods such as kernel mean matching and Gaussian mixture model can also be utilized). In particular,  X  i is formulated as follows, gory probabilities between the target domain and the source domain, which can be estimated from the labeled data on both domains based on the relative frequencies of each e-density estimation with the Gaussian kernel as follows, Where I T ij is an indicator function, which equals to 1 if y tion, which equals to 1 if y S the bandwidth parameter for the Gaussian kernel. The -1 factor in the denominator removes the effect of the instance itself (i.e., ( x S i , y S probability ratio.

It can be seen that if a source domain instance is close enough to target domain instances, its importance will be high. This is consistent with our expectation, which mean-s the corresponding instance is more representative in the target domain. With this approach, the data distribution of the training data in the source domain can be adjusted to fit the data distribution in the target domain.

The objective loss function expressed by Equation (3) forms a smooth convex optimization problem, and it can be optimized by any gradient descent method. In particu-lar, we use the Quasi-Newton method [6] that enjoys fast convergence rate with limited storage requirement.
The model introduced in the last section works in the sce-nario when the source domain and the target domain share the same set of emotion categories. On the other side, it is also necessary to consider domains associated with different emotion categories. For example, the source domain may contain a larger amount of binary sentiment polarity data (e.g., positive and negative) that can be more easily labeled, whereas in the target domain we want to tag multiple emo-tion categories (e.g., happy, surprised, sad and angry) and only have a limited amount of labeled training data. For building cross-domain emotion tagging solutions in this s-cenario, it is necessary to model the relationship between different sets of emotion categories in the source domain and the target domain to deal with the differences of label spaces.

Section 3.3.1 introduces a probabilistic model which in-fers the category correlations from data and Section 3.3.2 presents explicit models in which the category matchings are explicitly fixed by incorporating human prior knowledge.
Emotion categories are often highly correlated. For exam-ple, one set is a coarse-grained polarity set with two cate-gories of positive and negative, and the other set is a fine-grained emotion set containing happy, amused, angry, and sad. Even though they are different, we can easily find some correlations: if a comment shows happy or amused, it tends to be tagged as positive, and if it is labeled as angry or sad, it tends to have negative sentiment.

This nature of emotion categories inspires us to develop a model that can utilize the correlation between emotion cat-egories to transfer knowledge: first classify the comments from the target domain into the set of emotion categories of the source domain, and then use those class probabilities generated in the first step as features to infer the emotion category in the target domain. This is a two-level prob-abilistic model, in which we make use of abundant source domain data in the first level, and infer emotion category correlations in the second level.

The first step is similar to the problem addressed in Sec-tion 3.2, thus it is possible to utilize a similar model for transferring knowledge from the source domain within the first step. More specifically, given the i th comment in the target domain, the conditional probability that the com-ment should be associated with a predefined emotion e S l 1 ,...,K S ) within the set of emotion categories in the source domain can be calculated as normalized probability values with a soft-max function as follows, Here x T i represents the feature vector of the i th stance (i.e., user comment) in the target domain, and  X  denotes the weight parameters of a particular emotion e S
In the second step, we take the outputs of the classifi-er above as features, namely,  X  T i is composed by  X  T il 1 ,...,K S ), and use multinomial logistic regression model to transfer knowledge between different emotion categories in different domains. The negative loglikelihood function can be defined as follows: Here  X  k represents the weight parameters of a particular emotion e T k .

By incorporating the auxiliary training data from the source domain in the first level, the objective loss function can be defined as follows: where  X  S i is the loss value of each instance in the training da-ta from the source domain, defined in the same way of Equa-tion (7).  X  i models the data distribution differences between the source domain and the target domain for reweighting the source domain instances. R (  X  ) and R (  X  ) are two regulariza-tion penalties for parameters  X  and  X  respectively, in order to prevent overfitting. We use the L2 (i.e., ridge) regular-ization method.  X  1 ,  X  2 and  X  3 are three trade-off parame-ters. Note that if either the number of emotion categories in the target domain or that in the source domain is two, we can simply replace the soft-max function by binary sigmoid function accordingly.

Due to the differences of emotion categories between do-mains, we are no longer able to model the joint data distri-bution in different domains. Instead, the marginal probabil-ities of text features of comments are used. Specifically,  X  is defined with Gaussian kernel density estimator as follows, in a similar way as described in Section 3.2.2.

There are two sets of parameters to be estimated in the joint optimization problem,  X  and  X  , and we employ an al-ternative optimization method for the task. The value of  X  can be fixed, and then the problem is converted to a con-vex optimization problem with respect to  X  , which can be solved by any gradient descent method. The Quasi-Newton method [6] is used for this purpose. After that, the value of  X  is fixed and the value of  X  can be optimized in a similar manner. The above alternative process can be conducted iteratively until the convergence for obtaining optimal val-ues of  X  ? and  X  ? . The learned model can then be used for emotion tagging of any new comment in the target domain.
In the above two-level probabilistic model, we first tag comments in the source domain label space, in order to make use of abundant source domain data, and then in-fer the target domain labels from those source domain class probabilities. However, it may not work well when trans-ferring knowledge from a coarse-grained source domain to a fine-grained target domain, because in the second level it can be too difficult to infer fine-grained categories only from coarse-grained category probabilities.

On the other side, the valuable human prior knowledge about the correlation of category sets (e.g. which emotion categories are positive and which are negative) can be u-tilized in a more explicit manner. We propose the explicit models of category correlation which overcomes the deficien-cy of the probabilistic model.

First we formalize the explicit category correlation named matching correlation. Given a coarse-grained emotion cate-gory set E c = { e i } ( i = 1 ,...,K c ) and a fine-grained emotion category set E f = { e i } ( i = 1 ,...,K f and K f &gt; K can define a matching function M : E f  X  E c based on rea-sonable relationship of emotion categories, we say E E f have the matching correlation. For example, in the e-motion category set with  X  X appy X ,  X  X mused X ,  X  X ngry X , and  X  X ad X  and the sentiment polarity set, happy and amused can be matched to positive and angry and sad can be matched to negative, so these two sets have matching correlation.
Sub-Scenario 1: when the source domain is fine-grained and the target domain is coarse-grained and the emotion category sets have matching correlation, we propose a one-level explicit model as follows: first match the fine-grained labels of the source domain data to corresponding labels in the coarse-grained target domain category set according to matching function M and get a matched coarse-grained source domain dataset D 0 S , then we directly apply the mod-el introduced in Section 3.2 to transfer knowledge from D and do emotion tagging in the target domain label space with the target dataset D T . In this model we abandon some unnecessary fine-grained label information of the source do-main data and it helps reduce modeling noise.

Sub-Scenario 2: when the source domain is coarse X  grained and the target domain is fine-grained and the e-motion category sets have matching correlation, we propose a two-level explicit model. In the first level, we match the fine-grained labels of target domain data to corresponding labels in the coarse-grained source domain category set ac-cording to function M and get a matched coarse-grained target domain dataset D 0 T , then we apply the model intro-duced in Section 3.2 to transfer knowledge from D S do emotion tagging in the course-grained source domain la-bel space with the matched target dataset D 0 T . With this first step, we transfer knowledge from D S and build a mod-el which can more accurately tag comments in the target domain with coarse-grained labels as intermediate results.
In the second level, K c sub-classifiers are built for each category e i in the coarse-grained E S to further classify the fine-grained categories which are matched to the same coarse-grained category e i . More specifically, D T are divided into K c sub-sets according to the labels in the coarse-grained D
T , which means comments in each sub-set have the same coarse-grained tag in D 0 T . Then sub-classifiers are built for each sub-set to classify corresponding fine-grained emotions. Multinomial logistic regression models with L2 regulariza-tion method are applied for building those sub-classifiers.
In this two-level explicit model, we actually regard the tagging problem as a two-step procedure: first classify data into coarse-grained categories (e.g., polarities), then classify fine-grained categories within each coarse-grained category. The explicit model improves the tagging accuracy through transferring source domain knowledge in the first step.
We name the above two models with  X  X xplicit X  because the category correlations are used explicitly as prior knowledge instead of learned purely by data. By explicitly matching the categories, the explicit models directly project data from one domain into the label space of another domain and hence reduce noise and avoid unnecessary uncertainty.
In this section, we first introduces the experimental dataset-s and analyzes the domain differences between datasets. Then we reports an extensive set of experimental results of our proposed approaches and baseline algorithms in both sce-narios of using the same emotion categories and different categories in the source and target domains. Analysis and discussions are presented based on the results.
Two groups of datasets are used conducting the experi-ments and each group contains two datasets from different news domains. More specifically, in every run of experi-ments, one dataset in a group acts as the target domain dataset and the other one in the group acts as the source domain dataset.

The first group of datasets (first used in [34]) is in Chi-nese and comes from two online news services as Sina News and QQ News, which are among the largest news portals in China. In particular, top 20 most popular comments of most-viewed news articles are collected within six months of 2011 from the Society channel of Sina News and the En-tertainment channel of QQ News. These two datasets are referred as the Sina Society dataset and the QQ Entertain-ment dataset respectively.

The second group of datasets is in English and is collect-ed (by Bruno Jakic [15]) from the famous social news portal Reddit. More than 20 K news posts and corresponding com-ments from 8 domains are collected during the time period from January 2011 to March 2011. This paper choose 4 domains which are Politics, WorldNews, Science, and Tech-nology. Moreover, Politics and WorldNews comments are merged together and referred as Reddit Poli&amp;WorldNews dataset and Science and Technology comments are merged together and referred as Reddit Sci&amp;Tech dataset.
Emotion labels in all of the four datasets are manually an-notated. In Sina News and QQ News, even though readers can tag articles with built-in emotion categories, the tag-ging systems are independent from the commenting systems so a tag cannot be paired with a specific comment. Mean-while, users provide much fewer emotion tags than com-ments, probably because that most users feel comment is a better way for expressing their feelings. Thus we can-not utilize users X  tags as labels and instead, we just borrow the built-in emotion categories as predefined fine-grained e-motion categories in the annotating task for Sina Society dataset and QQ Entertainment dataset (note that the t-wo category sets are not the same). For the two Reddit datasets, no built-in emotion category is provided and we pick six emotions out from the 6 basic emotion categories [10] and some other common emotion categories as fine-grained emotion categories. For all of the four datasets, positive/negative are used as coarse-grained categories.
Due to the substantial laboring efforts, each dataset is an-notated by only two annotators as one takes charge of the coarse-grained polarity annotating and the other one con-ducts the fine-grained emotion annotating. Neutral com-ments are excluded since we focus on emotion classification instead of subjectivity detection. The statistics of annotated datasets are as shown in Table 1 and Table 2.
 Table 1: The statistics of labeled comments on the 8 emotion categories of Chinese datasets.
 Table 2: The statistics of labeled comments on the 8 emotion categories of Reddit datasets.

To test the annotating quality, 100 comments are ran-domly sampled from each dataset and a reviewer (not the annotator) annotated them blindly from the original labels. The number of consistent labels are listed in Table 3.
For different datasets in the same group, distributions in either the emotion label spaces or the word feature space are distinct since they are from different domains. Table 1 and Table 2 show the distribution differences in the label spaces. Table 3: Number of consistent labels in 100 samples Reddit Poli&amp;WorldNews 100 95
The two Chinese datasets have different category sets while the two Reddit datasets share the same one. It leads us to choose the 6 overlapped categories for the experiment of same category emotion tagging on Chinese datasets.

For feature spaces, emotion terms have been commonly used as features in the task of textual emotion recognition [27], since they are more likely to convey the emotions. This is consistent with our observation that more accurate results of textual emotion recognition can be obtained using only textual emotion features than using all bag-of-word features. Therefore, we utilize the occurrences of emotion terms in the content of comments as features. For the Chinese dataset-s, we use a Chinese word segmentation software ICTCLAS [33] to segment the comments into terms and extract the emotion terms by two lexical resources (i.e., NTU Senti-ment Dictionary [17], Hownet [9]). For the Reddit dataset-s which are in English, we use the Python NLTK toolkit to preprocess the comments and extract the emotion terms based on SentiWordNet [11]. As an example from Redddit Poli&amp;Worldnews dataset, the feature terms of a comment  X  X eactor pool 4 was empty and the disaster is worse than Chernobyl X  are  X  X ool X ,  X  X mpty X ,  X  X isast X , and  X  X ors X .
Although the two Chinese datasets share the same Chi-nese emotion term set as feature space (i.e., vocabulary) and the two Reddit datasets share the same English emotion ter-m set as feature space, their feature distributions vary from each other. Figure 1 shows the differences of feature dis-tributions between the two Chinese datasets. The X axis represents the term features which are ordered according to their term frequencies in QQ Entertainment dataset. Then the ln(term frequencies) values of both of the two Chinese datasets are plotted. The comparison of the feature distri-butions of the Reddit datasets is similar.
We adopt Accuracy( Accu @ m ) as the measurement. Given a comment c i , its labeled emotion e i and predicted emotion set E i @ m including top m ranked emotions, define Figure 1: Comparison between feature distributions of Chinese datasets Accu @ m for the entire collection C = { c i } ( i = 1 ,...,N ) is defined as follows: Accu @ m = 1 N P N i =1 accu i @ m .
Accu @2 , 3 can be calculated only under the settings where the target domain has more than 2 emotion categories.
Experiments in this section investigate the effectiveness of our proposed approach and baseline methods for the scenario when source domain and target domain share the same set of emotion categories.

The following methods are compared:
For all the methods, the trade-off parameters are set by five fold cross-validations. The average experimental results of 20 independent runs are reported.

The performance of all methods is evaluated on the two groups of datasets and each group has two settings by choos-ing either dataset as the target domain dataset. For the Chinese datasets, we use all data labeled in the overlapped 6 emotion categories in the source domain and randomly selected 1/64, 1/32, 1/16, 1/8 and 1/4 of data labeled in the target domain as the training data, and the remaining data in the target domain are used for testing. Figure 2 and Figure 3 show the Accu@1 results on both two groups of datasets with different ratios of training data in the tar-get domain. In particular, detailed Accu@1,2,3 results with 1 / 16 training samples on Sina Society dataset as the tar-get domain dataset and QQ Entertainment dataset as the source domain dataset are further reported in Table 4.
The results from Figure 2 and Figure 3 show that the per-formance of all three methods improves with more training data in the target domain, which is as expected. It can be seen from these results that under most settings the two methods utilizing data from both the source and target do-mains beat ETLR which only uses data from the target do-main especially when training data from the target domain is not sufficient. This fact clearly demonstrates the advantage of transferring knowledge from the source domain. The pro-posed approach CDET J outperforms SCL in most cases. This is consistent with our expectation that modeling the joint distribution helps capture useful information in data across domains. In most cases, SCL performs only slightly better than ETLR. This might be because SCL does not explicitly model the domain distribution differences and it highly depends on auxiliary tasks.
 Figure 2: The Accu@1 results with different training ratios in the target domain with the same emotion categories on Chinese datasets.
 Figure 3: The Accu@1 results with different training ratios in the target domain with the same emotion categories on Reddit datasets.
 Table 4: The Accu@1,2,3 results of 1/16 training ra-tio, QQ Entertainment is the target domain with the same emotion categories as in the source domain.

Significance tests using t-distribution are conducted for the Accu@1 results regarding result from each run as a sam-ple. Benefited from sufficient independent runs, such tests provide good discriminative power. On Chinese datasets, CDET J outperforms SCL and ETLR with 0.95 confidence level under all training ratios. On Reddit datasets, similar comparison results hold with training ratios lower or equal to 1/16. (Detailed p-values are not presented due to the limitation on number of pages.)
ETLR models trained with only source domain data are also evaluated on target datasets. It performs much worse than CDET J and also worse than ETLR trained with suf-ficient (e.g. more than 1/32) target domain data, we just claim it here instead of presenting detailed results.
Experiments in this section investigate the effectiveness of our proposed new methods for the scenario when the source and the target domains use different sets of emotion cate-gories. The following methods are compared:
For all models, their trade-off parameters are set by 5 fold cross-validations. The average experimental results of 20 in-dependent runs are reported. Notice that the SCL method is not compared as baseline here, as it cannot fulfill the re-quirement of transfer learning between different label spaces.
In the following experiments, all data from the source do-main are available for training, and different amounts of data are randomly sampled from the target domain for training while the remaining are for testing.
We first present the experiment results when the source domain is fine-grained and the target domain has binary po-larities. For the Chinese datasets, it is no longer required to use overlapped categories so each of them contains 8 emo-tion categories. Figure 4 and figure 5 show the experimental results with different sizes of target domain training data.
From the results, it can be observed that both of the t-wo proposed models outperform ETLR under most of the settings. This fact again clearly shows the effectiveness of transferring knowledge, even when it is from a fine-grained source domain to a coarse-grained target domain. Mean-while, the explicit model E CDCCET outperforms the prob-abilistic model P CDCCET, which proves that incorporat-ing prior knowledge on emotion category correlation helps improve classification accuracy.

Statistical significance tests have also been conducted for the Accu@1 results. On all domain settings, E CDCCET outperforms ETLR with 0.95 confidence level under all train-ing ratios and P CDCCET outperforms ETLR with 0.95 confidence level under training ratios lower or equal to 1/32. Meanwhile, E CDCCET outperforms P CDCCET with 0.95 confidence level in most cases.
 Figure 4: The Accu@1 results with fine-grained source domain and coarse-grained target domain on Chinese datasets.
 Figure 5: The Accu@1 results with fine-grained source domain and coarse-grained target domain on Reddit datasets.
Data with binary polarities can be more easily labeled than data with multiple emotion categories. However, it is a challenging task to do emotion tagging of comments when the source domain has binary sentiment categories and the target domain has fine-grained emotion categories.Figure 6 and Figure 7 show the comparison results on two groups of datasets with different sizes of target domain training data. More specifically, Table 5 provides the Accu@1,2,3 results under the training ratio 1 / 16 on QQ Entertainment dataset as target domain dataset.

From Figure 6 and Figure 7, we observe that the per-formance of the proposed probabilistic model P CDCCET is not ideal. Even though P CDCCET transfers knowledge from the source domain in the first level, it is too difficult to infer fine-grained categories from coarse-grained probability features in the second level.

When the ratio of the training data in the target domain is relatively low (e.g., below 1/8), E CDCCET outperforms ETLR substantially. This indicates that our explicit model can take advantages of abundant data labeled with senti-ment polarity to transfer knowledge and can help tag fine-grained emotion categories more accurately in the target do-main which has a relatively small size. Unlike P CDCCET which models the emotion category correlations probabilis-tically, E CDCCET benefits from utilizing the explicit prior knowledge for modeling category correlation.
 When the training ratio grows to 1/8 or higher, E CDCC-ET loses advantages. This may be explained as that E CDC-CET utilizes the binary labeled data from the source domain in the first step of classification to remedy the lack of data in the target domain. Under higher training ratios, there turns to be fairly enough training data from the target domain for binary classification and the advantages gained from the auxiliary source domain data are no longer significant.
Statistical significance tests conducted for the Accu@1 re-sults show that E CDCCET outperforms ETLR with 0.95 confidence level when training ratio is lower or equal to 1 / 32 on all domain settings.
 Table 5: The Accu@1,2,3 results with 1/16 training instances on QQ Entertainment dataset as the target domain with fine-grained sentiment categories and Sina Society dataset as the source domain but with binary sentiment polarity labels.

We explicitly fix the matching relations between categories in E CDCCET based on common sense. The corresponding matchings are as shown in Table 6.

For the probabilistic model P CDCCET, the category cor-relations are trained instead of preassigned. Table 7 shows the learned correlations by normalizing the learned weights  X  in Equation (8). They are sampled from one experiment when the source domain of Sina Society dataset has labels of 8 emotion categories while the target domain of QQ Enter-tainment has sentiment polarity as labels. Larger values in-dicate that the corresponding emotions are more likely to be Figure 6: The Accu@1 results with coarse-grained source domain and fine-grained target domain on Chinese datasets.
 Figure 7: The Accu@1 results with coarse-grained source domain and fine-grained target domain on Reddit datasets. positive, while smaller values indicate the opposite.  X  X appy X  is the most positive emotion and  X  X ngry X  is the most negative emotion. Besides,  X  X ouched X ,  X  X ympathetic X  and  X  X urprised X  are positive whereas  X  X mused X ,  X  X ad X  and  X  X nxious X  are neg-ative. These observations are quite consistent with common sense except for one mismatching. It explains the effective-ness of P CDCCET model under the setting of fine-grained source domain and coarse-grained target domain. Table 6: The pre-fixed emotion/polarity matchings. Table 7: The normalized learned weights for emo-tion correlation on QQ Entertainment dataset.

This paper proposes a novel framework to address the task of predicting emotions for comments of cross-domain online news by modeling the relationship between different but related sets of emotion categories for the source and tar-get domains. In particular, one method has been proposed for the task when the source and target domains share the same set of emotion categories and two methods have been proposed for the scenario when source and target domains use different categories. Our experimental results in both scenarios on four datasets demonstrate the effectiveness of the proposed approaches.

For possible future research, we plan to design a better text representation scheme by combining full text represen-tation with feature selection techniques to avoid using only emotion terms. Furthermore, a more sophisticated model-ing strategy for knowledge transfer may also improve the performance of cross-domain emotion tagging. This work is partially supported by NSF research grants IIS-0746830, CNS-1012208, IIS-1017837 and CNS-1314688, and also partially supported by NSF of China research grants 61170184. This work is also partially supported by the Cen-ter for Science of Information (CSoI), an NSF Science and Technology Center, under grant agreement CCF-0939370.
