 Classical matrix factorization approaches to collaborative fil-tering learn a latent vector for each user and each item, and recommendations are scored via the similarity between two such vectors, which are of the same dimension. In this work, we are motivated by the intuition that a user is a much more complicated entity than any single item, and cannot be well described by the same representation. Hence, the variety of a user X  X  interests could be better captured by a more com-plex representation. We propose to model the user with a richer set of functions, specifically via a set of latent vectors, where each vector captures one of the user X  X  latent interests or tastes. The overall recommendation model is then non-linear where the matching score between a user and a given item is the maximum matching score over each of the user X  X  latent interests with respect to the item X  X  latent representa-tion. We describe a simple, general and efficient algorithm for learning such a model, and apply it to large scale, real-world datasets from YouTube and Google Music, where our approach outperforms existing techniques.
 H.4 [ Information Systems Applications ]: Miscellaneous collaborative filtering, learning to rank, matrix factorization, nonlinear models
Standard latent models for recommendation are linear fac-torizations of the user-item matrix of preferences. These models are then applied at test time for recommendations of new items. For example, singular value decomposition (SVD) and its variants, such as SVD++ (see [2] for a good review), factorize the user-item matrix in a least-squares mainder of the paper is as follows. We first describe previous work in Section 2. We then present our model in Section 3, detailing the objective function and learning procedure to train such a model by gradient descent. Experimental re-sults on large scale recommendation tasks from Google Mu-sic and YouTube are reported in Section 4. We finally sketch some directions for future work in Section 5.
We have already talked about the most related linear fac-torization models in the introduction, but the method we propose in this work generalizes those to a nonlinear model. Several types of nonlinear models have been tried before for recommendation. The authors of [3] proposed a nonlinear matrix factorization approach with Gaussian processes by using a kernelized form for the model. They report very good results on 1M MovieLens and EachMovie, however their approach may have scalability issues for larger prob-lems. The authors of [5] applied Restricted Boltzmann ma-chines for collaborative filtering, which is a kind of neural network that introduces nonlinearities via Gaussian hidden units. They obtained results slightly better than SVD, and an ensemble of the two methods performs very well. Our method can also be considered to be a particular kind of neural network, utilizing max nonlinearities rather than the standard sigmoids, although it is quite different from that of [5].

Other machine learning models consider max-based non-linearities as we do, e.g. convolutional networks for image tasks use max-pooling [4]. To the best of our knowledge, however, they have not been used in latent models as in our approach, and have similarly not been applied to recommen-dation tasks.

Perhaps closest to our approach is the work of [1] where multiple profiles for user modeling (micro-profiling) are used for context-aware recommendation.
Standard linear user-item factorizations are of the form: where u is the given user, u  X  X  1 , . . . , |U|} , and d is an item to be recommended, d  X  { 1 , . . . , |D|} . The score assigned seen as the prediction of a missing element of the (full rank) matrix S of dimension |U| X |D| , which is approximated by the low rank factorization of S by U and V . The matrix U , which is of size m  X |U| , encodes the latent factors for the users, and a m  X |D| matrix V encodes those of the items. Hence, every user and every item has m latent factors.
The key idea of the proposed model is to define T interest vectors per user, where the user part of the model is written as  X 
U which is an m  X |U| X  T tensor. Hence, we also write  X  U iu  X  R m as the m -dimensional vector that represents the i th of T possible interests for user u . The item part of the model is the same as in the classical user-item factorization models, and is still denoted as a m  X |D| matrix V . The new scoring model is defined as: For any given item, we are now computing T dot products, rather than one, when comparing it to the user, and taking the positive item d relative to all the negative items: and L (  X  ) converts the rank to a weight. Choosing L (  X  ) = C X  for any positive constant C optimizes the mean rank, whereas a weighting such as L (  X  ) = P  X  i =1 1 /i optimizes the top of the ranked list, as described in [7]. To train with such an objective, stochastic gradient has previously been employed. For speed the computation of rank d ( u ) is then replaced with a sampled approximation: sample N items  X  d 0 and then approximate the rank with |D\D u | /N .
Although our model is nonlinear, we can still use almost the same procedure as used for the linear model in [10], we just need to compute the relevant gradients for our model. imum scoring user interest vector for d as  X  U ut and  X  U u  X  t for  X  d , where For a violating triple we then need to update for the user model: and for the item model: where  X  is the learning rate. At each step, one typically also enforces that || U ij || X  C and || V i || X  C , for all i and j , as a means of regularization.

The whole procedure is outlined in Algorithm 1, and is scalable to medium-size datasets, where the model fits in memory. Unfortunately, there is a major problem when the dataset becomes large. For example if we would like to apply this method to a dataset with 1 billion users (more than 1 billion unique users visit YouTube each month) and latent dimension m = 64, this gives a model of size &gt; 238GB (even for T = 1). This is too big for most machines, and even if it did fit, it might also be very slow to train. We therefore consider a MapReduce-based training solution to deal with this issue.

Our solution to scale this algorithm is to consider an al-ternating optimization: first optimize over the item embed-dings V and then train the user embeddings U . In the first phase where we train V , the user model U is unknown. One option would be to initialize U to random values, however V is unlikely to be trained well unless the process is iter-ated enough to allow U to also converge (but similarly U will be training with an impoverished V in early iterations). Instead, in the first phase we build a model that factors out U completely: i.e. we consider that U u , 1 |D is reminiscent of the item-based embedding of the user em-
We conducted experiments on three large scale, real world tasks: music recommendation using proprietary data from Google Music 1 , of both artists and individual tracks, and video recommendation from YouTube 2 . In all cases, the datasets consist of a large set of anonymized users, where for each user there is a set of associated items based on their watch/listen history. The user-item matrix is hence a sparse binary matrix. The sizes of the datasets are given in Table 1.

To construct evaluation data, we randomly selected 5 items for testing per user, and kept them apart from training. At prediction time, for the test users we then ranked all un-rated items (i.e. items that they have not watched/listened to that are present in the training set) and observe where the 5 test items are in the ranked list of recommendations. We then evaluate the following metrics: rank (the position in the ranked list, averaged over all test items), precision at 1 and 10 (P@1 and P@10), and recall at 1 and 10 (R@1 and R@10).

Hyperparameters (  X , C ) were chosen using a portion of the training set for validation, although for memory and speed reasons we limited the embedding dimension to be m = 64. As we trained our model, MaxMF (Max-nonlinearity Ma-trix Factorization), with a ranking criteria, we consider our baseline to be the same type of model, but without non-linearity, which is the Wsabie model of [10]. So we used the same  X  and C that are optimal for Wsabie and then report results for different values of T for MaxMF with those settings, using the MapReduce based training scheme. On Google Music Artist Recommendation and the YouTube tasks we also compare to SVD (L2-optimal matrix factoriza-tion for the complete matrix with log-odds weighting on the columns, which downweights the importance of the popular features, as that worked better than uniform weights). (For YouTube, we trained the SVD on a (large) subset due to scalabilty issues.) Note, however, that SVD was shown to be inferior to Wsabie on several datasets previously [10]. Hence, as Wsabie is our main baseline, we report relative changes in metrics when using other methods compared to it. Results on the three datasets are given in Tables 2, 3 and 4.

The first dataset, Google Music artist recommendation (Table 2), MaxMF gave only relatively small gains com-pared to Wsabie . SVD performed worse in all metrics. Note that a strongly performing model has a small mean rank, and large precision and recall values, hence we are looking for negative percentage changes in mean rank but positive changes in the other metrics. SVD likely underper-forms since we are measuring ranking based metrics, which it does not optimize at training time. In other respects, the models are very similar. For MaxMF , as we increased the number of user interests T that we model, mean rank de-creases from 3.9%, 8% and 11% compared to Wsabie , for T = 3, T = 5 and T = 10 respectively. Changes in precision and recall are smaller. We hypothesize that the relatively small size of this dataset compared to the other two is the reason why MaxMF has smaller gains.

The second dataset, Google Music track recommendation, is comprised of the same set of anonymized users, but with http://music.google.com http://www.youtube.com
