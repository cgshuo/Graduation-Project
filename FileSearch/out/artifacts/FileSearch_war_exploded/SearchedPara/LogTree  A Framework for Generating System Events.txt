 } @cs.fiu.edu
Modern computing systems are instrumented to generate huge amounts of system log data. The log data describes the status of each component and records system internal operations, such as the starting and stopping of services, detection of network connections, software configuration modifications, and execution errors. Analyzing system logs , as an attractive approach for automatic system manage-ment, monitoring and system diagnosis, has been enjoying a growing amount of attention [1][2][3][4][5][7][8]. With the increase of the system complexity, most modern sys-tems generate a huge amount of log data every day. For example, one PVFS2 server could produce more than 6000 text messages for every 5 seconds [9]. In current cloud computing environment, a data center typically maintains over thousands of servers. Therefore, it is a challenging ta sk to analyze the huge amount of log data.
 A. Analyzing System Logs
Generally there are two main challenges in performing automated analysis of system logs. The first challenge is transforming the logs into a collection of canonical events . Note that the number of distinct events observed can be very large and also grow rapidly due to the large vocabulary size as well as various parameters in log generation [10]. In addition, the variability in log languages creates difficul ty in deciphering events and errors reported by multiple product s and components [4]. Once the log data has been transformed into a canonical form, the second challenge is the design of efficient algorithms for analyzing log patterns from the from FileZilla [11]. In order to analyze the behaviors, the raw log messages need to be translated to several types of events. Figure 1 shows the corresponding event timeline created by the log messages. The event timeline provides a convenient platform for people to understand log behaviors and to discover log patterns.
 Figure 1: Event timeline for the FileZilla log example.
Recently, there have been lots of research efforts on using data mining and machine learning techniques for analyz-ing system logs [1][2][3][5][6][8]. Most of these efforts address the second challenge and focus on analyzing log patterns from events for problem determination such as discovering temporal patterns of system events, predictin g and characterizing system behaviors, and performing syste m performance debugging. They generally assume the log data has been converted into events and ignore the complexities and difficulties in transforming the raw logs into a collecti on of events.
 B. Contributions of the Paper
For modern complex systems, manually transforming raw log messages to system events is extremely expensive. Most modern systems are composed of various components developed by different development teams or even with different techniques [12]. Collecting all templates of log s from the system documents or source code is cumbersome and labor-intensive. In addition, there are some practical issues, such as the lack of the complete documentation and the permissions of accessing the source code, that would make the manual approach impossible. Some recent works [1][6][10] apply clustering techniques to translate the raw log messages into system events automatically. The basic idea is to build clusters of the raw log messages where each cluster represents one type of events. In clustering th e log messages, however, existing techniques only make use of the word/term information and ignore the format and structural information.

In this paper, we first describe the drawbacks of existing clustering techniques for event generation from system log s. We show that, current methods which only make use of the word/term level information, are not able to achieve good performance in transforming the raw log data into system events. Note that event generation is the basis for further log pattern analysis. Thus low accuracy in log data transformation would greatly limit the success of log pattern analysis for problem determination. To address the limitations of existing methods, we then propose LogTree , a novel framework for events generation from raw system log messages. LogTree utilizes the format and structural information of the raw logs in the clustering process to generate system events with better accuracy. An indexing data structure, Message Segment Table, is also introduced in LogTree to significantly improve the efficiency of events creation. We collect system logs from 4 different and popula r systems in real world applications and conduct extensive experiments are to demonstrate the effectiveness of LogTree . Our experimental results show that LogTree is about 2 -10 times faster than its competitors.

The rest of the paper is organized as follows: In Section II we formulate the problem of the system events generation and discuss the drawbacks of traditional solutions as well as our motivation. Section III first introduces the semi-structural model of the log messages and then presents our proposed similarity measurement based on this model. In Section IV, we describe the framework LogTree for the system events generation with its indexing data structure Message Segment Table. In Section V we present the experi-mental studies on 4 real system logs. Section VI summarizes the related studies on system events generation. Finally, Section VII concludes the paper and discusses the future work.

Formally, a series of system log is a set of messages S = { s 1 , s 2 , , s n } and n is the number of log messages. The length of denoted by | S | , i.e., n = | S | . The objective of the event creation is to find a representative set of message express the information of S as much as possible, where | S  X  | = k  X  | S | , each message of S  X  represents one type of event, and k is a user-defined parameter. The intuition is illustrated in the following Example.

Example 1: Table I shows a set of 15 log messages generated by a FileZilla client. It mainly consists of 6 types of messages, which include 4 different commands (e.g.,  X  X ut X ,  X  X d X ,  X  X kdir X , and  X  X s X ), responses, and erro rs. Therefore, the representative set S  X  could be created to be { s (including every type of the command, response, and error) are covered by S  X  , and k = 6 .

We hope the created events to cover the original log as much as possible. The quality of S  X  can be measured by the event coverage .

Definition 1: Given two sets of log messages S  X  and S , | S  X  |  X  | S | , the event coverage of S  X  with respect to J
C ( S  X  , S ) where F sage x  X  and the log message x . We will discuss the similarity function in detail in Section III.
 A. Problem Statement
Given a series of system log S with a user-defined parameter 0  X  k  X  | S | , the goal is to find a representative set S  X   X  S , which satisfies: Clearly, the system event generation can be regarded as a text clustering problem [14] where an event is the centroid or medoid of one cluster. However, those traditional text clustering methods are not appropriate for system logs. We show that those methods, which only extract the information at the word/term level, cannot produce good results when used for clustering system logs.
 B. Why is the word level information not enough?
It has been shown in [4] that log messages are relatively short text messages but have large vocabulary size. As a result, two messages of the same event type share very few common words. It is possible that two messages of the same type have two totally different sets of words.
 The following is an example of two messages from the PVFS2 log file [9]. The two messages are status messages. Both of them belong to the same event type status which prints out the current status of the PVFS2 internal engine.
Note that the two messages have no words in common and clustering analysis purely based on the word level information would not reveal any similarity between the two messages. The similarity scores between the two messages (the cosine similarity [14], the Jaccard similarity [15] or the words matching similarity [10]) are 0.
 C. Motivation
Although there is no common words between the two messages in Section II-B, the structure and format informa-tion implicitly suggest that the two messages could belong to a same category as shown in Figure 2. The intuition is straightforward: two messages are both split by the  X : X ; the left parts are both English words, and the right parts are 6 numbers separated by a tab. Actually, people often guess the types of messages from the structure and format information as well.

In real system applications, the structure of log mes-sages often implies critical information. The same type of messages are usually assembled by the same template, so the structure of log messages indicates which internal component generates this log message. Therefore, we should consider the structure information of each log message instead of just treating it as a sentence.

We propose a general semi-structural model to represent the system log messages. It is able to capture the important structural and format information in many real-world syste m logs. Formally, a semi-structural log is represented by a tr ee T = { V, E, L, v root , P } , where V is the set of nodes, the set of edges, P is the set of log message segments (or phrases), L is a mapping function between the set of nodes and the set of log messages segments (i.e., L : V  X  P and v structural as we don X  X  perform information extraction from the log messages. For building the tree, we only employ the context-free language parser to construct a hierarchic al structure of message segments. Example 2 shows examples for FileZilla [11] and MySQL [16] logs.

Example 2: Figure 3 shows two semi-structural log mes-sages for the FileZilla client logs. The first tree in Figure 3 shows an execution of a SFTP command  X  X d X , and the second tree is about a response message from the SFTP server. The response message in the second tree can be transformed to a semi-structural log T Figure 4 shows a semi-structural log message of the MySQL Server, which indicates the starting of the MySQL backend server.
 A. Log parsing
Building semi-structural log messages from the plain text For example, the context-free grammar for the FileZilla log could be established by the following 5 rules:
In our work, we have implemented all the parsers for 4 different system logs in Java. None of the parsers costs more based on the grammar.

It is important to note that the results of the system event generation depend on the implementation of the parser as well as many other data preprocessing steps. However, a lot of previous studies focus on preprocessing and analyzing th e format of textual logs. Some recent studies even suggest tha t the parser can be automatically created by an incremental learning approach [18]. So the discussion of the parser is beyond the scope of this paper.
 B. Similarity of Semi-structural Log Messages
Intuitively, for two semi-structural log messages T T , the coverage of T number of similar nodes and edges of T of methods have been proposed to compute the distance of two labeled trees in previous literatures [19] [20]. The edit distance and alignment distance are two typical method s where only the ancestral relation of nodes, not the imme-diate parental relation of nodes, are maintained during the computation. However, they are not appropriate for semi-structural log messages. For example, in Figure 4, we cannot derive the relation ( X  X Note] X ,  X 3306 X ) from the two edges ( X  X Note] X ,  X  X ort X ) and ( X  X ort X ,  X 3306 X ), because ( X  X Note]  X ,  X 3306 X ) expresses a different meaning.

We have analyzed many different kinds of system logs, such as the FTP/SFTP Client: FileZilla [11], Database Server: MySQL [16], Parallel File System: PFVS2 [9] and Apache HTTP Server [21]. One observation is that, the higher level nodes are more important in discriminating the log messages than the lower level nodes . As shown in the log messages of Figure 3, the root node indicates the current action of the log message, which is the most impor-tant node. Therefore, high importance should be assigned to high level nodes.

Let V ( T ) denote the set of nodes of tree T . For a node v , let T ( v ) denote the subtree rooted at node C ( v ) denote the set of the children of v . Let d ( L ( v ) , L ( u )) denote the similarity of message segments of node v (We will discuss the definition d ( , ) in Section III-C.). For two nodes v and u , let M  X  matching between v  X  X  children and u  X  X  children. Formally,
C ( v, u ) P C ( u ) and each node of C ( v ) and C ( u ) can be contained by exactly one pair.

Definition 2: Given two log messages s T 1 = { V 1 , E 1 , L, r 1 , P } the corresponding semi-structural log messages of s respectively, the coverage function F as follows: where v  X  X  children, and  X  is a parameter, 0  X   X   X  1 .
 Note that the function F function F  X  rooted at two given nodes v the two subtrees, besides the root nodes v to consider the similarity of their children as well. Then, there is a problem that which child of v with which child of v the best matching M  X  the best matching is actually a maximal weighted bipartite matching problem. In our implementation, we use a simple greedy strategy to find the matching. For each child of we assign it to the maximal matched node in unassigned children of v is
O ( n 1 n 2 ) where n 1 and n 2 are the numbers of children of v which is a decay factor. In order to improve the importance of higher level nodes, this decay factor is used to decrease the contribution of similarities at a lower level. Since  X   X  1 the decay factor w decreases along with the recursion depth. C. Similarity of Log Message Segments
Function d ( , ) determines the similarity between two log message segments. A log message segment is a phrase of a log message, which is a sequence of words and symbols. In information retrieval, there are a lot of measurements to compute the similarity between two sentence phrases. But for the log message segments, we consider two additional pieces of information as follows.  X  symbols, such as  X : X ,  X  X  X , are important to identify the  X  The type of a word/term implies the format information. As mentioned in [10], the word ordering is important to identify the similarity of two message segments. Therefore , we define the function d ( , ) as follows:
Definition 3: Given two message segments m p p n q , , q n is computed as follows: where and  X  is a user-defined parameter, 0  X   X   X  1 .
 Note that function d can be computed in a linear time complexity.
 D. Comparison with Tree kernel
In natural language processing, a tree kernel is a kind of similarity measurement for dependency trees [22] [23], which is similar to our coverage function F directly applying the tree kernel for clustering the log message is not appropriate in our work. The reasons are as follows.  X  A Tree kernel does not assign different importance val- X  Computing tree kernels is time-consuming. Hence, it
The generation of system events from the logs can be achieved by a clustering algorithm. We develop an algorithm independent framework to generate system events, which has the following two major features:  X  Efficiency: For current large complex and distributed A. Message Segment Table
Many message segments are fixed in the source code of the system. For example, the second log message in Figure 3 has a message segment:  X  X ew directory is X  . This message segment is generated with different targets or parameters to assemble many different response logs. Figure 4 shows another example for MySQL. The  X  X eady for connection X  can be assembled with different daemon processes of the storage engine. Therefore, a lot of message segments are duplicated in the log data. Based on this fact, we propose an indexing data structure, called Message Segment Table (MST) to improve the efficiency of the events generation. Figure 5 shows the overview of the Message Segment Table . This table is a two dimensional dynamic table. Each entry stores the similarity score of a pair of message segments. Each column and row represent a unique message segment. Let col ( i ) and row ( i ) denote the message segments of i -th column and i -th row index respectively. entry ( i, j ) denotes the entry at column i and row j , which is the similarity score of col ( i ) and row ( j ) . So the table can be viewed as a dynamic similarity matrix of message segments. Since every node is only possible to be compared with the same level X  X  nodes, we don X  X  need to put nodes at different levels in one table. Thus, we create separate MSTs for nodes at different levels.

A hash table is used to maintain the indexes of message segments in the MST. For each message segment, the corre-sponding column index and row index can be searched from this hash table. So this table is called Column Hash Table. Note that for a unique message segment, its column index and row index are the same. Figure 5 shows an example of the column hash table. The search key of the hash table is the message segment  X  X egment X  , and the search value is a tuple consists of the corresponding column index and the number of occurrences  X  &lt; Col, Occur &gt;  X  . The number of the occurrences is used to distinguish the frequent message segments and infrequent message segments. Some message segments only appear very few times in the log, such as the parameters of an event. Considering the limitation of the main memory size, we only store those frequent message segments in the MST. For this purpose, when we scan all log messages, we keep track of the number of occurrences of each message segment using the column hash table. After we put all message segments into the column hash table, we remove those segments whose frequency is less than a user-defined threshold f and the column hash table both become smaller when f increases.
 1) Building the MST: This message segment table is built on a given set of semi-structural log messages. Using the depth-first or breadth-first traversal, every log messag e segment can be visited and inserted into the column hash table. Once the column hash table is created, the MST can be built by computing the similarity score of every pair of message segments in the table. Algorithm 1 describes the detail of building the MST and its column hash table. V ( T ) denotes the set of all nodes in the forest T . For the hash table CT , CT [ k ] denotes the value of key k , and CT.i denotes the i -th key. For each node v of the log tree, v.col indicates the field of its corresponding column index at the MST. It is the virtual link of the node as shown in Figure 5. The time complexity of building the MST is O ( | V ( T ) | ) . 2) Computing F F the message segment of each node. We could obtain the similarity score directly from the virtual link to the MST. The virtual link of the node is stored by an integer. Since the maximal length of message segment is a constant, the time complexity of computing F But the I/O cost of computing F similarity score of d ( , ) in the MST is stored by a float number. The total I/O cost of computing d ( , ) is reduced from the total length of two message segments to be just 3 numbers. Furthermore, it enhances the cache-consciousnes s of the algorithm, which can bring a huge improvement on the algorithm efficiency in modern computing systems. 29 end Algorithm 1: MST building algorithm. 3) Update: The log message is a kind of streaming data, which is constantly generated over the time. So our indexing data structure should be updated efficiently. Since our MST is built by a dynamic table with a hash table, we can easily insert or remove a message segment. The time complexities of the two operations are O (1) .
 B. The Framework of Events Generation
The system event generation is based on the data cluster-ing algorithm. Various clustering algorithms can be plugge d in the LogTree framework. We have developed a log analysis system which uses LogTree to create events. In our system, we choose a hierarchical clustering algorithm. Hierarchic al clustering can provide a multi-level view of the events to the users. The users can roll up or drill down at different level in the event timeline similar to the OLAP operations in a data cube.

Algorithm 2 describes the process of events generation in our framework. The data clustering algorithm Clu is an input specified by the user. As for Clu , the input data objects and the similarity function are provided. The clustering algorithm returns representative data objects as a set of events.
 A. Experimental Platforms Our log analysis system is developed using Java 1.5 Platform. Table II shows the summary of two machines where we run our experiments. All experiments except for scalability test are conducted using Machine1, which is a 32 -bits machine. As for the scalability experiment, the progra m needs over 2G main memory, so it is conducted using Machine2, which is a 64-bits machine. All the experimental programs are single-threaded.
 B. Data Collection
In order to evaluate our work, we collect the log data from 4 different and popular real systems. Table III shows the summary of our collected log data. The log data is collected from the server machines/systems in the computer lab in the School of Computing and Information Sciences (SCIS) at Florida International University (FIU). Those systems a re very common system services installed in many data centers.  X  FileZilla client 3.3[11] log, which records the client X  X   X  MySQL 5.1.31[16] error log. The MySQL database is  X  PVFS2 server 2.8.2[9] log. It contains errors, internal  X  Apache HTTP Server 2.x[21] error log. It is obtained C. Comparative Methods
In order to evaluate the effectiveness and efficiency of our work, we use 4 other related and traditional methods in the experiments. Table IV shows all the comparative methods used in the experiments. As for  X  X ree Kernel X , the tree structure is the same as that used in the our method LogTree . Since the tree node of the log message is not labeled, we can only choose sparse tree kernel for  X  X ree Kernel X  [23]. The experiments of the event generation are conducted using two clustering algorithms, K-Medoids [24] and Single-Linkage [15]. The reason that we choose the two algorithms is that K-Medoids is a basic and classical algorithm for data clustering, and Single-Linkage is a typi cal hierarchical clustering which is actually used in our sys-tem. It should be pointed out that the comparison focuses on similarity measurements which are independent from a specific clustering algorithm. We expect that the insights gained from our experiment comparisons can be generalized to other clustering algorithms as well.
 D. The Quality of Events Generation
The entire log is split into different time frames. Each time frame is composed of 2000 log messages and labeled with the frame number. For example, Apache2 denotes the 2th frame of the Apache log. The quality of the results is evaluated using the F-measure (F1-score) [14]. First, the l og messages are manually classified into several types. Then, the cluster label for each log message is obtained by the clustering algorithm. The F-measure score is then computed from message types and clustered labels. Table V and Table VI show the F-measure scores of K-Medoids and Single-Linkage clusterings with different similarity approaches , respectively. Since the result of K-Medoids algorithm vari es by the initial choice of seeds, we run 5 times for K-Medoids clustering and the entries in Table V are computed by averaging the 5 runs.

Only  X  X ree Kernel X  and  X  X ogTree X  need to set parameters.  X  X ree Kernel X  has only one parameter,  X  matching subsequences of nodes [23]. We run it under different parameter settings, and select the best result fo r comparison. Another parameter k is the number of clusters for clustering algorithm, which is equal to the number of the types of log messages. Table VII shows the parameters used for  X  X ree Kernel X  and  X  X ogTree X .

FileZilla log consists of 4 types of log messages. One observation is that, the root node of the semi-structural log is sufficient to discriminate the type of a message. Meanwhile, the root node produces the largest contribution in the similarity in  X  X ree Kernel X  and  X  X ogTree X . So the two methods benefit from the structural information to achieve a high clustering performance.

PVFS2 log records various kinds of status messages, errors and internal operations. None of the methods can perform perfectly. The reason is that, in some cases, two log messages composed of distinct sets of words could belong to one type (An example is given in Section II-B.). Thus, it is difficult to cluster this kind of messages into one cluster .
MySQL error log is small, but some messages are very long. Those messages are all assembled by fixed templates. The parameter part is very short comparing with the total length of the template, so the similarity based on the templates wouldn X  X  be interfered by the parameter parts very much [10]. Therefore,  X  X atching X  always achieves the highest performance.
 Apache error log is very similar to the FillZilla log. However, it contains more useless components ,such as the client information. In our semi-structural log, those usel ess components are located at low level nodes. Therefore, when the parameter  X  becomes small, their contributions to the similarity are reduced, then the overall performance becom es better.

To sum up, the  X  X ree Kernel X  and  X  X ogTree X  methods outperform other methods. The main reason is that, the two methods capture both the word level information as well as the structural and format information of the log messages. In the next subsection, we show that our  X  X ogTree X  is more efficient than  X  X ree Kernel X .
 E. The Efficiency of Event Generation
We records the running time of each clustering algorithm on the log data. Due to the space limit, we only show the running time of K-Medoids algorithm on FileZilla log, PVFS2 log, and Apache error log in Figure 6a, 6b and 6c. The running time is the average number of 5 runs. In the implementation, we build the similarity matrix of each pair of log messages at the beginning, whose time complexity is O ( N 2 ) where N is the number of samples. Thus, the majority of the running time is used for building the similarity matrix. As for  X  X ogTree X , the threshold of Message Segment Table is f choice depends on the size of the main memory. Note that the running time of LogTree includes the time for building MST.

Figure 6 shows that the vector space model based text clustering,  X  X F-IDF X , is the most efficient approach. The reason is that, the sparse vector is a compact representatio n of the log message. The cosine similarity of two sparse vectors can be obtained in one pass. The vector transfor-mation can be performed in linear time by using a hash table. Furthermore, the cosine similarity of vectors do not consider the structural information of two log messages.
Our proposed approach,  X  X ogTree X , is in the second place in Figure 6. With the help of the Message Segment Table, it can save a lot of computation time to obtain the similarity of two tree nodes. However, in order to consider the structural information of the log message, the similarity function still needs find the most matched node at each level of the tree. So it cannot be completed in one pass as the cosine similarity.

The other three methods,  X  X ree Kernel X ,  X  X atching X  and  X  X accard X  are slower than the previous two methods. One reason is that, those three methods do not provide a compact representation of the log message in the main memory. For the similarity of every two messages, they all have to access the original messages, requiring more CPU and I/O costs. As for  X  X ree Kernel X , it compares every pair of nodes in the same level and its time complexity O ( mn 3 ) is very large, where m and n are the number of nodes in the two trees respectively [23].
 F. The Scalability of Event Generation 1) Time Scalability: We run all methods on the logs with different sizes to evaluate their time scalability. Figure 7a, 7b and 7c show the scalability results of K-Medoids algorithm with different similarity measurements. The running time i s obtained by averaging 5 different runs as mentioned before. This set of experiments needs more than 2G main memory, so it is conducted using Machine2 as we introduced in Section V-A. The results shown in Figure 7a, 7b and 7c are consistent with the efficiency tests in previous subsection .  X  X F-IDF X  is the most efficient approach, and our proposed method, X  X ogTree X , is in the second place, where the thresh-old for MST f 2) Space Scalability: The space costs for all methods are identical except for our method  X  X ogTree X . For  X  X ogTree X , there is an additional message segment table. The message segment table is always maintained in the main memory. Figure 8 shows the space cost of message segment tables, which is the sum of the entries of each level X  X  MST, where f min = 0 . 00001 space cost in MSTs. The reason is that, the diversity of FileZilla log is very low, so MST covers almost all message segments. On the other hand, the diversity of PVFS2 log is high, which covers various kinds of status messages, error, internal operations. Thus, only a few message segments X  frequencies are greater than f MST.

Every entry of MST is a float number, which occupies 4 bytes. The largest actual memory cost of those MSTs in Figure 8 is 3 . 2  X  10 7  X  4 = 128M bytes. Comparing to the similarity matrix of log messages built by the clusterin g algorithm, 20000  X  20000 / 2  X  4 = 1.6G bytes, the MST X  X  cost can be ignored.
 G. A Case Study
We have developed a log analysis toolkit using Logtree for events generation from the system log data. Figure 9 shows a case study of using our developed toolkit for detecting configuration errors in Apache Web Server. The configuration error is usually cased by human, which is quite different from random TCP transmission failures, or disk read errors. As a result, configuration errors typicall y lead to certain patterns. However, the Apache error log file has over 200K log messages. It is difficult to discover those patterns directly from the raw log messages. Figure 9 shows the event timeline window of our toolkit, where the user can easily identify the configuration error in the time frame. Th is error is related to the permission setting of the HTML file. It causes continuous permission denied errors in a short time. In addition, by using the hierarchical clustering method, LogTree provides multi-level views of the events. The user could use the slider to choose a deeper view of events to check detail information about this error.
 Figure 9: A case study of the Apache HTTP server log.
The related work about the log data analysis can be broadly summarized into two categories. One category is on system event generation from raw log data [10][18][13] and the other category is on analyzing patterns from system events [1][2][3][5][8]. Our work belongs to the first catego ry. A word matching similarity measurement is introduced in [10] for clustering the log messages. One problem is that, some types of log messages may not have much common words. [13] develops a 4-step partitioning method for clus-tering the log messages based on some characteristics of the log format. However, the method is not able to handle the situation that one event type with multiple message formats . [18] studies an automatically learning approach to capture the format the log. It can be treated as an assistant tool for many related works in this category.

In this paper, we show that traditional methods which only make use of the word level information, are not able to achieve an acceptable accuracy for generating system event s from the log data. To address the limitation of existing meth -ods, we propose LogTree , a novel and algorithm-independent framework for event generation from system log messages. LogTree utilizes the format and structural information in the log message and employs Message Segment Table for effective and efficient system event generation.

As for the future work, we will integrate the automatic log structure learning approach into our framework. Specially , semi-supervised learning techniques can be applied in our framework to capture the structural information of log mes-sages. We hope to identify those structures of log messages from a few labeled samples provided by the users.

The work is supported in part by NSF grants IIS-0546280 and HRD-0833093.

