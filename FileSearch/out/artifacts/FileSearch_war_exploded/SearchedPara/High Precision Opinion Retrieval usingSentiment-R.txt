 Opinion retrieval involves the measuring of opinion score o f a document about the given topic. We propose a new method, namely sentiment-relevance flow, that naturally unifies the topic relevance and the opinionated nature of a document. Experiments conducted over a large-scaled Web corpus show that the proposed approach improves performance of opinion retrieval in terms of precision at top ranks.
 H.3.3 [ Information Search and Retrieval ]: Retrieval Models Algorithms, Measurement, Experimentation opinion retrieval, sentiment analysis, sentiment-releva nce flow
Opinion retrieval is a new retrieval task which involves locating documents that express opinions about a topic of interest. With the rapid growth of user-centric media such a s blogs and forums, opinion retrieval has been gaining consid -erable attention in recent years from academia and industry motivated by the huge business opportunities.

A key to success in opinion retrieval is to leverage both the topical relevance and the opinionated nature of docu-ments simultaneously in ranking. However, most opinion re-trieval systems separate the two components independently by adopting a re-ranking approach [1]. This approach in-volves finding as many relevant documents with regard to a given topic as possible regardless of their opinionated na -ture at first and then re-ranking them by combining the topical relevance scores with the opinion scores computed using some opinion detection techniques. Although a few approaches have shown attempts to unify the two compo-nents, for example, by using the proximity between topic words and opinion words within a document [3], the results are not yet conclusive and require more investigation.
In this paper, we present a new opinion retrieval method that adopts a very recently proposed technique involving relevance flow graphs [2]. A relevance flow graph of a doc-ument is a graphical plot of the topic relevance degree of individual sentences (with regard to a query) versus their positions in the document. The line graph labeled  X  X ele-vance X  in Figure 1 illustrates an example; it visually shows the fluctuation of topic relevance levels within a document i n regard to the query. [2] demonstrates that topically releva nt documents have distinguishable flows from non-relevant one s in terms of the variance of relevance levels or the positions of high relevance levels (namely peaks), by designing a re-gression model based on such information and applying it to re-rank the retrieved results of conventional document ran k-ing. Such method has shown promising results in improving the accuracy at top ranks.

Motivated by this achievement, we hypothesize that a truly relevant document in opinion retrieval not only has opinion sentences regarding the topic but does have them in predictable patterns within the document. Our idea is to create a new flow graph, namely sentiment flow, that plots the opinionated nature of individual sentences using some opinion scoring method, and then merge it with the topic relevance flow to generate a whole new flow graph, called sentiment-relevance flow . The dotted line graph la-beled  X  X ent-Rel X  in Figure 1 illustrates an example. The following section will elaborate on such technique.
The sentiment-relevance flow of a document (SRF) is a sequence of scores that reflect both the topic relevance with regard to the query and the opinionated nature of individual sentences, ordered by the sentence positions. Given a query Q , we calculate the score of a sentence s i at position i as follows: where topic ( Q, s i ) refers to the topic relevance score of s for Q calculated using some conventional relevance scoring function, such as the BM25 function. opinion ( s i ) represents the opinion score of s i computed as follows: where W is the half size of the context window (empiri-cally set to 15), O is a set of opinion word lexicon, and freq ( s j , ow k ) is a function that returns the frequency of opinion word ow k in sentence s j . When computing this score, we look at not only the sentence at hand but also its context, because we have observed that opinions often appear not in the same sentence where topic words occur but in preceding or succeeding sentences.

We normalize the individual sentence scores and the sen-tence positions in range 0 to 1 as in [2]. The graphical plot of such SRF, as shown in Figure 1, indicates the fluctuation of both topic relevance and opinionated nature within the document in a comprehensive way. As in [2], we refer to sentences that have scores higher than 0.5 as peaks .
In order to infer document relevance from SRFs, we use maximum entropy modeling to train a regression model that is able to predict the relevance of a document based on its SRF. The main features extracted from the SRFs for re-gression are the ones found useful in [2], which include the following: the variance of sentence scores, the fraction of peaks, and the first peak position.

For opinion retrieval, we rank documents by linearly com-bining the topic relevance scores with the new relevance scores inferred from their SRFs as follows: score ( Q, D ) =  X   X  topic ( Q, D ) + (1  X   X  )  X  srf ( Q, D ) (3) where topic ( Q, D ) is the topic relevance of document D with regard to Q , and srf ( Q, D ) is the prediction score of the classifier for D .  X  is a weight parameter where 0  X   X   X  1. We conduct our experiments over Blogs06, a large-scaled Web blog collection. We use the title queries of 150 topics used in 2006, 2007, and 2008 TREC Blog Tracks. We val-idate our method in a re-ranking scheme. In other words, we initially retrieve the top n (=15) documents using two popular ranking models, the BM25 model and the query and then re-rank the results using Equation 3. When eval-uating one query set (50 topics), other two query sets (100 topics) are used to train a regression model. 15 top ranked documents for every training query are divided into positiv e and negative training instance groups based on their rele-vance judgments. The main evaluation measures are P@1, P@3, and P@5 since our method aims to achieve high accu-racy at top ranks via re-ranking. The relevance judgement set consists of two distict aspects, relevance and opiniona ted 1 We empirically tuned k 1 =1.2, b =0.1 for BM25 and  X  =5000 for QL smoothing parameter.
 relevance. Thus, we report the topic P@Ns and the opinion P@Ns of the system separately. For sentence boundary de-a public opinion dictionary in the linguistics field. We only collect adjectives, adverbs, and verbs from the opinion and emotion categories; as a result, the lexicon is made up of 1,496 entries.

Table 1 shows the performance of topical retrieval for the two initial results, relevance flow based re-ranking (RF ) and our sentiment-relevance flow based re-ranking (SRF). As mentioned from previous study, RF successfully re-ranks high position documents. It is notable that our SRF also im-proves the performance of traditional topical retrieval si nce it basically aims to capture the pattern of relevant sentenc es.
In aspect of opinion retrieval, as shown in Table 2, SRF shows significant and consistant improvement. We com-pare our method with two previous re-ranking approaches for opinion retrieval with QL setting (since it outperforms BM25). Opinion score measured by QL+FULL is domi-nated by a number of opinion words that appeared in a whole document, while QL+PROX only considers opinion words located within W sentences from the query terms. We can observe that proximity is a helpful feature for opin-ion retrieval. It is remarkable that our sentiment-relevan ce flow based re-ranking scheme achieves better improvement. Note that the maximum performance are acheived on low  X  values which implies that the trained regression model base d on SRF features are very accurate and reliable. [1] I. Ounis, C. Macdonald, and I. Soboroff. Overview of [2] J. Seo and J. Jeon. High precision retrieval using [3] M. Zhang and X. Ye. A generation model to unify topic
