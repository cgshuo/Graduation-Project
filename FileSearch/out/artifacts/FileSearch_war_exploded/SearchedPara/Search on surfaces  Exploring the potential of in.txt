 1. Introduction
In the movie The Day the Earth Stood Still (20th Century Fox, 2008), a group of scientists gather around a tabletop com-puter, pointing and arguing with each other  X  the tabletop supports their discussion, providing additional data and detail as they work. This scenario is, of course, science fiction: few computer systems today support smooth transitions between col-laborative work and data exploration.

Many types of information work are well-suited to collaboration: a team can provide a variety of perspectives, bring a spectrum of expertise, and parallelize tasks. Hence, group work is an important component of many types of information
Beheshti, &amp; Rahman, 2002; Talja, 2002; Twidale, Nichols, &amp; Paice, 1997 ). When using printed media, workgroups often col-laborate on information retrieval tasks ( Fidel et al., 2000 ), and traditional horizontal surfaces (desks and tables) are often the location where such media are examined, discussed, and made sense of. Yet when groups move to digital media, that com-fortable collaboration is lost: users are forced to gather around a single PC (perhaps projected on a meeting-room wall for communal viewing), or to work separately at their own computers.
 Recently, researchers have begun creating digital systems that support collaborative information retrieval ( Amershi &amp;
Morris, 2008; Morris &amp; Horvitz, 2007; Pickens, Golovchinsky, Shah, Qvarfordt, &amp; Back, 2008 ). Researchers have also made much progress in designing digital desks and tabletops ( Dietz &amp; Leigh, 2001; Haller et al., 2006; Han, 2005; Hartmann, Morris, Benko, &amp; Wilson, 2009; Johanson, Fox, &amp; Winograd, 2002 ) to support 21st-century work and educational practices.
The affordances of digital tabletops offer great promise for facilitating collaborative search experiences; indeed, we have be-gun to explore some of these synergies in our own work ( Hartmann et al., 2009; Isenberg &amp; Fisher, 2009; Morris, Paepcke, &amp; Winograd, 2006; Morris, Lombardo, &amp; Wigdor, 2010 ), which we discuss in more detail below.

In this article, we explore the potential of interactive tables for supporting collaborative search activities. We first discuss the unique affordances of tables, and consider both the benefits that these offer to collaborative search tasks, as well as the challenges they present; we then discuss the design space of table + search applications. We describe four systems from our own research, TeamSearch, FourBySix Search, Cambiera, and WeSearch, and reflect on how they fit into this design space. We close by discussing promising directions for future work at the intersection of these two fields. 1.1. Related work: systems for co-located collaborative search
A few researchers have begun to explore collaborative search on a tabletop form-factor. F X schl X r-DT ( Smeaton, Lee, Foley, &amp; McGivney, 2006 ) is a tabletop video search system that enables pairs of users to work together when searching through a video archive on a DiamondTouch table ( Fig. 1 ). The system was inspired by (and uses data from) the TRECVid video retrieval challenge. On F X schl X r-DT, video search is conducted by typing keywords on soft keyboards. Matching keyframes can then be examined using direct-touch interactions, played on an auxiliary monitor, or saved by being dragged to a special region of the table. Keyframes themselves can also be used to initiate a search, through a  X  X  X ind similar X  action. The designers of
F X schl X r-DT were particularly interested in the tradeoffs in designing a tabletop search system for maximum awareness among partners versus designing for maximum efficiency (i.e., supporting highly parallel work styles), and found that high-er-awareness versions of their application were more preferred by end-users.

The Personal Digital Historian (PDH) Shen, Lesh, Vernier, Forlines, and Frost, (2002) is a tabletop application designed for collaborative browsing of photo collections, in support of storytelling activities ( Fig. 2 ). While designed more for browsing than for search, the PDH provides four views that query the tagged photo collection  X   X  X  X ho X  (filtering the collection based on who is in a photo),  X  X  X hat X  (filtering based on what event is depicted),  X  X  X here X  (filtering based on the photo X  X  originating location), and  X  X  X hen X  (filtering based on timestamp). The PDH tabletop hardware supported only a single input at a time, so collaborative discussion was supported, but not collaborative input to the system itself.

Other than F X schl X r-DT, PDH, and our own work on the TeamSearch, FourBySix Search, Cambiera, and WeSearch systems (which we discuss in Section 3 ), we are not aware of any other research efforts that explore the potential of interactive table-tops for collaborative information seeking tasks. However, a closely-related body of work is the exploration of interfaces for co-located collaborative search using other, non-tabletop, technologies, such as multiple co-located PCs, PDAs, and/or mobile phones. The tasks that motivate many of these co-located search systems (education, information work, reviewing photos and video, etc.) could potentially be rich areas for support by tabletop systems, as well. The face-to-face working style en-abled by a tabletop display has the potential to support many of the co-located collaborative search tasks addressed by these systems, while providing higher awareness levels than when each user is focused on her own personal device.

Like F X schl X r-DT and PDH, the Cerchiamo system ( Pickens et al., 2008 ) is also focused on multi-media search, supporting search over a video archive. Cerchiamo is designed to support two co-located searchers, sitting side-by-side with their own
PCs, augmented by a large, shared wall display. Each partner X  X  personal PC displays information relevant to his distinct role in the search process (either the  X  X  X rospector X , who enters query terms, or the  X  X  X iner X , who triages results), while the shared display shows data relevant to both parties, i.e., the overall progress of the search task.

In addition to co-located multi-media search support, some researchers have been exploring tools for co-located collab-orative search of Web pages. Such systems tend to have a separate device (such as a phone or PDA) for each group member, sometimes augmented by a shared PC or wall-mounted display. CoSearch ( Amershi &amp; Morris, 2008 ) combines mobile phones (one per group member) with a shared display to support collaborative search. The phones X  keypads can be used to enter queries and the phones X  joysticks can be used to select links to follow; queuing mechanisms in the browser on the shared display help coordinate the input from each group member X  X  phone. WebGlance ( Paek et al., 2004 ) focuses on collaborative
Web browsing, rather than search per se , enabling users to control a browser on a large, shared display by issuing commands from their individual PDAs. Maekawa, Hara, and Nishio X  X  (2006) system divides a Web page into several non-overlapping segments, and shows each segment on a different group member X  X  phone, in order to enable the group to divide and conquer the task of visual search within a page. The Query By Argument system ( Blackwell, Stringer, Toye, &amp; Rode, 2004 ) is a rhetor-ical argument construction system that provides groups of students with RFID-tagged tangible objects representing key con-cepts from items in a document collection; manipulating these tangibles, such as by grouping them together in specific ways, results in re-calculating the relevance rankings of items in the document set, thus making the students aware of additional information that may be related to their current argument. 2. Designing collaborative search applications for tabletops: benefits and challenges
The affordances of horizontal computing surfaces are in many respects harmonious with the needs of collaborative search systems; however, there are still several challenges in adapting this emerging computing form-factor to information retrie-val tasks. In this section, we discuss both the benefits and challenges of using tabletops as a platform for collaborative search. 2.1. Benefits of tabletops for collaborative search
The face-to-face working style supported by interactive tabletops tends to encourage more equitable work styles than the shoulder-to-shoulder work style supported by other types of single display groupware, such as interactive walls ( Rogers &amp;
Lindley, 2004 ). Interactive tabletops support co-located collaboration, but can also support remote or mixed-presence col-laboration in situations where multiple tabletops are distributed at different locations; virtual arrangements of seating pat-terns ( Tuddenham &amp; Robinson, 2009 ) and virtual embodiments such as video arms ( Izadi et al., 2007 ) can help preserve the engagement of a face-to-face around-the-table experience even for distributed groups.

Awareness of collaborators X  searching activities has been found to be an important aspect of collaborative search systems ( Morris &amp; Horvitz, 2007; Paul &amp; Morris, 2009; Smeaton et al., 2006 ). Although awareness features can be designed into such systems, collaborators sharing a single display report higher awareness and better group work experiences than those with separate displays, even when all the displays are side-by-side ( Amershi &amp; Morris, 2008 ). The large, shared display provided by an interactive tabletop, then, can offer benefit for collaborative search tasks, by providing shared focus and awareness among group members.

Large, horizontal surfaces afford spreading, piling, and organizing content. Such affordances are well-suited to sensemak-since search in itself is never a group X  X  end-goal; rather, groups engage in collaborative search tasks in order to achieve some larger goal, such as to prepare a report or presentation, plan an itinerary, or make a purchasing decision ( Morris, 2008 ). Hence, the organizational affordances of tabletops offer great potential for rich collaborative sensemaking applications.
And last, but not least, horizontal displays can support placement of tangible props, and can respond and react to them using technologies such as recognition of RFID or optical tags ( Hartmann et al., 2009; Wilson &amp; Sarin, 2007 ). Future technol-ogies may eventually have high-fidelity vision systems that enable OCR of un-tagged documents. Such capabilities can en-able groups to incorporate traditional media into their search process. For example, a page from a book, a photograph, or a physical object could be used as input to initiate a search task. 2.2. Challenges of tabletops for collaborative search
While we believe that the aforementioned affordances of tables make them well-suited to collaborative search tasks, it is important to acknowledge that there are some challenges to designing successful tabletop search systems. Interactive table-tops are still an emerging technology, and some aspects of their design are still being explored by the tabletop research community.
 One of the most engaging aspects of interactive tabletops are their ability to provide direct-touch manipulations ( Benko, Morris, Brush, &amp; Wilson, 2009 ). However, direct-touch interaction is inherently less precise than interactions on traditional
PCs; pointing with fingers is less exact than mouse-based pointing (stylus-based tabletops address this concern to some ex-tent ( Haller et al., 2006 )), and typing on soft keyboards is much slower than on physical ones ( Hartmann et al., 2009 ). The tedium of text entry on tabletops using soft keyboards ( Benko et al., 2009; Hinrichs, Hancock, Collins, &amp; Carpendale, 2007 ) can be particularly challenging for search applications, where text entry is often a key part of the activity.
Although current tabletop technologies tend to be physically larger than PC displays (the Microsoft Surface, for example, much greater than the resolution of a standard monitor (and sometimes even less), since XGA (1024 768 pixels) is still the most common and affordable projector resolution, and most tabletop technologies are projection-based. This results in spa-tially large, but low-resolution displays. Even as tabletop hardware progresses to include larger, higher-resolution surfaces, space limitations will continue to be a challenge. The clutter caused by displaying content for an entire group of people on one display is one of the fundamental challenges of single display groupware systems ( Stewart, Bederson, &amp; Druin, 1999 ), and exploratory search tasks test the limits of this issue since they often involve a large amount of content ( Paul &amp; Morris, 2009 ).

Orientation is a perennial challenge for tabletop displays ( Shen, Vernier, Forlines, &amp; Ringel, 2004 ), since content that is right-side-up for one user is upside-down for anyone seated across the table. Some automated solutions are possible, includ-ing lazy-susan-style UIs ( Shen et al., 2004 ), replication of content for all users ( Morris, Paepcke, Winograd, &amp; Stamberger, 2006 ),  X  X  X agnetization X  of the UI in one direction at a time ( Shen et al., 2004 ), and affordances for manually re-orienting con-tent ( Shen et al., 2004 ). Orientation issues become particularly critical during collaborative search tasks, as search often in-volves dealing with large amounts of textual data, and dense text is particularly orientation-sensitive ( Wigdor &amp;
Balakrishnan, 2005 ); some domains, such as image or video search, are somewhat more resistant to this issue, although even in these cases considering orientation is still an important aspect of tabletop search application design, due to the important communicative properties conveyed by orientation in group settings ( Kruger, Carpendale, Scott, &amp; Greenberg, 2003 ).
As we have described, current tabletop technologies X  limitations regarding text entry, clutter, and orientation can make it however, with continued advances in hardware and software from the tabletop community, as well as careful application design by the search community, these challenges can be overcome. In the next section, we describe four applications that illustrate several approaches to addressing these issues. 3. Exploring the design space
Tabletop search applications can span a large design space that encompasses many group work styles and many types of search tasks. Here, we articulate what we see as the key dimensions of this design space based on our own projects and on others X  related work. By articulating this space, we hope to better understand how existing work in this area (such as our own systems, discussed below) complement each other, and what areas remain unexplored; such unexplored areas of the space suggest interesting directions for future research, as we discuss in Section 4 .
As with all collaborative search systems, it is important both to consider the mechanics of the collaboration itself, as well as the specifics of the type of search activity being supported. Thus, we subdivide our design space into the  X  X  X roup config-uration X  and  X  X  X earch task X  sub-sections. Table 1 illustrates the salient dimensions of the design space.

The first aspect of group configuration that we consider is the collaborative style the system is meant to support  X  very tightly-coupled collaborations, loosely-coupled parallel work, or styles that support transitions among both (an articulation of these different styles can be found in Tang, Tory, Po, Neumann, and Carpendale (2006) ). Group size is also a relevant fac-tor; we must consider whether a system is meant to support searches among pairs of users, small groups (3 X 6 users), or large groups (i.e., all of a meeting X  X  attendees, or an entire classroom full of students). The physical arrangement of these collab-orators is also an important design choice: they can be distributed in space, each at their own tabletop; co-located around a single surface; or in a mixed arrangement, with some team members co-located and others remote. Finally, understanding the larger ecology of the group X  X  collaboration is vital  X  are they conducting their entire search task on the tabletop, or do they need to import data they gathered individually before the collaborative phase began? Do they need to export the data for consumption by themselves or others after the tabletop session has ended? Do they have auxiliary inputs (paper docu-ments, laptops, phones, etc.) or outputs (such as vertical displays for detailed reading) that they will use in conjunction with the surface?
Several aspects of the search task also bear consideration. First, the type of search task must be considered. A search appli-cation can support Web search, multi-media search, search over group members X  own document collections, or search over a specialized database, such as medical databases or other types of digital libraries. These differences are important both in considering the size of expected result sets and the method of presenting individual results. How the search will be con-ducted is also a key consideration  X  will users specify inputs via keywords, via a visual query language, via touch and gesture interactions, or via tangible props (such as pages from a book, physical icons, or other artifacts), or will the inputs be sug-gested to the user via automatic,  X  X  X ntelligent X  means, such as based on the user X  X  or group X  X  recent actions? It is also impor-tant to consider what aspects of the search task the system will address: the application may support the process of search, understanding the products of search (i.e., sensemaking), or preparing a final  X  X  X eport X  containing the groups X  findings (or per-haps some combination of several of these phases).

Our own research has explored some of the ways in which interactive tabletops can support collaborative search tasks. In the next sections, we describe four prototype applications, TeamSearch, FourBySix Search, Cambiera, and WeSearch, and re-flect on how they address different aspects of this design space and how they resolve the challenges of adapting tabletops to search tasks. 3.1. TeamSearch
Our first prototype, TeamSearch ( Morris, Paepcke, &amp; Winograd, 2006 ), is designed to help small groups of co-located users search through tagged image repositories; for example, helping a family select photos from their collection in order to assemble a themed website or album, or helping students or co-workers assemble images to support preparation of a group presentation or report. Table 2 shows where the TeamSearch system falls in our design space.

TeamSearch uses a 42 00 diagonal DiamondTouch ( Dietz &amp; Leigh, 2001 ) table, which is a top-projected, capacitive-touch technology that is able to differentiate the identities of up to four users based on their seat via capacitive coupling connecting a special seating pad, the user, and the device ( Fig. 3 ). In this case, the projected display has SXGA (1280 1024) resolution.
The application is designed for searching over a tagged photo collection; the photo tagging itself is not part of TeamSearch, but can occur using other single-user (e.g., flickr.com) or collaborative (e.g., Morris et al., 2006 ) tagging systems. The appli-cation can be configured to use a photo + tag repository of the group X  X  choosing. Upon initialization, TeamSearch parses the tag structure and creates a circular widget representing each category of tags (i.e., people, location, etc.); each circle is sub-divided into sectors representing the range of values for that tag category (i.e., for the category  X  X  X eople X , values might in-clude  X  X  X om X ,  X  X  X ad X ,  X  X  X ary X ,  X  X  X ue X ,  X  X  X ob X , etc.).

In addition to the circular tag widgets, other key components of the UI include the photos themselves, which can be moved, rotated, and resized via gestures in a fashion consistent with other multi-touch applications. The UI also includes a rectangular tray area located near each user X  X  seat, which displays thumbnails of images matching the current search.
Pressing a thumbnail from the results tray brings the corresponding photo to the top of the pile of images (if it was buried beneath others) and causes it to blink, in order to help locate photos. And, finally, the TeamSearch UI includes query tokens , small circular widgets labeled with a  X  X ? X  that can be instantiated via a context menu.

TeamSearch supports two styles of query tokens. Collective query tokens , rendered in black, and parallel query tokens , ren-dered in four distinct colors, one color for each group member. Groups can query the image repository by placing query to-kens on top of the sectors of the circular tag widgets. All collective tokens are interpreted as a single query regardless of which user placed them (all covered sectors from one tag category are considered disjunctively, while each tag category that has any sectors covered is considered conjunctively) ( Fig. 4 ). Thumbnails of the images matching the collective query are replicated in the results tray of all group members. Parallel tokens, on the other hand, are interpreted per-user; the results of a user X  X  parallel query are shown in her own results tray, but not in other group members X  ( Fig. 5 ).

TeamSearch represents one approach to addressing the challenges of creating collaborative search applications for the tabletop form-factor. The text input challenge is mitigated by the media search domain  X  by utilizing tagging metadata, which is becoming increasingly common (human-computation games like ESP ( von Ahn &amp; Dabbish, 2004 ) aim to eventually provide tags for all images on the Web, for example), we create a faceted search experience that enables the use of visual tokens to specify which of the facets are of interest, thus avoiding the need to enter text. The result trays are designed to address the challenge of clutter (touching a search result thumbnail causes the corresponding original photo to become more salient even if it is lost in the clutter of photos and tag widgets on the tabletop). The trays also address the challenge of ori-entation, since in the collective mode results are replicated in each group member X  X  result tray for easy multi-angle viewing. 3.2. FourBySix Search
Our next prototype, FourBySix Search, supports group Web search; for example, FourBySix Search might be used by a group of students gathering material for a joint homework assignment. Table 2 illustrates the portions of the design space addressed by FourBySix Search.

The FourBySix Search application runs on a custom-built surface, named FourBySix ( Hartmann et al., 2009 ), that is 4 feet wide 6 feet long ( Fig. 6 ). The system is top-projected by two tiled XGA projectors (for a total resolution of 1024 1536), and illuminated from beneath with infrared light; two cameras beneath the table sense IR light reflected from users X  fingers, enabling multi-touch interactions. Objects that have been augmented with IR-reflecting tags can also be recognized by the system. FourBySix can recognize the location, orientation, and identity of each of several tagged keyboards placed on its sur-face. Simultaneous text entry from multiple keyboards is enabled through use of the Microsoft Raw Input SDK ( Hartmann et al., 2009 ).

FourBySix Search supports transitioning between loosely-coupled and closely-coupled collaborative search styles by using the relative position and orientation of keyboards as proxies for the relative positions of the collaborators themselves.
When collaborators X  keyboards are above a threshold distance from each other, their inputs are interpreted separately; when a user types keywords, they are projected in a textbox displayed immediately above his keyboard; this box tracks the key-board if it is moved to another part of the surface ( Fig. 7 A). When the user hits  X  X  X nter X , executing the search, results are dis-played as thumbnails in a grid that is again co-located above the keyboard itself, in order to make it clear which set of search results was fetched by which user ( Fig. 7 B).

When keyboards are placed within threshold distance of each other, the application transitions to a more tightly-coupled work style, in which the keywords entered by each of the adjacent keyboards are jointly interpreted as part of a single query.
The nature of this interpretation is parameterized by the relative orientation of the keyboards. If keyboards are joined in an open, side-by-side configuration ( Fig. 8 A), the keywords are combined disjunctively, so as to  X  X  X pen X  (broaden) the search. On the other hand, if the keyboards are joined in a closed, face-to-face orientation ( Fig. 8 B), the keywords are combined conjunc-tively, so as to  X  X  X lose X  (restrict) the search.

FourBySix Search deals with the challenge of text entry on tabletops by augmenting the tables with physical input de-vices, in order to enable fast and reliable text entry in the text-intensive domain of Web search. The system addresses the challenge of clutter by introducing a custom-built, large form-factor surface. The challenge of orientation is addressed by having search boxes and search results track the keyboard that spawned them, in order to orient content correctly for the issuing user; results can also be dragged away from a keyboard in order to be manually re-oriented for another group member using multi-touch gestures, if desired. 3.3. Cambiera
Our third prototype, Cambiera ( Isenberg &amp; Fisher, 2009 ), is designed as a small-group collaborative search tool for textual databases ( Fig. 9 ). It was motivated by the visual analytics tasks performed by intelligence analysts. Such tasks involve sort-ing through many textual documents to uncover a hidden narrative; the data set from the IEEE VAST competition provides a way for researchers to simulate such tasks. To complete this task, users must read many documents, searching and re-tom-projected (1024 768) multi-touch surface. Table 2 shows how Cambiera fits into our design space.

Since visual analytics tasks require high awareness among group members, Cambiera is built around the concept of col-laborative brushing and linking (CBL). Collaborative brushing and linking is named after the standard information visualiza-tion technique of brushing and linking ( Buja, McDonald, Michalak, &amp; Stuetzle, 1991 ), in which the same data point is linked across different visual objects, and so all instances of it are highlighted when any one of them is brushed. A similar technique highlighting related documents can be found in Sun, Chiu, Huang, Back, and Polak (2006) . In Cambiera, CBL means that the actions of one user are visible to other users at the places where data overlaps. For example, if the result sets for two users X  queries contain some documents in common, CBL calls for a visible cue showing this overlap ( Figs. 10 and 12 ). Similarly, if one user has read a document that is in another X  X  results, the other user should be able to see that the document has already been read.

In Cambiera, users begin by invoking a soft keyboard, which produces a search results box .In( Fig. 10 ), a user has created two search results boxes, one searching for the term  X  X  X SE X , the other for the term  X  X  X DA X . The latter has been expanded to show the five hits on the term  X  X  X DA. X  Each of those five documents is represented by a small gray rectangle, and highlighted with a dark orange stripe, emphasizing that FDA X  X ith its matching color X  X an be found in each document. In addition, three of the documents are further highlighted by a paler orange stripe, corresponding to the color of the search results box for  X  X  X SE X . That pale orange tells the user that these documents can be found by both the queries  X  X  X SE X  and  X  X  X DA X . The saturation of the gray shading on each search result indicates how often that particular document has been read by members of the group. The user can drag out any of these rectangles from the search results box in order to create a representation of the document on-screen. Initially, such representations show the document in a small,  X  X  X losed X  state, in which only the title is visible, and a gesture can be used to expand such documents to the  X  X  X pen X  state, in which the full text can be read ( Fig. 11 ).
The critical aspect of these search boxes is that they can simultaneously display which keywords have found a given doc-ument, which user typed each of these words, and whether the document has been read. This allows the users to smoothly transition between a loosely-coupled style and a tighter one: noticing that the other user is reading a document can encour-age a discussion of the document.

Cambiera alleviates the challenge of text input on tabletops by aiding users in minimizing the amount of soft-keyboard-based text input they need to do: once a user has successfully done one or more keyboard-based searches, many others can then be launched by re-using terms (via touch selections) from within the retrieved documents, allowing the user to type fairly infrequently. Additionally, persisting prior query terms through the search result box representations allows users to re-access old searches, again saving on typing. Cambiera addresses the clutter challenge by enabling data to exist at multi-ple scales. Search result boxes, for instance, can be minimized to show only the search term and number of results, or can be expanded to show the minimized result representations containing read-shading and CBL striping, and documents selected from search result lists can be represented in either the  X  X  X losed X  or  X  X  X pen X  states. Lastly, while objects can be freely rotated, they have natural orientations; users are encouraged to sit opposite each other, and documents face that well-known position. However, a special gesture can be used to transfer document ownership to one X  X  partner, which results in automatic re-orientation of that document. 3.4. WeSearch
Our final exemplar system, WeSearch ( Morris et al., 2010 ), is designed to support groups of up to four users conducting collaborative Web search tasks, including the accompanying sensemaking process. For example, WeSearch might be used by a family to trying to decide what type of laptop computer to purchase for their home, or by a group of colleagues selecting a location for their company X  X  next offsite meeting. WeSearch is designed for the custom-built, large-form-factor tabletop used by FourBySix Search (but with no augmentation by physical keyboards) ( Fig. 13 ). Table 2 shows how WeSearch fits into our design space.

Each group member has a color-coded toolbar containing a search box. Touching the search box opens a virtual keyboard that can be used to enter queries. Search engine results for that query are then displayed in a custom-designed Web browser, oriented to face in the direction of that user X  X  toolbar. In order to minimize clutter and facilitate sensemaking, the WeSearch browser offers the ability to divide a Web page into a set of clips by parsing the page X  X  HTML ( Fig. 14 ). Each clip is a small chunk of content (e.g., a single paragraph or a single image), that can then be removed from the browser; the originating Web page can then be closed to preserve space on the tabletop, leaving only the chosen clips behind.

In addition to a search box, each group member X  X  toolbar also contains a marquee ( Fig. 15 ). The marquee is designed to facilitate awareness, by showing color-coded content from other group members (such as query terms they have used and the titles of Web pages they have opened); this content slowly scrolls past in the marquee (the marquee can also be scrolled manually, in order to review or re-find content). To reduce tedious virtual-keyboard text entry, terms appearing in the mar-quee can be re-used by dragging them out of the marquee region and dropping them on the search box.

A button on the toolbars allows users to create containers , such as lists, grids, or free-form canvases. These containers can be used to collect and organize related clips, in order to support sensemaking ( Fig. 16 ). The ability to add labels to clips further supports the sensemaking process. WeSearch analyzes the set of clips stored in each container, and uses the space along each container X  X  bottom border to suggest query terms that are thematically related to the clips using several heuris-tics, such as common terms shared by the set. This  X  X  X earch by example X  feature ( Fig. 16 ) can further reduce the need for soft-keyboard text entry. Users can also continue their sensemaking process away from the tabletop by using WeSearch X  X  export feature, which creates an XML file (and accompanying XSLT file) that records information about the currently open clips (such as the clip contents, originating Web page, and the group member who created the clip), and information about their arrangement in containers; this file can then be viewed in any Web browser, such as on a user X  X  own PC or mobile phone.
WeSearch approaches the challenge of text entry on tabletops from two angles: by facilitating re-use of other group mem-bers X  query terms and terms from Web pages via the marquee, and by suggesting potentially useful query terms via the search-by-example feature. In addition to employing a large-form-factor tabletop, WeSearch attempts to reduce clutter by enabling users to extract clips from a Web page; in addition to conserving space, selecting pertinent clips can also facil-itate the sensemaking process, by indicating what information is most relevant to the group. Finally, WeSearch addresses the orientation challenge by providing each group member with a personal toolbar containing the marquee, which provides awareness of the content being read by other group members at an appropriate viewing angle for each user. 4. Discussion
TeamSearch,FourBySixSearch,Cambiera,andWeSearchpaintfourpicturesofhowinteractivetabletopscansupportcollab-orative search tasks; each supports different task domains and each offers different ways of addressing the challenges of text entry, clutter, and orientation. Table 2 illustrates how our own and others X  systems cover partially overlapping portions of the table + search design space  X  while each system covers some distinct aspects of the space (such as the target application domain,andthecollaborationstylesupported),thereisalsoagreatdealofoverlap,whichmeansthatsomeaspectsofthedesign space are left unexplored. These unexplored aspects of the design space highlight important areas for future work.
For example, these systems focus mainly on supporting the information retrieval process, but sensemaking and report preparation are also key parts of many search tasks. Designing systems that take advantage of tabletops X  spatial layout and high awareness properties for sensemaking (or for integrating information retrieval, sensemaking, and reporting activ-ities together), is a high-value area for further exploration.

These systems are also focused on a table-only device ecology (while FourBySix Search incorporates keyboards, we con-sider this a table-only system since the keyboards neither contain nor symbolize data). Tabletop researchers have explored and  X  X  X mart X  rooms ( Johanson et al., 2002 ); however, the utility of this larger ecology of input and output devices for facil-itating collaborative search on tables remains unexplored. Such additional devices could enrich the search experience, such as by facilitating text entry using a phone X  X  keypad, allowing high-resolution reading on a secondary monitor, or enabling personalized search results via combining techniques such as groupization ( Morris, Teevan, &amp; Bush, 2008 ) with the data repositories on personal devices. Auxiliary devices can also be used for pre-seeding a tabletop search session with the out-puts of earlier, private search sessions, or for capturing the state or results of a shared tabletop search for portability to other locations and work contexts.

Exploring the potential of tabletops to support different group configurations is also an exciting area for further work, such as supporting large groups (in classrooms, meetings, or public spaces). Tabletops, though often thought of as devices for co-located work, might also provide an interesting platform for mixed-presence or remote collaborations. 5. Conclusion
Interactive tabletops offer the potential to help migrate traditional collaborative practices, such as meeting face-to-face around tables and conducting joint research using traditional libraries and media, into the digital age, by serving as an engag-ing platform for collaborative search applications. In this article, we articulated the affordances that make tabletops a com-pelling platform for collaborative search, as well as the challenges they present in such circumstances. We described four prototype applications, TeamSearch, FourBySix Search, Cambiera, and WeSearch, that illustrate the potential of tabletops for collaborative search, and showed the different approaches each takes to addressing the challenges of supporting search on tables. By considering the larger design space of possibilities when combining collaborative search and interactive tables, we can see what areas have been explored by our own and others X  forays into this space, and what areas remain unexplored.
While our initial prototypes are promising, it is clear that the potential of this form-factor to support collaborative informa-tion seeking has only begun to be explored; we eagerly anticipate that many exciting advances will arise at the intersection of these two fields! Acknowledgements We would like to acknowledge Bjoern Hartmann, Hrvoje Benko, and Andrew Wilson for their work constructing the FourBySix table. We acknowledge Andreas Paepcke and Terry Winograd for their feedback on the TeamSearch prototype.
We thank Petra Isenberg, Kori Inkpen, and Mary Czerwinski for their contributions to the Cambiera system, and Jarrod Lom-bardo for his contributions to the development of WeSearch.
 References
