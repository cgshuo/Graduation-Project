 We present an incentive-based architecture for providing rec-ommendations in a social network. We maintain a distinct reputation system for each individual and we rely on users to identify appropriate correlations and rate the items using a system-provided recommendation language. The key idea is to design an incentive structure and a ranking system such that any inaccuracy in the recommendations implies the existence of a profitable arbitrage opportunity, hence making the system resistant to malicious spam and presen-tation bias. We also show that, under mild assumptions, our architecture provides users with incentive to minimize the Kullback-Leibler divergence between the ratings and the actual item qualities, quickly driving the system to an equi-librium state with accu rate recommendations.
 H.4.m [ Information Systems Applications ]: Miscella-neous Economics, Theory Incentives, Information aggregation, Recommender systems  X 
Research conducted while at Stanford University. Re-search supported by NSF ITR grant 0428868 and NSF award 0339262.  X 
Department of Management Science and Engineering and (by courtesy) Computer Science, Stanford University. Re-search supported by NSF ITR grant 0428868 and gifts from Google, Microsoft, and Cisco.  X  Department of Management Science and Engineering, Stanford University. Research supported by an A. G. Lev-entis Foundation Scholarship and the Stanford-KAUST al-liance for excellence in academics.

Recommender systems [1] are an important Internet mon-etization tool. They help in monetizing the heavy tail and play an important role in the success of Internet-based busi-nesses. The primary task of a recommender system is to suggest items of interest to its users. To this end, any corre-lation information regarding the similarities among various products and among the interests of individual users may prove very useful. Social networking services, whose success provides a fertile field for web-based commercial activity, offer a rich collection of such information. Coupling these tools and exploiting the information extracted from social networks, facilitates the generation of high-quality person-alized recommendations.

The approach of identifying similarities between users in the domain of social recommender systems has been applied in the form of collaborative filtering techniques. However, these systems make no guarantees about the quality of the recommendations. It has been experimentally observed [7] that in systems where individual decisions are influenced by the decisions of others, quality alone doesn X  X  determine the success of an item. We refer to this phenomenon as presentation bias. Spam is another deterrent in the effective functioning of these systems [4, 6]. Since the owner of an item has much to gain from its success, there is an incentive for agents to game the system.

Another approach, outlined by Bhattacharjee and Goel [2, 3], is to use incentive-based mechanisms for making ranking systems robust to presentation bias and spam. The work there assumed a simple setting of homogeneous population, and had no provisions for the mechanisms to work in the framework of personalized social recommendations. In this paper, we consider recommendations in this more complex landscape. We also show that under mild assumptions, the architecture we present provides users with incentive to min-imize the Kullback-Leibler divergence between the ratings and the item qualities, leading to a fast convergence to an equilibrium state with high-quality recommendations.
We break down a typical interaction of a user with her personalized reputation system into three steps. (1) In the first step, the system provides the user with a ranked list of recommended items (e.g. books). (2) Next, the user chooses to inspect the top j items. (3) Finally, among these items, the user utilizes a subset S (in the book example, purchases some of the books) and we say that a utility generation event has occurred for the items in S . We now present a model which captures this interaction. The set E = { 1 , 2 ,...,n models the n items and the set U = { 1 , 2 ,...,m } models the m users of the system. The users interact with their indi-vidual reputation systems and may also update the ratings of the items. The model specifics follow. 1. Quality. We define as q e,u , the probability that user 2. Slots. The k slots, 1 , 2 ,...,k are the placeholders for 3. Utility. If user u utilizes an item e , we say a utility
We now describe our feedback and incentive-based archi-tecture which is designed in a way that users benefit from correcting the rankings. 1. Social graph. The users are organized in a social 2. Feedback scores. Each of the m personalized rep-3. Tokens. In our model, a rater (user) is able to alter 4. Recommendation language. For any u  X  X  ,the 5. Revenue distribution. The fraction of the revenue
In this section, we present our main results. We define as visibility of item e for user u , the probability with which e is inspected by u , after being ranked in her recommendations and denote it  X  e,u . The expected rate at which revenue is generated for an item e ,byuser u ,isgivenby  X  e,u q e,u .Let, Note that f is proportional to the profit (or loss) that the rater can expect to make by making an instantaneous posi-tive (or negative) contribution to the feedback score of item e , in the reputation system of user u (since it is proportional to the derivative of the revenue sharing expression from Sec-tion 3). Our structure uses the ranking algorithm described by Bhattacharjee and Goel in [3], which has the following properties. 1. Higher feedback score implies higher visibility, that is, 3. Under mild assumptions (see [3]), the ranking algo-Now, using f , we will explain the notion of a profitable ar-bitrage opportunity .

Definition 1. For any user, the act of updating the scores of items e 1 ,e 2 ,...,e j , using the token vectors r 1 ,r (remember that each token vector is a linear combination of allowed recommendation vectors and can have both positive and negative entries), presents a profitable arbitrage oppor-tunity when, The inequality means that the user has instantaneous profit when making those recommendations and the equality guar-antees that the recommendation are compliant with the  X  bound on the sum of the user X  X  contributions (equal negative and positive contributions).
 We now define the notion of an inverted ranking in the rec-ommendations.

Definition 2. We say that the pair ( e, e ) is a case of an inverted ranking in the recommendations for some user u , At this point, we will define the notion of a complete recom-mendation language .

Definition 3. Let 1 u be the vector of size m with the u -th position equal to 1 and all other positions equal to 0 .We will say that a recommendation language is complete when it has the following properties. 1. For every u  X  X  , there exists a linear combination 2. For every user u , I =( 1 m , 1 m ,..., 1 m )  X  L u . That We now give the following theorem, which relates any inac-curacy in the recommendations with a profitable opportu-nity for the users.

Theorem 1. Assuming that the recommendation language is complete, the existence of an inverted ranking pair ( e, e ) in the recommendations for some user u ,impliestheexis-tence of a profitable arbitrage opportunity for some user.
Proof. Since ( e, e ) is an inverted ranking pair in the rec-ommendations for u ,wehave q e,u &lt;q e ,u and  X  e,u  X   X  Combining this with the properties of the ranking algo-rithm, mentioned earlier in this section, we get f ( e, u ) &lt; f ( e ,u ). This means the function f is not constant for all pairs ( e, u ). Let ( e h ,u h ) = arg max e,u f ( e, u )and( e arg min e,u f ( e, u ). We also know that the recommendation language is complete, so we will write  X  u,r , X  u,r for the mul-tipliers that give, We now examine the vector equal to 1 u h , it follows that the sum of its elements is equal to 1, hence we get
X From the definition of an allowed recommendation vector, we know that the elements of every r have unit sum. Which gives us, we get the same result for the multipliers The set { 1 , 2 ,...,m } models the m users of the system, who perform the role of inspecting the recommendations and, potentially, utilizing the items.  X  u,r as well. So, Now consider that some user u performs the following recom-mendations. Initially, u applies the token vector on item e h (we will call this Recommendation 1) to get in-stantaneous profit, Next, u applies the token vector  X  (Recommendation 2) to get instantaneous profit, Finally, u applies the token vector on some arbitrary item e (Recommendation 3) to get in-stantaneous profit, Observe that the sum of the contributions made by u is exactly 0, hence, there is no danger in violating the  X  limit on the sum of the contributions. We claim that there is some user u , such that the sum of her instantaneous profits for placing recommendations 1, 2, and 3 is positive and, thus, there exists a profitable arbitrage opportunity for u . We will prove this by showing that if we take the sum of the instantaneous profits (3), (4), (5), and sum it over all u , we get a positive number. Starting with summing (3) for all u and combining with (1), we get that the sum of the instantaneous profits Recommendation 1 is, Similarly, for Recommendation 2, from (1) and (4) we get, Finally, for Recommendation 3, summing (5) for all u and combining with (2), we get, Now, summing expressions (6), (7), and (8), we get that the sum of the instantaneous profits that each user would have by placing recommendations 1, 2, and 3, unilaterally, is f ( e h ,u h )  X  f ( e l ,u l ) &gt; 0.
 We now prove a conditional theorem which implies that at equilibrium the feedback scores are correlated with the qual-ity scores. The preco ndition refers to the mild assumptions given in the description of the algorithm in [3] and men-tioned in the beggining of this section.

Theorem 2. If there exists a ranking algorithm which en-sures visibility  X  e,u =  X  X  e.u ,where  X  is a constant for all ( e, u ) , then there exists an arbitrage opportunity unless the
Proof. Suppose q e,u there exist two pairs ( e  X  ,u  X  ), ( e ,c ) such that f ( e f ( e ,u ). Following arguments similar to the ones used in the last proof, we can prove that there exists an arbitrage opportunity.
 We now focus on the quadratic incentive scheme, that is, the case s = 2. Consider the following potential function, Notice that if we interpret q and  X  as distributions, then the above potential function is equivalent to the Kullback-Leibler divergence (remember that q is fixed), which is, In the light of this observation, the next theorem says that it is most profitable for users to leave feedback which provides the most additional information relative to the current state of the system, leading to an equilibrium where all items are correctly rated for all users.

Theorem 3. If there exists a ranking algorithm which en-sures visibility  X  e,u =  X  X  e,u ,where  X  is a constant for all ( e, u ) ,then, 1. The potential function P is minimized when the feed-2. At any given time, the most profitable arbitrage op-
Proof. The proof presented here follows the proof of the famous Gibbs X  inequality in information theory. However, for the sake of completeness, we give the details here. Let Q = constant). We modify P to get, Since q e,u  X  X  are fixed, P is minimized where P  X  is maximized, and vice versa. Note that log x  X  x  X  1, with equality if and only if x =1. Weget, Hence, the potential function P is uniquely minimized at  X  e,u = q e,u T Q . The second part of the theorem follows from the observation that the partial derivative of P ( q,  X  )with respect to  X  e,u is f ( e, u ).
At this point, we conclude the paper with a discussion of how our scheme might be applied in practical systems. Con-sider a Netflix-like recommender system and an underlying social structure. The set of items is the set of movies and the social graph is given by the social structure. A recommenda-tion can be made to all users who like sci-fi movies, or to all those belonging to a specific age group. Also, some user, who might know a user u (a friend) well, can specifically recom-mend a movie to u . All those recommendations can be made possible by including the appropriate vectors in the recom-mendation language. Every user interacts with a designed interface, which presents options compatible with human intuition and then translates the user X  X  selections into rec-ommendation vectors. The recommendation language can also be used to capture correlations between the interests of individual users, given from collaborative filtering tech-niques. The quality of a movie with respect to a user is the probability that the user rents a movie conditional on the fact that she inspects the recommendation. [1] G. Adomavicius and A. Tuzhilin. Toward the next [2] R. Bhattacharjee and A. Goel. Incentive based [3] R. Bhattacharjee and A. Goel. Algorithms and [4] S. K. Lam and J. Riedl. Shilling recommender systems [5] A. W. Marshall and I. Olkin. Inequalities: Theory of [6] M. O X  X ahony, N. Hurley, N. Kushmerick, and [7] M.Salganik,P.Dodds,andD.Watts.Experimental
