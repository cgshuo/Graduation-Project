 WWW provides a super big pool for interesting images. Recently, WWW image retrieval has been a very challenging research area. Such images are typically described by both high-level (text) and low-level (visual) features. To retrieve relevant images from large image database, two issues are essential: effectiveness and efficiency. However, most known research results [1] are on retrieval effectiveness. There is no clearly known research achievement on how to index this particular type on indexing completely different representations: text and visual features. Current method is to build one structure for every single feature. Given an image query, it has to access all individual structures and integrate results from each index to get the final results. Furthermore, these known indexing structures suffer from  X  dimensionality curse  X . When the dimensionality of data space reaches 20 or greater, indexing techniques fail to outperform sequential scan [2] for nearest neighbor search. 
In this paper, we propose a new method called Multi-scale Similarity Indexing (MSI) that can index WWW images X  multi-features in a single structure. MSI exhibits such as image text and visual features, where text feature is in Weighted Lexical space. MSI first partitions each feature space into clusters. Then the similarity of each indexing key. By a simple mapping function, we can keep the keys for each cluster in different feature space distinct in different scale level. Thus a standard B+ tree can be easily built on these indexing keys. 
However, like other existing indexing technique, MSI also suffers from  X  dimensionality curse  X . To release MSI from such curse, we propose a novel technique called Local Bit Stream (LBS). LBS exhibits a way to transform the high dimensional feature representation (big si ze) into a uniform, accurate and compact representation (small size). Given clusters in each feature space, LBS encodes each point in different feature space into a uniformly dimensional bit stream (BS). The BS LBS depends on how to generate the BS for each feature point. Due to the completely different nature of text and visual features , both are encoded in different schemes. We present different encoding strategies for text and visual features. However, both encoding strategies can produce the same uniformly BS representations for text and visual feature points. BS is an approximate representation of original data. It X  X  compact, much smaller in size, and accurate for similarity measures. Furthermore, BS comparisons involve bit operations only. Thus it is much faster in terms of efficiency. 
We implement our indexing techniques on top of MYSQL server. An extensive performance study is conducted to evaluate our methods. Our results show that single indexing structure is supreme to multi-indexing structures, and LBS breaks the dimensionality curse by improving the response time faster than sequential scan and iDistance [4] by an order of magnitude without sacrificing the retrieval precision. 
The rest of paper is organized as follows. In section 2, we review some related works. In section 3, some preliminary work on image features and similarity measures are introduced. In section 4, we present the single one-dimensional indexing structure  X  MSI, and in section 5 we propose the LBS and its encoding schemes. An extensive performance study is presented in section 6. Finally, we conclude our paper in section 7. Our related works cover several research areas: WWW image retrieval, evidence integration, high dimensional indexing, and multi-feature query processing. 
Several WWW image retrieval systems have been proposed in literature. Existing known systems, such as AMORE [5], ImageRover [6], and WebSeek [7], allow the WWW image retrieval on combination of multi-features, like keywords, color, shape and texture. Recently, the high-level features of WWW images were explored by a Weight ChainNet model [3] since low level features cannot represent the high level semantic meanings for WWW images. More recently, the textual and Hyperlink information are extracted from blocks of Web pages to improve the accuracy [24]. And relevance feedback techniques are also applied in WWW image retrieval [8, 25]. However, most of systems focus on retrieval accuracy only. 
To integrate multi-features together, most of systems used linear combination by assuming that text and visual features are linearly important. Recently, Dempster Shafer Theory, one technique to handle uncertainty, has been also employed on indexing of face retrieval on the web [9]. In this paper, we examine more techniques, including Certainty Factor and Compound probability. 
Recently, Nearest Neighbor (NN) search in high dimensional spaces has been a very active research topic. Several indexing structures [2, 4, 10, 11, 12, 13] have been proposed. However, all these techniques are for indexing an individual feature space purpose, and they all suffer from known  X  dimensionality curse  X . Their performances degrade rapidly as dimensionality increases. As dimensionality reaches high (&gt;20), for every feature space. Given a query, each index has to be accessed. ImageRover [6] tried to combine multi-features by first performing dimensionality reduction on each feature then used existing indexing structure to index concatenated feature vector from every reduced feature space. Anne et al [14] applied non-linear neural network techniques with dimensionality reduction method, then used the similar way to index reduced multi-visual features by existing indexing structure. However, both have the following drawbacks. First the dimensionality curse still remains. Their techniques Image features spaces are typically in dimensionality of a range of tens to hundreds. retrieval accuracy. Second, there was no clear report on their indexing efficiency. Third, neural network is tedious and hard for training, especially for WWW image database with text features. In this paper, we aim to index multi text and visual features in a one-dimensional single index and leave the dimensionality curse to the past. 
Another category of our related work is on processing multi-feature queries. Such problem appears obviously on multi-features images database. Given a query image, the typical steps are first to compute the similarity among the same feature space, then not present multi-feature query processing problem in this paper, but on indexing issues. In this section, we briefly present the features we used to describe the WWW images and respective similarity measures. 3.1 WWW Image Features Without losing the generality, we use text feature and one visual feature as the descriptors of WWW images. 3.1.1 Text Feature Text descriptions of WWW image carry high-level semantic meanings. We choose a recently proposed representation model called Weighted ChainNet Model [3] as the text feature. Weighted ChainNet constructs a Lexical Chain (or sentence) network given the WWW image X  X  surrounding text in its embedded web page, by assigning lexical chains were introduced: Title Lexical Chain Alt Lexical Chain, Page Lexical Chain, Sentence Lexical Chain, Reconstructed Sentence Lexical Chain, and Caption Lexical Chain. The first three types are constructed by image X  X  title, image X  X  alternate caption. To simplify the problem and illustration, here we summarize the chain network into a single weighted lexical chain by summing all the weight in each type of lexical china for each word in the network. The following formula is used to compute the total weight for each word. 
Thus all the weighted words form a single weighted lexical chain , which is used as our WWW image X  X  text feature. For simplicity, we denote image X  X  text feature as T. 3.1.2 Visual Feature Wavelet transform is a useful tool in effectively generating compact representation decomposition, and remain the most important sub bands (largest coefficients), we can get fixed size dimensional feature vectors independent of resolution and scaling. approximation captures image X  X  shape, text ure and location information in a single signature. We use daubechies' wavelets [17] to generate WWW image X  X  visual features. In this paper, we truncate the 64 most dominating coefficients as our image X  X  visual feature. Thus our WWW image X  X  visual feature is in 64-dimensional feature vector. For simplicity, we denote image X  X  visual feature as V. 3.2 Image Similarity Measurements For text feature, we employ the cosine formula as follows: where i T and j T is image i  X  X  and image j  X  X  text feature respectively. 
For visual feature, the similarity between two images is computed as follows based on Manhattan Distance: feature respectively. D is the dimensionality of visual feature space. 4.1 Building Indexing Structure In this section, we present the one-dimensional single indexing technique for image X  X  multi-features, called Multi-scale Similarity Indexing (MSI). MSI is mainly inspired from the following observations. First, in the same cluster, relevant images have close similarities to the cluster X  X  center. And this property is hold for both text feature space and visual feature space. Second, based on the similarities to the cluster center, images can be ordered within that cluster. Third, similarities are one-dimensional values. If we can map each image into corresponding similarity value and each cluster index like B+-tree can be easily built on these similarities. Thus in MSI, high dimensional features spaces are transformed into one-dimensional space. Certain amount of irrelevant images can be fast pruned based on these one-dimensional values X  comparisons. 
To build MSI, we need first to cluster each feature space into partitions and compute their centers. Let X  X  assume that there are m clusters in text feature space and n clusters in visual feature space. in text space, each cluster is assigned with a cluster Given an image with feature T and V, its indexing keys in different feature space are computed as follows: respectively. T_SCALE and V_SCALE are two constant scales with large gap to that features in different cluster have different range. Thus features in different clusters can be distinguished easily. For example, an image with feature T and V, T is two indexing keys will be transformed into the ranges [ T_SCALE+i*C, T_SCALE+(i+1)*C ] and [ V_SCALE+j*C, V_SCALE+(j+1)*C ] respectively. 
A single B+-tree can be used to index the similarity keys for fast retrieval. And an additional auxiliary array is used to store the clusters centers and their minimum and maximum radii/similarity values that define the cluster X  X  data space, where the minimum and maximum radii are used to facilitate searching. When there is only one similarity, rather than distance values. 4.2 Query Processing Given a query image Q to search for the K top relevant images (K nearest neighbors), divided into two sub queries, T Q and V Q respectively, where T Q and V Q are image X  X  text and visual features. Then nearest neighbor searching is performed to get T K and V K top ranked image Ids from text and visual feature space such that the methods are then applied to compute the final list of results. 
For each subquery, the searching starts with a query sphere by a relatively small radius R around T Q and V Q respectively. To find the desired number of most relevant images, the searching radius cannot be predetermined. Hence an iterative used. Searching in MSI begins with scanning the auxiliary array to determine which cluster whose data space overlaps with the searching sphere of T Q and V Q . This can be determined by the following triangle inequality property: where P is a feature point in either text or visual feature space. 
Figure 1 shows the searching spaces for two queries 1 Q and 2 Q corresponding to a cluster O which covers a space defined by its minimum and maximum radii. From the above triangle inequality property, for 1 Q , cluster O can be directly pruned since the similarity between 1 Q and O is greater than cluster X  X  maximum radius/similarity plus query searching radius R. The same situation occurs when the similarity between Q and O is less than the cluster X  X  minimum radius/similarity minus query searching radius R. And this pruning situation is common to both text and visual feature spaces. 
On the other hand, if both query sphere and cluster X  X  data space intersect, such as Q  X  X  searching sphere in figure 1, range searching has to be performed in MSI. visual space respectively, their ranges searched in MSI are: and Note that query sphere R is an increasing parameter with number of iterations. Searching for both sub queries is concurrent. It stops when there are at least K common image Ids are discovered in two sets of results searched from two sub queries. Thus MSI can provide approximate K nearest neighbors quickly using one dimensional data comparisons. 
So far, we have built a single one-dimensional indexing for WWW image X  X  multi-features. However, similarity-indexing key mapping function is lossy in nature. Searching the data whose similarities to cluster X  X  center are close to query point may (white area), the candidates for data access still include a number of points far away from query (green area, named as  X  false positive X  ). It will be perfect if we can remain only the points inside of query searching sphere (pink area). In next section, we propose Local Digital Coding to effectively filter most of these  X  false positives  X . 4.3 Clustering Techniques As mentioned earlier, the first step for building MSI is to partition each feature space. 
For WWW image text feature, every image is in weighted lexical chain model. We observed that WWW images are usually categorized by different topics. Here we propose a method called Topic-driven Clustering, to partition the text space into clusters. Topic-driven Clustering Algorithm: 1. select the top K hottest keywords, and each keyword is assigned as a center. 2. assign images into these K clusters based on similarities to each center. 3. reconstruct each cluster X  X  center by summarizing its images X  weighted lexical 4. reassign images into K clusters based on similarities to each new center. 5. merge K clusters into a desirable number of clusters. images can be assigned into clusters since K keywords cannot cover all images. A weighted lexical chain by summarizing all images X  lexical chains in the same way as summarizing the image X  X  representation from a lexical chain network. By doing so, information. Then images are partitioned again corresponding to these new centers. Finally we merge closely related clusters into one, until we get a desirable number of cluster we want. After we apply Topic-driven clustering algorithm, the image X  X  text feature are clustered into partitions, each of which has a weighted lexical chain as the center. 
To partition the high dimensional data space, such as image X  X  visual feature, several clustering methods [18, 19, 20] have been proposed in literature. In this paper space. The main purpose of finding correlated cluster is to perform the dimensionality dimensionality reduction on local correlated/elliptical cluster achieved much better effectiveness compared to reduce the dimensionality on the whole dataset. This is because dimensionality reduction methods such as Principle Component Analysis (PCA) are effectively only when the data space is well correlated. Otherwise, the retrieval accuracy should be affected greatly. In this section, we introduce our new indexing technique applied in MSI to break the dimensionality curse by filtering the irrelevant images greatly. smallest data representation. If each dimension of feature space can be represented by always fastest. However, in high dimensional space, the similarity computation on original data is very expensive. 
Realize that for WWW images, its text feature and visual feature are in different and standard high dimensional point to represent visual feature. Both have the following main differences. First, text feature is discrete in nature since each dimension of lexical chain is a word basically, while visual feature is continuous value along each dimension. Second, the dimensionality of text feature is dynamic, words to describe its semantics. To generate the uniform bits representation (we name it as Bit Stream, or BS) for both features, different encoding scheme have to be used. 
Except the uniform BS representation, how to produce an effective BS for each image feature is a challenging task. Here we associate the generation of BS with the cluster center where an image belongs. That is, for an image X  X  feature, we first allocate its cluster, and then compare it with its cluster center to generate its BS. Thus Next, we present the two encoding algorithms for text and visual features to produce a D-bit long uniform BS representation, where D is the dimensionality of feature space. 5.1 BS Generation for Text Feature before we start encoding by using the prope rty of ordered data. We first order every image X  X  lexical chain and the cluster center X  X  lexical chain based on alphabet order of the words. Second, every word in each image lexical chain is labeled with its position index in the center X  X  lexical chain. Since the center contains all the words appearing in representation for images inside of cluster. 
The encoding algorithm for an image text feature T in a cluster T O is shown below. Text Encoding: 1. BS=0; 2. range = T O .size()/D + 1; 3. for every word in T 4. pos = word.index / range 5. BS | = 1 &lt;&lt; pos; 6. end for intervals (line 2). For each word in a text feature T, since we know its corresponding value at that position counted from left to be 1 (line 5). For example, if T contains two words  X  X CM X  and  X  X ultimedia X  and their respective position index in the cluster center is 10 and 100. The center contains 1000 words. We want to construct a 64-bit interval is [0, 16), second is [16, 32), and so on. Words  X  X CM X  and  X  X ultimedia X  are in interval 0 and 6. Thus the BS for T is 0 6 2 2  X   X  + =65. If more bits are needed than integer, multi-integer or character can be used. on two BSs must be greater than 0. By checking this result, lots of irrelevant images can be pruned immediately. This encoding algorithm can make sure the retrieval precision is exactly the same as sequential scan. Further more, the space occupied by BS is fixed in D bits. However, each original text feature generally takes hundreds of bytes. 5.2 BS Generation for Visual Feature Different from text feature, visual features are in high dimensional uniform. And number of intervals divided from cluster center is used to produce a uniform D-bit BS similarity measurements between both spaces are also different. Thus we present a different encoding algorithm for continuous and fixed dimensionality feature spaces. Visual Encoding: 1. BS=0; 2. for i =0 to D-1 3. if (V[i]&gt; V O [i]) 4. BS | = 1 &lt;&lt; i; 5. end for 
Given a D-dimensional feature space, the above algorithm encodes each feature V be 0 (line 1). For each dimension, if its value is greater than the center value, we set the bit value to be 1 at that dimension for BS (line 3-4), else remain 0. Thus in visual space, the BS is a coarse approximation of original data. 
BS for visual feature is derived from comparing its cluster X  X  center. If two images are similar, their BSs should also be similar. To decide whether two BSs are similar, two similar BSs should have. Along a dimension, if both BSs have same bit value, two visual features are both greater than the center or both less than the center, then their BSs have one common bit. Clearly, BS representation for a visual feature more than  X  number of common bits, we say two BSs are similar. Given a 64-each feature, it occupies 64*4 bytes space. However, a BS occupies 64/8 bytes. There are 32 times differences. Again, by performing bit operations on BSs, we can fast effective. On the other hand, if it is too big, some relevant images may be filtered. In the experiments, we will see that while we keep the same accuracy as sequential scan, the retrieval speed can still be faster than sequential scan by times. 
So far, we have looked the encoding method to produce BSs for text and visual final outputs from both algorithms have the same representation model  X  BS. 
LBS builds a new simple feature representation called BS for each image in involved bit operations. BSs can be embedded into MSI lower than the indexing keys figure 2. Thus, after the first level pruning in MSI, a second level pruning by level pruning. The images whose BSs are similar to query BS are then accessed at data level. Experiments showed that while keeping the accuracy high, 90% more  X  X alse positives X  could be effectively pruned. In section, we present our experiments results on our proposals. We compare our indexing technique with sequential scan and multi-indices built by iDistance method following, we refer our MSI with LBS as LBS only. 6.1 Experiments Set Up Our database contains 100,000 WWW images downloaded by our web crawler randomly from around 40,000 websites. And we use the weighted lexical chain and wavelet descriptors as image X  X  text and visual features as explained in section 3. We manipulated these databases in MYSQL server. We implement our method in the environment of Ultra-10 SunOS 5.7 processor (333 MHz CPU and 256 MB RAM). 
Two parameters are used as measurements: Precision and Efficiency. Since our KNN (K nearest neighbor) to compute the precision. Obviously, within this K results, if the precision is higher, recall is higher also. We set K=20, and test 20 image queries for each experiment. Efficiency is measured by the Total Response Time (TRT), which includes the communication time to the MYSQL server. 6.2 Tuning  X  In our LBS method, the important parameter  X  which is used to measure the similarity greater than 0. So we need tune  X  for visual features only. changing of  X  for different dimensional data space. Here we the relative precision by comparing LBS with sequential scan. The relative precision is defined as precision by LBS divided by precision by sequential scan. The following figure 3 and 4 show the effect of different  X  values on retrieval precision and efficiency for two sets of visual features. 
From figure 3, we can see that for 64-dimendional original data, LBS can remain the same precision as sequential scan when  X  is less than 36. When  X  is greater than 36, there is rapid decreasing on precision. This is reasonable. When  X  is larger, more points can be pruned. As  X  becomes too large, there may be only less than K access the original data. Thus a  X  value which is a bit larger than the half size of the dimensionality of data space can remain the precision high. 
Figure 4 shows the  X  effects on the total response time. TRT for sequential scan is obvious reduction on TRT. This is clear that in high dimensional space, most of points have few common bits along few dimensions with query point, while they may not be necessary to be the top K nearest neighbors to the query point. However, when this case), the TRT is reduced dramatically. This indicates that most of the irrelevant points can be distinguished when  X  reaches around the half size of the dimensionality. As  X  becomes too large, more points can be filtered, but precision may be affected as shown in figure 3. Thus there is a tradeoff between precision and TRT. From figure 3 and 4, we can see that good values for  X  could be a bit larger than the half size of the high. In our later experiments, we chose  X  as 36 for our 64-dimensional feature. 6.3 Comparative Study Now we want to compare our indexing method LBS with sequential scan and multi-indices by iDistance [4], based on the retrieval speed. This experiment tested 3 datasets: text feature only, visual feature only, and text combined with visual features. The following table shows their differences in terms of total response time (s).
From table 1, we can see that multi-indices method built by iDistance performs even worse than sequential scan. There are two possible reasons. First, accessing and searching multi-indices take more time. Second, dimensionality curse resists in such purely similarity based one-dimensional index because too many  X  X alse positives X  are searched. By employing single index structure and LBS, the performance is improved significantly. LBS is more than an order of magnitude better than sequential scan. Clearly, our LBS is an effective method to filter those irrelevant points. In this paper, we presented a novel indexing technique called MSI to index WWW image X  X  multi-features in a single one-dimensional structure. Combined with Local iDistance significantly without degrading the retrieval precision.

