 As the internet reaches almost every corner of this world, more and more people write reviews and share opinions on the World Wide Web. The user-generated opinion-rich reviews will not only help other users make better judgements but they are also useful resources for manufacturers of prod-ucts to keep track and manage customer opinions. However, as the number of product reviews grows, it becomes difficult for a user to manually learn the panorama of an interesting topic from existing online information. Faced with this problem, re-search works, e.g., (Hu and Liu, 2004; Liu et al., 2005; Lu et al., 2009), of sentiment analysis on product reviews were proposed and have become a popular research topic at the crossroads of infor-mation retrieval and computational linguistics.
Carrying out sentiment analysis on product re-views is not a trivial task. Although there have al-ready been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang et al., 2006; Lu and Zhai, 2008; Titov and McDonald, 2008; Zhou and Chaovalit, 2008; Lu et al., 2009), there is still room for improvement on tackling this problem. When we look into the de-tails of each example of product reviews, we find that there are some intrinsic properties that exist-ing previous works have not addressed in much de-tail.

First of all, product reviews constitute domain-specific knowledge. The product X  X  attributes men-tioned in reviews might have some relationships between each other. For example, for a digital camera, comments on image quality are usually mentioned. However, a sentence like  X 40D han-dles noise very well up to ISO 800 X , also refers to image quality of the camera 40D. Here we say  X  X oise X  is a sub-attribute factor of  X  X mage quality X . We argue that the hierarchical relationship be-tween a product X  X  attributes can be useful knowl-edge if it can be formulated and utilized in product reviews analysis. Secondly, Vocabularies used in product reviews tend to be highly overlapping. Es-pecially, for same attribute, usually same words or synonyms are involved to refer to them and to de-scribe sentiment on them. We believe that labeling existing product reviews with attributes and cor-responding sentiment forms an effective training resource to perform sentiment analysis. Thirdly, sentiments expressed in a review or even in a sentence might be opposite on different attributes and not every attributes mentioned are with senti-ments. For example, it is common to find a frag-ment of a review as follows: Example 1:  X ...I am very impressed with this cam-era except for its a bit heavy weight especially with extra lenses attached. It has many buttons and two main dials. The first dial is thumb dial, located near shutter button. The second one is the big round dial located at the back of the camera... X  In this example, the first sentence gives positive comment on the camera as well as a complaint on its heavy weight. Even if the words  X  X enses X  ap-pears in the review, it is not fair to say the cus-tomer expresses any sentiment on lens. The sec-ond sentence and the rest introduce the camera X  X  buttons and dials. It X  X  also not feasible to try to get any sentiment from these contents. We ar-gue that when performing sentiment analysis on reviews, such as in the Example 1, more attention is needed to distinguish between attributes that are mentioned with and without sentiment.

In this paper, we study the problem of senti-ment analysis on product reviews through a novel method, called the HL-SOT approach, namely Hi-erarchical Learning (HL) with Sentiment Ontol-ogy Tree (SOT). By sentiment analysis on prod-uct reviews we aim to fulfill two tasks, i.e., label-ing a target text 1 with: 1) the product X  X  attributes (attributes identification task), and 2) their corre-sponding sentiments mentioned therein (sentiment annotation task). The result of this kind of label-ing process is quite useful because it makes it pos-sible for a user to search reviews on particular at-tributes of a product. For example, when consider-ing to buy a digital camera, a prospective user who cares more about image quality probably wants to find comments on the camera X  X  image quality in other users X  reviews. SOT is a tree-like ontology structure that formulates the relationships between a product X  X  attributes. For example, Fig. 1 is a SOT for a digital camera 2 . The root node of the SOT is a camera itself. Each of the non-leaf nodes (white nodes) of the SOT represents an attribute of a cam-era 3 . All leaf nodes (gray nodes) of the SOT rep-resent sentiment (positive/negative) nodes respec-tively associated with their parent nodes. A for-mal definition on SOT is presented in Section 3.1. With the proposed concept of SOT, we manage to formulate the two tasks of the sentiment analysis to be a hierarchical classification problem. We fur-ther propose a specific hierarchical learning algo-rithm, called HL-SOT algorithm, which is devel-oped based on generalizing an online-learning al-gorithm H-RLS (Cesa-Bianchi et al., 2006). The HL-SOT algorithm has the same property as the H-RLS algorithm that allows multiple-path label-ing (input target text can be labeled with nodes be-longing to more than one path in the SOT) and partial-path labeling (the input target text can be labeled with nodes belonging to a path that does not end on a leaf). This property makes the ap-proach well suited for the situation where com-plicated sentiments on different attributes are ex-pressed in one target text. Unlike the H-RLS algo-rithm , the HL-SOT algorithm enables each clas-sifier to separately learn its own specific thresh-old. The proposed HL-SOT approach is empiri-cally analyzed against a human-labeled data set. The experimental results demonstrate promising and reasonable performance of our approach.
This paper makes the following contributions:  X  To the best of our knowledge, with the pro- X  A specific hierarchical learning algorithm is  X  The proposed HL-SOT approach can be gen-The remainder of the paper is organized as fol-lows. In Section 2, we provide an overview of related work on sentiment analysis. Section 3 presents our work on sentiment analysis with HL-SOT approach. The empirical analysis and the re-sults are presented in Section 4, followed by the conclusions, discussions, and future work in Sec-tion 5. The task of sentiment analysis on product reviews was originally performed to extract overall senti-ment from the target texts. However, in (Turney, 2002), as the difficulty shown in the experiments, the whole sentiment of a document is not neces-sarily the sum of its parts. Then there came up with research works shifting focus from overall document sentiment to sentiment analysis based on product attributes (Hu and Liu, 2004; Popescu and Etzioni, 2005; Ding and Liu, 2007; Liu et al., 2005).

Document overall sentiment analysis is to sum-marize the overall sentiment in the document. Re-search works related to document overall senti-ment analysis mainly rely on two finer levels senti-ment annotation: word-level sentiment annotation and phrase-level sentiment annotation . The word-level sentiment annotation is to utilize the polar-ity annotation of words in each sentence and sum-marize the overall sentiment of each sentiment-bearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; An-dreevskaia and Bergler, 2006; Esuli and Sebas-tiani, 2005; Esuli and Sebastiani, 2006; Hatzi-vassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivas-siloglou, 2003). The phrase-level sentiment anno-tation focuses sentiment annotation on phrases not words with concerning that atomic units of expres-sion is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contex-tual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised learning algorithm was proposed to classify re-views as recommended or not recommended by averaging sentiment annotation of phrases in re-views that contain adjectives or adverbs. How-ever, the performances of these works are not good enough for sentiment analysis on product reviews, where sentiment on each attribute of a product could be so complicated that it is unable to be ex-pressed by overall document sentiment.

Attributes-based sentiment analysis is to ana-lyze sentiment based on each attribute of a prod-uct. In (Hu and Liu, 2004), mining product fea-tures was proposed together with sentiment polar-ity annotation for each opinion sentence. In that work, sentiment analysis was performed on prod-uct attributes level. In (Liu et al., 2005), a system with framework for analyzing and comparing con-sumer opinions of competing products was pro-posed. The system made users be able to clearly see the strengths and weaknesses of each prod-uct in the minds of consumers in terms of various product features. In (Popescu and Etzioni, 2005), Popescu and Etzioni not only analyzed polarity of opinions regarding product features but also ranked opinions based on their strength. In (Liu et al., 2007), Liu et al. proposed Sentiment-PLSA that analyzed blog entries and viewed them as a document generated by a number of hidden sen-timent factors. These sentiment factors may also be factors based on product attributes. In (Lu and Zhai, 2008), Lu et al. proposed a semi-supervised topic models to solve the problem of opinion inte-gration based on the topic of a product X  X  attributes. The work in (Titov and McDonald, 2008) pre-sented a multi-grain topic model for extracting the ratable attributes from product reviews. In (Lu et al., 2009), the problem of rated attributes summary was studied with a goal of generating ratings for major aspects so that a user could gain different perspectives towards a target entity. All these re-search works concentrated on attribute-based sen-timent analysis. However, the main difference with our work is that they did not sufficiently uti-lize the hierarchical relationships among a prod-uct attributes. Although a method of ontology-supported polarity mining, which also involved ontology to tackle the sentiment analysis problem, was proposed in (Zhou and Chaovalit, 2008), that work studied polarity mining by machine learn-ing techniques that still suffered from a problem of ignoring dependencies among attributes within an ontology X  X  hierarchy. In the contrast, our work solves the sentiment analysis problem as a hierar-chical classification problem that fully utilizes the hierarchy of the SOT during training and classifi-cation process.
In this section, we first propose a formal defini-tion on SOT. Then we formulate the HL-SOT ap-proach. In this novel approach, tasks of sentiment analysis are to be achieved in a hierarchical classi-fication process. 3.1 Sentiment Ontology Tree As we discussed in Section 1, the hierarchial rela-tionships among a product X  X  attributes might help improve the performance of attribute-based senti-ment analysis. We propose to use a tree-like ontol-ogy structure SOT, i.e., Sentiment Ontology Tree, to formulate relationships among a product X  X  at-tributes. Here,we give a formal definition on what a SOT is.
 Definition 1 [SOT] SOT is an abbreviation for Sentiment Ontology Tree that is a tree-like ontol-ogy structure T ( v, v + , v  X  , T ) . v is the root node of T which represents an attribute of a given prod-uct. v + is a positive sentiment leaf node associ-ated with the attribute v . v  X  is a negative sen-timent leaf node associated with the attribute v . T is a set of subtrees. Each element of T is also attribute of its parent attribute node.
 By the Definition 1, we define a root of a SOT to represent an attribute of a product. The SOT X  X  two leaf child nodes are sentiment (positive/negative) nodes associated with the root attribute. The SOT recursively contains a set of sub-SOTs where each root of a sub-SOT is a non-leaf child node of the root of the SOT and represent a sub-attribute be-longing to its parent attribute. This definition suc-cessfully describes the hierarchical relationships among all the attributes of a product. For example, in Fig. 1 the root node of the SOT for a digital cam-era is its general overview attribute. Comments on a digital camera X  X  general overview attribute ap-pearing in a review might be like  X  X his camera is great X . The  X  X amera X  SOT has two sentiment leaf child nodes as well as three non-leaf child nodes which are respectively root nodes of sub-SOTs for sub-attributes  X  X esign and usability X ,  X  X mage qual-ity X , and  X  X ens X . These sub-attributes SOTs re-cursively repeat until each node in the SOT does not have any more non-leaf child node, which means the corresponding attributes do not have any sub-attributes, e.g., the attribute node  X  X utton X  in Fig. 1. 3.2 Sentiment Analysis with SOT In this subsection, we present the HL-SOT ap-proach. With the defined SOT, the problem of sen-timent analysis is able to be formulated to be a hi-erarchial classification problem. Then a specific hierarchical learning algorithm is further proposed to solve the formulated problem. 3.2.1 Problem Formulation In the proposed HL-SOT approach, each target text is to be indexed by a unit-norm vector x  X  X , X = R d . Let Y = { 1 , ..., N } denote the fi-nite set of nodes in SOT. Let y = { y 1 , ..., y N } X  { 0 , 1 } N be a label vector to a target text x , where  X  i  X  Y : A label vector y  X  X  0 , 1 } N is said to respect SOT if and only if y satisfies  X  i  X  Y ,  X  j  X  A ( i ) : if y i = 1 then y j = 1 , where A ( i ) represents a set ancestor nodes of i , i.e., A ( i ) = { x | ancestor ( i, x ) } . Let Y denote a set of label vectors that respect SOT. Then the tasks of senti-ment analysis can be formulated to be the goal of a hierarchical classification that is to learn a function f : X X  X  , that is able to label each target text x  X  X  with classifier of each node and generating with x a label vector y  X  X  that respects SOT. The requirement of a generated label vector y  X  X  en-sures that a target text is to be labeled with a node only if its parent attribute node is labeled with the target text. For example, in Fig. 1 a review is to be labeled with  X  X mage quality + X  requires that the review should be successively labeled as related to  X  X amera X  and  X  X mage quality X . This is reasonable and consistent with intuition, because if a review cannot be identified to be related to a camera, it is not safe to infer that the review is commenting a camera X  X  image quality with positive sentiment. 3.2.2 HL-SOT Algorithm The algorithm H-RLS studied in (Cesa-Bianchi et al., 2006) solved a similar hierarchical classifica-tion problem as we formulated above. However, the H-RLS algorithm was designed as an online-learning algorithm which is not suitable to be ap-plied directly in our problem setting. Moreover, the algorithm H-RLS defined the same value as the threshold of each node classifier. We argue that if the threshold values could be learned sepa-rately for each classifiers, the performance of clas-sification process would be improved. Therefore we propose a specific hierarchical learning algo-rithm, named HL-SOT algorithm, that is able to train each node classifier in a batch-learning set-ting and allows separately learning for the thresh-old of each node classifier.
 Defining the f function Let w 1 , ..., w N be weight vectors that define linear-threshold classi-fiers of each node in SOT. Let W = ( w 1 , ..., w N )  X  be an N  X  d matrix called weight matrix. Here we generalize the work in (Cesa-Bianchi et al., 2006) and define the hierarchical classification function f as: where x  X  X  ,  X  y  X  X  . Let z = W  X  x . Then the function  X  y = g ( z ) on an N -dimensional vector z defines:  X  i = 1 , ..., N :  X  y where P ( i ) is the parent node of i in SOT and B ( S ) is a boolean function which is 1 if and only if the statement S is true. Then the hierarchical classification function f is parameterized by the weight matrix W = ( w 1 , ..., w N )  X  and threshold vector  X  = (  X  1 , ...,  X  N )  X  . The hierarchical learn-ing algorithm HL-SOT is proposed for learning the parameters of W and  X  .
 Parameters Learning for f function Let D de-note the training data set: D = { ( r, l ) | r  X  X  , l  X  Y} . In the HL-SOT learning process, the weight matrix W is firstly initialized to be a 0 matrix, where each row vector w i is a 0 vector. The thresh-old vector is initialized to be a 0 vector. Each in-stance in the training set D goes into the training process. When a new instance r t is observed, each row vector w i,t of the weight matrix W t is updated by a regularized least squares estimator given by: where I is a d  X  d identity matrix, Q ( i, t  X  1) denotes the number of times the parent of node i observes a positive label before observing the in-Q ( i, t  X  1) matrix whose columns are the instances r a Q ( i, t  X  1) -dimensional vector of the correspond-ing labels observed by node i . The Formula 1 re-stricts that the weight vector w i,t of the classifier i is only updated on the examples that are positive for its parent node. Then the label vector  X  y r t is computed for the instance r t , before the real label vector l r t is observed. Then the current threshold vector  X  t is updated by: where  X  is a small positive real number that de-notes a corrective step for correcting the current threshold vector  X  t . To illustrate the idea behind an element of the vector y  X  t . The Formula 2 correct the current threshold  X  i,t for the classifier i in the following way:  X  If y  X   X  If y  X   X  If y  X  1: Each vector w i, 1 , i = 1 , ..., N of weight ma-2: Threshold vector  X  1 is set to be 0 vector 3: for t = 1 , ..., | D | do 4: Observe instance r t  X  X  5: for i = 1 , ...N do 6: Update each row w i,t of weight matrix 7: end for 8: Compute  X  y r t = f ( r t ) = g ( W t  X  r t ) 9: Observe label vector l r t  X  X  of the in-10: Update threshold vector  X  t by Formula 2 11: end for
The hierarchial learning algorithm HL-SOT is presented as in Algorithm 1. The HL-SOT al-gorithm enables each classifier to have its own specific threshold value and allows this thresh-old value can be separately learned and corrected through the training process. It is not only a batch-learning setting of the H-RLS algorithm but also a generalization to the latter. If we set the algo-rithm HL-SOT X  X  parameter  X  to be 0, the HL-SOT becomes the H-RLS algorithm in a batch-learning setting. In this section, we conduct systematic experiments to perform empirical analysis on our proposed HL-SOT approach against a human-labeled data set. In order to encode each text in the data set by a d -dimensional vector x  X  R d , we first remove all the stop words and then select the top d frequency terms appearing in the data set to construct the in-dex term space. Our experiments are intended to address the following questions:(1) whether uti-lizing the hierarchical relationships among labels help to improve the accuracy of the classification? (2) whether the introduction of separately learn-ing threshold for each classifier help to improve the accuracy of the classification? (3) how does the corrective step  X  impact the performance of the proposed approach?(4)how does the dimensional-ity d of index terms space impact the proposed ap-proach X  X  computing efficiency and accuracy? 4.1 Data Set Preparation The data set contains 1446 snippets of customer reviews on digital cameras that are collected from a customer review website 4 . We manually con-struct a SOT for the product of digital cameras. The constructed SOT (e.g., Fig. 1) contains 105 nodes that include 35 non-leaf nodes representing attributes of the digital camera and 70 leaf nodes representing associated sentiments with attribute nodes. Then we label all the snippets with corre-sponding labels of nodes in the constructed SOT complying with the rule that a target text is to be labeled with a node only if its parent attribute node is labeled with the target text. We randomly divide the labeled data set into five folds so that each fold at least contains one example snippets labeled by each node in the SOT. For each experiment set-ting, we run 5 experiments to perform cross-fold evaluation by randomly picking three folds as the training set and the other two folds as the testing set. All the testing results are averages over 5 run-ning of experiments. 4.2 Evaluation Metrics Since the proposed HL-SOT approach is a hier-archical classification process, we use three clas-sic loss functions for measuring classification per-formance. They are the One-error Loss (O-Loss) function, the Symmetric Loss (S-Loss) function, and the Hierarchical Loss (H-Loss) function:  X  One-error loss (O-Loss) function is defined  X  Symmetric loss (S-Loss) function is defined  X  Hierarchical loss (H-Loss) function is defined Unlike the O-Loss function and the S-Loss func-tion, the H-Loss function captures the intuition that loss should only be charged on a node when-ever a classification mistake is made on a node of SOT but no more should be charged for any ad-ditional mistake occurring in the subtree of that node. It measures the discrepancy between the prediction labels and the true labels with consider-ation on the SOT structure defined over the labels. In our experiments, the recorded loss function val-ues for each experiment running are computed by averaging the loss function values of each testing snippets in the testing set. 4.3 Performance Comparison In order to answer the questions (1), (2) in the beginning of this section, we compare our HL-SOT approach with the following two baseline ap-proaches:  X  HL-flat: The HL-flat approach involves an al- X  H-RLS: The H-RLS approach is imple-Experiments are conducted on the performance comparison between the proposed HL-SOT ap-proach with HL-flat approach and the H-RLS ap-proach. The dimensionality d of the index term space is set to be 110 and 220. The corrective step  X  is set to be 0.005. The experimental results are summarized in Table 1. From Table 1, we can ob-serve that the HL-SOT approach generally beats the H-RLS approach and HL-flat approach on O-Loss, S-Loss, and H-Loss respectively. The H-RLS performs worse than the HL-flat and the HL-SOT, which indicates that the introduction of sepa-rately learning threshold for each classifier did im-prove the accuracy of the classification. The HL-SOT approach performs better than the HL-flat, which demonstrates the effectiveness of utilizing the hierarchical relationships among labels. 4.4 Impact of Corrective Step  X  The parameter  X  in the proposed HL-SOT ap-proach controls the corrective step of the classi-fiers X  thresholds when any mistake is observed in the training process. If the corrective step  X  is set too large, it might cause the algorithm to be too sensitive to each observed mistake. On the con-trary, if the corrective step is set too small, it might cause the algorithm not sensitive enough to the ob-served mistakes. Hence, the corrective step  X  is a factor that might impact the performance of the proposed approach. Fig. 2 demonstrates the im-pact of  X  on O-Loss, S-Loss, and H-Loss. The dimensionality of index term space d is set to be 110 and 220. The value of  X  is set to vary from 0.001 to 0.1 with each step of 0.001. Fig. 2 shows that the parameter  X  impacts the classification per-formance significantly. As the value of  X  increase, the O-Loss, S-Loss, and H-Loss generally increase (performance decrease). In Fig. 2c it is obviously detected that the H-Loss decreases a little (perfor-mance increase) at first before it increases (perfor-mance decrease) with further increase of the value of  X  . This indicates that a finer-grained value of  X  will not necessarily result in a better performance on the H-loss. However, a fine-grained corrective step generally makes a better performance than a coarse-grained corrective step. 4.5 Impact of Dimensionality d of Index In the proposed HL-SOT approach, the dimen-sionality d of the index term space controls the number of terms to be indexed. If d is set too small, important useful terms will be missed that will limit the performance of the approach. However, if d is set too large, the computing ef-ficiency will be decreased. Fig. 3 shows the im-pacts of the parameter d respectively on O-Loss, S-Loss, and H-Loss, where d varies from 50 to 300 with each step of 10 and the  X  is set to be 0.005. From Fig. 3, we observe that as the d increases the O-Loss, S-Loss, and H-Loss generally decrease (performance increase). This means that when more terms are indexed better performance can be achieved by the HL-SOT approach. However, considering the computing efficiency impacted by d , Fig. 4 shows that the computational complex-ity of our approach is non-linear increased with d  X  X  growing, which indicates that indexing more terms will improve the accuracy of our proposed approach although this is paid by decreasing the computing efficiency.
In this paper, we propose a novel and effec-tive approach to sentiment analysis on product re-views. In our proposed HL-SOT approach, we de-fine SOT to formulate the knowledge of hierarchi-cal relationships among a product X  X  attributes and tackle the problem of sentiment analysis in a hier-archical classification process with the proposed algorithm. The empirical analysis on a human-labeled data set demonstrates the promising re-sults of our proposed approach. The performance comparison shows that the proposed HL-SOT ap-proach outperforms two baselines: the HL-flat and the H-RLS approach. This confirms two intuitive motivations based on which our approach is pro-posed: 1) separately learning threshold values for each classifier improve the classification accuracy; 2) knowledge of hierarchical relationships of la-bels improve the approach X  X  performance. The ex-periments on analyzing the impact of parameter  X  indicate that a fine-grained corrective step gen-erally makes a better performance than a coarse-grained corrective step. The experiments on an-alyzing the impact of the dimensionality d show that indexing more terms will improve the accu-racy of our proposed approach while the comput-ing efficiency will be greatly decreased.

The focus of this paper is on analyzing review texts of one product. However, the framework of our proposed approach can be generalized to deal with a mix of review texts of more than one prod-ucts. In this generalization for sentiment analysis on multiple products reviews, a  X  X ig X  SOT is con-structed and the SOT for each product reviews is a sub-tree of the  X  X ig X  SOT. The sentiment analy-sis on multiple products reviews can be performed the same way the HL-SOT approach is applied on single product reviews and can be tackled in a hier-archical classification process with the  X  X ig X  SOT.
This paper is motivated by the fact that the relationships among a product X  X  attributes could be a useful knowledge for mining product review texts. The SOT is defined to formulate this knowl-edge in the proposed approach. However, what attributes to be included in a product X  X  SOT and how to structure these attributes in the SOT is an effort of human beings. The sizes and structures of SOTs constructed by different individuals may vary. How the classification performance will be affected by variances of the generated SOTs is worthy of study. In addition, an automatic method to learn a product X  X  attributes and the structure of SOT from existing product review texts will greatly benefit the efficiency of the proposed ap-proach. We plan to investigate on these issues in our future work.
 The authors would like to thank the anonymous reviewers for many helpful comments on the manuscript. This work is funded by the Research Council of Norway under the VERDIKT research programme (Project No.: 183337).

