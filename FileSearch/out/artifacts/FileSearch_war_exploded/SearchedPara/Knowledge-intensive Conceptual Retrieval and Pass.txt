 This paper presents a study of incorporating domain-specific knowledge (i.e., information about concepts and relationships between concepts in a certain domai n) in an information retrieval (IR) system to improve its effectiveness in retrieving biomedical literature. The effects of different types of domain-specific knowledge in performance contri bution are examined. Based on the TREC platform, we show th at appropriate use of domain-specific knowledge in a proposed conceptual retrieval model yields about 23% improvement ove r the best reported result in passage retrieval in the Genomics Track of TREC 2006. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  retrieval models, query formulation, information filtering. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing  X  thesauruses. Algorithms, Performance, Experimentation. Document Retrieval, Passage Ex traction, Biomedical Documents biologists, PubMed, an online serv ice of U.S. National Library of Medicine (NLM), is the most co mmonly used tool for searching the biomedical literature. PubMed allows for keyword search by using Boolean operators. For exampl e, if one desires documents on the use of the drug propanolol in the disease hypertension, a typical PubMed query might be  X  X ropanolol AND hypertension X , which will return all the docum ents having the two keywords. Keyword search in PubMed is effective if the query is well-crafted by the users using their expertise. However, information needs of biologists, in some cases, are expressed as complex questions [8][9], which PubMed is not desi gned to handle. While NLM does maintain an experimental tool for free-text queries [6], it is still based on PubMed keyword search. The Genomics track of the 2006 Text REtrieval Conference (TREC) provides a common platfo rm to assess the methods and techniques proposed by various gr oups for biomedical information retrieval. The queries were collected from real biologists and they are expressed as complex questions , such as  X  X ow do mutations in the Huntingtin gene affect Hun tington X  X  disease? X . The document collection contains 162,259 Highw ire full-text documents in HTML format. Systems from participating groups are expected to find relevant passages within the full-text documents. A passage is defined as any span of text that does not include the HTML paragraph tag (i.e., &lt;P&gt; or &lt;/P&gt;). We approached the problem by utilizing domain-specific knowledge in a conceptual retr ieval model. Domain-specific knowledge, in this paper, refers to information about concepts and relationships between concepts in a certain domain. We assume that appropriate use of domain-specific knowledge might improve the effectiveness of retrieval. For example, given a query  X  X hat is the role of gene PRNP in the Mad Cow Disease? X , expanding the gene symbol  X  X RNP X  with its synonyms  X  X rp X ,  X  X rPSc X , and  X  X rion protein X , more relevant documents might be retrieved. PubMed and many other biomedical systems [8][9][10][13] also make use of domain-specific know ledge to improve retrieval effectiveness. Intuitively, retrieval on the level of concepts should outperform  X  X ag-of-words X  approaches, sin ce the semantic relationships among words in a concept are utilized. In some recent studies [13][15], positive results have been reported for this hypothesis. In this paper, concepts are entry terms of the ontology Medical Subject Headings (MeSH), a cont rolled vocabulary maintained by NLM for indexing biomedical litera ture, or gene symbols in the Entrez gene database also from NL M. A concept could be a word, such as the gene symbol  X  X RNP X , or a phrase, such as  X  X ad cow diseases X . In the conceptual re trieval model presented in this paper, the similarity between a query and a document is measured on both concept and word levels. This paper makes two contributions: 1. We propose a conceptual approach to utilize domain-specific 2. We examine the effects of utilizing concepts and of different This paper is organized as follows : problem statement is given in the next section. The techniques are introduced in section 3. In section 4, we present the experimental results. Related works are given in section 5 and finally, we conclude the paper in section 6. We describe the queries, docum ent collection and the system output in this section. The query set used in the Genom ics track of TREC 2006 consists of 28 questions collected from real biologists. As described in [8], these questions all have th e following general format: where a biological object might be a gene, protein, or gene mutation and a biological process can be a physiological process or disease. A question might i nvolve multiple biological objects (m) and multiple biological proce sses (n). These questions were derived from four templates (Table 2). Table 2 Query templates and examples in the Genomics track of TREC 2006 
What is the role of gene in disease? 
What effect does gene have on biological process? 
How do genes interact in organ function? 
How does a mutation in gene influence biological process? Features of the queries : 1) They are different from the typical Web queries and the PubMed queries, both of which usually consist of 1 to 3 keywords; 2) They are generated from structural templates which can be used by a system to identify the query components, the biological object or process. The document collection contains 162,259 Highwire full-text documents in HTML format. The output of the system is a list of passages ranked according to their similarities with the query. A passage is defined as any span of text that does not include the HTML paragraph tag (i.e., &lt;P&gt; or &lt;/P&gt;). A passage could be a part of a sentence, a sentence, a set of consecutive sentences or a paragra ph (i.e., the whole span of text that are inside of &lt;P&gt; and &lt;/P&gt; HTML tags). This is a passage-level information retrieval problem with the attempt to put biologists in contex ts where relevant information is provided. We approached the problem by first retrieving the top-k most relevant paragraphs, then extracting passages from these paragraphs, and finally ranking the passages. In this process, we employed several techniques and methods, which will be introduced in this section. Fi rst, we give two definitions: ontology, or 2) a gene symbol in the Entrez gene database. This definition of concept can be generalized to include other biomedical dictionary terms. Semantic Network of the Unif ied Medical Language System (UMLS) [14]. The current release of the UMLS Semantic Network contains 135 semantic types such as  X  X isease or Syndrome X . Each entry term in the MeSH ontology is assigned one or more semantic types. Each gene symbol in the Entrez gene database maps to the semantic type  X  X ene or Genome X . In addition, these semantic types are linked by 54 relationshi ps. For example,  X  X ntibiotic X  prevents  X  X isease or Syndrome X . Th ese relationships among semantic types represent gene ral biomedical knowledge. We utilized these semantic types and their relationships to identify related concepts. The rest of this section is organi zed as follows: in section 3.1, we explain how the concepts are identified within a query. In section 3.2, we specify five different types of domain-specific knowledge and introduce how they are compiled. In section 3.3, we present our conceptual IR model. Fina lly, our strategy for passage extraction is described in section 3.4. A concept, defined in Definition 3.1 , is a gene symbol or a MeSH term. We make use of the query templates to identify gene symbols. For example, the query  X  X ow do HMG and HMGB1 interact in hepatitis? X  is derived from the template  X  X ow do genes interact in organ function? X . In this case,  X  X MG X  and  X  X MGB1 X  will be identified as gene symbols. In cases where the query templates are not provided, pr ograms for recognition of gene symbols within texts are needed. We use the query translation functionality of PubMed to extract MeSH terms in a query. This is done by submitting the whole query to PubMed, which will then re turn a file in which the MeSH terms in the query are labeled. In Table 3.1, three MeSH terms within the query  X  X hat is the role of gene PRNP in the Mad cow disease? X  are found in the PubMed translation: "encephalopathy, bovine spongiform" for  X  X ad cow disease X ,  X  X enes X  for  X  X ene X , and  X  X ole X  for  X  X ole X . Table 3.1 The PubMed translation of the query "What is the role of gene PRNP in the Mad cow disease?".
 Mad cow disease role "role"[MeSH Terms] OR role[Text Word] In this paper, domain-specific knowledge refers to information about concepts and their relations hips in a certain domain. We used five types of domain-speci fic knowledge in the domain of genomics: Type 1. Synonyms (terms listed in the thesauruses that refer to Type 2. Hypernyms (more generic terms, one level only) Type 3. Hyponyms (more specific terms, one level only) Type 4. Lexical variants (different forms of the same concept, Type 5. Implicitly related concepts (terms that are semantically Knowledge of type 1-3 is retrieved from the following two thesauruses: 1) MeSH, a controlled vocabulary maintained by NLM for indexing biomedical literature. The 2007 version of MeSH contains information about 190,000 concepts. These concepts are organized in a tree hierarchy; 2) Entrez Gene, one of the most widely used searchable databases of genes. The current version of Entrez Gene contains information about 1.7 million genes. It does not have a hierar chy. Only synonyms are retrieved from Entrez Gene. The compiling of type 4-5 knowledge is introduced in section 3.2.1 and 3.2.2, respectively. Lexical variants of gene symbols New gene symbols and their le xical variants are regularly introduced into the biomedical literature [7]. However, many reference databases, such as UM LS and Entrez Gene, may not be able to keep track of all this kind of variants. For example, for the gene symbol "NF-kappa B", at leas t 5 different lexical variants can be found in the biomedical literature: "NF-kappaB", "NFkappaB", "NFkappa B", "NF-kB", and "NFkB", three of which are not in the current UMLS and two not in the Entrez Gene. [3][21] have shown that expanding gene symbols with their lexical variants improved the retrieval effectiveness of their biomedical IR systems. In our system, we employed the following two strategies to retrieve lexical variants of gene symbols. Strategy I: This strategy is to automatically generate lexical variants according to a set of manually crafted heuristics [3][21]. For example, given a gene symbol  X  X LA2 X , a variant  X  X LAII X  is generated according to the heuristic that Roman numerals and Arabic numerals are convertible when naming gene symbols. Another variant,  X  X LA 2 X , is al so generated since a hyphen or a space could be inserted at the transition between alphabetic and numerical characters in a gene symbol. Strategy II: This strategy is to retrieve lexical variants from an abbreviation database. ADAM [22] is an abbreviation database which covers frequently used abbr eviations and their definitions (or long-forms) within MEDLINE, the authoritative repository of citations from the biomedical literature maintained by the NLM. Given a query  X  X ow does nucleos ide diphosphate kinase (NM23) abbreviation  X  X M23 X  and its l ong-form  X  X ucleoside diphosphate kinase X  using the abbreviation identification program from [4]. Searching the long-form  X  X ucle oside diphosphate kinase X  in ADAM, other abbreviations, such as  X  X DPK X  or  X  X DK X , are retrieved. These abbreviations are considered as the lexical variants of  X  X M23 X . Lexical variants of MeSH concepts ADAM is used to obtain the lexical variants of MeSH concepts as well. All the abbreviations of a MeSH concept in ADAM are considered as lexical variants to each other. In addition, those long-forms that share the same abbreviation with the MeSH concept and are different by an edit distance of 1 or 2 are also considered as its lexical variants. As an example, "human papilloma viruses" and "human papillomaviruses" have the same abbreviation  X  X PV X  in ADAM and their edit distance is 1. Thus they are considered as lexical variants to each other. The edit distance between two strings is measured by the minimum number of insertions, deletions, and s ubstitutions of a single character required to transform one string into the other [12]. Motivation: In some cases, there are few documents in the literature that directly answer a gi ven query. In this situation, those documents that implicitly answer their questions or provide supporting information would be very helpful. For example, there are few documents in PubMed that directly answer the query "What is the role of the genes HNF4 and COUP-tf I in the suppression in the function of the liver?". However, there exist some documents about the role of "HNF4" and "COUP-tf I" in regulating "hepatitis B virus" transcri ption. It is very likely that the biologists would be interested in these documents because "hepatitis B virus" is known as a virus that could cause serious damage to the function of liver. In the given example, "hepatitis B virus" is not a synonym, hypernym, hyponym, nor a lexical variant query concepts according to the UMLS Semantic Network. We call this type of concepts  X  X mp licitly related concepts X  of the query. This notion is similar to the  X  B -term X  used in [19] for generation. The difference is that we utilize the semantic relationships among query concep ts to exclusively focus on concepts of certain semantic types. A query q in format (1) of section 2 can be represented by where A is the set of biological objects and C is the set of biological processes. Those concepts that are semantically related to both A and C according to the UMLS Semantic Network are considered as the implicitly relate d concepts of the query. In the above example, A = { X  X NF4 X ,  X  X OUP-tf I X  X , C = { X  X unction of liver X  X , and "hepatitis B virus" is one of the implicitly related concepts. We make use of the MEDLINE database to extract the implicitly related concepts. The 2006 vers ion of MEDLINE database contains citations (i.e., abstracts, titles, and etc.) of over 15 million biomedical articles. Each document in MEDLINE is manually indexed by a list of MeSH terms to describe the topics covered by that document. Implicitly related concepts are extracted and ranked in the following steps: Step 1. Let list_ A be the set of MeSH terms that are 1) used for indexing those MEDLINE citations having A , and 2) semantically related to A according to the UMLS Semantic Network. Similarly, list_ C is created for C . Concepts in B = list_ A considered as implicitly rela ted concepts of the query. Step 2. For each concept b  X  B , compute the association between b and A using the mutual information measure [5]: where P( x ) = n / N , n is the number of MEDLINE citations having x and N is the size of MEDLINE. A large value for I ( b, A ) means that b and A co-occur much more often than being independent. I ( b, C ) is computed similarly. Step 3. Let r ( b ) = ( I ( b , A ), I ( b , C )), for b  X  B . Given b we say r ( b 1 )  X  r ( b 2 ) if I ( b 1 , A )  X  I ( b Then the association between b and the query q is measured by: The numerator in Formula 2 is the number of the concepts in B The denominator is the num ber of the concepts in B that are associated with both A and C equally with or more than b . Figure 3.2.2 shows the top 4 implicitly related concepts for the sample query. Figure 3.2.2 Top 4 implicitly related concepts for the query "How do interactions between HNF4 and COUP-TF1 suppress liver function?".
 In Figure 3.2.2, the top 4 implicitly related concepts are all highly  X  X epatoblastoma X  is a malignant liver neoplasm occurring in young children; the vast majority of  X  X luconeogenesis X  takes place in the liver; and  X  X epatitis B virus X  is a virus that could cause serious damage to the function of liver. The top-k ranked concepts in B are used for query expansion: if concept of A . A document having b but not A will receive a partial We now discuss our conceptual IR model. We first give the basic conceptual IR model in section 3.3.1. Then we explain how the domain-specific knowledge is inco rporated in the model using query expansion in section 3.3.2. A pseudo-feedback strategy is improve the ranking by avoiding incorrect match of abbreviations. Given a query q and a document d , our model measures two similarities, concept similarity and word similarity: Two vectors are derived from a query q , where v 1 is a vector of concepts describing the biological object(s) and v 2 is a vector of concepts desc ribing the biological process(es). The weight of v i is then measured by: where v is a vector that contains a subset of concepts in v the number of documents ha ving all the concepts in v . The concept similarity between q and d is then computed by where  X  i is a parameter to indicate the completeness of v document d has covered.  X  i is measured by: where idf c is the inverse document frequency of concept c . An example: suppose we have a query  X  X ow does Nurr-77 delete T cells before they migrate to the spleen or lymph nodes and how does this impact autoimmunity? X . After identifying the concepts in the query, we have: combinations of concepts are as follows: The weight of v i is then computed by (note that there does not exist a document having all the concepts in v 2 ): Now suppose a document d contains concepts  X  X urr-77 X , 'T cells', 'spleen', and 'lymph nodes', but not  X  X utoimmunity X , then the value of parameter  X  i is computed as follows:  X   X  The similarity between q and d on the word level is computed using Okapi [17]: where N is the size of the document collection; n is the number of documents containing w ; K = k 1  X  ((1-b )+ b  X  dl / avdl ) and k HNF4 and COUP-tf I b =0.75 are constants. dl is the document length of d and avdl is the average document length; tf is the term frequency of w within d . d will be ranked higher than d 2 , with respect to the same query q , if either 1) 12 (, ) (, ) s im q d sim q d &gt; or 2) 12 12 and (,) (,) (,) (,) s im q d sim q d sim q d sim q d =&gt; This conceptual IR model emphasizes the similarity on the concept level. A similar model but app lied to non-biomedical domain has been given in [15]. Given a concept c , a vector u is derived by incorporating its domain-specific knowledge: where u 1 is a vector of its synonyms, hyponyms, and lexical variants; u 2 is a vector of its hypernyms; and u implicitly related concepts. An occurrence of any term in u be counted as an occurrence of c . idf c in Formula 3 is updated as: 
D is the set of documents having c or any term in weight that a document d receives from u is given by: where w t =  X  . c idf  X  The weighting factor  X  is an empirical tuning parameter determined as: 1.  X  = 1 if t is the original concept, its synonym, its hyponym, or 2.  X  = 0.95 if t is a hypernym; Pseudo-feedback is a technique commonly used to improve retrieval performance by adding new terms into the original query. We used a modified pseudo-feedback strategy described in [2]. Step 1. Let C be the set of concepts in the top 15 ranked documents. For each concept c in C , compute the similarity between c and the query q , the computation of sim ( q,c ) can be found in [2]. Step 2. The top-k ranked concepts by sim ( q,c ) are selected. Step 3. Associate each selected concept c' with the concept c q that 1) has the same semantic type as c' , and 2) is most related to c' among all the concepts in q . The association between c' and c is computed by: where P( x ) = n / N , n is the number of documents having x and N is the size of the document collection. A document having c' but not c receives a weight given by: (0.5  X  ( k -i +1)/ k ) , position of c' in the ranking of step 2. Some gene symbols are very short and thus ambiguous. For example, the gene symbol  X  X PC  X  could be the abbreviation for many non-gene long-forms, such as  X  X ir pollution control X ,  X  X erobic plate count X , or  X  X rgon plas ma coagulation X . This step is to avoid incorrect match of abbreviations in the top ranked documents. Given an abbreviation X with the long-form L in the query, we scan the top-k ranked ( k =1000) documents and when a document is found with X , we compare L with all the long-forms of X in that the edit distance between L and the long-form of X in that document is 1 or 2), then the concept similarity of X is subtracted. The goal of passage extraction is to highlight the most relevant fragments of text in paragraphs. A passage is defined as any span of text that does not include the HTML paragraph tag (i.e., &lt;P&gt; or &lt;/P&gt;). A passage c ould be a part of a sentence, a sentence, a set of consecutive sentences or a paragra ph (i.e., the whole span of text that are inside of &lt;P&gt; and &lt;/P&gt; HT ML tags). It is also possible to have more than one relevant pa ssage in a single paragraph. Our strategy for passage extraction a ssumes that the optimal passage(s) in a paragraph should have all th e query concepts that the whole paragraph has. Also they shoul d have higher density of query concepts than other fragments of text in the paragraph. Suppose we have a query q and a paragraph p represented by a sequence of sentences 12 ... . n psss = Let C be the set of concepts in q that occur in p and S =  X  . Step 1. For each sequence of consecutive sentences 1 ... , i  X  j  X  n , let S = S 1 {...} ii j s ss +  X  if 1 ... and condition 2 requires 1 ... ii j s ss + be the minimal.
 remove those sequences of sentences in S that have lower density of query concepts. then do Repeat this step until for every two sequences of consecutive sentences in S , condition (5) does not apply. This step is to merge those sequences of sentences in S that are adjacent or overlapped. Finally the remaining sequences of sentences in S are returned as the optimal passages in the paragraph p with respect to the query. The evaluation of our techniques a nd the experimental results are given in this section. We first de scribe the datasets and evaluation metrics used in our experiment s and then present the results. Our experiments were performed on the platform of the Genomics track of TREC 2006. The docum ent collection contains 162,259 full-text documents from 49 Highwir e biomedical journals. The set of queries consists of 28 queries collected from real biologists. The performance is measured on th ree different levels (passage, aspect, and document) to provide better insight on how the question is answered from different perspectives. Passage MAP: As described in [8], this is a character-based precision calculated as follows:  X  X t each relevant retrieved passage, precision will be computed as the fraction of characters overlapping with the gold standard passages di vided by the total number of characters included in all nominated passages from this system for the topic up until that point. Similar to regular MAP, relevant passages that were not retrieved will be added into the calculation as well, with precision set to 0 for relevant pa ssages not retrieved. Then the mean of these average precisions over all topics will be calculated to compute the mean average passage precision X . Aspect MAP : A question could be addressed from di fferent aspects. For example, the question  X  X hat is the role of gene PRNP in the Mad cow disease? X  could be answered from aspects like  X  X iagnosis X ,  X  X eurologic manifestations X , or  X  X rions/Genetics X . This measure indicates how comprehensive the question is answered. Document MAP : This is the standard IR meas ure. The precision is measured at every point where a relevant document is obtained and then averaged over all relevant documents to obtain the average average precision for all queries is the MAP of that IR system. The output of the system is a list of passages ranked according to their similarities with the query. The performances on the three levels are then calculated base d on the ranking of the passages. The Wilcoxon signed-rank test was employed to determine the statistical significance of the results. In the tables of the following sections, statistically significant improvements (at the 5% level) are marked with an asterisk. The initial baseline was established using word similarity only computed by the Okapi (Formula 4). Another run based on our basic conceptual IR model was performed without using query expansion, pseudo-feedback, or abbreviation correction. The experimental result is shown in Ta ble 4.2.1. Our basic conceptual IR model significantly outperforms the Okapi on all three levels, which suggests that, although it re quires additional efforts to identify concepts, retrieval on the concept level can achieve substantial improvements over purely term-based retrieval model. A series of experiments were performed to examine how each type of domain-specific knowledge c ontributes to the retrieval performance. A new baseline was established using the basic conceptual IR model without incorporating any type of domain-specific knowledge. Then five r uns were conducted by adding each individual type of domain-specific knowledge. We also conducted a run by adding all ty pes of domain-specific knowledge. Results of these experiments are shown in Table 4.2.2. knowledge improved the performance in passage retrieval. The biggest improvement comes from the lexical variants, which is consistent with the result reported in [3]. This result also indicates that biologists are likely to use different variants of the same concept according to their own writing preferences and these variants might not be collected in the existing biomedical thesauruses. It also suggests that the biomedical IR systems can benefit from the domain-specific knowledge extracted from the literature by text mining systems. Hypernyms, hyponyms, and implicitly related concepts provided similar degrees of improvement. The overall performance is an accumulative result of adding different types of domain-specific knowledge and it is better than any i ndividual addition. It is clearly shown that the performance is significantly improved (107% on passage level, 63.1% on aspect level, and 49.6% on document level) when the domain-specific knowledge is appropriately incorporated. Although it is not explicitly shown in Table 4.2.3, different types of domain-speci fic knowledge affect different subsets of queries. More specifica lly, each of these types (with the exception of  X  X he lexical variants X  which affects a large number of queries) affects only a few queries. But for those affected queries, accumulative improvement is very significant. Using the  X  X aseline+All X  in Table 4.2.2 as a new baseline, the contribution of abbreviation corr ection and pseudo-feedback is given in Table 4.2.3. There is little improvement by avoiding incorrect matching of abbrev iations. The pseudo-feedback contributed about 4.6% improveme nt in passage retrieval. We compared our result with the results reported in the Genomics track of TREC 2006 [8] on the conditions that 1) systems are automatic systems and 2) passages are extracted from paragraphs. The performance of our system relative to the best reported results is shown in Table 4.2.4 (in TREC 2006, some systems returned the whole paragraphs as passages. As a cons equence, excellent retrieval results were obtained on document and aspect levels at the expense of performance on the passage level. We do not include the results of such systems here). Table 4.2.4 Performance compared with best-reported results . Best reported re sults 0.1486 0.3492 0.5320 Our results 0.1823 0.3811 0.5391 Improvement 22.68% 9.14% 1.33% levels (passage, aspect, and docum ent) are from different systems. better than the best reported resu lt by 22.68% in passage retrieval and at the same time, 9.14% better in aspect retrieval, and 1.33% better in document retrieval (Since the average precision of each individual query was not reported, we can not apply the Wilcoxon signed-rank test to calculate the significance of difference between our performance and the best reported result.). A separate experiment has been done using a second testbed, the Ad Hoc Task of TREC Genomics 2005, to evaluate our knowledge-intensive conceptual IR model for document retrieval of biomedical literature. The overall performance in terms of MAP is 35.50%, which is about 22.92% above the best reported result [9]. Notice that the performance was only measured on the document level for the Ad Hoc Task of TREC Genomics 2005. Many studies used manually-cra fted thesauruses or knowledge databases created by text mini ng systems to improve retrieval effectiveness based on either word-statistical retrieval systems or conceptual retrieval systems. Metathesaurus. Based on a word-statistical retrieval system, [11] used definitions and different type s of thesaurus relationships for query expansion and a deteriorat ed performance was reported. [1] expanded queries with phrases and UMLS concepts determined by the MetaMap, a program which ma ps biomedical text to UMLS concepts, and no significant impr ovement was shown. We used MeSH, Entrez gene, and other non-thesaurus knowledge resources such as an abbreviation database for query expansion. A critical difference between our work and those in [11][1] is that our retrieval model is based on con cepts, not on individual words. evaluate methods and techniques proposed by various groups for biomedical information retrieval. As summarized in [8][9][10], many groups utilized domain-specific knowledge to improve retrieval effectiveness. Among these groups, [3] assessed both thesaurus-based knowledge, such as gene information, and non thesaurus-based knowledge, such as lexical variants of gene symbols, for query expansion. They have shown that query expansion with acronyms and lexi cal variants of gene symbols produced the biggest improvement, whereas, the query expansion with gene information from gene databases deteriorated the performance. [21] used a similar approach for generating lexical variants of gene symbols and reported significant improvements. Our system utilized more types of domain-specific knowledge, including hyponyms, hypernyms and implicitly related concepts. In addition, under the conceptual retrieval framework, we examined more comprehensively the effects of different types of domain-specific knowledge in performance contribution. their lexical relationships devel oped by Princeton University, for query expansion in the non-biomed ical domain. In their studies, queries were expanded using the lexi cal semantic relations such as synonyms, hypernyms, or hyponyms. Little benefit has been shown in [20]. This has been due to ambiguity of the query terms which have different meanings in different contexts. When these synonyms having multiple meanings are added to the query, substantial irrelevant documents ar e retrieved. In the biomedical domain, this kind of ambiguity of query terms is relatively less frequent, because, although the abbreviations are highly ambiguous, general biomedical c oncepts usually have only one meaning in the thesaurus, such as UMLS, whereas a term in WordNet usually have multiple meanings (represented as synsets in WordNet). Besides, we have implemented a post-ranking step to reduce the number of incorrect matches of abbreviations, which will hopefully decrease the negative impact caused by the abbreviation ambiguity. Besides, we have implemented a post-ranking step to reduce the number of incorrect matches of abbreviations, which will hopefully decrease the negative impact caused by the abbreviation ambiguity. The retrieval model in [15] emphasized the similarity between a query and a document on the phrase level assuming that phrases are more important than individual words when retr ieving documents. Although the assumption is similar, our conceptual model is based on the biomedical concepts, not phrases. document retrieval of clinical medicine. They have shown that appropriate use of semantic knowledge in a conceptual retrieval framework can yield substantial improvements. Although the retrieval model is similar, we made a study in the domain of genomics, in which the problem structure and task knowledge is not as well-defined as in the domain of clinical medicine [18]. Also, our similarity function is very different from that in [13]. important ways: First, we pres ent a case study of conceptual retrieval in the domain of genomics, where many knowledge resources can be used to improve the performance of biomedical IR systems. Second, we have studied more types of domain-specific knowledge than previous re searchers and carried out more comprehensive experiments to look into the effects of different types of domain-specific knowledge in performance contribution. Third, although some of the techni ques seem similar to previously published ones, they are actually quite different in details. For example, in our pseudo-feedback pr ocess, we require that the unit of feedback is a concept and the concept has to be of the same semantic type as a query concept. This is to ensure that our conceptual model of retrieval can be applied. As another example, the way in which implicitly related concepts are extracted in this paper is significantly different from that given in [19]. Finally, our conceptual IR model is actually based on complex concepts because some biomedical meanings , such as biological processes, are represented by multiple simple concepts. This paper proposed a conceptu al approach to utilize domain-specific knowledge in an IR system to improve its effectiveness in retrieving biomedical literature. We specified five different types of domain-specific knowledge (i.e., synonyms, hyponyms, hypernyms, lexical variants, and implicitly related concepts) and examined their effects in performance contribution. We also evaluated other two techniques, pseudo-feedback and abbreviation correction. Experimental results have shown that appropriate use of domain-specific knowledge in a conceptual IR model yields significant improvements (23%) in passage retrieval over the best known results. In our future work, we will explore the use of other existing knowledge resources, such as UMLS and the Wikipedia, and evaluate techniques such as disambiguation of gene symbols for improving retrieval effectiveness. The application of our conceptual IR model in other domai ns such as clinical medicine will be investigated. We thank the anonymous SIGIR 2007 reviewers for their useful comments. We would like to thank Dr. David Featherstone for his insightful discussion. [1] Aronson A.R., Rindflesch T.C. Query expansion using the [2] Baeza-Yates R., Ribeiro-Neto B. Modern Information [3] Buttcher S., Clarke C.L.A., Cormack G.V. Domain-specific [4] Chang J.T., Schutze H., Altman R.B. Creating an online [5] Church K.W., Hanks P. Word association norms, mutual [6] Fontelo P., Liu F., Ackerman M. askMEDLINE: a free-text, [7] Fukuda K., Tamura A., Tsunoda T., Takagi T. Toward [8] Hersh W.R., and etc. TREC 2006 Genomics Track Overview. [9] Hersh W.R., and etc. TREC 2005 Genomics Track Overview. [10] Hersh W.R., and etc. TREC 2004 Genomics Track Overview. [11] Hersh W.R., Price S., Donohoe L. Assessing thesaurus-based [12] Levenshtein, V. Binary codes capable of correcting deletions, [13] Lin J., Demner-Fushman D. The Role of Knowledge in [14] Lindberg D., Humphreys B., and McCray A. The Unified [15] Liu S., Liu F., Yu C., and Meng W.Y. An Effective [16] Proux D., Rechenmann F., Julliard L., Pillet V.V., Jacq B. [17] Robertson S.E., Walker S. Okapi/Keenbow at TREC-8. NIST [18] Sackett D.L., and etc. Evidence-Based Medicine: How to [19] Swanson,D.R., Smalheiser,N.R. An interactive system for [20] Voorhees E. Query expans ion using lexical-semantic [21] Zhong M., Huang X.J. Concep t-based biomedical text [22] Zhou W., Torvik V.I., Smalheiser N.R. ADAM: Another 
