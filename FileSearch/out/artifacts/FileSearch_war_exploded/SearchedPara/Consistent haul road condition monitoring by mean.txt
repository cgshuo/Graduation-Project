 1. Introduction
Various road maintenance policies, such as routine, periodic and urgent maintenance ( Burningham and Stankevich, 2005 ) have been investigated towards the goal of minimising both road and vehicle maintenance costs. To support maintenance decisions many road agencies collect data which are representative of the road condition, such as road surface monitoring (RSM) which is based on laser technology, falling weight deflectometer (FWD) measurements, and ground penetrating radar (GPR) measure-the pavement condition index (PCI) which requires manual surveying of roadways, and the present serviceability index (PSI) have also widely been investigated as indicators of the condition of roads ( Ruotoistenm  X  aki and Sepp  X  al  X  a, 2007 ).
The aforementioned approaches are often expensive, time consuming or subjective so that they are not well suited to the frequent monitoring of haul roads. It has subsequently been proposed that vibration response, as measured directly on a vehicle, may be used to assess the condition of a road.
Thompson et al. (2003) investigate the use of on-board diagnostic data collection systems in conjunction with GPS coordinates to monitor open cast haul roads on a real-time basis. Based on field experiments they found that dist inct vibration signatures are generated for different road defects. Theoretically these signatures can be used to identify road conditions. However, they also found that certain operating conditions (such as the speed of the vehicle, its acceleration and its payload) affect these vibration signals. Isolated interpretation of the vibration data, without considering the vehicle operating conditions, could result in ambiguous road classification.
Thompson et al. (2003) propose that research should be conducted where artificial neural networks (NNs) are used to account for the effect of different operating conditions on the vehicle response.
Hugo et al. (2008) propose the use of an inverted model of a haul truck to estimate the road profile from the measured response. They implement a seven degree of freedom model, which consists of a set of coupled second order differential equations. These equations describe the interaction betw een the lumped masses, damping coefficients and stiffness constants of the vehicle. The condition of a section of road is estimated by converting its reconstructed road profile to a power spectrum which may then be assessed against the
ISO 8608 road classification standards ( International Organization for Standardization, 1995 ).

Ngwangwa et al. (2010) propose that a NN could be trained to directly model the inverse dynamics of a vehicle. This approach avoids the need to invert the vehicle model, rendering it possible to model the nonlinear characteristics of the vehicle, such as those exhibited by the wheels. This approach avoids the costly requirement to individually characterise vehicle components, by allowing the NN to learn the assembled vehicle characteristics from a set of training data. The training data are generated by measuring the response of the selected vehicle over different road profiles for different operating conditions. The estimated road profile is again classified according to the ISO 8608 standards ( International Organization for Standardization, 1995 ). data to train the models in the aforementioned approaches can limit the practical feasibility of these techniques. The model described by
Hugo et al. requires the characterisation of individual truck compo-nents, such as the suspension struts. The massive scale of these trucksrendersthisprocessbothc omplex and expensive. Similarly the NN models require training data, where either manually classified road defects or measured road profiles must accurately be synchronised with the m easured vehicle response.
 profile, it may be substantially simpler to perform maintenance based on some indication of the strain that a vehicle is subjected to when it traverses a section of road. The International Road Roughness
Experiment ( Sayers et al., 1986 ) comprises a large scale investigation into the feasibility of a variety of possible metrics to serve as an indication of the road roughness. One such vehicle response measure is the international road roughnes s index (IRI) which is based on the cumulative strut displacement of the vehicle ( Sayers et al., 1986 ). The
IRI exhibits a number of desirable characteristics, such as being easy to measure and being fairly well correlated with the actual road condition. It is found that these vehicle response type measures, including the IRI, are generally sensitive to both the road profile and the vehicle operating speed ( Sayers et al., 1986 ). For this reason it is necessary to compare these vehicle response measures a standar-dised speed; the IRI for instance is specified at a constant speed of 80 km/h ( Sayers et al., 1986; Kropa  X  c  X  and Mu  X  c  X  ka, 2005 ). measuring vehicle response on a vehicle which operates in traffic and hence cannot maintain a constant sp eed. They propose to improve the quality of vehicle response measures which are measured under fluctuating speeds by implementing speed calibration equations. It is however noted in the International Road Roughness Experiment ( Sayers et al., 1986 ) that the dependency between the vehicle response and the vehicle speed is not static, but rather depends on the type and roughness of the surface which is traversed. Thi s is because the vehicle responds to the presence of different wavebands and road signatures when operated at different speeds. It is subsequently difficult to implement a single calibration function.
 the underlying condition of the road is considered during the calibration phase. This renders it possible to obtain a dynamic calibration function which adjust itself to the instantaneous nature of the road which the vehicle traverses, hence allowing for more robust calibration.
 utility vehicle at an underground coal mine. A severity metric is defined based on the instantaneous magnitude of the vehicle response as measured on a wheel axle. The dynamic calibration function is implemented by means of Gaussian process regres-sion. The methodology may also be implemented with any of a number of standard regression analysis techniques, such as neural networks and support vector regression. This paper favour the use of Gaussian process regression due to its good generalization properties. The results indicate that the proposed methodology may potentially be of use as a generic, simple and cost effective approach to perform real time road condition monitoring. 2. Metric calibration for consistent road quality evaluation 2.1. Severity metric multiple criteria ( Ruotoistenm  X  aki and Sepp  X  al  X  a, 2007 ). Some criteria which may be considered include how safe the road is, how much wear it causes to a vehicle, and how comfortable it is to drive on. Towards this goal it is reasonable that various types of vehicle response measurements may be used to assess road quality. Since the vehicle response is dependent on the operating conditions, such as the vehicle speed, it is required to calibrate the proposed metrics to a standardised operating condition which will allow for consistent road quality comparison.

The proposed calibration framework discussed in this paper is intended to be generic, and not specific to a selected metric. However, for the presented case study a single metric which is deemed relevant to the continuous monitoring of haul roads is investigated.

An accelerometer is attached to the wheel axle. The position on the wheel axle, which is an un-sprung mass, is selected to ensure good transmissibility. The envelope of the acceleration signal is subsequently computed. This is done by taking the point-wise absolute value of the acceleration signal and then using a low pass filter to remove the high frequency content. The obtained metric is instantaneous and reflect the presence of individual humps. The metric is representative of the magnitude of the acceleration, and thus the force, which is transmitted to the vehicle. The metric is also easy to implement, since it only requires the installation of a single accelerometer. 2.2. Dynamic calibration function
The focus of this paper is the implementation of a dynamic calibration function which adjust itself to the instantaneous nature of the road which the vehicle traverses so that more robust calibration may be performed.

The implemented dynamic calibration function rests on the assumption that if a vehicle traverses a section of road at a measured speed v i so that vehicle response r i is observed, then the combination of these two measurements contains information regarding the underlying condition of that section of road. These two variables may thus be used in some nonlinear manner to adjust the calibration function to better represent the specific section of road. The adjusted calibration function may subse-quently be used to estimate the expected vehicle response r vehicle was to traverse the same section of road at a different (standardised) speed v j . The process where an individual datum point from the continuous measurement is calibrated is presented in Fig. 1 .

Nonlinear regression techniques may be used to learn the proposed calibration functions from training data. It will be shown how the required training data may be obtained in a cost effective manner, without the need for manual classification or profiling of the road surface.
 Various regression techniques such as polynomial, spline or Neural Network (NN) regression analysis may be implemented. The results indicated in this paper are based on Gaussian process regression, since this is the technique which offered the best performance on our data set. Rasmussen (1996) examines a number of case studies where Gaussian process regression gen-eralizes well and occasionally significantly outperforms other regression techniques, especially when limited training data are available. An empirical study by Wang et al. (2008) similarly found one of the main strengths of the Gaussian models to be their ability to generalize well from small data sets. For sake of brevity, and since the aim of this paper is not to compare different regression methodologies, our results from the polynomial and NN regression approaches are not included in this paper. Essen-tially it was found that our fairly small data set, which is subject to significant noise, was well suited to analysis by Gaussian processes. While Gaussian processes regression tends to offer good generalization, it does have the downside of being compu-tationally intensive on larger data sets ( Bishop, 2006 ). For this reason it might be preferable to implement neural network regression if more training data are available. 3. Gaussian process regression
Gaussian process (GP) regression may be used to model nonlinear functional mappings from an input space to a target space. It is based on a Bayesian statistics, and incorporates a nonparametric approach which differs substantially from para-metric techniques like NNs. By definition the GP represents an infinite collection of random variables, any finite subset of which have joint Gaussian distributions ( Rasmussen and Williams, 2006 ). A GP may be understood as describing a probability distribution over functions. The Gaussian process favours func-tions which are both in some sense smooth and which explains the training data well. It is this smooth characteristic of the function which allows it to generalise well.
 Let the vector x n denote a single position in the input space. The set of training input vectors X N f x n g N n  X  1 corresponds to the target vector y N f y n g N n  X  1 . A mean function m  X  x used to describe the expected value at any point of the input space, before any training data have been considered. During the preprocessing stage the data may be zero mean unit normalised so that the mean function may be set to zero, m  X  x  X  X  0 for all values of x .

Consider that the covariance between two function values at fixed positions x a and x b may be denoted by cov  X  x a covariance reduces to cov  X  x a , x b  X  E  X  X  y  X  x a  X  X  y  X  x the knowledge of this covariance function renders it possible to infer one function value, given knowledge of the other. The GP extends this idea by making use of a kernel function to explain the covariance as a function of the input space k  X  x a , x b This renders it possible to infer the value y n of a function at a novel position x n in the input space.

By implementing any kernel function some implicit assump-tions about the function space are made. It is possible to construct new kernel functions by combining simpler kernel functions ( Bishop, 2006 ). This makes it possible to impose a prior over the function space with certain desirable properties. The kernel function k c that is implemented in this paper comprises of the addition of three simple kernel functions, namely the squared exponential with automatic relevance detection k 0 , a linear kernel with automatic relevance detection k 00 , and a kernel function k which assumes that the signal is subject to independent identi-cally distributed (iid) Gaussian noise. The implemented kernel may thus be expressed as: k  X  x a , x b  X  X  k 0  X  x a , x b  X  X  k 00  X  x a , x b  X  X  k 000
The squared exponential (SE) is p erhaps one of the most popular kernel functions. It makes the assumption that function values which lie closely together in the feature space are likely to be more similar, with near unity covariances for variables which have closely corre-sponding feature inputs k 0  X  x a , x b  X  X  s f exp  X  X  x a M 1 is a diagonal matrix, with positive automatic relevance detection (ARD) parameters M 1  X  diag  X   X  1  X  where  X  1 is a vector of length D so that it corresponds to the dimension of the input space. The ARD parameters are also referred to as t he characteristic length-scale parameters and determines the rate at which the function varies in the corresponding direction of t he input space. The shorter the length scale parameter is for a specific feature component, the faster the function tends to vary for any variation of that feature. A short length scale thus corresponds to high relevance. The function variance s 2 f is related to the overall variance of the function.
The linear covariance function with automatic relevance detection (ARD) is parameterized by k 00  X  x a , x b  X  X  x represents the diagonal matrix M 2  X  diag  X   X  2  X  .

The final constituent of the covariance function is the noise presence of zero mean Gaussian noise. The noise variance is represented by s n and d  X  a , b  X  is the Kronecker delta function, which is 1 if and only if a  X  b and zero otherwise.

The matrices containing the ARD parameters f M 1 , M 2 g , the signal variance f s f g and the noise variance f s n g are all unknown and must be inferred from the training data. These parameters are collectively referred to as the hyperparameters of the GP and denoted by h . By means of Bayes X  rule it may be shown that the maximum a posteriori hyperparameter values h MP may be found by maximising the marginal likelihood p  X  y N 9 X N , y MP equivalent to minimising the negative log marginal likelihood: log P  X  y N 9 X N , h  X  X  1 2 y &gt; N  X  K c  X  X N , X N  X  X  where K c  X  X N , X N  X  is the N N covariance matrix between all pairs of training inputs X N and is computed with Eq. (1). Predictions y at the new locations X n may be inferred by conditioning the joint distribution on the observed target values y y "#
GP regression with assumed zero mean function reduces the distribution over prediction s given the training data to Rasmussen and Williams (2006)
P  X  y 9
X N , y N , X n  X  N  X  y n , cov  X  y n  X  X  X  4  X  where y  X  K c  X  X n , X N  X  K c  X  X N , X N  X  1 y N  X  5  X  cov  X  y n  X  X  K
The maximum a posteriori (MAP) estimates y n will be used as calibrated severity metrics.

Gaussian process regression is implemented in this paper based on the code developed by Rasmussen and Nickisch (2010) . 4. Experimental investigation
Vehicle response data were measured on a utility vehicle which is used in an under ground coal mine environment.
Fig. 2 (a) illustrates the position of an aluminium block on the wheel axle where the accelerometer was mounted. The vehicle response was measured with a DC coupled Crossbow acceler-ometer and recorded on a Somat eDAC-lite data acquisitioning system at a sampling frequency of 400 Hz. The integrity of the DC coupled Crossbow accelerometer was tested on a high frequency actuator and found to be very accurate over the 0 X 40 Hz frequency of range of interest.
 by rectifying the acceleration signal and low pass filtering it at a cut-off frequency of 2 Hz.
 rotational speed of the shaft. The vehicle speed is calculated from the measured drive shaft speed, the shaft-wheel rotation ratio and the rolling radius of the wheel. The vehicle speed was subsequently integrated over time to obtain an estimated vehicle position for each datum point. The time domain severity metric was interpolated according to the estimated vehicle position so that the severity metric may be visualized as a function of position, rather than time.
 on the ground, and a human operated push button were also connected to the eDAC. These reference signals helped to position the vehicle relative to the investigated road profile. With the severity metric being a function of distance it was possible to align the measurements which were measured at different speeds. 4.1. Generating training data and optimising hyperparameters training data represent how the severity metric varies when the utility vehicle traverses the same position on a road but at different speeds.
 consists of a 10 m long smooth and level surface, which halfway is intersected by a single row of 100 mm high and 200 mm wide concrete blocks. The concrete blocks serve to excite the vehicle in an impulse like fashion.

The acceleration signals are converted to the severity measure resampled to a function of distance rather than time. The various measurements are then aligned.

A typical training point is created in the following manner. The instantaneous speed v i w and severity r i w ,asmeasuredataspecific position w of the road, is taken as the first two entries of an input vector x w ij . The instantaneous speed v j w from a second measurement (at the same road position) is added as the third and final entry of the second run at position w is used as target y m ij  X  r w j illustrated in Fig. 4 where a typical training point is created from two severity measurements which were obtained as the vehicle traversed the concrete hump at different speeds.

The process of creating training points is now repeated for different combinations of measurements. Fig. 4 (a) and (b) indi-cates the variation between four severity measurements as generated under different speeds. The first two entries of the input can be taken from any one of the four measurements i  X  1, y ,4 and again be paired up with any one of the four measurements j  X  1, y ,4 to generate the third entry of the input vector as well as the target. A total of 16 training points are thus created to represent a single position in road. It is important that some training points exist where a measurement regress to itself, so that the calibration function can learn that the severity should not be altered if v w i  X  v w j . These 16 datum points are now representative of a single road condition at position w , even though that condition is not actually specified. Similarly can 16 additional points be created for every other position on the road. In this paper the 16 training points are generated at half meter intervals over the 10 m of track w  X  1, y ,21 so that a total of N  X  336 training points are obtained.
 The training points are clustered in the 336 3 input matrix X N and the associated target vector Y N .
 X
The Gaussian process hyperparameters are now chosen such as to minimise the negative log marginal likelihood of the training data. The implemented code as developed by Rasmussen and Nickisch (2010) makes use of the Polack X  X ibiere flavour of conjugate gradients to compute search directions, and a line search using quadratic and cubic polynomial approximations. The Wolfe X  X owell stopping criterion is used together with the slope ratio method for guessing initial step sizes. 4.2. Function interpretation
The characteristics of the calibration function are subsequently investigated.
 A contour plot of the calibration ratio is presented in Fig. 5 (a). The calibration ratio is obtained as the severity estimate from the Gaussian process y n divided by the measured severity. The contour plot is consistently defined for a target speed of 2.5 m/s. The y -axis indicates the measurement velocity and the x -axis the magnitude of the measured severity.

Fig. 5 (b) depicts the estimated standard deviation associated with any prediction. Dark contours indicate areas where the Gaussian process has observed little or no training data, so that it has little confidence in its own predictions. Bright areas indicate those areas where the GP is expected to make good predictions.
In Fig. 5 (a) a dark circular patch is observed in the vicinity where the measured severity has a magnitude of about 0.2, and the measured velocity is close to 1. From the colour bar it is seen that the adjustment ratio is 1.8. In other words, if the utility vehicle traverses a section of road at a slow speed of 1 m/s and it experiences a moderate vehicle response severity of 0.2, then the
GP predicts that the utility vehicle will experience a response severity which is 1.8 times greater if it were to travel over that section of road at 2.5 m/s.

If the vehicle travels over a section of road at 1 m/s and the measured severity is small, then the adjustment ratio will be close to 1. This corresponds to the utility vehicle travelling over a smooth road, where the vehicle response is approximately con-sistent, regardless of the vehicle speed.

When the measured speed as indicated on the y -axis exceeds the target speed of 2.5 m/s the adjustment ratio tends to drop beneath 1 to indicate that it is expected that the vehicle will respond less violently if it is driven slower over such a section of road.

It might be expected that a very large severity measurement such as 0.6 at a low speed should have a very large adjustment ratio, but Fig. 5 (a) indicates a near unity adjustment ratio. This is explained by noticing in Fig. 5 (b) the large uncertainty of the GP.
The limited amount of training data did not contain any examples of such severe road conditions. In the absence of training examples the GP predicts the most likely severity value, which is simply the mean of all the target values.

Fig. 6 (a) and (b) illustrates the results where the calibration function standardise each of the four training measurements to a consistent speed of 2.5 m/s. The severities as estimated from the four measurements are now much more consistent. The peak from run 4 which was measured at a speed of approximately 1.4 m/s now corresponds fairly well with the peak from run 1 which was measured at close to 3.2 m/s. It is however also seen that the supposedly near zero excitation just before the hump of run 2 is wrongly amplified. Better training data should avoid this problem.

It is thus seen that the calibration function makes intuitive sense within the range of training data. The training data represent both smooth road surfaces, as well as a road surface with a significant excitation. The training data also represents a speed range from about 1.4 to 3.2 m/s which is the typical range which was measured in underground operating conditions. It is thus expected that the calibration function is fairly representative of the conditions under which it will be expected to perform calibration. However, it is also anticipated that better perfor-mance might be obtained if training data were collected over a slightly larger range of speeds, and especially over a greater variety of excitations.
 4.3. Model evaluation and results novel data is subsequently investigated. The utility vehicle was repeatedly driven over an almost 700 m track of underground road. The human operated push button was used to indicate the start and end of each run. Measurements were taken when the vehicle drove in the forward direction, as well when the vehicle returned. The forward and return runs did not follow the same path, so that it is more consistent to split the forward and return runs into two sets of data. Each set of data contained three runs, which are representative of the vehicle response as measured at different, slightly fluctuating, speeds.
 to serve as measured road severity. The estimated vehicle speed is subsequently used to convert the measured severity to a function of distance, rather than time.
 return data sets. Two methods are used to investigate the validity of the calibration function. The first method will calibrate the severity from one run so as to resemble the speed of the other run. The second method will compare the standardised severity measurements. 4.3.1. Forward run forward direction is first investigated.

It has been explained that the input vector is defined as the input vector ( v i and r i ) contain information that indicates the underlying road condition, while the third entry v j determines the speed at which it is desirable to know the expected or calibrated severity r j . The calibration function is applied pointwise to the measured severity. Although it is ultimately the aim to standar-dise all the severity measurements to a constant speed to allow for consistent road quality comparison, the calibration function is not limited in this fashion. The target speed v j may be set equal to the measured (possibly fluctuating) speed of any other run. Each of the three forward runs were performed over nearly the same road profile. It is therefore expected that one run would more closely resemble another run, if it is speed calibrated to the measured speed of that second run.

Table 1 investigates how the characteristics of one severity measurement is affected if it is speed calibrated to the speed of a second run. The first column indicates which run is calibrated, and the second column indicates the speed of which run is used as target speed. The third column is the velocity difference between the two runs. The fourth, fifth, and sixth columns respectively indicate the root mean square (rms) of the measured severity of the original run O rms , the rms value of its point wise calibrated severity C rms , and the rms value of the severity metric of the run which served as target speed T rms .
 The original error (org. error) is defined as Original error  X  O rms T rms T while the calibrated error (cal. error) is defined as Calibrated error  X  C rms T rms T The calibrated error generally is much smaller than the original error.

Fig. 7 (a) and (b) investigates the statistics of the measured and pointwise calibrated severity measures. The probability distribu-tions are estimated by means of Parzen-window density estima-tion ( Bishop, 2006 ) as implemented in the Matlab ksdensity function. Normal distribution kernels and a consistent window length of 0.4 are used. The abscissa indicates the magnitude of the severity, while the ordinate indicates the relative frequency that any severity occurred.

Fig. 7 (a) indicates the process where the severity measure-ment of run 3 is calibrated to the measured speed of run 1. From Table 1 it is seen that the measured speed from run 1 is approximately 1.15 m/s faster than the speed of run 3. It is therefore expected that the calibrated severity will be greater than the measured severity. The dashed line in Fig. 7 (a) which represents the original measurement (run 1) indicates a mode (peak) at roughly 0.1, which is significantly less than the mea-surement of run 2. The calibrated severity from run 3 corresponds much closer to the measured response of run 1.

Fig. 7 (b) indicates the process where run 1 is calibrated to the lower speed of run 3. In this circumstance the calibration function over compensated by reducing the severity a bit too much. From Table 1 it is seen that the calibrated rms error is quite large (16.7%), but it is still smaller than the original error (40.5%).
The calibration function is subsequently investigated in the context which it is intended for, namely to standardise the severity metric to allow for consistent road quality evaluation. Fig. 8 (a) depicts the original severity measurements, while Fig. 8 (b) shows the severities as calibrated to a consistent speed of 2.5 m/s. In Fig. 8 (a) the grey area specifies the interval between the minimum and maximum measured severity measurements, and in Fig. 8 (b) it denotes the interval between the minimum and maximum calibrated severities. The dashed lines represent the means. The grey areas provide an indication of the variation between severity measurements obtained under different speeds.
The calibrated severities are presented in Fig. 8 (b). Some variation is still observed. This may partly indicate that the calibration function needs to be refined, but may also be due to the utility vehicle following slightly different routes over the same track introducing some unavoidable measurement varia-tions. In general the calibrated road severities are much more consistent, so that any one of the calibrated runs may serve as support for maintenance decisions. 4.3.2. Road section 2 presented for the reverse runs.
 severity measurement is affected if it is speed calibrated to the speed of a second run. The magnitude of the mean speed difference between run 2 and run 3 is 1.36 m/s, which is the largest difference observed between any two runs, including those in the forward direction. The calibrated error is seen to be significantly smaller compared to the original errors.
The probability distributions of runs 2 and 3 are subsequently also investigated in Fig. 9 (a) and (b). Fig. 9 (a) illustrates the process where the severity measurement of run 3 is calibrated to the measured speed of run 2. In Fig. 9 (b) the reverse is presented, so that the severity measurement of run 3 is calibrated to the measured speed of run 2. The modes of the calibrated severity measures correspond much better with the target distributions, so that it is clear that both runs were subject to road profiles with similar characteristics.

The last figures again compare the variability (depicted by the grey patches) associated with the measured severities ( Fig. 10 (a)) with those of the calibrates severities ( Fig. 10 (b)). The speed calibrated responses are very similar. Each of the three calibrated severity measures provides a good and consistent estimate of the underlying road condition. 5. Conclusion
Real time monitoring of haul roads by means of vehicle onboard accelerometers which measure vehicle response has previously been proposed in the literature. It has however also been noted that it is not only the underlying road condition, but also the vehicle operating conditions which influence the vehicle response. To avoid ambiguous road classification it therefore is important to implement a strategy which account for the operat-ing conditions of the vehicle.

This paper proposes a methodology which performs vehicle response calibration towards the aim of consistent haul road monitoring. Gaussian processes, which offers a robust, statistical and nonparametric approach to perform inference is used to learn a calibration function from training data. The calibration method performs pointwise calibration of the measured severity metric. Since the metric is continuous it is possible to adapt the function based on some understanding of the characteristics of the latent condition of the specific section of road. The required information which describes the characteristics of the latent condition of the road is extracted from the vehicle response itself.

The methodology was investigated on experimental data which were obtained by measuring the response from a utility vehicle in a coal mine environment. A simple set of training data was created by driving the utility vehicle over a selected track at different speeds. The road comprised of a smooth and level surface which was intersected by a single row of concrete blocks to simulate an impulse like excitation. Once trained the ability of the Gaussian process to generalise well was investigated by calibrating and comparing different measurements which were representative of the underground road conditions.

The implemented methodology requires no prior knowledge of the vehicle, nor does it require costly tests to characterise either the vehicle or individual components on it. Compared to the uncalibrated severity measurement, the standardised results are significantly more consistent. It thus appears that the proposed methodology may be used as a cost effective framework to monitor haul roads by means of vehicle response measurements.
The presented case study focussed on haul roads. Towards this goal a simple metric which emphasised the presence of individual relatively low frequency humps was implemented. It is however anticipated that the proposed framework may also be applied to urban roads, where higher frequency vehicle response and noise components become more important. Future research may be conducted where conventional IRI measurements are normalised with respect with different operating conditions.
 References
