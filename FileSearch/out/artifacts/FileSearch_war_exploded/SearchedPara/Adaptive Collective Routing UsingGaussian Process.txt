 We consider the problem of adaptively routing a fleet of cooperative vehicles within a road network in the presence of uncertain and dynamic congestion conditions. To tackle this problem, we first propose a Gaussian Process Dynamic Congestion Model that can effectively characterize both the dynamics and the uncertainty of congestion conditions. Our model is efficient and thus facilitates real-time adaptive rout-ing in the face of uncertainty. Using this congestion model, we develop an efficient algorithm for non-myopic adaptive routing to minimize the collective travel time of all vehi-cles in the system. A key property of our approach is the ability to efficiently reason about the long-term value of exploration, which enables collectively balancing the explo-ration/exploitation trade-off for entire fleets of vehicles. We validate our approach based on traffic data from two large Asian cities. We show that our congestion model is effective in modeling dynamic congestion conditions. We also show that our routing algorithm generates significantly faster routes compared to standard baselines, and achieves near-optimal performance compared to an omniscient routing algorithm. We also present the results from a preliminary field study, which showcases the efficacy of our approach.
 Categories and Subject Descriptors: H.2.8 Database applications: Data mining I.2.6 Artificial Intelligence: Learn-ing -parameter learning General Terms: Algorithms; Experimentation.
 Keywords: Collective routing; Gaussian Process; Dynamic congestion model.
We consider the problem of collectively routing a fleet of cooperative vehicles, with the goal of minimizing the to-tal travel time. Such problem settings naturally arise in contexts such as delivery services and cooperative fleets of automated self-driving vehicles.
 Figure 1: Example collective routing problem with uncertainty. Seven vehicles wish to travel from A (left) to B (right). The bottom road is faster in expectation, but there is a chance that the top road is currently faster. A good collective strategy is to send the first two vehicles down separate roads to observe which road is currently the faster one.

Intelligently routing vehicles in urban environments is a challenging problem due to uncertainty in the traffic condi-tions of the road network. Consider the example depicted in Figure 1, where seven cooperative vehicles wish to travel from point A (left side) to point B (right side) using either the top road or the bottom road. Suppose from historical measurements that we know the bottom road is faster in expectation. However, there is a reasonable chance that the top road is currently faster. A good collective strategy in this setting would be to send the first two vehicles down separate roads in order to observe current traffic conditions on both roads (i.e., vehicles can also be viewed as sensors). Afterwards, the remaining vehicles can be routed using much more reliable traffic information. 1
Two technical challenges arise from this example. First, we require a (probabilistic) model that reliably captures the distribution, or uncertainty, of traffic conditions (e.g., the model must be able to predict that the top road in Figure 1 is faster 40% of the time). Furthermore, such a model must be able to (efficiently) predict reliable posterior , or updated, distributions given real-time observations.

Second, we require routing algorithms that can balance the exploration/exploitation trade-off underlying all prob-
Note that our approach does not require vehicles to wait while the first two vehicles are exploring, but rather au-tomatically balances the collective exploration/exploitation trade-off for the entire fleet (see Section 5). lems pertaining decision-making under uncertainty  X  this issue is typically not explicitly considered in the routing lit-erature. In Figure 1, the first two vehicles are engaged in  X  X xploratory X  routing so that later vehicles can be routed more optimally. Exploration is inherently non-myopic since it often reduces the utility (i.e., increases the travel time) of the exploring vehicle. As such, effective routing algorithms must be careful to not over-explore, which requires reason-ing about the long-term impact of exploration. Our setting is further complicated due to collectively routing a fleet of cooperative vehicles, rather than a single vehicle in isolation.
In this paper, we make the following contributions:
Traffic data analysis: Traffic modeling is a very di-verse research area, which is primarily due to there being a large variety of measurement types (e.g., traffic cameras, GPS traces) as well as modeling goals. Our work is most closely related to the area of congestion estimation.
Congestion or traffic estimation has been studied using a variety of mathemetical tools, ranging from flow patterns [20], to per-individual statistical models [18], to Markov chain forecasting [29]. The two main types of measurement data are GPS or low-bandwidth cellular updates which are associated with individual vehicles [32, 7], and static traffic cameras which are associated with known location [2].
In contrast to most prior work, our goal is to derive a holis-tic generative probabilistic model of dynamic traffic condi-tions. Since our goal is to incorporate such a traffic model into a real-time routing algorithm, we require our model to not only accurately capture the distribution of future traf-fic scenarios (given real-time observations), but also be suf-ficiently fast to evaluate. For measurement, we use GPS traces collected from thousands of taxis from two large Asian cities (see Section 6).

Other work on traffic modeling have studied phenomenon such as traffic accidents or other outlier activitiy [3, 22] and evaluating the overall health of a road network design [34].
Adaptive Routing: Although there have been some work on personalized or adaptive routing based on histori-cal and real-time traffic conditions, prior work did not model the benefits of real-time exploration, and thus must resort to myopic routing [33, 8].

The routing problem we study is an instance of the gen-eral problem of decision-making under uncertainty. Such problems are typically cast as partially observable Markov decision processes (POMDPs) [14], where the world (i.e., road congestion conditions) is assumed to behave according to Markovian dynamics, and actions (i.e., routing) reveal partial observations regarding the state of the world (i.e., local congestion measurements).

We cast our problem as a POMDP with a continuous state space modeled using a Gaussian Process (GP). In contrast to previous work on continuous POMDPs (e.g., [10]), we are focused on solving problems with large structured action spaces (i.e., all possible routings of the cooperative vehicles).
There are three common types of approaches for solving discrete POMDPs with large action spaces. The first is to simplify the problem using canonical or macro actions [11]. After identifying the best plan consisting of macro actions, the planner can optionally refine at finer granularities. The second type is to always plan at finer granularities and use pruning approaches to avoid enumerating the full exponen-tially large decision tree (e.g., Monte-Carlo tree search [28]).
The third, more generic, type of approach is to sample from a generative distribution of the POMDP and then find a good plan that optimizes for this empirical distribution [12, 4, 15, 25]. 2 The most general approaches are called stochas-tic planning with recourse [12, 4, 26], which is a very general framework 3 where the goal is to compute a good initial plan while also allowing adaptive behavior, or recourse, during operation. Stochastic planning with recourse approaches are often focused on planning for relatively short time horizons due to efficiency reasons. Conversely, approaches such as PEGASUS [25] plan for longer time horizons but typically optimize over restricted classes of policies.

Our routing algorithm can be viewed as a stochastic plan-ning approach (over a continuous state space) that utilizes canonical actions. In contrast to previous work, our ap-proach optimizes both for the long-term plan and over the full action space of all possible routes . To control the com-plexity of long-term planning, we rely on the observation that typically only a few routes are optimal for any vehi-cle  X  we call these the canonical routes (see Section 5.1). Our approach efficiently trades off between exploration and exploitation by choosing routes that optimize the combina-tion of expected travel time (exploitation) and uncertainty reduction of the canonical routes (exploration to determine which canonical route is the best)  X  this bears affinity to al-gorithms for Gaussian Process bandit optimization [30, 17].
From a combinatorial routing perspective, our work is fo-cused on a relatively simple setting where each vehicle has a pre-defined destination. More complicated settings typ-ically assume that each vehicle is  X  X xchangeable X  and can be routed to any of the target destinations (cf. [9]). This leads to a challenging combinatorial optimization problem
It can be shown that a finite number of samples is sufficient for any planning problem (cf. [15, 25]).
It can be shown that all MDP planning problems can be instantiated as a (large) stochastic planning with recourse problem (cf. Chapter 4 of [13]). even without considering uncertainty. We instead focus on the complementary problem of how best to collectively route each vehicle to their pre-assigned destination while account-ing for uncertain traffic conditions.

Another line of related work is motivated from the net-work packet routing problem [1]. A key difference is that [1] is focused on the repeated games problem (i.e., gradu-ally learning about network conditions as more packets are routed) for a single routing problem at a time, whereas we seek to solve a single-shot multi-agent routing problem.
Let R denote our road nework, and Z denote the space of contexts (e.g., containing information about time of day or day of week). We wish to model the travel speed of road segments r  X  X  under varying contexts z  X  X  . We do so via a function f : R X Z  X  &lt; + , that outputs the travel speed for a given ( r,z ) pair.
 We assume that f is sampled probabilistically from a Gaussian process prior distribution f  X  P ( f ) [27]. A Gaus-sian process prior is fully specified by its mean function and its covariance, or kernel, function k (( r,z ) , ( r 0 ,z 0 )) = E [( f ( r,z )  X   X  ( r,z ))( f ( r A major computational benefit of Gaussian processes is that posterior inference can be computed in closed form. Sup-pose we have collected observations Y = [ y 1 ,...,y X = [( r 1 ,z 1 ) ,..., ( r T ,z T )], where each y i  X  N ( f ( r is corrupted by i.i.d. Gaussian noise. We also define the deviation of Y from its prior mean as Then we can write the posterior distribution given X and Y also as a Guassian process distribution with mean  X 
Y,X ( r,z ) =  X  ( r,z ) +  X  k Y,X ( r,z ) &gt; (  X  K Y,X +  X  and covariance k Y,X (( r,z ) , ( r 0 ,z 0 )) = k (( r,z ) , ( r 0 ,z 0 ))  X   X  k Y,X ( r,z ) &gt; (  X  K Y,X where  X  k Y,X ( r,z ) = [ k (( r 1 ,z 1 ) , ( r,z )) ,...,k (( r T ,z is a column vector of the kernel values between (r,z) and every observed location in X , and is the kernel Gram matrix of all observed locations in X .
Essentially, (1) states that the posterior mean  X  ( r,z | Y,X ) of f ( r,z ) deviates from its prior mean  X  ( r,z ) according to how much (and in what direction) the past observations de-viated from their prior means. If some ( r 0 ,z 0 )  X  X had high positive covariance with ( r,z ), then  X  ( r,z | Y,X ) would shift along the deviation of the associated observation y 0 from its mean y 0  X   X  ( r 0 ,z 0 ). Conversely, if some ( r 0 ,z 0 little covariance with ( r,z ), then the associated observation y would have little impact on  X  ( r,z | Y,X ).

Similarly, (2) states that the posterior covariance between ( r,z ) and ( r 0 ,z 0 ) decreases as we gather more observation that is related to (i.e., has high prior covariance with) ( r,z ) and ( r 0 ,z 0 ). Thus, the variance of our posterior estimate, k
Y,X (( r,z ) , ( r,z )), of f ( r,z ) decreases faster when our past observations have higher prior covariance with ( r,z ).
For a given road segment r  X  R and context z  X  Z , we wish to model the background distribution of the trav-eling speed y r,z . Furthermore, we wish to model the ap-propriate temporal and spatial dependences such that, after observing recent traveling speeds, we can make more confi-dent inferences of the traveling speeds of nearby roads in the near future. We now present the Gaussian Process Dynamic Congestion Model (GPDCM), which captures such proper-ties within the Gaussian Process framework. We assume for simplicity that the observation noise variance  X  2 is known.
We essentially assume that road traffic conditions behave according to Gaussian Process dynamics. In other words, given the current observations, the posterior GP distribution should accurately represent the distribution of future traffic conditions. It remains to define a suitable choice of  X  and k . We do so by estimating  X  and k using historical traffic data S , which we describe in the following.
Estimating  X  requires assuming regularities about how  X  behaves relative to z . For example, suppose we assume that temporal regularities can be characterized by time-of-day, which we denote as  X  ( z ). Then we can estimate  X  ( r,z ) as  X  ( r,z ) = mean y r,z 0 : ( y r,z 0  X  S )  X   X  ( z 0 ) =  X  ( z ) where y r,z 0 is a historically observed traveling speed on road r and time-of-day  X  ( z 0 ) =  X  ( z ). This allows computing the mean traveling speed on road r at any future time, but re-stricts us to modeling all days as being sampled from the same (prior) distribution. 4
Since it is unlikely that historical observations contain many data points with exactly matching time-of-day con-texts, we use standard temporal smoothing techniques to estimate a smoothed version of (3) [21].

We first partition time into intervals (which correspond to each time step in the routing problem definition). Let  X  ( t ) now denote the time-of-day interval corresponding to time step t (e.g., 5:10pm -5:20pm). For road segment r and time step t , we define Y ( t ) S ( r ) as the set of all the reported speeds matching  X  ( t ) at r in the historical data S , i.e., We can now use Y ( t ) S to construct an empirical distribution of travel times on road r at time step t .

Following [21], we employ temporal smoothing of the em-pirical cumulative distribution functions (CDF). We can write this smoothed CDF at road segment r as
We can alternatively use a feature representation of the context  X  ( z ) and a parametric model to estimate  X  ( r,z ). where CDF(y | Y (t) S ) denotes the empirical CDF w.r.t. Y and  X  and  X  control for the degree of smoothing. We refer to [21] for more details. Afterwards, we can compute the empirical mean (3) using H z S (y | r) via  X  ( r,z ) = E y  X  H
For simplicity, we assume the covariance kernel can be decomposed by road and context, i.e., This decomposition k = k 1 k 2 assumes that all road segments share the same temporal covariance k 2 ; while somewhat ide-alistic, this offers a compact and efficient representation.
Estimating k 1 ( r,r 0 ) is relatively straightforward, as it is essentially the covariance of the distribution of travel speeds between two road segments. We can estimate k 1 from his-torical data S as Note that, for (5), the two historical observations y r,z y ,z share the exact same context (e.g., were observed at the exact same time). As such, we also employed temporal smoothing (see Section 4.1.1) to estimate k 1 more reliably.
Intuitively, if two roads r and r 0 have high covariance ac-cording to S , then k ( r,r 0 ) will be high. As such, observa-tions of r 0 provide more information about the conditions on r than another road segment with low covariance with r 0 .
Note that since the roads in our system form a finite set, we can precompute the entire road-road kernel matrix.
Estimating k 2 ( z,z 0 ) is slightly more complicated, as it re-quires us to assume additional regularities about z . For example, we can assume that k 2 ( z,z 0 ) only depends on the difference in time | z  X  z 0 | , which leads to k 2 ( z,z 0 ) = mean { ( y r,z 1  X   X  ( r,z 1 ))( y r,z 2  X   X  ( r,z Here we compute the empirical covariance of traveling speeds at time distance | z  X  z 0 | averaged over every road. As when estimating k 1 , we also employ temporal smoothing to esti-mate k 2 more reliably.

Intuitively, the covariance should decrease as the time dif-ference increases. From the perspective of each y r,z distribution of the corresponding y r,z 2 should look more like the background distribution as | z 1  X  z 2 | increases.
Although (5) and (6) correspond to (modulo regularity assumptions) the  X  X orrect X  covariance estimates, their non-parametric form can be expensive to evaluate. Naively, (5) and (6) requires reprocessing S for each kernel evaluation. However, one can specify k 1 and k 2 using other forms as well. For example, one could use a RBF kernel: k 1 ( r,r exp  X  X  r  X  r 0 k 2 / X  1 , where k r  X  r 0 k denotes the distance between r and r 0 , and  X  1 is a tunable parameter used to fit the historical data (i.e., to be similar to (5)). One can also define an analogous kernel model for k 2 . This definition has an advantage of being more compact and thus more efficient than (5) and (6). We defer a more extensive study on the choice of kernels to future work.
The main purpose of using the GPDCM is to be able to make tractable probabilistic inferences of future road condi-tions given real-time observations. After estimating  X  and k from historical data, the posterior distribution is fully spec-ified via (1) and (2).

Note that the K Y,X matrix in (2) grows quadratically in size w.r.t. the number of observations. This can make infer-ence very costly as we collect more observations. Intuitively, we should expect that very old observations do not impact our model much when trying to predict future conditions (since the time difference is large, the k 2 component from very old observations should be close to 0). As such, we should be able to discard old observations from our model without compromising model accuracy.
We consider the setting where N cooperative vehicles must travel from source locations A = { a 1 ,...,a N } to destina-tions B = { b 1 ,...,b N } . We desire an adaptive routing pol-icy that can minimize the total travel time of all vehicles. Let Planner denote the routing algorithm being employed. For simplicity, we discretize time into intervals (e.g., every minute). At time step t the following occurs:
In our setting, each observation y t = { y t, 1 ,...,y t,N responds to the observed speed of the roads traveled by each vehicle for that time step t . In this section, we assume that congestion conditions behave according to a GPDCM. 5
We develop our algorithm, called Planning using Canoni-cal Routes (PCR), in three steps. First, we observe that typ-ically only a few routes are ever optimal for each vehicle  X  we call these the canonical routes . Second, we show how to uti-lize canonical routes to efficiently model the long-term value of exploration. Finally, we show how to compute collec-tive routing plans that balance the exploration/exploitation tradeoff for an entire fleet of cooperative vehicles. The PCR algorithm is described in Algorithm 1.
At first glance, computing (near-)optimal routing plans may seem hopelessly intractable, since the full decision space for even a single vehicle can be exponentially large. How-ever, it can often be the case that only a few routes are ever optimal for a given vehicle X  X  routing problem. For instance, given a GPDCM of congestion conditions, one can sample probable future traffic scenarios. Each such sample gives complete information of one probable future scenario (cf. [15, 25]), which allows us to compute the optimal route un-der that scenario. We call such optimal routes the canonical
Since we discretize time into intervals, we use the average travel speed of each road segment for routing. Figure 2: Distribution of the number of canonical routes for each individual vehicle routing problem (see Section 5.1). On average, there are 3.2 canoni-cal routes per vehicle. routes . Depending on the specific conditions, the optimal canonical route could be much faster than simply routing according to expected travel time.

Figure 2 shows the distribution of the number of canonical routes per vehicle. 6 We see that the number of canonical routes is often quite small  X  about 3.2 on average.
If a routing algorithm knew exactly which of the sampled scenarios reflects future traffic conditions, then that corre-sponding canonical route would be the optimal action to take. But due to uncertainty regarding which scenario actu-ally reflects future conditions, then it may be beneficial to perform some  X  X xploratory routing X  in order to more confi-dently identify which canonical route is actually best.
The standard approach for quantifying the value of ex-ploration is to measure the expected utility gain of future routing decisions [23]. Given the exponentially many possi-ble future routing decisions, computing this value of explo-ration exactly is intractable using naive approaches.
We use two approximations in order to efficiently quantify the long-term value of exploration. First, we focus explo-ration only on the canonical routes, rather than all possible routes. This approximation is motivated by the assumption that each vehicle should be routed (as closely as possible) according to the optimal canonical route. Therefore, the goal of exploration should be to determine which canonical routes are actually optimal. In addition, focusing on canon-ical routes is a form of long-term exporation, since canonical routes are complete paths to the vehicles X  destinations.
We next approximate the value of exploration using vari-ance reduction. 7 For any canonical route ~r  X  , the variance reduction of ~r  X  from running some other route ~r is  X k ( ~r,~r  X  | X,Y ) = k ( ~r  X  ,~r  X  | X,Y )  X  k ( ~r  X  ,~r where k ( ~r  X  ,~r  X  | X,Y ) denotes the variance reduction of ~r under the posterior distribution induced by observations X and Y , and k ( ~r  X  ,~r  X  | X,Y,~r ) denotes the variance of ~r posterior distribution induced by observations X,Y and ~r .
Estimating (7) exactly is expensive, since the variance of each road segment in ~r  X  depends on the exact arrival times at that segment (which depends on previous segments). We
We computed Figure 2 by sampling from a GPDCM esti-mated using traffic real data (see Section 6).
Variance reduction exactly quantifies the value of informa-tion in some settings (cf. [30, 17]).
 Algorithm 1 Planning using Canonical Routes (PCR) 1: input : L , Y ,  X  6: Initialize W  X  X  1 ,...,N } 7: Initialize  X   X  X  X  8: for j = 1 ,...,N do 11: W  X  W \{  X  n } 13: end for 14: Return  X  instead approximate k ( ~r  X  ,~r  X  | X,Y ) using the expected travel times for each segment in ~r  X  . We first write ~r  X  as where  X  i denotes the expected arrival time at road segment r . We can then approximate k ( ~r  X  ,~r  X  | X,Y ) as where ~r  X  [1: i  X  1] denotes the first i  X  1 road segments of ~r can similarly approximate k ( ~r  X  ,~r  X  | X,Y,~r ) as arrival before  X   X  i .

In summary, we quantify the long-term value of explo-ration of any route by how much that route reduces the variance, or uncertainty, of the travel times of the canonical routes. If we were routing a vehicle for purely exploratory purposes, then we would choose a route ~r that maximizes (7) summed over every canonical route ~r  X  in our set.
Our algorithm, called Planning using Canonical Routes (PCR), is described in Algorithm 1. At each time step t , the algorithm first computes a set of canonical routes by sampling from the posterior GPDCM distribution (Lines 4-5). The algorithm then computes the lowest cost (or highest utility) route ~r n for each vehicle n (Line 9). 8 Cost here is measured as a weighted combination of expected travel time of ~r n (under the posterior distribution) and negative average variance reduction (averaged over all canonical routes for all vehicles), with the parameter  X  controlling for the trade-off.
Intuitively, a route with a high travel time might still have the lowest cost if it greatly reduces the uncertainty of many canonical routes for many vehicles. Likewise, a route that does not offer much in terms of variance reduction may still have the lowest cost if it has (by far) the shortest travel time.
This can be done using the standard Dijkstra X  X  shortest path algorithm using our cost function. Figure 3: Recall (or coverage) of the optimal paths with respect to the number of samples K .

After computing the lowest cost route for each vehicle, the algorithm greedily commits to the route with the overall lowest cost (Lines 10-12). This process is repeated until all vehicles have been committed to a route.
The reason why we need to recompute the lowest cost routes each iteration (Lines 8-13) is because the variance re-duction of canonical routes change after the algorithm has commited to a route. For instance, if the two best routes from the current iteration both provide uncertainty reduc-tion to the same canonical routes, then after the algorithm commits to one of those routes, the value of exploration for the other route has decreased dramatically (i.e., it no longer provides the same variance reduction). This notion of dimin-ishing returns is often modeled using submodularity [24].
In fact, it is possible to show that Algorithm 1 is optimiz-ing for a submodular utility function (the negative of the cost function) under matroid constraints. As such, one can show that the greedy approach employed by Algorithm 1 has a (1/2)-approximation guarantee relative to the optimal lowest cost collective routing plan (of a single time step) [6, 31]. We omit the derivation for brevity.

One nice property of submodular function optimization is that one can employ a lazy variant of the greedy approach to significantly speed up computation [19]. It is straightfoward to incorporate this lazy variant into Algorithm 1.
Variance reduction is often an over-estimate of the true uncertainty reduction. As such, it is often beneficial to choose  X  to be small. In our experiments, we use  X  = 0 . 1.
Another design decision is the number of samples K (Line 4 in Algorithm 1). We would like to choose K sufficiently large so that all true canonical paths (those that are actually optimal) are covered. Figure 3 shows the recall (or coverage) of true canonical paths collectively for 50 vehicles. In our experiments, we choose K = 5000. 10
We conduct two types of empirical evaluation. First, we verify whether our Gaussian Process Dynamic Congestion
One can also tune  X  using a validation set for better per-formance.
We note that since sampling is efficient (due to the GPDCM allowing sampling in closed form) and routing is efficient (due to it being a modified Dijkstra X  X  algorithm), choosing K = 5000 still allows Algorithm 1 to be run efficiently. Model can accurately predict the distribution of future traf-fic scenarios given real-time observations. Second, we verify how our PCR algorithm compares versus conventional rout-ing baselines and also versus omniscient routing with perfect knowledge of congestion conditions. 11
We obtained two datasets consisting of GPS traces from a large number vehicles: We first validate the effectiveness of our Gaussian Process Dynamic Congestion Model (GPDCM), and verify that it can accurately predict the distribution of future traffic sce-narios given real-time observations.
Since our goal is to evaluate the how well our GPDCM predicts a distribution of the future, we require a method a measure of how well a predicted distribution matches the true or empirical distribution observed in nature (i.e., the observed distribution of travel speeds). For our evaluations we use the Kolmogorov-Smirnov test [16], which has a long tradition in the statistics community. 12
The Kolmogorov-Smirnov score quantifies the distance be-tween any two distributions. In our case, we wish to quan-tify the distance between the empirical distribution of travel speeds and the predicted distribution of our GPDCM.
Let F n denote the empirical cumulative distribution func-tion for n i.i.d. random variables X i : where I X i  X  x is an indicator function (i.e., 1 if X i  X  x , and 0 otherwise). The Kolmogorov-Smirnov score for a given cumulative distribution function F ( x ) and empirical distri-bution F n ( x ) is which corresponds to the supremum over all absolute dis-tances between the two distributions. The lower the KS score, the better the distributional fit. Two identical distri-butions will have a KS score of 0, and typically a KS score of less than 0.1 is indicative of a strong distributional fit.
For each city, we fit a GPDCM (  X  and k ) using six months of data (from February to June). We then evaluated the predictive accuracy of our GPDCM (via the KS score) on held-out data. For each day, we provide the GPDCM with two hours of observations from 8am-10am. We then measure the KS score of the GPDCM posterior compared to future
All of our experiments were conducted using a workstation with four Intel Core Quad CPUs (Q9550 2.83 GHz) and 32 GB of main memory.
Other options include the Berk-Jones test, the score test and their integrated versions [16, 5]. Figure 4: Showing the macro-averaged KS score (computing KS score for each day separately) on the two datasets for months of January and December.
 Figure 5: Showing the micro-averaged KS score (by aggregating all days into a single day) for the two datasets for the months of January and December. empirical distributions partitioned into one hour windows (e.g., [0-1], [1-2], etc., hours into the future).

Figure 4 shows the KS score averaged over multiple days (i.e., macro-averaged) for both datasets for the months of January and December (which are the furthest apart months in both datasets). We observe that the KS score is quite low for the first three hours, indicating that our GPDCM predicts accurate near-term traffic distributions. We also observe that the KS score degrades as the GPDCM predicts traffic distributions further into future, and eventually de-cays to the  X  X ackground X  prior KS score.

The performance difference for different cities and months in Figure 4 can be explained as follows. Since we have more data from City 1, we should expect a better model fit. Like-wise, our datasets also contain more data from December, which explains why our model makes more accurate (from a distributional point of view) predictions for the month of December. As such, one can interpret this difference in per-formance between December and January as being primarily attributed to data sparsity in the test set.

Figure 5 shows the KS score computed over all days (i.e., micro-averaged) for both datasets for the months of January and December. Because we construct an empirical distribu-tion by aggregating over all days (e.g., all [10am-11am] time windows for each day in January), we should expect the KS score here to be lower than the results in Figure 4 due to less data sparsity. As we can see, the KS score is indeed uniformly lower for both datasets and both months.

These results suggest that the GPDCM is an effective model for predicting the distribution of future traffic con-ditions given real-time observations. In the following, we evaluate how our PCR algorithm can utilize a GPDCM to effectively plan for non-myopic routing under uncertainty. Figure 6: Travel time versus number vehicles to be routed. The PCR algorithm performs nearly as well as the omniscient lower bound.
We now validate the effectiveness of our Planning us-ing Canonical Paths (PCR) algorithm for adaptive collec-tive routing under uncertainty. We compare our approach against both conventional baselines (described below) as well an omniscient lower bound: All routing algorithms utilize the same GPDCM for model-ing travel times.

We run all routing algorithms via simulation using con-gestion conditions mined from the same day in our historical data [21], 15 and assign each vehicle a source and destination pair ( A,B ).
Figure 6 compares the total travel time with respect to the number of vehicles to be routed. We observe that the PCR algorithm significantly outperforms both Static and Myopic routing, and nearly matches the performance of Omniscient routing. Figure 7 shows a comparison of total travel time with respect to the routing distance. We again observe that the PCR algorithm is near-optimal relative to Omniscient routing. These results suggest that the PCR algorithm is effective at balancing the exploration/exploitation trade-off in order to quickly identify the best possible routing paths for the majority of the vehicles in the system.
Myopic routing is essentially how conventional adaptive routing algorithms behave (cf. [33]).
Omniscient routing is only computable during simulation. We compute for each road the  X  X rowdedness X  metric in [21]. The crowdedness of a road is essentially the complement value of the CDF on that road X  X  speed distribution (i.e., crowdedness of 0.9 means the road is at its 10th percentile traveling speed). Figure 7: Travel time versus routing distance. The PCR algorithm performs nearly as well as the om-niscient lower bound.
 Figure 8: Travel time (min) versus size of historical data used to estimated  X  and k .
Although the PCR algorithm described in Algorithm 1 is already efficient due to relying on efficient subroutines such as Gaussian Process posterior inference and the Dijkstra X  X  shortest path algorithm, one can further trade off routing performance for computational or storage efficiency (the two notions of efficiency are often inter-related).

Our use of non-parametric mean  X  and kernel k functions leads to more computationally expensive posterior inference as the training data S grows. Figure 8 shows how the to-tal travel time degrades (for 20 vehicles) as the amount of historical data S (used to estimate  X  and k ) decreases. We see that the PCR algorithm is robust to using less reliable GPDCMs, which can lead to significant computational and storage savings for relatively small sacrifices in performance.
Another way to trade off performance versus efficiency is by varying the number of posterior samples K . Figure 9 shows how the total travel time degrades as fewer samples are used. We observe that the PCR algorithm can tolerate a small degree of undersampling of traffic scenarios.
We conducted a preliminary field study using twelve ve-hicles in City 1. Each routing trial comprises two groups of six cooperative vehicles, with each vehicle being assigned identical source and destination locations. The first group employs a version of Myopic routing, where the drivers are instructed to route according to their best knowledge and can communicate with each other. The second group em-ploys a restricted version of the PCR algorithm, where three drivers are routed to explore three canonical routes, and the other three are routed according to updated knowledge.
Table 1 shows the results from five trials. We observe that PCR routing consistently outperforms Myopic routing, Table 1: Travel Times (minutes) from Field Study which lends evidence that the PCR approach can be more broadly deployed to improve routing performance for larger fleets of cooperative vehicles. The improvement in Trial 3 is small, which is due to low congestion during that time.
Our approach is related to other approaches that first sam-ple from a POMDP distribution and then optimize for the resulting empirical distribution [15, 25]. One important the-oretical question is what number of samples K guarantees good performance (at least within one iteration). Another theoretical question is whether one can prove guarantees for the entire execution of the PCR algorithm. Such analysis may rely on using variance reduction to bound the perfor-mance gap between omniscient routing, which is is related to analysis for Gaussian Process bandit optimization [30, 17]. Two important differences between [30, 17] and our setting are that (1) variance reduction decays over time (i.e., past observations have low value) and (2) we must optimize over a structured action space (i.e., all possible routings), which significantly complicates the analysis.

From a combinatorial routing perspective, our work is fo-cused on a relatively simple setting where each vehicle has a pre-defined destination. It would be interesting to inves-tigate whether our PCR algorithm can be extended to ac-commodate more complicated settings, such as having each vehicle visiting a set of destinations, or assuming  X  X xchange-ability X  so that each vehicle can be routed to any of the destinations (cf. [9]), or assuming uncertainty in when and where destination goals arise (such as in a taxi service).
From a game-theoretic perspective, it would be interesting to consider cases where vehicles were not assumed to coop-erative, but rather could be incentive to cooperate. One possibility is to properly price the value of exploration. We proposed a Gaussian Process Dynamic Congestion Model to capture both the dynamics and the uncertainty of congestion conditions, and the Planning using Canoni-cal Routes algorithm to balance the exploration/exploitation trade-off for entire fleets of vehicles. We conducted extensive evaluations using GPS traces collected from two large Asian cities. Our results show that our GPDCM an effectively predict the distribution of future congestion conditions, and that our PCR algorithm can achieve near-optimal perfor-mance relative to omniscient routing. We also conducted a preliminary field study, where we found our approach to significantly outperform conventional myopic routing. [1] B. Awerbuch and R. Kleinberg. Adaptive routing with [2] J. Bacon, A. I. Bejan, A. R. Beresford, D. Evans, R. J. [3] C. Benjamin. Detecting the onset of congestion [4] J. Birge and F. Louveaux. Introduction to stochastic [5] M. C. Bryson. Heavy-tailed distributions: Properties [6] G. Calinescu, C. Chekuri, M. P  X al, and J. Vondr  X ak. [7] P. S. Castro, D. Zhang, and S. Li. Urban traffic [8] C. Chekuri, N. Korula, and M. P  X  A , al. Improved [9] J. Cordeau, M. Gendreau, A. Hertz, G. Laporte, and [10] P. Dallaire, C. Besse, S. Ross, and B. Chaib-draa. [11] R. He, E. Brunskill, and N. Roy. Efficient planning [12] J. Higle and S. Sen. Stochastic decomposition: An [13] S. A. Hong. Distributed Market-Based Algorithms for [14] L. Kaelbling, M. Littman, and A. Cassandra. Planning [15] M. Kearns, Y. Mansour, and A. Ng. Approximate [16] A. Koning and L. Peng. Goodness-of-fit tests for a [17] A. Krause and C. S. Ong. Contextual gaussian process [18] H.-P. Kriegel, M. Renz, M. Schubert, and A. Zuefle. [19] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [20] X. Li, J. Han, J.-G. Lee, and H. Gonzalez. Traffic [21] S. Liu, Y. Liu, L. Ni, J. Fan, and M. Li. Towards [22] W. Liu, Y. Zheng, S. Chawla, J. Yuan, and X. Xing. [23] J. Mockus, V. Tiesis, and A. Zilinskas. The application [24] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis [25] A. Y. Ng and M. Jordan. Pegasus: A policy search [26] G. Polychronopoulos and J. Ttsitsiklis. Stochastic [27] C. Rasmussen and C. Williams. Gaussian processes for [28] D. Silver and J. Veness. Monte-carlo planning in large [29] K. Sirvio and J. Hollm  X en. Spatio-temporal road [30] N. Srinivas, A. Krause, S. Kakade, and M. Seeger. [31] M. Streeter, D. Golovin, and A. Krause. Online [32] J. Yoon, B. Noble, and M. Liu. Surface street traffic [33] J. Yuan, Y. Zheng, X. Xie, and G. Sun. Driving with [34] Y. Zheng, Y. Liu, J. Yuan, and X. Xie. Urban
