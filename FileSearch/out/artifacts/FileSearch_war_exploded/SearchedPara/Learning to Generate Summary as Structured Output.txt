 We propose to use a structured output learning for summary generation based on the maximum coverage problem. Our method learns a function that outputs the benefit of each conceptual unit in the document cluster for this summariza-tion model. In the training, we iteratively run a greedy al-gorithm that accepts items (sentences) with different costs (length) in order to generate a summary within the given maximum length limit. We empirically show that the struc-tured output learning works well for this task and also ex-amine its behavior in several different settings. I.2 [ Artificial Intelligence ]: Natural Language Processing Algorithms, Experimentation text summarization
Automatic text summarization is one of the tasks that have long been studied in natural language processing. This task is to create a summary, or a short and concise doc-ument, that describes the content of a given set of docu-ments [8] without exceeding the given length limit.
A well-known approach to text summarization is the ex-tractive approach, which selects some linguistic units (e.g., sentences) from given documents in order to generate a sum-mary. The extractive method, which we will focus on in this paper, has an advantage that the grammaticality is guar-anteed. Unlike most traditional approaches that rely on the binary classification of determining whether each sen-tence should be selected or not, some researchers have at-tempted to represent the text summarization as an optimiza-tion problem and solve it globally. One promising model among them relies on the maximum coverage problem that aims at covering as many conceptual units (usually words) as possible by selecting some sentences [4]. Although this model is powerful [11, 9], its performance should depend on the elaborate work on determining the benefits on con-ceptual units. Logistic regression was applied to predict whether each word appears in the summary or not, and its output probability is regarded as the benefit. However, it does not directly try to estimate the benefits on words that generate a good summary, but tries to emulate a local deci-sion of whether the word should be in a summary or not.
The purpose of this paper is to propose a method for learning a function that outputs the benefit of each con-ceptual unit (word), using various features such as the word frequency. For that purpose, we employ the framework of structured output learning, since the number of possible summaries is exponentially large and its output should be regarded as a structure, instead of a single category. That is, we attempt to utilize the global training of a summarization model, followed by the global decoding of the model.
Most conventional approaches to text summarization are based on the sequential sentence selection in which sentences are selected one by one. Recently there has been an effort to represent the text summarization as an optimization prob-lem and solve it globally [4, 11, 9]. One promising model is the budgeted maximum coverage problem (BMCP), which maximizes the total benefits of the words covered by selected sentences [4, 11, 9]. However, the benefits of words are deter-mined either simply by the word frequency, or by the logistic regression. In information retrieval, a method for learning a function that outputs benefits on topics (conceptual units in our case) [12]. This method finds a diverse set of k relevant items (i.e., documents in information retrieval).
We introduce a summarization model based on the BMCP.
The budgeted maximum coverage problem (BMCP) [6] has shown to be a good model for text summarization [4, 11, 9]. In BMCP model, the contents of a sentence or a doc-ument cluster are represented as a set of conceptual units, which usually corresponds to words in most implementa-tions. This model selects the sentences so that the sum of the benefits of the words covered by those sentences is max-imized. The BMCP model is expressed as follows: z is 1 if conceptual unit e j is covered, 0 otherwise. x i is 1 if sentence s i is selected, 0 otherwise. b j is the non-negative number indicating the benefit on conceptual unit e j . a ij if sentence s i contains conceptual unit e j . c i is the length of sentence s i . K is the maximum legitimate summary length.
Suppose we are given document cluster D , which is rep-resented as a set of sentences : D = { s 1 , s 2 ,  X  X  X  , s would like to solve a BMCP to generate summary S for D . S will also be represented as a set of sentences. BMCP is NP-hard, and is hence intractable in general. However, if the problem size is not very large, the branch-and-bound method can find the exact solution. Even when such efficient algorithms will not work, we can still find a good approximate solution by a greedy algorithm [6]. Greedy Algorithm U  X  D , S  X   X  while U 6 =  X  if c i + delete s i in U end while s  X  arg max s if score ( S )  X  B t , then output S , else output { s t } score ( S ) returns the value of the objective function B l denotes the sum of the benefits of the words covered by sentence s l , while B 0 l denotes the sum of the benefits of the words covered by s l , but not by current summary S .
Taking the relevance of the sentence into account signifi-cantly improves the quality of summaries [9] : P j b j a ij is simply the sum of the benefits of the words in sentence s i , and indicates the relevance of s i to the docu-ment cluster.  X  is a mixture coefficient (0  X   X   X  1). The greedy algorithm introduced above is also applicable to this variant [9]. In this paper, we refer both the original problem in Sec. 3.1 and the variant as BMCP.
The summarization performance of BMCP largely depends on the benefits on conceptual units. There are essentially two approaches to estimation of the benefits. In one ap-proach, the benefit of a word (as a conceptual unit) is simply the relative frequency of the word in the document cluster, sometimes interpolated with the relative frequency at the beginning of each document. In the other approach, logistic regression is used to predict whether each word appears in the summary or not, and its output probability is regarded as the benefit of the word. Despite their high summarization performance, those approaches are not designed directly to generate a good summary. This work aims at learning a function that determines the benefits on conceptual units for BMCP, with the help of structured output learning.
We will briefly explain Yue et al. X  X  work [12] in the context of text summarization. Note that their method is applicable only when items have the same cost as common in IR.
Although the following explanation will be on BMCP with-out the relevance term (Sec. 3.1), the same algorithm is applicable to BMCP with the relevance term (Sec. 3.3).
We first suppose that the benefits are represented as a linear function : b j = w  X   X  ( j, D ).  X  ( j, D ) is the feature vector of word j in document cluster D . Hence the benefit of a word depends on the document cluster in which the word appears. w is the weight vector and its dot-product with feature vector  X  ( j, D ) produces the benefit of the word.
We also suppose that we have access to the training data: { ( D 1 , S 1 ) , ( D 2 , S 2 ) ,  X  X  X  , ( D N , S N ) } , where D cluster and S i is its extractive reference summary, which is therefore a subset of the sentences in the document cluster. We would like to estimate vector w so that the BMCP based on benefits w  X   X  ( j, D ) generates summaries that are similar to the extractive reference summaries.

The introduced linear representation b j = w  X   X  ( j, D ) leads also to the linear representation of the objective function : where cov ( S ) denotes the index set of the words in summary S .  X ( S, D ) is the sum of vectors  X  ( j, D ) associated with the words in S :  X ( S, D ) =
Since a summary is a set of sentences in the document cluster, the number of possible outputs is exponentially large. We thus need to use the framework of the structured output learning. Among others, we use the support vector machines with structured output (structured SVM) [10]. In structured SVM, we solve the following optimization problem : min where U is the set of candidate summaries that do not vio-late the summary-length constraint. Eq. (3) is the relaxed constraint that the objective function of the extractive refer-ence summary should be greater than other candidate sum-mary S , where  X  i is a non-negative slack variable.  X ( S denotes the dissimilarity of S i and S (to be specified later).
This optimization problem can be solved by the following cutting-plane algorithm [5] : Cutting-Plane Algorithm input: { ( D 1 , S 1 ) , ( D 2 , S 2 ) ,  X  X  X  , ( D N , S N repeat: for i = 1 to N end for until no S i has changed during iterations
An algorithm that solves arg max S 2 U H ( S, w ) in a prac-tical time will be introduced in Sec. 5.2.

Once we obtain w with the cutting-plane algorithm, we can generate a summary by calculating benefit b j = w  X   X  ( j, D ), and then solving a BMCP in Sec. 3.1 and Sec. 3.3.
We propose to use the structured output learning for text summarization. We modify the method introduced in Sec. 4 so that it can be applicable to the standard text summariza-tion, where items (sentences) have different costs (lengths).
The cutting-plane algorithm requires dissimilarity func-tion  X ( S i , S ), which is defined to be :  X  m is defined to be the number of manual summaries for D i that contain word e m . We call this function the weighted dis-similarity function . We can also set  X  i m to be a binary value indicating the presence of word e m in the manual summaries of D i . We call it the non-weighted dissimilarity function .
We require an algorithm that maximizes H ( S, w ) within a practical computational time. We rewrite this problem : arg max This objective function has the same form with BMCP in Sec. 3.1. To solve this maximization problem, we propose to use the greedy algorithm introduced in Sec. 3.2, which is applicable to the cases where items have different costs. However, we should be aware that the maximization of H ( S, w ) is not always a BMCP, because ( b i j  X   X  i j / can be negative. To address this issue, we modified the greedy algorithm in Sec. 3.2 so that if B 0 i /c i is negative, s will not be inserted into S and the algorithm halts. We call this modified algorithm the greedy algorithm with halt , while we call the original one the greedy algorithm without halt .
In Sec. 4.1, we assumed that, in the training phase, we are given extractive reference summaries, which are required for calculation of  X ( S, D i ). However, it is not always the case. Only manual abstractive reference summaries are often pro-vided. In such a situation, we generate extractive reference summaries S i that are similar to the manual summaries, by solving the optimization problem, whose objective function supposedly emulates ROUGE score [7] : s lm is 1 if conceptual unit e m appears in l -th manual refer-ence summary, 0 otherwise. Unlike the previous definition of z j , z lm indicates the co-occurrence of e m between l -th manual reference summary and the resulting extractive ref-erence summary. Since this is also a BMCP, we can use the algorithms for solving BMCPs.
We conducted experiments on task 2 of DUC X 04 dataset [3], which is a multi-document summarization task. 50 docu-ment clusters, each of which consists of 10 documents with 4 manual summaries, are given. Following the official set-ting of DUC, we set the target length to 665 bytes. The DUC X 03 dataset [2] was used as the training dataset, from which the extractive reference summaries are generated as in Sec. 5.3. 1 As conceptual units, we use stemmed content words (nouns, verbs, adjectives). ROUGE version 1.5.5 [7] was used for evaluation. 2 We focus on ROUGE-1, because it has been usually used for evaluation on DUC X 04 in other pa-pers, although other ROUGE scores are more often used on newer non-generic datasets. As an implementation of the structured SVM, we modified SVM div 3 . We first set the soft-margin hyper-parameter C to 1, though we will later see the effect of changing its value. We test 0, 0.1,  X  X  X  for  X  . The branch-and-bound method in ILOG CPLEX ver. 11.1 was used to obtain the exact solutions of integer pro-gramming problems. We used the feature set used in [11].
To find the extractive summary for initialization, we test the greedy algorithm and the exact method. For the final decoding to generate a summary, we test the greedy algo-rithm (Sec. 3.2), the exact method, and the following :  X  rand : the optimization problem is relaxed to a linear pro-gramming by removing integral constraints. The solution is rounded with a randomized algorithm [6].  X  stack : the best candidate solutions for each length are cre-ated from those for smaller lengths, and stored in priority queues. This is known as stack decoding [11].

For maximizing H ( S, w ) in the cutting-plane algorithm, we always use the greedy algorithm due to its high efficiency.
We also have other options. As dissimilarity function  X ( S i , S ), we can use either the weighted or the non-weighted dissimilarity function (Sec. 5.1). As the greedy algorithm for maximizing H ( S, w ), we can use either the greedy algorithm with halt or without halt (Sec. 5.2). We set the default op-tions to be with the exact initialization and decoding, the
The ROUGE-1 score of the generated extractive reference summaries were 0.418.
ROUGE score measured without stopwords was calculated with options -n 4 -m -2 4 -u -f A -p 0.5 -b 665 -t 0 -d -s. The option -s was removed when measured with stopwords. http://projects.yisongyue.com/svmdiv/ Table 1: ROUGE-1 scores for the proposed method with different final decoding algorithms and the ex-isting methods, measured without stopwords. These are the scores with the optimal  X  , which are written after /. exact and greedy init. mean the initializations (extractive reference summary generation) respec-tively with the exact and the greedy algorithms. str exact init. .336/0.3 .333/0.3 .342/0.3 .343/0.3 str greedy init. .330/0.4 .328/0.4 .339/0.2 .340/0.4 lr with rel. .327/0.1 .327/0.1 .336/0.4 .335/0.2 lr w/o rel. .315/ X  .318/ X  .314/ X  .324/ X  freq with rel. .308/0.2 .323/0.2 .328/0.1 .335/0.2 freq w/o rel. .305/ X  .306/ X  .315/ X  .320/ X  peer65 .309 weighted dissimilarity, the greedy algorithm with halt. We will later examine the effects of those options.

We will compare our method with the following methods ( freq and lr with relevancy are also tested (Sec. 3.3) [9]) :  X  freq : the BMCP model (Sec. 3.1). The benefits on words are their frequencies in the document cluster, interpolated with the frequencies at the first 100 tokens of the documents.  X  lr : the BMCP model. The benefits are obtained by logistic regression (Sec. 2).  X  peer65 : this achieved the best ROUGE-1 in DUC X 04 [1]. Models and decoding algorithms The results of the proposed method with the default setting (i.e., exact , the weighted dissimilarity, the greedy algorithm with halt) and the other existing methods are shown in Ta-ble 1. We first note that the proposed method achieved a very high ROUGE-1 score (0.343) with the exact initializa-tion and the exact final decoding. The proposed method with the exact initialization and various final decoding algo-rithms always outperforms lr and freq (with or without rel-evancy). greedy and stack showed a good performance when initialized with exact . When initialized with greedy , each decoding showed slight degradation of scores, but the scores still remain high. Its suggests that the proposed method works well even when the exact initialization is not possible.
The average computational time for generating a sum-mary with exact decoding was 0 . 817s when we achieved the score 0.343. The computational time for training was 5495s.
We also confirmed that a good value of  X  can be obtained simply by using development data (details skipped). Effect of training options We report the result with non-default training options. Tab. 2 (a) shows the result of exact . The performance slightly de-grades when the non-weighted dissimilarity or the greedy al-gorithm without halt for maximizing H ( S, w ) is used. This result supports the use of the weighted dissimilarity and the greedy algorithm with halt. Similar results are obtained for greedy (Tab. 2(b)) and rand (Tab. 2(c)). The exception is stack in Tab. 2(d), and its reason is still under investigation.
We also conducted experiments with various values of C for the proposed method with the exact initialization and Table 2: ROUGE-1 scores measured without stop-words for each final decoding algorithm, trained with options  X  X ith or without halt X  and  X  X eighted or non-weighted  X ( S i , S )  X . These are the scores with the optimal  X  , which are written after /. halt .343/0.3 .336/0.3 halt .333/0.3 .330/0.2 the exact decoding. The summarization performance was stable : 0.342 ( C = 0 . 1), 0.343 ( C = 1), 0.342 ( C = 10).
We proposed to use a structured output learning for sum-marization based on the BMCP. Our method learns a func-tion that maps a word in the document cluster to the benefit of the word for this summarization model. [1] J. M. Conroy, J. D. Schlesinger, J. Goldstein, and [2] Document Understanding Conference 2003. [3] Document Understanding Conference 2004. [4] E. Filatova and V. Hatzivassiloglou. A formal model [5] T. Joachims, T. Finley, and C.-N. J. Yu.
 [6] S. Khuller, A. Moss, and J. S. Naor. The budgeted [7] C. Lin. ROUGE: a package for automatic evaluation [8] I. Mani. Automatic Summarization . John Benjamins [9] H. Takamura and M. Okumura. Text summarization [10] I. Tsochantaridis, T. Joachims, T. Hofmann, and [11] W. Yih, J. Goodman, L. Vanderwende, and H. Suzuki. [12] Y. Yue and T. Joachims. Predicting diverse subsets
