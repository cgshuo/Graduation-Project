 The problem of data stream classification has been studied among the research community over the recent years. One of the m ajor characteristics of data stream mining is that, the classification is a continuous process thus the size of the training data can be considered infinite. So it is almost impossible to store all the examples to train the classifiers. Some m ethods regarding incremental learning are proposed in [4,9] to address this problem. Moreover, it is a common scenario that, the underlying concept may changes overtime; a characteristic known as concept-drift .

However, another significant phenomenon of the data stream is concept-evolution , which is considered as the emergence of novel classes in the stream. For example, a new topic may appear in social network or a new type of intru-sion may be identified in the network. If the number of classes in the classifiers is fixed and no novel class detection system is present, then the novel class is falsely identified as existing class. Co ncept Evolution has become a new research direction for the researchers recently beca use of its practical i mportance. For ex-ample, if a new type of attack occurs in the network, it is imperative to identify it and take actions as soon as possible. Several approaches regarding this issue have been studied in the literature [5,7].

A special case of concept-evolution is recurring class where a class reemerges after its long disappearance from the stream. For example, a popular topic may appear in a social network at a particular time of the year (i.e. festivals or elections). This result in a change of topics in the discussion on the social network over the time period and then when the event ends the topic disappears again. A recurring class creates several discrep ancies if not properly handled. If it is not properly identified, then it is erroneously considered as a novel class or an existing one. As a result, a significant amount of human resources is wasted to detect its reappearance. Some studies re garding the problem of recurring class are present in [1,6].

The classification model for data stream can be constructed by ensemble of classifiers. In an ensemble approach, multiple base classifiers learn the decision boundary on the learning patterns and their decisions on test example ares fused to reach the final verdict. The ensemble approach is more popular among the research community because of their higher accuracy, efficiency and flexibility [5].
The contributions of this paper are as follows. In this paper, we propose a new technique to generate ensemble of classifiers to detect novel and recurring class in the data stream which reduces overall classification errors. Moreover, we have observed the phenomenon that, if the class boundary between two classes is very close, then it is possible to get a false prediction if the instances falls closely to boundary region. In our approach, we have employed several strategies to mitigate this problem. Finally, we have also used the falsely predicted instances to update our model. Our proposed method has outperformed the state-of-the-art techniques in the literature.

The rest of the paper is organized as follows. In Section 2, we discuss the previous works regarding data stream classification in the literature. We present our approach in Section 3. We discuss the e xperimental results in Section 4. We briefly conclude in Section 5. Several studies are present in the literature on data stream classification [1 X 4,6, 8 X 10]. Due to page limitation we have highlighted studies only related to novel and recurring class detection. It has been observed that, existing approaches can be divided into two categories. First one is single model approach where one classification model is used and periodically updated for new data. On the other hand, batch-incremental method constructs each model using batch learning. When older model can no longer give satisfactory results, it is replaced by newer models [9]. The advantage of ensemble model is that, updating the classification model is much simpler in this case. However, these techniques generally do not include novel or recurring class detection.

An approach to identify recurring class is presented in [6]. Here in addition to primary ensemble model, an auxiliary ensemble of classifiers is present. The auxiliary ensemble model is responsible for storing all the classes even after they disappear from the data stream. When an instance is detected as outlier in the primary ensemble, but falls within the decision boundary of auxiliary ensemble, the instances is identified as recurrent cl ass. Any test data outside the decision boundary of both ensembles are analyzed for novel class.

The approaches described in [6] are considered as chunk-based method. A class-based ensemble approach is presented in [1]. Here an ensemble model is constructed for each class C of the data stream. Each ensemble has K micro-classifiers. Initially, micro-classifiers are trained from the data chunk. When a latest labeled chunk of data arrives, a separate micro-classifier is trained for each class. Then the newly trained micro -classifier replaces the one with highest prediction error of the respective class. An instance falls outside the decision boundary of all the micro-classifiers of all the classes is considered as an outlier and saved in a buffer. The buffer is checke d periodically to detect novel class. Authors of [1] have shown theoretically and experimentally that, class-based approach is better than the chunk-based technique.

In this paper, we propose a more sophisticated approach to construct a class-based ensemble of classifiers. We have also present a better way to update and maintain the ensemble model. Moreover, we propose two types of outliers to up-date the classifiers and novel class detect ion and also take the wrongly predicted data into account to modify the classifie rs. Experiments show the effectiveness of our methods compared to other techniques. First, we discuss the fundamental concept of data stream classification. Then we describe our approach for stream classification subsequently. 3.1 Preliminaries Each data in the stream arrives in the following format: where x i is the i th instance in the stream and S is the size of the stream. D i is the i th data chunk and D  X  is the latest data chunk. The problem is to predict the class of each data point. Let l i and  X  l i be the actual and predicted label of goal is to minimize the prediction error.

Stream classification can be used in various applications such as labeling mes-sage in social network or identify intrusion in the network traffic. For example, in credit card fraud detection system, ea ch transaction can be considered as an instance or data point and can be predicted either as authentic or fraud by any classification technique. If the transaction is predicted as fraud , then immedi-ate action can be taken to withhold the transaction. Sometimes, the predicted decision can be wrong (authentic transa ction predicted as fraud or vice versa). This can be verified from the cardholder later. The feedback can be considered as  X  X abeling X  the instance and used to refine the classification model.
The major task in the data stream classification is to keep the classification model up-to-date by modifying it periodically with the most recent concept. The overview of our proposed approach is shown in Figure 1(a). The major parts of the algorithm will be described step-by-step. 3.2 Ensemble Construction and Training Now, we present the approach for generating the ensemble model. We will refer our model as R ecurring and N ovel C lass D etector E nsemble (RNCDE).
Initially, the data chunk is partitioned into C disjoint groups ( G 1 , G 2 ,..., G C ) according to the true class labels, where C is number of classes in the chunk. Therefore, each group contains the instances of one class only. Then an ensemble class i ( G i ). We apply K-means clustering to generate K clusters on the instances of each class i . For each cluster H i l a summary of the cluster i.e.  X  , the centroid, r , the cluster radius (distance between centroid and the farthest data point of the cluster) and  X  ,thenumber of points belonging to the cluster. This way we do not need every data point of the cluster. Therefore, each sub-classifier S i l is composed of all the clusters built from the instances of class i ( S i l = K j =1 H i l sub-classifiers S i l is repeated L times to construct the ensemble model E i for class i ( for each class i ( E = C i =1 E i ). For visual purpose, the partial structure of the ensemble model is shown in hierarchical form in Figure 1(b). It should be noted that, each ensemble for class i has only one sub-classifier.
 Note that, each sub-classifier S i l of an ensemble E i is trained on the same data G . We vary the seed parameters (  X  1 , X  2 , ... X  L ) of K-means clustering to diversify the sub-classifier. We have shown our method using a hypothetical example in Figure 2. In Figure 2(a), the instances of the same class are shown. The K-means clustering is applied to construct sub-classifier 1 using seed parameter  X  1 (Figure 2(b)), where K = 3. Then again sub-classifier 2 is constructed by K-means clustering initia lized by the seed parameter  X  2 shown in Figure 2(c). We can see that, identical instances belong to different clusters at each sub-classifier. for class i which is shown in Figure 2(d).
The advantages of K-means clustering is that, its lower time complexity will allow to built classifiers in reduced time which is a critical requirements for data stream mining. Another benefit is that, after construction of the clusters, it is easy to modify them compared to other types of classifiers. 3.3 Classification Here we describe our classification procedure and outlier detection. Each data point in the most recently arrived chunk is first checked for whether it is an outlier. We have maintained two types of outlier i.e. class-outlier ( C -outlier) and universal-outlier ( U -outlier). If any instance is outside the decision-boundary of all the sub-classifiers of all the ensembles( C i =1 E i ), then it considered as a U -outlier. If a data point is a U -outlier, then it is saved in buffer to analyze it further. If an instance x i is not a U -outlier then, it is inside the decision boundary of any class. It is possible that, x i may be inside of more than one class due to noise and the curse of dimensionality. Let E x i be the set of such classes. We decide which class x i belongs to by computing a coefficient ( m -value). We called this coefficient membership coefficient .The m -value (  X  i l i  X  X  where d i l cluster H i l of the inverse of distance over the size of the classifier. We refer this constant as  X  -coefficient. The max size and max distance is used for normalization. After computing m -value for each cluster of all the sub-classifiers, the class label for instance x i is computed using the equation below, The reason behind introducing the cluster size in the classification process is depicted in Figure 3(a). Her e a hypothetical scenario is shown where two different clusters of different classes are present. Boundary of one of the clusters (cluster 1) is shown in continuous line (Class 1) and the other (cluster 2) is in dashed line (Class 2). We have also shown the data points of the clusters (i.e. dots and crosses). Now consider an instance shown by  X  X  X  in the figure. It is inside the boundary of both class. If we only consider only the Euclidean distance then it belongs to Class 2. However, from the figure it is evident that, it is more prone to the centroid of cluster 1 than cluster 2. Since size of cluster for Class 1 is larger, the decision boundary of cluster 1 is more expanded. Considering only the nearest neighbor to label the instance may result in erroneous prediction. However, if we make the assumption that, all the data points of a cluster are uniformly distributed, then the number of points in the overlapped reg ion (common region between two clusters) will be greater for cluster 1 than cluster 2. In this case, the test instance will be labeled as Class 1. Therefore, a more sophisticated measurement can be possible if we take account the size of the cluster in the classification process. 3.4 Ensemble Update When the labels for data points of a chunk are available (labeled by human expert), the incorr ectly predicted data ( W ) by the ensemble model is identi-fied. Then the wrongly predicted data are separated according to their correct label. As a result, the all the inaccurately predicted data are partitioned into disjoint sets ( W 1 , W 2 , .... W C ). Then the data in W i are clustered using K-means clustering. The number of clusters K is computed using the following equation: Here ChunkSize is a constant which can be initialized manually. These newly formed clusters can be called C i -outlier clusters where i  X  C . The union of C i -outlier is the C -outlier. After the formation of C i -outlier clusters, the Euclidean distance from each C i -outlier clusters to each H i l distance among the clusters we make two types of modifications. One is cluster merge and the other is cluster replacement.

If the distance between a C i -outlier clusters and one of the clusters ( H i l ensemble is less than the radius of H i l Recall that, the data points of C i -outlier are actually the wrongly predicted instances clustered accordin g to the actual class label i .Soitisnormalthat, any cluster from C i -outlier will tend to very remain very close to the H i l the ensemble model. A possible scenario depicting the condition for merging the clusters is shown in Figure 3(b). Here the distance between C i -oulier cluster and the centroid of H i l
Now to merge the cluster, we have to cal culate the new centroid, the cluster size and the radius. To calculate the p osition of new centroid we have used the the equation below: where  X  C X  outlier and  X  C X  outlier are the size and centroid of the C i -outlier. Since two clusters are merged, size is addition of the size of two clusters. The radius is computed by combining the radii of two cl usters with the distance between the centroids.
After the merging of clusters the remaining C i -outlier clusters are replaced with the clusters from the sub-classifie r. The replacement policy is as follows. We keep a count of error  X  i l that, classification is computed by the m -value of the cluster. If prediction is wrong then count of error is increased by 1 for the cluster with max  X  i l falsely identified the class as i . Now we replace the remaining un-merged clusters with clusters with highest  X  i l get rid of the obsolete clusters and the issue of concept-drift is resolved. Since we replace the older clusters with the cl uster constructed with the most recent data points, the ensemble model remains up-to-date with the latest concept. 3.5 Novel Class Detection We have extended and generalized the idea of novel class detection in [1]. The primary assumption behind the novel class detection in [1] was, data points of the same class should be closer to each other ( cohesion ) and farther apart from the other classes ( separation ). However, first assumption (i.e. cohesion) may prove different in some complex cases. It may be possible that, data points of the same class may be clustered together in various groups where these groups may be scattered through the feature space.

If the data points of a novel class emer ge in the stream, we can assume that, the instances belonging to novel class will be far from the decision boundary of existing classes. Since data points of U -outlier are outside the decision boundary of all the existing classes, these data are analyzed for novel classes. Recall that, the U -outliers are stored in a buffer, if the size of the buffer reaches a threshold then they are analyzed for novel cla ss. We have modified the metric called q -NSC authors of [1] used and called it q -mNSC . In this method, another metric called q,c-neighborhood is used. We modify the definition of q,c-neighborhood also, which we called q,h-neighborhood. We define it as follows: q,h-neighborhood: The q,h-neighborhood (q,h(x) in short) of an U -outlier x Here q is a user defined parameter which can be initialized at the beginning. In summary, we compute the nearest q number of clusters from instance x regardless of the class the clusters belong to.

Now suppose,  X  D h out ,q ( x ) be the mean distance of a U -outlier instance x to its qnearest U -outlier neighbors. Moreover, let  X  D h,q ( x ) be the mean distance from h is the set of clusters from the existing classes. Then the q -mNSC of x can be computed according our definition:
The value of q-mNSC(x) ranges between -1 to +1. When the value is positive x is closer to U -outlier instances and away from the existing classes resulting more cohesion and vice versa.

Now we explain how we can utilize the metric to detect novel class. First, we apply K-means clustering on U -outliers to partition the data to K 0 number of time complexity(reduces from O ( n 2 )to O ( K 2 0 ), where n is the total number of data points in U -outlier). For each U -cluster we compute q nearest cluster h n for all the sub-classifiers of all the class. After that, for each U -cluster we compute q-nearest neighbor cluster of that U -cluster. Then we apply the Equation 5 to compute the q -mNSC for each U -cluster. This way we get a q -mNSC value for each U -cluster in the ensemble. If the positive value of q -mNSC is greater than a fixed number ( q  X  ) than we can conclude a novel class has emerged at the stream. First we discuss about the data set and then the parameter settings. Later, we describe the results and our remarks.

We apply the procedure described in [5 ] to generate synthetic datasets with concept evolution and dri ft. We generate three types of datasets as described in [5]. Each dataset contain 2 . 5  X  10 5 instances with 40 real value attribute. We refer each set as SynNCX having X classes (i.e. SynNC10 where total 10 classes are present).

We have also taken the real-life dataset Forest from UCI database and the 10 percent version of KDD CUP 1999 intrusion detection challenge. First dataset contains 581000 instances with 7 classes and 54 numeric attributes while the sec-ond datasets have 490000 instances having 23 classes and 34 numeric attributes. We randomly permutate the instances an d construct 10 sequ ences and report the average results. We have made adjustments to have novel instances in the sequences.

We have compared our approach (RNCDE) with class-based approach (CL) [1], ECSMiner (EM) [5], the clustered-b ased method presented in [8] (OW) and chunk-based approach (SC) described in [6]. 4.1 Parameter Settings We have set the size of the ensemble L = 3, number of clusters per sub-classifier K = 20. The minimum number of instances to detect novel class q Moreover,  X  is varied between 3 to 8 and size of the buffer is set to the 20% of the size of the chunk. These parameters are set either according to the parameters of the previous works or by running preliminary experiments. 4.2 Evaluation We have used the following evaluation cr iteria for performance measurements. M new = % of novel class instances misclassified as existing class, F new =%of existing class instances mi sclassified as novel class, OTH = % of existing class instances misclassified as another existing class and ERR = average misclassfi-cation error (average of three types of error).

Initially, we construct the ensemble model from first three data chunks. Then we begin our performance evaluation from the chunk four. Table 1 summarizes the results from all the methods. We have taken the summary results on other methods from [1] and compared with our approach. OTH can be calculated from the other errors, so we do not show it. From the table, we can see that, OW has the highest error rate, because it can not detect majority of the novel class instances. Therefore, the F new rate is also high in case of OW.
EM can identify novel class but it can n ot detect recurring class. As a result, recurring classes are detected as novel class and it has a high F new rate also. SC maintains an auxiliary ensemble model which contains classifiers for all the class including recurring class. Theref ore, it has comparatively lower F new rate than EM. CL uses class-based ensemble to detect novel and recurring class and it has a lower error rate than the approaches above. Our proposed method RNCDE also have shown comparatively lower error rate than other methods. In Forest dataset, the ERR is slightly higher than CL, but in other case RNCDE shows better performance than other approaches.

In Figure 4, ERR rates for both Synthetic and Real Data are shown. In each case X axis represents number of data points and Y axis represents the ERR. For example from the Figure 4(a) and 4(b), we can see that, ERR rates after 300000 data points are 20% for forest , 10% in KDD . For synthetic data ERR remains almost constant. In case of KDD we can see at the beginning ERR fluctuates, but the ERR decreases afterwards. This occurs because the at first the class boundary among classes are not accurately drawn so misclassification among existing classes (OTH) rais es ERR. When the concept is learned comprehensively then ERR decreases. On the other hand, in forest ERR rises gradually. This is because M new increases continuously when more data points arrive.
 4.3 Parameter Sensitiveness We have observed the effect of a number of parameters on our algorithm. Due to page limitation we describe only one parameter number of clusters per sub-classifier K .The K is varied between 10 to 50. The impact of varying K for synthetic dataset is shown in Figure 5. We can see from the figure that, ERR decreases, if the number of cluster K increases. The reason behind this is when the number of clusters increases more accurate decision boundary can be drawn among the classes. When the value of K is increased, more clusters will be formed on the same instances. Therefore, the si ze of the clusters will be comparatively lower and each cluster will learn the small portion of the total concept. If the boundary between two classes is noisy then more and smaller clusters will per-form better than fewer and larger clusters. In other words, the boundary of the class will be more accurate co nstructed if an increased number clusters is formed. That is why ERR deceases if K is increased. However, it should be noted that, if the value of K is high, then it would result in high space requirements and increased time complexity, which has a detrimental effect on the performance of the model. So the value of K should be adjusted to balance between the performance and accuracy.
 In this paper, we have proposed a new ensemble model for detecting novel and recurring class in continuous data str eam (RNCDE) which can be considered as a class-based approach as opposed to the chunk-based approach. Our algorithm have shown good performance against state-of-the-art methods in the literature. We have built our initial ensemble model for each class and updated and modified it periodically to learn the most recen t concept. Each ensemble model has a sub-classifier which is composed of a numbe r of clusters. The union of the cluster constitutes the concept of class. Our m ethod has been proven very effective in data stream mining. Inspired by the promising results, we will concentrate on more efficient techniques for data strea m classification. We are also planning to experiment our method on other real life data.

