
For the discovery of similar patterns in 1D time-series, it is very typical to perform a normalization of the data (for ex-ample a transformation so that the data follow a zero mean and unit standard deviation). Such transformations can re-veal latent patterns and are very commonly used in datamin-ing applications. However, when dealing with multidimen-sional time-series, which appear naturally in applications such as video-tracking, motion-capture etc, similar motion patterns can also be expressed at different orientations. It is therefore imperative to provide support for additional trans-formations, such as rotation. In this work, we transform the positional information of moving data, into a space that is translation, scale and rotation invariant. Our distance measure in the new space is able to detect elastic matches and can be efficiently lower bounded, thus being computa-tionally tractable. The proposed methods are easy to imple-ment, fast to compute and can have many applications for real world problems, in areas such as handwriting recognition and posture estimation in motion-capture data. Finally, we empirically demonstrate the accuracy and the efficiency of the technique, using real and synthetic handwriting data. Advances in wireless communication, sensor devices and GPS technology make it possible nowadays to collect large amounts of trajectory data. A trajectory is a set of posi-tional information of a moving object, ordered by time. Ex-amples include tracking animals, gathering human motion data by tracking various body joints, or tracing the evolution of migrating particles in biological sciences. In fact, multi-dimensional trajectory data are prevalent in many fields such as environmental information systems, meteorology, wireless technology, video tracking, or video motion capture.
An important problem in such applications is designing techniques for identifying trajectories that are similar. Such techniques can be used to cluster sets of trajectories, to in-de xsets of trajectories so that nearest neighbor queries can be executed efficiently, and to classify new trajectories given a set of examples.

While the design of distance functions between trajecto-ries has been considered in recent work [15, 14, 7], none of these techniques consider similarity measures that are rota-tion invariant . In many applications, a similarity measure that is immune to rotation effects is desirable. To illustrate this, consider a hand-writing recognition application, where each letter is represented by a two-dimensional trajectory. In this application, we are interested in classifying a new trajectory, given a set of letter examples. For example, all the trajectories in Figure 1 represent the same letter, so they should be considered similar to one another. However, none of the currently proposed techniques can tackle the problem effectively, primarily because they are not capable of eliminating the rotation component from the similarity calculations.

In this paper we seek distance measures for trajectories that are invariant under rotations. Furthermore, we seek distance functions that are efficient to compute, so that op-erations such as clustering and indexing for nearest neighbor calculations do not suffer from performance penalties. Our main contributions are the following:
First, we present a distance measure that allows us to find similar trajectories under translation, scaling and rota-tional transformations. We adapt techniques developed in [4] to first map each trajectory to a trajectory in a rota-tion invariant space. We extend the robustness of this work by introducing a novel iterative modulo normalization tech-nique. The distance of two trajectories in the new rotation invariant space, is computed using Dynamic Time Warp-ing (DTW). We show that the resulting distance measure is robust under the desired family of transformations (trans-lation, rotation, scaling), and moreover, is very efficient to compute. We provide experimental evidence to demonstrate the accuracy of our distance measure.

Second, we give a new technique for lower-bounding our distance measure. Our lower-bounding is a general tech-nique for lower-bounding the DTW distance, and is there-fore of independent interest. We compare our technique with recent efforts on this problem, and show that our approach is efficient and more accurate than previously known tech-niques.
The problem that we examine in this paper is related to problems studied in the areas of pattern recognition and computer vision, such as testing for congruence of point sets [1, 5], which is a fundamental (and still open) problem in computer vision. Also related to this general area are prob-Transformation including (b),(c),(d) and deformation lems in medical image registration [10], and geometric hash-ing [6].

Inspired by the work of Cohen and Guibas [4], we use the turning angle transformation as our invariant matching signature. The work of [4] deals with planar lines (and not trajectories), where the x-y position of two dimensional line shapes are transformed into an angle/arc-length space. The partial (subsequence) matching problem, is solved by a line sweep algorithm in a scale-shift plane and guarantees scale, translation and rotation invariance. This comes at a high cost of O ( m 2 n 2 ) time complexity for lines of length m and n respectively. Moreover, while this method can handle global scaling, there is no support for local scaling. Compared to other methods based on algebraic moments, curvature [11] and Hausdorff distance [3], the turning angle has been shown to be the most robust for the retrieval of two dimensional images and shapes [12].
Let P be a trajectory of a moving object. P is then a sequence of 2-dimensional vectors 1 , each describing the po-sition of the object at time instants 0 to n  X  1:
Let F be a distance measure for trajectories. F can be, for example, the Euclidean metric, or the Dynamic Time Warping distance. Let R be the set of two dimensional rotations around the axis origin. Let also T be the set of two-dimensional translations and S be the set of all scaling operations by a global factor.

Figure 1 describes the effects of different transformations on a trajectory.

Let T X  be the set of transformations that are composed by rotations, translations and scaling.

Given two 2-dimensional trajectories T,Q , and a distance measure F , we are interested in computing the smallest pos-sible distance of T and Q if we allow transformations in T X  to be applied to one of the trajectories.
 This new distance measure, F inv can be expensive to com-pute, therefore here we tranform the trajectories into a new space with invariant characteristics where the matching can be more efficiently performed.
Although this paper considers mainly 2-dimensional appli-cations, the techniques can be extended to higher dimen-sions.
It is difficult to design distance measures that are invariant to rotation using positional information directly. Instead, we use a modification of a technique by [4] to map the trajec-tories to a space that is more amenable to this purpose. We briefly describe the technique below: We define the movement vector Vattime t as:
We extract the angles of each movement vector relative to a reference movement vector V ref . This reference vector is the positive x-axis or vector [1 , 0]. In other words, we calcu-late how much is the acute rotation angle that is required to align the vector V ref to the direction of the current move-ment vector V t .

The acute angle  X  between these two vectors is computed utilizing the dot product as follows: and &lt;  X  ,  X  &gt; signifies the vector dot product.
However, the dot product does not specify the direction of the rotation, which is denoted by sign .(e.g.,clockwise or counterclockwise). This information is obtained using the direction of the cross product between V t and V ref ,byexam-ining whether it spans towards the positive or the negative z-axis. For 2D trajectories the sign is calculated as:
In addition to the angle of each movement vector we also record its Euclidean length L (arc length). Therefore, we have transformed the spatial coordinates of a trajectory into a sequence of A ngle/ A rc-L ength pairs. We call this new transformed space, AAL space and figure 2 shows how the AAL representation of a 2-dimensional trajectory is com-puted.

We also consider different approaches to define the ref-erence vectors required by the AAL transformation. As a reference vector, instead of the positive x-axis (which we call exact angles ), one could use other vectors as well. In this work we also consider the following: Angle Relative to Previous ( relative angles ) :
The problem with this approach is that small differences in the angles can be compounded in the original trajectory, resulting to a large deviation between two sequences, while the distance in the AAL space remains small. Angle Relative to center of Mass ( cMass angles ): The center of mass is defined as the average of the different locations of the object over time:
P
In the experimental section we show that both exact and cMass angles, have good robustness under real or synthetic datasets. The relative angles perform well for the synthetic ones, but for real datasets their performance degrades rapidly.
Representation of trajectories in the new space offers sig-nificant advantages over the spatial representation, because it is translation invariant. Additionally when we are com-puting exact angles from a reference vector, rotation of a trajectory by  X  degrees this will result in a shifted pattern by  X  degrees in the AAL space. Finally, scale invariance can be accomplished by dividing the arc length of each move-ment vector by the total arc length of the trajectory.
After the transformation of the x-y position of the tra-jectories into the angle/arc-length space (using the exact angles ), similar but rotated trajectories will depict analo-gous patterns in the new space. However, the patterns may differ by some amount of vertical shift according to their orientation. Figure 3: Left: Trajectories plotted on 2D. Right: Angle/Arc-Length features extracted from the tra-jectories.

To create a rotation invariant transformation we normal-ize the transformed sequences. A simple normalization would be to subtract the average angle value. This, nonetheless, is not sufficient because this average value can be signifi-cantly distorted. For example, figure 3 shows two similar (but not identical) 2D trajectories. Their similarity is more prevalent if the darker one is rotated clockwise by around 70 o . The patterns in the AAL space appear very similar but they are distant by a vertical shift corresponding to 70 in the angle axis. Additionally, one can observe that some sections of the 2nd trajectory appear very noisy in the AAL space. This is attributed to the fact that certain consecutive movement vectors can oscillate around the  X  angle. Figure 4 demonstrates the two feature patterns when the average angle value is subtracted from both trajectories. Obviously, an even better matching can be found (see Figure 5).
For this purpose we introduce an iterative normalization procedure. The pseudo-code of the algorithm is illustrated in Figure 6 and it performs two basic steps: Figure 4: After Regular Normalization (subtraction of mean value)
These phases are repeated a certain number of times or until stability. For simplicity in all our experiments we it-erate the normalization steps five times, which proves to be more than adequate for achieving stability. Figure 5: After Iterative Normalization. Now the similarity between the two sequences is much more obvious. Figure 6: Algorithm Iterative Modulo- X  Normaliza-tion
Using the previous transformations we have addressed the issues of translation, rotation and scaling. However, in order for the two patterns in Figure 5 to be matched effectively it is necessary to provide support for local compressions and decompressions in the arc-length axis. To accomplish that we use a warping distance measure in the AAL space.
The most widely used measure that supports local com-pressions and decompressions is Dynamic Time Warping (DTW) [2, 8, 14]. In order to utilize the DTW one as-sumes that the measurement values (in this case the an-gles), are taken at discrete and equi-spaced time instances and from left to right. (arc lengths for our case), which we achieve this by resam-pling/interpolating the sequence of angle/arc-length pairs.
If Q =( Q 1 ,Q 2 ,...,Q n )and Head ( Q )=( Q 1 ,Q 2 ,...,Q (and similarly for a sequence T ) then the recursive equation to provide then warping distance between Q and T is: where D (  X  ,  X  ) is the distance between two points of the se-quence. Typically, D is the Euclidean distance, but it can be any distance complying to the requirements of a specific application.

In our setting of this problem we use a different distance function in the warping definition. We call the new distance D warp and we use it to mitigate the potential wrap-around effect of the turning angles: The DTW distance can be computed using a well known dy-namic programming algorithm in O ( n 2 )timeforsequences of length n .
Since the O ( n 2 ) complexity of DTW quickly becomes a bottleneck for large datamining tasks, one can reduce the warping scope within a matching region of  X  2 effectively re-ducing the complexity into O (  X n ). This simplification is realistic for most real applications and in many cases it can also improve accuracy by limiting the number of degenerate matchings 3 .
 We revisit some of the most recent DTW lower bounds. The work of Keogh [8] instigated an enhanced interest in the Warping Distance, by introducing a new tight lower bound, called LB-Keogh. The idea is based on the notion of the Minimum Bounding Envelope (MBE), which records the areas of possible matching, when local displacement is constrained within a region  X  .TheMBEofasequence Q
That is, allow matchings between two points if they are  X  points apart.
Typical values for  X  are 20  X  30% of n . consists of the area defined between the upper envelope U and the lower envelope L and their values at position i is given by:
L i = min ( Q i  X   X  ,...,Q i +  X  ) ,U i = max ( Q i  X   X  ,...,Q
The author further showed that this lower bounding func-tion can be indexed, by introducing a reduced dimension-ality version of it called LB  X  PAA , which is illustrated in figure 8. This is achieved by creating a simplified rep-resentation of the query MBE and all database sequences, by converting them into k equi-length Minimum Bounding Rectangles (MBRs) 4 .EachofthekMBRsof Q consists of a tuple, [ X  q i,L ,  X  q i,U ]withvalues: When segmenting any database sequence T into MBRs, us-ing the above equation we can essentially consider that U L
The lower bound distance LB X  X AA is the distance be-tween the MBRs of the query envelope ( MBR ( MBE ( Q ))) and the MBRs of T ( MBR ( T )), which is shown in gray vertical lines in Figure 8).
 Figure 8: LB X  X AA. The total length of the gray vertical lines represents the lower bound distance.
Extensions of the MBE for multidimensional sequences and introduction of new upper bounds have appeared in [14].

In [16] Zhu and Shasha, improved on the previous idea, by leveraging the lower bounding property of the PAA rep-resentation [9]. The PAA approximation is a simple and ef-fective dimensionality reduction technique, that converts a sequence of length n into k equi-length segments, that record k is a user defined parameter. average values of the original sequence. That is PAA ( Q )= (  X  q 1 ,  X  q 2 ,...,  X  q k ), where :
Similarly as before, the MBE of the query Q is constructed, however both the envelope (U &amp; L) and any other sequence T are approximated by their PAA representation. The new lower bound, LB X  X hu, is essentially the distance between PAA ( MBE ( Q )) and PAA ( T ). A schematic representation is given in Figure 9.
 Figure 9: LB X  X hu. The lower bound on the distance is marked by the gray vertical lines.
The envelope-based approaches are fast to compute, how-ever the tightness of the lower bound diminishes for large warping lengths (that is, when the parameter  X  becomes too large). This happens because the bounding envelope becomes very wide.
 We propose a different approach for approximating the DTW. In order to minimize the impact of  X  (the width of the bounding envelope), we use only approximations of the query sequence Q and the database sequence T .Wecom-pute the Minimum Bounding Rectangle approximation of the query sequence Q ( MBR ( Q )), and the PAA approx-imation of a sequence T in the database, PAA ( T ). The distance between the segments MBR i ( Q )=[ X  q i,L ,  X  q i,U PAA j ( T )=  X  t j is defined as:  X  can be any distance such as the squared Euclidean or, in our case, the D warp distance which mitigates the wrap-around effects.
 Figure 10: LB-Warp delivers a tighter lower-bound than previously used approaches.
 In order to lower bound the warping distance between Q,T we just need to run a DTW computation on the ap-proximations, using D seg as the base distance function. We call this lower bound LB  X  Warp . Additionally, the warping length needs to be modified. If the original warping compu-tation allowed matching within  X  points (out of n ), it has to be modified now to  X  ( k n ) . Therefore the running com-plexity is reduced from O ( n X  ), to O ( k  X  ( k n ) ). In Figure 11 we give an example of how the new bound is computed; no envelope is computed around the query sequence (compare with Figure 10), but the approximation segments of the two sequences can be matched with neighboring segments. We can state the following lemma: Lemma 1. (Lower Bounding Lemma): Given trajectories Q and T of length n and warping length  X  , and their approx-imations of length k , MBR ( Q ) and PAA ( T ) the following inequality holds:
LB  X  Warp  X  ( k
We show the rotation invariance of the new measures, using a real dataset obtained through a graphic tablet, where the x-y position of the stylus is recorded over time ( tablet real dataset). This dataset contained 90 two-dimensional time-series, a subset of which is shown is Figure 11. Figure 11: Subset of the dataset used in our ex-periments ,consisting of various strokes (at different angles) written on a graphic tablet.

Based on the tablet real dataset, we created also a syn-thetic dataset, using a single orientation of each tablet stroke and creating three additional copies by rotating the template at random angles between [  X  90 ... +90 o ]( tablet synthetic ) This dataset is used as a sanity check, to examine possible performance deviations between synthetic and real datasets.
We have conducted a leave-one-out Nearest Neighbor clas-sification scheme, in order to measure the classification accu-racy of the rotation invariant distance measures. We observe that the Exact Angles (all angles are with respect to a ref-erence direction) and the cMass Angles techniques are both very accurate. The performance of the Relative Angles ap-proach is good for synthetic data, however only Exact and cMass Angles give good accuracy for real data. This ex-ample indicates (once more) the great discrepancy that can exist in the performance of an algorithm between synthetic and real datasets.

In fig. 12 we show a 2D mapping of 40 handwritten strokes based on their pairwise distances. The position of the sym-bols on 2D plane, is derived using ISOMAP [13], which represents an improved implementation of Multidimensional Scaling. The spatial proximity in 2D of the rotated versions of the same symbol, indicates that the new representation is very robust to rotation transformations. Table 1: Accuracy rates for leave-1-out classification experiments using the handwriting dataset.
 Figure 12: 2D mapping of handwritten strokes based on the rotation invariant measures.
Using the sequences of the tablet real dataset as seeds, we generated datasets with larger cardinality (1000, 2000, 4000 and 8000) for testing the scalability and pruning power of the new lower bound.

We evaluate the pruning power of the lower bounds, us-ing a scheme not affected by implementation details. We accomplish this by measuring the number of raw sequences retrieved from disk, in order to find the 1-Nearest-Neighbor (1NN) to a given query, averaged over 50 queries.
We observe that the new lower bound represents a signifi-cant enhancement over the previous approaches. For certain queries we may examine up to 35 times fewer sequences than LB X  X eogh and up to 15 times fewer sequences compared to LB X  X hu (Figure 15).
 Figure 13: Fraction of the dataset objects examined, averaged over 50 queries. The new lower bound, LB X  X arp ,examines consistently the fewest number of sequences.

In figure 14 we report the cumulative time for return-ing the 1NN for 50 queries. This time includes the lower-bound distance calculation as well as the time to find the 1NN and the experiment is conducted for increasing dataset sizes. We observe that LB  X  Warp outperforms all previous approaches.
 Figure 14: LB-Warp can reduce the running time by 40% ,compared to next best method.
