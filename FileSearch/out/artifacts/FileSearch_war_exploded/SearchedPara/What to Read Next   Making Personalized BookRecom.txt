 Finding books that children/teenagers are interested in these days is a non-trivial task due to the diversity of topics cov-ered in huge volumes of books with varied readability levels. Even though K-12 readers can turn to book recommenders to look for books, the recommended books may not satisfy their personal needs, since they could be beyond/below their readability levels or fail to match their topics of interest. To address these problems, we introduce BReK12, a book rec-ommender that makes personalized suggestions tailored to each K-12 user U based on books available on a social book-marking site that (i) are similar in content to the ones that are known to be of interest to U , (ii) have been bookmarked by users with reading patterns similar to U  X  X , and (iii) can be comprehended by U . BReK12 is an asset to its users, since it suggests books that are appealing to its users and at grade levels that they can cope with, which can increase their reading selection choices and motivate them to read. We have also developed ReLAT, the readability analysis tool employed by BReK12 to determine the grade level of books. ReLAT is novel, compared with existing readability formu-las, since it can predict the grade level of a book even if an excerpt of the book is not available. We have conducted empirical studies which have verified the accuracy of ReLAT in predicting the grade level of a book and the effectiveness of BReK12 over existing baseline recommendation systems. H.3.3 [ Information Search and Retrieval ]: Information Filtering, Retrieval Models, Selection Process Book recommendation system, readability, K-12
Reading, an essential skill required for acquiring knowl-edge, is an integral part of the educational system. It is im-perative to encourage K-12 students to read, since research studies have confirmed the enormous influence of reading on students X  development as learners and members of society, especially at an early age. Finding books that K-12 readers are interested in, however, is a difficult task due to the di-versity of topics covered in the huge volume of books that target readers of different backgrounds and age groups. Rec-ommender systems, which have been developed to suggest items of interest to their users, are supposed to alleviate the book-finding problem. However, existing recommenders em-ployed at well-known book-affiliated websites, such as Novel-ist (www.ebscohost.com/novelist) and Amazon.com, adopt a  X  X ne-size-fits-all X  strategy, which makes the same sugges-tions to different users on a given book without considering their individual preferences [14]. On the contrary, recom-menders that offer personalized book suggestions overlook the readability levels of their users, since they are conceived with a general audience in mind. As a result, even if a book recommended to a user U matches U  X  X  interests, the book might include complex (simple, respectively) content that is beyond (below, respectively) the readability level of U , which fails to sustain the mission of matching users X  reading abilities with the suggested literature [1]. Moreover, these recommenders rely heavily on the existence of personal rat-ings [26] assigned to books by users, which are rarely pro-vided by K-12 users of the existing social bookmarking sites established for them.

To address the aforementioned design problems of book recommendation systems, we have developed BReK12, a book recommender that makes personalized suggestions for K-12 users. To locate books for a user U based on U  X  X  read-ing ability and interests, BReK12, which is designed to be integrated into a social bookmarking site on books, analyzes U  X  X  profile, i.e., books that have been bookmarked by U on the site. If U is a new user, BReK12 treats a book pro-vided by U as U  X  X  profile. In doing so, BReK12 bypasses the cold-start problem often encountered by recommenders [24]. BReK12 first infers U  X  X  readability level by analyzing the grade levels of books in his/her profile, which are deter-mined using ReLAT, a robust readability level analysis tool that we have developed. Hereafter, BReK12 identifies a set of candidate books, among the ones archived at the site, with grade levels compatible to the inferred readability level of U . For each candidate book, BReK12 determines its con-tent similarity and readership similarity with books in the profile of U based on the brief descriptions of books that are publicly available online and users X  bookmarking patterns on the site, respectively. An aggregation strategy [3] is adopted so that the top-10 candidate books, with grade levels appro-priate for U and with the highest combined content-and readership-similarity scores, are recommended to U .
BReK12 is unique, since its design goal is to suggest books to K-12 users that simultaneously match their interests and reading abilities , which in turn can motivate them to read. Unlike state-of-the-art recommenders [24], BReK12 simply employs readily available data, i.e., user bookmarks and brief descriptions of books, accessible from the social bookmark-ing sites where BReK12 is installed and book-affiliated web-sites, respectively to make recommendations. Moreover, BReK12 applies similarity, besides exact, matching on words to recommend books that are similar in content to users X  bookmarks, which otherwise could be ignored.

BReK12 relies on ReLAT to determine the grade level of abook B basedonthe subject areas addressed in B ,the readability level of the intended audience of books written by the author of B , subject headings assigned to B ,andthe grammatical/sentence structures in (an excerpt of) B ,ifany is available. Unlike existing readability formulas/tools, such as Lexile Analyzer and Flesch-Kincaid, ReLAT can predict the readability level of a book even if (a sample of) the text of the book is unavailable, which is its novelty.
Besides serving social bookmarking site users, BReK12 can also recommend books for each K-12 patron of a school/ public library, assuming that the list of books of interest provided by the library patron and the book catalog used by the library are given. In addition, BReK12 can be adapted to make recommendations for users of any book-affiliated website based on books searched by the users on the site. The remaining of this paper is organized as follows. In Section 2, we discuss existing readability formulas and book recommenders. In Sections 3 and 4, we introduce ReLAT and BReK12, respectively. In Section 5, we present the re-sults of the empirical studies conducted to (i) assess the performance of ReLAT and BReK12 and (ii) compare their performances with existing approaches. In Section 6, we give a concluding remark and directions for future work.
In this section, we present a number of widely-used read-ability formulas/analysis tools and book recommenders and compare them with ReLAT and BReK12, respectively.
For almost a century, hundreds of readability formulas have been developed for predicting the readability level of a text [4, 7]. Traditional readability formulas, such as Flesch-Kincaid and Coleman-Liau, rely on shallow features, which include word frequency and sentence length, to compute the grade level of a text. These formulas, however, often provide a rough estimation of text difficulty, which  X (may) judge a nonsense passage as quite readable if the text X  X  jum-bled words are frequent, short, and organized into brief sen-tences X  [4]. Recently-developed formulas are based on (i) linguistic features, such as the ones introduced by Feng et al. [9] and Collins-Thompson and Callan [7], (ii) pre-defined word lists , such as Lexile and Revised Dale-Chall formula, (iii) enhanced shallow features , such as the Advantage-TASA Open Standard for Readability (ATOS) formula, and (iv) non-textual features , such as SVM-Ranker [15], which ex-amines images on books to predict their grade levels, and ReadAid [22], which considers information about the au-thors of a book and US Curriculum topics addressed in the book in addition to exploring the lexicographical and syn-tactical structures of the book. While most of these formulas are widely-used and popular, none of them can predict the readability level of a book if (a sample of) its text is not available, which can be achieved by ReLAT. (See [4] for an in-depth discussion of existing readability formulas.)
A number of book recommenders [14, 20, 26] have been proposed in the past. Amazon X  X  recommender [14] suggests books based on the purchase patterns of its users. Yang et al. [26] analyze users X  access logs to infer their prefer-ences and apply the traditional collaborative-filtering (CF) strategy, along with a ranking method, to make book sug-gestions. Givon and Lavrenko [10] combine the CF strategy and social tags to capture the content of books. Similar to the recommenders in [10, 26], the one in [25] adopts the standard user-based CF framework and uses a domain on-tology to determine the users X  topics of interest. The rec-ommenders in [10, 25, 26] overcome the problem that arises due to the lack of initial information to perform the rec-ommendation task, i.e., the cold-start problem. However, unlike BReK12, they are constrained by requiring historical data in the form of ratings to make recommendations, which may not always be available. Moreover, the recommender in [25] relies on the existence of a book ontology, which can be labor-intensive and time-consuming to construct. In mak-ing recommendations, Park and Chang [20] analyze indi-vidual/group behaviors, such as clicks and shopping habits, and features describing books, such as their library classifi-cation, whereas PReF [21] suggests books bookmarked by connections of a LibraryThing user. Similar to BReK12, PReF adopts a similarity-matching strategy, which differs from the exact-matching constraint imposed in [20] and a number of content-based recommenders [11, 18]. However, neither PReF nor any of the aforementioned recommenders considers the readability level of their users as part of their recommendation strategies. While BReK12 is not a recom-mender system for learning [24] per se, its design goal is to aid children/teenagers in developing good reading habits so that they can succeed at school and in the living of a good life. With that in mind, BReK12 is designed as an educational enrichment tool. (An in-depth discussion of ex-isting recommender systems in the educational domain can be found in [16].)
As previously stated, existing readability formulas/analysis tools rely on at least a sample of a text to compute its read-ability level, which is a severe constraint, since text in a book is not always freely accessible due to the copyright laws. To alleviate the text constraint, we have developed ReLAT , which determines the grade level of any book using metadata on books publicly accessible from reputable online sources, in addition to sample texts of books only if they are available. Analyzing a book using multiple perspectives, ReLAT can predict its grade level even if an excerpt on the book is missing. Furthermore, ReLAT instantly produces the grade level of a book, which is not always possible using commercial readability analysis tools. For example, Lexile offers scores for only approximately 150,000 out of the mil-lions of books published worldwide in English, and requires Figure 1: The grade-level prediction process of Re-LAT, our proposed readability level analysis tool direct involvement of its developers to generate the readabil-ity level of any book which has not yet been analyzed [4]. Figure 1 depicts the grade level prediction process of Re-LAT. To determine the grade level of a book B ,ReLAT takes as an input a unique identifier of B ,whichcanbeits ISBN number or its title and author. Thereafter, ReLAT ex-tracts from reputable online sources, such as WorldCat.org and OpenLibrary.org, (i) an excerpt of B , (ii) topical in-formation of B , and (iii) information about the author 1 B , whatever is available. Based on the extracted data on B , ReLAT examines up to fifty-nine predictors to determine the grade level of B . The predictors are treated as contribut-ing factors , i.e., evidences, which are used in analyzing the grade level of B . Due to the space constraint, we do not define each predictor 2 . Instead, we present the nature of predictors in each category (as shown in Figure 1) below. (I) Predictors based on an excerpt of B examine
We have empirically verified that by considering only the first author of a book B , the processing time of ReLAT is minimized without affecting its accuracy in predicting the grade level of B . This is expected, since less than 10% of the hundreds of thousands of K-12 books we examined at AR-bookfind.com and Scholastic.com are written by co-authors.
The list of all the predictors and the categories to which they belong can be found in tinyurl.com/dyp6ysl. (II) Predictors based on topical information of B analyze its Subject Headings, e.g., X  X iography X , which are short phrases that capture the topics covered in books and are used by the US Library of Congress to categorize books. Based on a mapping between Subject Headings and grade levels (that we have already determined using Subject Headings assigned to books with a known grade level), ReLAT identifies the grade levels that correspond to each of the Subject Headings of B . These grade levels are taken into account by ReLAT to determine the grade level of B . (III) Predictors that consider author information of B are based on the fact that, in general, K-12 authors write for a particular group of readers at a certain grade level. For this reason, ReLAT treats the audience level metric of an author defined by WorldCat, which captures the  X  X ntellectual level of the audience for which the item is intended, X  in addition to the topical information and subject areas of the author X  X  other books (as introduced in I and II, respectively) as addi-tional predictors that determine the overall grade level of B .
Since the information required to compute the value of a predictor can be missing, it may not be possible to use all the predictors for predicting the grade level of B .ReLATcon-siders various combinations of the 59 predictor coefficients and applies multiple linear regression analysis [17] (given be-low) on predictors applicable to B to predict its grade level. where c 0 is the intercept term, c i (1  X  i  X  n )isthe regression coefficient of predictor x i ,and y is the predicted grade level.
Prior to applying Equation 1 to predict the grade level of a book, the intercept and coefficients associated with each ap-plicable predictor are computed through a one-time training process using the ordinary least squares estimation method [17] on a training set of 8,737 K-12 books written by dif-ferent authors that cover diverse topics and were extracted from various publishers X  websites and the Children X  X  Litera-ture Comprehensive Database (CLCD.com). Each training instance consists of the (values of) predictors that apply to a book B and the grade level of B determined by its publisher. Since publishers usually suggest a range of readability levels for each of their published books, ReLAT considers the av-erage grade level of the range defined for B as its grade level during the training process. In doing so, ReLAT avoids any bias that might occur by assigning books their lower/upper grade bound during the regression training.
 Example 1. Consider the book  X  X ive Little Kittens X  by Nancy Geller Jewell, which is a 32-page picture book with some long sentences. As stated in [23], unlike existing read-ability formulas that often overstate the difficulty of books for emergent readers, Accelerated Reader (AR) is a decent measure on the readability levels of books. Even though  X  X ive Little Kittens X  is appropriate for grades K-3, as sug-gested by its publisher, its Flesch-Kincaid grade level is 4.6 and its Lexile score is 970 (which corresponds to grades 6-7). The AR grade level for the book is 2.6, which matches the target audience for the book. The AR score, however, sug-gests that children should be at least in the 2 nd grade to read  X  X ive Little Kittens, X  whereas the grade level predicted by ReLAT, which is 0.9, indicates that Kindergartners can read the book, providing a grade level more compatible (than AR X  X ) with the book publisher X  X . (See Section 5.3 for the performance analysis of ReLAT.)
In this section, we present the design of BReK12. Given the profile P of a user U , BReK12 selects a set of candidate books, which are compatible with the readability level of U (determined in Section 4.1). Hereafter, BReK12 assigns a ranking score to each candidate book B , which is computed using an aggregation strategy (introduced in Section 4.4) on the content and readership similarity of B with respect to the books in P (defined in Sections 4.2 and 4.3, respectively).
BReK12 recognizes that  X  X eading for understanding can-not take place unless the words in the text are accurately and efficiently decoded X  [19] and only recommends books with readability levels appropriate to its users.
BReK12 applies Equation 2 to estimate the readability level of a user U , denoted RL ( U ), based on the grade level of each book P B in U  X  X  profile predicted by ReLAT, de-noted ReLAT( P B ). Note that only books bookmarked in a user X  X  profile during the most recent academic year are considered, since it is anticipated that the grade levels of books bookmarked by users gradually increase as the users enhance their reading comprehension skills over time. where | P | denotes the number of books in U  X  X  profile and average is employed to capture the central tendency on the grade levels of books bookmarked by U .
 Having established U  X  X  readability level, BReK12 creates CandBks , the subset of books archived at the bookmark-ing site that are within-one-grade-level range from U  X  X . By considering books within one grade level above/below U  X  X  mean readability level, BReK12 recommends books with an appropriate level of complexity for U and grade levels ap-proximate to the grade levels of books that have been read by U (as of the most recent academic year).

Example 2. Consider a BiblioNasium.com user U who has bookmarked a number of books from Dav Pilkey X  X  X  X ap-tain Underpants X  series. Based on the grade levels predicted by ReLAT for the books archived at BiblioNasium (see a sample of BiblioNasium books in Table 1) and U  X  X  readabil-ity level, which is 4, BReK12 does not include Bk 1 or Bk in CandBks , since their grade levels are below/beyond the range deemed appropriate for U .
BReK12 depends on the profile P of U to infer U  X  X  in-terests/preferences. To determine the degree to which the content of a book B in CandBks appeals to U , BReK12 computes the content similarity between B and each book P
B in P , denoted CSim ( B , P ) as defined in Equation 3, us-ing a  X  X ag-of-words X  representation on the brief descriptions of B and P B obtained from book-affiliated websites, such ID Book Title Grade Bk 1 Mummies in the Morning 2.9 Bk 2 Captain Underpants and the Big, Bad 4.7 Bk 3 The Hidden Boy 5.6 Bk 4 Dragon X  X  Halloween 3.1
Bk 5 Junie B. Jones Smells Something Fishy 3.0 ... ... ...
 Table 2: TF-IDF weighting scheme used in the en-hanced cosine similarity measure in Equation 3 as Amazon. To compute CSim ( B , P ), BReK12 employs an enhanced version of the cosine similarity measure based on word-correlation factors [12], which relaxes the exact-matching constraint imposed by the cosine measure and ex-plores words in the description of B that are analogous to, besides the same as, words in the description of P B .
Word-correlation factors in the correlation matrix intro-duced in [12] reflect the degree of similarity between any two words according to their (i) frequencies of co-occurrence and (ii) relative distances in Wikipedia(.org) documents. Ap-proximately 880,000 documents covering a wide range of topics and written by more than 89,000 authors with varied writing styles were used to construct the matrix. Compared with synonyms/related words compiled by WordNet (word-net.princeton.edu) in which pairs of words are not assigned similarity weights, word-correlation factors offer a more so-phisticated measure of word similarity. In addition, word-correlation factors have been successfully employed to solve a number of content-similarity problems [21, 22]. CSim ( B, P )= max where B and P B are represented as n -dimensional vectors VB = &lt;V B 1 , ..., VB n &gt; and VP B = &lt;V P B 1 , ..., VP respectively, n is the number of distinct words in the descrip-tions of B and P B ,and VB i ( VP B i , respectively), which is the weight assigned to word B i ( P B i , respectively), is cal-culated as shown in the equations in Table 2.

HS w in Table 2 is the set of words that are highly similar to, but not the same as, a given word w in the description of a book Bk , which is either B or P B , | HS w | is the size
Two words are highly similar if their correlation factor is included in a reduced version of the aforementioned word-correlation matrix which contains 13% of the most frequently-occurring words in the Wikipedia documents. quency of w in Bk ,and idf w = log N n w is the inverse document frequency for w in the collection of books N archived at a social bookmarking site, where n w is the number of books in N that include w in their descriptions. Relying on the tf -idf weighting scheme, BReK12 prioritizes discriminating words that capture the content of its respective book.
The max function in Equation 3 emulates the  X  X ost plea-sure X  strategy (commonly applied in game theory and group profiling [24]). Applying this strategy, BReK12 selects the highest possible score among the ones computed for each P in P and B .The larger the number of exact-matched or highly-similar words in the descriptions of both B and P B is, the more likely B is a relevant recommendation for U . Moreover, BReK12 adopts the widely-used cosine measure, which has been effectively applied to determine the degree of resemblance between any two items in content-based rec-ommenders [18]. While content-similarity is computed by BReK12 using book descriptions, other textual information on books, such as their tag representations, can be used. Tags, however, are not always publicly available.
Example 3. To illustrate the merit of using the en-hanced cosine similarity measure in Equation 3 to compute CSim ( B , P ), consider the profile P of user U in Example 2 and two of the books, Bk 2 and Bk 4 as shown in Table 1. Using the traditional cosine measure, Bk 2 and Bk 4 yield the same content similarity score with respect to P . However, employing the enhanced cosine similarity measure, BReK12 obtains a more accurate content-similarity score for each book, since CSim ( Bk 2 , P ) = 0.57 and CSim ( Bk 4 , P )= 0.39. These scores reflect that U is likely more interested in books similar to the ones in the  X  X aptain Underpants X  X eries (by Dav Pilkey) than books about  X  X ragons, X  which we have verified by manually examining the profile of U .
CSim locates books that are similar in content, to a cer-tain degree, to the ones users have read in the past. This measure, however, does not consider books that are dissimi-lar in content but match users X  specific preferences/interests. Hence, BReK12 explores another dimension of resemblance between each book B in CandBks and books in U  X  X  profile P by using the Lennon similarity measure [13] to perform co-readership analysis on users X  bookmarks on a social book-marking site. This readership similarity measure (as defined in Equation 4) is based on the popular item-item similarity approach employed by collaborative-filtering recommenders to examine patterns of co-occurrence of items bookmarked by users to make recommendations [6].
 RSim ( B, P )= max where S B ( S P B , respectively) is the set of users who book-marked B ( P B , respectively), S  X  = S B  X  S P B , | S  X  number of users who bookmarked both B and P B , | S B  X  S ( | S
P B  X  S  X  | , respectively) is the number of users who book-marked B , but not P B ( P B , but not B , respectively) at a social bookmarking site, and the use of the max function was discussed in Section 4.2.

In Equation 4, the min (imum) of the two differences be-tween | S B  X  S  X  | and | S P B  X  S  X  | is chosen, since by using the smaller of the two differences, we can more accurately capture the similarity between B and P B .Asa difference re-flects the number of users who bookmark B , but not P B (or vice versa), a smaller difference signifies that proportionally a larger number of users who bookmark one book also prefer the other book, which is a better indication of the degree of readership similarity between the two books.

Example 4. To illustrate the usefulness of readership similarity measure for making recommendations, consider Bk 5 in Table 1 and the book  X  X he Adventures of Captain Underpants X  by Dav Pilkey, denoted P B ,whichisabook in the profile of user U introduced in Example 2. The con-tents of the books differ, since P B is about the adventures of two fourth graders and a superhero, whereas Bk 5 details the events that occur when Junie, the main character in the book, takes her pet to school. The books, however, share some common thread of interest to a group of BiblioNasium users who have bookmarked both, since the books include characters of similar age , written in similar literary styles , and share the same genre . Relying partially on the reader-ship similarity between Bk 5 and P , which is 0.67, BReK12 retains Bk 5 as one of the top-10 recommendations for U , which otherwise would have been ignored due to the lack of related content between the two books.
Using the computed content-and readership-similarity scores of each book B (with a readability level appropri-ate for U )in CandBks , BReK12 applies the Borda Count voting scheme [3] to determine the ranking score for B .The Borda Count voting scheme is a positional-scoring proce-dure such that given k (  X  1) candidates, each voter casts a vote for each candidate according to his/her preference. A candidate that is given a first-place vote receives k -1 points, a second-ranked candidate k -2 points, and so on up till the last candidate, who is awarded no points. Hereafter, the points assigned to each candidate across all the voters are added up and the candidate with the most points wins .
The Borda Count strategy, which has been successfully applied to different information retrieval tasks [3], is em-ployed by BReK12 to generate a single ranking score for B , denoted Borda ( B ) as defined in Equation 5, that regards the content-and readership-similarity scores as equally impor-tant in determining the degree to which a user is interested in B . Using Equation 5, BReK12 assigns (i) k = | CandBks which is the number of candidate books selected for a user U , and (ii) C = 2, which is the number of voters, i.e., the two ranked lists of similarity scores on books computed in Sections 4.2 and 4.3, respectively. Candidate books with the top-10 Borda scores are recommended to U .
 where S B c is the position on the ranking of B based on the c th ranked list to be fused.

BReK12 adopts Borda as an aggregation strategy ,since(i) its combination algorithm is simple and efficient ,whichre-quires neither training nor compatible relevance scores that may not be available and (ii) its performance is competitive with other existing combination strategies [3].
In this section, we first introduce the datasets, metrics, and evaluation protocol used for assessing the performance
Simon &amp; Schuster 388 YABC 699 of ReLAT and BReK12 (in Sections 5.1 and 5.2, respec-tively). Hereafter, we present the results of the empirical studies conducted for evaluating the effectiveness of ReLAT and BReK12 (in Sections 5.3 and 5.4, respectively).
To the best of our knowledge, there is no benchmark dataset that can be used for evaluating readability-level pre-diction tools on books. Thus, to evaluate ReLAT we con-structed BookGL 4 , using data extracted from CLCD.com, a website established to assist teachers, parents, and librarians in choosing appropriate books for K-12 readers, the Young Adults Book Central (YAbookscentral.com), and reputable publishers X  websites. BookGL consists of 2,248 books dis-tributed among the K-12 grade levels with the grade level (range) of each book assigned by its publisher. (See Ta-ble 3 for the source websites and their number of books in BookGL.) Due to the lack of consensus among researchers on the accuracy of existing readability prediction tools [4], we consider publisher-provided grade levels as the  X  X old-standard, X  since they are defined by human experts.
Even though the BookCrossing dataset (informatik.uni-freiburg.de/  X  cziegler/BX) has been employed to evaluate book recommenders tailored to a general audience, it is not specifically designed for assessing the performance of book recommenders for K-12 users. Hence, we used data pro-vided by BiblioNasium, which is a safe and secure social networking site on books developed exclusively for children and teenagers, to evaluate BReK12. The dataset consists of the profile of, i.e., books that have been bookmarked by, each of the 297 BiblioNasium users who joined the site within its first month of being launched. As the design methodology of BReK12 relies on brief descriptions and predicted grade levels of books, we extracted the former from Amazon.com and predicted the latter using ReLAT.
To assess the performance of ReLAT, we apply the (ab-solute) error rate (ER) [8], which is the absolute difference between an expected and a predicted grade level for a book B . where | BookGL | is the total number of books in BookGL, GL ( B ) is the predicted grade level of B by a readability formula/analysis tool, and PR ( B )iseitherthelowerorup-per bound of the grade level range of B determined by its publisher, whichever is closest to GL ( B ). (Recall that pub-lishers often assign a grade range, not a level, to a book.)
We evaluate BReK12 using Precision@10 , Mean Recip-rocal Rank (MRR), and Normalized Discounted Cumulative Gain (nDCG) [8]. Precision@10 measures the fraction of the
BookGL and the set of books used to train ReLAT X  X  multi-ple regression predictor (discussed in Section 3) are disjoint. top-10 ranked recommendations that are relevant ,whereas MRR computes the average ranking position of the first rel-evant recommended book. nDCG determines the overall ranking performance of BReK12 and penalizes relevant books ranked lower in the recommendation list. The penalization is based on a reduction, which is logarithmically propor-tional to the position of each relevant book in a ranked list.
We adopt the popular five-fold cross validation strategy to evaluate BReK12 (and recommender systems considered for the comparison purpose). In each of the five repetitions, 80% of the books bookmarked by a user U in the BiblioNasium dataset are used to create U  X  X  profile and the remaining 20% are reserved for the testing purpose. A recommended book B is treated as relevant to U if it is included in the 20% of the books withheld for the testing purpose, and is non-relevant otherwise, which is a commonly-employed protocol for assessing the performance of recommendation systems [11]. Since only withheld books are considered relevant ,it is not possible to account for potentially relevant books a user has not bookmarked, which is a well-known limitation of this evaluation protocol. As the limitation affects all the recommenders evaluated in the conducted empirical studies, the results are consistent for the comparative purpose.
Using the 127 books in BookGL with excerpts, we com-pared the grade-level prediction accuracy of ReLAT with a number of well-known readability formulas: Coleman-Liau, Flesch-Kincaid, Rix, and Spache, which we have implemented. (See detailed discussion on these readability formulas in [4].) Figure 2(a) shows that (i) on the average the grade level pre-dicted by ReLAT for a book with text (in BookGL) is about half a grade from the grade (range) determined by its pub-lisher and (ii) ReLAT X  X  error rate is at least 33% lower than the error rate created by its counterparts.

We also evaluated the performance of ReLAT in predicting the grade level of books for which their excerpts cannot be obtained online. Among the 2,121 books in BookGL with-out sample text, the 0.82 error rate generated by ReLAT is less than one grade level off the ranges specified by the publishers of the books. This low error rate is not only an accomplishment of ReLAT, but also it cannot be achieved by any of the existing readability formulas/analysis tools, since none of them can predict the grade level of books without excerpts. The overall error rate of ReLAT on BookGL, in which 94% of the books are without text, is 0.81, which is within one grade level of the targeted grade level.
We further compare the performance of ReLAT with two popular readability analysis tools widely-accepted by grade schools and reading programs in the USA: Accelerated Reader (AR) and Lexile. Recall that the algorithms developed to compute AR and Lexile scores are not publicly accessible, but we were able to find 897 books with AR scores and 314 books with Lexile scores among the books in BookGL at ARbookfind.com and Lexile.com, respectively. As shown in Figure 2(b), ReLAT outperforms AR and is significantly more accurate than Lexile in predicting the grade level of the analyzed books (in BookGL).
In this section, we verify the correctness of the design methodology of BReK12 and compare its performance with a number of existing recommendation strategies. (a) Readability Formulas (b) Analysis Tools
The results of the study conducted to validate the method-ologies applied by BReK12 for selecting and ranking books to be recommended for K-12 users are presented as follows:
As previously stated, no other personalized book recom-mender explicitly considers the reading abilities of its users. Thus, we have compared the performance of BReK12 with a number of recommenders developed for a general audience.
Tag Vector Similarity (TVS) [11], L-Cosine (L-Cos) [18], and Item-Based Collaborative Filtering (IICF) [6] were em-ployed for comparison purposes, as opposed to other state-of-the-art book recommenders introduced in Section 2, since the latter require personal ratings on (K-12) books provided by individual users or social connections established by so-cial bookmarking site (K-12) users, neither of which are archived by BiblioNasium. To determine which books should be recommended to a user, TVS applies the cosine similar-ity measure on TF-IDF tag vector representations of books whereas L-Cos considers the weighted frequency of each key-word in the description or title of a book. IICF, on the other hand, calculates the degree of similarity between any two books based on the number of users who have bookmarked both books on a social bookmarking site, which is a varia-tion of the popular collaborative filtering strategy commonly adopted for making recommendations.

As shown in Figure 3, BReK12 outperforms its counter-parts based on the evaluation metrics introduced in Section 5.2. The improvements achieved by BReK12 over the others are statistically significant (with p&lt; 0.01). According to the computed MRR, on the average BReK12 users are required to browse through about one (  X  = 1 0 . 60 = 1.67) recommended book before locating a relevant one, whereas users of TVS, L-Cos, and IICF are required to scan through at least 4 (  X  mended books, respectively. The Precision@10 values reflect that, in general, close to 8 (out of 10) books suggested by BReK12 are relevant, as opposed to close to 4, 2, and 6 rele-vant books recommended by TVS, L-Cos, and IICF, respec-tively. The nDCG scores indicate the superiority of BReK12 over TVS, L-Cos, and IICF in ranking relevant books to be recommended higher in the list of suggested books.
While TVS, L-Cos, and IICF consider only textual de-scriptions of books or bookmaking patterns of users on a social site, BReK12 examines multiple contributing factors to identify potential recommendations, which increases the number of relevant reading selections for the users.
We have introduced BReK12, a unique recommender tai-lored to K-12 readers, which makes personalized suggestions on books that satisfy both the preferences and reading abili-ties of its users. Unlike current state-of-the-art recommenders that rely on the existence of users X  historical data in the form of ratings , which are missing among the K-12 users, BReK12 simply considers readily available brief descriptions on books, patterns of co-occurrence among books bookmarked on a social bookmarking site on which BReK12 is installed, and grade levels of books computed using our newly-developed ReLAT. ReLAT is novel, since it can determine the grade level of any book (even if a sample of the text of a book is unavailable) by analyzing the Subject Headings of books, US Curriculum subject areas identified in books, and in-formation about the authors of books. As children con-tinue to read more books if they can choose what to read [2], a significant contribution of BReK12 is to provide K-12 readers a selection of suitable books to choose from that are not only appealing to them, but can be comprehended
Tag descriptions on books can be extracted from the INEX 2012 Social Book Search Track dataset (inex.mmci.uni-saarland.de/tracks/books/). by them. The conducted experiments demonstrate (i) the accuracy of ReLAT and its superiority over existing read-ability formulas/analysis tools, and (ii) the effectiveness of BReK12, which outperforms baseline recommenders in sug-gesting books for K-12 users.

As part of our future work, we plan to extend BReK12 so that it can suggest reading materials for struggling readers, i.e., readers with learning disabilities and those who learn English as a second language, for whom the grade level of a recommended book is an important factor to be considered. [1] R. Allington. What Really Matters for Struggling [2] R. Allington and E. Gabriel. Every Child, Every Day. [3] J. Aslam and M. Montague. Models for Metasearch. [4] R. Benjamin. Reconstructing Readability: Recent [5] D. Blei, A. Ng, and M. Jordan. Latent Dirichlet [6] T. Bogers and A. van den Bosch. Fusing [7] K. Collins-Thompson and J. Callan. A Language [8] W. Croft, D. Metzler, and T. Strohman. Search [9] L. Feng, N. Elhadad, and M. Huenerfauth. Cognitively [10] S. Givon and V. Lavrenko. Predicting Social-Tags for [11] Z. Guan, C. Wang, J. Bu, C. Chen, K. Yang, D. Cai, [12] J. Koberstein and Y.-K. Ng. Using Word Clusters to [13] J. Lennon, P. Koleff, J. Greenwood, and K. Gaston. [14] G. Linden, B. Smith, and J. York. Amazon.com [15] Y. Ma, E. Fosler-Lussier, and R. Lofthus.
 [16] N. Manouselis, H. Drachsler, K. Verbert, and [17] R. Myers. Classical and Modern Regression with [18] C. Nascimento, A. Laender, A. da Silva, and [19] J. Oakhill and K. Cain. The Precursors of Reading [20] Y. Park and K. Chang. Individual and Group [21] M. Pera and Y.-K. Ng. With a Little Help From My [22] R. Qumsiyeh and Y.-K. Ng. ReadAid: A Robust and [23] Renaissance Learning. ATOS vs. Lexile Which [24] F. Ricci, L. Rokach, B. Shapira, and P. Kantor. [25] A. Sieg, B. Mobasher, and R. Burke. Improving the [26] C. Yang, B. Wei, J. Wu, Y. Zhang, and L. Zhang.
