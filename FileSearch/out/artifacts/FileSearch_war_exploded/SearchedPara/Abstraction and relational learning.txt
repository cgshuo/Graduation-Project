 Categories such as family , sonnet , above , betray , and imitate differ in many respects but all of them depend critically on relational information. Members of a f amily are typically related by blood or marriage, and the lines that make up a sonnet must rhyme with e ach other according to a certain pattern. A pair of objects will demonstrate  X  X boveness X  onl y if a certain spatial relationship is present, and an event will qualify as an instance of betrayal or imitation only if its participants relate to each other in certain ways. All of the cases just described are examples of relational categories. This paper develops a computational approach that helps to e xplain how simple relational categories are acquired.
 Our approach highlights the role of abstraction in relation al learning. Given several instances of a relational category, it is often possible to infer an abstr act representation that captures what the instances have in common. We refer to these abstract represe ntations as schemata , although others may prefer to call them rules or theories. For example, a sonn et schema might specify the number of lines that a sonnet should include and the rhyming pattern that the lines should follow. Once a schema has been acquired it can support several kinds of infe rences. A schema can be used to make predictions about hidden aspects of the examples already ob served X  X f the final word in a sonnet is illegible, the rhyming pattern can help to predict the ident ity of this word. A schema can be used to decide whether new examples (e.g. new poems) qualify as me mbers of the category. Finally, a schema can be used to generate novel examples of a category (e .g. novel sonnets).
 Most researchers would agree that abstraction plays some ro le in relational learning, but Gentner [1] and other psychologists have emphasized the role of comparison instead [2, 3]. Given one example of a sonnet and the task of deciding whether a second poem is al so a sonnet, a comparison-based approach might attempt to establish an alignment or mapping between the two. Approaches that rely on comparison or mapping are especially prominent in the lit erature on analogical reasoning [4, 5], and many of these approaches can be viewed as accounts of rela tional categorization [6]. For exam-ple, the problem of deciding whether two systems are analogo us can be formalized as the problem of deciding whether these systems are instances of the same r elational category. Despite some no-table exceptions [6, 7], most accounts of analogy focus on co mparison rather than abstraction, and suggest that  X  X nalogy passes from one instance of a generali zation to another without pausing for explicit induction of the generalization X  (p 95) [8]. Figure 1: A hierarchical generative model for learning and u sing relational categories. The schema s at the top level is a logical sentence that specifies which gro ups are valid instances of the cate-gory. The group g at the second level is randomly sampled from the set of valid i nstances, and the observation o is a partially observed version of group g .
 Researchers that focus on comparison sometimes discuss abs traction, but typically suggest that abstractions emerge as a consequence of comparing two or mor e concrete instances of a cate-gory [3, 5, 9, 10]. This view, however, will not account for on e-shot inferences, or inferences based on a single instance of a relational category. Conside r a learner who is shown one instance of a sonnet then asked to create a second instance. Since only on e instance is provided, it is hard to see how comparisons between instances could account for suc cess on the task. A single instance, however, will sometimes provide enough information for a sc hema to be learned, and this schema should allow subsequent instances to be generated [11]. Her e we develop a formal framework for exploring relational learning in general and one-shot sche ma learning in particular.
 Our framework relies on the hierarchical Bayesian approach , which provides a natural way to com-bine abstraction and probabilistic inference [12]. The hie rarchical Bayesian approach supports rep-resentations at multiple levels of abstraction, and helps t o explains how abstract representations (e.g. a sonnet schema) can be acquired given observations of concr ete instances (e.g. individual sonnets). The schemata we consider are represented as sentences in a lo gical language, and our approach therefore builds on previous probabilistic methods for lea rning and using logical theories [13, 14]. Following previous authors, we propose that logical repres entations can help to capture the content of human knowledge, and that Bayesian inference helps to exp lain how these representations are acquired and how they support inductive inference.
 The following sections introduce our framework then evalua te it using two behavioral experiments. Our first experiment uses a standard classification task wher e participants are shown one example of a category then asked to decide which of two alternatives i s more likely to belong to the same category. Tasks of this kind have previously been used to arg ue for the importance of comparison, but we suggest that these tasks can be handled by accounts tha t focus on abstraction. Our second experiment uses a less standard generation task [15, 16] whe re participants are shown a single exam-ple of a category then asked to generate additional examples . As predicted by our abstraction-based account, we find that people are able to learn relational cate gories on the basis of a single example. Our examples so far have used real-world relational categor ies such as family and sonnet but we now turn to a very simple domain where relational categorizatio n can be studied. Each element in the domain is a group of components that vary along a number of dim ensions X  X n Figure 1, the compo-nents are figures that vary along the dimensions of size, colo r, and circle position. The groups can be organized into categories X  X ne such category includes gro ups where every component is black. Although our domain is rather basic it allows some simple rel ational regularities to be explored. We can consider categories, for example, where all components in a group must be the same along some dimension, and categories where all components must be different along some dimension. We can also consider categories defined by relationships between d imensions X  X or example, the category that includes all groups where the size and color dimensions are correlated.
 Each category is associated with a schema, or an abstract rep resentation that specifies which groups are valid instances of the category. Here we consider schema ta that correspond to rules formulated Table 1: Templates used to construct a hypothesis space of lo gical schemata. An instance of a given template can be created by choosing an element from each set e nclosed in braces (some sets are laid out horizontally to save space), replacing each occurrence of D i or D j with a dimension (e.g. D 1 ) and replacing each occurrence of v k or v l with a value (e.g. 1). in a logical language. The language includes three binary co nnectives X  X nd (  X  ), or (  X  ), and if and only if (  X  ). Four binary relations ( = , 6 = , &lt; , and &gt; ) are available for comparing values along dimensions. Universal quantification (  X  x ) and existential quantification (  X  x ) are both permitted, and the language includes quantification over objects (  X  x ) and dimensions (  X  Q ). For example, the schema in Figure 1 states that all dimensions are aligned. Mo re precisely, if D 1 is the dimension of size, the schema states that for all dimensions Q , a component x is smaller than a component y along dimension Q if and only if x is smaller in size than y . It follows that all three dimensions must increase or decrease together.
 To explain how rules in this logical language are learned we w ork with the hierarchical generative model in Figure 1. The representation at the top level is a sch ema s , and we assume that one or more groups g are generated from a distribution P ( g | s ) . Following a standard approach to category learning [17, 18], we assume that g is uniformly sampled from all groups consistent with s : For all applications in this paper, we assume that the number of components in a group is known and fixed in advance.
 The bottom level of the hierarchy specifies observations o that are generated from a distribution P ( o | g ) . In most cases we assume that g can be directly observed, and that P ( o | g ) = 1 if o = g and 0 otherwise. We also consider the setting shown in Figure 1 whe re o is generated by concealing a component of g chosen uniformly at random. Note that the observation o in Figure 1 includes only four of the components in group g , and is roughly analogous to our earlier example of a sonnet w ith an illegible final word.
 To convert Figure 1 into a fully-specified probabilistic mod el it remains to define a prior distribution P ( s ) over schemata. An appealing approach is to consider all of th e infinitely many sentences in the logical language already mentioned, and to define a prior favoring schemata which correspond to simple (i.e. short) sentences. We approximate this appro ach by considering a large but finite space of sentences that includes all instances of the templa tes in Table 1 and all conjunctions of these instances. When instantiating one of these templates, each occurrence of D i or D j should be replaced by one of the dimensions in the domain. For example, the schema in Figure 1 is a simplified instance of template 6 where D i is replaced by D 1 . Similarly, each instance of v k or v l should be replaced by a value along one of the dimensions. Our first expe riment considers a problem where there are are three dimensions and three possible values alo ng each dimension (i.e. v k = 1 , 2, or 3). As a result there are 1568 distinct instances of the templ ates in Table 1 and roughly one million conjunctions of these instances. Our second experiment use s three dimensions with five values along each dimension, which leads to 2768 template instances and r oughly three million conjunctions of these instances.
 The templates in Table 1 capture most of the simple regularit ies that can be formulated in our logical language. Template 1 generates all rules that include quant ification over a single object variable and no binary connectives. Template 3 is similar but includes a s ingle binary connective. Templates 2 and 4 are similar to 1 and 3 respectively, but include two obj ect variables ( x and y ) rather than one. Templates 5, 6 and 7 add quantification over dimensions t o Templates 2 and 4. Although the templates in Table 1 capture a large class of regularities, s everal kinds of templates are not included. Since we do not assume that the dimensions are commensurable , values along different dimensions cannot be directly compared (  X  x D 1 ( x ) = D 2 ( x ) is not permitted. For the same reason, compar-isons to a dimension value must involve a concrete dimension (  X  x D 1 ( x ) = 1 is permitted) rather than a dimension variable (  X  Q  X  x Q ( x ) = 1 is not permitted). Finally, we exclude all schemata where quantification over objects precedes quantification o ver dimensions, and as a result there are some simple schemata that our implementation cannot learn ( e.g.  X  x  X  y  X  Q Q ( x ) = Q ( y ) ). The extension of each schema is a set of groups, and schemata w ith the same extension can be assigned to the same equivalence class. For example,  X  x D 1 ( x ) = v 1 (an instance of template 1) and  X  x D 1 ( x ) = v 1  X  D 1 ( x ) = v 1 (an instance of template 3) end up in the same equivalence cla ss. Each equivalence class can be represented by the shortest se ntence that it contains, and we define our prior P ( s ) over a set that includes a single representative for each equ ivalence class. The prior probability P ( s ) of each sentence is inversely proportional to its length: P ( s )  X   X  | s | , where | s | is the length of schema s and  X  is a constant between 0 and 1 . For all applications in this paper we set  X  = 0 . 8 .
 The generative model in Figure 1 can be used for several purpo ses, including schema learning (in-ferring a schema s given one or more instances generated from the schema), clas sification (deciding whether group g new belongs to a category given one or more instances of the categ ory) and genera-tion (generating a group g new that belongs to the same category as one or more instances). O ur first experiment explores all three of these problems. Our first experiment is organized around a triad task where pa rticipants are shown one example of a category then asked to decide which of two choice examples is more likely to belong to the category. Triad tasks are regularly used by studies of relational cate gorization, and have been used to argue for the importance of comparison [1]. A comparison-based ap proach to this task, for instance, might compare the example object to each of the choice objects in or der to decide which is the better match. Our first experiment is intended in part to explore whe ther a schema-learning approach can also account for inferences about triad tasks.
 Materials and Method. 18 adults participated for course credit and interacted wit h a custom-built computer interface. The stimuli were groups of figures that v aried along three dimensions (color, size, and ball position, as in Figure 1). Each shape was displ ayed on a single card, and all groups in Experiment 1 included exactly three cards. The cards in Figu re 1 show five different values along each dimension, but Experiment 1 used only three values alon g each dimension.
 The experiment included inferences about 10 triads. Partic ipants were told that aliens from a certain planet  X  X njoy organizing cards into groups, X  and that  X  X ny g roup of cards will probably be liked by some aliens and disliked by others. X  The ten triad tasks we re framed as questions about the preferences of 10 aliens. Participants were shown a group th at Mr X likes (different names were used for the ten triads), then shown two choice groups and tol d that  X  X r X likes one of these groups but not the other. X  Participants were asked to select one of t he choice groups, then asked to generate another 3-card group that Mr X would probably like. Cards cou ld be added to the screen using an  X  X dd Card X  button, and there were three pairs of buttons that allowed each card to be increased or decreased along the three dimensions. Finally, participan ts were asked to explain in writing  X  X hat kind of groups Mr X likes. X  The ten triads used are shown in Figure 2. Each group is repres ented as a 3 by 3 matrix where rows represent cards and columns show values along the three dimensions. Triad 1, for example, Figure 2: Human responses and model predictions for the ten t riads in Experiment 1. The plot at the left of each panel shows model predictions (white bars) and h uman preferences (black bars) for the two choice groups in each triad. The plots at the right of each panel summarize the groups created during the generation phase. The 23 elements along the x-axi s correspond to the regularities listed in Table 2. has an example group including three cards that each take val ue 3 along D 1 . The first choice group is consistent with this regularity but the second choice gro up is not. The cards in each group were arrayed vertically on screen, and were initially sorted as s hown in Figure 2 (i.e. first by D 3 , then by D 2 and then by D 1 ). The cards could be dragged around on screen, and participa nts were invited to move them around in order to help them understand each grou p. The mapping between the three dimensions in each matrix and the three dimensions in the exp eriment (color, position, and size) was randomized across participants, and the order in which tria ds were presented was also randomized. Model predictions and results. Let g e be the example group presented in the triad task and g 1 and g 2 be the two choice groups. We use our model to compute the relat ive probability of two hypotheses: h 1 which states that g e and g 1 are generated from the same schema and that g 2 is sam-pled randomly from all possible groups, and h 2 which states that g e and g 2 are generated from the and P ( h 2 | g e , g 1 , g 2 ) by integrating over all schemata in the hypothesis space alr eady described. Our model assumes that two groups are considered similar to t he extent that they appear to have been generated by the same underlying schema, and is consist ent with the generative approach to similarity described by Kemp et al. [19].
 Model predictions for the ten triads are shown in Figure 2. In each case, the choice probabilities plotted (white bars) are the posterior probabilities of hyp otheses h 1 and h 2 . In nine out of ten cases the best choice according to the model is the most common huma n response. Responses to triads 2c and 2d support the idea that people are sensitive to relation ships between dimensions (i.e. alignment and anti-alignment). Triads 2e and 2f are similar to triads s tudied by Kotovsky and Gentner [1], and we replicate their finding that people are sensitive to relat ionships between dimensions even when the dimensions involved vary from group to group. The one cas e where human responses diverge from model predictions is shown in Figure 2h. Note that the sc hema for this triad involves existential quantification over dimensions ( some dimension is uniform), and according to our prior P ( s ) this kind of quantification is no more complex than other kinds of q uantification. Future applications of our approach can explore the idea that existential quantific ation over dimensions (  X  Q ) is psycholog-ically more complex than universal quantification over dime nsions (  X  Q ) or existential quantification over cards (  X  x ), and can consider logical languages that incorporate this inductive bias. To model the generation phase of the experiment we computed t he posterior distribution where P ( h | g e , g 1 , g 2 ) is the distribution used to model selections in the triad tas k. Since the space of possible groups is large, we visualize this distribution using a profile that shows the posterior probability assigned to groups consistent with the 23 regul arities shown in Table 2. The white bar plots in Figure 2 show profiles predicted by the model, and the black plots immediately above show profiles computed over the groups generated by our 18 partici pants.
 In many of the 10 cases the model accurately predicts regular ities in the groups generated by people. In case 2c, for example, the model correctly predicts that ge nerated groups will tend to have no repeats along dimensions D 2 and D 3 (regularities 15 and 16) and that these two dimensions will b e aligned (regularities 2 and 5). There are, however, some dep artures from the model X  X  predictions, and a notable example occurs in case 2d. Here the model detect s the regularity that dimensions D 1 and D 3 are anti-aligned (regularity 9). Some groups generated by p articipants are consistent with Figure 3: Human responses and model predictions for the six c ases in Experiment 2. In (a) and (b), the 4 cards used for the completion and generation phases are shown on either side of the dashed line (completion cards on the left). In the remaining cases, the s ame 4 cards were used for both phases. The plots at the right of each panel show model predictions (w hite bars) and human responses (black bars) for the generation task. In each case, the 23 elements a long each x-axis correspond to the regularities listed in Table 2. The remaining plots show res ponses to the completion task. There are 125 possible responses, and the four responses shown always include the top two human responses and the top two model predictions. this regularity, but people also regularly generate groups where two dimensions are aligned rather than anti-aligned (regularity 2). This result may indicate that some participants are sensitive to relationships between dimensions but do not consider the di fference between a positive relationship (alignment) and an inverse relationship (anti-alignment) especially important.
 Kotovsky and Gentner [1] suggest that comparison can explai n how people respond to triad tasks, although they do not provide a computational model that can b e compared with our approach. It is less clear how comparison might account for our generation d ata, and our next experiment considers a one-shot generation task that raises even greater challen ges for a comparison-based approach. As described already, comparison involves constructing ma ppings between pairs of category in-stances. In some settings, however, learners make confident inferences given a single instance of a category [15, 20], and it is difficult to see how comparison co uld play a major role when only one instance is available. Models that rely on abstraction, how ever, can naturally account for one-shot relational learning, and we designed a second experiment to evaluate this aspect of our approach. Several previous studies have explored one-shot relationa l learning. Holyoak and Thagard [21] developed a study of analogical reasoning using stories as s timuli and found little evidence of one-shot schema learning. Ahn et al. [11] demonstrated, however , that one-shot learning can be achieved with complex materials such as stories, and modeled this res ult using explanation-based learning. Here we use much simpler stimuli and explore a probabilistic approach to one-shot learning. Materials and Method. 18 adults participated for course credit. The same individu als completed Experiments 1 and 2, and Experiment 2 was always run before Ex periment 1. The same computer interface was used in both experiments, and the only importa nt difference was that the figures in Experiment 2 could now take five values along each dimension r ather than three.
 The experiment included two phases. During the generation p hase, participants saw a 4-card group that Mr X liked and were asked to generate two 5-card groups th at Mr X would probably like. During the completion phase, participants were shown four m embers of a 5-card group and were asked to generate the missing card. The stimuli used in each p hase are shown in Figure 3. In the first two cases, slightly different stimuli were used in the g eneration and completion phases, and in all remaining cases the same set of four cards was used in both cases. All participants responded to the six generation questions before answering the six compl etion questions.
 Model predictions and results. The generation phase is modeled as in Experiment 1, but now th e posterior distribution P ( g new | g e ) is computed after observing a single instance of a category. The human responses in Figure 3 (white bars) are consistent with the model in all cases, and confirm that a single example can provide sufficient evidence for learner s to acquire a relational category. For example, the most common response in case 3a was the 5-card gr oup shown in Figure 1 X  X  group with all three dimensions aligned.
 To model the completion phase, let o e represent a partial observation of group g e . Our model infers which card is missing from g e by computing the posterior distribution P ( g e | o e )  X  cealing one component of g e . The white bars in Figure 3 show model predictions, and in five out of six cases the best response according to the model is the same as the most common human response. In the remaining case (Figure 3d) the model generates a diffu se distribution over all cards with value 3 on dimension 2, and all human responses satisfy this regula rity. We presented a generative model that helps to explain how rel ational categories are learned and used. Our approach captures relational regularities using a logical language, and helps to explain how schemata formulated in this language can be learned from observed data. Our approach differs in several respects from previous accounts of relational ca tegorization [1, 5, 10, 22]. First, we focus on abstraction rather than comparison. Second, we consider tasks where participants must generate examples of categories [16] rather than simply classify exi sting examples. Finally, we provide a formal account that helps to explain how relational categor ies can be learned from a single instance. Our approach can be developed and extended in several ways. F or simplicity, we implemented our model by working with a finite space of several million schema ta, but future work can consider hypothesis spaces that assign non-zero probability to all r egularities that can be formulated in the language we described. The specific logical language used he re is only a starting point, and future work can aim to develop languages that provide a more faithfu l account of human inductive biases. Finally, we worked with a domain that provides one of the simp lest ways to address core questions such as one-shot learning. Future applications of our gener al approach can consider domains that include more than three dimensions and a richer space of rela tional regularities.
 Relational learning and analogical reasoning are tightly l inked, and hierarchical generative models provide a promising approach to both problems. We focused he re on relational categorization, but future studies can explore whether probabilistic accounts of schema learning can help to explain the inductive inferences typically considered by studies o f analogical reasoning. Although there are many models of analogical reasoning, there are few that purs ue a principled probabilistic approach, and the hierarchical Bayesian approach may help to fill this g ap in the literature.
 [1] L. Kotovsky and D. Gentner. Comparison and categorizati on in the development of relational [2] D. Gentner and A. B. Markman. Structure mapping in analog y and similarity. American [3] D. Gentner and J. Medina. Similarity and the development of rules. Cognition , 65:263 X 297, [4] B. Falkenhainer, K. D. Forbus, and D. Gentner. The struct ure-mapping engine: Algorithm and [5] J. E. Hummel and K. J. Holyoak. A symbolic-connectionist theory of relational inference and [6] M. Mitchell. Analogy-making as perception: a computer model . MIT Press, Cambridge, MA, [7] D. R. Hofstadter and the Fluid Analogies Research Group. Fluid concepts and creative analo-[8] W. V. O. Quine and J. Ullian. The Web of Belief . Random House, New York, 1978. [9] J. Skorstad, D. Gentner, and D. Medin. Abstraction proce sses during concept learning: a [10] D. Gentner and J. Loewenstein. Relational language and relational thought. In E. Amsel [11] W. Ahn, W. F. Brewer, and R. J. Mooney. Schema acquisitio n from a single example. Journal [12] A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin. Bayesian data analysis . Chapman &amp; [13] C. Kemp, N. D. Goodman, and J. B. Tenenbaum. Learning and using relational theories. In J.C. [14] S. Kok and P. Domingos. Learning the structure of Markov logic networks. In Proceedings of [15] J. Feldman. The structure of perceptual categories. Journal of Mathematical Psychology , 41: [16] A. Jern and C. Kemp. Category generation. In Proceedings of the 31st Annual Conference of [17] D. Conklin and I. H. Witten. Complexity-based inductio n. Machine Learning , 16(3):203 X 225, [18] J. B. Tenenbaum and T. L. Griffiths. Generalization, sim ilarity, and Bayesian inference. Be-[19] C. Kemp, A. Bernstein, and J. B. Tenenbaum. A generative theory of similarity. In B. G. Bara, [20] C. Kemp, N. D. Goodman, and J. B. Tenenbaum. Theory acqui sition and the language of [21] K. J. Holyoak and P. Thagard. Analogical mapping by cons traint satisfaction. Cognitive Sci-[22] L. A. A. Doumas, J. E. Hummel, and C. M. Sandhofer. A theor y of the discovery and predica-[23] M. L. Gick and K. J. Holyoak. Schema induction and analog ical transfer. Cognitive Psychol-
