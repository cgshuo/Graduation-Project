 Tomasz Malisiewicz tomasz@csail.mit.edu Massachusetts Institute of Technology Abhinav Shrivastava ashrivas@cs.cmu.edu Abhinav Gupta abhinavg@cs.cmu.edu Alexei A. Efros efros@cs.cmu.edu Carnegie Mellon University Today X  X  state-of-the-art visual object detection sys-tems are based on three key components: 1) sophis-ticated features (to encode various visual invariances), 2) a powerful classifier (to build a discriminative ob-ject class model), and 3) lots of data (to use in large-scale hard-negative mining). While conventional wis-dom tends to attribute the success of such methods to the ability of the classifier to generalize across the positive class instances, here we report on empirical findings suggesting that this might not necessarily be the case. We have experimented with a very simple idea: to learn a separate classifier for each positive object instance in the dataset (see Figure 1 ). In this setup, no generalization across the positive instances is possible by definition, and yet, surprisingly, we did not observe any drastic drop in performance compared to the standard, category-based approaches.
 More specifically, we train a separate linear SVM for every exemplar in the training set (e.g., every anno-tated bounding box in case of object detection). Each of these Exemplar-SVMs is thus defined by a single positive instance and millions of negatives. Taken to-gether, an Ensemble of Exemplar-SVMs ( Malisiewicz et al. , 2011 ), aims to combine the e ff ectiveness of a discriminative object detector with the explicit cor-respondence o ff ered by a nearest-neighbor approach. While each detector is quite specific to its exemplar, we empirically observe that, after a simple calibra-tion step, an ensemble of such Exemplar-SVMs o ff ers surprisingly good performance, roughly comparable to the much more complex latent part-based model of ( Felzenszwalb et al. , 2010 ).
 It is interesting to note some of the properties of Exemplar-SVMs:  X  There is little sign of overfitting. Although each SVM has only a single positive example, the huge num-ber of negatives appear to provide enough to constrain the problem. In a way, the exemplar X  X  decision bound-di ff erent feature spaces (i.e., di ff erent template sizes as well as entirely di ff erent features).  X  Because of the long-tailed distribution of objects in the world (10% of objects own 90% of exemplars), the extra cost of using exemplars vs. categories will greatly diminish as the number of categories increases. Moreover, learning is embarrassingly parallel  X  instead of solving a single large and non-convex optimiza-tion problem ( Felzenszwalb et al. , 2010 ), here each Exemplar-SVM X  X  objective function is convex and can be optimized independently.
 Additionally, we have observed that even when the negative set is not completely clean (i.e., happens to contain some instances from the positive class), this has only a modest detrimental e ff ect on object detec-tion performance (3.2% drop on the PASCAL VOC 2007 ( Malisiewicz , 2011 )). Such robustness to the negative set being polluted by in-class instances moti-vated us to experiment with using the Exemplar-SVM formulation for the task of large-scale image re-trieval ( Shrivastava et al. , 2011 ). Here, the query image is treated as the single positive exemplar and a collection of tens of thousands random unlabeled
