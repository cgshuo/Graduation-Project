 Micro-blogging servi ces, such as Twitter, and location-based so-cial network applications have generated short text messages as-sociated with geographic information, posting time, and user ids. The availability of such data received from users o ff ers a good op-portunity to study the user X  X  spatial-temporal behavior and prefer-W ho + W here + W hen + W hat) to exploit such data to discover indi-vidual users X  mobility behaviors from spatial, temporal and activ-ity aspects. To the best of our knowledge, our work o ff ers the fi rst solution to jointly model individual user X  X  mobility behavior from the three aspects. Our model has a variety of applications, such as user pro fi ling and location prediction; it can be employed to an-swer questions such as  X  X an we infer the location of a user given a tweet posted by the user and the posting time?" Experimental re-sults on two real-world datasets show that the proposed model is e ff ective in discovering users X  spatial-temporal topics, and outper-forms state-of-the-art baselines signi fi cantly for the task of location prediction for tweets.
 H.2.8 [ Database applications ]: Data mining; H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing User Pro fi ling; Graphical Model; Prediction and Recommendation; Spatio-Temporal; Twitter Posting short messages through micro-blogging services ( e.g., Twitter and Tumblr) has become an indispensable part of the daily life for many users. For example, as of December 2012, there were message posted through Twitter is known as a tweet with the maxi-mum length of 140 characters. With the prevalence of GPS-enabled devices ( e.g., smart phones), many tweets are associated with loca-tion information. The locations may be in the form of the lati-tude and longitude coordinates, or in the form of exact addresses. The latter can be speci fi ed explicitly by users, detected by mobile devices, or geo-tagged by geo-tagging tools. Apart from Micro-blogging services, Location-based Social Network (LBSN) appli-cations, such as Foursquare and Facebook Places, allow users to share their current locations and activities by checking-in points of interests and composing short text messages at check-ins. In short, each the geo-annotated tweet or check-in message contains a user id, a text message, posting time, and a location.

The large availability of such short messages directly received from users o ff ers an exciting opportunity to study the behaviors of individuals ( who is the user?) with respect to three important aspects, namely, geographical location ( where does an individual visit?), time ( when does a user visit a place for some activity?), and activity ( what does a user do?).

To the best of our knowledge, most of previous studies on model-ing mobility behaviors of individual users have focused on at most three out of the four factors. Several studies [4, 5, 8, 11, 22] fo-cus on the geographical location and the temporal factors, aiming at modeling and analyzing the relationship between user X  X  mobility patterns and temporal factor. An example fi nding of such stud-ies would be that a user usually visits a region centered at a par-ticular building at 2-3pm. Note that understanding human mobil-ity has many applications, such as location-based recommendation and location-based advertisement among others. However, these studies ignore the activity aspects of users, which is represented as tweet content. There also exist studies [13] that focus on the geographic location and activity aspects, but ignore the temporal factor. An example fi nding captured by the models in these stud-ies is that a user participates in some activities ( e.g., having meals) in a geographic region. However, these models cannot capture the relationship with the temporal factor.

In this paper, we model the interactions of all the four factors in a uni fi ed way to better understand individuals X  behaviors. In par-ticular, we discover spatial-temporal topics and identify uses X  in-terest over time and regions from the geo-annotated messages ( e.g., tweets) from users. With our model, we are able to answer the following questions among others.
It is however challenging to develop a model to capture the four factors jointly, since they are in di ff erent data types (continuous and discrete), and the four dimensions together will make the modeling and parameter estimation complicated. Moreover, the interdepen-dencies among them and role played by each is unclear. To this end, based on several intuitions (to be detailed in Section 3.1), we propose a novel probabilistic generative model to model user be-havior from the geographic, temporal, and activity aspects, which has a variety of applications such as user pro fi ling, content recom-mendation, location prediction and recommendation, topic track-ing, etc. We show that our model is able to identify interesting spatial-temporal topics for users, and we demonstrate its e ff ective-ness on various applications such as predicting locations for tweets ( w / wo time), predicting locations for users at a given time, and pre-dicting users who will visit a given location at a given time. Ex-perimental results show that our approach outperforms the existing approaches [8, 13, 17] for these applications.

The contributions of this work are summarized as follows: 2. We propose new inference algorithms for estimating the model 3. Experimental results on two real-world datasets demonstrate
The rest of this paper is organized as follows: We survey the re-lated work in Section 2. Section 3 presents the proposed model and the method of estimating model parameters. We discuss some ap-plications of our model in Section 4, and present the experimental results in Section 5. Section 6 concludes our work.
We group the existing proposal s on mobility modeling and geo-graphical topic modeling based on the aspects considered in these proposals, namely Who, Where, When and What.
 Where What: The existing studies on geographical topic model-ing focus on the geographic (Where) and activity (What) aspects, but do not consider users at all. How to represent locations is an essential part of these studies. Locations have two properties: the geo-locations represented by coordinates, and the functions (e.g., a shop) represented by the topics. Based on the ways of representing locations, the existing studies can be divided into two categories:
First, some proposals [12, 23] represent locations by location ids, and this enables these proposals to distinguish the functions be-tween locations. However, this modeling manner fails to exploit the coordinate information, which is important to analyze the user mo-bility region. Speci fi cally, Wang et al. [23] propose a Latent Dirich-let Allocation (LDA) based model to learn the relationship between location and words. They assume that each word is associated with a location. When a word is generated, its associated location is also generated. Hao et al. [12] mine the location-representative topic from travelogues using an LDA-based model.

Second, other proposals [9, 21, 26] represent locations as coor-dinates, and they are capable of describing the mobility regions of users. However, they either neglect the functions of locations or assume that nearby locations have the same functions, which are generally not true in reality. Eisentein et al. [9] propose regional variants of topics, which are used to generate the words of a geo-referenced document. They use bi-variant Gaussian distributions of regions to generate coordinates of locations. Sizov [21] proposes GeoFolk model to manage geo-referenced documents. In addition to the word distribution, each topic in GeoFolk is also associated with two Gaussian distributions over latitude and longitude, re-spectively. In GeoFolk each geographic region represents a distinct topic / function. Hence, it fails to correlate the di ff erent regions with the same function; it would not be suitable to model a large area containing many topical regions since the topic model becomes computationally expensive as the number of topics is large. Yin et al. [26] propose a Probabilistic Latent Semantic Analysis (PLSA) based model to discover geographical topics. In the model, each region is characterized by a topic distribution, and represented by a bi-variant Gaussian distribution over coordinates.

In contrast, we propose an approach that is able to exploit both properties of locations. Further, di ff erent from these proposals, we model individual users and consider the temporal aspect.
 Where When What: Mei et al. [18] model topics of documents from spatio-temporal aspects using PLSA. Speci fi cally, they as-sume that each word is drawn from a background word distribu-tion, a time and location dependent topic, or a topic of the doc-uments. Similarly, Bauer et al. propose an LDA-based spatio-temporal model [1], where a city is divided into grids. Compared with the models [1, 18], our model considers more aspects:1) the models [1, 18] do not consider the user information at all; 2) it ei-ther does not consider the geographic property of locations [18], or does not consider the functions of locations [1]; 3) they only consider discretized time. There are also several works on extract-ing events from twitter stream [16, 19], which exploit the temporal (When) and activity (What) information, and some work even con-siders the geographic aspect (Where) [20]. However, their problem settings are di ff erent from ours, and none of them considers user information.
 Who Where When: We next review the work on modeling mo-bility behaviors of individual users (Who) that focuses on the geo-graphic (Where) and temporal (When) aspects.

Brockmann et al. [4] fi nd that human mobility behavior can be approximated by the continuous-time random-walk model. Gonz et al. [11] fi nd that users periodically return to a few previously vis-ited locations, such as home or o ffi ce, and the mobility of each user can be represented by a stochastic process centered at a fi xed point. Song et al. [5,22] focus on the predictability in human mobility, and report that there is a 93% predictability of human mobility, which is contributed by the high regularity of human behavior. Cho et al. [8] observe that the mobility of each user is centered at two re-gions ( representing  X  X ork X  and  X  X ome X ), and model each region as a Gaussian distribution over latitude and longitude. The proba-bility that a user stays at the two regions is modeled as a function of time. They propose a generative m odel, Periodic Mobility Model (PMM), to predict the location of a user. PMM takes a user and time as input; It generates a region, and the region further gener-ates a geo-location.

None of these studies consider the activity (topic) aspect of user behavior as we do in this paper.
 Who Where What: The recent work [13] presents a model from the geographic (Where) and activity (What) aspects for individuals (Who). Hong et al. [13] propose a method to learn the geographi-cal topics for twitter users. For a user, this method fi rst generates a region based on the popularity of regions and the preference of the user over the regions. Then, a topic is generated dependent on both the region and the user. The topic, together with the region, gener-ates the words of a tweet; the region alone generates the coordinates based on its Gaussian distribution over coordinates.

Di ff erent from our work, the work does not consider the tem-poral aspect. In addition, the regions [13] are global, which are shared by all users, and cannot precisely depict individual users X  mobility areas, while our proposed model is a ble to model regions of individuals. Moreover, the method fails to consider the semantic information of individual venues in the same region.

In summary, none of existing studies aim to model the three as-pects (Where, When, and What) for individual users (Who). In addition, previous work does not exploit the coordinates and func-tions of locations simultaneously, and thus they cannot capture both the geo-graphic region and functional information of locations. behavior with a collection of geo-tagged tweets. We fi rst describe Section 3.2, and detail the inference algorithm in Section 3.3, fol-lowed by the complexity analysis of the algorithm in Section 3.4.
We model user mobility behavior based on the following intu-itions. These intuitions jointly cover the four factors in user mobil-ity behavior ( i.e., who, where, when, and what). 1. Intuition 1 : an individual X  X  mobility usually centers at dif-2. Intuition 2 : the topics of a user at a place are in fl uenced 3. Intuition 3 : when a user chooses a location to visit, both the 4. Intuition 4 :di ff erent regions and di ff erent topics lead to dif-
We consider each user u has several personal regions, i.e., home region and work region, denoted by { r u , 0 , r u , 1 , ..., r the number of regions. The personal regions are estimated based on the locations of all geo-tagged tweets from a user. We model a location as a two-tuple = { id , c c cd d d } ,where id is the identi fi er of the location, and c c cd d d is the latitude and longitude coordinates of the location, denoted by c c cd d d , 0 and c c cd d d , 1 modeled by a bi-variant Gaussian over the latitude and longitude, parameterized by the mean vector  X   X   X  r and covariance matrix  X  Note that we use r to represent a region ( i.e., any one of the personal regions) when the semantic is clear.

To model the time factor, we model time t in a day as a contin-uous variable in { hh : mm : ss } format, and categorize days into two classes, namely, weekdays and weekends. Speci fi cally, we use s  X  X  0 , 1 } to denote a day of a week, i.e., s = 0 for a weekday and s = 1 for a weekend day. Note that t is cyclical on a daily basis. For instance, the time di ff erence between 23:00:00 and 1:00:00 is thesameasthedi ff erence between 1:00:00 and 3:00:00.

With the above notations, we consider a tweet d is a fi ve-tuple the tweet; d , t d ,and s d denote the location, the time in a day, and the day of a week, as described earlier; w w w d are the words in tweet d . For easy presentation, we use D , U ,and L to denote the collection of tweets, users, and locations respectively. The word vocabulary is denoted by V .Thatis, d  X  D , u  X  U ,  X  L , and each word w w w w d belongs to V . The topics of a user are re fl ected by the words in the user X  X  tweets.
 erates the day, time, words, and location for each tweet posted by a user, shown in Figure 1. The generative process is brie fl y described below. The details of the distributions are discussed after the gen-erative process, followed by the inference algorithm in Section 3.3. 1. For each tweet d of a given user u ,aday s is fi rst selected 2. Parameterized by the topic preference of the user u and the 3. After generating the region and the topic, the location and
In summary, to generate a collection of tweets D , the following generative process is applied to each user u  X  U :
While the distributions for modeling p ( s | u )and p ( t | u , s ) are rela-tively straightforward, it is complicated to model p ( r | u , s , t ), given that r is discrete while t is continuous. We propose a method to solve this problem, which will be detailed in Section 3.3. To model p ( w | r , z ), a parameter  X  is introduced to balance the importance between the region and the topic, i.e., p ( w | r , z ) =  X  p ( w | z ) + (1  X  z and region r , respectively. For sampling, an indicator x following a Bernoulli distribution is assumed with probability p ( x = 0) =  X  and p ( x = 1) = 1  X   X  .Aword w is sampled based on p ( w | z )if x = 0, and sampled based on p ( w | r )if x = 1. Because a tweet is very short, we assume all words in a tweet come from the same topic.

Next, we generate a location according to r and z .Itishowever challenging to model the generating process of location. Previous studies treat a location either as geographic coordinates or a loca-tion identi fi er. Treating locations as geographic coordinates makes it feasible to capture user X  X  mobility regions [26], or discover geo-regions that have speci fi c topics [13, 21], but fails to capture the topic variations of di ff erent locations. On the other hand, treating locations as location identi fi ers enables us to di ff erentiate the top-ics of locations [12, 18, 23] (because p ( | z ) is always modeled by a multinomial distribution, which calls for a limited location set L ), but the geographic coordinate information is ignored.

As stated in Intuition 3 , a user tends to visit a nearby location ( e.g., restaurant) that can ful fi ll her topical needs ( e.g., lunch). That is, when choosing a location to visit, a user jointly considers both its geographic location and its topic ( e.g., restaurant or bar). However, no previous work jointly models geographic locations and topics of locations. Indeed, it is hard to model them together: from the geographic perspective, a location is drawn from a Gaussian dis-tribution N (  X   X   X  r ,  X  r ), which is a continuous distribution, while from the topic perspective, a location is generated based on a multino-mial distribution p ( | z ), which is discrete. What makes the issue even more complicated is that if we treat p ( | r ) as the density of its Gaussian distribution at , p ( | r ) will have a di ff erent scale from that of p ( | z ). The former will be much greater than 1 if is close to the mean vector  X   X   X  r . Thus, a simple combination by linear in-terpolation of the two components leads to p ( | z ) overwhelmed by p ( | r ). A straightforward solution is to perform a good number of sampling based on the Gaussian distribution, and estimate p ( | r ) by counting the times each location is sampled. However, this ap-proach will introduce inner loops, which will greatly deteriorate the e ffi ciency. To solve this problem, we propose a method to com-pute the probability of generating ,givenaregion r , according to Lemma 1: where cd and cd are the geographic coordinates of and its close point after we perform the standardized coordinate transforma-tion for Gaussian as follows. For each point c c cd d d  X  f ( c c cd d d |  X   X   X   X  ), then we have c c cd d d  X  1 Lemma 1:
Proof: Draw a line from the mean point of a Gaussian f ( c c cd d d |  X  to a point c c cd d d , and on the line we can get another point c c cd d d that is  X  farther from the mean point than c c cd d d ,where  X  is a small value (Figure 2 (a)). If  X  is small enough, we can assume that the points between the contours de fi ned by c c cd d d and c c cd d d have equal proba-and c c cd d d , which de fi ne an annulus a with area  X  ( cd  X  ( cd 2 , 0 + cd 2 , 1 ). By integral in the polar coordinate system, we get the probability of a as follows. p ( a ) = (1  X  exp (  X  Dividing p ( a ) by its area, we get the probability value
After the transformation, we get a multinomial distribution p ( | r ), which has the same scale with p ( | z ). Then, a parameter  X  is intro-duced to balance p ( | z )and p ( | r ), i.e., p ( | r , z ) =  X  p ( | z ) + (1  X   X  ) p ( | r ). region r and topic z . The joint probability over tweet d = { u region r , and topic z , can be written as: where In the above equation, c ( w , w w w d ) is the count of word w in w w w
We use an indirect way to calculate p ( r | u d , s d , t from Figure 1, we fi nd the nodes u , s , t , r and the edges between them form a fully connected graph, and other nodes, namely, z , and w w w are all children of them. For this fully connected graph, we can re-order its nodes as follows [3]: where p ( t | u , s , r ) follows Gaussain distribution parameterized by user u stay within a region r is centered at the time  X  u , s , r probability of staying at r decreases as the time becomes derivative
Substituting Equation 2 into Equation 1, we have a new expres-sion of the joint probability:
We can also prove it in a di ff erent way: by applying Bayes The-orem to p ( r | u d , s d , t d ), we have:
By substituting Equation 4 into Equation 1, we again reach Equa-tion 3.

This model has a set of parameters p ( r | u , s ), p ( z | u , r ),  X  the log-likelihood of the historical data D :
We use Expectation-Maximization (EM) to fi nd parameters  X  that can maximize the log-likelihood of the historical data.
In the E-step , since there are two latent variables r and z in W 4 , we update their joint expectation p ( r , z | d ) according to Bayes rule as Equation 6. In the M-step ,we fi nd the new  X  that can maximize the log-likelihood as follows: where D u , s is the collection of tweets written by user u on the day s . We will not explain D ( . ) unless necessary. where td ( t 1 , t 2 ) is the di ff erence between time in a day t because the time in a day is cyclical. Note that for each region, we get two sets of  X  and  X  2 ,andthetwo  X   X  X  are 12-hour apart from each other. For example,  X  for 1:00 and 23:00 can be either 0:00 or 12:00, but the  X  2 value for 0:00 is much smaller than that for 12:00. Obviously, 0:00 is a better choice for the mean than 12:00. Thus, between the two sets, we choose the  X  ,  X  2 pair with the smaller  X  2 value.

Estimating p ( w | r )and p ( w | z ) is not straightforward, because they are coupled by the sum in logarithm in the log-likelihood, i.e., log (  X  p ( w | z ) + (1  X   X  ) p ( w | r )). We solve this problem by applying Jensen X  X  inequality [14]. Because logarithm is a concave function, we have: By substituting the above two Equations into Equation 5, we have a lower bound of the log-likelihood. By maximizing the lower bound, we have: Please note that the lower bound technique has no impact on the inference of other parameters, since they are surrounded in di ff erent logarithms. As a result, the derivative with respect to a parameter does not involve with the others.
We now analyze the time complexity of the inference algorithm proposed in Section 3.3. For Equation 6 in the E-step, the time number of topics, the size of collection or number of tweets, the total number of words in the collection, and the number of regions for each user, respectively. The evaluation of Equation 6 requires to estimate p ( | r ). Theoretically, the time complexity to estimate p ( | r )is O ( | U || R || L | ). However, early pruning of locations faraway from r can be conducted. For example, when estimating p ( | r )for a user in the United States, it is unnecessary to calculate p ( | r )for locations in Singapore, since its value approximates to zero based on Lemma 1 . A number of indexing techniques can be employed to achieve the early pruning of the search space | L | , such as R*-Tree [2], Quad-tree [10], etc. For M-step, the time complexity for f or Equations 11, 12. Thus, the time complexity for the M-Step is iterations, which is set to 50 in our experiments. some of them as examples: Location prediction for tweet . Given a tweet with its text content, user id, and posting time, the task of location prediction is to pre-dict the most likely location at which this tweet is posted. It has been shown [7, 8] that geographical locations can be used to predict user X  X  behavior, discover users X  interest, and deliver location-based advertisement or content. However, it is reported that only 1% X 2% of tweets have geographical locations explicitly attached. Hence, location prediction for tweets is an very important application.
A number of methods have been proposed for this task [9, 13, 15, 17, 24]. The studies [15, 17] build language models for each candi-date location, and make prediction based on these language models. They are designed to predict location identi fi er for a text. Instead of predicting a location for a give text, the work [24] segments the world into grids, and employs supervised models, such as Naive Bayes, to predict grid for a given text. The recent proposal [13] presents a new approach for predicting geographic coordinates of a text from a user(See Section 2 for details).

Since W 4 incorporates both location identi fi ers and geographic coordinates, we can make both kinds of predictions for a text from a user, namely, predicting location identi fi ers [15, 17] and geographic coordinates [13]. Our method is also able to take the time factor into consideration.

Formally, given a user u ,day s , time t ,andwords w w w d (represented with both location identi fi er and geographic coordi-nates) is predicted by maximizing p ( | u , s , t , w w w calculate p ( | u , s , t , w w w d ) for each candidate location as follows: where p ( u , s , t , r , z , w w w d , ) is computed as Equation 3. Requirement-aware location recommendation . Location recom-mendation aims to recommend new locations for users. Previous studies only rely on users X  historical visiting information [6, 25], neglecting the speci fi c needs at a given time. W 4 is able to utilize both the time and the needs (in the form of short text), to make more accurate recommendation. Given a user u ,day s , time t and words w w w d that describe the need, the candidate locations are ranked by p ( | u , s , t , w w w d ), de fi ned by Equation 16, and the top ranked ones are returned as results.
 Activity prediction .W 4 is able to predict the activity of a user at a given time. Speci fi cally, given a user u and time s and t ,thewords describing the activity are ranked by: User prediction . User prediction aims to predict the likelihood of a user visiting a location at a given time. This could be very useful for merchants for planning purpose, or for them to target on speci fi c costumers. Speci fi cally, given location ,day s , and time t ,werank candidate users by p ( u | , s , t ), which is calculated as follows: Note that previous studies on user mobility modeling ( e.g., [8]) can also be used for user prediction, if we use location and time as in-put, and fi nd the user who can maximize the likelihood.
 Location prediction for user . This task is to predict the place where a user stays at a given time. This would be useful for logis-tic planning, e.g., to arrange a meeting with a user or a group of users, and location-based advertisement delivery. Formally, given auser u and time t , we aim to rank all candidate locations based on p ( | u , s , t ), which is calculated by: Tweets recommendation . This task is to recommend tweets that are interested to a user based on the user X  X  topic preferences, current location and time. Speci fi cally, given user u ,day s , time t ,and location , we aim to rank tweets by considering p ( w w w where w w w d is the word vector of a candidate tweets, and
We evaluate the proposed model in this section. Against several for the application of location prediction for tweets in Section 5.2. We present samples of the discovered topics and the mobility pat-terns of users in Section 5.3. Results of other example applications
In our experiments, we use two real-world datasets, namely, WW dataset and USA dataset.
 WW Dataset . Using the streaming API provided by Twitter 2 ,we collect a large volume of tweets with location information from November 1, 2012 to February 13, 2013. We refer to this dataset as WW (World-wide) dataset as the tweets are from users in di ff erent countries.
 USA dataset . This dataset is the GeoText 3 (Geo-tagged Microblog Corpus) published by researchers from Carnegie Mellon Univer-sity [9]. This dataset comprises messages from geo-located mi-croblog users approximately in the United States. Each message is associated with its geographic coordinate. To map the geographic coordinates of each message to a location identi fi er, we crawl the geographic coordinates of locations in United States from Foursquare, and map the coordinates of each message to its nearest location.
For both datasets, we remove stop-words, and keep only the ac-tive users who visited at least 5 di ff erent locations. The statistics of the datasets after pre-processing is shown in Table 1. For each dataset, we randomly split the documents (tweets or messages) into three collections in proportion of 8:1:2 as the training set, develop-ment set, and testing set, respectively.
Given a tweet with its text content, user id, and posting time, the task of location prediction is to predict the most likely location at which this tweet is posted.
To evaluate the prediction performance of di ff erent models, we use two metrics, namely, prediction accuracy (Acc) and average error distance (Dis).
 Prediction accuracy (Acc) is the percentage of tweets for which the predicted locations are exactly the true location among all tweets in the test set.
 Average error distance (Dis) is the average of the Euclidian dis-tance between the predicted geographic coordinates and the true geographic coordinates for all tweets in the test set.
Note that Acc and Dis are di ff erent X  X t is possible that the num-ber of correctly predicted tweets is similar, but the wrongly pre-dicted locations are deviated from the true locations very di ff er-ently for di ff erent methods. Apparently, larger Acc and smaller Dis indicate better prediction performance.
We compare with two baseline methods to evaluate the perfor-mance, which are the state-of-the -art models for predicting loca-tions for text.
 KL-divergence based method (KL) [15, 17]. This method builds language models (LM) for each candidate location during training. Given a test text, it computes the KL-divergence between the LM of the test text and the LM of each candidate location, and returns the most close location as the result.
 Topic + Region (TR) [13]. This model captures the user preference over latent regions and topics. The location is generated from the Gaussian of regions, and words are generated based on the topic and region. This model represent locations as geographic coordi-nates. In addition, the latent regions in this model are not personal. Given a tweet from a user, TR predicts the geographic coordinates of the tweet, but cannot return the location identi fi er. Thus we can-not compute Acc for TR. In order to compare with other approaches in terms of Acc, we identify the location identi fi er for the predicted geographic coordinates by fi nding the nearest location to the coor-dinates.

Neither KL nor TR method makes use of the time factor in pre-diction. To study the performance of our model without time factor, we also use a simpli fi ed version of our proposed method as a base-line method.
 Who + Where + What (W 3 ). This W 3 method is based on similar inference modeling as our proposed model without considering the time factor ( i.e., time of a day and day of a week). Note that W 3 considers the similar set of aspects as does the TR model [13], but its modeling method is di ff erent from TR.
 Who + Where + When + What (W 4 ). The di ff erences between W 4 and other methods are summarized in Table 2, where  X  X snR X  and  X  X lbR X  represent  X  X sing geographical information by estimating personal regions X  and  X  X sing geographical information by estimat-ing global regions for all users X , respectively.
We fi x the number of personal regions as 2 for each user ( e.g., home region and work region), following the setting in [8]. Note that our model is capable of dealing with a larger number of per-sonal regions. In our datasets, we notice the cases that a user may visit only one location at a region, or visit a region at only one time point. Such cases will result in problems like (i) errors in calculat-To avoid these problems, we set the minimum values for the deter-minant of  X  u , s , r and  X  2 u , s , r to be 1e  X  16 and 1, respectively.
We set the three parameters in our model, namely, K : the number of topics,  X  : the weight of p ( w | z ), and  X  : the weight of p ( | z ), by tuning them one by one on the development set. The default values for them are 60, 0.5, and 0.1, respectively. The tuning results on both datasets are reported in Figure 3. The impacts of varying the three parameters are discussed below.

We fi rst study the e ff ect of number of topics K on the prediction performance. Figures 3(a) and (b) report the results of varying K from 10 to 100 on both datasets. Observe that K has almost no impact on Acc on both datasets. It has little impact on Dis on USA dataset. However, a larger K usually results in greater Dis on WW dataset. Recall that Acc and Dis are two di ff erent metrics, and Dis could be very di ff erent for di ff erent parameter settings even with similar Acc. We set K to 10 for WW data and 20 for USA data.
Next we tune  X  . Observe from Figures 3(c) and (d), when  X  = 0 or 1, Acc and Dis on both datasets are worse than other  X  values between 0 and 1. This result shows that word variations of both regions and topics are important for prediction. We set  X  to 0.6 for both datasets.

Finally we tune parameter  X  . The results are shown in Fig-ures 3(e) and (f). We observe that on both datasets, as  X  is in-creased, Dis increases, but Acc keeps stable. However, Acc almost drops to zero at  X  = 1 . 0, where the location selection is made only based on the topics ( p ( | z )), and the region information ( p ( | r )) of users is ignored. This is understandable since locations of all over the world can be returned as prediction results if the topic matches. At  X  = 0, the prediction is purely based on the region of the user without taking into account the topics of the user X  X he predicted locations would be close to the mean location of the regions of the user. Finally, we set  X  = 0 . 1 for both datasets.
We compare the prediction performance of the four methods information in prediction.
 line methods KL and TR signi fi cantly in terms of both Acc and Dis. WW and USA datasets, respectively. In terms of Dis, compared 77.02% on the two datasets, respectively.

KL is designed to predict the location label for short text. Be-cause it does not exploit geographic coordinate information, its prediction performance in terms of Dis is much worse than other methods, i.e., the average error distance of KL is much greater than those of the other methods. In addition, KL builds language model for locations based on the words posted by all users without consid-ering the individuals X  visiting history. In other words, it does not consider the preferences of individual users on locations. More-over, the number of tweets posted at each location is small on av-erage as observed from Table 1, and thus the language models of location are usually sparse, limiting the prediction performance of KL.

TR is designed to predict the geographic coordinates for short text. It returns the mean of the Gaussian distribution of the most likely latent region for a given tweet as the prediction result, but not the location identi fi er of the prediction. We observe that TR performs much better than KL in terms of Dis on both datasets. TR is based on topic models while KL adopts language models. Fur-thermore, TR incorporates the user preference information and the geographic coordinates information in its model. However, TR has the worst Acc among all methods, since the means of the global re-gions are less likely to be the exact locations of individuals X  tweets. TR, but it outperforms TR signi fi cantly. The reasons are two fold. latent geographic regions in TR is global for all the users. Hence, precisely than the regions in TR. Second, both the location identi-fi ers and the geographic information of locations are used by W 3 to enhance the prediction.
 mobility patterns in terms of geographic, temporal, and activity as-pects.
We take the model trained on WW dataset as an example to
We fi rst randomly select 5 topics, and check their representative words. Speci fi cally, for each topic z , we rank the words based on p ( w | z ) and use the top-6 English words to represent each topic. The results are shown in Table 3.
 For the ease of reading, we manually assign title for each topic. We fi nd that, the representative words well reveal the semantic meaning of each topic.

Next, we randomly select a user, and look into the user X  X  mobility patterns. We plot the two personal regions of the user in Figure 5, and the time patterns of each region in Figure 6. We assign the Topic Representative words Home family fun o ff road rental home love Dinning lunch dinner birthday breakfast drinks eat Nightlife night happy singing playing dance football Wor k working tonight co ff ee tired money friday
Holiday christmas friends holiday merry celebrating choir labels ( e.g., work and home) to the two regions based on the time of user visits. Figure 5 shows that the two geographic regions of the user are not far from each other. In addition, the contour lines of the work region are more close together than that of the home region, showing that the user usually stays in a small region at workplace, but visits a relatively larger range of places around her home.
From Figure 6, we observe that the user has di ff erent time pat-terns over the personal regions in weekdays and weekend. The time span that the user is more likely to stay in work region on weekends is much small than that on weekdays. In addition, the user is likely to spend more time in home region on weekends than that in week-days.
In addition to location prediction for tweets, we implement an-other three applications, namely, activity prediction, user prediction and user X  X  location prediction, and present their evaluation results in this subsection. We do not evaluate the location recommendation and tweet recommendation, because they require di ff erent datasets than what we use in our experiments.
 Activity prediction Activity prediction returns the representative words describing user X  X  activity at a given time. Using two dif-ferent time as input ( i.e., 14:30 weekday, and 10:00 weekend), the top-6 (in terms of p ( w | u , s , t )) English words returned by W 4 for a randomly selected user from WW data are shown in Table 4.

Observe that, in the weekday afternoon, the user X  X  activity is more about work, taking a co ff ee break or resting. The user may also do body-building sometimes in the weekday afternoons. In the morning of weekends, the user stays at home for breakfast. Shop-ping and eating are also keywords for weekend mornings for the selected user.
 User prediction . User prediction aims to predict the user who is most likely to visit a given location at a given time. We compare both datasets. Note that here we do not use the text of tweets, and thus PMM is applicable while the baseline approaches [13, 15, 17] for predicting locations of tweets take text as input and are not ap-plicable here. For each tweet in test set, its time and location are used as input; if the predicted user is the true user of the tweet, it is a correct prediction. We employ prediction accuracy (Acc) as the evaluation metric, which shows the percentage of correct predic-tions. time words 14:30 weekday break work co ff ee resting gym international 10:00 weekend good morning home breakfast shopping eat performs PMM by 21.62% and 45.81% on the two datasets, re-spectively. Potential reasons are two-fold: on the one hand, we use a new way to calculate the probability of latent regions at a given time, which is di ff erent from the way used in PMM; on the other hand, our model exploits both the functional and graphical coordi-nate information of locations, while PMM only utilizes the latter. Location prediction for user . This task aims to predict the loca-tion at which a given user is most likely stay at a given time. For each tweet in test set, its time and user are used as input; if the predicted location is the true location of the tweet, it is a correct prediction. We still evaluate the performance using prediction ac-curacy. The experimental results are reported in Table 6. For this task, the PMM method is also used as the baseline, where the in-put has no text. The results show that our method outperforms the baseline method signi fi cantly for similar reasons discussed earlier.
The large availability of geo-tagged tweets enables us to study individuals X  mobility behaviors from four factors, namely user, ge-ographic information, time, and activity. Unfortunately, none of the previous studies considers all of them. In this paper, we propose a the four factors jointly, and providing a comprehensive description several applications on two real-world datasets, and the experimen-tal results show that the proposed method outperforms state-of-the-art baselines signi fi cantly for these applications.

In the future, we aim to exploit the proposed model for other po-tential applications. In addition, it will be interesting to incorporate social information into the model.
This work is supported in part by a grant awarded by a Sin-gapore MOE AcRF Tier 2 Grant (ARC30 / 12), a Singapore MOE AcRF Tier 1 Grant (RG66 / 12), and a grant awarded by Microsoft Research Asia. Quan Yuan would like to acknowledge the Ph.D. grant from the Institute for Media Innovation, Nanyang Technolog-ical University, Singapore.
