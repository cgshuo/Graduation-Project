 Strategic planning and talent management in large enter-prises composed of knowledge workers requires complete, accurate, and up-to-date representation of the expertise of employees in a form that integrates with business processes. Like other similar organizations operating in dynamic en-vironments, the IBM Corporation strives to maintain such current and correct information, speci cally assessments of employees against job roles and skill sets from its exper-tise taxonomy. In this work, we deploy an analytics-driven solution that infers the expertise of employees through the mining of enterprise and social data that is not speci cally generated and collected for expertise inference. We consider job role and specialty prediction and pose them as super-vised classi cation problems. We evaluate a large number of feature sets, predictive models and postprocessing algo-rithms, and choose a combination for deployment. This ex-pertise analytics system has been deployed for key employee population segments, yielding large reductions in manual e ort and the ability to continually and consistently serve up-to-date and accurate data for several business functions. This expertise management system is in the process of being deployed throughout the corporation.
 I.2.6 [ Arti cial Intelligence ]: Learning; H.2.8 [ Database Management ]: Database Applications| Data Mining expertise assessment; human resources; supervised classi -cation; talent planning; workforce analytics
The International Business Machines (IBM) Corporation is one of the largest employers of knowledge workers in the world. The global workforce is over 425,000 employees strong, with greater and greater fractions selling or delivering in-formation technology and business consulting services every day. Two key trends in the information technology industry include a quickening pace of technological innovation and an increased customer-centrism by all employees. In the face of these trends, it is important for IBM's strategic and tactical business decision-making to be informed by com-plete, precise, accurate, and up-to-date information on the expertise of its employees. What team|in terms of compo-sition of employee skills|should serve a particular client, which emerging technology areas IBM has adequate skills and experience in to support (e.g., cloud computing, cogni-tive computing, social business), and other similar decisions are all predicated on such information [12, 18, 1].
The human capital, or talent and expertise, of its work-force is IBM's greatest asset; only through valid and trusted data on employee expertise can this human capital be uti-lized to its fullest potential. Such expertise information is captured by existing expertise management systems within the IBM enterprise, but can be enhanced using digital `bread-crumbs' and data `exhaust' from other enterprise systems of record that have `footprints' of employees' work activi-ties (e.g. project claims, sales pipeline, etc.). However these pieces of data often provide only a di use indication of ex-pertise. The main contribution of this work is using predic-tive analytics to churn such nebulous data into clear indi-cators of employee expertise in a way that commingles with existing IBM business processes.

Human resources (HR) departments are transforming from support functions to strategy leadership in many ways. David Bernstein, Vice President of Big Data for HR at eQuest, re-cently said in discussing di erent levels of talent analytics (operational reporting, advanced reporting, advanced ana-lytics, and predictive analytics) that 1 \predictive analytics is where HR develops predictive models and integrates with the organization's strategic planning. The majority of orga-nizations, however, are not doing this, yet." The fraction of organizations engaged in predictive HR analytics is reported to be as low as 4% [2]. Recent predictive modeling initiatives put IBM's HR organization into the 4% category. However, like most other organizations, the newly adopted predictive HR analytics in IBM are mostly focused on recruitment and hiring, resource deployment and proactive talent retention [22, 16, 6, 21]. Predicting expertise is a much more open-ended problem than the others. h ttp://www.bigdatarepublic.com/author.asp? section_id=3431
Ext ant expertise systems, such as LinkedIn's skill recom-mendation, are completely free-form in how skills are de-scribed. In order to operate the IBM business, however, we need a semi-structured approach which relies on IBM's ex-isting expertise taxonomy to link to solutions and products that IBM sells and to tap into an entire ecosystem of pro-cesses and reporting tools built around the taxonomy. The existing expertise assessment system and taxonomy yield many bene ts to the company, but have a few shortcom-ings in keeping data current and accurate as detailed in Sec-tion 2. Therefore, our goal is to start with the IBM expertise taxonomy and assessments, pull in other data sources infor-mative of expertise, and create good predictions of employee pro ciencies.

In our work, we speci cally investigate the prediction of an employee's primary job role and job role specialty (which are the third and fourth levels of the ve-level IBM exper-tise taxonomy) from enterprise systems of record and data from the internal corporate social networking site IBM Con-nections as features. Since employees have a single primary job role among a set of labels with not too exorbinant car-dinality, we approach the predictive modeling problem as a classi cation problem. Since we have veracious data on a reasonable fraction of employees' job roles and job role spe-cialties, we can further formulate the problem via supervised multi-category classi cation, using the veracious fraction of employees' data as a training set. We perform a comprehen-sive study of classi cation algorithms and feature sets, nd-ing the Liblinear implementation of logistic regression using job title and HR information features to perform with best generalization accuracy [9]. Moreover, since employees tend to be grouped in the IBM organizational structure by job role and skill set, e.g. mostly strategy consultants under one manager and mostly information architects under a di erent manager, we attempt to improve classi cation accuracy tak-ing these relationships into account, but do not nd enough improvement to warrant inclusion in the deployment.
In previous work, we investigated the prediction of skills |the lowest level of the IBM expertise taxonomy|using matrix completion-based collaborative ltering with side in-formation [24, 27], including in the cold-start regime [10]. This problem is di erent because unlike skills, which em-ployees have many of, employees only have one primary job role and one primary job role specialty each. Therefore, col-laborative ltering is not appropriate for job role and job role specialty prediction. Other approaches for predicting the expertise of employees within an enterprise such as IBM are focused on social media data only and importantly, are not meant to be integrated with existing business processes [13, 20, 4, 11, 5], whereas we consider other types of enter-prise data as well and integrate with existing practices.
Predicting primary job roles and primary job specialties is mainly intended to improve processes related to and built upon the `inventorying' of employees. This work represents a part of a larger e ort to transform the way the IBM Corpo-ration operates. A complimentary piece of work is enabling expertise search [23, 7, 8, 19, 14], i.e. the ability for em-ployees to nd other employees who are experts on some topic. Expertise search is driven by the need of employees to nd the right person to answer a question, to bring to a client meeting, to ll out a team, and so on. Another part of the e ort is the creation of enhanced pro le pages known as digital business cards that better enable the collection of expertise-related information and provide enhanced user experience. These parts have been deployed within IBM through web-based and mobile-based applications.

The job role and job role specialty prediction algorithms we have developed are in various stages of deployment in IBM. Predicted job roles from our algorithm have been ap-plied to the population of all salespeople worldwide in the company. This employee segment represents less than 10% of the employee population and is more active in maintaining accurate job roles than other employee populations. Admin-istrators responsible for these employees used our outputs to accurately enter job role values for thousands of salespeople with either no job roles entered or an invalid or outdated job role entered. This initial single one-time deployment saved the company the equivalent of one employee's full-time e ort for an entire year, not to mention all of the business bene ts from current, correct data. Moreover, we are now in the pro-cess of rolling out the predictive models with a user-centered design to allow administrators in the entire company to con-tinually maintain complete and accurate job roles and job role specialties with corresponding compounded e ort sav-ings.

The remainder of the paper is organized as follows. In Sec-tion 2, we provide a description of the expertise assessment system and processes that IBM currently uses. In Section 3, we formulate job role and job role specialty prediction as a supervised classi cation problem and describe the features available for making the prediction. Section 4 details our empirical study of various features and classi cation algo-rithms. We then describe the deployment of the approach within IBM in Section 5. The paper concludes in Section 6.
In this section, we focus on describing the problem in de-tail along with its signi cance. We rst recapitulate the history of expertise assessment in IBM and show how this history motivates an evolution to predictive modeling, as developed in this work.
IBM has a taxonomy of employee expertise with the fol-lowing ve coarse-to-ne levels: primary job category, sec-ondary job category, job role, job role specialty, and skill. The taxonomy is a directed acyclic graph with parent-child relationships between values at di erent levels. We provide three examples of paths through the taxonomy with the ve di erent levels separated by the greater than symbol: Sales &gt; Industry Sales &gt; Brand Client Representative &gt; Brand Client Representative: BAO-Advanced Analytics &amp; Opti-mization &gt; Sell ILOG Optimization; Human Resources &gt; Learning &gt; Learning Consultant &gt; Learning Consultant: Collaboration, Knowledge &amp; Communities &gt; Analyze Per-formance Improvement Needs; Research &gt; Research Sta &gt; Research Scientist &gt; Research Scientist: Computational Biology &gt; Develop Algorithms for Biological Data Analysis. An individual employee has a single primary job role and primary job role specialty, which are the values we predict in this work.
IBM utilizes an internally-developed application to collect expertise assessments from employees. The system was de-ployed in the year 2000 and at that time, contained many lea ding-edge functions, numerous approaches to customize for di erent parts of IBM's business organizations, and a be tting user interface for employees. The basic function of the application is: 1. collecting information from the employee on what area 2. having the employee select a primary job role and job 3. presenting each employee with a list of expertise skills The application interfaces directly with the IBM expertise taxonomy, which contains the relationships of expertise skills to the job role classi cation hierarchy. For example, each job role has a set of prede ned expertise skills that are associ-ated with it; based upon the employee-provided job role, the application asks the employee to assess the skills related to that job role.

While it is simple in concept, as IBM organizations have desired to collect ner expertise information over time, the taxonomy has grown, the number of job role specialties has grown, and the business rules that determine which employ-ees assess which job role specialties has become quite com-plex. In 2000, the number of job roles was around 200 and the number of specialties 1000; today, there are around 350 job roles and 7000 specialties. The goal is to use the informa-tion collected about employees to ensure that the expertise skills which they are asked to assess directly pertain to their success in the their job: `the right skills to the right employ-ees.' However, the business rules sometimes deliver more than 100 skills for employees to assess, which results in a suboptimal user experience and subsequent lack of compli-ance.

While the current expertise assessment application has served its purpose for many years, it was designed during a time when IBM's product portfolio changed perhaps once every three or four years. Updating the taxonomy requires adding new skills to re ect new product knowledge. Updat-ing the application's expertise delivery business rules also requires some thought to determine who should assess these new product skills. Therefore in an environment where an organization could set up the tool once every two years and have employees assess against a relatively constant set of expertise skills, the work required to set up the tool was relatively small compared to the bene t of the resulting ex-pertise information collected.
Today IBM is a much more dynamically-changing com-pany with new products, solutions, and acquisitions emerg-ing each quarter. Thus the time and work required to set up a structured assessment begins to limit the ability to have expertise information that is responsive to the rapidly-changing needs of the business. These rapidly-changing needs of the business are actually dictating that the company evolve to a new expertise assessment approach that is much more exible and requires much less time and e ort to set up. Any information collected directly from employees requires some degree of end user design, setup, and testing. Information inferred from normal work products bypasses much of this design, setup, and testing by its very nature.

Through the proposed work, IBM is moving toward a world in which predictive analytics based upon employees' digital footprints is almost constantly updating the current inventory of expertise across the company. The eventual goal is to move from the world of counting and taking in-ventory once a year based upon a taxonomic system that was put in place a year earlier, to a world of instantly updated inventories: updated as soon as new terminology nds its way to the folksonomy and as soon as an employee creates digital evidence of new expertise gained. All the bene ts that supply chain systems have realized over the last twenty years, with just-in-time inventories, point-of-sale inventory updates, economic order quantities, and predictive inventory demand are becoming possible for human resources and ex-pertise management.
In this section, we discuss the decisions and tradeo s in making design choices for the data mining solution to the job role and specialty prediction problem within the IBM enterprise. In Wagsta 's three stages of a machine learn-ing research program, this section is devoted to the neces-sary preparation phase: phrasing the problem as a machine learning task, collecting data, and selecting or generating features [25].
Several di erent machine learning or information retrieval formulations are possible for predicting and recommending primary job roles and job role specialties. We rst lay out the desiderata of the solution and then comment on the choices made.

As mentioned earlier, an employee is supposed to have one primary job role and one primary job role specialty. Each line of business (LOB) maintains a short list, or subset, of job roles and specialties in the taxonomy that its employ-ees may validly have. A reasonable fraction of employees throughout IBM have valid job roles and specialties, but there exists a signi cant fraction with values outside their LOB's short list or with no value entered at all.
The task at hand is two-fold: rst, lling in the job role and specialty of any employee whose value is blank or in-valid according to their LOB; and second, identifying em-ployees whose values, although valid, are nevertheless in-correct based on their current job responsibilities and cor-recting them. The users of the system are not intended to be individual employees, but managers, administrators, and planners. An analytics solution is not intended to be fully automatic, but to recommend predictions and corrections that the user may or may not accept for each employee. In this mode of operation, a list of top k predicted job roles and specialties along with con dence values in the predic-tions may be more useful than a single prediction without an indication of con dence (wth k not more than three or four from a human factors concern).

One approach to tackle this problem is through an infor-mation retrieval formulation. We can index various data sources that provide an indication of expertise. Then, per-forming searches using query terms related to each job role or specialty, we can see in which search result the employee is ranked highest. However, constructing appropriate query terms that well-di erentiate often-similar job roles and spe-cialties is dicult and this approach is an indirect way of ta ckling the problem. The direct way of approaching the problem is via classi cation because the task is to label an individual from a fairly small set of labels. As discussed in Section 1, collaborative ltering (narrowly construed as predicting the preference of an individual by collecting pref-erences from many individuals) is not appropriate because each employee has only one primary job role and specialty.
Classi cation need not be based on statistical machine learning. Oftentimes, manually-speci ed logical classi ca-tion rules developed by subject matter experts perform ex-cellently. However, as discussed, such manual work is not sustainable in the dynamic business environment of today. For a machine learning approach, we need to have reliable training data. The reasonable fraction of employees with non-blank and valid labels is sucient for the rst task even though there is label noise (the whole reason for the sec-ond task), because this noise is not overwhelming. 2 For the second task, we can take a cross-validation approach to construct training and test sets in such a way that we can identify employees that do not t the pattern when they are a part of the test set.

We do not consider semi-supervised learning because we want all unlabeled samples (the invalid-and blank-valued employees) to be a part of the test set in the rst task. Moreover, we focus on classi cation rather than learning to rank because of the form of the training data and because we are typically only concerned with accurately obtaining the best one, two, three, or four labels for an employee, not the entire permutation of ranked job roles or specialties for an employee.

Thus overall for the skills analytics problem we are facing, the most direct and appropriate formulation is supervised multi-category classi cation. Moreover, due to the busi-ness structure, we learn separate classi ers for the di erent LOBs within IBM because there are di erent valid class la-bels and di erent feature distributions among the di erent LOBs. Multi-task learning could be possible in this setting to do joint training for di erent LOBs, but we choose not to pursue this direction because it introduces unnecessary complexity.
There are several potential data sources that give some indication (sometimes in a quite di use way) about an em-ployee's expertise, speci cally as manifested in his or her job role and job role specialty. Within the IBM context, we can divide the potential data sources into four categories. The rst category is employees' descriptions of their job in their own words. For many years, one line shown underneath the employee's name in the corporate directory has been a free-text eld entered and edited by the employee. This text eld is known as the job title. A similar, but longer, text eld on the recently deployed digital business card mentioned in Section 1 deemed `what I'm known for' is also of this same category of data sources, but we do not use it in the work described herein because it is in its incipient stages of adop-tion.

The second data source category is standard HR infor-mation recorded about all employees as standard practice.
W e do not include any label noise correction, e.g. [17], to maintain implementational simplicity and because once the system has been deployed for some time, the label noise problem will fade away by itself.
 Example elds include the length of service; the work loca-tion; the names of the group, department, and business unit to which the employee belongs; the job category of the em-ployee, which is the highest level of the expertise taxonomy, but is maintained in a separate manner than job role and job role specialty; the employee's pay grade; and whether he or she is on a commission-based compensation plan.
The third category of data sources is work products, which includes artifacts produced by employees as part of their reg-ular job responsibilities. As such, in contrast to the other data source categories, this category is job-speci c. For ex-ample, researchers produce publications and patents, soft-ware developers produce documentation and code, salespeo-ple work on and record sales opportunities, delivery person-nel bill claims for their services, and so on. These days, much of this activity is captured digitally in various systems, but accessing and working with such data is often dicult. In this paper, we present empirical results on the LOB con-taining salespeople and show results from sales opportunity data.
 Activity on the internal corporate social networking site, IBM Connections, constitutes the fourth data source cate-gory. There are several di erent types of social media con-tent, including pro les, status updates, blogs, wikis, com-munities, forums, bookmarks, and calendars. They are also all associated with tags. Certain social media content is pri-vate whereas other content is public. For this project, we may only access public content and tags. Private material is typically con dential precisely because it relates to ongoing work activities, and thus its exclusion presents a limitation. Public content is not always work-related: there are com-munities for sports leagues, ethnic anity groups, etc. too.
For each employee, we collect content from the HR infor-mation management system, business data warehouse, per-sonal pro le, and internal enterprise social network. Fig. 1 demonstrates examples of the extracted raw data, including the job title information from the HR data warehouse, sales opportunity data from the business data warehouse, and the associated tags retrieved from the social network.
The key step in processing sales data is mapping sales opportunities to employees. Several roles are associated with opportunities, including opportunity owner, support-ing team, contact person, etc. In this work, we take the text descriptions of all opportunities a salesperson owns and create bag-of-words features from this text. To create a bag-of-words representation, we rst convert the text into lower case and eliminate stop words. Then the text is tokenized and numerical term frequencies are computed. We compute similar bag-of-words representations for job title and social tags. Furthermore, categorical HR elds such as reporting chain and work location are processed into binary features. In summary, we have derived multiple feature representa-tions for the employee in the feature engineering stage; the predictive power of each feature set is studied in our exper-iments section.
This section is devoted to the second stage of a machine learning research program, described by Wagsta as the \machine learning contribution" [25]. We discuss the choice and development of an algorithm, discuss the choice of a Figure 1: Examples of raw data for a single em-ployee: (a) tags from IBM Connections, (b) sales opportunity data, and (c) job title. metric, and conduct experiments to determine relative and absolute performance numbers.
We would like to solve a multi-category classi cation prob-lem with the features described in Section 3 to predict em-ployee job role or job role specialty. Many di erent classi-cation models may be applied to the problem; there is no particular a priori preference for any speci c algorithm. We compare the performance of several models in the sequel. The performance metric of interest in this problem is classi-cation accuracy. Although not the most sensible metric in many applications, it truly is the most sensible in job role prediction because the classes are not severely imbalanced and di erent types of misclassi cations do not have di erent costs.
In this empirical study, we focus on the job role classi ca-tion problem rather than the job role specialty classi cation problem, but algorithmically, we treat both in the same way with the same features and evaluation criteria. The speci c LOB that we focus on here is the set of all salespeople in the entire IBM Corporation worldwide. We have conducted similar empirical studies for other LOBs and populations, consistently nding similar results.
 For this LOB, there are eleven valid job roles: Brand Client Representative (BCR), Client Representative (CR), Client Technical Architect (CTA), Client Technical Man-ager (CTM), Client Technical Specialist (CTS), Client Unit Executive (CUE), Industry Solution Representative (ISR), Mid-Market Client Representative (MCR), Solution Rep-resentative (SR), Solution Representative { Brand Special-ist (SRB), and Solution Sales Manager (SSM). As may be guessed based on their names, several of these di erent job roles are fairly similar to each other. Due to this fact, it is not straightforward for employees to label themselves quickly and accurately, not to say anything about a machine learning algorithm.

As discussed in Section 3, we take all employees with valid labels as the training set. This amounts to 36,709 employees, which is 89% of the salesperson population. The largest class, SRB, represents 0.2633 of all sellers and thus this value is the baseline classi cation accuracy. We com-pare four one-against-the-rest multi-category classi cation algorithms: linear logistic regression with  X  2 and  X  1 regu-larization, linear support vector machine, and na  X  ve Bayes. The regularization parameters for the rst three models are found by cross-validation.

In order to estimate generalization accuracy, we calculate vefold cross-validation test error for the di erent classi ers. Cross-validation provides such an estimate because there is no reason to suspect any systemic bias in employees with blank or invalid class labels. We also compare the four dif-ferent feature sets individually and in combination: job title, HR information, sales opportunities, and social tags. We take the 1000 terms with the highest term frequency from the text analytics for each of the data sources except for HR information. The HR information consists of 23 categorical features converted to binary and one numeric feature. The test accuracy results are given in Table 1.

It is clear in the results table that the na  X  ve Bayes classi er performs the worst across all feature sets and the support vector machine is consistently a little bit worse than logistic regression. The two di erent regularization versions of lo-gistic regression are nearly the same across all feature sets. The most interesting thing to notice is that the classi ca-tion accuracy from only social tags is actually worse than the baseline accuracy. The performance from only sales op-portunities is also quite poor. This poor performance can be attributed to the words in descriptions of sales opportunities seen in Fig. 1(b) being very speci c and not well matched to di erentiating often-similar sales roles. More so, public social tags give a di erent indication of a person's activities and skills than what is required for predicting job roles.
The best performance is achieved by using the HR in-formation and the bag-of-words features of the job title, both individually and in combination. Adding the poor-performing social tags and sales opportunity features only introduces noise and degrades accuracy. Thus we go forward with the combination of HR and job title features for the de-ployment. Since both logistic regressions are essentially the same and the  X  2 -norm is easier to optimize, we choose the  X  -regularized logistic regression model. The 0.8016 accu-racy is quite good for this challenging eleven-class problem. The logistic regression also provides posterior probabilities or con dence scores for each of the eleven classes for each sample.

We show the confusion matrix of the cross-validation test set in Table 2. We note that most mistakes are within two clusters of very similar job roles: technical sellers f CTA, CTM, CTS g , and brand solution reps f BCR, SR, SRB, SSM g , which is to be expected due to their similarities. The classi ers evaluated here all deal with employees as statisti-cally independent samples; subject matter expertise suggests a possible way to improve accuracy based on relationships among employees, which we explore next.
IBM, like most large corporations, is a tree-structured or-ganization with a management chain representing the path from an employee to the Chief Executive Ocer. For ease of management, employees tend to be grouped by job function within the tree. We put forth a few methods to postpro-cess the predicted class probabilities output by the logistic regression and examine their e ects on test accuracy.
We rst construct groups of employees by taking sub-trees of the organizational structure at each level except for the highest three levels because they encompass the entire sales-force. Then, in the rst postprocessing method, we consider all groups having all training set employees with the same class label and change the predicted class label of all test set employees to that common class label (if they are not al-ready). This improves the accuracy from 0.8016 to 0.8022. As a further heuristic, if we only change those predicted test set class labels with con dence score less than 0.9, then the accuracy improves to 0.8039.

Another postprocessing method is provenance-assisted clas-si cation [26]. From the same sub-tree groupings, we con-struct a bipartite graph with one set of nodes being the groups and the other set of nodes being the employees. Then through an iterative expectation{maximization procedure similar to that found in error-correcting codes [15], we nd a maximum likelihood estimate of the class probabilities un-der the enforcement of consistency in groupings based on the bipartite relationships. However, such an approach with all grouping nodes decreases the accuracy signi cantly to 0.5982. Only including grouping nodes that have all train-ing set samples the same, as in the previous heuristic, also decreases the accuracy to 0.7999.

Very limited improvement or even a worsening of per-formance occurs primarily because the HR information al-Fi gure 2: Fivefold cross-validation accuracy as a function of number of predictions per employee. ready includes categorical attributes indicating three levels of membership in the organizational structure and because while the grouping of employees in the tree is generally true, there are many exceptions which are identi ed correctly by the classi er but then smoothed out by the postprocessing.
As discussed earlier, one use case of the classi er outputs is showing more than one predicted job role for an employee to a system user and allowing the user to choose the cor-rect one. In this case, we can also measure the accuracy of whether the true class label appears in the k class labels with the highest con dence scores. This accuracy value is plotted in Fig. 2, showing that with two or three predictions per em-ployee, we can achieve very good performance: 0.9138 and 0.9553 respectively. Most of the confusion is among similar jo b roles, which can be alleviated by giving more than one prediction per person.

As also discussed earlier, even the labels that we use for training and cross-validation have some level of noise. We can get a rough indication of the level of noise by compar-ing the job role and the job role specialty values among the 36,709 salespeople in our population: if the job role spe-cialty does not fall under the job role in the taxonomy, this mismatch indicates a possible error in the job role label. (Such a mismatch is only one possible manifestation of la-bel noise; the job role label could be incorrect for a host of other reasons as well.) The employees with such a mismatch constitute 6.6% of the population. Among the mismatched population, the cross-validation test accuracy is 0.7207 com-pared to 0.8073 among the sellers with job role and job role specialty values that are in concordance. Thus in comparing 0.8073 to 0.8016, we see that label noise is not very signi -cant, at least as manifested via job role and job role specialty discord.

Through the experimental results with di erent feature sets, classi ers, and predicted class probability postprocess-ing methods, we have seen that we can achieve approxi-mately 80% accuracy using HR information and job title with the  X  2 -regularized logistic regression without any post-processing. These are the choices we go forward with in the deployment.
In this section we describe the third stage of the ma-chine learning research program: the deployment of the data mining system we have developed within the business pro-cesses of IBM. The section begins with the initial deploy-ment among the population of all salespeople worldwide, and then discusses the deployment across the entire corporation that is currently in progress. Both of these parts discuss the business impact of the deployment. The section n-ishes with a discussion of lessons learned, from both the HR practioner's perspective and the data mining practitioner's perspective.
We rst deployed job role and speciality prediction to solve an issue with missing and incorrect job role informa-tion among IBM salespeople worldwide in the rst part of 2014. The salesforce is a key segment of the IBM workforce because these employees garner the revenue for the company. Job role information is used in myriad salesforce planning and strategy functions [1].

In 2014, a new situation was encountered that required the primary job roles to be accurate and within a certain num-ber of permitted values for 100% of the sellers. Even though sellers are asked to update job role information annually, approximately 4,000 of them fail to follow the directions or fail to provide the update. To get the employees to update this data eld would have taken approximately 30 minutes per employee or manager, including contacting them, guid-ing them through the process, and then having them submit the update. Summed over the 4,000 employees, this is an ef-fort of approximately 2,000 person-hours. Additional e ort from corporate headquarters to create the instructions, de-ploy the communication, and assist with the roll out would have incurred approximately 500 person-hours.

Instead we used the result of the predictive analytics to recommend a primary job role and put that value into the primary job role eld in the data. We then asked the man-agers to check the recommended job role and make any nec-essary changes. Since the predictions were accurate approx-imately 80% of the time, only a small number of managers had to physically make a change. Conservatively speak-ing, using predictive analytics saved 80% of the estimated 2,000 person-hours by employees and managers and most of the 500 person-hours by headquarters for setup and deploy-ment, resulting in huge savings totaling approximately 2,100 person-hours, which is the equivalent of one person-year. A typical year of e ort by an IBM salesperson results in rev-enue achievement in the range of $1 million; thus the time savings provided by the job role prediction can yield that much additional revenue for the company.

The salesforce is less than 10% of the total IBM work-force and is a population that is more compliant than many other LOBs. The less compliant an LOB is, the more time and e ort savings the analytics provide. Therefore, deploy-ment to the entire IBM workforce is expected to save more than 20 person-years of e ort if used on an annual basis. However, the even greater impact is a fundamental trans-formation in the way the company operates. Through the analytics, job role data can be refreshed at a much higher frequency than annually to support many di erent existing business processes and enabling new business practices with their own monetary and e ort savings or revenue achieve-ment improvements. We next discuss the deployment to the entire company that is currently in progress.
We see many other opportunities to use the job role pre-diction for populations besides salespeople with similar cir-cumstances. For example, IBM has some very large popu-lations of employees in which the primary job role eld is invalid almost all of the time unlike for sellers where it is valid most of the time. For these larger employee popula-tions with very sparse data for primary job role, the savings will be even more signi cant. Going forward, we are enthu-siastic about the ability to predict expertise from employees' digital breadcrumbs instead of constantly asking managers or employees to ll in the data. Invariably, there are com-pliance challenges with an annual update; keeping job roles and specialties accurate as people transfer, change organi-zations, or move to new jobs is almost impossible. As dis-cussed above, the ability to predict the primary job role and specialty and keep each continuously updated will not only save countless person-hours but will yield more up-to-date and accurate information from which to make manpower planning decisions.

The deployment to the worldwide sales organization was performed in a one-time manner without any speci c thought or development given to user interface and user experience design, or to system architecture. In preparing the deploy-ment to the entire company, we are taking a design thinking approach [3]. This process has centered around constructing user stories for the job role and specialty prediction tasks. The initial outcome has been the identi cation of managers and other administrators as the primary system users rather than individual employees. Also, the form of the user ex-perience has been set forth through an expertise inventory dashboard. Two initial wireframes of the user interface are shown in Fig. 3 and Fig. 4. The remaining work is in -nalizing the user experience design and then developing the system architecture, which involves collecting and merging data from several siloed data warehouses, as well as putting together a ow of text analytics and supervised learning (through the Liblinear implementation of logistic regression) for cross-validation, training and testing. Finally, rolling out the system will require some level of education and evange-lization within various business units throughout IBM.
In this section, we present lessons learned throughout the process of developing and deploying the predictive analytics from two perspectives. First, we give comments received from an HR practitioner involved in the project:
This process also involved quite a bit of learning for the machine learning practitioners as well. One of them reports: cation.
The talent and human capital of IBM is its most valuable resource that must be harnessed properly using trusted ex-pertise information. In this work, we developed a classi ca-tion methodology to predict the expertise of employees based on features derived from the digital footprints of employees with the label set coming from IBM's expertise taxonomy. We deployed this system initially to ll in missing and in-valid job role records and to correct erroneous records in the worldwide population of 40,000 IBM salespeople. The reduction in manual e ort obtained through using predic-tive analytics is estimated to be one entire person-year. We are now in the process of deploying the system for use by the entire corporation, which should result in approximately twenty person-years of savings in annual updates of job roles and specialties. The impact is even greater than the savings in manual e ort, because all business processes that depend on complete, accurate, and updated expertise data bene t from the predictions. Additionally, because of the steep re-duction in e ort, it will now be possible to update expertise assessments much more frequently than once a year, which is a transformation required to compete in today's dynamic business environment.

In developing the approach, we evaluated features from four di erent data sources: job title, HR information, social tags, and work products; several classi cation algorithms; and a few organizational chart-assisted postprocessing meth-ods. The nal choice of Liblinear  X  2 -regularized logistic re-gression with bag-of-words features derived from the job title and 24 HR features yields cross-validation accuracy of 80% for a single prediction per employee and 96% accuracy if we allow three predictions per employee, which is more than enough for the application of interest. This classi er choice also allows us to present con dence values associated with predictions to the system user, which has emerged as an im-portant feature from the user stories developed as part of the design thinking approach.

One immediate piece of future work is continued deploy-ment and evangelization throughout the corporation. Other future work we have identi ed includes evaluation of ad-ditional work product data sources for di erent employee populations and expanding the response variable beyond job roles and job role specialties to industry specialization. Also, the simple tokenization and frequency-based word selection can be improved through advanced text analytics.
The authors thank all of the members of the IBM Exper-tise team, including Karen Doherty and Anne Cunningham for support, and Derek Smith, Ed McFadden and Alison Eckholm for providing the design wireframes. [1] M. Baier, J. E. Carballo, A. J. Chang, Y. Lu, [2] J. Bersin, K. O'Leonard, and W. Wang-Audia.
 [3] T. Brown. Design thinking. Harvard Bus. Rev. , [4] C. Chelmis, V. Sorathia, and V. K. Prasanna.
 [5] V. Chenthamarakshan, K. Dey, J. Hu, A. Mojsilovic, [6] V. Chenthamarakshan, K. Dixit, M. Gattani, [7] K. Ehrlich, C.-Y. Lin, and V. Griths-Fisher.
 [8] K. Ehrlich and N. S. Shami. Searching for expertise. [9] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, [10] D. Fang, K. R. Varshney, J. Wang, K. N.
 [11] I. Guy, U. Avraham, D. Carmel, S. Ur, M. Jacovi, and [12] J. Hu, B. K. Ray, and M. Singh. Statistical methods [13] A. John and D. Seligmann. Collaborative tagging and [14] C.-Y. Lin, L. Wu, Z. Wen, H. Tong, [15] D. J. C. MacKay. Good error-correcting codes based [16] S. Mehta, R. Pimplikar, A. Singh, L. R. Varshney, and [17] N. Natarajan, I. S. Dhillon, P. Ravikumar, and [18] Y. Naveh, Y. Richter, Y. Altshuler, D. L. Gresh, and [19] A. Perer, I. Guy, E. Uziel, I. Ronen, and M. Jacovi. [20] N. S. Shami, K. Ehrlich, G. Gay, and J. T. Hancock. [21] A. Singh, R. Catherine, K. Visweswariah, [22] M. Singh, K. R. Varshney, J. Wang, A. Mojsilovic, [23] L. Terveen and D. W. McDonald. Social matching: A [24] K. R. Varshney, J. Wang, A. Mojsilovic, D. Fang, and [25] K. L. Wagsta . Machine learning that matters. In [26] D. Wang, M. T. Al Amin, T. Abdelzaher, D. Roth, [27] J. Wang, K. R. Varshney, A. Mojsilovic, D. Fang, and
