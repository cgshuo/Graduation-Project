 Our collaborative partitioning model posits a bicriteria ob-jective in which we seek the best item clustering that satisfies the most users at the highest level of satisfaction. We con-sider two basic methods for determining user satisfaction. The first method is based on how well each user X  X  preferences match a given partition, and the second method is based on average correlation scores taken over sufficiently large sub-populations of users. We show these problems are NP-Hard and develop a set of heuristic approaches for solving them. We provide lower bounds on the satisfaction level on ran-dom data, and error bounds in the planted partition model, which provide confidence levels for our heuristic methods. Finally, we present experiments on several real examples that demonstrate the effectiveness of our framework. Categories and Subject Descriptors: I.5.3, G.2.2 General Terms: Algorithms, Theory, Experimentation Keywords: Collaborative filtering
This paper considers the problem of partitioning item sets in the context of collaborative filtering preference data. Such partitions are useful, for example, in the construction of large web-scale directories to aid in the navigation of web-services and information retrieval, and in recommendation systems. We present a new framework called collaborative partitioning (CP) that focuses on the problem of identify-ing item partitions that optimize the fraction of users that will be satisfied with a given item partitioning. One motiva-tion for studying the CP problem comes from website and movie recommendation applications such as StumbleUpon [7] and Netflix [6]. In such systems users typically select topics or genres of interest, and preference data is recorded via toolbar. The question of how the topic or genre direc-tories are created and managed is an important issue, both for navigational purposes and for determining attributes for recommendation engines. Our paper addresses the problem of partitioning websites, movies or other itemsets automat-ically from user preference data to match user preferences.
CP is an example of a graph clustering method, compara-ble to correlation clustering introduced in [2], which consid-ers a graph with edges labeled from set { + ,  X  X  , and clusters nodes to maximize agreements with edge labels. Several re-cent papers (e.g., [5]) have given improved constant-factor approximation algorithms for maximizing agreements.

Our model of preference data consists of a matrix M = [ a ij ], where a i,j  X  X  X  1 , 0 , 1 } , and rows are indexed by n users U and columns are indexed by m items I . Here a ij = +1 indicates a positive opinion by user i on item j , a ij =  X  1 indicates negative opinion, and a ij = 0 indicates no opin-ion. Our goal is to partition the itemset I into k &gt; 1 (non-overlapping) segments P ( I ) = { I 1 ,I 2 ,...,I k } , such that a large fraction of users are highly satisfied with a filter of one or more of the subsets I i . In typical applications, users could select the segment(s) of the partition that best meet their needs, or the segment(s) of the partition could be de-termined automatically. The overall goal of the partition would be to improve system performance to maximize user satisfaction. We consider two models for quantifying the overall satisfaction-quality of partitions.

The A-model for CP measures the quality of partitions based on the number of threshold-satisfied users. To wit, we let each user X  X  preference data (stored as a row in matrix M ) be represented by a vector  X  u of length m . For a given parti-tion P ( I ) = { I 1 ,I 2 ,...,I k } , let  X  I j be the vector of length m over  X  1 representing the segment I j , i.e.,  X  I j ( i ) = 1 if i  X  I and  X  1 otherwise. We see that the dot product  X  u  X   X  I a count of the number of positive u -preferences minus the number of negative u -preferences in I j plus the number of negative u -preferences minus the positive u -preferences in complement I c j = I  X  I j . We say a partition P ( I ) of the itemset  X  -satisfies u if this dot product  X  u  X   X  I j  X   X  ||  X  u || , for some 1  X  j  X  k .
 Definition. An itemset partition P ( I ) = { I 1 ,I 2 ,...,I induces (  X , X  )-satisfaction in the A-model (for some 0 &lt;  X , X   X  1) if P ( I )  X  -satisfies at least  X  | U | users.
The B-model for CP measures the quality of partitions based on correlation clusterings of items. Consider the fam-ily of weighted graphs G = { G U 0 } on the same set nodes rep-resenting the itemset I ; and for each subset of users U 0 there is a graph G U 0 in the family where weights on the edges are given by correlation values between items, where the correlations are calculated by restricting to U 0 data. In general, for the B-model, it is reasonable to choose any vec-tor similarity measure, but we focus on cosine similarity for sake of concreteness. Given two column vectors c i ,c j of M , and a subset U 0 , we let sim U 0 ( i,j ) be the cosine similarity measure of the two column vectors restricted to the rows of U 0 . Hence, for the graph G U 0 the edge ( i,j ) has weight sim U 0 ( i,j ).
We use a natural cost model for the partitioning prob-lem on each G U 0 , where there is a positive benefit equal to the weight of a positive edge if it lies within a cluster, and induces a negative benefit otherwise, and vice versa for neg-atively weighted edges. The objective here is to find a subset U 0 of sufficiently large size, such that the graph G U 0 can be partitioned with maximum benefit -maximizing the posi-tive correlation among items within clusters and negative correlation among items between clusters, and minimizing the reverse.
 Definition. An itemset partition P ( I ) = { I 1 ,I 2 ,...,I duces (  X , X  )-satisfaction in the B-model (for some 0 &lt;  X , X   X  1) if there exist a set U 0  X  U of rows where | U 0 | X   X  | U | such that the weighted graph G U 0 when partitioned according to per edge is at least  X  .

For sufficiently large values of  X , X  , a partition P that induces (  X , X  )-satisfation in the A-or B-models indicates the existence of a large subpopulation of users for which the clustering P is largely consistent with the associated preference data. In both the A-model and B-model of CP the number of segment/clusters k is an not an important consideration, and will be chosen automatically.

Theorem 1. (Proof Omitted.) The two CP problems of optimizing (  X , X  ) -satisfaction in the A-model and B-model are both NP-Hard. The problems remain so for the restricted case where  X  = 1 in the A-model, and for the restricted case where  X  = 1 in the B-model.
 Significance Testing in CP. In the full version of the paper [1] we consider several data models and examine their impact in our model, including random data and planted partition [3] data models, and prove results that indicate the statistical significance of partitions that optimize (  X , X  )-satisfaction. Space limitations prevent discussion of these results here.
Our basic algorithmic framework is a shotgun approach in which we start with a polynomial size family P of par-titions. For our experiments we used a family of partitions given by six standard hierarchical agglomerative clustering (HAC) methods. For an instance of the A-model CP prob-lem, for each feasible partition and each input  X  value, we simply count the number of rows that are  X  -satisfied, and we output the partition(s) that yields the best result. For an instance of the B-model, for each feasible partition and input  X  value, we determine set of rows to use in calculating the satisfaction. Here we take a greedy approach; to wit, we begin with all rows and then remove the row that best improves the overall cost benefit. We iteratively repeat this greedy process until no such row can be found, or stop if the  X  threshold has been reached.

The running time for the A-model algorithm is bounded by the time it takes to generate the family of partitions P plus the time it takes to process each of the partitions. To determine if a row is  X  -satisfied takes time O ( m ). Hence, the total time complexity is O ( m 2 log m + nm 2 ), assuming that HAC generates O ( m ) partitions in time O ( m 2 log m ). To process each partition in the algorithm for the B-model takes time O ( nm 2 ), since in each iteration of the greedy operation we must consider each row and compute the cost benefit induced by the removal of the row. Hence, the total time complexity of the B-model algorithm is O ( m 2 log m + nm Figure 1: (  X , X  ) -sat results for A-and B-model algo-Figure 2: Error bound results for A and B-model algo-
We have run a set of experiments on preference data show-ing some typical tradeoffs found with  X  and  X  -values in each model. For the reported experiment, we chose a subset of Netflix prize [6] movie reviews containing ratings for 23 sam-ple movies that belong to three different genres  X  James Bond movies, Woody Allen movies, and black and white movies. The chosen subset contains ratings from 1429 users, who each rated at least 15 out of 23 movies. We ran the al-gorithms described above using six different HAC methods. We also ran the algorithms on random data as a test of sig-nifiance. As we can see from Figure 1, the Single Link and Centroid methods performed the best, and returned results significantly different from random data. In the second set of experiments (see Figure 2) we measured tradeoffs between the level of satisfaction  X  and the Jaccard error distance be-tween the returned partitions and the stated  X  X enre-based X  partition. From Figure 2 we see the minimal error distance from the genre partition was obtained in the A-model by Weighted Average Link, and for the B-model the Complete Link method performed best. In both sets the best method returned partitions statistically distinct from methods on random data.
