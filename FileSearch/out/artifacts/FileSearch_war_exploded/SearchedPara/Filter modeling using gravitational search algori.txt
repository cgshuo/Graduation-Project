 1. Introduction
The word  X  X  X ilter X  X  is derived from electrical engineering, where filters are used to transform electrical signals from one form to another, especially to eliminate various frequencies in a signal.
This means that the main role of the filter is to keep frequency contents in the desired band and to eliminate other parts when the external input signal passes the filter.

There are two main kinds of filter: analog and digital. An analog filter employs analog electronic circuits made up of components to produce the desired filtering effect. Such filter circuits are widely used in applications such as noise reduction, perform numerical calculations on sampled values of the signal.
Presently, due to the increase in speed and flexibility of digital systems, most signal processing tasks are being performed in the discrete time domain.

Digital filters are broadly classified into two main categories: linear and nonlinear filters. Two important types of linear filters are finite impulse response (FIR) filters and infinite impulse response (IIR) filters ( Oppenheim et al., 1999; Mitra and Kaiser, current and previous input values. This means that a FIR filter has a finite impulse response. However, the present output of an IIR filter is dominated not only by present and past inputs but also by past outputs. Current output of an IIR filter depends on previous output values. This means that an IIR filter has an infinite impulse filter is simply a linear difference equation with constant coefficients and nothing more. Nonlinear filters are another type of digital filters used in systems with nonlinear behaviour.
Nowadays, adaptive digital filters are applied in a wide range of areas such as signal processing, control, communication systems, image processing, system identification and modeling, and noise cancellation ( Su and Cai, 2009; Saha and Roy, 2009; Farouk and Smith, 2000 ). The objective of the adaptation is to alter filter coefficients of a digital filter to estimate actual parameters of an unknown system from its inputs and outputs. In this case, minimization of an objective function (typically the mean square error between desired response and estimated filter output) is often followed by gradient based iterative search algorithms.

However, when the error surface (objective function) is multimodal and/or non-smooth, gradient-based methods often cannot succeed in converging to the global minimum. In this condition, heuristic optimization methods that require no gradient and can achieve a global optimal solution offer considerable advantages in solving these difficult optimization problems. Genetic algorithm (GA; Goldberg, 1989 ), simulated annealing (SA; Kirkpatrick et al., 1983 ), ant colony optimization (ACO; Dorigo et al., 1996 ), and particle swarm optimization (PSO; Kennedy and Eberhart, 1995 ) are four well-known classes of such global optimization methods. The heuristic algorithms are widely used in solving system identification and filter modeling problems ( Valarmathi et al., 2009; Chang, 2007; Eftekhari and Katebi, 2008; Chen and Luk, 1999; Howell and Gordon, 2001; Karaboga et al., 2004; Kalinli and Karaboga, 2005; Das and Konar, 2007; Lin et al., 2008 ).

Filter modeling using these heuristic algorithms like GA, ACO, and PSO are reported in some researches ( Chen and Luk, 1999; Howell and Gordon, 2001; Karaboga et al., 2004; Kalinli and
Karaboga, 2005; Das and Konar, 2007; Lin et al., 2008 ). In Chen and Luk (1999 ), adaptive simulated annealing has been used in signal processing applications, including maximum likelihood (ML) joint channel data estimation and IIR filter design. In Howell and Gordon (2001 ), continuous action reinforcement learning has been applied in digital IIR filter design. Ant colony optimization has been used for IIR filter design in Karaboga et al. (2004 ). In
Kalinli and Karaboga (2005 ), immune algorithm (IA) has been proposed for designing IIR filters. In Karaboga et al. (2004 ) and
Kalinli and Karaboga (2005 ), estimations of a second-order filter with a first-order model and a second-order filter with a second-order model have been reported. Designing a 2-D filter with PSO has been reported for image denoising in Das and Konar (2007 ).
Nonlinear rational filter estimation using PSO and GA has been introduced in Lin et al. (2008 ).

Recently, a novel heuristic search algorithm, called gravita-tional search algorithm (GSA), has been proposed motivated by is characterized as a simple concept that is both easy to implement and computationally efficient. GSA has a flexible and well-balanced mechanism to enhance exploration and exploita-tion abilities. In the present work, GSA is proposed to model IIR the proposed GSA based filter modeling, different sets of initial population with the presence of different measurable noises are given and tested in simulations. GA and PSO are also used to model the same examples and some simulation results are compared.
 The rest of the paper is organized as follows. A brief review of GSA is given in the next section to provide a proper background.
This section is followed by problem definition and explanation in Section 3 and experimental results and comparison with other methods in Section 4. Finally, the paper is concluded in
Section 5. 2. Gravitational search algorithm
In physics, gravitation is the tendency of objects with mass to accelerate towards each other. In the Newton gravitational law, each particle attracts every other particle with a force, which is newest heuristic algorithms that has been inspired by the Newtonian laws of gravity and motion ( Rashedi et al., 2009 ). In
GSA a set of agents called masses are introduced to find the optimum solution by simulation of Newtonian laws of gravity and motion ( Rashedi et al., 2009 ).

To describe the GSA consider a system with s masses in which position of the i th mass is defined as follows:
X  X  X  x 1 i , ... , x d i , ... , x n i  X  , i  X  1 , 2 , ... , s  X  1  X  dimension of the search space. Based on Rashedi et al. (2009 ), mass of each agent is calculated after computing current population X  X  fitness as follows: q  X  t  X  X 
M  X  t  X  X  as follows (for a minimization problem): best  X  t  X  X  min worst  X  t  X  X  max
To compute acceleration of an agent, total forces from a set of heavier masses that apply on it should be considered based on the law of gravity (Eq. (6)), which is followed by calculation of agent acceleration using the law of motion (Eq. (7)). Afterwards, next velocity of an agent is calculated as a fraction of its current can be calculated using Eq. (9):
F  X  t  X  X  a  X  t  X  X  v  X  t  X  1  X  X  rand i v d i  X  t  X  X  a d i  X  t  X  X  8  X  x  X  t  X  1  X  X  x d i  X  t  X  X  v d i  X  t  X  1  X  X  9  X  where rand i and rand j are two uniformly distributed random Euclidean distance between two agents i and j , defined as
R best fitness value and biggest mass, which is a function of time, initialized to K 0 at the beginning and decreasing with time. Here
K is set to s (total number of agents) and is decreased linearly to 1. and it will be reduced with time: G  X  t  X  X  G  X  G 0 , t  X  X  10  X 
The GSA algorithm is different from other swarm based heuristic algorithm like PSO. In both GSA and PSO the optimiza-tion is obtained by agents X  movement in the search space; however the movement strategies are different. Some important differences are as follows ( Rashedi et al., 2009 ):
In PSO the direction of an agent is calculated using only two best positions, Pbest i and gbest (Eq. (23)), but in GSA, the agent direction is calculated based on the overall force obtained by all other agents.

In PSO, updating is performed without considering quality of the solutions, and fitness values are not important in the updating procedure while in GSA the force is proportional to fitness value and so agents see the search space around themselves in the influence of force.
 PSO uses a kind of memory for updating the velocity (due to
Pbest i and gbest ). However, GSA is memory-less and only current position of the agents plays a role in the updating procedure.
In PSO, updating is performed without considering the distance between solutions while in GSA the force is inversely proportional to the distance between solutions.
 Finally, note that search ideas of these algorithms are different.
PSO simulates social behaviour of birds and GSA is inspired by a physical phenomenon. 3. Filter modeling
The goal of filter modeling is to alter filter coefficients of a digital filter to match an unknown system transfer function. A schematic of filter modeling problem using the heuristic search algorithms is shown in Fig. 1 . As this figure shows, the heuristic search algorithm tunes parameters of the estimated filter such that the best estimation of actual system parameters can be obtained. In other words, the minimization of a performance function, typically the mean squared error between filter output and desired response, is attempted using a heuristic search algorithm.

The objective function in filter modeling problems is expressed as follows: J  X  1 L output of the estimated filter, and L the length of the input sequence. In some cases, we receive noise free y ( k ). This means ^ y  X  k  X  is the estimation of desired output or semi-desired output. In are tested based on GSA as the heuristic search algorithm. Each of them is briefly described below. 3.1. IIR filter modeling
Linear digital filters can be classified into two groups based on their structures: infinite impulse response (IIR) and finite impulse response (FIR; Oppenheim et al., 1999; Mitra and Kaiser, 1993;
Antoniou, 1993 ). The purpose of the filtering operation is to transform input signal or image in such a way as to enhance or suppress certain features. The present output of a FIR filter is influenced only by the present and past inputs. However, the present output of an IIR filter is dominated not only by present and past inputs, but also by past outputs. IIR digital filters compute their outputs recursively and have feedback.

Compared with FIR filters, IIR filters can obtain a comparable frequency response with lower filter order. On the other hand, IIR digital filters have the advantages of high selectivity and require fewer coefficients than FIR digital filters with similar perfor-mance. Consequently, producing IIR digital filters with good performance became a challenging aspect to many researches.
The general expression of IIR filters is y  X  k  X  X  at time k , N and M are numerator and denominator orders, respectively, a i and b i are real filter coefficients, and b difference equation leads to a H af ( z ) as follows: H af  X  z  X  X  An estimated filter model to approximate the actual filter is constructed as follows: H  X  z  X  X  where H ef ( z ) is the transform function of estimated filter and ^ a and ^ b i are real filter coefficients to be found by the heuristic search algorithm. Order of the estimated filter may be equal to or lower than that of the actual filter. 3.2. Nonlinear rational filter modeling
Although linear filters have achieved much success in many applications, for some cases where nonlinear behaviour arises, very effective to deal with signals containing features with different localizations in both time and frequency ( Lin et al., 2008 ). The poor representation of underlying localized features by linear filtering may be overcome by the nonlinear filtering method ( Lin et al., 2008 ).

The nonlinear rational filter model is defined by the ratio of two polynomial filter expressions. The general difference equation of the dynamic nonlinear rational filter is given as follows ( Lin et al., 2008 ): y  X  k  X  X  a  X  k  X  b  X  k  X   X  n  X  k  X  X  a  X  x  X  k 1  X  , ... , x  X  k N rational nonlinear filter, Z denotes a uniformly random noise, N and N y are the numbers of past inputs and past outputs required in the numerator polynomial, respectively, and M x and M y numbers of past inputs and past outputs required in the denominator, respectively. Usually, the numerator a ( k ) and denominator b ( k ) are functions of past inputs and past outputs. They can be expressed in terms of polynomials as follows ( Lin et al., 2008 ): a  X  k  X  X  b  X  k  X  X  where num and den represent the numbers of regression terms in the numerator and denominator, respectively, p ni ( k ) and p the products of past inputs and past outputs, and y ni and y the corresponding filter parameters. An estimated nonlinear rational model to approximate the actual filter is constructed as follows ( Lin et al., 2008 ): ^ y  X  k  X  X  ^ a  X  k  X  X  ^ b  X  k  X  X  ^ b  X  k  X  are the numerator and denominator polynomials, respec-estimated parameters of the nonlinear rational model found by the heuristic search algorithm. 4. Simulation results
In this section, some benchmark problems are selected to compare the performance of GA, PSO, and GSA algorithms. In all cases, the number of agents, s , is set to 50, and the initial population is selected randomly. The number of iterations is considered to be 1000 and input x ( k ) is considered as a white noise sequence of data samples length L  X  200.

In GSA, we used Eq. (21) for the gravitational constant, in which G 0 and a are set to 100 and 10, respectively. Also, K set to s (total number of agents) and is decreased linearly to 1 with time: G  X  t  X  X  G 0 e a  X  t = T  X   X  21  X  and Eberhart, 1995 ): x  X  t  X  1  X  X  x d i  X  t  X  X  v d i  X  t  X  1  X  X  22  X  v  X  t  X  1  X  X  w  X  t  X  v d i  X  t  X  X  c 1 r 1 i  X  pbest d i x d where r 1 i and r 2 i are two uniform random variables in the range
Also, X i  X  X  x 1 i , x 2 i , ... , x n i  X  and V i  X  X  v 1 velocity of the i th particle, respectively, pbest i  X  X  pbest i , ... , pbest n i  X  and gbest  X  ( gbest position among all particles in the population, respectively. In from 0.9 to 0.2.

In GA ( Goldberg, 1989 ), one-point crossover, uniform muta-tion, and roulette wheel selection are used. The crossover probability and mutation probability have been set to 0.9 and 0.005, respectively. 4.1. Modeling of a second order IIR filter by a second order filter
In the first example, a second order IIR filter is estimated by a noise ( Z ( k )) is absent. The system functions of actual and estimated filters are given in Eqs. (24) and (25), respectively, where [ b 1 , b 2 ] are the parameters to be found and their optimum values are [1.2, 0.6].

For maintaining stability, the search space is limited between 2 and 2. Table 1 shows simulation results for 5 independent runs. The mean square error of estimated filter according to
Eq. (11) is given too. As these results suggest PSO and GSA provide similar results and superior to those of GA.

H z 1  X  1 1 1 : 2 z 1  X  0 : 6 z 2  X  24  X 
H z 1  X  1 1 b 4.2. Modeling of a second order IIR filter by a first order one
In the second example, a second order IIR filter is estimated by noise ( Z ( k )) is absent. The system functions of actual and estimated filters are given in Eqs. (26) and (27), respectively, where [ a 0 , b 1 ]are the parameters to be found and their optimum values are [ 0.311, 0.906], ( Chen and Luk, 1999; Howell and Gordon, 2001; Karaboga et al., 2004; Kalinli and Karaboga, 2005 ).
For maintaining stability, the search space is limited between 1 and 1. Table 2 shows simulation results for 5 independent runs. The mean square error of the estimated filter according to
Eq.(11) is given too. As results suggest the three algorithms provide similar performances.

H z 1  X  0 : 05 0 : 4 z 1 1 1 : 13 z 1  X  0 : 25 z 2  X  26  X 
H z 1  X  a 0 1 b 4.3. Rational filter modeling
In the third example, parameters of the actual nonlinear rational filter (Eq. (28); Lin et al., 2008 ) are estimated based on
Eq. (29). In this example, the search parameters are [ y n 1 y , y d 2 ] with the optimum values [0.3, 0.8, 0.6, 1, 1]. y  X  k  X  X  0 : 3 y 2  X  k 1  X  X  0 : 8 x  X  k 1  X  X  0 : 6 y  X  k 2  X  y  X  k  X  X  y n 1 y 2  X  k 1  X  X  y n 2 x  X  k 1  X  X  y n 3 y  X  k 2  X 
In this section, three simulations with different types of noise sidered. For maintaining stability, the search space is limited between 0 and 5. In each situation, five optimization runs with different random sets of initial population for modeling the nonlinear rational filter are done and the results are presented in
Tables 3 X 5 . As these results show in low-noise or noise-free situations, PSO and GSA have similar performance, while in the high noise case, GSA provides the best estimation.
 4.4. Result analysis and discussion
In the previous sub-sections, we compared performance of the proposed algorithm with those of PSO and GA in three different cases. In the first case, a unimodal function with a simple error surface was considered. In this case, both PSO and GSA achieved similar results, superior to those of GA. Our second experiment is to apply the three algorithms to find estimated values of a multimodal function with two local and one global minima. GA,
PSO, and GSA can find the global optimum without getting trapped in the local minimum. In the third case, we increased complexity of the problem by introducing an added noise. In this case, GSA achieved better solutions than both PSO and GA.
Overall, considering the above results, one can conclude that GSA provides a suitable tool in filter modeling. 5. Conclusion
In this paper, gravitational search algorithm, GSA, has been used to solve the parameter estimation problem for IIR and nonlinear rational filters. By a comparative study, it is shown that the proposed method is well suited to solve complex problems. Based on this study, GSA provides a comparable performance to those of two well-known heuristic algorithms GA and PSO. References
