 For recommender systems, time is often an important source of in-formation but it is also a complex dimension to apprehend. We propose here to learn item and user representations such that any timely ordered sequence of items selected by a user will be repre-sented as a trajectory of the user in a representation space. This allows us to rank new items for this user. We then enrich the item and user representations in order to perform rating prediction using a classical matrix factorization scheme. We demonstrate the inter-est of our approach regarding both item ranking and rating predic-tion on a series of classical benchmarks.
During the last decade, the emergence of collaborative filtering has demonstrated the interest of exploiting past ratings to estab-lish relevant profiles for both users and items in various application fields [17, 10]. Recent works has focused on profile enrichment: the better we understand users X  tastes, the more accurate our sug-gestions will be. Several directions have been investigated for this: global ratings of reviews have been manually split into different aspects [7], then [11] has proposed to automate this process by learning a common latent space to represent the items, the users and the reviews they wrote. Yet another approach directly exploits tokens extracted from those reviews in order to improve user char-acterization [15]. Time is another important dimension since the perception of a user may change with time or be time dependent. There are different ways to handle time, for example one can con-sider the temporal evolution of items perception [9] or model the evolution of the user X  X  way of thinking [12]. Considering the time dimension usually considerably increases the complexity of recom-mendation models. Instead of time, we propose to consider the or-dering of user actions and to embed this information into the users and the items representations for recommendation tasks. Ordered sequences convey less information than full time sequences of user actions, but allow for a compromise between the information pro-vided to the system and the system complexity needed to handle this information. More precisely, we consider ordered sequences of items corresponding to sequences of user actions. We learn a representation -a vector in a multidimensional euclidean space-of individual items in the context of the sequences where they appear. Each item will then have a unique vector representation in a vector space. A user representation will be a function operating on this item representation space that allows to move from one item to the next one, or said otherwise to infer the next item from the current one. In this paper, we consider a simple vectorial operator corre-sponding to a translation. Given a sequence of items, this allows us to infer the future sequence and then to recommend at each step an ordered list of items to a user. We then enrich this representation by additional dimensions and use a classical matrix factorization scheme in order to learn this new representation for learning to pre-dict item ratings like in classical collaborative filtering.
This approach offers two advantages: it models the dynamical aspects of the user profile while keeping the number of parameters low. We demonstrate the effectiveness of our approach on classical review datasets through two evaluation schemes: item ranking and rating prediction.
 The paper is structured as follows: related work is reviewed in Section 2, then we describe the model and the training algorithm in Section 3. In Section 4, we describe the datasets and our results.
Recommender systems can be evaluated in two different setups, one consists in recommending a set of items (ranking) [3, 13] while the other aims at estimating how a user would rate a given item (rating prediction) [17, 2, 8].

In the recommendation literature, time is often considered as a relevant contextual information as it facilitates detecting the changes in users preferences [18]. A better understanding of these changes allow the recommender systems to capture periodicity in users in-terests [5] or simply to improve its performance [9].

However, capturing temporal dynamics in a recommender en-gine is not straightforward. For example using an exponential de-cay to downweight older reviews either improve [6] or degrade [9] the system performance. As another example, while in [1], the au-thors used a time-dependent data partition to learn context-aware user profiles, they found best results for a random split. [4] surveys different ways to handle time inthe recommender literature like us-ing temporal drift, heuristics or splits. Two recent interesting con-tributions for introducing time in recommender systems are [19] who uses Kalman filters to represent a transition between the latent representations of the users over time and [12] who represents this evolution as user experience gained over time.

We will use the following notations: Items (resp. users) are in-dexed using i (resp. u ) and gathered in a set: I = { i k U = { u k } k = 1 ,..., M ). To each user corresponds a trace ordered sequence of items he rated:  X  u = { ( i , r ) | i  X  I } where r is the rating ; those traces are gathered in a set  X  = {  X  u Figure 1: The Mikolov et al. [14] architecture predicts the cur-rent item based on the context Mikolov et al. Word2Vec model [14], as illustrated in Fig.1, uses a neural network to build a latent representation of words depend-ing on the surrounding words in a sentence, by optimizing a word prediction criterion. In this paper we used the same neural net ar-chitecture for learning from item sequences corresponding to user traces {  X  u , u  X  U } , a contextualized item representations. For every item i , we build a representation  X  i (in blue in Fig.2) that considers the items order in all the sequences corresponding to user traces. Figure 2: Representation for d=2 of an extract of a user trace (numbered items in blue) and the user representation as a vec-tor (in green) for the RateBeer dataset.
 For every user u , we learned a representation  X  u ( u in Fig. 2) mod-eling the way u moves from an item to the next one in the sequence representation in the latent space, by performing a gradient descent on the following ranking loss: In equation 1, the + sign indicates that we used a hinge loss func-tion. This means that during the learning phase, we only updated the parameter values when L ranking ( u , i , e ) &gt; 0.  X  u is a vector which represents the mean of the translations needed to move from one item in the representation space to the next one in a sequence corresponding to a user trace. From these repre-sentation, we can -by applying the  X  u translation from an item representation-compute the nearest neighbors of the resulting point and thus produce ordered list of items to recommend. Given a user u and i the most recent item he reviewed, the item recommendation is given by: In a second step, we construct new representations enriching  X  u and  X  i , in order for our model to tackle the rating task. by performing a gradient descent for optimizing the following mean square rating loss:
We added the regularization term  X  X  (  X   X  u ,  X   X  i overfitting [16].

Given a user u and an item i , the rating score is computed using the classical matrix factorization formula proposed in [8]. Let  X  ,  X  and  X  i denote respectively the overall bias, the user bias and the item bias:
In this section, we evaluate our model performance regarding two different tasks, item ranking and rating prediction. In order to evaluate our rating prediction, we implemented a matrix factorization (MF) as presented in [10] and the model presented by McAuley et al. (EXP) in [12] as baselines. To evaluate our model in an item ranking paradigm we used the popularity function that always return the most popular result (POP) as a prediction. In order to perform our experiments, we used five time-labeled datasets: BeerAdvocate and RateBeer datasets from [12] contain reviews on beers, MovieLens10m and Flixster datasets contain re-views on movies and FineFoods from [12] contains reviews from the fine foods category from Amazon. The characteristics of each dataset can be found in Table 1.

As the ratings were on different scales, we normalized them all to be on the scale [ 0 , 5 ] . Then, we used the settings presented in [19]: only the users with more than 20 reviews were kept, and every dataset has been divided in time windows, each representing a year period (except for the Flixster dataset which is divided bimonthly regarding its smaller timespan).

In order to perform the evaluation, the last three time windows were selected as test U and for each U , we used all the previous windows for training T . We ran each experiment 5 times on each window and report the average results for reliability. in recall.
 We evaluated our model by computing the Recall@K measure for K=300 and compared them to the baselines. The results are pre-sented in Table 2. A plot of the evolution of recall@K for K vary-ing between 50 and 500 on the BeerAdvocate and Flixster datasets is also available in Fig.3.
 T able 2: Ranking Results averaged over all three time windows, given in Recall@300 for the matrix factorization (MF), the ex-perience based model (EXP), the popularity model (POP) and the directional vector based model (DIR)
Our model (DIR) clearly outperforms all other models. This cor-roborates the relevance of taking into account the sequential struc-ture of the user-item interaction as a core feature. Furthermore, the MF and EXP baselines show that the rating prediction is not a good indicator for item prediction ; this validates the idea that using the same representations to compute both rating and ranking values re-quires some sort of tradeoff. The DIR model uses two different yet intertwined representations, freeing it from the aforementioned tradeoff constraint.
 The results of our experiments expressed in MSE can be found in Table 3. We compared our items to a classic Matrix factorization as described in [10] and to the EXP model.
 T able 3: Rating Results averaged over all three time windows, given in MSE for the matrix factorization (MF), the experi-ence based model (EXP) and the directional vector based model (DIR)
Here also, the proposed model significantly outperforms both models, showing that incorporating the order information allows learning better user and item representations.
In this paper, we have proposed a light and scalable latent method for recommendation using item sequence information which has been shown to be also efficient as we performed evaluations re-garding two different tasks: rating prediction and item ranking.
Regarding future work, there are many paths to explore. First, we would like to find better ways to model the user representation e.g. using a more sophisticated prediction functions. We would also like to add an expertise notion in order to model more precisely the temporal dimension. Last, we think that touristic data follow the same kind of temporal evolution as web data and we plan to adapt this method to visit recommendation. The authors would like to thank the AMMICO project (F1302017 Q -FUI AAP 13) for funding our research. [1] L. Baltrunas and X. Amatriain. Towards time-dependant [2] J. Bennett and S. Lanning. The netflix prize. In KDD Cup [3] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [4] P. Campos, F. D  X   X ez, and I. Cantador. Time-aware [5] P. G. Campos, F. Diez, and A. Bellogin. Temporal rating [6] Y. Ding and X. Li. Time weight collaborative filtering. In [7] G. Ganu, N. Elhadad, and A. Marian. Beyond the stars: [8] Y. Koren. Factorization meets the neighborhood: A [9] Y. Koren. Collaborative filtering with temporal dynamics. In [10] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization [11] J. McAuley and J. Leskovec. Hidden factors and hidden [12] J. J. McAuley and J. Leskovec. From amateurs to [13] M. R. McLaughlin and J. L. Herlocker. A collaborative [14] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient [15] M. Poussevin, V. Guigue, and P. Gallinari. Extended [16] S. Rendle and L. Schmidt-Thieme. Online-updating [17] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [18] L. Xiang, Q. Yuan, S. Zhao, L. Chen, X. Zhang, Q. Yang, [19] C. Zhang, K. Wang, H. Yu, J. Sun, and E. Lim. Latent factor
