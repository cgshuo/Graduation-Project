 Flash memory is a new kind of data storage media. Different from Hard Drive Disk (HDD), it has a lot of attractive char acteristics such as fast access speed, shock resistance, low power consumptio n, smaller size, lighter weight and less noise. Flash memory is widely used in a la rge number of electronic devices. The latest mobile phones, digital cameras, DV recorders, MP4 players, and other electronic handheld devices use flash memory as the main data storage devices. During the past years, the capacity of flash memory doubles every year, which is faster than Moore X  X  law, and flash chip of 1TB has been reported available in market [1]. As the capacity increases and price drops dramatically during the past years, flash memory (instead of magnetic disk) has been considered as the main storage media in the next generation of storage devices.

In database systems, transaction pro cessing like instantaneous queries and updates incurs frequent random IO. Additionally, in data warehousing, multiple streams of queries, insertions and deletions, also need large number of random IO operations. While, in current disk based database (or warehousing) systems, the major bottleneck is the IO disk performance. As we know, random IO is the drawback of hard disks. It is because that with the mechanical moving arms, a hard disk can only produce very limited number of IO operations per second. To overcome the shortcomi ng, flash memory would be the perfect alternative to traditional magnetic disks.

The access characteristics of flash memo ry are different from those of magnetic disks. Since traditional databases were designed to utilize disk features, thus we can X  X  take full advantage of high I/O performance of flash memory if we transfer traditional database system onto flash memory without any modification. The rationale is the write granularity and erase-before-rewrite limit of NAND flash memory. Particularly, in NAND flash memory the write granularity is a page. And we cannot overwrite the same address unless we erase the whole block containing that page.

Logging is an important component of DBMS [2, 3]. It aims at maintaining the ACID property of transactions. However, erase-before-rewrite and page write characteristics lead to lower performance for transaction processing when the underlying hardware changes from traditional magnetic disks to flash memory. As for logging and recovery, the situation becomes more serious because of the out-of-place update model which leads to high cost with large quantity of minor random writes during the course of recovery. Therefore, it is necessary to design a new logging technique for flash-based DBMS [4, 5, 6].

In this paper we analyze the logging design problems in flash memory based databases and propose a new solution called LB-Logging. It makes use of the history versions of data which is naturally disposed in flash memory due to out-of-place updates. Furthermore, LB-Logging uses list structures instead of sequential structures in the traditional databases to store log records. We sum-marize our contributions as follows.  X  A novel logging method called LB-Logging is proposed for the first time to  X  By making use of list structures instead of sequential structures to store log  X  Additionally, to effectively reduce the log redundancy and improve the space  X  Results of empirical studies with implementations on a real database system The rest of this paper is organized as follows: In Section 2, we give the related work and compare our approach with them. Section 3 discusses the character-istics of flash memory and their impact on traditional disk-based databases. Section 4 and section 5 introduces the b asic concepts and the design of the LB-Logging schema. Experimental results are given in Section 6 and we conclude in Section 7.
 It X  X  not been long since flash memory began to be used as data storage media for computers. There is not much work to solve the problem of logging in flash-based DBMS [7-10].

Some researchers tried to change the storage of data files and use logs to record the updates instead of in-place-updates. IPL [11] is an influential work among them. In IPL design principles, each block,the erase unit on flash memory, is divided into two segments, data pages and log region [12, 13]. All the update operations are transformed into logs in main memory buffer firstly. Later the logs are flushed out to log sectors of the erase unit allocated for the corresponding data pages. If data pages fetched from the same erase unit get updated often, the erase unit may run out of free log sectors. It is when merging data pages and their log sectors is triggered by the IPL storage manager. This storage model could provide indirect recovery through the logs stored in database. But it requires a lot of modifications of traditional DBMS, so it can not be easily added to an existing DBMS.

FlashLogging [14] is trying to exploit multiple flash drives for synchronous logging. As USB flash drive is a good match for the task of synchronous log-ging because of its unique characteristi cs compared to other types of flash de-vices. FlashLogging designed an unconventional array organization to effectively manage these dispersed synchronous logging stored in different USB devices. Similarly, Lee also tried to combine USB flash drives and magnetic disks as a heterogeneous storage for better performance. However, as the price of SSD con-tinues to decline, the advantage of USB dev ice X  X  price is gradually disappearing. FlashLogging is not a convenient model to build. In this section, we will present the problems caused in logging and recovery when transferring traditional databases to flash memory without any modifica-tion. And first we will describe the characteristics of flash memory to help us understand the problems. 3.1 Flash Memory The characteristics of flash memory are quite different from those of magnetic hard disks. In flash memory, data is stored in an array of flash blocks. Each block spans 32-64 pages, where a page is the smallest unit of read and write operations. The read operations of flash memory are very fast compared to that of magnetic disk drive. Moreover, unlike disks, random read operations are as fast as sequential read operations as there is no mechanical head movement. The major drawback of the flash memory is that it does not allow in-place updates. Page write operations in a fla sh memory must be preceded by an erase operation and within a block, pages need be to written sequentially. The typical access latencies for read, write, and era se operations are 25 microseconds, 200 microseconds, and 1500 microseconds, respectively. 3.2 Problem Definition Log-based recovery techniques are widely used in traditional databases. Differ-ent protocols determine different desig ns of log storage format, buffer manage-ment, checkpoint and recovery mechanisms. Take undo logs as an example. When transaction T updates element X whose original value is v, undo log will gener-ate a log record like T,X,v in the DRAM. And finally the log will be flushed into disk.When transaction T rolls back, we have to re-write X to its original value v.

Here, we replay this process on flash memory. The original table is as shown in Tab. 1(a). When a transaction updates A from v1 to v2, it is necessary to insert a new record of A, as shown in Tab. 1(b) in the last line. And if T has to roll back sometimes later, we must re-write A X  X  original value v1 again because of out-place update, as shown in Tab. 1(c). We can see that the last record is the same as the first record. In other words, the last one is actually redundant in this situation. We can infer that there may be large amounts of data X  X  history versions. In fact, the recovery process doesn X  X  have to write the data which has already existed. It is not only a waste of space, but also a waste of time.
As we discussed earlier, every write operation occupies at least one page (typ-ically 2KB) regardless of the size of the data. But generally speaking, the size of the rolled back element may be less than 2KB. It brings extra space wasted. Apart from that, the additional writes may bring some unnecessary erase opera-tions with time cost even greater. Therefore, to avoid rewrite operations, a new design of logging and recovery method is needed for flash-based DBMS. In this section, we present the basic concepts of LB-Logging approach for flash-based databases that we propose to address the problems of the conventional logging designs for disk-based databases. We will introduce LB-Logging X  X  log structures, recovery process and check-po int strategy to give a detailed explain-ing of its principles and advantages.
 4.1 Logging Algorithm From the previous analysis, it can be found that in flash memory, there is no need to use explicit rollback operation to re-write the original data elements in recovery as is done in disk-based databases. Taking into account that the history versions of data exist, we can make full use of it for rollback and recovery. It would speed up the process without executing write operations which are more expensive. LB-Logging uses list structures to store log records. In this sense, LB-logging is a redo logging. It maintains a chain across different log records for the sequence of data operations logged in each transaction and a list of different versions of each data element in one log r ecord. So during the recovery process, we can search all the log records of every operation in each transaction.
Information stored in each log record includes transaction ID ( T Id ), mod-ified data item name ( Element ), former element updated by this transaction ( Pre Element ), and the list of all versions of current data item ( Address List ). The list is arranged by the order of operation time. The log file structure is shown in Table 3.

When a transaction starts, LB-Logging creates a log record, but wait until the first database changed by the transaction, it will insert a log record for the first updated element with Pre Element Field marked with Begin .Asthe transaction updates the data subseque ntly, we insert new log records and the list of addresses of data elements needed to be maintained. For insert and delete operations, several identifiers are used to distinguish them in Address List .For example, if an element X  X  history list ends with a NULL address, that means this element is deleted fr om the database. Similarly, if the first address of an element X  X  history version is NULL , that means this element is inserted by this transaction. If the transaction is committed or rolled back, we will insert a log record for commit or rollback operation. The Pre Element field stores the former updated item and the Address List field is set to empty. Thus, using this structure of log records, all the operations to the database can be recorded completely.
We follow WAL rule to decide when to flush log records, which means as long as the local database is modified, there must be associated log records. But the opposite is not true. In other words, there may be cases that when system crashes, changes are only logged in stable storage, but these changes may not be propagated to the database. When we need to execute a recovery operation, according to the database redo log files, the above mechanisms can ensure the consistency and integrity of the database.
 4.2 Recovery Process In LB-Logging, what we mainly do in recovery is redo the database operations in committed transactions according to the redo log files. Recovery manager finds all the committed transaction log records from the list structure of log files, and redo them one by one.

When a transaction which has not been submitted is rolled back, we just need to delete the log records simply. Because the corresponding logs are still in memory, and the data is not flushed out to the external storage media. However, if the application has a lot of long transactions, there may be some log records which haven X  X  been committed. These log records may take up a large proportion of the memory space. Part of the logs may be forced to flush out of the memory. This is acceptable. Because we can dete rmine that the tran saction X  X  changes do not reach the flash memory database since the transaction has not been committed. So we just need to insert a roll back log to ensure that the operations has no effect on the database.

If the system crashes, it needs to recover immediately. We have to read the log file from secondary storage media to m emory. Typically, if a system crashes when writing logs. There are usually some uncommitted log records at the end of the log file. We do not do anything about these operations. Since LB-logging ensures that as long as there is no commit log records, the changes have not been flushed to the database yet. For the transactions that have been submitted, we need to read the log records and redo them one by one. The detailed procedure is shown in Algorithm 1. In this section, we present some improvement of LB-Logging approach that we propose to overcome the problems of basic LB-Logging approach to provide an much better performance. 5.1 Checkpoint Policy We can notice that log file is frequently updated. With the updated data being propagated to storage, a large number of log records becomes useless. Under normal cases, transaction rollback rate is usually not too high. Therefore, if there are a large number of useless log records, the length of log file will be unnecessarily increased, thus taking too much flash storage space. Aside from that, we need to read logs during recovery, the long log file will harm the efficiency of recovery. This inspires us to establish check points to avoid an overly long log file that would affect the overall performance of the system.

We take a simple checkpoint policy for flash-based DBMS. We only transfer the log records that are still valid. In oth er words, when set up one check point, we will do as follows. Firstly, find a clean block. Then, check the validity of each log record one by one. Finally, select the records which are still valid and write them to the new free block. After all the log records of the old log block are scanned, the original records on the log block are no longer useful to us. Therefore, we can erase the old block. The actual amount of log records that need to be transferred is quite small. So the transfer cost is acceptable. The specific steps of this transfer operation are shown in Algorithm 2.
The value of checkpoint interval requires to be examined. Long interval will bring to large log file. And short checkpoint interval may shorten the lifetime of flash memory and affect overall performance. So the checkpoint interval can be variably set according to applications X  characteristics. Here we assume that features of the application is very clear. And database administrator can choose to do checkpoints off line or in non-peak time to minimize impact on the perfor-mance of the database application. 5.2 Heterogeneous Storage The main operations of log files include logging, recycling the invalid log records and reading log records to recover the sy stem. So the most frequent operations for log files are small random write and erase operations. As we introduced before, small sized write operations are the biggest limitation of flash memory whose performance may be worse than those of magnetic disks. The other critical technical constraints of flash memory is limited erase cycles. Thus too many unnecessary erase operations will greatly s horten the service life of flash memory. Therefore, log file is not suitable for flash memory.

Current databases generally support log files and data files to be stored sep-arately. Here we use hybrid storage systems to store different types of database objects. As shown in Fig. 1, data records are stored in flash disks, while log records are stored in magn etic disk. In this design, we can restore the system without increasing the complexity of the algorithm and save the space of flash memory occupied by log records. Thus it improves the flash space utilization, reduces the cost to build the database system, and enhances the overall perfor-mance of database system. In this section, we present real system experimental evaluations of LB-Logging. We first describe the experimental setup in section 6.1. Then we present experi-mental results with different update transaction size and different update times for each data in section 6.2 an d section6.3, respectively. 6.1 Experimental Setup We examine the performance of LB-logging compared with ARIES and HV-Logging[15]. The latter one only makes use of the history versions of data with-out linked structures. We implement both our approaches and the comparable methods in a real database called Oracl e Berkeley DB[16]. And our experiments run on two platforms which are exactly identical except that one is equipped with an HDD and the other with an SSD. We used two HP Compaq 6000 Pro MT PC. Each machine is equipped with an Intel(R) Core(TM) 2 Quad Q8400 @ 2.66GHz 2.67GHz CPU, 4GB DRAM, running Windows 7 Professional. The SSD we use is Intel SSDSA2MH080G1GC 80G, and the HDD we use is 250G 7200rpm ST3250310AS with 8MB cache.

Our experimental process is as follows . A transaction starts doing all the required updates. Before the transaction X  X  commission, we roll back the transac-tion. The performance is measured by reco very time which we carefully records. However, when we try to record the elaps ed time of recovery process, there are some little differences between multiple runs for one workload. Here we use the average value. Through the description of our algorithm above, we can find that two key factors are important to the system. They are update transaction size and average update times for each data. So we varied the two critical parameters in our experiments to see how the performance changes. 6.2 Varying Update Transaction Size In recovery process, the number of rolled back log records directly influences the recovery time. Here, the number of updates of a single transaction is an important parameter. In this section, we guarantee that all data individually have 2 times update in average.

Fig. 2 and Fig. 3 show our experimental results. Fig. 2 describes the result when the update transaction size is small. Fig. 3 shows the result when increasing update transactions X  size. From the experimental result, we can find that the advantage of SSD over HDD is obvious. Whether it is the traditional logging method, or the improved logging method for flash memory, the recovery time on SSD is much less than that on disk. We also observe that whether on SSD or HDD, the recovery efficiency is much higher for LB-Logging. Compared with HV-Logging, LB-Logging costs only 70% recovery time. With the increasing amount of data, the advantage of LB-Logging is even more obvious. This could fully reflect the superiority of our algorithm. 6.3 Varying Update Times for Each Data In this section, we discuss how the variation of update times for each data reflects the recovery performance. As previously described, in order to employ flash memory X  X  high-speed random read advantage, LB-Logging uses a kind of linked structure for log records. In the linked structure, the list length is a key factor. In our design, the length of the list depends on how often each data gets updated.
Fig. 4 shows the experimental results. When the updates are less frequent, it is difficult to reflect the superiority of ou r design. With the increasing times of updates per data, LB-Logging X  X  advantage is highlighted increasingly. We find that when the update frequency is incr eased to 8 times, disk-based recovery time is about 15 times longer than that of LB-Logging. These results sufficiently justify the LB-Logging X  X  superiority over other logging schemes.
 LB-Logging makes use of the data X  X  history versions which naturally exists in flash-based database for logging and exploits a kind of list structure as the replace of sequential structure to store l og records to provide efficient recovery. Through periodic checkpoints mechanism, LB-Logging reduces the length of the log file by removing invalid log records and saves the space for flash memory. Using hybrid storage system, LB-Logging stores the log records in both SSD and HDD separately to improve the recovery performance on flash-based database. So the proposed algorithm LB-Logging provides stronger reliability, faster recovery, smaller space consumption for log files.

The results show that the recovery time of traditional logging algorithm is 15 times longer than LB-Logging in the best conditions. And the recovery time of traditional logging algorithm on SSD is 7 times longer than LB-Logging. The recovery time of optimized algorithm for flash memory is 5 times longer than LB-Logging. This fully demonstrates the superiority of LB-Logging.
 Acknowledgements. This research was partially supported by the grants from the Natural Science Founda tion of China (No, 60833005, 91024032, 91124001, 61070055,); the Research Funds of Renmin University of China (No: 11XNL010, 10XNI018); National Science and Technology Major Project (No: 2010ZX01042-002-003).

