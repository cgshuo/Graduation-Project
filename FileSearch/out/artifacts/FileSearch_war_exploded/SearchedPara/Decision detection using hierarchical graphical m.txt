 In work environments, people share information and make decisions in multi-party conversations known as meetings. The demand for systems that can automatically process information contained in audio and video recordings of meetings is grow-ing rapidly. Our own research, and that of other contemporary projects (Janin et al., 2004) aim at meeting this demand.

We are currently investigating the automatic de-tection of decision discussions. Our approach in-volves distinguishing between different dialogue act (DA) types based on their role in the decision-making process. These DA types are called De-cision Dialogue Acts (DDAs). Groups of DDAs combine to form a decision region.
 Recent work (Bui et al., 2009) showed that Directed Graphical Models (DGMs) outperform other machine learning techniques such as Sup-port Vector Machines (SVMs) for detecting in-dividual DDAs. However, the proposed mod-els, which were non-hierarchical, did not signifi-cantly improve identification of decision regions. This paper tests whether giving DGMs hierarchi-cal structure (making them HGMs) can improve their performance at this task compared with non-hierarchical DGMs.

We proceed as follows. Section 2 discusses re-lated work, and section 3 our data set and anno-tation scheme for decision discussions. Section 4 summarizes previous decision detection exper-iments using DGMs. Section 5 presents the HGM approach, and section 6 describes our HGM exper-iments. Finally, section 7 draws conclusions and presents ideas for future work. User studies (Banerjee et al., 2005) have con-firmed that meeting participants consider deci-sions to be one of the most important meeting outputs, and Whittaker et al. (2006) found that the development of an automatic decision de-tection component is critical for re-using meet-ing archives. With the new availability of sub-stantial meeting corpora such as the AMI cor-pus (McCowan et al., 2005), recent years have seen an increasing amount of research on decision-making dialogue. This research has tackled is-sues such as the automatic detection of agreement and disagreement (Galley et al., 2004), and of the level of involvement of conversational partic-ipants (Gatica-Perez et al., 2005). Recent work on automatic detection of decisions has been con-ducted by Hsueh and Moore (2007), Fern  X  andez et al. (2008), and Bui et al. (2009).

Fern  X  andez et al. (2008) proposed an approach to modeling the structure of decision-making di-alogue. These authors designed an annotation scheme that takes account of the different roles that utterances can play in the decision-making process X  X or example it distinguishes between DDAs that initiate a decision discussion by rais-ing an issue, those that propose a resolution of the issue, and those that express agreement to a pro-posed resolution. The authors annotated a por-tion of the AMI corpus, and then applied what they refer to as  X  X ierarchical classification. X  Here, one sub-classifier per DDA class hypothesizes oc-currences of that type of DDA and then, based on these hypotheses, a super-classifier determines which regions of dialogue are decision discus-sions. All of the classifiers, (sub and super), were linear kernel binary SVMs. Results were bet-ter than those obtained with (Hsueh and Moore, 2007) X  X  approach X  X he F1-score for detecting de-cision discussions in manual transcripts was 0.58 vs. 0.50. Purver et al. (2007) had earlier detected action items with the approach Fern  X  andez et al. (2008) extended to decisions.

Bui et al. (2009) built on the promising results of (Fern  X  andez et al., 2008), by employing DGMs in place of SVMs. DGMs are attractive because they provide a natural framework for modeling se-quence and dependencies between variables, in-cluding the DDAs. Bui et al. (2009) were espe-cially interested in whether DGMs better exploit non-lexical features. Fern  X  andez et al. (2008) ob-tained much more value from lexical than non-lexical features (and indeed no value at all from prosodic features), but lexical features have limi-tations. In particular, they can be domain specific, increase the size of the feature space dramatically, and deteriorate more in quality than other features when automatic speech recognition (ASR) is poor. More detail about decision detection using DGMs will be presented in section 4.

Beyond decision detection, DGMs are used for labeling and segmenting sequences of observa-tions in many different fields X  X ncluding bioin-formatics, ASR, Natural Language Processing (NLP), and information extraction. In particular, Dynamic Bayesian Networks (DBNs) are a pop-ular model for probabilistic sequence modeling because they exploit structure in the problem to compactly represent distributions over multi-state and observation variables. Hidden Markov Mod-els (HMMs), a special case of DBNs, are a classi-cal method for important NLP applications such as unsupervised part-of-speech tagging (Gael et al., 2009) and grammar induction (Johnson et al., 2007) as well as for ASR. More complex DBNs have been used for applications such as DA recog-nition (Crook et al., 2009) and activity recogni-tion (Bui et al., 2002).

Undirected graphical models (UGMs) are also valuable for building probabilistic models for seg-menting and labeling sequence data. Conditional Random Fields (CRFs), a simple UGM case, can avoid the label bias problem (Lafferty et al., 2001) and outperform maximum entropy Markov mod-els and HMMs.

However, the graphical models used in these applications are mainly non-hierarchical, includ-ing those in Bui et al. (2009). Only Sutton et al. (2007) proposed a three-level HGM (in the form of a dynamic CRF) for the joint noun phrase chunk-ing and part of speech labeling problem; they showed that this model performs better than a non-hierarchical counterpart. For the experiments reported in this study, we used 17 meetings from the AMI Meeting Corpus 1 , a freely available corpus of multi-party meetings with both audio and video recordings, and a wide range of annotated information including DAs and topic segmentation. The meetings last around 30 minutes each, and are scenario-driven, wherein four participants play different roles in a com-pany X  X  design team: project manager , marketing expert , interface designer and industrial designer . We use the same annotation scheme as Fern  X  andez et al. (2008) to model decision-making dialogue. As stated in section 2, this scheme dis-tinguishes between a small number of DA types based on the role which they perform in the for-mulation of a decision. Besides improving the de-tection of decision discussions (Fern  X  andez et al., 2008), such a scheme also aids in summarization of them, because it indicates which utterances pro-vide particular types of information.

The annotation scheme is based on the observa-tion that a decision discussion typically contains the following main structural components: (a) A topic or issue requiring resolution is raised; (b) One or more possible resolutions are considered; (c) A particular resolution is agreed upon, and so adopted as the decision. Hence the scheme dis-tinguishes between three main DDA classes: issue ( I ), resolution ( R ), and agreement ( A ). Class R is further subdivided into resolution proposal ( RP ) and resolution restatement ( RR ). I utterances in-troduce the topic of the decision discussion, ex-amples being  X  X re we going to have a backup? X  and  X  X ut would a backup really be necessary? X  in Table 1. In comparison, R utterances specify the resolution which is ultimately adopted as the deci-(1) A: Are we going to have a backup? Or we do Table 1: An excerpt from the AMI dialogue ES2015c. It has been modified slightly for pre-sentation purposes. sion. RP utterances propose this resolution (e.g.  X  X  think maybe we could just go for the kinetic energy .. .  X  ), while RR utterances close the discussion by confirming/summarizing the decision (e.g.  X  X kay, fully kinetic energy X  ). Finally, A utterances agree with the proposed resolution, signaling that it is adopted as the decision, (e.g.  X  X eah X  ,  X  X ood X  and  X  X kay X  ). Unsurprisingly, an utterance may be as-signed to more than one DDA class; and within a decision discussion, more than one utterance can be assigned to the same DDA class.

We use manual transcripts in the experiments described here. Inter-annotator agreement was sat-isfactory, with kappa values ranging from .63 to .73 for the four DDA classes. The manual tran-scripts contain a total of 15,680 utterances, and on average 40 DDAs per meeting. DDAs are sparse in the transcripts: for all DDAs, 6.7% of the total-ity of utterances; for I ,1.6%; for RP , 2%; for RR , 0.5%; and for A , 2.6%. In all, 3753 utterances (i.e., 23.9%) are tagged as decision-related utterances, and on average there are 221 decision-related ut-terances per meeting. To detect each individual DDA class, Bui et al. (2009) examined the four simple DGMs shown in Fig. 1. The DDA node is binary valued, with value 1 indicating the presence of a DDA and 0 its absence. The evidence node (E) is a multi-dimensional vector of observed values of non-lexical features. These include utterance features (UTT) such as length in words 2 , duration in mil-liseconds, position within the meeting (as percent-age of elapsed time), manually annotated dialogue act (DA) features 3 such as inform , assess , suggest , and prosodic features (PROS) such as energy and pitch. These features are the same as the non-lexical features used by Fern  X  andez et al. (2008). The hidden component node (C) in the -mix mod-els represents the distribution of observable evi-dence E as a mixture of Gaussian distributions. The number of Gaussian components was hand-tuned during the training phase.
 Figure 1: Simple DGMs for individual decision dialogue act detection. The clear nodes are hidden, and the shaded nodes are observable.

More complex models were constructed from the four simple models in Fig. 1 to allow for de-pendencies between different DDAs. For exam-ple, the model in Fig. 2 generalizes Fig. 1c with arcs connecting the DDA classes based on analy-sis of the annotated AMI data.
 Figure 2: A DGM that takes the dependencies be-tween decision dialogue acts into account.

Decision discussion regions were identified us-ing the DGM output and the following two simple rules: (1) A decision discussion region begins with an Issue DDA; (2) A decision discussion region contains at least one Issue DDA and one Resolu-tion DDA. The authors conducted experiments using the AMI corpus and found that when using non-lexical features, the DGMs outperform the hierar-chical SVM classification method of (Fern  X  andez et al., 2008). The F1-score for the four DDA classes increased between 0.04 and 0.19 ( p&lt; 0 . 005 ), and for identifying decision discussion regions, by 0.05 ( p&gt; 0 . 05 ). Although the results just discussed showed graph-ical models are better than SVMs for detecting de-cision dialogue acts (Bui et al., 2009), two-level graphical models like those shown in Figs. 1 and 2 cannot exploit dependencies between high-level discourse items such as decision discussions and DDAs; and the  X  X uperclassifier X  rule (Bui et al., 2009) used for detecting decision regions did not significantly improve the F1-score for decisions.
We thus investigate whether HGMs (structured as three or more levels) are superior for discov-ering the structure and learning the parameters of decision recognition. Our approach composes graphical models to increase hierarchy with an ad-ditional level above or below previous ones, or in-serts a new level such as for discourse topics into the interior of a given model.
 Fig. 3 shows a simple structure for three-level HGMs. The top level corresponds to high-level discourse regions such as decision discussions. The segmentation into these regions is represented in terms of a random variable (at each DR node) that takes on discrete values: { positive, negative } (the utterance belongs to a decision region or not) or { begin, middle, end, outside } (indicating the position of the utterance relative to a decision dis-cussion region). The middle level corresponds to mid-level discourse items such as issues, resolu-tion proposals, resolution restatements, and agree-ments. These classes ( C 1 ,C 2 ,...,C n nodes) are represented as a collection of random variables, each corresponding to an individual mid-level ut-terance class. For example, the middle level of the three-level HGM Fig. 3 could be the top-level of the two-level DGM in Fig. 2, each middle level node containing random variables for the DDA classes I, RP, RR, and A. The bottom level cor-responds to vectors of observed features as before, e.g. lexical, utterance, and prosodic features. Figure 3: A simple structure of a three-level HGM: DRs are high-level discourse regions; C 1 ,C 2 ,...,C n are mid-level utterance classes; and Es are vectors of observed features. The HGM classifier in Figure 3 was implemented in Matlab using the BNT software 4 . The classifier hypothesizes that an utterance belongs to a deci-sion region if the marginal probability of the ut-terance X  X  DR node is above a hand-tuned thresh-old. The threshold is selected using the ROC curve analysis 5 to obtain the highest F1-score. To evalu-ate the accuracy of hypothesized decision regions, we divided the dialogue into 30-second windows and evaluated on a per window basis.

The best model structure was selected by com-paring the performance of various handcrafted structures. For example, the model in Fig. 4b out-performs the one in Fig. 4a. Fig. 4b explicitly models the dependency between the decision re-gions and the observed features.
 Figure 4: Three-level HGMs for recognition of de-cisions. This illustrates the choice of the structure for each time slice of the HGM sequence models.
Table 2 shows the results of 17-fold cross-validation for the hierarchical SVM classifica-tion (Fern  X  andez et al., 2008), rule-based classifi-cation with DGM output (Bui et al., 2009), and our HGM classification using the best combina-tion of non-lexical features. All three methods were implemented by us using exactly the same data and 17-fold cross-validation. The features were selected based on the best combination of non-lexical features for each method. The HGM classifier outperforms both its SVM and DGM counterparts ( p&lt; 0 . 0001 ) 6 . In fact, even when the SVM uses lexical as well as non-lexical features, its F1-score is still lower than the HGM classifier. Table 2: Results for detection of decision dis-cussion regions by the SVM super-classifier, rule-based DGM classifier, and HGM clas-sifier, each using its best combination of non-lexical features: SVM (UTT+DA), DGM (UTT+DA+PROS), HGM (UTT+DA).

In contrast with the hierarchical SVM and rule-based DGM methods, the HGM method identifies decision-related utterances by exploiting not just DDAs but also direct dependencies between deci-sion regions and UTT, DA, and PROS features. As mentioned in the second paragraph of this section, explicitly modeling the dependency between deci-sion regions and observable features helps to im-prove detection of decision regions. Furthermore, a three-level HGM can straightforwardly model the composition of each high-level decision region as a sequence of mid-level DDA utterances. While the hierarchical SVM method can also take depen-dency between successive utterances into account, it has no principled way to associate this depen-dency with more extended decision regions. In addition, this dependency is only meaningful for lexical features (Fern  X  andez et al., 2008).
The HGM result presented in Table 2 was computed using the three-level DBN model (see Fig. 4b) using the combination of UTT and DA features. Without DA features, the F1-score de-grades from 0.8 to 0.78. However, this difference is not statistically significant (i.e., p&gt; 0 . 5 ). To detect decision discussions in multi-party dia-logue, we investigated HGMs as an extension of the DGMs studied in (Bui et al., 2009). When using non-lexical features, HGMs outperform the non-hierarchical DGMs of (Bui et al., 2009) and also the hierarchical SVM classification method of Fern  X  andez et al. (2008). The F1-score for identifying decision discussion regions increased to 0.80 from 0.55 and 0.50 respectively ( p&lt; 0 . 0001 ).

In future work, we plan to (a) investigate cas-caded learning methods (Sutton et al., 2007) to improve the detection of DDAs further by using detected decision regions and (b) extend HGMs beyond three levels in order to integrate useful se-mantic information such as topic structure. The research reported in this paper was spon-sored by the Department of the Navy, Office of Naval Research, under grants number N00014-09-1-0106 and N00014-09-1-0122. Any opinions, findings, and conclusions or recommendations ex-pressed in this material are those of the authors and do not necessarily reflect the views of the Office of Naval Research.

