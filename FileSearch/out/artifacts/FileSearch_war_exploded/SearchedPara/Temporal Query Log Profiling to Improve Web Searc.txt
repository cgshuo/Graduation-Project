 Temporal information can be leveraged and incorporated to improve web search ranking. In this work, we propose a method to improve the ranking of search results by iden-tifying the fundamental properties of temporal behavior of low-quality hosts and spam-prone queries in search logs and modeling those properties as quantifiable features. In partic-ular, we introduce the concepts of host churn , a measure of changes in host visibility for user queries, and query volatil-ity , a measure of semantic instability of query results, and propose the methods for construction of temporal profiles from search query logs that can be used for estimation of a set of features based on the introduced concepts. The utility of the proposed concepts has been experimentally demonstrated for two language-independent search tasks: the regression-based ranking of search results and a novel classification problem of detecting spam-prone queries in-troduced in this work.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  search engine spam ; I.7.5 [ Document Capture ]: Document analysis X  document classification,spam filtering Experimentation Search Spam, Search Logs Analysis, Temporal Data Mining  X  Contributed while the author was an intern at Yahoo!
Search engines are widely used tools for effectively explor-ing information on the Web. One of the core components of a search engine is its ranking function: when a search engine receives a user query, this function determines the order of presentation of retrieved results (documents or URLs). The main goal of the ranking process is to promote high-quality and relevant content to the top of the result list, which is an important and challenging problem by itself. In addition to that, since search engines are a highly trafficked and high-revenue generating Web resource, influencing the ranking process by promoting abusive and irrelevant yet monetizable content in search results becomes a highly sought-after ca-pability for spammers and so-called search engine optimizers (SEOs). Consequently, improving the quality of ranking is a multi-faceted problem. While, on one hand, improvements can be achieved by proposing better methods for ranking high-quality content, on the other hand, efficient and ac-curate identification, demotion, and filtering of artificially promoted adversarial content is critically important to the overall quality of search results as well [20]. In this work, we propose a method that addresses these two important as-pects of ranking of search results through temporal analysis of search logs.

In particular, our method focuses on quantifying the tem-poral changes in ranking of search results with respect to the two main concepts that we introduce, each of which is focused on two orthogonal dimensions. The first concept is host churn , which is aimed at quantifying the changes in temporal behavior of hosts in search results for different queries. The second concept is query volatility , which is a measure of semantic stability of search results for a query over time. The introduced concepts have different interpre-tations. When viewed from the perspective of eliminating adversarial content, host churn can be considered as a mea-sure of the likelihood of in-organic host behavior and query volatility as a measure of the likelihood of a query being compromised by search spammers.

Application of temporal profiling to adversarial informa-tion retrieval (AIR) [22, 8, 23] is based on the observation that spammers target specific query verticals (separable sub-sets of all queries), that are both highly monetizable (com-mercial and adult queries) and have a low barrier to entry (e.g. misspellings, tail queries), with the goal of altering the ranking of results returned for those verticals by promoting specific URLs or hosts within a short period of time. The main intuition behind the proposed method is that when a particular query is compromised by spammers, it typically results in two types of unnatural changes that can be cap-tured through temporal analysis of search logs. Firstly, the two sets of search results, returned for a query before and after it was compromised, are likely to be different. Sec-ondly, a successful attack on a vertical typically results in abnormal increases in search results position, query cover-age, click-through rate and number of impressions for spam hosts in search results returned for queries in a compromised vertical. Therefore, by constructing the temporal profiles for hosts and queries from search logs it becomes possible to identify attempts to alter the natural ranking of search results, regardless of the specific method to achieve it. In addition to that, temporal behavior of queries in search logs can be used to characterize the properties of queries, which are often targeted by SEOs and spammers. In particular, it becomes possible to identify spam-prone queries, which is a novel classification problem introduced in this work.
The use of temporal profiling to improve the ranking of search results, however, is not limited by the detection of adversarial content. When viewed from the perspective of improving search results presentation, host churn can be considered an indicator of certain properties of documents, belonging to the host. Significant and frequent temporal changes in impressions of a host in search results of different queries may indicate that its content is either of low quality or highly temporally correlated (e.g. news). Queries with high volatility (i.e. queries, which retrieve semantically dif-ferent sets of results at several distinct time points) should receive special attention, as they may also reveal potential problems with the ranking function.

The proposed concepts of host churn and query volatility are represented as a set of quantifiable features in the classi-fication framework, which are estimated from the statistical temporal profiles constructed for the queries and hosts from the search logs. These features can be effectively used both within the traditional learning-to-rank framework to directly improve the performance of a ranking function or within the classification problem of identifying spam-prone queries.
We enumerate our primary contributions as follows: (i) we investigate the use of fundamental properties of temporal be-havior of queries and hosts to improve the ranking of search results from traditional and adversarial perspectives; (ii) we introduce and formalize the notion of spam-prone queries and the problem of identification of spam-prone queries; (iii) we propose the first method for detection of artificially pro-moted adversarial content that utilizes temporal information from the search logs, and (iv) finally, our method is among the first efforts to approach search spam detection indepen-dent of the specific spamming techniques.

The rest of this paper is organized as follows. In Section 2, we summarize the previous efforts in IR and AIR that are related to present work. Methods for constructing the temporal profiles and computing the associated features for hosts and queries are presented in detail in Sections 3 and 4 respectively. In Section 5, we discuss how temporal profiles can be used for improving the quality of search ranking. In Sections 6 and 7, we present the evaluation results of the proposed method in two different contexts. Finally, Section 8 concludes the paper with a discussion of limitations of the proposed method and future work.
In this section, we provide an overview of the previous ef-forts to improve the ranking of search results by introducing a better ranking function or a method to detect and elimi-nate adversarial content, the two major research directions highly relevant to present work.

In recent years, the ranking problem is frequently formu-lated as a supervised machine learning problem [4, 30, 32, 17]. The learning-to-rank approaches are capable of combin-ing different types of features to train the ranking function. A number of previous works have also focused on exploring the methods to obtain useful information from click-through data to benefit search relevance [27]. This information can be expressed as pair-wise preferences [7, 11], or sequential data [18], or represented as ranking features [1]. Until re-cently, however, only a few attempts have been made to ex-plore the idea of leveraging temporal information to improve web search ranking. Diaz [9] proposed a solution to integrate search results from the news vertical into web search results, where the news intent is detected by either inspecting the query dynamics or using the click feedback. Zhang et al. [31] proposed a ranking score adjustment method on year qualified queries, for which a few simple but effective ad-justment rules are applied to the ranking results based on the time stamps extracted from the documents.

There are several ways to approach the problem of detec-tion of artificially promoted adversarial content. One way is to address each individual technique [19] as it appears by proposing a detection method and a counter-measure. Most of the previous work in AIR has followed this highly reac-tive and ad hoc path, which can be explained by the fact that spamming techniques have a very transient nature and need to be addressed within a short period of time. Since spam filtering is traditionally viewed as as a two-class clas-sification problem, the main line of research efforts in AIR is primarily focused on designing new effective features for classifiers. Typically, most features are simple statistical measures, which, depending on the nature of captured sig-nals, can be grouped into two major categories. The first category is topological features [28, 6], which are designed to detect irregularities in the link structure of Web pages. In particular, [6] used the topology of the Web to identify spam, based on the intuition that spam pages tend to form clusters in the Web graph, primarily due to rank boosting techniques such as link farms [29]. The other category is content-based features [14], designed to identify content ir-regularities, indicative of certain spamming techniques, such as content stuffing [26]. Several other ideas from traditional IR, such as applying methods for deeper analysis of web page content at different granularity levels, using either language modeling [24] or LDA [2] have been applied in the spam do-main as well. In [5] search log data is represented in the form of the click-view and anti-click graphs, which combine both the query and document nodes. Nodes are assigned the distribution of category labels by propagation from a set of manually categorized pages. Within this approach, queries and documents are characterized as either spam or non-spam by the entropy of the distribution of the inferred semantic categories for graph nodes. Our work is conceptu-ally different from the previous work in AIR in that, to the best of our knowledge, there have been no attempts to study the fundamental properties of spam pages and queries, inde-pendent of the particular spamming methods. In this sense, temporal profiling of hosts and queries can be considered as a general pro-active method to indicate abnormal temporal behavior of hosts and queries and improve the quality of Web search ranking by eliminating the artificially promoted adversarial content.

There are several other notable directions beyond feature engineering in the general classification setting of AIR that are related to our work as well. One particularly notable direction is focused on using temporal information to im-prove the quality of retrieval results. Viewing search from the temporal perspective was arguably first proposed in [10]. They identify queries that require temporal tuning by corre-lating them with temporally relevant documents. Temporal analysis of data has also been actively explored in the con-text of social media [16]. The more recent research efforts in AIR [22, 8, 23] also indicate the increasing importance of temporal inferences. In particular, one of the earliest meth-ods that used temporal information in the context of spam detection was proposed in [28]. This method is based on the observation that spam and legitimate pages exhibit different patterns of link evolution.

As follows from the above discussion of the previous ef-forts, our approach unifies and complements the previously proposed approaches along two different research directions. In the next section, we move on to a detailed discussion of the proposed approach.
Our first hypothesis is that, unlike normal hosts, temporal profiles of most low quality hosts exhibit higher host churn. This is tied to the fact that spammers compete among them-selves to increase referrals from the search engines, which is the main incentive behind abusive advertisement. This in-crease in referrals for low quality hosts is abnormal and can be captured by quantifying churn across four key metrics, (a) the number of queries a host appears in (  X  X  X  ), (b) the number of impressions for a host (  X  X  X  ), (c) the number of referrals/clicks from the search engines (  X  X  X  X  X  X  ), and (d) the average position of a host in the queries it appears (  X  X  X  X  ). For each of these metrics normal hosts show an organic and controlled pattern of growth or decay, as opposed to low quality hosts.

Organic and inorganic temporal nature of hosts can be illustrated through an example. Table 1 shows a normal host exhibiting an organic growth. The table depicts the four metrics measured at three different months on a large sub-sample of search logs, as measured across the top ten results. We use the click-through rate  X  X  X  X  X  X / X  X  X  for better clarity. The normal host shows a gradual increase in impres-sions  X  X  X  and query coverage  X  X  X  , while maintaining stable click-through and positional attributes. Table 2 shows inor-ganic changes for a host involved in abusive advertisements. The host in question is a popular social networking site. Il-legitimate profiles were created on this host and promoted through the search engines, which was noticed at the begin-ning of the search log analysis. As can be seen from Table 2, over time there has been a significant drop in query coverage and the number of impressions. This churn could occur due to multiple reasons, either improved abnormal page detec-tion by the search engines or identification and removal of Table 1: Temporal host attributes (query coverage, impressions, click-through rate, average position) of a normal host during three different months. The normal host shows an organic improvement in search visibility with a fairly stable click-through rate and average search result position. Table 2: Temporal host attributes (query coverage, impressions, click-through rate, average position) of a low quality host during three different months. The spam host shows an in-organic change in search visibility, with a sharp drop in visibility once the abnormal page detection problem is resolved. these profiles by the social networking site. Independent of the mechanism of removal, the host subsequently returned to its natural level of search visibility. Therefore, it would be interesting to capture such inorganic host behavior.
Our method proceeds as follows. First, we assume that host profiles  X  = {  X  1 ,  X  2 , . . . ,  X   X  } are available across each of the n contiguous time points. Each  X   X  is a  X   X  4 matrix, with an entry  X   X   X  X  X  representing the value of a host  X  on property  X  at the time point  X  . Overall, for any spe-cific host we compute the following four temporal attributes (  X  X  X ,  X  X  X ,  X  X  X  X  X  X ,  X  X  X   X   X  X  X  X  ). Next, for any host  X  , across a tem-poral attribute  X  , the host churn is computed as a sum of values of the churn metric  X  on  X   X  1 adjacent pairs of time points as follows: The score is a function of the chosen churn metric  X  . We use two candidate metrics to quantify churn, the first of which is a logarithmic ratio across the two time points: Since the above metric does not fully take into account the size of a host, we use a second metric, the log-likelihood (LL) test, which has been successfully used to compare two lan-guage models to quantify surprise and select representative terms in [25]. In contrast to language models, where an n-gram is compared across the two distributions, we compare a temporal property of a host across the two time points. Us-ing this metric, the churn for a host  X  on a temporal attribute  X  across the two time points  X  and  X  can be computed as follows: where the normalizing term  X   X  w.r.t  X   X  , common across Table 3: Host churn profiles extracted from the search logs across four temporal properties. Log-arithmic ratio and the log-likelihood test are used to independently quantify the churn. all hosts, (and similarly  X   X  w.r.t  X   X  ) is defined as: We use the above two metrics of churn when comparing hosts along each of the four dimensions. Clearly, these metrics are not designed to be exclusive for low quality host detection and will surface many upcoming popular hosts as having high churn. However, such upcoming normal hosts do not typically appear in spam-prone verticals and tend to be out-liers in the respective verticals they appear. Within spam-prone verticals, however, most of the hosts show abnormal host churn , which is a key differentiator from the less spam-prone verticals. Depending on the used temporal attribute, we term the derived host churn profiles as Host Query Churn , Host Impression Churn , Host Click Churn , and Host Positional Churn . The eight host churn profiles used in present work are summarized in Table 3.
We next turn our attention to methods for constructing the temporal profiles of queries, based on the results they serve and the user behavior observed on such results.
We assume the availability of search logs in the following format. The input is a temporally ordered collection of  X  document result sets  X   X  = {  X  1 ,  X  2 , . . . ,  X   X  } for a query  X  with query frequencies  X  = {  X  1 ,  X  2 , . . . ,  X   X  } over a set  X  of  X  discrete time points  X  = {  X  1 ,  X  2 , . . . ,  X   X  } . Each result set  X  is an ordered set of  X  URLs  X  = {  X  1 ,  X  2 , . . . ,  X  returned by the search engine in response to a query  X  . At each time slice, we also have available the user feedback information for the query in the form of clicks at position  X  ,  X  X  X  X  = {  X  X  X  X  1 ,  X  X  X  X  2 , . . . ,  X  X  X  X   X  } , and skips at position  X  ,  X  X  X  X  = {  X  X  X  X  1 ,  X  X  X  X  2 , . . . ,  X  X  X  X   X  } , where each skip  X  X  X  X  responds to the number of times all other URLs but  X   X  are clicked. The goal of constructing the temporal query profiles is to surface highly variable queries with low user satisfac-tion. We propose to quantify the query variability along sev-eral major dimensions: query result set, query impressions, clicks on query results and user query session behavior. We begin by characterizing the results shuffling behavior com-mon to many spam-prone verticals.
Queries affected by abusive advertisement show results that are highly volatile. A result at a particular position at one point in time is unlikely to be at the same position in a subsequent time point. Given a collection of result sets  X  for a query  X  , we calculate  X  (  X  ), the result-set volatility function of  X  , based on the distance measure  X  between individual result sets in  X  . The volatility score over  X  time intervals is calculated in general form as:
The chosen distance measure  X  should reflect the differ-ence between individual result sets, with lager values indi-cating higher difference. Therefore, the more dissimilar are the result sets, the greater the value of  X  . There exists a variety of distance measures [12], that can take into account only the elements of the two sets by themselves or other factors, such as position of the elements in an ordered set. Next we describe the distance measures that we use in this work.

Jaccard distance is defined on two sets  X   X  and  X   X  as: Jaccard distance measures dissimilarity between two sets, with larger values corresponding to more dissimilar sets. It does not take into account either the specific positions or the ordering of elements in both sets.

KL-divergence is a measure of distance between two language models. A language model for a result set  X   X  is constructed at each time point by tokenizing the URLs in the result set on all non-alphabetic symbols. Formally, KL-divergence between the language models of the result sets,  X   X  and  X 
We use both Jaccard distance and KL-divergence as dis-tance measures  X  in evaluating the volatility score  X  (  X  ) for a query  X  .

We compute the Jaccard-based measure up to different positions and refer to them as SHUF  X  i.e. SHUF 5 refers to temporal Jaccard-based similarity up to the result number five. The KL-divergence based measure will be referred to as KLTEMPORAL. The most temporally unstable queries are either in the adult domain, highly monetizable or wrongly formulated by the user.
The number of times a query is served can also be a good indicator of whether a query is spam-prone or not. For in-stance, popular queries, like myspace or facebook , for which the normal pages have accumulated a large number of in-links, are more difficult to be compromised and hence are less targeted by abusive advertisers. Furthermore, buzzy queries are also less likely to be spam-prone , since buzz is not a trivial prediction. To capture such classes of queries, we elicit various temporal query properties based on the query frequency across different time points.

Specifically, we compute the mean, standard deviation, kurtosis, and Pearson coefficients. While mean and standard deviation are well-known measures, kurtosis is a measure of buzz, and Pearson coefficient is a measure of the skewness of a distribution. Given the frequency of a query across  X  time points  X  = {  X  1 ,  X  2 , . . . ,  X   X  } with mean  X   X  , kurtosis is Figure 1: Temporal click pattern for an informa-tional, non spam-prone query  X  X vanka trump X . The click pattern for a non spam-prone query appears to be concentrated towards the top few results and is consistent across the time points. defined as: And Pearson coefficient is defined as: We refer to these profiles as IMP MEAN, IMP SD, IMP KURTOSIS, and IMP PEARSON.
Unlike normal queries, spam-prone queries typically ex-hibit higher click volatility as well. Figure 1 shows a tem-poral click profile of an informational query not prone to be abused, while figure 2 shows a similar click profile for a spam-prone query. The x-axis corresponds to the time points and the y-axis corresponds to the position in search results. The intensity signifies click-through, with white shade cor-responding to the click-through of 1 and black shade cor-responding to the click-through of 0. As follows from the click intensity plots in Figures 1 and 2, a click-through ma-trix, corresponding to a spam-prone query, indicates a higher degree of confusion among users. The informational query shows clicks typical to queries providing good user experi-ence with higher click density on the first few results.
To capture click discrepancies, we aggregate these metrics temporally as the mean, standard deviation, Pearson corre-lation and kurtosis coefficients for both the clicks  X  X  X  X   X  skips  X  X  X  X   X  at each position.
We next discuss features based on the aggregate user ses-sion behavior on the search results page. Note that the search results page typically consists of organic search re-Figure 2: Temporal click pattern for a spam-prone query  X  X uy percocet online X . The click-pattern for spam-prone query lacks the uniformity seen on a non spam-prone query. sults, sponsored search results, reformulation suggestions and, sometimes, news results. The primary intuition is that in spam-prone verticals users are seldom satisfied with the presented organic results and, therefore, are less likely to click on any of them. On the other side of the spectrum, high user satisfaction generally maps to a single click on an organic result before the end of a user session. This is gen-erally the case for all navigational queries, i.e. queries where the user X  X  intent is to navigate to another site (e.g. the query  X  X acebook X  leading to  X  X acebook.com X ).

For our purpose, a user session is bounded by 30 minutes of user inactivity. To capture typical and atypical session be-havior, we identify four distinct, but related characteristics, as measured by user clicks on the search results page. (i) ONLYCTR is the ratio of the number of sessions, in which the users click only on a single organic result, to the num-ber of all sessions, in which a query appears (ii) NOCTR is the ratio of the number of sessions, in which the users do not click on any of the presented content (organic and spon-sored) to the number of all sessions, in which a query ap-pears (iii) NOWCTR is the ratio of the number of sessions, in which there are no user clicks on any of the presented organic results, to the number of all sessions, in which a query appears, and, finally, (iv) REFCTR is the ratio of the number of sessions, in which the users click on a query re-formulation, to the number of all sessions, in which a query appears. To capture query session volatility, we compute the mean and standard deviation for the above metrics across all the time points.
Having introduced the concept of temporal profiles that can help identify abnormal behavior of hosts and queries, we can now focus our attention on using such temporal pro-files in two tasks: the classification problem of identifying spam-prone queries and the problem of using regression to rank search results. We approach both tasks by learning a classifier on a catalog of features.

First, for the spam-prone query classification task our method is based on the assumption that one of the dis-tinguishing properties of spam-prone queries is volatility in their result sets, clicks, as well as the underlying churn of the hosts providing such results, taken over a period of time. The query level properties can be directly used as features in the query classification task. However, churn is a prop-erty of a host, not a query. We map individual host churns into queries by applying the aggregate metrics (HQ MEAN, HQLL MEAN, HQ SD, HQLL SD) to the number of im-pressions (HI, HILL), referrals (HC, HCLL), and positional attributes (HP, HPLL) over all the hosts appearing in the results for a specific query. The main intuition is that spam-prone queries show a higher incidence of volatile hosts in-volved in abusive advertisement techniques.

Second, we use the spam-prone query classification results for search results ranking. The spam-prone query score is treated as a new query-level feature to be used by the ranking function. The baseline constitutes all existing fea-tures used by a production-level ranking function of a major search engine. The intuition is that identifying spam-prone queries can support new feature interactions in spam-prone verticals, interactions that are more robust to abusive ad-vertisement techniques.

We use the gradient boosted decision tree (GBDT) [15] as a classifier for both problems. GBDT is an additive regres-sion algorithm consisting of an ensemble of trees, fitted to current residuals, gradients of the loss function, in a forward step-wise manner. It iteratively fits an additive model as such that the loss function  X  (  X   X  ,  X   X  (  X  +  X  )) is minimized, where  X   X  (  X  ;  X   X  ) is a tree at iteration  X  , weighted by param-eter  X   X  , with a finite number of parameters,  X   X  and  X  is the learning rate. At iteration t, tree  X   X  (  X  ;  X  ) is induced to fit the negative gradient by least squares: where  X   X  X  X  is the gradient over current prediction function The optimal weights of trees  X   X  are determined by Each node in the trees represents a split on a feature. The tuneable parameters in this model include the number of leaf nodes in each tree, the relative contribution of score from each tree, called the shrinkage, and the total number of shallow decision trees.

The relative importance of a feature  X   X  in such forests of decision trees is aggregated over all the  X  shallow decision trees [3] as follows: where  X   X  is the feature on which a split occurs,  X   X  and  X  are the mean regression responses from the right and left sub-trees, and  X   X  and  X   X  are the corresponding weights to the means, as measured by the number of training examples traversing the left and right sub-trees. We report on the relative importance of the extracted temporal features in the results section.

In the following sections, we discuss the use of features based on temporal profiles in the classification (Section 6) and regression (Section 7) settings.
In this section, we report the results of an experimental evaluation of using temporal profiling to classify the queries as spam-prone and non spam-prone. A spam-prone query is any query frequently targeted by abusive advertisements. However, since this definition is not quantifiable, we consider a stricter definition. A query is considered to be spam-prone if it is targeted by either (a) multiple abusive advertisers at any given snap-shot of search results, or (b) one or more abu-sive advertisers at two different snapshots of search results, separated by a month. Intuitively, requirement (a) enforces that more than one result in the top ten is spam, and re-quirement (b) enforces that the query is consistently prone to spam. In either case, we are more interested in the class of queries repeatedly targeted by an abusive advertisement, or a group of abusive advertisements. To account for the la-tent causes of search engine result changes, we require that the snapshots be separated by at least one month. Although shorter time intervals could be potentially more interesting, in this work we limit ourselves to monthly intervals.
For all experiments in this work we used the search logs from a major search engine for the year 2008. The logs fea-ture aggregate information for the queries themselves and for the results presented for such queries, including user clicks. We remove results beyond the top ten and divide the data by one month into twelve subsets. We eliminate the queries that were served less than ten times every month and queries that were not served repeatedly across the twelve months, thus eliminating the queries in the long-tail, i.e. rare queries. Many of these queries typically repeat less often, rendering our temporal features less useful. We leave out targeting such queries as future work and focus on identifying spam-prone queries that are in the head and torso of the query frequency distribution. Next, from each monthly subset we remove the results that appear less than ten times, to elim-inate random noise URLs. All temporal features are ex-tracted on this data, with a total number of 3.2 Million queries. For the SHUF  X  features we collapse URLs to hosts.
The natural process to obtain labeled data ( spam-prone , non spam-prone ) would be as follows. First, the dataset is uniformly sub-sampled for a smaller set of candidate queries. All URLs appearing on these candidate queries are inde-pendently labeled by annotators as spam and non-spam. Queries satisfying our definition of spam-prone query are labeled as a positive class and all other queries are labeled as a negative class. However, given the number of URLs to be judged in order to label a single query, this direct process is highly inefficient. Furthermore, since abusive ad-vertisements affect only a small percentage of all queries, the resulting data will be highly biased towards the non-spam queries. To work around this, we generate the candidate labeled data using three approaches and use them in combi-nation. (i) First, we randomly sample one thousand queries from the collection at a given instance, and label the results as spam/non-spam by independent annotators. From this query sample, we consider all queries with more than one spam page in the top-10 results as spam-prone . Queries, with no spam pages in the top-10 are treated as non spam-prone . (ii) Second, we use a dictionary of queries that re-peatedly (more than once) received spam complaints at a major search engine and treat all such queries as spam-prone , and (iii) Finally, we active-learn on the SHUF  X  feature i.e. we sample for queries with SHUF 10 values in twelve equally sized ranges. The results of these queries are then judged by editors as spam/non-spam. All queries with more than two spam results are labeled spam-prone and all queries with no spam results are labeled as non spam-prone . Although this dataset may have some overall bias, we believe this is the closest possible approach to generating a reasonable labeled dataset, given the nature of this problem and the editorial constraints that any such effort has to face.

In order to train the classifier, we created and made avail-able a training set of roughly 500 queries, labeled as spam-prone and non spam-prone , and evaluated the effectiveness of features, extracted by using temporal profiling, in a super-vised classification setting. Since the overall percentage of spam-prone queries is temporally highly variable, the gener-ated positive and negative candidate samples were uniformly sub-sampled to create a balanced dataset.
We use a shrinkage value of 0.05, with 10 trees and 4 leaf nodes at each tree as a configuration of the gradient boosted decision tree. We report on the precision, recall, and F 1 the best F 1 value, using a 20-fold cross-validation on training data.
 Table 4: Results depicted at the best F1. The content-independent temporal features together are as useful as SPAMMEAN developed over many years. In addition the combination of the two meth-ods outperforms SPAMMEAN. The AUC score is significantly higher for the combination.

The results presented in Table 4 are summarized at the best  X  1 value. The baseline is set by SPAMMEAN , a simple approach that quantifies spam-prone query as the average spam value for all the hosts, appearing in search results for this query. The spam value for each host is computed as the mean of the spam scores for all the pages, belonging to a host. This spam score for each individual page is computed Figure 3: The precision-recall curves indicate that using the TEMPORAL features alone is close in performance to SPAMMEAN, whereas their combi-nation (TEMPORAL + SPAMMEAN) outperforms SPAMMEAN.
 Table 5: The importance of temporal features within the spam-prone query classification model. A di-verse range of temporal properties surface up among the top features, involving both query volatility and host churn . using existing spam classifiers of a major search engine. This classifier has been developed over the years and makes use of both content and link-based features to evaluate a page. It is comparable in performance to the best spam classifiers in published literature and sets a challenging baseline. Interest-ingly, results obtained by using only the temporal features, which is completely content and language agnostic, are com-parable in performance with the baseline. A combination of SPAMMEAN and temporal features, however, improves on all the metrics by around 5%, confirming the overall utility of temporal profiling. The improvements in AUC (Area Un-der the Curve) measure also support this conclusion. From Table 5, it follows that the temporal profiles, which are the most important for classification, include query results volatility (SHUF 4 ), skips (SKP 9 MEAN), query frequency, and host churn on query coverage (HQ MEAN). However, in the combined model SPAMMEAN continues to rank as a top feature, indicating the strength of the baseline set by using this feature alone.

We next run the spam-prone query classifier on the entire corpus of yearly search logs, i.e. around 3.2 million queries satisfying our pre-processing criteria. The classifier was con-figured to provide the spam-likelihood score of a query in the Figure 4: The plot shows a distribution of spam-prone query scores within the range of [0, 255] on a sample of queries. The left peak is for the queries featuring the token  X  X niversity X , the right peak is for the queries featuring the token  X  X ex X . range [0 , 255], from the least spam-prone to the most spam-prone . We then identified some of the key terms occurring in the queries on the two boundaries of this interval, using the constructed language models and the log-likelihood test for individual terms in these language models. Both sets of terms are presented in Table 6. Adult themes, pharmacy, ringtones, gratis products etc. feature prominently in the spam-prone class. In Figure 4, we also plot the score distri-bution of all queries with the term  X  X ex X , against all queries with the term  X  X niversity X .

Having discussed the utility of temporal profiles for the problem of spam-prone query classification, we next turn our attention to their use in search ranking. Table 6: Key indicator terms in spam-prone queries vs. non-spam prone queries. These terms were gen-erated from the language models derived from run-ning the spam-prone query classifier on a large cor-pus of queries.
The problem of search ranking is a well known applica-tion of regression modeling. In this setting, a model learns useful features and their interactions for ranking documents in response to a user query. The features are generally ei-ther (i) query-specific, i.e. an attribute of the query only (ii) document-specific, i.e. an attribute of the document only, or (iii) query-document specific, i.e. an attribute connecting a query to the document. The model is trained on a large set of labeled examples, where relevance labels are assigned to the documents for each query.
The ranking models are trained using a large dataset of labeled examples. For each query, editors independently la-bel five to thirty candidate URLs on a relevance scale of zero to four, where zero represents irrelevant document, and four represents highly relevant. These are considered equivalent to  X  X ad, Fair, Good, Excellent, Perfect X  grades respectively. Using this approach we obtained editorial labels for approx-imately 1.8 Million documents across these five grades for a training set of around seventy thousand queries. A second independently sampled dataset of seven thousand queries with similar editorial relevance judgments was used as a val-idation set.

From this dataset we extracted all the features used by a popular search engine in production. These features are in the hundreds and exist in all three classes of features out-lined above. Document-specific features include the spam classifiers pointed to earlier, as well as many other features of document and host authority. Query-document features include popular text-matching features used in information retrieval as well as user feedback features from the click logs. To this set of features we added a query-specific feature that measures the likelihood of a query to be compromised by spammers ( spam-likelihood score ). We hypothesize that a combination of existing features interacting with the spam-likelihood score will enable the search ranking function to better rank the results both in the spam-prone and non spam-prone query verticals.
Different feature sets are compared using the popular Dis-counted Cumulative Gain (DCG) metric [21], defined up to position  X  as: where  X   X  is the grade of the document at position  X  . We also use NDCG, defined as: where  X   X  is the grade of the document at position  X  and  X  is a normalizing factor to ensure that the score of an ideally ranked list is one.

The baseline model is trained with all the features used by the current production of a popular search engine. The number of trees is set to 2500, with 20 terminal nodes per tree and shrinkage of 0.07. The challenger model is trained using the spam-likelihood query classification score ([0 , 1]) in addition to the baseline features. For queries that do not have a spam-likelihood score , we set the value to  X -1 X . The coverage of the queries by the spam-likelihood score is around 50%.

The results of comparing a new model against the base-lines on a held-out dataset of 7000 randomly selected queries are shown in Table 7. The overall improvement across all Table 7: Knowledge of the spam-likelihood score can be useful to a search ranking function. Statistically significant results are in bold, as compared against a production baseline of a popular search engine. queries is not statistically significant (at the 0.05 level), which is expected, given that the overall coverage of queries with the spam-likelihood score is around 50%. However, queries populated with the spam-likelihood score show sig-nificant improvement. Although these improvements appear small (less than 1%), they are targeted at the adversarial spam-prone vertical. We believe these improvements are a result of the spam-prone query feature interacting with other document level features more robust to spam. The spam-likelihood score based feature ranks among the top thirty features in the resulting model.

Two example queries from the validation set that show relevance improvement when using temporal profiling are shown in Tables 8 and 9. Both queries are frequently prone to spam and are generally highly optimized by search en-gine optimization firms. For the query  X  X iet pill X , an in-formational result from Wikipedia is promoted higher. For the query  X  X aby gifts X , stores more well-known in popular culture are promoted to the top. In both cases, the over-all relevance, as measured by NDCG, is improved for the queries affected by temporal profiling.
In this work, we proposed a new approach for improv-ing the ranking of search results by constructing the tempo-ral profiles from the search logs that allow to quantitatively characterize the concepts of host churn and query volatil-ity . We have experimentally shown that the features, which are based on these two concepts and are estimated from the temporal profiles, although being fully content-independent, outperform state-of-the-art baselines in two different tasks of regression-based ranking of search results and detection of spam-prone queries.

While the presented results are highly encouraging, the present work also opens up several directions for future work. The first direction is related to exploring other concepts, characterizing temporal behavior, besides the host churn and query volatility . Secondly, although our temporal pro-filing approach to the problem of classifying spam-prone queries outperforms existing baselines, there is still room for improvement. Specifically, there exist many other ver-ticals that share similar traits with spam-prone verticals. For instance, popular trending queries on news and current affairs also often have temporally unstable search results. Many of these interactions with other verticals can be bet-ter quantified and incorporated into the ranking framework. One interesting and related direction is qualitative analy-sis of spam-prone queries to better understand the relative incidence of adult, misspelled or commercial queries along semantic and syntactic query dimensions.

In order to incorporate the dynamics of spam creation and the delays associated with the production search system, in this work we only consider monthly time intervals for con-struction of temporal profiles. Although we show the utility of temporal profiling using only this chosen time interval, questions about the utility of shorter time intervals, per-haps within the contexts other than spam detection, remain open.

Better understanding of spam-prone verticals can also en-able focused ranking improvements in query classes that are highly spam-prone . Although we approached this problem by using an existing methodology and viewed it as an in-cremental addition of new features, the question of whether a specialized ranking function exclusively along this vertical is more suitable still remains unanswered. Such a function can also provide higher importance to spam-related features, thus improving the overall user satisfaction.

Even though many lines of future research remain open, we believe that the novel dimension of improving the quality of search results initiated in this paper can enable more prin-cipled and effective solutions to ranking search results and eliminating adversarial content, as compared to the state-of-the-art. [1] E. Agichtein, E. Brill, and S. Dumais. Improving web [2] I. B  X  X r  X o, J. Szab  X o, and A. A. Bencz  X ur. Latent dirichlet [3] L. Breiman, J. Friedman, R. Olshen, and C. Stone. [4] C. Burges, T. Shaked, E. Renshaw, A. Lazier, [5] C. Castillo, C. Corsi, D. Donato, P. Ferragina, and [6] C. Castillo, D. Donato, A. Gionis, V. Murdock, and [7] O. Chapelle and Y. Zhang. A dynamic bayesian [8] N. Dai, B. D. Davison, and X. Qi. Looking into the [9] F. Diaz. Integration of news content into web results. [10] F. Diaz and R. Jones. Using temporal profiles of ranking.

Position Result from Improvement (Grade) Result from Baseline (Grade) 3 http://www.babygiftsupply.com/ (Good) http://www.gotobaby.com/ (Good) promoted in the new ranking.
 [11] G. Dupret and C. Liao. A model to estimate intrinsic [12] R. Fagin, R. Kumar, and D. Sivakumar. Comparing [13] D. Fetterly and Z. Gy  X  ongyi, editors. AIRWeb 2009, [14] D. Fetterly, M. Manasse, and M. Najork. Spam, damn [15] J. H. Friedman. Greedy function approximation: A [16] N. S. Glance, M. Hurst, and T. Tomokiyo. Blogpulse: [17] J. Guiver and E. Snelson. Learning to rank with [18] F. Guo, C. Liu, A. Kannan, T. Minka, M. Taylor, [19] Z. Gy  X  ongyi and H. Garcia-Molina. Web spam [20] M. R. Henzinger, R. Motwani, and C. Silverstein. [21] K. J  X  arvelin and J. Kek  X  al  X  ainen. Ir evaluation methods [22] Y. joo Chung, M. Toyoda, and M. Kitsuregawa. A [23] Y.-R. Lin, H. Sundaram, Y. Chi, J. Tatemura, and [24] G. Mishne, D. Carmel, and R. Lempel. Blocking blog [25] G. A. Mishne. Applied Text Analytics for Blogs . PhD [26] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly. [27] F. Radlinski and T. Joachims. Active exploration for [28] G. Shen, B. Gao, T.-Y. Liu, G. Feng, S. Song, and [29] B. Wu and B. D. Davison. Identifying link farm spam [30] J. Xu and H. Li. Adarank: a boosting algorithm for [31] R. zhang, Y. Chang, Z. Zheng, D. Metzler, and J. yun [32] Z. Zheng, K. Chen, G. Sun, and H. Zha. A regression
