 Text retrieval queries frequently contain named entities. The standard approach of term frequency weighting does not work well when estimating the term frequency of a named entity, since anaphoric expressions (like he , she , the movie , etc) are frequently used to refer to named entities in a docu-ment, and the use of anaphoric expressions causes the term frequency of named entities to be underestimated. In this paper, we propose a novel 2-Poisson model to estimate the frequency of anaphoric expressions of a named entity, with-out explicitly resolving the anaphoric expressions. Our key assumption is that the frequency of anaphoric expressions is distributed over named entities in a document accord-ing to the probabilities of whether the document is elite for the named entities. This assumption leads us to for-mulate our proposed Co-referentially Enhanced Entity Fre-quency ( CEEF ). Experimental results on the text collection of TREC Blog Track show that CEEF achieves significant and consistent improvements over state-of-the-art retrieval methods using standard term frequency estimation. In par-ticular, we achieve a 3% increase of MAP over the best per-forming run of TREC 2008 Blog Track.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Retrieval models ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  Text analy-sis Algorithms, Experimentation, Performance, Theory Entity retrieval, co-reference resolution, term frequency
Named entities referring to entities in the real world are important queries in text retrieval. Examples of named en-tities include person names (such as Bill Clinton ), company names (such as Qualcomm ), movie names (such as Broke-back Mountain ), etc. A recent study reported that named entity queries constitute a significant portion of search en-gine queries [6]. A number of recent evaluation exercises fo-cus on named entities: searching people and disambiguating people with the same name on the Web in WePS [2], retriev-ing geographical location names in GeoCLEF [5], and find-ing relevant or opinionated blog articles for named entities in TREC Blog Track [13]. Furthermore, TREC currently organizes an Entity Track in 2009, aiming to search named entities on Web data and focusing on new information needs of entity-related search.

In this paper, we focus on the ad-hoc retrieval task for named entities. In this task, given a named entity as the query, the output is a list of ranked documents relevant to the named entity, and evaluation is based on standard re-trieval evaluation metrics like mean average precision (MAP) [11]. This ad-hoc retrieval task is a fundamental step in most text retrieval applications involving named entities.
One problem with retrieving relevant documents related to named entities is that the standard approach of term frequency weighting does not work well when estimating the term frequency of a named entity. This is because anaphoric expressions (like he , she , the movie , etc) are frequently used to refer to named entities in a document, and the use of anaphoric expressions causes the term frequency of named entities to be underestimated.

To deal with this problem, intuitively we would like to count the frequency of anaphoric expressions in a document that are coreferential with the named entity in the query, and add this frequency to the count of the named entity in the document to compensate for underestimating the fre-quency of the named entity due to the use of anaphoric expressions.

A direct way to achieve this is to perform coreference resolution to resolve all anaphoric expressions in a docu-ment [12, 19]. However, state-of-the-art coreference resolu-tion programs achieve less than 70% accuracy. Also they make use of many basic natural language processing (NLP) modules such as part-of-speech (POS) tagging, noun phrase chunking, and named entity recognition, and have not been optimized for efficiency. For example, BART [20], an open source coreference resolution program takes about 24 hours to perform coreference resolution of only 1,000 documents in the TREC Blog Track on an Intel 2.83GHz CPU, which is a slow throughput considering that the entire TREC Blog Track has more than 3.2 million documents.

However, in our ad-hoc retrieval task, since we only need to estimate the frequency of anaphoric expressions that are coreferential with the named entity in the query, there is no need to resolve all anaphoric expressions in a document. Armed with this observation, we propose a novel 2-Poisson model to estimate the frequency of anaphoric expressions coreferential with the query named entity in a document, without using any coreference resolution program to explic-itly resolve anaphoric expressions. Our key assumption is that the frequency of anaphoric expressions is distributed over named entities in a document according to the proba-bilities of whether the document is elite for the named en-tities. This assumption leads us to formulate our proposed Co-referentially Enhanced Entity Frequency ( CEEF ) to esti-mate the frequency of the query named entity in a document. The notion of eliteness was proposed by Harter [7] and Robertson and Walker [15] in information retrieval (IR). A document is elite for a term if the document is  X  X bout X  the concept represented by the term. In this framework, the relevance of a document to a query is related to eliteness rather than directly to term frequency. The distribution of term frequencies is modeled by a 2-Poisson mixture model for elite documents and for non-elite documents, with two different means.

In our proposed approach, eliteness is used to estimate the probability of anaphoric expressions referring to the query named entity, which is proportional to the probability of eliteness of the document for the query named entity. The frequency of a named entity in a document is modeled by a 2-Poisson mixture model. The posterior probability of eliteness of a document for a query named entity is estimated based on the observed frequency of the named entity.
Furthermore, we consider the task of how to automat-ically identify anaphoric expressions which can be coref-erential with the given query named entity. We propose a novel feedback-based approach to automatically identify anaphoric expressions from the top M retrieved documents for the query named entity. This feedback-based method enables us to apply CEEF to any named entity types. Experimental results on the text collection of TREC Blog Track show that CEEF achieves significant and consistent improvements over state-of-the-art retrieval methods using standard term frequency estimation. In particular, we achieve a 3% increase of MAP over the best performing run of TREC 2008 Blog Track [13]. To the best of our knowledge, our work is the first to propose approximating the frequency of anaphoric expressions coreferential with a query named en-tity in a document using a 2-Poisson model, without the use of any coreference resolution program. In addition, we per-form the first large-scale empirical evaluation on a standard TREC collection with more than 3.2 million documents.
The rest of this paper is organized as follows. In Section 2, we review related work on the topic of improving text re-trieval using anaphora resolution. Section 3 presents an il-lustrating example to motivate the importance of anaphora resolution to text retrieval. Section 4 describes our pro-posed CEEF and a 2-Poisson mixture model for estimating the eliteness of a document for a named entity. Section 5 presents our feedback-based approach to automatically iden-tify anaphoric expressions. Experiments and results are pre-sented in Section 6. Finally, Section 7 gives the conclusion.
There are relatively few prior research efforts on improving text retrieval using anaphora resolution [9, 14, 4]. Liddy [9] conducted the first empirical study using a small collection consisting of 487 documents, where anaphoric expressions were manually resolved. However, the results indicated that improvements were achieved on only some of the queries, without a conclusive outcome.

Pirkola and Jarvelin [14] re-examined the effect of anaphora resolution on an ad-hoc retrieval task using about 55,000 Finnish newspaper documents, where anaphoric expressions were manually resolved. They showed that anaphora res-olution helped to find additional relevant documents. Al-though their work was the first successful work on applying anaphora resolution to text retrieval, their evaluation was conducted on a relatively small collection and without an automatic procedure for anaphora resolution.

Edens et. al. [4] examined the effect of automatic anaphora resolution using their own anaphora resolution system, and evaluated their approach on the CLEF 2002 English col-lection consisting of 100,000 documents and 50 topics [3]. They showed that retrieval performance on a realistic text retrieval task was improved by automatic anaphoric resolu-tion.
To see why anaphora resolution is important to the ad-hoc retrieval task and how standard term frequency estima-tion can severely underestimate actual frequency, consider the following document from the TREC Blog Track collec-tion [13]. Although this document is relevant to one TREC query  X  Mozart  X  (Q935), the name Mozart occurs only once at the beginning in the document, while pronouns core-ferring to Mozart appear multiple times. Thus, standard term frequency estimation severely underestimates the ac-tual term frequency of Mozart , causing this document to rank lower than other non-relevant documents. This ex-ample illustrates the importance of accounting for the fre-quency of the anaphoric expressions that are coreferential to the query named entity.

This section formally presents our probabilistic approxi-mation to estimate the actual frequency of a named entity. Let Q be a given query and e Q the named entity in Q , called the query entity . We assume that Q contains only a single named entity. When a named entity e in a document is not a query entity, we call it a non-query entity .

An anaphoric expression r is considered feasible when its semantic type is consistent with the type of a query entity e . For example, pronouns such as he and she are feasible anaphoric expressions when e Q is a person name (such as Bill Clinton ). As another example, in the sentence  X  Titanic is a 1997 American film ... . The film was an enormous critical and commercial success ...  X . Here,  X  the film  X  is a feasible anaphoric expression for  X  Titanic  X .

Given a query entity e Q , entity e is considered feasible when e can be coreferential with a feasible anaphoric expres-sion r of e Q . Feasible entities depend on the set of feasible anaphoric expressions. For example, suppose that e Q is X  Bill Gates  X , then  X  he  X  and  X  she  X  are feasible anaphoric expres-sions, and in a document  X  Apple CEO Steve Jobs and Mi-crosoft Chairman Bill Gates both gave big keynote addresses last week  X ,  X  Steve Jobs  X  and  X  Bill Gates  X  are feasible enti-ties since these entities can be coreferential with the feasible anaphoric expression X  he  X , while X  Microsoft  X  X nd X  Apple  X  X re not feasible entities.

Suppose A is the set of feasible anaphoric expressions for e , tf ( A ; d ) is the frequency count of all feasible anaphoric expressions A in document d , and E ( A ; d ) is the set of fea-sible entities in document d , each of which is coreferential with a feasible anaphoric expression in A . We define two different frequencies for the true entity frequency. First, the raw entity frequency ( REF ) of e , denoted by tf ( e ; d ), is the frequency count of e in a document d , without counting its coreferring anaphoric expressions. Second, the anaphoric entity frequency of e , denoted by atf ( e ; A, d ), is the fre-quency count of feasible anaphoric expressions of A coref-erential with e in document d .
 The true entity frequency of e Q , denoted by tf TRUE ( e is the sum of the raw entity frequency and the anaphoric en-tity frequency:
Our main focus is to estimate atf ( e Q ; A, d ). We ignore the specific context of an anaphoric expression, and treat all anaphoric expressions uniformly by introducing P ( e Q | A, d ), the probability that an anaphoric expression in A is coref-erential with e Q in document d . This leads us to formulate the following approximation for true entity frequency: where P ( e Q | A, d ) is assumed to be 0 when tf ( e Q ; d ) is 0. We call this estimated frequency Co-referentially Enhanced Entity Frequency ( CEEF ), denoted by tf CEEF ( e Q ; d ). The standard term frequency estimate corresponds to the case when P ( e Q | A, d ) = 0 , resulting in the raw entity frequency. To compute CEEF, we need to estimate P ( e Q | A, d ).
Our estimation of P ( e Q | A, d ) is based on the eliteness of a document, as reported in the work of Harter [7] and Robertson and Walker [15]. Here, we give the definition for eliteness: Eliteness : A document is elite for a term if the document is  X  X bout X  the concept represented by the term [15]. In this paper, eliteness is used for multi-word named entities, in addition to single-word terms. That is, a document is elite for a named entity if the document is about the entity  X  .
Let P ( E ( e ) = 1 | d ) be the probability that a document d is elite for e , where E ( e ) is a binary random variable indicating whether the document is elite for e , in which E ( e ) is 1 (0) for elite (non-elite).

Our central assumption for approximating P ( e Q | A, d ) is that the frequency of anaphoric expressions is distributed over named entities in a document according to the proba-bilities of whether the document is elite for the named enti-ties. According to this assumption, we formulate P ( e Q | A, d ) as follows:
Instead of recognizing all feasible entities for each docu-ment, we make some simplifying assumptions for approxi-mation. First, we sort all non-query entities (i.e., E ( A ; d )  X  { e Q } ) by the probabilities that d is elite for them (i.e., P ( E ( e ) = 1 | d )), and select top K non-query entities  X  e  X  X  X  , e ( K ) N . Since the top K non-query entities have the high-est probabilities of P ( E ( e ) = 1 | d ), they will play the most significant roles in Eq. (1) than other non-query entities. From this, we approximate the denominator of Eq. (1) by only considering the top K non-query entities for every doc-ument as follows: P ( e Q | A, d )  X  P ( E ( e Q ) = 1 | d )
Second, we treat all top K non-query entities in the same way by introducing P ( E ( e N ) = 1 | d ) where e N is a represen-tative of the top-K non-query entities. From this assump-tion, Eq. (1) is further approximated as follows: P ( e Q | A, d )  X  P ( E ( e Q ) = 1 | d ) We call our estimation an eliteness-based approximation .
The remaining problem is to estimate the probabilities of eliteness of a document for the query entity and non-query entities. We explore two estimation methods in our work.
This assumes that a document d is regarded as elite for e if tf ( e ; d )  X  t : where  X  ( expr ) is 1 if expr is true, and 0 otherwise.
We assume that a document is elite for all top-K non-query entities, i.e., P ( E ( e N ) = 1 | d ) = 1 . Thus, the approx-imated form Eq. (2) is simplified to: We denote this estimation method by CEEF-Thr .
An alternative method is to adopt a 2-Poisson mixture model [7], in which the frequency of a named entity e in a document is modeled by the mixture of two different Poisson models  X  elite (non-elite) document model with mean  X  e (  X  e ). Thus, the probability that e appears tf times in a document is modeled by: where  X  e indicates the prior probability that a document is elite for named entity e .

Under the 2-Poisson mixture model, we define P ( E ( e ) = 1 | d ) by the posterior probability that the document d is elite for named entity e , given the observed data of a named entity e with raw entity frequency tf ( e ; d ) in d as follows: that e appears tf times under the above Poisson model for elite (non-elite) document. By substituting Poisson formulas into the above equation, we obtain the following expression for P ( E ( e ) = 1 | d ):
P ( E ( e ) = 1 | d ) =  X  e
The problem is how to estimate  X  e ,  X  e , and  X  e . Our estimation method differs according to whether entity e is a query entity or a non-query entity. 1) When e = e Q (query entity) We construct an ad-hoc labeled document set based on the following assumptions. First, a document d is elite for e if tf ( e ; d )  X  1. Second, every document d in the test collection is non-elite for e . Note that this ad-hoc labeled set is used only for estimating unknown parameters in 2-Poisson mod-els, not for estimating P ( E ( e ) = 1 | d ). That is, even when a document d is elite in the ad-hoc labeled set, it does not mean that P ( E ( e ) = 1 | d ) is 1.

Using this ad-hoc labeled set, all unknown parameters can be directly estimated:  X  e is estimated by the size of the elite set divided by the sum of the sizes of elite and non-elite sets.  X  e (  X  e ) is estimated by the average term frequency of e in the elite (non-elite) set.

Suppose N is the total number of documents in the test collection, df ( e ) is the document frequency of e (i.e., the number of documents that contain e ), and cf ( e ) is the total frequency count of e in all documents in the test collection (
P By substituting these estimates into Eq. (4), we obtain:
P ( E ( e ) = 1 | d ) = 1 2) When e 6 = e Q ( e = e N ) (non-query entity) The estimation formulas in Eq. (5) for  X  e ,  X  e , and  X  e easily applied for a query entity since we can just count its occurrences in a document and the test collection. However, since we do not explicitly identify all named entities in a document, we cannot use the same estimation formulas for the top K non-query entities.

In our work, we make the following simplifying assump-tions. First, we note that non-query entities and the query entity are of the same entity type because they are feasible entities for the same set of feasible anaphoric expressions. Therefore, we assume that  X  e ,  X  e , and  X  e for a top-K non-query entity e N are approximately the same as those for a query entity e Q . Second, for the term frequency of a top-K non-query entity e N in each document, we set it to be the average frequency of the query entity in an elite document (i.e.,  X  e ).

With these assumptions, Eq. (4) for a non-query entity e becomes: Finally, we can complete Eq. (2) by using Eq. (6) for P ( E ( e Q ) = 1 | d ), and Eq. (7) for P ( E ( e N ) = 1 | d ).
In addition, this paper uses normalized raw entity fre-quency [16]: where len ( d ) is the length of a document d , and avglen is the average length of a document. Then  X  e (  X  e ) is the average normalized term frequency in elite (non-elite) doc-uments. Similar to the above derivation, we can derive esti-mation formulas for  X  e and  X  e when using normalized term frequency. We denote our normalized term frequency esti-mation method by CEEF-2Poisson .
Several retrieval models can be applied after CEEF counts are estimated. In this paper, we adopt BM25 to retrieve documents as follows [16]: where BM 25 CEEF ( e Q ; d ) is the BM25 formula using CEEF for entity term frequency, IDF ( e Q ) is the inverse document frequency for e Q used in the Okapi model, and OkapiTF ( e is given as follows [16]: OkapiTF ( e Q ; d ) = ( k 1 + 1)  X  tf CEEF ( e Q ; d ) where b and k 1 are normalization parameters.
Our CEEF-based retrieval model can be combined with other state-of-the-art retrieval methods such as language modeling [23, 22]. We use linear interpolation [21] for com-bining two retrieval methods: Sim ( Q ; d ) = (1  X   X  )  X  Sim BASE ( Q ; d )+  X   X  BM 25 CEEF where Sim ( Q ; d ) indicates the combined similarity score, Sim BASE ( Q ; d ) is the baseline similarity score of a state-of-the-art retrieval method (like language modeling), and  X  is a tuning parameter for balancing between Sim BASE ( Q ; d ) and BM 25 CEEF ( e Q ; d ) to obtain a good combination. An important remaining problem is how to estimate tf ( A ; d ). We need to define the set of feasible anaphoric expressions A for a given entity query.
As the default, we consider the following as the feasible anaphoric expressions: 1) If query entity is a person: 2) If query entity is a non-person: This setting provides our default approach for tf ( A ; d ).
Since our method uses different feasible anaphoric expres-sions for person entities and non-person entities, we con-struct an SVM classifier to determine if a query entity is a person entity or non-person entity, by using the top M retrieved documents for a given query entity. The features used by the SVM classifier are the following two real-valued features for the top-M retrieved document set F ( Q ) of each query Q . feasible anaphoric expressions for a person (non-person) query in d . f P ( Q ) corresponds to the average probability of A from top-retrieved documents. Similarly, f O ( Q ) corresponds to the probability of A O .
The set of person anaphoric expressions ( A P ) of the de-fault setting is useful because most person names are fre-quently referred to by pronouns. In contrast, the set of non-person anaphoric expressions ( A O ) is too restrictive, be-cause non-person names are more frequently referred to by noun phrases rather than by pronouns, compared to person names. For example, X  X he movie X , X  X his amazing movie X , and  X  X he great film X  X re such noun phrases for a movie entity. To address this problem, we use an approximation method with feedback-based identification based on the top-retrieved doc-uments. This is motivated by our assumption that the top-retrieved documents contain feasible definite noun phrases.
We regard a definite noun phrase as feasible if it is a fea-sible anaphoric expression for a query entity. For example,  X  X he film X ,  X  X he movie X , and  X  X he fantastic film X  are feasible definite noun phrases for a movie entity. A head-noun is the rightmost word in a noun phrase, and is considered feasible when the head-noun can be the head of a feasible definite noun phrase. In the above example,  X  X ilm X  and  X  X ovie X  are feasible head-nouns for a movie entity. Thus, the problem of finding feasible definite noun phrases is equivalent to finding feasible head-nouns.

Our feedback-based identification procedure consists of four basic steps as follows. First, we pre-construct lexico-syntactic patterns to automatically extract a definite noun phrase in a document, where a lexico-syntactic pattern is Table 1: Top head-nouns sorted by their frequencies in top 50 documents, for Q872 and Q1048 Q872 :  X  Brokeback Mountain  X  Q1048 :  X  Sopranos  X 
Head-noun Frequency Head-noun Frequency film 85 show 29 movie 59 season 16 story 44 series 13 line 31 bracco 13 year 21 cents 8 audience 21 graduate 8 world 19 time 7 a sequence of words and part-of-speech (POS) tags. For example,  X  X he NN X  indicates a word bigram starting with  X  X he X  and ending with a noun, where NN denotes the singu-lar noun POS tag. Similarly,  X  X he JJ NN X  indicates a word trigram starting with  X  X he X , followed by an adjective, and ending with a noun, where JJ denotes the adjective POS tag. To extract these patterns, we use POS tagged training data used for the CoNLL chunking task [18]. Second, we retrieve top M documents by applying our retrieval model. Third, we extract all definite noun phrases from the top M retrieved documents and extract all their head-nouns. Finally, we cal-culate the frequency count of each head-noun, and sort by their frequencies, and select the top T head-nouns. Selected top head-nouns are regarded as feasible head-nouns for a given query entity.

To see whether this simple procedure works, Table 1 shows the list of top head-nouns after applying the feedback-based procedure for two entity queries  X  Q872:  X  Brokeback Moun-tain  X  (type: Movie) and Q1048:  X  Sopranos  X  (type: TV pro-gram). For these queries, feasible head-nouns are ranked near the top with high frequencies ( X  X ilm X ,  X  X ovie X , and  X  X tory X  X or Q872, and X  X how X , X  X eason X , and X  X eries X  X or Q1048).
There are commonly used head-nouns such as X  X ear X , X  X orld X , and  X  X ime X  which occur with relatively high frequency. To prevent the inclusion of these words into our set of feasi-ble head-nouns, we perform an additional filtering step to remove the top 10 most frequent head-nouns that appear in all documents in the test collection. Our feedback-based identification is applied only for non-person names. The reason is that the most frequent anaphoric expressions for person names are pronouns. Therefore, our feedback-based identification should be applied after first performing person query classification as described in Section 4.6.
For evaluation, we used the TREC Blog collection [13], where most of the queries are named entities. Table 2 shows the frequency and an example of each type of query entities for the 150 queries in the TREC Blog collection. Among them, the number of person entities is 33, the number of non-person entities is 108, and the number of general topical queries is 9. We used 50 queries from TREC  X 06 (Q850  X  Q900) as the development set for parameter tuning, and the remaining 100 queries from TREC  X 07 (Q901  X  Q950) and  X 08 (Q1001  X  Q1050) as the test set. Table 2: Frequency ( Freq. ) and example for each entity type of 150 TREC blog queries.
 Query Type Freq. Example Person 33 Q854:  X  Ann Coulter  X  Company / Store 27 Q884:  X  Qualcomm X   X  Product 17 Q1005:  X  Windows Vista  X  TV program / Movie 14 Q928:  X  Big Love  X  Organization 12 Q945:  X  Bolivia  X  Event / Award 10 Q936:  X  Grammys  X  Other Types 28 Q923:  X  Challenger  X  Topic 9 Q896:  X  global warming  X  Total 150
Each blog post in the collection was first preprocessed by removing HTML tags and boiler templates. The subse-quent preprocessing steps are different according to whether we calculate BM 25 CEEF ( e Q ; d ) or Sim BASE ( Q ; d ). For BM 25 CEEF ( e Q ; d ), they were annotated by applying a POS tagger 1 . No stemming and stopword elimination were per-formed and all terms in queries and documents were con-verted to lowercase when matching a query entity with doc-uments for calculating CEEF (or REF). For Sim BASE ( Q ; d ), we performed standard preprocessing by applying the Porter stemmer and removing stopwords using the standard IN-QUERY 418 words stoplist [1].

For all evaluations, we used the title query. Most of the title queries (more than 95%) consist of only a single entity not containing other terms. However, some of the queries contain other generic nouns. For example,  X  Mark Warner for President  X (Q1006) has X  for President  X  X n addition to the entity name X  Mark Warner  X . For these queries, we manually identified the boundary of entity name and eliminated the other terms to obtain the cleaned form for entity query.
We used 50 queries from TREC  X 06 as training data for learning an SVM-based person query classifier (Section 4.6) after annotating all queries into person and non-person query sets 2 . The number of top-retrieved documents was fixed at 50. We used RBF (Radial Basis Function) kernel. For RBF kernel parameter, we selected the best performing parameter after comparing the classification accuracy of each trained SVM classifier according to different kernel parameters.
The final classifier achieved 93% classification accuracy on 100 test queries from TREC  X 07 and  X 08, where 7 queries were misclassified. Among them, 4 non-person queries were misclassified as person queries, and 3 person queries were misclassified as non-person queries.
For Sim BASE ( Q ; d ) in Section 4.4.1, we used the Lemur toolkit to obtain each baseline run 3 , by considering the fol-lowing two baseline methods. 1. LM : Ranking by the language modeling approach using Dirichlet-prior smoothing [23]. 2. LMFB : Ranking by pseudo-relevance feedback based on the query model estimated from two-component mixture model [22].
For BM 25 CEEF ( e Q ; d ), we evaluated the following five different entity frequency methods: 1. REF : Ranking by using the raw entity term frequency (using tf ( e Q ; d ) for tf CEEF ( e Q ; d ) of Eq. (8)). 2. CEEF-Thr : Ranking by using CEEF with threshold-based approach (using Eq. (3) for Eq. (2)), based on the de-fault setting of feasible anaphoric expressions (Section 4.5). 3. CEEF-2Poisson : Ranking by using CEEF with 2-Poisson mixture model (using Eq. (6) and Eq. (7) for Eq. (2)), based on the default setting of feasible anaphoric ex-pressions (Section 4.5). 4. CEEF-FB-2Poisson : Same as CEEF-2Poisson, ex-cept for using feedback-based anaphoric expressions for non-person queries (Section 4.3.2 and Section 5.1). The top-retrieved documents are obtained from the corresponding baseline run (LM or LMFB). The top-retrieved documents for evaluation in Section 6.2 are obtained from LM. 5. CEEF-FB-2Poisson* : Same as CEEF-FB-2Poisson, but using an oracle person query classifier and not an auto-matic classifier.
There are several tuning parameters for each entity fre-quency method  X  the number of feasible non-query entities K in Eq. (2), the threshold parameter t in Eq. (3), the normalization parameters k 1 and b in Eq. (8), the interpo-lation parameter  X  in Eq. (9). To tune these parameters, we divided 150 queries in Table 2 into training and test query sets. We used 50 queries from TREC  X 06 as training set, and used 100 queries from TREC  X 07 and  X 08 as test set. We performed an exhaustive grid search for finding param-eters that produce the best MAP (Mean Average Precision) for each run on the training query set. The search space for each parameter is given as follows:  X  K : { 1, 5, 10 } (CEEF-Thr and CEEF-FB-2Poisson  X  Eq. (2))  X  t : { 1, 3, 5 } (CEEF-Thr  X  Eq. (3))  X  k 1 : { 0.5, 0.8, 1.0, 1.2, 1.5, 2.0, 2.2 } (all methods)  X  b : { 0, 0.1, 0.2, 0.5, 0.75, 0.9 } (all methods)  X   X  : { 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 } (all methods) Other parameters were not tuned but fixed in advance. For our feedback-based extraction in Section 5.1, the number of top-retrieved documents ( M ) was fixed at 50, and the number of top head-nouns ( T ) was fixed at 5. For evaluation measures, MAP (Mean Average Precision), Pr@5 (Precision at 5 documents), and Pr@10 (Precision at 10 documents) were used [11]. For each query, our evalua-tion is based on top 1000 documents. To provide more de-tailed information, we conducted statistical test to compare results. Sanderson and Zobel showed that t-test is more re-liable than sign test or Wilcoxon test [17]. Inspired by their findings, we report significance test results of non-directional paired t-test at 0.95 confidence level.
We first compare CEEF and REF without combining any retrieval models (  X  is fixed to 1 in Eq. (9)). Table 3 shows MAP, Pr@5, and Pr@10 of each CEEF method, compar-ing with the REF method. From Table 3, we can see that CEEF-2Poisson and CEEF-FB-2Poisson significantly out-Table 3: Comparison of MAP, Pr@5, and Pr@10 of REF and CEEF methods on the test set. The  X  symbol indicates statistical significance over REF at 0.95 confidence interval.
 Methods MAP Pr@5 Pr@10 REF 0.3929 0.6707 0.6616 CEEF-Thr 0.3968  X  0.6788 0.6778 CEEF-2Poisson 0.4139  X  0.7060  X  0.6940  X  CEEF-FB-2Poisson 0.4165  X  0.7320  X  0.7200  X  CEEF-FB-2Poisson* 0.4177  X  0.7420  X  0.7270  X  Table 4: Comparison of MAP of REF and CEEF methods combining with LM and LMFB for test set.
 The 1st column and 2nd column show the results when B (Baseline Run) for LM and LMFB, respec-tively. The  X  symbol indicates statistical significance over B+REF at 0.95 confidence interval.
 perform REF. The improvements over REF from CEEF-2Poisson and CEEF-FB-2Poisson were found to be statis-tically significant for MAP, Pr@5, and Pr@10 with large margin. Two-tailed paired t-tests on comparing CEEF-FB-2Poisson with REF showed p-values of 0.00075 on MAP, 0.00023 on Pr@5, and 0.00018 on Pr@10. The improvement over REF from CEEF-Thr is very small, and the difference on Pr@5 and Pr@10 was not found to be statistically signif-icant. We think that the reason for this small difference is due to the na  X   X ve estimation style of CEEF-Thr, which might over-estimate the anaphoric entity frequency.

Comparing two runs using the automatic method and the oracle classifier for person query classification, we can see that the MAP difference between CEEF-FB-2Poisson and CEEF-FB-2Poisson* is small (0.12% of MAP) on the whole test query set. In fact, CEEF-FB-2Poisson results in 1.7% decrease in MAP on average over CEEF-FB-2Poisson* for each misclassified query.
In this section, we see how much the retrieval performance can be improved from CEEF when combining with each baseline run. As well as non-combined model, our expec-tation on this evaluation is that CEEF can provide a bet-ter effect than REF in the combined method, because of its enhanced and corrected term frequency. Table 4 shows MAP of each frequency method when combining with LM or LMFB for Sim BASE ( Q ; d ). In Table 4, B (Baseline Run) indicates the corresponding baseline run for each column, and B+X indicates a combining approach using the esti-mation method X for CEEF, and using B for baseline run. For example, LM+CEEF-2Poisson means the method of combining LM for Sim BASE ( Q ; d ) and CEEF-2Poisson for BM 25 CEEF ( e Q ; d ). From Table 4, we can again see that CEEF-FB-2Poisson shows the best performances for both Table 5: Comparison of MAP of REF and CEEF methods, combining with LMFB for each query type. CEEF and CEEF-FB indicate CEEF-2Poisson and CEEF-FB-2Poisson, respectively. The  X  sym-bol indicates statistical significance over REF at 0.95 confidence interval.
 Query Type LMFB ( B )+ Person 0.5640 0.5793  X  0.5761  X  0.5781  X  Company, etc. 0.5061 0.5170 0.5305  X  0.5305  X  Product 0.5245 0.5401 0.5680  X  0.5680  X  TV program, etc. 0.3664 0.3754 0.3793 0.3944  X  Organization 0.4468 0.4682 0.4701 0.4701 Event, etc. 0.5039 0.4987 0.5012 0.5021 Other Types 0.4785 0.4889 0.5040  X  0.5040  X  Topic 0.2754 0.3078 0.3094 0.3123 All 0.4868 0.5000  X  0.5090  X  0.5106  X  Table 6: Comparison of MAP of the TREC best run, REF and CEEF methods for TREC  X 07 and  X 08 test set. Parameters were tuned on TREC  X 06 test set.
 The  X  symbol and  X  symbol indicate statistical sig-nificance at 0.95 confidence interval, over REF and NONE, respectively. NONE means non-combined baseline run.
 Topic Set TREC08BEST + TREC  X 07 0.5406 0.5569  X  0.5646  X  0.5733  X  X 
TREC  X 08 0.5032 0.5216  X  0.5248  X  0.5330  X  X  baseline runs, and significantly improve over REF on MAP. We can also see that the improvement over baseline from REF is very large, showing more than 6% increase of MAP. We think that this result is obtained from the effect of the phrase-based matching of REF. Liu et al have shown that phrase-based matching significantly improved upon simple word based matching [10].
Table 5 gives more detailed results according to each query type. Due to space limit, Table 5 only shows the results using LMFB for the baseline run and CEEF-2Poisson for the entity frequency method. In Table 5, we use CEEF for CEEF-2Poisson and CEEF-FB for CEEF-FB-2Poisson. From Table 5, we can see that CEEF-FB methods signifi-cantly improve REF for major entity types such as Person, Company, and Product. The statistical test is sometimes not passed even though the performance difference is not small (e.g., Topic and Organization). The reason is that the number of query topics is not sufficient to confidently pass the statistical test. However, CEEF does not give large im-provements for TV program and Event. This result implies that there is room for further study on CEEF.
In addition, we see how effective CEEF is when combined with a more sophisticated baseline. We used the best per-forming run at TREC 2008 Blog Track [8] 4 . We call this run TREC08BEST . Table 6 shows MAP of each entity frequency method when using TREC08BEST for the base-line run. We again see that CEEF-FB shows the best per-formance, significantly improving over TREC08BEST and also REF for each TREC topic set, achieving 3% increase of MAP over TREC08BEST on TREC  X 08 Test Set.
In this paper, we propose a novel 2-Poisson model to esti-mate the frequency of anaphoric expressions of a named en-tity, without explicitly resolving the anaphoric expressions. Our key assumption is that the frequency of anaphoric ex-pressions is distributed over named entities in a document according to the probabilities of whether the document is elite for the named entities. This assumption leads us to for-mulate our proposed Co-referentially Enhanced Entity Fre-quency (CEEF). Experimental results on the text collection of TREC Blog Track show that CEEF achieves significant and consistent improvements over state-of-the-art retrieval methods using standard term frequency estimation. In par-ticular, we achieve a 3% increase of MAP over the best per-forming run of TREC 2008 Blog Track. [1] J. Allan, M. E. Connell, W. B. Croft, F.-F. Feng, [2] J. Artiles, J. Gonzalo, and S. Sekine. The [3] M. Braschler and C. Peters. CLEF 2002 methodology [4] R. J. Edens, H. L. Gaylard, G. J. F. Jones, and A. M. [5] F. Gey, R. Larson, M. Sanderson, K. Bischoff, [6] R. Guha and A. Garg. Disambiguating people in [7] S. P. Harter. A probabilistic approach to automatic [8] Y. Lee, S.-H. Na, J. Kim, S.-H. Nam, H.-Y. Jung, and [9] E. D. Liddy. Anaphora in natural language processing [10] S. Liu, F. Liu, C. Yu, and W. Meng. An effective [11] C. D. Manning, P. Raghavan, and H. Schutze.
 [12] V. Ng. Machine learning for coreference resolution: [13] I. Ounis, C. Macdonald, and I. Soboroff. Overview of [14] A. Pirkola and K. J  X  arvelin. The effect of anaphor and [15] S. E. Robertson and S. Walker. Some simple effective [16] S. E. Robertson, S. Walker, M. M. Beaulieu, [17] M. Sanderson and J. Zobel. Information retrieval [18] E. F. T. K. Sang and S. Buchholz. Introduction to the [19] W. M. Soon, H. T. Ng, and D. C. Y. Lim. A machine [20] Y. Versley, S. Ponzetto, M. Poesio, V. Eidelman, [21] C. C. Vogt and G. W. Cottrell. Fusion via a linear [22] C. Zhai and J. Lafferty. Model-based feedback in the [23] C. Zhai and J. Lafferty. A study of smoothing methods
