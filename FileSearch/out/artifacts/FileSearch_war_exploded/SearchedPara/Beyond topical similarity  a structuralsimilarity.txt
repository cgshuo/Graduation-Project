 REGULAR PAPER Xiaojun Wan Abstract Accurately measuring document similarity is important for many text applications, e.g. document similarity search, document recommendation, etc. Most traditional similarity measures are based only on  X  X ag of words X  of docu-ments and can well evaluate document topical similarity. In this paper, we propose the notion of document structural similarity, which is expected to further evaluate document similarity by comparing document subtopic structures. Three related ing factor) are proposed and combined to evaluate document structural similarity, among which the optimal matching factor plays the key role and the other two factors rely on its results. The experimental results demonstrate the high perfor-mance of the optimal matching factor for evaluating document topical similarity, which is as well as or better than most popular measures. The user study shows the good ability of the proposed overall measure with all three factors to further find highly similar documents from those topically similar documents, which is much better than that of the popular measures and other baseline structural similarity measures.
 Keywords Document structural similarity  X  Similarity measure  X  Subtopic structure  X  TextTiling  X  Optimal matching  X  Text order 1 Introduction such as document recommendation, document filtering, and similarity search. Most text applications aim to measure document similarity by how much in-formation (content) the documents share. Lin [ 19] clarifies the intuitions about similarity as follows: The similarity between two documents and is positively re-lated to their commonality and negatively related to the differences between them. The commonality and difference between documents are measured based on the co-occurrences of words or phrases in the documents. If two documents share more words/phrases while keep less different words/phrases, the documents are more similar. Most popular similarity measures, such as the Cosine measure, the Dice measure, the Jaccard measure, the Overlap measure [ 3, 32] and the informa-tion theoretic measure [ 2], all observe the above intuitions. We refer to the above similarity as topical similarity between documents. Most text applications, includ-definition.
 topic-identical documents. The topical similarity measures usually have good ca-documents are topically correlated. For these measures, the similarity is evalu-ated based on how much content information they share, represented by words or phrases in the documents. The distribution of words/phrases over the whole docu-ment is not considered in the above measures. Actually, a document is written or presented with an implicitly or explicitly planned structure, such as the paragraphs or more complex passages acquired by natural language processing techniques. It is deemed that the more similar the document structures are, the more similar the documents themselves are. A simple example is that two articles focusing on the same topic might be different enough, while if the articles have similar passage compositions and each of the passages in one article corresponds to a similar pas-sage in the other article, we can say that these articles are highly similar. However, all the structural information is ignored in the topical similarity measures because they simply treat a document as a bag of words/phrases or a word/phrase vector. In essence, those topical similarity measures evaluate document similarity from only one perspective, i.e. the topical perspective. Accurately measuring document similarity from overall perspectives, including the structural perspective, will ben-efit many text applications. For example, in recommender systems, it is required to find the most similar documents to a given document, which means it is still user to browse the highly similar documents first.
 structured documents, such as XML documents and HTML documents. For the formation. Much work [ 10, 22] has explored the structural similarity between XML or HTML documents. However, the structural similarity between XML and HTML documents usually denotes the similarity of their DTDs or schemas, which is totally different from the structural similarity for ordinary documents. Two structurally similar XML or HTML documents might express totally dif-ferent topics. For example, two web pages with the same layout are considered structurally similar, irrespective of their text content. Moreover, for ordinary docu-ments, no structural information is given explicitly, so we need to derive document structures from ordinary documents before we evaluate document structural similarity.
 image retrieval. In document image databases, documents are stored as images without text content. Much work [ 12, 29] has investigated using the layout struc-ture or logical structure of document image for document image matching or re-trieval. The logical structure usually provides a description of the document X  X  log-ical components, such as title, body text, graphics, and footnotes. Other related work includes duplicate detection and plagiarism analysis and detection. Dupli-cate detection [ 4, 7, 20] aims to recognize and eliminate such duplicated docu-ments in a document set or search results. A duplicate document usually refers to the document almost identical to another, such as a photocopy of a document, a fax or a mirror web page. Plagiarism detection [ 16, 31] aims to recognize pla-giarized documents in document set. A plagiarized document is a document in which the author claims to own the material that someone else actually wrote. The granularity of plagiarism varies from a short sentence to the whole document and small string chunks are usually used for comparison based on edit distance or fingerprints.
 sign a measure to evaluate the structural similarity between documents, i.e. it eval-uates the document similarity from the structural perspective. We adopt the seman-tic passages obtained by the TextTiling algorithm [ 14 ] to represent the structure of a document. Then, we propose a measure to evaluate the document similar-ity based on the derived structures. The measure takes into account three factors: the optimal matching factor, the text order factor and the disturbing factor. The experimental results demonstrate the high performance of the proposed measure with only the optimal matching factor for evaluating document topical similarity, which is as well as or better than most popular measures. The user study shows the good ability of the proposed overall structural measure with all three factors ments, which is much better than that of the popular measures and other baseline structural similarity measures. In brief, the proposed measure has a good ability to measure document structural similarity, while keeping the ability to measure document topical similarity.
 similarity measures are reviewed in Sect. 2. The notion of document structural similarity and the proposed measure are described in detail in Sect. 3. Section 4 presents the experiments and user study for evaluation. We discuss the cons and pros of the proposed measure in Sect. 5. Lastly, we conclude with Sect. 6. 2 Document topical similarity and popular measures A document usually has one or a few main topic discussions, which can be ei-ther broad or narrow. The text in the document is involved with the main topics. Document topical similarity refers to the similarity between the main topics of same topics. The similarity computation is usually based on the co-occurrences of the words/phrases. If two documents share more words/phrases while have less different words/phrases, they are topically similar. This kind of similarity is widely adopted in many text applications and different measures are developed to evaluate it. Several popular measures are described in detail as follows. 2.1 The Cosine measure The Cosine measure is the most popular measure for document similarity based on the vector space model (VSM). The vector space model creates a space in which documents are represented by vectors. For a fixed collection of documents, a vec-tor is generated for each document from sets of terms with associated weights. Then, a vector similarity function is used to compute the similarity between vec-tors.
 ing two numbers: (1) term frequency tf d , t , the number of occurrences of term t in document d ; (2) inverse document frequency, idf t = log ( N / n t ) ,where N is the total number normalized inner product of the two vectors a and b : where t represents a term. a  X  b gets the common words between a and b .Term weight w d , t is computed by tf d , t  X  idf t . 2.2 The Jaccard measure The Jaccard measure and the following two measures (i.e. the Dice measure and the Overlap measure) are all based on the vector space model. The document rep-resentations are the same with the Cosine measure and the words weights are all based on tf  X  idf calculation. The three measures differ from the Cosine measure in that they normalize the inner product of two document vectors in different ways. The similarity function of the Jaccard measure is as follows 2 : 2.3 The Dice measure The Dice measure is defined as follows: 2.4 The Overlap measure The Overlap measure is defined as follows: where min { x , y } returns the minimal value of x and y . 2.5 The information theoretic measure Aslam and Frost [ 2] extend the concept that the assessment of pairwise object similarity can be approached in an axiomatic manner using information theory and develop an information theoretic measure for pairwise document similarity as follows: documents containing term t . For each document d and term t ,let p d , t be the fractional occurrence of term t in document d ; thus, t p d , t = 1forall d .Two mon X , while they contain p a , t and p b , t amount of term t individually. 2.6 The BM25 measure The BM25 measure [ 25, 26] is one of the most popular retrieval models in a prob-abilistic framework and it is widely used in the Okapi system. In this study, we use the BM25 model to compute the similarity value between documents by using one document as the query. Given the query document q , the similarity score for document d is defined as follows: where t represents a unique term; N is the number of documents in the collection; n is the number of documents in which term t exists; f q , t is the frequency of term this measure when a is taken as the query would be different from the similarity value when b is taken as the query. In the experiments, the query documents are defined beforehand, and so we can apply this measure directly, which is the same for the following PivotedVSM measure and language model measure. 2.7 The vector space model with document length normalization The vector space model with document length normalization [ 27 , 30] is also a pop-ular retrieval model used in the Smart system. In this study, we use this retrieval model to compute the similarity value between documents by using one document as the query. Given the query document q , the similarity score for document d is defined as follows: S = 0 . 2 is a constant. 2.8 The language model measure The language model measure [ 9, 34] adopts a probabilistic framework and it inter-prets the relevance between a document and a query as the probability of generat-ing the query from the document. We use the widely used Dirichlet prior smooth-ing method for the unigram document model. Given the query document q ,the similarity score for document d is defined as follows: score LM ( q , d ) = where  X  = dl f d /( dl f d +  X ) ,and P MLE ( t | C ) is the maximum likelihood estimate of the probability of term t in collection C ;  X  is a parameter usually set to be multiples of the average document length. 3 Document structural similarity and the proposed measure A document usually has discourse structures at different granularities. Document structural similarity aims to evaluate document similarity based on the discourse structures at the same granularity of two documents. This kind of similarity is ex-pected to further evaluate the document similarity beyond the topical similarity. To the best of our knowledge, document structural similarity has not been well investigated yet. In this study, we first derive structural representations for docu-ments and then propose a novel approach to evaluate document similarity based on the structural representations of documents. 3.1 The TextTiling algorithm To date, a number of document discourse structure representations have been pro-posed, such as the attentional/intentional structure [ 13] and the rhetorical structure theory [ 21]. In this study, we adopt the discourse structure representation based on overlapping or non-overlapping passages, which is widely used in many informa-tion retrieval tasks, such as passage retrieval [ 5, 15, 17]. The passages in a docu-ment have no hierarchical relationship with each other. The types of passages can be grouped into three classes: discourse, semantic, and window [ 5]. Discourse pas-sages are based on textual discourse units (e.g. sentences, paragraph and sections). Semantic passages are based on the subject or content of the text (e.g. TextTiling). Window passages are based on a number of words.
 man X  X  cognition and extensively investigated in the field of natural language pro-cessing. As mentioned by Hearst [ 14 ], the text can be characterized as a sequence of subtopical discussions that occur in the context of a few main topic discussions. The principle idea of semantic passages is to partition documents into segments, each corresponding to a topic or to a subtopic. In this study, we use a set of se-mantic passages to represent document structure.
 the good bilateral relationship between China and the United States, can be de-scribed as consisting of the following subdiscussions (numbers indicate paragraph numbers): subtopics, which can represent the text X  X  underlying subtopic structure. describe a subtopic will co-occur locally, and a switch to a new subtopic will be signaled by the ending of co-occurrence of one set of terms and the beginning of the co-occurrence of a different set of terms. The algorithm has the following three steps: (2) Lexical score determination: All pairs of adjacent lexical units are compared (3) Boudary identification: The resulting sequence of similarity values is graphed one or more overarching main topics, which span the length of the text. Since the segments are adjacent and non-overlapping, they are called TextTiles. length, and more efficient implementations are available, such as Kaufmann [ 18 ] and JTextTile [ 6].
 posed into the following two sets of subtopics (TextTiles) respectively: A = { a 3.2 Baseline structural similarity measures 3.2.1 Sequential matching (SM) Sequential matching is the most intuitive method to compare document structures, represented by a sequence of subtopics. It matches subtopics strictly according to the sequence order. Given two sequences of subtopics A ={ a 1 , a 2 ,..., a n } and B ={ b is the minimum of n and m . The similarity value between any pair of subtopics is computed with the Cosine measure, and the structural similarity between doc-malized by sim SM ( a , b ) = sim SM ( a , b )/ min { n , m } . 3.2.2 Greedy matching (GM) Given two sequences of subtopics A ={ a 1 , a 2 ,..., a n } and B ={ b 1 , b 2 , ..., b a in A with the most similar subtopic b j available in B . The algorithm goes as follows: (1) Initialize the document similarity value, i.e. sim GM ( a , b ) = 0; (2) Iteratively perform steps (3) X (5) from i = 1to n ; (3) Find the most similar subtopic  X  b k in B for subtopic a i in A ,i.e. (4) Let sim GM ( a , b ) = sim GM ( a , b ) + sim Cosine ( a i ,  X  b k ) ; (5) Remove  X  b k from the available subtopic set B ,i.e. B = B  X  X   X  b k } ; (6) Normalize the similarity value by sim GM ( a , b ) = sim GM ( a , b )/ n . 3.3 The proposed structural similarity measure The proposed document similarity measure incorporates the following three fac-tors borrowed from the work [ 23] for video clip retrieval: optimal matching aims subtopics by maximizing the total weight of the one-to-one matching between the two subtopic sets; text order aims to assess to what degree that two set of subtopics are expressed in a similar way by comparing the orders of the matched subtopics; disturbing factor also aims to assess the degree of subtopic correspondence by pe-nalizing those unmatched subtopics. Note that optimal matching is the key factor, and text order and disturbing factor rely on the results of optimal matching to fur-ther evaluate document structural similarity by complementing optimal matching. 3.3.1 Optimal matching (OM) Optimal matching (OM) and maximal matching (MM) are classical problems in graph theory. Given two sequences of subtopics A ={ a 1 , a 2 ,..., a n } and B = { b measuring the similarity between a i and b j . The similarity between two subtopics (TextTiles) is measured with the popular Cosine measure. In order to get the truly similar subtopic pairs, we set a threshold to remove noisy subtopic pairs. The edge weight is normalized as follows: to solve the optimal matching problem. In the experiments,  X  is set to 0.05. edges of M share the same node. MM is to find a matching M that has as many edges as possible. OM is to find the matching M that has the largest total weight. acquire the total value of the optimal matching in G . In order to balance the effect of the lengths of different documents, we normalize the total value as follows: where  X ( G ) represents the total value of the optimal matching in G ;min { n , m } returns the minimal value of n and m .
 a and b .
 faster version of optimal matching algorithms exists [ 28] and can find the optimal matching of G in O (( m + n )( k + ( m + n ) log ( m + n ))) ,where k is the number of matching edges. 3.3.2 Text order (TO) Given a bipartite graph G computed by optimal matching, the similarity of two documents based on the text order 3 of matched TextTiles can be formulated as the Longest Common Subsequence (LCS) problem [ 8], which can be solved by dynamic programming. Denote L as a array indicating the number of subtopic pairs that are matched along the text order, we have
L [ i , j ]= where M is the optimal matching in the graph. The running time of Eq. ( 11 )is O ( nm ) after the optimal matching has been computed, where n and m are respec-tively the numbers of subtopics in a and b . The similarity between documents a and b based on the text order is defined as 3.3.3 Disturbing factor (DF) Disturbing factor aims to penalize the matching with a large number of unmatched subtopics in the optimal matching M in the graph, i.e. n + m  X  2  X | M | .The similarity between documents a and b based on disturbing factor is O ( 1 ) time after the optimal matching has been computed. 3.3.4 Overall structural similarity The structural similarity between documents a and b is measured jointly by the optimal matching similarity, text order similarity and disturbing factor as follows: where  X  ,  X  and  X  are the weights of different similarity factors. These weights control the final structural similarity value and they are tuned heuristically based on a small dataset, and in the experiments,  X  ,  X  and  X  are set to 0.7, 0.2, 0.1, respectively. 4 Experiments and user study 4.1 Overview The experiments have two aims: one is to empirically evaluate the effectiveness of the topical similarity measures described in Sect. 2, and exhibit the ability of the proposed structural similarity measure to evaluate document topical similar-ity; the other is to demonstrate the ability of the proposed structural similarity measure to further distinguish topically similar documents. In other words, the proposed structural similarity is expected to find topically similar documents and then further find structurally similar documents for a given document. similarity, we use a number of documents as queries and retrieve topically sim-ilar documents from a document corpus based on different similarity measures. Then the returned list of 500 documents for a query document is compared with a ground truth list, consisting of all human-annotated documents relevant (similar) to the query document. The higher the document is in the ranked list, the more similar it is with the query document. In order to assess the performances of the similarity measures for structural similarity, a user study is performed to evaluate the retrieved document list because it is difficult to build a ground truth list of structurally (highly) similar documents for a given query document. 4.2 Dataset We built two datasets for the experiments: 4.2.1 TDT3 The TDT-3 corpus has been used for evaluation of the task of topic detection and tracking [ 1] in 1999 and 2000. The TDT-3 corpus is annotated by Linguistic Data Consortium (LDC) from eight English sources and three Mandarin sources for the period of October through December 1998. 120 topics are defined and about 9000 stories are annotated over these topics with an  X  X n-topic X  table presenting all stories explicitly marked as relevant to a given topic.
 topic are similar and relevant. After removing the stories written in Chinese, we used 40 topics and more than 2500 stories as a test set, while the others were used as a training set. The documents were preprocessed in the following four steps: (1) Sentence tokenization was firstly applied to all documents. (2) The JTextTile tool 4 was used to segment the documents and get the TextTiles or subtopics. (3) The stopword list in Smart system was employed in order to remove stopwords. (4) The texts were stemmed using the porter X  X  stemmer [ 24 ]. We randomly chose a document as the query document for each topic and all the other documents within the same topic were the topically relevant (similar) documents, while all the documents within other topics were considered topically irrelevant (dissimilar) to the query document. All the stories except the query stories were considered as the document collection for performing search. 4.2.2 DUC2005 The DUC2005 corpus has been used for evaluation of the task of multi-document summarization [ 11]. The corpus consists of 50 document clusters and 1593 doc-uments. All the documents within a cluster reflect a specific TREC topic chosen by NIST assessors and the relevance of the documents have been verified by the assessors. Each of these clusters has at least 35 relevant documents and the docu-ments all come from two TREC collections: Financial Times of London and Los Angeles Times. The documents within the same topic are similar and relevant, and we used all the 50 document clusters as another test set. The documents were preprocessed in the same way as the TDT3 dataset. Similarly, we randomly chose a document as the query document from each cluster and all the other documents within the same cluster were the topically relevant (similar) documents, while all the documents within other clusters were considered topically irrelevant (dissim-ilar) to the query document All the documents except the query documents were considered as the document collection for performing search. 4.3 Evaluation for topical similarity 4.3.1 Evaluation metric We use the precision ( P )attop N results and the non-interpolated average preci-sion to evaluate the performance.
 where R is the set of top N similar documents returned by our system, and C is the set of relevant documents defined above for a given query document. Then the values are averaged over all queries.
 all precision values calculated after each relevant document is retrieved. If a rel-values are then averaged over all queries.
 evaluation. Note that the number of documents within each topic is different and some topics contain even less than five documents, so its corresponding precision values may be low. But these circumstances do not affect the comparison of the performances of different measures. 4.3.2 Experimental results In our pilot experiments, we found that in the proposed structural similarity mea-sure in Eq. ( 14 ), the text order factor and the disturbing factor do not benefit to evaluate topical similarity, so only the optimal matching factor is adopted to evalu-ate topical similarity between documents. In other words, we take Eq. ( 10 ) instead values corresponding to three factors can be computed and saved respectively, and only the optimal matching similarity value is used in the phase of retrieving top-ically similar documents, and the overall similarity value is used in the phase of retrieving structurally similar documents by reranking the top retrieved documents in the first phase.
 on the two datasets are shown and compared in Tables 1 and 2 and Figs. 1 and 2, respectively. The upper bounds are the ideal values under the assumption that all the relevant (similar) documents are retrieved and ranked higher than the irrelevant (dissimilar) documents in the returned list. If the number of relevant documents for a query document is smaller than 5 or 10, the P @5 or P @10 for this query will never reach 1. There are a few such queries in the TDT3 corpus, so the average P @5 or P @10 (i.e. the upper bounds of P @5 or P @10) will not reach 1. timal matching (OM) factor performs better than all other measures over all three metrics on the TDT3 dataset. Seen from Table 2 and Fig. 2, the proposed measure based on the optimal matching factor achieves the highest P @5 values and com-parable P @10 and AverageP values with several representative measures with good performances (i.e. the Cosine measure, the information theoretic measure and the language model measure) on the DUC2005 dataset. The optimal match-ing measure also outperforms the baseline structural measures, including the se-quential matching measure (SM) and the greedy matching measure (GM) over all three metrics on both datasets. The reason underlying this result is that sequential matching and the greedy matching cannot achieve an optimal solution to matching subtopic structures.
 Jaccard measure, the Dice measure and the Overlap measure), the Cosine measure performs best over all three metrics on the DUC2005 dataset, and it achieves the highest AverageP value and comparable P @5 and P @10 values with the Jaccard measure and the Dice measure on the TDT3 dataset. The Overlap measure per-forms worst on both datasets. The results validate that the Cosine measure is one of the state-of-the-art measures for evaluating document topical similarity. guage model measure (LM) achieve high performances better than or compara-ble with the Cosine measure. For the three measures derived from retrieval func-tions, the BM25 measure and the PivotedVSM measure perform poorly while the language model measure achieves comparatively high performances. This result shows that measuring the similarity between full documents is different from mea-suring the similarity between a short query and a full document, as in the key-word search in TREC experiments. The query of a full document is different from the relatively short query in that the full document contains more redundant and ambiguous information and even greater noise effects stemmed from the presence of a large number of words unrelated to the overall topic in the document. 4.4 User study for evaluating structural similarity documents for a given query document, so we perform a user study for further evaluating the structural similarity between the query document and the retrieved topically similar documents.
 DUC2005 dataset and recorded for each query the top five topically similar docu-ments retrieved based on the similarity measures. Then subjects were employed to evaluate the structural similarity between the query document and each of the five returned documents. In order to evaluate the proposed overall structural similarity measure (OM + TO + DF), we employed the text order factor and the disturbing factor plus the optimal matching factor to rerank the top 10 topically similar doc-uments retrieved by the optimal matching measure (OM), and then like for other similarity measures, each of the top five documents and the query document were assessed by subjects. Because subjective evaluation was time-consuming, we did not evaluate all topical similarity measures mentioned above and chose only sev-eral representative measures for comparison, including the Cosine measure, the information theoretic measure and the language model measure.
 larity between the query document and the five topically similar documents. The document pair of the query document and each of the top retrieved documents was presented to the subjects. The five subjects were required to express an opin-ion for each pair of documents to further evaluate their similarity, the opinion over a 5-point scale, where 1 stood for  X  X ot at all similar X , 3 for  X  X omewhat similar X , and 5 for  X  X xtremely similar X . Then, we collected their responses and averaged the points for comparison. Tables 3 and 4 show the averaged points across the five subjects and the five topically similar documents on the TDT3 dataset and the DUC2005 dataset, respectively. The last columns in Tables 3 and 4 correspond to the averaged points across the 10 topics.
 structural similarity measure (OM + TO + DF) can retrieve highly similar docu-ments from the topically similar documents, and it significantly outperforms the Cosine measure ( t -test: p -values &lt; 0.02 on both datasets), the information theo-retic measure ( t -test: p -values &lt; 0.05 on both datasets) and the language model measure ( t -test: p -values &lt; 0.02 on both datasets) on both datasets. The sequen-tial matching measure performs worst. We also observe that the optimal match-ing measure (OM) significantly outperforms the Cosine measure, the information theoretic measure, the language model measure and the two baseline structural similarity measures (all p -values &lt; 0.05 for t -test), which demonstrates that the optimal matching is of great importance to evaluate document structural similar-ity. We can explain the results by that the sequential matching is largely dependent on an unreasonable assumption that two documents have the same subtopic struc-ture, and the greedy matching can only reach a local optimum, while the optimal matching can attain a global optimum. We can also find that the text order factor and the disturbing factor do improve the performance because the proposed over-all measure (OM + TO + DF) outperforms the optimal matching measure ( t -test: p -values &lt; 0.05 on both datasets). 5 Discussion The proposed similarity measure has several potential advantages in contrast to traditional similarity measures. First, it is more convenient to the users to acquire the pairs of similar passages in the retrieved documents and the query document. For example, when evaluating the similarity of transcript texts, which are consec-utive and there are no clear indications of discrete parts, or books and chapters with long texts, it is convenient to present the pairs of similar passages to the users and they would understand the text similarity easily and intuitively. Second, the proposed measure can ignore noisy passages in the documents by solving the op-timal matching problem and it might benefit the evaluation performance. Third, the proposed measure can avoid the difficulties of document length normaliza-tion by partial matching between passages. Finally, the proposed measure takes into account the sequential order of text passages by incorporating the text order factor.
 if two documents are both short, the proposed measure will be degenerated into the Cosine measure, and if one document is short and the other document is long, the proposed measure will take a risk to measure the short document to only one of the passages of the long document. plexity than the Cosine measure, which is largely due to the algorithm to solve the optimal matching problem. We can address this problem in the following two ways: on the one side, we can employ faster algorithms to solve the optimal match-ing problem; on the other side, we can use the Cosine measure to retrieve a can-didate set of topically similar documents, and then use the proposed measure to rerank the documents in the small document set. The reduction of the set of docu-ments will make the retrieval process much more efficient. 6 Conclusion and future work We have proposed the concept of document structural similarity and designed a measure to evaluate the structural similarity between documents. The structural similarity can further measure document similarity beyond the traditional topical similarity based only on the  X  X ag of words X  representation. The results obtained from the experiments demonstrate the high performance of the proposed optimal matching measure for evaluating document topical similarity, which is as well as or better than most popular measures. The user study shows the better ability of the proposed structural similarity measure with OM, TO and DF factors to further find highly similar documents from those topically similar documents than that of the popular topical measures and other baseline structural similarity measures. uating both topical similarity and structural similarity between documents. Note that the optimal matching allows one passage in a document to be matched to only one passage in the other document, i.e., it allows only a one-to-one match-ing between passages. In future work, we will investigate allowing many-to-many matching between passages under strict constraints.
 study. In future work, a more comprehensive and large-scaled user study will be preformed to draw more solid conclusions.
 References Author Biography
