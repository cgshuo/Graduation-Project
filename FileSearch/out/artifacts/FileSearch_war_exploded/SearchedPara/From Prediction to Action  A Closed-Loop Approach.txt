 Machine learning methods have been widely used in mod-eling and predicting network user experience. In this pa-per, moving beyond user experience prediction, we propose a closed-loop approach that uses data-generated prediction models to explicitly guide resource allocation for user experi-ence improvement. The closed-loop approach leverages and verifies the causal relation that often exists between certain feature values (e.g., bandwidth) and user experience in com-puter networks. The approach consists of three components: we train a neural network classifier to predict user experi-ence, utilize the trained neural network classifier as the ob-jective function to allocate network resource, and then eval-uate user experience with allocated resource to (in)validate and adjust the original model. Specifically, we propose a dual decomposition algorithm to solve the neural network-based resource optimization problem, which is complex and non-convex. We further develop an iterative mechanism for classifier optimization. Numerical results show that the dual algorithm reduces the expected number of unsatisfied users by up to 2x compared with the baseline, and the optimized classifier further improves the performance by 50%. Classification; Resource Optimization; Computer Networks
Based on network measurement and user behavior data, much recent research focuses on modeling and predicting us-er experience in computer networks using machine learning techniques, e.g., [1, 16, 6, 2, 10]. However, while it provides important insights, user experience prediction itself is usu-ally not the ultimate goal in networks. Ideally, a network could identify users with poor experience and take proper actions proactively to improve their experience (e.g., by al-locating additional bandwidth to selected users). Thus, we are facing a natural problem: given limited resources, how should we allocate them to multiple users to optimize the overall experience?
To answer this question, we advocate a closed-loop ap-proach that uses data-generated prediction models to ex-plicitly guide resource allocation for user experience opti-mization. This approach is illustrated in Fig. 1. Figure 1: A closed-loop framework in data-driven resource allocation.

First, we start with a historical dataset with labeled user experience and the corresponding feature values (including network performance metrics). Based on the data, we con-struct an appropriate user experience prediction model to reflect the correlation between feature values and user ex-perience. Then, we feed the constructed prediction model into the resource allocation component as the objective func-tion to optimize resource allocation for users based on their real time feature values (network metrics). The output is an appropriate resource allocation and users with improved feature values. Last, the evaluation and data sampling com-ponent samples data after resource allocation, validates or invalidates the model, and adjusts the constructed predic-tion model as needed.

In this framework, we leverage existing machine learning methods for user experience prediction. Specifically, in this paper, we use the neural network prediction model. We focus on the resource allocation algorithms for the trained model (Sec. 4) and how to adjust the classification model based on evaluating resource allocation results to further improve performance (Sec. 5).

The proposed framework has two benefits. First, the con-structed classifier illustrates a quantitative relationship be-tween the feature values and the user experience. Using such a quantitative relationship and domain knowledge, we are able to allocate network resources more precisely to re-duce the expected number of users with poor experience, in contrast to the typical approach of using abstract utili-ty functions for resource allocation. Second, the framework includes an evaluation component, where users are sampled after resource allocation to validate or invalidate the causal relationship hypothesis between the feature values and the user experience. This step also provides further opportu-nities to adjust the constructed prediction model, which is shown to be highly beneficial.

The proposed framework has several challenges. First, it is typically more challenging to optimize resource allocation based on prediction models derived from real data than to use utility functions with nice properties such as convexi-ty [18, 8]. In our work, the neural network model generates a complicated function, requiring us to solve a non-convex and complex optimization problem. Second, choosing the best classifier is difficult for the following reasons: 1) The objective of the classifier is not to best classify all data sam-ples, but to best guide resource allocation to improve user experience with respect to ground truth; and 2) resource allocation inevitably modifies the distribution of the users, making the best classifier a moving target.

In this paper, we present a holistic solution using the closed-loop framework in data-driven resource allocation. Specifically, we make the following contributions:
The framework of data-guided resource allocation is first proposed in our previous work [3] that includes the classifier construction and resource allocation components. In [3], we utilize a logistic regression classifier learned on labeled data to guide resource allocation on unlabeled data. In compar-ison, in this paper, we consider the neural network model, which is more general, yet more challenging when used as the objective function for resource allocation. More impor-tantly, we study the closed-loop approach that allows us to evaluate the impact of resource allocation and to select a better classifier, which are critical, yet not considered earli-er.

User experience has been studied extensively recent years [1, 16, 6, 2, 10]. In [1], the authors use a month-long anony-mous data collected from a cellular network provider to s-tudy Quality of Experience (QoE) metrics including session length, abandonment rate, and partial download ratio. The relation between mobile video streaming performance and user engagement from the perspective of network operators is discussed in [16]. Using 27 TB video streaming traffic from more than 37 million flows, the authors observe strong cor-relations between many network features and abandonment or skip rates.

A large body of literature considers learning-based cost-efficient decision making in other applications. For example, [9] discusses a high-level pipeline of data collection, predic-tive model, and decision analysis. Specific combinations of prediction and actions have been proposed in many areas, such as clinical treatment [4] and route planning [20, 19, 14]. Certain preliminary studies have combined learning and re-source allocation in data center networks [11, 5].
Network Utility Maximization (NUM) has been extensive-ly studied, e.g., in [12, 7, 8, 21, 22, 23]. The difference be-tween our work and their work lies in three aspects: 1) Our utility function is learned from real datasets, and thus is more complicated; 2) Our problem includes multiple type-s of resources, which makes the problem more challenging; 3) We consider a closed-loop approach that optimizes the utility function based on the feedback from the real system.
In this section, we first present the notation used in this paper, including the neural network classifier. Furthermore, we discuss the research questions and introduce a baseline algorithm for resource allocation.
Consider users in a D -dimensional feature space, i.e., for user i ,wehave where x i,d is the value of feature d ( d =1 , 2 , ..., D ), and theconstantfeaturewithvalue1isincludedfortheeaseof notation. Eachuserisassociatedwithalabel y i ,whichis either positive (a user with poor experience) or negative .
There are K types of resources, and the resources allocat-ed to user i are denoted by We assume that the relationship between the allocated re-sources and the change of feature values is captured by a function g (  X  ). Given r i amount of resources, user i has its feature vector updated to Domain knowledge plays a significant role here in decid-ing the function g (  X  ). In computer networks, such domain knowledge typically exists, e.g., how bandwidth or transmis-sion power allocation affects users X  throughput. Such do-main knowledge is widely used in current network resource allocation schemes.

Clearly, not all feature values can be altered through re-source allocation. For example, the device type is a static feature that does not change regardless of network resource allocation. We focus on the subset of features, named con-trollable features, whose values can be altered by resource allocation. The term  X  X esource allocation X  refers to general actions that a network can take (potentially in cooperation with users/content providers). Examples include bandwidth allocation, frequency allocation, transmission power alloca-tion, device reconnection, increasing buffering (e.g., for video streaming), content prefetching or caching, selecting multi-ple networks/interfaces, processing power allocation (e.g., in a cloudlet setting), etc. Note that the resources could be new types of resources that are not used yet by the system, or additional resources. For instance, in wireless communi-cations users have already been allocated with bandwidth. Additional bandwidth could be reserved to serve the poten-tially unsatisfied customers.

We note that it is highly likely that network resource al-location could only improve user experience of certain users, but not all. The problem formulation here applies to the case where resources are scarce. When the resources are unlimited, then likely the user experience is constrained by other factors, and could not be solved by network resource allocation.
In the classifier construction component, the network s-tarts with a set of samples with user experience labels. The objective is to model the relationship between feature val-ues and the corresponding labels. Different classifiers can be adopted in the proposed framework, such as logistic regres-sion [3], random forests and neural networks, depending on the application scenarios.

We consider a neural network with three layers: input layer, hidden layer and output layer. A three-layer neural network can be realized by a two-layer logistic regression.
Let w =[ w 0 ,w 1 ,w 2 , ..., w D ] T be the weights of a logistic regression model. Then, the likelihood of instance x being positive is
Let H be the number of hidden neural nodes in the hidden layer, and w 1 , w 2 ,..., w H be the corresponding weights from input features to the hidden nodes. The weight vector from the hidden nodes to the output node is denoted by w 0 = [ w the parameters that need to be learned from the training data.

Given the trained neural network classifier f (  X  ), the like-lihood of x being positive is In this paper, we study the following two questions: 1) Given a classifier, how to allocate resources to the instances in order to reduce the expected number of positives? 2) How to improve the learned classifier by incorporating new samples?
The first question implicitly hypothesizes a causal rela-tionship between feature values and user experience, in which case, allocating resources to change feature values would im-prove user experience. We can first establish this relation-ship by using domain knowledge. For example, according to domain knowledge, user experience improves with increased bandwidth allocation. Then we can further validate or in-validate this causal relationship by the evaluation and da-ta sampling component. We can see that the causal rela-tionship diminishes after a certain threshold, as shown in one of the evaluations (This is partially captured by user side resource constraints in Eq. (8)). This closed-loop ap-proach enables the practical application of data-driven re-source allocation. It also addresses a drawback in the tra-ditional abstract-utility-function-based resource allocation, where the causal relationship is not evaluated, but taken for granted.

With a learned classifier, a typical baseline algorithm al-locates available resources as follows: in runtime, one first uses the learned classifier to predict the labels of the user-s. Then it allocates resources evenly among the predicted positives. In other words, the baseline algorithm uses the prediction model along with its trained weights to gener-ate the prediction results (i.e., positives and negatives), and then allocates resources based on the predictions. Note that the learned classifier identifies a quantitative relationship between the network performance metrics and user experi-ence. However, this information is ignored in the resource allocation step in the baseline algorithm.

By contrast, we explicitly use the quantitative relation-ship captured by the trained classifier (i.e., Eq. (5)): We incorporate the information in the resource optimization ob-jective functions (Sec. 4). Numerical results show that our proposed framework significantly improves the performance, because it explicitly leverages the quantitative relationship to allocate resources to users.

The above approach raises the question of what a good classifier should be. We note that : 1) The objective of the classifier is not to best classify all data samples, but to best guide resource allocation in order to improve user experience with respect to the ground truth; and 2) resource allocation inevitably modifies the user distribution, and thus changes the best classifier. Therefore, we need to adapt the classifier to better quantify the relationship in the targeted regions, where users are distributed as the result of resource allocation. We study how to select such a classifier in Sec. 5.
In this section, we consider resource allocation based on a neural network model learned from the training data. We start with the problem formulation, and then propose a dual algorithm to obtain a proper solution. Finally, based on the intuition obtained from the dual algorithm, we propose a Goal algorithm with lower complexity.
Assume there are M users in the system, and the overall available resources are R  X  R K  X  1 . Given the classifier f ( the multi-user resource optimization problem is formulated as where R is the total available resource for all users, and is the allocatable resource space for user i . Note that can be continuous, discrete, or hybrid. For example, user i  X  X  allocatable bandwidth is bounded by the his/her network condition and data requirement. We also note that we can include artificial bounds here so that the model is reason-ably valid within the bound, in order to address the issue of diminishing causal relationship, as discussed in Sec. 3.3.
This objective function is non-convex and complex be-cause of the nature of neural networks. It is difficult, if not impossible, to solve this problem efficiently by gradient-based numerical methods. Therefore, we propose an algo-rithm that solves this problem approximately in Sec. 4.2. The idea is to decompose the Lagrangian of the optimiza-tion problem into individual sub-problems. The Lagrangian multiplier serves as a signal that coordinates users to ap-proach to the global optimal solution.
The dual algorithm is based on dual decomposition. First, the dual algorithm determines a proper Lagrangian multi-plier by solving the dual problem approximately. Then, in-dividual users use the Lagrangian multiplier to maximize their own utilities in a distributed manner.

Since x i is given for each user i , for the ease of notation, denote f ( g ( x i , r i )) by f i ( r i ). The Lagrangian of (P-0) is L ( r 1 , r 2 ,  X  X  X  , r M ,  X  )= M i =1 f i ( r i )+  X  T ( where  X   X  R K  X  1 is the Lagrangian Multiplier (LM). The dual problem of (P-0) is where Typically,  X  is interpreted as the prices of the K types of resources, and  X  T r i is the cost of user i  X  X  resource consump-tion r i .Asshownin (D-i ) ,given  X  ,eachuser i minimizes its own positive likelihood plus the cost of resource con-sumption separately. Intuitively, when the cost of resource k increases, a user tends to reduce the consumption of re-source k . We discuss how to obtain the optimal solution for problem (D-i ) , denoted by r i  X  (  X  ), in Sec. 4.3. Note that (D-i ) may have more than one optimal solutions.
Denote one of the optimal LM-s by  X   X  ,i.e.,
Dual algorithm first finds the optimal LM  X   X  ,andthen allocates resources to users based on  X   X  , subject to the re-source constraints. When the system has only one type of resource, binary search is used to find  X   X  efficiently, because the resource consumed is a monotonically non-increasing function of the price  X  .

When there are multiple types of resources, we use a sub-gradient method to update  X  , as shown in Algorithm 1. For agiven  X  ( t ), we obtain the solution r  X  i (  X  ( t )) for problem (D-i ) , and denote r need as total resources consumed by user-s. Note that R  X  M i =1 r  X  i (  X  ( t )) is one of the subgradients, we update the LM as follows (in Lines 3 to 4): where the step size a ( t ) should satisfy the following condi-tions [12], For instance, we can choose a ( t )as  X /t for some positive constant  X  . After achieving the optimal LM  X   X  , resources are allocated in an arbitrary order, as shown in Algorithm 1 (Lines7to10).
 Algorithm 1: Dual Algorithm
Input : positive likelihood function
Output : r 1 p , r 2 p ,  X  X  X  , r M p 1 while  X  ( t +1)  X   X  ( t )  X   X  do 2 r i  X  = arg min r i f i ( r i )+  X  ( t ) r i s.t. r i  X  R 4  X  ( t +1)=  X  ( t )  X  a ( t )( R  X  r need ) 5end 6  X   X  =  X  ( t +1); 7for user i do 8 r i p = arg min r i f i ( r i )+  X   X  r i (See Sec. 4.3) 9 Update available resource: R = R  X  r i p ; 10 end
Since (P-0) is non-convex, the gap between the primal problem (P-0) and the dual problem (D-0) is not necessar-ily zero. Therefore, the optimal solution for the dual prob-lem may not be the optimal solution for the primal problem. However, recent advances [21, 22, 23] on optimization with separable objectives show the duality gap is bounded as the number of users increases.
When (D-i ) is convex, we can use the gradient-based method to find the optimal resource allocation for each indi-vidual user efficiently. If the utility function is non-convex, but simple, we can develop heuristics. In this paper, we con-sider the case where the utility function is both non-convex and complex, but the number of resource types is limited. In this case, we can use exhaustive search to obtain an ap-proximate solution.

Considering the feasible solution set R i of user i , assume for resource k , the allocated resource is bounded by R max If the step size for this type of resource is  X  k ,thenum-ber of searches performed will be t k = R max i,k /  X  k . There-fore, considering K types of resources, the overall number of searches is K k =1 t k . The best among the K k =1 t k dates is chosen as the resource allocation solution for user i .

Denote the partial derivative of g ( x , r ) on variable r g d,k -s, where k is the resource index and d is the feature index. We have the following lemma to decide a proper step size for the exhaustive search.

Lemma 1. When the step size of the exhaustive search is chosen as
 X  for resource k , the best solution found by the exhaustive search is at least  X  -suboptimal.

Proof. Suppose  X  : R n  X  1  X  R m  X  1 , and let x  X  ( x ) denote the derivative of  X  at x , which is a m  X  n matrix. According to the chain rule, we have Since x f ( x )=  X  ( w 0 , [  X  ( w 1 , x ) , X  ( w 2 , x ) , ...,  X  ( [  X  ( w 1 , x ) , X  ( w 2 , x ) , ...,  X  ( w H , x )][ w 0 , 1 w , and |  X  (  X  ) | &lt; 1 4 ,wehave
Assume the optimal solution is r  X  , then the exhaustive search covers at least one r that satisfies Therefore, we have i.e., r is a  X -suboptimal solution.

Note that when R i is discrete, we can try all candidates and select the best.
The dual algorithm may require a large number of iter-ations to find the optimal LM. Here, we propose a Goal algorithm with much lower complexity, inspired by the intu-ition of the dual algorithm, i.e., users close to the boundary area are allocated with resources with higher priority.
The dual algorithm decomposes the resource allocation a-mong users by introducing the prices of resources. In this part, we propose the Goal algorithm with low complexity to decompose the multi-user optimization problem. First of all, we define a goal v  X  (0 , 1) for the users. Basically, the best v can be found by testing the candidate numbers in the interval (0 , 1) with a small step size. For the user-s whose positive probability is larger than v ,wecalculate the minimal total resource needed for them to achieve the v . Note that the less total resource needed, the more effi-cient it is to allocate resources to this user. Therefore, the resources are allocated in a non-decreasing order of required resources. This algorithm has much lower complexity since no iteration is needed. However, the weakness is that all types of resources are treated equally, which does not reflect the different scarcities of resources.

We will compare the dual algorithm, the Goal algorithm, as well as the baseline (discussed in Sec. 3.3), in Sec. 6.
In the proposed framework, the  X  X valuation &amp; Data Sam-pling X  component plays two important roles. First, it allows us to validate or invalidate the causal relationship hypothe-sized in Sec. 4. Specifically, similar to the idea of random-ized test, if we see improved user experience after resource allocation, we validate the causal relationship between the network performance metrics and user experience. Second,
Figure 2: The necessity of classifier optimization. it allows us to further collect data samples and to adjust the constructed classifier. Specifically, the resource allocation scheme inevitably modifies the distributions of user perfor-mance metrics, and new samples may appear in regions with few or no existing samples. Thus, the original constructed classifier needs to be adjusted.

Consider the following illustrative example, where posi-tives ( X + X ) and negatives ( X - X ) are distributed in a 2D space in Fig. 2. Given this dataset, the best classifier learned from the existing positives and negatives could be a line in the middle. This classifier separates positives and negatives nicely and would be considered optimal under certain accu-racy metrics. Based on this classifier, resources are allocat-ed, where a subset of positives are moved to the boundary area, shown as  X  X  X . All these moved points are negative ac-cording to the linear classifier. However, the ground truth of these points turns out to be positive and the resource al-location reduces no positives. This is because the original dataset has no instance in the boundary area, and thus a lot of prediction errors occur in this area. Therefore, the feed-back from resource allocation is necessary to obtain a better classifier that pays more attention to the targeted area of the resource allocation.

In this section, we study the issue of classifier optimiza-tion. We first discuss the desirable properties of a good classifier and then propose an iterative method to obtain a good classifier.
We note that the goal of the classifier optimization here is different from that of the traditional classifier. Tradition-ally, the goal of the classifier is to maximize accuracy in predicting user labels. In contrast, the goal of the classifier here is to best guide resource allocation with respect to the ground truth. In particular, it needs to better quanti-fy the relationship in the targeted region: where users are distributed as the result of resource allocation.
Specifically, denote the ground truth by a function G ( x representing the positive probability for a given feature vec-tor x . The set of classifiers that can be expressed by a certain machine learning method (e.g. logistic regression, neural networks) is denoted by F . Then, the task is to find the optimal f  X  within F such that 0) . If we know the ground truth G ( x ), we can find the optimal f  X  by optimizing (P-1) .However, G (  X  ) is unknown and thus we need to approximate it based on the sampled data.

We are facing a problem of improving a classifier given cer-tain historical data and opportunities to sample more data. Techniques from active learning can be leveraged to solve this problem. However, existing active learning algorithms are mainly accuracy-centric, i.e., targeting at improving the prediction accuracy. In contrast, user experience-guided re-source allocation aims to improve the user experience and is usually more sensitive to the model accuracy of the targeted area of the resource allocation. Emphasis on the targeted area will be helpful for improving user experience. Moreover, a learning model tries to minimize the total loss function over all training samples, and thus the distribution of train-ing data will affect the trained model. In traditional active learning, either streaming-based or pool-based learning, the accuracy is measured under a certain  X  X atural X  distribution that does not change. In comparison, our resource alloca-tion schemes change the distribution, and thus, the  X  X est X  model becomes a moving target and much more difficult to obtain.

This problem also inherently requires an exploration v.s. exploitation tradeoff, where we need to balance between op-timizing the user experience based on the learned classifier (exploitation) and improving the classifier by sampling more data (exploration). However, the feature space is typically huge and exploring all this space to obtain an accurate clas-sifier will result in a large cost as noted in [17].
In practice, the problem is usually most sensitive to the targeted area of the resource allocation. Thus, a classifi-er that pays more attention to the points in the targeted area may be sufficient for improving the resource allocation performance. This principle motivates the design of the fol-lowing iterative classifier optimization mechanism. Algorithm 2: Iterative Classifier Optimization Input : Initial classifier f 0 , iteration number T
Output : The best classifier f  X  1 t =0; 2 while t  X  T do 3 Allocate resources based on classifier f t using the 4 Construct a new training data by sampling the 5 Train an updated classifier f t +1 based on the new 6 t = t +1; 7end 8 Choose f  X  from [ f 0 ,f 1 ,f 2 , ..., f T ], based on performance evaluation.

We propose an iterative algorithm to improve the classi-fier by taking into account the new samples after resource allocation. As shown in Algorithm 2, we adjust the classifier by utilizing the points after resource allocation. There are different ways of utilizing the historical data, with different emphases on the original data and the data after resource allocation. Specifically, the sampling method in Line 4 de-fines a sampling rate p (  X ,r flag ) for each historical instance. p (  X ,r flag ) is a function of two parameters: the iteration in-dex  X  and the instance type flag r flag ( r flag = 1 for an instance with allocated resource, r flag = 0 for others). In-tuitively, p (  X ,r flag ) should give more emphasis on the most recent instances and instances with allocated resource. In the following, we list four sampling heuristics to achieve this goal to different degrees: (1) Sample all the historical data, i.e, p (  X ,r flag )=1for (2) Sample data only from the last iteration, i.e, p ( t  X  (3) Sample all historical data with allocated resource (moved (4) Sample all historical data with allocated resource (moved In (1), the data from all past iterations are used as training data; In (2), only the data in the last iteration are considered as training data; Both (3) and (4) contain all historically moved data, and they differ in whether the non-moved data in the last iteration are included or not. The obtained T +1 classifiers may not get improved every single iteration based on evaluation, and there could be oscillations. However, the algorithm keeps tracing the performance of classifiers for all iterations and chooses the best from the T + 1 candidates. Depending on different applications and different distribu-tions of the data, some sampling methods may outperform the others, as shown in Sec. 6.1.

Note that instead of fixing the iteration number T ,we can also use some other criteria as the stop condition. For example, stop searching when the performance is no longer increasing for the last T iterations.
In this section, we test the performances of the designed algorithms based on datasets with ground truth. Experi-ments in our work are different from traditional machine learning experiments, where training data are used to learn a model and test data are used to evaluate the performance. This is because in this framework, we need to get the labels for the instances with allocated resource, and these instances probably are not contained by the original training or test data. 1 Therefore, we need ground truth to label new in-stances.

Using the experiments, we hope to answer two questions: 1) Based on the initial classifier, how efficient is the resource optimization? 2) Based on the ground truth, how efficient is the classifier optimization?
In this part, we consider 2000 points distributed evenly in a two-dimensional square [  X  20 , 20]  X  [  X  20 , 20]. There are 12 cases with ground truth shown in Table 1. In experiments 1 X 6, we assume the ground truth is deterministic, i.e., given alocation[ x 1 ,x 2 ], its probability to be positive is either 0 or 1. In experiments 7 X 12, the ground truth is probabilistic.
Even though they are contained in the original dataset, labeling new instances based on the past data may not reflect the ground truth. (d) Exp4 (j) Exp10 We also illustrate the distributions of positives and negatives in Fig. 3.

We assume there are two types of resources that can be utilized to change feature values (and thus their locations in the 2D space). We assume i.e., one unit of resource 1 and 2 increases feature 1 (x-axis) and 2 (y-axis) by one unit, respectively. The trained neural network classifiers have 5 neurons in the hidden layer.
The resource allocation results are given in Table 2. For each experiment, we check three different combinations of resources, as shown by columns  X  X 1 X  and  X  X 2 X . Columns  X  X ual(C) X ,  X  X oal (C) X  and  X  X aseline (C) X  show the reduced positives of the resource allocation algorithms as well as the baseline according to the initially learned classifier. Since the classifier is not the ground truth, the results can be over-optimistic or under-optimistic. Columns  X  X ual(G) X ,  X  X oal (G) X  and  X  X aseline (G) X  show the reduced positives of the resource allocation algorithms as well as the baseline accord-ing to the ground truth. The last four columns  X  X 1 X ,  X  X 2 X ,  X  X 3 X  and  X  X 4 X  give the results of the dual algorithm based on the optimized classifiers using the four sampling meth-ods presented in Sec. 5.2. The one that achieves the best performance is made bold.

Comparing columns  X  X ual(C) X ,  X  X oal (C) X  and  X  X aseline (C) X , we can see the dual algorithm outperforms the base-line by almost one order of magnitude, especially when the available resources are scarce (100, 100). In certain cases, the Goal algorithm can have a similar performance with the dual algorithm. However, there are also cases where the du-al algorithm outperforms the Goal algorithm by more than 20%. Note that these three columns are based on the initial classifier, which is not the ground truth. Therefore, the re-sults only show the efficiency of the optimization algorithm.
Columns  X  X ual(G) X ,  X  X oal (G) X  and  X  X aseline (G) X  are based on ground truth. The dual algorithm also outper-forms the baseline by almost one order of magnitude. In a few experiments, the dual algorithm is outperformed by the Goal algorithm. This is due to the mismatch between the initial classifier and the ground truth. When the initial classifier is biased, optimization based on it could lead to poor performance. As shown by  X  X 6.1 X , the dual algorithm according to the initial classifier reduces 58.88 positives, but actually only reduces 10 positives with respect to the ground truth.

Comparing column  X  X ual(G) X  with columns  X  X 1 X ,  X  X 2 X ,  X  X 3 X  and  X  X 4 X , we can see the benefits of classifier optimiza-tion. In  X  X 4.1 X ,  X  X 4.2 X ,  X  X 6.1 X  and  X  X 9.2 X , the optimized classifier reduces at least 2x positives compared with the ini-tial classifier. In  X  X 3.1 X ,  X  X 4.3 X ,  X  X 6.2 X ,  X  X 8.1 X ,  X  X 9.3 X  and  X  X 10.1 X , more than 50% gain is achieved by the optimized classifier. Among the four sampling methods,  X  X 1 X  gener-ally performs well, although occasionally achieves slightly smaller gain compared to the best of the four.

When the boundaries between positives v.s. negatives are non-linear and complex, it is difficult for the initial classi-fier to represent the boundaries well. Thus, the evaluated performance according to the initial classifier could be very different from the evaluated performance according to the ground truth, e.g,  X  X 4 X ,  X  X 5 X ,  X  X 6 X  and  X  X 9 X . In this case, the gain of classifier optimization is usually larger.
From properly conducted controlled experiments, we can study the causal relation between features and correspond-ing labels. In the following, we introduce two datasets col-lected from controlled experiments. Both datasets are avail-able online. We first construct ground truth using statisti-cal analysis on the collected data. Then the ground truth is used to label new instances. We know in a real system, the ground truth is typically not available. However, this method enables us to evaluate the proposed mechanisms.
The first dataset comes from experiments conducted in [13]. The goal of this experiment is to study the effect of network features on user experience for video services. The dataset contains 8 original videos and 8  X  5 streamed videos. The streamed videos are the original videos transmitted over a limited network bandwidth. Each video is viewed and subjectively scored by 30 viewers. Therefore the dataset in-cludes 240 views of the original videos and 1200 views of the streamed videos. Each view is associated with a MOS (Mean Opinion Score) given by the subject. MOS, a score from 1 to 5, is a subject measurement of user experience in many applications. For each view, it has two features: the bandwidth used to transmit the video ( x 1 ) and the viewer X  X  preference ( x 2 ). The bandwidth has 5 discrete values: 0.5, 1, 2, 3 and 5 Mb/s. A viewer X  X  preference is the score the viewer gives to the original video. The preferences are re-lated to the video contents and video quality but not any network features. In the dataset, all preferences are larger than 1, and the histogram is shown in Fig. 4(a). With a lin-ear regression, we have the following estimation of the pdf of user preferences,
We assume that when MOS  X  3, the viewer is unsatisfied with the viewed video and thus a positive instance. Other-wise, the viewer is satisfied and thus a negative instance. In Fig. 4(b), we show the effect of bandwidth and user prefer-ence on positive ratios. When the bandwidth is less than 2.5 Mbps, the users are unsatisfied with probability 1. When the bandwidth is greater than 2.5 Mbps, whether a user is satis-fied or not depends on the user preference, and the relation is almost linear. Therefore, the ground truth we generate Figure 5: Resource vs Reduced Positives (Video MOS). from the dataset as where 1 (  X  ) is the indicator function.

We consider 2000 users in the system, with each user watching one video. The user preference is generated ac-cording to the distribution given by Eq. (24), and the band-width received is assumed to be Gaussian distributed with mean 2.5 Mbps and standard deviation 0.5 Mbps. The clas-sifier we consider is a neural network with 5 neurons in the hidden layer.

The resource allocated is (additional) bandwidth, and one unit of bandwidth increases the value of feature 1 by one unit. Resource allocation results are shown in Fig. 5. We compare the dual algorithm with the baseline, under the ini-tial classifier ( X  X  X ) and ground truth ( X  X  X ), as well as with the best classifier from the four sampling methods. Each sampling method outputs an optimized classifier, and the best among the four is chosen. In Fig. 5, we change the available bandwidth from 50 to 1600 Mbps. Blue curves show the performance of the baseline according to the ini-tial classifier (w/ ) and the ground truth (w/  X  ). Red curves show the performance of the dual algorithm accord-ing to the initial classifier (w/  X  )and the ground truth (w/ ). The dual algorithm achieves at least 2x performance gain compared with the baseline when the available band-width resource is less than 400 Mbps. When the resource allocation is based on the optimized classifier (green curve, w/ ), the reduced number of positives is further improved by 50%. When the resource is over 800 Mbps, the gap be-tween the actual performance (based on the ground truth) and the predicted performance (based on the initial classi-fier) becomes much larger. This demonstrates the necessity of classifier optimization.
In dataset [15], the authors conducted controlled experi-ments to study the relation between bandwidth and user ex-perience for web browsing. The dataset contains 572 MOS values for users who surfed four types of web sites. After removing the instances with insufficient data, we have 418 valid instances. We assume when the MOS  X  3, the user is unsatisfied, i.e., a positive instance.

From the dataset, we find that the positive ratio goes down linearly with the logarithm of bandwidth, as shown in Fig. 6. Therefore we assume the ground truth in this dataset is
We generate 10,000 users whose bandwidth is Gaussian distributed with mean 512 kbps and standard deviation 128 kbps. The neural network classifiers we considered have two neurons in the hidden layer.

Additional bandwidth is the available resource we can al-locate to users, and one unit of bandwidth increases the feature by one unit. Resource allocation results are shown in Fig. 7. When the available resource is larger than 10,000 kbps, the gain increases exponentially. The reason is that the positive probability is relatively low in this dataset, and the learned classifier can only pick up a few positives with high true positive rate. Since the baseline only allocates bandwidth to predicted positives, which are a small por-tion of real positives, the reduced positives stop increasing when the resource is sufficient. The dual algorithm takes the learned classifier as the objective function for resource optimization, and therefore it does not suffer from this is-sue. It is also shown by the figure that the initial classifier is over-optimistic compared with the ground truth. In this dataset, the gain of the optimized classifier over the initial classifier is limited.
The proposed algorithms can handle cases with a large number of features. However, if there are many types of resources to allocate, it will be expensive to use exhaus-tive search to find individual optimum. Therefore, our al-gorithms are suitable to the scenarios where the number of resource types is small, which is usually the case in computer networks.

Most existing resource allocation mechanisms rely on do-main knowledge to decide resource allocation. The proposed framework provides an alternative way of resource alloca-tion, and can be used to augment existing mechanisms. If user experience is the ultimate goal, collecting user experi-ence data is a necessary step. Sometimes, user experience data comes naturally (e.g., user call complains [3]), and oth-er times, one needs to collect user experience data (e.g., video MOS scores). Once such data collection exists, one is able to build a model offline and adjust the model period-ically. The classifier optimization algorithm needs to train multiple classifiers iteratively based on the feedback of re-source allocation. In computer networks, the feedback of re-source allocation may often be obtained quickly. Therefore, the classifier optimization could obtain a good classifier in a relatively short amount of time, which makes the closed-loop framework practical.

When adjusting the classifier, we only use heuristic algo-rithms to sample the historical data, including the original data and the data with allocated resource. However, there is still a lack of knowledge about the areas that are neither covered by original data set nor the targeted data set. This lack of information may make the learned classifier inaccu-rate and result in suboptimal resource allocation. Therefore, from a long term perspective, we may need to temporally apply a suboptimal resource allocation scheme to explore those areas. This will require an appropriate exploration-exploitation tradeoff and will be investigated in the future.
There is a tradeoff between maximizing efficiency and guaranteeing fairness. As our algorithms tend to focus on the users whose experience can be improved with the least amount of resources, the fairness among users could deteri-orate. In the future, we will consider the balance between efficiency and fairness.
In this paper, we propose a closed loop approach to the data-driven resource allocation problem where the objective is to minimize the number of positives based on neural net-works. We consider a novel framework, where the classifier learned by machine learning is utilized as the objective func-tion in resource allocation, and the classifier is further opti-mized based on post-allocation evaluation and feedback. We design a dual algorithm to coordinate the resource allocation among users, and a classifier optimization algorithm to find the most proper neural network classifier. Experiments us-ing synthetic data and real data from computer networks show our algorithms can reduce the expected number of un-satisfied users by up to 2x compared with the baseline, while the classifier optimization further improves the performance by 50%. This work was partially supported by NSF through grants CNS-1547461; CNS-1457060; CCF-1423542. [1] A. Balachandran, V. Aggarwal, E. Halepovic, J. Pang, [2] A. Balachandran, V. Sekar, A. Akella, S. Seshan, [3] Y. Bao, X. Liu, and A. Pande. Data-guided approach [4] M. Bayati, M. Braverman, M. Gillam, K. M. Mack, [5] J. L. Berral,  X  I. Goiri, R. Nou, F. Juli` a, J. Guitart, [6] A. J. Chan, A. Pande, E. Baik, and P. Mohapatra. [7] M. Chiang, S. Zhang, and P. Hande. Distributed rate [8] M. Fazel and M. Chiang. Network utility [9] E. Horvitz and T. Mitchell. From data to knowledge [10] S. S. Krishnan and R. K. Sitaraman. Video stream [11] G. Lee, N. Tolia, P. Ranganathan, and R. H. Katz. [12] J.-W. Lee, R. R. Mazumdar, and N. B. Shroff. [13] P. Paudyal, F. Battisti, and M. Carli. A study on the [14] M.Qu,H.Zhu,J.Liu,G.Liu,andH.Xiong.A [15] R. Schatz and S. Egger. An annotated dataset for web [16] M. Z. Shafiq, J. Erman, L. Ji, A. X. Liu, J. Pang, and [17] A. Slivkins. Contextual bandits with similarity [18] G. Song and Y. Li. Utility-based resource allocation [19] T. Tulabandhula and C. Rudin. Machine learning with [20] T. Tulabandhula, C. Rudin, and P. Jaillet. Machine [21] M. Udell and S. Boyd. Maximizing a sum of sigmoids. [22] M. Udell and S. Boyd. Bounding duality gap for [23] M. Wang. Vanishing price of anarchy in large
