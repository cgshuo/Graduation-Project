 By analyzing explicit &amp; implicit feedback information re-trieval systems can determine topical relevance and tailor search criteria to the user X  X  needs. In this paper we investi-gate whether it is possible to infer what is relevant by ob-serving user affective behaviour. The sensory data employed range between facial expressions and peripheral physiolog-ical signals. We extract a set of features from the signals and analyze the data using classification methods, such as SVM and KNN. The results of our initial evaluation indicate that prediction of relevance is possible, to a certain extent, and implicit feedback models can benefit from taking into account user affective behavior.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Relevance Feedback, Search Pro-cess; I.5.1 [Computing Methodologies]: Pattern Recogni-tion[Models General Terms: Experimentation, Human Factors, Per-formance
To deal with information uncertainty, retrieval systems have employed in the past a range of relevance feedback techniques, which vary from explicit to implicit. Relevance is a key notion of information science, which is intertwined with many interactive processes, such as the act of com-munication, information seeking, assessment, reflection, etc. People very often apply relevance when performing some kind of information processing task, in order to determine the degree of appropriateness or relation of the perused in-formation item [4].

By analyzing explicit and implicit feedback information the retrieval systems can determine topical relevance with greater accuracy, offer improved query reformulations and tailor the search criteria to the user needs. However, as dis-cussed in [1], existing feedback techniques determine con-tent relevance only with respect to the cognitive and situ-ational levels of interaction, failing to acknowledge the im-portance of intentions, motivations and feelings in cognition and decision-making [3]. According to McKechnie and Ross [2], affective variables can play an important role in reading-related information behavior, especially in the domain of ev-eryday life. Information processing, which can occur during the appraisal process of a goal, an event, or an item, of-ten results in a series of changes in the user X  X  cognitive and affective states.

We argue that such changes are often expressed through a psycho-physiological mobilization, which is reflected by a se-ries of more or less observable cues (facial expressions, local-ized changes in the electrodermal activity, variations in the skin temperature, etc.). Since the significance of an event or information item can vary from low to high, depending on the number of goals or needs that are affected by it, so do these peripheral physiological symptoms vary in inten-sity and duration. We do not assume anything about the details of the relationship between users X  affective responses and topical relevance; we systematically build our ground truth from the data, using classification and pattern recog-nition methods.This work is a study of how effectively we can determine topical relevance by measuring key physiological signals taken from the user. To justify our key assumption we make the following research hypothesis:
H 1 : Users X  affective responses, as determined automatic facial expression recognition, will vary across the relevancy of perused information items.

H 2 : Users X  affective responses, as determined from pe-ripheral physiological signals processing, will vary across the relevancy of perused information items.
In this study we employed a facial expression recognition system (eMotion) [5], of reasonably robust performance and accuracy across all individuals. In addition, we recorded a range of peripheral physiological signals using a set of wear-able devices (Polar RS800 and BodyMedia SenseWear R Pro 3 Armband), which gave us a more fine-grained imprint of participants X  affective states. For the completion of the search tasks we used a customized version of Verge Engine [6], which worked on top of TREC 9 (2000) Web Track and TRECVID 2007 test collections. Twenty-four participants (14 male and 10 female) applied for the study through an organisational wide ad. Each participant completed four search tasks, two for each media type. In each task they were handed four topics and were asked to proceed with the one they considered more interesting. For every topic the system returned ten pre-selected results (either exclu-sively relevant or irrelevant), which the participants had to evaluate within 10 minutes, while considering the relevance criteria provided by the given scenario description.  X  63.7 65.5 64.4
The modeling goal was to predict with reasonable accu-racy topical relevance, using sensory data that derive from facial expressions and other peripheral physiological signals as the only feedback information. From the latter signals we extracted a set of features and performed discriminant analysis, using a range of classification methods such as sup-port vector machines (SVM) and nearest neighbour cluster-ing (KNN). We measured the performance of our models us-ing the standard information retrieval metrics of accuracy, precision and recall. Accuracy was computed as the fraction of items in the test set for which the prediction was correct.
For each classification method, we present only the model which achieved the best performance, among the rest in its category. The results are shown in Table 1. The McNemar X  X  test was applied to check for statistically significant varia-tion against the baseline. Models marked with (  X  ) got sig-nificantly different results, compared to the baseline model, with p &lt; 0.005. Among all the models, the SVM model held the best performance, giving a reasonable, though rather noisy, prediction of topical relevance. The boosting that we performed, using either 5 or 10 weak classifiers, gave a slight increase in the accuracy. With the exception of one SVM model, all the rest had a statistically significant differ-ence in their classification accuracy, compared to the base-line model. The discriminative KNN model had in all cases the lowest performance.
Overall, the evidence that we accumulated validates both of our hypotheses, namely that users X  affective responses, as determined from the observation of their facial expressions and other peripheral physiological signals, will vary across the relevancy of perused information items. This improved the classifiers X  prediction accuracy, compared to the baseline, across the media type. Furthermore, the results of our ini-tial evaluation indicate that prediction of topical relevance is possible, and to a certain extent models can benefit from tak-ing into account user affective behavior. Our model-based approach was also designed to be as independent as possi-ble from the viewed content and context, therefore, making its application generalizable to a range of different search topics and media types. This is perhaps the most signifi-cant contribution of this work, since it will potentially influ-ence other aspects of the retrieval process, such as implicit feedback methods, indexing, ranking and recommendation techniques. The research leading to this paper was supported by the European commission, under the contract FP6-033715 (MI-AUCE Project). Our thanks to MKLab for participating in this study.
