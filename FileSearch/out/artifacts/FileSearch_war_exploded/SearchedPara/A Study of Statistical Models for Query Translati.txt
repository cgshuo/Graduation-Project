 This paper presents a study of three statistical query translation models that use different units of translation. We begin with a review of a word-based translation model that uses co-occurrence statistics for resolving translation ambiguities. The translation selection problem is then formulated under the framework of graphic model resorting to which the modeling assumptions and limitations of the co-occurrence model are discussed, and the research of finding better translation units is motivated. Then, two other models that use larger, linguisti-cally motivated translation units (i.e., noun phrase and depend-ency triple) are presented. For each model, the modeling and training methods are described in detail. All query translation models are evaluated using TREC collections. Results show that larger translation units lead to more specific models that usu-ally achieve better translation and cross-language information retrieval results. H.3.3 [ Information Storage and Retrieval ]: Retrieval models Design, Algorithms, Theory, Experimentation Query Translation, Cross-Language Information Retrieval, Statistical Models, Linguistic Structures Query translation is a long standing research topic in the com-munity of cross-language information retrieval (CLIR). Assume that a query is translated using a bilingual dictionary, there are two fundamental research tasks: (1) how to improve the cover-age of the bilingual dictionary; and (2) how to select the correct translation of the query among all the translations provided by the dictionary. The second task is also called the problem of translation selection , and is the focus of this paper. translation selection. To make a statistical model trainable, we always decompose the translation of a query into a sequence of smaller translation units . Given that we will use statistical mod-els to model translation, one important question is: what unit of translation should a statistical model represent ? ful linguistic unit. However, a word-based model, though sim-ple to train, is always over-general and may lead to too many translation ambiguities for resolving. In theory, larger units such as phrases are more specific and lead to less translation ambiguities. However they pose bigger challenges in model structuring and training. that use different translation units. We will begin with a review of a classical word-based translation model that uses co-occurrence statistics to resolve translation ambiguities. Then, we will formulate the translation selection problem under the framework of graphic model (GM). We will discuss the model-ing assumptions and limitations of the co-occurrence model, and motive our research of finding better translation units. guistic-motivated translations units. They are noun phrases (NPs) and dependencies. A dependency, represented as a triple, is a pair of words that have a syntactic dependency relation, such as verb-objective. In both models, we assume that the se-lection of a translation only depends upon other selected trans-lations in the same unit. While NPs capture dependence of adjacent words in a query, dependency triples can capture syn-tactic dependences between non-adjacent words. Though simi-lar models have been proposed earlier, we will refine those using recent advances in the research community of statistical machine translation (SMT). We will show that (1) NP and de-pendency translation can be performed using a reranking ap-proach based on a linear model; (2) the linear model provides a flexible statistical framework to incorporate various kinds of information, defined as feature functions, for resolving transla-tion ambiguities; (3) the parameters of the linear model can be learned discriminatively so as to optimize the translation qual-ity directly, and (4) most effective feature functions used in the linear model can be derived from generative models that are traditionally used in SMT, thus the ranking approach provides an appropriate framework to combine the strengths of both generative models and discriminative training methods. lections. To our knowledge, this is the first systematic compari-son of those models on the task of English to Chinese CLIR on gold test sets. We shall demonstrate that linguistic units such as NP and dependency triples are beneficial to query translation if they can be detected and used properly. A co-occurrence model uses words as the unit of translation. The basic principle of the model is that correct translations of query words tend to co-occur in the target language and incor-
Permission to make digital or hard copies of all or part of this work for not made or distributed for profit or commercial advantage and that copies cific permission and/or a fee. SIGIR X 06, August 6 X 11, 2006, Seattle, Washington, USA. 
Copyright 2006 ACM 1-59593-369-7/06/0008...$5.00. rect translations do not. Therefore, for a given query word in source language (i.e., English in this study), the likelihood of its translation (i.e., Chinese) is measured via the similarity between a translation candidate (e.g., provided by a bilingual dictionary) and the other selected translations in the query. The definition of similarity between words can take different forms of co-occurrence statistics. Mutual information is among the most commonly used ones [22]. to train. There is no need to measure cross-language word simi-larities (e.g., translation probabilities). Only relationships be-tween words of the same language are used. They can be ob-tained through co-occurrence statistics in a monolingual text corpus. The disadvantage of the model is that it is difficult to find an efficient algorithm that optimizes exactly the translation of a whole query according to the model. We now describe it in detail. should select for each query term the translation that co-occurs the most often with (or the most similar to) the selected transla-tions of other terms in the same query. However, finding such an optimal translation is computationally very expensive, as will be described below. Therefore, one has to use an approxi-mate greedy algorithm as follows [1, 10, 11]: (1) Given an English (source language) query e = { e (2) For each set D ( e i ) (a) For each translation c i,j  X  D ( e (c) Select the translation c  X  D ( e i computed with regard to all possible translations of other query terms. It does not differentiate correct translations from incor-rect ones. As a result, the translation of different query terms is determined independently. In spite of the deficiency, the greedy search algorithm has been widely used since an exact algorithm is prohibitively expensive. In the next section, we will formulate the translation selection problem under the framework of GM [e.g., 13], and discuss the underlying as-sumptions of the greedy algorithm. A query translation model can be viewed as an undirected GM. For example, Figure 1 shows a query translation model of a 5-term query. Each node represents a distribution of a translation set of a query term. The edges of the graph represent a set of independency assumptions among query term translations. The task of query translation is to find a set of 
Figure 1. GMs the co-occurrence query translation model (a) and its approximation (b). P ( w 1 , w 2 , w 3 , w 4 , w 5 ). lation. The first is how to generate translation candidates for each term, and how to model the distribution of the candidates. Traditionally, a bilingual dictionary is used and all translations of a query term are assumed to be uniformly distributed. We may also induce a distribution using a statistical translation model learned from parallel bilingual corpora. what independence assumptions we may use. The third is how to compute the joint probability. These two problems are closely related. The efficiency of the joint probability computing largely depends on the graph topology. that the selection of each translation is consistent with the se-lected translations for other query terms. Therefore, we assume that the five nodes form a clique as shown in Figure 1 (a). Sup-pose that we wish to compute the marginal probability P ( w We obtain this marginal by summing over the other variables as: where h (.) is a feature function, and Z is a normalization factor. d 6 (assuming that each query term has d possible translations). This is prohibitively expensive even for a very short query. We therefore resort to an approximated word selection algorithm as described in Section 2 by introducing a translation inde-pendence assumption. The corresponding GM is shown in Fig-ure 1 (b). Now, P ( w 1 ) can then be factored as: Notice that if we define h (.) in Equation (4) as the similarity between two words, the idea behind Equation (4) is similar to that of Equation (2) ( Z can be removed when the probability is used to rank translation candidates), where no more than two variables appear together in any summand, and thus the com-putational complexity is reduced to d 2 . However, as discussed earlier, the reduction of complexity may come with the sacrifice of accuracy due to the independence assumption used. largest size of the clique in the graph. The NP and dependency translation models described in Sections 5 and 6 are used to implement the idea that the linguistic structure of a sentence can be utilized to identify cliques. Linguistic units, such as NPs or dependency triples, can be translated as unit and the transla-tion can be done accurately using only internal information of the unit. As a consequence, the graph would be divided into a few smaller sub-graphs. The probability of each sub-graph can be inferred independently, with an optimal order that leads to a lower computation complexity. paper, our query translation process can be cast in a sequential manner as follows.  X  Identify NPs and dependency triples of a query.  X  Translate words in NPs using the NP translation model  X  Translate words in dependencies using the dependency  X  Translate remaining words using the co-occurrence model. This section describes the reranking approach which is the fun-damental modeling framework for both NP and dependency translation models. some way of detecting linguistic structures s of e . We also as-sume some way of generating a set of candidate Chinese trans-lations c , denoted by GEN ( e ). The task of a query translation model is to assign a score for each of the translation candidates in GEN ( e ) and select the one with the highest score: ear model, which consists of (1) a set of D feature functions that set of parameters, each for one feature,  X  i for i = 1 ... D . Then the decision rule of Equation (5) can be rewritten as Notice that the linear model of Equation (6) is a very general framework [6]. For example, the source-channel models for SMT [16] can be viewed as a special case of the linear model if we define both source model and channel model as feature functions. We shall show that most feature functions can be derived from generative models which are traditionally used in the framework of source-channel models for SMT. The values of those feature functions are (log) probabilities that are learned from large monolingual or bilingual corpora via MLE. There-fore, those features are more informative than binary features that are traditionally used in linear models for classification problems [6]. mated using an iterative procedure that is used for multi-dimensional function optimization [18]. Assume that we can minimize query translation errors with respect to one parame-ter  X  using line search . The procedure works as follows: Take  X   X  , ...,  X  N as a set of directions. Using line search, move along the first direction so that the number of translation errors on training data is minimized; then move from there along the second direction to the minimal error rate, and so on. Cycling through the whole set of directions as many times as necessary, until the error number stops decreasing. In our experiments, we found that the procedure can converge on different minima given different starting points. We thus perform the procedure multiple times, each from a different, random starting point, and pick the parameter setting that achieves the minimal errors. Note that this optimization approach is limited to a very small number of model parameters. Efficient algorithms for tuning a larger number of model parameters can be found in [9, 17]. translation model and the dependency translation model. Both models are of the form of linear models in Equation (6). For each model, we will first describe a generative translation model (consisting of a series of component models) under the framework of source-channel models. Then, we derive feature functions (e.g., from the component models) used in the linear models. The use of NP as a unit of translation is motivated by two ob-servations. First, most English NPs are translated to Chinese as NPs. For example, on a 60K-sentence-pair word-aligned Eng-lish-Chinese bilingual corpus, we found more than 80% of Eng-lish NPs being aligned to their translated Chinese NPs. Second, as pointed out in [14], word selection can almost always be resolved depending solely upon the internal context of the NP. NP patterns is the fundamental to our NP translation model. For example, a [NN-1 NN-2] English phrase is usually trans-lated into a [NN-1 NN-2] sequence in Chinese, and a [NN-1 of NN-2] phrase is usually translated into a [NN-2 NN-1] se-quence in Chinese. The concept of translation templates is very similar to that of alignment templates in [16]. Formally, a NP describes the alignment A between an English NP pattern E and a Chinese NP pattern C . The alignment A is represented as a set connected to the j -th Chinese word class in C . Either i or j can be empty, denoted by  X  , indicating that an English (or Chinese) word class is connected to no Chinese (or English) word class. 
In our experiments, translation templates are extracted from a word-aligned bilingual corpus. We first used an in-house parser to tag POS, base NP, and complex NP for English sen-tences. Then, for each English NP pattern E , we extracted its translated Chinese NP patterns C and the alignment A . An ex-ample is shown in Figure 2, where (a) is an English sentence with each word marked by its POS tag and position and ele-ments within [...] are base NPs, or complex NPs; (b) is the aligned Chinese sentence that has been segmented into a se-quence of words; (c) shows the word alignment between the English and Chinese sentences; and (d) shows three translation templates extracted respectively for two base NPs and for the whole phrase. Notice that the word positions in the alignments translation templates can be recursively defined. Given an English NP e , we search among all possible transla-tions the most probable Chinese NP c* as Here, P ( c ) is the Chinese language model probability estimated via a trigram model as P ( e | c ) is the translation probability. Formally, the NP transla-tion template z is introduced as a hidden variable as Hence, there are two probabilities to be estimated. The prob-ability P ( z | c ) to apply a translation template and the probabil-ity P ( e | z , c ) to use a translation template for word selection. plicable and C ( c ) be the number of occurrences of c in training data. P ( z | c ) is estimated as sume that the English words are translated independently. We then decompose the probability as Here, P ( e | c ) is a translation probability estimated by relative frequencies: word e, and C ( c ) is the frequency of word c in training data. in [16]. However it is not necessary to normalize it since we only use the model as a feature function for ranking translation candidates. We also notice that it is possible to define an align-ment in A at the level of base NP such as z 3 in Figure 2 (d). As shown in Figure 2 (d), we assume that all alignments in A are pairs of word positions. Therefore, when we apply A in NP translation, we recursively map each alignment pair of base NP position to a set of pairs of word positions. For example, the pair (1, 2) in z 3 in Figure 2 (d), which is an alignment between the positions of two base NP, can be mapped into a set of word position pairs using the alignment of z 2 . are trained on different corpora of different sizes. The dynamic value ranges of different component model probabilities can be but a score ) that it is inappropriate to combine all these models through simple multiplication as in Equation (13). Moreover, models that are poorly trained (e.g., due to lack of training data) should be less weighted than well-trained ones. One way to balance the impact of these models is to introduce for each component model a model weight  X  to adjust the model score P ( . ) to P ( . )  X  . In our experiments, these weights are optimized so as to minimize the NP translation errors on training data under the framework of linear models. It is thus worth noticing that the source-channel models are the rationale framework behind the NP translation model. Linear models are just another repre-sentation based on which we describe the optimization algo-rithm of model weights. We used three feature functions. They are derived from the above three component models in Equation (13), respectively. 1. Chinese language model feature. It is defined as the 2. Translation template selection model feature. It is defined 3. Word selection model feature. It is defined as the Notice that the linear model of Equation (6) does not take into account the sum on z in Equation (13), because considering the sum in decoding directly is computationally expensive. There-fore, we approximate the sum during decoding: Given an Eng-lish NP e , we take the following steps to search for the best Chinese translation. 1. Template matching. We find all translation templates that 2. Candidate generating. For each translation template, we 3. Searching. For each lattice, we use a best-first decoder to 4. Fusion and reranking. We fusion all retained translation First, for each z , we find the best translation. Second, we select the translation among all retained best translations according to the linear model. Figure 2. NP translation templates patterns A dependency is denoted by a triple ( w 1 , r , w syntactic dependency relation r between two words w Among all the dependency relations, we only consider the four types that can be detected precisely using our parser and can-not be handled by the NP translation model: (1) subject-verb, (2) verb-object, (3) adjective-noun, and (4) adverb-verb. translation model is also developed based on two hypotheses. First, dependencies have the best cohesion properties across languages [7]. That is, dependency representation usually re-mains in the translations, and an ideal query translation should contain the same syntactic dependences as in the original query. Second, word selection can mostly be resolved via the internal context of the dependency. dependency relations in the translation between English and Chinese, despite the great differences between the two lan-guages. For example, a subject-verb relation in English, e.g. (dog, subject-verb, barking), is usually translated into the same 27] also showed that more than 80% of dependency relations of the above four types have one-to-one mappings between Eng-lish and Chinese. a translation template between English dependency triples and Chinese ones. Unlike NP translation templates, there is only one translation template: An English dependency triple e r , e 2 ) is most likely to be translated to a Chinese dependency of the English terms e 1 and e 2 , respectively, and r counterpart of r e . Given an English dependency triple e t = ( e 1 , r its candidates of Chinese dependency triple translation, the best mizes the following equation Chinese dependency triple. It can be estimated using MLE as where C ( c t ) is the number of occurrences of c t in the collection, and N is the number of all dependency triples. and c t can be translated with each other only if they have the same type of dependency relation, i.e., r e = r dependency triple are translated independently. We therefore decompose the probability P ( e t | c t ) as where  X  ( r e , r c ) = 1 if r e = r c and 0 otherwise. timated on word-aligned bilingual corpus using Equation (12). However, we observe that within a dependency triple ( w 1 the translation selection of a word (e.g., w 1 ) largely depends on the other word w 2 and the relation r . For example, the word  X  X ear X  in a dependency triple (bear, verb-object, child) is trans-lated to  X  , while it is most likely to be translated to  X  X  X  as an individual word (if the translation probability is trained directly on a word-aligned corpus or the translation is obtained via dictionary look up). This suggests that translation probabilities in Equation (16) are better trained on a set of aligned bilingual dependency triple pairs. Unfortunately, it is difficult to obtain such a corpus in large quantity. Therefore, in our model, in-stead of using a translation probability we assume that the like-not necessary to be a translation pair but just a pair of cross-lingual synonyms , e.g.,  X  is not a translation of  X  X ear X  defined in a dictionary, but a synonym . Since our goal is to obtain good IR results, such cross-lingual synonyms may solve the term mismatch problem and boost the CLIR performance. the value of sim ( e , c ). The advantage of the method is that sim ( e , c ) can be learned on unrelated English and Chinese dependency triple corpora. We see from Equations (14) and (16) that the likelihood of e be translated to c t , assuming that r e = r c NP translation model, we define a feature function for each type of factors, and combine them under the framework of linear models as shown in Equation (6). The two types of fea-tures are defined as follows. 1. Chinese language model feature. It is defined as the 2. Cross-lingual word similarity feature. It is defined as the We evaluate the three proposed query translation models on CLIR experiments on TREC Chinese collections. The TREC-9 collection contains articles published in Hong Kong Commer-cial Daily, Hong Kong Daily News, and Takungpao. They amount to 260MB. A set of 25 English queries (with translated Chinese queries) has been set up and evaluated by people at NIST (National Institute of Standards and Technology). The TREC-5&amp;6 corpus contains articles published in the People's Daily from 1991 to 1993, and a part of the news released by the Xinhua News Agency in 1994 and 1995. A set of 54 English queries (with translated Chinese queries) has been set up and evaluated by people at NIST. segmented using the Chinese word segmentation system MSRSeg [8]. The system also identifies named entities of vari-ous types. Then, stop words are removed. Each of the TREC queries has three fields: title, description, and narratives. In our experiments, we used two versions of queries, short queries that contain titles only and long queries that contain all the three fields. human compiled bilingual lexicons, including the LDC English-Chinese dictionary and a bilingual lexicon generated from a parallel bilingual corpus automatically. The dictionary contains 401,477 English entries, including 109,841 words, and 291,636 phrases. the basic retrieval system. The main evaluation metric is inter-polated 11-point average precision. Statistical significance test (i.e., t-test) is also employed. The main results are shown in Tables 1 to 3 (i.e., average preci-sions) and Figures 2 and 3 (i.e., precision-recall curves). To in-vestigate the effectiveness of our models for query translation, three baseline methods are compared, denoted by ML, ST and BST, respectively. 
ML (Monolingual) . We retrieve documents using the manually translated Chinese queries provided with the TREC collections. Its performance has been considered as an upper-bound of CLIR because the translation process always intro-duces translation errors. However, recent studies show that CLIR results can be better than monolingual retrieval results [24]. This is also observed in our experiments. 
ST (Simple Translation). We retrieve documents using query translation obtained from the bilingual dictionary. Phrase entries in the dictionary are first used for phrase matching and translation, and then the remaining words are translated by their translations stored in the dictionary. For each phrase/word with multiple translations stored in the dictionary, we only take the first translation, which is supposed to be the most frequently used translation. We could take more transla-tions for each phrase/words, but our pilot experiments show that it hurts the performance in most cases. 
BST (Best-Sense Translation). We retrieve documents us-ing translation words selected manually from the dictionary, one translation per word, by a native Chinese speaker. If none of the translations stored in the dictionary is correct, the first one is chosen. This method reflects the upper bound perform-ance using the dictionary. Section 2. We implemented a variant, called decaying co-occurrence model [10]. The word similarity is defined as 
Table 1 : 11-point average precision (AP) for short queries on TREC-9 dataset (* indicates that the improvement is statistically significant.) 1 ML 0.2956 2 ST 0.1398 44.28% 3 BST 0.1833 62.01% 40.03%* 4 COTM 0.1399 47.33% 6.88% 5 NPTM 0.2345 79.33% 79.14%* 6 COTM + NPTM 0.2708 91.61% 106.88%* 
Table 2 : 11-point average precision (AP) for long queries on TREC-9 dataset (* indicates that the improvement is statistically significant.) Translation Model AP % of 1 ML 0.3179 2 ST 0.2003 62.99% 3 BST 0.2924 91.96% 46.00%* 4 COTM 0.2657 83.58% 32.69%* 5 NPTM 0.2562 80.58% 27.93%* 6 DPTM 0.2160 67.94% 7.86% 7 NPTM+NPTM 0.3093 97.28% 54.44%* 8 COTM+DPTM 0.2705 85.09% 35.09%* 9 COTM+NPTM+DPTM 0.3303 103.88% 64.92%* Table 3 : 11-point average precision (AP) for long queries on TREC5&amp;6 dataset (* indicates that the improvement is statistically significant.) 1 ML 0.5184 2 ST 0.2811 54.22% 3 BST 0.3906 75.35% 38.95%* 4 COTM 0.3391 65.41% 20.63%* 5 COTM+NPTM 0.3894 75.12% 38.53%* 6 COTM+NPTM+DPTM 0.4541 87.60% 61.54%* Figure 3: Precision-Recall curves for short queries on TREC-9 dataset. 
Figure 4: Precision-Recall curves for long queries on TREC-9 dataset. where MI (.) is the mutual information between two words, and is estimated on a Chinese newspaper corpus. D (.) is a penalty function, indicating that the mutual information between words decreases exponentially with the increase of the distance between them. It is defined as where  X  is the decaying rate (  X  = 0.8 in our experiments), and Dis ( w i ,w j ) is the average intra-sentence distance between w w in the Chinese newspaper corpus. The translation template selection model (i.e., value of h is trained on a word-aligned bilingual corpus containing ap-proximately 60K English-Chinese sentence pairs. Translation templates are first extracted automatically from the corpus using an in-house chunking parser, and then filtered by a lin-guist. The probability P ( z | c ) is then estimated according to Equation (10). For each Chinese NP pattern, there are 4.21 translation templates on average. The word selection model (i.e., h
WS ( e , z , c )) are computed according to Equation (12) using the same word-aligned bilingual corpus. The Chinese trigram model (i.e., h LM ( c )) is trained on a word-segmented Chinese corpus consisting of about 1 billion words. Section 6. sim ( e , c ) is estimated using two unrelated English and Chinese corpora (i.e., 87-97 WSJ newswires for English and 80-98 People X  X  Daily articles for Chinese). An English and Chinese parser NLPWIN [12] is used to extract dependency triples in both corpora. Notice that NLPWIN is a rule-based parser and performs well only when the input is a grammatical sentence, so we only tested DPTM on long queries (i.e., to parse the de-scriptions and narratives). and 3 give rise to the following observations. nificant improvements over ST for long queries but its im-provement over ST for short queries is marginal. This is ex-pected because COTM resolves translation ambiguities with resort to context terms. Long queries contain much richer con-textual information than short queries. provements over ST for both long and short queries, and even outperforms BST for short queries, as shown in Rows 3 and 5 in Table 1. It is thus interesting to compare the phrase translation results using NPTM and with that using dictionary look-up (Rows 2 and 3 in Table 1). A further analysis shows that by using NP identification and translation, we obtained better translations. For example, in TREC-9 short query retrieval, only 11 multi-word phrases out of 25 queries are stored in the dic-tionary, and translated as a phrase, whilst using NPTM, 26 NPs are identified and translated. It thus leads to a significant im-provement over BST. ness well below that with COTM and NPTM. For example, as shown in Table 2 (Rows 2 and 6), the improvement of DPTM over ST is not statistically significant. This is however expect-able because dependency triples have a much lower coverage than the other models. Consider TREC-9 long query retrieval, only a few triples from 11 queries out of 25 have been trans-lated by DPTM. So this  X  X ounter-performance X  is not surpris-ing. A further analysis shows that from the 11 queries, NLPWIN extracted 52 dependency triples which appear at least 5 times in the corpus. The 52 triples include 12 verb-object de-pendency triples, 8 sub-verb triples, 32 adjective-noun triples and no adv-verb triple. For these queries, the dependency triple translation has positive impact on the methods of ST and COTM for 10 out of the 11 queries, which leads to a statistically significant improvement of 58% over ST, and 11% over COTM for the 11 queries. ing the sequential combining approach described in Section 3) always perform better than each component model to be com-bined. Interestingly, for some queries, their CLIR results are even better than their monolingual retrieval results. Co-occurrence information has been utilized by several recent studies [2, 3, 10, 11, 15] to deal with the translation selection problem for CLIR. One potential problem of most proposed co-occurrence model is the use of the approximate word selection algorithm. As described in Section 2, each query term transla-tion is actually determined independently. To remedy the prob-lem, Liu et al. [15] presented a so-called maximum coherent model that is able to estimate translations of multiple query terms simultaneously. In this paper, we remedy the problem simply by combining it with other two translation models using larger, linguistic-motivated units of translation. The basic idea jointed optimized only when they are really correlated tightly such as query words within a NP or a dependency. In this sense, our query translation methods are both stochastically and lin-guistically motivated: stochastically because we use statistics from corpus, linguistically because the translation units (NPs and dependencies) we defined are informed by syntactic analy-sis. phrase-based SMT. Our NP translation template is very similar to the template-based translation model described in [16]. The use of hierarchical structure in our NP translation templates can be viewed as a special case of the hierarchical phrase-based model in [4]. There are however two major differences between our work and that of [4, 16]. First, the NPs that we deal with are syntactically well-defined constitutes. [4, 16] extract phrases from bilingual corpus. These phrases are just a sequence of consecutive words, and could be completely meaningless syn-tactically. Second, our translation templates use POS tag as word class while in [16], the templates use word classes that are automatically learnt from bilingual corpus. In a word, our model is more syntactically-motivated, and would potentially more accurate and efficient. Moreover, in our study we view NP translation as a subtask of machine translation. We believe that focusing on such a narrower problem would allow more dedicated modeling. Koehn [14] presents a pretty comprehen-sive piece of work along this line. The rich feature set used for NP translation, presented in [14], might also improve the accu-racy of our method. syntax information to resolve translation ambiguities. The same goal has also motivated the research of syntax-based MT, which is closely related to our work. Similar to our method, [5] also use parsers to identify linguistic structures of both Chinese and English languages. Then, they identify those sub-structures from both languages that can be mapped. The identified map-pings form the so-called transduction grammar . Due to the struc-tural difference between source and target language, people also use a parser in one language, and map the extracted lin-guistic structure to the other language [19, 25], assuming that there exist a large set of word-aligned bilingual sentence pairs. There are also some methods that can learn a transduction grammar without parsing monolingual sentences [4, 23]. While most previous work requires a large amount of word-aligned bilingual corpus, which is not always available; our model can be learned from unrelated bilingual corpus. This benefit results from the fact that we define dependency translation as a sub-task of MT, like the case of NP translation model. We also argue that while most existing methods rely on constituency analysis , we believe that dependency analysis bring semantically related words together, and is more effective for resolving translation ambiguities. This paper presents three statistical query translation models for dealing with the problem of query translation ambiguity. The models differ in the use of translation unit and the use of linguistic information. The co-occurrence model is based on word translation. It does not take into account any linguistic structure explicitly, and simply views a query as a bag of words. The other two models, the NP translation model and the de-pendency translation model, use larger, linguistically motivated translation units, and can exploit linguistic dependency con-straints between words in NPs or in higher level dependencies. Our experiments of CLIR on TREC Chinese collections show that models using larger and more specific unit of translation are always better, if the models can be well trained, because more specific models could model more information. This is consistent with the observations on general reasoning: when more information is available and is used in reasoning, we usu-ally obtain better results. The integration of different types of knowledge in query translation is the most apparent in the NP and dependency models. Both are constructed under the framework of linear models, where different information is combined as feature functions. This combination method is very effective flexible to incorporate more types of information or knowledge when it is available. form better with larger translation units. It is also well-known that models using larger translation units require more training data. Thus, our work can be viewed as finding a tradeoff be-tween specificity and trainability. Given a limited amount of training data, we always try to make the model as specific as possible. Recently, people have tried to automatically collect bilingual corpora from web [20, 26]. Since the web provides a potentially unlimited data source, it turns out to be a very promising research area. 
