 Ad-hoc processes, a special category of processes, have flexible underlying pro-cess definition where the control flow be tween activities cannot be modeled in advance but simply occurs during run time [9]. The semistructured nature of ad-hoc process data requires organizing process entities, people and artifacts, and relationships among them in graphs. The structure of process graphs, describ-ing how the graph is wired, helps in understanding, predicting and optimizing the behavior of dynamic processes. In many cases, however, process artifacts evolve over time, as they pass through the business X  X  operations. Consequently, identifying the interactions among people and artifacts over time becomes chal-lenging and requires analyzing the cross-cutting aspects [12] of process artifacts. In particular, process artifacts, like cod e, has cross-cutting aspects such as ver-sioning (what are the various versions of an artifact, during its lifecycle, and how they are related) and provenance [7] (what manipulations were performed on the artifact to get it to this point).

The specific notion of business artifact was first introduced in [23] and was fur-ther studied, from both practical and theoretical perspectives [17,13,5,8,6]. How-ever, in a dynamic world, as business artifacts changes over time, it is important to be able to get an artifact (and its provenance) at a certain point in time. It is chal-lenging as annotations assigned to an artifact (or its versions) today may no longer be relevant to the future representation of that artifact: artifacts are very likely to have different states over time and the temporal annotations may or may not apply to these evolving states. Consequently, ana lyzing evolving aspects of artifacts (i.e. versioning and provenance) over time is important and will expose many hidden in-formation among entities in process gra phs. This information can be used to detect the actual processing behavior and therefore, to improve the ad-hoc processes.
As an example, knowledge-intensive processes, e.g., those in domains such as healthcare and governance, involve hum an judgements in the selection of activi-ties that are performed. Activities of kno wledge workers in knowledge intensive processes involve directly working on and manipulating artifacts to the extent that these activities can be considered as artifact-centric activities. Such pro-cesses, almost always involves the collect ion and presentation of a diverse set of artifacts, where artifacts are develop ed and changed gradually over a long pe-riod of time. Case management [28], also known as case handling, is a common approach to support knowledge-intensive processes. In order to represent cross-cutting aspects in ad-hoc processes, th ere is a need to collect meta-data about entities (e.g., artifacts, activities on top of artifacts, and related actors) and rela-tionship among them from various systems/departments over time, where there is no central system to capture such activit ies at different systems/departments. We assume that process execution data are collected from the source systems and transformed into an event log using existing data integration approaches [3].
In this paper, we present a novel framework for analyzing cross-cutting as-pects in ad-hoc processes and show experimentally that our approach addresses the abovementioned challenges and achieves significant results. The unique con-tributions of the paper are:  X  We propose a temporal graph model for representing cross-cutting aspects  X  We introduce two concepts of timed-folders to represent evolution of artifacts  X  We extend FPSPARQL [3], a graph query language for analyzing processes The remainder of this paper is organized as follows: We fix some preliminar-ies in Section 2. Section 3 presents an example scenario in case management applications. In Section 4 we introduce a data model for representing cross-cutting aspects in ad-hoc processes. In Section 5 we propose a query language for querying the proposed model. In Section 6 we describe the query engine implementation and evaluation experiments. Finally, we discuss related work in Section 7, before concluding the paper in Section 8. Definition 1. [ X  X rtifact X  X  An artifact is defined as a digital representation of something that exists separately as a single and complete unit and has a unique identity. An artifact is a mutable object, i.e., its attributes (and their values) are able or likely to change over periods of time. An artifact Ar is represented by a set of attributes { a 1 ,a 2 , ..., a k } ,where k represents the number of attributes. Definition 2. [ X  X rtifact Version/Instance X  X  An artifact may appear in many versions. A version v is an immutable deep copy of an artifact at a certain point in time. An artifact Ar can be represented by a set of versions { v 1 ,v 2 , ..., v n } , where n represents the number of versions. Each version v i is represented as an artifact instance that exists separately and has a unique identity. Each version v i consists of a snapshot, a list of its pa rent versions, and meta-data, such as commit message, author, owner, or time of creation.
 Definition 3. [ X  X ctivity X  X  An activity is defined as an action performed on or caused by an artifact version, e.g., an act ion can be used to crea te, read, update, or delete an artifact version. We assume that each distinct activity does not have a temporal duration. A timestamp  X  can be assigned to an activity.
 Definition 4. [ X  X rocess X  X  A process is defined as a group of related activities performed on or caused by artifacts. A starting timestamp  X  and a time interval d can be assigned to a process.
 Definition 5. [ X  X ctor X  X  An actor is defined as an entity acting as a catalyst of an activity, e.g., a person or a piece of software that acts for a user or other programs. A process may have more than one actor enabling, facilitating, con-trolling, and affecting its execution.
 Definition 6. [ X  X rtifact Evolution X  X  In ad-hoc processes, artifacts develop and change gradually over time as they pass through the business X  X  operations. Con-sequently, artifact evolution can be defined as the series of related activities on top of an artifact over different periods of time. These activities can take place in different organizations/departments/systems and various actors may act as the catalyst of activities. Documentation of these activities will generate meta-data about actors, artifacts, and activity relationships among them over time. Definition 7. [ X  X rovenance X  X  Provenance refers to the documented history of an immutable object which tracks the steps by which the object was derived [7]. This documentation (often represented as graphs) should include all the information necessary to reproduce a certain piece of data or the process that led to that data [22]. To understand the problem, we present an example scenario in the domain of case management [28]. This scenario is based on breast cancer treatment cases in Velindre hospital [28]. Figure 1-A represents a case instance, in this scenario, where a General Practitioner (GP) susp ecting a patient has cancer, updates pa-tient history, and referring the patient to a Breast Cancer Clinic (BCC), where BCC refers the patient to Breast Cancer Specialist Clinic (BCSC), Radiology Clinic (RC), and Pathology Clinic (PC). These departments apply medical ex-aminations and send the results to Multi-Disciplinary Team (MDT). Analyzing the results and the patient history, MDT will decide for next steps. During inter-action among different systems and organizations a set of artifacts will be gen-erated. Figure 1-B represen ts parent artifacts, i.e., ancestors, for patient history document, and Figure 1-C represents parent artifacts for its versions. Figure 1-D represents a set of activities which shows how version v 2 of patient history document develops and changes gradually over time and evolves into version v 3 . Time and Provenance. Provenance refers to the documented history of an immutable object and often represented as graphs. The ability to analyze prove-nance graphs is important as it offers the means to verify data products, to infer their quality, and to decide whether they can be trusted [15]. In a dynamic world, as data changes, it is important to be able to get a piece of data as it was, and its provenance graph, at a certain po int in time. Under this perspective, the provenance queries may provide different r esults for queries looking at different points in time. Enabling time-aware querying of provenance information is chal-lenging and requires explicitly representing the time information and providing timed abstractions for time-aware querying of provenance graphs.

The existing provenance models, e.g., t he open provenance model (OPM) [22], treat time as a second class citizen (i.e., as an optional annotation of the data) which will result in loosing semantics of time and makes querying and analyz-ing provenance data for a particular point in time inefficient and sometimes inaccessible. For example, the shortest path from a business artifact to its ori-gin may change over time [26] as provenance metadata forms a large, dynamic, and time-evolving graph. In particular, versioning and provenance are important cross-cutting aspects of business artifacts and should be considered in modeling the evolution of artifacts over time. 4.1 AEM Data Model and Timed Abstractions We propose an artifact-centric activity model for ad-hoc processes to represent the interaction between actors and artifacts over time. This graph data model (i.e., AEM: Artifact Evolution Model) can be us ed to represent the cross-cutting as-pects in ad-hoc processes and to analyze the evolution of artifacts over periods of time. We use and extend the data model proposed in [3] to represent AEM graphs. In particular, AEM data model supports: (i) uniform representation of nodes and edges; (ii) structured and unstructured entities; (iii) folder nodes: A folder node contains a set of entities that are related to each other, i.e. the set of entities in a folder node is the result of a given query that requires grouping graph entities in a certain way. A folder can be nested and may have a set of attributes that describes it; and (iv) path nodes: A path node represents the results of a query that consists of one or more paths, i.e., a path is a transitive relationship between two entities showing a sequence of edges from the start entity to the end.

In this paper, we introduce two concepts of timed folders and timed paths, which help in analyzing AEM graphs. T imed folder and path nodes can show their evolution for the time period that they represent. In AEM, we assume that the interaction among actors and artifa cts is represented by a directed acyclic graph G (  X  instances of artifacts in time, and E (  X  activity relationships among artifacts. It is possible to capture the evolution of AEM graphs G (  X  4.2 AEM Entities An entity is an object that exists independently and has a unique identity. AEM consists of two types of entities: Artifact Version: Artifacts are represented b y a set of instances each for a given point in time. Artifact instances considered as data objects that exist separately and have a unique identity. An artifact instance can be stored as a new version: different instances of an entity fo r different points in time, departments, or systems may have different attribute values. An artifact version can be used over time, annotated by activity timestamps  X  activity , and considered as a graph node whose identity will be the version unique ID and timestamps  X  activity . Timed Folder Node: We proposed the notion of folder nodes in [3]. A timed folder is defined as a timed container for a se t of related entities, e.g., to represent artifacts evolution (Definition 6). Timed folders, document the evolution of a folder node by adapting a monitoring code snippet. A time-aware controller is used for creating a snippet and to allocate it to a timed folder node in order to monitor its evolution and update its content (details can be found in [2]). New members can be added to timed folders ove r time. Entities and relationships in a timed folder node are represented as a subgraph F (  X  where V (  X  added to the folder F between timestamps  X  1 and  X  2 ,and E (  X  directed edges representing relationships among these related nodes. It is possible to capture the evolution of the folder F (  X  4.3 AEM Relationships A relationship is a directed link between a pair of entities, which is associated with a predicate defined on the attributes of entities that characterizes the rela-tionship. AEM consists of two types of relationships: activity and activity-path. Activity Relationships: An activity is an explicit relationship that directly links two entities in the AEM graph, is defined as an action performed on or caused by an artifact version, and can be described by following attributes:  X  What (i.e., type) and How (i.e., action), two types of activity relationships  X  When , to indicate the timestamp in which the activity has occurred;  X  Who , to indicate an actor that enables, facilitates, controls, or affects the  X  Where , to indicated the organization/department the activity happened;  X  Which , to indicate the system which hosts the activity;  X  Why , to indicate the goal behind the activity, e.g., fulfilment of a specific Activity-Path: Defined as an implicit relationship that is a container for a set of related activities which are co nnected through a path, where a path is a transitive relationship between two entities showing the sequence of edges from the starting entity to the end. Relationship can be codified using regular expressions in which alphabets are the nodes and edges from the graph [3]. We define an activity-path for each query which results in a set of paths between two nodes. Activity-paths can be used for efficient graph analysis and can be modeledusingtimedpathnodes.

We proposed the notion of path nodes in [3]. A timed path node is defined as a timed container for a set of related e ntities which are connected through tran-sitive relationships. We define a timed path node for each change-aware query which results in a set of paths. New paths can be added to timed path nodes over time. Entities and relationships in a timed path node are represented as a subgraph P (  X  resenting instances of entities in time which added to the path node P between a time period of  X  1 and  X  2 ,and E (  X  transitive relationships among these related nodes. It is possible to capture the evolution of the path node P (  X  represents the implicit and explicit relationships between versions v 2 and v 3 of patient history (a sample folder node) document including: (A) activity edges; (B) constructed activity-path stored as a timed path node; and (C) represen-tation and storage of the activity path. We use triple tables to store objects (object-store) and relationships among them (link-store) in graphs [2]. FPSPARQL [3,4], a Folder-, Path-enabled extension of SPARQL, is a graph query processing engine which supports primitive graph queries and construct-ing/querying folder and path nodes. In this paper, we extend FPSPARQL to support timed abstractions. We introduce the discover statement which enables process analysts to extract information about facts and the relationship among them in an easy way. This statement has the following syntax:
This statement can be used for discove ring evolution of artifacts (using evo-lutionOf construct), derivation of artifacts (using derivationOf construct), and timeseries of artifacts/actors (using timeseriesOf construct). The filter state-ment restrict the result to those activiti es for which the filter expression evalu-ates to true. Variables such as artifact (e.g ., artifact version), type (e.g., lifecycle or archiving), action (e.g., creation, use, or storage), actor, and location (e.g., organization) will be defined in where statement. In order to support temporal aspects of the queries, we adapted the time semantics proposed in [31]. We intro-duce the special construct,  X  X imesemanti c( fact, [t1, t2, t3, t4]) X  in FPSPARQL, whichisusedtorepresentthe fact to be in a specific time interval [ t 1 ,t 2 ,t 3 ,t 4]. A fact may have no temporal duration (e.g., a distinct activity) or may have temporal duration (e.g., series of activ ities such as process instances). Table 1 represents FPSPARQL time semantics, adapted from [31]. The when construct will be automatically translated to timesemantic construct in FPSPARQL. Fol-lowing we will introduce derivation, evolution, and timeseries queries. 5.1 Evolution Queries In order to query the evolution of an artifact, case analysts should be able to discover activity paths among entities in AEM graphs. In particular, for querying the evolution of an AEM entity En , all activity-paths on top of En ancestors should be discovered. For example, cons idering the motivating scenario, Adam, a process analyst, is interested to see how version v 3 of patient history evolved from version v 2 (see Figure 2-A). Following is the sample query for this example.
In this example, the evolutionOf statement is used to represent the evolution The variable  X ?pathAbstraction X  is reserved to identify the attributes for the path node to be constructed. Notice that, by specifying the  X  X abel X  attribute (line 3), the implicit relationship, with ID  X  X pn1 X , between versions v 2 and v 3 will be added to the graph. It is possible to query the whole evolution of version v 3 by not considering the first parameter, e.g., in  X  X volutionOf( ,?artifact2) X . The attributes of variables  X ?artifact1 X  and  X ?artifact2 X  can be defined in the where clause. As illustrated in Figure 2-A, the result of this query will be a set of paths stored under an activity-path. Please refer to the extended version of the paper [2] to see the FPSPARQL translation of this query.
 5.2 Derivation Queries In AEM graphs, derivation of an entity En can be defined as all entities which En found to have been derived from them. In particular, if entity En b is reachable from entity En a in the graph, we say that En a is an ancestor of En b .Theresult of a derivation query for an AEM entity will be a set of AEM entities, i.e., its ancestors. For example, Adam is intere sted to find all ancestors of version v 3 of patient history (see Figure 1-C) generated in radiology clinic before March 2011. Following is the sample query for this example.
In this example, derivationOf statement is used to repre sent the derivation(s) of version v 3 of patient history. Attributes of variable  X ?artifact X  can be defined in the where clause. The filter statement is used to restrict the result to those activities, happened before March 2011 in radiology clinic. A sample graph result for this query has been depicted in Figure 1-C. Please refer to the extended version of the paper [2] to see the FPSPARQL translation of this query. 5.3 Timeseries Queries In analyzing AEM graphs, it is important to understand the timeseries, i.e., a sequence of data points spaced at uniform time intervals, of artifacts and actors over periods of time. To achieve this, we introduce timeseriesOf statement. The result of artifact/actor timeseries queries will be a set of artifact/actor over time, where each artifact/actor connected through a  X  X appened-before X  edge. For example, Adam is interested in Eli X  X  activities on the patient history document between timestamps  X  1 and  X  15 . Following is the sample FPSPARQL query for this example.
In this example, timeseriesOf statement is used to represent the timeseries of Eli, i.e., the variable  X ?actor X . Attributes of variable ? actor can be defined in the where clause. Considering the path number one in Figure 2-B, where Eli did activities on top of patient history document on  X  5 ,  X  9 ,and  X  14 ,Figure3 represents the timeseries of Eli for the this query. Please refer to the extended version of the paper [2] to see the FPSPARQL translation of this query. 5.4 Constructing Timed Folders To construct a timed folder node, we use FPSPARQL X  X  fconstruct statement proposed in [3]. We extend this statement with  X  X timed X  attribute. Setting the value of attribute timed to true for the folder, will assign a monitoring code snippet to this folder. The code snippet is responsible for updating the folder content over time: new members can be added to timed folders over time. For example, considering Figure 1-C, a timed folder can be constructed to represent a patient history document. Following is a sample query for this example.
In this example, variable  X ?med-doc X  represents the folder node to be con-structed (line 1). This folder is of type  X  X rtifact X  (line 2). Setting the attribute timed to true (line 2) will force new artifacts having the patient ID  X  X 14 X  (line 4) to be added to this folder over time. The attribute  X  X escription X  used to describe the folder (line 34. The variable  X ?version X  is an AEM entity and represents the patient history versions to be collected. Attribute  X  X atient-ID X  (line 4) indicate that the version is related to the patient history of the patient having the id  X  X 14 X . Please refer to the extended version of the paper [2] for more details. Implementation. The query engine is implemen ted in Java. Implementation details, including architecture and graphical representation of the query engine can be found in [2]. Moreover, we have implemented a front-end tool to assist process analysts in two steps: (i) Query Assistant: we provided users with a front-end tool (Figure 4-A) to generate AEM queries in an easy way. Users can easily drag entities (i.e., artifacts and actors) in the activity panel. Then they can drag the operations (i.e., evolution, derivation , or timeseries) on top of selected entity. The proposed templates (e.g., for evolution, derivation, and timeseries queries) will be automatically generated; and (ii) Visualizing: we provided users with a timeline like graph visualization (Figure 4-B) with facilities such as zooming in and zooming out.
 Experiments. We carried out the experiments on t hree time-sensitive datasets: (i) The real life log of a Dutch academic hospital 1 , originally intended for use in the first Business Process Intelligence Contest (BPIC 2011); (ii) e-Enterprise Course 2 , this scenario is built on our experience on managing an online project-based course; and (iii) Supply Chain Management log 3 . Details about this datasets can be found in [2]. The preprocessing of the log is an essential step in gaining meaningful insights and it can be time consuming. For example, the log of a Dutch academic hospital contains 1143 cases and 150291 events referring to 624 distinct activities. We extracted various activity attributes both at the event level and at the case level, e.g., 11 diagnosis code, 16 treatment code, and 16 attributes pertain-ing to the time perspective. Afterward, we generate the AEM graph model, out of these extracted informat ion. In particular, a system needs to be provenance-aware [7] to automatically collect and maintain the information about versions, artifacts, activities (and its attributes such as type, who, when).

We have compared our approach with that of querying open provenance model (OPM) [22]. We generated two types of graph models, i.e., AEM and OPM, from proposed datasets. The AEM graphs generated based on the proposed model in Section 4.1. The OPM graphs generated based on open provenance model specification [22]. Figure 5, represents a sample AEM graph (Figure 5-A) for the hospital log, a sample OPM graph generated from a part of AEM graph (Figure 5-B), and open provenance model entities and relationships (Figure 5-C). Both AEM and OPM graphs for each datasets loaded into FPSPARQL query engine. We evaluated the p erformance and the query results quality using the proposed graphs.
 Performance. We evaluated the performance of evolution, derivation, and time-series queries using execution time metric. To evaluate the performance of queries, we provided 10 evolution queries, 10 deriv ation queries, and 10 timeseries queries. These queries were generated by domain experts who were familiar with the pro-posed datasets. For each query, we gener ated an equivalent query to be applied to the AEM graphs as well as the OPM graphs for each dataset. As a result, a setofhis-torical paths for each query were discov ered. Figure 6 shows the average execution time for applying these queries to the AEM graph and the equivalent OPM graph generated from each dataset. As illustrated in Figure 6 we divided each dataset into regular number of events, then we generated AEM and OPM graph for differ-ent sizes of datasets, and finally we ran the experiment for different sizes of AEM and OPM graphs. We sampled different sizes of the graphs very carefully and based on related cases (patients in the log hospital, projects in the e-Enterprise project, and products in the SCM log) to guarantee the attributes of generated graphs. The evaluation shows the viability and efficiency of our approach.
 FPSPARQL queries can be run on two types of storage back-end: RDBMS and Hadoop. We also compare the performance of query plans on relational triple-stores and Hadoop file system. All experiments were conducted on a virtual ma-chine, having 32 cores and 192GB RAM. Fig ure 6-D illustrates the performance analysis between RDBMS and Hadoop for queries (average execution time) in Figure 6-A applied to Dutch academic hospital dataset. Figure 6-D shows an al-most linear scalability between the response time of FPSPARQL queries applied to Hadoop file system and the number of events in the log.
 Quality. The quality of results is assessed using classical precision metric which is defined as the percentage of discovered results that are actually interesting. In this context, interestingness is a subjective matter in its core, and our approach is to have statistical metrics and thresholds on what is not definitely interest-ing, and the results are presented to user for subjective assessment of their relevance, depending on what they are looking for. Therefore, for evaluating the interestingness of the result, we asked domain experts who had the most accurate knowledge about the datasets and the rel ated processes to analyze discovered paths and identify what they considered relevant and interesting. We evaluated the number of discovered paths for all th e queries (in performance evaluation) and the number of relevant paths chosen by domain experts. As a result of ap-plying queries to AEM graphs generated from all the datasets, 125 paths were discovered and examined by domain experts, and 122 paths (precision=97.6%) considered relevant. And as a result of applying queries to OPM graphs gener-ated from all the datasets, 297 paths discovered, examined by domain experts, and 108 paths (precision=36.4%) considered relevant.
 Discussion/Tradeoffs/Drawbacks. Cross-cutting aspects in ad-hoc processes differs from other forms of meta-data because they are based on the relationships among objects. Specifically for aspects such as provenance and versioning, it is the ancestry relationships that form the heart of ad-hoc processes X  data. There-fore, the proposed AEM model considers the issue of paths and cycles among objects in ad-hoc processes X  data. Evaluation shows that the path queries applied to the OPM graph resulted in many irrelevant paths and also many cycles dis-covered in the OPM graph: these cycles h ide the distinction between ancestors and descendants. Conversely, few cycles and irrelevant paths have been discov-ered in the AEM model. Moreover, to increase the performance of path queries in AEM graphs, we implemented an interface to support various graph reacha-bility algorithms such as all-pairs shortest path, transitive closure, GRIPP, tree cover, chain cover, and Sketch [2].

AEM model requires pattern matching over sequences of graph edges as well as pattern matching against the labels on graph edges, where the support for full regular expressions over graph edges is important. Moreover, AEM model re-quires the uniform representation of nodes and edges, where this representation encodes temporal data into versions while fully retaining the temporal informa-tion of the original data. Even though this may seem a bloated representation of the graph, however, this will guarantee the (provenance) graph to be acyclic, but risks leading to large quantities of data. This tradeoff is similar to the trade-offs for versioning, but it enables users to have reproducible results. In terms of versioning, versions can be created implicitly each time more information is addedtoanexistingartifact. We study the related work into three main areas: artifact-centric processes, provenance, and modeling/q uerying temporal graphs.
 Artifact-Centric Processes. Knowledge-intensive processes almost always in-volve the collection and presentation of a diverse set of artifacts and capturing the human activities around artifacts. This, emphasizes the artifact-centric na-ture of such processes where time becomes an important part of the equation. Many approaches [17,13,5,8,6] used business artifacts that combine data and process in a holistic manner and as the basic building block. Some of these works [17,13,8] used a variant of finite state machines to specify lifecycles. Some theoretical works [6,5] exp lored declarative approaches to specifying the artifact lifecycles following an event oriented style. Another line of work in this category, focused on modeling and querying artifact -centric processes [20,30,11]. In [20,30], a document-driven framework, propos ed to model business process management systems through monitoring the lifecycl e of a document. Dorn et.al. [11], pre-sented a self-learning mechanism for determining document types in people-driven ad-hoc processes through combining process information and document alignment. Unlike our approach, these approaches assumed a predefined docu-ment structure or they presume that the e xecution of the business processes is achieved through a BPM system (e.g., BPEL) or a workflow process.

Another related line of work is artifact-centric workflows [5] where the pro-cess model is defined in terms of the lifecycle of the documents. Some other works [25,9,10,27], focused on modeling and querying techniques for knowledge-intensive tasks. Some of existing approaches [25] for modeling ad-hoc processes focused on supporting ad-hoc workflows through user guidance. Some other ap-proaches [9,10,27] focused on intelligent user assistance to guide end users during ad-hoc process execution by giving reco mmendations on possible next steps. All these approaches focused on user activities and guide users based on analyzing past process executions. Unlike these approaches, in our model (AEM), actors, activities, artifacts, and artifact versions are first class citizens, and the evolution of the activities on artifacts over time is the main focus.
 Provenance. Many provenance models have been presented in a number of domains (e.g., databases, scientific workflows and the Semantic Web), motivated by notions such as influence, dependence, and causality. The existing provenance models, e.g., the open provenance model (OPM) [22], treat time as a second class citizen (i.e., as an optional annotation of the data) which will result in loosing semantics of time and makes querying and analyzing provenance data for a particular point in time inefficient and sometimes inaccessible. Discovering historical paths through provenance graphs forms the basis of many provenance query languages [18,15,32]. In ProQL [18], a query takes a provenance graph as an input, matches parts of the input graph according to path expression and returns a set of paths as the result of the query. PQL [15] proposed a semi-structured model for handling provenance and extended the Lorel query language for traversing provenance graph. NetTrails [32] proposed a declarative platform for interactively querying prov enance data in a distributed system. In our approach, we introduce an extended provenance graph model to explicitly represent time as an additional dimension of provenance data.
 Modeling/Querying Temporal Graphs. In recent years, a plethora of work [16,19,26] has focused on temporal graphs to model evolving, time-varying, and dynamic networks of data. Ren et al. [26] proposed a historical graph-structure to maintain analytical processing on such evolving graphs. Moreover, authors in [19,26] proposed approaches to transform an existing graph into a similar temporal graph to discover and d escribe the relationship between the internal object states. In our approach, we propose a temporal artifact evolution model to capture the evolution of time-sensitive data where this data can be modeled as temporal graph. We also provide abstractions and efficient mecha-nisms for time-aware querying of AEM graphs.

Approaches for querying graphs (e.g., [1,14,24,29]) provide temporal extensions of existing graph models and languages. Tappolet et al. [29] provided temporal se-mantics for RDF graphs. They proposed  X  -SPARQL for querying temporal graphs. Grandi [14] presented another temporal extension for SPARQL, i.e. T-SPARQL, aimed at embedding several features of TSQL2 [21] (temporal extension of SQL). SPARQL-ST [24] and EP-SPARQL [1] are extensions of SPARQL supporting real time detection of temporal complex patterns in stream reasoning. Our work dif-fers from these approaches as we enable registering time-sensitive queries, propose timed abstractions to store the result of such queries, and enable analyzing the evolution of such timed abstractions over time. In this paper, we have presented an artifact-centric activity model (AEM) for ad-hoc processes. This model supports timed queries and enables weaving cross-cutting aspects, e.g., versioning and prov enance, around business artifacts to im-bues the artifacts with additional semantics that must be observed in constraint and querying ad-hoc processes. Two concepts of timed folders and activity-paths have been introduced, which help in analyzing AEM graphs. We have extended FPSPARQL [3,4] to query and analyze AEM graphs. To evaluate the viability and efficiency of the proposed framework, we have compared our approach with that of querying OPM models. As future work, we are weaving the timed ab-stractions with our work on on-line analytical processing on graphs [4] to support business analytics. Moreover, we plan to employ interactive graph exploration and visualization techniques to design a visual query interface.

