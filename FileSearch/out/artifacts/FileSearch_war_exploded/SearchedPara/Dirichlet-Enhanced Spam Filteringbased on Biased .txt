 Design and analysis of most machine learning algorithms are based on the assumption that the train-ing data be drawn independently and from the same stationary distribution that the resulting model will be exposed to. In many application scenarios, however, control over the data generation pro-cess is less perfect, and so this iid assumption is often a naive over-simplification. In econometrics, learning from biased samples is a common phenomenon, where the willingness to respond to sur-veys is known to depend on several characteristics of the person queried; work that led to a method for correcting sample selection bias for a class of regression problems has been distinguished by a Nobel Prize [6]. In machine learning, the case of training data that is only biased with respect to the ratio of class labels has been studied [4, 7]. Zadrozny [14] has derived a bias correction theorem that applies when the bias is conditionally independent of the class label given the instance, and when every instance has a nonzero probability of being drawn into the sample. Sample bias correction for maximum entropy density estimation [3] and the analysis of the generalization error under covariate shift [12] follow the same intuition.
 In our email spam filtering setting, a server handles many email accounts (in case of our industrial partner, several millions), and delivers millions of emails per day. A magnitude of spam and  X  X am X  ( i.e., non-spam) sources are publicly available. They include collections of emails caught in  X  X pam traps X   X  email addresses that are published on the web in an invisible font and are harvested by spammers [11]  X  the Enron corpus that was disclosed in the course of the Enron trial [8], and Spam-Assassin data. These collections have diverse properties and none of them represents the global distribution of all emails, let alone the distribution received by some particular user. The resulting bias does not only hinder learning, but also leads to skewed accuracy estimates, since individuals may receive a larger proportion of emails that a filter classifies less confidently. The following data generation model is paramount to our problem setting. An unknown process, distribution of incoming spam ( y = +1 ) or ham ( y =  X  1 ) messages x .
 The goal is to obtain a classifier f i : x 7 X  y for each  X  i that minimizes the expectation of some loss Labeled training data L are drawn from a blend of data sources (public email archives), resulting in  X  and  X  is such that (a) any x that has nonzero probability density p ( x |  X  ) of being drawn into the In addition to the (nonempty) labeled sample, zero or more unlabeled data U i are available for each  X  and are drawn according to  X  i . The unlabeled sample U i is the inbox of user i . The inbox is empty for a newly established account and grows from there on. Our problem setting corresponds to an application scenario in which users are not prepared to manually tag spam messages in their inbox. Due to privacy and legal constraints, we are not allowed to personally read (or label) any single personal email; but the unlabeled messages may be used as input to an automated procedure. The individual distributions  X  i are neither independent (identical spam messages are sent to many users), nor are they likely to be identical: distributions of inbound messages vary greatly between (professional, recreational, American, Chinese, . . . ) email users. We develop a nonparametric hier-archical Bayesian model that allows us to impose a common prior on new  X  i . Such generalization may be particularly helpful for users with little or no available data U i . The desired outcome of the learning process is an array of personalized spam filters for all users.
 The rest of this paper is structured as follows. We devise our solution in Section 2. In Section 3, we study the effectiveness of correcting sample bias for spam, and of using a Dirichlet process to generalize across users, experimentally. Section 4 concludes. The available labeled data L are governed by p ( x |  X  ) ; directly training a classifier on L would there-to find classifiers f i that minimize, for user i , the expected loss E ( x ,y )  X   X  p ( x |  X  i ) . We can minimize the loss with respect to  X  i from a sample L whose instances are governed by  X  when each instance is re-weighted. The weights have to be chosen such that minimizing the loss on the weighted sample L amounts to minimizing the loss with respect to  X  i .
 In order to derive weighting factors with this property, consider the following model of the process that selects the labeled sample L . After drawing an instance x according to p ( x |  X  i ) , a coin s is label) if s = 1 ; otherwise, x is discarded. Our previous assumption that any x with positive p ( x |  X  ) also has a positive p ( x |  X  i ) implies that there exists a p ( s | x ,  X  i ,  X  ) such that fact minimizes the expected loss with respect to  X  i . The rationale behind this claim deviates only in minor points from the proof of the bias correction theorem of [14]. Proposition 1 introduces a normalizing constant p ( s = 1 |  X  i ,  X  ) . Its value can be easily obtained as it normalizes Equation 1. Proposition 1 The expected loss with respect to p ( x , y |  X   X  i ) = p ( x , y |  X  ) p ( s =1 |  X  i , X  ) pected loss with respect to p ( x , y |  X  i ) , when p ( s | x ,  X  i ,  X  ) satisfies Equation 1. Proof. Equation 2 expands the expected value and the definition of p ( x , y |  X   X  i ) in Proposition 1. tion 4. Equation 4 is rewritten as an expected value.
 2.1 Individualized Bias Estimation individualized empirical sample bias is an estimate of the unknown true bias, conditioned on a user X  X  unlabeled inbox U i and labeled data L ; hence,  X  p I ( s | x ,  X  i ,  X  ) = p ( s | x , U i , L ) . Equation 1 immediately implies been selected into the labeled sample; i.e., s = 1 | x  X  L . Instances in U i have not been selected into the labeled sample; i.e., s = 0 | x  X  U i . We define s U instances in U i and L . That is, s U A density estimator  X  p ( s | x ,  X ,  X  i ) can be trained on the instances in L and U i , using vector s U target variable. We use a regularized logistic regression density estimator parameterized with w i : The likelihood of the density estimator is We train parameters w i = argmax regularizer) [15] using the fast implementation of regularized logistic regression of [9]. 2.2 Dirichlet-Enhanced Bias Estimation on the new user X  X  inbox U n +1 and the labeled data L , but also on all other users X  inboxes. We write  X  p Equation 1 says that there is a p ( s = 1 | x ,  X  n +1 ,  X  ) for user n + 1 that satisfies Equation 5. Let us assume a parametric form (we employ a logistic model), and let w n +1 be the parameters that cess G |{  X , G 0 }  X  DP (  X , G 0 ) with concentration parameter  X  and base distribution G 0 generates parameters w i : The first element w 1 is drawn according to G 0 ; in our case, the uninformed prior. It generates w n +1 according to Equation 8, where  X  ( w i ) is a point distribution centered at w i . Equation 9 integrates over the parameter of the bias for new user n + 1 . Equation 10 splits the posterior into the likelihood of the sample selection coin tosses and the common prior which is modeled as a Dirichlet process. Likelihood P ( s U 2.3 Estimation of the Dirichlet Process The parameters of previous users X  bias w 1 , . . . , w n constitute the prior w n +1 |{ w i } n since this is not feasible, MCMC sampling [10] or variational approximation [1] can be used. more than 800,000 dimensions. In each iteration of the MCMC process or the variational inference of [1], logistic density estimators for all users would need to be trained X  X hich is prohibitive. We therefore follow [13] and approximate the Dirichlet Process as Compared to the original Equation 8, the sum of point distributions at true parameters w i is replaced by a weighted sum over point distributions at pivotal w  X  steps. First, pivotal models of the sample bias are trained for each user i , solely based on a user X  X  inbox and the labeled data. Secondly, parameters  X  i are estimated using variational EM; they express correlations between, and allow for generalization across, multiple users. Tresp and Yu [13] suggest to use a maximum likelihood estimate w  X  Algorithmically, the pivotal models are obtained analogously to the individualized estimation of the selection bias for each user described in Section 2.1.
 After the pivotal models have been identified, an EM algorithm maximizes the likelihood over the parameters  X  i . For the E step we rely on the assumption that the posterior is a weighted sum over point distributions at the pivotal density estimates (Equation 13). With this assumption, the posterior is no longer a continuous distribution and the E step resolves to the computation of a discrete number of variational parameters  X  ij (Equation 14). Equation 11 yields the M step with  X  i = P n as in Equation 7. The entire estimation procedure is detailed in Table 1, steps 1 through 3. 2.4 Inference Having obtained pivotal models p ( s | x ; w  X  the known users from U 1 , . . . , U n . At application time, we may furthermore experience a message bound for user n + 1 .
 Without loss of generality, we discuss the inference problem for a new user n + 1 . Inserting  X  G ( w ) into Eqs. 9 and 10 leads to Equation 15. Expanding  X  G ( w ) according to Eq. 11 yields Equation 16. The second summand in Equation 16 is determined by summing over the pivotal models p ( s | x ; w  X  The first summand can be determined by applying Bayes X  rule in Equation 17; G 0 is the uninformed prior; the resulting term p ( s | x , U n +1 , L ) = p ( s | x ; w  X  estimator, trained to discriminate L against U n +1 . It is determined as in Equation 12. weighted sum of the pivotal density estimate p ( s | x ; w  X  all users i ; the latter are weighted according to their likelihood P ( s U ing the messages of user n + 1 . Inference for the users that are available at training time is carried out in step 4(a) of the training procedure (Table 1).
 Input: Labeled data L , unlabeled inboxes U 1 , . . . , U n . Return classifiers f i for all users i . 2.5 Training a Bias-Corrected Support Vector Machine Given the requirement of high accuracy and the need to handle many attributes, SVMs are widely acknowledged to be a good learning mechanism for spam filtering [2]. The final bias-corrected SVM f n +1 can be trained by re-sampling or re-weighting L according to s ( x ) = that assures P term) of  X  k . The expected contribution of x k to the SVM criterion is s ( x )  X  k because x k will be drawn s ( x ) times on average into each re-sampled data set. Therefore, training the SVM on the re-sampled data or optimizing with re-scaled slack terms lead to identical optimization problems. Optimization Problem 1 Given labeled data L , re-sampling weights s ( x ) , and regularization pa-rameter C ; over all v , b ,  X  1 , . . . ,  X  m , minimize The bias-corrected spam filter is trained in step 4(b) of the algorithm (Table 1). 2.6 Incremental Update The Dirichlet-enhanced bias correction procedure is intrinsically incremental, which fits into the typical application scenario. When a new user n + 1 subscribes to the email service, the prior w U n +1 is still empty (the new user has not yet received emails), then the regularizer of the density esti-for the new user proceeds as discussed in Section 2.4.
 When data U n +1 becomes available, the prior can be updated. This update is exercised by invok-ing the EM estimation procedure with additional parameters  X   X  P ( s U procedure returns the updated prior w n +2 | L, { U i } n +1 In our experiments, we study the relative benefit of the following filters. The baseline is constituted by a filter that is trained under iid assumption from the labeled data. The second candidate is a  X  X ne size fits all X  bias-corrected filter. Here, all users X  messages are pooled as unlabeled data and the bias p ( s | x ,  X  n +1 ,  X  ) is modeled by an estimator  X  p O ( s | x ,  X  n +1 ,  X  ) = p ( s | x , the Dirichlet-enhanced bias-corrected filter. It uses the hierarchical Bayesian model to determine messages, the labeled data, and all previous users X  messages.
 Evaluating the filters with respect to the personal distributions of messages requires labeled emails from distinct users. We construct nine accounts using real but disclosed messages. Seven of them contain ham emails received by distinct Enron employees from the Enron corpus [8]; we use the individuals with the largest numbers of messages from a set of mails that have been cleaned from spam. We simulate two foreign users: the  X  X erman traveler X  receives postings to a moderated German traveling newsgroup, the  X  X erman architect X  postings to a newsgroup on architecture. Each account is augmented with between 2551 and 6530 spam messages from a distinct source, see Table 2. The number of ham emails varies between 1189 and 5983, reflecting about natural ham-to-spam ratios. The ham section of the labeled data L contains 4000 ham emails from the Spam-Assassin corpus, 1000 newsletters and 500 emails from Enron employee Taylor. The labeled data contain 5000 spam emails relayed by blacklisted servers. The data are available from the authors. The total of 76,214 messages are transformed into binary term occurrance vectors with a total of 834,661 attributes; charset and base64 decoding are applied, email headers are discarded, tokens occurring less than 4 times are removed. SVM parameter C , concentration parameter  X  , and the regularization parameter of the logistic regression are adjusted on a small reserved tuning set. We iterate over all users and let each one play the role of the new user n + 1 . We then iterate over the size of the new user X  X  inbox and average 10 repetitions of the evaluation process, sampling U n +1 from the inbox and using the remaining messages as hold-out data for performance evaluation. We train the different filters on identical samples and measure the area under the ROC curve (AUC). Figure 1 shows the AUC performance of the iid baseline and the three bias-corrected filters for the first two Enron and one of the German users. Error bars indicate standard error of the difference to dependent on strength of iid violation (center); number of existing users vs. training time (right). the iid filter. Figure 2 (left) aggregates the results over all nine users by averaging the rate by which the risk 1  X  AUC is reduced. We compute this reduction as 1  X  1  X  AUC corrected is one of the bias-corrected filters and AUC baseline is the AUC of the iid filter.
 The benefit of the individualized bias correction depends on the number of emails available for that user; the 1  X  AUC risk is reduced by 35-40% when many emails are available. The  X  X ne size fits all X  filter is almost independent of the number of emails of the new user. On average, the Dirichlet-enhanced filter reduces the risk 1  X  AUC by about 35% for a newly created account and by almost 40% when many personal emails have arrived. It outperforms the  X  X ne size fits all X  filter even for an empty U n +1 because fringe accounts ( e.g., the German users) can receive a lower weight in the common prior. The baseline AUC of over 0.99 is typical for server-sided spam filtering; a 40% risk reduction that yields an AUC of 0.994 is still a very significant improvement of the filter that can be spent on a substantial reduction of the false positive rate, or on a higher rate of spam recognition. The question occurs how strong a violation of the iid assumption the bias correction techniques can compensate. In order to investigate, we control the violation of the iid property of the labeled data as follows. We create a strongly biased sample by using only Enron users as test accounts  X  i , and not using any Enron emails in the labeled data. We vary the proportion of strongly biased data versus randomly drawn Enron mails in the labeled training data (no email occurs in the training and testing data at the same time). When this proportion is zero, the labeled sample is drawn iid from the testing distributions; when it reaches 1, the sample is strongly biased. In Figure 2 (center) we observe that, averaged over all users, bias-correction is effective when the iid violation lies in a mid-range. It becomes less effective when the sample violates the iid assumption too strongly. In this case,  X  X aps X  occur in  X  ; i.e., there are regions that have zero probability in the labeled data L  X   X  but nonzero by weighting data drawn according to p ( x |  X  ) ineffective.
 Figure 2 (right) displays the total training time over the number of users. We fix | U n +1 | to 16 and vary the number of users that influence the prior. The iid baseline and the individually corrected filter scale constantly. The Dirichlet-enhanced filter scales linearly in the number of users that constitute the common prior; the EM algorithm with a quadratic complexity in the number of users contributes only marginally to the training time. The training time is dominated by the training of the pivotal models (linear complexity). The Dirichlet enhanced filter with incremental update scales favorably compared to the  X  X ne size fits all X  filter. Figure 2 is limited to the 9 accounts that we have engineered; the execution time is in the order of minutes and allows to handle larger numbers of accounts. It is most natural to define the quality criterion of an email spam filter with respect to the distribution that governs the personal emails of its user. It is desirable to utilize available labeled email data, but assuming that these data were governed by the same distribution unduly over-simplifies the problem setting. Training a density estimator to characterize the difference between the labeled training data and the unlabeled inbox of a user, and using this estimator to compensate for this discrepancy, im-proves the performance of a personalized spam filter X  X rovided that the inbox contains sufficiently many messages. Pooling the unlabeled inboxes of a group of users, training a density estimator on this pooled data, and using this estimator to compensate for the bias outperforms the individualized bias-correction only when very few unlabeled data for the new user are available.
 We developed a hierarchical Bayesian framework which uses a Dirichlet process to model the com-mon prior for a group of users. The Dirichlet-enhanced bias correction method estimates  X  and com-pensates for  X  the discrepancy between labeled training and unlabeled personal messages, learning from the new user X  X  unlabeled inbox as well as from data of other users. Empirically, with a 35% reduction of the 1  X  AUC risk for a newly created account, the Dirichlet-enhanced filter outper-forms all other methods. When many unlabeled personal emails are available, both individualized and Dirichlet-enhanced bias correction reduce the 1  X  AUC risk by nearly 40% on average. Acknowledgment This work has been supported by Strato Rechenzentrum AG and by the German Science Foundation DFG under grant SCHE540/10-2.

