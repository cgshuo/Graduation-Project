 Spatial collaboration is a specialized form of collaboration where the discussion relates to a physical space. This work investigates how to support distributed spatial collaboration activities. It presents a novel prototype that integrates both two -dimensional and three -dimensional representations. This collaborat ive software is examined in a qualitative study as a group virtually rearranges their lab furniture. The results describe the group X  X  collaboration and their use of the combined representations. The findings highlight the usefulness of multiple representat ions and the need for additional features to support collaboration across representations.
 D H.5.3 [ Information Interfaces and Presentation ]: Group and Organization Interfaces  X  collaborative computing, computer -support ed cooperative work, Design, Experimentation, Human Factors Collaborative visualization, interactive maps, collaborative virtual environments (CVE), groupware, awareness . Spatial collaboration describes the combined work of multiple people to solve problems involving physical space [21]. This space is typically large. It might be indoors, such a home or an office, or it could be outdoors, such as a yard or a nature park. With the indoor spaces, the collaboration activitie s might involve discussing floor plan layouts, including the uses for various rooms and the locations of furniture. In outdoor spatial collaboration, a landscape architect might need to work with a client to design the trees, shrubs, and flowers to surroun d a new building. The common factor is that groups of people are collaborating to solve a spatial problem involving a physical area.
 Distributed collaboration research has investigated a variety of task domains, such collaborative writing, shared calendars, and instant messaging, but only a few projects have looked at tasks involving spatial problems. Shared whiteboards are one example. They encourage spatial discussions through collaborative drawing features. Similarly, groupware research has exa mined tasks such as arranging newspaper articles [10], editing concept maps [8], and creating fictitious pipelines [9]. These applications have not considered representing large, physical spaces, however. The requirements for supporting collaboration focu sed on a physical space, or spatial collaboration, are different. For instance, a representation of a physical space will likely require additional features. Physical spaces are much more complex than drawings, newspapers, and concepts maps. Navigation tec hniques such as scaling and levels of detail are often needed manage this complexity. Spatial collaboration also involves discussions with many spatial concepts. Collaborators reference location information, distance measurements, and route -based direction s as they share ideas related to a particular spatial environment. Typical shared whiteboards and groupware tools do not facilitate these discussions.
 Distributed spatial collaboration is a common activity that lacks a collaborative solution. Consider the case of a landscape architect or an interior designer working with a client. The two parties are often in different locations and they frequently need to discuss a spatial design.
 The work described in this paper investigates a case of an existing group. T he group is interested in rearranging their lab furniture, although all of the group members are rarely together at the same time to discuss the changes. Our work designs and evaluates a novel prototype to investigate the group X  X  spatial collaboration need s.
 The prototype is unique in its use of two types of spatial representations. Spatial collaboration problems are often complex and involve numerous considerations. Multiple, different representations can enable the users to explore various aspects of the space and produce a comprehensive solution. This work integrates a two -dimensional and a three -dimensional representation. Somewhat similar to commercial games that use two -dimensional overviews and three -dimensional action environments, this work investig ates the combination of differing dimensional representations. In particular, the prototype allows each user to view one type of representation and provides techniques to switch between the two. This design is interesting because the collaborators can choo se to use the same or different representations depending on the task at hand. While collaborating some of the group members might work with the same two -dimensional representation or the same three -dimensional representation. In other instances, a combina tion of the two -dimensional and three -dimensional views might be beneficial. This work considers how the multiple representations support different activities. It examines choices made between the two representations and observes how the collaborators coor dinate their representations to complete the task in a distributed setting. In the following sections, we discuss work related to spatial collaboration and the prototype design. We present the observations from a qualitative study with the participant gro up and discuss the implications for the design of spatial collaboration solutions. Spatial collaboration relates to the field of geocollaboration [18]. These systems focus on collaborative, geographic visualizations to solve domain specific pr oblems. For instance, a project at the GeoVISTA Center allows distributed scientists to explore climate and drainage patterns [19]. The GroupARC prototype integrates a GIS with a groupware toolkit [5]. Our work differs from these projects in the study of m ore informal spatial collaboration tasks, such as furniture rearranging.
 The prototype in our work includes a Collaborative Virtual Environment (CVE). CVEs allow distributed users to share and manipulate objects in a three -dimensional environment. One exam ple is the prototype CALVIN [16]. This system explores using different virtual reality hardware configurations, such as CAVE and Immersadesk technology, for collaboration. The findings indicate that users with an exocentric, or birds -eye, viewpoint take ch arge of large object movements, while egocentric, or first person, viewpoint users perform fine adjustments [15]. This agrees with the belief that a first -hand view affords fine grain manipulations, while a global view preferable for gross manipulations [2 7]. Marsic has also explored an infrastructure for multiple hardware displays that supports different dimensional representations [20]. The work reported here is an extension, investigating desktop displays and differing representations. It considers how a choice in representation affects the collaboration of a real group, as opposed to pre -assigning participants to specific representations.
 Other prominent CVE research has studied object -focused interactions with desktop, collaborative virtual environments [11, 12]. Using a furniture manipulation task, they observe collaboration issues with CVEs. They report on problems with limited fields of view, additional speech to compensate, and difficulties understanding other users X  perspectives. Our work uses a sim ilar furniture task and considers a different collaborative interface. Integrating multiple representations, the prototype explores how multiple views can support spatial collaboration. One thought is that these integrated spatial representations will limi t the collaboration issues observed in prior CVE work. With a choice in representations, the collaborators will not have to rely on only the awareness cues available with the three -dimensional representation.
 This work also relates to mixed reality systems . In studying a game between online players and people jogging in the real world, the Equator project used both a CVE and collaborative, two -dimensional map [6]. The representations were fixed so that the players interacted with the CVE and the runners use d the map. Also, mixed reality museums have supported combinations of physical museum visitors, virtual reality visitors, and web -based visitors, using a shared two -dimensional map that indicates each person X  X  location and orientation [2, 17]. The focus o f this work differs from playing a spatial game or making a museum exhibit enjoyable. It concerns solving spatial problems through object -focused interactions. We have previously investigated distributed spatial collaboration. In a two -dimensional experiment, a collaborative map was used to study navigation and awareness techniques [21] (Figure 1). Use of map software is common with the availability of consumer products and online services. The study compared two navigation techniques in combination with two approaches to radar views. As an awareness technique, radar views display a miniature of the entire representation and indicate each collaborator X  X  current viewport into the representation. Pairs of users completed map -marking tasks w ith each of the techniques in an empirical study. This work reuses the continuous navigation design, which offers many overlapping viewports into the space. It also reuses the traditional radar view, which displays colored boxes for each collaborator X  X  vie wport. The prior study showed that continuous navigation supports the collaborators X  comprehension of a space and that the traditional radar view offers an intuitive design. Figure 1. A collaborative map in a previous study used a radar view (on the left) to display the collaborators X  viewports.
 A second experiment studied the effects of different frames of reference within a CVE [22]. It investigated combinations of an exocentric, or bird X  X  -eye, frame of reference and an egocentric, or first person frame of reference (Figure 2). Working in pairs with both similar and different viewpoints, one participant knew the task objective and the other completed the necessary object manipulations. Avatars within the environment indicated each collaborator X  X  position and orientation. The work described here reuses the egocentric frame of reference, which afforded exploring the space firsthand, examining the details, and recognizing fine grain tasks. It also reconsiders the combination of exocentric and egocentric persp ectives. Previously, egocentric pairs required quite a bit of time to complete the tasks, but understood each other X  X  ideas the best; exocentric pairs completed tasks quickly, but found them difficult; and combination pairs took advantage of their differin g perspectives. Figure 2. A collaborative virtual environment investigated combinations of egocentric (above) and exocentric (below) frames of reference. Spatial collaboration activities such as landscaping, interior design, and furniture arran gement are complex. They all involve the design of a physical space. In same -place collaboration, multiple perspectives are used to create and evaluate solutions. For instance, in rearranging furniture, people often move around the room and view it from di fferent perspectives. Likewise, multiple representations can provide different perspectives in an online tool. Two -dimensional representations can show the layout of the space and the locations of features with respect to one another. Three -dimensional rep resentations can portray the height of features, elevation changes, and shadows. Our prototype combines these two representations to investigate their use in a collaborative setting. Unlike prior work, the study does not directly contrast the two -dimensio nal versus the three -dimensional, nor does it compare user interactions performed with each interface [e.g. 4, 24, 26]. Rather, it examines their use together in a single system.
 Participants can choose to interact with either a two -dimensional representat ion, called a floor plan, or a three -dimensional representation, known as a virtual environment. An alternative user interface design would allow users to view both representations on the screen at the same time. In this study, however, limiting the users to one representation allows the work to investigate how the two representations are used. The researchers can easily monitor which representation each participant is attending to and his/her current goals.
 The representations in the prototype include a s imilar set of moveable objects. These objects correspond to actual furniture pieces in the participants X  lab and they are shared, such that when an object X  X  position changes all the participants witness this manipulation from their own display. The changes occur in both the floor layout and the virtual environment synchronously. Object interaction is restricted so that only one user can manipulate an object at a time. Figure 4 shows a user manipulating an object with the floor plan. In Figure 5, this user h as switched interfaces. He/She is working with the same object and another collaborator interacting with the virtual environment is visible. The current visualization techniques are appropriate for the lab furniture task and the research group. Other appl ications, like landscape architecture and interior design, however, will likely require enhancements. The prototype includes awareness features that allow the collaborators to understand each other X  X  work efforts. In addition to the prim ary display with either the floor plan or the virtual environment, a radar view offering awareness information is ever -present. The radar view displays a miniature of the entire space and indicates each collaborator X  X  current representation and their view into the space (Figure 3). The radar view is unlike previous designs [e.g. 1, 8, 25] in that it portrays information for both representations. It uses a colored rectangle to indicate a user X  X  viewport into the floor plan and a crosshair, or telepointer, to indicate the position of the cursor. For the virtual environment, a colored v -shape reflects a user X  X  location and field of view. A colored line also signifies the direction the user X  X  cursor in the virtual environment. Combining the v and line can someti mes look like an arrow, although this is not intentional. Each collaborator is assigned a color that is used within the radar view and with the other awareness features.
 There are also awareness cues for collaborators using the same representation concurre ntly. In the floor plan, users are indicated within the display with colored rectangles and crosshairs identical to radar view. These markings on the floor plan are only visible when there is an overlap between viewports. Similarly, in the virtual environm ent, floating head avatars represent other collaborators looking at the virtual environment. Considering the user embodiment design issues identified in prior work [3], the head and face reflects a collaborator X  X  location and orientation within the environ ment. The color of the hair identifies the collaborator. A similarly colored line emanating from the floating head indicates the direction of the user X  X  pointing and manipulation interactions. This line directly corresponds to user X  X  cursor location on the screen. Opaque objects within the environment, such as walls and doors, block a user X  X  view of the avatars and lines.
 Figure 3. The radar view uses a rectangle and crosshair to represent a user looking at the floor plan. A v shape and extended line indic ates a user within the virtual environment . environment.
 The prototype incorporates interaction techniques that are pe rformed with a mouse and keyboard. The techniques allow users to navigate each representation, switch between the representations, and select and manipulate objects . The floor plan interface supports zooming and panning through scroll bars and a slider widget. The zoom slider is to the left of the floor plan so it will not be confused with panning [23]. In the virtual environment, users experience the representation by walking and looking around the environment. They cannot  X  X ly X  throug h the space or change the height of their viewpoint. Arrow keys move the user forward/backward and side step left/right. One can walk through objects and walls. Clicking and dragging on the window changes a user X  X  orientation. This allows the user to turn and look in a different direction. A button on the always -present radar view provides the switch from the virtual environment to the floor plan. The interface automatically adjusts the user X  X  orientation so that he/she is looking straight ahead, as opposed to slightly up or down, and so that he/she faces the direction that corresponds to the top of the floor plan. The display animates from a forward -facing viewpoint to top -down view of the virtual environment and then switc hes to the floor plan. In the newly switched to interface, the floor plan is centered on the user X  X  prior location in the virtual environment. To switch from the floor plan to the virtual environment, there is a context, or pop -up, menu feature. Using the menu on the floor plan, the user specifies the desire to switch and his/her new location in the virtual environment. A similar animation occurs in reverse In both interfaces, objects are selected with a mouse click and the n indicated by a colored bounding box. If the user clicks on a location without a selectable object, the current selection is released. To perform the selection in the virtual environment, the position of the cursor on the screen is transformed into three -dimensional ray. Furniture objects along this ray can be selected. When the ray does not intersect an object, a click releases the current selection.
 With the floor plan, users drag the objects to reposition. Rotation is available through a small, circular handle. Dragging the handle, a dashed circle signifies the interaction and the object turns accordingly. When an object is selected in the virtual environment, a popup menu offers buttons for manipulation. Both forward/backward and left/right movements a re based on the user X  X  perspective. Objects can move through one another and pass through the walls. The software in the prototype uses the Simple Virtual Environment Toolkit (SVE) to generate the virtual environment [14]. The floor plan ex pands on Java software created for previous map prototypes. Both representations interface with the Content Object Replication Kit (CORK) that provides distributed data sharing [13]. The study examines a realistic setting of distributed s patial collaboration. It does not use a formal experiment with anonymous participants like previous spatial collaboration studies [i.e. 21, 22]. It rather observes one group X  X  efforts to address a realistic, complex, and open -ended spatial problem. This gr oup is the 3D Interaction research group at Virginia Tech. The members are experienced with interactions in two -dimensional and virtual environment software and their research focuses on single user systems. This group allows us to focus the evaluation on collaboration, rather than interaction issues, and offers a rigorous test of the prototype. The task is also realistic in that the group has recently tried different furniture configurations for their lab space and has yet to identify an arrangement they e njoy. This study uses four active members of the group, three male graduate students and one female graduate student. The participants are very familiar with one another and they frequently work together. They are all knowledgeable about the lab space and the furniture needs. They participate in two collaborative sessions on two different days. The first day examines the usability features of the prototype and initiates collaboration on the furniture arrangement problem. The participants are given a brief overview of the system and then work together on a simple task to become familiar with the interface and provide constructive criticism. Pretending to be in different physical locations, they interact with the prototype and collaboratively reposition the f urniture objects. The furniture is initially positioned in random, scattered locations within the space and their objective is to reposition it along the outside walls of the lab. They explore the two interfaces, including the furniture objects, the awaren ess features, and each of the interaction techniques. The task lasts twenty minutes with another twenty minutes to discuss the features in a face -to -face meeting facilitated by the researcher. The rest of the session focuses on the realistic problem of des igning a new furniture arrangement for their lab. Using the prototype again, they see the furniture in the same preset, random locations and begin to investigate different designs. Manipulating objects, switching between interfaces, and having discussions they exchange different layout ideas. This lasts another twenty minutes.
 In the second session, the furniture arrangement discussion continues and a concluding meeting occurs. The participants do not talk with one another about the project between sessions . The prototype initially displays the present, random arrangement and the group quickly begins to rearrange objects, discussing the past ideas and investigating new positions. After forty minutes, each object is in different location and an overall layout exists. Everyone is in agreement about the design during a final face -to -face meeting. During this time, the group reflects on their approach to the problem, the different strategies used, and their solution.
 In both sessions, the participants are seated at four different computers located outside of their lab space. To create a distributed setting, dividers are positioned between them so they cannot see one another or each other X  X  screens. This allows them to converse without additional technology. They a re asked not to get up or move from their seat. This experimental setup is unique in that one researcher can easily observer the interactions of all four participants. Positioning the computers so that they all faced a central location, the researcher can walk around the outside and view the monitors. Future work could investigate the use of video -conferencing in spatial collaboration tasks. This study, however, focuses on the utility of the prototype in a common, audio -conferencing setting.
 Throughout the study, we recorded the audio conversations and the video of the four displays. The four video streams were combined into one split -screen recording for analysis. A number of observations were made while the participants worked with the prototy pe. Some of these observations relate to the group X  X  general collaboration approaches, while others relate to their use of the different types of representations. In general, the collaborators took an ad hoc approach towar d the furniture layout problem. Initially, there were comments such as  X  X hat are we going to do? X  and suggestions such as  X  X hould we all go down there and see what X  X  going on? X  in reference to the virtual environment. These statements were directed to the entire group, but in some cases no one responded and in others only one collaborator agreed to switch to the virtual environment. Instead, each participant explored the space individually and thought about new design ideas. Eventually, one user made a loca tion suggestion and another participant responded with his comments, but the others still continued with an individual approach. This style of behavior was observed throughout the sessions. Often, it was clear that two people w ere closely working together. Engaged in an ongoing conversation, they did not reference each other by name, but rather made statements such as  X  X ow about this? X  and the other would quickly respond. While their conversation progressed, the other participan ts remained silent. Sometimes this lack of talking was attributed to being engrossed in a different, individual task and other times the participants were simply observing and not sharing their own ideas. For instance, one participant said very little thro ughout the sessions. He would perform adjustments in the virtual environment, such as rearranging the chairs so that were paired with monitors and faced the desks. At one point he also commented:  X  X  X  X  hiding from everyone. X  This user worked by himself for most of the study. In another example, one user was working with an object in the floor plan and another was located in the virtual environment. The user with the floor plan commented how the  X  X quipment rack X  he believed he was manipulating should be posit ioned near the  X  X ance floor X  (floor space with sensors) object and rotated so that it faced away from the wall. This user was moving an object with a shape similar to the equipment rack and did consult the floor plan legend. The user in the virtual environ ment heard the comment though and began to move the actual  X  X quipment rack X  object to the specified position. When the first user switched to the virtual environment and saw his mistake, it was clear that the second was listening to his ideas, as he said:  X  X s that you, Participant A? X  At a few points in the sessions, one collaborator would verbally attempt to create a second subgroup that was separate from the two participants already working together. Each of these attempts failed. In one inst ance, one participant asked another if he was moving a chair and asked what his plans were, but the colleague did not respond and so the inquiring participant listened in on the other group X  X  activities. In another case, a participant in the virtual enviro nment noticed that she had a desk, like the one held by another participant in the virtual environment. They began to work on a plan for a good location for the two desks, but their conversation was interrupted by the other subgroup X  X  communication and the coordination was abandoned. In working on the layout problem, the group adopted two main strategies that they used throughout the task: areas of functionality and comparisons with the existing layout. One of thes e strategies was to conceive of the space in terms of different areas of functionality. Frequently, in working with the floor plan, the participants would talk about different areas of their design. For example, at one point a user commented:  X  X he students could hang out here and the rest of equipment could be over here. X  Similarly, the large  X  X ance floor X  object and the equipment required for its operation became another area of the design. Talking with the group in the final discussion, they also explaine d their ideas through the different functional areas. They mentioned a graduate student space, a  X  X ance floor X  corner, and a collection of computers with specialized use. The other strategy employed was to relate the emer ging design to their observations and knowledge of the current lab. For instance, one participant reflected on the distance between his desk and the wall in the current lab. There is about 1 foot, or 0.3 meters, between the two so that he can get to the de sk. Looking at their design, the group would comment on where people would walk, paying particular attention to the space in between furniture and the major walking paths through the layout. Another participant commented on a row of computers in the curren t lab that are used less frequently because they are on a major pathway. The group also considered working in the spaces they designed. They put thought into which way one would face sitting at a desk, whether there would be a glare from the windows, and w hether areas would be used for social gatherings. They also considered the size and location of the windows in the space. The subgroups would use the floor plan to try out different ideas. After moving a couple of objects, they would stop and reflect on the layout. They would discuss the implications such as which direction someone would face while working, how accessible the space is, how the layout affects the rest of the space, whether the equipment needs were met, etc., and then t ry another design idea in response. The conversation included comments such as:  X  X et X  X  try this X ,  X  X hy don X  X  you show us what you mean? X  and  X  X eah, that X  X  an excellent idea. X  The group frequently worked with the large objects with the floor plan using thi s approach. They spent much of the time repositioning two cumbersome L -shaped desks. Once these desks were positioned, they rarely were moved in the virtual environment. The floor plan also corresponded to comments about space efficiency. For example, a p air of participants in the virtual environment noticed there were many workstations of the same type scattered throughout. Switching to the floor plan, they were able to group them so that they took up much less space. Lastly, we observed users switching to the floor plan interface in order to comprehend major changes in the layout. For instance, one user working the floor plan began to reposition many of the objects in a drastically different design. Another user, who was observing within the virtual envi ronment, immediately switched to the floor plan when many objects began to move quickly across his display. He knew someone was making a major adjustment and it was much easier to follow this new idea by looking at the same floor plan interface. Unlike the floor plan, the users did not work closely together within the virtual environment. This representation was used for independent work and so the collaborators did not struggle with previous issues identified with CVEs [11, 12]. This interface afforded finalizing the positions of objects in order to experience how the room would actually feel. The manipulations performed with the environment were limited primarily to rotations and changes in the objects X  height. Participants rotated a bookshelf so that it was backed against a wall, or rotated a chair so that it sat facing a desk, or positioned a monitor up on the desk space. After moving objects around with the floor plan, users frequently switched to the virtual environment t o see how it looked in a more realistic setting. This interface allowed them to evaluate their design once they created a layout with the floor plan that everyone agreed with. For instance, during the session one user announced:  X  X  switched back to 3D and no one can use the computers where they are! X  This user noticed that two rows of monitors were lined up so that they faced one another instead of facing outward. Usually, the participants navigated the virtual environment to look at the spatial relationshi ps between objects, but incorrect rotations, such as the computers, were also quickly spotted.
 We also observed the participants realizing the magnitude of the problem in the virtual environment. Users with this interface noticed the objects in disarray mo re often and would frequently question,  X  X here should we put Object X? X  in effort to help. On a few occasions during the study the collaborators would use both interfaces. One participant would work with the flo or plan and another would use the virtual environment. The two representations enabled the collaborators to have unique perspectives and each user would contribute different information. The participants realized this poten tial early in the sessions. When beginning the task one user asked:  X  X oes someone want to stay in the big room and we X  X l send objects to you? X  He was implying that one person could work with the objects in the virtual environment while the others moved the objects into the room that needed to be designed with the layout view . One user verbally accepted this role and switched to the virtual environment, while two others moved objects with the floor plan interface. This coordinated approach was successful unt il the user within the virtual environment became overwhelmed with the amount of furniture appearing. The collaborators had not considered how quickly one could move an object with the floor plan. Activities taking place be tween the two representations were not always successful, however. One example during the session occurred when there was a discussion about the amount of space in between two pieces of furniture. The participant looking at the floor plan claimed that ther e was  X  X  good foot X  between the objects and that he could physically fit between them, but the user within the virtual environment was unsure of this assessment. This participant tried to express her concern over whether there was really enough space, but the user viewing the floor plan disregarded the comment and did not switch to the virtual environment to see the situation for himself. There was a breakdown in the coordination that led to a less than satisfactory design. In another instance, one particip ant became confused when his colleague in the virtual environment would repeatedly reposition each of the objects he had just moved using the floor plan. These extra movements confused the user looking at the floor plan. The virtual environment user was mo ving each monitor and keyboard up from ground level, placing each on top of a desk. These height interactions are not visible on the floor plan interface and the user only saw the objects moving around, causing the confusion. When two part icipants were using the floor plan, there were few gesturing issues. Occasionally, one user would check to make sure that the collaborators could see his telepointer, or the participant observing the telepointer would ask to repeat the gesture. These probl ems were solved fairly easily.
 When the participants used the two different interfaces, gesturing was more problematic. The radar view provided awareness information about the collaborators X  work efforts. Understanding the cursor positions was not straight forward, however. On multiple occasions, users viewing the floor plan were unsuccessful in pointing out a location to a user in the virtual environment. For example, a user looking at the floor plan pointed out where he thought a computer should be placed. Not understanding this location, the floor plan user encouraged his colleague to de -select the object in the virtual environment so that he could demonstrate his idea.
 On another occasion, a user within the virtual environment had trouble pointing out an object. This virtual environment user, who did not recognize an object, asked if others knew what she was pointing at. A user looking at the floor plan interface responded, but as he could not discern the pointer, he switched to the virtual environment to help with the identification. These observations document a complex and realistic example of distributed spatial collaboration. They also reflect the use of multiple, spatial representations in solving a spatial problem. Both of these have imp lications for the design of spatial collaboration solutions. The availability of two representations was both useful and helpful to the collaborators in the study. It enabled the users to investigate dif ferent aspects of the space. Collaborators used the floor plan to examine the overall layout, while the virtual environment offered a first -person perspective. Considering all of the activities performed during the study, the prototype supported a range o f tasks between the two representations. The floor plan afforded large -scale movements. Collaborators used this interface to easily explore arrangement ideas and make major adjustments to the design. The virtual environment, on the other hand, allowed the collaborators to experience their design. The participants switched to this interface to  X  X alk through X  the layout they created with the floor plan. They also observed minor changes such as objects that needed to be rotated or changed in height. Each repre sentation was used for a specific set of tasks and there was very little overlap between these tasks.
 Other spatial collaboration activities can also benefit from this advantage of multiple representations. Different dimensional representations can support viewing both high -level details and three -dimensional spatial relationships. Combining these representations allows for a diverse set of activities, which enables collaborators to better address the issues of complex spatial problems. The multiple representations are an interesting aspect of the prototype, but the study also observed the collaborators using the same representation. In particular, the participants would frequently use the floor plan together. The y used this interface to discuss the overall furniture layout. They also collaboratively explored different object positions. For example, one collaborator would move a couple of objects to arrange a small area, and the others would reflect on the design. The floor plan representation enabled them to have a common frame of reference for these activities. With similar views of the space, they easily understood one another and did not struggle with verbal references to objects or with telepointers to referen ce locations. Collaborators even would switch representations to create this commonality. Other spatial collaboration solutions should also enable collaborators to view the same representation. In future applications, similar representations should not be discounted in favor of the multiple perspectives afforded by different representations. Having a similar perspective on the space allows collaborators to easily observe as others express their ideas. One of the ma in issues with the multiple representations was coordinating activities across the interfaces. The combination of representations enabled the collaborators to be efficient. With one user looking at the floor plan and another looking at the virtual environm ent, the group worked together to position objects. The communication between the users with different perspectives was not flawless, however.
 Often, it was not clear whether the participants knew about each other X  X  efforts. Some participants work ed closel y with a partner, establishing a common work effort. Yet others primarily worked on their own or listened and followed along without conversing. The activities of such a quiet collaborator were frequently unknown to group. In a few instances, a user lookin g at the floor plan would switch to the virtual environment and quickly see how a colleague had been contributing to his/her task. Other times a collaborator with a different representation went unnoticed. This lack of awareness left the participants unsu re of what their partners were doing and uncoordinated in their group effort.
 There were also issues in expressing ideas across representations. In particular, participants struggled to gesture their ideas to one another. Pointing occurs within the context of a spatial activity and needs to be interpreted within this context [7]. In this study, the radar view provided the only awareness information between the representations. Hence, pointing out a location with the floor plan led to confusion in the virtua l environment. A user in the virtual environment trying to determine this location needed to understand the viewpoint with respect to the radar view and the collaborator X  X  telepointer. Likewise, in pointing at an object in the virtual environment, a floor plan user would have to align the collaborator X  X  telepointer in the radar view with their floor plan view. With similar spatial features appearing in both representations, the collaborators needed a way to refer to common objects across the representations , despite the visualization differences. This extends Tang X  X  emphasis on pointing and gesturing abilities within a shared workspace [28]. These communication problems limited the usefulness of the representations. They also introduce questions about how th e multiple representation design can be improved. New techniques are required that convey the collaborators X  activities across the different representations. In light of these issues, one possible solution is to include additional awaren ess features. Novel approaches that represent collaborators within the virtual environment on the floor plan, and similarly, a floor plan user within the virtual environment could enable collaborators to know of others in the same area. Users would not hav e to rely on the secondary, radar view, but could determine their collaborators X  perspectives within the primary interface. For instance, the floor plan could be augmented with the same collaborator markings provided in the radar view. A v -shaped figure an d corresponding pointer line would allow users of the floor plan to know of their partners X  location and orientation in the virtual environment and the direction of their pointing.
 Adding the floor plan users X  information to the virtual environment is not as straightforward. Floor plan viewports are rectangular areas, which are difficult to represent. One possibility is to apply lighting effects to indicate these areas, where different color shadings of light could represent different floor plan users. This may have usability problems as floor plan viewports overlap and the colored light shades mix. Another approach is to simply portray the floor plan user X  X  cursor within the virtual environment. This facilitates pointing and leaves any viewport differences to be verbally negotiated. Somewhat similar issues have occurred in mixed reality research. In a shared museum application, a physical visitor, a virtual reality visitor, and a web visitor are displayed on a two -dimensional map using colored arrows [2]. T his incongruously portrays the web view as a point in space with an orientation. Also, the web visitor is portrayed as an avatar in a virtual environment, having a three -dimensional location and orientation. Their results describe coordination issues as th e visitors tried to communicate across different environments. Also, their technique was problematic without an interaction for pointing. Additional awareness techniques need to help the participants not only know about colleagues within the same area usi ng a different interface, but they also need to facilitate the gesturing between the representations. In this prototype, in particular, users viewing the floor plan should know of nearby collaborators manipulating objects within the virtual environment. Li kewise, a collaborator in the virtual environment should notice a floor plan user interacting with objects in the same area. In addition to the finding related to using multiple representations, this study ha s implications for supporting spatial collaboration in general. Throughout the layout task of the study, the group was unfocused. There were many independent efforts and only one subgroup at any point. At times it seemed they were not making progress towar d a solution. For instance, large objects moved at the beginning would be relocated again toward the middle and end of the sessions. Movements to finalize object positions early in the session also seemed inefficient. Users would frequently push chairs up to desks, even though the desks would likely be rearranged later. The group was successful in creating a layout at the end of the session, but they could have benefited from more process support during the task. This points to a need for additional feature s to help organize the open -ended task. One way to support the spatial collaboration process is to enhance the common strategies employed. In the layout task, the use of different functional areas reflects a need to designate areas of a space and also group objects, to be moved together. During the study, the participants created these areas and referred to them as they continued, but occasionally an area would be disassembled as a new area emerged. It was unclear if the participants simp ly forgot about the area X  X  functionality or whether they meant to break it apart. A feature could be added to enhance this strategy. It could allow the users to easily mark and unmark areas, allowing everyone to see the designated area. Such an area -marki ng feature could also provide increased awareness. Through the creation and destruction of areas, the collaborators could have a better sense of their collaborators X  activities. For instance, if one participant were to create an area and label it, others c ould know where he is working and what he is doing. This level of awareness could be beneficial to the others as they work independently. Using specific area markings also facilitates a common language between the collaborators and encourages them to refer to their actions with respect to these areas. For instance, in this study, one participant might have said that he was working within a particular area instead of quietly manipulating and then verbally commenting about the implications. Lastly, marking a reas could have encouraged more explicit subgoals for the task. As everyone saw the marked areas, a design layout discussion could take place. Participants might think about the current areas identified and consider alternative ways to create areas of func tionality. Decomposing the spatial problem with respect to areas could also lead to a natural grouping of objects. In this way, the area markings would facilitate a more defined approach to the complex task. This work addresses the problem of su pporting distributed, spatial collaboration. It presents a unique prototype that uses multiple representations to enable distributed spatial collaboration. Focusing on the realistic task, the prototype allows the members of a research group to explore diff erent furniture arrangements for their lab space. The study confirms the usefulness of multiple representations of the same space. It demonstrates collaborators choosing the different interfaces to position objects. It also realizes the utility of offering both similar and different representations. More importantly, it highlights the need for awareness techniques that transcend multiple representations. Providing additional visual indicators of all the collaborators in both interfaces would have allowed th e participants to communicate between the representations. Lastly, the study reflects on the need for process support in spatial collaboration solutions. It offers a unique feature that could allow the collaborators to understand the areas where people are working and the progress the group is making. [1] Begole, J.M.A. Flexible Collaboration Transparency: [2] Brown, B., MacC oll, I., Chalmers, M., Galani, A., Randell, [3] Benford, S., Bowers, J., Fahl X  n, L.E., Greenhalgh, C. and [4] Cockburn, A. and McKenzie, B. Evaluating Spatial Memory [5] Churcher, N.I. and Churcher, C.D. GroupARC  X  A [6] Crabtree, A., Benford, S., Rodden, T., Greenhalgh, C., [7] Goodwin, C. Pointing as Situated Practice, in Kita, S. (ed.) [8] Gutwin, C. and Greenberg, S. Design for Individuals, Desig n [9] Gutwin, C. and Greenberg S. The Effects of Workspace [10] Gutwin, C., Roseman, M., and Greenberg S. A Usability [11] Hindmarsh, J., Fraser, M., Heath, C., Benford, S., and [12] Hindmarsh, J., F raser, M., Heath, C., Benford, S., and [13] Isenhour, P.L., Rosson, M.B. and Carroll, J.M. Supporting [14] Kessler, G., Bowman, D., and Hodges, L. The Simple Virtual [15] Leigh, J. and Johnson, A.E. Supporting Transcontinental [16] Leigh, J., Johnson, A.E. and DeFanti, T.A. CALV IN: an [17] MacColl I., Millard, D., Randell, C. and Steed, A. Shared [18] MacEachren, A.M. and Brewer, I. Developing a Conceptual [19] MacEachren, A.M., Brewer, I. and Steiner, E. [20] Marsic I. Real -Time Collaboration in Heterogeneous [21] Schafer, W.A. and Bowman, D.A. A Comparison of [22] Schafer, W.A. and Bowman, D.A. Evaluating the Effects of [23] Schafer, W.A., Bowman, D.A., and Carroll, J.M. Map -Based [24] Sebrechts, M., Vasilakis, J., Miller, M., Cugini, J., and [25] Smith, R.B., O'Shea, T., O'Malley, C., Scanlon, E., and [26] Steiner, K.E. and Moher, T. Encouraging Task -Related [27] Stoakley, R., Conway, M.J. and Pausch, R. Virtual Reality [28] Tang, J.C. Findings from Observational Studies of 
