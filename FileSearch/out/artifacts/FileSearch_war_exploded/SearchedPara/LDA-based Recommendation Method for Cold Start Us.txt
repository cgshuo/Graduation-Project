 For companies, quickly find ing the tender information which they are interested in from a large number of government tender information means that they can explore more business opportunities. The tender info rmation should be recommended to compan ies to bid but has the business scope related to the tender information. For example, tender information about server room X  X  constru ction implies the demand for socket s in addi-also be recommended to the socket suppliers to increase the socket suppli ers X  business opportunities even though the socket suppliers cannot directly bid for the tender infor-mation. 2
The interest of users in the ordinary recommender system is complex and changea ble, while the business scope of companies is relatively fixed , which means the interest of companies is relatively fixed. And the tender information itself already contains the key contents. Therefore, when we recommend tender information to companies, the business scope of companies and the contents of tender information c an be used as the main input, and recommendation can be made based on the similarity between them. However, both the business scope and tender information are short text s which do not contain enough features  X  so they may not make us get the recommendation results we want.

Based on the discussions above , this paper mainly uses the similarity between business scope of companies and contents of tender information to recommend tender information to companies. First of all, according to LSA, we extracted the mo st relevant documents from the Wiki Chinese corpus and a certain amount of keywords from these documents to exp a nd business scope and tender information . Then we map the expanded business scope and tender information to topic space using LDA to get their t opic distribution. Finally tender information is recommend ed to companies according to JS distance between them.

In summary, three main contributions are as follows: 1) our method makes the small and medium -sized enterprises who have no qualification to bid can extra business opportunities; 2) our method extend s the target data by exploiting the idea of transfer learning based on LSA, and uses the Wiki Chinese corpus which is data -rich and easy companies according to similarity ( between the companies and tender information) with LDA, avoiding the cold start problem resulted from the sparse feedback matrix between companies and tender information . With the rapid development of information technology, especially internet technology, information overload is becoming more and more serious. As an important branch of personalized service research, recommendation system [1, 2] can help users find the and generate personalized recommendation lists to meet the individual needs. At present, the recommendation system generally adopts the collaborative filtering method to recommend to users [2]. Both user -based collaborative filtering methods and item -based collaborative filtering methods rely heavily on users X  feedback on items, including explicit feedback and implicit feedback. Explicit feedback requires a user to such as clicking, browsing, etc. However, for collaborative filtering, there is always a problem of feedback matrix sparsity and cold -start [1]. For a new user or a new item, recommend.
Transfer learning which the researchers have paid more and more attentions to existing knowledge to solve the problem in different but related areas. In order to ensure the accuracy and reliability of the trained model, there are two basic assumptions in the traditional machine leaning [4]: 1) the training data and the test data have to satisfy the co nditions of independent and identically distribution; 2) there must be enough available training data in order to get a good model. Transfer learning relaxes these two basic assumptions in order to address the learning problem that there are few labeled distribution. 
Latent Dirichlet Allocation (LDA) model [5] is an important model in natural document represents the probability distribution of topics, and each topic represents the probability distribution of words. LDA makes it easier to compare the similarity between documents by representing each document as a probability distri bution of topics [6].

In order to address cold -start problem , [7] combines additional information about users and collaborative information, and others exploit demographic data or even user X  X  personality [8] to address the user cold -start problem. Cross -domain recommender sys-tems [9] that leverage additional information from different but related source domains have been introduced as a potential solution to cold -start situations. This auxiliary in-formation can be exploited to mitigate the lack of historical data in the target recom-mendation domain, thus addressing the user cold -start [10]. Subsequent work proposed methods to effectively learn and transfer knowledge from the source domain to the tar-get [11], and found that the quality of the recomme ndations improves when the in-volved domains are semantically more related [12]. [13] shows that cross -domain pref-erence data is useful to provide more accurate suggestions when user feedback in the target domain is scarce or not available at all, and may l ead to more diverse recommen-dations depending on the target domain. [14] proposes a tensor factorization -based al-gorithm that exploits content features extracted from music audio to deal with the cold -start problem of emerging application next -song recomme ndation. [15,16] model the user preference with additional context information to recommend next song to users. Other researchers have also considered the technique to exploit auxiliary information about users or items besides the rating data that are usua lly available [17 -24, 25]. item X  X  auxiliary information to recommend. In this paper, our purpose is to avoid the user -item rating matrix, and to use directly both user X  X  inf ormation and item X  X  infor-mation to make recommendation . 4 3.1 Definition and  X  &amp; is the key contents of tender information whose ID is  X  .

U =  X  ,  X  . |  X   X   X  : U is the companies set . M is the ID set of companies , and  X  . is the key content of business scope.  X  . is to the tender information  X  &amp; . 3.2 E xpand the Target Data Because both the tender information and the business scope in the target data are short texts and contain only a small amount of feature information, the first thing to do is to exploit the ideal of transfer learning to extend the feature information of the target data. In order to get auxiliar y information related to the target data, inspired by [3], we make full use of Wiki Chinese corpus which is free, data -rich and easy to get. For each piece of tender information and business scope, LSA [26] extracts several texts from Wiki Chinese corpus w hich are most semantically related to the target data.

Next step is to identify the useful information for the target data from the extracted texts. One simple method often is using the bag of words model to represent the source relationship hidden in context keywords, especially the semantic relationships. The [26]. It assumes that there is a link, namely a potential sematic structure between the text and words. Here, we use the LSA to extract the feature information.

First construct the text -word matrix: M =  X  ;&lt; quency that the j -th word appeared in the i -th text. Since each word appears in a small amount of text, M is a high -level sparse matrix. Then apply the technology of singular value decomposition (SVD) and map words and texts f rom a high -dimensional space to a low -dimensional latent semantic space. Finally, a new matrix M can be gotten: In the formula above, U , V are orthogonal matrix (  X  X  X  B =  X  X  X  B =  X  ). 
In the matrix M , the value in the i -th row and j -th column represents the relevance When t he value is greater than  X  , the keyword can be selected to expand the target data. 3.3 LDA Model layer structure model including document, topic and word. It can mine potential topics through modeling documents and words. Fig 1 shows the generation process of LDA model .

In Fig 1,  X  and  X  are para meters.  X  = is the topic distribution of the m -th document.  X  senting the topic of the n -th word in the m -th document .  X  = , ? is a word derived from the probability distribution and represents the n -th word in the m -th docume nt. K is the number of topics. M is the number of documents.  X  = is the number of words in the m -th document.

This paper regards the expended business scope and tender information as the doc-uments in LDA. Model them with LDA and map them from a high -dimensional docu-ment -word space to a low -dimensional document -topic space. Thus, new feature vec-tors of the tender infor mation and the business scope represented by topic probability distribution can be obtained: 3.4 Calculate similarity Since the exp a nded business scope and tender information are mapped into the docu-ment -topic space, the similarity between them can be c alculated from their correspond-ing topic probability distribution. The distance to the probability vector can be calcu-lated by the Kullback -Leibler (KL) divergence [27] which is calculated as follows:
When  X  &lt; =  X  &lt; ,  X  ST  X  ,  X  = 0 . However, KL divergence is not always symmetrical, namely  X  ST  X  ,  X   X   X  ST  X  ,  X  . So use its symmetrical version: 6
When  X  = 1/2, this formula is the Jensen -Shannon (JS) divergence [28]:
In this paper, JS divergence is used to measure the similarity bet ween business scope and tender information re presented by topic probability distribution:
The larger the value of sim  X  ,  X  is, the more similar the company  X  is to t he tender information  X  .
 Algorithm 1 shows the overall steps.
 tender information set), threshold value  X  most semantically relate d with the target data according to LSA; sim  X  ,  X  4.1 Data set In order to make the results more authentic, we captured the actual tender data from the Tianjin government procurement website. We crawled 11948 piece s of tender infor-mation released from 2011 to 2016, and got 621 companies who have won at least one bid.

All the auxiliary data comes from the Wiki Chinese corpus which is 744 MB and contains 275571 documents. We selected the most semantically related keywords from every document of the 10 documents [3] which are most semantically related to the target data i n the Wiki Chinese corpus . 4.2 E valuation criterion Our method uses the similarity between company information and tender information precision accuracy and recall accuracy, d o not work for our method. Actually, infor-mation of the bid won by a company is possible not in the top -N recommended list for it . Because maybe there is other tender information which is more similar to this com-pany's business scope, resulting in low prec ision accuracy and low recall accuracy, we determine to use user satisfaction to evaluate our method . 4.3 Results The user satisfaction questionnaire was set from  X  X ot interested at all X  to  X  X ery interested X , corresponding to 0 to 4 points respectively, for ev ery piece of tender information in the top -N recommendation list. For comparison, we compared the top -N recommendation list recommended by our method (LDA -TL) with the one recommended by the LDA -based method.

The user satisfaction questionnaire was sent to 100 companies randomly chosen from all the 621 companies collected from the source data. However only 20 companies replied finally.
 The threshold value of  X  is set to 0.7 [3]. And the number of topics is set to 250 [6]. The LDA and LSA are modeled by the toolkit of Gensim which is a free Python library. information list recommended by LDA -TL (mean=2 .965, SD=0.527) are mostly much larger than the ones recommended by LDA (mean=2.425, SD=0.174). The average points of the top -20 recommended to companies are mostly larger than 2 points, which means that companies are interested in the recommended tender i nformation list more or less. In other words , the tender information list recommended by LDA -TL can meet data, it will expand the business scope of one company. However, ther e may exist some tender information in the top -N list which cannot arouse any company X  X  interest. This is the reason why the standard deviation of LDA -TL is larger than the one of LDA. tender information list recommended by LDA -TL and LDA. As shown in Fig.3, most information list recommended by LDA -TL (mean=2.965, SD=0.284) are larger than that recommended by LDA (mean=2.810, SD=0.301). The average points of the i -th piece of tender information in the top -20 recommended to companies are mostly larger than 2.5 points, which means that companies are interested in the i -th piece of recommended tende r information more or less.

In the top -20 tender information list recommended by LDA -TL of socket provider companies, there exists some tender information about the laboratory expansion and computer purchase. This result confirms our initial idea mentioned in the section of Introduction. 8 Cold -start is one of m ajor challenges in the design of recommender system. Transfer learning is a technique that finds useful knowledge and skills in the previous tasks and applies them to the new tasks or domain. LDA is a very useful method for natural lan-guage processing and can make calculating text similarity easier by mapping docu-ments into the latent topic distribution. In this paper, we solve the problem of recom-mending tender information to companies in cold -start problem. Our method can rec-ommend tender information not only to the companies who have the ability to bid, but also to the companies who do not have the ability to bid while their business scope is related to the tender information. In order to address the problem that both the tender information and the busine ss scope of companies do not contain enough useful feature information, we use Wiki Chinese corpus to expand the target data by exploring the idea of transfer learning. We extract the most semantically related keywords as the aux-iliary data from the Wiki C hinese corpus by using LSA method and then model LDA with the expanded data. As our method directly use the similarity between the business scope of companies and tender information to recommend tender information to com-panies, it avoids the effects caused by the sparse user -item rating matrix. Also, the rec-ommended list can meet the need of companies well. In the future, in order to find the relationship between items, we will use more related source data to expand the target data, such as Alibaba and Amaz on. Additionally, we will apply our method to improve the present collaborative filtering methods .
 References 10
