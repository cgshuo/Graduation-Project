 Faculty of Mathematics, University of Belgrade, Studentski Trg 16, Belgrade 11000, Serbia Tel.: +381 648 650 064; E-mail: nikolic@matf.bg.ac.rs 1. Introduction
Many or most data analysis techniques are designed for data that are represented by vectors of num-bers. However, this kind of representation often leads to loss of structural information contained in the original data, while preserving structural information may be essential in some applications. This requires a richer problem representation and corresponding data analysis techniques. For example, in many practical domains, structural information in the data can be represented using graphs. Similarity measures between objects are of central importance for various data analysis techniques. The same holds for the special case of similarity measures related to graphs. A number of measures for such purposes have been proposed. In this paper, we focus on iterative methods for calculation of simi-larity of graph nodes (some of them allowing extension to similarity of whole graphs) [1,7,9,21]. These methods have been successfully applied in several domains like adequate ranking of query results [9], synonym extraction [1], database structure matching [13], construction of phylogenetic trees [7], analy-sis of social networks [12], etc.

In this paper, we try to identify desirable properties not present in the existing methods for measuring similarities of graph nodes. We propose a re fi nement of the notion of similarity of two nodes which leads to a new method for measuring similarities of graph nodes and similarities of graphs. We prove convergence of the proposed method and show that it h as some additional desirable properties that, to our knowledge, the existing methods lack.
We implemented the proposed method and evaluat ed it on four problems in order to illustrate that our method can capture the notion of similarity useful for practical problems. The problems we used are fi nding a subgraph of a graph that is isomorphic to some other given graph, measuring similarity of and classi fi cation of engineering symbols.

The rest of the paper is organized as follows. In Section 2, we present the preliminaries used in this paper. Existing methods are described and analyzed in Section 3. In Section 4 we present our new method  X  the method of neighbor matching and prove its properties. Results of experimental evaluation and comparison to other methods are given in Section 5. In Section 6, we draw fi nal conclusions and give some directions of the future work. 2. Preliminaries
A directed graph G =( V,E ) is de fi ned by its set of nodes V and its set of edges E . There is an edge between two nodes i and j if ( i, j )  X  E . For the edge e =( i, j ) ,the source node is the node i ,and node i is an in-neighbor of node j and that node j is an out-neighbor of the node i if ( i, j )  X  E .An i if ( f ( i ) ,f ( j ))  X  E B . An isomorphism of a graph G to itself is called automorphism .A colored graph is a graph in which each node is assigned a color. For colored graphs, the de fi nition of isomorphism a graph with n nodes in which each two nodes sha re an edge w ith probability p [4]. A graph G B is an if and only if ( i, j )  X  E A .

The similarity measure s is a function s : D 1  X  D 2  X  R where D 1 and D 2 are possibly equal sets of objects. A higher value of similarity measure should imply a higher similarity in some intuitive sense. Choice of a similarity measure to be used in some context is often guided by its usefulness in practice.
Similarity measure over the nodes of two graphs can be represented by a similarity matrix X =[ x ij ]
Let A and B be two fi nite sets of arbitrary elements. A matching of elements of sets A and B is a set of pairs M = { ( i, j ) | i  X  A, j  X  B } such that no element of one set is paired with more than one element of the other set. For the matching M we de fi ne enumeration functions f : { 1 , 2 ,...k } X  A a function assigning weights to pairs of elements a  X  A and b  X  B .The weight of a matching is the sum of weights assigned to the pairs of elements from the matching. The goal of the assignment problem is some elements of the larger set will not have corresponding elements in the smaller set). The assignment problem is usually solved by the well-known Hungarian algorithm of complexity O ( mn 2 ) where m = Edmonds and Karp of complexity O ( mn log n ) [3] and even more ef fi cient one, due to Fredman and Tarjan of complexity O ( mn + n 2 log n ) [5].
 3. Existing methods for measuring graph node similarity
In this section we brie fl y describe relevant iterative methods for measuring similarity of graph nodes and we try to identify some desirable properties that they lack.

Assume that two directed graphs G A =( V A ,E A ) and G B =( V B ,E B ) are given. Iterative methods using some update rule of form [ x k +1 condition is met. At the end, the similarity matrix X =[ x ij ] is produced. Different rules for update of similarity of two nodes are proposed. They usually include summing all the similarities between the neighbors of fi rst node and the neighbors of the second node.
 et al. [1]. In the method of Blondel et al. the update rule for x ij in step k +1 is given by The similarity matrix X is normalized by X  X  X/ X 2 after each step.

The earlier approach by Melnik et al. [13] can be seen as a more general version of of this method where the similarities between neighbor nodes x k
The method of Blondel et al. was modi fi ed by Zager and Verghese [21] to account for similarity of the edges too. The update rule for the edge similarity matrix Y =[ y uv ] ,where u  X  E A and v  X  E B ,is given by The update rule for similarity of nodes is then given in terms of similarities of the edges Matrix normalization of the similarity scores is applied in this approach too.

The approach by Heymans and Singh [7] is somewhat different and more complex than the described methods, and we only brie fl y mention its most important aspects. In order to estimate similarity in each iteration, similarity terms and dissimilarity terms are calculated, based on the similarity scores of the previous iteration. These terms average the similarities of the in-n eighbor and sim ilarities of the out-neighbors. Similarity terms are calculated both for the original graphs and their complements. Dissimilarity terms are calculated using one graph and the complement of the other, and vice versa. Dissimilarity terms are subtracted from similarity terms to obtain new estimate of similarity scores. The matrix normalization is performed after each iteration.

There are approaches that are designed for measuring similarity only between the nodes of the same graph [8,12], but we do not discuss these methods. Also, there are various approaches that deal with the similarity of graphs, but do not consider the similarity of their nodes (e.g., [17,18]).
The described methods lack some desirable and natural properties. Of course, not all the methods lack all the listed properties. If the graph is compared to itself, each node should be most similar to itself. This is a natural prop-graphs for which there is a node which is more similar to some other node of the same graph than to itself. This can easily occur, for instance, in methods where the update rule consists of simple summa-tion of similarities of nei ghbor nodes. This results in nodes of higher degree having more terms in the summation and hence, higher similarity with other nodes [2].
 value. It is customary for similarity measures in gene ral (not only for similarity measures related to intuitive understanding of similarity scores. Well-known examples of measures for which these require-methods for calculating graph node similarity lack this property. When the similarity scores are calcu-from the similarity score of some other node compared to itself.
 It is reasonable to make even stricter requirement: if two graphs G A and G B are isomorphic, f : V A  X  V
B being one such isomorphism, the similarity score x if ( i ) should be 1 for all i A similarity score should be meaningful in itself. Due to the normalization of the similarity matrix, one interdependence between similarity scores that is not a result of the topology of two graphs. It actually is more similar than some other pair of nodes.

As an example, consider the following special case. Suppose that all the nodes of one graph are equally ity scores are equal to 0, or that all the similarity scores are equal to 1. Because of the normalization nodes of one graph are equally similar to all the nodes of the second graph, but not how much.
It would be good if similarity score is meaningful in itself and not only relative to other scores in the similarity matrix.

The lack of this property, also makes it harder to use similarity scores of the nodes to construct the similarity measure of whole graphs. Heymans and Singh [7] were able to achieve this because they use similarity scores that can be negative (as the consequence of subtracting dissimilarity scores that they use), but as discussed in the previous special case, it would not be possible with other methods. If two nodes do not have ingoing or outgoing edges, they should be considered similar. To our knowl-edge, this property is present only in the method of Heymans and Singh. We believe that concepts of in-similarity and out-similarity should be recognized. Moreover, in-similarity and out-similarity should be 1 if there are no in-neighbors or out-neighbors. 4. Method of neighbor matching
In this section we re fi ne the notion of node similarity. Based on that re fi nement, we describe a new method (we call this method the method of neighbor matching ) for measuring similarity of nodes of graphs and prove its properties. Then, we de fi ne a measure of similarity of whole graphs based on the similarities of their nodes. 4.1. Notion of similarity of graph nodes
In the existing methods, the calculation of similarity x ij is based on adding or averaging the similar-ities between all t he neighbors of node i  X  V A and all the neighbors of node j  X  V B . We propose a j  X  V j (hence the name neighbor matching). 4.2. Measuring similarity of graph nodes de fi ned by some update rule. In our method, we will differentiate between in-similarity s in and out-similarity s out and will give them equal weights. In order to calculate in-similarity, the matching of in-neighbors with maximal sum of sim ilarities (as described in Section 2) has to be constructed, and analogously for out-similarity. More formally, the update rule is given by In and out similarities are de fi ned by where functions f in nodes i and j with weight function w ( a, b )= x k the summation (which are each less or equal to 1 as we show later).

This method is easily extended to colored graphs. By de fi nition, we can set x k j are of different color.

As in other iterative methods, one has to choose the initial similarity scores x 0 x leads to intuitive results. If, for instance, a node i has 3 in-neighbors and a node j has 5 in-neighbors, the in-similarity of nodes i about the similarities of the neighbor nodes  X  in th at case we can only reason about the number of neighbor nodes.

The termination condition is max ij | x k nation condition could be used too.
 Note that our method has computationally more complex update rule compared to previous methods. for out-neighbors. In our method, we have to solve the assignment problem for id ( i ) and id ( j ) in-(mentioned in Section 3) exist, and the graphs in most real world problems are reasonably sparse, the need for solving assignment problem, should not be a signi fi cant problem in practice. Of course, if the graphs are dense, the method will be more demanding, especially as the graphs get larger. However, as it will be discussed in Section 5, in the case of dense graphs, one could deal with complement graphs (that are sparse) instead of the original ones, and so reduce the computation time.
 Example 1. In order to illustrate our method, we applied it on example graphs (shown in Fig. 1) used by Zager [21]. The similarity scores for the nodes of the graphs are presented in Table 1. The proposed method converges, as stated by the following theorem.
 Theorem 1. For any choice of graphs G A and G B , for each pair of nodes i  X  V A and j  X  V B ,there exists x ij = lim k  X  X  X  x k Proof. For any i  X  V A and j  X  V B , the corresponding sequence ( x k prove this by induction on the number of iterations k .

The initial similarity score x 0 of the matching of any two nodes is 1. Since m in n in and m out n out it holds s 1 and s 1 proves that in the fi rst step, the similarity scores cannot grow. This proves the base of induction.
Suppose that up to the step k , the sequence of scores x k This actually states that the weights ( x k are not greater than the weights ( x k  X  1 s functions of the optimal matching of in-neighbors of nodes i  X  V A and j  X  V B in iteration t . Note that for a pair of nodes these functions can differ from iteration to iteration. We prove that the following inequalities hold The fi rst inequality holds by inductive hypothesis that states that x k equality, the optimal matching of in-neighbors of node i to in-neighbors of node j in iteration k , need not be the same as the optimal matching of those in-neighbors in iteration k +1 . Since the matching de fi ned by enumeration functions f k than the weight of the matching de fi ned by enumeration functions f k +1 the second inequality states. Dividing all three expressions by m in , we conclude s k +1 The same holds for out-similarities. Consequently, we have x k +1 Hence, the sequence of similarity scores ( x k rule consists of averaging some of the scores from the previous iteration. By averaging nonnegative values one cannot obtain a negative value, so each sequence of similarity scores is nonnegative. Hence, the sequences are bounded from below by zero. Nonincreasing sequence bounded from below must have a limit, so x ij = lim k  X  X  X  x k proves the theorem.
 Simple examples can be produced to show that the bounding interval [0 , 1] is tight.
 Important property of the similarity for isomorphic graphs is established by the following theorem. Theorem 2. For two isomorphic graphs G A and G B ,let f : V A  X  V B be an isomorphism between two graphs. For each node i  X  V A , it holds that x if ( i ) =1 .
 Proof. We show that x k
The initial value x 0 nodes i and f ( i ) must have the same number of in-neighbors and out-neighbors. Hence, m in = n in and m out = n out .Itsuf fi ces to prove that the weights of the optimal matchings when calculating in Since there is n in in-neighbors, the weight of the optimal matching of in-neighbors is n in . Analogous reasoning is used to show that the weight of the optimal matching of out-neighbors is equal to n out . similarity score x k +1
Since x k
In the case G A = G B where f is the trivial automorphism f ( i )= i for all i  X  V A , this theorem implies a simple corollary. Corollary 1. For any graph G A and each node i  X  V A , it holds x ii =1 .
 It is easy to check that the proven theorems hold for colored graphs too.
 By the above statements, the neighbor matching method ful fi lls the fi rst two requirements listed in Section 3. The matrix normalization is avoided and it is easy to produce examples of graphs with all the neighbors is recognized because in that case in or out similarity will be equal to 1. So, we can conclude that all the requirements listed in Section 3 are met. 4.3. Measuring similarity of graphs
The method of neighbor matching can be used to construct a similarity measure of two graphs in the way of Heymans and Singh [7]. When the similarity scores x ij for graphs G A and G B are computed, the optimal matching between their nodes can be found by solving the assignment problem between the nodes from V A and V B with the weight of matching two nodes being the similarity of the nodes. Let f graphs G A and G B can be computed as By Theorem 1, the value of the similarity measure s is bounded in the interval [0 , 1] .Asasimple corollary of Theorem 2, if G A and G B are isomorphic, it holds s ( G A ,G B )=1 .

Of course, different similarity measures for graphs could be constructed based on the similari-ties of their nodes. For instance, the sum of weights of the optimal matching could be divided by comparing two graphs. Another interesting choice would be to take the average of all the values in the similarity matrix. In such a case, graphs with gr eater number of automorphisms would be considered to be more self-similar than graphs without automorphisms. In the rest of the paper we will use the measure de fi ned by Eq. (2). 5. Experimental evaluation Heymans and Singh in C ++ . 2 For solving the assignment problem, we used an available implementation In this section, we describe four experiments we performed to test the performance of our method. The fi rst two are concerned with node similarities, and the second two with graph similarities. 5.1. Evaluation of node similarity
We will evaluate node similarity on two problems. The fi rst is isomorphic subgraph matching, and the second is measurement of similarity of friends in a social network. 5.1.1. Isomorphic subgraph matching
Here we present a slightly modi fi ed experiment from Zager and Verghese [21] which we use to com-pare several methods for computing node similarity.
 We will consider a problem of fi nding a subgraph of a graph A that is isomorphic to some other graph B . We will use random Erd  X  os X  X  X nyi graphs G n,p . The experiment consists of generating a random graph A of size n and randomly selecting m n nodes which induce a subgraph B of A . The similarity of nodes of A and B is calculated, the assignment problem between the nodes of A and B is solved, and the matching of the nodes is obtained. Then, it is checked if graph B is isomorphic to the subgraph of A induced by the obtained matching.

For n =15 , this procedure is repeated 500 times for each pair of m =8 , 9 ,..., 15 and p = and the same termination condition was used  X  max ij | x k
The methods compared were the method of neighbor matching (NM), the one of Heymans and Singh (HS), and the one of Zager and Verghese (ZV). It was noted that NM and ZV methods are heavily in-fl uenced by density parameter p both in matching performance and speed, while the HS method is not. We believe that it is due to the fact that HS method is considering both the input graphs and their com-plements. As suggested in Section 4, we made a modi fi cation to other two methods which we call  X  X he complement trick X   X  for dense graphs ( p&gt; 0 . 5 ) the similarity of nodes is measured for the comple-computed for the complement graphs would be close to the similarity scores computed for the original graphs. We only expect that their computation would be less expensive and that the obtained results would be better. That might even be a rationale for including the complement trick in the de fi nition of the method. This modi fi cation introduced methods NM* and ZV*. For completeness of the evaluation, we introduced HS*, too.

For each method, for each value of parameter p , we present one plot that shows the percentage of successes in isomorphic subgraph matching for each value of m . The plots are presented in Figs 2 X 4. It can be noted that the accuracy rises much slower for in the case of ZV and ZV* than in the case of other methods. NM* obviously performs the best. In Table 2, for each method, we present the overall accuracy in the experiment and the total time of the experiment.
 The complement trick obviously improved NM and ZV methods. As expected, it did not affect the HS method. For NM* and ZV* methods, apart from boosting the accuracy, the computation time is signi fi cantly reduced. For NM method, this modi fi cation reduces the computation time for solving the assignment problem in NM update rule, since it reduces the number of nodes to be matched in the cases when this number can be large (dense graphs).
One can observe that the performance of all the methods rapidly decreases as the subgraph size de-creases. Probable cause of this behavior is that if a graph B is given, which is small, and A contains an induced subgraph A isomorphic to B , the number of the edges of A that connect the nodes of A to the nodes of A that are not in A is signi fi cant in comparison with the number of the edges of A ,sothe topology of B becomes less discernible in A as B gets smaller. 5.1.2. Similarity of friends in a social network
It could be expected that the nodes of a social network that correspond to friends are more similar than the nodes that do not correspond to friends. We analyzed a network dataset describing email exchange between the members of University Rovira i Virgili [6]. Each member represents a node in the graph G . There is an edge between two nodes of G if the person corresponding to the fi rst node sent an email to the person corresponding to the second node. The graph contains 1133 nodes and 10903 edges. We calculated similarities for all pairs of nodes of the graph using the same methods as for isomorphic subgraph matching problem. As an evaluation met ric we used the probability of a randomly chosen pair of friends having greater similarity than a randomly chosen pair of persons that are not friends. We estimated this probability using Wilcoxon statistic [19]. The probability for N M method is 0.87 and the computation time is 1719s. The pr obability for ZV method is 0.75 and the computation time is 850s. For HS method the computation did not fi nish even in 10h. As before, NM performs better than ZV, but requires more time. 5.2. Evaluation of graph similarity
We will evaluate graph similarity derived from node similarities on two problems. The fi rst is classi-show that our method can capture a meaningful similarity of graphs in real world problems. The fi rst one is also used to evaluate the s calability of the p roposed method. 5.2.1. The classi fi cation of boolean formulae
Various important practical problems can be modeled in Boolean logic including problems in elec-gence, and other domains. Each instance of the problem is represented by a Boolean formula. Classi fi -cation of Boolean formulae has been investigated in order to automatically tune SAT solvers (systems lem. A very reliable approach to Boolean formulae classi fi cation is based on measuring the distances between the formulae [14]. In that approach, in order to compute the distance between the formulae, they are represented by numerical vectors of some syntactical features, that can be computed for each formula. However, Boolean formulae have a natural variable-clause graph representation [15] that could be used for their classi fi cation.

We performed the classi fi cation of Boolean formulae using our similarity measure for graphs on their graph representation. We used 149 structur ed instances from SAT comp etition 2002 benchmark nodes, but 25 of them were larger (up to 5280 nodes). Formulae were grouped in 9 classes correspond-ing to the problems the formulae originate from. Graphs corresponding to the formulae had from 122 to 5280 nodes. Differences in graph size of order of magnitude were present within each class too. The classi fi cation was performed using the k nearest neighbors algorithm with leave one out evaluation pro-cedure  X  for each formula F , its graph similarity to the remaining formulae was computed, and the set formulae being classi fi ed.

Total time used for the experiment which involved 11026 computations of graph similarity is 102 was 93% for k =7 . The best accuracy for a domain speci fi c approach from [14] on the same set is 96% for k =1 . Somewhat more accurate, the domain speci fi c approach is based on long lasting research in speci fi cally for this purpose, is good.

A very interesting remark concerning this experiment is that the difference in size of the compared graphs did not in fl uence the adequateness of the similarity measure. This kind of robustness might be interesting for practical applications.

Since the number of nodes of graphs used in this example varies signi fi cantly, we can use it to analyze the scalability of the method with respect to the graph size. The dependence of computation time on the size of the graphs is given in Fig. 5. One can see that the dependence of computation time on the product several linear dependencies corresponding to comparisons of Boolean formulae from various classes can be spotted. The amount of time that can be spent on similarity calculation varies from application to application, but from given fi gure, one can form an impression of the way the proposed method scales with the size of the given graphs. 5.2.2. Classi fi cation of engineering symbols electronic drawings [16]. The dataset contains 1100 graphs uniformly distributed in 22 classes split in training, validation and test set containing 286, 286, and 528 instances respectively. Maximal number of measure was used. The total time used for the experiment is 3876 s, and the average graph similarity computation time is 0.01 s. The accuracy for k =1 is 92%. On the other hand, the approach based on graph edit distance achieves 95.5% accuracy [16]. As in the previous example, the proposed method is not the best, but its performance is good. 6. Conclusions and future work
We proposed a re fi ned notion of similarity of graph nodes, and based on that re fi nement we developed a new iterative method for measuring similarity of nodes of two graphs. This method was extended to a method for measuring similarity of whole graphs. We proved the convergence of the method and showed lack.

We implemented the method and evaluated the implementation on four test problems. On two test problems involving node similarities, we con fi rmed that the proposed method performs better than other methods. On other two problems involving graph similarity, the proposed method was not the best, but its performance was good. It is con fi rmed that the proposed similarity measure is able to capture a meaningful similarity in real world problems. The method showed to be robust to differences in graph size. The performance on dense graphs can be signi fi cantly boosted by measuring the similarity of nodes of complement graphs. This modi fi cation can signi fi cantly reduce the running time of the method.
An obvious limitation of the method is that the computation time is linear with respect to the product not easy to understand the magnitude of the similarity value. For instance, it would be hard for a domain expert to choose a threshold on this similarity measure to make a yes-or-no decision whether two nodes or two graphs are similar, and one would probably have to choose such a threshold experimentally using the available data. One should also be aware that in some domains small changes to the graph structure, or changes that do not affect the graph structure can have a large impact on the phenomenon of interest. An example could be that different conformations of a chemical compound can have different chemical properties. This is an inherent limitation for application of topology-based similarity measures.
As for the future work, we are planning applications of the neighbor matching method in real-world problems in bioinformatics, text classi fi cation, and other domains suitable for graph similarity tech-niques. Acknowledgements The author thanks prof. Ambuj Singh for his Java implementation of his method, to prof. Predrag valuable suggestions.
 References
