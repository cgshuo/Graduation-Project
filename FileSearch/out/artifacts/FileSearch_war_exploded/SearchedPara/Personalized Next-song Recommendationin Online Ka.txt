 In this paper, we propose Personalized Markov Embedding (PME), a next-song recommendation strategy for online karaoke users. By modeling the sequential singing behavior, we first embed songs and users into a Euclidean space in which distances between songs and users reflect the strength of their relationships. Then, given each user X  X  last song, we can generate personalized recommendations by ranking the candidate songs according to the embedding. More-over, PME can be trained without any requirement of content infor-mation. Finally, we perform an experimental evaluation on a real world data set provided by ihou.com which is an online karaoke website launched by iFLYTEK, and the results clearly demonstrate the e ff ectiveness of PME.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information filtering Music Recommendation; Personalization; Markov Embedding
Advances in the Internet and mobile technologies have exposed people to the massive amount of online multimedia entertainment. Among them, online karaoke has attracted significant attention, s-ince everybody can sing along with the recorded music anytime and anywhere, or even with a music video like a professional singer. As a trend, much more music are becoming available, and thus the demand for intelligent karaoke services, i.e., personalized song rec-ommendation, is expected to increase dramatically.

Actually, music recommendations have been widely studied and applied in the literature. For instance, since music is rich in both textual and acoustic information (e.g., artists, genres and pitch-es), several recommendation algorithms[4, 8, 12, 15] exploited it and modeled users or user behaviours based on extracted features. However, content information cannot be easily extracted in many cases. Thus, collaborative filterings have become the most popular when the cheerful  X  X ptown Girl X  is just sung, even if you do like these two songs. Thus, besides capturing the general (long-term) preference of each user, it is also important to model the sequential nature of singing lists for the user X  X  contextual (short-term) prefer-ence[13] when making personalized next-song recommendations.
To address the above challenges, in this paper, we extend the existing Logistic Markov Embedding (LME)[5] algorithm and pro-pose Personalized Markov Embedding (PME), a next-song recom-mendation strategy for online karaoke users. Specifically, we first embed songs and users into a Euclidean space in which distances between songs and users reflect the strength of their relationship-s. This embedding could e ffi ciently combine users X  long-term and short-term preferences together. Then, given each user X  X  last song, we can generate recommendations by ranking the candidate songs according to the embedding. Moreover, our PME can be trained without any content information of songs, namely just with the in-teraction history of users X  singing. Finally, we perform an experi-mental evaluation on a real world data set, and the results demon-strate that the PME algorithm outperforms several state-of-the-arts, including the non-personalized LME algorithm.
Given the songs that have been performed previously by each karaoke user, our goal is to recommend a ranked list of songs to a given user for the current context (the last song). We formal-ize this problem as follows. Let S = set and U = song records, which are usually similar, performed by the same us-er during short time intervals form a session. For instance, the j -th session of user u is represented by p u ; j = by user u is p u = can be represented as D = { ( u ; p u ) | u  X  U } . In other words, given D , the current user u and the last song s performed by user u , we want to train a model to generate a candidate song list for user u to choose from for his / her next performance. Along this line, we should estimate the transition probabilities between songs for each user (session) by measuring user preferences.
In this subsection, we describe the way to simultaneously mea-sure users X  long-term and short-term preferences and the relation-ships between users and songs by PME. Thus, the next-song rec-ommendation list can be generated naturally.

To this end, we map songs and users into points in a R d space, and use vector x ( s ) and vector y ( u ) to denote song s  X  X  and user u  X  X  coordinates in this space, respectively. The Euclidean distance be-tween two points reflects the relation between corresponding user-s / songs. If two songs stay apart from each other, it is not likely that they will show up in the same session. Also, if a user stays close to a song, he / she may often sing it. Worth noting that the relations are asymmetric, and this can be inferred from the later illustration.
First, we assume the probability Pr ( s b | s a ; u ) of a transition from song s a to song s b made by user u is related to the Euclidean dis-as user u  X  X  short-term and long-term preferences. Straightforward-ly, it can be described as: Thus, the user information is ignored by LME, while being consid-ered by our PME.

Further, we apply regularization of Frobenius norm to Equa-tion (6), and our target becomes: where is the regularization coe ffi cient, and we can get the updat-ing rules through partial derivations: where is the learning rate and n is the total number of song tran-sitions in data set D .

Finally, after the embedding, given the current user u and his / her last song s a , we could generate the next-song recommendation by ranking the candidate songs based on Equation (5). Meanwhile, we
In this section, we evaluate PME on the real world karaoke da-ta provided by ihou.com from July 2011 to April 2012. To reduce noise, we only consider the users who have sung more than 10 d-i ff erent songs and the songs which have been sung by more than 3 di ff erent users. For the singing session segmentation, we let the songs to be in the same session, if the user X  X  inactive intervals be-tween adjacent songs are less than 1 hour. We put the last transition of songs from each session into the test set, the rest for training, and ensure that every test song exists in the training set. The statistical information of the final data can be found in Table 1.
 Evaluation Metrics. To measure the ranking accuracy, we adopt Precision, Recall, F 1 -score and Mean Average Precision (MAP) as our evaluation metrics[7]. These metrics pay more attention to the first several candidates in the ranked list, and try to characterize the recommendation results from di ff erent perspectives.

Baselines. We choose the following four baseline methods: Specifically , we first separate transitions in the test set into 5 dif-ferent splits according to their occurrence time in the training data, with each split having roughly the same amount of transitions. For instance, the transitions in the test set that didn X  X  occur or occurred only once in the training set and transitions in the test set that oc-curred 2 to 5 times are evaluated separately. We calculate the Recall value on Top-10 recommendations of three typical algorithms (Bi-gram, LME and PME) for all 5 splits in R 50 , and the final results are shown in Figure 3. Figur e 3: Comparisons of the Recall value on Top-10 recom-mendations of Bigram, LME and PME with di ff erent splits.
From Figure 3 we can see that for the transitions that don X  X  occur many times (less than 17) in the training set, PME performs much better than Bigram and LME. However, the advantage of PME be-comes smaller with the increase of the occurrence. Specifically, PME achieves an average lead of 7.6% over the first three ranges, which take up about 60% percent of the test data, and Bigram is slightly better than PME only on the last range. Since most of the transitions have comparably low occurrence rate, PME could out-performs LME and Bigram in real applications, i.e., PME is better at predicting the unseen and sparse data.

Case Study. Figure 4 is a visualization of the trained PME model in
R 2 where all songs are represented by blue dots and 3 randomly picked users are represented by circles with di ff erent colors. We find out the songs sung by these 3 users in the training set, and then highlight them by semitransparent circles with their sizes propor-tional to the singing frequency of the corresponding user.
It shows that PME can successfully extract user preferences, s-ince the embedding position of each user is near to his / her previous actions. In the stage of recommendation, the songs that are close to the given user, or in other words close to the songs which the given user have sung, are more likely to be recommended to this user according to Equation (5).
