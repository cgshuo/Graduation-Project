 To model time-dependent user inte nt for Web search, this paper proposes a novel method using machin e learning techniques to ex-ploit temporal features for effective time-sensitive search result re-ranking. We propose models to inco rporate users X  click through information for queries that are seen in the training data, and then further extend the model to deal with unseen queries considering the relationship between queries. Experiment shows significant im-provement on search result ranking over original search outputs. General Terms: Algorithms, Design Keywords: Time sensitive query, temporal features Traditional search engine uses keyword matching with link-based strategies, such as PageRank, to improve search results without considering users' intent. We have observed through web query logs that the ideal ranking of search re sults does depend on query intent, which usually vary with time. Fo r the same query, the users may want to find different web pages in different time of the day. For example, from AOL dataset, we f ound that users who enter the que-(www.alcoholics-anonymous.org ) from 7am to 2pm, but the visiting preference changes to American Airline website ( www.aa.com ) from 3pm to 3am next day (see Figure 1). The aim of this paper is to re-rank search results based on user intents at different time of a day. Several researchers have observed that query popularity changes over time. Beitzel et al. [7] show changes in popularity of topically categorized queries across differen t hours of a day. Anagha et al. [6] explore how queries, their associated documents, and the query intent change over the course of 10 weeks by analyzing query log data. Dong et al. [2] propose ideas of "recency ranking X , which re-fers to ranking documents by re levance which takes freshness into account. They use multiple recency features to provide temporal evidence which effectively represents document recency. Li and Croft [4] identify a type of query that favors very recent documents, and propose a time-based language m odel to retrieve these queries. However, above works do not focus on exploiting queries intent with time to improve the search quality. We use the users X  temporal clic k information from query logs as training data to re-rank the search results at different time period. We design models to handle queries with click history, existing queries (see 3.1) , and queries with few or no click information, missing queries (see 3.2) . Finally, we use a learning-based method to build an ensemble of our predictions for search result re-ranking. The training data contains the a ggregated user click counts, with time stamp, of top URLs returned for each query. We use several different models to generate a raw score for each &lt;query, URL&gt; pair at each time period. Then, we e xploit a learning approach to com-bine the scores from different m odels and rank each URL for each given query. Finally, such ranking is linearly combined with the original (or baseline) ranking results through the following re-ranking formula,  X  X  X  X  X   X   X   X   X   X  where  X  is a weighting parameter varied from 0.0 to 1.0. Given the query and time, we propos e several models to estimate the quality of each returned docum ents for the re-ranking task.
 Temporal Prior: The relevance of a document/URL u to an exist-ing query q issued at time t is defined as: P  X  u | q,t  X   X  where f  X   X  q,u  X  is the frequency of users visiting URL  X  when search-probability given query q at time t in training data. This can be con-sidered as a maximum-likelihood model. Time-sensitive Content Model: Previous model only works for URLs that has been seen in the training set. To overcome such limi-tation, we propose to exploit the similarity between unseen docu-ments. The relevance of a URL u to query q issued at time t is de-the URL that are already in the training corpus and Sim X  X ,u context similarity of u and  X  X  . Sim(u,u') can be estimated from com-paring the difference between the n-gram distributions generated from u and u' , and P X  X  X  X q,t X  is the temporal prior of u X  . Temporal PageRank: PageRank is a popular model to assess the authority of a page. Unfortunately , the original PageRank algorithm does not consider temporal information. Here we propose temporal PageRank to incorporate such information by adding time infor-mation (click count of each URL u at time t ) into PageRank. To facilitate such idea, we first build a directed graph of all URLs in the dataset. There is a link connecting two webpages if the content of one URL contains a hyperlink to another URL. Then, we assign a click number for each webpage which is the total number of user clicks for that URL at time t . Temporal PageRank function is de-fined below.  X  X  X   X   X ,  X   X  is the adjacency function of these URLs , N is the total number of URLs, and d is the damping factor . The main difference URL u at time t. Note that this model measures the temporal authori-ty of pages, and thus is query in dependent (similar to PageRank). Missing queries presents a more di fficult challenge because of the insufficient temporal click information to learn from. To solve this problem, we propose to expl oit click information from extended queries which we have sufficient click information. First, we build a bi-partite graph of all queries and URLs as shown in Figure 3. We eliminate popular hub URLs such as Amazon.com, to avoid the interference from hub sites. Then, we define a query set  X  contains queries q X  that are 2 steps away from missing query q, as the extended queries, and generate new f  X   X  q,u  X  by combining user clicks of q and q X  as defined in the following equation, f f  X  q,u  X   X   X  f  X   X  X   X  ,u X  Q X  X  X  X  . Note that f t (q,u) is either 0 or a very small number based on the definition of missing query. Since extended queries may have different degree of resemblance to the missing query, we propose to we ight click counts based on the similarity between them. We define two similarity measures: 1. Sim  X  q,q  X   X   X   X  LM  X  u,u  X   X   X ,U X  X   X  U X   X  where LM  X  u,u tent similarity of u and u X  using character-based Language Model described in [10] while U and U X  are the set of URLs returned by search engine for query q and q X  respectively . We use the similarity measures define d in this section as features in Support Vector Regression for missing query dataset. Eventually we want to combine the results from proposed models with global features, including query term, query time, click count, and target URL. Instead of manual ly choosing the ensemble weights, we propose to learn them through a regression model. We choose epsilon-SVR with linear kernel for its superior performance. We collect data from the AOL que ry log, which contains click-through records from March 1, 2006 to May 31, 2006, representing the search behavior of 650,000 users generating 20 million queries. Each record has five fields, user id, query, query time, URL, and the relevance rank of each URL. The re levance rank is the default rank-ing of URLs for a query given by AOL search engine. Note that here we assume the query time in AOL dataset reflects the local time zone instead of an adjusted global time. To verify our hypothesis, we compare it with the query log from Sogou, a popular search en-gine in China, as China uses on e time zone throughout the country. The result shows similar searching behavior over time (see Figure 4), and support our hypothesis that AOL data reports local time zone, where there are fewer records from midnight to early morning. If the time were converted to a global time zone in AOL, it is likely we would have seen more evenly distributed graph throughout the day. We merge the clicks within four-hour interval starting from 2am, resulting in six time periods. Then 70% raw data are selected at random as training with the remaining 30% as testing and the pro-cess repeats 10 times. Existing queries are defined as queries con-taining two or more URLs whose cumulative click counts are great-er than 50 in the training data. Missing queries are those containing two or more URLs whose cumulative click counts are greater than 25 in testing data, but do not appear in the training data. The base-line is determined by the original search ranking given in the AOL query log. For ground truth, we use the click number rankings from testing data. We calculate the Kendall X  X  tau value between the ground truth and the ranking we predicted. Note that the baseline (i.e. without re-ranking,  X 1 X  ) reaches Kendall X  X  tau value 0.570. Existing Queries: The first row of Table 1 shows a decent im-provement of 9.1% on content mode l over the baseline. Note that the temporal prior model is not list ed as it cannot be generated with missing URLs. The final row of Ta ble 1 shows using all features achieves the best result of 10.3% over the baseline when  X  =0.2. Missing Queries: On top of the global fe atures, our learner adds similarity scores obtained from S ection 3.2 for ensemble. The Ken-dall X  X  tau value of the original order is 0.189, much lower than that of existing queries. The baseline is not as good because these que-ries usually contain typos or unpopular combinations of terms, which causes problems for a search engine due to lack of training data. Our model achieves Kendall X  X  tau value of 0.309, a significant improvement of 12%. The results show that considering users X  tem-poral intent can bring relatively mo re information to missing queries than to existing ones. This study verifies that understanding how users X  search intents change over time is critical for a search system. The consistent im-provement with a wide range of  X  , together with the fact that better improvement can be achieved when  X  decreases (i.e. the weight of our model increases) show the eff ectiveness of this framework. Fu-ture work includes exploiting a dvanced models (e.g. probabilistic graphical model) and design more temporal features for learning. 
