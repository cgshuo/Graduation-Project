 We study a new type of graph queries, which injectively maps its edges to paths of the graphs in a given database, where the length of each path is constrained by a given threshold specified by the weight of the corresponding matching edge. We give important applications of the new graph query and identify new challenges of processing such a query. Then, we devise the cost model of the branch-and-bound algorithm framework for processing the graph query, and propose an efficient algorithm to minimize the cost overhead. We also develop three indexing techniques to efficiently answer the queries online. Finally, we verify the efficiency of our proposed indexes with extensive exper-iments on large real and synthetic datasets.
 H.2.4 [ Database Management ]: System X  Query process-ing Graph Databases, Graph Matching Algorithm, Graph In-dexing, Graph Querying
Graph is a powerful data model that can naturally repre-sent various entities and their relationships. Graph data is ubiquitous today and being able to query such graph data is beneficial to many applications. For example, in bio-informatics and chemical informatics, graphs can model compounds and proteins, and graph queries can be used for screening, drug design, motif discovery in protein struc-tures, and protein interaction analysis. In computer vision, graphs represent organization of entities in images and graph queries can be used to identify objects and scenes. In het-erogeneous web-based data sources and e-commerce sites, graphs model schemas and graph matching can be applied to solve problems of schema matching and integration. There are also many other applications, such as program flows, software and data engineering, taxonomies, etc., where data is modeled as graphs and it is essential to search and query the graph data.

Existing research focuses on mainly two types of graph datasets, one consisting of a single large graph (e.g., an on-line social network or the entire citation graph in a certain domain) and the other consisting of a large set of small or medium-sized graphs. We focus on the later, which are also very popular in real life (e.g., most of the examples we listed earlierbelongtothistype).

To query a graph database, G , that consists of many small graphs, there are three types of queries commonly studied in the literature. Let q be a query graph. The first one is subgraph query [4,9,13,15,18,21,23], which finds the subset of graphs A of G such that q is a subgraph of any graph in A . The second one is supergraph query [2, 3, 14, 22], which finds the subset of graphs A of G such that q is a supergraph of any graph in A . The third one is similarity query [12,19, 20, 24], which finds the subset of graphs A of G such that q is a similar graph of any graph in A accordingtoagiven similarity measure.

The three types of queries are useful in different appli-cations. However, both subgraph queries and supergraph queries are too rigid and therefore similarity queries are proposed as an alternative. Existing similarity queries are mostly measured by the edit distance [20, 24] or maximum common subgraph [12,19], which is reasonable for some ap-plications but often fails to capture meaningful patterns or targets in applications where critical objects or entities may have to be matched or they may be within a distance from each other that is beyond the specified similarity distance (i.e., the similarity threshold). We show such an applica-tion, where both exact queries and similarity queries are not applicable, by the following example.

Example 1. Consider a drug design system, which sup-ports the inventive process of finding new medications based on the knowledge of the biological target. Figure 1 shows some compounds in the database, i.e., g 1 , g 2 ,and g 3 .A compound can be naturally modeled as a graph, where atoms are vertices, the chemical name of the atom is the label of the correspond vertex, and the chemical bonds between any two atoms are modeled as edges in the graph. Among many drug design methods, the pharmacophore model is the most popular one whose goal is to find the substructures that are closely matched to the objective. ALADDIN [17] is a com-puter program for the design and recognition of compounds that meet geometric, steric, and sub-structural criteria. AL-Figure 1: A drug database, G = { g 1 ,g 2 ,g 3 } ,andtwo query graphs, q 1 and q 2 Table 1: A graph query in ALADDIN language ADDIN also uses a precise geometric description language to define the properties of a designed molecule.

The query shown in Table 1 is written in the ALADDIN language, which is to find a graph pattern where 1. there are four atoms: N , H , O ,and C , whose positions 2. the distance between N and H is 1 to 3, and similarly
Since the distance between all pairs of atoms can be esti-mated [11], the distance can be further modeled as the num-ber of bonds that connect the atoms. Thus, the query in Table 1 can be converted to a graph query which finds all graphs in the database such that 1. there exist four vertices u 1 to u 4 in the graph whose 2. let P = u i ,...,u j be a path that connects u i and u
Such a query can be naturally represented as the query graph 1 q 1 shown in Figure 1, and the answer to this query is { g 3 } . In such a query, subgraph query cannot be applied, while similarity query is also not suitable when the matching paths are long.

In this paper, we study this new type of graph queries as described in Example 1, which will be formally defined in Section 2. But intuitively, the new query is a generalization of the subgraph query, which generalizes exact edge match-ing to path matching constrained by a path length; that is, instead of matching each edge as in a subgraph query, we find a path with two matching end vertices for each edge in the query graph, where the length of the matching path must be within the specified edge weight. Thus, the new query has a much stronger expressive power than a subgraph query. We assume that path length cannot be negative.
 Such a query is also useful in many other applications. For example, in querying user online traversal graphs, one may be only interested in whether users have visited certain important sites within a certain number of clicks, while an exact or a quality similar matching may not exist. In search-ing pictures in an image database, it is often rare to find an exact or even similar matching due to the huge amount of ir-relevant information in the background (note that similarity measure by edit distance or maximum common subgraph of-ten counts all such irrelevant information in the matching); in this case, we can specify a few features to be focused in the matching while relaxing the links between the features by some reasonable edge weight.

Processing the new query, however, is significantly more challenging. For both subgraph and supergraph query pro-cessing, it involves subgraph isomorphism which is NP-hard. The relaxation in the new query from exact edge matching to approximate path matching essentially further explodes the already exponential search space. Existing pruning tech-niques cannot be directly applied or they are simply not ad-equate, since our generalized query graph is different from the indexed features. Therefore, this paper proposes new effective pruning techniques and efficient data structures to solve this challenging problem.
 Our contributions. The contributions of this paper are four-fold. First, we propose the problem of generalized subgraph query processing, which is useful in applications where subgraph queries are too restrictive to apply while similarity queries may return low quality answers due to large edit distance arisen from abundant irrelevant informa-tion. Second, we devise a fast algorithm for generalized sub-graph matching, which is a significantly more complicated matching problem than subgraph isomorphism. Third, we develop three indexes for the efficient processing of gener-alized subgraph queries, namely, a distance-based index, a frequent-pattern-based index, and a star-structure-based in-dex. We discuss in details the strengths and limitations of the indexes. Fourth, we verify the efficiency of our matching algorithm (for candidate verification) and our indexes (for filtering) using both real and synthetic datasets. Paper Organization. Section 2 gives the notations and formally defines the problem. Section 3 presents the gener-alized subgraph matching algorithm. Section 4 discusses in details the three indexes. Section 5 reports the experimental results. Section 6 discusses the related work and Section 7 concludes the paper.
Let G be a database that contains a set of simple and labeled graphs. We denote each graph g  X  X  as a triplet g =( V g ,E g ,l g ), where V g and E g are the sets of vertices and edges in g ,respectively,and l g is a labelling function that maps each vertex in g to a label in a finite alphabet. For ease of exposition, we assume that all edges in g are undirected; our results can be easily extended for directed graphs.

For any vertices u and v in a graph g  X  X  , we define the distance between u and v , denoted as dist g ( u, v ), as the num-ber edges in the shortest path between u and v . For instance, in the graph g 3 in Figure 1, we have dist g 3 ( v 1 ,v 3 since the shortest path between v 1 and v 3 contains two edges ( v 1 ,v 2 )and( v 2 ,v 3 ).
We aim to support generalized subgraph queries on G .In particular, a generalized subgraph q is a simple, undirected, and labelled graph where each edge carries a positive integer weight. We denote q as a quadruple ( V q ,E q ,l q ,t ), where V and E are the sets of vertices and edges in q , respectively, l is the labelling function for q ,and t is a function that maps each edge in q to its weight. We say that a graph g  X  X  matches q , if there exists an injective function f from V V , such that for any edge ( u, v )in q ,(i)thelabelsof u and f ( u ) are the same, (ii) the labels of v and f ( v )arethesame, and (iii) the distance between f ( u )and f ( v )in g is no more than the weight of ( u, v ).

For example, in Figure 1, the graph g 3 matches the gen-eralized subgraph q 1 . To explain this, let us consider an injective function f that maps u 1 to v 3 , u 2 to v 1 , u and u 4 to v 5 .Fortheedge( u 1 ,u 2 )in q 1 ,wehave f ( u and f ( u 2 )= v 1 , and the distance dist g 3 between v 3 in g 3 equals 2, which is no more than the weight associated with ( u 1 ,u 2 ). The cases for the other edges in q 1 can be verified in a similar manner.

Given a generalized subgraph q , a generalized subgraph query on G returns the graphs in G that match q .Forcon-venience, we refer to q as the query graph , and the graphs in G as the data graphs . In addition, we say that a data graph g contains q (denoted by q  X  g ), if g matches q .
To enable generalized subgraph queries on G , we need to first address a crucial problem: How do we decide whether a data graph g  X  X  matches the query graph q ? We refer to this problem as the generalized subgraph matching prob-lem. It is not hard to see that this problem is NP-hard; in particular, when the weights of all edges in q equal 1, test-ingwhetheradatagraph g matches q is equivalent to the subgraph isomorphism problem, which has been shown to be NP-complete [5].

Given that generalized subgraph matching is theoretically intractable, we resort to heuristics and propose a solution that provides practical efficiency. The core of our solution is a cost-based matching approach that significantly extends and improves the existing heuristic algorithms [13, 16] for the subgraph isomorphism problem. In what follows, we will first introduce the existing methods for subgraph iso-morphism (in Section 3.1), and then present the details of our solution (in Section 3.2).
The classic solution for the subgraph isomorphism is Ull-mann X  X  algorithm [16], which matches the vertices in the query graph q to the vertices in the data graph g in an iter-ative manner. Specifically, in each iteration, the algorithm selects an unmatched vertex u in q , maps it to an unmatched vertex in g with the same label, and then checks whether the mapping is feasible , i.e., whether any two matched vertices in q that induce an edge in q are mapped to two vertices in g that induce an edge in g . If the mapping is feasible, the al-gorithm will enter the next iteration to match the remaining vertices in q . Otherwise, the algorithm will try matching u to another unmatched vertex in g . If there is no vertex that u can be matched to, the algorithm backtracks to the last matched vertex u in q ,re-maps u to an unmatched vertex in g , and then re-starts the current iteration.

For example, in Figure 1, given the query graph q 2 and the data graph g 3 , Ullmann X  X  algorithm may first map u 5 v ,andthenmap u 6 to v 5 .Inthatcase, u 5 and u 6 induce an edge in q 2 , while v 3 and v 5 also induce an edge in g the matching is feasible. Assume that, in the next iteration, the algorithm maps u 7 to v 4 . Then, u 6 and u 7 induce an edge in q 2 , but the vertices that they are mapped to (i.e., v and v 4 ) do not induce any edge in g 3 . As a consequence, the mapping is infeasible, and hence, the algorithm would proceed to re-map u 7 to another unmatched vertex in g 3 .
Intuitively, the efficiency of Ullmann X  X  algorithm depends on the order in which the vertices in q are matched. For in-stance, assume that q contains only two vertices u 1 and u such that u 1 has the same label with only one vertex v 1 the data graph g ,whereas u 2 has the same label with almost all vertices in g . If we invoke Ullmann X  X  algorithm and map u 1 to v 1 in the first iteration, then in the remaining itera-tions, we only need to examine whether u 2 can be mapped to a vertex adjacent to v 1 . In contrast, if the first iteration maps u 2 (instead of u 1 )tosomevertex v in g ,theninthe remaining iterations, we not only need to try mapping u 1 to the neighbors of v , but also need to consider other possi-ble mappings that match u 2 to other vertices in g , i.e., the search space of the algorithm becomes significantly larger.
Despite the importance of vertex mapping order, it is not taken into account in Ullmann X  X  algorithm. This motivates a more advanced method called QuickSI [13], which improves over Ullmann X  X  algorithm by heuristically choosing a map-ping order that is likely to reduce computation cost. Specif-ically, QuickSI decides the vertex mapping order based on two sets of statistics pre-computed from the graph database G . First, for any vertex u that can possibly appear in a query graph, QuickSI pre-computes its frequency in G , i.e., the average number of vertices in each data graph (in G ) that have the same label with u . Second, for any edge e that may appear in a query graph, QuickSI also pre-computes its frequency in G , i.e., the average number of edges in each data graph that have endpoints with labels matching those of the endpoints of e . With these statistics, for any given query graph q , QuickSI first generates a spanning tree of q , such that vertices and edges closer to the root of tree tend to have lower frequencies in G . After that, QuickSI gener-ates an ordering of the vertices in q following a traversal of the spanning tree that recursively visits the branch with the least frequent edge. The resulting vertex order is then used whenever QuickSI compares a data graph g with q .In-tuitively, this vertex order improves efficiency, as it tends to ensure that the search space of the matching algorithm would be reduced significantly after each iteration.
Both Ullmann X  X  algorithm and QuickSI can be extended for generalized subgraph isomorphism, with a modified fea-sibility check in each iteration. Specifically, each time after we map a vertex u in the query graph q to a vertex v in the data graph g , we would decide whether the mapping is feasible by examining every edge e in q that is induced by u and any vertex u in q that has been matched. Let v be the vertex in g that u is mapped to. If for each e , the distance dist g ( v,v ) between v and v is no more than the weight w ( e )of e , then the mapping is feasible, and we would proceed to the next iteration. Otherwise, we would re-map u to other unmatched vertex in g ; if there does not exist any feasible mapping for u , we would backtrack to the last matched vertex in q and re-map it (as with the case of subgraph isomorphism).

The aforementioned extensions of Ullmann X  X  algorithm and QuickSI, however, leave much room for improvements. In particular, Ullmann X  X  algorithm does not exploit the order of vertex mapping for efficiency; QuickSI heuristically tunes the vertex mapping order, but its tuning method is rather ah hoc and is without a formal model that justifies mapping a vertex ahead of any other. To remedy this, we propose a novel algorithm for generalized subgraph isomorphism that incorporates a cost model for selecting a preferable order of vertex mapping. In the following, we will first present the rationale behind our method, and then provide the details about our cost model and algorithm.

Assume that the query graph q and the data graph g contain m and n vertices, respectively. Totally, there exist P ( n, m )= n ! / ( n  X  m )! different ways to map the vertices in q to distinct vertices in g ,andthese P ( n, m ) possible match-ings constitute the search space for the generalized subgraph isomorphism algorithm. ( P ( m, n ) denotes the number of m -permutations of n .) To efficiently decide whether g matches q , it is essential that the algorithm should traverse the search space in a judicious order that enables it to pinpoint a so-lution (if any) as quickly as possible. This motivates us to match vertices in q in an order based on how likely they can reduce the search space that we need to explore. Note that we use the same node mapping order for all data graphs (as in QuickSI), so as to avoid the overhead of re-computing the node order for each data graph.

Specifically, to pick the first vertex in q to be matched, we would inspect each edge e in q , and examine the frequency of e (denoted as c ( e )) in the data graphs in G . The frequency of ( u ,u  X  )in q is defined as the average number of vertex pairs ( v ,v  X  )ineachdatagraphin G , such that (i) the labels of u and v are the same, (ii) the labels of u  X  and v  X  are the same, and (iii) the distance between v and v  X  is no more than the weight of ( u ,u  X  ). (To facilitate this step of the algorithm, we pre-compute the frequency of any edge that may appear in the query graph.)
For each e , we intuitively estimate that it can be matched to c ( e ) vertex pairs in the data graph. Given this estimation, if a vertex u is an endpoint of e and we choose to match u first, then the search space size induced by mapping u can be estimated as c ( e )  X  P (  X  n  X  1 ,m  X  1), where  X  n denotes the average number of vertices in the data graphs. The rationale here is that u is expected to be mapped to around c ( e ) vertices in a data graph, and the other unmatched m vertices in q are expected to be matched to around  X  n  X  vertices in g in P (  X  n  X  1 ,m  X  1) different ways; therefore, the number of possible matchings that remain to explored can be estimated as c ( e )  X  P (  X  n  X  1 ,m  X  1). Accordingly, we pick a vertex u incident to the edge e with the smallest c ( e ), and set u as the first vertex to be matched. The term P (  X  n  X  1 ,m  X  1) is ignored since its value is the same for all vertices in q . (This helps us avoid the pathological case when  X  n&lt;m ,i nwhichcase P (  X  n  X  1 ,m  X  1) is undefined.) Given that the edge e with the smallest c ( e ) has two endpoints, we choose the endpoint u with the smaller frequency c ( u ).
The order of the remaining vertices is decided in a similar manner. Assume that we have picked a set S of k vertices and we are about to choose the next vertex to be matched. Let u be any vertex that has not be selected. If u is not connected to any vertex in S by an edge in q ,thenweesti-mate the search space size induced by mapping u as where N ( S ) denotes the number of ways to match the first k vertices, and P (  X  n  X  k  X  1 ,m  X  k  X  1) is the number of ways to match the remaining m  X  k  X  1verticesexcept u . As will be shown shortly, we do not need to compute the values of N ( S )and P (  X  n  X  k  X  1 ,m  X  k  X  1).

On the other hand, if u has some edges that are incident to the vertices in S , then our estimation of the search space size would take those edges into account. Let E be the set of edges in q that connect u to the vertices in S .Foreach e in E that connects u to a vertex u  X  , we examine the frequency of u  X  (denoted as c ( u  X  )) in G , as well as the frequency of e mate that the vertex u  X  is connected to around c ( e ) /c ( u vertices that have the same label with u . Therefore, the search space size induced by mapping u is estimated as where u  X  S c ( u )and P (  X  n  X  k  X  1 ,m  X  k  X  1) are as explained in Equation 1. We refer to c ( e ) /c ( u  X  )asthe matching rate of u implied by e , and we denote it as r ( u ,e ).
Observe that each edge e  X  E may imply a different matching rate of u , leading to different estimations of the search space size. We combine all estimations by taking the smallest one, i.e., the size of the search space is estimated as
For convenience, we let r ( u )=min e  X  E r ( u ,e )if u is connected to the vertices in S by at least one edge in the data graph, otherwise we let r ( u ) be the minimum frequency of an edge in q that is adjacent to u . Given Equations 1 and 4, we choose the next vertex u to be matched as the one that minimizes the estimated search space size, i.e., Note that Equation 4 does not involve the terms N ( S )and P (  X  n  X  k  X  1 ,m  X  k  X  1) (which appear in both Equations 1 and 4). This is because their values are the same for all possible u , and hence, they have no effect on the selection of u .

In summary, our algorithm optimizes the vertex matching order by a qualitative prediction of how each vertex may help reduce the search space size. As will be shown in Section 5, our experimental results demonstrate the superiority of our algorithm over both Ullmann X  X  algorithm and QuickSI on both standard and generalized subgraph isomorphism tests.
Although in Section 3 we proposed a reasonably fast al-gorithm for generalized subgraph matching, it is still im-practical to answer a query by sequentially scanning the input database and matching the query graph with each data graph, especially if the database is large. We apply the filtering -and-verification strategy to reduce the match-ing cost, that is, we first filter out as many unmatching data graphs as possible and then verify the remaining candidate data graphs by matching them with the query graph one by one. To do this, it is important to design an effective index-ing technique to filter out the unmatching data graphs. In this section, we propose three indexing techniques: D-Index , FP-Index and S-Index . First, in Section 4.1 we present D-Index, which can be easily constructed but its pruning power is relatively weak. Then, we propose FP-Index in Section 4.2, which has an expensive construction cost but is partially verification-free. Lastly, in Section 4.3 we propose S-Index, which explores the star structures to achieve effective pruning as well as a low construction cost.
We first present D-index, which is constructed based on the distance among pairs of vertices in each data graph. Given a data graph g =( V g ,E g ,l g )  X  X  , we obtain the dis-tance set ( DS ) of all triplets of every two vertices consisting of their ordered labels and the correspond distance in g as follows.
 DS ( g )= { ( l g ( u ) ,l g ( v ) ,dist g ( u, v )) : u, v
A distance triplet ( l 1 ,l 2 ,d )  X  X S ( g ) is subsumed by an-other distance triplet ( l 1 ,l 2 ,d )  X  X S ( g )if d&gt;d .Wesay that a subset DS min ( g )  X  X S ( g ) is minimal if each distance triplet in DS min ( g ) is not subsumed by any other distance triplet, that is, for each ( l 1 ,l 2 ,d )  X  X S min ( g ), there does not exist ( l 1 ,l 2 ,d )  X  X S min ( g ) such that d &lt;d .
Example 2. Assume that vertex labels are ordered lexi-in Figure 1, the distance set of g 3 is DS ( g 3 )= { ( C (
C , C ,2), ( C , C ,3), ( H , C ,1), ( H , C ,2), ( H , C ,3), ( (
O , C ,1), ( O , C ,2), ( O , C ,3), ( O , C ,4),( N , H ,2), ( (
O ,
N ,1), ( O , N ,2), ( O , O ,1) } ,and DS min ( g 3 )= { (
H , C ,1), ( N , C ,1), ( O , C ,1), ( N , H ,2), ( O , H ,3), ( Note that |DS ( g 3 ) | =18 while | DS min ( g 3 ) | =8 .
The minimal set of distinct distance triplets in the database is then given by
For each distance triplet ( l 1 ,l 2 ,d )  X  X S ,thesetofdata graphs that contain ( l 1 ,l 2 ,d )isgivenby The Distance Index ( D-index ) is constructed on DS and A ( l 1 ,l 2 ,d )foreach( l 1 ,l 2 ,d )  X  X S , which is to be detailed as follows.
The structure of D-index consists of the following parts:
Algorithm 1: Build-DIndex ( G ) input : the graph database, G output : the D-index, LPI 1for g  X  X  do 2 Compute DS min ( g ); 3for ( l 1 ,l 2 ,d )  X  X S min ( g ) do 4 LP I  X  ( l 1 ,l 2 ); 5 LP I ( l 1 ,l 2 ) .DV  X  d ; 6 LP I ( l 1 ,l 2 ) .DV ( d )  X  g ; 7return LP I
Algorithm 2: Query-DIndex ( q,LPI, G ) input : the query graph, q =( V q ,E q ,l q ,t ) output : the candidate set of q , C ( q ) 1
C ( q )  X  X  ; 2for ( l 1 ,l 2 ,d )  X  X S min ( q ) do 3 C ( l 1 ,l 2 ,d )  X  X  X  ; 4for k  X  LP I ( l 1 ,l 2 ) .DV and k  X  d do 5 C ( l 1 ,l 2 ,d )  X  X  ( l 1 ,l 2 ,d )  X  LP I ( l 1 ,l 2 ) .DV ( k ); 6 C ( q )  X  X  ( q )  X  X  ( l 1 ,l 2 ,d ); 7return C ( q )
The algorithm for D-index construction, Build-DIndex , is shown in Algorithm 1. For each data graph g  X  X  ,we first compute its minimal distance set DS min ( g )(Line2). Then, for each distance triplet ( l 1 ,l 2 ,d )  X  X S min ( g ), we assign ( l 1 ,l 2 )to LPI and put the distance value d to the sorted list LP I ( l 1 ,l 2 ) .DV (Line 4-5). Finally, g is included in LP I ( l 1 ,l 2 ) .DV ( d )(Line6).
Given a query graph q =( V q ,E q ,l q ,t ), we first obtain its minimal distance set DS min ( q ) by all pairs shortest path algorithm. For each distance triplet ( l 1 ,l 2 ,d )  X  X S min the correspond candidate set C ( l 1 ,l 2 ,d ) can be obtained by merging all the graph sets associated with LP I ( l 1 ,l 2 for 1  X  k  X  d . The final candidate set C ( q ) for verification is the intersection of all the candidate sets of each distance triplet ( l 1 ,l 2 ,d )  X  X S min ( q ), that is As shown in Algorithm 2, processing the query graph q by D-index obtains the candidate set for each distance triplet ( l ,l 2 ,d )  X  X S min ( q ) (Lines 3-5), and then intersects them to output the candidate set of q (Line 6).

Lemma 1. Given a query graph q =( V q ,E q ,l q ,t ) ,itsan-swer set A ( q ) is a subset of Build-DIndex ( q,LPI, G ) . Proof. Consider a data graph g =( V g ,E g ,l g )  X  G that matches q . For each edge ( v,u )  X  E q ,we can map it to a path P = f ( v ) ,...,f ( u ) such that |
P | X  t ( v,u ). Without the loss of generality, we assume that l g ( f ( v ))  X  l g ( f ( u )). Consider the distance triplet ( l ( f ( v )) ,l g ( f ( u )) ,d )  X  X S min ( g ), we have d  X | is d  X  t ( v,u ), which completes the proof.
Assume that  X  is the average number of vertices and  X  is the average number of edges for the graphs in G ,thespace complexity of D-index is O (  X  2 |G| ). Since the construction time for each DS min ( g )is O (  X  X  ) by starting a BFS from each vertex in g , the time complexity of constructing D-index is O (  X  X  |G| ).

The generation of minimal distance set of query graph q can be done in O ( | V q | 3 ) time. For each distance triplet in
DS min ( q ), the response time of D-index is O (log( md )) where m is the number of distinct labels in G and d is the largest distance. Thus, the index response time for the graph pattern is O ( | V q | 3 + k 2 log( md )), where k is the number of distinct labels in q . Note that, in practice, both | V q are very small.
The shortcoming of D-index is that it loses the structural information of data graphs. As a result, the filtering is not effective enough, leading to a lot of unmatched candidate graphs. Although there are graph indexing approaches that retain structural information of data graphs [4,9,15,18,23], they cannot be directly applied to answer generalized sub-graph queries.

In order to employ structural information for answering generalized subgraph queries, we propose the concept of fre-quent generalized subgraph ( FGG ) patterns and apply FGGs to design a structural index called Frequent Pattern Index ( FP-index ). The challenges, however, are 1) how to effi-ciently mine the FGGs, 2) how to apply and index FGGs for filtering. We address the two challenges as follows.
The first challenge can be addressed by the pattern-growth approach [1]. The difference is that in an FGG, edges are weighted. To obtain weighted edges for FGGs, we grow the frequent patterns from weighted edges. We initialize the set of weighted edges by taking the set of distinct distance triplets E =  X  g  X  X  DS ( g ) introduced in Section 4.1, where each distance triplet ( l 1 ,l 2 ,d )  X  X  is considered as an edge ( l ,l 2 )withweight d , while |C ( l 1 ,l 2 ,d ) | is the frequency of the edge.

A subgraph pattern f is frequent if its frequency is greater than a pre-defined threshold  X  . Since the number of FGGs can be too large and indexing a large number of FGGs will increase the index size and hence the search time, we apply a maximum pattern size threshold,  X  , and a maximum edge weight threshold,  X  , to obtain only FGGs with size at most  X  and any edge weight at most  X  .Inourexperiments,we set these thresholds as the best possible values such that the FGGscanfitinthemachinememory.
The FP-index consists of two parts: frequent pattern graph index ( FPG-index )and edge index ( E-index ). FPG-index stores the FGGs in a B+-tree, with the key as an FGG and the data value as the set of data graphs containing the FGG. To answer queries that may contain infrequent edges, we also construct E-index that builds a B+-tree on the set of infrequent edges and frequent large-weight edges whose weights are larger than  X  , with the key as an edge and the data value as the set of data graphs containing the edge.
Given a query graph q , we process the query with FP-index as follows:
Figure 2: Two star structures: s g 3 ( v 1 ) and s g 3 ( v
Similar to other structural graph indexes such as FG-index [4], the construction cost of FP-index is dominated by the cost of mining FGGs and the index size is dominated by the overall size of FGGs. Likewise, the query processing complexity also heavily depends on the number of FGGs indexed as well as the value of  X  |G| . However, the complexity of mining FGGs, as well as the size and number of FGGs, may vary significantly from database to database and we are not aware of any formal analysis for these factors in the literature.
Since the number of FGGs can be large, FP-index can only be used to process queries of small size efficiently. Moreover, mining FGGs may also be too expensive. Thus, we propose another index, called Star Index ( S-index ), which uses only star structures (instead of subgraph structures) to reduce both the index construction and storage overhead, while still capturing much of the structural information for effective filtering in query processing.

For a vertex v in a data graph g =( V g ,E g ,l g )  X  X  ,we define the star structure of v as s g ( v )=( V g ,E v g ,l (1) v is the center of the star structure; (2) E v g consists of the edges from v to other vertices in V g ,thatis E v g = { v { v } ); (3) w is a function that assigns the distance dist g to each edge ( v,u )  X  E v g , i.e., w ( v,u )= dist g ( v,u ). For example, Figure 2 shows the star structures of v 1 and v 3 the graph g 3 in Figure 1.

We group the weights of the edges in a star structure by the label of the non-center end vertex. Let L = { l g ( u ): u V g \{ v }} .Weobtaina multiset of weights (called weight multiset ) for each label as follows
W g ( v,l )= { w ( u, v ): l g ( u )= l, l  X  L, and u  X  V
The weight values in the weight multiset are sorted in ascending order. Table 2 lists all the weight multisets for each label and each star structure of g 3 . For example, for the star structure s g 3 ( v 1 ), W g 3 ( v 1 , C )= { 1 , 2 , 3 { 3 , 4 } ,and W g 3 ( v 1 , N )= { 2 } .

Given two weight multisets W 1 = { w 1 ,...,w k } and W 2 { w 1 ,...,w t W 2 as follows.

W 1  X  X  2 = { min( w 1 ,w
For some vertices in a graph, they may share the same la-bel. So, we further compress the weight multisets as follows.
Table 3 lists the compressed weight multisets. For exam-ple, v 2 and v 5 share the same label C ,so W g 3 ( v 2 , and W g 3 ( v 5 , H )= { 3 } are merged into one W g 3 ( C { min(1 , 3) } = { 1 } .

The set of distinct compressed weight multisets of each la-bel pair ( l 1 ,l 2 ) in the database G can be obtained as follows.
For each compressed weight multiset w  X  X  ( l 1 ,l 2 ), the set of data graphs whose corresponding compressed weight multiset is w is defined as follows.

S-index is constructed based on W ( l 1 ,l 2 )foreachdistinct label pair ( l 1 ,l 2 )and A ( w )foreach w  X  X  ( l 1 ,l 2 index structure of S-index consists of the following parts:
Algorithm 3 outlines the construction of S-index. For each data graph g  X  X  , for each distinct label pair ( l 1 ,l 2 obtain the compressed weight multiset W g ( l 1 ,l 2 ), and store it in the record with the key ( l 1 ,l 2 )in SI . Then, we access the record with the key W g ( l 1 ,l 2 ) in the nested B+-tree SI ( l 1 ,l 2 )andadd g to the corresponding record.
Algorithm 3: Build-SIndex ( G ) input : the graph database, G output : the S-index, SI 1for g  X  X  do 2 Let L ( g )= { ( l g ( u ) ,l g ( v )) : u, v  X  V g and u = v 3for ( l 1 ,l 2 )  X  L ( g ) do 4 Compute w = W g ( l 1 ,l 2 ); 5 Add w to the record in SI with key ( l 1 ,l 2 ); 6 Add g to the record in SI ( l 1 ,l 2 )withkey w ; 7return SI
Algorithm 4: Query-SIndex ( q,SI, G ) input : the query graph, q =( V q ,E q ,l q ,t ) output : the candidate set of q , C ( q ) 1
C ( q )  X  X  ; 2 Let L ( q )= { ( l g ( u ) ,l g ( v )) : u, v  X  V g and u = v 3for ( l 1 ,l 2 )  X  L ( q ) do 4 Compute W q ( l 1 ,l 2 ); 5 C ( l 1 ,l 2 )  X  X  X  ; 6for w  X  SI ( l 1 ,l 2 ) and w  X W q ( l 1 ,l 2 ) do 7 C ( l 1 ,l 2 )  X  X  ( l 1 ,l 2 )  X  X  ( w ); 8 C ( q )  X  X  ( q )  X  X  ( l 1 ,l 2 ); 9return C ( q )
We now discuss query processing by S-index. Given two compressed weight multisets W 1 = { w 1 ,...,w k } and W 2 { w 1 ,...,w t and 2) w r  X  w r for 1  X  r  X  t .

Lemma 2. Let s g ( u ) and s q ( v ) be two star structures, such that u and v are vertices in graphs g =( V g ,E g ,l and q =( V q ,E q ,l q ,t ) , respectively. If s g ( u ) matches s pairs ( l 1 ,l 2 ) of q .

Proof. Consider a label pair ( l 1 ,l 2 )of q , l 1 is the label of the center vertex of a star structure of q and l 2 is the label of a non-center vertex. Since g matches q ,thenumber of vertices in V g with label l 2 is no smaller than the number of vertices in V q with the same label. Therefore, we have |W g ( l 1 ,l 2 ) | X |W q ( l 1 ,l 2 ) | . Moreover, for each vertex v V q of label l 2 , there exists a vertex u  X  V g such that u maps to v and dist g ( u, u )  X  dist q ( v,v ). Thus, the proof is complete.

According to Lemma 2, we process a query by S-index as shown in Algorithm 4. For each distinct label pair ( l 1 ,l of q , we merge all the candidate sets associated with ( l that are smaller than W q ( l 1 ,l 2 ), which gives C ( l candidate set of q is then obtained by intersecting C ( l for all distinct pairs ( l 1 ,l 2 )of q .
Let m be the average number of distinct labels in a data graph. Thus, the number of distinct label pairs is O ( m 2 ), and the number of compressed weight multisets in Figure 3: Efficiency of Generalized Subgraph Iso-morphism Algorithms the database G is O ( m 2 |G| ). Assume that the average num-ber of vertices in a data graph is  X  , then the average size of a compressed weight multiset is  X /m .Thus,thespace complexity of S-index is O (  X m |G| ).

Assume that the number of distinct labels in a query graph q is t . The index response time is the summation of the time for searching the compressed weight multisets of q ,thusthe running time complexity is O ( t 2 log( m 2 |G| )). Note that, in real life queries, the number of distinct labels is often small.
This section experimentally evaluates our indices and al-gorithms for generalized subgraph matching. Section 5.1 describes the experimental settings. Section 5.2 evaluates our algorithms for the generalized subgraph isomorphism problem, and Section 5.3 tunes the parameters for the pro-posed FP-Index. After that, Sections 5.4 and 5.5 demon-strate the efficiency of our indexing methods on real and synthetic datasets, respectively. Datasets. We use two benchmark datasets commonly adopted in the literature [8, 18]. Both datasets contain graphs that represent chemical molecules. The first one is the AIDS Antiviral Screen Dataset [18], which consists of 10 , 000 graphs. The second dataset is referred to as PubChem [18], and it contains 100 , 000 graphs. We use PubChem. m K to denote a sample set of PubChem with m thousands of graphs. In addition, we use synthetic datasets produced from GraphGen 2 , a public available syn-thetic graph generator.
 Query sets. For the AIDS dataset, we adopt the query sets from [18], but we ignore the label on each edge and add a weight on the edge (since we target at query graphs where the edges are unlabelled and weighted). For the other datasets, we generate the query sets by first extracting gen-eralized subgraphs from the graphs in the datasets, such that the number of data graphs matching each extracted generalized subgraph is at most 10% of the total number of data graphs. In other words, we avoid generating general-ized subgraph matching queries that would return excessive numbers of results.

All of our experiments are conducted on a machine with aIntelXeon2 . 4GHz CPU with 48GB RAM.
Our first set of experiments compares three algorithms for generalized subgraph isomorphism: our cost-based ap-http://www.cse.ust.hk/graphgen/ Figure 4: Space and Pre-computation Costs of the FP-index proach (denoted as CBA), as well as the extensions of Ull-mann X  X  algorithm and QuickSI. Figure 3 illustrates the aver-age running time required by each algorithm to match each query graphs in query set Q i to all data graphs in the AIDS dataset. In particular, each query set Q i contains 1000 query graphs, and each query graph in Q i contains i vertices. Fig-ure 3a shows the results when the edges in the query graph have average weight 1 . 5. Observe that CBA considerably outperforms the extension of QuickSI, which in turn is su-perior than the extension of Ullman X  X  algorithm. Figure 3b shows the results when the average edge weight in the query graph equals 1, i.e., when the generalized subgraph isomor-phism problem degenerates to the standard subgraph iso-morphism problem. Even in this degenerated case, CBA still consistently outperforms QuickSI and Ullmann X  X  algorithm. This demonstrates the superiority of our cost-based method for optimizing vertex matching order. We have conducted a similar set of experiments on the PubChem datasets, and we found that the results are qualitative similar; we omit those results for the interests of space.
The second set of our experiments evaluation the space and pre-computation costs of the FP-index (presented in Section 4.2) on a set of 40 thousands data graphs sampled from the PubChem dataset. Figure 4a illustrates the num-ber of Frequent Generalized subGraphs (FGG) that need to be stored in the FP-index, varying the maximum edge weight  X  in the graph patterns from 1 to 4, with the fre-quency threshold set to  X  =0 . 05 and the maximum number of vertices in the FGGs set to  X  = 4. Note that the num-ber of FGGs increases exponentially with maximum edge weight  X  . Figure 4b shows the time required to mine the FGGs, which also exhibits an exponential growth with the increase of  X  . These results indicate that maximum edge weight adopted in the construction in the FP-index have to be carefully selected and has to be reasonably small.
Figures 4c and 4d illustrate the number of FGGs and pre-computation time required by FP-index, respectively, vary-ing the frequency threshold  X  from 0 . 01 to 0 . 05, with the maximum edge weight set to  X  = 3 and the maximum num-ber of vertices in the FGGs set to  X  =4. Observethat both the number of FGGs and the pre-computation time decreases exponentially when the frequency threshold  X  in-creases. Hence, we may use a large  X  to reduce the space and pre-computation cost of the FP-index. One may be tempted to set  X  to be even larger than 0 . 05, which, how-ever, may significantly reduce the effectiveness of FP-index, as an excessively large  X  would make it difficult for FP-index to answer a query without invoking the verification process.
Based on the results in Figure 4, we set  X  =3,  X  =0 . 05, and  X  = 4 for the FP-index in all following experiments.
Our next set of experiments compares the performance of the three proposed indices (i.e., D-index, S-index, and FP-index) in terms of query processing performance, space overhead, and construction time. For these experiments, we use sample sets of PubChem dataset with sizes varying from 10K to 100K. We do not use the AIDS dataset as it contains only a small number of data graphs.

Figure 5a illustrates average query processing time of each index for a query set with 1000 graphs, such that on aver-age each graph has 5 vertices and 7 edges, and the average edge weight equals 2 . 5. Both the S-index and the FP-index significantly outperforms the D-index, and the FP-index is slightly better than the S-index. This is consistent with the results in Figure 5b, which shows the average size of the candidate set induced by each index during query process-ing. As shown in Figures 5c and 5d, however, the space and construction overheads of FP-index are significantly higher than those of the S-index, which in turn are higher than those of the D-index.

Figure 6a shows the average query time of each index for query sets V i E j on the dataset with 40K data graphs, such that each query set V i E j contains 1000 query graphs, each of which has i vertices and j edges, and the average weight of the edges equals 2 . 5. The FP-index achieves the smallest query time when the numbers of vertices and edges in the query graphs are small, but it is outperformed by the S-index on large query graphs. In addition, the D-index is consistently slower than both the FP-index and the S-index.
Figure 6b illustrates the average query time of each index for query set V 5 E 7 , with the average edge weight varying Figure 6: Index Performance v.s. Parameters of the Query Graphs
Figure 7: Index Performance v.s. Graph Density from 1 to 5. The FP-index performs the best when the av-erage edge weight is no more than 3, which is the maximum edge weight handled in its preprocessing step. When the average edge weight is larger than 3, however, the perfor-mance of the FP-index degrades, and the S-index becomes the most efficient one.
The experiments use synthetic datasets to evaluate the performance of our indices with respect to a parameter that has not been investigated in the previous experiments, i.e., the densities of the data graphs. In particular, the density of a data graph with n vertices and m edges equals m/ n 2 We generate synthetic graphs with densities varying from 0 . 3to0 . 7, and we use them to construct datasets, such that each dataset contains 10K data graphs, each of which has 30 edges and a fixed density. The query graphs for each dataset is constructed in a manner similar to previous experiments, such that each query graph on average has 5 vertices, 7 edges, with an average edge weight 2 . 5.

Figure 7 illustrates the performance of each index as a function of the data graph density. As with our previous experiments, the FP-index achieves the best query perfor-mance, but it incurs the highest space and pre-computation overheads. The D-index requires the smallest space and pre-processing time, but its query time is the largest. The S-index consistently lands on the middle ground between the FP-index and the D-index. Summary. Our experiments show that the FP-index offers superior query performance at the cost of space and pre-computation time. Therefore, it is suitable for the applica-tions where (i) efficient query processing is crucial, and (ii) space and pre-computation overheads are not a major con-cern. In contrast, the D-index entails relatively high query cost, but it incurs minimal space and preprocessing over-head. This renders it preferable in the scenarios with strin-gent requirements on space consumption or pre-computation time. Finally, the S-index X  X  space and pre-computation costs are only slightly higher than that of the D-index, but its query efficiency is almost comparable to that of FP-index. Hence, it offers user a choice to strike a good balance be-tween query processing and space (preprocessing) overheads.
There are some existing studies of graph matching prob-lem by allowing edges to map to paths for graphs [6,7,10,25]. However, their queries are too rigid by fixing the length of all the mapping paths [25], or too relax by allowing node similarity matching [7]. Besides, all these works are tailored to query a single large graph making them unsuitable for querying a large set of small or medium-sized graphs.
On the other hand, various types of graph query process-ing on a large set of small or medium-sized graphs have been studied in the literature in recent years and we restrict our discussion on the closely related ones, namely subgraph query processing [4, 9, 13, 15, 18, 21, 23], supergraph query processing [2, 3, 14, 22], and similarity graph query process-ing [12,19,20,24]. All these works proposed some indexing techniques to filter out as many unmatching data graphs as possible. Although many different types of graph index-ing techniques have been proposed, none of them is simi-lar to our indexes except FG-index [4], which is similar to FP-index. However, the only similarity lies on the use of frequent patterns to avoid verification and the use of infre-quent edges to reduce the candidate set size, while the index structure of FP-index (which builds on B+-trees) is totally different from that of FG-index (which is an unbalanced tree built on the clusters of frequent patterns). Apart from that, both D-index and S-index are entirely different from all ex-isting indexes. In addition, our work is the first to propose indexes for processing generalized subgraph queries.
We studied a new type of graph queries, generalized sub-graph queries. We proposed a succinct and effective cost model to minimize the cost of generalized subgraph isomor-phism. We also developed three indexes that can effectively filter out unmatching data graphs, which significantly re-duces the total query response time. We evaluated our al-gorithms with experiments on both real datasets and syn-thetic datasets. The results show that our matching algo-rithm is efficient in candidate verification as it considerably outperforms the direct extension of existing graph matching algorithms, while our indexes are also effective in filtering. Thus, the results verify that our method is efficient in query processing (in both filtering and candidate verification). Al-though some of the indexes have weaknesses, we show how the weaknesses are addressed by another index; in particu-lar, our results show that S-index achieves both a low index construction cost and a short query response time. Xiaokui Xiao was supported by Nanyang Technological University under SUG Gr ant M58020016 and AcRF Tier 1 Grant RG 35/09, and by the A*STAR SERG Grants 1021580074. James Cheng was supported in part by the A*STAR TSRP Grants 1021580034 and 1121720013.
