
University of Maryland CP, MD, USA empirically, demonstrate its superior performance over EA .
 other existing classifiers. theoretical analysis which specifically demonstrate why EA ++ is better than EA. In this section, we introduce notations and provide a brief o verview of E ASY A DAPT [1]. 2.1 Problem Setup and Notations Let X  X  R d denote the instance space and Y = { X  1 , +1 } denote the label space. Let D distribution and D set of target labeled examples L denoted by U by  X   X  the corresponding expected errors are denoted by  X  and  X  2.2 EasyAdapt (EA) used to learn a linear hypothesis  X  h  X  R 3 d in the augmented space. Let us denote  X  h = h g g , g transformed sample. This is equivalent to applying ( g to be simultaneously training two hypotheses: h domain. The commonality between the domains is represented by g the source and target domain, respectively. 3.1 Motivation not extend to other supervised classifiers. 3.2 EA++: E ASY A DAPT with unlabeled data  X  h s = ( g c + g s ) In EA++, we want the source hypothesis h unlabeled target sample x each other. Formally, it aims to achieve the following condi tion: labeled samples and target unlabeled samples is summarized in Figure 1(a). class  X  1 and their summation. 3.3 Implementation  X  1 classes (shown in Figure 1(b)c). that remains is to bound the Rademacher complexity of the var ious hypothesis classes. 4.1 Define Hypothesis Classes for EA and EA++ using data from both domains, and the three sub-hypotheses ( g h s = ( g c + g s ) underlying supervised classifier in augmented space uses a s quare L SVM). This is equivalent to imposing the regularizer ( || g Differentiating this regularizer w.r.t. g h , empirical target error on h The EA algorithm minimizes this cost function over h uses target unlabeled data, and encourages h as having an additional regularizer of the form P EA++ (denoted as Q hyperparameters  X  EA implicitly sets all these hyperparameters (  X  is defining the hypotheses classes is to substitute trivial hyp otheses h all regularizers and co-regularizers equal to zero and thus bounds the cost functions Q Q
EA ( 0 , 0 )  X  1 hypothesis pair ( h EA and EA++, The source hypothesis class for EA is the set of all h class for EA is the set of all h classes for EA can be defined as: Similarly, the source and target hypothesis classes for EA+ + are defined as: target labeled and target unlabeled data as shown below: 4.2 Relate empirical and expected error (for both source and target) random draws of samples, where f  X  F is the class of functions mapping X 7 X  Y , and  X  R defined as  X  R If we can bound the complexity of hypothesis classes J s the difference of expected and empirical errors ( |  X  on source and target samples. The following sections aim to a chieve this goal. 4.3 Relate source expected error and target expected error bound is in terms of  X  labeling functions, and h  X  distance [14], which is defined as sup other,  X  represent the notion of adaptability in our case.
 any two source and target hypotheses h where H as above.
 Proof. Please see Appendix A in the supplement. 4.4 Relate target expected error with source and target empi rical errors terms of source and target empirical errors. The following t heorem achieves this goal. 1  X   X  we have for any h Proof. We first use Theorem 4.1 to bound (  X  by combining these two bounds and Theorem 4.2.
 and target hypotheses jointly. We also note that the bound in Theorem 4.3 depends on || h that || h provide a tighter bound compared to Theorem 4.1.
 able to use Theorem 4.3, which are provided in the next sectio ns. 4.5 Bound the Complexity of EA and EA++ Hypothesis Classes 4.5.1 E ASY A DAPT (EA) Theorem 4.4. For the hypothesis class J t  X  R fined as in Eq. 4.6.
 Proof. Please see Appendix B in the supplement.
 with change in  X  This result in conjunction with Theorem 4.1 gives a bound on t he target generalization error. Due to the symmetry of paired hypothesis class (Eq. 4.3) in h 4.5.2 E ASY A DAPT ++ (EA++) Theorem 4.5. For the hypothesis class J t  X  Proof. Please see Appendix C in the Supplement.
 The second term in ( C t can also be written as P positive definite matrix Z . Since E error in terms of target empirical error.
 Again, as in case of EA, using the symmetry of paired hypothes is class H where ( C s A of labeled source and target data.
 A tested on the entire amount of available target test data.
 for other tasks and datasets (refer Figure 3 of [2]). version.
