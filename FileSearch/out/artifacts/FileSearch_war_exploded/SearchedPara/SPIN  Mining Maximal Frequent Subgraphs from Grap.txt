 One fundamental challenge for mining recurring subgraphs from semi-structured data sets is the overwhelming abundance of such patterns. In large graph databases, the total number of frequent subgraphs can become too large to allow a full enumeration using reasonable computational resources. In this paper, we propose a new algorithm that mines only maximal frequent subgraphs, i.e. subgraphs that are not a part of any other frequent subgraphs. This may exponentially decrease the size of the output set in the best case; in our experiments on practical data sets, mining maximal frequent subgraphs reduces the total number of mined patterns by two to three orders of magnitude.

Our method first mines all frequent trees from a general graph database and then reconstructs all maximal subgraphs from the mined trees. Using two chemical structure benchmarks and a set of synthetic graph data sets, we demonstrate that, in addition to de-creasing the output size, our algorithm can achieve a five-fold speed up over the current state-of-the-art subgraph mining algorithms. Categories and Subject Descriptors: H.2.8 [Database Applica-tions]: Data Mining General Terms: Algorithms Keywords: Subgraph Mining, Spanning Tree
In this paper, we focus on the problem of finding recurring sub-graphs from graph databases, which is a very active topic in current data mining research. Graphs provide a general way to model a va-riety of relations among data, hence finding recurring subgraphs has many applications in interdisciplinary research such as chem-ical informatics [2] and bioinformatics [11]. There are also many applications in data management research such as efficient storage of semi-structured databases [5], efficient indexing [21], and web information management [16].

One performance issue (among many others) in mining large graph databases is the huge number of recurring patterns. The phe-Copyright 2004 ACM 1-58113-888-1/04/0008 ... $ 5.00. (2) we integrate several optimization techniques, some from exist-ing maximal itemset mining research and some developed by our-selves, to speed up the mining process, (3) we perform an exten-sive analysis of the proposed algorithm and analyze how its perfor-mance on graph data sets with different characteristics.

The remainder of the paper is organized as follows. In Section 2, we present the data structure and the proposed algorithm. Section 3 presents the results of our experimental study using synthetic graph databases and two benchmark chemical data sets. We conclude the paper with a discussion, related works, and conclusion.
In the following discussion, we present a novel framework for mining maximal frequent subgraphs from a graph database. The framework combines tree mining and subgraph mining; we first find all frequent trees from a graph database and then reconstruct the group of frequent subgraphs from the mined trees. There are two important components in the framework. The first is a graph partitioning method through which we group all frequent subgraphs into equivalence classes based on the spanning trees they contain. The second important component is a set of pruning techniques which aim to remove some partitions entirely or partially for the purpose of finding maximal frequent ones only.

There are three reasons we advocate this two-step method for finding maximal graph patterns. First, tree related operations such as isomorphism, normalization, and testing whether a tree is a sub-tree of another tree are asymptotically simpler than the comparable operations for graphs, which are NP-complete. Second, in certain applications, such as chemical compound analysis, most of the fre-quent subgraphs are really trees. Last but not least, this frame-work adapts well to maximal frequent subgraph mining, which is the focus of this paper. Using a chemical structure benchmark, we show 99% of cyclic graph patterns and 60% of tree patterns can be eliminated by our optimization technique in searching for maximal subgraphs; further details about the efficiency of the optimization techniques can be found in [10]. To the best of our knowledge, we are the first to combine the two distinct methodologies: mining frequent subgraphs in graph databases and mining frequent trees in forests (a set of trees) for the purpose of designing efficient sub-graph mining algorithm.
We define a subtree of an undirected graph G as an acyclic con-nected subgraph of G . A subtree T is a spanning tree of G if T contains all nodes in G . Given a graph G , there are many spanning trees and we define the maximal one, according to a total order de-fined on trees [4, 10], and call it the canonical spanning tree of G .

E XAMPLE 2.1. In Figure 1, we show an example of a labeled graph P (upper-left) with all four-node subtrees of P . Each subtree is represented by its canonical representation and sorted according to the total order (as given in [10]). Each such tree is a spanning tree of the graph P and the first one ( T 1 ) is the canonical spanning tree of P .

D EFINITION 2.1. Tree-based Equivalence Classes: Given two graphs P and Q , we defined a binary relation  X  = such that P  X  = Q if and only if their canonical spanning trees are isomorphic to each other. The relation  X  = is reflexive, symmetric, transitive, and hence an equivalence relation. Figure 3: Example of enumerating graph X  X  search space. We use for the same purpose. Therefore, in the following discussion, we focus on step 2, which is how to enumerate the equivalence class of a tree T and how maximal subgraph mining is related to this enumeration. We want to point out that the two-step division of the mining algorithm is artificial but it makes it easy to explain the key ideas of the algorithm without introducing too many details. In our longer version of this paper [10], we discuss a fully optimized algorithm which (1) uses a modified FFSM algorithm to enumer-ate trees from graph databases and (2) integrates tree discovery and maximal pattern mining for maximal performance.
We first outline a basic enumeration scheme to search the equiv-alence class of a tree. We define a joining operation  X  between a graph(tree) G and a hypothetical edge connecting any two nodes i, j in G with label e l such that G  X  ( i, j, e l )= G where G is a supergraph of G with one additional edge between nodes i and j with label e l . If the graph G already contains an edge between nodes i and j , the joining operation fails and produces nothing. If G is frequent, we denote the hypothetical edge ( i, j, e l ) as a can-didate edge for G . The above definition can serve as the basis for a recursive definition of the joining operation between a graph G and a candidate edge set E = { e 1 ,e 2 ,...,e n } such that G  X  E = ( G  X  e 1 )  X  X  e 2 ,...,e n } .
 Let X  X  assume we already calculated the set of candidate edges C = { c 1 ,c 2 ,...,c n } from the set of all possible frequent hypo-thetical edges. We define the search space of G , denoted by G : C , as the set of graphs which might be produced by joining the graph G and a candidate edge set in the powerset set of C (denoted by In the following discussion, the group of candidate edges are some-times referred to as the  X  X ail X  of the graph G in its search space. We present a recursive algorithm in Table 2 to enumerate the search space for a graph G . The procedure we use to calculate the set of candidate edges for a tree pattern can be found in [10].

E XAMPLE 2.3. in Figure 3, we single out the largest equiva-lence class (Class One) from Figure 2. We show a tree K together with its tail C = { ( k 2 ,k 3 ,y ) , ( k 3 ,k 4 ,x ) } . K  X  X  search space is hence composed of four graphs { K, K S 1 ,K S 2 ,K S 3 } ( K is al-ways included in its search space) and is organized into a  X  X earch tree X  in analogy to frequent item set mining. This tree structure follows the recursive procedure we present in Table 2.

The search space of a graph G is exponential in the cardinality of the candidate edges set C . One heuristic to avoid such an exponen-tial search space is to check whether the largest possible candidate G = G  X  C is frequent or not. If G is frequent, each graph in the search space is a subgraph of G and hence not maximal. This heuristics is referred to as the Bottom-Up Pruning and can be ap-plied to every step in the recursive search procedure presented in Table 2. By applying bottom-up pruning to the equivalence class I presented in Figure 2, graph K S 1 and K S 3 are pruned.
 Dynamic Reordering : An important technique related to the effi-ciency of the bottom-up pruning is the so-called dynamic reorder-ing technique, which works in two ways. First, it trims infrequent candidate edges from the tail of a graph to reduce the size of the search space (an edge candidate can become infrequent after sev-eral iterations since other edges are incorporated into the patterns). Second, it rearranges the order of the elements in the tail accord-ing to their support value. For example, given a graph X  X  tail C , by dynamic reordering, we sort the elements in C by their support values, from lowest to highest. After this sorting, the infrequent  X  X eads X  are trimmed. At the end of the remaining tail is a family of elements individually having high support and hence the pat-tern obtained by grouping them together is likely to still have high support value. This heuristics is widely used in mining maximal itemsets to gain performance. However, without the spanning tree framework, applying dynamic ordering is very difficult in any of the current subgraph mining algorithms, which intrinsically have a fixed order of adding edges to an existing pattern for various per-formance considerations.
Given a graph G and a supergraph G of G ,an embedding of G in G is a subgraph isomorphism f from G to G . We prefer the term embedding to subgraph isomorphism, though they are inter-changeable, for the purpose of intuitive descriptions. In Figure 4, we show a subgraph L and its supergraph P . There are two em-beddings of L in P : ( l 1  X  p 1 ,l 2  X  p 2 ,l 3  X  p 3 ,l 4  X  p 4 ) and ( l 1  X  p 1 ,l 2  X  p 3 ,l 3  X  p 2 ,l 4  X  p 4 ) . We define a candidate edge ( i, j, e l ) to be associative to a graph G if it appears in every embedding of G in a graph database. In other words, a candidate edge ( i, j, e l ) of G is associative if and only if for every embed-ding f of G in a graph G , G has the edge ( f ( i ) ,f ( j )) with label e . One example of associative edge is edge ( l 1 ,l 3 ,y ) to the tree L shown in Figure 4.

If a tree T contains a set of associative edges { e 1 ,e 2 ,...,e n } , any maximal frequent graph G which is a supergraph of T must contain all such edges. Hence we can remove these edges from the tail of T and augment them to T without missing any maximal ones. This technique is referred to as the tail shrink technique. Tail shrink has two advantages: (1) it reduces the search space and (2) it can be used to prune the entire equivalence class in certain cases. To elaborate the latter point, we define a set of associative edges C of a tree T to be lethal if the resulting graph G = T  X  C has a canonical spanning tree other than that of T . For example, in Figure 4, associative edge e =(1 , 3 ,y ) of L is lethal since G = L  X  e has a different canonical spanning tree than that of L . In the same example, the lethal edge e can be augmented to each member of the class II to produce a supergraph with the same support. Therefore the whole class can be pruned away once we detect a lethal edge(s) to the tree L . Detecting a group of lethal edges can do further pruning other than trimming off the whole equivalence class. Those details as well as the formal proof of the optimization are discussed in [10].
 and excluding the null graph. These subgraphs are partitioned into five non-singleton classes, shown in Figure 2, and twelve singleton classes (not shown). There is only one maximal subgraph, namely, graph P itself. We have successfully pruned every one of the five non-singleton equivalence classes ( P of the equivalence class I is left untouched since it is maximal). What we do not show further is that we can apply the same techniques to the remaining twelve singleton equivalence classes to eliminate all of them. Interested readers might verify that themselves.

Table 3 and Table 4 integrate these optimizations into the basic enumerate technique we presented in Table 1 and Table 2.
 Table 3: An algorithm for exploring the equivalence class of a tree T Table 4: An outline of the maximal subgraph mining algorithm
Due to the space limitation, several important details are omitted which include: (1) how to enumerate frequent trees from a graph database using a modified FFSM algorithm, (2) how to interleave the tree mining algorithm and the maximal subgraph mining algo-rithm and deliver the final optimized algorithm, (3) how we guaran-tee that each reported pattern is (a) frequent, (b) maximal, and (c) unique, (4) how to calculate the edge candidates for a tree, and (5) how to determine associative external edges. Those can be found in [10].
We performed our empirical study using a single processor of a 2.8GHz Pentium Xeon with 512KB L2 cache and 2GB main memory, running RedHat Linux 7.3. The SPIN algorithm is imple-mented using the C++ programming language and compiled using g++ with O3 optimization. We compared SPIN with two alter-native subgraph mining algorithms: FFSM ([9]) and gSpan [19]. Every maximal subgraph reported by SPIN in synthetical and real data sets are cross validated using results from FFSM and gSpan to make sure it is (a) frequent, (b) maximal, and (c) unique.
Knowledge discovery from semi-structured data sets is an ac-tive topic in the data mining/machine learning community. Many different pattern de fi nitions were proposed from different perspec-tives such as fi nding patterns from a single large network [14], fi nd-ing approximately matched patterns [17], mining patterns using do-main knowledge from bioinformatics [8], and fi nding frequent sub-graphs. The later one is the focus of our paper.

Recent subgraph mining algorithms can be roughly classi fi ed into two categories. Algorithms in the fi rst category use a level-wise search scheme based on the Apriori property to enumerate the recurrent subgraphs [12, 13]. Rather than growing a graph by one single node/edge at a time, Vanetik et al. recently proposed an Apriori-based algorithm using paths as building blocks with a novel support de fi nition [18].

Algorithms in the second category use a depth-fi rst search to enu-merate candidate frequent subgraphs [19, 20, 2, 9]. As demon-strated in these papers, depth fi rst algorithms provide advantages over level-wise search for (1) better memory utilization and (2) ef-fi cient subgraph testing, e.g. it usually permits the subgraph test to be performed incrementally at successive levels during the search [9].

Our current work bene fi ts extensively from existing algorithms for maximal itemset mining such as [3, 6] and frequent subtree mining algorithms [1, 22].
In this paper we present SPIN, an algorithm to mine maximal fre-quent subgraphs from a graph database. A new framework, which partitions frequent subgraphs into equivalence classes is proposed together with a group of optimization techniques. Compared to cur-rent state-of-the-art subgraph mining algorithms such as FFSM and gSpan, SPIN offers very good scalability to large graph databases and at least an order of magnitude performance improvement in synthetic graph data sets. The ef fi ciency of the algorithm is also con fi rmed by a benchmark chemical data set. The algorithm of compressing large number of frequent subgraphs to a much smaller set of maximal subgraphs will help us to investigate demanding ap-plications such as fi nding structure patterns from proteins in the future.
 Acknowledgement We thank Dr. Jack Snoeyink at the University of North Carolina for helpful discussions about the paper.
