 1. Introduction Forty-eight years ago Maron and Kuhns published  X  X  X n Relevance, Probabilistic Indexing and Information
Retrieval  X  (1960). This was the first paper to present a probabilistic approach to information retrieval, and perhaps the first paper on ranked retrieval. Although it is one of the most widely cited papers in the field of information retrieval, many researchers today may not be familiar with the influence that it has had. This paper describes the Maron and Kuhns article and the influence that it has had on the field of information retrieval, and also suggests that there is more to be learned from that paper today.

After World War II, when general purpose computers were first developed to calculate ballistic trajectories, to aid in the design of nuclear weapons, and to decipher coded enemy messages, among the first uses that were considered for the new computers was document retrieval ( Bagley, 1951 ). In 1945 Vannevar Bush had pub-lished his seminal, conceptual article on the Memex, a machine that would provide a scientist with personal-ized navigation of scientific literature ( Bush, 1945 ). Maron and Kuhns referred to this problem of finding scientific papers as the library problem. Mooers had coined the term  X  X  X nformation retrieval  X  ( 1950 ), but the problem was perhaps most often thought of as access to scientific information. In 1946 the Royal Society of the United Kingdom had held the British Empire Scientific Conference ( Brown, 1959 ). At this conference planning began for another Royal Society conference, the International Conference on Scientific Information in 1948, which was the first international conference on this topic. Various new retrieval systems were devel-oped during the 1950s and early 1960s, often based on notched card technology ( Mooers, 1950; Taube &amp;
Wooster, 1958 ), and new manual indexing schemes were studied ( Cleverdon, 1962 ). Then in 1958  X  the same year that Maron and Kuhns, along with Ray, published the first of two technical reports ( 1958, 1959 ), which ultimately led to Maron and Kuhns 1960 paper  X  the International Conference on Scientific Information was held in Washington, DC ( National Academy of Sciences, 1959 ). Planning for the conference had begun in 1956, but even more importance was attached to the conference with the 1957 launch of Sputnik and the per-ception that the Soviet Union X  X  handling of scientific information was more advanced than elsewhere. It was claimed that about 1000 people attended the conference, while another 1000 who wanted to attend were turned away.

It was natural to think of the automated solution to accessing scientific information, or the library problem, in terms of what had gone before, that is the practice of librarianship. In 1960 librarians cataloging a docu-ment provided metadata by which a document was represented in a card catalog. Each document had a unique identifier, or accession number, but this number was not used to provide intellectual access to the document.
Rather several other entry points were provided: (1) a main entry, generally the author X  X  name; (2) a title entry; (3) one or more subject headings. Physical cards were made for each of these entries and the cards were stored in the card catalog in alphabetical order. When asked his views on automated solutions to the library problem during this time, Norbert Wiener, the noted mathematician and cybernetician, said that he had no need for a solution to the problem as he personally knew of all work being done in any field of interest to him. Of course, all researchers were not similarly well situated with respect to their fields, and now the problem has only been worsened given the increasing rates of publications available not only in libraries, but on the Web, and in organizational repositories.

Maron and Kuhns proposed a radically new approach to the information retrieval problem. They sug-gested that two-valued indexing of documents be replaced by weighted indexing, where the weights were to be interpreted as probabilities. They viewed the retrieval problem as a problem involving clues and inference  X  that an information retrieval system should predict, given a user X  X  query, which documents in the collection would most probably be relevant to that user and then rank those documents in descending order by those computed values of probability of relevance. Thus the output response to a library query was not a set of doc-uments whose indexes  X  X  X atched  X  the query term(s), but rather a ranking of documents by their computed values of probability of relevance. Maron and Kuhns called their approach  X  X  X robabilistic Indexing  X  and it was, in fact, a theoretical attack which replaced traditional two-valued indexing and matching with a statis-tical approach involving use of library statistics and user queries as clues to make predictions about the rel-evance of documents in the collection. It should be noted that  X  X  X elevance  X  has been interpreted in many ways in the field of information retrieval ( Saracevic, 1975 ). As Maron commented later ( 1984 ), his view of relevance is equated with a user X  X  wanting a document. Cooper and Maron also developed a utility-theoretic interpre-tation of relevance in terms of subjective utility ( 1978 ).

Probabilistic concepts and statistical techniques for information retrieval had been considered by others before Maron and Kuhns, but not for the purpose of ranking documents. Fairthorne (1961) describes Mooers X  (1950) definition of information retrieval in these terms.  X  X  X he term [information retrieval] ... denotes the recovery from a given collection of documents, and with stated probability, of a set of documents that includes, possibly together with some irrelevant ones, all documents of specified content; or, a set of docu-ments that includes nothing but documents of specified contents, but possibly not all of them  X  . Thus the prob-ability that was considered was that of having, on the one hand, perfect recall, or on the other hand, perfect precision. Ranking was not considered. An excellent discussion of the origins of probabilistic information retrieval is given by van Rijsbergen (2005) . 2. What the Maron and Kuhns paper showed
In addition to being the first paper on probabilistic information retrieval, the Maron and Kuhns paper was the first to introduce the notions of query expansion and expansion of the set of relevant, retrieved documents.
Section 2.1 shows how probability of relevance was calculated. Section 2.2 describes how the set of relevant retrieved documents was expanded. Section 2.3 describes the general search strategy proposed by Maron and
Kuhns. Section 2.4 discusses the contribution of the experimental results. 2.1. Deriving the relevance number
Maron and Kuhns first considered the probability that if a user requests information on subject or topic I then that user will be satisfied with Document D i , i.e., judge D used different notation, this can be represented as P ( D to the user X  X  information need. By Bayes X  theorem P ( D i probability of relevance can be determined by library statistics. In other words if n is the number of times that any document is judged relevant and m is the number of times that that document being judged is D
P ( D i )= m / n . Thought of most simply, interpreting P ( D with no new documents entering or leaving, but P ( D i ) could be estimated in more dynamic settings. P ( I the probability that if D i is retrieved and found relevant by a searcher that I term. An estimate of this probability is to be provided by the probabilistic indexer. Maron and Kuhns also showed how probabilities of relevance associated with Boolean combinations of terms could be derived. 2.2. Expanding the set of relevant, retrieved documents
Next Maron and Kuhns considered ways to automatically produce the best set of documents to return for a given request. Given a request R and class C of retrieved documents whose indexing matches the Boolean logic of the request, how can one either: (a) automatically generalize the request R to R
C , which is larger than C , or (b) leave R as it is, but automatically generalize C to C automatic generalization, Maron and Kuhns introduce the concept of an Index Space, where each point rep-resents an index term and an n -dimensional Document Space wherein individual documents are represented as n -dimensional vectors. They discuss semantic and statistical similarity of terms, where statistical similarity would relate to the tendency of two terms to index the same documents. They then define three measures of similarity of terms in Index Space. First, the probability that if a term I another term I k will also be assigned to the documents, that is P ( I be expanded by adding the term I k for which P ( I k | I j term I j picks the I k , which provides the highest value for P ( I ficient of association based on how far P ( I j I k ) diverges from P ( I two values would be equal. These three measures can be used to automatically modify R , the request, by add-ing similar terms. Maron and Kuhns also show how similarities (or dissimilarities) between documents can be determined based on these measures, so that the set C of documents returned by a request can be automati-cally expanded. Looking at such similarities among index terms or documents was novel in 1960. Since then many researchers have experimented with a wide variety of similarity measures among index terms and documents. 2.3. A search strategy
Having defined relevance numbers and measures of similarity, or dissimilarity, in Index Space and Docu-ment Space, Maron and Kuhns show how all of these ideas can be used in a search strategy. The components of the search strategy include: Input, including the request, possibly weighted.

A probabilistic matrix, including dissimilarities among documents, significance measures for index terms (based on inverse document frequency, anticipating idf weighting), and measures of closeness between index terms.
 The a priori probability of relevance for each index term.

Output, i.e., the method of selecting documents, based on Boolean matching and ranking by probability of relevance.

Control numbers, e.g., parameters such as the total number of relevant documents desired or relevance thresholds.

Operations, including the basic selection process and elaborations of the retrieved set based on measures of index term or document closeness. 2.4. Experimental results from the Maron and Kuhns paper
Readers interested in details of the results of Maron and Kuhns X  experiments should refer to the 1960 paper. The specific results are not so much important intrinsically, as they are important because they pro-vided an empirical validation of the first probabilistic theory of information retrieval. Moreover, Maron and Kuhn X  X  empirical approach was one of the early empirical studies published in the scientific literature.
The paper showed that experiments could be conducted to test and evaluate alternative theories and tech-niques. Other larger scale empirical evaluations were already underway even at the time of Maron and Kuhn X  X  earlier technical reports. Cleverdon (1959) in his Area 4 paper at the International Conference on Scientific Information mentioned above gives a good characterization of the state-of-affairs in 1958.

Maron and Kuhns not only devised a new indexing system, but they also evaluated it both theoretically and empirically. The project to which Cleverdon referred was the Cranfield project, which has become the model for large scale experimental evaluation of retrieval systems. Other empirical work was already underway, e.g.,
Luhn (1961) , or about to begin, e.g., Salton and Lesk (1968) , but much of this work was either proprietary or only available in technical reports. I.J. Good had also briefly discussed probabilistic information retrieval in an IBM technical report published shortly after the 1958 conference on scientific information ( 1958 ). He men-tions having heard of Maron X  X  ongoing work at Ramo Woolridge at the 1958 conference.

Although Maron and Kuhns did not use the term relevance feedback, the notion of relevance feedback was implicit in their discussion of techniques for expanding the set of relevant retrieved documents. It was not until the work of Rocchio (1966) that relevance feedback was treated explicitly. 3. Information Retrieval since the Maron and Kuhns paper
Over the next several years another approach came to dominate academic research in information retrieval in the United States. This was the vector space model developed by Salton and his students from around 1960 uments in a collection, and queries against the collection as n -dimensional vectors, where each component rep-resented one, generally normalized, word in the collection. (Again, the notion of representing documents as weighted (as opposed to binary) vectors was used in the 1960 Maron and Kuhns paper .)
During the 1970s Cooper and Maron published a paper on utility-theoretic retrieval ( 1978 ), and Cooper published a paper on Gedanken experimentation indexing ( 1978 ). The Cooper and Maron paper on utility-theoretic indexing proposed that indexers not assign terms interpreted as probabilities in the Maron and
Kuhns sense, but rather that they estimate the utility which a searcher using that term as a search term would derive from retrieving the document. In the Gedanken indexing paper Cooper reflected on how an indexer might make such utility estimates. During this time Cooper was also the first to formally state the probability ranking principle, though the use of the principle goes back to the Maron and Kuhns paper (1977). Meanwhile in England a new approach to probabilistic information retrieval was being developed ( Miller, 1971 ). This has been considered the initial paper on what was later called the Model 2 approach to probabilistic information retrieval (van Rijsbergen, personal communication). Model 1, then, was the approach to probabilistic infor-mation retrieval begun by Maron and Kuhns ( Robertson, Maron, &amp; Cooper, 1982 ). It was Miller X  X  work, and that of Barkla (1969), which influenced work on Model 2, rather than the work of Maron and Kuhns ( van
Rijsbergen, 2005 ). In the early 1970s, the concept of term frequency inverse document frequency weighting tf idf was developed by Sparck Jones (1972) , in the context of probabilistic retrieval and by Salton and Yang (1973) , in the context of the vector space model. This was shortly followed by a paper by Robertson and Sparck Jones, which was the first to formally define Model 2 ( 1976 ).

The direct influence of the Maron and Kuhns paper continued in two ways during the 1970s, 1980s, and beyond. First, there were developments of Model 1 itself. Second, Model 1 and Model 2 were combined to form a unified model, Model 3 (Robertson et al.). While, after some initial work ( Maron, 1984; Maron, Curry, &amp; Thompson, 1986; Robertson, Maron, &amp; Cooper, 1983; Thompson, 1990a, 1990b ) Model 3 was not devel-oped further in the 1980s, the indirect influence of Model 1, through Model 3, has continued in some more recent re-examinations of the unified model ( Bodoff, 1999; Bodoff &amp; Robertson, 2004; Robertson, 2003 ).
As was mentioned above, Cooper and Maron formalized Model 1 and generalized the theory to include a util-ity-theoretic interpretation ( 1978 ). Maron and Cooper considered relevance to be a binary relation between a user with an information need and a document. They did not consider relevance to have degrees. On the other hand, they acknowledged that some documents might be more useful than others. This led to their theory of utility-theoretic indexing, where the task of the indexer would be to predict the utility of the document to a user with a given query, rather than the probability of the document X  X  being relevant. Fuhr (1986, 1989) also made further developments with Model 1. According to Fuhr, Model 1 had not been implemented over the years because of the problems in estimating its probabilistic parameters. Fuhr showed how these problems in estimation could be overcome by deriving the parameters from manual indexing.

In the world of commercial document retrieval full text document retrieval products were being developed to complement the existing bibliographic retrieval systems. Now systems could retrieve not only based on indexer assigned metadata, but on any word appearing in the document. Many saw this as the ultimate solu-tion of the library, or document retrieval, problem. In a paper, even more widely cited than the 1960 Maron and Kuhns paper , reporting a large scale study of full text retrieval using the IBM STAIRS system for litiga-tion support, Blair and Maron showed that full text retrieval did not live up to these expectations ( 1985 ).
Attorneys and paralegals using the full text system, who believed that they were retrieving at least 75% of all relevant documents using the system, were shown to be retrieving at best only 20%. The legal information retrieval companies, Lexis X  X exis and West Publishing, initially tried to dispute these findings ( Dabney, 1986 ), but a few years later, in the early 1990s, each of these companies provided its users with a ranked retrieval mode, implicitly acknowledging the possibility of improvement upon retrieval based on human subject index-ing. West X  X  ranked retrieval mode was provided by an implementation of the Inquery system ( Turtle &amp; Croft, 1991 ) from the University of Massachusetts, Amherst, suitably tailored for the legal domain, while that of
Lexis X  X exis was based on the vector space model. Thus, ranked document retrieval seemed to have entered the mainstream of commercial retrieval systems in 1992, when West, soon to be followed by Lexis X  X exis and
Dialog, offered its users a ranked retrieval search mode. At about the same time the Tipster program and its more widely accessible TREC program showed strong U.S. government research support for ranked retrieval. Then, an unexpected new factor entered the picture.

The 1990s brought the World Wide Web and Web search engines. Early Web search engines, especially as the Web grew to contain large numbers of documents, tended to provide unsatisfactory performance. Even-tually graph structure algorithms were developed such as Kleinberg X  X  HITS (1998) and Brin and Page X  X  Page-
Rank (1998) . PageRank, when implemented commercially in the Google search engine along with other algorithms, such as those based on the use of anchor text, i.e., the textual context of the hyperlink in the citing document, provided noticeably better Web retrieval performance. Basically these algorithms calculate the rank of a page based on the patterns of links among Web pages. Since these links are generally made by the human creators of Web pages, these algorithms incorporate human judgment of relevance of one Web page to another. However, since these judgments are not in the context of any particular search, graph linking structures can at best be seen as providing a Bayesian prior for relevance. On the other hand, because anchor text is considered to be part of the representation of the document to which the link is made, the human rel-evance judgment implicit in the link can be associated with particular queries.

While some academic research has been influenced by developments with Web search algorithms, other researchers continued to develop more general new probabilistic algorithms, in particular those based on prietary online retrieval services such as Westlaw, Lexis X  X exis, and Dialog, which in the early 1990s had given their users the choice of Boolean or ranked retrieval, found that the vast majority of their users preferred to stay with Boolean retrieval. The option of ranked retrieval is still offered searchers using Westlaw, Lexis X  Nexis, or Dialog, but there has been little motivation for proprietary search services, such as Westlaw,
Lexis X  X exis, and Dialog to conduct further research on ranking algorithms. On the other hand, there are many other commercial search sectors other than Web search, e.g., enterprise search, where new ranked retrieval algorithms are still being pursued. 4. Discussion
One might draw the conclusion from the success of ranked retrieval algorithms on the Web, and the rejec-tion of ranked retrieval by users of the proprietary online systems mentioned above, that fully automated pro-cessing is most appropriate for the large, diverse content of the Web, while for premium content requiring manual classification and indexing, such as in legal, patent, or biomedical domains, that binary indexing and Boolean querying, practiced substantially today as in the 1960s, are still the preferred techniques. And yet, if these human indexers were to assign terms with weights, whether interpreted as probabilities, as sug-gested by Maron and Kuhns in 1960 , or as utilities, as later suggested by Cooper and Maron (1978) , improved results might be possible, as indicated by Maron and Kuhns X  experiments reported in 1960 . In this light, it is of interest to consider this statement from Hodge and Milstead X  X  Computer Support to Indexing ( 1998 ). Maron (1977) discussed aboutness in this context as one factor contributing to relevance. In Robertson,
Maron, and Cooper X  X  unified model of probabilistic retrieval it was shown how an indexer could on the one hand assign binary index terms to a document from one thesaurus of document features, while at the same time making probabilistic estimates for terms taken from a second thesaurus of searcher features (1982). While the future uses made of a document might be difficult to predict, a well-trained indexer might be expected to make a reasonable estimate for the immediate future ( Thompson, 1988 ). Relevance judgments provided by searchers who retrieved the document could update these initial probabilities ( Thompson, 1990a, 1990b ).
It has long been recognized that multiple sources of evidence can be combined to provide improved retrie-val. This is inherent in the probability ranking principle ( Robertson, 1977 ) and has been shown in empirical ( Saracevic &amp; Kantor, 1988a, 1988b; Saracevic, Kantor, Chamis, &amp; Trivison, 1988 ) and theoretical studies ( Croft, 2000, chapter 1 ). In the graph structure of the Web contemporary Web search engines have found one effective source of evidence. Probabilistic term assignment by human indexers, i.e., the assignment of weighted index terms, is another source of evidence, identified 48 years ago, but still completely unexploited.
The approach to document retrieval pioneered by Maron and Kuhns can be applied more broadly. Doc-ument retrieval is one example of an inductive search problem. Maron and his colleagues later developed a system called HelpNet, which applied the probabilistic document retrieval theory which began with the Maron and Kuhns paper to the problem of finding people as sources of information, what is now called the problem of expert finding ( Maron et al., 1986 ). More generally, the same probabilistic searching technology can be used to find a wide variety of objects, e.g., jobs, homes, or products of any kind. 5. Conclusion
Probabilistic retrieval, or more generally ranked retrieval, had its origins in the 1960 Maron and Kuhns paper . This paper provided the initial theory and empirical research for ranked retrieval. The specific approach which Maron and Kuhns advocated, based on probabilistic human indexing has not been followed, but ranked retrieval has had widespread application in academic research and in commercial systems. In the 48 years since the paper was published the field has grown enormously in at least three dimensions: depth of theory; new ramifications, techniques, and directions; and new and powerful applications.

Finally, despite the many changes in ranking algorithms, hardware, and network infrastructure that have come about since 1960, the library problem is still far from being fully solved. The suggestion of the Maron and Kuhns paper that human indexers might assign term as probabilities, rather than binarily, has not been seriously explored in the intervening years. Although there are many search environments where the expense of human indexing cannot be supported, there are others where adopting this suggestion might yet lead to improved retrieval.
 Acknowledgements
The author thanks M.E. Maron, I.J. Good, and R. Solomonoff for their comments on the state of infor-mation retrieval research around 1960. The author also thanks the two anonymous reviewers whose comments helped improve the paper.
 References
