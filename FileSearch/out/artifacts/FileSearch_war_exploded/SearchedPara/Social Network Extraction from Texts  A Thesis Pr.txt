 Language is the primary tool that people use for es-tablishing, maintaining and expressing social rela-tions. This makes language the real carrier of social networks. The overall goal of my thesis is to build a system that automatically extracts a social network from raw texts such as literary texts, emails, blog comments and news articles. I take a  X  X ocial net-work X  to be a network consisting of individual hu-man beings and groups of human beings who are connected to each other through various relation-ships by the virtue of participating in social events . I define social events to be events that occur be-tween people where at least one person is aware of the other and of the event taking place. For ex-ample, in the sentence John talks to Mary , entities John and Mary are aware of each other and of the talking event. In the sentence John thinks Mary is great , only John is aware of Mary and the event is the thinking event. My thesis will introduce a novel way of constructing networks by analyzing text to capture such interactions or events.

Motivation : Typically researchers construct a so-cial network from various forms of electronic in-teraction records like self-declared friendship links, sender-receiver email links and phone logs etc. They ignore a vastly rich network present in the content of such sources. Secondly, many rich sources of social networks remain untouched simply because there is no meta-data associated with them (literary texts, new stories, historical texts). By providing a methodology for analyzing language to extract in-teraction links between people, my work will over-come both these limitations. Moreover, by empiri-cally analyzing large corpora of text from different genres, my work will aid in formulating a compre-hensive linguistic theory about the types of linguistic constructs people often use to interact and express their social interactions with others. In the follow-ing paragraphs I will explicate these impacts.
Impact on current SNA applications : Some of the current social network analysis (SNA) ap-plications that utilize interaction meta-data to con-struct the underlying social network are discussed by Domingos and Richardson (2003), Kempe et al. (2003), He et al. (2006), Rowe et al. (2007), Lin-damood et al. (2009), Zheleva and Getoor (2009). But meta-data captures only part of all the interac-tions in which people participate. There is a vastly rich network present in text such as the content of emails, comment threads on online social networks, transcribed phone calls. My work will enrich the social network that SNA community currently uses by complementing it with the finer interaction link-ages present in text. For example, Rowe et al. (2007) use the sender-receiver email links to connect peo-ple in the Enron email corpus. Using this network, they predict the organizational hierarchy of the En-ron Corporation. Their social network analysis for calculating centrality measure of people does not take into account interactions that people talk about in the content of emails. Such linkages are relevant to the task for two reasons. First, people talk about their interactions with other people in the content of emails. By ignoring these interaction linkages, the underlying communication network used by Rowe et al. (2007) to calculate various features is incom-plete. Second, sender-receiver email links only rep-resent  X  X ho talks to whom X . They do not represent  X  X ho talks about whom to whom. X  This later infor-mation seems to be crucial to the task presumably because people at the lower organizational hierarchy are more likely to talk about people higher in the hi-erarchy. My work will enable extraction of these missing linkages and hence offers the potential to improve the performance of currently used SNA al-gorithms. By capturing alternate forms of commu-nications, my system will also overcome a known limitation of the Enron email corpus that a signifi-cant number of emails were lost at the time of data creation (Carenini et al., 2005).

Impact on study of literary and journalistic texts : Sources of social networks that are primar-ily textual in nature such as literary texts, historical texts, or news articles are currently under-utilized for social network analysis. In fact, to the best of my knowledge, there is no formal comprehensive categorization of social interactions. An early effort to illustrate the importance of such linkages is by Moretti (2005). In his book, Graphs, Maps, Trees: Abstract Models for a Literary History , Moretti presents interesting insights into a novel by looking at its interaction graph. He notes that his models are incomplete because they neither have a notion of weight (number of times two characters interact) nor a notion of direction (mutual or one-directional). There has been recent work that partially addresses these concerns (Elson et al., 2010; Celikyilmaz et al., 2010). They only extract mutual interactions that are signaled by quoted speech. My thesis will go beyond quoted speech and will extract interac-tions signaled by any linguistic means, in particular verbs of social interaction. Moreover, my research will not only enable extraction of mutual linkages ( X  X ho talks to whom X  ) but also of one-directional linkages ( X  X ho talks about whom X ). This will give rise to new applications such as characterization of literary texts based on the type of social network that underlies the narrative. Moreover, analyses of large amounts of related text such as decades of news ar-ticles or historical texts will become possible. By looking at the overall social structure the analyst or scientist will get a summary of the key players and their interactions with each other and the rest of net-work.

Impact on Linguistics : To the best of my knowl-edge, there is no cognitive or linguistic theory that explains how people use language to express social interactions. A system that detects lexical items and syntactic constructions that realize interactions and then classifies them into one of the categories, I de-fine in Section 2, has the potential to provide lin-guists with empirical data to formulate such a the-ory. For example, the notion of social interactions could be added to the FrameNet resource (Baker and Fillmore, 1998) which is based on frame semantics. FrameNet records possible semantic frames for lexi-cal items. Frames describe lexical meaning by speci-fying a set of frame elements, which are participants in a typical event or state of affairs expressed by the frame. It provides lexicographic example annota-tions that illustrate how frames and frame elements can be realized by syntactic constructions. My cate-gorization of social events can be incorporated into FrameNet by adding new frames for social events to the frame hierarchy. The data I collect using the system can provide example sentenctes for these frames. Linguists can use this data to make gen-eralizations about linguistic constructions that real-ize social interactions frames. For example, a pos-sible generalization could be that transitive verbs in which both subject and object are people, frequently express a social event. In addition, it would be in-teresting to see what kind social interactions occur in different text genres and if they are realized dif-ferently. For example, in a news corpus we hardly found expressions of non-verbal mutual interactions (like eye-contact) while these are frequent in fiction texts like Alice in Wonderland . So far, I have defined a comprehensive set of social events and have acquired reliable annotations on a well-known news corpus. I have built a preliminary system that extracts social events from news articles. I will now expand on each of these in the following paragraphs.

Meaning of social events : A text can describe a social network in two ways: explicitly, by stat-ing the type of relationship between two individuals (e.g. Mary is John X  X  wife ), or implicitly, by describ-ing an event which initiates or perpetuates a social relationship (e.g. John talked to Mary ). I call the later types of events  X  X ocial events X  (Agarwal et al., 2010). I defined two broad types of social events: interaction , in which both parties are aware of each other and of the social event, e.g., a conversation, and observation , in which only one party is aware of the other and of the interaction, e.g., thinking of or talking about someone. For example, sentence 1, contains two distinct social events: interaction: Toujan was informed by the committee , and observa-tion: Toujan is talking about the committee . I have also defined sub-categories for each of these broad categories based on physical proximity, verbal and non-verbal interactions. For details and examples of these sub-categories please refer to Agarwal et al. (2010) (1) [Toujan Faisal], 54, { said } [she] was
As a pilot test to see if creating a social network based on social events can give insight into the so-cial structures of a story, I manually annotated a short version of Alice in Wonderland . On the man-ually extracted network, I ran social network anal-ysis algorithms to answer questions like: who are the most influential characters in the story, which characters have the same social roles and positions. The most influential characters in the story were de-tected correctly. Another finding was that characters appearing in the same scene like Dodo , Lory , Ea-glet , Mouse and Duck were assigned the same social roles and positions. This pointed out the possibility of using my method to identify separate scenes or sub-plots in a narrative, which is crucial for a better understanding of the text under investigation.
Motivated by this pilot test I decided to anno-tate social events on the Automatic Content Extrac-tion (ACE) dataset (Doddington et al., 2004), a well known news corpus. My annotations extend previ-ous annotations for entities, relations and events that are present in the 2005 version of the corpus. My an-notations revealed that about 80% of the times, en-tities mentioned together in the same sentence were not linked with any social event. Therefore, a sim-ple heuristic of connecting entities that are present in the same sentence with a link will not reveal a meaningful network. Hence I saw a need for a more sophisticated analysis.

Extraction of social events : To perform such an analysis, I built models for two tasks: social event detection and social event classification (Agarwal and Rambow, 2010). Both were formulated as bi-nary tasks: the first one being about detecting ex-istence of a social event between a pair of entities in a sentence and the second one being about dif-ferentiating between the interaction and observation type events (given there is an event between the en-tities). I used tree kernels on structures derived from phrase structure trees and dependency trees in con-junction with Support Vector Machines (SVMs) to solve the tasks. For the design of structures and type of kernel, I took motivation from a system proposed by Nguyen et al. (2009) which is a state-of-the-art system for relation extraction. I tried all the kernels and their combinations proposed by Nguyen et al. (2009). I used syntactic and semantic insights to de-vise a new structure derived from dependency trees and showed that this plays a role in achieving the best performance for both social event detection and classification tasks. The reason for choosing such representations is motivated by extensive studies about the regular relation between verb alternations and meaning components (Levin, 1993; Schuler, 2005). This regularity provides a useful generaliza-tion that helps to overcome lexical sparseness. How-ever, in order to exploit such regularities, there is a need to have access to a representation which makes the predicate-argument structure clear. Dependency representations do this. Phrase structure represen-tations also represent predicate-argument structure, but in an indirect way through the structural config-urations. These experiments showed that as a result of how language expresses the relevant information, dependency-based structures are best suited for en-coding this information. Furthermore, because of the complexity of the task, a combination of phrase-based structures and dependency-based structures perform the best. To my surprise, the system per-formed extremely well on a seemingly hard task of differentiating between interaction and observation type social events. This result showed that there are significant clues in the lexical and syntactic struc-tures that help in differentiating mutual and one-directional interactions. Currently I am working on incorporating semantic resources to improve the performance of my prelim-inary system. I will work on making convolution kernels scalable and interpretable. These two steps will meet my goal of building a system that will ex-tract social networks from news articles. My next step will be to survey and incorporate domain adap-tation techniques that will allow me port my system to other genres like literary and historical texts, blog comments, emails etc. These steps will allow me to extract social networks from a wide range of textual data. At the same time I will be able to empirically analyze the types of linguistic patterns, both lexi-cal and syntactic, that perpetuate social interactions. Now I will expand on the aforementioned future di-rections.

Adding semantic information : Currently I am exploring linguistically motivated enhancements of dependency and phrase structure trees to formulate new kernels. Specifically, I am exploring ways of in-corporating semantic information from VerbNet and FrameNet. This will help me reduce data sparse-ness and thus improve my current system. I am interested in modeling classes of events which are characterized by the cognitive states of participants X  who is aware of whom. The predicate-argument structure of verbs can encode much of this infor-mation very efficiently, and classes of verbs express their predicate-argument structure in similar ways. Levin X  X  verb classes, and Palmer X  X  VerbNet (Levin, 1993; Schuler, 2005), are based on syntactic simi-larity between verbs: two verbs are in the same class if and only if they can realize their arguments in the same syntactic patterns. By the Levin Hypothesis, this is because they share meaning elements, and meaning and syntactic realizations of arguments are related. However, this does not mean that verbs in the same Levin or VerbNet class are synonyms; for example, to deliberate and to play are both in Verb-Net class meet-36.3-1 . But from a social event per-spective, I am not interested in exact synonymy, and in fact it is quite possible that what I am interested in (awareness of the interaction by the event partici-pants) is the same among verbs of the same VerbNet class. In this case, VerbNet will provide a useful ab-straction. Future work will also explore FrameNet, which provides a different type of semantic abstrac-tion and explicit semantic relations that are not di-rectly based on syntactic realizations.

Scaling convolution kernels : Convolution ker-nels, first proposed by Haussler (1999), are a con-venient way of  X  X aturally X  combining a variety of features without having to do fine-grained feature engineering. Collins and Duffy (2002) presented a way of successfully using them for NLP tasks such as parsing and tagging. Since then they have been used for various NLP tasks such as relation extrac-tion (Zelenko et al., 2002; Culotta and Jeffrey, 2004; Nguyen et al., 2009), semantic role labeling (Mos-chitti et al., 2008), question-answer classification (Moschitti et al., 2007) etc. Convolution kernels cal-culate the similarity between two objects, like trees or strings, by a recursive calculation over the  X  X arts X  (substrings, subtrees) of objects. This calculation is usually made computationally efficient by using dynamic programming. But there are two limita-tions: 1) the computation is still quadratic and hence slow and 2) the features (or parts) that are given high weights at the time of learning remain inaccessible i.e. interpretability of the model becomes difficult.
One direction I will explore to make convolution kernels more scalable is the following: The deci-sion function for the classifier (SVM in dual form) is given in equation 1 (Burges, 1998, Eq 61). In this equation, y i denotes the class of the i th support vector ( s i ),  X  i denotes the Lagrange multiplier of s , K ( s i ,x ) denotes the kernel similarity between s i and a test example x , b denotes the bias. The kernel definition proposed by Collins and Duffy (2002) is given in equation 2, where h s ( T ) is the number of times the s th subtree appears in tree T . The kernel function K ( T 1 ,T 2 ) therefore calculates the similar-ity between trees T 1 and T 2 by counting the common subtrees in them. By combining equations 1 and 2 I get equation 3 which can be re-written as equation 4.
The motivation for exchanging these summation signs is that the contribution of larger subtrees to the kernel similarity is strictly less than the contri-bution of the smaller subtrees. I will investigate the possibility of approximating the decision function of SVM without having to compare all subtrees, in par-ticular large subtrees. I will also investigate if this summation can be calculated in parallel to make the calculation more scalable. Pelossof and Ying (2010) have done recent work on speeding up the Percep-tron by stopping the evaluation of features at an early stage if they have high confidence that the example will be classified correctly. Another relevant work to improve the scalability of linear classifiers is due to Clarkson et al. (2010). However, to the best of my knowledge, there is no work that addresses approxi-mation of kernel evaluation for convolution kernels.
Interpretability of convolution kernels : As mentioned in the previous paragraph, another dis-advantage of using convolution kernels is that inter-pretability of a model is difficult. Recently, Pighin and Moschitti (2009) proposed an algorithm to lin-earize convolution kernels. They show that by ef-ficiently encoding the  X  X elevant X  fragments gener-ated by tree kernels, it is possible to get insight into the substructures that were given high weights at the time of learning a model. But their system currently returns thousands of such fragments. I will inves-tigate if there is a way of summarizing these frag-ments into a meaningful set of syntactic and lexical classes. By doing so I will be able to empirically see what types of linguistic constructs are used by peo-ple to express different types of social interactions thus aiding in formulating a theory of how people express social interactions.

Domain adaptation : To be able to extract social networks from literary and historical texts, I will ex-plore domain adaptation techniques. A notable work in this direction is by Daum  X  e III (2007). This work is especially useful for me because Daum  X  e III presents a straightforward kernelized version of his domain adaptation approach which readily fits the machine learning paradigm I am using for my problem. I will explore the literature to see if better domain adap-tation techniques have been suggested since then. Domain adaptation will conclude my overall goal of creating a system that can extract social networks from a wide variety of texts. I will then attempt to extract social networks from the increasing amount of text that is becoming machine readable.

Sentiment Analysis : 1 A natural step to try once I have linkages associated with snippets of text is sen-timent analysis. I will use my previous work (Agar-wal et al., 2009) on contextual phrase-level senti-ment analysis to analyze snippets of text and add polarity to social event linkages. Sentiment analy-sis will make the social network representation even richer by indicating if people are connected with positive, negative or neutral sentiments. This will not only give us information about the protagonists and antagonists in the text but will also affect the analysis of flow of information through the network. This work was funded by NSF grant IIS-0713548. I would like to thank Dr. Owen Rambow and Daniel Bauer for useful discussions and feedback.

