 In this paper we consider both the classification and re-gression problems. For the former problem, we adopt the support vector classification, and for the latter we use the penalized kernel ridge regression. All param-eters in the learning machines (e.g., the kernel width and regularization parameter) are selected by cross-validation.
 Reweighted support vector classification : Sup-port vector classifiers can be extended to incorpo-rate non-uniform importance weights of the training instances. Associated with each training instance is the importance weight  X   X  ( y i )  X   X  ( x i ,y i ), which can be incorporated into (1) via the following minimization problem: minimize subject to y i (  X   X , X  ( x i )  X  + b )  X  1  X   X  i , X  i  X  0 (13b) where  X  ( x ) is a feature map from X to a feature space F . The dual of (13) is minimize subject to 0  X   X  i  X   X   X  ( y i )  X   X  ( x i ,y i ) C, (14b) Here k ( x,x 0 ) ,  X   X  ( x ) , X  ( x 0 )  X  F denotes the inner prod-uct between the feature maps. We have modified the LIBSVM implementation 4 for reweighted instances. Reweighted kernel ridge regression (KRR) : The original kernel ridge regression (Saunders et al., 1998) represents the vector of fitted target values as f = Kc , where K is the kernel matrix of x tr , and find the estimate of c by minimizing ( y tr  X  Kc ) | ( y tr  X  Kc ) +  X  c | Kc . The estimate is  X  c = ( K +  X  x I )  X  1 y tr consequently, the fitted target values are  X  f = K  X  c = K ( K +  X  c I )  X  1 y tr . Similarly, the reweighted kernel ridge regression minimizes ( y tr  X  Kc ) |  X  diag {  X   X  ( y  X  ( x tr , y tr ) } X  ( y tr  X  Kc ) +  X  x c | Kc , where denotes the Hadamard (or entrywise) product. This gives  X  c = [ K +  X  x diag  X  1 {  X   X  ( y tr )  X   X  ( x tr , y tr ) } ] the fitted values are f = K [ K +  X  x  X  diag  X  1 {  X   X  ( y  X  Proof 8.1 In (4), U [ P tr X | Y ] is a linear operator, E constraints are convex. We can see that the optimiza-tion problem (4) is convex in  X  .
 According to assumption A TarS 1 , we have  X  [ P te X U [ P tr X | Y ]  X  [ P te Y ] , and the function in (4) reduces to It achieves zero, which is clearly a minimum, when E teristic. Moreover, combining assumptions A TarS 1 and A 4 implies that there is no other solution of  X  ( y ) to (4).
 Proof 8.2 This theorem is a special case of Theo-rem 3: in Theorem 3, setting P new Y = P tr Y = P te Y gives this theorem.
 The gradient of J ConS w.r.t.  X  K and  X  K c is  X   X  K  X   X  K c Using the chain rule, we further have the gradient of J ConS w.r.t. the entries of G and H : where The derivative of J reg w.r.t. G and H is Combining assumption A ConS , i.e., P te X = P Theorem 3, we have X  X  X Because of assumption A ConS 2 , we know that  X  i ,
Y ( y i ) P Taking the integral of the above equation gives P
Y ( y i ) = P P We iteratively alternate between the QP to minimize (11) w.r.t  X  and the SCG optimization procedure w.r.t. { W , B } . Algorithm 1 sunmmarizes this procedure Algorithm 1 Estimating weights  X   X  , W , and B under LS-GeTarS Input: training data ( x tr , y tr ) and test data x te
Output: weights  X  and x new corresponding to the training data points  X   X  1 m , W  X  1 m 1 | d , B  X  0 repeat until convergence  X   X   X   X  , x new = x tr W + B . for clarity. For details of the two optimization sub-procedures, see Sections 3 and 4, respectively. Af-ter estimating the parameters, we train the learn-ing machine by minimizing the weighted loss (2) on ( x As discussed in Sec. 2, all hyperparameters in the sub-sequent learning machines reweighted SVM and KRR are selected by importance weighted cross-validation (Sugiyama et al., 2007). In addition, there are three types of hyperparameters. One is the kernel width of X to construct the kernel matrix K . In our experi-ments we normalize all variables in X to unit variance, and use some empirical values for those kernel widths: they are set to 0 . 8 0 . 3 is the dimensionality of X . This simple setting always works well in all our experiments; for a more principled strategy, one might refer to Gretton et al. (2012). The second type of hyperpameters are involved in the parameterization of  X  for regression under TarS (the kernel width for L  X  and regularization parameter  X   X  ) and  X  LS for LS-GeTarS in (12). We set these param-eters by cross-validation. (On some large data sets we simply set  X  LS to 0.001 to save computational load.) Although the objective functions (Eq. 5 for TarS, and Eq. 11 for LS-GeTarS) is the sum of squared errors, the corresponding problems are considered unsuper-vised, or in particular, as density estimation problems, rather than supervised. We treat P new X as the distribu-tion given by the model, and x te as the corresponding observed data points. They are different from the clas-sical density estimation problem in that here we use the maximum mean discrepancy between P new X and P
X as the loss function. We divide x size subsamples, use four of them to estimate  X  or W and B , and the remaining one for testing. Finally we find the values of these hyperparameters that give the smallest cross-validated loss, which is (5) for re-gression under TarS or (11) for LS-GeTarS. The last type of hyperparameters, including hyperparameters in L and the regularization parameter  X  , are learned by the extension of Gaussian process regression in the multi-output case (Zhang et al., 2011).
 The four simulation settings are (a) a nonlinear regression problem X = Y + (b) a classification problem under TarS, where (c) a classification problem approximately (d) a classification problem under non-location-scale Table 4 reports the results on pseudo real-world data sets. In these experiments, we split each data set into training set and test set. The percentage of train-ing samples ranges from 60% to 80%. Then, we per-form the biased sampling on the training data to ob-tain the shifted training set. Letting P ( s = 1 | y ) be the probability of sample x being selected given that the its true output value is y , we consider the follow-ing two biased sampling schemes for selecting train-ing data: (1) Weighted Label uses P ( s = 1 | y ) = exp( a + by ) / (1 + exp( a + by )) denoted by label(a,b) , and (2) PCA In this case, we generate biased sam-pling schemes over the features. Firstly, a kernel PCA is performed on the data. We select the first principal component and the corresponding projection values. The biased sampling scheme is then a normal distribu-tion with mean m +(  X  m  X  m ) /a and variance (  X  m  X  m ) /b where m and  X  m are the minimum value of the projec-tion and the mean of the projection, respectively. We denote this sampling scheme by PCA(a,b,  X  ) , where  X  is the bandwidth of the Gaussian RBF kernel. In sum-mary, the LS-GeTarS outperforms Unweight, CovS, and TarS on 5 out of 6 data sets for classification prob-lem. The TarS outperforms all other approaches on one of these data sets. For regression problem, TarS outperforms the Unweight and Covs on 7 out of 12 data sets.
 Hyperspectral remote sensing images are characterized by a dense sampling of the spectral signature of dif-ferent land-cover types. We used a benchmark data set in the literature which consists of data acquired by the Hyperion sensor of the Earth Observing 1 (EO-1) satellite in an area of the Okavango Delta, Botswana, with 145 features; for details of this data set, see (Ham et al., 2005). The labeled reference samples were col-lected on two different and spatially disjoint areas (Area 1 and Area 2), thus representing possible spa-tial variabilities of the spectral signatures of classes. The samples taken on each area were partitioned into a training set TR and a test set TS by random sam-pling. The numbers of labeled reference samples for each set and class are reported in Table 5. TR 1 , TS 1 , TR 2 , and TS 2 have sample sizes 1242, 1252, 2621, and 627, respectively. One would expect that not only the prior probabilities of the classes Y , but also the conditional distribution of X given Y would change across them, due to physical factors related to ground (e.g., different soil moisture or composition), vegeta-tion, and atmospheric conditions. Our target is to do domain adaptation from TR 1 to TS 2 and from TR 2 to TS 1 .
 Class Water 69 57 213 57 Hippo grass 81 81 83 18 Floodplain grasses1 83 75 199 52 Floodplain grasses2 74 91 169 46 Reeds1 80 88 219 50 Riparian 102 109 221 48 Firescar2 93 83 215 44 Island interior 77 77 166 37 Acacia woodlands 84 67 253 61 Acacia shrublands 101 89 202 46 Acacia grasslands 184 174 243 62 Short mopane 68 85 154 27 Mixed mopane 105 128 203 65 Exposed soil 41 48 81 14 Total 1242 1252 2621 627 After estimating the weights and/or the trans-formed training points, we applied the multi-class classifier with a RBF kernel, provided by LIBSVM, on the weighted or transformed data. Each time, the kernel size and parameter C were chosen by five-fold cross-validation over the that the selected values always belonged to the interior of the sets.) Table 3 shows the overall classification error (i.e., the fraction of misclassified points) obtained by different approaches for each domain adaptation problem. We can see that in this experiment, correction for target shift does not significantly improve the performance; in fact, the  X  values for most classes are rather close to one. However, correction for conditional shift with LS-GeTarS reduces the overall classification error from 20.73% to 11.96% for domain adaptation from TR 1 to TS 2 , and from 25.32% to 13.56% for that from TR 2 to TS 1 . Covariate shift helps slightly for TR 2  X  TS 1 probably because our classifier is rather simple in that all dimensions have the same kernel size.
 Correction for conditional shift with LS-GeTarS re-duces the overall classification error (fraction of mis-classified points), as seen from Table 3. In addition to the overall classification error, we also report the number of correctly classified points from each class; see Fig. 7. One can see that for both domain adap-tation problems, LS-GeTarS improves the classifica-tion accuracy on classes 11, 9, and 3. It also leads to significant improvement on class 13 for the problem TR 1  X  TS 2 , and on class 2 for TR 1  X  TS 2 . Note that this is a multi-class classification problem and we aim to improve the overall classification accuracy; to achieve that, the accuracy on some particular classes, such as classes 10 and 6, could be worse. Fig. 8 plots some of the estimated scale transformation coefficients w ( y tr ) and location transformations b ( y tr ) that are significant (i.e., w ( y tr ) is significantly different from one, and b ( y tr ) different from zero). One can see that roughtly speaking, the transformation learned for the domain adaptation problem TR 2  X  TS 1 is the inverse of that for the problem TR 1  X  TS 1 .
 In this experiment, we consider automatic assign-ment of semantic tags to video segments, which can be a fundamental technology for content-based video search (Smeaton et al., 2009). For each semantic con-cept, classifiers can be obtained from annotated train-ing data (source domain) and used to determine the presence of the concept for each segment in test data (a) Estimated scale transformation coefficient for selected classes for domain adaptation TR 1  X  TS 2 . (b) Estimated location transformation for selected (c) Estimated scale transformation coefficient for selected classes for domain adaptation TR 2  X  TS 1 . (d) Estimated location transformation for selected Mountain Natural X  X isaster Office (target domain). We show that the proposed TarS and LS-GeTarS can improve the performance of concept detection when the training and test data are from different domains, for example different TV channels. We consider the 39 semantic concepts from the LSCOM-lite lexicon (Naphade et al., 2005), with anno-tation on the TRECVID 2005 data set. The data set contains 61 , 901 segmented video shots from 108 hours of television programmes from six different broad-cast channels, including three English channels (CNN, MSNBC and NBC), two Chinese channels (CCTV and NTDTV) and one Arabic channel (LBC). For each shot, 346 low-level features were extracted from its keyframe (Yang et al., 2007), including Grid Color Mo-ment (225 dim.), Gabor Texture (48 dim.), and Edge Detection Histogram (73 dim.). We split the data set into a source domain that consists of video shots from the English and Chinese channels, and a target domain that contains shots from the Arabic channel.
 We apply asymmetric bagging to handle the scarcity of positive training instances (Tao et al., 2006). For each concept, five SVM classifiers were trained using up to 1000 positive training instances and the ran-domly sampled same amount of negative instances. The overall rank list on the test data was obtained from the average classification confidence. We used the default parameters for training the SVM classi-fiers, as suggested by Tao et al. (2006) The average precision of all concepts is shown in Fig. 9. Overall, TarS achieved a Mean Average Pre-cision (MAP) of 0 . 2345 across all concepts, and out-performed the baseline method (MAP: 0 . 2272). TarS achieved substantial improvements on concepts such as Snow , Vegetation , and Flag-US , where P Y varies significantly. LS-GeTarS further improved the perfor-mance and achieved an MAP of 0 . 2358. As shown in Fig. 9, LS-GeTarS worked particularly well for the concept Snow , where considerable conditional shift is expected. Note that our methods should be distin-guished from previous work by Duan et al. (2009), as we do not use any annotation from the target domain. Duan, L., Tsang, I. W., Xu, D., and Chua, T. S. Do-main adaptation from multiple sources via auxiliary classifiers. In ICML , 2009.
 Gretton, A., Sriperumbudur, B., Sejdinovic, D., Strathmann, H., Balakrishnan, S., Pontil, M., and
Fukumizu, K. Optimal kernel choice for large-scale two-sample tests. In NIPS 25 . 2012.
 Naphade, M. R., Kennedy, L., Kender, J. R., Chang, S. F., Smith, J. R., Over, P., and Hauptmann, A. A
Light Scale Concept Ontology for Multimedia Under-standing for TRECVID 2005 , 2005. IBM Research Technical Report.
 Smeaton, A. F., Over, P., and Kraaij W. High-Level Feature Detection from Video in TRECVid: A 5-Year Retrospective of Achievements. In Divakaran A. (eds.), Multimedia Content Analysis, Theory and
Applications , pp. 151 X 174. Springer Verlag, Berlin, 2009.
 Sugiyama, M., Krauledat, M., and M  X uller, K. R.
Covariate shift adaptation by importance weighted cross validation. JMLR , 8:985 X 1005, December 2007.
 Tao, D., Tang, X., Li, X., and Wu, X. Asymmet-ric bagging and random subspace for support vec-tor machines-based relevance feedback in image re-trieval. IEEE T-PAMI , 28(7):1088 X 1099, 2006.
 Yang, J., Yan, R., and Hauptmann, A. G. Cross-domain video concept detection using adaptive
