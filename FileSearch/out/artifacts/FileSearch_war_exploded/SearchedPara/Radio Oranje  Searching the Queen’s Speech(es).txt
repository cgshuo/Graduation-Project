 The  X  X adio Oranje X  demonstrator shows an attractive multi-media user experience in the cultural heritage domain based on a collection of mono-media audio documents. It supports online search and browsing of the collection using indexing techniques, specialized content visualizations and a related photo database.
 Categories and Subject Descriptors: H.5.2 [User Inter-faces]: Graphical user interfaces (GUI) General Terms: Design.
 Keywords: Multimedia retrieval; Information visualiza-tion.
Retrospective digitization of historic audio collections is ongoing (e.g. the EU IST PrestoSpace project 1 ). The  X  X a-dio Oranje X  collection is an example of such a collection: it contains the speeches that Queen Wilhelmina (1880-1962) addressed to the Dutch people in occupied areas during World War II, broadcast from London, England. The record-ings and manual transcripts were preserved by the Nether-lands Institute for War Documentation (NIOD) and the Netherlands Institute for Sound and Vision (NIBG). The collection is of high historical value and part of the Dutch cultural heritage. Until now, it could only be searched by reading the transcripts kept at the NIOD and then visiting the NIBG to obtain copies of the audio. The demonstra-tor 2 provides an example of how state-of-the-art visualiza-tion and indexing technology can boost the accessibility and enliven the perception of such collections.

First the text versions of the 37 speeches were synchro-nized with the audio using alignment, a technique from http://www.prestospace.org http://hmi.ewi.utwente.nl/choral/demo automatic speech recognition (ASR) research. Alignment matches an utterance (speech) to a speech sound representa-tion of the utterance X  X  transcript (1940s text) using acoustic models. The speeches were aligned at the word level and evaluation showed that over 90% of the word boundaries were within 100 ms of the reference.

On the basis of the alignment a time-stamped index was created that  X  apart from access to the speeches  X  allows additional functionalities. The first is browsing at the col-lection level and search at the fragment level. The second is an interactive visualization of the audio content that shows an overview of the entire speech and a zoomed-in view of a 45 s window around the cursor. Highlights, e.g. query terms, are shown in both bars and clicking anywhere restarts the audio at that point in time. The third functionality is karaoke-style subtitling to aid intelligibility given the poor audio quality. The latter two functionalities are shown on the playback page, see figure 1.
 Figure 1: Screen shot of the playback interface
Finally, images from a topically related photo database where automatically linked to the speech content on the ba-sis of broad semantic classifications of the images and syn-chronously presented along with the speech. In this way, an attractive multimedia user experience was created from a collection of mono-media audio documents.
This research was supported by the research program Mul-timediaN and the NWO-CATCH project CHoral.

