 Structured knowledge bases are an increasingly important way for storing and retrieving information. Within such knowledge bases, an important search task is finding sim-ilar entities based on one or more example entities. We present QBEES, a novel framework for defining entity sim-ilarity based only on structural features, so-called aspects, of the entities, that includes query-dependent and query-independent entity ranking components. We present evalu-ation results with a number of existing entity list comple-tion benchmarks, comparing to several state-of-the-art base-lines.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models list completion; entity search
More and more data is available in semantic form, e.g., within the Linking Open Data cloud [8], product databases or common knowledge ontologies like DBpedia [2] or YAGO [9]. In consequence, information retrieval methods become more important to navigate the semantic data [12]. One typical IR task is the search for similar information pieces given an example. While explicit search interfaces allow a fine-tuned control, many use-cases rather suggest implicit query interfaces. Whenever a retrieval task is too compli-cated to be explicitly expressed by average users, is vague in nature or unclear to the user herself, an implicit search interface is a natural user-friendly choice. Consider, for in-stance, the task to replace a particular worker of a company X  X  workforce or searching for all possible replacements of a par-ticular part in a production process. Instead of specifying ilar two entities are. One of the earliest approaches was SimRank [10] which considers two entities as similar if their context is similar. A more recent line of work uses random walks with restart to compute similarities of one entity or a group of entities to all other entities, such as Personalized Pagerank [7], with a focus on relational data graphs [1, 11].
Another group of approaches uses features extracted from the context of entities to determine their similarity, includ-ing textual features (terms in the entity X  X  uri or appearing in documents close to the entity) and structural features (cate-gories or types of the entity). Balog et al. [4] propose to use language models that include terms and categories. Bron et al. [5], which is closest to our work, combines a term-based language model with a simple structural model including uniformly weighted facts about the entity. In contrast, our query model does not include a keyword component, our set of structural features in the aspects is more general, and our model allows to give different weights to different features. We experimentally compare our model to their structural model in Section 6.

Yu et al. [14] solve a slightly different problem where en-tities similar to a single query entity are computed, exploit-ing a small number of example results. Focusing on het-erogeneous similarity aspects, they propose to use features based on so-called meta paths between entities and several path-based similarity measures, and apply learning-to-rank methods for which they require labelled test data. Wang and Cohen [13] present a set completion system retrieving candidate documents via keyword queries based on the en-tity examples. Using an extraction system additional enti-ties are then extracted from semi-structured elements, like HTML-formatted lists.
A Knowledge Graph (KG) consists of two basic compo-nents: A Fact graph F G and an ontology O .

The Fact graph F G is a directed multigraph where each node represents some entity (e.g. Warsaw , Poland ). Each pair of nodes connected by a labelled arc represents an instance of a binary relation between two entities where the arc la-bel represents the kind of relation (e.g. isCapitalOf ), thus representing a fact about the entities (e.g.  X  X arsaw is the capital of Poland X ). In the following we will use the nota-tion relation ( arg1 , arg2 ) for any arc with label relation in KG that connects nodes arg1 and arg2 . In this notation the fact  X  X arsaw is the capital of Poland X  is represented as isCapitalOf ( Warsaw , Poland ).

Each node in the ontology tree O represents a class (type) of entities (e.g. person or city ). The root of this tree repre-sents the most general class of entities (e.g., owl:Thing or wordnet_entity ) The nodes in the ontology tree are con-nected by directed arcs labelled as subClassOf .

The fact graph F G connects the entities to the ontology O : an arc of the form hasType ( anEntity , aClass ) represents the information that the entity anEntity is an instance of class aClass . Due to inheritance, each such entity is implicitly also an instance of all classes that are more general than the explicitly mentioned class. As an example, the explicit arc hasType ( Chopin , composer ) implies also an implicit arc hasType (
Chopin , person ). Notice that an entity may be an instance of several different classes so that none of them is more general than another (e.g. hasType ( Chopin , composer ), hasType ( Chopin , pianist )). aspects M A ( Q ) of Q . 2. filter the maximal aspects by types typical for the entities in Q , 3. rank the maximal aspects, 4. pick the entity with largest popularity pop ( e ) from the top aspect and update the aspect X  X  rank, 5. redo step 4 until k entities are picked. 1. Maximal Aspects. Given a set of entities Q , first for each entity q  X  Q the set of its basic aspects A ( q ) is computed. Then the shared properties are identified by in-tersecting the aspect sets A ( Q ) =  X  q  X  Q A ( q ). This provides the corresponding family of maximal aspects M A ( Q ). (For a set of entities Q , we extend the definition of a maximal aspect set such that the entity set of a maximal aspect must contain at least one entity not in Q .) 2. Typical Types. One of our basic assumptions is that the goal is to find other entities of relatively equal type. For instance, given a city, the output should be other cities and not, e.g., a country, because they share the same river passing through.
 Thus, for each query Q we determine a set of typical types T ( Q ) and consider only maximal aspects that contain at least one such typical type (or descendant thereof) as basic aspect. Some details aside, T ( Q ) consists of all types shared by all entities in Q excluding some very general classes. If this yields an empty set, we also allow types that are shared by a majority of q  X  Q . 3. Aspect Ranking. The resulting maximal aspects are of different specificity and thus quality. For instance, a maximal aspect for Arnold Schwarzenegger might consist of hasType ( x , person ) and hasBirthplace ( x , Austria ) while an-other one might consist of hasType ( x , GovernorOfCalifornia ). Hence, in order to decide which aspect set is more likely to be of interest, we rank the maximal aspects (see Section 5.1). 4. Picking an entity. Similarly to aspects, the enti-ties in the entity set of an aspect may have different likeli-hoods of importance to a user, especially for relatively broad aspects. We use two different entity importance measures that provide an estimated popularity pop ( e ) for an entity e . First, we use the stationary probabilities of a random walk on KG . Alternatively, as a YAGO-specific method we esti-mate popularity based on the click count of the Wikipedia page corresponding to the entity.
Given a set of query entities Q , we rank aspects in a language-model-style approach, i.e. each aspect A is ranked according to P ( A | Q ), which we model as: where P ( Q | A ) is the likelihood to generate the original query entities given the aspect A and P ( A ) is the likelihood to pick A (from all maximal aspects). In order to estimate P ( Q | A ) and P ( A ) we employ different approximations that are combined in 4 rankers. These ranking approaches are based on the following components. Given an estimator for the popularity of an entity, pop ( e ), the popularity of an as-pect can be estimated as the aggregated popularity of its en-tities, i.e. pop ( A ) = P e  X  E ( A ) pop ( e ) normalized by the sum over the popularity of all entities. A basic aspect b might be considered for its worth or likelihood to be generated v ( b ). We estimate the value of a basic aspect by its selectivity, i.e. ratio ratio ( A, B ) between two (compound) aspects A, B can
Figure 3: Topic Category Constraints -INEX2007 for the entities, we automatically mapped these to YAGO wikicategory-classes and used them as a constraint for sug-gested entities. Figure 3 shows that this does not work well, since the resulting classes are too over-fitting, i.e. unfortu-nately the YAGO data is quite incomplete in this perspec-tive, such that the class constraints often filter out too many entities. Note that in cases where the automatic category mapping failed, we fell back to the default method (which is what we compare against).

Competitors. We now evaluate our approach with its different ranking approaches ( spop , cost , dist , distp ) against (1) a random walk with restart at the query nodes, ( rwalk:c , rwalk:tf , rwalk:n ) as a graph-based baseline, and (2) the structure-only approach suggested by Bron et al. in [5] ( bronetal ). Note that in (1) we optionally applied a filter on resulting entities, either using the categories provided in the INEX dataset for the topic where possible ( X :c X  versions) or using our own typical type identification approach( X :tf X ).
Results. Figure 1 shows the map and mndcg values for all approaches on the inex2008 dataset. Note that the random walk computation was so slow that we left it out for the higher query sizes. As the results show, the random walk benefits strongly from entity filtering ( X :c X , X :tf X  versions vs  X :n X  version). Note that all our approaches behave similarly well. While for queries of size 1, our approach provides roughly the same quality as the approach suggested by Bron et al and the best random walk, for larger queries our aspect based approach outperforms both. The mndcg values indicate a quality dampening at query size 5, this is probably due to over-fitting and lower agreement for the typical types.
In this paper we presented a facet aware entity similar-ity model and evaluated its use for set completion tasks. While our preliminary evaluation shows that it can outper-form state of the art structure-only models in several cases, the narrow focus on very specific similar entities can also be a drawback. In particular, future work will need to look
