 Microarray gene expression profiling technology is one of the most important research algorithms, such as support vector machines, neural networks, and logistic regression, which have been used in the tumor classification from gene expression data. Soinov et al . [5] and Li et al . [6] used tree structures to classify microarray samples. Hvidsten et al . [7] proposed learning rule based models of biological process from gene expression feature space, compared with logistic regression models. 
In pattern recognition problems, the scoring ability is important not only to quantify the certainty grades of samples belonging to each class, but also to help researchers to finding out the true active samples and filtering out the background noise [9]. Liu et al. [10] proposed a scoring algorithm based on negative entropy to position specific frequency matrix (PSFM) and Markov model to predict protein-DNA binding site. Murvai et al. [11] used a probabilistic scoring method for protein domain identification. Jensen and Liu [12] proposed a bayesian scoring function approach to motif discovery. 
In this study, a completely new and effective scoring method for tumor prediction from microarray data is investigated. It is necessary to cope with the following difficulties in designing the scoring system, described below. 1) It is desirable to select a minimal number of relevant genes while maintaining the highest accuracy for designing tumor classifiers, which is essential for developing inexpensive diagnostic tests. 2) The desrived scores can faithfully respond to accurate tumor classification with an interpretable manner. To achieve the above-mentioned goals, we propose a scoring method based on an interpretable fuzzy classifier (named iSFC, interpretable scoring fuzzy classifier). 
The design of iSFC has three classification and one scoring function objectives to be simultaneously optimized: maximal classification accuracy, minimal number of rules, minimal number of used features, and maximal area under a ROC curve. High performance of iSFC arises from that the flexible membership function, simplified fuzzy rule, and rule/gene selection are simultaneously optimized [13]. An intelligent number of tuning parameters [14]. 
The performance of iSFC is evaluated using two benchmark datasets. It is shown that iSFC has concisely interpretable rules and better performance than the existing Vinterbo  X  X  classifier [8]. iSFC is also comp arable to some non-rule-based methods using a large number of genes in terms of accuracy performance. Furthermore, the efficient scoring ability of iSFC is evaluated using the mean areas under ROC curves having 0.984 and 0.930 for training and test data, respectively. 2.1 Membership Function and Fuzzy Partition The classifier design of iSFC uses flexible generic parameterized fuzzy regions which can be determined by flexible generic parameterized membership functions (FGPMFs) and a hyperbox-type fuzzy partition of feature space. Each fuzzy region corresponds to a parameterized fuzzy rule. In this study, each value of gene expression is normalized defined as where x  X  [0, 1] and abcd  X  X  X  X  . The variables a , b , c , and d determining the shape of a trapezoidal fuzzy set are the paramete rs to be optimized. Five parameters V 1 , V 2 , ..., V 5  X  [0, 1] without constraints instead of a , b , c , and d are encoded into a chromosome for facilitating IGA. Let an additional variable L = V 1 which determines the location of the fuzzy set characterizing the occurrence of training patterns. When V i are obtained, and d feasible and reduce interactions among encoded parameters of chromosomes. 2.2 Fuzzy Rule and Fuzzy Reasoning Method The following fuzzy if-then rules for n -dimensional pattern classification problems are used in the design of iSFC: number of classes, CL j  X  {1, ..., C } denotes a consequent class label, CF j is a certainty training phase. 
To enhance interpretability of fuzzy rules, linguistic variables in fuzzy rules can be example, x i is Low for down-regulated genes; x i is Medium for neutral genes; and x i is High for up-regulated genes. An antecedent fuzzy set A ji  X  A u where A u denotes a set of the subsets of U . Examples of linguistic antecedent fuzzy sets are shown in Fig. 1. 
In the training phase, all the variables CL j and CF j are treated as parametric genes encoded in chromosomes and their near-optimal values are obtained using IGA. The following fuzzy reasoning method is adopted to determine the score of an input pattern x = ( x p 1 , x p 2 , ..., x pn ) based on voting using multiple fuzzy if-then rules: Step 1) Calculate the difference of certainty grades, DCG p , between Class 1 and Class Step 2) Normalize all DCG of training samples to [0, 100] and the normalized value is 2.3 Fitness Function and Chromosome Representation In this study, we define the fitness function (or objective function) of IGA as where W r and W f are positive weights. In this study, we use W r = 0.1 and W f = 0.001 [13]. 
A chromosome consists of control genes for selecting useful features and significant fuzzy rules, and parametric genes for encoding the membership functions and fuzzy 1,..., N , represented by one bit for eliminating unnecessary fuzzy rules. If r j = 0, the the feature x i is excluded from the classifier. Otherwise, x i is included. The parametric genes consist of three types: individual, as shown in Fig. 2. The number of encoding parameters to be optimized is encoding control and parametric genes. There are 8 bits for encoding one of parameters V and independent of value n but dependent on the number of fuzzy regions. Generally, N is set to the maximal number of possible fuzzy regions. In this study, N is set to 3 C . The design of an efficient fuzzy classifier is formulated as a large-scale parameters optimization problem (LPOP). If the optimal or near-optimal solution to the LPOP can be found, an efficient fuzzy classifier can be obtained. 2.4 IGA for Designing iSFC evolutionary algorithm [14] to solve the design problem of iSFC. The main difference between IGA and the traditional GA is an efficient intelligent crossover operation. The intelligent crossover is based on orthogonal experimental design to solve intractable optimization problems comprising lots of design parameters. Orthogonal Experimental Design. The two-level orthogonal arrays (OAs) used in IGA are described below. Let there be  X  factors, with two levels each. The total number ceiling operation, build an OA L M (2 M -1 ) with M rows and M -1 columns, use the first  X  columns, and ignore the other M - X  -1 columns. OA can reduce the number of level combinations for factor analysis. The number of OA combinations required to analyze all individual factors is only M = O(  X  ), where  X  +1  X  M  X  2  X  . 
After proper tabulation of experimental results, the summarized data are analyzed follows. Let y t denote a objective function value of the combination t , where t = 1, ..., M . Define the main effect of factor i with level k as S ik where i = 1, ...,  X  : that the objective function is to be maximized. For the two-level OA, level 1 of factor i makes a better contribution to the objective function than level 2 of factor i does when S contribution. The main effect reveals the individual effect of a factor. The most one of two levels of each factor is determined, an efficient combination consisting of all factors with the better levels can be easily derived. Intelligent Crossover. All parameters are encoded into a chromosome using binary codes. Like traditional GAs, two parents P 1 and P 2 produce two children C 1 and C 2 in one crossover operation. Let all encoded parameters be randomly assigned into  X  groups where each group is treated as a factor. The following steps describe the intelligent crossover operation. Step 1: Use the first  X  columns of an OA L M (2 M -1 ) Step 2: Let levels 1 and 2 of factor i represent the i th groups of parameters coming from Step 4: Compute the main effect S ik where i = 1, ...,  X  and k = 1, 2. Step 5: Determine the better one of two levels of each factor. Step 6: The chromosome of C 1 is formed using the combination of the better genes Step 7: The chromosome of C 2 is formed similarly as C 1 , except that the factor with the  X  2  X  , to explore the search space of 2  X  combinations. Intelligent Genetic Algorithm. The used IGA is given as follows: Step 1: Randomly generate an initial population with N pop individuals. Step 2: Evaluate fitness values of all individuals. Let I best be the best individual in the Step 3: Use the simple ranking selection that replaces the worst P s  X  N pop individuals with Step 5: Apply a conventional bit-inverse mutation operator to the population using a Step 6: Termination test: If a pre-specified termination condition is satisfied, stop the P =0.01. The stopping condition is to use 100 X  N p fitness evaluations. All the ten-ford cross validation test (10-CV) is used. 
Two benchmark data sets from [15] were used. For comparison, we adopted the same Wilcoxon rank sum test with [8] as a non-parametric feature pre-selection method for the unbalanced data set, such as microarray gene expression data. In this study, we have pre-selected n =10, 15 and 20 features (genes) to evaluate the performance of our method on various values of n . After computer simulation, the results of iSFC using the two data sets for n =10, 15 and 20 revealed no significant difference. In the following experiments, we used the data sets with n =15. Table 1 shows the used two data sets and the number N p of parameters to be optimized using IGA. 
Two experiments are conducted to evaluate iSFC. Experiment 1 is to compare the performances of iSFC with the Vinterbo  X  X  fuzzy classifier [8]. Experiment 2 is to compare the performances of iSFC with the non-rule-based classifiers in [13]. Due to terms of ROC curves. 3.1 Experiment 1 For easy comparisons, we conducted two evaluations on the Vinterbo X  X  method using different numbers of pre-selected features. One is to use 200 features (V200), which is the same with that in [8]. The other is to use 15 features (V15), which is the same with that of the proposed method. 
Table 2 shows the statistical results (average and standard deviation) of iSFC, V200, and V15 in terms of training accuracy ( TrCR ), test accuracy ( TeCR ), number of rules ( N r ), number of features ( N f ), and rule number per class ( N r / C ). The results of V200 and V15 were obtained by using the execution file provided by S. A. Vinterbo et al . [8]. 
From these results, we can obviously observe that iSFC is more compact and accurate using 15 candidate features than th e Vinterbo X  X  classifier using 200 candidate features in terms of TrCR (97.93% vs. 83.72%), TeCR (89.67% vs. 83.50%), N r (1.92 vs. 2.80), and N r / C (0.96 vs. 1.40). On the other hand, V200 is better than V15 in test accuracy but worse in training accuracy and using more candidate features and computation time. Moreover, the classifiers V200 compare favorably to those of logistic regression models, one of the standard classification methodologies applied in the biomedical domain [8]. Prostate tumor 3.2 Experiment 2 We compare the proposed method with some non-rule-based methods to evaluate the various efficient classifiers which can handle multiple classes using a very large number of genes, the reported accuracy without using gene selection can be used as an upper bound for comparisons. Table 3 shows the test accuracy comparison using 10-CV on the two data sets between iSFC and the following methods: multicategory support vector machine (SVM), k -nearest neighbors ( k -NN), backpropagation neural networks (NN), and probabilistic neural networks (PNN) which are the most common methods for gene expression data analysis. The results are obtained from [13]. 
Table 3 indicates that the multicategory SVM with 94.75% is the most accurate classifier for tumor classification. However, it cost too much to take thousands of genes to make the classification decision such that it is not practical to implement the chips of medical test containing such lots of genes in real environment. On the other hand, iSFC needs just a few genes. It means that our method takes much less cost to make a biological test and is better in another economical view. The proposed fuzzy classifier iSFC with 89.67% using 3.87 genes on an average is worse than SVM but superior to k -NN (86.03%), NN (84.41%), and PNN (80.04%) using thousands of genes in terms of accuracy only. Because the sample sizes of microarray data are extremely small, it results in the high training accuracy (97.93%) and relatively low test accuracy (89.67%). From the viewpoint of analysis and practical applications, iSFC can serve as one of efficient tools for analysis of gene expression profiles. 
Furthermore, iSFC performs well in terms of ROC curves, and results in the large areas under the ROC curve in training and test phases, TrAUC and TeAUC (0.984 and 0.930), near to 1. It reveals that iSFC has the scoring ability to efficiently differentiate each sample between two classes and effectively quantify the likelihood or certainty grades of classification for each sample. Moreover, with the ability of quantifying the certainty grades of samples belonging to each class, researcher can easily find out the accurate experimental result. Figs. 3(a) and (b) show the score distribution histogram of test samples using the dataset prostate tumor and the corresponding ROC curve from 0.963, respectively. 
Another advantage of iSFC is the interpretability of learning result. Fig. 4 shows an example of iSFC for the data set DLBCL using 90% samples for training and the rest Where TrCR =100% and TeCR =100%. The fuzzy rule R 1 tells us that when the expression of gene 8 is not greater than medium-small, the impact of gene 8 to classifying samples to Class 1 is proportional to its expression, otherwise gene 8 does linguistically interpretable meaning of fuzzy rule R 2 is: This paper has proposed an interpretable scoring fuzzy classifier, named iSFC, for microarray data analysis. The superiority of the proposed iSFC has been evaluated by computer simulation on two benchmark datasets of gene expression. The experimental results reveal that: 1) the proposed method can obtain interpretable classifiers with an accurate and compact fuzzy rule base, compared with the existing fuzzy classifier [8]; 2) iSFC using few genes is worse than SVM but superior to k-NN, NN, and PNN using thousands of genes in terms of accuracy; and 3) iSFC has an efficient scoring ability to quantify certainty grades of samples belonging to each class with the average areas under ROC curve in training and test phases (0.984, 0.930) nearly to 1. 
