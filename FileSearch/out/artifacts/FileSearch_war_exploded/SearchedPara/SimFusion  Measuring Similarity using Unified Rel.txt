 In this paper we use a Unified Relationship Matrix ( URM ) to represent a set of heterogeneous data objects (e.g., web pages, queries) and their interrelationships (e.g., hyperlinks, user click-through sequences). We claim that iterative computations over the URM can help overcome the data sparseness problem and detect latent relationships among heterogeneous data objects, thus, can improve the quality of information applications that require com-bination of information from heterogeneous sources. To support our claim, we present a unified similarity-calculating algorithm, SimFusion . By iteratively computing over the URM , SimFusion can effectively integrate relationships from heterogeneous sources when measuring the similarity of two data objects. Experiments based on a web search engine query log and a web page collection demonstrate that SimFusion can improve similarity measurement of web objects over both traditional content based algorithms and the cutting edge SimRank algorithm.
 H.3.3 [ Information Storage and Retrieval ]: Information search and retrieval; G.2.2 [ Discrete Mathematics ]: Graph Theory. General Terms : Algorithms, Experimentation SimFusion, Information retrieval, Information integration. Concerned with the information explosion that was gathering momentum after WWII, Vannevar Bush gave us a vision of linked information in 1945, which has helped inspire the WWW [4]. Today, the success of the WWW , and many other information technologies, leaves us with a much larger information explosion. To survive this challenge, we must learn to manage that information more effectively, and so must have new, more powerful models and techniques for information integration, in complex contexts. Authors, documents, users, metadata, and other types of entities present in scientific/scholarly domains; as well as web pages, users, queries, and other entities found in web domains; all can be considered as data objects containing information. The information may characterize content features of individual objects, as well as relationships between objects, from the same or different types of sources. In the web domain, for example, we know that users browse web pages and issue queries. Queries, in turn, may lead to the referencing of web pages. These three operations ( browsing , issuing , and leading to a page reference) are relationships that connect different types of objects. We also know that users are connected by their social relationships, web pages are connected by hyperlinks, and queries are connected by their content similarities. These three latter connections can be viewed as relationships within the same type of objects .
 Modern information applications, such as searching and document clustering, mainly use three approaches to represent information objects and the interrelationships involved: 1. Spaces: Vector and probability spaces implicitly use a set of 2. Databases: Relational databases operate on objects and their 3. Networks: Belief, inference, and spreading activation However, most information applications being used today take only one of the three approaches to analyze one kind of relationship within the same type of objects (e.g., document clustering, web link analysis) or only between two types of objects (e.g., web search, collaborative filtering). These applications are hard to change. We run into problems when the users of these applications require more accurate models of reality, wherein the number of types and sub-types of objects that must be handled expand rapidly (e.g., considering both queries and users when clustering web pages), and the relationships between different types of objects (e.g., considering both reference and browsing relationships when analyzing behaviors associated with web pages) grow tremendously. More specifically, the problem we are facing can be stated as:  X  How can the broad variety of heterogeneous data and relationships be effectively and efficiently combined to improve the performance of various information applications?  X  The purpose of our research is to find effective and efficient means of combining relationships from multiple heterogeneous data sources, thus overcoming limitations of the three traditional approaches discussed above. In this paper, we claim that the Unified Relationship Matrix ( URM ) (described in detail in Section 4.2) can be used to represent relationships from multiple and heterogeneous information sources. We further claim that iterative computation, over the URM , will improve the quality and utility of information from heterogeneous sources for a variety of search related information applications. To prove this, we have focused our research on a specific information application: similarity calculation involving heterogeneous data objects. The underlying hypothesis is that: Relationships can be represented through matrices accurately, with either binary or real-valued weights. Matrices representations of different types of relationships are sometimes complementary. A matrix representation of a single relationship may be sparse, but when reinforced by other types of relationships represented in complementary matrices, the information it contains may be more dense and helpful. We contend that matrix representation and matrix processing are effective approaches for combining relationships from difference sources . Figure 1 gives a simplified illustration of our hypothesis. Note that as a result of our methods, the bottom row of matrices, which can be used for various applications, is presumably of higher quality (e.g., less sparse, due to the addition of accurate new values, and so more effective). Figure 1: Matrix representations of relationship integration Many works have focused on using a single type of relationship when calculating the similarity of data objects. Approaches that calculate the similarity of document-query objects using document-term relationships include: Vector Space Model (VSM) [26], Generalized Vector Space Model [30], Latent Semantic Indexing [11], query expansion [25], and dynamic vector space modification [2]. These can be viewed as variations of a general algorithm that projects documents and queries into a vector space using singular vectors; they differ in how the vectors are constructed and how weights are assigned. Reference relationships also can help us gauge the similarity among scientific papers, e.g., by considering co-citations [27] and bibliographic coupling [17]. These in turn have been used to cluster scientific journals [19]. In the WWW , relationships among pages (e.g., based on hyperlinks) were used to calculate the similarity of web objects [10], and helped in web clustering tasks [1] [29]. Relationships between people and artifacts have been used to calculate the preferences of people for artifacts, in collaborative filtering [14] and recommender systems [23]. Most works discussed above only consider a single type of relationship when calculating the similarity of data objects. Some recent works [7] [15] proposed using multiple relationships to calculate the similarity between data objects. However, these works differ from ours mostly in 1) how different kinds of attributes (relationships) are combined, 2) the representation of relationships, and 3) theoretical foundations. Most r ecently, [20] and [33] focused on taking advantage of mutual reinforcement effects, and iteratively calculate the similarity of data objects. However, these works lack a theoretical foundation, and their integration methodology also is different from ours. Although the representation and calculation in [8] and [31] are similar to our work, they differ in how similarity is calculated using matrices (see Section 5). In [8], the expensive iterative computations limit its online use. [31] differs in that its purpose is to find the attribute values of single data objects, not the similarity of data objects. We go beyond earlier works by providing a unified representation of different types of relationships, by developing a framework and a solid theoretic foundation for calculating with regard to relationships between data objects, and by considering multiple types of relationships as well. We first give simple definitions for key terms as they will be used in the rest of this paper: Data Type : A data type refers to a class of objects, defined by a set of characteristic features (e.g., user has a set of features including name, gender, etc.). A data object is an instance of a data type. Data Space : A data space is a set of data objects with the same data type (e.g., web pages in the Internet). Table 1 gives examples of related data spaces and data objects. Homogeneous/Heterogeneous : Each data space is homogeneous within itself, but heterogeneous with respect to other data spaces. Intra-type relationship: connects information objects within a homogeneous data space (e.g., hyperlinks within web pages). Inter-type relationship: connects information objects across heterogeneous data spaces (e.g., users issue queries and browse web pages. The issuing and browsing activities can be regarded as inter-type relationships connecting the user and web page data spaces, and the user and query data spaces, respectively.). Data Spaces Examples of Data Objects People Authors, editors, users Terms Concepts, stems, words Queries Natural language queries, Boolean queries 
Documents Journals papers, refereed conference papers The formal definition of the Unified Relationship Matrix ( URM ) that represents both inter-and intra-type relationships among heterogeneous data objects in a unified manner is given below. Suppose there are t different data spaces S 1 , S within the same data space are connected via intra-type relationships R i  X  S i  X  S i . Data objects from two different data spaces are connected via inter-type relationships R ij  X  S intra-type relationships R i can be represented as an m  X  m adjacency matrix L i ( m is the total number of objects in data space S from the x th object to the y th object in the data space S type relationship R ij can be represented as an m  X  n adjacency matrix L ij ( m is the total number of objects in S i number of objects in S j ), where the value of cell l xy inter-type relationship from the x th object in S S . If we merge N data spaces into a unified data space U , then previous inter-and intra-type relationships are all part of intra-type relationships R u in data space U . Suppose L u is the adjacency Data Ob j ect
Inter-type relationship matrix of R u , then L u is a square matrix. We define the Unified Relationship Matrix L urm as a matrix that combines all the relationship matrices, as given in Eq. (1): The URM provides a generalized way of viewing data objects and their relationships. In the URM , different types of objects are treated as elements of a  X  X nified X  data space. Previous inter-and intra-type relationships are each considered as a generic intra-type relationship that connects data objects in the  X  X nified X  data space. The URM can be used to explain a variety of real world information application scenarios. For example, if we only consider one data space, of web pages, and one type of intra-type relationship, the hyperlink relationship, then the URM is reduced to the link adjacency matrix of the web graph, upon which advanced web link analysis works such as [3] and [18] are based. Consider another example. If we have two data spaces, documents and terms, then an inter-type relationship is defined when a document contains a term or a term is contained by a document. A URM can be built as in Eq. (2). L = (2) L is the traditional document-term matrix used in the VSM [26]. The 0 sub-matrices on the diagonal indicate that we have no prior knowledge of intra-type relationships within the document or term space. All the information applications that manipulate the document-term matrix can still be used on L urm . Furthermore, the intra-type relationship of the document and term spaces can be obtained by simply multiplying L urm with itself: L X  L wise similarity matrix and term pair-wise similarity matrix obtained by most traditional VSM similarity calculations. By adding L X  urm and L urm , we can have a complete URM for the document and term spaces: combines document pair-wise and term pair-wise relationships with traditional document-term relationships was named by Davidson [8] as the  X  X eneric augmented matrix X . Our basic assumption is that:  X  X he similarity between two data objects can be reinforced by the similarity of related data objects from the same and different spaces X , as is illustrated below: Figure 2: Illustration of similarity reinforcement assumption As can be seen in Figure 2, the similarity between two data objects (big black nodes in the center) is reinforced by relation-ships from the same type of related data objects (small black nodes) as well as the relationships (both inbound and outbound) from different types of data objects (white and gray nodes). Suppose there are N different data spaces X 1 , X objects in the same space are related via intra-type relationships R  X  X i  X  X i . Data objects from different spaces are related via inter-considered are similar in nature. S ij (x,y) represents the similarity between object x from space i and object y from space j . R represents the inter-(i=j) or intra-type (i  X  j) relationship from object x in space i to object y in space j , while a and b are any data objects in any data spaces under the condition that x is related to a and y is related to b . Then the similarity reinforcement assumption can be mathematically presented as: ij b a S b y R a x R y x S y x S where  X  and  X  are positive parameters used to adjust (during the reinforcement process) the relative importance of the original similarity of objects x and y with the importance of the similarity reinforced by inter-and intra-type relationships. If we use a set of positive parameters  X  ij to represent the relative importance of similarity reinforced from data space i to data space j , and consider the amount of original similarity value involved in this process as the similarity value reinforced via a special intra-type relationship that leads to the data object itself (indicated in Figure 2), the similarity reinforcement assumption can be represented as: Eq. (4) can be reduced to Eq. (5): ij b a S b y R a x R y x S Considering one data object X  X  related objects in other data spaces as its mappings in those data spaces, the reason the similarity reinforcement process can yield better estimates is that the similarity of two data objects is measured in multiple perspectives (data spaces) instead of a single perspective. However, a pre-condition is that relationships involved are accurate and additive. Thus, care should be taken to avoid involving contradictory or ambiguous types of relationships. Based on the  X  X imilarity reinforcement assumption X , we develop a unified similarity calculation algorithm over a set of heterogeneous data spaces:  X  SimFusion  X . The name indicates that the similarity of two data objects is calculated using evidence from multiple sources (data spaces). It is formally described as: Suppose there are N different spaces being considered, and a URM is developed in a similar way to Eq. (2) to represent the inter-and intra-type relationships as shown in Eq. (6): L Here L i is the intra-type relationship matrix of data space i and L is the inter-type relationship matrix from data space i to data space j . The sum of each row from any of the sub-matrices is normalized to 1. In cases that data object x from space i has no relationship to any data objects in data space j (all the elements in the i th row of the matrix L ij are zero), then each element in the i row of relationship matrix L ij is set to 1/n , where n is the number of elements in space j . This is equivalent to using a random relationship to represent no-relationship. We also define a set of parameters  X  s to adjust the relative importance of different inter-and intra-type relationships, so that for any i , matrix and can be rendered as a single step probability transformation matrix in a Markov Chain [16]. We also define a Unified Similarity Matrix ( USM ), S represent the similarity values of any data object pairs from same or different data spaces at the beginning of the algorithm: Each element s a,b in S usm represents the similarity value between data objects a and b in the unified space. T is the total number of objects in the unified space. Since each data object is always maximally similar to itself, we have s ab =1 if a=b, and 0 a  X  b . S usm is a symmetric matrix since s ab = s ba . We also define that the order of data objects presented in S usm and L urm are similar, that is, if the element l ab in L urm represents the relationship from object value between objects a and b . Having URM and USM defined, the similarity reinforcement assumption can be represented as: Eq. (8) is the basic similarity reinforcement calculation in the SimFusion algorithm. Eq. (8) can be continued in an iterative manner until the calculation converges or a satisfactory result is obtained, as shown in Eq. (9). usm L S L L S L S ) ( 0 1 = = The proof of convergence for Eq. (9) can be found in the appendix of [32]. The proof is based on the convergence proof of the PageRank [3] algorithm, by converting Eq. (9) into a power calculation of a matrix with a vector. It is worthwhile to note that, similar to the PageRank algorithm, the values in the USM after convergence are independent to the initial values in the USM at the beginning of the calculation. In practice, the initial USM is often set to be an identity matrix. It also is important to note that the similarity of a data object to itself (i.e., the values in the calculation in Eq. (9) may not be equal to 1 and even may be smaller than the similarity between two data objects (i.e., values in non-diagonal positions in S n usm ). We argue that the S during the iterative calculation can be interpreted more precisely as the reliability of the similarity evidence rather than as exact similarity values. For example, if a data object (or two data objects) is related to a set of less similar data objects, then the similarity of the data object (or the two data objects) is less reliable when used as evidence to reinforce the similarity of data objects related to it in the next iteration than if the data object (or two data objects) is related to a set of very similar data objects. equal to 1 and may be even smaller than the similarity of some object pairs, as is illustrated in Figure 3: In Figure 3, the white nodes at the bottom represent the objects being considered. The black nodes on the top represent the objects that the white objects relate to. Arrows between two black nodes or two white nodes indicate their degree of similarity through their thickness. Thus, (a) is a high similarity-confidence object, (b) is a weak similarity-confidence object, (c) is a high similarity-confidence object pair, and (d) is a low similarity-confidence pair. The theoretical foundation, and the time/sp ace complexity analysis of the SimFusion algorithm, are discussed below. Two Random Walker Model and Spectral Graph Partition Since L urm can be considered as a single step transition matrix of a Markov Chain, the iterative similarity reinforcement process of Eq. (9) can be explained in a  X  X wo random walker model X . Suppose two random walkers start at two data objects in the unified space and they walk from one object to another, step by step. In each step, each of them would choose the next object to set foot on according to the probability distribution of how the current data is related to other objects as defined in L also can be rendered as an object to object relationship distribution matrix, then the reinforced similarity between the two original objects on which the two walkers started their trip, can be translated into the likelihood that the two walkers meet each other, after each of them walks n steps according to L urm . SimFusion also can be considered as a generic spectral graph partition process. The reasons we do not use other spectral graph partition processes such as [11] [13] are: 1) SimFusion exactly follows the Similarity Reinforcement Assumption; 2) other methods may not scale well. Detailed discussion is found in [32]. Time and Space Complexity The space complexity of the SimFusion algorithm is O(n the total number of objects in the unified space), since we only store the USM . In each step of the reinforcement process, the similarity between two data objects x and y is updated exactly |R(x)|+|R(y)| times, where |R(x)|(|R(y)|) is the number of data objects to which x(y) relates. (Note that all 0 elements in the corresponding columns and rows in the URM and USM can be pre-excluded from the reinforcement calculation.) Suppose d is the average number of objects to which an object relates, then, the time complexity of the SimFusion algorithm is O(Kn 2 d), where K is the number of iterations. In the worst case, where all the data objects are fully connected (therefore d=n ), the time complexity would increase to O(Kn 3 ). However, in most real world scenarios, data objects are sparsely connected to each other and d can be considered as a constant with respect to n . Jeh and Widom proposed the SimRank algorithm [15] in 2002. In SimRank , the similarity of two objects also was measured according to their contextual structure. The theoretical assumption behind the SimRank algorithm is similar to that of the SimFusion algorithm:  X  X he similarity of two data objects can be affected by the similarities of other data objects that the two data objects are related to X . The basic similarity reinforcement calculation used in SimRank is: where s(a,b) is the similarity value between objects a and b ; |R(a)| and |R(b)| are the total number of objects related to objects a and b , respectively. R i (a) represents the i th object related to a . C is a damping factor. If we take all  X  s equal to 1 and average the value of relationships from one object to 1/n ( n is the total number of relationships from the object) in the URM , then Eq. (5) can be reduced to Eq. (10) (where C=1 ). Different from the SimFusion algorithm, which uses matrices to represent object pair-wise similarities and pair-wise relationships, SimRank considered any pair of data objects as the nodes in a general directed graph, and values of any nodes (pairs of data objects) are updated according to Eq. (10). The procedure discussed above is equivalent to flattening the nxn USM in the SimFusion algorithm into a vector of n 2 length, and then updating this vector by iteratively calculating it over a sparse n 2 x n 2 matrix. SimRank also can be modeled as a modified random walker model:  X  X andom Surfer-Pairs Model X . The major differences from SimFusion are: First, the similarity of object pair (a,b) is updated |R(a)|x|R(b)| times during each iteration, which is much more than the number of updates in SimFusion ( |R(a)|+|R(b)| ). The time complexity of SimRank is O(Kn 2 d 2 ) . In the situations where data objects are heavily connected to each other (e.g., smoothing web linkage relationships [3]), the time complexity of the SimRank algorithm would grow to O(Kn 4 ). Second, SimRank assumes that all the relationships are binary, and Eq. (10) can be considered as taking an average of the similarity values of the object pairs that are related to object pair (a,b) . However, this assumption is na X ve and in the real world the relationships among data objects are often unequal (e.g., a user spending more time reading web page A than web page B may indicate the user has a preference for A over B). This kind of prior knowledge can be more easily and efficiently incorporated into the URM in SimFusion . Third, the parameter C in SimRank is the base of the  X  X xpected-f Meeting distance X  function. It is difficult to understand the real world effect of C , and it is difficult to select C by intuition. However, the parameters  X  ij in SimFusion directly reflect the relative importance of different kinds of relationships involved in SimFusion and can be tuned by intuition. SimFusion is more flexible at combining relationships from different sources by providing a set of parameters  X  ij . Fourth, SimFusion can easily be used to model most existing similarity-calculating algorithms (see Section 5.4). However, SimRank only can be used to model a few non-iterative similarity-calculating algorithms (e.g., [27]). A comparison of SimFusion and SimRank algorithms is summarized in Table 2. Simplified versions of SimFusion that only consider one or two types of data objects have been validated through prior studies. For example, consider only one data space, of journal articles, and one type of relationship, the reference relationship between journal articles. Set the initial S usm to be the identity matrix. Eq. (9) reduces to co-citation [27], where the similarity of two articles is determined by the number of articles they both cite. If we only consider reverse reference relationships, Eq. (9) reduces to bibliographic coupling [17], where the similarity of two articles is determined by the number of articles that cite them both. Let us consider the URM in Eq. (2), which represents a document space, term space, and the  X  X ontaining X  relationship of documents to terms. Suppose we have no prior knowledge about similarity of any data objects and set S usm to be the identity matrix. Applying Eq. (9) would result in calculating the pair-wise document similarity and pair-wise term similarity according to the VSM. It remains an interesting problem, whether enriching the URM and USM with some prior knowledge (e.g., thesaurus, or document references relationships) and iteratively reinforcing the similarity, would result in better knowledge of the term similarities, document similarities, and document-term similarities? Recently, researchers have tried to use query-web page relationships to better predict the web object similarities so as to help improve the effectiveness of web-clustering algorithms [22][29]. Their methods for calculating the similarity of web objects also can be well modeled by our SimFusion algorithm. Suppose there are two data spaces: the Web pages space and the query space. The two spaces are modeled in a URM as: L where L query refers to the query content similarity relationship matrix and L webpage refers to the Web page content similarity relationship matrix. If L query-page refers to the query with its corresponding search list relationship, and L usm is the identity URM will result in Raghavan and Sever X  X  work [22], in which they measure the similarity of queries based on corresponding result document lists. If L query-page refers to the web query web page click-through relationship, and S usm is the identity matrix, and all the  X  s remain the same, applying Eq. (9) to this URM will result in Beeferman and Berger X  X  clustering method [1], in which they measure the similarity of queries using the similarity of their clicked web pages and calculate the similarity of web pages using the similarity of the queries that lead to the selection of the web pages. If we define  X  11 &gt;0,  X  22 &gt;0,  X  12 &gt;0 and  X  (9) to this URM would result in Wen X  X  work [29], where query similarity is based on both the query contents similarity and the similarity relationship of the documents that are selected by users who submitted the queries. In this section, we show how SimFusion can be validated on a real world data set. Our experiment is designed around a real user search click-through log collected from a large scale search engine. The log contains 62.5 million query request records with the URLs of the corresponding clicked web pages from a 3 hour period in 2003. The log is formatted in such a way that each query is followed by the URL s of the corresponding clicked web pages and the number of clicks during a period of time, as shown below: We selected the top 10K popular queries in this query log and crawled all the corresponding clicked web pages; we use the top 20K popular web pages in our experiments. Then, we parsed the hyperlinks in the content of the web pages and built a hyperlink graph of the web page collection.  X  The similarity of two queries can be reinforced by the similarity of the web pages they relate to.  X  The similarity of two web pages can be reinforced by the similarity of the queries for which they are retrieved, as well as the similarity of other web pages to which they relate. Thus, the web pages and the queries each form a unique data space. Queries are c onnected to the web pages via click-through relationships (inter-type relationship). Web pages are connected via hyperlinks (intra-type relationship) in the web page space. A URM for our data set can be built as: L  X   X  = (12) where L q is the query inter-type relationship matrix. Since there is no intra-type relationship in the query space, L q identity matrix. L d is the web pages hyperlink adjacency matrix. L and L qd are query click-through relationship matrices that connect queries with the web pages.  X  is a non-negative parameter that adjusts the relative importance of the click-through relationship to the hyperlink relationship during the similarity reinforcement process. Each sub-matrix in Eq. (12) is normalized to a row-stochastic matrix. We use an identity matrix as USM and we apply the SimFusion algorithm on Eq. (12) and Eq. (13) to iteratively calculate the similarities of queries and web pages. The performance of the SimFusion algorithm will be compared with a pure content similarity measurement (i.e., tf*idf ) and the SimRank algorithm. We use Precision to measure the performance of the similarity calculation algorithm: Given an input object, Precision at N is defined as the number of similar data objects identified in the top N objects returned by the algorithm: Ten human experts were hired to manually judge the similarity of objects returned by different algorithms. The final judgment of relevance was decided by majority vote. We set  X  =0.5 and developed the URM as in Eq. (12) and developed USM as in Eq. (13). Then, we iteratively calculated using the SimFusion algorithm until convergence was achieved (9 iterations in our experiment). Randomly selected sets of queries and URLs were used to evaluate the effectiveness of the SimFusion algorithm. The results are reported below. Since it is difficult to evaluate the similarity of single word queries to other queries, we randomly chose 30 multi-word queries from the query log. We computed the precision at top 10 queries returned by the SimFusion , SimRank, and tf*idf algorithms, for each of the 30 queries. Then, we compared the average precision at 10 for the three algorithms. The results are: The table shows that SimFusion achieves a 13.6% improvement over SimRank and a 67% improvement over the tf*idf algorithm in terms of precision at 10. A query-by-query breakdown analysis of SimFusion over SimRank is presented in Figure 4. The vertical axis indicates the percentage of improvement of SimFusion over SimRank . It shows that in the 30 queries being analyzed, SimFusion outperformed SimRank in 14 queries, and was only slightly worse than SimRank in 6 queries. A t-test (2-tailed) for matched pairs showed that this improvement of SimFusion over SimRank is significant at the  X  =0.009 level. Figure 4: Query Breakdown for SimFusion vs. SimRank To further validate our algorithm, we randomly selected another set of 20 multi-word queries and evaluated the results returned by SimFusion, SimRank, and tf*idf. The results again show that SimFusion is almost 12% better than SimRank with significance level  X  =0.03, and 80% better than tf*idf , with significance level  X  =0.00002 . A detailed report on the query sets and corresponding results in our experiments can be found in [32]. Consider a case study, analyzing the top similar queries returned for the query  X  X izza hut X  by different algorithms (Table 3): Bold font cells indicate similar queries. The tf*idf results are not best since they only reflect similarities in content (e.g.,  X  X izza X ). SimRank does not achieve best performance either because it returns too many semantically  X  X arginal X  relevant queries (e.g., kfc, taco bell, burger king). SimFusion acts as a combination of the other two algorithms and can achieve best performance by returning both content similar (e.g., dominos pizza) and semantically similar (e.g., papa johns, dominos) queries. We also analyze how the number of iterations can affect the performance of the SimFusion algorithm. We evaluate the precision of SimFusion at each iteration (1 to 9), and draw the precision vs. iteration curve in Figure 5. We see that SimFusion improves the precision faster at the initial iterations than at the latter iterations. Similar findings have been reported in [15]. We use the metric of Section 6.2 to evaluate the performance of SimFusion on web pages. We randomly chose 10 web pages from the log. For each of them we compare the similarity of the top 10 web pages returned by SimFusion , SimRank, and tf*idf . Precision We found that the average precision for SimFusion (0.67) is 71% better than SimRank (0.39) and 29% better than tf*idf (0.52). A 2-tailed t-test shows that improvement is significant at  X  =0.005 versus both SimRank and tf*idf . A detailed page-by-page comparison of the three algorithms is shown in Figure 6. Further information can be found in [32]. Figure 6: SimFusion vs. SimRank on web page similarities To further validate our algorithm, we randomly selected another set of 10 web pages and evaluated the similar web pages returned by SimFusion , SimRank, and tf*idf. The results again show that the performance of SimFusion (0.64) is 110% better than SimRank (0.3), with significance level  X  =0.003, and is 64% better than tf*idf (0.39), with significance level  X  =0.006 (2 tailed t-tests). We also conducted a case study (see Table 4) by analyzing the top similar web pages for  X  X ttp://www.tvguide.com X , as returned by two algorithms. Bold font cells indicate similar web pages. We see that SimFusion has returned one more semantically similar web page (e.g., http://tvlistings2.zap2it.com) than tf*idf while keeping other content similar web pages. On the other hand tf*idf returns some non-similar web pages on top (e.g., www.nbc.com), since that sites X  topmost dynamic page just happened to advertise the same TV shows as the target page, at the time we crawled the web pages. We investigated how different values of  X  defined in Eq. (12) can affect the performance of the SimFusion algorithm. We chose 10  X  values from 0 to 1, at intervals of 0.1, and evaluated the performance of SimFusion on finding similar queries at each  X  value. Figure 7 illustrates the resulting performance curve. We see that the SimFusion algorithm achieves best performance when  X  =0.3, which indicates that the query web page click-through relationship is more important than the content similarity of queries, when used to calculate the similarity of different queries. When analyzing the data, we also found that different queries find their most similar queries at different  X  values. Might it be possible to automatically determine a set of parameters for each data object being considered in the URM ? Average precision In this paper, we introduce the Unified Relationship Matrix ( URM ) to represent heterogeneous data objects and their relationships in a unified manner. We addressed the information integration problem by showing how different relationships can be used to improve the similarity measurement of data objects. Next, we introduced the SimFusion algorithm. By iteratively computing over the URM , the SimFusion algorithm can effectively integrate relationships from multiple sources to measure the similarity of data objects. Experiments based on real world data demonstrate that the SimFusion algorithm can significantly improve the similarity measurement of data objects over both the traditional content-based algorithms and the cutting edge SimRank algorithm. In the future, we plan to use machine-learning technologies to automatically optimize the parameters used in SimFusion . We also will try to improve the efficiency of SimFusion so that it can be easily applied to large-scale mining applications (e.g., MapReduce [9]). The authors from Virginia Tech would acknowledge the NSF funding support under grants DUE-0435059, 0333531, and 0121679, and under IIS-0307867 and 0325579. The authors would also thank Baoping Zhang, Ming Luo, Rao Shen and other members from Digital Library Research Lab of Virginia Tech for their helpful comments and insightful suggestions during various discussions. [1] D. Beeferman and A. Berger.  X  X gglomerative clustering of a [2] T. L. Brauen,  X  X ocument Vector Modification X , in The [3] S. Brin and L. Page, The Anatomy of a Large-Scale [4] V. Bush,  X  X s We May Think X , The Atlantic Monthly , vol. [5] P. Calado and B. Ribeiro-Neto,  X  X n Information Retrieval [6] S. Chakrabarti, B.E. Dom, S.R. Kumar, P. Raghavan, S. [7] G. Das, H. Mannila, P. Ronkainen,  X  X imilarity of attributes [8] B. D. Davison,  X  X oward a unification of text and link [9] J. Dean and S. Ghemawat,  X  MapReduce: Simplified Data [10] J. Dean and M.R. Henzinger.  X  X inding Related Pages in the [11] S. T. Dumais, G. W. Furnas, T. K. Landauer, S. Deerwester, [12] N. Fuhr and T. Rolleke,  X  X  Probabilistic Relational Algebra [13] D. Gibson, J. Kleinberg, and P. Ragavan,  X  X lustering [14] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl, [15] J. Jeh and J. Widom.  X  X imRank: a measure of structural-[16] O. Kallenberg, Foundations of Modern Probability. New [17] M. M. Kessler. Bibliographic coupling between scientific [18] J.M. Kleinberg,  X  X uthoritative Sources in a Hyperlinked [19] R.R. Larson.  X  X ibliometrics of the World-Wide Web: An [20] N. Liu et al.  X  X  similarity reinforcement algorithm for [21] A. Popescul, G. Flake, S. Lawrence, L.H. Ungar, and C.L. [22] V.V. Raghavan and H. Sever.  X  X n the reuse of past optimal [23] P. Resnick, and H. R. Varian,  X  X ecommender Systems X  [24] B. Ribeiro-Neto and R. Muntz,  X  X  Belief Network Model for [25] J.J. Rocchio. Relevance feedback in information retrieval. In [26] G. Salton, Automatic Information Organization and [27] H. Small. Co-citation in the scientific literature: A new [28] H. Turtle and W. B. Croft,  X  X nference networks for document [29] J.-R.Wen, J.-Y. Nie, and H.-J. Zhang,  X  X uery Clustering [30] S. K. M. Wong, W. Ziarko, V. V. Raghavan, and P. C. N. [31] W. Xi, et al.,  X  Link Fusion: A Unified Link Analysis [32] W. Xi, B. Zhang and E. A. Fox  X  X imFusion, A Unified [33] G. Xue, et al.,  X  X RSSA: An Iterative Algorithm for 
