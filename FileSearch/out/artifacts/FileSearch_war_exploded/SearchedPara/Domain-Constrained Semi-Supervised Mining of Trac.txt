 Accurate localization of mobile objects is a major research prob-lem in sensor networks and an important data mining application. Specifically, the localization problem is to determine the location of a client device accurately given the radio signal strength values re-ceived at the client device from multiple beacon sensors or access points. Conventional data mining and machine learning methods can be applied to solve this problem. However, all of them re-quire large amounts of labeled training data, which can be quite ex-pensive. In this paper, we propose a probabilistic semi-supervised learning approach to reduce the calibration effort and increase the tracking accuracy. Our method is based on semi-supervised condi-tional random fields which can enhance the learned model from a small set of training data with abundant unlabeled data effec-tively. To make our method more efficient, we exploit a Gener-alized EM algorithm coupled with domain constraints . We vali-date our method through extensive experiments in a real sensor net-work using Crossbow MICA2 sensors. The results demonstrate the advantages of methods compared to other state-of-the-art object-tracking algorithms.
 I.2.6 [ Artificial Intelligence ]: Learning; H.2.8 [ Database Man-agement ]: Database Applications X  Data mining Algorithms Localization, Calibration, Tracking, Sensor Networks, EM, CRF
Recently, wireless sensor networks have attracted great interests in several related research fields and industries. Many tasks such as context-aware computing [4] and environmental monitoring can be realized with the help of wireless sensor networks, which offer Copyright 2007 ACM 978-1-59593-609-7/07/0008 ... $ 5.00. unique advantages of being lightweight, distributed, environment-aware and network-based. Object tracking, event-detection and activity recognition can now be realized in sensor networks us-ing probabilistic algorithms[7, 11]. It is a fundamental task for many of these applications to locate mobile client devices using collected wireless signals (in terms of radio-signal-strength, RSS, values) from different sensor nodes that act as beacons.
In the past, some conventional data mining technologies have been applied for solving the localization problem [7, 9]. Gener-ally, some statistical models are obtained offline which can map signals to locations. These models are then used online to predict the client locations based on the real-time signal values. Among the past works, many researchers have developed ranging-based al-gorithms for localizing mobile nodes in a wireless sensor network. steps. It first transforms the sensor readings into a distance mea-sure. It then attempts to recover the coordinate locations in terms of relative distance to the beacon nodes. This approach relies on an ideal signal propagation model and extensive hardware support. It suffers from low accuracy problem since RSSs do not follow ideal propagation patterns, especially in complex environments.
In this paper, we address this problem using a semi-supervised statistical relational learning approach based on conditional random fields (Semi-CRF). We assume that a mobile sensor node moves in a sensor network environment. The RSS of the mobile node can be received by several sensors in the network, which are then forwarded to a processor for tracking. It can also happens in the way that all sensors in the network are sending signals to the mobile sensor node, which performs the localization itself. In either case, we have a sequence of multi-dimensional vectors that corresponds to a trace. Each vector along the trace can be labeled with a physical location coordinate, or unlabelled.

This paper makes the following contributions. First, we iden-tify and solve a major bottleneck in the application of data mining technologies in sensor networks. Second, we present a novel semi-supervised learning method for mobile-node tracking and localiza-tion by utilizing both labeled and unlabelled RSS trace data. Third, we introduce domain-driven heuristics for reducing the complexity of the learning procedure, which greatly improve the scalability of the statistical models. Finally, we validate the proposed methods through the experiments over a real sensor network. Consider a two-dimensional tracking problem. Our objective is to determine the location of a mobile object y t =( u t ,v as it moves in a sequence, given the observed signal vectors Figure 3 shows an example of the floor in one of our experimental test beds, which consists of N =8 beacon nodes and one mobile unknown node. The localization problem can be converted to a su-pervised classification problem if we had sufficient labeled data for each location. However, when the labeled data are insufficient at each location, we wish to make the best use of some partially la-belled or totally unlabeled RSS sequences as well in our prediction. Now let us formally introduce the notation of training data. In our study, the training data consist of a set of fully la-belled sequences D f = { ( X 1 ,Y 1 ) ,..., ( X M ,Y M ) } set of partially labeled (or totally unlabeled) sequences D { of signal vectors x i 1 ,..., x im i , i =1 ,...,M + L ,and Y quence of corresponding locations y i 1 ,...,y im i , i =1 ,...,M + L . Some values of y ij are unknown for M +1 i M + L .A mobile robot can be employed to collect these unlabelled data by simply wandering around.
In this paper, we propose a statistical relational learning ap-proach using CRF to exploit the relationship between RSS read-ings at two neighboring time points in terms of their corresponding physical distance. As a mobile object moves around, a sequence of RSS values can be received, with each corresponding to a certain location. This process can be modeled by an 1-D Linear-chain CRF as introduced in the following section, where the states correspond to the location labels and the inputs or observations correspond to the RSS readings.

Linear-chain CRF models have been widely used to model sequential data. These models can be roughly viewed as conditionally-trained finite state machines [5]. A linear-chain CRF, as shown in Figure 1, defines a distribution over state sequence y = y 1 ,y 2 ,...,y T given an input sequence x = x 1 ,x 2 ,...,x by making a first-order Markov assumption on states, where T is the length of the sequence. These Markov assumptions imply that the distribution over sequences factorizes in terms of potential func-tions  X  t ( y t  X  1 ,y t , x ) as: where the partition function Z ( x ) is the normalization constant that makes the probability of all state sequences sum to one. It is defined as follows: The potential functions  X  t ( y t  X  1 ,y t , x ) can be interpreted as the cost of making a transition from state y t  X  1 to state y similar to a transition probability in an HMM.

Computing the partition function Z ( x ) requires summing over the exponentially many possible state sequences y . By exploiting the Markov assumption, however, Z ( x ) (as well as the node mar-ginal p ( y t | x ) and the Viterbi labeling) can be calculated efficiently by variants of the standard dynamic programming algorithms used in HMM.

We assume that potentials factorize themselves according to a set of features f k that are given and fixed, so that The model parameters are a set of real weights  X = {  X  k } for each feature (to be defined below). The feature functions can describe any aspect of a transition from y t  X  1 to y t as well as y the global characteristics of x . For example, f k may have value 1 when the distance between y t  X  1 and y t is smaller than 50 cm .
The parameters  X  can be estimated through a maximum likeli-hood procedure using the training data. That is, we can estimate them by maximizing the conditional log-likelihood of the labeled sequences in the training data  X = { ( X 1 ,Y 1 ) ,..., ( X which is defined as: where M is the number of sequences. As discussed in Sutton et al. in [10], L ( X ) is concave in light of the convexity of the kind of functions g ( x )=log
Given the conditional probability of the state sequence defined by a CRF in Equation (1) and the parameters  X  , the most probable labeling sequence can be obtained as which can be efficiently calculated using the Viterbi algorithm [8]. The marginal probability of states at each position in the sequence can be computed by a dynamic programming inference procedure similar to the forward-backward procedure for HMM [3]. We can define the  X  X orward values X   X  t ( y | x ) by setting  X  1 ( y the probability of starting with state y and then iterate as follows: where  X  t ( y ,y, x ) is defined by: Then Z ( x ) equals to  X  ( y | x ) can be defined similarly. After that, we calculate the marginal probability of each location given the observed signal sequence:
So far, we have introduced a linear-chain CRF model for un-known mobile-node tracking. We can see that f k ( y t  X  1 Equation (3)) is an arbitrary feature function over the entire ob-served sequences and the states at positions t and t  X  1 . In our problem, the locations are two-dimensional continuous values. The number of possible locations are infinite large. Therefore, it is ex-tremely difficult to compute the feature of two arbitrary locations.
Fortunately, the tracking area is known in advance usually. One solution is to discretize a 2-D location space into grids. For in-stance, in a 5 m  X  4 m area, we can divide it into 10  X  8 grids with each grid being 50  X  50 cm 2 . This example is shown in Figure 2. In this way, we can convert the known locations into such grids. In the test phase, if a mobile object is located at grid g i the coordinates of the center point in g i to represent the location of the mobile object. After limiting the location space, it is possible to use the linear-chain CRF approach for tracking problem. However, a major issue is how to determine the size of the grid. This prob-lem can be solved in two ways. First, the size often is determined by the nature of the problem itself, which is decided by the preci-sion requirement posed by application users. Another approach is to study the problem empirically, as we will do in the experimental section.
After reducing locations to grids, we can specialize the feature functions for each possible transition among different grids. That is, we can define f k ( y t  X  1 = g, y t = h, x ) by f ( g,h However, the number of the transition feature functions, as well as the corresponding parameters, reaches n 2 ( n is the number of grids), which can be quite large. For instance, in the above ex-ample in Figure 2, n =80 , then in the CRF learning, we need to estimate 6400 parameters for the potential f k ( y t  X  1 though we can still estimate the values of the parameters with large n , it will certainly increase the computational cost and run the risk of overfitting. What is worse, learning CRF with more parame-ters requires more training data, which will increase the labelling costs. In addition, we also need to trade off the complexity of the model and its generalization capability. If we increase the grid size to reduce the computational cost, we will sacrifice the estimation accuracy.

In this paper, we incorporate the domain constraints in the data mining process to reduce the number of parameters that need be learned. In particular, we note that a mobile object in a sensor net-work typically moves around in the same way, such that the like-lihood of transiting between two neighboring points are roughly same. The likelihood of traveling between two distant points will also be roughly the same, although the value will be much smaller. Such a domain constraint is supported by our experiments.
To incorporate the domain constraints mentioned above, we use a so-called parameter tying technique that is designed for speech recognition [6] to combine similar parameters. Our assumption is that the characteristics of two transitions with the same distance are alike. Intuitively, in Figure 2, we observe that the transitions g g and g 8  X  g 9 should happen with similar frequencies as they both transit by one grid in terms of Euclidean distance. Similarly, the transitions g 24  X  g 35 and g 35  X  g 46 should happen similarly as the their Euclidean distances are both
From this observation, we can tie the parameters of the tran-sition feature functions so long as they have the same transition distance, which is defined as follows: The value of the transi-tion feature function f k ( y t  X  1 ,y t , x ) equals one if and only if dis ( y t  X  1 ,y t )= k , where the dis defines the distance between the two points. As expected, the number of parameters is greatly re-duced by using this constraint.
In this section, we introduce how to incorporate sequences whose labels are fully or partially observed in the parameter estimation of CRF.

An efficient method for parameter estimation with incomplete data can be derived by the extension of EM algorithm [2]. In this paper, we use a Generalized Expectation Maximization (GEM) al-gorithm to learn the parameters  X  of CRF with both fully and par-tially observed data [1]. In the GEM algorithm, the probabilistic optimization problem is divided into two-step iterations. The un-observed data are estimated in the E-step with the parameters ob-tained in the last iteration and the parameters of CRF are optimized in the M-step. We first compute the log likelihood of Equation (4) with expectation over the unobserved data as follows: In this equation, Y ( u ) i is the unobserved locations of the i -th se-quence, Y ( o ) i is the observed counterpart, and
Similar to Equation (4), L ( X ;  X  t ) is also concave. We can use the same method to optimize it. The only problem left is how to infer for partially observed sequences. We need to change Equa-tions (6) and (8) for some cases. If y t = j is observed, we directly values of  X  t and  X  t .If y t is not observed, we follow Equations (6) and (8). The new inference formulae are summarized in Equations (10) to (12).  X  ( y = j | x )=  X  ( y = j | x )=
We now summarize the Semi-CRF learning algorithm in Table 1. There are several ways of parameter initialization. The common one is to randomly assign them values from 0 to 1 . To speed up the convergence, we use an alternative that preliminarily estimates parameters with labeled data. As to the number of iterations, we will discuss it in the experimental section.
 Table 1: The training algorithm for CRF with both fully and partially observed data.
 Algorithm Semi-CRF Input: The fully and partially observed data D f , D p Output: The parameters  X  of CRF Initialize parameters  X  0 of CRF.
 while log-likelihood has not converged or the max number of iterations is not reached, do endwhile return  X 
We test the effectiveness and robustness of our location track-ing algorithm for mobile sensor nodes in a sensor network based on the RSS signals. Our experiments are performed in the Perva-sive Computing Laboratory (Figure 3) in the Department of Com-puter Science and Engineering at Hong Kong University of Sci-ence and Technology. The room is large enough for us to set up an experimental test-bed of 5.0 meters by 4.0 meters. In Figure 3, |
P 1 P 3 | = | P 4 P 6 | =5 . 0 m and | P 1 P 4 | = | P 3 P 6 are three main components of our setup: We use two performance measurements to evaluate the original CRF and the CRF model using parameter tying (denoted by CRF-PT) localization algorithms. The first metric is the mean error-distance values between estimated and true locations. The second measurement is the accuracy in percentage. Given an error-distance threshold  X  , the accuracy rate is the probability that the distance be-tween the estimated and true locations is smaller than  X  . Two more baselines in our experiments include (1) Logistic Regression (LR), (2) Support Vector Regression (SVR). We control a mobile robot to run and stop around the test area (Figure 3) for collecting data with sampling interval 0 . 5 s . The data set formed a trace of length about 600 m with 3 , 000 examples. For every experiment below, we randomly select a subset of the data as fully observed training data, a subset of data as partially observed training data by ran-domly removing the locations associated with them, and evaluate the performance on the rest. To reduce the statistical variability, we repeated the experiments for 30 times and reported the average results.
One question about the the Semi-CRF algorithm is the conver-gence of the EM iterations. In this experiment, we use 10 fully labelled and 50 partially labelled sequential data to train the CRF, where the length of each sequence is 5 and only one node is labelled in the partially labelled data. Figure 4 shows the convergence rate of Semi-CRF. We can see that about 4 iterations are enough. In the experiments of this paper, the maximum number of iterations of the Semi-CRF is set to 10 .
In the following experiments, we fix the training data size at 550 , and tune the ratio of the labelled data from 0 . 33 to 1 . In Figure 5, we show the mean error performance of the four algorithms de-scribed above. As can be seen, Semi-CRF consistently outperforms the other algorithms in terms of mean error distance, while CRF beats the remaining two baselines. One important reason is they both effectively leverage the sequential information of the mobile node. Moreover, as Semi-CRF can also learn from the unlabelled data, it gains much better performance when there are a lot of such data with a small portion of labelled ones. We list some more infor-mation of these experiments including the accuracy performance in Table 2.
The grid size may affect the performance of the localization al-gorithms. In this experiment, we fix the ratio of labelled data at 5% and vary the side length of the grids from 10 cm to 100 cm . Fig-ure 6 shows the experimental results of CRF and Semi-CRF . From the figure we can see that when the grid size ranges from 20 cm to 50 cm , the performance of both the two methods is less sensitive than that with the grid size of 10 cm and 100 cm .
Figure 6: Vary the grid size (ratio of labelled data is 5% .)
We have presented a new approach to reducing the calibration effort when tracking mobile sensor nodes in a wireless sensor net-work. Our approach made extensive use of the sequential informa-tion of moving sensor X  X  trajectory. These sequences provided unla-belled examples which can be used to train CRF together with the manually labelled RSS values. We introduce a Semi-CRF model to utilize such partially labelled data. By using parameter tying techniques we significantly improve the performance of Semi-CRF algorithm while reducing calibration effort. A sensor network was set up based on Crossbow MICA2 and MICA2Dot nodes which are used as both beacon and mobile nodes. Experimental results showed that the proposed method could achieve a better perfor-mance with relatively fewer number of labelled examples.
In the future, we plan to continue to test the Semi-CRF based framework in a large scale sensor network. We are also interested in introducing different factors, such as changing time and space, to see how the knowledge learned in one setting can be applied to another. [1] H. L. Chieu, , S. W. Lee, and P. K. Leslie. Activity [2] A. P. Dempster, N. M. Laird, and D. Rubin. Maximum [3] J. Lafferty, A. McCallum, and F. Pereira. Conditional [4] J. Lester, T. Choudhury, N. Kern, G. Borriello, and [5] A. McCallum. Efficiently inducing features of conditional [6] C. Neukirchen, D. Willett, and G. Rigoll. Soft State-Tying [7] X. Nguyen, M. I. Jordan, and B. Sinopoli. A kernel-based [8] L. R. Rabiner. A tutorial on hidden markov models and [9] A. Savvides, C. Han, and M. B. Strivastava. Dynamic [10] C. Sutton and A. McCallum. An introduction to conditional [11] J. Yin, X. Chai, and Q. Yang. High-level goal recognition in
