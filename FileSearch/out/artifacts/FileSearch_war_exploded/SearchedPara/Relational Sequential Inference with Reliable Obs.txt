 Alan Fern afern@purdue.edu Robert Givan givan@purdue.edu School of Electrical and Computer Engineering, Purdue University We consider processes with hidden state that pro-duce sequences of noisy observations. By watching the observations, our task is to infer the underlying state sequence of the process. We are interested in problems with enormous numbers of possible states and observations that are re presented in relationally factored form (with sets o f relational atoms such as ON(block 1 , block 2 )). In such large problems, general-purpose modeling approaches that fail to make strong structural assumptions are typically intractable. In place of more familiar independence assumptions (e.g. Markov modeling), our inference approach ex-ploits an assumption that the process generates  X  X e-liable X  observations. By this we mean that hidden states persist for multiple observations, and that the sequence of observations generated while remaining in a single hidden state reliably determines the state X  i.e. no other hidden state is likely to generate that sequence of observations. The assumption of reli-able observations appears to hold well in our video-interpretation domain. Many video frames pass while the underlying interpretation remains fixed, and we are able to infer (using a  X  X tate inference function X ) that underlying interpretation from the sequence of frames. We introduce the idea of using a state-inference func-tion to represent process knowledge. We provide an efficient sequential-inferenc e algorithm that is correct, assuming reliable observations and a correct state-inference function. Our inference method is not tied to a particular representation of states, observations, or state-inference function. Thus, we first describe the problem setup (Section 2) and inference method (Section 3) for arbitrary sets of observations and states. When these sets are relationally represented, our method provides general-purpose, relational, se-quential inference, given reliable observations. Although our inference technique is independent of the representation, representation is relevant because the required state-inference function is generally unavail-able and must be learned automatically. To facilitate learning, the states and observations must be repre-sented in some factored form, and below we describe a familiar general relational representation (in Section 4). We then describe a logic-based representation for relational state-inference functions and provide a cor-responding supervised learning algorithm (in Section 5). Finally, we give promising experimental results for that relational representation (in Section 6) in our noisy video-interpretation application.
 We note that probabilistic modeling is a popular ap-proach to dealing with noisy problems such as ours; however, here we do not use probabilistic methods. As discussed in Section 7, applying probabilistic modeling work to our setting presents a number of challenges. Here, we present a simple, logical-constraint-based ap-proach with good robustness to noise. A sequential process is a triple P =( O , S , D ), where the observation space O and state space S are ar-bitrary disjoint sets that contain all possible obser-vations and states, respectively. D is a probability distribution over ( O X S )  X  , i.e. the space of finite se-quences constructed from members of O X S .Wecan extract from each such sequence a pair of an obser-vation sequence (o-sequence) and a state sequence (s-sequence) , and we often treat P as assigning proba-bilities to such pairs according to D .Wesaystate s generates o-sequence o 1 ,...,o k in state-observation sequence P ,if( s, o 1 ) ,..., ( s, o k ) is a subsequence of P , and also that o 1 ,...,o k is generated by consecutive states s 1 and s 2 in sequence P if, for some t ,these-quence ( s 1 ,o 1 ) ,..., ( s 1 ,o t ) , ( s 2 ,o t +1 ) ,..., ( s subsequence of P .
 Sequential inference is the problem of mapping an o-sequence to the most likely hidden s-sequence. In our large structured problems, the o-sequence typically de-termines the s-sequence, so we simplify this goal to finding the single possible s-sequence. Here, we do not require a model of P , rather we use supervised learn-ing, needing only to sample a training set of sequences of state/observation pairs from P .
 Our method leverages an assumption that hidden states persist for many observation steps. We also assume that the utility of an inferred state se-quence primarily derives from the sequence of dis-tinct states (with consecutive repetitions removed), rather than whether it also i dentifies the exact state-transition points. This assumption holds in our video-interpretation domain, where the exact locations of transition points are often ambiguous (as judged by a human) and unimportant. For example, in Figure 1, it will typically be unimportant exactly which frame is considered to be the transition. Thus, we consider a state-sequence label to be accurate if it agrees on the sequence of distinct states. Let Compress ( S ) denote the sequence that is derived from S by re-moving its consecutive repetitions. For example, Compress ( S ) to be an accurate label for sequence S . Example 1. In our experimental video-interpretation domain, the process corresponds to a hand playing with a set of blocks. Figure 1 shows key video frames from a sequence where the hand picks up a red block from a green block. Our goal is to ob-serve the video and infer the underlying force-dynamic states, describing the support relations among the objects. The figure caption describes the single state transition. States are represented as sets of force-dynamic facts, such as Attached ( hand , red ) . Observations are represented as sets of low-level numeric facts, such as Distance ( green , red , 3) , that are easily derived from an object tracker X  X  noisy output (shown by the polygons in the figure). The state and observation sets are large, with roughly 2 35 states for a three-block scene with one hand. A simple approach to sequential inference is to assume that each observation deter mines the state generating it. We could then use training data to learn a possibly non-trivial observation-state mapping that can recon-struct a hidden s-sequence from a given o-sequence. However, this assumption is quite strong, and, empir-ically, does not hold in our video-interpretation do-main, due to noise and natural ambiguity near force-dynamic transitions. Instead, we make a much weaker assumption sufficient for robust performance: we as-sume reliable observations, as defined below. Definition 1 (Defining Sequence). For process P ,ano-sequence O is a defining sequence for state s if: (1) s generates O in some sequence drawn from P , and (2) no other state generates O in any sequence drawn from P .
 Definition 2 (Reliable Observations). Process P has reliable observations with redundancy r if, in each sequence drawn from P , each state s generates an observation sequence that can be divided into at least r consecutive defining sequences for s .
 Let RO r denote the set of processes having reliable ob-servations with redundancy at least r .Intuitively,for processes in RO r , each state persists long enough so that it can generate an o-sequence that can be divided into r (or more) sequences that each let us identify the state. Later we show that our inference technique is correct for processes in RO 2 . In practice, processes with rare violations of this assumption also admit our techniques. The reliable observations assumption is intuitively nearly met by ou r video-interpretation do-main and many others, wher esemanticsceneproper-ties persist for enough video frames to be inferred. Reliable observations (with redundancy at least 1) im-ply that the maximal-length observation sequence gen-erated by a state, any time that state occurs, cannot be generated by any other state. Thus, under reliable ob-servations, there exists a mapping from  X  X ong enough X  o-sequences generated by single states to the unique states likely to generate them. A state-inference func-tion  X  is, then, a mapping from O  X  to S X  X  X } .Wesay that  X  is correct if, for each O  X  X   X  ,  X  ( O ) is a state ca-pable of generating O under P ,and  X  ( O )=  X  exactly when no single state is capable of generating O under P . Our inference algorithm assumes we have a nearly correct state-inference func tion (particularly, correct for  X  X ong enough X  observation sequences), which we provide for our application by machine learning (see Section 5). A state-inference function is monotone if it returns  X  for a sequence whenever it returns  X  for any subsequence. It is easy to show that a correct state-inference function is always monotone.
 Given an o-sequence O , if we are somehow told which subsequences of O were generated by single states, then we can apply a correct state-inference function to each such subsequence to correctly infer the underly-ing s-sequence. However, in practice, we are not given this information. Nevertheless, under reliable observa-tions we are able to infer this subsequence information with sufficient accuracy by detecting state transitions. To see how, note that, by definition, no single state can generate an o-sequence that contains defining se-quences for two distinct states. This implies that a correct state-inference func tion  X  X etects transitions X  by returning  X  on a  X  X ong enough X  o-sequence gener-ated by consecutive states X  X  n particular, long enough to include a defining sequence from each state. This property leads to a greedy algorithm for constructing a compressed s-sequence.
 The forward-greedy-merge (FGM) algorithm, Fig-ure 2, applies a state-inference function  X  to increas-ing prefixes of o-sequence O , until locating the short-est prefix o 1 ,...,o k for which  X  ( o 1 ,...,o k )is  X  .For correct  X  ,and O drawn from P , k  X  2. If k =1, then o 1 has been incorrectly labeled  X  X mpossible X , and the algorithm returns  X  X ail X . Otherwise, FGM adds FGM( O,  X  )  X  ( o 1 ,...,o k  X  1 ) to the inferred s-sequence and recur-sively processes the remaining suffix of O .Thenum-ber of calls to  X  is linear in | O | . In our application,  X  runs in poly-time in its input size, and thus the overall inference process is poly-time.
 In practice, we handle the case that FGM returns  X  X ail X  due to an incorrect  X  by pre-processing the ob-servation sequence to remove all single observations identified incorrectly as  X  X mpossible X  by  X  .Thatis, since each individual observation must be generated by some state, we know that  X  is incorrect for an indi-vidual observation if it returns  X  given just that obser-vation (perhaps due to extreme noise). We simply re-move all such observations. We give empirical results with and without this sequence-cleaning preprocess-ing , showing that very few observations are removed, but that such removal improves performance.
 Example 2. The FGM algorithm is inspired by imagining a viewer watching a noisy video very slowly, analyzing each frame consciously. Any given frame may not provide enough information to reconstruct the scene semantics (the hidden state). Each new frame provides more information about the scene, which the viewer adds to the saved partial knowledge. Only when something contradictory to the currently inferred scene is noticed does the viewer assume that a state transi-tion has occurred. At that point, whatever has been inferred about the previous  X  X urrent state X  is taken to completely describe that state.
 FGM is not guaranteed to be correct for all processes in RO 1 . However, for processes in RO 2 ,FGMcan detect state transitions a ccurately enough to correctly infer the underlying compressed state sequence. 1 Proposition 1. Let process P be in RO 2 and  X  be a correct state-inference function for P . For any state and observation sequences S and O drawn together from P ,FGM ( O,  X  ) returns Compress ( S ) . Proof : (Sketch) Let Compress ( S )= s 1 ,s 2 ,...,s n and O i denote the maximal o-sequence in O that was generated by s i (assume w.l.o.g. that no two s i are the same state). Note that O = O 1 ; O 2 ;  X  X  X  ; O n ,where X ; X  indicates concatenation. Since P has a redundancy of at least two, each O i can be written O i = O i ; O i , where O i and O i are both defining sequences for state s i . To complete the proof, prove by induction on k that, for 1  X  k  X  n ,FGM( O 1 ;  X  X  X  ; O k , X  )= s ,s 2 ,...,s k and s k was  X  X roduced X  by applying  X  (in the last line of FGM in Figure 2) to a suffix of O k that includes O k . The key proof step notes that applying  X  to such a suffix, with O k +1 concatenated on the end, yields  X  . Thus, state transitions will be detected. Without reliable observa tions or a correct state-inference function, FGM is not guaranteed correct. However, FGM does solves an intuitively appealing optimization problem, finding a state sequence allowed by  X  with the fewest possible state transitions. More formally, a partition of an o-sequence O is a sequence ( Q 1 ,...,Q k ) of non-empty subsequences of O such that Q 1 ;  X  X  X  ; Q k = O .Wesaythat  X  allows a state sequence S for O if S =(  X  ( Q 1 ) ,..., X  ( Q k )) for some partition ( Q 1 ,...,Q k )of O . We prefer fewer tran-sitions both because we have an inertial bias and be-cause longer o-sequences yiel d more reliable state infer-ence (we assumed  X  is correct for  X  X ong  X  o-sequences). Proposition 2. When  X  is monotone, FGM ( O,  X  ) is a minimal-length state sequence allowed by  X  for O , or there is no allowed state sequence.
 Proof : (Sketch) Prove, by induction on | O | ,thatfor any observation sequence O ,withsuffix O ,anystate sequence allowed by  X  for O is at least as long as FGM( O,  X  ). Finally, we note that our technique does not yet reason about connections between di stinct, adjacent states, beyond detecting transitions. Proposition 1 tells us that such reasoning is not necessary in the presence of reliable observations and a correct state-inference function. We also show, empirically, that such rea-soning is not needed in our domain. Reasoning about likely transitions is a possible extension to our tech-nique that may be required in other domains. We say that a process ( O , S , P )is relational when O and S are given by specifying a domain set of objects D , a set of observation predicates R o , and a set of state predicates R s .An observation fact ( state fact )isa predicate symbol in R o ( R s ) applied to the appropriate number of objects from D . For example, a state fact might be ON( a, b ) where  X  X n X  is in R s and a and b are objects in D . Observations are taken to be finite sets of observation facts and O contains all such sets, likewise the states are taken to be finite sets of state facts with S containing all such sets.
 Example 3. Our video-interpretation application involves inferring the sequence of force-dynamic states in videos of a hand playing with blocks. The do-main of objects D , contains all hands and blocks that may eventually enter the visual field, along with the real numbers. To describe the state and observation spaces, there are three force-dynamic state predicates 2 and eight observation predicates, shown in Table 1. The movie in Figure 1 contains two distinct force-dynamic states given by the state-fact sets shown in the caption. 3 The object tracker places convex polygons around each object in the visual field, and the observa-tions are low-level numeric features of these polygons and polygon pairs. For each video frame, an observa-tion is the set of observation facts calculated by com-puting the numeric argument of each predicate for all objects and object pairs. For relational processes, a state-inference function maps relational o-sequences to relational states (or  X  ). Learning such a function corresponds to the diffi-cult problem of multiple-pr edicate learning (De Raedt et al., 1993) from the area of inductive logic program-ming (ILP) (Muggleton &amp; De Raedt, 1994). In or-der to achieve robust and  X  X xample efficient X  learn-ing, below we introduce a representation for relational state-inference functions, based on DATALOG (Ull-man, 1988), that leverages problem structure found in our application domain and others like it. Given this novel representation, we then use an off-the-shelf ILP system, Claudien (De Raedt &amp; Dehaspe, 1997), to learn the required DATALOG program.
 Representation. A DATALOG program consists of logical atoms over available predicates. Here, the avail-able predicates are the observation and state predi-cates along with the comparison predicates  X  and =. A logical atom is a predicate applied to the appro-priate number of variables and/or numeric constants. The rule &lt; body &gt; is a conjunction of logical atoms, and the &lt; head &gt; is either  X  or a logical atom whose vari-ables appear in the body.
 We define state-inference functions using two types of rules. First, o-rules allow only observation predicates in the body and state predicates in the head, and can derive state facts from observations. For example, if
Distance ( x, y, d )  X  ( d  X  5)  X  Speed ( y, s )  X  (6  X  s )then Attached ( x, y ) is an o-rule. Second, s-constraints are rules that do not involve observation predicates (the head may in-volve  X  ). These rules place logical constraints on sets of state facts and can detect sets of facts that do not belong to any state (i.e. sets that violate some constraint). For example, (if Attached ( x, y )  X  Contacts ( x, y )then  X  )isans-constraintthatsays x cannot support y by both contact and attachment. 4 Any way of replacing the variables in a rule with ob-jects and/or numbers gives an instance of that rule. Applying a rule to a set of state and observation facts produces new assertions, in the usual way: for each in-stance of the rule with the instance body true, relative to the premise set, the instance head is produced as an assertion. For example, if we are given the observation {
Distance ( green , red , 3) ,..., Speed ( red , 10) } ,the aboveo-rulewillassert Attached ( green , red ). Given a rule set R and premise set Q ,the one step consequence operator  X  R ( Q ) computes the union of all rule assertions for Q . We inductively define  X  i R ( Q )=  X  (  X  i  X  1 R ( Q )), where  X  0 R ( Q )= Q ,andlet  X   X  R ( Q )denote the union over all i of  X  i R ( Q ).
 A DATALOG program  X  =  X  o  X   X  s ,witho-rules X  o and s-constraints  X  s , defines a state inference function  X  as follows. The result set  X ( O ) for an o-sequence O =( o 1 ,...,o n ) is calculated by computing the o-rule assertions for each o i and then iteratively applying the s-constraints to the union of the assertions. Formally we have  X ( O )=  X   X   X  s ( i  X   X  o ( o i )). 5 Finally, we define  X  ( O )tobe  X  if  X  X  X   X ( O ), and to be  X ( O ), otherwise. This DATALOG representation for state-inference functions is motivated by two observations about our application. First, although we are unable to learn o-rules that accurately map single observations to all underlying state facts (due to noise/ambiguity), we are able to learn nearly sound o-rules (i.e. rules that rarely produce false assertions) that assert some of the under-lying state facts for single observations. Intuitively, the rules only assert the  X  X ost ob viously true X  state facts for a given observation. Typically, for states in our application, each state fact is  X  X bviously true X  in at least one of the observations a state generates. Thus, unioning o-rule assertions across observations (as done above) typically yields exactly the true state facts. The second observation about our application domain is that the union of facts from distinct consecutive states do not correspond to any actual state, i.e. the state facts are inconsistent. Given s-constraints to de-tect such inconsistent fact sets, the above computation can detect when an input observation sequence was (most likely) not generated by a single state. Example 4. As an example of when  X  will re-turn  X  , assume that  X  includes ( if Attached ( x, y )  X  Contacts ( z, y ) then  X  ) , representing the constraint that no object is supported via both contact and attach-ment. Let O be the o-sequence from the video in Fig-ure 1, which is generated by two distinct force-dynamic states. We expect that, for some frame during the first force-dynamic state (e.g. frame 1), the rules will be able to assert Contacts ( green , red ) , and that, for some frame in the second state (e.g. frame 20), the rules will assert Attached ( hand , red ) . Given these assertions, the above rule will assert  X  and thus  X  ( O )=  X  , which signals that O did not arise from a single state according to  X  .
 Learning. We use Claudien to search for the most general o-rules and s-constraints that agree with all of the state-observation pairs in the training set. 6 Here, arule r 1 is more general than r 2 if any assertion pro-duced by r 2 can also be produced by r 1 , for all premise sets. For our domain, Claudien typically produces a large, redundant ruleset (with 300-400 rules). Motivated by Occam X  X  Razor and the fact that small rulesets are cheaper to apply, we prune to find a smaller, but  X  X ractically equivalent X , subset of the Claudien -generated o-rules. Let  X  be a set of o-sequences (typically from the training data). We con-sider two rulesets  X  and  X  to be FGM-equivalent on  X  (written  X  =  X   X  ) if for any O in  X , we have FGM( O,  X  )=FGM( O,  X  ), where  X  and  X  are the state-inference functions defined by  X  and  X  . Given the Claudien ruleset  X  =  X  o  X   X  s ,witho-rules  X  o and s-constraints  X  s , we use a heuristic method to findasmaller X  that is FGM-equivalent. Let the cov-erage C ( X  ,  X ) of  X  be the sum, over all individual ob-servations o in  X , of |  X ( o ) | . This measure rewards rule sets that assert true state facts more frequently. We start with  X  = X  s and add o-rules greedily, according to coverage, until FGM equivalence is achieved. We show pseudo-code for our pruning method in Figure 3. In our application, pruning reduces error by over 50%, indicating significant pre-pruning overfitting. We evaluate our techniques by applying them to force-dynamic sta te inference. The Leonard system (Siskind, 2001) uses inferred force-dynamic states to recognize visual events from video-camera input X  X  simple example of an event is  X  X  hand picking up a block X ,asdepictedinFigure1. Leonard is distinc-tive in its use of force-dynamic properties for event recognition, which Siskind argues is more semanti-cally grounded (and thus more generally accurate) for many event types than motion profile analysis. Leonard uses a hand-crafted for ce-dynamic inference technique (details in (Siskind, to appear)), based on kinematic physics that was shown to correctly infer force-dynamic relations for approximately 80% of the 10,000 video frames in a test corpus. A large part of the inaccuracy stems from noi se in the object tracker X  X  output, including, for example, variable strength  X  X it-ter X  and more serious errors such as  X  X bject teleporta-tion X . Our original motivation for this work was to de-velop a robust trainable system to replace and improve the accuracy and speed of Leonard  X  X  reconstruction of force-dynamic state. We note that, in improving these features, we have dropped the kinematic-physics approach to the problem (among other things), which may have ramifications yet to be explored in either system by evaluation on a much wider variety of data. Procedure 7 . We use the same 210 videos (and the same object tracker output) that were used to demon-strate Leonard (Siskind, to appear). The videos de-pict a hand playing with up to 3 blocks and are divided into 7 different event types (30 movies each), which vary in complexity from a simple pick-up to assem-bling towers. From the tracker output of each video, we can construct the corresponding relational obser-vation sequence as described in Example 3.
 We hand-labeled 3 randomly selected videos from each event type with the huma n-judged force-dynamic state, yielding 21 training videos in total. We labeled the other 189 videos with their compressed s-sequence only (the output of Compress ), as that is the label-ing our algorithm produces. This compressed label, in fact, depends only on the event type.
 We drew three training sets of 7, 14, and 21 videos from the training instances, drawing equally from each event type in each set, and learn state-inference func-tions  X  7 ,  X  14 ,and  X  21 . For each state-inference func-tion and each test-video observation sequence, we in-ferred a force-dynamic state sequence using the FGM inference algorithm, both with and without the pre-processing sequence cleaning described in Section 3. We compare our results with Leonard .Wenote, Table 2: Test error. Parentheses indicate results with no sequence cleaning preprocessing.
 however, that the goals of the Leonard project and our work are quite different. Leonard is an attempt to create a general , force-dynamic int erpretation sys-tem, whereas our approach represents a trainable se-quential inference technique that can be tuned to the class of videos exibited by the training data. This comparison is analagous to work showing that learned domain-specific language parsers (Tang &amp; Mooney, 2000) outperform general-purpose language parsers within the trained domain.
 We hand-designed programs for force-dynamic infer-ence aimed at the class of movies in our corpus. Hack 1 was designed after examining the size-14 train-ing videos. Hack 2 was designed by examining the er-rors of Hack 1 on the test data  X  X  form of cheating. Whole-Movie Performance. The second column of Table 2 shows the percentage of test videos labeled incorrectly. The first three rows are for FGM with the learned state-inference functions, both with and with-out sequence cleaning (the latter in parentheses). The final three rows show Leonard and our hand-coded programs. We see that, the peformance of FGM im-proves with more training data. With only a relatively small set of training data, FGM achieves a 3% error rate with sequence cleaning . Sequence cleaning signif-icantly improves the FGM performance, though less than 0.5% of the observations were removed. Com-paring to our hand-coded systems, FGM always out-performs Hack 1 and is comparable to Hack 2 for the larger training sets. So, our system is able to learn an inference system that is on par with a significant, even cheating, attempt to hand-code a solution.
 Per-Frame Performance. The poor performance of Leonard relative to whole-movie error does not properly reflect its ability. Although Leonard rarely computes the exact true co mpressed state sequence, it does correctly label most individual observations with the correct force-dynamic s tate. The evaluation mea-sure used in (Siskind, to appear) considered the in-ferred state sequence as a multi-set, and then calcu-lated the percentage of the multi-set members that did not appear in the correct state labeling (so state order does not affect the error). The first column of Table 2 shows this error measure for Leonard and FGM. Under this measure, Leonard labels over 80% of the frames correctly. FGM , however, significantly outperforms Leonard .
 We also compare inference time on the 210 videos for each method, all implemented in Scheme and running on the same machine. Frame rates were 1 per sec-ond for Leonard ,3.8persecondforFGM(with  X  7 ,  X  14 ,or  X  21 ), and 5.3 per second for either Hack 1 or Hack 2 . So, FGM is about 4 times faster than Leonard , but 28% slower than our hand-constructed domain-specific programs. Importantly, 90% of FGM X  X  runtime was spent computing the observation predi-cates from the tracker output. FGM runs at frame rate (30 frames/second) when given the observation predicates. We believe these predicates can also be computed at frame rate with a C implementation. Sliding-window techniques (Dietterich, 2002) label each observation using a fixed-size local window of ob-servations and possibly previous classifications. These techniques leverage a stronger assumption than reli-able observations due to the fixed window size. Find-ing a good state-inference function is problematic here because of the ambiguity at transitions X  X GM can be viewed as varying the window size to avoid the ambi-guities at transition points.
 Other work, e.g. (LeCun et al., 1998; Punyakanok &amp; Roth, 2000), uses observation-subsequence classifiers to construct optimization problems. Each classifica-tion assigns a measure of  X  X ood fit X  (with the classified subsequence) to each state, and then an optimization problem is solved to select a state sequence. These methods have assumed a small explicit state space, and generalization to our problem is unclear. Probabilistic modeling is a widely preferred approach to achieving robustness to noise, but is not straight-forward to apply to our problem. In particular, most probabilistic models used for temporal data, such as hidden Markov models (Rabiner, 1989), conditional random fields (Lafferty et al., 2001), and segment mod-els (Ostendorf et al., 1996) have traditionally assumed small  X  X xplicit X  state spa ces. Extensions such as dy-namic Bayesian networks (Dean &amp; Kanazawa, 1989) assume a fixed number of state variables. In our prob-lem, this number varies with the number of objects. A recent approach to overcoming these issues is to rep-resent probabilistic models for relational domains via  X  X odel schemas X  with  X  X hared parameters X  X  X .g. dy-namic probabilistic relational models (Sanghai et al., 2003) and relational Markov networks (Taskar et al., 2002). Learning and utilizing such models relies on the ability to perform inference that is typically computa-tionally hard. This problem generally requires the use of heuristic or approximate inference techniques (e.g. loopy belief propogation and particle filtering) that have unclear semantic characterizations and unclear practical implications.
 However, it is not our intention to argue against the use of probabilistic models for problems such as ours. Rather, we first explore what can be accomplished without probabilities, by exploiting nearly sound hard constraints and redundant information provided by reliable observations. We give a simple logic-based approach, providing both a learning and inference method, along with a semantic characterization of the inferred state sequence which the inference method is guaranteed to find quickly. This approach achieves good robustness to noise in our application. We presented a new, trainable approach to relational sequential inference. The key novelties of our approach are: 1) the introduction of the reliable observations assumption; 2) the use of a state-inference function for representing process knowledge; 3) the forward-greedy-merge algorithm for utilizing that function; 4) a representation for relational state-inference functions that facilitates effective learning and inference. Our empirical results for the pr oblem of constructing force-dynamic models of video show that the approach out-performs recent, huma n-coded solutions.
 In future work, we plan to explore new application domains. In particular, many video-interpretation domains appear to approximately have reliable observations X  X .g. tracking the location of a wearable camera (Torralba et al., 2003) (many frames are gen-erated at each location) o r infering semantic prop-erties of sports video (a basketball player dribbles a ball for many video frames). However, one weakness of our current approach is t he assumption of access to a nearly correct state-in ference function for  X  X ong enough X  observation sequ ences. Here, we were able to leverage structure of our domain to learn a robust func-tion and, in large part, correct for its small number of errors via sequence-cleani ng preprocessing. However, in general this will not always be possible. Thus, we are currently pursuing integrations of our framework (exploiting nearly sound hard constraints) with softer probabilistic modeling techniques in order to improve robustness while retainin g efficient exact inference. We thank the reviewers for helping to improve this paper. This work was supported in part by NSF grants 9977981-IIS and 0093100-IIS.

