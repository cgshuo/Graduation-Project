 fl ing mechanism. Furthermore, we introduce a new learning framework that 1. Introduction
Particle swarm optimization (PSO) is a metaheuristic search (MS) algorithm proposed by Kennedy and Eberhart (1995) .Itis inspired by the collaborative behavior of a school of fi sh or a Eberhart and Shi, 2001 ; Kennedy and Eberhart, 1995 ). In PSO, each individual (i.e., particle) represents the potential solution to the optimization problem, whereas the location of the food source represents the global optimum solution. During the searching process, all these particles share information and collaborate with each other. This collaboration enables the population to move toward the food source from different directions, thereby leading to swarm convergence ( Banks et al., 2007 ; Eberhart and Shi, 2001 ). PSO is characterized by conceptual simplicity and high ef Thus, it has received increasing attention and has been widely applied to solve a large class of engineering design problems such as power system design ( AlRashidi and El-Hawary, 2009 ; Chen et al., 2007 ; del Valle et al., 2008 ; dos Santos Coelho and Mariani, 2008 ; Neyestani et al., 2010 ; Wang et al., 2013 ), trajectory planning ( Alonso Zotes and Santos Pe X as, 2012 ; Fu et al., 2012 ; Marinakis et al., 2010 ), arti fi cial neural network (ANN) training ( Gudise and Venayagamoorthy, 2003 ; Mirjalili et al., 2012 ; Yaghini et al., 2013 ), data mining ( Holden and Freitas, 2008 ;  X zbak  X  r and Delice, 2011 ; Sarath and Ravi; Wang et al., 2007 ), data clustering ( Kiranyaz et al., 2010 ; Shih, 2006 ; Sun et al., 2012 ; Van Der Merwe and
Engelbrecht, 2003 ; Yang et al., 2009 ), parameter estimation and system identi fi cation ( Liu et al., 2008 ; Modares et al., 2010 ;
Sakthivel et al., 2010 ), and many other engineering problems ( Banks et al., 2008 ; Huang et al., 2009 ; Lin et al., 2009 ; Paoli et al., 2009 ; Sharma et al., 2009 ; Wachowiak et al., 2004 ).
However, despite its competitive performance, PSO possesses certain undesirable dynamic characteristics that restrict its search-ing capability. Previous studies ( van den Bergh and Engelbrecht, 2004 ) revealed that PSO is beset by a premature convergence issue, as the particles tend to be trapped in the local optima solution, which is attributed to the rapid convergence of PSO and the loss of swarm diversity. Another major concern in the application of PSO is the algorithm's capability in balancing exploration/exploitation searches. Excessive exploration or exploi-tation searches are undesirable, as the former prevents swarm convergence, whereas the latter has a high tendency to cause premature swarm convergence ( Shi and Eberhart, 1998 ). Although various approaches ( Banks et al., 2007 , 2008 ; del Valle et al., 2008 ) have been reported to alleviate the drawbacks of
PSO, little effort has been made to address the issue of balancing the PSO's exploration/exploitation searches by varying the parti-cle's topology connectivity with time. Furthermore, the most existing PSO variants do not provide an alternative strategy to the particles when they fail to improve their fi tness during the searching process. This lack of an alternative strategy inevitably limits the algorithm's performance. Motivated by these facts, we propose a new PSO variant, namely the PSO with increasing topology connectivity (PSO-ITC). The key bene fi t of the PSO-ITC is the synergy of a novel ITC module into the PSO, in offering better control of the PSO's exploration/exploitation searches. Speci the ITC module linearly increases the topology connectivity of each particle with time as the lower topology connectivity encourages the particle to perform exploration, whereas the higher topology connectivity favors exploitation ( Kennedy, 1999 ; Kennedy and
Mendes, 2002 ). A shuf fl ing mechanism is also introduced into the ITC module to prevent swarm stagnation. We also develop a learning framework that consists of a new velocity update mechanism and a new neighborhood search (NS) operator to further enhance the searching performance of PSO-ITC. The NS operator is triggered only if the PSO-ITC particle fails to improve its personal best fi tness when it is evolved through the new velocity update mechanism.
 brie fl y discusses some related works. Section 3 provides novel insights into the workings of the proposed PSO-ITC. Section 4 presents the experimental setting and results. Section 5 concludes the study. 2. Related works mechanism of the basic PSO (BPSO), after which we review several well-established PSO variants. 2.1. Basic PSO represents a potential solution to a problem, and its current state is associated with two vectors, namely the position vector X [ X i 1 , X i 2 , ... , X iD ] and the velocity vector V i unique feature of BPSO that differentiates it from other metaheur-istic search (MS) algorithms is the ability of particle i to memorize the best position that it has ever achieved, that is, its personal best particle in the population stochastically adjusts its trajectory according to its personal best experience P i and to the group best experience found by all the particles so far, P g  X  [ P g 1, ] ( Eberhart and Shi, 2001 ; Kennedy and Eberhart, 1995 ). Speci for each particular d th dimension of particle i , its velocity
V i,d ( t  X  1) and position X i,d ( t  X  1) at ( t  X  1)th iteration of the searching process are updated as follows:
V i ; d  X  t  X  1  X  X   X  V i ; d  X  t  X  X  c 1 r 1  X  P i ; d  X  t  X  X
X i ; d  X  t  X  1  X  X  X i ; d  X  t  X  X  V i ; d  X  t  X  1  X  X  2  X  and c 2 are the acceleration coef fi cients that control the in r 1 and r 2 are two random numbers generated from a uniform distribution with the range of [0, 1]; and  X  is the inertia weight used to balance the exploration/exploitation searches of particles ( Shi and Eberhart, 1998 ). 2.2. PSO variants and improvements formance of PSO, among which parameter adaptation strategy has become one of the more promising. Clerc and Kennedy (2002) incorporated a constriction factor  X  into the PSO to address the swarm explosion issue. Ratnaweera et al. (2004) developed a time-varying acceleration coef fi cient (TVAC) strategy, where the c and c 2 are dynamically changed with time to better regulate the exploration/exploitation searches. To this end, two variants of PSO-TVAC, namely the PSO-TVAC with mutation (MPSO-TVAC) and the self-organizing hierarchical PSO-TVAC (HPSO-TVAC), have been proposed. Zhan et al. (2009) developed an adaptive PSO (APSO) capable of identifying the swarm's evolutionary states through the proposed evolutionary state estimation (ESE) module.
The outputs of the ESE module are used to adaptively adjust the particles  X   X  , c 1 , and c 2 . Leu and Yeh (2012) employed the gray relational analysis in their gray PSO to tune the particles c . Based on the searching feedback status obtained from the population manager, Hsieh et al. (2009) developed an ef fi population utilization strategy for PSO (EPUS-PSO) to adaptively adjust the population size.

Population topology also plays a major role in PSO  X  s perfor-mance as it decides the information fl ow rate of the best solution within the swarm ( Kennedy, 1999 ; Kennedy and Mendes, 2002 ).
Mendes et al. (2004) proposed a fully connected PSO (FIPSO) by advocating that each particle  X  s movement is in fl uenced by all its topological neighbors. Kathrada (2009) combined the global and the local version of PSO, and proposed a fl exible PSO (FlexiPSO).
A simple heuristic is developed in the FlexiPSO to increase the fl exibility of the swarm to search across various types of fi landscape. Inspired by the social behavior of the clan, Carvalho and
Bastos-Filho (2008) proposed a clan PSO, where the population is divided into several clans. Each clan fi rst performs the search, and the particle with the best fi tness is selected as the clan leader.
A conference is then performed among the leaders to adjust their position. Bastos-Filho et al. (2009) and Pontes et al. (2011) further improved the clan PSO by hybridizing it with the migration mechanism and APSO, respectively. To alleviate the de fi ciencies of fi xed neighborhoods, Liang and Suganthan (2005) proposed a dynamic multi-swarm PSO (DMS-PSO) with a dynamically chan-ging neighborhood structure. Montes de Oca et al. (2009) adopted the concept of time-varying population topology into their Fran-kenstein PSO (FPSO). Initially, the particles in FPSO are connected with a fully connected topology. The topology is then decreased over time and eventually reduced into the ring topology. Marinakis and Marinaki (2013) proposed a PSO with an expanding neighbor-hood topology (PSOENT) by hybridizing the PSO with the variable neighborhood search strategy. In their approaches, the particle neighborhood expands based on the quality of the produced solutions. The PSOENT was applied to solve eight feature selection problems and successfully achieved an overall average classi tion accuracy of 92.48%.

Another area of research is the exploration of PSO  X  s learning strategies. Liang et al. (2006) developed a comprehensive learning
PSO (CLPSO). Accordingly, each particle is allowed to learn either from its P i or from other particle  X  s historical best position in each dimension. Tang et al. (2011) further improved the CLPSO by introducing the feedback learning PSO with quadratic inertia weight (FLPSO-QIW). Unlike the CLPSO, their FLPSO-QIW gener-ates potential exemplars from the fi rst 50% fi ttest particles. More-over, the learning probability of FLPSO-QIW particles is assigned according to the particle  X  s fi tness instead of the particle
Inspired by the DMS-PSO and the CLPSO, Nasir et al. (2012) proposed a dynamic neighborhood learning-based PSO (DNLPSO).
In their approach, the particle  X  s exemplar is selected from a neighborhood, which is made dynamic in nature. Huang et al. (2012) proposed an example-based learning PSO (ELPSO). Instead of a single P g particle, an example set of multiple global best particles is employed to update the particle  X  s velocity in ELPSO.
Zhou et al. (2011) introduced the random position PSO (RPPSO), where a random particle is used to guide the swarm if a randomly generated number is smaller than the proposed probability P  X 
Zhan et al. (2011) proposed the orthogonal learning PSO (OLPSO) that employs the orthogonal experimental design (OED) ( Hicks, 1993 ) to construct an effective exemplar to guide the search. OLPSO with the local topology (OLPSO-L) reportedly outperforms its counterpart with the global topology (OLPSO-G). Another OED-based PSO variant is the orthogonal PSO (OPSO) introduced by Ho et al. (2008) . Accordingly, an intelligent move mechanism is designed to predict the particle  X  s next position. Numerical results show that OPSO can fi nd a better solution to the 12 selected benchmark functions and one task assignment problem.

Mariani et al. (2012) combined the chaotic Zaslavskii map ( Zaslavsky, 1978 ) with the quantum PSO (QPSO) ( Sun et al., 2004 ) to solve heat exchanger optimization problems. Sun et al. (2012) developed a new clustering scheme based on a QPSO variant, namely the multi-elitist QPSO (MEQPSO). The MEQPSO-based clustering algorithm was applied in the gene expression data analysis for discovering the function of a gene. Yaghini et al. (2013) proposed a hybrid improved opposition-based PSO and a backpropagation algo-rithm with a momentum term to produce an ef fi cient ANN training algorithm. Accordingly, opposition-based learning and random per-turbations help the algorithm to maintain the population diversity. The simulation results revealed that the training time and the accuracy of the proposed algorithm are superior to those of the three other well-known ANN training algorithms. Sun et al. (2011) explored the applicability of QPSO to combinatory optimization problems. Combining the QPSO with the loop deletion operation produced a modi fi ed QPSO that was used to solve the quality-of-service (QoS) multicast routing problem. To address the vehicle routing problem, Marinakis et al. (2010) introduced hybrid PSO (HybPSO) by incorporating the multiple phase neighborhood search-greedy randomized searc h procedure (MPNS-GRASP) algo-rithm, the expanding neighborhood search strategy, and a path relinking strategy into the PSO. E xtensive experimental analyses show that the HybPSO is very promi sing in solving very large-scale vehicle routing problems within a short computational time.
To ef fi ciently solve multi-objective (MO) problems, Mousa et al. (2012) combined the PSO and the genetic algorithm to form a hybrid MO evolutionary algorithm. More speci fi cally, the proposed method employs a local search scheme to explore less crowded areas in the current archive to obtain more non-dominated solutions. Wang et al. (2013) developed a novel multi-objective PSO (MOPSO) variant, namely dynamic neighborhood small popu-lation PSO (DNSPPSO), based on the regeneration and dynamic neighborhood strategies. The former strategy improves the algo-rithm  X  s convergence speed, whereas the latter converts MO problems into single-objective (SO) ones by sorting and evalua-ting the objectives one by one. DNSPPSO is successfully applied as an intelligent dynamic recon fi guration strategy to prevent power failure in an electric ship  X  s power system. Motivated by the fact that the algorithm  X  s convergence characteristics towards the Pareto-optima set is signi fi cantly dependent on the proper selection of local guides, Sahoo et al. (2011) proposed a heuristics-based selection of guides in MOPSO (HSG-MOPSO). Accordingly, the HSG-MOPSO consists of two types of local guides, namely non-dominated and dominated guides. During optimization, a certain number of PSO members follow their nearest non-dominated guides, while the remaining ones are guided by the nearest dominated solutions. Sahoo et al. (2012) employed the principles of fuzzy Pareto-dominance into the MOPSO (FPD-MOPSO) to ef fi ciently discover and rank non-dominated solutions on the Pareto-approximation front. The proposed strategy is capable of simultaneously maintaining the quality and the diversity of the solutions retained in the elite archive. Both HSG-MOPSO and FPD-MOPSO are used as multi-objective planning algorithms for electrical distribution systems. Wang and Singh (2009) proposed an improved MOPSO to solve multi-area economic dispatch problems by combining MOPSO with the synchronous particle local search strategy ( Liu et al., 2007 ). This hybridization strategy can preserve distribution diversity and uniformity, and speed up the search process. Omkar et al. (2012) developed a novel parallel approach to vector evaluated PSO (VEPSO) ( Parsopoulos and
Vrahatis, 2002 ) in solving the multi-objective design of composite structures. Extensive simulations revealed that the parallel imple-mentation of VEPSO outperforms the one with the serial implementation. 3. PSO with increasing topology connectivity (PSO-ITC)
In this section, we describe in detail the ITC module employed in the proposed PSO-ITC. Next, we present the methodologies employed in our proposed learning framework. Finally, we provide the complete framework of PSO-ITC. 3.1. ITC module The ITC module is one of the key factors that determine PSO-
ITC  X  s performance by dynamically changing the particle  X  s topology connectivity during the searching process. Speci fi cally, the ITC module aims to better control exploration/exploitation searches by linearly increasing the particle  X  s topology connectivity with time as well as performing the shuf fl ing mechanism. The mechanism of the ITC module is inspired by early studies performed as follows.
PSO with larger topology connectivity favors the simple problem, whereas the smaller connectivity counterpart performs better in complex problems ( Kennedy, 1999 ; Kennedy and Mendes, 2002 ).
This fi nding implies that the former PSO variant is more exploi-tative, whereas the latter is more explorative. Shi and Eberhart (1998) advocated that PSO particles in the early stage of optimiza-tion require higher diversity to wander around the full range of the search space, thus emphasizing the exploration search. At the latter stage of the search, fi ne-tuning of the solution becomes the priority, and thus, the exploitation search is required. The ITC module works as follows: initially, each particle in the
PSO-ITC is connected with one neighbor that is randomly selected from the population. As the optimization process evolves, the ITC module gradually increases the particle  X  s topology connectivity until all particles are fully connected. Mathematically, each parti-cle  X  s topology connectivity is linearly increased as follows:
TC  X   X  TC min  X  TC max  X  X  k 1  X  =  X  FE max 1  X   X   X  3  X  where TC i is the current connectivity of particle i ; TC represent the maximum and minimum connectivity, respectively, where TC min  X  1 and TC max  X  S  X  1; k is the current fi tness evalua-tions (FEs) consumed by the algorithm; FE max is the maximum FEs allocated; and  X  X  X  represents the fl oor operator.
 randomly selects  X  TC i new neighbors from the population. Unlike the neighborhood structure shown in the previously proposed
DMS-PSO ( Liang and Suganthan, 2005 ) and DNLPSO ( Nasir et al., 2012 ), the particles in our PSO-ITC are not connected in a bidirectional manner. For example, in the case of TC i  X  1, if particle i has selected particle j as its neighbor, then particle j does not necessarily select particle i as its neighbor as well. Instead, particle j may select another particle, for example, particle k , as its neighbor. Fig. 1 illustrates the aforementioned scenario. with time, the ITC module also incorporates a shuf fl ing mechanism to alleviate swarm stagnation. As shown in Fig. 2 ,ifparticle i fails to improve the fi tness of the group best experience found by all the reassigns new neighbors to particle i by randomly selecting TC members from the population. This mechanism provides the new topological information for particle i , thereby allowing it to perform the search in a new direction provided by the new neighborhood members. We also perform perturbation on the P g particle to help it escape from the local optimum. Speci fi cally, one d th dimension of the where P per g ; d is the perturbed P g,d ; r 3 is a random number with the range of [0,1]; P x,d and P y,d are the personal best positions of the two particles randomly selected from the population. The perturbed P lower) fi tness than the latter. Eq. (4) is in fact inspired by the social learning strategy proposed by Montes de Oca et al. (2011) .Asshown in Eq. (4) ,the P per g ; d particle learns socially from a subset of more the cost of acquiring that knowledge individually from scratch.
Consequently, the P per g ; d particle produced is biased toward the best particle. This approach lets the P per g ; d particle jump to promising regions of the search space instead of to inferior ones.
Fig. 3 illustrates the mechanism of the proposed ITC module. In the initial stage, each particle in the population randomly selects one population member as its neighbor. For example, particles i and n select particles j and m as their neighbors, respectively.
After a certain number of FEs, the connectivity of all particles is increased from one to two, and each particle of the population randomly selects another population member as its neighbor.
For example, particle i selects particle k as its new neighbor when its topology connectivity is increased to two. Thus, particle i neighborhood, that is, a set of particles connected with particle i , now consists of two members, namely particles j and k . Next, particle i performs the shuf fl ing mechanism as it fails to improve the global best fi tness for z successive FEs. Speci fi cally, particle i gives up its original neighbors, that is, particles j and k , and randomly selects particles l and n as its new neighbors. The new neighbors (i.e., particles l and n ) provide particle i a new searching direction, thereby preventing the latter from stagnating in the local optima. Both steps  X  (1) linearly increasing topology connec-tivity and (2) shuf fl ing mechanisms  X  are repeated until all parti-cles in the population are fully connected.

Fig. 4 illustrates the implementation of the ITC module. As shown in the fi gure, a variable fc i is de fi ned to record the number of successive FEs where particle i fails to improve the f ( P As shown in the main algorithm block (i.e., Fig. 9 ), the fc is reset to zero if the global best particle  X  s fi tness is successfully improved. Otherwise, the value of fc i is incrementally increased by one. Also, the two exemplars that play major roles in evolving particle i through our proposed learning framework (i.e., the cogni-c exp , i and s exp,i exemplars are generated by the Generate_Exemplars procedure described in Section 3.2.1 . 3.2. Proposed learning framework
In this section, we introduce the new learning framework adopted by the proposed PSO-ITC. We fi rst explain the methodol-ogy employed to generate the c exp , i and s exp,i exemplars that are essential in guiding particle i in the proposed learning framework. Next, we provide a detailed description of the new velocity update mechanism and the new NS operator employed in the PSO-ITC. 3.2.1. Derivation of the cognitive exemplar (c exp,i ) and the social exemplar (s exp,i )
From Eq. (1) , we observe that the second component of ( P X ) acts as the cognitive component, whereas the third compo-nent of ( P g,d  X  X i,d ) represents the social component. It is worth mentioning that the fi tness of the global best particle P not worse (i.e. not higher) than the personal best position of particle i , P i .

Inspired by this observation, we propose to generate two exemplars, the c exp , i and the s exp,i exemplars, from the neighbor-process. Speci fi cally, we fi rst sort the neighborhood members of particle i, including particle i itself, according to their personal best fi tness. The fi tter neighborhood members with their personal best fi tness ranked at the fi rst quartile range (i.e., neighbor_upper are used to generate the s exp,i exemplar, while the members in the remaining three quartiles (i.e., neighbor_lower i ) produce the c exemplar. As the c exp,i exemplar is derived from three-fourth of the neighbors with the worst fi tness, it may have an inferior particle i  X  s personal best fi tness. Nevertheless, as explained in the following subsection, using the individuals with worse fi that of the particle itself makes sense, because they are used to repel the particle. In addition, unlike the CLPSO ( Liang et al., 2006 ) and the DNLPSO ( Nasir et al., 2012 ) that employed tournament selection, we utilize roulette wheel selection to generate the c and the s exp,i exemplars from neighbor_lower i and neighbor_upper respectively. Speci fi cally, each member k in the neighbor_lower and neighbor_upper i is assigned a weightage value, W k
W  X  f max f  X  P k  X  f where f max and f min represent the maximum (i.e., worst) and the minimum (i.e., best) personal best fi tness values of the members in neighbor_lower i or neighbor_upper i , respectively, and K repre-sents the number of members in neighbor_lower i or neighbor_-upper i . From Eq. (5) , the neighborhood member k with a lower fi tness is assigned a larger W k value, which implies that it has a greater probability of being selected as the c exp , i or s exemplar. To prevent the derivation of the c exp , i and s plars solely from the fi ttest members of the neighbor_lower neighbor_upper i , respectively, we randomly select one dimension d of the c exp , i and s exp,i exemplars, c exp , i ( d r ) and s former is replaced with the d r th component of the P i particle itself,
P i ( d r ), whereas the latter is derived from the d r th component of a randomly selected particle from neighbor_upper i . The procedure that generates the c exp , i and s exp,i exemplars for particle i is illustrated in Fig. 5 . 3.2.2. Proposed velocity update mechanism updated according to its c exp , i exemplar and the P g particle. As each component of the c exp , i exemplar is selected through a probabil-istic mechanism, two possible scenarios may be encountered: (1) the c exp , i exemplar has better (i.e., lower) fi tness than particle i , that is, f ( c exp , i ) o f ( P i ), and (2) the c exp higher) fi tness than particle i , that is, f ( c exp , i velocity update mechanisms are employed in response to these two scenarios. For scenario (1), particle i is encouraged to attract towards the c exp , i exemplar as the latter has better fi offering particle i a more promising search direction. For scenario (2), as the c exp , i exemplar is unlikely to contribute to particle i improvement, the latter is thus repelled from the former to let particle i search the unexplored regions of the search space. Mathematically, particle i  X  svelocity V i is updated as follows:
V  X 
The new position of particle i is updated by using Eq. (2) .Itis then evaluated and compared with the fi tness of P i and P former has better fi tness than the latter, the latter  X  s position are replaced by the former. When particle i successfully improves its personal best fi tness, it may have some useful information about certain components of the newly improved P position. Thus, when particle i successfully improves its P and if the improved P i is different from P g , an elitist-based learning strategy (EBLS) is employed to extract the useful information from the newly improved P i to further improve the P g particle. Speci-fi cally, when particle i successfully fi nds a better P i , the EBLS will iteratively check each dimension of P g by replacing the dimension with the corresponding dimensional value of P i , if P g is improved by doing so. This mechanism enables the P g to learn useful information from dimensions of a P i that have been improved, thereby improving the algorithm  X  s convergence speed. The imple-mentation of EBLS is presented in Fig. 6 . 3.2.3. Proposed neighborhood search operator
The ability of particle i to improve its P i  X  s fi tness each time when it is evolved through the proposed velocity update mechan-ism is not guaranteed. To address this issue, we developed a NS operator as an alternative strategy to further evolve particle i when it fails to improve its P i  X  s fi tness during the learning stage.

To perform the proposed NS operator on particle i ,we fi rst exclude the c exp , i and the s exp , i exemplars produced by particle i itself, and store the cognitive and social exemplars produced by other particles into the arrays of c candidate,i  X  [ c exp c s exp , S ], respectively. Based on the fi tness criterion, we select two guidance particles, namely s guide,i and c guide,i from the arrays of c candidate,i and s candidate,i , respectively, through the roulette wheel selection. An o exp , i exemplar, which is used to guide particle i in the
NS operator, is then derived from the selected c guide,i and s
Speci fi cally, if a randomly generated number is smaller than 0.5, the s guide,i ( d ). Otherwise, it is contributed by the d th component of c . The procedure NS_Generate _Exemplars used in generating the o exp , i exemplar is illustrated in Fig. 7 .

Similar to the c exp , i exemplar, the fi tness of o exp , either be better or worse than the personal best fi tness of particle i .
Thus, a similar strategy is employed to handle these scenarios: (1) if f ( o , i ) o f ( P i ), particle i is attracted towards the o exp (2) if f ( o exp , i ) Z f ( P i ), particle i is repelled from the o
Speci fi cally, each particle i adjusts its P i as follows:
P where P i,temp is the adjusted cognitive experience of particle i and r and r 9 are the random numbers in the range of [0, 1]. The fi tness of
P i,temp is then evaluated and compared with the P i and P g former  X  s fi tness is better than the latter, the improved P replaces both P i and P g . As in the previous subsection, if the newly improved P i,temp has better fi tness than the old P i , the EBLS is triggered to extract the useful information from P i,temp
P g ,. The NS operator  X  s implementation is presented in Fig. 8 . 3.3. Complete framework of the PSO-ITC tion of the proposed PSO-ITC is summarized in Fig. 9 .Althoughsome working mechanisms in PSO with expanding neighborhood topology (PSOENT) proposed by Marinakis and Marinaki (2013) are similar to PSO-ITC, several differences exist between these two PSO variants.
First, the particle  X  s topology connectivity in our PSO-TVTC is updated according to the schedule de fi ned in Eq. (3) , whereas PSOENT updates its neighborhood based on the quality of the produced solution.
Second, our PSO-ITC is equipped with the shuf fl ing mechanism in the ITC module to reassign a particle  X  s neighborhood members when contrast, PSOENT expands its neighborhood when a similar circum-stance is encountered. Finally, a learning framework is designed for thePSO-ITCtoimprovethealgorithm  X  s performance, whereas no such learning framework is adopted by the PSOENT. 4. Simulation results evaluate the PSO-ITC and present the experimental results. 4.1. Benchmark functions ( Suganthan et al., 2005 ; Tang et al., 2011 ; Yao et al., 1999 )to extensively evaluate the performance of PSO-ITC and its contenders.
We perform the evaluation with 50 variables, D  X  50. Table 1 lists these benchmarks and describes their for mulae, their feasible search range
RG , their global minimum fi tness F min , and their accuracy level accuracy level is used to decide whether a particular algorithm run is successful, that is, the problem is considered solved when the approximate solution is not farther than  X  from the actual one.
Table 1 shows that the employed benchmarks are categorized into four classes: (1) conventional problems, (2) rotated problems, (3) shifted problems, and (4) complex problems. Each function in the conventional problems (F1  X  F8) has a different characteristic, which enables us to assess the algorithm  X  s performance with the use of various criteria. For example, function F1 is used to test the algorithm  X  s convergence speed, as it is relatively easy to be solved.
Functions F4, F5, F7, and F8 are multimodal functions used to evaluate the algorithm  X  s capability to escape from the local optima, as these functions consist of a large number of local optima in a high-dimensional case. The rotated problems (F9 are developed to prohibit a one-dimensional search, which is permissible in certain conventional problems (e.g., functions F1,
F4, F5, and F8). The prevention of one-dimensional search can be done by multiplying the original X i variable with an orthogonal matrix M ( Salomon, 1996 ) to produce a rotated variable Z
Z  X  M n X i . As a result, any change that occurs in X i will affect all dimensions in Z i , which then leads to non-separability of the rotated problems. For shifted problems (F14  X  F17), a vector o  X  [ o o , ... , o D ]isde fi ned to adjust the global optima of the conventional problems to a new location, Z i  X  X i  X  o . The complex problems (F18
F20) consist of the shifted and rotated problems (F18 and F19) and the expanded problem (F20). The former integrates both the rotating and the shifting characteristics into the conventional problems, whereas the latter is derived by taking the two-dimensional Rosenbrock function (F3) as the input argument of the Griewank function (F8) ( Suganthan et al., 2005 ). 4.2. Simulation settings for the involved PSO algorithms
In this paper, we employ nine well-established PSO variants for a thorough comparison of the PSO-ITC with other PSO variants.
The parameter settings for all PSO variants are extracted from their corresponding literatures and summarized in Table 2 . The para-meter settings of these nine PSO variants are set by their corresponding authors, and these settings are the optimized ones. For our PSO-ITC, a parameter sensitivity analysis described in the following subsection is performed to investigate the effect of parameter z on the searching performance of the PSO-ITC.
To ensure fair performance assessment between the PSO-ITC and its contenders, all PSO variants are run independently 30 times on the employed 20 benchmarks. We use the maximum number of fi tness evaluation FE max as the termination criterion for all involved algo-rithms. In addition, the calculations are stopped if the exact solution X is found, F ( X )  X  F ( X n ). The population size and FE cases are 30 and 300,000, respectively ( Suganthan et al., 2005 ). 4.3. Performance metrics
We assess the PSO  X  s performance based on three criteria, namely accuracy, reliability, and ef fi ciency, through the mean fi tness value ( F mean ), success rate ( SR ), and success performance ( SP ), respectively ( Suganthan et al., 2005 ).
 best (i.e., lowest) fi tness value found by the algorithm and the actual global optimum  X  s fi tness ( F min )( Suganthan et al., 2005 ).
A smaller F mean is favorable, as it implies that the algorithm has better searching accuracy. The SR value is used to evaluate the consistency of an algorithm to achieve a successful run, that is, the ability to solve the given problem with the prede fi ned accuracy level  X  ( Suganthan et al., 2005 ). The algorithm with the larger SR value is more reliable, as it can consistently solve the problem with prede fi ned  X  .
 problem with the prede fi ned  X  can be measured by the SP value ( Suganthan et al., 2005 ) or the mean computational time ( t
However, previous papers state that the former is more suitable than the latter for evaluating the performance of algorithms that solve real-world problems ( Zhan et al., 2009 ). Thus, we employ the SP value to justify the algorithm  X  s speed. A smaller SP value is preferable as it implies that the algorithm requires less computa-tion cost to solve the problems with acceptable accuracy levels.
Finally, to thoroughly investigate the signi fi cance of the perfor-mance deviation between the PSO-ITC and its peers, we perform a two-tailed t -test ( Tang et al., 2011 ) with 58 degrees of freedom at a 0.05 level of signi fi cance (or 95% con fi dence level). More precisely, the h sign produced by the t -test is used to evaluate if the performance of the PSO-ITC is better (i.e., h  X   X   X   X  ), insigni (i.e., h  X   X   X   X  ), or worse (i.e., h  X   X   X  ) than the other nine algo-rithms at the statistical level. 4.4. Parameter sensitivity analysis the shuf fl ing mechanism when the PSO-ITC fails to improve the
The dependency of the ITC module on z implies that different values of z may affect the performance of the PSO-ITC. Thus, we perform parameter sensitivity analysis to investigate the perfor-mance of the PSO-ITC under variant z values.
 sensitivity analysis are as follows: we evaluate four 10-D bench-marks with different characteristics, namely the Sphere (F1),
Rastrigin (F4), Noncontinuous Rastrigin (F5), and Ackley (F7) functions. These problems are solved by PSO-ITC with the use of z with an integer value from 1 to 9. Each different z value is run 30 times, with the population size ( S ) and the maximum fi tness evaluation numbers ( FE max ) of 10 and 5.00E  X  04, respectively. The experimental fi ndings obtained by the PSO-ITC with different values of z are summarized in Fig. 10 .
 The simulation results reveal that the searching accuracy of the
PSO-ITC, represented by the F mean value, is not sensitive to the parameter z .Morespeci fi cally, the PSO-ITC successfully locates the global optima of all employed benchmarks (i.e., functions F1, F4,
F5, and F7) regardless of which z valueischosen.Weomittheresults of F mean from the graphs in Fig. 10 because the F mean values produced by the PSO-ITC in all employed benchmarks are zero for z  X  1,..,9 and presenting all-zero data in the graphs is not useful. We also observe that the parameter z in fl uences the algorithm  X  sef fi ciency, which is represented by SP values. Speci fi cally, the PSO-ITC  X  sef rates when the values of z are set too high (i.e., z  X  7, 8, 9) or too low the shuf fl ing mechanism is not triggered frequently enough. Conse-quently, the diversity provided by the ITC modules to the population is inadequate, which in turn entraps the PSO-ITC swarm at local optima for too long a time. In contrast, the shuf fl ing mechanism in the ITC module can be overemphasized when the z value is set too high.
In this extreme scenario, the ITC module provides excessive diversity to the swarm, which in turn potentially jeopardizes the convergence rate of the PSO-ITC toward the problem  X  s global optimum. Finally, the results of parameter sensitivity analysis reveal that the PSO-ITC ef fi ciently solves the four employed benchmarks with z values between4and6.Moreprecisely,thePSO-ITCachievesthebest SP values in functions F1 and F4 when z is set as 6, whereas the z value of 5 solves the functions F5 and F7 with the least computational cost.
Based on these fi ndings, we set z to be 5 for PSO-IDL in the following performance evaluations. 4.5. Comparisons of the PSO-ITC with other well-established PSO variants
The results of the F mean , standard deviation ( SD ), t -test ( h ), SR , and SP attained by all nine PSO variants for all problems are presented in Table 3 . The best result for each benchmark is indicated in boldface. We also include the convergence graphs of all benchmark problems in Appendix A1 for us to qualitatively (i.e., visually) compare the F mean and convergence speed of all involved algorithms.

At the bottom of Table 3 , we summarize the F mean comparison results between PSO-ITC and other peers as  X  w / t / l  X  and #BMF . means that PSO-ITC wins over a particular peer in w functions, ties for 0.00E+00 2.00E+02 4.00E+02 6.00E+02 8.00E+02
SP (FEs) 0.00E+00 2.00E+02 4.00E+02 6.00E+02 8.00E+02
SP (FEs) t functions, and loses in l functions. #BMF represents the number of results ( h ) are summarized as  X   X  /  X  /  X  to indicate the number of functions in which PSO-ITC performs signi fi cantly better, almost the same as, and signi fi cantly worse than its contender, respectively.
Finally, the SR and the SP results are summarized as  X  #S / #PS / #NS and #BSP , respectively, where the form er indicates the numbers of functions that are solved completely (i.e., SR  X  100%), solved partially (i.e., 0% o SR o 100%), and never solved (i.e., SR  X  0%) by a particular
PSO variant, whereas the latter represents the number of the best (i.e., lowest) SP values attained by the involved PSO variants. 4.5.1. Comparison among the F mean results
Table 3 indicates that the proposed PSO-ITC has the most superior searching accuracy as it outperforms its peers with a large margin in the majority of the problems. Speci fi cally, the PSO-
ITC achieves 15 best F mean values out of the 20 employed bench-marks. For the conventional (F1  X  F8) and the rotated (F9 problems, the proposed PSO-ITC successfully locates the global optima of all problems, except for the functions F3 and F11. More particularly, the PSO-ITC is the only algorithm to solve the conventional functions of F1, F2, F4, F5, and F7. Another signi fi nding is that except for the PSO-ITC, the remaining PSO variants experience different levels of performance degradation in the rotated problems compared with the conventional counterpart.
Our PSO-ITC is the only PSO variant that is robust in the rotation operation, as it is able to fi nd the global optima for all rotated problems, except for function F11. We also observe that the F values attained by all involved algorithms in the conventional (F3) and the rotated (F11) Rosenbrock functions are relatively large. The inferior performance of all algorithms in functions F3 and F11 is attributed to the fact that the global optima of these functions are located in a long, narrow, parabolic-shaped valley to test the algorithm  X  s ability in navigating fl at regions with a small gradient.
Most of the involved algorithms are able to locate the aforemen-tioned valley but are hardly able to converge towards the global optimum, which causes them to obtain a poor F mean value.
Meanwhile, all the involved algorithms, including PSO-ITC, also suffer performance deterioration in shifted problems (F14 as none of them is able to fi nd the global optima for all shifted problems, except for function F17. Nevertheless, we observe that the PSO-ITC is least affected by the shifting operation, as it produces the three best F mean and one second best F mean in four shifted problems. Speci fi cally, the PSO-ITC is the only algorithm to successfully obtain the F mean values with an accuracy level of 10 7 in functions F15 and F16. On the complex problems (F18  X 
F20), we observe further performance degradation of the involved algorithms, as the inclusion of both rotating and shifting operations (F18  X  F19) and expanded operation (F20) has signi cantly increased the problems  X  complexities, which makes the problems more dif fi cult to solve. We observe that the performance of the PSO-ITC in complex problems is competitive, as it produces the best, second best, and third best F mean values in functions 20, 19, and 18, respectively. Despite slightly inferior F mean compared with the FLPSO-QIW and HPSO-ITC in functions 18 and 19, such performance deviations are relatively insigni when compared with the outstanding performances of the PSO-
ITC over the aforementioned peers in other types of problems. 4.5.2. Comparisons among the t-test results
The t -test results, represented by the h signs in Table 3 , are largely consistent with the previously reported F mean values, given that the summarized results of  X  w / t / l  X  and  X   X  /  X  / the same. Table 3 shows that PSO-ITC performs signi fi cantly better than its peers in more problems and achieves signi fi cantly worse results than its peers in fewer problems. Speci fi cally, PSO-ITC signi fi cantly outperforms all its contenders in 10 of the 20 employed functions, that is, functions F1, F4, F5, F7, F10, F12, F13,
F15, F16, and F20. These observations validate the excellent searching accuracy of the PSO-ITC compared with its peers. different F mean values produced by PSO-ITC and FLPSO-QIW in function F6 (i.e., 0 and 5.75E-04, respectively), the t -test's result reveals that such a performance difference is insigni fi cant at a statistical level. Similar ambiguous scenarios could be observed in FLPSO-QIW, FIPSO, RPPSO, and FlexiPSO in functions F6, F2, F9, and
F17, respectively. This ambiguity is due to fact that when certain algorithms, such as FLPSO-QIW, run with a prede fi ned number of independent runs, they have a small probability of stagnating in the local optima, thereby producing a relatively large fi that can jeopardize the overall F mean value. As shown in Table 3 , despite having a relatively large F mean value in function F6, the FLPSO-QIW successfully solves the problem completely, that is,
SR  X  100%. 4.5.3. Comparisons among the SR results searching reliability than its peers, as it is able to completely solve 15 of the 20 employed benchmarks, that is, it is 2.5 times better than the second ranked OLPSO-L that completely solved six problems. Speci fi cally, the PSO-ITC has successfully solved all the conventional and the rotated problems completely, except for the rotated and the non-rotated Rosenbrock problems (i.e., F11 and
F3). The PSO-ITC is the only algorithm to completely solve the functions F2, F10, F12, and F13, as well as partially solve function
F3. The excellent performance of the PSO-ITC can also be observed in the shifted problems, as it is the only algorithm to completely solve all the shifted problems with the prede fi ned  X  . For complex problems, we observe that the searching reliabilities of all involved algorithms are compromised, as none of them is able to solve the problems completely or partially, except for function F18, where
PSO-ITC achieves the third best SR value. Although none of the involved algorithms is able to solve functions F19 and F20 completely, PSO-ITC performs competitively because it produces prominent F mean values in these aforementioned problems, as reported in Table 3 . 4.5.4. Comparisons among the SP results
Obtaining the SP value is impossible if an algorithm never solves a particular problem (i.e., SR  X  0%) because the SP value is the computational cost required by an algorithm to solve the problem with a pre-speci fi ed accuracy level  X  . In this scenario, an in fi nity value  X  Inf  X  is assigned to the SP value, and only the convergence graphs, as illustrated in Appendix A , are used to justify the algorithms  X  speed.

From Table 3 , we observe that PSO-ITC achieves the best SP values in all conventional problems, which implies that our proposed approach requires the least computational cost to solve the conventional problems with an acceptable  X  . The excellent convergence of PSO-ITC in these problems is well supported by the corresponding convergence graphs shown in Appendix A . Except for function F3, we observe a typical feature exhibited by the convergence curves of the PSO-ITC in all other conventional problems, that is, a curve that sharply drops off at one point, usually at the early stage [functions F1, and F4  X  F8, as illustrated in Fig. A1(a) and (d)  X  (h) , respectively] or the middle stage [function
F2 as illustrated by Fig. A1(b) ] of the optimization. These observa-tions reveal the ability of the PSO-ITC to break out of the local optima and to locate the global optima by consuming a signi cantly small amount of FEs.

For rotated problems, the PSO-ITC achieves three (out of fi best SP values in functions F9, F10, and F13. The competitive convergence speeds of the PSO-ITC in the rotated problems are also well justi fi ed by the convergence graphs in Appendix A . Speci fi cally, the convergence graphs of the PSO-ITC in functions
F9 and F13 [illustrated by Fig. A1(i) and (m) , respectively] are sharply dropped off at a very early stage of the optimization, which indicates the high ef fi ciency of PSO-ITC in solving these two rotated problems. Meanwhile, as illustrated in Fig. A1(j) and (l) , the convergence graphs of PSO-ITC in functions F10 and F12 sharply drop off at one point at the later stage of the optimization.
These observations prove the robustness of PSO-ITC in handling premature convergence at local optima. In contrast, the conver-gence speed of the PSO-ITC in the shifted problems is slightly compromised, as it produces one best, one second best, and two third best SP values in functions F17, F16, F15, and F14, respec-tively. We speculate that PSO-ITC may require higher computa-tional cost to locate the shifted global optimum regions, thereby leading to the slightly inferior SP values. Nevertheless, we observe that the algorithm with smaller SP values is not guaranteed to have the best searching accuracy, as shown in functions F15 and F16 [illustrated by Fig. A1(o) and (p) , respectively]. For example, FlexiPSO achieves smaller SP values than the PSO-ITC in the functions F15 and F16. However, as shown in Table 3 as well as in Fig. A1(o) and (p) , the PSO-ITC achieves a signi fi cantly better F mean value than FlexiPSO, and the former reaches the solution with the prede fi ned  X  earlier than the latter. Finally, the PSO-ITC demonstrates a competitive convergence speed in complex pro-blems, as shown in Fig. A1(r) and (t) . Speci fi cally, the convergence speed of the PSO-ITC in functions F18 and F20 is signi fi than that of its peers during the early stage of the optimization. 4.6. Comparison of mean computational time
As shown in the previous SP analysis, the proposed PSO-ITC is more computationally ef fi cient than its peer algorithms. To further verify this fi nding, we conducted an experiment to compute the mean computational time ( t mean ) or runtime of all involved PSO variants on the employed 20 benchmarks. Similar to the previous experiments, the dimensionality level of 50 was considered. The mean computational times for all the algorithms were measured on a PC Intel Core 2 Duo 2.13 GHz with 3.50 GB RAM that runs
Windows XP with Matlab implementation. The results are sum-marized in Table 4 and Fig. 11 .

The results in Table 4 and Fig. 11 show that the involved PSO variants exhibit diverse t mean values. In general, both APSO and
FLPSO-QIW appear to have higher computational overhead with respect to the other algorithms, as these two algorithms produce 6 and 14 worst t mean values out of the 20 employed benchmarks, respectively. Meanwhile, we observe that the computation over-heads of the OLPSO-L and the proposed PSO-ITC are the lowest in a majority of the employed functions. Speci fi cally, OLPSO-L achieves 15 best and 2 s best t mean values, whereas PSO-ITC records 5 best and 11 s best values out of the 20 employed benchmarks. In most of the employed benchmarks, the differences between t mean produced by OLPSO-L and PSO-ITC are relatively insigni fi which suggests that these two algorithms have a comparable computational overhead. The excellent performance of PSO-ITC in terms of t mean and previously reported SP values con fi the proposed algorithm is indeed more computationally ef fi than its peers. 4.7. Effect of different strategies
The proposed PSO-ITC consists of three strategies, namely ITC module, NS operator, and EBLS. The contribution of each strategy in improving the PSO-ITC's overall performance is worth investi-gating. To perform this study, we decompose the complete PSO-
ITC into (1) PSO-ITC with ITC module only (PSO-ITC1), (2) PSO-ITC with ITC module and EBLS operator (PSO-ITC2), and (3) PSO-ITC with ITC module and NS operator (PSO-ITC3). We compare the
F mean values produced by PSO-ITC1, PSO-ITC2, PSO-ITC3, and
PSO-ITC with those produced by BPSO. The degree of improvement of each PSO-ITC variant over the BPSO is expressed in terms of percentage improvement (%Improve) calculated as follows ( Lam et al., 2012 ): %
Improve  X  F mean  X  BPSO  X  F mean  X  where  X  denotes PSO-ITC1, PSO-ITC2, PSO-ITC3, or PSO-ITC. If outperforms BPSO, the %Improve has a positive value. Otherwise, the %Improve is assigned a negative value. The (1) number of best
F values ( #BMF ), (2) number of global optima found (# GO ), and (3) %Improve values produced by all compared algorithms in the conventional, rotated, shifted, and complex problems are presented in Table 5 . The last column of Table 5 summarizes the overall results, that is, the total #BMF ,total #GO , and average %Improve values achieved by all involved algorithms.
 improved signi fi cantly compared with that of BPSO, which implies that any strategy, that is, ITC module, NS operator, or EBLS, indeed helps to enhance the algorithm's searching accuracy. Among all these PSO-ITC variants, the complete PSO-ITC achieves the largest average %Improve value, followed by PSO-ITC2, PSO-ITC3, and PSO-ITC1.
 improvement, as it is only able to successfully solve seven (out of eight) conventional problems. The searching accuracy of PSO-ITC1 deteriorates when it is employed to solve rotated, shifted, and complex problems. This deterioration implies that the ITC module alone is insuf fi cient to help the particles to escape from the local minima in other classes of problems. In contrast, the performance of PSO-ITC2 and PSO-ITC3 is good in shifted and rotated problems, respectively. We speculate that the combination of ITC module and EBLS is more effective in tracking the shifted global optima, whereas the combination of ITC module and NS operator plays a major role in solving non-separable problems. However, the performance of these two variants in complex problems (F18 F20) is still unsatisfactory, which implies that the combination of
ITC module with any of the NS or EBLS strategies is still insuf in handling problems with a more complex fi tness landscape.
Finally, we observe that the complete PSO-ITC outperforms the other improved variants in all types of problems. Speci fi successfully achieves seven (out of eight), fi ve (out of (out of four), and two (out of three) best F mean values in the conventional, rotated, shifted, and complex problems, respectively.
Such an observation is reasonable, as the integration of ITC module with EBLS and NS operator is suf fi cient for solving the shifted and rotated problems, respectively. The superior performance of the complete PSO-ITC in all tested problems implies that the afore-mentioned strategies are integrated effectively. None of the con-tributions of the aforementioned strategies is compromised when the PSO-ITC is used to solve different types of problems. 4.8. Comparison with other state-of-the-art metaheuristic search algorithms cutting-edge metaheuristic search (MS) algorithms, as these MS algorithms are capable of solving optimization problems. Speci we compare our PSO-ITC with real-coded chemical reaction optimi-zation (RCCRO) ( Lam et al., 2012 ), differential evolution with strategy adaption (SaDE) ( Qin et al., 2009 ), orthogonal learning-based arti cial bee colony (OCABC) ( Gao et al., 2013 ), group search optimizer (GSO) ( He et al., 2009 ), real-coded biogeography-based optimization (RCBBO) ( Gong et al., 2010 ), and covariance matrix adaptation evolution strategy (CMAES) ( Hansen and Ostermeier, 2001 ). RCCO is a real-coded version of the che mical reaction optimization ( Lam and Li, 2010 ) that was developed based on an analogy to a chemical reaction. SaDE is an improved variant of the differential evolution (DE) ( Storn and Price, 1997 ). OCABC employs orthogonal learning into the arti fi cial bee colony (ABC) to achieve better searching performance. The development of GSO is motivated by an animal's searching behavior, i.e., the producer  X  scrounger (PS) model. RCBBO is the real-coded version of biogeo graphy-based optimization ( Simon, 2008 ), inspired by the geographical distribution of biological organ-isms. The CMAES is an improved evolutionary strategy ( Beyer and
Schwefel, 2002 ) with the restart and increasing population size mechanism.

To compare the proposed PSO-ITC with the aforementioned MS algorithms, we simulate various 30 dimensional conventional problems and summarize the F mean values produced by all the algorithms in Table 6 . All the results of the compared MS algorithms are extracted from their corresponding literature. Thus, we assign the F mean value as  X  NA  X  if the algorithm's F a particular benchmark is not available in its original literature.
Table 6 shows that PSO-ITC has the most superior searching accuracy as it successfully solves almost all tested functions.
Speci fi cally, the PSO-ITC locates the global optima of eight out of 10 problems, that is, two times better than the second ranked
OCABC. Also, the PSO-ITC is the only algorithm to fi nd the global optima for Sphere, Schwefel 2.22, Schwefel 1.2, Schewefel 2.21, and Ackley functions. 4.9. Comparative study on two real-world engineering design problems
In this section, we study the feasibility of the proposed PSO-ITC in engineering applications. More precisely, we investigate the performance of the PSO-ITC over two real-world engineering design problems, namely (1) the gear train design problem ( Sandgren, 1990 ) and (2) the spread spectrum radar polyphase code design problem ( Das and Suganthan, 2010 ). The descriptions and mathematical models of these two engineering design pro-blems are presented in the following subsections. 4.9.1. Gear train design problem
The gear train design problem aims to optimize the gear ratio for a compound gear train that contains three gears. The objective function of this problem is represented as ( Sandgren, 1990 ) f  X  x  X  X  1 6 : 931 x 1 x 2 x must be as close as possible to 1/6.931 to minimize the cost of gear ratio in the gear train. The bound constraint of this problem restricts the number of teeth of each gear in the range of 12 4.9.2. Spread spectrum radar polyphase code design problem
The spread spectrum radar polyphase code design problem plays an important role in the radar system design. This problem has no polynomial time solution, and its formal statement is de fi ned as follows ( Das and Suganthan, 2010 ): Global min f  X  x  X  X  max f  X  1  X  X  X  ; ... ;  X  2 m  X  X  X g X  10  X  where X  X f X  x 1 ; ... ; x D  X  A R D j 0 r x j r 2  X  g and m  X  2 D 1, with  X  X  X  X  0 : 5  X   X  D 4.9.3. Experimental settings for the two real-world engineering design problems
In this study, all the 10 PSO variants employed in the previous experiment are tested in these two engineering design problems. The parameter settings of each algorithm remain the same as in the previous experiment. For the gear train design problem, the population size ( S ) and the maximum fi tness evaluation numbers ( FE max ) are set to 10 and 3.00E  X  04, respectively. Meanwhile, we consider the spread spectrum radar polyphase code design pro-blem for D  X  20. The S and FE max of this problem are set to 20 and 2.00E  X  05, respectively. The experimental settings for these two problems are summarized in Table 7 . 4.9.4. Simulation results of the two real-world engineering design problems
The simulation results over 30 independent runs for the gear train design and spread spectrum radar polyphase design pro-blems are presented in Table 8 , which contains the values of mean fi tness ( F mean ), standard deviation ( SD ), t-test's result ( h ), and mean computational time ( t mean ).

For the gear train design problem, almost all PSO variants exhibit excellent searching accuracy, except for the BPSO. Among these PSO variants, our proposed PSO-ITC achieves the third best
F value, that is, its searching accuracy in solving the gear train design problem outperforms seven other peers, namely APSO, FPSO, FIPSO, OLPSO-L, HPSO-TVAC, RPPSO, and BPSO. Although the
F mean value produced by the PSO-ITC in the gear train design problem is slightly inferior to that of FLPSP-QIW and FlexiPSO, the former is at least two times more superior to the latter two in terms of computational overhead (represented by t mean ). Mean-while, all involved PSO variants have a similar searching accuracy in tackling the spread spectrum radar polyphase design problem, as the produced F mean values are relatively similar. As shown in
Table 8 , the searching accuracy exhibited by the PSO-ITC in this problem is competitive because it achieves the third best F values. In terms of searching accuracy, the performance deviation between the PSO-ITC (i.e., F mean  X  1.10E  X  00) and the fi
FLPSO-QIW (i.e., F mean  X  1.02E  X  00) is relatively insigni latter is only 1.08 times better than the former. On the other hand, the mean computational time required by our proposed PSO-ITC (i.e., t mean  X  2.66E  X  02 s) to solve the spread spectrum radar poly-phase design problem is signi fi cantly less than that of FLPSO-QIW (i.e., t mean  X  9.63E  X  02 s). More precisely, the proposed PSO-ITC is 3.62 times better than the FLPSO-QIW in terms of computational overhead. Based on the simulation results in Table 8 , we conclude that our proposed PSO-ITC achieves a better trade-off between the produced F mean and the t mean values compared with its peers. The prominent performance of the PSO-ITC in terms of searching accuracy and computational overhead proves that its application is indeed feasible in real-world engineering problems. 4.10. Discussion
The simulation results of the benchmark and real-world problems indicate that our proposed PSO-ITC has superior search-ing accuracy, searching reliability, and convergence speed com-pared with the other nine well-established PSO variants and six cutting-edge MS algorithms. The excellent performance of PSO-ITC is attributed to the two major contributions proposed in our work, namely the ITC module and the proposed learning framework. The ITC module aims to achieve better control of the exploitation/ exploration searches of PSO-ITC particles by linearly increasing the particle's connectivity with time. The linearly increasing scheme is adopted in the ITC module as early studies ( Kennedy, 1999 ; Kennedy and Mendes, 2002 ; Shi and Eberhart, 1998 ) revealed that particles at the early stage of optimization need to perform more exploration, which makes small topological connectivity prefer-able. At the later stage of optimization, particles should exploit the most promising explored region, which requires large topological connectivity. To prevent particle stagnation in the local optima, a shuf fl ing mechanism is incorporated in the ITC module to offer a new searching direction for the particle if it fails to improve the global best fi tness for z successive FEs.

The proposed learning framework consists of a new velocity update mechanism and a new NS operator. For the new velocity update mechanism, two exemplars of c exp,i and s exp,i are generated to update the velocity of particle i . Both exemplars are generated from particle i ' s neighborhood through the roulette wheel selection to ensure that good quality exemplars are employed to guide particle i to a more prominent search space. If particle i fails to improve its personal best fi tness when evolved through the new velocity update mechanism, the NS operator is triggered. In the NS operator, another exemplar, the o exp,i exemplar, is used to further evolve particle i . Unlike the c exp,i and s exp,i exemplars, the o exp,i exemplar is derived from the c guide,i and s guide,i guidance particles contributed by another particle's neighborhood. This mechanism establishes information exchange between the different neighborhoods that exist in the population, thereby allowing particle i to locate potentially better unexplored regions based on the useful information provided by other neighborhoods. In addition, when the particle is evolved through the new velocity update mechanism or the new NS operator, the particle can be attracted towards or repelled from its exemplar depending on its exemplars  X  fi tness. This mechanism automatically assigns different search tasks (i.e. , exploration and exploitation) to different particles in the population, thereby resolving the explora-tion/exploitation balancing issue.

Although the proposed PSO-ITC ex hibited superior performance in the previously reported experiments, it is applicable only to uncon-strained single-objective (SO) problems with continuous search space. Moreworkneedstobedonetofurtherextendtheapplicabilityofthe proposed PSO-ITC to a more general c lass of optimization problems, including those with discrete and mixed search spaces as well as multiple-objective (MO) problems. For example, MO problems have a rather different perspective compared with SO problems because the former contains more than one objective that needs to be achieved simultaneously. Also, unlike SO problems which consist of only one global optimum, a set of solutions, namely the Pareto-optima set, are considered equally important in MO problems. In general, two main aspects need to be considered to adapt the proposed PSO-ITC for MO problems.First,thePSO-ITCneedstoguidesolutionstowardthe Pareto-frontier by employing strategies, such as Pareto-ranking or
Pareto-sorting ( Fonseca and Fleming, 1995 ). Second, some mechan-isms, such as sharing or niche methods ( Fonseca and Fleming, 1995 ), need to be incorporated in the PSO-ITC to ensure that a set of well-distributed solutions are generated across the Pareto-frontier. For more discussions of the extension of an optimization algorithm to facilitate its application in a more general class of optimization problems, refer Page et al. (2012) .

In this paper, our main suggestion is to explore the possible bene fi ts of combining the ITC module with the proposed learning framework in the context of PSO algorithms in solving the uncon-strained SO optimization problem with continuous search space.
Extensive experimental results obtained from our current study prove that the combination of the ITC mo dule and the proposed learning strategy signi fi cantly enhances the searching performance of PSO in the aforementioned search space. In our future works, we will extend the applicability of PSO-ITC to a diverse class of optimization problems, such as discrete, mixed, and multi-objective search spaces. 5. Conclusion In this paper, the PSO-ITC is proposed to solve unconstrained
SO optimization problems with continuous search space. The ITC module is developed to vary the particle's topology connecti-vity during processing, thereby achieving better balance of the exploration/exploitation searches. In addition, a new learning framework, which consists of a new velocity update mechanism and a new NS operator, is incorporated into the PSO-ITC. Both aforementioned strategies aim to improve the searching accuracy of the algorithm by generating the more promising exemplars as the guidance particles. The simulation results reveal that the proposed PSO-ITC signi fi cantly outperforms its peers in terms of searching accuracy, searching reliability, and computation cost.
This superior performance implies that the increasing topology approach and the new learning framework are promising ways of enhancing the searching performance of PSO.
 Acknowledgments editor and the reviewers for their signi fi cant contributions to the improvement of the fi nal paper. The authors would also like to thank Abdul Latiff Abdul Tawab, Ahmad Ahzam Latib, Nor Azhar
Zabidin, and Amir Hamid for their technical supports. This research was supported by the Universiti Sains Malaysia (USM) Postgraduate Fellowship Scheme and the Postgraduate Research
Grant Scheme (PRGS) entitled  X  Development of PSO Algorithm with Multi-Learning Frameworks for Application in Image Segmentation.  X  Appendix A. Convergence curves for 50 dimensional problems References
