 difference t and learning in cortical networks of neurons.
 non-spiking approximations to the spiking network conside red in section 2. randomly sampled from this subset with a uniform distributi on of digit classes. changed in dependence of the firing times t synaptic neuron z which was chosen in the simulations according to the varianc e tracking rule 7 . Pixel values x duced for each variable y Every neuron y firing of one of the neurons z winning neuron at time step t was chosen from the soft-max distribution where u  X  y STDP with the learning curves shown in Fig. 1B was applied to a ll synapses w neurons y after STDP (according to Fig. 1B) was applied to their weight s w for 50 ms (like in panel A). The three output neurons z models for the three shown handwritten digits according to F ig. 3C. models which the output neurons z 4 4 learning (using rule (12)) in a corresponding non-spiking n eural network N sisting of thresholds w connection from the i th input node y vector z  X  X  0 , 1 } K with P K for each pixel the difference w possible values (black/white) of the variable x neurons had created internal models for the newly introduce d digit 4 . over { 1 , . . . , K } defined by We consider the case where there are arbitrary discrete exte rnal variables x variables y In other words: the group G ing for the discrete variable x p ( x ) , . . . , p K ( x ) that factorize, i.e., for arbitrary distributions p words: there exists some distribution over hidden binary va riables z k with z w by the neural network N as defined before: for In addition, N a mixture of multinomials of the type (4).
 by demanding that is maximized.
 Note that the architecture N then the weighted sum u stochastic WTA rule of N Expectation Maximization (EM) is the standard method for ma ximizing E mation to the maximization step. 3.1 Reduction to EM The standard method for maximizing the expected log-likeli hood E tribution p of the form p ( y | w ) = P E p  X  [log p ( y | w )] where KL( . ) denotes the Kullback-Leibler divergence.
 achieving E w setting with values for the variables z distribution (2) of the output of the neural network N Hebbian learning rule to the weights w of the neural network N 3.2 A Hebbian learning rule for the M-step Hebbian learning rule: It is obvious (using for the second equivalence the fact that y Analogously one can show that E[ X  w calculations one can show that E[ X  w update of w statistics, as log a ki +1 role of the learning rate  X  as the reciprocal of the equivalent sample size 6 . decaying learning rate  X  ( t ) such that P  X  unsupervised learning.
 One can easily see the correspondence between the update of w rule of Fig. 1B. In fact, if each time where neuron z neuron y of for the non-spiking network where some attributes are missi ng (i.e., y group G N 3.3 Stochastic online EM each M-step of a batch EM approach for maximizing E  X  is applied just once (for z z ing E to increase the value of F . We set According to (5) one can write p ( y | w ) = P K arrives at the following conditions for the Lagrange multip liers  X  : which yield  X  Plugging these values for  X  into  X  example y , drawn according to p  X  , is expected to increase E (7). 3.4 Impact of missing attributes non-spiking network N action is then not to change the weights w well as (12), reduce also these weights by  X  if z analysis (13): where r is the probability that i belongs to a group G this probability r is independent of the neuron z external variable x E-step according to (2). 3.5 Relationship between the spiking and the non-spiking ne twork with the simple STDP curve from Fig. 1B (and external variabl es x from neurons y N Each firing of a neuron z plication of the Hebbian learning rule (12). Each neuron y t , and a value  X  y missing attributes, as discussed in section 3.4.
 Since several neurons z implemented through (12) according to the analysis of secti on 3.3. 1 tive learning approach.
 instead an almost constant negative part.
 quite well by experimental data.
 Acknowledgments References
