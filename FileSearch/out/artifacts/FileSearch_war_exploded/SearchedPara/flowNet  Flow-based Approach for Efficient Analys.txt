
A complex system is defined as a network having a significantly large number of objects and complex connec-tivity among them. Biological networks, such as metabolic networks, protein interaction networks and gene regulatory networks, are typically described as the complex systems. Biological networks contain the information of biochemi-cal reactions or biophysical interactions between molecular components at a certain environmental condition. Since molecular functions are performed by a sequence of such reactions and interactions, biological networks are valuable resources for predicting functions of unknown genes or proteins and discovering functional pathways. Systematic analysis of biological networks has thus become a primary issue in Bioinformatics research.

Recently, the inherent, dynamic and structural behaviors of biological networks have been characterized in a topo-logical perspective to uncover hidden knowledge in the systems. Small-world phenomenon [1] is an example of the intriguing features of biological networks. It is known that the average clustering coefficient is higher than expected by random chance, but the average shortest path length is significantly small. In sparse networks, it can be verified by the connections through hubs between any node pair. Another typical property of complex biological systems is the scale-free distribution [2] which indicates the power-law degree distribution having a heavy tail. The scale-free networks have the clustering coefficient distribution decreasing as the node degree increases. This observation can be interpreted as low-degree nodes belong to dense subgraphs having the links to a few hubs. The networks are thus vulnerable on targeted attacks to the hubs, but robust on random attacks.
 Modularity is another key property of biological networks. A module (also called a functional module) is defined as a maximal set of molecules that participate in the same function [3]. It can be identified from biological networks as a sub-network whose components are highly associated with each other. In recent studies, it has been investigated that biological networks are typically modular in terms of connectivity [4]. A wide range of graph-theoretic algorithms have been applied to biological networks for identifying functional modules [5]. However, they had a limitation in accuracy and efficiency because of the critical challenges as following:
In this paper, we present a novel flow-based approach, called flowNet, to efficiently analyze large-sized networks with complex connectivity. Our approach is on the basis of the functional influence model on biological networks. This model has the assumption that a molecular component (a node) functionally influences another in a network by its information flowing through all possible links. We then introduce a dynamic flow simulation algorithm to generate the flow pattern of the influence of each node. The patterns exhibit the quantity of functional influence of a node on the others across the whole network. Those patterns are useful in many applications for knowledge discovery. For example, we can identify modules using state-of-the-art pattern clustering algorithms. The main strength of the flow-based approach is efficiency. Our flow simulation algorithm runs very ef-ficiently in sparse networks having a low average degree. Furthermore, we experimented the module identification in a real application to the yeast protein interaction network. We demonstrated that our approach outperforms previous graph clustering methods with respect to accuracy.
Since the flow-based approach requires a weighted net-work as an input, we also propose two weighting schemes for unweighted networks. The assigned weights should prop-erly represent the intensity or reliability of the edges. If other resources supporting the evidence of network connections are available, we can use the supervised approach by inte-grating the information to measure edge weights. However, if they are unavailable, we have to use the unsupervised approach which estimates edge weights by combination of the local connectivity around the object of interest and the global connectivity across the whole network. Each method was also tested in the yeast protein interaction network.
Previous graph clustering methods can be categorized into three groups: density-based clustering, partition-based clus-tering and hierarchical clustering. First, the density-based clustering approaches search for densely connected sub-graphs. A typical example is the maximum clique algorithm [6] for detecting fully connected sub-graphs. Because of the strict constraints of the maximum cliques, relatively dense sub-graphs can be identified rather than complete sub-graphs by either using a density threshold or optimizing an objective density function [7]. Various algorithms using alternative density functions have been recently presented, e.g., com-puting a density of k -core [8], allowing the percolation of k -cliques [9], tracking density and periphery for each neighbor [10], connecting weak siblings and comparing with chordal graphs [11] and statistically measuring the quality of sub-graphs [12]. These methods have been frequently applied to biological networks because of the feasibility of generating overlapping clusters. However, even though the density-based methods accurately detect the subsets of potential functional modules, they are not able to identify uniform groups of nodes. According to the scale-free distri-bution, sparsely connected nodes are abundant in biological networks. Since the sparse connections decrease the density of clusters, a significant number of nodes are excluded from the clusters generated by the density-based methods.
The partition-based clustering approaches explore the par-tition of a network including all sparsely connected nodes. The Restricted Neighborhood Search Clustering (RNSC) algorithm [13] searches the best partition using a cost function. It starts with randomly partitioning a network, and iteratively moves the nodes on the border of a cluster to an adjacent cluster to decrease the total cost. It finally finds the partitions with the lowest cost. A critical drawback of this method is that the prior knowledge of the exact number of clusters in a network is required. As another partition-based approach, the Markov Clustering (MCL) algorithm [14] finds the clusters by a mathematical bootstrapping procedure. It uses the iterative rounds of expansion and inflation that promote the strongly connected regions and weaken the sparsely connected regions, respectively. This process finally converges towards a partition of the graph. However, the number of clusters highly depends on the inflation parameter. The CASCADE algorithm [15] implements the selective voting of representatives for each node to group the members of the same votes, and iteratively refines the clusters based on the occurrence probability. The occurrence probability of a series of node pairs is propagated through the graph via the quasi-all-path algorithm. This algorithm does not require the prior knowledge of the number of clusters, but is computationally inefficient as a shortcoming.

The hierarchical clustering approaches are widely used in graph clustering because of several advantages. First, they are able to reveal hierarchical organizations within complex systems in a global view. They can also flexibly determine the number of clusters in a network. The hierarchical clus-tering methods are classified into two groups: the bottom-up approaches (e.g., the agglomerative algorithm) and the top-down approaches (e.g., the divisive algorithm).

The bottom-up approaches start from single-node clusters and iteratively merge the closest nodes or clusters into a super cluster. For the iterative merging, the similarity or distance between nodes or clusters should be measured, e.g., the similarity using the reciprocal of the shortest path distance between two nodes [16] and the similarity from the statistical significance of common interacting partners [17], [18]. The similarity or distance can be measured in two steps to improve the accuracy. The UVCLUSTER algorithm [19] first uses the shortest path distances as primary distances to apply the agglomerative hierarchical clustering. Next, based on the clustering results, it calculates the secondary distances. As a greedy optimization algorithm [20], two sub-graphs to be merged can be found on each iteration by searching the best modularity. The Super Paramagnetic Clustering (SPC) method [21] is another example of iterative merging. The most similar pair of nodes is selected from the identical ferromagnetic spins. Despite the advantages of hierarchical clustering, these approaches may not have a meaningful guidance of halting the merging process to yield true functional modules. In addition, the clustering results of iterative merging are analogous to those from density-based methods because density functions are generally used to halt the merging process. The bottom-up hierarchical clustering approaches hence have the same drawbacks to the density-based methods.

The top-down approaches have the opposite procedure, starting from one cluster including all nodes in a graph and recursively dividing it. The recursive minimum-cut algo-rithm [22] is a typical example of the top-down hierarchical clustering approaches. However, it is computationally expen-sive to find the minimum number of cut in a complex system. Thus, the node or edge cut is selected using alternative measures. For example, it can be found using betweenness centrality [23], which assesses the fraction of the shortest paths passing through the node or edge. Iterative elimination of the nodes or edges with the highest betweenness value divides a graph into two or more sub-graphs, and the itera-tion is recursively proceeded into each sub-graph to detect final clusters [24]. Instead of the betweenness measured from the global connectivity pattern, the local connectivity can be considered to select the interconnecting edges to be cut [25]. As a disadvantage, finding the break point is time-consuming, in particular, for the application to large-sized, complex biological networks. Also, the top-down hierarchical clustering approaches are sensitive to noisy data, which frequently occur in real biological networks. A. Functional Influence Model
We consider a biological network as an undirected, weighted graph G ( V, W ) with a set of nodes V and a set of weighted edges W . Suppose each edge has its weight w i,j as the intensity or reliability of the link between two nodes, v and v j . If there is no edge between v i and v j , w i,j The edge weighting schemes we use will be discussed in detail in section 5.

The functional influence model is designed to describe the propagation of functional information of a node over the entire network. This model is thus implemented by simulating the quantity of the influence of a node v i  X  V on the others v j  X  V, j = i in the input graph G ( V, W ) . The primary assumption is that each node contains the self-information which can be propagated through all possible links. As a central component of this model, we first define the path strength S of a path p as the product of the weights of all the edges on p .
 where p = v 0 ,v 1 ,  X  X  X  ,v n . v 0 is the start node and v the end node of p . w i ( i +1) denotes the weight of the edge between v i and v ( i +1) .  X  is the normalization parameter to make the path strength rated in the range between 0 and 1. d i is the shape parameter. It represents the degree of connectivity of v i .  X  is the scale parameter which depends on the network structure. Since the shape parameter does not force the starting and ending nodes of p ,weset d 0 =1 . The formula 1 then becomes The path strength of a path p thus has a positive relationship with the average weight of the edges on p . It also has inverse relationships with the length of p and the degrees of the nodes on p . As the length of p increases, the product of the normalized weights decreases monotonically. In the same way, as the average degree of the nodes on p increases, the path strength of p decreases. For example, in Figure 1, the higher the edge weights, w 0 , 1 , w 1 , 2 and w 2 , 3 , the higher the path strength S ( v 0 ,v 3 ) . And, the higher the degrees of the nodes v 1 and v 2 ,thelower S ( v 0 ,v 3 ) .

Next, we formulate the measurements of the quantity of a functional influence between two nodes. In a view of discrete paths, the influence is measured by the path strength between them. In general, the single-path-based method or the all-path-based method is used to calculate the path strength. The single-path-based strength between two nodes is obtained by the maximum path strength among all possible paths between them, whereas the all-path-based strength between two nodes sums up the strength of all the paths between them. In terms of computational efficiency, the single-path-based method has a better performance. However, it does not take into consideration the effect from any alternative paths. In contrast, although the all-path-based method handles all influential factors in the network topology, it is not computationally acceptable. In addition, as a weakness of the measurements by discrete paths, they do not capture the cycling effect from the nodes repeatedly involved.
Therefore, the functional influence model should consider all options for the potential influence between two nodes through links. A walk in a graph is a sequence of nodes including cycles. The quantity of an influence of a node on another is calculated by the cumulative strength from all possible walks between them. In Figure 2, suppose we measure the functional influence F ( v 0 ,v 9 ) of a node v a node v 9 in the weighted network. To calculate F ( v 0 ,v the prior knowledge of the influence of v 0 on the neighbors of v 9 , i.e., F ( v 0 ,v 6 ) , F ( v 0 ,v 7 ) and F ( v 0 obtained first. In other words, given F ( v 0 ,v 6 ) , F ( v F ( v 0 ,v 8 ) , the degrees of v 6 , v 7 and v 8 , and the weights of the edges connecting to v 6 , v 7 and v 8 , we can estimate F ( v 0 ,v 9 ) using the Formula 2. In the same way, F ( v F ( v 0 ,v 7 ) and F ( v 0 ,v 8 ) requires the prior knowledge of the influence of v 0 on the neighbors of v 6 , v 7 and v 8 respectively. Thus, the iterative computation of the influence of v 0 on the other nodes can finally achieve the quantity of the functional influence of v 0 on v 9 through all links across the network.
 B. Dynamic Flow Simulation Algorithm
We present an algorithm to efficiently implement the func-tional influence model. This algorithm performs dynamic flow simulation under the assumption that flow takes a constant time to traverse each edge. It requires a weighted network and a source node s as inputs, and produces the distribution of the functional influence of s on all the other nodes in the network as an output. For the influence of a node s on a node t , s and t are called a source node and a target node, respectively, of the flow from s to t . The flow pattern of s then represents the distribution of the influence of s on all the other nodes in the network. It is thus accomplished by the flow simulation starting from the source node s to all target nodes.

We first introduce the notations for our flow simulation algorithm. f s ( x  X  y ) denotes the quantity of an influence of s , which is traveling from a node x to a node y where x and y are connected directly. inf s ( y ) denotes the quantity of an influence of s on y . Intuitively, inf s ( y ) has the maximum value when y = s . Finally, P s ( y ) is the accumulation of inf s ( y ) during the continuing flow.

The initial influence rate inf s ( s ) is a user-specific con-stant value. For example, we can assign 1 as inf s ( s ) .The flow then delivers the initial rate of s to its neighbors with being reduced by normalized weights. where w s,y is the weight of the edge between s and y , and  X  is the normalization parameter to set the term into the range between 0 and 1. The quantity of the influence of s on y , inf s ( y ) , is then updated by adding the sum of all incoming flow to y from its neighbors. The functional information of s traverses all connected edges by the formula defined as where | N ( y ) | denotes the degree of y . During the flow, the quantity of the influence of s on each node is repeatedly updated by Formula 4, traverses the connected edges by For-mula 5, and is accumulated into P s . The flow on a walk stops if the influence reaches a user-dependent minimum threshold  X  inf . The flow simulation starting from s terminates when there is no more flow in the network.

As an output, the set of cumulative quantities of functional influences P s of s over all the target nodes t in the network becomes the flow pattern of s . The set of target nodes t is considered as the feature space F in the output format. Given the connectivity and weights of the input network, the output pattern of s on F becomes a unique characteristic of s . Applying the flow simulation starting from every source node, we finally obtain the set of flow patterns of all nodes in the network. The flow simulation algorithm is described as following. 1) Initialize inf s ( s ) . 2) Compute the initial flow f init ( s  X  y ) by Formula (3) 3) Compute inf s ( y ) by Formula (4) for each y . 4) Compute the flow f s ( y  X  z ) by Formula (5) for each 5) Remove the flow f s ( y  X  z ) if it is less than a 6) Replace z with y , and repeat 3,4,5 and 6 until there 7) Output cumulative inf s ( x ) for each x  X  V . C. Flow Pattern Clustering
The flow patterns, generated by our flow simulation algorithm, are used to identify modules in a complex system. The existing pattern clustering algorithms can be applied to this task. The schematic view of the flow pattern clustering procedure using a simple example is illustrated in Figure 3. Figure 3 (a) is a synthetic weighted network with 20 nodes. The weight of an edge is described as its thickness. Figure 3 (b) is the set of flow patterns generated by our flow simulation algorithm. Each pattern stands for an object, representing the unique characteristic of a source node. The x-axis is the feature space F , i.e., the set of target nodes in the flow. The y-axis represents the quantity of an influence of a source node on each target node. Figure 3 (c) shows the clustering results by searching coherent patterns.
The simplest way of clustering the set of flow patterns is the agglomerative hierarchical clustering using the coherence for each pair of patterns. The coherence of two patterns, X and Y , can be calculated by the Pearson correlation coefficient r . where X i is the quantity of the influence of a source node x on a target node i , and X is the mean value on all target nodes in the network. The agglomerative hierarchical clustering method then iteratively merges the most coherent pattern to generate the set of clusters.

A multitude of advanced pattern-based clustering algo-rithms [26], [27] have been proposed recently. They usually capture similar patterns in a subspace of features, i.e., a subset of target nodes in the flow simulation. The key issue of the pattern-based clustering methods is to consider the shifting or scaling effects when the similarity between patterns is measured. For example, the pCluster algorithm [27] solves the shifting effects by pScore in a 2  X  2 matrix of the object by feature, pScore where X i is the quantity of the influence of a source node x on a target node i . The shifting patterns P can be accepted when pScore ( P ) is less than a user-specified threshold. This algorithm also solves the scaling effects by transforming the values to the logarithmic form.

The efficiency is one of the major strengths of our approach. The overall time complexity relies on the pattern clustering algorithm we adopt. The run time of the flow simulation algorithm does not exceed that of the pattern clustering. In general, the random walk on a graph is manipulated by the matrix computation. The product of adjacency matrices for each round of random walks runs in O ( n 3 ) .Forthe n rounds, the time complexity grows to O ( n 4 ) . However, our flow simulation algorithm outperforms the matrix computation because it efficiently chases the flow through only existing links, and prunes each flow as soon as it becomes trivial.

Unlike other graph-theoretic methods, the run time of our flow simulation algorithm is obviously unrelated to the network diameter because flow traverses through all possible walks including cycles. Since our algorithm uses a threshold to halt the flow as a user-specified criterion, the theoretical upper-bound of its run time is unknown. However, we investigated the potential factors that affect the time complexity of our flow simulation.

We structured synthetic networks with different features and monitored the average run time of flow simulation starting from randomly selected 200 source nodes. First, we created the networks by increasing the numbers of nodes, from 500 to 7000 , but retained the density as 0 . 002 .The density of a network represents the proportion of the number of actual edges to the number of all possible edges. Next, we used the networks produced by the same change of the number of nodes but a constant average degree of 5 . The results are shown in Figure 4 (a). When the density is constant, the rum time increases as adding nodes, because of the squared increase of the number of edges for the constant density. However, when the average degree is constant, the run time is uniform regardless of the network size. We additionally tested the run time with the networks created by the change of density in the fixed number of nodes as 2000 and in a constant average degree of 5 . As shown in Figure 4 (b), when the network size is fixed, the run time increases as the density becomes higher. However, when the average degree is constant, the run time is also uniform regardless of the network density. These results indicate that the average degree of networks is a more critical factor to reduce the time complexity of flow simulation than the size or density of networks. Since the average degree of complex systems is typically low in a power-law degree distribution, the flow simulation does not dominate the overall time complexity.
Since our flow simulation algorithm requires a weighted network as an input, the unweighted graphs should be converted to weighted graphs. The intensity or reliability of the link between two nodes should be properly measured as the edge weight. We present two different approach for weighting edges, an unsupervised approach and a supervised approach. The supervised approach can be applied if other resources supporting the evidence of a connection between two nodes are available. However, if they are unavailable, we have to apply the unsupervised approach using only the network connectivity.
 A. Unsupervised Approach
The unsupervised approach estimates the edge weights based on the connectivity in the network. The connectiv-ity can be assessed in a local view and a global view. For the local connectivity, we focus on the proportion of other close indirect connections between two nodes directly connected. For example, if two nodes x and y , which are directly connected, i.e., e ( x, y )  X  E , have many common neighbors (i.e., many alternative length-2 paths), then their connection has high reliability. If the neighbors of x have many interconnections to the neighbors of y (i.e., many alternative length-3 paths), then it implies their connection is also reliable. We thus measure the local-connectivity-based weight w loc x,y of the edge between two nodes x and y by the ratio of the number of alternative length-2 and length-3 paths. where N ( x ) is the set of neighbors of x , and | N ( x ) | is the size of N ( x ) .

For the global connectivity, all possible alternative paths should be investigated to weight an edge. However, because finding all possible paths between two nodes is not com-putationally acceptable, we propose a heuristic algorithm. Suppose we measure the global-connectivity-based weight w x,y of the edge between two nodes x and y .First,we disconnect the edge between x and y . Next, we iteratively disconnect an edge randomly selected until x does not have any indirect connecting path to y . w glob x,y is then approximated by the ratio of the number of disconnected edges to the total number of edges.

We finally obtain the edge weight w x,y from the combina-tion of the local-connectivity-based weight and the global-connectivity-based weight. The coefficients c 1 and c 2 depend on the network complex-ity. If the network is clearly modular, then c 1 should be larger than c 2 . However, if the network consists of plenty of interconnections among potential modules, smaller c 1 and larger c 2 compute the weight more accurately.
 B. Supervised Approach
Suppose structured ontology data sets, which contain the information related to the network components, are avail-able. The supervised approach estimates the edge weights by measuring semantic similarity between two connected ob-jects. Previously introduced sematic similarity measurements are categorized into two groups, path-length-based methods and information-content-based methods.

Counting the path length between two concepts in a taxonomy is the simplest way to calculate the similarity between them. It can be scaled down by the maximum depth of the taxonomy. The amount of common parent concepts can be used to normalize the similarity distorted through the depth of the concepts [28]. For example, the similarity of two concepts C 1 and C 2 can be calculated by where C 0 is the most specific common parent concept of C and C 2 , and C root is the root concept. However, these path-length-based methods are not applicable to the taxonomy structure in which the edges do not uniformly represent the same degree of specificity.

As an alternative way, the information-content-based se-mantic similarity measures are frequently used. In Informa-tion Theory, self-information is a measure of the information content associated with the outcome of a random variable. The amount of self-information contained in an event c de-pends on the probability P ( c ) of the event. More specifically, the smaller the probability of the event, the larger the self-information to be received when the event indeed occurs. The information content of a concept C in the taxonomy is then defined as the negative log likelihood of C ,  X  log P ( C ) .
Semantic similarity between two concepts can be mea-sured by their commonality, i.e., more common information two concepts share, more similar they are. Resnik [29] proposed to measure the semantic similarity of the concepts, C 1 and C 2 , by the information content of the most specific concept C 0 that subsumes both C 1 and C 2 . Lin [30] considered not only commonality but a difference between two concepts by normalizing Resnik X  X  similarity measure with the sum of the individual information contents of C 1 and C 2 . Formula 12 and 13 can precisely measure the intensity of edges in unweighted networks when the information contents in the available taxonomy are reliable.
 A. Data Source
Our flow-based approach can be applied to a wide range of biological networks such as metabolic networks, protein in-teraction networks and gene regulatory networks. We tested our algorithm using the yeast protein interaction network. We downloaded the core version of the yeast protein-protein interaction data set from the DIP database [31], which includes 5663 interactions among 2314 distinct proteins. It thus makes a sparse graph with the density of 0.002. The protein interaction network also follows the typical proper-ties of complex systems. As the small-world phenomenon, the average characteristic path length is approximately 4, i.e., on average, 4 hops through edges starting from a node can reach any other nodes in the network. The  X  value in the scale-free distribution is around 1.7. The relatively high average clustering coefficient, around 0.25, demonstrates that the network is modular. However, it is difficult to identify modules because of the complex inter-connectivity between them.
 B. Network Weighting We computed the edge weights by a supervised approach. As the structured ontology data, we employed the Gene On-tology (GO) [32]. The ontology terms in GO are structured as a directed acyclic graph (DAG) according to the  X  X s-a X  and  X  X art-of X  relationships among them. Each characterized protein is annotated on one or more terms. The annotations follow the transitivity property, i.e., if a protein is annotated on a GO term, then it is also included in the annotations of all parent terms on the paths towards the root term. The proportion of proteins annotated on a GO term thus becomes the information content for semantic similarity measures in Formula 12 and 13.
As derived from the semantic similarity measure in For-mula 12, the edge weight between two nodes x and y is calculated by where G ( x, y ) is a set of proteins annotated on the GO term, whose annotation includes both x and y , and G root is a set of proteins annotated on the root GO term. As a similar way to Formula 13, it can be normalized by the information contents of individual terms. where P i ( x ) is the ratio of the annotation size on the GO term t i whose annotation includes x , P j ( y ) is the ratio of the annotation size on the GO term t j whose annotation includes y , and P ij ( x, y ) is the ratio of the annotation size on the most specific common parent term of t i and t j . However, for edge weighting in the protein interaction network, we used Formula 14 because Formula 16 produced a biased distribution of weights. Almost 70% of interactions had the weights greater than 0.9 by Formula 16.

We evaluated the measured edge weights in terms of func-tional consistency. We downloaded the functional categories from MIPS [33] and observed the proportion of common functions that interacting proteins have. Figure 5 shows the functional consistency with respect to the edge weight normalized into the range between 0 and 1. It verifies that the weights were properly measured because they approximately have a linear relationship with the functional consistency. C. Assessment of Flow Patterns
The application of our flow pattern mining approach to a protein interaction network is based on the hypothesis such that two proteins, which have similar flow patterns, are likely to perform the same biological function. To validate this hypothesis, we assessed the correlation of flow patterns in terms of functional co-occurrence of proteins from MIPS. We first randomly selected two sets of 450 protein pairs: the pairs that co-occur in the same functional categories and not, respectively, and then implemented our flow simulation algorithm starting from each selected node. The correlation of each pair of flow patterns is calculated by Pearson coefficient and normalized by cube root transformation.
Figure 6 shows the mean values of the correlations in two groups. The error bars represent the standard deviation of two distributions. The result indicates that the pairs co-occurred in the same functions have higher correlations of flow patterns than the pairs in different functions. It implies that the flow patterns are capable of classifying and discriminating proteins with regard to their biological functions.
 D. Functional Module Identification
We implemented our flow simulation algorithm starting from each node to achieve the full set of flow patterns. We then applied the pCluster pattern clustering algorithm [27] for module identification. To test the performance of identifying specific functional modules, we compared the output modules to the MIPS functional categories. We extracted the proteins appeared in the fourth-level functional categories (the third-level category if there is no fourth-level in a branch), which are related to  X  X ell cycle and DNA processing X . We thus used 452 distinct proteins annotated on 18 different functional categories. Since a protein can perform multiple functions, the modules should be overlap-ping, i.e., a fraction of nodes belong to several different modules simultaneously.

For statistical evaluation of the output modules, we used the p  X  value from the hypergeometric distribution, which is defined as: where | V | is the total number of distinct proteins, | X number of proteins in a reference function, n is the number of proteins in an output module, and k is the number of common proteins between the function and the module. It is understood as the probability that at least k proteins in a module of size n are included in a reference function of size | X | .Low P in Formula 17 indicates that the module closely corresponds to the function because the network has a lower probability to produce the module by chance.
We assessed the performance of our algorithm com-paring to the previous methods in different categories: the clique percolation method [9] in density-based ap-proaches, the edge-betweenness cut method [34] in hierar-chical approaches, and the Markov Clustering (MCL) [14] in partition-based approaches. The clique percolation and edge-betweenness cut methods use the unweighted interac-tion network. However, since the MCL accepts a weighted network as an input, we use the same weights to our flow simulation for implementing the MCL. The clustering results of these four methods are shown in Table I. Although the clique percolation method was able to find the overlapping clusters and the MCL uses the weighted network as an input, they generated numerous small-sized clusters with a very few disproportionally large clusters, which caused low accuracy. The edge-betweenness cut method yielded a large number of clusters because all isolated sub-networks are considered as clusters. The number of disjoint clusters made this method inaccurate. As a result, our flow pattern mining algorithm showed better performance than the three compet-ing methods. It demonstrates that our flow-based approach properly handled the complex connections by dynamic flow simulation. Moreover, the problem of false positive data, which frequently appear in biological networks, could be resolved by weighting interactions with their reliability.
Discovering hidden patterns in complex systems has been urgently required in diverse fields. Interestingly, the complex systems have shown collective behaviors in topology. In this paper, we proposed the functional influence model and dynamic flow simulation algorithm for efficient analysis of biological networks. The algorithm quantifies the influence of each node on the others through links, and generates a flow pattern for the node. The pattern thus represents a unique characteristic of the biological component corre-sponding to the node in terms of its functional relationships with the other components. Using the set of output flow patterns, our approach collaborates with top-notch pattern clustering algorithms to detect modules in a complex bio-logical network.

In conclusion, this study could have many potential appli-cations in the field of Computational Systems Biology. Using the yeast protein interaction network, we demonstrated our approach identified functional modules, the sets of proteins that participate in the same biological function, in high confidence. As a future work, this work will be consolidated by developing an advanced pattern clustering algorithm that runs in high efficiency and high accuracy with large-scale, noisy patterns.

