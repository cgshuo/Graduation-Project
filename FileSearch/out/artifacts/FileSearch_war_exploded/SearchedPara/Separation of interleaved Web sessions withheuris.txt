
In the past decades World Wide Web (WWW) has become one of the main sources of information. It has enabled unprece-dented data exchange between different parties. Companies need web sites to reach customers and sell their products, institutions advertise their programmes, individuals effectively access various Internet services. With the growing number of web pages and documents, web sites are coping with increasing competition. It is becoming difficult to attract new customers and retain the existing ones. Under such circum-stances, only web sites that understand the needs of their customers will prevail. Analysing users X  behavior has therefore become an important part of web page data analysis. A sequence of clicks that a user makes while browsing through a web site is called a clickstream . Clickstream data represent the main data source for the analysis of user behavior [1]. Analysis of web data such as clickstreams entails certain problems with availability and quality of data [2].

Behavioral patterns of web site visitors have become one of the most important sources of information in most web-aware companies. They play an important part in daily transactions and important business decisions. It is essential to perform reliable data analyses, and this requires both appropriate methods and data. The quality of the the discovered patterns crucially depends on data quality. Clickstreams are partitioned into user sessions each representing one visit of a user to a web on data representation with first-order Markov models, upon which the separation process is build. To the very best of our knowledge, the Markov approach has not been used before for this particular purpose. The only remotely similar work concerning separation of interleaved sessions is by Viermetz et al. [5] who work on building a user X  X  clicktree. Such a clicktree contains all possible paths a user could have taken through a web site map. While their approach is dedicated to better understanding of actual user behavior, our approach is focused on separation process. Based on training first-order Markov model on validated (clean) sessions, our approach is effective in separating process. We introduce a special-purpose methodology for evaluation of separation process, evaluate our method on clickstreams from different sources, and present experimental results.
 A. Clickstream
In order to attract more visitors to our web site we need to know who our visitors are, what they do on our site, and what X  X  annoying them. A great aid in achieving this goal is clickstream data. Clickstream is a sequence of hyperlink clicks or pages visited as a visitor explores a particular Web site. Clickstream data are often large, inadequately structured, and show incomplete picture of users X  activity. For example, server side log files do not register browser and network caching ( X  X ack X  browser actions or requesting pages in intermediate server X  X  cache) [2].

Clickstream data are collected, preprocessed and cleaned prior to the analysis. Work done in this phase crucially affects the quality of further analyses.

The basic, and the most usual, form of clickstream data from a Web server is stateless  X  no session identifier is logged. This is the consequence of the fact that the HTTP protocol is stateless. Each line in the log file shows an isolated resource retrieval event, but does not provide a link to other events in a user session. Since we are interested in all user actions in a certain time period, we have to group all related individual events into a user session. The process is called sessionization . Without some context help it is next to impossible to reliably identify complete user session. Berendt et al. [3] describe sessionization tools based on heuristic rules and assumptions about the site X  X  usage, and complain that they are seriously prone to errors.
 B. Discrete Markov models for clickstream analysis
A Markov chain (a discrete Markov model) is defined as follows. We have a set of states S = { s 1 ,s 2 , ..., s N } , where N denotes the number of states. The process starts in one of the states and moves forward from one state to another at regularly spaced discrete times. The Markov chain moves from state s i to state s j with the transition probability p ij (the next state depends only on the current state). The starting state is defined by a probability distribution. We denote the steps in which the process changes states as discrete time t =1 , 2 , ...n , time-oriented heuristics. Ting et al. [1] developed the Pattern Restore Method (PRM) algorithm, which attempts to recon-struct missing server-side clickstream data based on referring site information and the Web site X  X  link structure. Berendt et al. [3] used the web site structure to reconstruct incomplete sessions.

Markov models have also been used in the clickstream analysis area. Many approaches have been proposed. In [8] the authors primarily focus on visualization aspects of web site navigation patterns. Model-based clustering (using finite mixtures of Markov models) is used to assign users to clusters. Sarukkai [9] employs Markov chains to both predict the most likely sites that a user will visit next and generate tours (sequences of web sites) that a user might be interested in according to his or her current browsing history. The model can be continuously updated with data provided by new users of the web sites it covers.

In [6] authors look at the ways of reducing the state-space complexity of higher order Markov models, while retaining their high coverage. This is achieved by first building a full model from some of the training data, then pruning it with the rest. The results show that these methods can greatly reduce the state-space complexity while generally improving its accuracy. Ypma and Haskes [10] expanded the work done by Cadez and Heckerman [8] by using mixtures of Hidden Markov models. This enabled them to process the dataset without first grouping actual URI requests into page categories. Their work shows that even without artificially categorized webpages, a mixture of HMMs will generate classes of pages with similar characteristics.

In [11] we discussed a basic process for separating inter-leaved sessions. Separation is based on first-order Markov model and sequential allocation of pages. Presented process takes into account the fact that transition between two pages s  X  s i +1 is more likely to belong to one of the consisting sessions. Each page s i in an interleaved session is sequentially allocated to one of the started separated sessions according to the probability of transition from the last page of separated session to the page s i . Separating process can be seen in the Figure 1. The deficiency of the presented method is that it uses greedy approach which does not guarantee separated sessions with the highest probability of transition between consisting pages. The method was also limited to separation of interleaved session into up to two separated sessions only. We also found out that for large web sites with tens of thousands of web pages (possible states), the use of higher-order Markov models is discouraged because of increasing time and space complexity ( K -th order polynomial).
 D. Evaluation of separating process
Let S 1 and S 2 be two HTTP sessions (sequences of Web pages). Let S be an interleaved session produced by mixing S 1 and S 2 . After the separation process we get two separated sessions: S 1 and S 2 . In order to evaluate the quality of separating process, we need to measure similarity between original sessions ( S 1 and S 2 ) and sessions, produced with Weighted longest common subsequence (WLCS).
 E. Separating interleaved sessions with best-first search
In clickstream analysis, discrete Markov models are fre-quently used as analytical tools. In our approach discrete Markov models are only used as an appropriate clickstream data representation. The problem of separating interleaved sessions can be transformed into the problem of searching in discrete Markov model space of partially separated interleaved sessions.

Generally speaking, state space is a graph whose nodes correspond to problem situations, and finding a solution to the problem corresponds to finding a path in the graph. In the separating process we split a sequence of pages, (representing user sessions), into one or more shorter non-overlapping sub-sequences. The process of assigning pages runs sequentially from the first to the last page in a sequence. Sequential order of pages in the separated sessions has to be the same as the order of pages in the interleaved session.

We begin the separating process with the original inter-leaved session of length n and an list of n empty separated sessions (the maximum possible number of sessions, where each state is in its own session). We finish with an empty interleaved session and a list of k  X  n nonempty separated sessions. In each step we transfer the subsequent state (Web page) from the interleaved session to one of the growing separated sessions. Actually, we have to search for the optimal sequence of assignments of pages to the separated sessions.
The problem of separating sessions can be formulated as a state-space approach. Each state Z represents interleaved session S P =[ s 1 ,s 2 ,...,s n ] of length n and r started separated sessions S R .
 The starting state is represented as From one state to another we move with legal actions (transi-tions with positive weight). Figure 2 shows an example of two sample states and action, that transforms one state to another.
Each action represents an assignment of the next page s i from interleaved session at the end of one of growing separated sessions S R . One of the possibilities is also starting a new separated session with the number R +1 .

An example of a tree that represents a state space with the first few states is shown in Figure 3. We reach most probable (the cheapest in this sense) path from the start node to one of possible goal node, which represents the sequence of page allocations to separated sessions S R . The cost of the solution is the sum of edges along the solution path. Unfortunately, due to the space and time complexity reasons, it is impossible to use established graph algorithm (e.g Dijkstra X  X  algorithm). The size of the state space graph is too large. There are 142417 possible states in a state space for separating an interleaved session length of 10. An algorithm that cuts down on the size of the subgraph that must be explored, should be used instead.

Problem states connected with actions form directed graph that represent state space. Every state is connected with other states according to valid actions of partial interleaving.
Let us assume that from the state Z we can transit to a set { Z next } of adjacent states by appending the page page s i from the interleaved session to the end of one of the separated sessions S R . Suppose state Z has n r separated sessions. Since the first unallocated page s i of state Z can be appended at the end of an existing session or start a new session, the state Z leads to n r +1 new states ( Z next ). It means that every state Z has n r +1 successors. Every state in the set of successors {
Z is seen that the number of nodes in the state space increases rapidly with the height of the state space search tree.
If we have an interleaved session S P with n pages, the state space for the problem of interleaving represents the tree G with height n . With every allocated page s i from the interleaved session to one of the separated sessions, the height of the tree G increases by 1. The number of nodes for the tree G according to the tree level is shown in table I. It can be proven that the number of nodes to the level k correspond to Bell numbers B k , which represent the number of partitions of set of size k . Bell numbers can be computed using the recursive formula
If we want to find the most probable session separation, we would principally have to search all possible states of the tree G . The number of all states in the tree G is n k =0 B k . Exhaus-tively searching all the states in graph G can be extremely time consuming due to the problem of combinatorial complexity we do not know the page allocations, we obviously cannot calculate the probability of transitions between them. The function h ( Z ) is therefore an estimate of the cost of the path from node Z to the goal node. Therefore, h ( Z ) is a heuristic guess, based on our knowledge of session separation problem. We constructed a non-trivial admissible heuristic function h for the problem of separating interleaved sessions. Admissible heuristic function guarantees to find optimal solutions, that means the cheapest 1 path from start to goal node if the path exists. Best-first search which uses admissible function, finds the first goal node that is also the optimal one. Admissible functions are optimistic. That means that they underestimate the length of the path to the goal node. We considered this condition while constructing our heuristic function.
 F. Heuristic function
Admissibility is a desired property of heuristic evaluation functions. When admissible heuristic evaluation functions are used with search algorithms such as A  X  or RBFS it is guaranteed that search algorithms will always find an optimal solution (minimum-cost path) [18]. Let, for each node n in the state space h  X  ( n ) denote the cost of an optimal path from n to a goal node. A known theorem about the admissibility of A  X  says: an A  X  algorithm that uses a heuristic function h such that for all nodes n in the state space is admissible [19]. An inadmissible heuristic evaluation func-tion does not guarantee to find an optimal solution.

Regarding our problem of separating interleaved sessions we have to find the goal node, which has the biggest product of transitions between pages in all separated sessions. Admissible heuristic function h ( Z ) has to optimistically estimate the separation of the remaining part of the interleaved session. It has to maximize the product of the transition probabilities (and therefore minimize the sum of negative logarithms) between pages, that have not been assigned to the separated sessions yet. In the following part we will present several heuristics for the problem of separating interleaved sessions. We start with a trivial heuristic and continue with improved ones. The last one gives the best results, so we used it with the separation process. All developed heuristic functions are admissible in case of starting pages of separated sessions can be determined with certainty. If separated session starting pages could not be determined reliably the separating process results in too many separated sessions.

A trivial heuristic admissible function for the problem of separating interleaved sessions is or (in negative logarithm space)  X  log h 0 ( Z )=0 . Number 1 denotes the probability of transition between pages in an interleaved session. Typically this scenario is rare. Usually one or more probabil-ities of transition between pages P ( s i  X  1  X  s i ) inside one of the separated session is smaller than the maximal probability of transition to page s i from any page. Heuristic function is admissible but it X  X  deficiency is that when calculating the max { P (?  X  s i ) } it takes into account all pages in the system not only the pages that actually present in the interleaved session. That results in max { P (?  X  s i ) } being closer to value 1 and trivial heuristics that could actually be. The biggest shortcoming of the presented heuristics h 1 is, that all nodes on the same level of the search tree have the same heuristic value, and thus does not provide enough guidance.

In the calculation of the maximum probability of transition to page s i ( max { P (?  X  s i ) } ) we can take in account only those pages that reside in the interleaved session. The transition to the page s i is possible only from these pages. We can further cut down the number of pages that we take in account when calculating max { P (?  X  s i ) } by considering the actual state of the separating process. Let us observe the node z 3 in the Figure 4. In the further separation process the page S 5 will be either assigned to the existing session consisting of pages [ S 3 ,S 0 ,S 1] , or it will follow one one of the pages that have not yet been assigned and reside before page S 5 . When we calculate max { P (?  X  S 5) } we can take into account only pages S 3 ,S 0 ,S 1 and S 4 . The described procedure can be seen in Figure 5. The heuristic function h 2 is admissible since we can use the same considerations as we used for h 1 . The values of h 2 are closer to that of h  X  , resulting in better guidance of the search through state space tree. The presented heuristic function can be further improved with taking into account the structure of already separated part of the interleaved session.
Let us take a look again to the example in the figure 4 that shows node z 3 . An interleaved session is partly separated in two started separated sessions as we can see in the figure 6. The first page in the interleaved part of the session S 4 can be only attached at the end of one of the current separated session. When we calculate max { P (?  X  s i ) } we need not consider all the pages in the separated part but only the last page in each separated session. In case of node z 3 and assignment of page S 4 the expression is: max { P (?  X  S 4) } = max { P ( S 0  X  S 4) ,P ( S 1  X  S 4) }
Similarly to the heuristic function h 2 , we consider only the pages that reside before page s i . The procedure for calculating at the same time, and this creates interleaved sessions. Since users have to be logged on we can always determine the session entry point. The Web server log files use the basic CLF format. Clickstream data was taken for 4 months of use, which resulted in more than 150.000 user sessions.

The second clickstream source is taken from a large web shop, which is considerably different from the student records information system. Users do not have to sign in (except for buying items), it has many more users and many more pages. We had to cut down number of states of Markov model in order to efficiently use it. Every state of our Markov model represents a group of pages, not an individual page. We transformed the web shop pages to 900 states. The session entry point can be almost any page, which makes separating interleaved sessions harder. The Web shop site map has plenty of links between pages. In fact only few pages are not linked with all others. The web shop generates about 10.000 user sessions a day.

For both clickstreams we took the same steps as with artificially generated data. After separating interleaved sessions we evaluated results with evaluation methods that we presented earlier.

The proposed procedure was used for separating interleaved sessions of two real-world data sources: web shop and student records IS. Clickstream data were first cleaned, sessionized and prepared for the data webhouse. Cleaned quality click-stream data were analysed in order to find out what are typical user sessions for both clickstream data sources. In the phase of interleaving and separating interleaved sessions only the sessions that comply with the typical user sessions were used.
In the separation process the first order discrete Markov model (Markov chain) was used as an appropriate tool for clickstream data representation. For training the Markov model we used clean sessions from the data webhouse. Clickstreams from data webhouse were used partly for training set and partly for test set. 70% of clean session were used as a training set for Markov model and 30% of clean sessions for creating interleaved sessions in the test set in order to evaluate the true power of the proposed approach. Table II shows for both clickstream data sources size of the training set, the number of clean sessions available for generation of interleaved sessions and size of test set with interleaved ses-sions. We tested the process of separating interleaved sessions on artificially generated interleaved sessions made from real-world clean sessions. Interleaved sessions were created having in mind the properties and structure of typical real interleaved records IS have more defined structure, we can also more easily detect starting pages of consisting clean sessions. A possible reason for worse results for web shop may be that we used groups of pages instead of single pages for Markov model. Grouping pages together affects the results. Since the web shop site map is larger, there may be numerous user paths, that also affects the results. User can enter the web shop at almost any page, so it is harder to detect where the subsequent session in interleaved session starts. All this reflects in slightly better results for student records IS.

Figures 8 and 9 shows graphs for two different methods of results evaluation. Figure 8 reports results for student IS clickstream while Figure 9 reports results for web shop. Interleaved sessions were created as per Table II and separated. Each graph corresponds to one evaluation method. The X axis presents intervals for perfect match or F -measure based sequence similarity, while the Y axis shows percentage sepa-rated sessions that fall in the similarity interval. A dotted line in each graph represents the median session similarity for the corresponding similarity measure. Better results of separations are the ones that have more separations evaluated close to 1. An ideal result would be presented with a graph that has just one column in the interval of session similarity between 0.9 and 1.

The first graph in both figures depicts the first column in the table III, that is, the number of perfectly matched separated sessions. For student records IS 50% of interleaved sessions have been separated 100% correctly (session sequence similarity = 1) and for web shop 40%. The second graphs in both figures depict results according to the WLCS evaluation method. WLCS graphs show that majority of sessions are more than 50% similar to the original ones. Comparison of WLCS graphs for both clickstreams shows that the quality of interleaved sessions separation is much better for the student records IS than for the web shop. Let us focus only to the interval of similarity between 0.1 and 0.9 for WLCS evaluation method. The distribution of separated sessions with the similarity interval between 0.1 and 0.9 is quite similar to both clickstream data sources. The biggest difference is for the separated sessions with the similarity between 0 and 0.1. This are the separated sessions that have very little in common with the actual clean sessions that construe interleaved sessions, so we would like to cut down their number as much as possible. For the student records IS there are three times less badly separated sessions (10%) than for web shop (30.3%).

We propose a new method for improving the quality of clickstream data in pre-processing phase that is based on the first-order Markov model and best-first heuristic search. We present the motivation that led us to implementation, and apply the method in practice on two real data clickstreams. The pro-posed method proved to be quite successful. It gives promising results and works regardless of the number of contained sub-sessions. Since the method automatically determines the most probable number of interleaved sessions, the highest possible
