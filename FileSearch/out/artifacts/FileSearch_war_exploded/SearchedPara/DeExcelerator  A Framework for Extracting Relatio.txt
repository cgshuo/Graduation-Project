 In this paper, we aim at transforming partially structured documents, e.g. spreadsheets or HTML pages, into first normal form relations without any user interaction. To this end, we will at first present a set of typical denormalizations and irregularities that appear in spreadsheets and web tables alike in Section 2. These features are usually introduced to enhance readability, but constraint the reuse of these docu-ments. We will then present the DeExcelerator , a framework for normalizing a partially structured document into one or more relational tables in Section 3, and give the results of a preliminary user study in Section 4. Then, we will discuss re-lated work as well as the demonstration scenario in Sections 5 and 6, respectively.
By manually studying a corpus of real-world Open Data published as Excel spreadsheets on the platform data.gov (see Section 4), we identified a set of typical denormaliza-tions that often appear in spreadsheets. Our goal was to transform the corpus of documents from this platform into a set of tables that can be handled by an off-the-shelf rela-tional database management system. While we originally studied spreadsheets to identify these characteristics, other tables created for human consumption, e.g. web tables on Wikipedia, show most of the identified characteristics, as well. Note, that most of these denormalizations are not in-troduced because of lack of database know-how, but because spreadsheets are designed to be comprehended visually by a human, not to be processed by a DBMS.
 We found the following (non-exhaustive) list of challenges for spreadsheet normalization. Examples for all challenges are shown in Figure 1. some relational data, into a first normal form relation that can be imported into a relational database. It implements a pipeline of abstract extraction phases, each one cleaning or removing one of the artifacts and denormalizatons described in Section 2. The phases and their order correspond to the challenges given in there.
 Before the first phase there is an ingestion step, in which input files are transformed into a generic representation. As the minimal, common representation of our problem space we chose a two dimensional array of strings, with optional cell-level metadata attached. It is simple enough to be used with HTML tables as input, which do not have much infor-mation attached to them except the structure of row and cell tags, but also allows to capture the metadata available in spreadsheets. After the ingestion step there will be cells containing metadata text, headers or data values at any position in the matrix, as shown in Figure 1.
 For each of the further phases, the DeExcelerator contains concrete implementations of the abstract extraction opera-tions, which are based on our study of real-world datasets, as well as on table extraction techniques from the literature (see Section 5). Extraction heuristics implemented in the DeEx-celerator operate on the string matrix only, but may use the cell-level metadata attached by the ingestion step, e.g., to use color information defined on the original spreadsheet cells as evidence for the header recognition. All implemented heuris-tics will return a transformed matrix , e.g. a matrix where cells containing textual metadata have been removed, as well as a confidence value. It may also attach new metadata to the cells of the matrix. The confidence value is used by the DeExcelerator to decide on the extraction output in case of conflicting results, e.g., two different sets of attribute names. For space reasons, we can not give all the heuristics currently implemented in the DeExcelerator. Notice however, that the source code of the framework and its operators is available (see Section 6). To give the reader a better understanding of the style of our heuristics, we will provide some selected examples.
 Consider the problem of header-detection , in which we want to find the separation between table header and data, e.g., the red line in Figure 1a. The DeExcelerator currently im-plements the following list of heuristics, whose output is combined to decide on a separator. relational data from source documents, for example Wran-gler[4] and Google Refine[3]. Both systems offer tooling to help a user working manually on a document cleaning project. In contrast, DeExcelerator is a predefined pipeline that can be applied to large heterogeneous documents collec-tions automatically. The user can be involved by creating new implementations of the extraction steps.
 The second category of related work covers table recognition algorithms. They exist for various types of input, e.g. web tables, web lists, PDF files and even images, and use a large variety of heuristic, learning-based and even many visual techniques. An extensive overview of these approaches is given in [6]. The DeExcelerator implements many previ-ously published heuristics for table recognition, and defines an abstract pipeline of extraction steps specifically tuned for transforming spreadsheets and web tables into relational tables. An especially active area of research is concerned with extracting relational tables from large HTML corpora and interpreting the meaning of their attributes, e.g., [5] and [2] among many others. While these approaches focus more on specifics of identifying relational tables in large corpora, and semantic annotation, respectively, the DeExcelerator focuses on syntactic artifacts that occur in tables meant for human consumption. So the DeExcelerator could be seen as a preprocessing step to these techniques.
In this interactive demonstration, users will be able to chal-lenge the DeExcelerator with their own Excel Spreadsheets, or use some of the packaged datasets from data.gov as input. We created a Web interface which visualizes the steps of the extraction pipeline and shows the input document as it transforms step by step into a relational table. The interface also displays the results of the heuristics implemented in each step, and thus allows the user to understand what is going on in each respective step. The DeExcelerator website 1 features a screencast, a link to the actual GUI, as well as a link to the source code. [1] K. Braunschweig, J. Eberius, M. Thiele, and W. Lehner. [2] M. J. Cafarella, A. Y. Halevy, Y. Zhang, D. Z. Wang, [3] D. Huynh and S. Mazzocchi. Google refine. [4] S. Kandel, A. Paepcke, J. Hellerstein, and J. Heer. [5] J. Wang, H. Wang, Z. Wang, and K. Zhu.
 [6] R. Zanibbi, D. Blostein, and R. Cordy. A survey of table
