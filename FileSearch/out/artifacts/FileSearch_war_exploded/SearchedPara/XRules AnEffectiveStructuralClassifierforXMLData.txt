 XML documen ts have recen tly become ubiquitous because of their varied applicabilit y in a num ber of applications. Classi cation is an imp ortan t problem in the data mining domain, but curren t classi cation metho ds for XML doc-umen ts use IR-based metho ds in whic h eac h documen t is treated as a bag of words. Suc h techniques ignore a signi -can t amoun t of information hidden inside the documen ts. In this pap er we discuss the problem of rule based classi cation of XML data by using frequen t discriminatory substructures within XML documen ts. Suc h a technique is more capable of nding the classi cation characteristics of documen ts. In addition, the technique can also be extended to cost sensi-tive classi cation. We sho w the e ectiv eness of the metho d with resp ect to other classi ers. We note that the metho d-ology discussed in this pap er is applicable to any kind of semi-structured data.
 H.2.8 [ Database Managemen t ]: Data Mining XML/Semi-structured data, Classi cation, Tree Mining The classi cation problem is de ned as follo ws. We have an input data set called the training data whic h consists of a set of multi-attribute records along with a special variable called the class . This class variable dra ws its value from a discrete set of classes. The training data is used to construct a mo del whic h relates the feature variables in the training data to the class variable. The test instanc es for the clas-si cation problem consist of a set of records for whic h only This work was supp orted in part by NSF CAREER Aw ard IIS-0092978, DOE Career Aw ard DE-F G02-02ER25538, and NSF gran t EIA-0103708.
 the feature values are kno wn while the class value is un-kno wn. The training mo del is used in order to predict the class variable for suc h test instances. The classi cation prob-lem has been widely studied by the database, data mining and mac hine learning comm unities [1, 4, 7, 10, 11, 12, 14, 15, 16]. However, most suc h metho ds have been dev elop ed for general multi-dimensional records. For a particular data domain suc h as strings or text [1, 17], classi cation mo dels speci c to these domains turn out to be most e ectiv e. In recen t years, XML has become a popular way of stor-ing man y data sets because the semi-structured nature of XML allo ws the mo deling of a wide variet y of databases as XML documen ts. XML data thus forms an imp ortan t data mining domain, and it is valuable to dev elop classi cation metho ds for suc h data. Curren tly, the problem of classi ca-tion on XML data has not been very well studied, in spite of its applicabilit y to a wide variet y of problems in the XML domain.
 Since XML documen ts are also text documen ts, a natural alternativ e for suc h cases is the use of standard information retriev al metho ds for classi cation. A simple and frequen tly used metho d for classi cation is the nearest neigh bor classi-er [10]. This metho d works quite well for most text applica-tions con taining a small num ber of class lab els. However, the use of the text format for classi cation ignores a signi can t amoun t of structural information in the XML documen ts. In man y cases, the classi cation beha vior of the XML docu-men t is hidden in the structural information available inside the documen t. In suc h cases, the use of IR based classi ers is likely to be ine ectiv e for XML documen ts. A second, but more promising metho dology for XML mining is to directly use asso ciation based classi ers suc h as CBA [16], CAEP [9] or CMAR [13], on the XML data. Even though an XML data record has hierarc hical structure, its structure can be attened out into a set, whic h allo ws the use of an asso cia-tion classi er. This also results in loss of structural informa-tion, but the overall accuracy is still somewhat better than the \bag of words" approac h for a text classi er.
 Recen t work has focused on the use of rule based classi ers [16] as an e ectiv e tool for data classi cation. Rule based classi ers have also been extended to the string classi cation problem [1]. Rule based classi ers are an interesting metho d whic h integrate the problem of asso ciations and classi ca-tion. These techniques pro vide an e ectiv e and scalable al-ternativ e for classi cation, and often turn out to be highly interpretable by their nature.
 In this pap er, we will discuss the problem of construct-ing structur al rules in order to perform the classi cation task. The training phase nds the structures whic h are most closely related to the class variable. In other words, the pres-ence of a particular kind of structural pattern in an XML documen t is related to its likeliho od of belonging to a par-ticular class. Once the training phase has been completed, we perform the testing phase in whic h these rules are used to perform the structural classi cation. We will sho w that the resulting system is signi can tly more e ectiv e than an asso ciation based classi er because of its abilit y to mine dis-criminatory structures in the data.
 The main con tribution of this pap er is to prop ose XR ules , a structural rule-based classi er for semi-structured data. In order to do so, we also dev elop XMiner whic h mines pertinen t structures for multiple classes sim ultaneously . We extend our classi er to the cost sensitiv e case, so that it can handle normal as well as skewed class distributions. We also sho w that our class assignmen t decisions are rooted in Bayesian statistics. We mo del XML documen ts as ordered, lab eled, rooted trees, i.e., child order matters, and eac h node has a lab el. We do not distinguish between attributes and elemen ts of an XML documen t; both are mapp ed to the lab el set. We denote a tree (an XML documen t) as T = ( V; B ), where V is the set of lab eled nodes, and B the set of branc hes. The lab el of eac h node is tak en from a set of lab els (also called items) L = f 1 ; 2 ; 3 ; :::; m g ; di eren t nodes can have the same lab el. Eac h branc h, b = ( x; y ), is an ordered pair of nodes, where x is the paren t of y . The size of T is the num ber of nodes in T .
 We say that a tree S = ( V s ; B s ) is an emb edded subtr ee of T = ( V; B ), denoted as S T , pro vided i) V s V , and ii) b = ( x; y ) 2 B s , if and only if x is an ancestor of y in T . Note that in the traditional de nition of an induc ed subtree, for eac h branc h b = ( x; y ) 2 B s , x must be a paren t of y in T . Em bedded subtrees are thus a generalization of induced subtrees; they allo w not only direct paren t-child branc hes, but also ancestor-descendan t branc hes. As suc h embedded subtrees are able to extract patterns \hidden" or embedded deep within large trees whic h will not be captured by the traditional de nition. If S T , we also say that T contains S . A (sub)tree of size l is also called a l -(sub)tree. The classi cation mo del discussed in this pap er can be used for the general case of cost-sensitiv e classi cation [8]. In this section, we pro vide some de nitions relev ant to this topic. We assume that the training database D for classi cation consists of a set of jDj structures, eac h of whic h is asso-ciated with one of k class variables. Let C = f c 1 : : : c be the k classes in the data. For a structure T 2 D , we use the notation T:c to refer to the class asso ciated with T . We assume that eac h of these structures is an XML documen t that can be represen ted in tree format. 1 There-fore the database D is essen tially a forest with N comp o-nen ts, so that eac h of the trees in the forest is lab eled with a class variable. The class lab el of eac h structure in D in-duces a partition of the database into k disjoin t parts. Let
Tree Structured XML documen ts are the most widely oc-curring in real applications. We note that even if an XML documen t is not a tree, it can alw ays be con verted into one by using a node splitting metho dology [5].
 D i = f T 2 Dj T:c = c i g , i.e., D i consists of all structures with class c i . Clearly D = k i =1 D i .
 The goal of classi cation is to learn a mo del, R : D ! C , R ( T ) = c j (where T 2 D and c j 2 C ), that can predict the class lab el for an unlab eled test instance. We can nd out how well the classi er performs by measuring its accuracy . Let D be some collection of structures T with kno wn lab els T:c . Let ( D ) = jf T 2 Dj T:c = R ( T ) gj denote the num ber of correct predictions made by the mo del for examples in D . Thus, ( D i ) gives the num ber of correct predictions for ex-amples with class c i , and ( D ) = k i =1 ( D i ) gives the total num ber of correct predictions made by R over all classes. The accuracy of the classi cation mo del R on data set D is the ratio of correct predictions to the total num ber of predictions made: ( R ; D ) = ( D ) jD j .
 For man y classi er mo dels, the accuracy is often biased in fa-vor of classes with higher probabilit y of occurrence. In man y real applications, the cost of predicting eac h class correctly is not the same, and thus it is preferable to use the notion of cost-sensitiv e accuracy . For eac h class c i , let w positiv e real num ber called weight , with the constrain t that i =1 w i = 1. The cost-sensitive accuracy , denoted de ned as the weigh ted average of the accuracy of the clas-si er on eac h class. Formally , we de ne There are sev eral cost-mo dels that one could use to compute the classi cation accuracy: Lemma 2.1. For proportional model cs ( R ; D ) = ( R ; D ) . In this pap er we will con trast the inverse cost-mo del with the prop ortional and equal mo del. The inverse mo del works well for binary classi cation problems with skewed class dis-tribution, since it gives a higher rew ard to a correct rare class prediction. Let D be any collections of trees with class lab els dra wn from C . For a tree T , we de ne its absolute supp ort in D , denoted A ( T; D ), as the num ber of trees in D that con tain T , i.e., The (relative) supp ort of T in D , denoted ( T; D ), as the fraction of trees in D that con tain T , i.e., T is said to be frequent in D if ( T; D ) min , where min is a user de ned minim um supp ort threshold.
 Rules are de ned as entities whic h relate the frequen t struc-tures on the left hand side to the class variables on the righ t. Suc h rules are able to relate the complex structural patterns in the data to the class variable. Formally , a structur al rule is an entity of the form T ) c i , where T is a structure, and c is one of the k classes.
 This rule implies that if T is a substructure of a given XML record x , then the record x is more likely to belong to the class c i . The \go odness" of suc h an implication is de ned by two parameters whic h were refer to as supp ort and strength. The glob al supp ort of T ) c i in the database D , is de ned as the join t probabilit y of T and c i , i.e., the percen tage of the trees in the database con taining T and having class lab el c Formally ( T ) c i ) = P ( T ^ c i ) = The last step follo ws from Equation 3. The local supp ort of a rule T ) c i is simply its relativ e frequency in D i , given as ( T; D i ). The strength of a structural rule can be measured by dif-feren t measures; we focus on three: con dence, likeliho od ratio, and weigh ted con dence, as de ned below.
 Con dence: The con denc e of the structural rule T ) c i is de ned as the conditional probabilit y of class c i given T , i.e., the ratio of the num ber of trees con taining T and having class lab el c i , to the num ber of trees con taining T in the entire database. Formally , we de ne Let's assume that we have k classes ( k 2), and let C i = C f c i g be the set of all classes other than c i . We de ne D i = D D i to be the set of trees in D with their classes tak en from C i . Our approac h for multi-class problems (with k &gt; 2) is to treat them as a binary class problem as follo ws: we compare eac h class c i with the rest of the classes tak en as a group to form a negativ e class C i . That is, we compare ( T ) c i ) with ( T ) C i ). Using the observ ation that D = D i + D i , we can rewrite Equation 5 as: It is clear that ( T ) c i ) = 1 ( T ) C i ).
 Lik eliho od Ratio: The likeliho od ratio for a rule T ) c de ned as the ratio of the relativ e supp ort of T in examples with class c i , to the relativ e supp ort of T in examples having negativ e class C i . Formally , it is de ned as follo ws:
Lemma 2.2. Likeliho od ratio for a rule is relate d to its con denc e by the formula: Pr oof : From Equation 5, we get A ( T; D i ) = ( T ) c i ( T; D ) (similarly for A ( T; D i )). Plugging into Equation Weigh ted Con dence: We de ne another measure called the weighte d con denc e , whic h com bines the above two mea-sures, given as follo ws: We can rewrite the Equation 8, as a weigh ted version of Equation 6, as follo ws: In other words, while con dence uses absolute supp orts, weigh ted con dence uses relativ e supp orts (i.e., weigh ted by class probabilit y). By next lemma, weigh ted con dence can also be though t of as a normalized likeliho od measure.
Lemma 2.3. The weighte d con denc e of a rule is relate d to its likeliho od by the formula: Pr oof : From Equation 7, ( T; D i ) = ( T ) c i ) ( T; D Plugging into Equation 8, we get: Lik e the value of w lies between [0 ; 1], while can tak e values between [0 ; 1 ]. In our exp erimen ts, we will study the e ects of using one measure over the other. Let denote the measure of strength; for con dence 2 , for weigh ted con dence w , and for likeliho od .
 We use the notation T ; ) c i to denote a rule with supp ort and strength . Our goal is to learn a structural rule-set R = f R 1 ; R 2 ; ; R m g , where eac h rule is of the form R i : T i ; ) c i , with min j and with min . That is, rules whic h satisfy a user-de ned level of minim um supp ort min , and a global minim um strength threshold, min . Note that min min for (weigh ted) con dence based measure and min min for likeliho od based measure. We set the default minim um strength values to min = 0 : 5 and min = 1 : 0; Giv en k classes C = f c 1 ; : : : ; c k g , with C i = C c D i is the portion of data set D with class c i and D i is the remaining data set, with class in C i . An unseen example T should be assigned to class c i if the probabilit y of class c given T , P ( c i j T ) is the greatest over all classes, i.e., assign c against the negativ e class C i , we assign T to class c i The three strength measures di er in whic h equation they use for class prediction. For instance, con dence measure
The notation denotes that the two entities are equiv alen t. directly uses Equation 10, since by de nition (Equation 5), ( T ) c i ) = P ( c i j T ). Thus using the con dence measure T is assigned to class c i if ( T ) c i ) &gt; ( T ) C i ). The likeliho od measure uses Equation 12. Rearranging the terms in Equation 12, we get P ( T j c i ) tion 7), we have ( T ) c i ) = ( T ; D i ) (Equation 12) assigns T to class c i if ( T ) c i ) &gt; P ( C The likeliho od measure assigns T to class c i if ( T ) c min . If we use the default value of min = 1, this corre-sponds to ignoring the ratio of class prior probabilities, i.e., or equal cost mo del) it mak es logical sense to use the class priors, since in the absence of any information, we should predict the class of T to be the class with higher prior. How-ever, if c i is rare (inverse cost mo del), then it is better to ignore the prior, since the prior ratio is biased in favor of the class with higher probabilit y. By setting the prior ratio to 1, we set all classes on an equal footing.
 Finally , the weigh ted con dence measure uses Equation 11 (consider its LHS): LH S = P ( T j c i ) P ( c i ) Once again, ignoring class priors ratio (i.e, setting P ( C 1), we obtain the de nition of weigh ted con dence in Equa-tion 9. Thus LHS of Equation 11 corresp onds to w ( T ) c and by Bayes rules we assign T to class c i if w ( T ) c i ( T ) C i ).
 As describ ed above, con dence measures strength across the entire database D . On the other hand, likeliho od measures the local tendency of the pattern to be asso ciated with the target class; it compares the local supp ort of the rule for the target class ( c i ) with its local supp ort for the negativ e class C i (the rest of the classes). In skewed data sets, with unev en class distributions, con dence is biased in favor of the dominan t class, since globally the patterns asso ciated with this class will have higher absolute supp orts compared to the minorit y class. Lik eliho od and weigh ted con dence do not have this bias, since they ignore class priors and use local relativ e supp orts. The classi cation task con tains two phases. The training phase uses a database of structures with kno wn classes to build a classi cation mo del; in our case a set of structural classi cation rules, called a rule-set . The testing phase tak es as input a database of structures with unkno wn classes, and the goal is to use the classi cation mo del to predict their classes. At the beginning of classi cation we have a database D = i =1 D i with kno wn classes; D i is the set of structures with class c i . Our goal is to learn a structural rule-set R = f R 1 ; R 2 ; ; R m g , where eac h rule is of the form R i : T c There are three main steps in the training phase: The rst step is accomplished via an ecien t structural-rule mining algorithm, XMiner , whic h we will discuss in detail in section 4. For the momen t let us assume that XMiner can be used to nd all structural rules related to any class. XMiner accepts as input a list of minim um supp ort thresh-olds for eac h class, i.e., min j ; 8 j = 1 ; k . XMiner outputs a set of frequen t rules for eac h class, R j = f R 1 ; ; R with m j rules, eac h rule having c j as the consequen t, i.e., R Since we want only predictiv e rules, we need to remo ve any rule that lacks predictiv e power. Consider a rule ( T ) c R . If its (weigh ted) con dence = w = 0 : 5 or if its likeliho od ratio = 1 : 0, then T cannot distinguish between the class c i and its negativ e class C i , and we prune suc h a rule from R i . In general, the acceptable range of values for a user-de ned minim um con dence threshold is min 2 (0 : 5 ; 1], while the acceptable range for minim um likeliho od is min 2 (1 ; 1 ].
 The goal of precedence ordering is to deriv e the nal com-bined rule-set R from the rule-set of eac h class based on a precedenc e relation , , whic h imp oses a total order on R , using a metho d analogous to that prop osed in CBA [16]. say that R i precedes R j , denoted R i R j , if the follo wing conditions are met: 1. The strength of R i is greater than that of R j , i.e., 2. i = j , but the supp ort of R i is greater than that of 3. i = j and i = j , but R i con tains a smaller num ber 4. If none of the above is true, then T i occurs lexicograph-For precedence ordering, we sort the rules across all classes using to deriv e the nal ordered rule-set R = k i =1 R i In the testing phase, the ordered rules are used in various ways to predict the target class for a new structure with unkno wn class. A rule T ) c i is said to match a given tree S , when its anteceden t, T , is a substructure of S , i.e., T S . A rule set R is said to cover an example tree S , if at least one rule matc hes S . In general, a rule set may not necessarily cover all examples (ev en in the training set D ). Since a classi er must pro vide coverage for all possible cases, we need to de ne a default lab el, denoted default-class , whic h will be chosen to be the lab el of a test example, if none of the rules matc h it.
 Let = f S 2D j69 ( R i : T i ) c i j ) 2R^ ( T i S ) g , be the set of examples from the training set D whic h are not covered by the ordered rule-set R . Let i = f S 2 j S:c = c i g be the set of unco vered training examples with class c i . A simple way to choose the default-class is to pick the ma-jorit y class in , i.e., default-class = arg max c i fj i = ; , then pick default-class to be the ma jorit y class in D . The problem with this metho d is that it does not tak e into consideration the real cost of the classes (it uses the pro-portional cost mo del by default). The approac h we adopt is to choose the class that maximizes the cost-sensitiv e ac-curacy of the resulting rule-based classi er. Let ( D ) de-note the num ber of correct predictions for data set D using our rule-set R . If 6 = ; , then the default class is given as default-class = arg max c i f w i j i j jD weigh t w i (obtained by setting i = D i ). It is clear that suc h a technique is sup erior from the persp ectiv e of a cost-sensitiv e approac h.

Lemma 3.1. The cost-sensitive accuracy is maximize d for default-class = arg max c j f w j j j j jD Pr oof: Assume 6 = ; . The base accuracy for a given class c in D i is given as ( R ; D i ) = ( D i ) jD overall base cost-sensitiv e accuracy is given as Assume that we pick class c j as the default class. This a ects only the accuracy of class c j due to the addition of correct predictions for class c j in , whereas the accuracy of all c 6 = c j remains unc hanged. Therefore, we have ( R ; D j ) = After simplifying, we get cs ( R ; D ) = w j j j j jD Since cs old ( R ; D ) remains the same no matter whic h class we pick as default, the overall accuracy is maximized for the class yielding the maxim um value of w j j j j jD If = ; , we set j = D j . So the class yielding maxim um accuracy is the one with maxim um w j .

Cor ollar y 3.1. For the proportional cost model, the ac-curacy is maximize d if the default class is the majority class in (or in D if = ; ).
 Pr oof: Assume 6 = ; . Substituting w i = jD i j jD j in the term to be maximized, we get j i j jD j . This is maximized for the class with the maxim um value of j i j , i.e., the ma-jorit y class in . If = ; , then setting i = D i gives the desired result.
 As describ ed above we prune all unpredictiv e rules having min = 0 : 5 or min = 1 : 0. Also recall that when building a mo del we alw ays compare the con dence of the rule on class c i versus its negativ e class C i . In some cases, the rules may be poorly related to an example. This happ ens when the average (weigh ted) con dence or likeliho od of the rules whic h are matc hed by a given example are close to 0 : 5 or 1 : 0, resp ectiv ely, for a given class c i . This means that the rule is equally predictiv e of c i as well as C i , and thus not suitable for classi cation. If the user sets min &gt; 0 : 5 or min any example with matc hing rules having average (weigh ted) con dence in the range [1 min ; min ] or having average likeliho od is in the range [1 = min ; min ], is assumed to be an ambiguous case, whic h cannot be accurately classi ed. Suc h ambiguous vases are added to the default set (essen tially treating them as examples having no matc hing rule in R ), whic h is used for the nal determination of default-class as describ ed above. At the end of training our classi cation mo del is complete. It consists of an ordered collection of predictiv e rules R , and a default-class. The testing phase tak es as input the classi cation mo del, and a data set D 0 of examples with unkno wn classes. The goal of testing phase is to predict the class for eac h test example. There are two main steps in testing: The rule retriev al step is simple; for eac h test example S in the database D 0 , we nd the set of all matc hing rules, called the matching rule-set , R ( S ) = f R i : T i i ) c i j T For predicting the class of S 2 D 0 , we can use sev eral dif-feren t approac hes for com bining the statistics of the matc h-ing rule-set R ( S ). There are two cases to be considered: First, if R ( S ) = ; , when there are no matc hing rules. In this case, the class is predicted to be the default class, i.e., S:c = default-class . On the other hand, if R ( S ) 6 = ; , then let jR ( S ) j = r . Also let R i ( S ) denote the matc hing rules in R ( S ) with class c i as the consequen t, and let jR i ( S ) j = r Eac h rule in R i ( S ) is of the form T j j ) c j i , with Any matc hing rule T k 2 R ( S ) R i ( S ) is more predictiv e of a class other than c i . However, XMiner nds the sup-port of T k all classes (see Section 4), so we can compute the strength of T k for the negativ e class C i ( T k n ) C strength of T k for c i , i.e., the rule T k k ) c i is given as = 1 n if (or w ), and as k = 1 = n if (by Equations 5, 7, 8). Thus, for eac h class c i we can nd the strength of eac h structural rule for that class. A matc h-ing rule with &gt; 0 : 5 or &gt; 1 : 0 corresp onds to a rule with positiv e predictiv e power for c i , while a matc hing rule with &lt; 0 : 5 or &lt; 1 : 0 is more predictiv e of the negativ e class, and thus has negativ e predictiv e power for c i .
 There are sev eral possible metho ds for com bining evidence: In our exp erimen ts we used the average con dence metho d for com bining evidence, since it gave us the best results. We note that for average strength-based metho ds, if the classi cation beha vior of a test instance is ambiguous (equal to or close to default min values), the classi er can also output this fact as useful information to the end user. While classi ers traditionally striv e for 100% coverage (i.e., they predict a lab el of eac h test case), a practical application may often bene t greatly from kno wledge of the fact that certain test instances are harder to classify than others. This results in lower coverage, but a better understanding of the overall classi cation pro cess. In order to determine the set of rules, XR ules rst needs to mine the frequen t subtrees in the data. Sev eral recen t meth-ods for tree mining have been prop osed, suc h as FREQT [6], TreeMiner [21], and TreeFinder [19]. FREQT is based on an apriori-st yle, level-wise, candidate generation and pattern matc hing based coun ting approac h. A similar approac h is describ ed in [20]. TreeFinder uses an Inductiv e Logic Pro-gramming approac h, and it is not a complete metho d, i.e, it can miss man y frequen t subtrees, esp ecially as supp ort is lowered or when the di eren t trees in the database have common node lab els. TreeMiner uses a novel vertical rep-resen tation for fast subtree supp ort coun ting. It is a com-plete metho d, and outp erforms a level-wise metho d similar to FREQT. We thus chose TreeMiner as a basis for XMiner . Giv en a dataset D with k classes, and thus k partitions D one approac h to mining structural rules would be to mine eac h D i separately using TreeMiner, and then to com bine the results. There are two problems with this approac h: 1) XR ules needs to kno w the supp ort of a tree T in eac h class, but T may be frequen t in one class D i , but not in another D j . 2) We would need one extra scan to coun t suc h missing class supp orts, thus this approac h is inecien t. XMiner extends TreeMiner to nd all frequen t trees related to some class, and also incorp orates multiple minim um sup-port criteria, one per class. This ensures that any tree gener-ated is suitable for classi cation purp oses. Lik e TreeMiner, XMiner utilizes the vertic al tree represen tation for fast sup-port coun ting and uses a depth-rst (DFS) pattern searc h. Let X be a k -subtree of a tree T . Let x k refer to the last node of X . Eac h node in T has a well-de ned numb er , i , according to its position in a depth-rst (or pre-order) traversal of the tree. We use the notation n i to refer to the i th node according to this num bering scheme ( i = 0 : : : j T j 1). Let T ( n l ) refer to the subtree rooted at node n l , and let n be the righ t-most leaf node in T ( n l ). The scope of node n is given as the interv al [ l; r ], i.e., the lower bound is the position ( l ) of node n l , and the upp er bound is the position ( r ) of node n r . Figure 1 sho ws a database of 3 trees, with 2 classes; for eac h tree it sho ws the node num ber n i , node scop e [ l; u ], and node lab el (inside the circle). Let D denote a database of trees (i.e., a forest), and let subtree S T for some T 2 D . Eac h occurrence of S can be iden ti ed by its match label , whic h is given as the set of matc hing positions (in T ) for nodes in S . More formally , f s 1 ; s 2 ; : : : ; s m g be the nodes in S , with j S j = m . Then S n , and 2) branc h b ( s j ; s k ) 2 S i t i j is an ancestor of t in T . Condition 1) indicates that all node lab els in S have a matc h in T , while 2) indicates that the tree top ology of the matc hing nodes in T is the same as S . A matc h lab el is unique for eac h occurrence of S in T . We say that two k -subtrees X; Y are in a pre x equivalenc e group i they share a common pre x up to the ( k 1)th node. Let P be pre x subtree of size k 1. We use the notation [ P ] k 1 to refer to its group, whic h con tain all the last items ( k -th node) of trees that share P as their pre x. We use the notation L ( X ) to refer to the scope-list of X . Eac h elemen t of the scop e-list is a triple ( t; s; m ), where t is a tree id (tid) in whic h X occurs, s is the scop e of x k is a matc h lab el for X . Since a subtree can occur multiple times in a tree, eac h tid can be asso ciated with multiple scop es and matc h lab els.
 The initial scop e-lists are created for single items i that oc-cur in a tree T . Let [ l; u ] be the scop e of a node with lab el i . Since the matc h lab el of item i is simply l we omit storing m when dealing with the scop e-lists of single items. We will sho w below how to compute pattern frequency via joins on scop e-lists. Figure 1 sho ws the scop e lists for the frequen t single items (the minim um supp ort is 100% for both classes). Item 5 is not sho wn, since it is not frequen t for any class; it has supp ort 50% in class c 1 . Figure 2 sho ws the high level structure of XMiner . The main steps include the computation of the frequen t items and the enumeration of all other frequen t subtrees via DFS searc h within eac h group. XMiner also main tains a global class index sho wing the class for eac h tree in the database. This index is used to quic kly update the per class supp ort for a candidate tree to chec k if it is frequen t in any class. Figure 1 sho ws the class index for the example database. Figure 2: XMiner : Tree Mining for Classi cation The input to Enumerate-Xrules is a set of elemen ts of a group [ P ], along with their scop e-lists. Frequen t subtrees are generated by joining the scop e-lists of all pairs of ele-men ts (including self-joins). Before joining the scop e-lists a pruning step can be inserted to ensure that all subtrees of the resulting tree are frequen t. If this is true, then we can go ahead with the scop e-list join, otherwise we can avoid the join. The collection of candidate subtrees is obtained by extending eac h tree in a group by adding one more item (the last item) from another tree in the same pre x group. We use R to denote the possible candidate subtrees that may result from extending tree with last node x , with the tree with last item y (denoted x y ), and we use L ( R ) to denote their resp ectiv e scop e-lists.
 The subtrees found to be frequen t at the curren t level form the elemen ts of groups for the next level. This recursiv e pro-cess is rep eated until all frequen t subtrees have been enu-merated. In terms of memory managemen t it is easy to see that we need memory to store intermediate scop e-lists for two groups, i.e., the curren t group [ P ], and a new candidate group [ P x ]. We now describ e how we perform the scop e-list joins for any two subtrees in a group [ P ]. Let s z = [ l z ; u z the scop e for a node z . We say the s x is strictly less than s , denoted s x &lt; s y , if and only if u x &lt; l y . We say that s con tains s y , denoted s x s y , if and only if l x &lt; = l u x &gt; = u y . When we join last elemen ts x y in a group, there can be at most two possible outcomes, i.e., we either add y as a child of x or as a sibling of x to the class [ P To chec k if the subtree, obtained when y is added as a child of x , occurs in an input tree T with tid t , it is su-cien t to searc h if there exists triples ( t y ; s y ; m ( t ; s x ; m x ) 2 L ( x ), suc h that: i) t y = t x = t , ii) s and iii) m y = m x .
 In other words, we chec k 1) if x and y both occur in the same tree T with tid t , 2) if y is within the scop e of x , and 3) that x and y are both extensions of the same pre x subtree, P T , whose matc h lab el is m x = m y . If the three conditions are satis ed, we add the triple ( t y ; s y ; f m to the scop e-list of y in [ P x ]. We refer to this case as an in-sc ope test.
 The second pattern chec ks what happ ens when y is added as a (em bedded) sibling of x . This happ ens when both x and y are descendan ts of node at position j in the pre x P , and the scop e of x is strictly less than the scop e of y . To chec k if y occurs as an embedded sibling in T with tid t , we ( t ; s x ; m x ) 2 L ( x ), suc h that: i) t y = t x = t , ii) s and iii) m y = m x .
 If the three conditions are satis ed, we add the triple ( t f m y [ l x g ) to the scop e-list of y in [ P x ]. We refer to this case as an out-sc ope test.
 Figure 1 sho ws the pro cess of scop e-list joins for both in-scop e and out-scop e tests. To chec k if a new candidate is frequen t, one can deriv e a per class coun t using the class index. For example, consider the tree in pre x group [1], with the branc h (1 ; 2). It app ears in tids 0,1, and 2 (we coun t only once per tid). Using the class index we nd that is occurs in classes c 2 , c 1 , c 2 resp ectiv ely. Its supp ort for class c 1 is 1 and for class c 2 is 2. It is thus 100% frequen t locally in both classes. We compared our XR ules structural classi cation approac h for XML documen ts against an IR classi er, as well as the CBA classi er. For the IR classi er (IR C) cen troids for eac h class were constructed using a clustering pro cess [2]. Then, a nearest neigh bor classi er was implemen ted on these sets of clusters. The CBA implemen tation was pro vided to us by its authors [16]. We evaluate our approac h on both real and syn thetic clas-si cation data sets. The adv antage of using syn thetic data sets was the additional exibilit y in studying the e ects of di eren t kinds of embedded patterns and database size. On the other hand, the real data sets help to validate the ap-proac h in a practical setting. We use the Log Markup Language (LOGML) [18], to de-scrib e log rep orts at the CS departmen t website. LOGML pro vides a XML vocabulary to structurally express the con-ten ts of the log le information in a compact manner. Eac h user session is expressed in LOGML as a graph, and includes both structure and con ten t.
 The real CSLOG data set spans 3 weeks worth of suc h XML user-sessions. To con vert this into a classi cation data set we chose to categorize eac h user-session into one of two class la-bels: edu corresp onds to users from an \edu" domain, while other class corresp onds to all users visiting the CS depart-men t from any other domain. As sho wn in Table 1, we sep-arate eac h week's logs into a di eren t data set (CSLOG x , where x stands for the week; CSLOG12 is the com bined data for weeks 1 and 2). Notice that the edu class has much lower frequency rate than other . Our goal is to minimize the cost of classi cation inaccuracy based on the various mo dels. We use the notation CSLOG x y to denote that we trained on CSLOG x and tested on CSLOG y . For example, CSLOG1-2 means that we learned a mo del from CSLOG1 and tested how well we could predict CSLOG2. We constructed a syn thetic data generation program sim u-lating website bro wsing beha vior. We rst construct a mas-ter website bro wsing tree W based on parameters supplied by the user. These parameters include the maxim um fanout F of a node, the maxim um depth D of the tree, the total num ber of nodes M in the tree, and the num ber of node lab els L . For eac h node in master tree W , we assign proba-bilities of follo wing its children nodes, including the option of bac ktrac king to its paren t, suc h that sum of all the probabil-ities is 1. Using the master tree, one can generate a subtree T W by randomly picking a subtree of W as the root of T and then recursiv ely picking children of the curren t node according to the probabilit y of follo wing that link. To create a classi cation data set we group users into two classes, c 1 and c 2 . First we generate a small pool of signature trees for class c 1 , denoted T p . Second, we generate a larger collection of trees, denoted T D . Subset of trees from T selected as training and testing pools, and T D is also split into training and testing sets. If a tree T 2 T D con tains a tree from the signature pool then T has class c 1 , otherwise it has class c 2 . To con trol the e ects of structure in the classi cation pro cess, a fraction f c , called confusion ratio , of trees that belong to one class ( c 1 ) are added to other class ( c ), after attening out. This is called one-w ay addition. If we also allo w mem bers of c 2 to be added to c 1 , it is called a two-w ay addition.
 The di eren t syn thetic data sets generated are sho wn in Table 1. For the DS x data sets, we trained on DS x -train and tested on DS x -test. The master tree W used the values D = 10 ; F = 10 ; M = 100 ; L = 10. We next generated j T
D j = 100 ; 000 trees for the database and j T p j = 1000 trees for the pool. T D was split into training and test sets by using DB #Sessions edu other %edu %other CSLOG1 8074 1962 6112 24.3 75.7 CSLOG2 7407 1686 5721 22.8 77.2 CSLOG12 13934 2969 10965 21.3 78.7 CSLOG3 7628 1798 5830 23.6 76.4 DB total c 1 c 2 % c 1 % c 2 DS1.train 91288 41288 50000 45.2 54.8 DS2.train 67893 17893 50000 26.4 73.6 DS3.train 100000 50000 50000 50.0 50.0 DS4.train 75037 35298 39739 47.0 53.0 DS5.train 129 66 63 51.2 48.8 DS1.test 88493 38493 50000 43.5 56.5 DS2.test 72510 22510 50000 31.0 69.0 DS3.test 100000 50000 50000 50.0 50.0 DS4.test 74880 37977 36903 50.7 49.3
DS5.test 72 42 30 58.3 41.7 a 50 50 split. For DS1, the training and testing pool were both of size 20, with half the trees common to both. We set f c = 1 : 0, with one-w ay addition from c 1 to c 2 . For DS2, the training and testing pool were iden tical (of size 10), and f = 1 : 0 from c 1 to c 2 . DS3 is the same as DS2, with with two-w ay confusion. Finally DS4 is same as DS2, but with two-w ay addition only half the time ( f c = 0 : 5). The small data set DS5 was pro duced by a di eren t syn thetic XML documen t generator 3 . The IRC approac h uses the actual text of the data in order to perform the classi cation. Therefore, it uses a greater amoun t of information than a purely structural classi er like XR ules . IRC uses both the node con ten t and edge information from the user-sessions. In con trast, XR ules uses only the structure (tree-format) for the classi cation pro cess. CBA uses the asso ciations among di eren t nodes visited in a session in order to perform the classi cation. Table 2 sho ws the weigh ted accuracy results for the three classi ers on di eren t data sets. The table sho ws the accu-racy for all three cost mo dels. The best accuracy is high-ligh ted in bold. We can see that for all data sets and all cost mo dels, XR ules is the best classi er. For the CSLOG data sets, XR ules deliv ers an accuracy between 82.99% and 85.30% for the prop ortional mo del compared to IRC's accu-racy from 73.76% to 77.64% and CBA's accuracy between 75.7% to 77.23%. Thus, the accuracy of XR ules is about 8-10% higher (in absolute accuracy) than that of IRC and 5-10% higher than that of CBA for the traditional Prop or-tional mo del. For this mo del, CBA app ears to be a better classi er than IRC. However, the mo del that CBA learns generally has only one rule. This rule alw ays predicts a test case to be other . While this strategy pays o in the prop ortional cost mo del (since other is the ma jorit y class with 76-79% occurrence), it does not work for the equal mo del (50% accuracy) and fails completely for the inverse cost mo del (23-24% accuracy). IRC does a much better job than CBA in distinguishing one class from the other. For example consider the confusion matrix for CSLOG1-2 sho wn in Table 3, whic h sho ws the num ber of test cases, by class, that were correctly and incorrectly classi ed by the three classi ers (with prop ortional cost-mo del). CBA essen tially lab els eac h test case as other , thus it is ine ectiv e for any pro vided by Elio Masciari (personal comm unication) DB Classi er Accuracy (%) CSLOG1-2 XR ules 82.99 74.83 74.75 CSLOG2-3 XR ules 84.61 75.70 76.19 CSLOG12-3 XR ules 85.30 75.70 76.08 CSLOG3-1 XR ules 83.81 74.09 76.08 DS1 XR ules 71.87 74.02 76.31 DS2 XR ules 80.71 76.01 71.31 DS3 XR ules 61.63 61.63 61.63 DS4 XR ules 68.31 67.78 67.24 DS5 XR ules 88.63 88.81 88.99 cost-mo del other than the prop ortional one.
 For the equal and inverse cost mo dels, we nd that XR ules has higher accuracy than CBA and IRC since it explicitly incorp orates cost. In the case of the CSLOG data sets, the accuracy of XR ules is about 6% higher than that of IRC and 25% higher than that of CBA for the equal cost mo del. The situation is more pronounced for inverse mo del, where the accuracy of XR ules is 14% higher than that of IRC and 50% higher than CBA! On syn thetic data sets, whic h do not have con ten t (only structure), the IR classi er does not work. So we compared only XR ules and CBA. The results are sho wn in Table 2. Once again, we found that CBA degenerated into a default classi er most of the time, lab eling eac h test case with the ma jorit y class, though it did have a small num ber of rules (less than 17) relating to the two classes. As we can see for prop ortional cost mo del on DS1, DS3, and DS5, CBA fails to classify the test cases correctly , deliv ering an accuracy of only 50%, whereas the accuracy of XR ules is 11-38% higher. On DS2 and DS4 CBA has some discrimination power, but the accuracy of XR ules is still 12-17% higher. For the equal and inverse mo del, XR ules outp erforms CBA by up to 40%! In summary , XR ules gives consisten tly better performance than the other classi ers for all cost mo dels and data sets. It works better than an asso ciativ e classi cation approac h like CBA, whic h attens out the structure into a set represen ta-tion. It outp erforms an IR based classi er whic h explicitly learns over the con ten t, but only implicitly over the struc-tural information in the XML documen ts. Therefore, the impro ved results of our structural classi cation pro cess are esp ecially signi can t. Table 4 sho ws the num ber of frequen t patterns (rules) mined by XMiner , and time for training and testing. The results underscore the high eciency of that XMiner (XM) engine. The frequen t trees for classi cation are determined in less than 8 seconds. The total training and testing time are comparable, since in both cases we have to nd the matc hing rules for eac h example. This is needed to determine the default class in training, and to nd the accuracy in testing. The running time can be impro ved by storing the rules in an appropriate index structure; curren tly XR ules performs a linear searc h for matc hing rules.
 DB Sup Rules Train Time (s) Testing CSLOG1-2 0.3% 28911 5.5 469.7 425.8 CSLOG2-2 0.3% 19098 3.6 273.9 277.5 CSLOG12-3 0.35% 29028 7.4 858.8 447.9 CSLOG3-1 0.2% 31661 4.8 470.8 487.4 DS1 0.3% 883 7.2 147.6 152.4 DS2 0.3% 1589 5.9 210.2 231.1 DS3 0.3% 739 7.6 137.7 129.5 DS4 0.3% 900 5.8 140.1 125.5
DS5 15% 347 0.2 0.3 0.1 We next study how the choice of strength measure a ects the accuracy of XR ules , as sho wn in Table 5. The best results are in bold. For the prop ortional mo del, con dence performs better than both likeliho od and weigh ted con -dence. Its accuracy is typically 2-4% higher on CSLOG and as much as 20% higher on DSx data sets. This is in agree-men t based on the Bayesian interpretation in section 2.4.1. On the other hand, with the exception of DS2 and DS4, like-liho od and weigh ted con dence perform better than con -dence with equal cost mo del. The weigh ted con dence has a sligh t (if insigni can t) edge over likeliho od (for both pro-portional and equal costs).
 The likeliho od measure has a sligh t edge over weigh ted con -dence for the inverse cost mo del on CSLOG data sets. These results are in agreemen t with the discussion in section 2.4.1. The only exceptions are DS2 and DS4 where con dence does better. The reason is that in these data sets the confusion factor complicates the decision making, since one-w ay (two-way) addition adds patterns from one class to the other (and vice-v ersa). On DS5, all measures give the same result. In summary , we conclude that con dence is a better measure for prop ortional mo del and either likeliho od or weigh ted con-dence is better for equal or inverse costs. The righ t choice of strength measure dep ends on the data set characteristics and cost mo del. If we exp ect man y patterns with similar global supp orts but di eren t local supp orts of rare classes, the likeliho od/w eigh ted con dence measure will usually pro-vide better results. Table 6 sho ws the e ect of varying the minim um likeliho od min on the accuracy of prediction for CSLOG1-2. Best ac-curacy for eac h cost mo del is in bold. For prop ortional cost mo del, the accuracy tends to increase up to a point (82.87% for min = 5) and then starts to drop. The same e ect DB Strength Prop ortional Equal Inverse
CSLOG1 81.09 74.73 74.75
CSLOG2 82.34 75.70 76.19
CSLOG12 81.22 74.09 76.08
CSLOG3 81.22 74.09 76.08
DS1 71.30 73.68 76.07
DS2 55.06 61.65 68.23
DS3 61.63 61.63 61.63
DS4 58.29 58.88 59.47
DS5 88.63 88.81 88.99 is observ ed for inverse mo del, but the mo del con tinues to impro ve until min = 10. For the equal cost mo del, the ac-curacy tails o at the very beginning. Similar results were obtained for other strength measures. These results suggest that by choosing an appropriate min one can get a mo del that can beha ve like for the prop ortional mo del (e.g., at min = 5, we get 82 : 87% accuracy compared to 82.99% ac-curacy using con dence, in Table 5), and can impro ve the accuracy for the inverse mo del.

Table 6: E ect of Lik eliho od Ratio (CSLOG1-2) min Prop ortional Equal Inverse #Rules Time 1 81.09 74.73 74.75 28911 432.2 2 81.57 74.67 74.85 28553 428.9 3 82.38 73.83 75.46 25698 378.7 4 82.68 72.58 75.32 24190 355.9 5 82.87 72.14 75.72 17732 270.3 6 82.56 69.93 76.47 12006 180.5 7 82.42 69.37 76.17 10008 149.3 8 82.04 67.81 76.35 8936 134.6 9 81.53 66.27 76.50 8424 126.1 10 81.48 65.79 76.54 8199 123.5 15 80.73 62.62 76.25 7848 120.9 20 79.90 60.28 76.20 7636 121.9 In this pap er, we discussed an e ectiv e rule based classi er for XML data called XR ules . The technique mines frequen t structures from the data in order to create the classi cation rules. XR ules is cost-sensitiv e and uses Bayesian rule based class decision making. Metho ds for e ectiv e rule prioriti-zation and testing were also prop osed in this pap er. The technique was implemen ted and compared against CBA as well as an IR classi er. Since the technique performs better than the CBA classi er, this indicates that the system relies on the classi cation information hidden in the structures for an e ectiv e rule generation pro cess. Furthermore, it outp er-forms the IR based metho d in spite of the greater amoun t of input used by the latter. The results sho w that structural mining can pro vide new insigh ts into the pro cess of XML classi cation. [1] C. C. Aggarw al. On E ectiv e Classi cation of Strings with Wavelets. SIGKDD , 2002. [2] C. Aggarw al, S. Gates, P. Yu. On the merits of using sup ervised clustering to build categorization systems.
SIGKDD , 1999. [3] R. Agra wal, R. Srik ant. Fast Algorithms for Mining
Asso ciation Rules. VLDB Confer ence , 1994. [4] K. Alsabti, S. Rank a, V. Singh. CLOUDS: A Decision
Tree Classi er for Large Datasets. SIGKDD , 1998. [5] R. Andersen et al. Professional XML. Wrox Press Ltd , 2002. [6] T. Asai, et al. Ecien t substructure disco very from large semi-structured data. 2nd SIAM Int'l Confer ence on Data Mining , 2002. [7] W. W. Cohen. Fast E ectiv e Rule Induction. Int'l
Conf. Machine Learning , 1995. [8] P. Domingos. MetaCost: A general metho d for making classi ers cost sensitiv e. SIGKDD , 1999. [9] G. Dong, X. Zhang, L. Wong, J. Li. CAEP: Classi cation by Aggregating Emerging Patterns. Int'l
Confer ence on Disc overy Scienc e , 1999. [10] R. Duda, P. Hart. Pattern Classi c ation and Scene
Analysis , Wiley , New York, 1973. [11] J. Gehrk e, V. Gan ti, R. Ramakrishnan, W.-Y. Loh. BO AT: Optimistic Decision Tree Construction.

SIGMOD , 1999. [12] M. James. Classi cation Algorithms, Wiley , 1985. [13] W. Li, J. Han, J. Pei. CMAR: Accurate and Ecien t Classi cation Based on Multiple Class-Asso ciation
Rules. IEEE Int'l Conf. on Data Mining , 2001. [14] J. R. Quinlan. C4.5: Programs for Mac hine Learning.
Morgan Kaufmann, 1993. [15] R. Rastogi, K. Shim. PUBLIC: A Decision Tree
Classi er that Integrates Building and Pruning. VLDB , 1998. [16] B. Liu, W. Hsu, Y. Ma. Integrating Classi cation and
Asso ciation Rule Mining. SIGKDD , 1998. [17] K. Nigam, A. K. McCallum, S. Thrum, T. Mitc hell.
Text Classi cation from lab eled and unlab eled documen ts using EM. Machine Learning , 39(2/3):103-134, 2000. [18] J. Punin, M. Krishnamo orth y, M. Zaki. LOGML: Log markup language for web usage mining. In WEBKDD
Workshop (with SIGKDD) , August 2001. [19] A. Termier, M-C. Rousset, M. Sebag. TreeFinder: a
First Step towards XML Data Mining. IEEE Int'l Conf. on Data Mining , 2002. [20] K. Wang, H.Q. Liu. Disco vering Typical Structures of
Documen ts: A Road Map Approac h. SIGIR , 1998. [21] M. J. Zaki. Ecien tly Mining Frequen t Trees in a
Forest. SIGKDD , 2002.
