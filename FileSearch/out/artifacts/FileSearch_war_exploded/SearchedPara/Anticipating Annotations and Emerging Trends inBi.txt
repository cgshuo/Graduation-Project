 The BioJournalMonitor is a decision support system for the analysis of trends and topics in the biomedical literature. Its main goal is to identify potential diagnostic and therapeu-tic biomarkers for specific diseases. Several data sources are continuously integrated to provide the user with up-to-date information on current research in this field. State-of-the-art text mining technologies are deployed to provide added value on top of the original content, including named en-tity detection, relation extraction, classification, clustering, ranking, summarization, and visualization. We present two novel technologies that are related to the analysis of tem-poral dynamics of text archives and associated ontologies. Currently, the MeSH ontology is used to annotate the sci-entific articles entering the PubMed database with medical terms. Both the maintenance of the ontology as well as the annotation of new articles is performed largely manually. We describe how probabilistic topic models can be used to anno-tate recent articles with the most likely MeSH terms. This provides our users with a competitive advantage because, when searching for MeSH terms, articles are found long be-fore they are manually annotated. We further present a study on how to predict the inclusion of new terms in the MeSH ontology. The results suggest that early prediction of emerging trends is possible. The trend ranking functions are deployed in our system to enable interactive searches for the hottest new trends relating to a disease.
 H.4 [ Information Systems Applications ]: Miscellaneous Algorithms, Measurement Text mining, Trends, Prediction PubMed, MeSH, LDA
The information landscape is rapidly growing and humans are struggling to keep up with it. Scientific research, for ex-ample, is highly dynamic with groundbreaking technologies changing established fields and creating new research ter-ritories. Especially in the biomedical domain breakthrough technologies are increasing the fragmentation and the inven-tion of new fields make it impossible for humans to keep up with the latest information, trends, and findings in a reason-able amount of time. However, gathering up-to-date infor-mation is crucial for the business success and indispensable at any level of organization: from the discovery of a new technology in the R&amp;D department up to the definition of new strategies in the management.

Automated text analysis methods that scan large amounts of content for interesting knowledge are needed. We present a system that supports information retrieval tasks for the purpose of technology monitoring in biomedical research. It integrates several information sources in a single user inter-face and provides added value not found in existing applica-tions using the same or similar data.

PubMed 1 , the largest biomedical bibliographic text database with over 17 million articles and more than 10.000 newly submitted research abstracts every week, represents a perfect basis for monitoring breakthrough technologies and extracting trends. The U.S. National Library of Medicine (NLM) is hosting and maintaining the database and takes responsibility for the categorization and annotation of in-coming documents with metadata based on the Medical Subject Headings (MeSH) 2 ontology. Besides its usefulness as a resource for associating semantic tags (annotations) to PubMed abstracts, the MeSH ontology also provides a formal and explicit specification of the present biomedical knowledge. Given these properties, the BioJournalMonitor processes textual and MeSH ontology meta-data together in a twofold way in order to effectively monitor technologies and extract trends: http://www.ncbi.nlm.nih.gov/PubMed/ http://www.nlm.nih.gov/mesh/
The remainder of this paper is structured as follows: In the next section, we give an overview of the trend detection system. In Section 3 we describe a probabilistic approach to automatically annotate incoming articles with MeSH terms. We present results on monitoring new emerging technologies by predicting the inclusion of terms into the MeSH ontology in Section 4. Related work is listed in Section 5 before we conclude with a discussion of our findings in Section 6.
The rapid advances in bioinformatics, medicine, bio-molecular sciences and related scientific areas led to a dra-matic increase of publications. The large amount of avail-able knowledge leads to the common problem that finding the right information at the right time itself constitutes a challenge and valuable time of researchers needs to be spent for this task instead of focusing on the actual research itself.
We have developed the BioJournalMonitor platform that supports screening multiple textual resources for potential targets such as biomarkers and related technologies. The users can evaluate possible target candidates and narrow down the list of candidates for subsequent experimental pipelines.

Several publicly available data sources are utilized by the screening system, including Proprietary data sources include patent information and news articles. Most of the sources are dynamic requiring continuous updates to the system to provide the user with up-to-date information on current research in this field. The http://clinicaltrials.gov information is processed with state-of-the-art text mining methods to provide an added value on top of the mere inte-gration of the data sources.

Named-entity recognition Named-entities such as genes, diseases, or substances are detected with a combina-tion of dictionary based recognition and Natural Language Processing [16] techniques. The results are used to empha-size such words in the feature representation to increase the quality of other algorithmic steps like clustering and classification. Disease-biomarker relations are automatically extracted.

Classification Recent documents are automatically an-notated with terms of the MeSH ontology using a proba-bilistic topic model. See Section 3 for details.

Trend analysis The frequency of all terms including named-entities is tracked over time. Features are extracted from the trends to automatically detect emerging trends. See Section 4 for details.

Clustering Stream clustering is used to discover global trends in the document streams [20]. On-demand clustering is used to structure the results of a user-defined search.
Ranking Documents, document clusters, and trends are ranked using extracted features and weights assigned to these features. Since different users have different interests, the weights used in the ranking functions for features like age or relevance to the query can be set as a preference. We are currently collecting user data to be able to enhance the ranking automatically [13].

The documents and trends are presented to the user in an interactive web-based user interface shown in Figure 1. The user can query for keywords and is presented with a list of document clusters on the right hand side. Each clus-ter is described by a tag cloud of the most important words and entities detected in the documents of the cluster. For each cluster the list of documents and the distribution of the documents over time can be displayed. Large clusters can be refined by breaking them into smaller clusters. The left hand side of the user interface is dedicated to the trend analysis. For each query the system automatically deter-mines the most relevant terms used in the document. The user can browse and compare the trends from different cat-egories such are genes, protein, diseases, or substances. For each trend the corresponding document can be analyzed. Figure 1: User interface of BioJournal Monitor. Search results are clustered and relevant emerging trends are automatically extracted.
The annotation of unstructured textual data with struc-tured machine readible information is an important step for further applications such as information retrieval, document clustering etc. Articles selected for inclusion in PubMed, for example, are indexed with descriptors from the Medical Sub-ject Headings thesaurus to facilitate later retrieval. We will refer to these descriptors as MeSH  X  X erms X  and MeSH  X  X on-cepts X  interchangeably. These MeSH terms are mostly as-signed manually by medical experts who read the full text of an article, resulting in a very expensive and time-consuming procedure. The annotation process itself is therefore a ma-jor bottleneck for keeping the PubMed database up-to-date given the enormous amount of submissions per day. How-ever, in order to detect trends as early as possbile, it is essential to be able to overcome this information bottleneck to provide up-to-date annotations for the latest articles. Here, we present a document annotation module for the BioJournalMonitor that is based on a generative model for document collections. The so-called Topic-Concept (TC) model [5] simultaneously models the content of documents and the process of annotating documents. As in [4] each document is represented as a mixture of probabilistic top-ics. It extends previous work by modeling the process of in-dexing based on assigned topic distributions for words (see Figure 2).
Let D = { d 1 ,d 2 , ..., d D } be a set of documents, where D denotes the number of documents in the corpus. A docu-ment d is represented by a vector of N d words, w d , where each word w i is chosen from a vocabulary of size N . In our extension, a document d is additionally described by a vec-tor of M d MeSH concepts c d , where each concept c i is chosen from a set of MeSH concepts of size M . The collection of D documents is defined by D = { ( w 1 , c 1 ) , ..., ( w D , c
The Topic-Concept model extends the LDA framework by simultaneously modeling the generative process of docu-ment generation and the process of document indexing .In addition to the steps performed in the classical LDA frame-work (see Figure 2(a)), two further steps are introduced to model the process of indexing. For each of the M d concepts in the document a topic  X  z is uniformly drawn based on the topic assignments for each word in the document. Finally, each concept c is sampled from a multinomial distribution over concepts specific to the sampled topic. This genera-tive process corresponds to the hierarchical Bayesian model shown in Figure 2(b). In this model,  X  denotes the vector of multinomial distribution over M concepts for each of T topics being drawn independently from a symmetric Dirich-let prior  X  . After the generation of words, a topic  X  z is drawn from the document specific distribution, and a concept c is drawn from the  X  z specific distribution  X . The probability distribution over M MeSH concepts for the generation of a concept c i within a document is specified as: where  X  z i = t represents the assignment of topic t to the i th concept, p ( c i |  X  z i = t ) is given by the concept-topic distribu-tion  X . The topic for the concept is selected uniformly out off the assignments of topics in the document model, i.e., tween both generative components. The generative process Figure 2: Graphical model for a) LDA and b) Concept-LDA in plate notation. Shaded nodes rep-resent observed random variables, unshaded nodes represent latent random variables of the TC model is essentially the same as the Correspon-dence LDA model proposed in [3] with the difference that the TC model imitates the generation of documents and their subsequent annotation, while [4] models the dependency be-tween image regions and captions.
Estimating  X ,  X  and  X  provides information about the underlying topic distribution in a corpus and the respective word and MeSH concept distributions in each document. Given the observed documents, the learning task is to infer these parameters for each document. Instead of estimating the parameters directly [11, 3] we follow the idea of [8] and estimate  X  and  X  from the posterior distribution over the as-signments of words to topics p ( w | z ). As the posterior cannot be computed directly, we resort to Gibbs sampling generat-ing samples from the posterior by repeatedly drawing a topic for each observed word from its probability conditioned on all other variables. In the LDA model the algorithm goes over all documents word by word. For each word w i , a topic z is assigned by drawing from its conditional distribution where z i = t represents the assignments of the i th word in a document to topic t , w i = n represents the observation that the i th word is the n th word in the lexicon, and z represents all topic assignments not including the i th word. C nt is the number of times word n is assigned to topic t and C DT dt is the number of times topic t has occurred in document d , both excluding the current instance. In the TC model the posterior p ( c |  X  z ) is approximated by assigning for each concept c i , a topic  X  z i from the following distribution:  X  z = t represents the assignments of the i th concept in a doc-ument to topic t , c i = m represents the observation that the i th concept in the document is the m th concept in the lexi-con, and z  X  i represents all topic assignments not including the i th concept. Furthermore, C CT mt is the number of times concept m is assigned to topic t , not including the current instance, and C TD td is the number of times topic t has oc-curred in document d , not including the current instance.
Parameters were estimated by averaging samples from 10 randomly-seeded runs, each running over 100 iterations, with an initial burn-in phase of 500 iterations (resulting in a total of 1.500 iterations). We found 500 iterations to be a convenient choice by observing a flattening of the log likeli-hood. The training time ranged from 10 hours to 15 hours depending on the data set (run on a standard Linux PC with Opteron Dual Core processor, 2.4 GHz). Instead of estimat-ing the hyperparameters  X  ,  X  and  X  , we fix them to 50 /T , 0 . 001 and 1 /M respectively in each of the experiments. We also fix the number of topics to T = 400. The values were chosen according to [27, 8].
Two large MEDLINE corpora, previously generated by [23, 22], were used to train the TC model. The first data set is a collection of PubMed abstracts randomly selected from the MEDLINE 2006 baseline database provided by the NLM. The collection consists of D = 50000 abstracts, M = 17716 unique MeSH main headings and a N = 22531 unique word stems. Word tokens from title and abstract were stemmed with a standard Porter stemmer [25] after stop words were removed using the PubMed stopword list. Additionally, word stems occurring less than five times in the corpus were removed. For each abstract MeSH main headings were linked to the corresponding concept in the MeSH thesaurus of 2006. Note that no filter criteria were defined for the MeSH vocabulary. The second data set con-tains D = 84080 PubMed abstracts, with M = 18350 unique MeSH main headings and a total of N = 31684 word stems and the same text-processing steps were applied. This cor-pus is composed of genetics abstracts from the MEDLINE 2005 baseline corpus. See [23, 22] for more information about both corpora. In the following, the data sets are re-ferred to as random 50K data set and genetics data set respectively.

For each document in the training and test set, we prune each assigned MeSH descriptor to the first level of each taxonomy-subbranch resulting in 108 unique MeSH con-cepts. For example, if a document is indexed with the MeSH descriptor Muscular Disorders, Atrophic [C10.668.550] the concept is pruned to Nervous System Diseases [C10] .We believe that this setting represents a reasonable prerequi-site for discipline-based indexing. Note that from a machine learning point of view, this is a very challenging 108 multi-label classification problem. In the pruned setting of our task, we have on average 9.6/10.5 (random 50K/genetics) pruned MeSH labels per document.
The prediction of MeSH terms for unseen documents can be formulated as follows: based on the word-topic and concept-topic count matrices learned from the training data, the likelihood of a concept c given the test document d is p ( c | t ), is given by the learned topic-concept distribution. The mixture of topics for the document p ( t | d ) is estimated by drawing for each word token in the test document a topic based on the learned word-topic distribution p ( w | t ). Thus, given an unseen document d , the TC model returns a ranked list of MeSH terms based on p ( c | d ).

We benchmarked the performance of the TC model against a method called centroid profiling [12] as well as a multi-label naive Bayes classifier. Centroid profiling com-putes for each word token w i and each MeSH concept c j , in a training corpus, a term frequency measure TF i,j w MeSH concepts. Thus, TF i,j measures the number of times a specific word w i co-occurs with the MeSH concept c j , nor-malized by the total number of times the word w i occurs. As a consequence, each word token in the training can be represented by a vector consisting of the term frequency dis-tribution over all M MeSH concepts. When indexing a new unseen document, the centroid over all word token vectors in the test document is computed returning a ranked list of MeSH terms. We assumed a bag of words representa-tion for the multi-label naive Bayes classifier and trained it for each of the MeSH concepts (108 labels). We used a multi-variate Bernoulli Model for naive Bayes [18]. Recall, that in contrast to the TC model and centroid profiling ap-proach, the multilabel naive Bayes classifier does not return a ranked list MeSH terms. For both data sets, models were trained on 90% of the documents and tested on the remain-ing 10%. The training and test splits are available online Figure 3 plots F2-macro measure against the number of rec-ommended MeSH concepts. According to [7], we decided to weight recall over precision and average F2-macro measure over documents rather than over indexing categories. We evaluate the results until a cut-off value of 30 recommended MeSH concepts, except for the naive Bayes classifier. The TC model clearly outperforms the naive Bayes classifier and the centroid profiling with the best result at a cut-off value of 15 recommendations for both data sets (0.60 (random 50K)/0.62 (genetics)). Using a cut-off value which equals to the number of average MeSH assignments (rounded-up) in the two training corpora the F2-macro is 0.570 (random 50K) and 0.599 (genetics) for the TC model, while the cen-troid profiling reaches only 0.517 (random 50K) and 0.55 (genetics). The multi-label naive Bayes classifier reaches a F2 measure of 0.525 (random 50K) and 0.570 (genetics). Note that using the average number of MeSH assignments is the most simple way to determine an appropriate cut-off value. A more analytical way of determining the cut-off value would be to set up an independent development set for the given corpus and to maximize the F2-macro measure with respect to the number of recommendations. http://www.dbs.ifi.lmu.de/~bundschu/research/ data/
A key component of our text monitoring system is the de-tection of emerging trends. This provides users with a key advantage in scouting tasks. Our text monitoring system tracks the frequency of all words over time to support the trend discovery. The user can search the document database and is not only returned a set of document clusters but also relevant emerging trends. We performed a study to investi-gate the feasibility of discovering trends by trying to predict the inclusion of important medical terms in the MeSH on-tology. The goal is to automatically report new biomarkers that potentially represent a scientific breakthrough.
We filtered the PubMed database from 01/1975 through 10/2007 for abstracts with the following cancer related key-words (substrings): cancer , carcinoma , tumor , neopla , ma-lignant . About 1.5M documents were found and processed with the standard text mining pipeline: word level pars-ing, stop word removal, word stemming [25]. The stop word list included some very common medical terms such as re-sult , patient , study , method . In total about 600 stop words were used. The MeSH annotations of the abstracts were not used and no named-entity recognition was performed to ensure that no information is used that would not have been available at the time the abstracts were published. In-dividual parts of composite terms with hyphens or slashes, e.g., P53-induced , were considered as separate words if they were longer than a single character and not a number. Some biomarker specific normalization was performed, for exam-ple by replacing the suffix -ii with -2 . The word stems and trends as well as the ground truth described below are avail-able online 5 .

Each document in PubMed has up to four date fields: creation date, completion date, revision date, and publica-tion date. There is no total order among these dates. We used the earliest available date for each document as a time stamp. This corresponds to the time that a researcher that would have had access to all resources would have seen the article.
 We utilized the temporal information associated with MeSH terms to obtain a ground truth for emerging trends. We assume that MeSH terms are added once the NLM con-siders a term an established and relevant medical concept and that there must have been significant research activity http://www.mybytes.de/research/pubmed prior to the inclusion in the ontology. The terms are placed in the ontology and cross-referenced with existing terms such as diseases.

Similar to the documents, MeSH terms are associated with several dates. The creation date usually indicated the inclu-sion in the ontology and the established date indicate the date of the earliest annotated article. This can be earlier than the creation date, because the PubMed database is then retro-annotated by searching for relevant existing doc-uments and adding new MeSH terms to those records. Un-fortunately some terms did not have a created date when the MeSH ontology was restructured in 1999. They were assigned the creation date 01/01/1999. We ignored these terms in this analysis. The 2008 version of MeSH was used.
We searched the MeSH ontology for cancer related terms that were added within the time period under study and would have been interesting to a researcher monitoring the literature for scientific breakthroughs. Our filtering strate-gies are very strict to ensure that we only have truly inter-esting concepts as true positives. We started out with all MeSH terms that were observed in at least one of the can-cer related documents. These 22,169 terms covered almost the complete ontology. Obviously not all these terms are related to cancer. We therefore used the tree structure to filter the MeSH terms for entries that are listed in a tree that has one of the cancer keywords (see above) in the path name. This results in 223 relevant trees with 759 relevant terms. From these 187 were removed because they had a cre-ation date of 01/01/1999 and 65 were removed because they had a creation date before 01/01/1975. 524 of the remain-ing terms were associated with the top level tree Neoplasms [C04] . Since we are interested in predicting biomarkers and technologies relevant for the diagnosis and treatment of dis-eases but not so much in predicting disease type themselves we excluded these terms. We only kept terms in one of the top level trees listed in Table 1 resulting in 140 remaining terms. For the evaluation the MeSH terms needed to be mapped to the observed word stems from the abstracts. In this process we removed umbrella concepts such as Genes, neoplasm or Cell line, tumor and terms that cannot be easily identified with a single word(stem) such as b-cell maturation antigen . While we could have processed the document with n-grams this would have increased the complexity of the study tremendously. We also removed duplicates where the same word stem was matched to a gene and a protein en-try in MeSH. The MeSH term with the earlier creation time was used in this case. The final result was a list of 81 MeSH Table 1: Top level MeSH trees used to filter terms for biomarkers.
 terms as true positives for cancer-related biomarkers. The distribution of these terms over time is shown in Figure 4 and some examples are listed in Table 2. Figure 4: Addition of new Mesh terms describing biomarkers related to cancer.
 Table 2: True positive cancer-related biomarkers.
Type Count Examples genes 41 ras, p53, dcc, erbb-2, brca1 antigen 8 cd27, cd137, cd70, ca-125, ca-19-9 receptors 18 tnf1, tnfsf14, traf4, ox40, xedar proteins 6 wt1, p14arf, p130, p107, fas cells 8 pc12, hl-60, caco-2, k562, jurkat
The number of cancer-related articles per month is shown in Figure 5. The clear upward trend is another proof of the information overload analysts are facing nowadays. The peaks have a yearly period and might be caused by the in-clusion of journals or other publications on a yearly basis. In order to remove the yearly peaks and add some smoothing to the trends we used a moving average: For each month we consider the frequency of a word stem in all cancer-related documents from the last year up to the month. To ac-count for the global trend in biomedical (cancer) research the trends were divided by the total number of documents in the same time range.

Figure 6 shows an example of such a normalized frequency trend for the Breast Cancer gene BRCA1. The dashed line indicates the time when the corresponding MeSH term was added to the ontology. There was significant research ac-tivity with a sharply increasing trend starting in January of 1993. The corresponding MeSH term was added in February 1996, more than 3 years later. A trend analysis system works Figure 5: Number of cancer related documents per month in PubMed database. The frequency of pub-lications is strongly increasing. Figure 6: Trend of word stem brca1 that corre-sponds to the MeSH term Genes, BRCA1 added on 2/16/1996 (dashed line). by monitoring candidate terms, and, at each time point, as-signing each term a score indicating the interestingness of the term. Since we are interested in newly emerging trends we would like the score to reflect the rate at which the rel-ative frequency f ( w, t ) of a term w changes with time. We compute the score s ( w, t c ) of trend w at time t c in the fol-lowing way: 1. Define time t 0 as the time of the first occurrence of 2. Consider an interval I =[ max ( t c  X  24 ,t 0 ) ,t c ]-we 3. Select pairs { t, f ( w, t ) | t  X  I,f ( w, t ) &gt; 0 4. Fit a line to pairs { t, log ( f ( w, t )) } . The slope a of this
The scores are then used to rank trends -a higher score indicates a more interesting trend.
Due to computational costs of conducting the evaluation on all 180K terms, we consider a set containing all 81 positive examples and a randomly selected 10K other terms. In order to evaluate our approach we consider several different types of measures, illuminating different aspects of the problem. Since in our application the trends are the behaviors of the terms, we will use  X  X rends X  and  X  X erms X  interchangeably.
One question of interest is whether in fact our approach is capable of detecting new important trends early, i. e. , whether we can predicting MeSH terms in advance. One way to answer that is to consider the time between positive term X  X  first appearance in top-k terms and its inclusion into MeSH. Figure 7 shows the distribution of differences between these two events for k = 100 and k = 200. We detect 75 out of 81 terms with k = 200, and 66 with k = 100 and most of the trends are detected between 5 and 20 years in advance. This shows that our simple approach can detect true positives far in advance of their acceptance into MeSH. Obviously there are some costs attached. Considering 200 terms each month for 20 years could potentially lead to a total of 48000 terms -certainly a high cost for detecting only 81 true trends. It turns out however, that the real cost is significantly lower because terms appear in top-k sets multiple times. For example, only 5760 unique terms appear in top 200 from 01/1980 to 01/2004. The effort in following such number of trends over 25 years is quite manageable. Also, the numbers in the figures are  X  X essimistic X , because in computing them we do not remove previously correctly identified terms or the irrelevant trends that the user would have the option to remove in the actual system.

The other measures we use are standard Information Re-trieval (IR) metrics: precision and recall [1]. Before we de-fine those, we first need to clarify how we categorize terms in a way that is consistent with our applications. In the experiments described here we set h 0 = 12 months, and h 1 = 60 months. Given the numbers above precision P and recall R can be calculated. Note that since the earliest any of the 81 terms are added to MeSH is on 04/25/1985 and the latest is added on 12/21/2005, it only makes sense to consider time period from 01/1980 (which is when we could possibly detect the earliest trend) to the end of 12/2004 (which is when we would still be able to detect the last trend without being late). Towards the end of this period we would effectively be making predictions for trends which may only be added to MeSH in the coming years, and this could result in a reduced precision. In Figure 8 we show precision and recall of our approach for k = 100 and k = 200. The fact that the precision stays between 1% and 10% (except in the end) is not surprising, since we only look at top k terms at each time point and because real trends are rare. For many time points this is significantly better than random: the overall expected value is less than 1% (81/10081) and the number of positive trends is commonly much smaller (at most 40). The recall is very high initially, when there are relatively few positive trends in the window and it decreases as more positive trends appear. At any time somewhere between 5 and 35 positive trends are potentially detectable, and the recall is mostly greater than 20% (10% for k = 100) except for a few small regions of sharp drops and the final period which we discuss in more detail below.

The performance drops in the last 40 months of the ob-served period. This occurs for the following reason. Many of true trends that are added to MeSH around 2005 have al-ready slowed down their growth so they are no longer among the top k (though they were detected earlier). Meanwhile, since we reached the end of the experimental period, no new trends appeared that can be detected by the method. It is also possible that the method is detecting trends that will yet to be added to MeSH, but in the evaluation we are forced to treat them as false positives. In other words, the change in last period reflects the nature of our evaluation rather than the weakness of the method.
Modeling documents in a probabilistic framework via la-tent topics has first been introduced by [10], resulting in the so-called aspect model. However, the parameterization of the model was susceptible to overfitting. [4] addressed these limitations by introducing the LDA framework. Depending on the addressed generative process, the LDA framework has been extended e. g. to model the dependencies between authors, topics and documents [27] or the dependencies be-tween author and recipients [17]. Further approaches include the modeling of images and their captions [3], the modeling of dependencies between topics and named entities [24] and the uncovering of latent topic structure hidden in biomedical text corpora [2].

One of the earliest work mentioning trends in document archives is [15]. The frequency of phrases is tracked over time and the user can query for trends of predefined shapes. This could include recently emerging trends. No evaluation with ground truth was performed.

Many studies concentrate only on the main topics in a document archive and perform a retrospective analysis while we are interested in the early detection of new topics. [28] uses significance tests to detect time periods where words the top k trends every month. Larger value indicates earlier detection. and false negatives) in period from January 1980 to January 2004. have a higher than usual frequency. A temporal extension of LDA is proposed in [29] to better model evolving topics.
Even though the detection of interesting temporal phe-nomena is most useful in online settings where the data is continuously monitored, many studies have only described retrospective algorithms and leave online methods for fu-ture work. A state-based model is used in [14] to model a hierarchical structure of bursts in a document stream. One application is the automated categorization of emails into topics and subtopics. The burst detection is used in [6] to cluster trends of words. We have so far concentrated on the ranking of individual features but this could be extended to clusters of features. The burst detection is also used in [9] to emphasize features for subsequent text mining steps such as document clustering.

Several approaches use a partition of the time axis into large intervals to detect changes in document archives. Fi-nite mixture models are used in [21] to represent the docu-ments of each interval. A comparison of the models among subsequent time intervals is used to report new trends. In [19] clustering is performed for each time step and clusters are connected with a graph model to obtain a temporal rep-resentation of the document collection. A similar method is applied in [26] with the goal to detect emergent and per-sistent topics for the extension of ontologies. New clusters that cannot be connected to clusters from the previous time interval are candidates for new ontology concepts. While we have tried to predict the extension of the MeSH ontol-ogy this was mainly done to obtain a ground truth for the ranking evaluation. In our system we do not really care whether a trend is at some point included in MeSH or not, we just want to provide the user with pointers to emerging technologies as early as possible.
We have presented an integrated system for screening and monitoring of information feeds describing biomedical re-search. After an overview of the complete system we pre-sented two particular modules that provide an added value using data mining methods.

The experimental evaluation on annotating abstracts shows the advantage of our generative approach. In the cur-rent setting, we restrict our experiments to subparts of the MeSH thesaurus. However, we plan to conduct experiments on the whole MeSH taxonomy. The extension of the genera-tive process model for capturing the hierarchy of taxonomies is a matter of ongoing research.

We demonstrated that early prediction of technological trends is feasible. Several key concepts for cancer were de-tected with high confidence years before they were intro-duced in the ontology. We also propose an approach for preparing ground truth in the realm of biomedical research and evaluating rankings for this task. To our knowledge this is the first attempt at predictive evaluation of trend de-tection, as opposed to retrospective detection. Our experi-ence highlights some of the difficulties of such an evaluation, namely: complicated selection of candidates and definition of false negatives and true positives at each time point, and incomplete information on relevance of trends (due to the evolving and expanding vocabulary of MeSH). The task is complicated by existence of trends that do not pick up at the first few occurrences of a term, but develop later, since we have no way of knowing this in evaluation.

The ranking with a simple unsupervised scoring function and selection of the top k worked surprisingly well. We plan to expand the ground truth and move toward supervised al-gorithms. In the meantime the ranking is already deployed in our system and has received positive feedback. Some of the drawbacks revealed in our evaluation can be removed in a live system. For example, terms already in MESH or predicted to be included can be removed from future consid-eration. More importantly, terms not describing biomarkers, for example, or those deemed irrelevant by the user can be eliminated, improving performance. [1] R. Baeza-Yates and B. Ribeiro-Neto. Modern [2] D. M. Blei, K. Franks, M. I. Jordan, and I. S. Mian. [3] D. M. Blei and M. I. Jordan. Modeling annotated [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [5] M. Bundschus, M. Dejori, S. Yu, V. Tresp, and H.-P. [6] G.P.C.Fung,J.X.Yu,P.S.Yu,andH.Lu.
 [7] C. W. Gay, M. Kayaalp, and A. R. Aronson.
 [8] T. L. Griffiths and M. Steyvers. Finding scientific [9] Q. He, K. Chang, E.-P. Lim, and J. Zhang. Bursty [10] T. Hofmann. Probabilistic latent semantic analysis. In [11] T. Hofmann. Unsupervised learning by probabilistic [12] S. M. Humphrey, T. C. Rindflesch, and A. R.
 [13] T. Joachims. Optimizing search engines using [14] J. Kleinberg. Bursty and hierarchical structure in [15] B. Lent, R. Agrawal, and R. Srikant. Discovering [16] C. D. Manning and H. Schutze. Foundations of [17] A. McCallum, A. Corrada-Emmanuel, and X. Wang. [18] A. McCallum and K. Nigam. A comparison of event [19] Q. Mei and C. Zhai. Discovering evolutionary theme [20] F. M  X  orchen, K. Brinker, and C. Neubauer. Any-time [21] S. Morinaga and K. Yamanishi. Tracking dynamics of [22] A. N  X  ev  X  eol, S. E. Shooshan, S. M. Humphrey, T. C. [23] A. N  X  ev  X  eol, S. E. Shooshan, J. G. Mork, and A. R. [24] D. Newman, C. Chemudugunta, and P. Smyth.
 [25] M. F. Porter. An algorithm for suffix stripping. pages [26] R. Schult and M. Spiliopoulou. Discovering emerging [27] M. Steyvers, P. Smyth, M. Rosen-Zvi, and [28] R. Swan and J. Allan. Automatic generation of [29] X. Wang and A. McCallum. Topics over time: a
