 The ultimate goal of information retrieval science continues to be providing relevant information to users while placing minimal cog-nitive load on them. The retrieval and presentation of relevant infor-mation (say, search results) as well as any dynamic system behavior (e.g., search engine re-ranking) depends acutely on estimating user intent. Hence, it is critical to use all the available information about user behavior at any stage of a search-session to accurately infer the user intent. However, the simplistic interfaces provided by search engines in order to minimize the user cognitive effort, and intrin-sic limits imposed by privacy concerns, latency requirements, and other web instrumentation challenges, result in only a subset of user actions that are predictive of the search intent being captured.
In this paper, we present a dynamic Bayesian network (DBN) that models user interaction with general web information systems, tak-ing into account both observed (clicks etc.) as well as hidden (result examinations etc.) user actions. Our model goes beyond the ranked list information access paradigm and gives a solution where arbi-trary context information can be incorporated in a principled fash-ion. To account for heterogeneity in user behavior as well as in-formation access tasks, we further propose a bi-clustering algorithm that partitions users and tasks, and learns separate models for each bicluster. We instantiate this general DBN model for a typical static search interface comprising of a single query box and a ranked list of search results using a set of seven common user actions and var-ious predictive state attributes. Experimental results on real-world web search log data indicate that one can obtain superior predictive performance on various session properties (such as click positions and reformulations) compared to simpler instantiations of the DBN. H.3.3 [ Information Search and Retrieval ]: Search process Algorithms, Experimentation Latent user intents, hidden action sequences, search sessions, user interaction modeling Figure 1.1: Unobserved eye movements (edges to red/dark ovals) and observed actions (edges to green/light ovals) in two search sessions for the query  X  X reyhound austin X . Note that the two search sessions result in the same observed user activity but involve very different underlying (hidden) user actions.
Web systems are the main source of information for people, es-pecially in developed countries. Many traditionally off-line activ-ities, such as consuming news, communicating with friends, buy-ing/selling, and even dealing with government, have moved almost entirely online. More significantly this migration of people X  X  at-tention online is expected to lead to a commensurate movement of advertising dollars as well. In large part this is because online adver-tising lends itself to extensive measurements via implicit feedback from observing user behavior. This feedback can also be used to optimize the content and layout of these websites for the purpose of improving user experience. However, the first step in any such endeavor is to interpret the observed behavior in the context of the user X  X  state of mind (or intent). In this paper we propose a dynamic Bayesian model to achieve this. While our proposed model is appli-cable to web information systems in general 1 , to explain and evalu-ate our work in concrete terms, in this paper we focus on web search engines.

There are many benefits of learning such a model of user behav-ior on search engines; here we discuss just two. As a first use case, consider a user with the query  X  X reyhound austin X  (Figure 1.1). The query is inherently ambiguous in that it could refer to the dog breed or the buses. Even within the  X  X ransportation X  intent the user might be interested in the Greyhound ticketing website (result 3) or find-ing the reviews for the service (result 5). In the absence of further knowledge of the user X  X  intent, search engines tend to hedge their
The model in its abstract form can be applied to web information systems with multi-frame, multi-tabbed views (like Facebook, Twit-ter, Yahoo!), and also to those with long-term offline interactions (like customer relationship management systems) bets and show a diverse set of results. If a model could infer the user X  X  intent from behavior, say, by first inferring which results cap-ture the user X  X  attention or by observing the first click, the search en-gine could dynamically  X  X e-emphasize X  the results to improve user experience. As a second use case, consider a situation when a user behavior model, that takes into account query terms, topics, returned results, and even demographic information, predicts identical be-havior for two groups of users on a particular search task, when in reality the two groups exhibit very divergent behaviors. We might discover, for instance, that users in one group do not click on the returned results, choosing instead to reformulate their queries. This might be because those users are automated robots, or maybe are confused by the search interface. The ability of a behavior model to predict normal behavior could bring such anomalous groups of activity to the attention of researchers who could then dig deeper to debug the situation.
 T
While there is some past work on modeling the behavior of vis-itors to content portals [18], a large number of works target search engines. Due to paucity of space, from among these we only cite some representative works and contrast our approach with them.
As the scenarios mentioned above show we need a model that relates user behavior with user and sessions properties, like under-lying intents, result relevance, demographics, etc. Moreover, this model must account for all aspects of user behavior that have been observed in experiments. A particularly important aspect is position bias : users tend to click more on higher ranked results no matter the ordering [5, 8]. To account for this bias, Richardson et al. [14] pro-posed the examination hypothesis that users click on a search result after examining each result independently in a biased fashion and determining its relevance. However, this model ignores sequential dependencies in the clicks: a user is unlikely to examine a relevant result later in a list if her information need is satisfied by a higher ranked relevant webpage. To handle this possibility, Craswell et al. [3] proposed the cascade model , which describes how the first click happens when the users scan linearly through the ranked list. The cascade model has been enhanced to handle more than one click by Guo et al. [7] and Chapelle and Zhang [2]. While, these methods have shown good results in tasks such as re-ranking search results, they all make a restrictive assumption about the top-down order of examination of results with no skips. However, this assumption does not seem valid (see Figure 1.1 for an example). In query click logs from a major search engine we found that &gt; 25% of all clicks were out of order , meaning that oftentimes users click on a result after having explored and clicked on other results lower down in the rank-ing. Moreover, there is also evidence from eye-tracking studies done on search results lists [9] and general web pages [12] that suggest that users do not simply scan ranked lists top-down, but that they show a rich behavior of skipping and re-examining results. Unfor-tunately, privacy concerns, latency requirements, and other funda-mental limits of search results page instrumentation, mean that be-haviors like examination and skipping of results are not captured. Hence, almost all past works assume a top-down order of exam-ination since this gives them a unique set of user actions for any observed sequences of events (clicks); this assumption, however, might hide a rich set of interaction highly predictive of user intent (see Figure 1.1). Wang et al. [16] propose an approach that allows for skipping of results but this model has many other shortcomings when compared with our approach: it allows only a very restricted set of actions, does not handle arbitrary context features, and as-sumes clicks on a page are independent (does not respect the cas-cade model ). In our work we model users while taking into account a complex set of actions like examinations, skips, and jumps, etc. that are not observed. Moreover, in our model these actions can be dependent on each other in arbitrary ways. While the space of possible actions is huge, we abstract out a rich set of frequently oc-curring actions from eye-tracking studies and domain knowledge, and incorporate them into our model. As we show in experiments in Section 4, using a richer set of actions helps our system learn a more accurate user behavior model.

A second technical challenge (and criticism of past work) stems from the fact that web/search interfaces are changing dramatically and that it is vital to move away from modeling over a simple ranked list. In fact, current search engines already serve information in multiple blocks: a menu on the left, advertising to the right, and the search results in the middle. Most existing user modeling ap-proaches do not handle this sort of a context in any principled man-ner. Those existing works that attempt to do so [4, 13] restrict themselves to only observed actions and limited transitions between them. Downey et al. [4] assume a coarse set of fully observed user/system actions and a deterministic user state, while Piwowarski et al. [13] employ a hierarchical HMM, where the hierarchical tran-sitions are always observed; further comparison with HMM-based models [13, 16] is given in Section 3.1. Other simple examples of context that might be incorporated into models to make them more accurate are previous search history of the user, demographic infor-mation like gender and age, or even the time of the day. In our work we propose a general model that is not limited to the search ranked list paradigm, and can incorporate information on both observed as well as hidden predictive attributes derived from context.
Finally, a third shortcoming of most prior work is the assumption that user behavior is homogeneous enough to be modeled by a single set of parameters. A related assumption is that search strategies do not vary across tasks. Guo et al. [6] learn two click models by classi-fying the query into  X  X nformational X  and  X  X avigational X  classes and see improved results. However, the query groups are defined apriori and not based on user behavior. In this work, we use our model of user behavior to cluster users and tasks into groups.
 O 1. We give a general formulation of the problem of modeling user behavior in interactive web information systems. We then give a dynamic Bayesian network model for these user interactions. This model goes beyond the ranked list paradigm of information con-sumption and gives a principled way to incorporate domain knowl-edge about hidden user actions. 2. In order to deal with the heterogeneity in user behavior we give a clustering based formulation that learns a separate model for each user and task group. 3. We instantiate our general model for a search engine setting. The advantages of our model are that it can handle a richer set of user actions, even those that result in unobservable changes to the user state, and incorporate user and task properties in a principled way. 4. We evaluate our model on real-world search engine logs and show that both, the richer set of actions and the clustering capability, are important to accurately model user behavior. Our model improves performance over strong baselines on two real-world tasks: com-pleting user sessions and predicting post-session actions. O
In this section we motivated the problem and provided a detailed comparison with related work. In Section 2 we define the general problem of modeling user behavior on web information systems and give a dynamic Bayesian model for it in Section 3. Finally, in Sec-tion 4 we present our evaluation of an instantiation of the general model to web search engines.
In this section, we first describe a natural way to represent user sessions on a website in terms of actions/responses. Using this rep-resentation, we provide a concrete formulation of the user behavior modeling problem. We make the discussion concrete by giving run-ning examples from the search engine setting.
A typical single user web session 2 consists of a user initiating an interaction with a web system followed by an initial response from the system, and then a series of alternating user actions and web system responses that could potentially depend on each other. Example. Figure 1.1 depicts a user X  X  interaction with a search en-gine while querying  X  X reyhound austin X ; we will use this as a run-ning example in this paper. In this case, the initial user action in-volves issuing the keyword query while the initial system response involves presenting a ranked list of the top-k results relevant to the query (henceforth called SERP ). The subsequent user actions in-clude glancing over the presented results, closely examining the as-sociated titles and snippets, and clicking on the relevant ones. On the other hand, the system responses can include transferring control to the clicked result pages, actively reordering/grouping the search results, requesting the user to provide further clarification on the initial query, etc.

In the current work, we take the perspective of the system de-signer who has complete knowledge/control of the system response policy, and focus on modeling the user behavior conditioned on this policy. Therefore, even though each session is composed of alter-nating series of user actions and system responses, we mainly focus on the user action sequence, and in particular, user actions that are predictive of the user X  X  intent for the session. To minimize the user cognitive effort, most web systems explicitly allow and record (via web protocols) only a small number of observed user actions that are highly informative of the user X  X  intent, e.g., querying, clicking, tagging, scoring. Some of these user actions, e.g, querying, tag-ging, can be further broken to finer-grained actions by considering the associated keywords or phrases. In addition to these observed actions, there also exist a small number of highly common hidden user actions that are potentially indicative of user intent, and that are typically not captured by a web system X  X  instrumentation. Some of these, such as mouse movements and scrolling, can be recorded via slightly enhanced techniques (javascript or AJAX). Other hid-den actions such as examination patterns or dwell times on content items can only be discovered using more sophisticated monitoring of users, e.g., via eye-tracking studies. Note that since the system is unaware of the hidden actions, it does not provide any response unlike in the case of observed actions.
 Example. For the search scenario shown in Figure 1.1, the observed actions (marked in green ovals) include ( a 1 ) query , ( a on the result currently being examined , and ( a 3 ) end examination . The hidden actions involve changing the current result position being examined by the user, and are marked by red ovals. They include ( a 4 ) examine the next position in result list , ( a 5 ) examine the previous position in result list , ( a 6 ) re-examine the first result etc. The user X  X  SERP activity can thus be represented as a sequence is represented as &lt; a 1 a 4 a 4 a 4 a 2 a 6 a 3 &gt; . The full set of ob-served/hidden actions allowed in an instantiation of our model to a web search engine is given in Table 1(b)
In complex web systems,e.g., instant messaging, a single session might involve multiple users, but we restrict to single user session. Example. The problem being considered applies to all kinds of web information systems. Consider the problem of designing a system response policy for recommending personalized content for users on web portals [ ? ]. In this scenario a user X  X  observed actions might be relatively straightforward, such as click on a link (Yahoo!), post a message (Twitter), initiate a friend request (Facebook), etc. However, the set of hidden actions that need to be modeled might be richer since the content is not just representable as a ranked list. A user might examine the link to the above/below/left/right of current link , or in the case of portal such as Yahoo!, view mail or weather .
Using the above representation of web sessions, our primary goal is learn a stochastic model of the web sessions (i.e., user action se-quence) given the user and the system response policy, using data on a large number of sessions. For a new user session, this learnt model can then be used to dynamically infer the user X  X  future be-havior given his actions so far, which can be used to optimize the system response.
 Let R sys denote the system response policy. Let A O , A A = A O S A H denote the set of observed, hidden, and all actions respectively, U = { u i } N U i =1 denote the set of users. Further, let W = { w i } N W i =1 denote the set of user web sessions where each session w is a tuple ( u i ,r i ,  X  a i ) comprising the associated user u response r i , and the sequence of user actions  X  a i , with  X  a the sub-sequence of observed actions. Example: in web search, r will consist of the query as well as the top-k returned results (SERP), and A will contain, among others, the actions mentioned in the previous section above, and  X  a i will be the time-ordered sequence of observed as well as hidden actions that the user performs on the SERP. From the rest of the paper we will skip the subscript referring to the user when clear from context.

The problem of modeling user behavior in web information sys-tems can be thought of as three different, but intertwined problems. The first problem, which we call user behavior model learning , in-volves designing a suitable parametric form for the conditional dis-tribution p  X  (  X  a | u,r ) , and estimating the parameters  X  that optimize the  X  X odel quality X  with respect to the available session data con-does not contain the hidden actions the users may have performed.
A natural way to characterize this model quality is in terms of data likelihood 3 . Since the training data consists of only the observed ac-tion sequence, the parameters are chosen to optimize the incomplete data likelihood obtained by marginalizing over the hidden action se-quence, i.e., where C (  X  a O ) is the set of all the user action sequences compatible with  X  a O . Example: in Figure 1.1, the two different user action se-quences represented in the left and right panels are both compatible with the same observed action sub-sequence ( &lt; a 1 a 2 a 3 &gt; ).
We refer to the second problem as user intent inference . Given the user behavior model p  X   X  (  X  a | u,r ) , a user u , system response policy R sys , and a partial sequence of observed actions {  X  a O the t th observed action, the problem is to infer the entire action sequence (including future actions and past hidden actions) for that session, i.e.,
Though one might also choose to have alternate formulations based on margin-like measures Figure 3.2: The dynamic Bayesian network model. The vari-ables S 1 , 1 and A t, 1 have all attributes fully observed. States S t, 1 ,t &gt; 1 only have the components [ S O t, 1 ,S PO t, 1 states S t,i ,t &gt; 1 ,i &gt; 1 have only S O t,i observed. Finally, the variables A t,i ,i &gt; 1 correspond to fully hidden variables. using Bayes rule. Example: in Figure 1.1, this corresponds to infer-ring the entire sequence of user actions (both observed and hidden) after observing only the query and, say, the initial one or two clicks.
A third related problem involves system response optimization wherein given the learnt user session model parameters  X   X  tial sequence of observed actions {  X  a O 0 ...  X  a O t action, the goal is to identify the future system response r timizes a target optimization criteria T (  X  a ) ; we might want to opti-mize for user satisfaction, number of ad clicks etc. Example: while current search engines respond to user clicks by transferring control to clicked pages, one could envision a scenario where after the t click, the system might decide that moving the 4 th result up to the 2 nd position improves user experience.

The three problems described above are intimately related, and optimizing the system response policy is the ultimate goal of most web systems. However, key elements of the system response opti-mization problem such as choice of appropriate target optimization criteria (user satisfaction or number of ad clicks etc.) and the space of candidate system responses vary considerably across domains, and require an in-depth exploration of multiple open issues pertain-ing to lifetime user behavior, mathematical representation of system user interface, etc. Hence, in the current paper, we focus on solving the first two problems: user behavior model learning (Equation 2.1) and user intent inference (Equation 2.2). In the next section we will construct our user behavior model and give the associated estima-tion and inference algorithms.
In this section, we first consider the desiderata for a user behavior model, and then present our proposed Bayesian approach. For the proposed model, we give solutions to the user behavior model learn-ing and user intent inference problems in Section 3.3. In Section 3.4, we describe a clustering-based approach that partitions the users and tasks into homogeneous groups and estimates model parameters for each cluster. To aid clarity and concreteness we will continue using user behavior modeling on search engines as our running example.
Since the primary purpose of the user behavior model is to obtain actionable knowledge of the user intentions so as to adapt the system response, it is desirable to not only figure out the various possible user actions, but the exact sequence in which these are likely to oc-cur. Hence, a sequential model of the action sequence is appropriate.
One possible way to achieve this is by focusing only on the ob-served actions and modeling the hidden user behavior using a Hid-den Markov Model (HMM); this is similar to the approach followed in [13, 16]. The basic assumption is that the user goes through a sequence of hidden states drawn from a discrete set and emits a sig-nal, i.e., observed action along with associated properties, in each state, which can be used to infer the hidden state sequence. Learn-ing such a model, however, involves some challenges. First, the appropriate number of states is not known and can often be large to accommodate observed user actions that are annotated with text (e.g., querying a phrase). Second, the learnt hidden states are dif-ficult to interpret and validate through alternate advanced monitor-ing of users, e.g., via eye-tracking. This is especially important in real-world systems for guiding exploration of new potentially useful user interfaces. Finally, it is not straightforward to incorporate com-monly available domain expertise on frequent hidden actions (e.g., examine next/previous result in the list) and hidden attributes pre-dictive of user intent(e.g., number of results examined so far) into a simple HMM model.

Hence, we consider an alternate model that retains the temporal sequential nature of a Hidden Markov Model, but explicitly incor-porates the hidden actions and predictive hidden attributes by con-sidering a continuous state space consisting of both observed and hidden components and the state transitions being influenced by the intermediate actions (hidden and observed).
The fundamental assumption in our user session model is sim-ilar to that of HMM, i.e., each session involves a user traversing through a sequence of states following a first order Markov process. However, unlike in a HMM, each state is represented as a vector of attributes, which can be grouped into: (a) observed attributes , whose values are known throughout the ses-sion, (e.g., number of results clicked so far) (b) partially observed attributes , whose values are only known in the initial state and immediately preceding an observed action, (e.g., time since query) (c) hidden attributes , whose values are only known at the start of the session, (e.g., number of results examined so far)
The user traverses from one state to another by performing one of the possible actions. These can be observed actions (e.g. click ) or hidden actions (e.g. examine next ). Therefore, a session comprises a fully observed initial state vector (i.e., all attributes are observed), followed by an alternating sequence of user states and actions, and is terminated by an exit state.

Following the notation introduced in Section 2.2, let w denote a web session with the associated user u and the sequence of user ac-tions  X  a with the terminal actions assumed to be always observed. To describe the model in further detail, we partition the action se-quences into action segments ; let L ( w ) denote the number of ac-tion segments in session w . Each action segment is a contiguous sub-sequence of  X  a beginning with an observed action and ending just before the next observed action. Let the t th segment comprise L ( w,t ) number of actions and be denoted by  X  a { t } . Example: for the session in left panel of Figure 1.1, discussed in Section 2.1, there are two action segments, &lt; a 1 a 4 a 4 a 4 &gt; and &lt; a
Further, let A t,i ,S t,i denote the i th user action in the t and the user state immediately preceding this action respectively. Let S O t,i ,S H t,i and S PO t,i denote the observed, hidden, and partially observed components of the state S t,i . By definition, A served action and the partially observed attributes are known for the state S t, 1 . For notational convenience, we denote the state imme-diately following the t th action segment, as S t,L ( w,t )+1 Figure 3.2 shows the dynamic Bayesian network that captures the sequential dependencies in our user behavior model.
 A
Our model involves two key Markovian assumptions. (A1) The user action A t,i following any state S t,i is conditionally independent of all the past session history given the state vector. In other words, we assume that the user state representation is rich enough to encode all the historical session information that deter-mines the next user action. A larger set of hidden actions typically necessitates a richer state representation that can discriminate be-tween the various actions. (A2) The next user state S t,i +1 following any state S t,i tionally independent of all the past session history given S the user action A t,i and the known system response policy. This as-sumption essentially ensures that the user states follow a first order Markov process, but the key difference is the observability of the user action in certain cases. 4 .

Based on the above assumptions, the joint distribution of all the a session w can be decomposed in terms of two distributions: 1. Action Generation Probability. We capture the conditional probability of a user action given the current state via a paramet-ric distribution p  X  ( A t,i | S t,i ) . Since the actions A a small finite set of actions A = { a q } N A , we pose this as a multi-class problem 5 and choose an appropriate parametric representation such as a multinomial logit or naive Bayes model. In case of multi-nomial logit model, we have where X ( S t,i ) is a feature vector constructed by suitable transfor-mation of the original state vector by binning and inclusion of inter-action features. 2. State Transition Probability. Similarly, we encode the depen-dencies between the next user state S t,i +1 and the current state and action ( S t,i ,A t,i ) via a parametric distribution p  X  Even though there is a strong dependency on the system response policy R sys , we do not need to explicitly model it since R known and invariant in the current setting. Since S t,i +1 dimensional vector potentially containing attributes of different types (categorical / ordinal / real), we approximate p  X  ( S t,i +1 as a product of appropriately chosen multivariate conditional distri-butions associated with the key attribute types, e.g., Gaussian for real-valued attributes, Poisson for integer-valued attributes and Bernoulli or multinomial models for binary/categorical attributes. In most real systems, however, there is sufficient domain expertise to deterministically compute most attributes of the next state so that, in practice, the parameter  X  in this model has very few degrees of freedom.
 To be precise, let a given session w be composed of W W
H (the observed and hidden portions respectively). Then the joint apply correctly even at the segment boundaries
In certain case, one can have a large number of actions when naively considering actions annotated with keywords (e.g., succes-sive queries in a query chain), but such actions can be reduced to a smaller subset of more meaningful actions (e.g., specialization, generalization) conditioned on the initial action. distribution of the session variables is given by where the conditioning on user u and system R sys in all distri-butions is implicit. Since only W O is observed, the distribution p ( W 0 | u, R sys ) is obtained by marginalizing Equation 3.3 over all the hidden action and state variables.
 Example. Before proceeding to learning and inference of this model we give a simple example of how it might map to the web search setting; see Section 4.1 for the full instantiation of this model for a search engine. At any time in the session, a user could be mod-eled as being in a state given by a six dimensional vector: (P1) number of results clicked , (P2) cumulative match of query with results clicked , (P3) time since query , (P4) current position , (P5) number of results examined , and (P6) cumulative match of query with all results examined . Of these, values of (P1) and (P2) are known at all times ( observed ), (P3) and (P4) are known only when a click is observed ( partially observed ), and (P5) and (P6) are hidden . As mentioned earlier, assumption (A1) is equivalent to stating that the six dimensional state attribute vector encodes all the relevant in-formation for determines the next action of the user (e.g., clicking, examining up/down the results). Given these attributes and some others about the initial predisposition of the user, this assumption seems fairly realistic. Furthermore, for this choice of state repre-sentation, it is clear that the all the attributes except time since query can be computed deterministically using the current user state and the action taken by the user. For example, if P4 has a value 2, then depending on the next action then value can be deter-mined: P4 is 3 if action is examine next , or P4 is 1 if action is examine previous or P4 remains 3 if action is click . Even attributes such as time since query can be modeled stochasti-cally with reasonable accuracy. Hence, the assumption (A2) that the next user state depends only on the current state and the action taken is also valid. In the user session shown in the left panel of Figure 1.1, the initial state S 1 , 1 after the query is given by the vector [000000] , the state after second action ( examine next ) S 1 , 2 is [001111] , and after the fifth action ( click ) S 2 , 1 is [115333] . Interested read-ers can work through this example to familiarize themselves with our user-state model. In this section we give algorithms to solve these two problems: User Behavior Model Learning , i.e., estimating the model param-eters  X  = (  X , X  ) from the available web session data.
 User Intent Inference , i.e., determining the most likely user action sequence (including past and future hidden actions) given the learnt user behavior model and a partially observed web session.
Given the parametric form for the joint distribution p of all the variables associated with a web session, and a set of observations natural approach for estimating the model parameters involves max-imizing the likelihood of the training data (Equation 2.1). Since the session observations are incomplete, we choose to optimize the in-complete data likelihood obtained by marginalizing over the hidden action and state variables. As discussed earlier, let W H hidden state/action variables associated with the web sessions, i.e., the hidden actions ( A t,i ,i &gt; 1) and intermediate state variables ( S t,i ,t &gt; 1 ,i &gt; 1) , and, let  X  p denote their posterior probability function. In order to compute the likelihood, following the analysis in [11], we consider the free energy function, which is defined as the sum of the expected complete log-likelihood and the entropy of the hidden variables with respect to an arbitrary distribution  X  p , Since  X  consists of the action-generation model parameters (  X  ) and the state-transition model parameters (  X  ) the free energy function can be rewritten as The non-convex nature of the free-energy function L (  X  p, X , X  ) makes it intractable to obtain a global optimum. Hence, we follow a gen-eralized EM-based alternate minimization approach that involves cyclically optimizing the free energy function over each of the ar-guments (  X , X ,  X  p ) keeping all the other ones fixed. We now discuss each of these update steps:
Updating  X  : Optimizing the free energy function in Equation (3.4) with respect to  X  , we obtain, On closer examination, we note that this maximization is equivalent to optimizing the likelihood with respect to the chosen state-action classification model (e.g., multinomial logistic regression/Naive Bayes) given a collection of labeled, weighted training samples by the posterior distribution  X  p . The model parameters  X  can thus be learned in a modular fashion using the estimation techniques appro-priate for the chosen classification model.

Updating  X  : The state transition model parameters  X  can also be updated in a similar fashion,  X   X   X  argmax As in the case of updating  X  case, the objective function to be max-imized can be expressed as the data likelihood of a collection of weighted tuples with respect to the chosen state transition regres-sion model. Here each tuple corresponds to a single state transition and contains the response variable (components of the next state S t,i +1 ) and the covariates (components of the prior state S the preceding action A t,i ). The tuple weights depend on the poste-rior distribution  X  p . Depending on the choice of the state-transition regression model, one can estimate the parameters  X  using a suitable algorithm.

Updating  X  p . Estimating the posterior distribution of the hidden session variables  X  p ( W H ) is much more complex than that of the parameters  X , X  since each W H comprises of multiple hidden vari-ables that span multiple session segments and exhibit sequential de-pendencies. A naive application of EM would involve a random ini-tialization of the posterior distribution of all the latent variables (hid-den actions/states) and cyclic optimization over each one of these distributions. This is likely to require multiple restarts and large number of iterations making it computationally infeasible. Hence, we adopt a modular sequential approach that minimizes the compu-tational effort by a judicious propagation of information from each action-segment to the successive one.
 We first partition the hidden variables associated with a session W
H into disjoint groups { W H t } L ( w ) For each segment t , W H t consists of its hidden actions set { A den session variables, we impose additional constraints on the pos-terior distribution  X  p by assuming that the session variables associ-ated with the different segments are independent of each other. In other words, we restrict  X  p ( W H ) to have the form Q L ( w ) and separately optimize each of the component distributions.
To perform this optimization, we employ a sequential approach that involves first estimating the posterior distributions of the hid-den segment variables  X  p ( W H 1 ) in the natural order of the segment. The key motivation for this choice is based on the following ob-servation. The initial state S 11 = [ S 0 11 ,S PO 11 ,S observed. This makes it possible to infer the hidden variables asso-ciated with this segment W H 1 (including the hidden component of the state at the end of the first segment S H 1( L ( w, 1)+1) fairly high accuracy without any additional information from other segments. However, for the later segments, there is a strong depen-dency between the segment hidden variables W H t and the hidden component of the segment initial state S H t 1 (which is contained in W t  X  1 ). An accurate estimate of the distribution of S H result in better estimates of  X  p ( W H t  X  1 ) and hence, it is beneficial to update the  X  p ( W H t  X  1 ) in a sequential manner. The actual update step is given by  X  p ( W H t )  X   X  argmax
Finally, since each segment consists of multiple actions and state transitions, it is also often advantageous to update the parameters (  X , X  ) after each successive segment to obtain better convergence. Algorithm 1 provides the details of such an iterative approach and is guaranteed to converge to a local optimum.
Given the user behavior model parameters (  X , X  ) and a partial user interaction sequence {  X  a O 1 ...  X  a O T } up to the T ference problem consists of determining the most likely choices for the hidden state/action variables up to the T th segment { W as well as the future state/action sequence.

Note that the action sequence up to the T th segment can be eas-ily translated to the set of observed variables in the state { W Hence, we observe that the inference of the most likely hidden vari-ables up to the T th segment is equivalent to estimation of the pos-terior distributions {  X  p ( W H t ) } T t =1 assuming them to be degenerate. Therefore, we employ the same approach as in the case of model learning and sequentially infer the hidden variables as follows:
For future segments, i.e., when t &gt; T , the update step has the same form with the main difference being that the boundary state S included into W H t .
In the user behavior model discussed so far, we have a common action-generation and state-transition model across all user sessions. However, in practice, there is a lot of heterogeneity in user behavior, e.g., eye-tracking studies have shown that unsophisticated web users tend to browse web pages slowly and sequentially, while younger, more net-savvy, users exhibit faster and more irregular scanning be-havior. Given that users on the Web are largely anonymous, this difference in behavior cannot readily be modeled by incorporating a feature in the state vector. It is also common for a single user to exhibit different behavior depending on the current task, e.g., it is well known that web users exhibit very different behaviors on navigational and informational searches. This variation across tasks can be partially addressed by incorporating the query words into the state vector. However, this solution is often inadequate for low fre-quency query words (a huge fraction since queries follow a heavy tail distribution) or polysemous queries (e.g., greyhound).
Before, we describe our approach to capture these behavioral variations due to latent properties of users and tasks, we need to develop the notion of task . We take a task q to be a domain depen-dent property of sessions that capture the intent behind the sessions. For example, in case of search query sessions, the task could be defined as a normalized query (with stemming, stop word removal, synonym resolution etc.). Hence, slightly different queries executed by two different users could be said to accomplish the same task. Given this augmented web session data { u,q,r,  X  a } sider a bi-clustering based web session model that involves simul-taneously partitioning the users and tasks into disjoint groups that exhibit similar behavior in terms of the associated action-generation model and state-transition models.
 Let U , Q denote the set of users and tasks and  X  : { 1 ,  X  X  X  ,N { 1 ,  X  X  X  ,k } and  X  : { 1 ,  X  X  X  ,N T } 7 X  { 1 ,  X  X  X  ,l } denote the map-ping from the users and tasks to the user clusters and task clusters respectively. We let the state-transition and action-generation dis-tribution be homogeneous within each user-task bicluster, i.e., we associate with the gh th bi-cluster model parameters  X  gh conditional likelihood of a web-session ( u,q,r,  X  a ) , then depends on the bicluster to which user-task pair ( u,q ) belongs, and is given by with implicit conditioning on u , q and R sys .

Model Learning. To learn the above bi-clustering based model, we not only need to estimate the parameters  X  gh , X  gh , but also iden-tify the user and task clustering (  X , X  ) that maximizes the data like-lihood, i.e.,
L (  X  p, X , X , X , X  ) = E
As in previous case, we alternately optimize over each of the ar-guments (  X  p, X  gh , X  gh , X , X  ) keeping the others fixed. The estima-tion of the posterior distribution  X  p remains identical to that of the single model with the state-transition and action-generation param-eters (  X , X  ) chosen to correspond to the bicluster (  X  ( u ) , X  ( q )) . The update steps for (  X  gh , X  gh ) also remain identical with the key dif-ference being that only web sessions ( u,q,.,. ) such that  X  ( u ) = g and  X  ( q ) = h needs to be considered while updating the parameters associated with the gh th bicluster.
 To optimize the user-task clustering (  X , X  ) , we note that the like-Algorithm 1 User Behavior Model Learning and Clustering lihood function is separable across users and tasks and adopt a k-means like approach. In particular, for each user U , we compute the likelihood of all the sessions of this user for each possible user clus-ter assignment (keeping all the other parameters including the task clustering fixed), and choose the one that results in the maximum value. The clustering of task Q is performed similarly.  X  ( U )  X  argmax  X  ( Q )  X  argmax
Algorithm 1 provides the overall details of the approach and is guaranteed to converge to a local optimum.

Inference. For a known user u and task q , inferring the past and future hidden session information from a partial session given the model and user-task clustering, is identical to the process described in Section 3.3.2 and depends on the model parameters  X   X  ( u ) , X  ( q ) and  X   X  ( u ) , X  ( q ) associated with the user-task bicluster. However, in case of a session involving a new user and/or a new task, we need to first determine the best choice of user-task bi-cluster by maxi-mizing the likelihood over the k.l possible choices and then use the appropriate model parameters for further inference.
In this section we instantiate our proposed user behavior model to a web search setting and evaluate our learnt model against com-petitive baselines that use the same learning framework. The ideal evaluation would have used ground truth derived from eye-tracking studies. However, in the absence of such data we evaluate candidate methods on real-world tasks that we would expect to perform with them, completing user sessions and predicting post-session actions. Table 4.1: Instantiation of the DBN to a web search engine set-ting.
In our experiments, we define a search session as consisting of a query-task, a search results page ( SERP ), and a sequence of user actions on the SERP . All the information present on the SERP is used to define the state of the user; the attributes that make up the user state vector are listed in Table 1(a). We selected these attributes so as to comprehensively summarize the state of the search session, hence, ensuring that our Markovian assumption about the next ac-tion being conditionally independent of session-history is valid. The state attributes are modified by the user actions listed in Table 1(b). The allowable actions were selected to simulate some of the user behavior idioms discernible in eye-tracking studies. For example, before clicking users typically rapidly scan over the result set revis-iting some of the already examined results. Moreover, users tend to maintain mental markers in the results-list to jump to; such as the first result, or the maximum result position visited so far.
In terms of learning, we use a multinomial logit model over the state variables for computing the action-generation probabilities. Lo-gistic Regression with a ridge parameter of 10  X  7 was used to learn the parameters of this model. As we can see from Table 1(a) all state variables can be computed exactly given the last state and the latest action taken by the user. Hence, state-transition model is com-pletely deterministic. Finally, in order to make marginalizing over hidden action sequences tractable, we limit the number of possible hidden actions between consecutive clicks to 10 , the minimum time required for a hidden action to 1 second, and only use the most prob-able hidden action sequence found.
 D sion to be a user issuing a single query followed by views/clicks on the set of results returned on the first search results page. A click on  X  X ext 10 results X  or a  X  X uery suggestion X  is regarded as the end of the current session. The session data used in these experiments comprises all search sessions of around 3500 users over a period of a month in the fall of 2008. The selected set of users was randomly picked from a larger set in which each user had a significant number ( &gt; 20 ) of searches within the month. The bias introduced is un-avoidable since learning from fewer sessions per user is impractical and uninteresting. For each session we have the following informa-tion available: the query, the set of viewed results, the set of clicked results and the corresponding timestamps. In addition we fetch the content of the results returned by the search engine in the SERP . The cosine similarity of the query to the title, the important text(within &lt;h*&gt; tags), and the full-text of each web page is also available to the modeling methods. We selected cosine similarity since it has been shown to be meaningful on text data, however, any similarity mea-sure could have been used. Queries that map to the same string after normalization that includes, lower case, stop word removal, porter stemming, and sorting the terms, are given the same task id. The final data used in our experiments included around 210K sessions involving 120K unique queries issued by around 3500 users. All in-formation that can be used to identify an user was removed from the dataset. The train-test split was 50% ; no validation data was needed as we did not set any parameters based on cross-validation.
In this section we evaluate the performance of our approach in predicting completions of partial user sessions. In particular, we at-tempt to predict the remainder of clicks on a search results page after observing the first k clicks. We posed this as the user intent infer-ence problem in Section 2 and gave a solution to it in Section 3.3.2. O fer to the model of user behavior that we learn using the instantia-tion of our DBN model to the search engine setting as detailed in Section 4.1. This approach models the entire set of allowable user actions and clusters the users and tasks into 4 groups each. Past work [2, 4, 13] in modeling search engine users has not taken into account a complex set of hidden user actions. In order to eval-uate the performance gain from modeling these complex hidden actions, we construct a baseline (called O NLY N EXT A CT stricts users to only the Examine Next action along with the two observable actions Click and End Session . In addition, this baseline does not perform any clustering of users and tasks. All other parameter settings in O NLY N EXT A CT are identical to those of A LL A CTS C LUSTS . This, along with the fact that O NLY N approach uses the entire set of state attributes (in Table 1(a)) to rep-resent users, makes it a competitive representative of past work in the area of user modeling in search engines [2, 4, 13].

In order to further quantify the benefit achieved by performing clustering, we experiment with another version of our approach (called O NE C LUST ) that models user session using all actions mentioned in Table 1(b), but does not perform any clustering of users and tasks. Other than setting the number of user and query clusters to 1 all other parameter settings are the same as those for A LL A E
VALUATION M EASURES . In order to evaluate the ability of our approach in completing partial user sessions we use two metrics. N
UM C LICKS denotes the absolute difference in the number of clicks predicted by the model upon observing a partial session and the ac-tual clicks in the session. This metric scores models based on their ability to predict an aggregate property of search sessions. We use E
DIT D ISTANCE to measure how well the model predicts the actual sequence of click positions. E DIT D ISTANCE is computed as the minimum number of operations (insertion, deletion, or substitution of a single position) needed to transform our predicted click position sequence into the ground truth sequence. The cost of substitution was set proportional to the absolute difference in the positions that were being substituted. We set the cost of insertion/deletions to be 5 times the cost of substitution of one position since we wanted to penalize a model less if the correct click position was found but was simply misaligned.
 R ESULTS . Tables 2(a) and 2(b) list the performance numbers for A LL A CTS C LUSTS and O NLY N EXT A CT . Note that for both N C
LICKS and E DIT D ISTANCE measures lower values indicate better performance. We observe that in general the performance of A A CTS C LUSTS is significantly better than that of O NLY N EXT Moreover, this advantage in performance is especially large when very few clicks of the session have been observed. This implies that the knowledge of user behavior with a full set of hidden actions as Table 4.2: Performance of A LL A CTS C LUSTS and O NLY N EXT in terms of N UM C LICKS and E DIT D ISTANCE . k denotes the number well as user and task cluster memberships are critical to make pre-dictions when nothing is known about user behavior in the session. However, as more information is known after observing multiple clicks ( k  X  3 ) the need for a more complicated model is avoided. These observations hold for both the N UM C LICKS and E DIT TANCE measures.

We noticed that there was a huge improvement in performance after observing 1 click. We speculate that this is due to navigational queries that typically result in a single user click and are known to comprise a large fraction of search traffic (around 20% by some es-timates [15]). Hence, after observing the first click, the session ends for an artificially large fraction of queries and this makes the pre-dicting the sequence rather easy. Indeed, even a trivial policy that always ends sessions immediately scores around 0 . 40 after observ-ing the first click. Hence, in order to ensure that the performance improvement of A LL A CTS C LUSTS in relation to O NLY N EXT is not simply due to these queries, we created a separate set of test queries from which we removed all navigational ones. The naviga-tional queries were determined using an in-house system that uses signals/data that are unavailable to either of the approaches. From the Tables 2(a) and 2(b), we can see that while the performance of both approaches deteriorates on non-navigational queries as ex-pected, A LL A CTS C LUSTS still outperforms O NLY N EXT A The performance of the O NE C LUST approach is very close to A
LL A CTS C LUSTS . In fact, after observing one click ( k  X  1 ), the performance of the two approaches is statistically indistinguishable. However, the O NE C LUST approach has a score of 0 . 84 and 4 . 17 for the N UM C LICKS and E DIT D ISTANCE measures respectively when k = 0 averaged over all queries. As we can see from the data in Table 4.2, this is significantly worse than the performance of A A
CTS C LUSTS . This shows that the knowledge of behavioral vari-ations exposed by the user and task clustering are especially useful when zero observed information is available about a session.
In this section, we will evaluate whether the completions of ses-sions performed by our approach are useful for predicting the post-session action of the user. This is a significant problem and has been been studied before [10].
 M
ETHODOLOGY . From the query logs we determine the next action performed by users after they end the session. The user can End : leave the search engine for more than 30 minutes Next : request another set of N results for the same query Reformulate : issue another query We then construct a classifier B ASE C LASS that takes as input sets of features derived from the observed clicks of the session and pre-dicts one of the above actions. The set of features used encodes the time taken for all the clicks, the highest position clicked, the number of positions skipped, time used between successive clicks, fraction of out-of-order clicks, etc. Hence, B ASE C LASS uses the observed behavior of the user to make a prediction about what the user would C OMP C LASS 65.4% 63.2% 61.3% 60.6% 61% Table 4.3: Classification accuracy of C OMP C LASS and B C
LASS in predicting post-session user actions. do at the end of the session. We could have constructed a stronger classifier by including additional features [10], but we wanted to isolate the benefit of using unobserved behavioral features, in addi-tion to just the features from observed behavior, on the prediction of post-session user actions.

As in the previous experiment, we used the solution we gave for the user intent inference problem in Section 3.3.2 to obtain the com-plete action sequence of users, given a partial observed one. From the predicted clicks and hidden action sequence we constructed all the features used by B ASE C LASS as well as additional ones like number of hidden actions between clicks, total number of hidden actions in the session, fraction of Re-examine Previous ac-tions, fraction of Re-examine Position x and Re-examine Position 1 actions, and the fraction of Re-examine Position max-examined+1 actions. We used Random Forest [1] to pre-dict post-session actions from features in both B ASE C
OMP C LASS as it has been shown to be very effective in a host of classification tasks. We used the Random Forest implementa-tion in Weka [17] and ran it with the following parameter setting: numTrees = 10 , maxDepth = 0 ( unlimited ) .
 R
ESULTS . The performance of C OMP C LASS and B ASE C LASS predicting post-session user actions via behavioral features are sum-marized in Table 4.3. The numbers reported are classification ac-curacy averaged through 10-fold cross-validation. As we can see C
OMP C LASS out-performs B ASE C LASS by a very large margin when zero clicks of the session have occurred and no observed user be-havior is known. In fact, the performance of B ASE C LASS a random policy would achieve for a 3-class problem with equal-sized classes. C OMP C LASS , on the other hand, uses observed and unobserved behavioral features created using automated completion of sessions by A LL A CTS C LUSTS . Therefore, even when no user behavior has been observed, C OMP C LASS achieves a classification accuracy of &gt; 65% . This prediction, available before a user has even interacted with the system, can be extremely useful for search engines in tailoring their search engine results pages.
 As more clicks are observed in the sessions, the margin by which C
OMP C LASS outperforms B ASE C LASS drops to about 4% . Finally, when enough clicks have been observed B ASE C LASS outperforms C
OMP C LASS as the noise added by features constructed by first pre-dicting the sequence of clicks starts overwhelming the additional benefit of knowing the complete sequence of clicks. Note, that the performance of C OMP C LASS is not comparable across different val-ues of k since the set of queries with &gt; k clicks changes drastically. Table 4.4: User and task clusters, properties, and representative terms. M
ETHODOLOGY . Evaluation of clustering is a hard problem, espe-cially when true groupings are unavailable for the test set. Hence, in this section, we present an anecdotal evaluation of one particular clustering of users and queries obtained by A LL A CTS C LUSTS parameters are set same as before and we obtain 4x4 biclusters.
We interpret the clusters obtained in terms of properties of users and tasks that are placed in them. For the users we use as ground truth self-reported demographic properties Age and Gender , and properties like isWin , isIE , isUS , derived from the http-agent string. For the tasks we obtained properties like Navigational and Com-mercial which are obtained from third-party classifiers that predict whether a task is  X  X avigational X  or  X  X ommercial X , respectively. We  X  X ag X  the clusters with user/task properties and the query-words that are over-represented in the sessions in the clusters than in the general population. The degree of over-representation is computed using p-values, which tell us the chance (by random) of seeing a word/property in a particular cluster as many times as is actually observed. We as-sume that word or property occurrences are governed by a hyper-geometric distribution, which models samples drawn from small populations without replacement. Query words and properties that score a p-value of &lt; 0 . 05 for a cluster are considered its  X  X ags X .
The results of this experiment are summarized in Table 4.4. Due to lack of space we only show the  X  X ags X  for four user-task biclus-ters 6 . In the table the first row lists the various session properties associated with members of each task cluster while the first column does the same for each user cluster. The meaning of these proper-ties is evident from the names, but we will explain them as they are encountered. Note that tagging a user or task cluster with a prop-erty does not imply that all members of a cluster retain that property value. Moreover, this table also does not imply that there exists a session with the all the properties found over-represented together in a cluster. The checkerboard area of the table contains the query words found over-represented in the biclusters. Sometimes addi-tional words are included in (...) to clarify the original word X  X  sense. R ESULTS . Let us first consider the task clusters. The Task cluster TC1 contains queries that are typically short and often times receive exactly one click. Moreover, the user typically ends her search ses-sion after executing queries that fall into TC1. All these properties seem to point to TC1 containing navigational queries. This is fur-ther confirmed by the property Navigational being set to  X  X es X . On the other hand, Task cluster TC2 contains queries that are typically longer than 2 words and often receive more than 1 click. Further-more, users issuing queries in this cluster are likely to request more
For full results on all 16 clusters please see www.ideal.ece.utexas.edu/~kunal/papers/ cikm10-searchengineusermodel-long.pdf results or reformulate the query. This is a textbook definition of  X  X n-formation queries X  [15]. Moreover, the intent behind many of these queries is also commercial as witnessed by the Commercial and Ad-Clicks properties. Hence, it is apparent that using just the behav-ioral tendencies of users on tasks, A LL A CTS C LUSTS has been able to clearly separate out  X  X avigational X  and  X  X nformational X  tasks. The first column of Table 4.4 shows two of the clusters found by A
LL A CTS C LUSTS . As we can see the users are segmented very well by their Age . The values for the property Gender did not seem to be concentrated in any user cluster expect UC1. This suggests that the behavior on the search results page is more indicative of the age of the person than the gender. Finally, we observe that the user X  X  OS and browser tend to be correlated to their search behavior.
We presented a DBN to model user behavior on web information systems. Further, we gave a clustering based formulation to handle heterogeneity due to variations in behavior of users and on tasks. Finally, we gave an instantiation of the DBM for search engines and evaluated our model against strong baselines on real-world data. Our evaluation shows that our model, due its use of a more expres-sive set of possible user actions and learning of different models for each user-task bicluster, outperforms baselines on two real-world tasks: completing user sessions and predicting post-session actions.
