 Hierarchically structured data abound across a wide variety of domains. It is thus not surprising that hierarchical clustering is a traditional mainstay of machine learning [1]. The dominant approach to hierarchical clustering is agglomerative: start with one cluster per datum, and greedily merge pairs until a single cluster remains. Such algorithms are efficient and easy to implement. Their primary limitations X  X  lack of predictive semantics and a coherent mechanism to deal with missing data X  can be addressed by probabilistic models that handle partially observed data, quantify goodness-of-fit, predict on new data, and integrate within more complex models, all in a principled fashion. Currently there are two main approaches to probabilistic models for hierarchical clustering. The first takes a direct Bayesian approach by defining a prior over trees followed by a distribution over data points conditioned on a tree [2, 3, 4, 5]. MCMC sampling is then used to obtain trees from their posterior distribution given observations. This approach has the advantages and disadvantages of most Bayesian models: averaging over sampled trees can improve predictive capabilities, give confidence estimates for conclusions drawn from the hierarchy, and share statistical strength across the model; but it is also computationally demanding and complex to implement. As a result such models have not found widespread use. [2] has the additional advantage that the distribution induced second approach uses a flat mixture model as the underlying probabilistic model and structures the posterior hierarchically [6, 7]. This approach uses an agglomerative procedure to find the tree giving the best posterior approximation, mirroring traditional agglomerative clustering techniques closely and giving efficient and easy to implement algorithms. However because the underlying model has no hierarchical structure, there is no sharing of information across the tree.
 We propose a novel class of Bayesian hierarchical clustering models and associated inference algo-rithms combining the advantages of both probabilistic approaches above. 1) We define a prior and compute the posterior over trees, thus reaping the benefits of a fully Bayesian approach; 2) the dis-efficient and easy to implement inference algorithms that construct trees agglomeratively; and 4) the induced distribution over data points is exchangeable. Our model is based on an exchangeable distri-bution over trees called Kingman X  X  coalescent [8, 9]. Kingman X  X  coalescent is a standard model from population genetics for the genealogy of a set of individuals. It is obtained by tracing the genealogy backwards in time, noting when lineages coalesce together. We review Kingman X  X  coalescent in Section 2. Our own contribution is in using it as a prior over trees in a hierarchical clustering model (Section 3) and in developing novel inference procedures for this model (Section 4). Figure 1: (a) Variables describing the n -coalescent. (b) Sample path from a Brownian diffusion coalescent process in 1D, circles are coalescent points. (c) Sample observed points from same in 2D, notice the hierarchically clustered nature of the points. Kingman X  X  coalescent is a standard model in population genetics describing the common genealogy a countably infinite set of individuals. Like other nonparametric models (e.g. Gaussian and Dirich-let processes), Kingman X  X  coalescent is most easily described and understood in terms of its finite dimensional marginal distributions over the genealogies of n individuals, called n -coalescents. We obtain Kingman X  X  coalescent as n  X  X  X  .
 Consider the genealogy of n individuals alive at the present time t = 0 . We can trace their ancestry backwards in time to the distant past t =  X  X  X  . Assume each individual has one parent (in genetics, ing sets  X  1 ,..., X  m of descendants (we will make this identification throughout the paper). Note that  X  ( t ) = {  X  and succinctly characterizes the genealogy; we shall henceforth refer to  X  as the genealogy of [ n ] . Kingman X  X  n -coalescent is simply a distribution over genealogies of [ n ] , or equivalently, over the space of partition-valued functions like  X  . More specifically, the n -coalescent is a continuous-time, backwards in time , merging (coalescing) lineages until only one is left. To describe the Markov Markov chain over partitions) and the distribution over coalescent times. Both are straightforward and their simplicity is part of the appeal of Kingman X  X  coalescent. Let  X  li , X  ri be the i th pair of duration between adjacent events (see Figure 1a). Under the n -coalescent, every pair of lineages merges independently with exponential rate 1. Thus the first pair amongst m lineages merge with among those right after time t i , and with probability one a random draw from the n -coalescent is a binary tree with a single root at t =  X  X  X  and the n individuals at time t = 0 . The genealogy is: Combining the probabilities of the durations and choices of lineages, the probability of  X  is simply: The n -coalescent has some interesting statistical properties [8, 9]. The marginal distribution over tree topologies is uniform and independent of the coalescent times. Secondly, it is infinitely ex-changeable: given a genealogy drawn from an n -coalescent, the genealogy of any m contemporary individuals alive at time t  X  0 embedded within the genealogy is a draw from the m -coalescent. for which the marginal distribution of the genealogy of any n individuals gives the n -coalescent. Kingman called this the coalescent . time . We will alter our terminology from genealogy to tree, from n individuals at present time to n observed data points, and from individuals on the genealogy to latent variables on the tree-structured distribution. Let x = { x 1 ,...,x n } be n observed data points at the leaves of a tree  X  drawn from We use a continuous-time Markov process to define the distribution over the n data points x given the tree  X  . The Markov process starts in the distant past, evolves forward in time, splits at each coalescent point, and evolves independently down both branches until we reach time 0, when n data points are observations of the process at the n leaves of the tree. The joint distribution described by this process respects the conditional independences implied by the structure of the directed tree  X  . y at time t . This Markov process need be neither stationary nor ergodic. Marginalizing over paths of the Markov process, the joint probability over the latent variables and the observations is: Markov process at time 0 . However the observations are not independent as they share the same sample path down the Markov process until it splits. In fact the amount of dependence between two observations is a function of the time at which the observations coalesce. A more recent coalescent time implies larger dependence. The overall distribution induced on the observations p ( x ) inherits the infinite exchangeability of the n -coalescent. We consider in Section 4.3 a brownian diffusion (Figures 1(b,c)) and a simple independent sites mutation process on multinomial vectors. We develop two classes of efficient and easily implementable inference algorithms for our hierar-chical clustering model based on sequential Monte Carlo (SMC) and greedy schemes respectively. In both classes, the latent variables are integrated out, and the trees are constructed in a bottom-up fashion. The full tree  X  can be expressed as a series of n  X  1 coalescent events, ordered backwards in time. The i th coalescent event involves the merging of the two subtrees with leaves  X  li and  X  ri the first i coalescent events.  X  n  X  1 is equivalent to  X  and we shall use them interchangeably. y probability of x , but does impact the accuracy and efficiency of our inference algorithms. We found The marginal probability p ( x |  X  ) is now given by the product of normalization constants: Multiplying in the prior (2) over  X  , we get the joint probability for the tree  X  and observations x : Our inference algorithms are based upon (7). The sequential Monte Carlo (SMC) algorithms approx-imate the posterior over the tree  X  n  X  1 using a weighted sum of samples, while the greedy algorithms construct  X  n  X  1 by maximizing local terms in (7). Both proceeds by iterating over i = 1 ,...,n  X  1 , based upon the i th term in (7), interpreted as the product of a local prior exp  X  n  X  i +1 2  X  i and a local likelihood Z  X  i ( x , X  i ) for choosing  X  i ,  X  li and  X  ri given  X  i  X  1 . 4.1 Sequential Monte Carlo algorithms w i  X  1 . At iteration f (  X  s is approximated by: p (  X , x )  X  P s w s n  X  1  X   X  s weights normalized. An important aspect of SMC is resampling, which places more particles in high probability regions and prunes particles stuck in low probability regions. We resample as in Algorithm 5.1 of [10] when the effective sample size ratio as estimated in [11] falls below one half. computationally very efficient, but performs badly with many objects due to the uniform draws over pairs. SMC-PriorPost . The second approach addresses the suboptimal choice of pairs to coalesce. We first draw  X  s i from its local prior, then draw  X  s li ,  X  s ri from the local posterior: f This approach is more computationally demanding since we need to evaluate the local likelihood of every pair. It also performs significantly better than SMC-PriorPrior . We have found that it works This approach requires the fewest particles, but is the most computationally expensive due to the integral for each pair. Fortunately, for the case of Brownian diffusion process described below, these integrals are tractable and related to generalized inverse Gaussian distributions. 4.2 Greedy algorithms SMC algorithms are attractive because they can produce an arbitrarily accurate approximation to the full posterior as the number of samples grow. However in many applications a single good tree is often sufficient. We describe a few greedy algorithms to construct a good tree.
 Greedy-MaxProb : the obvious greedy algorithm is to pick  X  i ,  X  li and  X  ri maximizing the i th term in (7). We do so by computing the optimal  X  i for each pair of  X  li ,  X  ri , and then picking the pair maximizing the i th term at its optimal  X  i . Greedy-MinDuration : pick the pair to coalesce whose optimal duration is minimum. Both algorithms require recomputing the optimal duration for each as a Markov process where each pair of lineages coalesces at rate 1. Greedy-Rate1 : for each pair  X  pair with most recent time (as in Greedy-MinDuration ). This reduces the complexity to O ( n 2 ) . We found that all three performed similarly, and use Greedy-Rate1 in our experiments as it is faster. 4.3 Examples Brownian diffusion . Consider the case of continuous data evolving via Brownian diffusion. The positive definite covariance matrix. Because the joint distribution (3) over x , y and z is Gaussian, we can express each message M  X  i ( y ) as a Gaussian with mean likelihood is:  X  where D is the dimensionality. The message at the newly coalesced point has parameters: v Multinomial vectors . Consider a Markov process acting on multinomial vectors with each entry taking one of K values and evolving independently. Entry d evolves at rate  X  d and has equilibrium K ones and I entry d from  X  i to its parent as a vector M d  X  the local likelihood terms and messages are computed as, Unfortunately the optimal  X  i cannot be solved analytically and we use Newton steps to compute it. 4.4 Hyperparameter estimation We perform hyperparameter estimation by iterating between estimating a tree, and estimating the hyperparameters. In the Brownian case, we place an inverse Wishart prior on  X  and the MAP posterior  X   X  is available in a standard closed form. In the multinomial case, the updates are not available analytically and are solved iteratively. Further information on hyperparameter estimation, as well predictive densities and more experiments are available in a longer technical report. Synthetic Data Sets . In Figure 2 we compare the various SMC algorithms and Greedy-Rate1 on a range of synthetic data sets drawn from the Brownian diffusion coalescent process itself (  X  = I D ) to investigate the effects of various parameters on the efficacy of the algorithms 1 . Generally SMC-PostPost performed best, followed by SMC-PriorPost , SMC-PriorPrior and Greedy-Rate1 . With especially Greedy-Rate1 . This is because the posterior becomes concentrated and the Greedy-Rate1 approximation corresponds well with the posterior. As n increases, the amount of data increases as well and all algorithms perform better. However, the posterior space also increases and SMC-PriorPrior which simply samples from the prior over genealogies does not improve as much. We see this effect as well when S is small. As S increases all SMC algorithms improve. Finally, the algorithms were surprisingly robust when there is mismatch between the generated data sets X   X  and the  X  used by the model. We expected all models to perform worse with SMC-PostPost best able to maintain its performance (though this is possibly due to our experimental setup).
 MNIST and SPAMBASE . We compare the performance of Greedy-Rate1 to two other hierarchical clustering algorithms: average-linkage and Bayesian hierarchical clustering (BHC) [6]. In MNIST, Figure 2: Predictive performance of algorithms as we vary (a) the numbers of dimensions D , (b) observations n , (c) the mutation rate  X  (  X  =  X I D ), and (d) number of samples S . In each panel other parameters are fixed to their middle values (we used S = 50 ) in other panels, and we report log predictive probabilities on one unobserved entry, averaged over 100 runs.

Table 1: Comparative results. Numbers are averages and standard errors over 50 and 20 repeats. dimensions, repeating the experiment 50 times. In SPAMBASE, we use 100 examples of 57 binary attributes from each of 2 classes, repeating 20 times. We present purity scores [6], subtree scores ( # scores between 0 and 1, higher better). The results are in Table 1; except for purity on SPAMBASE, ours gives the best performance. Experiments not presented here show that all greedy algorithms perform about the same and that performance improves with hyperparameter updates.
 Phylolinguistics . We apply Greedy-Rate1 to a phylolinguistic problem: language evolution. Un-like previous research [12] which studies only phonological data, we use a full typological database of 139 binary features over 2150 languages: the World Atlas of Language Structures (WALS) [13]. The data is sparse : about 84% of the entries are unknown. We use the same version of the database as extracted by [14]. Based on the Indo-European subset of this data for which at most 30 features are unknown (48 languages total), we recover the coalescent tree shown in Figure 3(a). Each lan-guage is shown with its genus, allowing us to observe that it teases apart Germanic and Romance languages, but makes a few errors with respect to Iranian and Greek.
 Next we compare predictive abilities to other algo-rithms. We take a subset of WALS and tested on 5% of withheld entries, restoring these with var-ious techniques: Greedy-Rate1 ; nearest neighbors (use value from nearest observed neighbor); average-linkage (nearest neighbor in the tree); and probabilistic PCA (latent dimensions in 5 , 10 , 20 , 40 , chosen opti-mistically). We use five subsets of the WALS database, obtained by sorting both the languages and features of the database according to sparsity and using a varying percentage ( 10%  X  50% ) of the densest portion. The results are in Figure 3(b). Our approach performed reasonably well.
 Finally, we compare the trees generated by Greedy-Rate1 with trees generated by either average-linkage or BHC, using the same evaluation criteria as for MNIST and SPAMBASE, using language outperforms the other methods. NIPS . We applied Greedy-Rate1 to all NIPS abstracts through NIPS12 (1740, total). The data was preprocessed so that only words occuring in at least 100 abstracts were retained. The word counts were then converted to binary. We performed one iteration of hyperparameter re-estimation. In the supplemental material, we depict the top levels of the coalescent tree. Here, we use the tree to generate a flat clustering. To do so, we use the log likelihood ratio at each branch in the coalescent to determine if a split should occur. If the log likelihood ratio is greater than zero, we break the branch; otherwise, we recurse down. On the NIPS abstracts, this leads to nine clusters, depicted in Table 3. Note that clusters two and three are quite similar X  X ad we used a slighly higher log likelihood ratio, they would have been merged (the LLR for cluster 2 was only 0 . 105 ). Note that the clustering is able to tease apart Bayesian learning (cluster 5) and non-bayesian learning (cluster 7) X  X oth of which have Mike Jordan as their top author! We described a new model for Bayesian agglomerative clustering. We used Kingman X  X  coalescent as our prior over trees, and derived efficient and easily implementable greedy and SMC inference algorithms for the model. We showed empirically that our model gives better performance than other agglomerative clustering algorithms, and gives good results on applications to document modeling and phylolinguistics.
 Our model is most similar in spirit to the Dirichlet diffusion tree of [2]. Both use infinitely ex-changeable priors over trees. While [2] uses a fragmentation process for trees, our prior uses the reverse X  X  coalescent process instead. This allows us to develop simpler inference algorithms than those in [2] (we have not compared our model against the Dirichlet diffusion tree due to the com-plexity of implementing it). It will be interesting to consider the possibility of developing similar agglomerative style algorithms for [2]. [3] also describes a hierarchical clustering model involving model relational data; it would be interesting to apply our approach to their setting. Another related work is the Bayesian hierarchical clustering of [6], which uses an agglomerative procedure returning a tree structured approximate posterior for a Dirichlet process mixture model. As opposed to our work [6] uses a flat mixture model and does not have a notion of distributions over trees. There are a number of unresolved issues with our work. Firstly, our algorithms take O ( n 3 ) compu-tation time, except for Greedy-Rate1 which takes O ( n 2 ) time. Among the greedy algorithms we see that there are no discernible differences in quality of approximation thus we recommend Greedy-Rate1 . It would be interesting to develop SMC algorithms with O ( n 2 ) runtime, and compare these against Greedy-Rate1 on real world problems. Secondly, there are unanswered statistical questions. For example, since our prior is infinitely exchangeable, by de Finetti X  X  theorem there is an underly-ing random distribution for which our observations are i.i.d. draws. What is this underlying random distribution, and how do samples from this distribution look like? We know the answer for at least a simple case: if the Markov process is a mutation process with mutation rate  X / 2 and new states are [8]. Another issue is that of consistency X  X oes the posterior over random distributions converge to the true distribution as the number of observations grows? Finally, it would be interesting to gen-eralize our approach to varying mutation rates, and to non-binary trees by using generalizations to Kingman X  X  coalescent called  X  -coalescents [15].
 References
