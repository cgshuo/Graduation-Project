 An important challenge for biomedical information retrieval (IR) is dealing with the complex, inconsistent and ambigu-ous biomedical terminology. Frequently, a concept-based representation defined in terms of a domain-specific termi-nological resource is employed to deal with this challenge. In this paper, we approach the incorporation of a concept-based representation in monolingual biomedical IR from a cross-lingual perspective. In the proposed framework, this is real-ized by translating and matching between text and concept-based representations. The approach allows for deployment of a rich set of techniques proposed and evaluated in tradi-tional cross-lingual IR. We compare six translation models and measure their effectiveness in the biomedical domain. We demonstrate that the approach can result in significant improvements in retrieval effectiveness over word-based re-trieval. Moreover, we demonstrate increased effectiveness of a CLIR framework for monolingual biomedical IR if basic translations models are combined.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Retrieval Models  X  language models General Terms: Algorithm, Experimentation, Performance. Keywords: CLIR framework, Biomedical IR, concepts, TREC Genomics, MeSH, UMLS.
A major challenge for information retrieval in the life sci-ence domain is coping with its complex, inconsistent and ambiguous terminology [14, 22]. A single biomedical con-cept is often referred to using multiple terms (synonymy), including long multi-word phrases, ad hoc abbreviations and spelling variations. Shorter terms, in particular abbrevia-tions, can be ambiguous: often the same term is used to refer to different concepts (homonymy).

It is evident that word-based information retrieval in this domain may benefit from knowledge found in terminologi-cal resources, such as controlled vocabularies, thesauri and domain-specific databases. These resources are commonly used for query expansion. Experiences during the TREC Genomics benchmarks illustrated, however, that beneficial incorporation of these terminological resources is far from trivial. An out-of-the-box TF.IDF retrieval system outper-formed many sophisticated approaches incorporating knowl-edge from terminological resources [10]. Approaches which do benefit from terminological resources are frequently ad hoc or heavily geared towards the task at hand [21].
In this work, we view the integration of a concept-based representation in biomedical IR as a cross-lingual retrieval problem. We will demonstrate that approaches to tradi-tional cross-lingual IR can be successfully applied for the integration of domain knowledge in biomedical IR.
The structure of this paper is as follows. First, we will describe our  X  X ross-lingual X  framework for biomedical IR. In section 3 we will describe a number of translation models in this framework. In section 4 we will describe how these translation models are used to improve word-based retrieval. In section 5 the experimental setup for evaluating the pro-posed framework will be described. In section 6 the results of the experiments will be reported and discussed. We will conclude in section 7.
Traditional cross-language IR (CLIR) is concerned with retrieving documents in a language different from the user X  X  query language. For example, a user can formulate his or her information need in Spanish and the retrieval system retrieves English documents. Some kind of translation has to take place to allow for such cross-lingual matching. The translation can be based on a machine translation system, bilingual lexicons, translation models learned from multilin-gual document collections to name but a few [17].
Also in the monolingual setting, the mismatch between terms used in a query and terms used in relevant documents can be viewed as a cross-lingual matching problem. Berger and Lafferty [3] formalized this observation by viewing the query formulation process as a noisy translation from the language used in relevant documents. In biomedical IR the vocabulary mismatch can be substantial given the number of synonyms and ambiguous terms. In this paper, we take Berger et al. X  X  (1999) work a step further by identifying a second concept-based representation language.
 The framework we propose is visualized in figure 1.
We identify two representation languages in this frame-
Figure 1: A cross-lingual view on biomedical IR work. Firstly, a textual language in which queries are for-mulated by a user in free text and in which documents have been written. Secondly, a conceptual language which is defined by the concepts or synset entries in a termino-logical resource. For instance, the concept [Mad cow dis-ease] 1 , which groups synonymous terms such as  X  X ad cow disease X  and  X  X SE X . In some cases, documents are already available in such a conceptual representation. The citations in MEDLINE, for instance, have been manually annotated with terms from the Medical Subject Headings (MeSH) the-saurus. Queries are typically not directly available in a concept-based representation; some form of translation has to take place to obtain such a representation. In many other cases, both the query and document concept-based represen-tations have to be obtained automatically. For instance, a biomedical named entity recognizer can be used to tag oc-currences of concepts in (document and query) text.
Table. 1 shows an example of a document in three repre-sentations. The first column shows the title and the abstract of the citation. The second column lists a concept-based rep-resentation which has been manually determined by human indexers. The last column shows a concept-based represen-tation which has been automatically obtained.

The integration of a concept-based representation in biomed-ical IR is then reduced to translating the query and/or doc-uments, and matching them in the same representation lan-guage. Such a cross-lingual perspective gives the opportu-nity of adopting a large set of established CLIR methods and techniques for this domain.

In theory, a conceptual representation is preferred over a word-based representation. Synonymous (including com-plex multi-word) terms are mapped to a single conceptual representation. Ambiguous terms are mapped onto the con-ceptual representation which corresponds to the context in which they appear. IR then simply reduces to matching the conceptual representations of documents to queries.
In practice, however, a concept-based representation has its limitations. Early work by [11] demonstrated that using only a concept-based representation for retrieval was harm-ful for retrieval effectiveness. One reason was that not all square bracket notation is used to refer to concepts information needs could be represented in terms of the con-cept vocabulary. Therefore we combine text or word-based retrieval with concept-based retrieval. This is clearly differ-ent from traditional CLIR where queries and documents are available only in different languages. In this CLIR-enhanced framework for biomedical IR, retrieval based on a text or word-based representation can be improved with a concept-based representation.

We identify two main translation resources for this type of biomedical CLIR. Firstly, the concept vocabulary itself. The concept vocabulary defines which phrases are used to express a concept, but does not indicate how frequently these terms are actually used or show the ambiguity of these terms. Analogous to traditional CLIR, the concept vocabulary can be used as a dictionary to translate between concepts and phrases and vice versa. Secondly, document corpora in a dual representation of both a text and concept-based repre-sentation can be used as a translation resource. In conven-tional CLIR, such parallel or comparable corpora are used to train translation models. Translation models between a source and target language are obtained from a large cor-pus of translated sentences or documents in both languages. A similar approach can be used to train translation models between a concept and a word-based representation.
Ourmainresearchquestionisasfollows: How can we adapt CLIR methods and techniques for more effective mono-lingual biomedical information retrieval? We are interested in particular in how to build translation models in this do-main and how these translation models can be used to im-prove monolingual (that is, text only) retrieval.
In this paper we will investigate a basic implementation of the framework. The text or word-based representation is re-stricted to a unigram word-based representation. Moreover, we limit the trained translation models to word-to-concept and concept-to-word translations.
 We will investigate two concept languages in our work: MeSH The Medical Subject Headings thesaurus 2 ,acon-
A major difference between the two is that for MeSH a manually curated document representation is already avail-automatically, using Peregrine [19]. Peregrine scans for UMLS entries in the text and performs a lightweight disambigua-tion strategy to resolve ambiguous terms. Another difference is the alignment of the concept representations with the text. it refers to. For MeSH, such an alignment is not available: MeSH terms are assigned at the citation level. Hence, the pus, whereas the representation in MeSH can be viewed as a comparable corpus.
In the previous section, we mentioned two resources to build translation models. Firstly, a collection of documents in both a text and a concept representation. And secondly, the terminological resource itself, which groups a number of phrases into a concept.

The first translation model we will investigate, based on pseudo-feedback translation, translates a text-based repre-sentation as a whole to a concept-based representation, based on the co-occurrence of words and concepts in a comparable corpus. The other five translation models we will investi-gate are used to translate representations in a term-by-term fashion. They employ different methods to estimate proba-bilities for P ( w | c ) (the probability of translating a concept c to the word w )and P ( c | w ) (the probability of translating the word w to a concept c ). On their own these term-by-term translation models are not expected to perform well, since they rely on only very little information for translation. However, they are expected to be useful when combined with the KNN translation model.

We will now describe six models based on these resources.
The first translation model we will discuss is based on pseudo-relevance feedback in a different representation. The representation to translate is used to search a collection in a dual representation, and the translation of the nearest neighboring documents is used as a translation. In conven-tional CLIR such an approach was proposed by [15]. In work by [20] and [24], a similar feedback mechanism was used for MeSH. We refer to this translation as KNN, since K nearest neighboring documents are used to obtain the translation.
The translation is modeled as follows. We assume to have a document collection D available in both a conceptual and textual representation. For each document D ,wecanesti-mate a textual language model and a conceptual language model, P ( w |  X  D )and P ( c |  X  D ) respectively.
We want to translate the text to translate (referred to as Q ) to a conceptual language model P ( c |  X  Q ). The ap-proximation of the language model is based on the joint probability of observing the concept c with the query Q in the previously introduced document collection D .Inwords, this approach determines which concepts are most likely to co-occur with the query. Formally: where P ( c, Q ) is the joint probability of observing a concept c with the query Q .

The joint probability of observing the concept with the query is approximated by independently sampling documents from the collection D , followed by independently sampling the concept and the query from each document.
 where P ( D ) is a prior probability of sampling the docu-ment D from the collection (assumed to be uniform) and P (
Q |  X  D ) is the probability of sampling the query from the document, the query likelihood (assuming term indepen-dence P ( Q |  X  D )= i =1 ..n P ( q i |  X  D )).

Obviously, requiring the complete collection D to be pro-cessed for classifying a piece of text, makes the model infea-sible in practice. The contribution of many documents to P ( c, Q ) is relatively small, however, since they are not likely to generate the query ( P ( Q |  X  D ) is small). Therefore, fol-lowing [15], we can safely reduce this document collection to n documents with the highest probability of generating the query P ( Q |  X  D ). In practice, these are the top n documents ranked by query likelihood.
The second translation model we will investigate is based on IBM Model 1, a statistical model of the translation pro-cess commonly used for traditional CLIR. [6] proposed five models for determining statistical translation models based on a bilingual collection of sentences. Central to these mod-els is the estimation of an alignment of the sentences in two languages. This alignment connects terms in the sentences in one language to terms in the translated sentence in the other language. An EM-algorithm is employed to iteratively improve the alignment and the parameters of the translation model, respectively.

IBM Model 1 is the simplest of the five models proposed by [6], and does not take word order into account. Models 2 to 5 are increasingly sophisticated, incorporating abso-lute and relative word reordering and a fertility model. For biomedical CLIR, the concept-based representation does not have a term order. Since we limited our experiments to term-by-term translation models, we will only use Model 1 for our translation models from text to concepts and vice versa.
An advantage of using Model 1 for training biomedical translation models is its theoretical soundness. The sub-sequent models proposed by [6] illustrate that Model 1 is highly suitable to be extended to more sophisticated mod-els. Disadvantages are that training the translation model is resource intensive and that with new concepts the whole training process has to be repeated.
The third translation model we will investigate is derived from the pointwise mutual information (PMI) between the concept-based and word-based event space [7]. PMI indi-cates the association of two events based on their joint distri-bution in comparison to their individual probabilities. PMI and mutual information have frequently been used as an as-sociation measure for IR [25] and in particular for filtering ambiguous translations in a CLIR setting [4, 9]. [3] used the mutual information statistic for constructing a distribu-tion function of words over documents to sample queries for documents. We will use such a distribution directly as a translation model. We argue that strongly associated con-cepts and words can be used as translations of each other.
In the literature, definitions of mutual information and pointwise mutual information are frequently confused. In this work, the following definition will be used for PMI. where p ( w,c ) is the probability of encountering the word and concept together in a document collection, and p ( w )and p ( c ) are the probabilities of encountering them separately in the collection. In the subsequent estimation of these prob-abilities f ( w, c ) denotes the number of documents in which the words w and c appear together; f ( w )and f ( c ) indicate the number of documents in which the word and concept appear respectively, and N is the size of the collection. [16] noted that PMI is not an ideal measure for measuring the association between terms, since it is biased towards low-frequency words. Similar to [3], we circumvent this bias towards low-frequency words by introducing an additional factor based on occurrence frequency of the pair:
Based on these scores, we create the translation model for aterminanadhocfashion: the n translation terms with the highest PMI scores are selected and normalized by dividing the sum of the top n scores.
The fourth translation model we will investigate is based on the conditional probabilities of encountering the target (translation) term after observing the source term in a large set of documents. Formally: where f ( w, c )isthenumberoftimesawordandaconcept term occur together in a document, and the denominator indicates the sum of co-occurrences of the concept with any word in the word vocabulary.

Using this formula, relatively high translation probabili-ties will be assigned to frequently occurring words or con-cepts. It is unde sirable to assign a high probability to the frequently appearing word  X  X tudy X  as a translation of the con-cept [Parkinson X  X  disease] simply because the word  X  X tudy X  frequently co-occurs with the concept. An Expectation Max-imization (EM) algorithm proposed by [12] is employed to Table 3: KNN Concept translations for  X  X erroportin-1 in humans X . prune low probability translations and remove these com-mon terms. In monolingual IR, this approach has been used for query expansion [18] and determining domain models [1].
We use the EM algorithm as follows. After initializing the translation probabilities with the maximum likelihood estimate defined in eq. 6, the EM algorithm will be applied: During the expectation step, the probability mass will be redistributed depending on the global probability of a term. During the maximization step, the probability distribution will be normalized, that is, normalizing the sum of the trans-lations to one.
 where P ( w ) is the probability of encountering the term w in a large collection and  X  determines how parsimonious the translation model will be: a value of 0 results in the maximum likelihood estimate; a value close to 1 results in a translation model in which probability mass has been redis-tributed to fewer translations.

We will refer to these translation models as parsimonious term translation models (PTT).
The last two translation models we will investigate use the thesaurus for determining translation probabilities between concepts and terms. In traditional CLIR, similar approaches have used to machine readable dictionaries to estimate trans-lation models [13].

In the naive translationmodelbasedonathesaurus(THES), the translation from words to concepts and vice versa, is es-timated by their relative co-occurrence frequencies in entries in the thesaurus. As a formula: where f( w,c )isthenumberoftimestheword w is used to describe c in the thesaurus. For instance, when the concept [Mice] has synonyms  X  X ice X ,  X  X ouse mouse X  and  X  X ouse X , the probability of P (mouse | [Mice]) is equal to 2 1+1+2
Similarly, the probability of translating a word to a con-cept can be approximated ( P ( c | w )= f ( w,c )
The model based on a statistical thesaurus (STATTHES), also takes into account how frequently a particular word is used to refer to a concept in a corpus of documents. This requires the text to be tagged with concepts found in a the-saurus. f( w,c ) is then defined as the frequency that the word w was tagged with the concept c . Model Translations Model Translations
In this section we will first describe the retrieval model used for integrating word and concept-based retrieval. After that, we will describe a number of extensions of this retrieval model which combine multiple translation models.
Our basic word and concept-based retrieval system is based on statistical language models. Queries and documents are represented by unigram word and unigram concept language models. As a baseline, only the word language models of queries and documents are matched. Matching is enhanced by matching the (translated) concept query and document language models. Documents are ranked according to the negated cross entropy between query and document word and concept language models: where  X  Q and  X  D are the concept-based query and docu-ment language models respectively;  X  Q and  X  D are the word-based query and document language models;  X  controls the relative importance of the concept-based representation (for the baseline  X  is set to 0). Other fusion methods were inves-tigated as well (such as CombMNZ, CombMax and Comb-Sum [8]), but this form of interpolation of document scores turned out to be most effective.  X  D and  X  D are smoothed document language models based on a maximum likelihood estimate. P ( c |  X  D ), the probabil-ity of generating the concept c from the language model is estimated as follows: where f ( c, D C ) is the concept term frequency; | D C | total number of concepts in the document representation;  X   X 
C is a background language model used for smoothing and  X  c is a parameter which controls the amount of smoothing. P ( w |  X  D ) is estimated in a similar fashion.

The word-based query language model is based on an (un-smoothed) maximum likelihood estimate from the original query text. The concept-based query language model is ob-tained through query translation. The KNN translation model translates the word-based query model as a whole, that is, it translates a probability distribution over words di-rectly to a probability distribution over concepts. The other five translation models are used to translate the word-based query word-by-word, similar to [3]. Formally:
P ( c |  X  Q )= where w are the words in the word-based query Q , P ( w |  X  is the probability of w in the word-based query model and P ( c | w ) is the translation probability as determined using the various translation models (PMI, M1, PTT, THES and STATTHES).
In traditional CLIR, combining different translation re-sources has shown to be an effective way to improve transla-tion quality [2, 5]. In the following sections we will propose a number of retrieval models and strategies which aim for a similar effect in biomedical CLIR.
Since the translation based on pseudo-feedback (KNN) is based on documents, it is expected to contain noisy concepts which are only indirectly related to the original query. In-deed, the example translation in table 3 contains concepts which were found in related documents, but could not be di-rectly linked to the text to translate (for example, [Animals], [Mice] and [Zebrafish]).

We propose the use of the term-by-term translation mod-els to prune concepts from the translated concept-based query obtained through feedback (KNN). The concept-based rep-resentation obtained by feedback translation is filtered as follows: where P KNN ( c |  X  Q ) is the conceptual query language model estimated through feedback; P ( t | c )isaconcepttoterm translation model; and  X  is a query dependent normaliza-tion constant, which normalizes c P ( c |  X  Q )to1.
Note that this type of pruning based on term-by-term translation models is not very restrictive: concepts are only pruned from the translation when this concept cannot be translated to any of the query words; the translation proba-bility in the concept-to-word translation model is not taken into account.
A well-known drawback of using pseudo-relevance feed-back is possible query drift: an expanded query can overem-phasize or neglect particular aspects from the original query, or skew towards aspects not mentioned in the original query. In the case of a pseudo-feedback translation to a conceptual representation, the neglect of a particular query aspect can be substantiated by the fact that aspects cannot be repre-sented accurately by the concept vocabulary. As a result, combining a word and concept-based representation based on feedback may understate aspects present in the word-based representation. The goal of the reweighting procedure we will now describe is to prevent that a word-based query combined with a concept-based query (obtained through feedback) neglects aspects found in the word-based query. To achieve this, the word-based query model is reweighted: depending on how well the concept-based representation cov-ers the words in the query, the word weights are updated: well-covered words receive a lower weight, whereas poorly covered words receive an increased weight.

The reweighting process is as follows: 1) The feedback translation model (KNN) is used to translate a word-based query model P ( w |  X  Q ) to a concept-based query model P 2) The coverage of the words in the original word-based query model P cov ( w |  X  Q ) is determined by translating the concept-based query model using the term-by-term transla-tion models described earlier. 3) An updated word-based query model P ( w |  X  Q ) is based on P cov ( w |  X  Q ). The updated word-based query model is combined with the concept-based query model for retrieving documents.

How the coverage and updated word-based query model are determined will now be described.
 Determining the coverage of the word-based query
The coverage of a word-based query by a concept-based representation is defined as a probability distribution over the words in the original query. If the word-based query is evenly covered by a concept-based representation this prob-ability distribution is uniform: all query words are covered by concepts in the concept-based representation.

We use a term-by-term translation model to determine this coverage as follows.
 where P ( c |  X  Q ) is the concept language model obtained through pseudo-feedback translation of the original word-based query and P ( w | c ) is the term-by-term translation probability of translating a concept c toaword w . In the (unlikely) case that none of the concepts can be translated to a query word P cov ( w |  X  Q ) is equal to 0 for all w 4 .
This can be viewed as a coverage of a null -query word with probability 1.
 Updating the word-based query language model
The coverage of the original word-based query language model is used to determine an updated word-based query language model.

We assume that all the aspects mentioned in the origi-nal text-based query are equally important: when searching with a combined word and concept-based query representa-tion this balance should be maintained. When the concept-based representation does not cover all query aspects this balance is disturbed: some aspects are overemphasized lead-ing to query drift. This query drift of a combined word and concept-based query representation can be prevented by de-creasing the weight of words which are well covered by the concept-based representation.

We assume that the aspects of a query can be represented by the original word-based query language model (based on a maximum likelihood estimate). To retain the origi-nal query balance, the updated word-based query language model combined with the coverage by the concept-based query language model should approximate the original query word distribution. Formally: where P ( w |  X  Q ) is the original query word language model, which should be covered by the translation of a conceptual query language model P cov ( w |  X  Q ) and by an updated query language model P ( w |  X  Q ). The query dependent parameter  X 
Q indicates the relative importance of the updated word-based query language model in comparison to the translated concept-based query language model.

To approximate eq. 17, initial estimates of the updated word-based query language model are calculated as follows: e The updated query language model is determined by nor-malizing these initial estimates: Note that the second line of the equation is obtained by rewriting eq. 17. The value  X  Q has to be restricted to prevent P ( w |  X  Q ) becoming less than zero, formally:
A  X  -value of 0 indicates that the updated word-based query language model is exactly the same as the original word-based query model; the largest possible value of  X  mod-ifies P ( w |  X  Q ) as much as possible to retain the original query term balance.

Table 4 illustrates this reweighting in practice for a query consisting of three words ( w 1 to w 3 ). Their original impor-tance weights, based on the original query formulation is found in the second column. The third column indicates to what extent the words are covered by concepts found in the query. w 1 for example, has an original probability of 0.5, but is only covered by the translation with a probability of 0.1. The updated probability should therefore be higher than 0.5. The last three columns of the table show the re-estimated weights for three different values of  X  Q . The highest possible value of  X  Q for this query is 0.25, resulting in a reweighted probability for the word w 3 of 0.

To control the value of  X  Q at a global level (that is across different queries), we introduce the parameter  X  (between 0 and 1) which linearly scales  X  Q between its minimum and
The last approach we investigate to combine translation models combines the original textual query with a concep-tual query based on pseudo feedback into a structure. The approach is motivated by the idea that the translated con-cepts should be linked to the query words they represent. We hypothesize that such an approach balances the original textual query with its translation, and prevents query drift.
To allow for such an integration we need to model con-cepts and words in the same event space. We achieve this by simply merging the two representations, that is mixing the identifiers of the concepts with the tokens extracted from the text. From a principled modeling perspective, mixing the representations is not very attractive: concepts and words are different units of information and should therefore be kept separated. On the other hand, the mixed representa-tion is easy to understand and straightforward to implement. The parameters of the mixed document language model P ( t |  X  D ) are again based on a maximum likelihood estima-tion, smoothed with a background language model.
 The initial parameters of the mixed query language model P ( t |  X  D ) are based on a linear interpolation of the word-based query model and the concept-based query model: where  X  indicates the relative importance of the text-based representation with respect to the concept-based represen-tation.

We will use a translation model P ( w | c )tocreatean align-ment between the concepts and the words in this mixed query language model. Based on the translation model, each concept is assigned to (at most) one word. Assuming that the l terms in the word-based query are w 1 to w l ,andthat the m concepts in the concept-based query are c 1 to c m , we can define an alignment function between c i and w j as follows.
In words: the concept c i is aligned to the word w j with the highest translation probability. We now define  X  ( w of a word w j as the set containing the word itself and the concepts which have been assigned to it.
Similar to [13, p. 133], we use this set to define an equiv-alence class of the word and the concepts mapped to it:
P ( class ( w j ) |  X  D )=
The query language model of the equivalence class is de-fined as follows.

In this section we will describe the experimental setup for comparing the different translation and retrieval models.
The TREC Genomics document collections and topics sets between 2004 and 2007 were used for the evaluation [10]. The 2004 and 2005 topic sets consist of 50 queries and were used to search a document collection of 4,591,008 MEDLINE citations (referred to as the 2004 document collection). The 2006 and 2007 topic sets consist of 28 and 36 queries and were used to search a document collection of 162,259 full-text journal articles from Highwire Press (the 2006 docu-ment collection). The TREC Genomics task of 2006 and 2007 were passage retrieval tasks. In this evaluation, how-ever, we only investigated ad hoc document retrieval: docu-ments containing relevant passages were assumed to be rel-evant to the query.

Mean average precision (MAP) and rank precision (preci-sion at 10) were used as evaluation measures. Due to space limitations, we will only mention MAP in the results section of this paper.

The translation models which required training data (all except for the naive thesaurus translation model), were trained with documents from the TREC Genomics 2004 document collection. Word-based representations of these documents were obtained using a tokenizer adapted to biomedical text [23]. The MeSH-based representations of the documents were based on the major MeSH headings assigned by NLM indexers; representation was obtained using the Peregrine[19]. The tations was used both as a parallel and a comparable cor-pus. For training the STATTHES translation models, the explicit alignment between words and concepts (obtained from Peregrine) were used. For the other translation mod-els, the alignment was discarded and the representation was treated as a comparable corpus. The document collection in word and MeSH-based representations was only used as a comparable corpus. Translation models were built for trans-vice versa.

The translation models for PMI and PTT were based on co-occurrence counts of concepts and words in the complete 2004 document collection. Because of scalability issues, the IBM model 1 translation models were built on a subset of the collection. 1,200,000 randomly selected documents from the collection were used to build the translation models. A slightly modified version of the GIZA++ 5 machine trans-lation toolkit was used to train the models based on IBM model 1. The default setting of 5 iterations of the EM algo-rithm was used.

All translation models went through the following post-processing to remove noise: 1) Translations with a probabil-ity smaller than 0.001 were removed; 2) Words or concepts which occurred in fewer than 3 documents in the collection were pruned; 3) Single character words and numbers were removed. The remaining translations were normalized for each term (assuring t P ( t | t )=1).

The Lemur Toolkit 6 was used for indexing and retrieval.
This results section is structured as follows. First, we will investigate the effectiveness of the individual transla-tion models. In sections 6.2 to 6.4 we will look into the effectiveness of combining the pseudo-feedback translation model with the term-by-term translation models for prun-ing, reweighting and structuring respectively.

As a baseline, retrieval using only the word-based repre-sentation was used. Each column lists the results of the TREC Genomics query set of that year (2004 to 2007). Re-sults using a statistical thesaurus (STATTHES) are only re-ulary such a translation model was available.
Table 5 lists the retrieval effectiveness in terms of mean average precision when using the combined word and trans-lated concept-based language models for retrieval.
A first observation is that a concept-based representation translated from the textual query can significantly improve word-based retrieval. Using an additional MeSH-based rep-resentation leads to (significant) improvements up to 9.5% observed. The precision at 10 (not displayed in the table) shows similar improvements.

As expected, KNN performs best when considering all 4 topic sets. For 6 out of 8 cases, retrieval using a word-based representation combined with the concept translation obtained with KNN results in the highest MAP. The other translation models are all extremely limited in the amount of context they take into account for translation: a concept-based query is obtained by individually translating each word in the query to concepts. Considering the ambiguity of individual words in this domain, it is in fact surprising that this naive term-by-term translation results in improvements in retrieval effectiveness.

Using translations obtained from the naive thesaurus trans-lation model does show slight improvements in mean aver-age precision, but none of the improvements are statistically significant. A possible explanation for this lack of signif-icant improvement is noise in the terminological resource: the resource sometimes mentions terms for concepts which are rarely used. The correct, or most common, translation of a concept or term may therefore receive a low translation probability.

The translation models trained on the comparable cor-pus (M1, PTT and PMI), performed slightly better than the translation model based solely on thesaurus information (THES). No significant differences were observed, however, between M1, PTT and PMI.
The effect of pruning obviously depends on how many concepts are in fact pruned. The pruning method described in section 4.2.1 removed many concepts: between 49.9% and 91.5% of the concepts in the KNN translation were re-moved. The translation models based on PMI and IBM model 1, resulted in the most restrictive pruning (between 49.9% and 79.1%); the models based on PTT and the the-sauri (THES and STATTHES) resulted in stronger pruning (between 81.9% and 91.5%).

This indicates that the KNN and term-by-term transla-tions are quite different: for many concepts found in the KNN translation no translation to a word in the original query is indicated by the term-by-term translation models.
Table 6 lists the results of combining the pruned concept language model with a word-based language model for re-trieval.

For MeSH, the pruned concept language model can still be used to increase the performance of word-based retrieval. However, for the query sets using the 2004 document col-lection (consisting of citations with relatively little text), the original concept translation performs better than the pruned translation. Apparently, pruning resulted in the re-moval of MeSH concepts which were beneficial for retrieval. For searching the full-text article collection (2006 and 2007 topic sets), pruning turned out to be more useful: pruning the KNN translation with the naive thesaurus translation model resulted in the highest retrieval effectiveness. tations with the text representations turned out to be almost as effective as or even more effective than the unpruned rep-resentation. Irrespective of the type of translation model used for pruning, significant improvements (up to 10.5% in MAP) over the text-based baseline were observed. For 50.5% and 91.5% of the terms in the concept-based query could be pruned with the same or improved retrieval effec-tiveness.
Table 7 shows the result of reweighting the word-based query model, based on the coverage of the KNN concept language model, determined using the term-by-term trans-lation models. The table shows the results for  X  set to 0.5. On average 0.19 and 0.17 of the probability mass of word-based query language model was redistributed for MeSH and
Reweighting based on coverage by MeSH concepts in many cases led to detrimental retrieval effectiveness. For the 2004, 2006 and 2007 not reweighting resulted in a higher effective-ness. For the 2006 and 2007 topic sets, effectiveness even significantly dropped below the word-based baseline. This effect can be explained by the exhaustiveness of the MeSH-based document representation. On average, a document in the 2006 Genomics collection is represented by only 15 MeSH concepts. It is likely that many more MeSH terms are in fact relevant to this document but have not been assigned. The word-based representation of the document is more exhaus-tive than the concept-based representation. Despite the fact that according to a translation model a concept  X  X overs X  a query word, it is likely that this covering concept reduces the recall in comparison to the query word.
 out to be more effective. Improvements (up to 5.3%) could be observed for the 2005, 2006 and 2007 topic sets. Many of the results are insignificant however. For the 2004 topic set, no improvements could be observed, even with differ-ent values of  X  . The effect of reweighting turned out to be independent of the translation model used.
Considering the original number of concepts in a query (50), the structuring does not result in very large changes to the original query. On average between 1.1 to 3.2 equiva-lence classes were created, with between 1.8 and 6.2 concepts grouped into a single equivalence class.

Table 8 lists the impact of structuring the query using the term-by-term translation models. Structuring the represen-tations turned out to give strongly varying results, from sig-nificant deteriorations (up to 22.7% in MAP) to significant improvements (up to 6.4% in MAP). The decline in perfor-mance can to some extent be attributed to a difference in granularity of the word terms which have been grouped with more specific or over general concept terms. For instance, tion] is treated as a synonym of the word  X  X icotin X . In other cases, clearly incorrect equivalence classes were formed. For with the word  X  X reak X  in the context of  X  X NA breaks X . In this case, the translation through feedback introduced these errors; by mapping these errors to original query words and treating them as equivalent, the impact of the erroneous translation was further emphasized. Improvements were ob-served when the words and concepts in the same equivalence class were clearly linked and were defined at the same gran-ularity level.
In this paper we proposed a cross-lingual framework for biomedical IR. We distinguish between a concept and word-based representation language. We hypothesized that the integration of a concept-based representation in biomedi-cal IR could benefit from methods and techniques used in established CLIR. In analogy to what is common in tradi-tional CLIR, we identified three types of translation models for biomedical CLIR: 1) a comparable corpus of documents in both a text and concept-based representation; 2) term-by-term translation models trained on a comparable corpus; and 3) a thesaurus. We used these sources in different cross-lingual retrieval models. Despite the limited context taken into account, word-to-concept translation could still improve word-based retrieval. Translation based on pseudo-feedback using a comparable corpus in both a word and concept-based representation proved to perform best. In the other three retrieval models we evaluated whether translation between text and concepts could be improved by combining trans-lation models. Despite the simplicity of the term-by-term translation models, the results showed that a combination of translation models could improve retrieval effectiveness when combined with a word-based representation.

The results also demonstrated the added value of the con-cept representations MeSH and an extended version of UMLS hancing device, especially useful for citation retrieval. For a MeSH-based representation to be effective, however, many (also indirectly related) terms were required to represent the to precisely represent information needs and can be used as a precision enhancing device.

We conclude that the proposed cross-lingual framework offers a transparent view on the integration of a concept-based representation for monolingual biomedical IR. Based on the promising results with relatively simple translation and retrieval models, we have high expectations for more sophisticated translation and retrieval models.
We thank Martijn Schuemie (Erasmus MC, Rotterdam) for annotating the document collections with Peregrine. This work was part of the BioRange programme of the Nether-lands Bioinformatics Centre (NBIC), which is supported by a BSIK grant through the Netherlands Genomics Initia-tive (NGI). This research was supported by the Netherlands Organization for Scientific Research (NWO, under project number 612-066-513).

