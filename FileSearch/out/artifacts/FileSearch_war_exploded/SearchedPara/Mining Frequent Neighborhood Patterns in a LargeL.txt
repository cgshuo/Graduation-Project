 Over the years, frequent subgraphs have been an impor-tant kind of targeted pattern in pattern mining research, where most approaches deal with databases holding a num-ber of graph transactions , e.g., the chemical structures of compounds. These methods rely heavily on the downward-closure property (DCP) of the support measure to ensure an efficient pruning of the candidate patterns. When switching to the emerging scenario of single-graph databases such as Google X  X  Knowledge Graph and Facebook X  X  social graph, the traditional support measure turns out to be trivial (either 0 or 1). However, to the best of our knowledge, all attempts to redefine a single-graph support have resulted in measures that either lose DCP, or are no longer semantically intuitive.
This paper targets pattern mining in the single-graph set-ting.

We propose mining a new class of patterns called fre-quent neighborhood patterns, which is free from the  X  X CP-intuitiveness X  dilemma of mining frequent subgraphs in a single graph. A neighborhood is a specific topological pat-tern in which a vertex is embedded, and the pattern is frequent if it is shared by a large portion (above a given threshold) of vertices. We show that the new patterns not only maintain DCP, but also have equally significant inter-pretations as subgraph patterns. Experiments on real-life datasets support the feasibility of our algorithms on rela-tively large graphs, as well as the capability of mining inter-esting knowledge that is not discovered by prior methods. H.2.8 [ Database Management ]: Database Applications X  Data mining Pattern Mining, Frequent Neighborhood Mining  X 
T he work was done when the first author was visiting Mi-crosoft Research Asia.
 Author writes (a) 47.0% of authors have a t least two papers.
 Figure 1: Neighborhood patterns with support ra-tios, mined from a public citation network dataset
Since Agrawal et al. introduced the concept of Associa-tion Rule Mining[1] in 1993, frequent itemset mining, which is the core subtask of association rule mining, has resulted in fruitful follow-up work. Among the horizontal explorations that target mining substructures more expressive than a subset, including subsequences, subtrees, and subgraphs[11], the Frequent Subgraph Mining (we refer to it as FSM later for short) problem turns out to be the most expressive.
In the typical graph-transaction setting , the database con-sists of a large number of transactions , e.g., chemical struc-tures of small molecules. The measure of frequency, a.k.a. support, is then naturally defined as how many transactions a given pattern is observed to be a subgraph of. This def-inition provides clear semantics in applications. For exam-ple, an atom group commonly found among a set of organic compounds may indicate that they potentially share some properties. Moreover, it also satisfies the downward-closure property (DCP), which requires that the support of a pat-tern must not exceed that of its sub-patterns. This property is essential to all frequent pattern mining algorithms, as it enables safely pruning a branch of infrequent patterns in the search space for efficiency.

Nevertheless, when switching to a single-graph setting , i.e., the database is itself a large graph and the knowledge inside the single graph is of major concern, the definition of support by counting transactions easily fails because the support of any pattern is simply 0 or 1. In other words, this defini-tion cannot quantify our intuition that a subgraph occurs  X  X requently X  in a large graph.

Indeed, it is straightforward to define the support as the number of  X  X istinct X  embeddings of the pattern in the graph. However DCP simply does not hold for this case. Consider Figure 1(a), which describes the event  X  X uthor X writes pa-Figure 2: A toy database.  X  X rites X  X nd  X  X ites X  X abels a re omitted. per Y and Z . X  When it is matched to a toy database con-sisting of exactly one author writing n p apers, the number of different embeddings for the three vertices is n ( n  X  1). For the sub-pattern  X  X uthor X writes one paper Y , X  the count is n &lt; n ( n  X  1). Even if we consider the automorphism of the pattern, and regard two embeddings as identical if one differs from the other by only swapping the papers that Y and Z are matched to, it is still the case that n &lt; n 2
Intuitively, complicated patterns have larger support counts because they tend to reuse elements in the database. In-spired by this observation, Vanetik et al.[29] and Kuramochi et al.[18] redefined the support in the single-graph setting to be the maximum number of edge-disjoint embeddings, which satisfies DCP. According to them, the support of the  X  X n-author-writes-two-papers X  pattern on the toy database should be  X  n/ 2  X  ( &lt; n ), since we can find at most that many embeddings without reusing any writes  X  X  X  X  X  X  X  edge. In addition to the increase in problem complexity, we argue that this definition introduces non-determinism to the support com-putation, which disobeys the human sense that counting is a  X  X ne-by-one X  procedure.

Since it cannot be avoided that traditional embeddings reuse elements, it seems to be a fact that DCP and intu-itiveness can never both be achieved in any subgraph sup-port that counts embeddings of the entire pattern. How-ever, if we assign the count operator to a fixed vertex in a pattern, and treat two embeddings as identical if they match the fixed vertex to the same vertex in the database, we obtain a support measure that regains DCP. Consider Figure 1(a) again, where the author vertex is painted solid and should be counted. On the toy database in Figure 2, ( X, Y, Z ), they only contribute one to the support because they share the same author a 1 . Moreover, a 2 and a 3 may also serve to compose legal embeddings, so the overall sup-port is 3. Similarly, Figure 1(b) is a super-pattern of Figure 1(a). Only by matching the author vertex to a 1 or a 2 can we appropriately arrange the two paper vertices given that one should cite the other. So the support is 2 ( &lt; 3). Best of all, our new support ensures that the new patterns induced have clear interpretations. E.g., the two patterns in Figure 1 actually describe  X  X uthors who have at least two papers X  and  X  X uthors who once cited their own paper, X  respectively. Since this new class of patterns characterizes vertices that are embedded in a specific local topology, we denote them as neighborhood patterns , and the corresponding mining prob-lem as F requent N eighborhood M ining (denoted as FNM for short). By neighborhood we refer to not only other ver-tices directly linked to the counted vertex as defined in the graph theory terminology, but also to the vertices and edges indirectly connected, along with their labels.

Previously, [10, 15] studied similar problems by defining the number of such  X  X artial matches X  as the support of a graph structure. However, only tree-like patterns were ad-dressed as their mining targets. Instead, we try to remove the constraint that cycles are not allowed, and investigate the new class of pattern in the same generalized way that the FSM problem was studied. Our contribution lies in that we established rich and deep connections between the two problems in terms of basic definitions, problem complexity, solutions, and possible optimizations. By testing on a real-life dataset we confirm that trading the problem complexity for better expressivity is worthwhile, as patterns with cycles can lead to more informative and interesting discoveries in the data being investigated. E.g., taking Figure 1(b), 1(a), and the support ratios in their captions into consideration, we can conclude that among all authors who are  X  X ble X  to cite their own paper (having at least two papers), one out of five will do so.

The rest of this paper is organized as follows: In Sec-tion 2 we formalize the FNM problem, where the Pivoted Subgraph Isomorphism problem is identified as the core of FNM, similar to what subgraph isomorphism is to the FSM problem. Section 3 discusses our basic solution and further optimization for FNM. We prove that the building blocks of FNM are not as trivial as those of FSM, while some of the ways to optimize the latter can still be adapted for ours. In Section 4 we conduct experiments on real datasets to verify the performance of our solution and the utility of the mined neighborhood patterns. After introducing related and future research we finally conclude the paper.
In this section, we first introduce basic notations to de-scribe a labeled graph and a neighborhood pattern. With the notations we then formulate the decision problem of checking whether a neighborhood pattern matches a given vertex in a large graph as the Pivoted Subgraph Isomor-phism problem. We prove that, as the name indicates, this problem is np -complete, making our problem as difficult as FSM. Finally, after defining the support of a neighborhood pattern as the number of vertices in the database it can be matched to, we briefly justify its downward closure property. Definition 1. A (directed) labeled graph is a 5-tuple G = h V, L V , E,  X  V ,  X  E i , where
Note that unlike [14, 31, 17], we allow an arbitrary num-ber of labels on a single vertex. This is a reasonable general-ized assumption for possible applications. For example, in a knowledge base consisting of objects and their relationships, an object may be a father, a politician, and a vegetarian at the same time. It X  X  also possible that a vertex has no label, i.e., we know nothing about the object, except its existence. On the other hand, parallel edges carrying distinct label names may link a pair of vertices to model multiple rela-t ionships simultaneously existing between two objects. We do not allow edges with no label because we do not process an  X  X rbitrary X  or  X  X niversal X  relationship. Without losing any generality, we do not allow loops, i.e., edges starting and ending with the same vertex. Instead, we can use a vertex label with a specially designed name to indicate the existence of a loop on a vertex. We use  X  X lements X  as the joint name of vertex labels and labeled edges, and define ( | L V | + | E | ), i.e., the number of elements, as the size of a labeled graph.
Definition 2. A pivoted graph is a tuple G = h G, v p i , where
By introducing the concept of  X  X ivot, X  we aim to charac-terize the semantics of fixing a vertex in a subgraph to form a neighborhood pattern (e.g., Figure 1), or selecting a vertex in the database to match a pattern to. Previous to us, this notation has at least been used by Vacic et. al [28]. However they were using it to address a different problem.
Definition 3. A pivoted graph G 1 is pivoted subgraph isomorphic to G 2 , denoted as G 1  X  p G 2 , if and only if there exists an injective f : V ( G 1 )  X  V ( G 2 ) such that
The first two descriptions indicate that the isomorphic function preserves both vertex labels and edge labels. In addition, the special isomorphism between pivoted graphs requires that the isomorphic function maps the pivot of G to that of G 2 . As a subtask of FNM, the problem of deciding whether a pivoted graph is pivoted subgraph isomorphic to another is np -complete.

Theorem 1. The problem of testing pivoted subgraph iso-morphism between two arbitrary pivoted graphs is np -complete.
We prove this in the appendix by reducing it to the clas-sical subgraph isomorphism problem.
 Property 1. The relation  X  p is transitive.
 Proof. (Sketch) Given P 1 , P 2 , and P 3 , where P 1  X  p and P 2  X  p P 3 . Let f 12 : V ( G 1 )  X  V ( G 2 ) be the isomorphic function between P 1 and P 2 , and f 23 : V ( G 2 )  X  V ( G that for P 2 and P 3 . It is clear that there exists f 13 f 23 ( f 12 ( v )), which is a legal isomorphic function between P and P 3 (it is injective and maps pivot to pivot). Therefore, P
D efinition 4. Given a large labeled graph G , a neighbor-hood pattern P matches v  X  V ( G ), if P  X  p h G, v i . Denot-ing the set of all vertices in G that P matches as M G ( P ) = { v  X  V ( G ) |P  X  p h G, v i} , we define the support of P in G as the size of M G ( P ), and call P a frequent neighborhood pattern of G , if its support is above a given threshold  X  .
With the support measure defined, the frequent neighbor-hood mining problem is simply finding all frequent neigh-borhood patterns in a large graph, with respect to a given threshold. To control the problem complexity, we further require the mined patterns be connected, i.e., paths exist between the pivot and every other vertex. In later discus-sions, sometimes we consider the operation of removing a labeled edge from a pattern. If the removal leads to an redundant vertex, i.e., a vertex without any vertex label or edge associated to it, we further remove the vertex to make the resulting pattern legal, without affecting its size. If we adopt  X  p to describe the sub-pattern/super-pattern relationship between neighborhood patterns, the fact that a pattern cannot be more frequent than any of its sub-patterns is directly derived via Property 1.

Theorem 2. The support measure defined in Definition 4 satisfies the downward closure property.

Proof. (Sketch) Given G , P 1 , and P 2 , where P 1  X  p P For any v  X  G , if P 2  X  p h G, v i , according to Property 1 we have P 1  X  p h G, v i . Therefore, M G ( P 1 )  X  M G ( P 2 holds that | M G ( P 1 ) | X | M G ( P 2 ) | .
I n this section, we describe the algorithm for mining fre-quent neighborhood patterns, which follows the apriori breadth-first search paradigm. We reveal the major technical dif-ference between mining subgraph and neighborhood pat-terns. That is, the latter task has more complicated  X  X uild-ing blocks. X  We prove that the building blocks in our task are no longer all frequent size-1 patterns. Instead, they consist of all frequent paths , and require special treatments. Addi-tionally, similarities between the solutions and optimizations of FNM and FSM are also discussed.
Typically, the traditional FSM algorithm generates sub-graph patterns in order of size. First, all frequent subgraphs of size 1 are pre-computed as  X  X uilding blocks. X  Then, can-didates of size K are obtained by joining pattern pairs of size ( K  X  1) that differ by only one vertex or edge, after which false positives are filtered by a verification against the database. We indicate that the join ensures a complete re-sult because every candidate of size K  X  2 is decomposable , that is, we can always find two distinguished elements, and a fter removing either one we obtain a connected, thus legal, sub-pattern of size ( K  X  1). They may be isomorphic to each other, but their join takes the candidate into consideration.
For our neighborhood mining problem, however, this is not the case. Consider the path-like neighborhood patterns in Figure 3. Obviously, to find a connected sub-pattern of size ( K  X  1) for Figure 3(a), the only choice is to remove the edge and vertex at the end of the path. Meanwhile, in the case of Figure 3(b), only the vertex label to the right can be removed. Otherwise, the resulting patterns will be illegally unconnected. Since they are not decomposable , it X  X  impossible to derive them by joining two smaller patterns. Luckily, the following theorem clarifies that these special patterns are only limited to what is described in Figure 3 and Definition 5, which enables us to treat them as building blocks and pre-process them in advance.

Definition 5. A neighborhood pattern is a path pattern if the following statements holds: F igure 4: Decomposable cases in the proof of Theo-rem 3. Labels with no direct influence on the proof are omitted.
Theorem 3. A neighborhood pattern is not decomposable, iff. it is a path pattern.

Proof. The sufficiency of the theorem is apparent and has been briefly discussed above. Therefore we only concen-trate on proving the necessity.

If a neighborhood pattern P is not decomposable, it must have at most one vertex label. Otherwise, we can arbitrarily choose two of them as l 1 and l 2 , and decompose the pattern as P\{ l 1 } and P\{ l 2 } , as illustrated in Figure 4(a). More-over, it must not contain cycles. Otherwise, we arbitrarily choose two edges on the cycle as e 1 and e 2 , and decompose it as P \{ e 1 } and P \{ e 2 } (Figure 4(b)). Note that this does not harm the connectivity of the patterns since edges on a cycle are not cutting edges.

So far, the shape of P has been limited to being a tree with at most one label. We transform it to a rooted tree, where the root is the pivot of the pattern. This tree must have only one leaf. If there are two leaves, we can again remove them with associated edges respectively (in the case where the leaf possesses the only vertex label, we only remove the label instead) to decompose the pattern (Figure 4(c)). Algorithm 1 B uilding block construction Input: T he single-graph database G , minimum support  X  Output: All frequent path patterns 1: queue  X  X   X  } 2: repeat 3: path  X  queue.Dequeue () 4: count [] .Clear () 5: for all v  X  V ( G ) do 6: for all nextStep  X  v.T raverse ( path ) do 7: count [ nextStep ]  X  count [ nextStep ] + 1 8: end for 9: end for 10: for all nextStep  X  count.Keys () do 11: if count [ nextStep ]  X   X  then 12: newP ath  X  path.Append ( nextStep ) 13: R  X  R  X  X  newP ath } 14: if nextStep.IsEdgeStep () then 15: queue.Enqueue ( newP ath ) 16: end if 17: end if 18: end for 19: until queue.Empty () = true 20: return R
Now the tree with only one leaf is actually a path. How-e ver, we still have to prove that if the tree contains a vertex label, it must be on the only leaf: if any vertex other than the leaf carries the label, removing the label and removing the leaf with its associated edge respectively will cause the pattern to decompose (Figure 4(d)).
A s a special case of the general neighborhood patterns, path patterns can still be organized into a level-wise struc-ture, or more exactly, a hierarchical one, which preserves the downward closure property. The parent of each path pattern is uniquely found, by removing the vertex label or the ver-tex on the other end of the path than the pivot. Thus, the level-wise search algorithm on such a structure deserves an  X  X xtending X  approach to generate larger patterns from small ones, rather than the  X  X oining X  one used for non-building-blocks.

In Algorithm 1, we describe the basic algorithm for find-ing frequent paths. First, a queue used for the bread-first search is initialized with an empty path  X  . When extending a path on the front of the queue, we traverse according to the pattern, each time with one vertex in G as the starting point. Note that for each starting point, we should not visit a vertex more than once. Each traversal returns all possible moves when we arrive at the ending point(s) and try to take one more step. E.g., we traverse along a X   X  writes  X  X  X  X  X  X  X  X  X  path starting from vertex  X  X iawei Han, X  and stop at the ver-tex of paper [18] (it cites [31] of Jiawei Han), then all possible moves on [18] may be to follow a  X  X ites X  edge to another un-visited paper it cites (such as paper [14]) to produce Figure 3(a), or to terminate the path with a vertex label  X  X aper X  to end up with Figure 3(b). Each time a new move for the current starting point is discovered, the counter for this move is increased by 1. When all traversals are over, those moves with a count of more than  X  are used to extend the path. After saving all extended paths to the result set, non-terminated paths, i.e., new paths obtained by appending Algorithm 2 F requent neighborhood mining Input: T he single-graph database G , minimum support  X  Output: All frequent neighborhood patterns 1: fP aths  X  F requentP aths ( G ) 2: f 1  X  fP aths.SelectSize (1) 3: k  X  2 4: while f k  X  1 .Empty () = false do 5: for all 1  X  i  X  j  X  f k  X  1 .Count () do 6: c k  X  c k  X  Join ( f k  X  1 [ i ] , f k  X  1 [ j ]) 7: end for 8: for all P  X  c k do 9: if G.CountSupport ( P )  X   X  then 10: f k  X  f k  X  X P} 11: end if 12: end for 13: f k  X  f k  X  fP aths.SelectSize ( k ) 14: k  X  k + 1 15: end while an edge rather than a vertex label such as Figure 3(a), are a dded to the queue for further expansion. The algorithm terminates when all extendable paths in the queue are con-sumed.
As stated above, what distinguishes our problem from tra-ditional ones solved by a  X  X oin-verify-join-. . .  X  scheme is the fact that large path patterns cannot be derived by joining smaller patterns, no matter whether these smaller ones are paths, trees, or else. Therefore, the working flow of Algo-rithm 2 differs from other apriori-based subgraph mining algorithms only by Line 13. This line adds path patterns of the current size to F k , the frequent non-building-blocks of the same size, to ensure that larger patterns relying on them are not lost due to their absence.

Additionally, our join operation at Line 6 is also worth an detailed explanation. Roughly speaking, we determine whether two patterns should be joined via deleting one ele-ment from the first, and check whether the remaining struc-ture is pivoted subgraph isomorphic to the second. Notice that there may be multiple isomorphic mappings so the num-ber of results produced by a single join may be more than one. For each mapping, the deleted element is mapped to the correct position in the second pattern, and inserted to produce a joining result. If the removed element is a vertex label, the join is relatively easy. But if it is an edge, the operation is a bit tricky.

On the one hand, the remaining structure is not necessar-ily connected after the deletion of an edge. Consider Fig-ure 5(a), where we are going to join the patterns  X  X uthors having a cited paper X  and  X  X uthors having a paper citing another. X  For the sake of the example and w.l.o.g., we as-sume that this join is in a branch of the search space where vertex labels are not introduced yet, while readers can still infer by the context that the pivots are author vertices, and the non-pivot vertices represent papers. After deleting the  X  X  X  X  X  X  X  edge marked with a dotted line and italic label in the first pattern we obtain an unconnected structure. The remaining structure is pivoted subgraph isomorphic to the second pattern, where the mapping is illustrated by dotted lines. Since the paper vertex in the first pattern that the deleted edge points to is mapped to the second paper vertex in the second pattern, we restore the mapped writes  X  X  X  X  X  X  X  edge between the author vertex and the second paper vertex to generate the result on the right. Obviously, this pattern is the skeleton of Figure 1(b).

On the other hand, new vertices may be introduced when handling dangling edges. In Figure 5(b) we again try join-ing the same patterns as in Figure 5(a), but this time we delete the cites  X  X  X  X  X  X  edge. As is required in Section 2.3, this deletion makes the second paper vertex redundant, so the vertex is also removed. When the pivoted subgraph isomor-phism from the remaining structure to the second pattern is established, the vertex that the deleted edge was associ-ated with is mapped to the first paper vertex in the second pattern, which is the new ending point of the restored edge. But be aware that the new starting point may be the other unmatched paper vertex, as well as an additionally intro-duced vertex. Neglecting this case will cause the bottom-right pattern to be lost, which is the representative of all tree-like patterns.

Moreover, it should be noted that Line 10 actually embeds a procedure of checking for duplicated patterns. If neglected, they will cause more duplicated patterns, joins, and support computations in later computations. To efficiently check for duplicates, we can hash each produced pattern with the ver-tex labels on, and the associated edges of the pivot. When a new pattern is produced, we first use the hash table to find potential duplicates, and further verify them with a series of isomorphism checks.

Finally, the last performance overhead of this algorithm lies in the pivoted subgraph isomorphism checker at Line 9 and 10. At this stage, we have not considered adapting any advanced heuristic optimizations of the original subgraph isomorphism problem to ours. In the experiments we simply implemented a depth-first search checker, utilizing an index built on all label names of the large graph G .
In [17], Kuramochi et al. used TID (Transaction Identi-fier) lists to optimize their FSM algorithm under the graph transaction setting. Analogously, we propose VID (Vertex Identifier) lists to improve our efficiency both in the building block construction phase and the joining phase. Both of our EntityCube 4,685,439 165,533 75,831 288 207 A rnetMiner 2,495,972 0 7,791,406 0 3
Table 1: Two datasets used in the experiments o ptimizations originate from the fact that for any patterns P 1  X  p P 2 , the set of vertices (transactions in Kuramochi X  X  cases) matching P 1 , i.e., M G ( P 1 ), must be a superset of M
G ( P 2 ). This is essentially a reinforced version of the DCP, which enables us to reduce the number of vertices considered when counting the support of a candidate. To utilize it, we have to maintain the IDs of all vertices in M G ( P ) as an ordered list for any P , instead of recording only its size.
Specifically, at Line 5 in Algorithm 1, when extending path , we only need to consider M G ( path ) instead of all vertices in G . In Algorithm 2, for each enumerated pair of patterns at Line 5, we first intersect M G ( F k  X  1 [ i ]) and M
G ( F k  X  1 [ j ]) in linear time. If the number of results is be-low  X  , they need not be joined because vertices matching their shared super-patterns must be within the intersection. If they pass the test, M G ( F k  X  1 [ i ])  X  M G ( F k  X  1 and at Line 9 we only need to verify the intersection instead of the whole V ( G ) to count the support of the size-K pat-terns. Let X  X  take the join in Figure 5(a) on the toy database in Figure 2 for example. The upper left pattern matches au-thor a 1 , a 2 , and a 3 , and the lower left one matches a and a 4 . Since a 4 does not appear in the intersection, it will not be checked when computing the support of the joined pattern. Vertices matching the pattern under consideration are stored again in VID lists at Line 7 of Algorithm 1 and Line 9 of Algorithm 2 for the use of larger patterns.
In our experiments, the VID-optimization reduced the running time by up to two orders of magnitude. In Sec-tion 4 we will discuss in detail the experimental results and the feasibility of this optimization.
Our experiments were performed on two real datasets: En-26], the statistics of which are presented in Table 1. Due to their intrinsic characteristics, the efficiency of our algo-rithm was mainly tested on the first dataset, while the sec-ond was used to showcase the distinctive form of knowledge our method is able to discover. The algorithm was imple-mented in C# and run on a 2.4G 16-core Intel Xeon PC with 72GB of main memory. The code optimization option was turned on in the compiler. All reported times are in seconds.
The EntityCube system is a research prototype for ex-ploring object-level search technologies, which automatically summarizes the Web for entities (such as people, locations, and organizations). We utilized the relationship network be-tween person entities extracted by the system. Specifically, with a list of people names as seeds, we queried the sys-tem using one name each time, and got related persons and the corresponding relationship names in return. On the one hand, the seed people and returned people were used to form the vertex set V . On the other hand, the system returned two types of relationships. The name of one was in the plural form, such as  X  X oliticians(Barack Obama, Bill Cliton), X  in-dicating the connection that they X  X e both politicians. Thus, the relationship name naturally served as vertex labels for the two associated entities. The other type of relationship appeared in the singular form, e.g.,  X  X ife(Michelle Obama, Barack Obama) X . They were interpreted as labeled edges between the corresponding vertices.
The ArnetMiner Citation Network dataset contains many papers with associated attribute information, as well as their citation relationship. The dataset consists of five versions and we use the fifth one. We extracted all papers, authors, and conferences appearing in the data, and constructed the vertex set with them. Conferences of the same series but in different years were treated as identical. There were only three types of labeled edges, i.e.,  X  X rites X  between an author and a paper,  X  X ccepts X  between a conference and a paper, and  X  X ites X  between one paper and another. Because these edge label names actually imply the type of both the starting and ending vertices of an edge, we didn X  X  employ any vertex labels to avoid redundancy. In the data, IDs were provided to uniquely denote papers and form citations, which were adopted by us. However in the author and conference sec-tions of each paper, only texts were presented. Therefore, when converting them into the IDs in our algorithm, we re-quired an exact text-match and didn X  X  perform any cleaning operation involving external data.
In this section, we report the performance of our algo-rithms for frequent neighborhood mining. Since no pre-vious work has addressed exactly the same problem, our experiments were dedicated to validating the feasibility of our VID optimization. In practice, the running time of such a pattern-mining algorithm is heavily influenced by the size of the result set. Therefore, we decided to con-duct the experiments on the EntityCube data with rich la-bel names, for it has a potentially larger result set and the running time is more sensitive to parameters such as the minimum support  X  . In all experiments,  X  was chosen from an average of five consecutive runs.

In Figures 6(a) and 6(b), we terminated the search after all frequent patterns below size 4 were discovered. It is clear that our VID optimization successfully accelerates both the building block construction and the join-verify phases by up to one and two orders of magnitude, respectively. Analogous to the TID optimization [17] for FSM, the advantages of the VID optimization are two-fold. First, two patterns will not be joined if the intersection of their VID lists is smaller than  X  . Therefore, the algorithm successfully avoids veri-fying false positives caused by joining unpromising pattern pairs, which is a vital overhead to the overall performance. In Figure 6(c), the number of candidates with/without the VID-list-pruning, and the number of true patterns are il-lustrated. This figure shows that the pruning helps narrow (e) Percentage of different pattern types down the number of candidates by several times. Second, for each pair of patterns that passes the pruning, the time spent on counting the support of the joining results is also reduced because vertices that are not in the intersection won X  X  con-tribute to the count, and therefore are not checked. Figure 6(d) presents the average verification time for each non-path candidate where  X  = 0 . 0001. The x-axis denotes different stages of the search procedure, where candidates of size 2 to 5 are verified. Obviously the VID optimization is signif-icantly effective for verifying candidates of all sizes. Partic-ularly, without the optimization, the algorithm didn X  X  finish the verification of size 5 in a reasonable time.
As mentioned above, the major superiority of FNM over [10, 12, 15] is that it discovers patterns with cycles that are not targeted by others. With the hands-on experience of experimenting on both datasets, we realize that a cyclic pattern can be viewed as a set of constraints with a lower degree of freedom than a tree-like one of the same size. Fig-ure 6(e) shows the constitution of all patterns in EntityCube data, whose size are below 5. Patterns with cycles actually make up around 10% among all three types. The trend also shows that when we decrease the support ratio and specify a pattern into its super-patterns, it is more difficult for a cycle to form, than a fork to appear.

However, once formed, patterns with cycles serve as a good complement to tree-like patterns. Introducing them does not linearly increase our knowledge about the data being investigated, but actually makes a mutual reinforce-ment with tree-like ones. As patterns from the ArnetMiner dataset have better interpretability, we selected some inter-esting neighborhood patterns mined from this dataset to demonstrate our points. In addition to the example given in Figure 1, more patterns are displayed in Figure 7. By com-bining two or more of them, we can make very interesting discoveries.

For example, the support ratio of Figure 7(g) is lower than those of Figures 1(a) and 7(f), which reflects the common sense that it is more difficult to get one X  X  paper cited than to write more papers. Also, the small gap between the ratios of Figures 1(a) and 7(e) reveals the fact that most writ-ers are willing to maintain a co-authoring relationship. On the other hand, the ratios of Figures 1(a) and 7(h) together prove that an average author relatively favors a conference that once accepted his paper. Moreover, Figure 7(c) alone points out that most of us (assuming that we all have pa-pers) have a paper with no less than three authors. Surpris-ingly, as Figure 7(l) indicates, there are even papers citing each other! By checking the data we find two cases of such a phenomenon. One is caused by the dataset itself. The data treats books as conferences, and their chapters as pa-pers. Of course, chapters from the same book can cite each other. This case is rare. The other case is more common: an author simultaneously submitted two papers to the same conference and got them both accepted. When preparing the camera-ready versions, he had them cite each other.
When browsing all mined patterns, we also find that, de-spite those interesting ones, the results tend to be flooded by a significant number of uninteresting patterns. Most of them are superpositions of some basic components. E.g.,  X  X uthors citing his own paper, while having a third paper X . We be-lieve that this is caused by the vagueness of  X  X nterestingness X  and the gap between  X  X requent X  and  X  X ruly interesting X . One possible way out may be to compress the results (e.g., re-quire them to be closed [31]). We leave it as our future work.

For all patterns presented in this paper, we use support ratios w.r.t. vertices with a specified label, instead of the absolute count mentioned in the problem statement. Such (a) 94.6% of authors have a co-author.
 (d) For about 61.8% of papers, two of t heir authors have other cooperations.
 (g) 27.6% of authors have a cited paper.
 (j) 19.0% of authors have a paper that w as cited at least twice.
 P aper (sampled) 500,000 53,422 796 147 a variation enhances the interpretation of patterns, and it only requires a small modification to the algorithm to ap-ply the variation. Suppose we want facts about all authors with a minimum support ratio of 1%. In Algorithms 1 and 2, when a scan on the entire V ( G ) is required for support counting, we only scan those author vertices by accessing an index on the label names. Moreover, when calling the modi-fied algorithms,  X  should be assigned with 1% of the number of all author vertices. With this variation, though it is easy to mine a mixture of, say, paper and author vertices, it is insignificant, at least in this dataset. Because a pattern that simultaneously describes papers and authors seldom exists, mining such a heterogenous vertex set tends to result in the union of results of mining papers and authors separately. When mining patterns about authors, conferences, and pa-pers, the support ratios were uniformly set to 1%. As the number of paper vertices is huge (over 1.5 million), the sup-port calculation was performed on a subset sampled from the paper vertex set, which consists of 0.5 million papers. We didn X  X  explore path patterns of size 4, or any pattern whose size exceeds 4. Readers may refer to Table 2 for more details.
The frequent subgraph mining problem is well-investigated by the literature under the graph-transaction setting. Among them, the most influential methods include AGM[14], FSG[17], gSpan[30], FFSM[13], and Gaston[20]. The first and second adopt the apriori-based BFS scheme, and feature vertex-incremental and edge-incremental approaches, respectively. The last three fall under the pattern-growth-based DFS cat-egory. To the best of our knowledge, there exists no reason-able conversions between graph-transactional FSM and our FNM in either directions. However, the optimizations they utilized, such as canonical labeling, vertex invariants, and depth-first search, were inspiring and potentially employable in our method.

The literatures tackling the single-graph setting, however, are still at the stage of proposing various support measures, due to the reasons we mentioned above. The Maximum In-dependent Set support and corresponding mining algorithms were studied in [18, 29]. When calculating the MIS support of a pattern, one needs to solve a maximum independent set problem on the instance-overlap graph of that pattern, which is NP-hard. The Harmful Overlap support[7, 8] and t he MiNimum Image support[3] avoid solving the MIS prob-lem. However, compared with our neighborhood patterns, which can be directly interpreted as  X  X % percent... X , sub-graph patterns mined under their supports cannot provide such intuitive interpretations. [21] discussed generalizations, optimizations, and approximations for the MNI-based meth-ods. [2] proposed a network-flow based definition of single-graph support, and is more application-oriented.

It is worth noting that [29, 20] also use paths as building blocks to generate larger patterns. In their FSM problem setting, they start the mining procedure with paths instead of size-1 patterns to reduce the number of duplicate candi-dates and improve efficiency. However, in our problem set-ting, path is not an alternative, but a mandatory building block to ensure the completeness of results.

In recent works on heterogeneous information networks[23, 16], their key concept  X  X eta path X  resembles our path pat-tern described in Figure 3(a). As a chaining join of multiple binary relations, a meta path is essentially a binary relation between instances. However, a path pattern is roughly an unary relation, which describes all instances associated with such a path.
In [10, 12, 15], the authors attempted to mine tree pat-terns in graphs, whose support measure resembles ours in the way that distinct matches of some vertices are counted, while the match conditions on the others are only existen-tial. They did not target patterns with cycles, which added a great deal to the users X  understanding of the data. More-over, because [10, 12] allowed multiple vertices to be counted (in other words, as our  X  X ivots X ), their problems were more complicated and thus did not completely follow and bene-fit from the well-solved apriori pattern mining scheme. We argue that, patterns with more than three pivots may ex-plode in number, while bringing about some knowledge that is less explainable and utilizable. Finally, these papers both claimed that their mining algorithms supported constants in the patterns, e.g.,  X  X % of the authors once cited a paper published in CIKM. X  Our problem setting supports multiple labels on a vertex. Therefore, we can achieve it by simply adding the name of each vertex to its label set. We can also modify our algorithm to implicitly perform such a data transformation.
In [4], Dehaspe et al. introduced an inductive logic pro-gramming system for mining frequent patterns in a datalog database. Their frequency measure for patterns are simi-lar to ours, while the confirm of a match is slightly differ-ent. For our isomorphism-based match, two vertices in the source graph cannot be mapped to the same vertex of the target graph. However, they allow different variables in the pattern to be bound to the same constant, which resembles the graph homomorphism problem in some sense. We argue that, none of the two settings is contained by the other. Con-sider Figure 1(a), the two paper vertex are supposed to be matched to different paper vertices in the database, which exactly conveys the semantics of  X  X as two papers X . How-ever, in their setting, it is trivially equivalent to a pattern where an author vertex points to a paper vertex with label  X  X rites X . Conversely, despite the fact that a father may be-come a friend to his child, when describing  X  X  person with a father and a friend X , our setting unnecessarily partitions this pattern into two patterns, each specifying whether the father and friend are or are not the same person. [6] also adopts the homomorphism setting, but only tree-shaped patterns are addressed. Methods learning horn clauses from knowl-edge bases such as [22, 19, 9] also belong to the Inductive Logic Programming category. These methods are character-ized by a variety of metrics to evaluate the utility of a rule. Since noise and scalability issues in real data are their main concerns, they adopt stricter language biases and the rules mined are of more limited forms.
Under the current problem setting and solution, encour-aging results have been achieved in terms of performance and result utility. However, our method can still be fur-ther extended from the following aspects. First, the defi-nition of closed neighborhood patterns may be introduced in a similar way as [31]. A pattern is closed if there ex-ists no proper super-pattern with the same support. This definition is expected to significantly reduce the size of the results, while preserving the most meaningful ones. Second, the pivots may be allowed to be an edge to enable character-izing the  X  X eighborhood X  of an edge. This generalized pat-tern introduces new semantics, e.g.,  X  X % of all citations are made between papers from the same institutes. X  Finally, we are also interested in exploring whether neighborhood pat-terns are effective in single-graph-based classification tasks, since it is reasonable to assume that vertices located in sim-ilar neighborhoods have similar properties[5]. We believe that neighborhood-based features or kernels are orthogonal to distance and connectivity-based techniques, and have po-tential applications in the social network research.
In this paper, we addressed mining single-graph databases and introduced the new neighborhood patterns as mining targets. They have clear semantics and are not limited to tree-like shapes. We formally defined the frequent neighbor-hood mining problem, and proved that it is as difficult as the frequent subgraph mining problem. We indicated that the major difference between FNM and FSM in terms of so-lution is that our patterns have non-trivial building blocks, which are clearly separated by us via a theorem and proof. After discussing possible optimizations, we conducted ex-periments on two real datasets to validate the efficiency and effectiveness of our method. The algorithm has proven to be feasible and shows a unique ability to provide users with especially interesting insights into the analyzed data.
We are grateful to the anonymous reviewers for their help-ful comments. We also thank Changliang Wang and Chun-bin Lin for their discussions and feedbacks. [1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining [2] P. Anchuri, M. J. Zaki, O. Barkol, R. Bergman, [3] B. Bringmann and S. Nijssen. What is frequent in a [4] L. Dehaspe and H. Toivonen. Discovery of frequent [5] C. Desrosiers and G. Karypis. Within-network [6] A. Dries and S. Nijssen. Mining patterns in networks [7] M. Fiedler and C. Borgelt. Subgraph support in a [8] M. Fiedler and C. Borgelt. Support computation for [9] L. Galarraga, C. Teflioudi, K. Hose, and [10] B. Goethals, E. Hoekx, and J. V. den Bussche. Mining [11] J. Han, H. Cheng, D. Xin, and X. Yan. Frequent [12] E. Hoekx and J. V. den Bussche. Mining for [13] J. Huan, W. Wang, and J. Prins. Efficient mining of [14] A. Inokuchi, T. Washio, and H. Motoda. An [15] G. Jeh and J. Widom. Mining the space of graph [16] X. Kong, P. S. Yu, Y. Ding, and D. J. Wild. Meta [17] M. Kuramochi and G. Karypis. An efficient algorithm [18] M. Kuramochi and G. Karypis. Finding frequent [19] N. Lao, T. M. Mitchell, and W. W. Cohen. Random [20] S. Nijssen and J. N. Kok. A quickstart in frequent [21] M. E. Saeedy and P. Kalnis. Grami: generalized [22] S. Schoenmackers, J. Davis, O. Etzioni, and D. S. [23] Y. Sun, J. Han, X. Yan, P. S. Yu, and T. Wu. [24] J. Tang, L. Yao, D. Zhang, and J. Zhang. A [25] J. Tang, D. Zhang, and L. Yao. Social network [26] J. Tang, J. Zhang, R. Jin, Z. Yang, K. Cai, L. Zhang, [27] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su. [28] V. Vacic, L. M. Iakoucheva, S. Lonardi, and [29] N. Vanetik, E. Gudes, and S. E. Shimony. Computing [30] X. Yan and J. Han. gspan: Graph-based substructure [31] X. Yan and J. Han. Closegraph: mining closed Proof of Theorem 1 . We prove it by reducing it from the subgraph isomorphism problem. Labels are ignored because it is a generalization of, thus reducible from, the non-label case.

Given an instance h G 1 , G 2 i of the subgraph isomorphism problem, we add a new vertex v 1 to G 1 , and v 2 to G 2 , re-spectively. They are marked as pivots and edges are created from them to all vertices of the same graph. Obviously, G 1  X  G 2 iff. h G 1 , v 1 i  X  f h G 2 , v 2 i . By solving the pivoted subgraph isomorphism problem hh G 1 , v 1 i , h G 2 , v 2 able to answer whether G 1  X  G 2 . So our problem is np -hard. The solution of an instance of our problem is verified in polynomial time. Therefore, our problem is np -complete.
