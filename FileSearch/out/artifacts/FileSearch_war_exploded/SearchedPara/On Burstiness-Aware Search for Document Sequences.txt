 As the number and size of large timestamped collections (e.g. sequences of digitized newspapers, periodicals, blo gs) increase, the problem of efficiently indexing and searching such data becomes more important. Term burstiness has been extensively researched as a mechanism to address event detection in the context of such collections. In this paper, we explore how burstiness information can be further utilized to enhance the search process. We present a novel approach to model the burstiness of a term, using discrepancy theory concepts. This allows us to build a parameter-free, linear-time approach to identify the time intervals of maximum burstiness for a given term. Finally, we describe the first burstiness-driven search framework and thoroughly evalua te our approach in the context of different scenarios. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Indexing methods ; H.2.8 [ Database Management ]: Database applications X  Data Mining ; G.3 [ Probability and Statistics ]: Time series analysis Algorithms, Theory Document Sequences, Search, Burstiness
Suppose we are presented with a long document sequence , formed by newspaper articles spanning several local titles (e.g., New York Times, The Wall Street Journal, etc.), over a large period of time. Such corpora is becoming increas-ingly available, due to initiatives such as The National Dig -ital Newspaper Program (NDNP) [15] by the Library of Congress (LC), and other similar ventures for the digitiza-tion of periodicals by large corporations such as Microsoft (www.microsoft.com) and Google (www.google.com). The articles in such collections cover newsworthy events that took place at various times. Each event is characterized by a set of descriptive keywords, revealing basic informati on such as the place where the event occurred, or the names of the persons involved. For the duration of the event X  X  lifespan and consequent coverage in the news, these char-acteristic terms appear repeatedly in relevant articles, l ead-ing to uncommonly high frequencies (bursts). In the typ-ical search paradigm, the user encodes a topic of interest using a query (i.e. a set of keywords), which is then sub-mitted to a search engine. Typical search engines rely on static, frequency-based measures (e.g. tf-idf ) for the pur-poses of indexing and querying the underlying collection. These measures record the frequency of a term in each doc-ument, typically normalized by a global frequency measure, in order to capture the impact of the term in the entire col-lection. The underlying assumption is that an occurrence of a term has the same significance, regardless of the moment in time it occurs. Our claim is that, for a contiguous doc-ument sequence observed through time, this assumption is invalid: the importance of terms varies through time, as the y are used to describe current influential events that are dis-cussed in the corpus. Therefore, it is essential to consider the temporal dimension of the data in the indexing and ranking process. The ultimate purpose of our work is the creation of an efficient, end-to-end framework that, given a document sequence, identifies  X  X ursty X  intervals for each term and ut i-lizes this information toward an efficient, burstiness-awar e search mechanism.

Even though some work has been devoted to measuring burstiness in different contexts, the concept has yet to be formalized. A major contribution of our work is a formal definition of burstiness that is based on the concept of dis-crepancy. Discrepancy theory has applications in several fields including machine learning, computer graphics and computational geometry [7, 8, 4, 1]. The concept is gen-erally used to describe the deviation of a situation from the  X  X xpected X  behavioral baseline. Based on our definition, we present a parameter-free, linear-time algorithm to identi fy the time-intervals that maximize the burstiness score of an y given term. We present the theoretical foundations of our work and proceed to evaluate it thoroughly on a new dataset. Our Contributions: In this paper we make the following contributions: ii. A parameter-free, linear-time method to identify the iii. An efficient search framework for documents, that con-
The rest of this paper is organized as follows: Section 2 discusses related work. Section 3 describes the basic nota-tion used in the paper. Section 4 introduces our definition of burstiness and discusses efficient techniques for the iden -tification of bursty intervals for a given term. In Section 5, we present two different versions of a complete, burstiness-aware search framework. Finally, we conclude with a thor-ough experimental evaluation in Section 6.
The concept of burstiness has been studied in several do-mains. A significant portion of this work has been inspired by Kleinberg X  X  seminal paper on the bursty and hierarchical structure of streams [13]. We discuss Kleinberg X  X  approach in more detail in Section (6.2). A considerable amount of work has been devoted to developing efficient burst-detectio n methods [10, 11, 18, 19]. Even though we propose a method of our own, we do so in the process of creating a complete search framework, which is the main contribution of our work. The main benefits of our method are that it runs in linear-time and is also completely parameter-free. This makes it ideal for very large sequences of documents, span-ning significant periods of time. That being said, our search framework is compatible with any burst detection method that can report non-overlapping bursty intervals and their respective scores, for any given term.

Another burst-detection method is presented by Fung et al.[10]. In this work, bursty terms are clustered to represe nt events discussed in the data. In [11], the authors classify terms in four burstiness categories, based on their frequen cy trajectory. Their use of spectral analysis is similar to the one used by Vlachos et al. in [18], where the authors focus on periodic and bursty artifacts in query logs. In [19], the authors use a wavelet-based structure for aggregate moni-toring of data streams.

Burstiness has also been evaluated in the context of other applications, such as stream clustering [12], and even in th e context of graphs [14]. Further, He et al. [16] apply Klein-berg X  X  model to topic clustering.

Bansal and Koudas [2, 3] have presented a system for the analysis of streaming blogs. Even though no details on the employed methods are given, their work is relevant to ours, in that they ultimately map bursty terms to specific blogposts. To the best of our knowledge, our work is the first that directly incorporates burstiness information in the indexing and ranking of documents, leading to a complete burstiness-aware search framework.
In this paper, we explore corpora that are formed as a se-quence of documents, spanning a pre-defined timeline. For a timeline of m consecutive timestamps, we define a document sequence S as: where S i represents the set of documents appearing on the i th timestamp. Further, we define the frequency sequence Y for a given term t as: where y ti expresses the frequency of term t on the i th times-tamp of the timeline. We assume that y ti is equal to the number of documents in S i that include term t . Finally, by Y t [ l : r ], we represent an interval of Y t that includes all timestamps from y tl to y tr (inclusive). Note that the words  X  X nterval X  and  X  X egment X  are used interchangeably through -out the paper.
In this section we present a formal definition of term bursti-ness in the terms of numerical discrepancy . We then show how the problem of finding the maximum burstiness inter-vals can be solved in linear time.
We first present the general definition of numerical dis-crepancy [7, 8, 4]. Let P be a set of points distributed over random locations in [0 , 1] d , where d is the number of dimen-sions on the plane. For any region R in [0 , 1] d , let  X  ( R ) be the Euclidean measure of R  X  [0 , 1] d (i.e. the area of R ), and  X  ( R ) be the discrete measure | R  X  X | / |P| (i.e. the fraction of points of P inside R ). Then, the numerical discrepancy of R with respect to P is defined as: Even though the concept is meaningful for any d &gt; 1, we will focus on the one-dimensional case, suitable for our sequenc e representation. For d = 1, a region R is reduced to a one-dimensional interval I , defined within the unit interval [0 , 1]. Following Equation (4.1), the discrepancy of a given interv al I is defined as the absolute value of the difference between its length and the ratio of points from P that fall within I : where len ( I ) is the length (i.e. the euclidean measure) of interval I . Conceptually,  X  ( I ) expresses the baseline, i.e. the fraction of points from P that is expected to fall within I , while  X  P (I) represents the observed fraction. This con-stitutes an appropriate definition for term burstiness, whi ch is similarly expressed by increased frequency values that d i-verge from a term X  X  individual baseline. In the mapping of term burstiness to numerical discrepancy, the set of points P is represented by the total frequency of a term, observed throughout the entire document sequence. Next, we for-mally define the baseline  X  ( I ) and the observed fraction  X  ( I ) in the context of term burstiness.

Depending on the nature of the data,  X  ( I ) can be either pre-defined or based on the underlying distribution. In [1], the authors explore discrepancy in the context of different distributions (Poisson, Binomial). Even though such an ap-proach may work well in some scenarios, the assumption that the entire dataset can be accurately described by a sin-gle distribution is not always valid. In addition, the use of a probability distribution introduces parameters that are n ot always intuitive to tune. Given an interval Y t [ l : r ] of the frequency sequence for a term t , we define the baseline as i.e. the average frequency observed over all timestamps, multiplied by the length of the interval. To conform with the definition of numerical discrepancy, we then project Y [ l : r ] on the unit interval [0 , 1] by dividing the baseline by P Formally, let I be the projection of Y t [ l : r ] on [0 , 1]. Then, we define the baseline  X  ( I ) for I as: By replacing the average and solving further, we get:
Indeed, the baseline is equal to the Euclidean measure (length) of I , as mandated by Eq. (4.2).
 Next, we define  X  P ( I ), the fraction of the term X  X  frequency observed within the interval, as the frequency of t observed within interval Y [ l : r ], divided by the total frequency of t throughout the sequence: By replacing Equations (4.4) and (4.5) in Eq. (4.2), we get:
Note that Eq. (4.6) takes positives values if the observa-tion is either greater or less than the baseline. Conceptually, the latter occurs if the frequency of a term within an interva l is less than expected. Even though this typically constitutes a case of discrepancy, it is of little value for the purposes o f measuring term burstiness. Instead, we would like bursti-ness to be positive only for uncommonly high frequency observations. Thus, given a term t and an interval [ l : r ] on the timeline, we define the Burstiness of t in [ l : r ] as:
Using Eq. (4.7), we can measure the burstiness of a given term for any interval on the timeline. The next step is to identify high-burstiness intervals for each term. On a high er level, the problem definition is the following: Problem 1. Bursty Intervals Problem: Given the fre-quency sequence Y t of a given term t , identify the set of intervals that maximize the Burstiness function B ( t,  X  ) .
Next, we argue that Problem 1 is equivalent to the well-known maximum sum segments problem , defined as such: Problem 2. Maximum Sum Segments Problem: Given an input sequence X = x 1 , x 2 , ..., x n of real numbers, identify the K segments with the highest total scores, where the score f ( X [ i : j ]) of a segment X [ i : j ] = x i is equal to the sum of its elements: The Maximum Sum Segments Problem comes up in dif-ferent domains and has been extensively researched in the past [5]. To show that Problems (1) and (2) are equivalent, it is sufficient to show that, given a term t , the Burstiness score of any given interval is equal to the sum of the Burstiness values observed in the individual timestamps of the interva l. Formally:
Proof. Problem (1) is now reduced to solving the Maximum Sum Segments Problem on the burstiness sequence B t , defined as such:
B t ( i ) = B ( t, [ i : i ]) = Eq. (4.10) assumes the global baseline given by Eq. (4.3). Alternatively, one could use the local average of each inter val as a baseline. In that case, consecutive segments of B t could be computed separately, and then concatenated to form the entire sequence. This could allow for a more flexible calcula -tion of burstiness, and avoid reporting anticipated period ical bursts (e.g. a burst of the term  X  X hristmas X  during Decem-ber).

The standard formulation of the Maximum Sum Seg-ments problem has the following disadvantage: given a high-scoring segment, one can easily generate several oth-ers by simply appending or removing a small number of el-ements. These segments convey little extra information re-garding the burstiness of a term. To address this, we adopt a slightly different formulation, based on the concept of the maximal segment : Definition 1. Maximal Segment: Let X be a non-empty score sequence. A segment X [ i : j ] is maximal in X if ii. No proper super-segments of X [ i : j ] in X satisfies (i).
Figure (1) illustrates the Burstiness Sequence B t for the term  X  X arthquake X , as it manifested in a daily newspaper over a fixed period of time. The values on the x-axis repre-sent consecutive timestamps. Following Eq. (4.10), negati ve values correspond to points when the observed frequency was less than the baseline. Here,  X  X Z X  is identified as a maximal segment; conceptually, extending the interval fro m either side can only reduce its score, since more negative than positive values will be included.

No two maximal sequences can overlap. A formal proof appears in [17], but essentially, given two maximal overlap -ping sequences, either the union or the intersection of the two would have higher discrepancy than one of the two, cre-ating a contradiction. Thus, every element of the input se-quence belongs to exactly one maximal segment. Therefore, for any given sequence of real numbers, there exists a finite set that contains all the maximal scoring segments. We can now formalize the problem as such: Problem 3. All Maximal Segments Problem: Given an input sequence X = x 1 , x 2 , ..., x n of real numbers, identify the set of all segments of X that satisfy Definition (1).
In [17] the authors present a linear-time algorithm for solv -ing the All Maximal Segments Problem . The algorithm accepts as input a sequence of real numbers and reports the set of all maximal segments. For the rest of this paper, we refer to this algorithm as MAX-1 . The details and pseudocode of the algorithm can be found in [17]. MAX-1 filters out max-imal segments with a negative score. This is ideal for the purposes of burstiness evaluation, since negative-scorin g in-tervals represent regions where the observed frequency of a term was less than the expected. Finally, in addition to be-ing linear, the approach is completely parameter-free. Nex t, we present an extension of MAX-1 and discuss its advantages.
In [13], Kleinberg discusses anisochronies , the non-uniform relationships between the time spanned by a story X  X  events and the amount of time devoted to these events in the ac-tual telling of the story. Considering the coverage of event s in news streams (e.g. newspapers, blogs), we identify two primary levels of bursty behavior for the terms describing an event: the first level represents the extended time period when the event was generally discussed in the news. De-pending on the nature and significance of the event, this pe-riod can be extended to include weeks or even months. The second burstiness level pertains to smaller intervals with in this extended period, when the event was particularly pop-ular and extensively covered in the news. In the context of a newspaper, such intervals may represent the first time an event made the headlines, or a new development in an older event that brings it back to the front page.

Conceptually, the intervals reported by MAX-1 capture the first level of burstiness activity for a given term. By re-applying the algorithm on each of the reported maximal intervals independently, we can easily identify the second -level burstiness intervals. For the rest of this paper, we re fer to this algorithm as MAX-2 . The pseudocode is shown in Algorithm (1). Multiple iterations of MAX-2 could be used to obtain a hierarchical structure of the bursty intervals. As we demonstrate in the Experiments section, a single iteration is enough to capture the burstiness patterns of events. Algorithm 1 : MAX-2 1: I 0  X  X  X  2: for every interval I  X  X  do 3: I 0  X  X  0  X  MAX-1 ( I ) // MAX-1 returns 1st level intervals
In this section, we describe two different ways to uti-lize burstiness information to create a complete, burstine ss-aware search framework. The described search frameworks constitute the main contribution of our work. Our first ap-proach focuses on indexing and ranking documents directly, while the second approach is more advanced and performs a more informative, interval-based evaluation of a given que ry. For each approach, we start by discussing the underlying in-dexing mechanism, and then proceed to discuss the respec-tive query evaluation algorithms.

It is important to note that both approaches are com-patible with any method than can evaluate the frequency sequence of a term over a specified timeline, and report non-overlapping bursty intervals and their respective scores.
Next, we describe a burstiness-aware query evaluation fra-mework that retrieves and ranks documents based on a given query. First, we discuss the employed indexing mechanism. Indexing: In the standard inverted index structure, each term is mapped to the list of documents that contain the term. In a more advanced scenario, the document lists are sorted on a pre-computed score that expresses the strength of the connection between the term and the document. In order to use such a structure in our framework, we need to define a formula that evaluates a document with respect to a given term, in the context of burstiness: Definition 2. Given a term t and a document d , let I t,d the bursty interval of t that includes (the timestamp of) d . Then, the Burstiness of d with respect to t is defined as: where d -score stands for document score . Conceptually, B ( t, I t,d ) returns the burstiness score of I t,d , as defined by Eq. (4.7). Also, freq ( t, d ) returns the frequency of term t with respect to document d . In our experiments, we assume freq ( t, d ) = log( T F ( t, d ) + 1), where T F ( t, d ) returns the number of occurrences of t in d . The logarithm is used to moderate the effect of the frequency and ensure that bursti-ness is the dominant factor. Finally, if d -score ( t, d ) = 0, d is not included in the sorted list. Note that
We can now build an inverted index structure, where each term is mapped to a list of documents, sorted on their d -score . Next, we discuss how we can use this index to evaluate multi-term queries.
 Evaluation: First, we formally define the Document Eval-uation Problem as such: Problem 4. Document Evaluation Problem : Given a query of terms q = { t 0 , t 1 , ... } , retrieve the k documents with the k highest values for P t  X  q d -score ( t, d ).
With an appropriate index structure at our disposal, the next step is to find a query evaluation algorithm to address Problem 4. For this purpose, we use the Threshold Algo-rithm ( TA )[9], an efficient top-k evaluation algorithm, which is able to deal with multi-predicate queries. The algorithm goes through the sorted lists mapped to the terms of a query, evaluating documents in descending order. For every docu-ment seen under sorted access in some list, a random access probe retrieves the respective scores of the document from the other lists. The cumulative score is then calculated, an d the document is considered as a top-k candidate. The al-gorithm maintains a threshold value T , based on the score of the last document seen from every List. As soon as k documents with a cumulative score of at least T have been found, the algorithm terminates. The authors prove that, while this mechanism allows for early termination, it does not affect the optimality of the result. Algorithm (2) con-tains the pseudocode of the TA algorithm. The algorithm is designed so that candidates from different sorted lists can be also evaluated in parallel. In that case, lines 5-11 of the algorithm can be handled by independent threads.

The proposed Inverted Index structure and the TA algo-rithm compose a complete search framework that efficiently solves the Document Evaluation Problem . The frame-work is thoroughly evaluated in the Experiments Section.
The framework described in the previous section focuses on the indexing and ranking of documents. In this section, we describe an alternative approach that places the focus on intervals. Given a query of terms, we would like to find peri-ods of time when all terms simultaneously displayed bursty behavior, indicating the occurrence of an underlying event . Next, we describe a search framework for this problem. Indexing: First, we define a formula that evaluates the burstiness of interval with respect to a given term: Definition 3. Let I t be the set of bursty intervals for a term is identified as bursty with respect to q , if  X  t  X  q,  X  I 0  X  I , s.t. I  X  I 0 . Then, the burstiness score of I with respect to q is defined as: Algorithm 2 TA Algorithm 1: TopK  X  X  X  // sorted, holds at most k elements 2: Threshold T  X  0 3: L = { L 0 , L 1 , .. } // set of Doc Lists for each term in q 4: while ( Not All lists in L Have Been Exhausted ) do 5: for ( every List L  X  X  ) do 6: cand  X  getNext ( L ) 7: total  X  cand . score // Holds cumulative score 8: T  X  ( T  X  lastSeen ( L ) + cand . score ) 9: for ( every List L 0  X  X  , L 0 6 = L ) do 10: total + = getDScore ( L 0 , cand ) 11: TopK . insert ( cand , total ) 13: return TopK // Early Termination 14: return TopK  X  getNext ( L ) returns the next candidate to be evaluated from list L , under sorted access.  X  getDScore ( L 0 , cand ) is a random access probe that re-trieves the d -score of the candidate document from list L 0 .  X  lastSeen ( L ) returns the score of the last candidate seen under sorted access in List L  X 
TopK . last () returns the score of the lowest-scoring element in the Result. where i -score stands for interval-score . Also, super ( I returns the interval I 0  X  I t , s.t. I  X  I 0 (i.e. I 0 is a super-segment of I ).
 Conceptually, I is bursty with respect to a query if it has been included in a bursty interval for all the terms in the query. The i -score of I is then the sum of the scores of all the bursty intervals that include it. Note that this definiti on requires the bursty-interval set I t for a given term t to con-sist of non-overlapping intervals . This guarantees that at most one interval I 0  X  I t is a super-segment of I . Us-ing Eq. (5.2), we can now build an inverted index structure, where each term is mapped to a list of intervals, sorted on their i -score . Next, we discuss how we can use this index to evaluate multi-term queries.
 Evaluation: First, we formally define the Interval Evalua-tion Problem as such: Problem 5. Interval Evaluation Problem: Given a query of terms q = { t 0 , t 1 , ... } , retrieve the k intervals with the highest values for P t  X  q i -score ( t, d ).
 For the top-k evaluation phase, we introduce a modified ver-sion of the TA Algorithm, which we refer to as TA  X  (Algorithm (3)). TA  X  is similar to TA , differing only in the use of the ran-dom access probe. In the standard version, a random access probe looks for the candidate document in the various docu-ment lists and retrieves its d -score (line 10 of Algorithm 2). In the case of intervals, this step is more complicated, sinc e the candidate may overlap with multiple intervals in a list. Procedure (1) provides an implementation of the Random Access probe. Given an Interval I and a list of intervals L the probe returns the set of (sub)intervals of I that over-lap with some interval in L . The procedure can be easily implemented with the use of interval-trees [6]. Procedure 1 RandomAccess ( Interval I , Interval List L )
Return a set of intervals I , s . t .  X  I 0  X  L , where I 0  X  I 6 =  X  ,  X  I  X   X  X  , where I  X  = I 0  X  I AND I  X  . score = I . score + I 0 . score Algorithm 3 TA  X  Algorithm 1: TopK  X  X  X  // sorted, holds at most k distinct elements 2: Threshold T  X  0 3: L X  X  L 0 , L 1 , .. } // set of Doc Lists for each term in q 4: while ( Not All lists in L Have Been Exhausted ) do 5: for ( every List L  X  X  ) do 6: cand  X  getNext ( L ) 7: T  X  ( T  X  lastseen ( L ) + cand . score ) 8: X [ i ]  X  X  cand } 9: for ( every List L 0  X  X  , L 0 6 = L ) do 10: X [ j ]  X  RandomAccess ( cand , L 0 ) 11: F  X  merge ( X [ 0 ] , X [ 1 ] , ... ) 12: for every Interval I in F do 13: TopK . insert ( I , I . score ) 15: return TopK // Early Termination 16: return TopK  X  getNext ( L ), lastSeen ( L ) and TopK . last () are as in the TA Algorithm.  X  The X [ ] variables represent sets of intervals.  X  The RandomAccess () function is described in Procedure 1.  X  The use of the merge () function is shown in Figure (2).
After the sets of overlapping (sub)intervals from each List have been retrieved, they are merged to produce the fi-nal set F , consisting of segments included in bursty in-tervals for all the terms of the query (Line 11 of Algo-rithm 3). Figure (2) shows an example of the merging process for a query q = { t 0 , t 1 , t 2 , t 3 } . The interval-set X [0] contains only one interval: the candidate, selected un-der sorted access from the bursty-interval list of term t Also, X [1] , X [2] and X [3] contain intervals that overlap with the candidate, retrieved by applying the RandomAccess Pro-cedure on the bursty-interval lists of terms t 1 , t 2 and t respectively. According to Definition 3, only the interval I = [5 : 7] qualifies as bursty with respect to q . Follow-ing Eq. (5.2), the burstiness score of candidate I is equal to P t  X  q B ( t, super ( I t , I )) = 6 + 4 + 5 + 4 = 19. The top-k set produced by TA  X  optimally solves the Inter-val Evaluation Problem . The reported intervals reveal bursty periods for any multi-term query. This allows us to not only locate events correlated with particular terms, bu t also estimate their lifespan. Further, the framework can be easily extended to report the documents that appear within each interval, and also contain all the query terms. Thus, we can obtain ranked groups of documents, where each group is relevant to a specific bursty period. Clearly, this is more informative than a mechanism that simply reports k docu-ments from completely arbitrary timestamps.

In this section, we illustrate the efficacy of our search framework through a rigorous experimental evaluation. Sec -tion 6.1 describes the datasets we used. Section 6.2 discuss es the different burst-detection methods used in our experi-ments. Finally, Sections 6.3-6.5 evaluate our search frame -work in different scenarios.
Newspaper Datasets : We have conducted a series of experiments using real-world datasets from the Center for Bibliographical Studies and Research (CBSR) at the Uni-versity of California, Riverside (UCR). CBSR has received two grants from the National Endowment for the Humanities to participate in the National Digital Newspaper Program (NDNP). The NDNP is a joint venture of the National En-dowment for the Humanities and the Library of Congress to create a national digital newspaper resource, representin g papers from all states, published between 1836-1922.
For the experimental evaluation we have gathered over 390,000 articles from the San Francisco Call , a daily news-paper with publication dates between 1900-1909. After the removal of stopwords, approximately 120,000 distinct term s were identified. We have several attributes for each arti-cle, including the title, the date of publication, and the ra w (punctuation and capitalization included) content. Due to the age and size of the corpus, some issues were not located for digitization, leaving small gaps in the data set. To ad-dress this, we extracted 3 independent document sequences from the data, for which all the articles were available: These large sequences of chronologically ordered articles will serve as datasets for the experiments described in this sec-tion. The data is available on request.
 Major Events List : In order to perform a qualitative eval-uation of our approaches, we manually composed a list of major events that took place at a time covered by one of the three Newspaper Datasets . The events were taken from Wikipedia (www.wikipedia.com), which maintains an-nual lists of major events. For every event, a query was composed, consisting of keywords chosen for their particu-lar significance with respect to the event. Table (3) contain s the list of events and their respective queries.
Throughout the experiments section, we evaluate the per-formance of the proposed search frameworks, using the MAX-1 and MAX-2 algorithms, described in Section 4, to obtain the required bursty intervals. As an alternative, we try the popular burst-detection method proposed by Kleinberg in [13]. This algorithm is based on a Hidden Markov Model, with states that correspond to frequency levels for individ -ual terms. State transitions (bursts) correspond to points in time, around which the frequency of a term changes signifi-cantly. Given the frequency sequence Y t of a term t , dynamic programming is used to fit the most possible state sequence that is likely to have generated Y t . The state assigned to each interval will serve as its burstiness score, which is re -quired by our framework. For the rest of this paper, we refer to this algorithm as KLEIN .

The states reported by KLEIN form a hierarchical struc-ture, with a long burst of low intensity including several bursts of higher intensity. Clearly, this violates our requ ire-ment for non-overlapping bursty intervals. To address this , we give priority to higher-state intervals, by assigning to every timestamp i the highest state observed over all the reported intervals that include i . To be fair, if the length of the highest-state interval is too small( &lt; 3), we take the interval with the second-highest state. We believe this to b e a reasonable and intuitive aggregation method.

Further, by assigning a high cost to state transitions, one can restrain the number of states in the hierarchy reported by KLEIN , thus eliminating short bursts and leading to longer intervals. Reasonably long intervals that reflect the true lifespan of an event are desirable, since they are likely to contain more relevant documents. On the other hand, the assignment of very high costs will limit the score-space to a small set of (low-intensity) states. Consider having to ran k 10 documents based on their state, where each document has 1 of 2 distinct states; inevitably, multiple ties will le ad to a meaningless ranking. For our experiments, KLEIN was tuned to find a balance between reasonably long intervals and an adequate number of distinct states. Note that our parameter-free algorithms resolve such issues by using the concept of the maximal segment to automatically extend a segment as long as it can benefit its score.
The purpose of this experiment is to evaluate the Docu-ment Evaluation framework described in Section 5.1. The evaluation is done as follows: First, an inverted index is bu ilt on top of each on the three Newspaper Datasets , as de-scribed in Section 5.1. Then, the queries from the Major Events List are evaluated using the TA Algorithm. Queries mapped to events from 1900 and 1901 are evaluated using the index built on top of SF-Call-1 and so forth. The en-tire process is repeated 3 times, each time using one of the three burst-detection algorithms ( MAX-1 , MAX-2 and KLEIN ) to build the search framework. We also compare against Lucene (lucene.apache.org), a popular text-search engine. Lucene uses frequency-based measures such as the frequency of the term within each document and the term X  X  global fre-quency to rank documents in the context of a given query.
A human annotator studied each of the top-10 documents reported for each event, marking them as  X  X elevant X  X r  X  X on-relevant X . This allows us to evaluate the achieved precisio n, defined as the ratio of the number of relevant documents over the total number of retrieved documents. The results are shown in Table (1). The table contains a separate column for the achieved recall in the top-5 documents, to provide more insight on the quality of the produced ranking. Our framework performs consistently well, clearly outperform ing Lucene in almost every case. Regarding the different burst detection algorithms, MAX-1 and MAX-2 achieved near-perfect precision values for all submitted queries. KLEIN  X  X  precision was just as good, although it failed to retrieve any docu-ments for 5 of the 16 queries. This can be due to the fact that KLEIN did not identify any intervals as bursty for all the terms in the query. Alternatively, even if such a region was identified, it did not include any documents containing all the query-terms. This could be addressed by separately tuning the parameters of the algorithm for each term. In practice, however, this is not desirable for obvious reason s. The purpose of this experiment is to evaluate the Interval Evaluation framework described in Section 5.2. The experi-ment is similar to the one described in the previous Section. In this case, the index built on top of each of the Newspa-per Datasets was the one described in 5.2, which considers term burstiness to index intervals rather than documents. Also, the TA  X  Algorithm was used to evaluate the queries from the Major Events List . For each event, we identify the interval among the reported 10 that is closest to the actual date of the event. We then report the start and end dates of that interval. The process is again repeated 3 times , each time using one of the three burst-detection algorithms . The results are shown in Table (4).

Both MAX-1 and MAX-2 produce reasonable intervals for the evaluated queries. As anticipated, MAX-2 gives tighter inter-vals, which commonly span a few days or weeks around the actual date of the event. The intervals produced by KLEIN are of similar or smaller length. Also, no bursty intervals were identified for queries 3, 5, 12, 14 and 16. As discussed in Section 6.2, even though the algorithm could be tuned to report larger segments, this would also reduce the number of states and thus have an adverse effect top-k evaluation. In general, KLEIN produced accurate results, indicating that our search framework is compatible with any efficient burst-detection method. Finally, it is also important to note that , for all three algorithms, the intervals closest to the actua l event date were always ranked first in the top-10 list. In order to illustrate the utility of the proposed Interval Evaluation Framework, we do an additional experiment: let A be the set of all articles within the interval reported by a query. Also, let V be the set of distinct terms appearing in the titles of the articles in A . We then report the top-10 terms from V , ranked in descending order on the number of titles they appeared in. For lack of space, we only report the results reported by MAX-2 , since it produced the most rea-sonable intervals for all the queries in the Major Events List . The results, shown in Table (5), prove that the docu-ments of a top-k interval can be used to identify terms that describe the underlying event. In the context of a search engine, these terms can compose an informative cloud that suggests insightful queries to the user.
In this experiment, we show that, by focusing only on bursty intervals, we can greatly reduce the number of doc-uments mapped to each term. This fact, combined with the high-quality results shown in the previous experiments , proves that our index structure is compact, while preservin g all the useful information for each term.

First, we build the Document Evaluation framework, de-scribed in Section 5.1, for each of the three Newspaper Datasets . For each dataset, we compute the average num-ber of documents mapped to a term. The process is re-peated 3 times, once for each of the three burst-detection algorithms. We compare against Lucene, which essentially maps each term to all the documents that include it. A sim-ilar evaluation is done for the Interval Evaluation Frame-work, described in Section 5.2: for each term, we compute the percentage of the timeline (spanned by each collection) that is covered by bursty intervals. We then report the av-erage over all terms. The results are shown in in Table (2). As can be seen from the Table, our framework achieves a significant reduction in the number of documents. As antic-ipated, MAX-2 and KLEIN result in higher reductions, since they generally produce smaller intervals. Further, only a small percentage (as low as 8%) of the timeline is covered by bursty intervals. Nonetheless, as illustrated by our previ ous experiments, these intervals provide all the information t hat our search framework needs to effectively evaluate queries.
In this paper we explored how term burstiness can be used to enhance the search process for large document sequences. We provided a formal definition of burstiness and proposed efficient, parameter-free algorithms for the identification of bursty intervals for any given term. The main contribution of our work is an efficient search framework that considers term burstiness in the indexing and ranking process. We describe two alternative versions of our framework, and dis -cuss how they can be useful to a user querying a document sequence. Finally, we thoroughly evaluated our approaches on a new dataset, in the context of different scenarios. This work was supported by NSF IIS-0534781, NSF 0803410, the ONR N00014-07-C-0311 Aware, the Health-e-Child, and the SemsorGrid4Env projects.
ID Description Date Query
