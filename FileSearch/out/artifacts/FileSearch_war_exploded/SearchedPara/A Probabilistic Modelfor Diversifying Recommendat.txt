 Many online services, such as Amazon 1 ,Netflix 2 , and YouTube 3 , employ rec-ommender systems because they are exp ected to improve user convenience and service provider profit [6, 10, 12, 18]. This is promoting a lot of research on recommendation methods [1]. Many conventional recommendation methods are accuracy -oriented, i.e., their goal is to accurately predict items that the user will purchase in the future.

These accuracy-oriented algorithms, ho wever, sometimes degrade user satis-faction. The recommendation results are often presented to users in the form of a multiple item list, not one single item. The recommended items in a list gen-erated by an accuracy-oriented method o ften have similar content. According to [21], since such a list reflect only partial aspects of the user X  X  interests, it cannot necessarily satisfy the user.
Researchers have recently addressed this problem by focusing on the diversity of recommendation lists [9, 11, 17, 19, 21]. This novel evaluation metric indicates balance of recommendation list entries, i.e. how well they satisfy the active user X  X  full range of interests.
 This paper proposes a theoretical met hod to diversify recommendation lists. Our method make a recommendation list so as to maximize the probability that a user purchases at most one item from the list. While exactly optimizing our objective function is difficult, we derive a greedy heuristic for approximately optimizing it. Consequently, the diver sity of the recommendation lists offered by our method is naturally enhanced. Specifically, estimating the probability that a user will purchase the l th item from the list requires us to consider, in addition to the user X  X  preferences, the additional condition that the first l  X  1th items are not purchased. This additional condition suggests that the l th item should be dissimilar to the first l  X  1items.

We formulate a model and its parameter estimation for our method by setting the following three policies as: First, we reduce the number of parameters for the robust estimation. Second, parameters are estimated only from purchase history, which can be automatically collected. Collecting the other kinds of information used by conventional methods, such as item taxonomy [21] and ratings [11, 17, 19] requires some manual tasks. Finally, we avoid the use of hyperparameters in con-trolling the trade-off between accuracy and diversity, unlike [9, 17, 21]. Determin-ing such hyperparameters is difficult, since we do not know the optimal balance between them that will maximize end-user satisfaction in advance.

The rest of this paper is organized as follows. In  X  2, we explain the detail of our method. In  X  3, we formulate a model and its parameter estimation for our method. In  X  4, we briefly review related work. In  X  5, we formally and experimentally evaluate our method, by comparing it with conventional methods. Finally, we offer concluding remarks and a discussion of future work in  X  6. Our method offers a recommendation list consisting of L items maximizing the probability that a user u purchases an item from the list. Our objective function for determining the recomme ndation list is as follows: the l th item is purchased or not ( y l = 1 if purchased, y l = 0 if not). On the other hand, the objective function of a con ventional accuracy-oriented method is individually set for each item in the list without considering a purchase from the whole list [2].

Here, we assume that the target user purchases at most one item from the list. This assumption is based on the behavior of many actual recommendation services, such as on Amazon.com. On th ese services, a user cannot purchase multiple items from a list, since the screen is transited when the user selects (click a link) an item from a recommendation list.

We use the greedy algorithm because exa ctly maximization of the objective function expressed by Eq. (1) falls into a combinatorial optimization problem, which is difficult in general. Since many users decide whether to purchase each item in the list in order of rank, applying the greedy approach seems reasonable.
The first item can be easily obtained by maximizing P ( y 1 =1 | u, i 1 )asis done in conventional methods. Having chosen the first item i 1 , we determine the expand P ( y 1 =1  X  y 2 =1 | u, i 1 ,i 2 )as: where the partitioning of the event of y 1 =1  X  y 2 = 1 into the disjoint events y 1 =1and y 1 =0 line is based on the independence of y 1 and i 2 . Since only the second factor in this equation depends on i 2 , we can formulate the probability that the user u selects the second item i 2 from the list as follows: Recursively, we can express the probability that the user u selects the l th item i from the list as follows: This probability means that for choosing i l according to our two assumptions, we should take into account not only the target user u but also the condition that items i 1 ,...,i l  X  1 are not purchased. We formulate a model and its parameter estimation for our method based on the following three policies: 1. We reduce the number of parameters for the robust estimation. The direct 2. We use only purchase history, which can be automatically collected. This 3. We avoid the use of hyperparameters in controlling the balance between We expand Eq. (2) in accordance with Bayes X  rules as follows:
P ( y l =1 | u, i l ,y 1 =0 ,...,y l  X  1 =0 ,i 1 ,...,i l  X  1 ) We approximate the numerator of Eq. (3) so as to satisfy the policies. First, to satisfy the first policy, we assume that y l (the event that i l is purchased) is independent of the items shown before, and the first factor becomes as follows: The probability expressed as the right hand side can be equivalent to the rec-ommendation score of conventional accuracy-oriented methods, and thus can be regarded as a personalization factor focused on accuracy. To satisfy the first and the third policies, we approximate the second factor by assuming the inde-pendence of y 1 =0 ,...,y l  X  1 = 0 (the event that the first l  X  1 items are not purchased) and u (the target user) as: The probability expressed as the second line is high when i l is dissimilar to the past items, i 1 ,...,i l  X  1 , and thus can be regarded as a diversification factor that ensures diversity. This probability does not depend on any hyperparame-ters controlling diversity. Additionally, to satisfy the first policy, we assume the conditional independence of the event that the l th item is not purchased and the event that the l th item is not purchased given the event that l th item is purchased as: We also approximate the denominator of Eq. (3) in the same manner as the numerator.

In summary, the probability that u will purchase the l th item from the list canbeexpressedasfollows: The number of parameters in this model is O UN + N 2 , which is far smaller than O UN l , the number in the model expressed by Eq. (2).

We approximate the personalization factor as follows without considering po-sition l : where y is a binary variable representing the event that item i is purchased or not ( y = 1 if purchased, y = 0 if not). For the second policy, we estimate the per-sonalization factor by analyzing purchase history via Latent Dirichlet Allocation ( LDA ) [2], since it can offer high recommenda tion accuracy with only purchase history. With LDA, P ( i | u ), which is the probability that the user will choose i from items 1 ,...,N , is estimated instead of P ( y =1 | u, i ) for recommendations. For estimating the probability expressed as Eq. (4), we formulate the estimation of P ( y =1 | u, i )using P ( i | u ). Since the order of the recommendation list for each user must remain after the conversion, we assume that the ratio between P ( y =1 | u, i )and P ( i | u ) depends on only the user and is independent of each item as follows: In accordance with Bayes X  rule,  X  u becomesasfollows: where, for the readability, we skip the detailed derivation of  X  u .Once P ( y = 1 | u, i ) is estimated, we can easily estimate P ( y =0 | u, i ) included in the denomi-nator of the Eq. (4) as 1  X  P ( y =1 | u, i ). With LDA, first we assign latent topics to the past purchases using collapsed Gibbs sampling [7], and then P ( i | u )is calculated as: P ( i | u )= where Z is the given number of topics, M u is the number of u  X  X  purchases, z um is the assigned latent topic for the m th purchase of user u , i um is the item in the m th purchase of user u , I [  X  ] is the indicator function, and  X  and  X  are Dirichlet parameters. Z can be easily determined by cross validation as minimizing the prediction error metric, which is called perplexity , and Dirichlet parameters  X  and  X  can be inferred via Minka X  X  fixed point iterations [13]. An expression for the MAP estimation of P ( y =1 | u ) using purchase history can be written as: where  X  is a hyperparameter for smoothing. The numerator of this expression is the number of items which u purchased.

We approximate the diversification factor without considering positions l and l as follows: where y represents the event that item i is purchased or not ( y = 1 if purchased, y = 0 if not).

For the second policy, we formulate the MAP estimation of this approximated diversification factor from the purchase history as follows: where  X  is a hyperparameter for smoothing. The denominator of this expression is the number of users who have purchased item i , and the numerator is the number of users who have purchased item i but not item i . Recently, diversification of recommendati on lists has targeted by many researchers [9, 11, 17, 19, 21] since it is known to be an important factor in improving user satisfaction through recommendations. [21] proposed a re-ranking algorithm that uses item taxonomy to realize topic diversification. Their method can control the trade-off between accuracy and diversity by using a hyperparame ter determined in an actual user experiment. [9] formalized the intra-listtopic diversification problem by addressing a multi-objective optimization problem on diversity and preference similarity. [11] proposed a method to make diversified recommendations over time, and discovered the negative correlation between user profile length and the degree of recommendation diversity. [19] raised the issue of evaluating the novelty and diversity of recommendations. [17] studied the adaptive diversification problem for recommendations by connecting latent factor models with portfolio retrieval.
Additionally, in the area of information retrieval and Web search, many re-searchers have studied the diversity of search results [3 X 5, 8, 14 X 16]. In particu-lar, [4] is strongly related to our work since they are pioneers in the use of the probabilistic approach to list diversification. Our method can be positioned as an extension of [4] to recommendations. We expand Eq. (1) to Eq. (2) in the same manner as the greedy approach to maximize the probability that least one document in the search results is relevant. 5.1 Formal Evaluation First, we evaluated our method formally in terms of practicality, by comparing it to conventional methods for diversifying recommendation lists. We pick up three conventional approaches, which we label Ziegler [21], Hurley [9], and Shi [17].
First, our method and Hurley do not require any manual tasks for generating information sources, while Ziegler and Shi do. Ziegler uses item taxonomy, which is manually provided by service developer. Shi uses ratings, which are manually given by users. On the other hand, our method and Hurley work even if only the purchase history is available, and thus allow us to skip such manual tasks.
Second, our method and Shi do not use any hyperparameters for controlling the balance between accuracy and diversity, while Ziegler and Hurley do. Accord-ing to [21], there is a trade-off between a ccuracy and diversity, and balancing the two maximizes end-user satisfaction. This balancing operation varies with the service and/or the dataset, so a par ameter tuning is needed to determine the optimal balance. In general, such tuning is difficult since it requires end-user experiments.

To summarize, we formally demonstrated that our method is superior to con-ventional methods in terms of practicality. 5.2 Experimental Evaluation Dataset. We experimentally evaluated our method using the MovieLens-1M dataset 4 . This publicly available dataset contains 1M ratings from about 6K users on about 3.7K items. The data sparseness is 95.5%. Each user in this dataset has at least 20 ratings. Additionally, genre labels of the items are pro-vided. There are 18 genres, and each item can be associated with multiple genres. The average number of genres per items is 1.62. Note that we interpreted the MovieLens data as purchase data and discarded the ratings.

We evaluated our method by 5-fold cross validation. That is, we randomly partitioned the data into 5 subsets. Of the 5 subsets, we held-out a single subset as the test data (for evaluation), and we used the remaining 4 subsets as training data (for estimating parameters), where we removed movies not appearing in the training data from the test data and user-item pairs contained in the training data from the test data. Then we repeated this cross-validation process 5 times, with each of the 5 subsets used exactly once as the test data. Finally, we averaged the 5 results to produce a single estimation.
 Compared Methods. We compared the following recommendation methods in terms of recommendation a ccuracy and diversity: 1. Proposed : This is the method we propose. In this paper, we used hyperpa-2. Non-diversified : Straight collaborative filtering using LDA [2]. The list of-3. Ziegler : The diversification method proposed by Ziegler et al. [21]. We used Result. In our experiments, we evaluated the accuracy and the diversity of the recommendation lists produced by the three methods.

We used precision , micro-averaged recall ,and macro-averaged recall curves to measure accuracy. It is important to us e both micro-and macro-averaged recall [20], as micro-averaged metrics stress performance on prolific users, while macro-averaged ones target those with few transactions. Both are used in this paper for fairness and for detail. The formulae of precision@ K , micro-averaged recall@ K , and macro-averaged recall@ K are given below: mended items to u . Figure 1 show the recommenda tion accuracy of compared methods via precision, micro-averaged r ecall, and macro-averaged recall curves. These results reveal that our diversific ation also degrades the accuracy as does Ziegler . The precision curves show that our m ethod is of practical use because its loss in accuracy at high rank is less pronounced than is true for Ziegler . Specifically, our method degrades the accuracy less than Ziegler at the high rank ( K  X  5), but the accuracy curves for o ur method drastically drop, and our method is then outperformed by Ziegler at the low rank ( K&gt; 8). Compar-ing micro-averaged and macro-averaged recall, the drop of our method is less for macro-averaged recall than for micro-averaged recall. This result means that our method can offer more accurate r ecommendations to the users who make few purchases.

To measure diversity, we employed intra-list similarity and original list overlap as used in [21]. Intra-list similarity is calculated as follows: where  X  i uk is the k th recommendation to u ,andsim(  X  ) is the item similarity measured by the metric proposed in [22]. The original list overlap can be calcu-lated by counting the number of recommended items that stay the same after the diversification. Higher values of thes e metrics denote lower diversity. Figure 2 shows recommendation diversity of the compared methods based on intra-list similarity and original list overlap. These figures reveal that our method can increase diversity even though it uses only purchase history. From Figure 2 (a), we found that our method can significantly lower the taxonomy-driven pairwise similarity in lists without recourse to item taxonomy. Specifically, in Figure 2 (a), the curve of our method is closer to the Ziegler curve than to the Non-diversified curve. Figure 2 (b) demonstrates that both diversification meth-ods change recommended items drastically. For the top-10 recommended items, only 3 items remain after diversification.

Finally, we investigate the combinat ion of accuracy and diversity via  X  DCG [5] using the genres in MovieLens dataset: where G is the number of unique genres,  X  i uk is the k th recommendation to u , g are the genres assigned to item i , q u g,k  X  1 denotes the number of items ranked up to position k  X  1 that contain genre g in the recommended items to u .  X  is a constant controlling the magnitude of the penalty placed on recommendation redundancy. Higher values of  X  indicate larger penalties. In our experiments, we used the setting discussed based on the official TREC judgments for QA tasks in [5]:  X  =0 . 36. Although  X  DCG is originally normalized via  X  IDCG as  X  NDCG, we skipped normalization because our fo cus in this experiment was to compare diversification methods. Figure 3 shows the  X  DCG scores of the compared meth-ods. This figure shows that our method is competitive with Ziegler at the high rank ( K  X  5).

Table 1 illustrates three sampled items from this user profile and an example of the recommendation lists made by the three compared methods. From the profile, we can see that this user watches various kinds of action movies. Intu-itively, this example shows that our met hod produced a moderately diversified recommendation list: The list includes three action movies, two comedy movies. Ziegler yielded a similar recommendation list. On the other hand, the list offered by Non-diversified is overly focused. Specifically, it provides only similar action movies.
To summarize, we experimentally demonstr ated that end-user satisfaction for the recommendations via our method may be competitive with Ziegler in terms of accuracy and diversity. We developed a new method to diversify recommendation lists. Our key advances were to naturally derive a diversification method by determining a recommenda-tion list so as to maximize the probability that a user purchases at most one item from a list, and and formulate a model and its parameter estimation based on several policies. In this paper, we formally showed that our method can, unlike conventional methods, avoid manual tasks such as the collection of information and the control of the balance between a ccuracy and diversity. Additionally, ex-periments on a real-world data set demonstrated that our method is competitive with the conventional methods in terms o f accuracy and diversity. These results suggest that our method is practically promising.

Future work involves three issues. First, we would like to extend our method to use recommendation information other than purchase history such as item metadata automatically drawn from external knowledge bases. Second, we will examine the effectiveness of diversificat ion parameters, which are not used in the current model. We would like to formulate a new model that uses a param-eter to control the trade-off between accu racy and diversity , and automatically estimate this parameter from user behavior logs. Finally, we would like to apply our method to an online store and examine how well it can enhance end-user satisfaction.
 Acknowledgements. We would like to thank the GroupLens Research Group for the use of the MovieLens 1M dataset.

