 1. Introduction
Video surveillance systems are very essential for safety and security. Actually, the automatic surveillance system has tremen-dously progressed due to the high applicability in public institu-tions, private firms, and houses. In fact, smart surveillance is a hot issue of extensive research, such as human actions recognition ( Park and Aggarwal, 2004 ), traffic flow visualization ( Shastry and Schowengerdt, 2005 ), association analysis of home videos ( Pan and Ngo, 2007 ), home activity recognition ( Naeem and Ham, 2009 ), explorative visualization and analysis ( Buter et al., 2011 ), telecommunication applications ( Rahman and Pathan, 2011 ), human X  X achine interaction ( Halim et al., 2011 ), and many others. In the developing video surveillance systems, several significant functionalities must be taken into consideration, but not limited to, motion detection ( Wren et al., 1997 ; Manzanera and Richefeu, 2004 , 2007 ; Shoushtarian and Ghasem-aghaee, 2003 ; Wang et al., 2008 ), tracking ( McFarlane and Schofield, 1995 ; Stauffer and Grimson, 2000 ), identification ( Wang et al., 2003 ; Hayfron-acquah et al., 2003 ; Chong and Tanaka, 2010 ), data hiding ( Wang et al., 2010 ), and feature recognition ( Panganiban et al., 2011 ). This paper focuses on the design of motion detection since the first function significantly affects the performance of the surveillance system.

In general, motion detection can be performed by three categorized methods, including temporal difference, optical flow, and background subtraction methods ( Hu et al., 2004 ). Temporal difference method can effectively accommodate environmental changes, but the shapes of moving objects are often not complete.
On the other hand, optical flow method generally shows the projected motion on the image plane with good approximation.
However, one common limitation of optical flow is that the computational complexity is often too high, making it difficult to implement. Background subtraction method consists of detect-ing moving objects that deviate from a maintained up-to-date background model. This is the most popular method for motion detection because it requires less computational complexity and provides high quality motion information. In other words, the background subtraction method is the most effective way to solve motion detection problems. The existing method of background subtraction computes the absolute difference between each pixel of the incoming video frame and background model. The thresh-old is then applied to get the binary motion detection mask ( Pai et al., 2010 ). Although the existing background subtraction method can be easily implemented, threshold selection is still a critical operation for the noise immunity.

In order to distinguish background and foreground components, spectral, spatial, and temporal features are usually extracted from video sequences. Spectral feature s represent the gray-scale of an image frame. Spatial features are associated with regional variations of the local structure in the same frame. Temporal features represent changes in pixels within video streams. The organization of exis-ting background models are broadly classified into pixel-based methods and block-based methods. Pixel-based methods use gray-level changes for each pixel in the video sequence to represent the spectral and temporal features. Bl ock-based methods utilize varia-tions within spaces between differe nt frames for the representation of spatial and temporal features.
 rates both pixel-based and block-based methods to represent the spectral, spatial, and temporal features in a video stream. The organization of the proposed method is as follows: (1) An intelligent matching process that uses both pixel-based (2) Using Bezier curve smoothing method to suppress the possi-(3) Achieving complete motion detection through the proposed the most effective, as indicated by the qualitative and quantitative results of the performance study, which presented a wide range of natural video sequences. The rest of this paper is organized as follows: Section 2 gives a fairly compact overview of some of the compared approaches for background subtraction. Section 3 describes the proposed method in detail. Section 4 reports the experimental results and discusses this paper. Section 5 contains our concluding remarks. 2. Related work improved motion detection masks that are able to detect moving objects completely. Some state-of-the-art methods of background subtraction include Simple Background Subtraction (SBS), Run-ning Average (RA) ( Wren et al., 1997 ), S -D Estimation (SDE) ( Manzanera and Richefeu, 2004 ), Multiple S -D Estimation (MSDE) ( Manzanera and Richefeu, 2007 ), Simple Statistical Difference (SSD), Temporal Median Filter (TMF) ( Shoushtarian and Ghasem-aghaee, 2003 ), and Running Average with DCT domain (RADCT) methods ( Wang et al., 2008 ).
 which contains static background of the observed scene, and the incoming video frame I t  X  x , y  X  , which possibly contains the moving objects and the background. The reference image B  X  x , y  X  and the incoming video frame I t  X  x , y  X  are taken from the video sequence. A binary motion detection mask D  X  x , y  X  is calculated as follows:
D  X  x , y  X  X  where t is an empirically selected threshold to distinguish pixels with either the moving objects or the background in an image frame.
 current image frame exceeds t , the pixels of the detection mask are labeled with  X  X 1 X  X  which means it contains moving objects; otherwise non-active ones are labeled with  X  X 0 X  X . The primary problems of the SBS method are the noise in the incoming video real video sequences.
 an up-to-date background model using the RA method to adapt the temporal changes in the video sequence. Different from the
SBS method, the RA background model guarantees the reliability of motion detection because each background image frame B of the adaptive background model is updated frequently. The current background image is integrated into the new incoming video frame I t  X  x , y  X  and the previous background frame B
The adaptive background model is achieved by the following first-order recursive filter:
B  X  x , y  X  X  X  1 b  X  B t 1  X  x , y  X  X  b I t  X  x , y  X  ,  X  2  X  where b is an empirically adjustable parameter. While faster background adaptation can be performed with a greater para-meter b , the production of artificial  X  X  X host X  X  trails is also caused behind moving objects in the adaptive background model.
Based on the generated adaptive background model, the binary motion detection mask D  X  x , y  X  is defined as follows:
D  X  x , y  X  X  where I t  X  x , y  X  is the current incoming video frame, B current background model, and t is an experimentally predefined threshold by which the binary motion detection mask can be detected.

SDE method : This method computes the temporal statistics for the pixels of the original video sequence based on the pixel-based decision framework. In the first background estimate, the com-putation uses the sgn function to estimate the background value.
The sign function sgn can be expressed as follows: sgn  X  a  X  X  where a is the input real value.

Based on sgn function, the background estimation can be expressed as the following recursive filter:
B where B t  X  x , y  X  is the current background model, B t 1 previous background model, and I t  X  x , y  X  is the current incoming video frame. The intensity of the background model increases or decreases by a value of one through the evaluation of the sgn function at every frame.

The background model is estimated through the sgn function for a simple increment or decrement of one at every frame. Then the absolute difference D t  X  x , y  X  is computed as the differential estimate between I t  X  x , y  X  and B t  X  x , y  X  :
D  X  x , y  X  X  9 I t  X  x , y  X  B t  X  x , y  X  9 :  X  6  X 
Similarly, sgn function is also used to compute the time-variance V t  X  x , y  X  representing the measure of motion activity to decide whether the state for each pixel belongs to  X  X  X ackground X  X  or  X  X  X oving object X  X :
V vious time-variance, and N is the predefined parameter which ranges from 1 to 4.

Based on the generated current time-variance V t  X  x , y  X  , the binary motion detection mask D  X  x , y  X  is detected as follows:
D  X  x , y  X  X 
MSDE method : Nevertheless, the SDE method is characterized by its updating period with a constant time to build a background model, which induces a limitation in certain complex scenes, typically in some cases of scenes with a lot of moving objects, or with the moving objects slowing down or stopping. Therefore, the
MSDE method was developed in order to solve the problem. The adaptive background model of MSDE method can be expressed as the following formula: b  X  x , y  X  X  b i t 1  X  x , y  X  X  sgn  X  b i 1 t  X  x , y  X  b i where b i t  X  x , y  X  is the current i -th reference background, b the previous i -th reference background, and b i 1 t  X  x , y  X  is the current i 1-th reference background. Additionally, the reference difference D i t  X  x , y  X  and reference time-variance v i computed: v  X  x , y  X  X  v i t 1  X  x , y  X  X  sgn  X  N D i t  X  x , y  X  v i where D i t  X  x , y  X  X  9 I t  X  x , y  X  b i t  X  x , y  X  9 .
The confidence adaptive background model B t  X  x , y  X  can be formula as follows: B  X  x , y  X  X  where each a i is the predefined confidence value, i is the reference number, R is the total number of i ,and B t  X  x , y  X  is the confidence adaptive background model. According to Manzanera and Richefeu (2007) , R is experimentally set to 3 and confidence values a are set to 1, 8, and 16, respectively.
 SSD method : Based on mean value and standard deviation, the SSD method uses the individual pixels of the incoming frame to construct more advanced background models that can be orga-nized by calculating the mean value of the previous frame. Each pixel value m xy of the background image is produced from a collection of previous frames in the time interval  X  t 0 , t pixel, a threshold is also represented by the standard deviation xy in the same interval:
Motion detection can be achieved by computing the absolute difference between the incoming video frame and the background model, where l is the predefined parameter. The pixel is a part of moving objects if the absolute difference is larger than l s otherwise it belongs to background: D  X  x , y  X  X  Empirically, l experimentally set to 3 yields much better results for motion detection.
 RADCT method : The developed method modifies the traditional RA method to model the adaptive background in the DCT domain, corresponding to the same function in the spatial domain. The adaptive background model can then be expressed as follows: d t  X  X  1 b  X  d where b is an empirically adjustable parameter similar to that used in the traditional RA method, d k t denotes the DCT coefficient vector of the k -th pixel block for the current incoming video frame, d B , k t denotes the background estimation of the k -th pixel block in the DCT domain, and d B , k t 1 denotes the previous back-ground estimation.

Compared with the traditional RA method, the RADCT algo-rithm can save time if the video is compressed by DCT transfor-mation-based methods. Unlike the traditional RA method which uses the intensity of each pixel, the RADCT method is able to effectively generate the adaptive background using the DCT coefficient vector within each separate block instead of pixel values.

TMF method : This method statistically computes the temporal median value for each pixel in order to generate the adaptive term timer T L  X  x , y  X  which counts the number of frames in which a given pixel exists B L t  X  x , y  X  : T  X  x , y  X  X  level of the incoming pixels and increases the long term timer T  X  x , y  X  if it is within the tolerance t , after which the short term timer T S  X  x , y  X  counts the consecutive number of frames which are associated with the gray-level pixels: T  X  x , y  X  X 
If the short term timer T S  X  x , y  X  is greater than the long term timer T L  X  x , y  X  then the pixels of B L t  X  x , y  X  and B the new incoming frame I t  X  x , y  X  and the short term timer T can be subsequently reset to zero. If the long term timer T greater than the tolerance m then the long term timer T L be reset to m . According to Wang et al. (2008) , m is experimentally set to at least 10 X 15% of the number of frames in the test video sequence. 3. Proposed method
In this section, a novel flowchart of a background subtraction approach is presented. The proposed method makes use of spectral, spatial, and temporal features extracted from the video sequence in order to completely achieve high performance detection of moving objects.

Initially, the proposed background model adopts both block-based and pixel-based matching methods for selecting the back-ground candidates. After each background candidate is matched using the proposed intelligent matching procedure technique, each precise background candidate is selected as a replacement for the adaptive background model. In order to ensure that the results of motion detection are of the highest quality, adoption of noise reduction approaches is suggested after the background model is generated. For our approach, we propose the use of the
Bezier curve smoothing method to reduce the noise for motion detection based on our proposed adaptive background model.
As the final step of our process, the binary moving object detection mask is computed by the use of the suitable threshold which is then applied automatically through the proposed intel-ligent threshold selection procedure conducted by Probability
Mass Function followed by the Cumulative Distribution Function. 3.1. Background model
We propose a background model which employs a two-layered image pyramid structure in order to combine pixel-based and block-based matching methods that represent the use of the three features (spectral, spatial, and temporal) extracted from the video sequences.

An M N incoming video frame is defined as a two-dimen-sional array where x and y are spatial coordinates, and the amplitude of F t at any pair of coordinates ( x , y ) represents the video frame at the frame t of the video sequence. Each incoming video frame F t  X  x , y  X  exhibits M rows and N columns to represent rows and N = n columns to form the two-layered image pyramid structure. It is clear that the upper level f t can be seen as the base level F t , reduced n n times.

As shown in Fig. 1 , experiments lead us to form each pixel block to the image pyramid structure with n  X  2. As depicted, the upper left of F t has been formed into a 2 2 pixel block. Therefore, the original image can be separated into M N = 4 image blocks, where M N represents the image resolution. For each image block, the sum of absolute difference (SAD) is calculated as follows: SAD  X  where a 0 is the randomly sampled pixel, and  X  a 1 , a 2 , ... , a represents the other pixels set in this block. (1) Initialized Background Model : First, a recursive mean pro-cedure is used to calculate the mean of previous frames for the initial background model generation. For each pixel, the corre-sponding values of the current background model B t  X  x , y  X  are initialized as following recursive mean procedure:
B  X  x , y  X  X  where B t 1  X  x , y  X  is the previous background model, F current incoming video frame, and t is the frame number in the video sequence. In this paper, the number of previous frames is experi-mentally set at 100 to represent the initial background model. (2) Background Candidates Modes : As shown in Fig. 2 ,an example of sampled pixel is plotted for its gray-level variation over time. We can easily observe that pixel values can be formed by the stable signal (major part of the background) and fluctuant signal (moving objects) that occurs occasionally. In order to generate the background model effectively, the suitable back-ground candidates should be determined accurately based on our proposed two-phase matching method. The first basic matching phase is emphasized to search the block candidates expeditiously.
Then the ideal background pixels can be rigorously selected from the block candidates during the precise matching phase at each video frame.

By combing the two-layered image pyramid structure, the pro-posed intelligent matching proced ure (IMP) distinguishes between l the background and moving object pixels in the incoming frame of the video stream. The framework of IMP can be seen in Fig. 3 .It consists of the following steps: 1. Finding the block candidate of each incoming frame through the rough matching procedure. 2. Using the precise adaptive procedure to provide a measure of temporal activity of the pixels within each block candidate. 3. Determining the best background pixels through the precise matching procedure.

Rough matching : Initially, every block is examined expedi-tiously in raster scan order from left-top to right-bottom within a frame. Each stable SAD value m t  X  i , j  X  is obtained after the corre-sponding SAD value of the upper level f t is updated using the basic adaptive procedure, after which the block candidates are deter-mined by whether or not their respective stable SAD values m equal the corresponding SAD value of the upper level f t . The basic adaptive procedure is expressed as follows: m value m 0 is set to f 0 .

Precise adaptive procedure : All pixels from the block candidates are updated through the proposed precise adaptive procedure in order to obtain the best background pixels. The precise adaptive procedure can be expressed as follows: M
Note that M t  X  x , y  X  is the ideal background pixel within the block candidates and the coefficient Q is the same as the corresponding value in the adjacent block of m t  X  i , j  X  .

Precise matching for background updating : As shown on the right in Fig. 3 , after each corresponding pixel within the block candidate of M t  X  x , y  X  is updated, the background pixels of the incoming video frame F t  X  x , y  X  can be selected if the value of M equals the value of F t  X  x , y  X  . Based on the proposed matching procedure, all selected background pixels of F t  X  x , y  X  are supplied to update the high-quality background model B t  X  x , y  X  at each frame. 3.2. Noise filter
The background model is generated through the updating procedure according to IMP at each frame. The absolute difference
D  X  x , y  X  is then calculated as the differential estimation between incoming video frame F t  X  x , y  X  and the proposed background model
B  X  x , y  X  :
D  X  x , y  X  X  9 B t  X  x , y  X  F t  X  x , y  X  9 :  X  22  X 
During the acquisition and transmission of video, noise is inadvertently created by a variety of factors including commu-nication channels, electrical interference, sensor oscillation, and so on. The presence of noise may cause poor motion detection damaging the quality of the resultant video. Thus, complete noise filtration should be performed.

There are two mechanisms can be utilized to ensure high video expressed as follows:
N  X  x , y  X  X  where the tolerance t is defined to detect possible noise pixels in the detector N  X  x , y  X  which, if found, is labeled with  X  X 1 X  X . Those pixels that are unlabeled are designated as non-active.
This is completely contained in the convex hull of the selected control points and used to manipulate the curve intuitively, which is useful in a number of applications ( Crouch et al., 1999 ) such as the interpola-tion of global motions for the planar motion model ( Liang et al., 2008 ), the optimal shape of the minimized magnetic field ( Ziolkowski and Gratkowski, 2008 ), and approximation of the intra-video object plane for spatial error concealment of MPEG-4 Video ( Chen et al., 2005 ).
 We propose a noise filter that utilizes the Bezier curve method.
After a smooth curve is generated, the parametric point is determined to remove the possible noise pixels of D t  X  x , y  X  corre-sponding to N  X  x , y  X  , which is established by ranking the pixels contained in the w w mask of each possible noise pixel based on the order-statistic filter. In this paper, the mask size is experi-mentally set to 3 3. The pixels of the 3 3 mask are sorted and then calculated to the corresponding value through the Bezier curve smoothing method. For example, suppose that a 3 3 mask 5, 8, 9, 13) and employed as the control point for Bezier curve smoothing. Then the Bezier curve smoothing function of degree s can be defined as follows: P  X  s  X  X  where w 2 1 is the degree of the curve, C k is the control point, s is the predefined parameter which ranges from 0 to 1, and P ( s ) is the output value employed to replace the gray-level of noise pixel. In this paper, s is experimentally set to 0.5. The possible noise pixel in the center of the 3 3 mask is replaced by the Bezier curve smoothing result. 3.3. Motion mask generation
The gray-level brightness change can be observed by the obtained absolute difference D t  X  x , y  X  between the background threshold for binarization is the critical challenge. To solve this problem a two-phase function  X  Probability Mass Function (PMF) and Commutative Distribution Function (CDF)  X  is designed to produce the binary motion detection mask for the intelligent threshold selection.

Suppose that an input of absolute difference D t  X  x , y  X  composed of V discrete gray-levels, denoted by f L 0 , L 1 , ... , L PMF of L h is defined as PWF  X  L h  X  X  n h = n :  X  25  X  of n versus L h . The CDF based on PWF is then obtained by
CDF  X  L h  X  X 
Finally, the reported moving object detection mask of the video sequence frames is computed by the intelligent threshold selection es , where e is the predefined parameter which ranges from 1 to 1.5. The weighted mean value m is computed by using 0 50 100 150 200 255 l 0 1000 0 50 100 150 200 255 l t the CDF and is defined as below: m  X 
Then the weighted standard deviation s is calculated as follows: s  X  traction method has been built for performing vision processes in the detection of moving objects. To achieve this objective a number of modules are involved, including a background model generation module, a noise filter module, and a motion detection module, as illustrated in Fig. 4 . 4. Experimental results other state-of-the-art methods, experimental results have been produced for several natural video sequences and analyzed both qualitatively and quantitatively by our performance study.
Table 1 reports 12 different video sequences in representation of typical situations which are critical for video surveillance sys-tems. Both indoor and outdoor environments are presented with overall image size, noise level, object class, object size, and object number varying considerably from image to image.
 background model without any moving objects. There are some properties which are indicative of a high quality background model; these include stable background mo del adaptation, reduction of the probability of erroneous associations owing to noise, and artificial  X  X  X host X  X  trails created by cluttered motion.
 the background model of the different methods for a particular pixel extracted from a country scene for a 6000-frame sequence.
In this scene, many vehicles pass through a country road, which
In order to differentiate between the fluctuant signal of moving objects and those produced by the background, the output signal of the background should be more stable. Compared to other state-of-the-art methods, it is obvious to see that the output flatter than those of Fig. 5 (a) X (d).

For the background model image of the RD sequence, Fig. 6 shows the five representative frames and background images generated by the SDE, RA, TMF, MSDE, and our proposed method, respectively. The background images computed by our proposed model are illustrated in Fig. 6 (f). We can easily observe that our method can generate the accurate background image without the erroneous generation of the the background models generated in the ST video sequence by the
SDE, RA, TMF, MSDE, and our proposed method, respectively. The background images computed by our proposed model are illustrated in Fig. 7 (e). Here, it can be observed that our proposed model is the most successful in modeling background images compared with those of other methods.

In some video surveillance systems, the available resources are limited. In other words, the unfavorable artifacts may exist (system noise, block artifacts, etc.) in the video sequence. Hence, one of our significant targets is to improve the performance for the resource-limited surveillance condition. Fig. 8 illustrates the background model and the influence of noise standard deviation (STD) for the IR sequence. As shown in Fig. 8 (b), the noise STD significantly affects image quality that leads the low influence of performance in the surveillance system. After coping with this problem by the proposed noise filter module as shown in Fig. 8 (c), the influence of the noise
STD can be reduced to enhance the quality of the consequence for the further motion detection.

Experimental results of motion detection obtained by our proposed background subtraction method (PRO) are compared with those obtained through other state-of-the-art methods. For measuring the accuracy, both quantitative and qualitative evalua-tions were performed on several video sequences using different metrics, namely Recall , Precision ( Maddalena and Petrosino, 2008 ; Chen et al., 2008 ; Gualdi et al., 2008 ; Albanese et al., 2008 ), F ( Maddalena and Petrosino, 2008 ; Bartolini et al., 2001 ; Avitzour, 2004 ), and Similarity ( Maddalena and Petrosino, 2008 ).
Recall gives the percentage of necessary positives through the compared total number of true positive pixels in the ground truth. The formula of Recall can be expressed as follows:
Recall  X  tp =  X  tp  X  fn  X  ,  X  29  X  where tp is the total number of positive pixels, fn is the total number of false negative pixels, and  X  tp  X  fn  X  indicates the total number of true positive pixels in the ground truth.

Precision gives the percentage of unnecessary positives through the compared total number of positive pixels in the detected binary objects mask. The Precision can be expressed as the following formula:
Precision  X  tp =  X  tp  X  fp  X  ,  X  30  X  where fp is the total number of false positive pixels and  X  tp  X  fp  X  indicates the total number of positive pixels in the detected binary objects mask.

However, since only Recall measures the erroneous association of lost true positive pixels and only Precision measures the erroneous association of superfluous positive pixel they alone cannot offer an adequate comparison between the different methods.

Hence, two accuracy metrics, F 1 metric and Similarity are used to fairly measure accuracy by weighting the harmonic means of Recall and Precision :
F 1  X  2  X  Recall  X  X  Precision  X  =  X  Recall  X  Precision  X  X  31  X  and Similarity  X  tp =  X  tp  X  fp  X  fn  X  :  X  32  X 
Note that all metric-attained values range from 0 to 1 with higher values representing greater accuracy.
 sequence and the Similarity measures of their binary objects masks obtained by each method are shown in Table 2 . Here we can observe that, for almost every test sequence, the generated binary objects mask of the PRO method is more precise than those obtained by the MSDE, SDE, SSD, and RADCT methods.
 value of single frames compared above, the average accuracy values produced by using the F 1 metrics for all test sequences are reported in Table 3 . As a result, the PRO method attains the highest Similarity and F 1 values than other state-of-the-art meth-ods. In particular, the PRO method results in the only accuracy rate over 80% in the  X  X  X R X  X  and  X  X  X R X  X  sequences.

F 1 for the MSDE method were 57.52% or less and 75.11% or less, respectively; the accuracy rates produced by Similarity and F the SDE method were 73.02% or less and 72.00% or less, respec-tively; the accuracy rates produced by Similarity and F 1
SSD method were 69.20% or less and 65.56% or less, respectively; the accuracy rates produced by Similarity and F 1 for the RADCT method were 37.31% or less and 27.45% or less, respectively. 5. Conclusion background candidates based on the background matching fra-mework. After a high quality background model is generated, the
Bezier curve smoothing method can reduce possible noise pixels to refine the subtraction results for motion detection. Finally, an intelligent threshold function was proposed by PMF and CDF to detect objects pixels for video surveillance systems. Compared with other state-of-the-art methods, the efficacy of our method was demonstrated by quantitative and qualitative measurements.
As indicated by the results, our proposed method is effective and has the potential to be fully utilized in a wide range of natural video sequences.
 Acknowledgment
The authors would like to thank the National Science Council of the Republic of China, Taiwan, for financially supporting this research under Contract No. NSC 100-2628-E-027-012-MY3. References
