 Uppsala University University of Vigo tree. We propose a simple modification to the original system that enforces the tree constraint without requiring any modification to the parser training pr ocedure. Experiments on multiple languages show that the method on average achieves 72% of the error reduction possible and consistently outperforms the standard heuristic in curren t use. 1. Introduction
One of the most widely used transition systems for dependenc y parsing is the arc-eager system first described in Nivre (2003), which has been u sed as the backbone for greedy deterministic dependency parsers (Nivre, Hall, and Nilsson 2004; Goldberg and Nivre 2012), beam search parsers with structured predic tion (Zhang and Clark 2008; Zhang and Nivre 2011), neural network parsers with lat ent variables (Titov and Henderson 2007), and delexicalized transfer parsers (McDo nald, Petrov, and Hall 2011).
However, in contrast to most similar transition systems, th e arc-eager system does not guarantee that the output is a well-formed dependency tr ee, which sometimes leads to fragmented parses and lower parsing accuracy. Alth ough various heuristics have been proposed to deal with this problem, there has so far been no clean the-oretical solution that also gives good parsing accuracy. In this article, we present a modified version of the original arc-eager system, which is p rovably correct for the class of projective dependency trees, which maintains the l inear time complexity of greedy (or beam search) parsers, and which does not require a ny modifications to the parser training procedure. Experimental evaluation on the CoNLL-X data sets show that the new system consistently outperforms the standard h euristic in current use, on average achieving 72% of the error reduction possible (co mpared with 41% for the old heuristic). 2. The Problem
The dependency parsing problem is usually defined as the task of mapping a sen-tence x = w 1 , . . . , w n to a dependency tree T , which is a directed tree with one node for each input token w i , plus optionally an artificial root node corresponding to a dummy word w 0 , and with arcs representing dependency relations, optiona lly labeled with dependency types (K  X ubler, McDonald, and Nivre 2009). In this article, we will furthermore restrict our attention to dependency trees tha t are projective, meaning that every subtree has a contiguous yield. Figure 1 shows a labele d projective dependency tree.
 non-deterministic transition system for deriving depende ncy trees, guided by a statisti-cal model for scoring transitions from one configuration to t he next. Figure 2 shows the arc-eager transition system for dependency parsing (Nivre 2003, 2008). A parser con-figuration consists of a stack  X  , a buffer  X  , and a set of arcs A . The initial configuration for parsing a sentence x = w 1 , . . . , w n has an empty stack, a buffer containing the words w , . . . , w n , and an empty arc set. A terminal configuration is any configur ation with an empty buffer. Whatever arcs have then been accumulated in the arc set A defines the output dependency tree. There are four possible transit ions from a configuration Initial: ([ ], [ w 1 , . . . , w n ], {} ) Terminal: (  X  , [ ], A ) Shift: (  X  , w i |  X  , A )  X  (  X  | w i ,  X  , A ) Reduce: (  X  | w i ,  X  , A )  X  (  X  ,  X  , A ) HEAD ( w i )
Right-Arc: (  X  | w i , w j |  X  , A )  X  (  X  | w i | w j ,  X  , A  X  X  w
Left-Arc: (  X  | w i , w j |  X  , A )  X  (  X  , w j |  X  , A  X  X  w 260 where top is the word on top of the stack (if any) and next is the first word of the buffer: 1 1. Shift moves next to the stack. 2. Reduce pops the stack; allowed only if top has a head. 3. Right-Arc adds a dependency arc from top to next and moves next to the 4. Left-Arc adds a dependency arc from next to top and pops the stack;
The arc-eager system defines an incremental left-to-right p arsing order, where left dependents are added bottom X  X p and right dependents top X  X o wn, which is advanta-geous for postponing certain attachment decisions. Howeve r, a fundamental problem with this system is that it does not guarantee that the output parse is a projective dependency tree, only a projective dependency forest, that is, a sequence of adjacent, non-overlapping projective trees (Nivre 2008). This is dif ferent from the closely related arc-standard system (Nivre 2004), which constructs all dep endencies bottom X  X p and can easily be constrained to only output trees. The failure t o implement the tree con-straint may lead to fragmented parses and lower parsing accu racy, especially with respect to the global structure of the sentence. Moreover, e ven if the loss in accuracy is not substantial, this may be problematic when using the pa rser in applications where downstream components may not function correctly if the par ser output is not a well-formed tree.

Parser (Nivre, Hall, and Nilsson 2006), is to use an artificia l root node and to attach all remaining words on the stack to the root node at the end of p arsing. This fixes the formal problem, but normally does not improve accuracy beca use it is usually unlikely that more than one word should attach to the artificial root no de. Thus, in the error analysis presented by McDonald and Nivre (2007), MaltParse r tends to have very low precision on attachments to the root node. Other heuristic s olutions have been tried, usually by post-processing the nodes remaining on the stack in some way, but these techniques often require modifications to the training proc edure and/or undermine the linear time complexity of the parsing system. In any case, a c lean theoretical solution to this problem has so far been lacking. 3. The Solution
We propose a modified version of the arc-eager system, which g uarantees that the arc set A in a terminal configuration forms a projective dependency tr ee. The new system, shown in Figure 3, differs in four ways from the old system: 1. Configurations are extended with a boolean variable e , keeping track of Initial: ([ ], [ w 1 , . . . , w n ], {} , false ) Terminal: ([ w i ], [ ], A , true )
Shift: (  X  , w i |  X  , A , false )  X  (  X  | w i ,  X  , A , [[  X  Unshift: (  X  | w i , [ ], A , true )  X  (  X  , [ w i ], A , true )  X 
Reduce: (  X  | w i ,  X  , A , e )  X  (  X  ,  X  , A , e ) HEAD ( w
Right-Arc: (  X  | w i , w j |  X  , A , e )  X 
Left-Arc: (  X  | w i , w j |  X  , A , e )  X  (  X  , w j |  X  , A  X  X  w 2. Terminal configurations have the form ([ w i ], [ ], A , true ), that is, they have 3. The Shift transition is allowed only if e = false . 4. There is a new transition Unshift , which moves top back to the buffer and
The new system behaves exactly like the old system until we re ach a configuration with an empty buffer, after which there are two alternatives. If t he stack contains exactly one word, we terminate and output a tree, which was true also in th e old system. However, if the stack contains more than one word, we now go on parsing b ut are forbidden to make any Shift transitions. After this point, there are two cases. If the bu ffer is empty, we make a deterministic choice between Reduce and Unshift depending on whether top has a head or not. If the buffer is not empty, we non-determini stically choose between
Right-Arc and either Left-Arc or Reduce (the latter again depending on whether top has a head). Because the new Unshift transition is only used in completely deterministic cases, we can use the same statistical model to score transit ions both before and after we have reached the end of the input, as long as we make sure to blo ck any Shift transition favored by the model.
 maximum number of transitions is O ( n ), where n is the length of the input sentence, which guarantees linear parsing complexity for greedy (and beam search) parsers with constant-time model predictions and transitions. From pre vious results, we know that the system is guaranteed to reach a configuration of the form (  X  , [ ], A ) in 2 n  X  k transi-tions, where k = |  X  | (Nivre 2008). 2 In any non-terminal configuration arising from this point on, we can always perform Reduce or Unshift (in case the buffer is empty) or
Right-Arc (otherwise), which means that termination is guaranteed if we can show that the number of additional transitions is bounded. 262 to the buffer (because a word can only be moved back to the buff er if it has no head, which can only happen once since Shift is now forbidden). at most k  X  1 Right-Arc transitions, moving a word back to the stack and attaching it to its head. Finally, we can perform at most k  X  1 Reduce and Left-Arc transitions, removing a word from the stack (regardless of whether it has fi rst been moved back to the buffer). In total, we can thus perform at most 2 n  X  k which means that the number of transitions is O ( n ).
 we now show that it also guarantees that the output is a well-f ormed dependency tree.
In order to reach a terminal configuration, we must pop n  X  1 words from the stack, each of which has exactly one incoming arc and is therefore co nnected to at least one other node in the graph. Because the word remaining in the sta ck has no incoming arc but must be connected to (at least) the last word that was popp ed, it follows that the resulting graph is connected with exactly n  X  1 arcs, which entails that it is a tree. the unattached words left on the stack in the first configurati on of the form (  X  , [ ], A ), it may not be able to construct every possible tree over these nodes. More precisely, a sequence of words w j , . . . , w k can only attach to a word on the left in the form of a chain (not as siblings) and can only attach to a word on the ri ght as siblings (not as a chain). Nevertheless, the new system is both sound and co mplete for the class of projective dependency trees, because every terminating transition sequence derives a projective tree (soundness) and every projective tree is d erived by some transition sequence (completeness). By contrast, the original arc-ea ger system is complete but not sound for the class of projective trees. 4. Experiments In our empirical evaluation we make use of the open-source sy stem MaltParser (Nivre,
Hall, and Nilsson 2006), which is a data-driven parser-gene rator for transition-based dependency parsing supporting the use of different transit ion systems. Besides the original arc-eager system, which is already implemented in MaltParser, we have added an implementation of the new modified system. The training pr ocedure used in Malt-
Parser derives an oracle transition sequence for each sente nce and gold tree in the training corpus and uses every configuration X  X ransition pa ir in these sequences as a training instance for a multi-class classifier. Because the oracle sequences in the arc-eager system always produce a well-formed tree, there will b e no training instances corresponding to the extended transition sequences in the n ew system (i.e., sequences containing one or more non-terminal configurations of the fo rm (  X  , [ ], A )). However, because the Unshift transition is only used in completely deterministic cases, where the classifier is not called upon to rank alternative transition s, we can make use of exactly the same classifier for both the old and the new system. 4
CoNLL-X shared task on multilingual dependency parsing (Bu chholz and Marsi 2006), which all assume the existence of a dummy root word prefixed to the sentence. We tune the feature representations separately for each language a nd projectivize the training data for languages with non-projective dependencies but ot herwise use default settings in MaltParser (including the standard heuristic of attachi ng any unattached tokens to the artificial root node at the end of parsing for the original system). Because we want to perform a detailed error analysis for fragmented parses, we initially avoid using the dedicated test set for each language and instead report resu lts on a development set created by splitting off 10% of the training data.
 tion) achieved with the two systems. We see that the new syste m improves over the old one by 0.19 percentage points on average, with individua l improvements ranging from 0.00 (Japanese) to 0.50 (Slovene). These differences m ay seem quantitatively small, but it must be remembered that the unattached tokens left on t he stack in fragmented parses constitute a very small fraction of the total number o f tokens on which these scores are calculated. In order to get a more fine-grained pic ture of the behavior of the two systems, we therefore zoom in specifically on these token s in the rest of Table 1. the end of the input (excluding the artificial root node). Col umn 5 shows for how many of these tokens the correct head is also on the stack (includi ng the artificial root node).
Both statistics are summed over all sentences in the develop ment set. We see from these figures that the amount of fragmentation varies greatly betw een languages, from only four unattached tokens for Japanese to 230 tokens for Sloven e. These tendencies seem to reflect properties of the data sets, with Japanese having t he lowest average sentence length of all languages and Slovene having a high percentage of non-projective depen-dencies and a very small training set. They also partly expla in why these languages show the smallest and largest improvement, respectively, i n overall attachment score. 264 tokens on the stack are attached to their correct head in the fi nal parser output, as a result of heuristic root attachment for the old system and ex tended transition sequences for the new system. Columns 8 and 9 show the same results expre ssed in terms of recall or error reduction (dividing column 6/7 by column 5). These r esults clearly demonstrate the superiority of the new system over the old system with heu ristic root attachment.
Whereas the old system correctly attaches 40.60% of the toke ns for which a head can be found on the stack, the new system finds correct attachments i n 72.12% of the cases. For some languages, the effect is dramatic, with Arabic improvi ng from just above 10% to over 90% and German from about 15% to almost 70%, but all langu ages clearly benefit from the new technique for enforcing the tree constraint.
 of unattached tokens that should be attached to the artificia l root node. Because the old root attachment heuristic attaches all tokens to the roo t, it will have 100% recall on tokens for which this is the correct attachment and 0% reca ll on all other tokens.
This explains why the old system gets 100% recall on Japanese , where all four tokens left on the stack should indeed be attached to the root. It als o means that, on average, root attachment is only correct for about 40% of the cases (wh ich is the overall recall achieved by this method). By contrast, the new system only ac hieves a recall of 82.81% on root attachments, but this is easily compensated by a reca ll of 63.50% on non-root attachments.
 cluding punctuation) on the dedicated test sets from the CoN LL-X shared task, shown in Table 2. The results are perfectly consistent with those a nalyzed in depth for the development sets. The average improvement is 0.12 for LAS an d 0.10 for UAS. The largest improvement is again found for Slovene (0.58 LAS, 0. 25 UAS) and the smallest for Japanese, where there is in fact a marginal drop in accura cy (0.04 LAS/UAS). all other languages, however, the new system is at least as go od as the old system and in addition guarantees a well-formed output without heu ristic post-processing.
Moreover, although the overall improvement is small, there is a statistically significant improvement in either LAS or UAS for all languages except Bul garian, Czech, Japanese,
Spanish, and Swedish, and in both LAS and UAS on average over a ll languages accord-ing to a randomized permutation test (  X  = . 05) (Yeh 2000). Finally, it is worth noting that there is no significant difference in running time betwe en the old and the new system. 5. Conclusion
In conclusion, we have presented a modified version of the arc -eager transition system for dependency parsing, which, unlike the old system, guara ntees that the output is a well-formed dependency tree. The system is provably sound and complete for the class of projective dependency trees, and the number of tran sitions is still linear in the length of the sentence, which is important for efficient p arsing. The system can be used without modifying the standard training procedure for greedy transition-based parsers, because the statistical model used to score transi tions is the same as for the old system. An empirical evaluation on all 13 languages from the CoNLL-X shared task shows that the new system consistently outperforms the old s ystem with the standard heuristic of attaching all unattached tokens to the artifici al root node. Whereas the old method only recovers about 41% of the attachments that ar e still feasible, the new system achieves an average recall of 72%. Although this give s only a marginal effect on overall attachment score (at most 0.5%), being able to guara ntee that output parses are always well formed may be critical for downstream modules th at take these as input.
Moreover, the proposed method achieves this guarantee as a t heoretical property of the transition system without having to rely on ad hoc post-proc essing and works equally well regardless of whether a dummy root word is used or not.
 Acknowledgments References 266
