 Factoid questions often contain one or more assertions (facts) about their answers. However, existing question-answering (QA) systems have not investigated how the multiple facts may be leveraged to enhance system performance. We ar-gue that decomposing complex factoid questions can benefit QA, as an answer candidate is more likely to be correct if multiple independent facts support it. We categorize de-composable questions as parallel or nested, depending on processing strategy required. We present a novel decompo-sition framework X  X or parallel and nested questions X  X hich can be overlaid on top of traditional QA systems. It con-tains decomposition rules for identifying fact sub-questions, a question-rewriting component and a candidate re-ranker. In a particularly challenging domain for our baseline QA system, our framework shows a statistically significant im-provement in end-to-end QA performance.
 I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing X  text analysis, language parsing and understanding Algorithms, Design Question Answering, Question Decomposition
We look at complex factoid questions, specifically ones which contain multiple facts related to the correct answer, as in e.g. Which company with origins dating back to 1876 became the first U.S. company to have 1 million stockholders in 1951? . Two facts of relevance here are the time-frame of the company X  X  origins, and it becoming the first to reach a particular landmark. We use the decomposed facts to garner independent, but potentially mutually-reinforcing, support for the correct answer from independent sources of evidence.
Recent approaches to QA acknowledge that some ques-tions need decomposing, to tease out information beyond what  X  X ingle-shot X  QA systems generally assume. They tend to defer to discourse and/or semantics of the question, and use complex processes like textual entailment [4], question refocusing [2, 3], or temporal/spatial analysis [6, 2]. De-composition work has mostly looked at  X  X eyond factoid X  questions. In contrast, we develop decomposition to im-prove quality of QA for a broad set of factoids . The ques-tions we use (from the popular TV quiz show Jeopardy!) cover numerous topics, and make for an excellent test bed for open-domain QA. 1
Our definition of  X  X ecomposable X  questions X  X ontaining independent support for the correct answer X  X eads to cat-egorizing such questions into parallel and nested . The ex-ample above, and an example from our data X  This coun-try singer who did time in San Quentin was pardoned by Governor Ronald Reagan  X  X re parallel decomposable: sub-questions can be evaluated independently of one another. In contrast, nested questions require sequential processing, with the answer to an  X  X nner X  sub-question plugged into the  X  X uter X : It was named for Britain X  X  last Stuart monarch, who gave the city its charter in 1708 . In this work we develop a uniform framework for handling decomposable questions of both types, and demonstrate that it is capable of improving the end-to-end performance of a state-of-the-art QA system.
A single-shot QA system may find answers whose support-ing evidence satisfies only some of the question X  X  facts, and ignores the remainder of the question. At the same time, looking at all question terms as a whole, instead of sepa-rate meaningful facts, may distract the search for candidate answers. For nested decomposable questions, the missing piece of information implied by the  X  X nner X  fact is often a facilitator to obtaining the correct answer. We would like to be able to enhance such single-shot systems so they can decompose questions (when appropriate) and identify parts thereof to be further processed, in parallel or in sequence.
Figure 1 shows the high-level architecture of such an adap-tation. Ours is a  X  X eta X  framework overlaid on top of an existing QA system. It can be conceptualized around four main components.
In this data, questions are posed in a declarative format, with highly stylized marking of question focus. This should not detract from referring to them as  X  X uestions X . Figure 1: Fact-Based Decomposition Framework
Decomposition Recognizers analyze the question and iden-tify decomposable parts (facts) using largely lexico-syntactic cues (Section 3). Question Rewriters reformulate the facts as sub-questions, adding key contextual information (Sec-tion 4.1). Underlying QA System generates, for any factoid question, a ranked list of answer candidates, each with a con-fidence corresponding to the probability of the answer being correct [1]. Candidate Re-rankers combine ranked answers to the original question with solutions for the decomposed facts (sub-questions) and generate a uniformly ranked an-swer list. Candidate answer confidences are used either by a machine learning-based approach or by a heuristic selection strategy to do the final ranking (Section 4.2).

We use the QA system described in [1]. However, our meta-framework will host any system that satisfies two cri-teria: it can solve factoid questions by providing answers with confidences reflecting their probability of being cor-rect; it can separate the question X  X  topic information from its main content by weighing the former less than the latter.
The figure highlights the distinction between parallel and nested processing: the parallel decomposition components produce multiple (two or more) sub-questions, submitted to the underlying QA system; the nested components generate inner-outer sub-question pairs, processed via a feedback loop re-invoking the underlying QA capability.
Finding the question segments representative of indepen-dent facts about the correct answer is not trivial: multiple facts can be  X  X eaved X  into a single complex question in a va-riety of ways: modifiers to the focus 2 , subordinate clauses, attached prepositional phrases, may all be expressing facts. From a fact-checking perspective, we consider facts to be expressions of relations between the focus and one or more entities (named entities, dates or quotations) as these tend
The focus is the part of the question referring to the answer. to be more substantial or meaningful. This, coupled with a set of syntactic cues we have found to be reliable indicators for decomposition, allows us to generalize recognition rules for question decomposition.
Our rules exploit fine-grained lexico-syntactic information, and fall within three major categories: independent subtrees , composable units and segments with qualifiers . The rules in each rule set target both parallel and nested configurations. Details of rule sets fall outside of the scope of this paper; be-low we outline some highlights, as representative examples. Independent Subtrees: Intuitively, potentially in-dependent facts X  X apturing unique information about the answer X  X ould be in clauses distinct from the rest of the question: e.g. relative or subordinate constructions. In the absence of more focused contextual information (see below), such configurations are indicative of parallel decomposition. The syntactic labels connecting such subtrees to the focus are generally good indicators for  X  X reaking away X  a subtree from the question as a decomposable fact. Thus in The name of this character, first introduced in 1894, comes from the Hindi for  X  X ear X  , an independent fact about the answer is  X  this character, introduced in 1894  X  (note that  X  this charac-ter  X  is the focus). This category also triggers on conjunctions as decomposition points, as in Its original name meant  X  X it-ter water X  and it was made palatable to Europeans after the Spaniards added sugar .

Configurational information, reinforced by lexical cues, is used to determine the question X  X  decomposition profile, par-allel or nested. The syntactic contour of the first example in this section shows that both the main and subordinate clauses characterize the (same) focus entity: a clear indica-tor that the sub-questions are parallel. Conversely, A con-troversial 1979 war film was based on a 1902 work by this author exhibits a very different set of configurational prop-erties. The focus is just one of several underspecified entities which do not  X  X hare X  their facts (e.g. via a common head). This is indicative of nestedness, with the inner sub-question around an unspecified, non-focus element (  X  X  controversial 1979 war film X  ), and the outer taken from the complement of the original question (  X  X film] was based on a 1902 work by this author X  ). Nested decomposition returns a pair of sub-questions; but there may be more than one way to de-compose into an inner-outer.
 Composable Units: An alternate strategy for identify-ing facts is to  X  X ompose X  them by combining elements from the question. In contrast to  X  X reaking off X  independent sub-trees, rules in this set combine different parts of the tree into a sub-question. For instance, the focus with its pre-and post-modifiers (if they are sufficiently specific) can be interpreted as separate, parallel, fact(s). Alternatively, find-ing the focus itself in a modifier position may be a signal of nestedness: in To honor his work, this man X  X  daughter took the name Maria Celeste when she became a nun in 1616 , the focus is dominated by an underspecified node,  X  X augh-ter X  . Traversing such a tree without descending to focus level  X  X arves out X  an inner sub-question, itself focused on the dominating (linking) node:  X  X o honor his work, [this] daughter took the name Maria Celeste ... X  .
 Segments with Qualifiers: This group of rules de-tects focus modifiers which are relative qualifiers:  X  X he first X  ,  X  X nly X  ,  X  X he westernmost X  . Such qualifiers need to be  X  X om-pleted X  by information from elsewhere:  X  X he third man X  is meaningless without a supporting clause, e.g.  X  X he third man . . . to climb Mt. Everest X  . The rules here combine character-istics of the other two rule sets, to manipulate independent subtrees and compose them with modifiers to the focus.
Several heuristic filters reduce over-generation; primarily, they discard facts that do not contain a named entity, a quoted string, or a temporal (time or date) expression X  X his is in line with our definition of fact, earlier in this section.
We also discard facts with significant overlap with the entire question, or with other facts from previously applied rules. This is based on a (partial order) prioritization of rules, reflecting intuitions (borne by inspecting rule results) of how informative the facts generated by the rule are.
Submitting a decomposed sub-question, as-is, to the un-derlying QA system meets serious problems: sub-questions are often much shorter than the original, and tend to not have a unique answer. Moreover, some of the information from the full question that was dropped in the sub-question may offer relevant contextual cues crucial for coming up with the correct answer. In extreme cases, loss of context may lead to recall failures X  X hus defeating the whole purpose of decomposing in the first place.

Sub-question rewriting provides such crucial contextual information. For a sub-question Q i , we first obtain the set of all named entities and nouns (minus stopwords) in the origi-nal question text that are not present in Q i . We then insert these keywords into the topic of the original question. 3 nally, the underlying QA system is given the enriched topic/ sub-question pair; recall that our decomposition framework (Section 2) expects to be able to take advantage of the dif-ferential weighting of information in a question X  X  topic and content. Sub-question rewriting thus ensures that the larger context of the original question is still taken into account when evaluating a sub-question, although with less weight.
The different decomposition regimes require different stra-tegies for using the sets of candidate answers, with confi-dences. In the parallel case, a final set of uniformly ranked answers needs to be composed from the set of ranked answer lists produced by independently solving the sub-questions. In the nested case, a subset of the answer list to the inner sub-question needs to be selected for substitution into the outer.
 Parallel Decomposition A simple approach to assign-ing a final score for each candidate answer is to multiply scores for each of the sub-questions X  X iven the assumption that they are independent. However, sub-question rewriting breaks this assumption. Also, different decomposition rules have different precision and recall: thus sub-questions ought not to be weighed equally. In the extreme case of rules pro-ducing bad decompositions, it makes sense to fall back to
Jeopardy! questions topics are confined to a category field. the original question: therefore the confidence of the  X  X ingle-shot X  pass (Figure 1) should also inform the final decision. Consequently, we train a machine learning model to combine information across sub-question answer confidences.
To capture this range of information, the model uses the following features: whether a candidate was a top answer to the full (non-decomposed) question; confidence value for a candidate answer to full question; number of sub-questions with candidate answer in top 10; and a feature for every (parallel) rule set, whose value is the confidence of the can-didate answer for a fact derived by this rule set.

If a candidate answer is not in the answer list of the full question or any of the decomposed sub-questions, the cor-responding feature value is set to missing . If a rule pro-duces multiple sub-question, the corresponding (rule) fea-ture value for the candidate answer is set to the sum of the confidences obtained for that answer across all the sub-questions. For the machine-learning algorithm, we use the Weka implementation [7] of logistic regression with instance weighting (weights are tuned over the development set). Nested Decomposition Each candidate answer from the inner sub-question X  X  answer list, if substituted into the outer sub-question, has ramifications on end-to-end accu-racy: incorrect answers from the inner lead to incorrect final answers. We rely on the ability of the underlying QA sys-tem to produce meaningful confidences for its answers. Thus only the top answer to the inner sub-question is considered for substitution in the outer X  X f its confidence exceeds some threshold (obtained by tuning over the development set).
With an answer to the inner sub-question, we are now in a position to rewrite the outer. Similar to the case for par-allel sub-questions, we also adhere to the policy of provid-ing additional relevant contextual information to the system (cf. Section 4.1).

A simple heuristic strategy appeals to joint probability of the inner-outer pair to perform candidate re-ranking: the confidence of the top answer to the outer sub-question is multiplied with that of the top answer to the inner question; the product is compared with the top-ranking confidence for the full question; the answer with the higher confidence is selected as final.
Our data set X  X ith ground truth for both training a sys-tem and evaluating its performance X  X s a collection of Jeop-ardy! question-answer pairs (from www.j-archive.com ). Given our focus on question decomposition, only Final Jeopardy! (FJ) questions are in our test set: they tend to be complex, with multiple constraints, and typically much harder to an-swer (for humans and the underlying QA system alike). Ap-proximately 3000 FJ questions are split into 1138 for train-ing, 517 for development and 1269 for testing (blind data).
The parallel decomposition rules were defined and tuned on the development set of 517 questions. The final re-ranking model (with features as in Section 4.2) was built over our FJ training set (Section 5.1). It was trained for logistic regres-sion with instance re-weighting, setting the negative instance weight 0.25 times lower (based on analysis over the develop-QA End-to-End Decomposable Q System Accuracy Accuracy PB 635/1269 (50.05%) 339/598 (56.68%) PD-QR 634/1269 (49.96%) 338/598 (56.52%) PD+QR 643/1269 (50.66%) 347/598 (58.02%) NB 635/1269 (50.05%) 129/255 (50.58%) ND+QR 640/1269 (50.43%) 134/255 (52.54%) ment set, and motivated by the underlying QA system X  X  ten-dency to generate many more negative answers than positive ones). To determine the impact of our context-preserving sub-question rewriting strategy (Section 4.1), we modified the algorithm to issue the sub-question as-is, using the orig-inal category (topic). The results of applying the parallel decomposition rules followed by the re-ranking model to the 1269 test questions are shown in Table 1.

In the table, PB refers to Parallel Baseline (the perfor-mance of the underlying QA system with decomposition dis-abled), NB refers to Nested Baseline (same configuration as PB but separately run on nested decomposable questions), PD and ND refer to Parallel and Nested Decomposition sys-tems respectively, and QR refers to Question Rewriting.
Nested decomposition strategy (Section 4.2) was similarly evaluated, comparing the (nested) baseline to a heuristic re-ranking approach (whose parameter thresholds were tuned on the development set). Results are also in Table 1.
Table 1 shows the parallel decomposition rules applying to a large fraction of the test set (598 out of 1269 questions). Interestingly, the performance of the baseline QA system on the decomposable set is 56.6%, i.e. 6% higher than the overall performance. One reason for this is that parallel-decomposable questions typically contain more information (more than one fact/constraint to be satisfied by the answer) and the system can, in some cases, exploit this redundancy (e.g. when a fact is strongly associated with the correct an-swer and there is evidence in the sources supporting this).
Decomposition without sub-question rewriting does not show much impact over the baseline: question context is clearly crucial for QA. With rewriting to maintain context, our parallel decomposition algorithm achieves an improve-ment of 1.4% (10 gains/2 losses) on the decomposable ques-tion set, which translated to an end-to-end gain of 0.6%.
The nested decomposition rules fired on roughly a fourth of the test set (255 out of 1269 questions); the performance of the baseline QA system on the nested decomposable set was roughly the same as the overall performance (and much lower than the parallel decomposable cases). The likely ex-planation is that nested questions are harder to solve than parallel: correct solution to the inner is crucial for find-ing the answer to the outer, whereas parallel sub-questions are, by definition, independent. Our nested decomposition algorithm using the heuristic re-ranking approach achieves an improvement of 2% (6 gains/1 loss) on the decomposable question set, which translated to an end-to-end gain of 0.4%.
The impact of using both parallel and nested decompo-sition is a 1.5% gain in accuracy on the decomposable set, and a 1% gain on end-to-end system accuracy (our rules for finding parallel and nested decompositions are disjoint so a given question cannot fall in both classes).

A key point concerning these results is that the base-line QA system represents state-of-the-art in solving Jeop-ardy! questions. Moreover, our FJ evaluation data is known to be harder than regular Jeopardy! questions. We estimate qualified Jeopardy! players X  accuracy on FJ to be 48% (based on player performance statistics from j-archive ). A gain of 1% end-to-end on such questions is, therefore, a strong im-provement. McNemar X  X  test with Yates X  correction for con-tinuity [5] found the results to be statistically significant, where significance is assessed for p &lt; . 05.
We argue that a question decomposition capability can enhance the quality of factoid QA. We have developed a general-purpose decomposition framework for complex fac-toid questions, which distinguishes between parallel (inde-pendent) and nested (sequential) question types, and ac-commodates appropriate strategies for solving both. The framework can be overlayed on any QA system that pro-vides answers with confidences, and that considers the topic of the question separate from its main content.

In addition to the typology of decomposable question types (and associated detection rules), we propose a novel ques-tion rewriting approach to mitigate the loss-of-context prob-lem when dealing with shorter (non unique) facts, and a re-ranking strategy that suitably combines results of the de-composition analysis with information from the single-shot QA approach.

This decomposition capability brings an improvement to the performance of a state-of-the-art factoid answering QA system X  X n the domain of Final Jeopardy!, which even qual-ified human players find difficult X  X y 1.5% on decomposable questions: a statistically significant gain. [1] D. Ferrucci, E. Brown, J. Chu-Carroll, J. Fan, [2] S. Hartrumpf. Semantic Decomposition for Question [3] B. Katz, G. Borchardt, and S. Felshin. Syntactic and [4] F. Lacatusu, A. Hickl, and S. Harabagiu. The Impact of [5] Q. McNemar. Note on the Sampling Error of the [6] E. Saquete, P. Mart  X  X nez-Barco, R. Mu  X noz, and [7] I. Witten and E. Frank. Data Mining X  X ractical
