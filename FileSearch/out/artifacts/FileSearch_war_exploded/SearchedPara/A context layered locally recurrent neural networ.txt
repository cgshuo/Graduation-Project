 Ramazan Coban n 1. Introduction application of neural networks to dynamic system identification and control. Identification is necessary if sufficient information about the system being modeled is not available. One needs only observed input X  X utput data and order of the system for identifi-cation in contrast to mathematical modeling on which the physical laws govern the system X  X  behavior. Once input X  X utput data is observed and order of the system is determined, an empirical model instead of mathematical model characterizing the system with complex differential equations can be easily obtained by means of neural networks.
 networks (FNNs) and recurrent neural networks (RNNs). There are only feed forward connections in the FNNs but both feed forward and feedback connections in the RNNs. The RNNs have been used in identification and control problems while the FNNs have been successfully applied in pattern recognition. As an alternative approach to application of the FNNs in pattern recognition, a single layered recurrent neural network with a time delay in its feedback configuration, in a fully recurrent manner, has been suggested by Hopfield (1982) . Such a fully recurrent neural network thanks to its dynamic structure repre-sents nonlinear dynamic feedback systems. Identification of dynamic systems via Hopfield X  X  fully recurrent neural network depends on only the initial conditions because its structure has no external input. Both continuous-time and discrete-time recurrent neural networks with constant inputs have been proposed by
Pineda (1987) . A general recurrent multilayer perceptron archi-tecture (RMLP) consisting of several layers, each of which has nodes fully interconnected with each other, has been proposed by
Puskorius and Feldkamp (1994) . The RMLP architecture covers both the FNN and the single layer fully RNN. However, it does not contain feedback connections from the outputs of nodes in one layer to the inputs of nodes in preceding layers.
 constructed using the FNNs in cascade and feedback configura-tions in globally recurrent manner (without local feedback) and the inputs are functions of time rather than constant, referred to as a nonlinear autoregressive moving average model with exo-genous inputs (NARMAX), Bhat and McAvoy (1990) , Narendra and Parthasarathy (1990) , Yamada and Yabuta (1990) . When such types of recurrent neural networks are used in identification process, the number of delayed input and output should be known in advance, and these delayed input and output are fed to the input of the network as a tapped delay line. The main problem of this approach is that the exact order of the dynamic system is generally unknown. Furthermore, the usage of the long tapped delay line input and output increases the network size, in turn, computational cost and decreases accuracy of the network. Since the globally recurrent neural networks (GRNNs) use the current and past inputs and past outputs as inputs of the network, the next output of the network is predicted by means of not only the external inputs but also the past outputs. Because of the usage of the past outputs as inputs to the network, it is not easy to identify a dynamic system satisfactorily. If the same training and test structures are used in identification process, referred to as parallel model in which the past outputs of the network are fed back into the network inputs, there is no guarantee that the identification process will converge. If the different training and test structures as in series-parallel model that the outputs of the system being modeled instead of the network outputs are fed back into the network are used in identification process, in this case the training structure is different from the test structure and frequently the network seems to have been trained well with the training structure but shows poor performance with the test structure ( Pham and Liu, 1995 ). Locally recurrent neural networks (LRNNs) do not suffer from the above shortcomings owing to their structure. In general, LRNNs can be classified as fully recurrent neural networks (FRNNs) and partially recurrent neural networks (PRNNs). The fully recurrent neural networks of which all nodes in a layer except the input layer are fully connected to each other, all of which are trainable, can effectively learn temporal sequences ( Chen and Soo, 1996 ; Dongpo et al., 2010 ; Pearlmutter, 1989 ; Williams and Zipser, 1989 ). However, the FRNNs are difficult to train and to converge in a short time due to their large structural complexity.

On the other hand, the partially recurrent neural networks involve feed forward and feedback connections. The Elman net-work ( Elman, 1990 ) is a PRNN consisting of one input layer, one hidden layer, one output layer, and one additional context layer through which the feedback signals from the hidden layer are provided again to the hidden layer. The Jordan neural network ( Jordan, 1986 ) is also a PRNN having the feedback connections from output to the context layer where the nodes have self-recurrent connections. Modified versions of these PRNNs have been developed and their performances in system identification have been tested against the original Elman and Jordan networks ( Coban et al., 2010 ; Pham and Liu, 1992 ; Pham and Oh, 1992 ). Cottrel and Tsung (1993) have compared the Elman and Jordan networks and concluded that the Elman network performs better than the other. Even though the original and modified Elman and Jordan networks can identify linear systems successfully, they do not perform satisfactorily on the nonlinear dynamic systems. A different architecture of the PRNNs called diagonal recurrent neural network (DRNN) has been proposed by Ku and Lee (1995) . The DRNN has only one hidden layer of recurrent nodes, each feeding back its output only into itself and not to other nodes in the same layer. Owing to the fact that there is no interconnection among the nodes, the DRNN has fewer weights and is trained much faster. In spite of its simplicity and fast training capability, the DRNN does not perform well in identifica-tion of complex nonlinear dynamic systems. Moreover, the posi-tion of dynamic nodes is confined to the hidden layer only. Lee and Song (1997) has developed a kind of the PRNN in which each output node is connected to itself and is also fully connected to other output nodes and all hidden nodes for visual pattern recognition. Even if this network is successful for visual pattern recognition it may be inefficient in identification of dynamic systems. A number of researchers have put forth various structures of the LRNNs in which local recurrence is introduced in the weights and nodes through FIR or IIR filters ( Back and Tsoi, 1991 ; Tsoi and Back, 1994 ). Frasconi et al. (1992) have suggested an LRNN architecture which contains dynamic nodes with local output feedback, without cross-talk. The feedback signal is taken from the output of the activation function and it is fed as input to the node after it is delayed for several times. Parlos et al. (1994) have proposed a recurrent multilayer perceptron (RMLP) with static weights for modeling complex process dynamics. The local signal feedback of the RMLP is provided by both cross-talk connections and self-recurrent connections in the hidden layers. A drawback of this network is the increased network complexity and the long training times. Another drawback is that even if the RMLP captures the characteristics of nonlinear dynamic systems successfully it does show poor performance on the linear case. Sastry et al. (1994) have suggested a recurrent network with internal memory called memory neuron network (MNN). In the MNN, each unit of neuron has a memory neuron whose single scalar output summarizes the history of past activations of that unit. The architecture and training procedure of a recurrent neural network called the multifeedback-layer neural network (MFLNN) has been proposed by Savran (2007) . The Levenberg X  Marquardt (LM) algorithm with a trust region approach has been employed to train the MFLNN connection weights.

During the last decades, considerable research has been carried out to develop recurrent fuzzy networks. Gorrini and Bersini (1994) have proposed a recurrent fuzzy system (RFS) which comprises several TSK type fuzzy rules with crisp output which are inter-connected through internal variables and feedback loops. A recur-rent self-organizing neural fuzzy inference network (RSONFIN) constructed by Mamdani type fuzzy rules is suggested by Juang and Lin (1999) . In the RSONFIN, temporal relations in the network are built by adding some feedback connections which represent the memory elements (called the context elements) to a feed forward neural fuzzy network. Lee and Teng (2000) have reported a recurrent fuzzy neural network (RFNN) in which recurrent property is performed by feeding the output of each membership function back to itself. In contrast to its local feedback structure, a TSK-type recurrent fuzzy network (TRFN) which contains a global feedback has been proposed by Juang (2002) . Its recurrent signals are achieved by transmitting the internal variables coming from fuzzy firing strengths back to both the network input and output layers. Mastorocostas and Theocharis (2002) have developed a new fuzzy model referred to as the dynamic fuzzy neural network (DFNN) consisting of recurrent TSK fuzzy rules. The premise and defuzzi-fication parts of the DFNN are static while the consequent parts are recurrent neural networks with internal feedback and time delay weights. Most recently, Yilmaz and Oysal (2010) have proposed a fuzzy wavelet neural network (FWNN) models, which are obtained from the traditional Takagi X  X ugeno X  X ang fuzzy system by repla-cing the THEN part of fuzzy rules with wavelet basis functions and the IF part of the rules with Gaussian type of activation functions, for prediction and identification of nonlinear dynamical systems.
In view of the conclusions drawn from the above research, the tradeoff between computational complexity and superior perfor-mance is quite important. It is also important that both linear and nonlinear dynamic systems should be identified by the same network architecture, not different network architectures. In this paper, to overcome the above drawbacks a novel recurrent neural network architecture, called the context layered locally recurrent neural network (CLLRNN), is proposed for dynamic system iden-tification. Only the architectural issue is proposed rather than a novel training algorithm for the unknown parameters in terms of convergence and accuracy in the architecture. Training of the
CLLRNN is accomplished using the dynamic backpropagation proposed by Narendra and Parthasarathy (1990 , 1991) . The princi-pal contribution of the paper is to design a recurrent neural network which is fast, simple, easily trainable using a standard learning algorithm, and applicable to real-world problems for dynamic system identification. The proposed network has the following features. (a) It has the same architecture for both learning and testing phases. (b) It does not require degree of the system to be identified. (c) It does not necessitate past values of the system inputs and outputs. (c) It can be easily constructed since its architecture is similar to composition of the feed forward neural networks and Elman neural networks. (d) It can be used to identify and control dynamic systems in the real-world. To demonstrate applicability of the CLLRNN to real world-problems, an experi-mental application to a dc motor connected to a load is carried out. system identification are introduced in Section 2 . The CLLRNN architecture and training algorithm are introduced in Section 3 .In
Section 4 , illustrative examples are given. Finally, concluding remarks are given in Section 5 . 2. System identification the following linear equations in vector X  X atrix form: Xk  X  1  X  X   X  AX  X  k  X  X  BU  X  k  X  X  1  X 
Y  X  k  X  X  CX  X  k  X  X  DU  X  k  X  X  2  X  where the coefficients A , B , C and D are properly dimensioned matrices. The notation k represents time index. U ( k ) is the input vector, Y ( k ) is the output vector, and X ( k ) is the state vector:
U k  X  X  Xk  X  1  X  X  X  A  X  k  X  X  X  k  X  X  B  X  k  X  U  X  k  X  X  3  X 
Y  X  k  X  X  C  X  k  X  X  X  k  X  X  D  X  k  X  U  X  k  X  X  4  X  matrices.
 a similar manner by Xk  X  1  X  X  X  fX  X  k  X  X  , U  X  k  X  X  X  5  X 
Y  X  k  X  X  gX  X  k  X  X  , U  X  k  X  X  X  6  X  where f  X  d  X  and g  X  d  X  are nonlinear functions.
 as an input argument. Hence, the nonlinear equations (5) and (6) is turned into the following equations: Xk  X  1  X  X  X  fX  X  k  X  X  , U  X  k  X  , k  X  X  7  X  Y  X  k  X  X  gX  X  k  X  X  , U  X  k  X  , k  X  X  8  X  model structure of a system with unknown parameters, given some prior knowledge about the system and input X  X utput obser-vations. Employing artificial neural networks for identification, one can exploit their ability to learn the system behavior and requires a reduced amount of knowledge such as observed input X  output data and order of the system. Selecting the locally recurrent neural networks rather than the globally recurrent neural networks eliminates the need for knowledge of the order of the system; hence a reasonable set of observed input X  X utput data pairs is sufficient to identify the system. The LRNNs have to approximate the system using only the observed input X  X utput data pairs. In its training process, since the network is parallel to input U ( k ) as shown in Fig. 1 . For the same input, the output of the network ^ Y  X  k  X  is compared with the output of the system Y ( k ). Therefore, the error signal e ( k ) is produced by the difference between the output of the network and the output of the system in the following way: e  X  k  X  X  Y  X  k  X  ^ Y  X  k  X  X  9  X 
As a matter of fact this error signal is employed for updating the weights of the network so as to minimize the error. 3. The context layered locally recurrent neural network
The proposed CLLRNN architecture is constructed by taking a generalized feed forward network and adding a special hidden layer called the context layer in addition to an ordinary hidden layer as in the Elman and Jordan networks. The CLLRNN archi-tecture is depicted in Fig. 2 . In the figure, the bias terms are not shown for the sake of simplicity and the notation z 1 represents the time delay operator. The network has a multi-layered struc-ture similar to the structure of multi-layer perceptrons (MLPs). The CLLRNN is composed of one input layer, one or more hidden layers, one output layer, and also one context layer. Unlike the Elman and Jordan networks, more than one hidden layer can be employed in the network according to situation in which a system may be approximated to an arbitrary degree of accuracy. All layers are interconnected in feed forward manner but no connec-tion between the input layer and context layer is allowed. The context layer receives feedback signals from the first hidden layer and outputs of the nodes in the context layer are fed forward to the first hidden layer. Therefore, dynamic memory is provided by means of feedback connections from nodes in the first hidden layer to nodes in the context layer and in case of being two or more hidden layers, from nodes in a hidden layer to nodes in the preceding hidden layer. In addition to feedback connections, there are self-recurrent connections in all nodes of the context and hidden layers. Thus, each node in the context and hidden layers has an adjustable self-recurrent connection to itself and feed forward connections to the nodes in the next layer but no connection to every other node in its own layer. The self-recurrent connections have one time unit delay. It differs from the original and modified Elman and Jordan networks in identify-ing nonlinear systems successfully. The CLLRNN has self-recurrent connections in all nodes of the hidden layers but the Elman and Jordan networks do not. In addition, the CLLRNN may have more than one hidden layer for more complex systems whereas the others have just one. Self-recurrent connections in the nodes of the hidden layers give the CLLRNN much more generalization capability to identify nonlinear systems. It is important to say that the number of nodes in the context layer is set equal to the number of hidden layer nodes and the number of nodes is the same for all hidden layers.

On the other hand, the input and output layer nodes have no self-recurrent connection. The input and output nodes of the network interact with outside environment but the context and hidden layer nodes do not. In this sense, the input nodes get signals from outside and pass them to the hidden layer nodes without changing them. The output nodes emit the signals from hidden layer nodes to the outside.

All the feed forward connections, feedback connections, and self-recurrent connections can be adapted by the gradient-descent based algorithms. It is also possible to use a learning algorithm such as genetic algorithms and particle swarm optimi-zation to update the whole weights of the network. Thus, the CLLRNN may be regarded as a fully recurrent neural network due to the fact that all of its connection weights are trainable although all nodes in a layer are partially connected. If the feedback connections are preset to unity as in partially recurrent networks, the self-recurrent connection weights remain as the only train-able weights besides the feed forward connections weights.
The dynamic behavior of the CLLRNN may be described in discrete-time as follows: ^ Y  X  k  X  X  hX  X  k  X  X  , U  X  k  X  , W  X  k  X  X  X  10  X  function characterized by activation functions, W ( k ) is the para-meters of the network formulated by W  X  k  X  X  X  w f  X  k  X  w a  X  k  X  w b  X  k  X  w b  X  k  X  T  X  11  X  the feed forward connections, self-recurrent connections, and feedback connections, respectively. The last element w b ( k ) is the bias vector.

Consider a CLLRNN composed of M layers, each of which contains N  X  nodes, for  X   X  0 , ::: , M with  X   X  0 and  X   X  M representing the input and output layers, respectively. The notation  X  is layer index. N 0 is equal to number of external inputs of the system N plus number of nodes in the context layer N c . Thus, N 0 indicates the number of nodes in the output layer, which is equal to the number of the system outputs. It should be noted that the number of the nodes in the context layer equals the number of the number of nodes in all the hidden layers is the same ( N 1  X  N 2  X  ...  X  N M 1 ).

In the forward sweep, upon presenting an input signal into the network at time k , the total input to the node n in the input described as s  X  k  X  u  X  i  X   X  k ,  X   X  0  X  X  X  12  X  where s  X   X   X   X  n  X   X  k is the total input to the node n in the layer and n is node index. Note that u ( i ) [ k ] is the input signal for i  X  1, 2,..., N u . The input to the node n in the context layer for n  X  1, 2,..., N c is defined by s
The input to the node n in layer  X  for n  X  1 , 2 , ::: , N follows: s  X  k  X  s  X  k  X  s  X  k  X  from the node n in layer  X  to back itself, w  X   X   X  b  X  n  X  connection weight from the node n in layer  X   X  1 to node n in layer the output of the node n in layer  X  . The time index [ k 1] indicates that the feedback is delayed by one time step. For the sake of the notational clarity, hereafter the weights are usually denoted without time index k .
 node n in layer  X  preceding the last hidden layer. It includes all node n in the layer  X   X  1 at time step k 1 is fed back to the input of the node n in the previous layer. The Eq. (15) formulates the total input of the node n in the last hidden layer and does not contain w b ( k ) since there is no hidden layer following it. The
Eq. (16) does not include w a ( k )and w b ( k ) because it is the output layer.
 where the operator s  X  d  X  denotes the activation function. the network output ^ y  X  n  X  : ^ y  X  n  X   X  k  X  x  X   X   X   X  n  X   X  k ,  X   X  M  X  X  X  18  X  because it acts as a buffer. In the other layers, one can use a linear, logistical, or hyperbolic tangent function as an activation function.
 estimation of the network parameters W ( k ). Among numerous algorithms proposed in the literature such as backpropagation through time ( Pearlmutter, 1989 , 1995 ; Werbos, 1990 ; Williams and Peng, 1990 ), real-time recurrent lerning ( Williams and Zipser, 1989 ), and dynamic backpropagation ( Narendra and Parthasarathy, 1990 , 1991 ) which are based on the conventional gradient method using first-order derivative ( Rumelhart et al., 1986 ; Werbos, 1974 ), a learning algorithm using the dynamic backpropagation is derived and given in the following. To obtain the dynamic backpropagation algorithm, a quality measure for the network performance is required. When one input X  X utput data pair is presented to the network, the squared error at time step k is Ek  X  1 2 where n is an element of the network outputs, ^ y  X  n  X   X  k is the actual output of the node n in the output layer at time step k , y nth output of the system to be identified or desired output. The total network error for the whole training data set containing a sequence of length K is: E  X  layer are updated based on the steepest descent (gradient) method by differentiating Eq. (19) with respect to the feed forward weights in the following expression for  X   X  M , M 1 , ... , 0: where Z is a learning rate, taking values in the range [0, 1] and
D w  X   X   X  f  X  nm  X  is the change to be made to the connection weight w .

For the output layer, the output of the node n is equal to the network state as in Eq. (18) . Hence, the derivative at the right-hand side of Eq. (21) is obtained in the following manner: where s 0  X  d  X  is the derivative of the node activation function with of the performance index to changes in the total input of unit n in layer  X  given by
Hence, substituting Eqs. (22) and (23) in Eq. (21) , respectively, one can get arbitrary hidden layer is given by using the steepest descent method as follows: network outputs ^ y  X  n  X   X  k are affected and hence, the summation S N  X   X  1 n  X  1 is required in the above chain rule for  X  o M  X  X  . Using
Eqs. (23), (16), and (17) in Eq. (26) , the following generalized error signal is obtained: the feed forward weights in the layer  X  : the situation is slightly different for the self-recurrent and feed-back connection weights. They have dynamic derivatives, and the error gradients of the dynamic derivatives are calculated propa-gating them forward in space and time through the layers. The following recurrent update rule for the self-recurrent connection weights is obtained by differentiating Eq. (19) with respect to the self-recurrent weights during learning phase for the node n in layer  X  , which is the context layer or an arbitrary hidden layer: right-hand side of Eq. (29) is obtained in the following way: equation for the state gradients, and solved recursively with given initial conditions. Thus, the initial values for the recursion are @ x
In a manner similar to the self-recurrent weight update rule, to node n in layer  X  1 are adjusted in the following rule:
According to the chain rule of calculus, the derivative at the right-hand side of Eq. (35) is obtained in the following way: @ ^ y
The last component of Eq. (36) becomes @ x Obtaining a recursive algorithm for Eq. (37) is not simple as for Eq. (33) because Eq. (37) is not recursive if one looks closer at the partial derivatives in both sides of the equation. One has two options to derive the gradient: first is to ignore the derivative algorithm. The other is to compute the gradient by @ x
If a momentum term l is added to Eqs. (28), (29), and (35) to accelerate the learning by reducing the oscillations at the output response, the changes in the connection weights are obtained, respectively, as
In similar to Eq. (39) , the following update rule is used for biases whose input signals are fixed at  X  1:
Furthermore, the learning rate Z is adjusted to speed up the learning according to the following rules ( Hertzet al., 1991 ):  X  k  X  Z  X  k 1  X  D Z  X  k 1  X  43  X  D Z  X  k 1  X  where D Z is the change of the learning rate, D E is the change of the cost function, g and x are increasing and decreasing coeffi-cients of the learning rate, respectively. Initially, Z takes a relatively small value, i.e., 0.01 and as the training process proceeds, it is raised by g or decreased by x depending on whether the cost function E is increasing or decreasing, therefore avoiding the algorithm getting stuck in a local minimum.

Selection of control parameters such as learning rate and momentum term is very crucial for the convergence of the proposed recurrent neural network. These parameters affect the learning speed and generalization capability of the network. While a larger value of the learning rate speeds up the conver-gence, it causes overshoots or divergence. In the other hand, a small value slows down the convergence. Momentum term also can be used to increase the speed of convergence. Selecting a larger momentum value can create a risk of missing the global minimum or making the network unstable. In this paper, values of these parameters have been selected in the range from 0.0001 to 0.1 by trial and error. The best values found for each example are given in the next section.

In most cases the feedback connections are fixed; there are some reasons not to adjust them. To best of the author X  X  knowl-edge, most importantly the standard backpropagation may easily be used for training. The training process may also be sped up by not updating them. Finally, in view of the fact that adjusting the feedback connections cause the learning algorithm to become more unstable compared with taking it fixed at predefined value, so they should be preset to unity. Indeed, it has been the experience of the author that updating the feedback weights by using the dynamic backpropagation algorithm has increased the network instability for the studied examples. Though the formu-las to be used to adjust them have been derived just before, they are set to unity for the examples in the following section.
Evaluation of computational cost of the CLLRNN can be carried out calculating the number of multiplications and additions for one iteration in a learning stage consisting of the forward phase and backward phase. Computational cost of the CLLRNN with M layers for one time-step is ON c 2 M  X  N c N M . It can be seen that the proposed network have considerably smaller computational load. Therefore, besides its simplicity the algorithm is fast. 4. Illustrative examples
In this section, various simulation examples of linear and nonlinear dynamic systems identified by the CLLRNN are demon-strated. Performance comparisons with some existing recurrent networks such as recurrent neural networks are also made. A parallel model whose structure is shown in Fig. 3 is used for identification of SISO dynamic systems. A similar structure is also used for MIMO systems. In addition, for demonstration of applic-ability of the CLLRNN to real world-problems, an experimental application to a dc motor connected to a load is carried out. The main reasons for selecting the examples below are that provide fairly complex systems and that all of them are stable in the bounded-input bounded-output (BIBO) sense. For all examples, the training and testing performances are determined by the root-mean-squared error (RMSE) criteria: RMSE  X  where K is again the size of data pairs in the training and testing set and ^ y denotes the prediction of the CLLRNN.

Example 1. In the first example, the learning and generalization capability of the CLLRNN is tested through a second-order linear system described by y  X  k  X  X  1 : 8398533 yk 1  X  X  0 : 8607080 yk 2  X  X  where the current output of the dynamic system depends on two previous outputs and two previous inputs. Since the globally recurrent neural network proposed by Narendra and
Parthasarathy (1990) use the past inputs and past outputs as inputs to the network, a structure with four input nodes is used to feed the appropriate past values of the input and output. As in
Fig. 3 , owing to the locally recurrent property of the CLLRNN, only the control input u is fed as the input but the other past values of y and u are not used. If a globally recurrent neural network structure is used, then the exact order of the system should be known in advance. In contrast to the globally recurrent neural networks, one does not need to know the exact order of the system in the CLLRNN. In training the CLLRNN, the input is an independent and identically distributed (i.i.d.) uniform sequence over [ 2, 2] for about half of the 1000 time steps and a sinusoid
SISO identification problem, the CLLRNN has one input node, one output node, and five hidden layer nodes. The linear activation function is used in the all layers. During the training phase, 9000 time steps are used and the learning rate is 0.05. Momentum term is 0.001. The feedback connection weights are set to unity and are not adjusted during training process. The other weights are initialized in the range [ 0.5, 0.5] using a random number generator with a different seed in each case. The training procedure is repeated for 50 times and the best network para-meters are used for test phase. For the test phase, the following input sequence consisting of mixtures of sinusoids and constant signals is used ( Sastry et al., 1994 ): u  X  k  X  X  sin p k = 25 , k o 250
CLLRNN for the test input given by Eq. (47) . The CLLRNN has achieved the RMSEs of 0.0044 and 0.0046 for training and testing, respectively. Since the dynamic system and CLLRNN outputs are almost the same, the prediction error between them is plotted in
Fig. 5 . For performance comparison, Elman type recurrent neural network (ERNN) proposed by Elman (1990) is simulated. The
ERNN has five hidden layer nodes. The linear activation function is used in the all layers. With the same training time step and data, the RMSEs of the ERNN for the training and testing data are presented in Table 1 . From the table, it is seen that the CLLRNN shows better performance than the ERNN for the linear system.
Example 2. As a second example, identification of a nonlinear dynamic system is considered to demonstrate the structural capabilities of the CLLRNN. In this example, the nonlinear dynamic system to be identified is described by the following difference equation ( Narendra and Parthasarathy, 1990 ): yk  X  X  X  yk 1  X  X  yk 2  X  X  yk 3  X  X  uk 2  X  X  X  yk 3  X  X  1  X  uk 1  X  X  where the current output of the dynamic system depends on three previous outputs and two previous inputs. Since the globally recurrent neural network proposed by Narendra and
Parthasarathy (1990) use the past inputs and past outputs as inputs to the network, a network structure with five input nodes is used to feed the appropriate past values of the input and output. Using the CLLRNN identification structure similar to one in Fig. 3 , only the control input u is fed as the input but the other past values of y and u are not required. In order to make some comparisons with other recurrent networks, the same dynamic system used by Sastry et al. (1994) , Juang and Lin (1999) , and
Juang (2002) is chosen. In training the CLLRNN, the input u ( k ) consists of 500 samples from an i.i.d. uniform sequence over [ 2, 2] and 500 samples from a sinusoid given by 1 : 05sin  X  p k = 45  X  .In this nonlinear identification task, the CLLRNN has one input node, one output node, and four hidden layer nodes. The linear activa-tion function is used in the output layer. The hyperbolic tangent activation function is used in the hidden and context layers.
During the training phase, 9000 time steps are used and the learning rate and momentum term are 0.015 and 0.01, respec-tively. The feedback connection weights are set to unity and are not adjusted during training process. The other weights are initialized in the range [ 0.5, 0.5] using a random number generator with a different seed in each case. The training procedure is repeated for 50 times and the best network para-meters are used for test phase. For the test phase, the testing input signal u ( k ) used in Example 1 is adopted to determine the identification results.

CLLRNN for the test input given by Eq. (47) and Fig. 7 shows the and 0.020 for training and testing, respectively. In this example, to show the advantage of the CLLRNN, it is compared with the ERNN ( Elman, 1990 ) and MNN ( Sastry et al., 1994 ). The ERNN is simulated to see the identification results. The ERNN has five hidden layer nodes. The hyperbolic tangent activation function is used in the hidden and context layers. With the same training time step and data, the RMSEs of the ERNN for the training and testing data are given in Table 2 . Also, the results appeared in the literature for the other network are used and the details are given in Table 2 . When the performance of the CLLRNN is compared to the MNN, the CLLRNN exhibits better performance than the other although the MNN has more hidden layer nodes and training time steps than the CLLRNN has. From the table, it can be observed that among the three recurrent networks, the proposed CLLRNN out-performs the other recurrent networks, showing lower RMSE both in the training and testing phase.
 Example 3. In the third example, identification of a nonlinear dynamic system with two inputs and two outputs is considered to indicate the ability of the CLLRNN to learn a multiple-input multiple-output (MIMO) system. The MIMO nonlinear dynamic system to be identified in this example is the same as that used by Sastry et al. (1994) , and Juang and Lin (1999) . The nonlinear dynamic system is specified by Narendra and Parthasarathy (1990 ) y 1  X  k  X  y 2  X  k  X  "# where u 1 , u 2 and y 1 , y 2 are the inputs and outputs of the dynamic system, respectively. Using the parallel identification structure for MIMO system as in Fig. 3 , only the control inputs u 1 and u as the inputs but the other previous values of u 1 , u 2 and y not required. During the training phase, the training data is obtained by applying an i.i.d. uniform sequence over [ 2, 2] for 500 samples and a sinusoid signal given by 1 : 05sin  X  p k = 45  X  for the remaining 500 samples to both inputs u 1 and u 2 . In this MIMO identification problem, the CLLRNN has two nodes for input layer, two nodes for output layer, and five nodes for hidden and context layers. The linear activation function is used in the output layer. The hyperbolic tangent activation function is used in the hidden and context layers. During the training phase, 9000 time steps are used and the learning rate is 0.1. In this example momentum term is 0.01. The feedback connection weights are fixed at 1.0 and are not subject to adjustment during training process. The other weights are initialized in the range [ 0.5, 0.5] using a random number generator with a different seed in each case. The training procedure is repeated for 50 times and the best network para-meters are used for test phase. For the test phase, the testing data set is obtained by applying the testing input signal used in previous examples to both inputs.

CLLRNN for the test input signals given by Eq. (47) . The prediction errors between the outputs of the dynamic system and the
CLLRNN are depicted in Fig. 9 in order to distinguish the difference between them. In this example, to show the superiority of the CLLRNN in terms of modeling accuracy, it is compared with the ERNN ( Elman, 1990 ) and MNN ( Sastry et al., 1994 ). The ERNN is simulated for comparison purposes. The ERNN has six hidden layer nodes. The hyperbolic tangent activation function is used in the hidden and context layers. With the same training time step and data, the RMSE values of the ERNN for the training and testing data are given in Table 3 . Also, the results appeared in the literature for the other network are used and the details are given in Table 3 . Making the comparisons by means of data presented in
Table 3 , it can be found that the CLLRNN needs fewer training time steps and hidden layer nodes, and achieves higher accuracy than the MNN. With the same training time step, the CLLRNN performs better than the ERNN in terms of the accuracy. When the performance of the CLLRNN is compared to that of the MNN and ERNN, it can be observed that the CLLRNN shows the best performance in the three recurrent networks, achieving lower RMSE values for both inputs.

Example 4. In the last example, an experimental application to a dc motor connected to a load is presented to show practicability and effectiveness of the proposed neural network. Digiac 1750 DC motor experimental setup in the electrical and electronics engi-neering department laboratory is used. The dc motor operates with a maximum output shaft speed of 2400 rpm and drives a shaft that carries disks that operate various transducers, and a tachogenerator. A low pass filter is used to filter the output speed signal from high frequency noise components. A digital computer is used to obtain input X  X utput data pairs. Output shaft speed is measured from a tachogenerator connected to the motor shaft as volts. A data acquisition card (Advantech, Model: PCI-1716, 250 kHz in speed and 0.03% of accuracy, 16 bit) is utilized to communicate between the plant and the computer. Input is the motor armature voltage and output is shaft speed as volts. The sampling period is taken to be 30 ms for the experimental tests.
The equations for the plant consisting of a dc motor connected to a load via a long shaft can be given as ( Eker, 2010 ; Kayacan et al., 2011 ): v a t  X  X  X  L a di a  X  t  X  dt  X  R a i a t  X  X  X  K m o m t  X  X  X  50  X 
J m d o m  X  t  X  dt  X  T m t  X  X  T s t  X  X  R m o m t  X  X  T f o J L d o L  X  t  X  dt  X  T s t  X  X  R L o L t  X  X  T d t  X  X  T f o
T s  X  t  X  X  k s y m  X  t  X  X  y L  X  t  X  X  X  B s o m  X  t  X  X  o L  X  t  X  X  X  53  X  d y m  X  t  X  where v a is the motor armature voltage, R a and L a are the armature coil resistance and inductance respectively, i a armature current, K m is the torque coefficient, T m is the generated motor torque, o m and o L are the rotational speeds of the motor,
J m and J L are the moments of inertia, R m , R L , and B coefficients of viscous-friction, T d is the external load disturbance,
T f is the nonlinear friction, and T s is the transmitted shaft torque, k s is the spring constant, t is the time.
 voltage  X  12 V, no load current  X  120 mA, stall current  X  1.93 A, starting torque  X  7 Ncm/A, armature inductance  X  5 mH, armature resistance  X  6.2 O , time constant  X  19.6 ms, and torque constant  X  3.5 Ncm/A.
 applying an i.i.d. uniform sequence over [0, 10 V] for 300 samples to the plant input. In this real-world problem, the CLLRNN has one node for input layer, one node for output layer, and five nodes for hidden and context layers. The linear activation function is used in the output layer. The hyperbolic tangent activation function is used in the hidden and context layers. In this example, 9000 time steps are used. The learning rate and momentum term are 0.005 and 0.01, respectively. The feedback connection weights are fixed at 0.75 and are not subject to adjustment during training process. The other weights are initialized in the range [ 0.35, 0.35] using a random number generator with a different seed in each case. The training procedure is repeated for 50 times and the best network parameters are used for test phase. For the test phase, the testing data set is obtained by applying an i.i.d. uniform sequence over [0, 10 V] for 300 samples, which are not same as the data used to train the network, to the plant input.
In this example, to show the superiority of the CLLRNN in terms of modeling accuracy, it is compared with the ERNN ( Elman, 1990 ). The ERNN is simulated for comparison purposes. The ERNN has five hidden layer nodes. The hyperbolic tangent activation function is used in the hidden and context layers. With the same training time step and data, the RMSE values of the ERNN for the training and testing data are given in Table 4 . Making the comparisons by means of data presented in Table 4 ,it can be found that the CLLRNN achieves higher accuracy than the ERNN. Convergence behaviors of the ERNN and the CLLRNN are depicted in Fig. 10 in order to compare them. One can see that the CLLRNN converges smoother than the other. Fig. 11 illustrates the output of the real plant and the CLLRNN for the same random test input signals. They almost match each other exactly. 5. Conclusions
In this paper, the architecture and training procedure of a novel recurrent neural network, called CLLRNN, have been described. In order to demonstrate the structural capabilities of the CLLRNN, performance comparisons are made with several recurrent networks suggested in the literature. The CLLRNN is tested on some theoretical and experimental examples which contain linear, nonlinear, and MIMO dynamic systems. Simulation results demonstrate that in almost all cases examined, the CLLRNN has showed superior performance in terms of modeling accuracy. Thus, it can be regarded as a general identification network that can be applied to the identification of a wide class of both linear and nonlinear dynamic systems.
 References
