 Classical retrieval models are primar ily based on exact matching of terms be-tween documents and queries, and are unable to capture relations between queries and documents terms. When users utilize different terms from those that are used in the index to express the same meaning, classical retrieval mod-els suffer from term mismatch problem. Co nsequently, in order to overcome the term mismatch problem, we need a retri eval model that captures semantic re-lations between terms. Term relations are normally obtained from an external knowledge or resource 1 . The integration of term relations contributes to reduce the gap during the matching between a query representation and a document index. Several types of semantic relations are identified between terms. We only focus on hierarchical relations or specific-generic relations.

Term specificity is a semantic property that can be applied to index terms: a term is more specific when its meani ng is more detailed and precise. Term specificity may cause a mismatch when a u ser formulates her/his query using terms which are more general than those in the index. For instance, in the med-ical domain, the terms  X  B-Cell  X  X nd X  T-Cell  X  are more specific than the term  X  Lymphocyte  X . Moreover,  X  B-Cell  X  X nd X  T-Cell  X  X retypesof X  Lymphocyte  X  X n the adaptive immune system. Therefore, when a user query contains the term  X  Lymphocyte  X , then, a document talking about  X  B-Cell  X  X r X  T-Cell  X  is relevant to this query.

Term mismatch has been heavily studied in IR, and various approaches have been proposed to overcome it, generally through a pragmatic or an ad-hoc ap-proach. However, a few of them have focused on formal integration of semantic term relations into retrieval models. Inside the family of language models for IR, the statistical translation models have been shown as an effective way to mitigate the term mismatch problem [3], [9], [20]. Statistical Translation models integrate semantic relations into language models to reduce the gap between documents and queries, but they require an estimation of the translation probabilities be-tween words which is a crucial and hard point. We propose in this paper an alternative approach rather than statistical translation models to formally in-tegrate semantic term relations into the framework of language models. Our approach propose to modify a document according to a given query and some knowledge about term relations. We then integrate the modified document into two smoothing methods from language models: Dirichlet and Jelinek-Mercer. In the rest of the paper, we refer by a term to an indexing term, which can be either: a word, a noun phrase, a n-gram, or a concept [5].

The paper is organized as follows: first, we present the term mismatch prob-lem, and we discuss several approaches to solve this problem in Section 2 followed by our approach presented in Section 3. Our experimental set-up and the em-pirical results are presented in section 4; finally, section 5 concludes the paper and presents the future work. Several techniques have been proposed to tackle the term mismatch problem. Among these techniques: relevance feedback [11], [17], dimension reduction [2], 2.1 Relevance Feedback Relevance feedback involves the user in the IR process in order to reformulate her/his query and to improve retrieval results. There are three types of rele-vance feedback: 1) explicit feedback, 2) implicit feedback and 3) pseudo or blind feedback [13]. Rocchio algorithm [17] is the classic algorithm for implementing explicit feedback which enables the user to select relevant documents in order to reformulate the original query. Query Reformulation is achieved by adding terms extracted from the selected do cuments into the original query.
Implicit feedback incorporates user behavior like clicks or the duration of time spent viewing a document, in order to predict relevant documents which are used to reformulate a user query. Blind feedback automates the manual part of the Rocchio algorithm without any consideration of the user interaction by assuming that the top k ranked documents are relevant. Lavrenko and Croft [11] propose a blind feedback approach to estimate a relevance model. The main problem in implicit and explicit feedback is that they may cause query drift 2 because not all documents in the feedback set may be relevant. Besides, documents in the feedback set, although containing relevant information, are sometimes partially related to the query topic. 2.2 Dimension Reduction Dimension reduction is the process of reducing the chance that a query and a document use different terms for repre senting the same meaning. Among the techniques that are used for achieving this mission, we can mention: Stemming [10], [14], [16], Latent Semantic Indexing (LSI) [7], and Conceptual Indexing [2], [5], [12]. These techniques propose different strategies to reduce the chances that the query and the document refer to the same concept but using different terms.
Peng et al. [14] perform a stemming method according to the context of the query which helps to improve the accuracy and the performance of retrieval com-pared to the query independent stemmers such as Porter [16] and Krovetz [10]. Deerwester et al. [7] propose to solve the dimension reduction by representing queries and documents in a latent semant ic space. In latent se mantic space, each term is grouped with its similar terms. Similar terms in the space tend to be the terms that share the same context. The context is: a sentence, a paragraph, a window of successive words, etc..

Effectiveness of dimension reduction te chniques essentially depend on the ap-plication domain and on the characteris tics of the studied collection. Besides, dimension reduction may cause an oversimplification of the term space that may limit the expressiveness of the indexing language and could result in incorrect classification of unrelated terms [6]. 2.3 Exploiting Term Similarity We present, in this section, a class of retrieval models that attempt to solve the term mismatch problem by exploiting a partial or complete knowledge of term similarity. The use of term similarity enables to enhance classical retrieval by taking into account non-matching terms. We present two categories of models: Vector Space and Language Models. Term Similarity in Vector Space Models. Crestani [6] proposes a general framework to exploit the term similarity into the matching process where w d ( t ) is the weight assigned to term t in the document d ,and w q ( t )istheweight assigned to term t in the query q , as shown below:
In order to consider the non-matching terms from the query, Crestani ex-ploits the term similarity by utilizing a similarity function Sim .If t i = t j ,then and otherwise it is 0.

In fact, Crestani proposes to extend the previous RSV of Equation 1 in two ways. First, he extends the matching process, in case of mismatch: t  X  q and t/  X  d by determining the closest document term t  X  , for which we have maximum value of similarity with the query term t . As a result, the extended RSV max is defined: when t = t  X  then Sim ( t, t  X  ) = 1, and we return back to the Equation 1.
Second, Crestani also extends RSV of Equation 1 by considering, not only the most similar term, but all the related terms from the document to a non-matched query term. As a result, the extended RSV tot is:
Crestani integrates term similarity into vector space model, which is an out-dated model in information retrieval. We propose to integrate term similarity into language models which have been proven as very effective method for text retrieval [15], [21].
 Term Similarity in Language Models. Statistical translation models are shown as an effective way to mitigate the term mismatch [3], [9], [20]. Statistical translation models incorporate semantic relations between terms into language models to reduce the gap between documents and queries. The idea is based on information theory where a translation model estimates the probability of translating a document to a user query according to the probability distribution P ( u | v ), which gives the probability of translating a word v intoaword u . Statistical translation models [3], [9] are related to the second proposition of Crestani [6] where the idea is to conside r the similarity between each query term and all document terms. The results obtained by statistical translation models show that integrating term similarity into language models is more effective than the existing approaches in information retrieval. However, Karimzadehgan and Zhai [9] noticed that the self-translation probabilities lead to non-optimal retrieval performance because it is possible that the value of P ( w | u ) is higher than P ( w | w ) for a word, w . In order to overcome this problem, Karimzadehgan and Zhai [9] defined a parameter to control the effect of the self-translation.
In a nutshell, we can remar k that statistical translation models represent similarity between terms as a translation probability which may cause some problems: 1) the estimation of translation probabilities is not an easy practice, 2) the normalization of the mutual information is rather artificial and requires a parameter to control the effect of the self-translation, and 3) the regularization of the translation probabilities may look uncertain. Therefore, in the next section, we present an alternative approach that i s based on a similarity measure between terms rather than translation probabilities. We believe that our approach is simpler and more efficient than sta tistical translation models. Referring to the different approaches which are presented in section 2, each ap-proach has its strategy to reduce the potential gap that exists between queries and documents: Relevance feedback modifies the user query by adding some terms in order to shift it toward relevan t documents. Dimension reduction rep-resents documents and queries in a new space where the gap between queries and their relevant documents becomes smaller. Exploiting term similarity ap-proaches integrate semantic relations b etween terms into retrieval models in order to reduce the gap between documents and queries.

We present, in this section, our approac h that integrates semantic term re-lations into language models. Our approach modifies documents according to a given query and some knowledge about term relations. We then estimate the document language model according to the modified document in two smoothing methods of language models: Dirichlet and Jelinek-Mercer. 3.1 Query and Knowledge Dependent Document Model Our aim is to reduce the gap between documents and queries by considering semantic relations between query and document terms. To do this, we propose to modify a document index according to the query and the external knowledge about term relations. Classical IR models compute the relevance value between a document d and a query q based on the coordination level, namely d  X  q .Instead of that, we here propose to compute the relevance value by considering also the unmatched terms of the query t  X  q \ d ,where \ is the set difference operator. We therefore expand d by the query terms that are not in the document, but they are semantically related to at lea st one document term. In this way, we maximize the coordination level between the modified document and the query. As a result, we maximize the probability of retrieving relevant documents for a given query. We follow the first idea of Crestani presented in Equation2. Fig. 1 illustrates how we expand d using the external knowledge, denoted by K , in order to maximize the coordination level between d and q . To put it more formally, the modified document, denoted by d q , is calculated as follows: where F ( q \ d, K, d ) is the transformation of q \ d according to the knowledge K and the document d . The knowledge K provides a similarity function between terms Sim ( t, t ) denoting the strength of the semantic similarity between the two terms t and t , see section 3.5. For each term in the query X  X  unmatched terms t  X  q \ d , we look for a document term t  X  which is given by: t is the most similar term of d for t  X  q \ d . Then, the pseudo occurrences of a query term t in the modified document d q rely on the occurrences of its most similar document term #( t  X  ; d ), we define the pseudo occurrences of t as follows: this pseudo occurrences of the term t are then included into the modified document d q . Based on this definition, we now define the transformation function F which expands the document.

Not that, if t is not related to any document term, then we do not have a corresponding t  X  for t . Then, the unmatched term t  X  q \ d will not expand d . Now, we replace the the transformation F with its value in the Equation 4 to obtain the modified document as follows:
The length of the modified document | d q | is calculated as follows:
We see in section 3.3 and 3.4 that the modified document d q will replace d ,and the language models for a query q will be estimated according to the modified document d q instead of d . We believe that the probability estimation will be more accurate and more effective than ordinary language model. 3.2 Language Models Language modeling approach to information retrieval is proposed by Ponte and Croft [15]. The basic idea of language models assumes that a query q is generated by a probabilistic model based on a document d . Language models are interested in estimating P ( d | q ), i.e. the probability that a document d is used to generate query d . By applying Bayes X  formula, we have:  X  means that the two sides give the same ranking. P ( q | d ) the query likelihood for a given document d . P ( d ) is often assumed to be uniform and thus can be discarded for ranking documents, then we can rewrite the formula after adding the log function as: where #( t ; q ) is the count of term t in the query q and V is the vocabulary set. Assuming a multinomial distribution, the simplest way to estimate P ( t | d )isthe maximum likelihood estimator: where | d | is the document length. Due to the data spareness problem, the maxi-mum likelihood estimator directly assign null to the unseen terms in a document. Smoothing is a technique to assign extra probability mass to the unseen terms in order to solve this problem. 3.3 Extended Dirichlet Smoothing Dirichlet smoothing [21] is one of the smoothing technique based on adding an extra pseudo term frequency:  X P ( t | C ) as follows where C is the collection. The main idea of our proposal is to formally integrate term semantic relations into the current Dirichlet formula in order to solve the mismatch. As we mentioned in section 3.1, we assume the case of mismatch: t  X  q ,and t/  X  d . There is a document term t  X   X  d semantically related to t that can play its role during the matching. More specifically, we consider that if t does not occur in the initial document d , it occurs in the modified document d q ,which is the result of expanding d according to the query q and some knowledge 3 .
The probability of the term t is defined according to the modified document model d q . Now, the extended Dirichlet smoothing leads to the following proba-bility for a term t  X  d q , P  X  ( t | d q ) which is defined as: Note that in the special case where all the query terms occur in the document, 3.4 Extended Jelinek-Mercer Smoothing Jelinek-Mercer smoothing [21] is anoth er smoothing technique to add an extra pseudo term frequency:  X P ( t | C ) to the unseen term as follows: The probability P ( t | d ) is estimated using the maximum likelihood Equation 12. Similarly to the previous discussion for extending Dirichlet smoothing, we also refine the probability for a term t  X  d q , P  X  ( t | d q ) which is defined as: 3.5 Term Similarity We only focus, in this work, on the hierarchical relation or specific-generic re-lations between terms. We make the assumption that a term t is semantically related to a term t ,iff t is a descendant of t in the term hierarchy within an external knowledge K . Assume a query term t , t refers to a document term, and the vocabulary V . We define the semantic similarity function Sim ( t, t )as follows, Sim : V  X  V  X  [0 , 1]: 1. Sim ( t, t )=0,if t and t are not semantically related, and t = t . 3. Sim ( t, t )=1,if t = t .
The similarity Sim denotes the strength of the similarity between the two terms (the larger the value, the higher the similarity between these two terms). We propose to use a lightweight way to calculate the semantic similarity between terms. Our semantic similarity relies on a term hierarchy in an external knowl-edge. The similarity between two terms t and t is the inverse of their distance, denoted distance ( t, t ), between these two terms. We use the path length or the number of links in the hierarchy between two terms as distance [19].
The similarity score is inversely proportional to the number of nodes along the shortest path between the two terms. Th e shortest possible path occurs when the two terms are directly linked. Thus, the maximum similarity value is 1: 4.1 Documents and Queries Conceptual indexing is the process of mapping text into concepts 4 of an external resource . Therefore, it needs a resource out of documents and queries which con-tains concepts, their relations, and other information about them. In our study, we use concepts as indexing terms i.e. documents and queries are represented by means of concepts rather than words.

Documents and queries are mapped into UMLS 5 concepts using MetaMap [1]. UMLS is a multi-source knowledge base in the medical domain, whereas, MetaMap is a tool for mapping text to UMLS concepts. Using concepts allows us to investigate the semantic relations between concepts, so it allows to build our concepts similarity values. We only consider, the hierarchical relations or specific-generic relations (ISA) between concepts from the different UMLS con-cept hierarchies. We define general concepts which are internal nodes in a con-cept hierarchy, or nodes which have at least one child. Returning to the example about term specificity in the introduction, the general concept  X  Lymphocyte  X  has two children  X  B-Cell  X  X nd X  T-Cell  X . Then, when a user query contains the term  X  Lymphocyte  X , then, a document talking about  X  B-Cell  X  X r X  T-Cell  X  X s retrieved using our approach. Therefore, general concepts have the potential to be linked, in the case of mismatch, to a descendant concept from a document using our extended matching model. 4.2 Corpora Five corpora from CLEF 6 are used. Table 1 shows some statistics about them.  X  Image2010, Image2011, Image2012: contain short medical documents and  X  Case2011, Case2012: contain long medical documents and queries.
 4.3 Results All the experiments are conducted using the XIOTA engine [4]. The perfor-mance is measured by Mean Average Precision (MAP). The approaches used for experiments are as follows:  X  DIR-BL (baseline): language model with Dirichlet smoothing.  X  JM-BL (baseline): language model w ith Jelinek-Mercer smoothing.  X  DIR-TM: translation model using Dirichlet smoothing [9].  X  JM-TM: translation model using J elinek-Mercer smoothing [9].  X  DIR-CS: our extended Dirichlet smoothing after integrating the concept sim- X  JM-CS: our extended Jelinek-Mercer smoo thing after integrating the concept
Results of our extended language models are summarized in Table 2. We first observe a consistent performance improvement achieved over ordinary smoothing methods for our five target collections, w hich confirms our belief that integrating hierarchical relations from an external r esource improves relevance model esti-mation. Second, the improvement occurs in the studied collection is independent to the length of documents and queries in these collections. It seems to be sim-ilar for both types of collection: 1) short documents and short queries, 2) long documents and long queries. Finally, the improvement in the two collections: Image2010 and Case2012 is not statistically significant because:  X  Image2010: general concepts present in a limited number of queries and not  X  Case2012: the rate of general concepts is not high enough comparing with In nutshell, the improvement is related to the rate of general concepts and their distribution inside queries.

We now check how our extended models performs as comparing with the statistical translation models. Table 2 shows the results for (DIR-CS,JM-CS) and (DIR-TM,JM-TM) methods. Comparing the columns (DIR-CS,JM-CS) and (DIR-TM,JM-TM) indicates that our extended models (DIR-CS,JM-CS) are, in most cases, better than statistical translation models (DIR-TM,JM-TM). Sig-nificant tests using Fishers Randomization [18] show that our extended models are statistically better than ordinary language models in five cases, whereas sta-tistical translation models are statistically better in only three cases. We propose, in this paper, a model to exploit semantic relations between indexing terms in order to overcome the term mis match problem. The proposed approach is based on modifying documents acco rding to a given user query and some knowledge about semantic term relations. We extend the document by query terms which are not in the document but they are semantically related to at least one document term. We then integrate the modified document into two smoothing methods from language models: Dirichlet and Jelinek-Mercer. We only consider hierarchical relations bet ween concepts in our similarity measure. Our experimental results indicate that our extended models are statistically better than exact match approaches, and in most cases better than translation models in retrieval performance. This im provement is independent of the length of documents and queries within the tested collections, but it is related to the rate of general terms and their distribution inside queries. We believe that our extension is suitable to integrate any o ther type of mutual information between indexing terms.

For future work, we plan to validate our extension using other types of rela-tions between terms rather than hierarchical relations. In addition, we plan to apply our extension to other domains rather than the medical domain and other test collections like TREC.

