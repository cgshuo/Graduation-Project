 It is known that memory-based collaborative filtering sys-tems are vulnerable to shilling attacks. In this paper, we demonstrate that hubness , which occurs in high dimensional data, is exploited by the attacks. Hence we explore meth-ods for reducing hubness in user-response data to make these systems robust against attacks. Using the MovieLens dataset, we empirically show that the two methods for reducing hub-ness by transforming a similarity matrix X (i) centering and (ii) conversion to a commute time kernel X  X an thwart at-tacks without degrading the recommendation performance. H.4 [ Information Systems Applications ]: Miscellaneous Collaborative filtering; Shilling attack; Hubness
Memory-based collaborative filtering (CF) is a type of rec-ommendation system that predicts a user X  X  response to un-seen items by referencing past responses from the k -nearest neighbor ( k -NN) users. A considerable drawback to memory-based CF is its vulnerability to shilling attacks . Shilling attacks inject recommendation systems with fake users in order to force the systems to generate biased recommenda-tions [3, 1]. By design, memory-based CF issues recommen-dations based on the past responses to items by other users, rather than the individual to whom the recommendation is made. This design provides room for attackers to alter the system X  X  decision by injecting fake users and forged ratings.
On the other hand, it has recently been found that hubness is subject to a form of the so-called curse of dimensionality c  X  c  X  [5]. That is, in higher dimensions, a small number of objects, called hubs , appear frequently in the k -NNs of other objects.
When k -NNs of users are computed in memory-based CF systems, hub users emerge because past user-response data is generally high dimensional [4, 2]. Because hub users con-tribute to the recommendation process, they can signifi-cantly influence recommendation systems.
 We view shilling attacks as attacks that exploit hubness. The attacks inject fake users that are likely to become hubs, in order to gain maximum control over the output of the systems. To mitigate the effects of the attacks, we pro-pose reducing hubness by transforming the similarity mea-sure used in the k -NN computation. Because shilling at-tacks fabricate objects that are similar to the data centroid in an effort to maximize their influence, we transform sim-ilarity measure such that all objects, including the injected objects, are equally similar to the centroid. This transforma-tion is achieved by computing a commute time kernel from a given similarity matrix [7], or more simply, by centering the similarity matrix [8]. Using the MovieLens dataset, we demonstrate that after such transformation, the hubness of fake users tends to be reduced. As a result, the transfor-mation provides systems with tolerance to attacks, without degrading the accuracy of the predicted ratings. 1
We assume a set of observed responses is provided in a number of users and items, respectively. A component value of R in the u th row and the i th column, R ( u,i ), denotes the degree of preference of the u th user for the i th item. Matrix R may contain missing values, represented by nil ; R is usually very sparse, in the sense that greater part of its components is nil. The goal of the system is to predict the value of each missing component in R , which corresponds to the future response from a user on an item. Using observed responses, memory-based algorithms predict missing values by interpolating the values of the k -NNs.
Although this paper focuses solely on reducing hubness ex-ploited by average attacks against user-based algorithms, the proposal can similarly be adopted for reducing hubness exploited by segment attacks against item-based algorithms.
Below, Pred ( u,i ) denotes a function that predicts a future response of user u to item i .
 Pred ( u,i ) = where Sim (  X  ,  X  ) is a function that returns the similarity of two users, U is a set of the k most similar users to user u as measured by Sim (  X  ,  X  ) that satisfies R ( n,i ) 6 = nil for n  X  U , and is the averaged response of user u to items.  X  [  X  ] is the indi-cator function taking on 1 if the proposition in the brackets holds, or 0 otherwise.

The appropriate selection of a similarity function, Sim (  X  ,  X  ), is important, because the function determines the k -NNs (i.e., U ), as well as their weighting, to compute a weighted sum of the k -NNs X  responses according to (1). A popular similarity function calculates the cosine of the angles be-tween row or column vectors of matrix R , after converting the nil components of R to zeros [6].
 where x u is an N item dimensional vector, the component of which is given as x u ( i ) = R ( u,i ) if R ( u,i ) 6 = nil, x otherwise. One disadvantage of using the above functions is that a bias caused by the difference in each user X  X  mean response is ignored. Therefore, a popular correction is to subtract  X  R ( u ) from each vector component [6, 4, 2]. The resulting similarity using corrected vectors is known as the Pearson correlation between users, as follows. 2
Sim ( u,v ) = Pearson ( u,v ) = where, if R ( u,i ) 6 = nil and R ( v,i ) 6 = nil, then x x ( i ) = 0 and x 0 v ( i ) = 0.
Memory-based CF determines recommendations based solely on users X  responses (i.e., ratings) to items, and therefore, the recommendations can be changed by manipulating the ma-trix R stored in the systems. One such (malicious) manipu-lation, on which we focus in the following, is called average attack [3]. It injects fake users that pretend to prefer target items, as well as imitating genuine users X  average behav-
As opposed to cosine similarity, user vector x 0 u must be recomputed for each user it is paired with. Moreover, the number of nonzero elements of user vectors is determined by the number of items that are given a (non-nil) response by both paired users. For paired users giving responses to a few items in common, the number of non zero elements of vectors becomes small, and hence, the resulting Pearson correlation becomes less trustworthy. Therefore, we employ the shrunken variant N c N number of non zero elements of paired vectors, N c , with a positive valued parameter  X  [2]. Figure 1: N 10 distribution. Objects with large N 10 values emerge in high dimension: max N 10 is 38 in (a) but 133 in (b). Figure 2: Scatter plot of objects for N 10 values and similarity to data centroid. A strong correlation emerges in high dimension (b). ior for other items. More precisely, fake users are tailored to give a high rating for target items, but average ratings for each of the remaining items. As a result, fake users that prefer target items become similar to any genuine users, and therefore, memory-based algorithms tend to falsely associate target items with all genuine users.
Hubness is a new aspect of the curse of dimensionality [5]. Let D be a d -dimensional dataset and N k ( x ) denote the number of times an object x  X  D occurs in the k -NNs of other objects in D under some similarity measure. As the dimension d increases, the shape of the distribution of N changes to become right tail longer, or a small number of objects takes large N k values. Such objects are called hubs , and the phenomenon is called hubness . 3
We now review the emergence of hubness using synthetic data, as reported in [5]. To simulate situations of CF, where each user gives ratings to a few items and thus the rating matrix R is sparse, we produce a sparse dataset. The dataset consists of 2000 objects, each of which is a d -dimensional vector. For each dimension i = 1 ,  X  X  X  ,d , we draw a real number from Lognormal (5; 1) distribution and compute its rounded integer n i . We then choose n i objects out of the Following [5], we evaluate hubness by the skewness of the N k distribution, defined as S N k = E ( N k  X   X  N k ) 3 / X  where E [  X  ] is the expectation operator, and  X  N k and  X  the mean and the standard deviation of the N k distribution, respectively. A large S N k means the emergence of hubness. 2000 uniformly at random, and assign a random number drawn uniformly from [0 , 1] to their i th component. We calculate the similarity between the objects using the cosine similarity.

To illustrate the emergence of hubness, we compare the distribution of N 10 in two cases where the dimension is low ( d = 50) and high ( d = 1000). Figure 1 shows that, in high dimension, objects with large N 10 values emerge, and as a result, the distribution of N 10 becomes skewed to the right. We then compare a scatter plot of objects with respect to the N 10 value and similarity to the data centroid, shown in Figure 2. We can see that a strong correlation arises in high dimension, and this indicates that the origin of hubness is an increased bias to the centroid caused by high dimensionality.
For memory-based CF, Nanopoulos et al. [4] and Knees et al. [2] reported that hubness emerges because k -NNs are computed in high dimensional spaces. Since the number of users and items are usually large, the feature spaces used for computing similarity, such as cosine and Pearson corre-lation, become high dimensional, and hence, hubness occurs. Hub objects very often appear in the k -NNs of other objects, and therefore, are responsible for determining many recom-mendations. However, hubs are not effectively similar to many objects. In other words, hub objects frequently occur in k -NNs only because they are similar to the data centroid in higher dimensions. In fact, according to [2], the perfor-mance of recommender systems is affected by the existence of hubs. In any case, because hubs are influential objects for recommender systems, manipulating hubs from outside the system can be effective for attacking the system.

Indeed, hubness renders memory-based recommender sys-tems vulnerable to attacks. More precisely, fake users in-jected in the system during an average attack are more likely to constitute hubs and affect the system. Therefore, we ex-pect that, by reducing hubness, attacks can be thwarted.
On the premise that specific objects become hubs because they are particularly similar to the data centroid, hubness can be reduced by transforming the similarity measures to make all objects equally similar to the data centroid. Such similarity measures can be obtained by computing a com-mute time kernel from a given similarity matrix [7], or more simply, by centering the similarity matrix [8].

Let N be the number of objects and K denote a similarity matrix of size N . 4 A commute time kernel K CT is given as where L = D  X  K is called a graph Laplacian and D is a diagonal matrix with D ii = P j K ij . Next, let I be an identity matrix and ~ 1 be an N -dimensional all-ones vector. A centered similarity matrix is computed in the form
When the algorithm (1) is used, N = N user and Sim ( u,v ) in (2) or (3) gives the ( u,v ) component of K .
Mean Absolute Error Figure 3: Prediction accuracy without attack using several similarity measures for different k .
We used the MovieLens 1M dataset ( ml-1m ) 5 for evalu-ation. This dataset contains 1,000,209 ratings (i.e., inte-gers from 1 to 5) from 6,040 users and 3,706 items, with every user rating at least 20 items. We examined the al-gorithm (1), which was combined with two similarity mea-sures: cosine similarity ( Cos ), and shrunken Pearson cor-relation ( Pearson ). 6 The parameter  X  for Pearson was set to  X  = 100, following [2]. To reduce hubness, we trans-formed the similarity matrix by converting it by (4) to ob-tain a commute time kernel ( CT ), or by (5) to center the similarity matrix ( Cent ). The main goal of this experiment is to compare the robustness of the system against attacks before and after the transformations.
Before investigating the robustness against attacks, we verified whether or not Cent and CT transformations af-fect the prediction accuracy when no attacks are present. To simulate a recommendation task, we divided 1,000,209 rat-ings in the dataset into 939,809 training data (observed rat-ings) and 60,400 test data (for prediction). 7 8 We evaluated the prediction accuracy using mean absolute error (MAE), a common metric used for evaluating CF algorithms, calcu-T is the set of user-item pairs given as test data (here, | T | = 60400).

Figure 3 shows the MAE of the compared systems for var-ious nearest neighbor parameter k . The figure indicates that Cent almost always decreases MAE (i.e., improves predic-tion accuracy), and CT also decreases MAE for Pearson . For the evaluation of robustness below, we set k = 50, since these are the k values that achieved best MAE overall in the above experiment. http://grouplens.org/datasets/movielens/
We also tested unshrunken versions of Pearson correlation, but the results are not presented here because the prediction accuracy was inferior to that of the shrunken variants.
We used the partition named ra.train and ra.test made from the whole dataset ratings.dat in ml-1m.zip by run-ning a script split_ratings.sh distributed in ml-10m.zip .
Test data is constructed by picking up 10 ratings randomly for each of 6040 users. Table 1: Prediction shift caused by average attack and skewness of the N k distribution ( k = 50 ).
 Figure 4: Behavior of injected users (red points).
We selected 21 movies as target items for average attack, such that the target movies are as close as possible to those presented in Lam et al. [3, Table 1, p. 397], a pioneer work of the average attack. For the setting of attack, we injected 100 fake users that were invented to introduce false ratings into systems. To raise the reputation of the target items, fake users assigned the highest rating (i.e., 5) to target items. For items other than target ones, fake users gave average ratings. That is, for each item, we generated a random number from Normal(  X  ;  X  ), where  X  equals the average rating of genuine users who rated the item and  X  = 1 . 0, and assigned the num-ber after converting it to a nearest integer from 1 to 5. For evaluation, we used a metric called prediction shift , which measures the difference in the predicted rating before and after the attack. We calculated the prediction shift for each pair of genuine user and target item, except those belonging to the training data. We report the average over all target user-item pairs. Smaller the value of the shift, the better.
Table 1 shows the results of the prediction shift caused by the attack. The amount of prediction shift is reduced after the Cent or CT transformations are applied. This indicates that using the transformed similarity measures makes the recommendation system robust against the attack.

We now analyze why Cent and CT provided robustness against the attack, in terms of hubness. Figure 4(a) shows a scatter plot of users for Pearson , where the horizontal axis is N 50 , and the vertical axis represents similarity to the data centroid. The scatter plot indicates that a strong correlation was observed, and hence, hubness occurred. In addition, fake users injected by the average attack (displayed as red points) had a higher similarity to the centroid, because they were invented to imitate the average genuine user. There-fore, injected users became hubs that have large N 50 values ( min 465 and max 961) as compared to most genuine users, as seen from the N 50 distribution in Figure 4(b). In con-trast, hubness was reduced by Cent or CT transformations, resulting in a decrease in the N 50 values of injected users be-tween min 101 and max 156 using Cent , as shown in Figure 4(c), and a decrease between min 0 and max 4 using CT , as shown in Figure 4(d). It clearly shows that injected users appeared less frequently in k -NNs of other users by using Cent or CT than using original Pearson . Thus, fake users became less influential in determining recommendations.
In total, applying transformations that reduce hubness, we can obtain the system with more robust against attacks as well as comparative or even better prediction accuracies than using the original similarity measures. We have proposed a method for making memory-based CF robust against shilling attacks, by reducing the hubness that occurs in the user-response data. Our approach stands on the ground that hubness is one of the primary factors exploited by shilling attacks. We applied to the similarity matrix two transformations that are known to reduce hub-ness: centering and conversion to a commute-time kernel. Using the MovieLens dataset, we demonstrated that these transformations make the recommender system less suscep-tible to shilling attacks without degrading its recommenda-tion accuracy. [1] R. Burke, B. Mobasher, R. Bhaumik, and C. Williams. [2] P. Knees, D. Schnitzer, and A. Flexer. Improving [3] S. K. Lam and J. Riedl. Shilling recommender systems [4] A. Nanopoulos, M. Radovanovi  X c, and M. Ivanovi  X c. How [5] M. Radovanovi  X c, A. Nanopoulos, and M. Ivanovi  X c. On [6] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [7] I. Suzuki, K. Hara, M. Shimbo, Y. Matsumoto, and [8] I. Suzuki, K. Hara, M. Shimbo, M. Saerens, and
