 emerging subject in data mining with various time-sensitive applications such as intensive unit found that abnormal heartbeat rate was significantly associated with early as possible may lead to earlier diagnosis and effective treatment. 
The aim of early classification is naturally different than that of classic classifica-tive early classifiers have been proposed to make early prediction on univariate time series [18, 19], and these classifiers reta ined accuracy which was comparable to tradi-tional classifiers [2, 4, 14]. However, to gain insights into the classification results in need to be considered further. 
To overcome the deficiency of the previous early classification methods that consider emerged as a novel and important topic of research [7, 8, 10]. The common idea of the existing methods is to extract multivariate shapelets as main features from all dimensions of time series with numerical attributes (or called numerical time series) that can manifest the target classes, where shapelet indicates a segment of numerical time series [8, 14, 20]. However, multivariate time series is usually composed of both numerical and categorical attributes in lots of real world data sets. For example, chronic asthmatic sufferers have to series with numerical and categorical attributes. Moreover, Xing et al. [18, 19] argued that an early classifier should guarantee the stability of accuracy which was comparable to the classifier to be reliable and consistent.

In this paper, we propose a novel method for reliable early classification on M ulti-MTS-NC ). However, achieving such an aim is not an easy task with the following challenges: (I) Multivariate time series is heterogeneous and each variable has differ-find the potential interactions/relations between different variables in MTS-NC . (II) It is not an easy task to build an early classifier being serial on MTS-NC . To the best of ments such as discrimination, frequency, earliness are employed to estimate the quali-obtaining the features satisfying these conditions. (IV) The proposed classifier has to different phases. However, the two-phase approach cannot be directly employed to generate patterns from MTS-NC , which might lead to a huge number of redundant with numerical attribute, discovering shapelets still has a higher computation overhead on existing methods [7, 8, 10]. 
To address all of the above challenges, this paper proposes a novel framework named REACT on MTS-NC . The major contributions of this work are shown below: 1. REACT incorporates the concept of heterogeneous multivariate time series with both numerical and categorical attributes into early classification to simultaneously consider numerical and categorical time se ries on construction of early classifier. 2. REACT constructs a reliable early classifier which is serial and guarantees the sta-bility of accuracy compared to the classifier using full-length time series. 3. To avoid generating a huge number of features which may be redundant, we design a procedure of feature extraction in REACT named MEG ( M ining E quivalence classes with shapelet G enerators) based on the concept of Equivalence Classes 
Mining [12, 15]. MEG can efficiently and effectively generate the discriminative features. In addition, several strategies are proposed to prune the search space and reduce the number of redundant features in the processes of feature extraction. 4. Since discovering shapelet generators takes huge calculation operations, REACT incurs still high computation overhead. In view of this, we employ and integrate concepts of GPU technique of parallel computing [4] to propose a process of pa-rallel MEG for substantially reducing the computational overhead of discovering shapelet generators. 5. We conduct an extensive empirical evaluation on several real datasets. The results show that REACT outperforms the state-of-the-art method in terms of f-score and earliness. In addition, the GPU implementation significantly runs faster than the baseline approach of building REACT by several orders of magnitudes. 
The remainder of this paper is organized as follows. Section 2 introduces the back-ground of early classification on multivariate time series. We then describe REACT in give prospective future work in Section 5. 2.1 Preliminaries We introduce definitions and properties related to early classification on multivariate time series. For more details, readers can refer to [8, 14, 18, 19, 20]. r len ( t ) &gt;, where len ( t ) is the length of t and r Given a time series t = &lt; r 1 , r 2 , ..., r number for 1  X  i  X  len ( t ) . A MTS-NC mt = { t 1 , t where t x is a categorical/numerical time series, where 1 responding class label of MTS-NC mt . Dataset of MTS-NC D is a collection of mt and C ( mt ), where C ( mt )  X  class label set C . In addition, D example of MTS-NC . Definition 2 (Subsequence and super-sequence of time series). Given two time series t = &lt; r 1 , r 2 , ..., r len ( t ) &gt; and t  X  = &lt; r say that t X  is a subsequence of time series t if there exists a sequence of integers 1 &lt; z &lt; ... z len ( t  X )  X  len ( t ) such that r i  X  = r zi t . On the other hand, t is a super-sequence of time series t  X . Definition 3 (Shapelet/Numerical feature). Given two numerical time series nt 1 and subsequences of time series as ST ( t ) l = { ST ( t ) Euclidean distance is defined by dist ( nt 1, nt 2) =  X  nt 2) = minimum { dist ( nt 1, ST ( nt 2) j , len ( nt 1) len ( nt 2). A shapelet/numerical feature is a pair ( s , s= &lt; r , r 2 , ..., r len ( s ) &gt;, and r i  X   X  for all i ( 1 a time series t , denoted by f  X  t , if BMD ( s , t ) Definition 4 (Categorical feature). Let ct be a categorical time series, a categorical feature is a subsequence of length l extracted from ct and denotes by f = &lt; r where l  X  len ( ct ).
 Definition 5 (Utility of a feature). Given a feature f and a dataset of MTS-NC D con-taining N instances and C different class labels, and assume that each class label c n instances in D , where 1  X  i  X  C and N =  X  n i  X   X  X  X  X  =  X   X  X  X  X  . In addition, the minimum prefix of t is defined as the readings from the first reading to the i th reading, where f firstly appears in t for 1 is denoted as minprefix ( t , f ). Its Earliest Matching Time is the time point of minimum ( E ( D ) X  E ( D f ))  X   X  wsup ( f ), where D f = { mt | mt where f appears in, and  X  X  X  X   X   X   X   X  measure frequency and earliness of features, in which | D | is the number of instances in D . The parameter  X   X  1 determines the relative importance of information versus earliness and popularity. Definition 6 (Information gain and separation gap w.r.t. a shapelet). Given a da-taset D and a shapelet f = ( s ,  X  ), the information gain of the split point stances match f , and D n is the remained time series removing D 2.2 Related Works Early classification on numerical time series aimed to classify a partial case only using the prefix of complete time series, which was first introduced by Diez et al. [4]. They Xing et al. [18] then explored a feature based method for early classification on cate-gorical time series. However, it had to discretize the time series when this method was neighbor approach to tackle the problem of early classification on numeric time series. emerged as a novel and important topic of research [7, 8, 10]. In the existing frame-where shapelet is a segment of numerical time series [8, 14, 20]. However, multivariate world data sets. Therefore, this paper simultaneously considers MTS-NC on construc-tion of early classifier. In this section, we shall describe the proposed methodology named REACT ( Reliable attributes (abbreviated as MTS-NC ). The framework of REACT is shown in Figure 2. We will introduce each process in the following subsections, and we discuss imbalance problem and implementation on GPUs in the last two subsections, respectively. 3.1 Feature Extraction concise and lossless representation of frequent itemsets, and they have been extensively studied [6, 13]. In addition, by Minimum Description Length principle, generators are preferable to closed patterns for model selection and classification [6, 13]. In [3, 12], authors gave discussions for the benefit of generators over closed patterns. 
In the following paragraphs, we introduce how to extract categorical generators and shapelet generators from categorical and numerical time series, respectively.  X  Categorical Generators Extraction bound of utility is computed as SeqUB ( f ) =  X  X  X  X  X  X  super-sequence of f X  must be less than min_utility [17]. Definition 7 (Extension timestamp of a categorical feature w.r.t a categorical time ries S is defined as ET ( f ) = { t | t = matching time + 1, t database of prefix s once, and compute the exact utility for each item Initially the prefix is empty, and the projected database of empty is the original dataset. should be continued or not by Downward Closure Property of Non-Generator [17].  X  Shapelet Generators Extraction We adopt best matching distance as the similarity between shapelet f and time series t  X  ), once we find that the distance between t and f is no greater than the distance thre-shold  X  . In addition, if several shapelets in the different classes satisfy the assumption, we select the first shapelet. Furthermore, to avoid existence of redundant patterns in the set of shapelets, generator mining is applied to shapelet extraction. Definition 8 (Shapelet generator). A shapelet f = ( s , (I) there is no shapelet f X  = ( s X  ,  X   X  ) satisfying U ( f X  ) the same equivalence class. Example 1. Given two shapelets f 1 = (&lt;10, 20&gt;, 10) and f belong to the same equivalence class, and f 1 and f 2 have the same covered instances. In addition, f 1 has higher utility value because f 1 precedes f of &lt;15, 15, 30&gt;, and f 1 is a generator in the equivalence class. 
We show the procedure of Mining Equiva lence classes with shapelet Generators tances from candidates to all time series (line 1-5). For the length of shapelet between minLen and maxLen , the best matching distance (which refers to Definition 3) are computed (line 6-8). After the distance thresholds are calculated, the information gain and separation gap are computed for each candidate (line 9), and the procedure then obtains the set of the supporting instances of shapelets to determine equivalence classes (line 10-12). If the utility of shapelet is no less than user-specified threshold, it is collected into the set SGs (line 13). 3.2 Feature Selection As indicated by many existing associative classification [2, 4, 14], learning an optimal equivalence classes in descending order using their utility score, and then iterates over the features starting from the highest ranked one. 
Step 1. We select the feature and remove all covered instances. Here, a feature f
Step 2. We then use the next highest ranked feature to see whether it covers any 
Step 3. If it covers some of them, then we select the feature and remove all in-
Step 4. This process continues step 2 to step 4 until the set of extracted features or 3.3 Feature-Based Sequential Pattern Discovery In discovery of feature-based sequential patterns, we consider two kinds of combina-tions of features, sequential combination and simultaneous combination, to improve further the effectiveness of the classification model. Therefore, to discovery the rela-tionship of the features mined from feature extraction, we associate each feature with a unique identifier, and then construct encoded sequence database composed of these identifiers. Figure 1(c) shows an example of encoded sequence database. 
However, the encoded sequence dataset contains simultaneous event type, and there is more than one item at the same timestamp. It may increase the complexity of patter mining procedure. The downward closure Property of Feature-based Generator is thus proposed to modify for reducing the computational overhead. Definition 9 (Simultaneous extension timestamp). The simultaneous extension time-stamp of a feature-based sequential pattern P for an encoded sequence S is defined as  X  X  X   X   X , X   X   X   X   X  |  X  X   X  X   X  X  X  X   X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  . Property 1 (Downward closure property of feature-based generator). Given a feature-based sequential pattern P 1 , if  X  a pattern P { P }-projected database and { P 1 }-projected database are the same, and P sub-pattern of P 1 , and then, any serial extension of P hand, if SET ( P 1 ) = SET ( P 2 ) for each instance and P simultaneous extensions are not generators. 3.4 Serial Decision Tree information from Feature-based Sequential Pattern Discovery, as shown in Figure 4. Similar to classical decision tree algorithm [2, 6, 17, 19], we select the attribute of the constructed recursively. In addition, for each leaf node in SDT , we consider the stabili-make sure that all error rates at timestamp MPL+ k for k Definition 10 (Error Rate of a leaf node). The error rate of a leaf node N in SDT is a ratio of difference of classification results between subspace formed by the prefix of the sub-dataset which N represents and SDT(mt ) is the class label of multivariate time series mt classified by SDT at time point l . 3.5 Imbalance Issue To tackle the imbalance problem, we utilize the ratio of sub-dataset to instead of using the standard information gain and determine the discriminations of features, as shown in Definition 11. Definition 11 (Ratio confidence and ratio entropy). Given a dataset D from C dif-ferent classes and a sub-dataset D f from D , the ratio of D stances of majority class and minority class are 1733 and 72 respectively, and suppose all instances in this dataset match P . The confidence and entropy of P are 96% and 0.24 respectively. It is a highly discriminative pattern at first sight. As a matter of fact, this pattern always appears in this dataset. In this work, the discrimination is estimated by the modified formula such that rconf ( P  X  c ) = 50% and rE ( D 3.6 Implementation on GPUs For each thread, parallel MEG loads all subsequences of time series in dataset to shared memory T i and synchronizes all the threads (line 1-2). Then again, parallel MEG loads all subsequences to shared memory T j and performs calculation of line 06-13 of algo-rithm MEG for each thread (line 3-6). Finally, parallel MEG returns the set of shapelet generators (line 7). sifier. All experiments were performed on a computer with a four-core Intel Xeon host CPU at 2.40GHz with 96GB of memory, and this computer combined an NVIDIA Fermi C2075 GPU with 448 cores at 1.15GHz, 64KB shared memory per GPU multi-processor, 64KB constant memory, and 6GB global memory. All algorithms are im-plemented in Java language and the GPU code is implemented in CUDA C++. 
The experiments were performed on several real-world datasets: drug response [3], robot execution failures [1], ECG [16], wafer [16] and asthma [11]. Table 1 shows the characteristics of the datasets in the experiments. For evaluating the performance of the results. We compare five versions of the algorithm named as follows: REACT , REACT -Full ( REACT with full-length time series), MSD ([8], the only study addressed to early classification with interpretability on multivariate time series), MSD-Full suggested by a comparison of dozens of time series classification algorithm on various datasets [5]). The similarity measures of numerical time series for MSD and 1NN-Full are Euclidean distance. 
For shapelet extraction, we set minLen = 1 and maxLen to be 50% of the maximum the average of f-score, applicability and earliness. The average f-score is computed as . In this study, a true positive ( TP ) occurs when the class of time series is predicted negative ( FN ) occurs when the model miss that the class of time series is positive. 
In applicability evaluation, we regard the percentage of testing dataset which can be 
Table 2 lists the results on all datasets where the similarity measurement of numer-ic time series is Euclidean distance. The wafer dataset cannot be handled by MSD as a result of enormous computation cost. In general, REACT outperforms MSD and achieves comparable accuracy to that of 1NN-Full because our algorithm can discover more potential information of multivariate time series. Although MSD makes the MSD prefers earliness and frequency rather than discrimination, the result demon-strates that it is too early to be accurate. Due to characteristic of being serial, the dif-ference of Avg. f-score between REACT and REACT -Full is small, which shows that REACT can capture the key features with suitable lengths of prefixes and make con-fident classification at appropriate timestamp. 
Table 3 compares the training time of REACT , REACT on GPUs and MSD using the caching technique described in section 3. The result shows that REACT is slower than MSD on small datasets since our approach requires feature extraction and fea-ture-based sequential pattern discovery for each variable and class. However, on the datasets of long time series or large amount of instances, REACT is faster than MSD in execution time. The reason is that MSD have to generate a huge number of shapelet candidates and pick out a small rule set from them. In addition, REACT on GPUs runs faster than REACT over 40 to 150 orders of magnitude on MS70, Robot and ECG Datasets, and over 2 to 4 orders of magnitude on Wafer and Asthma Datasets. We observed that Wafer and Asthma Datasets are large size and Wafer is also a long time series, and they needed lots of distance calculations on subsequences of time series. In this paper, we have proposed a novel methodology named REACT ( Reliable EArly numerical and categorical features. Our experimental results clearly show that REACT REACT model by several orders of magnitudes. for exploration in the future work. For example, we aim to find the significant features combination of non-significant features in di fferent time series may be identifiability wavelet or Fourier transform, may be employed to transform MTS-NC to find the significant combination features.

