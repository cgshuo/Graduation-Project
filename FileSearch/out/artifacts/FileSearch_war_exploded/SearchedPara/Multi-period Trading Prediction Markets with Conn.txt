 Jinli Hu J . HU @ ED . AC . UK Amos Storkey A . STORKEY @ ED . AC . UK Following the mainstream interest in  X  X ig data X , one valu-able direction of machine learning is towards building up distributed, scalable and self-incentivised systems which could organise for solving large scale problems. Recently, prediction markets (Wolfers and Zitzewitz, 2004) show promise of being an abstract framework for machine learn-ers to design these systems. As one type of markets, predic-tion markets naturally introduce the concepts such as self-incentivised computation and distributed environment. Ad-ditionally, the close relationship between prediction mar-kets and probabilities sheds light on a new way of achieving probabilistic modelling (Storkey, 2011).
 Since Pennock and Wellman (1996), researchers have spent decades on building connections between machine learning and prediction markets. However there is still much scope for research in this area. One reason is that the frame-work of prediction markets still leaves open many design decisions, and in order to analyse the markets for machine learning goals one has to first specify a market model to describe the prediction markets. The other reason is that given a market model, we may still not know what the mar-ket is doing, even if we understand agent behaviours and market mechanisms. As distinct from most machine learn-ing methods which explicitly define and optimise certain objectives, markets only introduce local objectives for each individual agent. To interpret a market as a machine learn-ing method, we have to find the global objective that the market aims to optimise. This idea motivates our work. Instead of just focusing on market mechanisms (Chen and Wortman Vaughan, 2010), we would like to incorporate the agents and analyse our market as a whole. This setting is similar to Storkey (2011); Frongillo et al. (2012); Barbu and Lay (2012); but unlike Barbu and Lay (2012), we will build a model on agent behaviours; and unlike Storkey (2011) and Frongillo et al. (2012), we model agents using risk measures, which provides analytical advantages. The novel results of this paper include:  X  a simple model for whole markets, which includes  X  the analysis of the model which shows that there is a  X  a primal-dual relation that exists between the market Let  X  be the space of all possible future states. We say a prediction market is built on  X  if it trades securities as-sociated with the future state  X   X   X  . Specifically, secu-rities are defined as a set of random variables {  X  k (  X  ) } = {  X  ment function, that is, one unit of this security will pay to the holder  X  k (  X  ) if  X  turns out to be the future state. This definition is quite general, and securities defined in this way are also referred to as complex securities (Abernethy et al., 2013). We require that all securities {  X  k (  X  ) } (col-lected into the vector  X  (  X  ) ) are linearly independent, that is, for a  X  R K , we have a  X   X  (  X  ) = 0 only if a = 0 . If they are not, then we can always pick a subset {  X  k 0 (  X  ) } of linearly independent securities from {  X  k (  X  ) } such that all linear combination of {  X  k 0 (  X  ) } (Kreyszig, 2007). There-fore it is redundant to consider {  X  k (  X  ) } that are not linearly independent. As an example, the Arrow-Debreu security is a special case of complex securities. When the sam-ple space  X  is discrete and contains only finite number of states, Arrow-Debreu securities are a set of K = |  X  | secu-rities, in which the k -th one pays one unit if the k -th state is true:  X  k (  X  ) = 1 (  X  = k ) . Note that in general cases K &lt; |  X  | , e.g. when the value of  X  is continuous, there will be infinite number of states but we always have a finite K for practice.
 Agents can only trade these predefined securities. The behaviour of an agent is characterised by its portfolio { w,s k } = { w,s 1 ,s 2 ,...,s K } , where w is the amount of money that the agent has, and s k is the amount of shares the agent holds in security k . We collect all s k into vector s . If an agent has a portfolio { w,s k } , the total payment of the securities is where X (  X  ) :  X   X  R is in essence a random variable on  X  . We call X (  X  ) the risky asset because of its uncertainty and w the risk-free asset . The gross payment is thus which is also a random variable. We call  X  X (  X  ) the (gross) asset . Denote X the set of all X (  X  ) that are accessible for an agent, and similarly  X  X the set of all  X  X (  X  ) . Notice that since {  X  k (  X  ) } are linearly independent, there exists a unique map (bijection) between X (  X  ) and s via (1). Therefore a portfolio could also be represented by { w,X (  X  ) } . In our to make X more abstract, which is not a space spanned by a prefixed number of securities but allows new security types to be added on the fly. This discussion is beyond our scope. A market consists of two processes, that 1) each agent chooses a portfolio { w,X (  X  ) } it would like to hold, and 2) agents try to move to their preferred portfolio by trad-ing. To describe the decision making process we need a model of portfolio selection, while to describe trading we need to specify a market mechanism. These two parts will be discussed in Section 3 and 4.
 Later in this paper, when the context is clear we will omit parentheses and write a random variable in an uppercase letter, e.g. X (except the securities, which are denoted by  X  ), and use the lowercase of the same letter for the value of it, e.g. x . We will also write functionals in letters without any parentheses. Agents select assets based on their preferences. An agent X  X  preference order of two assets is measured by a functional f :  X  X  X  R , such that the agent prefers one asset  X  X than the agent is indifferent between X and Y if and only if f (  X 
X ) = f (  X  Y ) . There are plenty of theories on choosing and analysing a specific form of f . These includes ex-pected utility theory (EUT) (Von Neumann and Morgen-stern, 2007), dual utility theory (Yaari, 1987), risk mea-sures (Artzner et al., 1999), etc. EUT is perhaps the most popular theories in economics and game theory, while risk measures are commonly seen in finance literature. We choose to use risk measures to model agent behaviours. We introduce risk measures in this section, while putting the detailed justification of using risk measures and its relation to EUT in Section 6. 3.1. Risk measures As is indicated by their name, risk measures assign higher scores to assets that are more  X  X isky X . They can also be understood as measures of the potential loss of choosing certain asset. A (monetary) risk measure is defined as a functional  X  : X  X  R such that  X  (0) is finite and  X  satisfies the following conditions (Artzner et al., 1999): Translation invariance If X  X  X  and m  X  R , then Monotonicity If X,Y  X  X  and X  X  Y , then Here X  X  Y should be understood as P ( x  X  y ) = 1 , that is, with the probability of one that X will generate a lower return than Y . Thus monotonicity indicates that an asset with a better return deserves a lower risk. Due to transla-tion invariance, a risk measure maps any risk-free asset to itself, and is additive w.r.t. any risk-free asset. Therefore, the output of a risk measure has the same unit with a risk-free asset, and can be calculated like an asset.
 The domains of risk measures and the preference functional f are different, as risk measures are defined on X while the space of assets that agent can hold is  X  X . Fortunately, we could easily extend the definition of risk measures to the domain  X  X by applying translation invariance (3) A corresponding f can thus be obtained by f =  X   X  . Risk measures are very generic. In our discussion we will use both risk measures and a specific class of them, the convex risk measures (F  X  ollmer and Schied, 2002). A risk measure is convex if  X  X 1 ,X 2  X  X  and  X   X  [0 , 1]  X  (  X X 1 + (1  X   X  ) X 2 )  X   X  X  ( X 1 ) + (1  X   X  )  X  ( X 2 It says that the risk of a combination of two assets should not be higher than holding them separately. In other words, convex risk measures encourage diversification, which is a natural condition on risk measures.
 Examples of risk measures A famous non-convex risk measure is the Value at Risk (VaR) (Linsmeier and Pear-son, 2000), which outputs a threshold loss l such that the probability of  X  X exceeding l is smaller than a predefined level A famous convex risk measure is the Entropic risk measure (F  X  ollmer and Schied, 2004)  X  Here M X ( t )  X  E P [ e tX ] is the moment-generating func-tion, and D [  X || X  ] is the KL-divergence (and this is where  X  X ntropic X  comes in). We mention that the second repre-sentation of  X  E holds for all convex risk measures, and this representation becomes the key to connecting the markets to machine learning (cf. Section 5). 3.2. Rational Choices Recall that a portfolio that leads to a higher value of f ( is preferred. Thus the favourite portfolio of an agent should be the one that maximises f , which we denote by { w,X } opt . The behaviour of choosing { w,X } opt is called the rational choice , and an agent is rational if it always chooses { w,X } opt as its trading goal. Since in our frame-work f =  X   X  , a rational agent will choose will { w,X } opt under the rule of In a market an agent only cares about its own goal (9). It seems like this property prevents us from linking markets to machine learning methods, as the latter always aim to achieve certain global objectives. However, with a care-ful design, we can let our markets implicitly define global objectives and make an agent contribute to the global ob-jective at the same time as it achieves its own goal. In this section we will build our market, a multi-period trading market whose trades are driven by a market maker.  X  X ulti-period X  is used to indicate that the prices of the se-curities are allowed to vary at different time steps, and that agents can trade with the market maker at multiple times (F  X  ollmer and Schied, 2004). The market maker is intro-duced to simplify the market mechanism and to make the market run efficiently.
 It is difficult to characterise the trading process in the mar-kets with unspecified mechanisms, and those markets may not run efficiently. For example, there may not exist a con-sistent agreement among agents on how much should be paid to buy/sell one share of a security. Moreover, one agent who wants to sell a certain amount of shares may not find any buyers (Chen and Pennock, 2007). One way to simplify the trading process is by introducing a market maker (Hanson, 2007). A market maker is a special agent. It is a price maker, who defines the price for trading each security. All agents are only allowed to trade with the mar-ket maker. They can, however, make a trade at any time as long as they agree to pay under the market maker X  X  pric-ing. The pricing rule of a market maker at time step t is a functional c t : X  X  R . At different time steps the cost for purchasing an asset may be different, i.e. it may happen that c t ( X ) 6 = c t 0 ( X ) when t 6 = t 0 .
 Suppose that an agent has a portfolio { w t  X  1 ,X t  X  1 } at time t  X  1 and it would like to buy  X  X t from the market maker at t . The agent cannot propose an arbitrary price  X  w t  X  X t but has to accept the price provided by the market maker  X  w t =  X  c t ( X  X t ) . The updated portfolio is thus dated asset is restricted to  X  X t = X t  X  1 + w t  X  1 +  X  X c ( X  X t ) . Now a rational agent only cares about choosing its optimal purchase amount  X  X t such that  X  (  X  X t ) is min-imised: This portfolio selection procedure leads to Algorithm 1. selection of a rational agent rule c t (  X  ) Choose the  X  X t that minimise (10) Output: {  X  X t ,  X  c t ( X  X t ) } We now consider a multi-period market which involves a set A = { 1 , 2 ,...,N } of agents and a market maker. As-sume that at each round t there is only one agent a t  X  A that trades with the market maker. This assumption indi-cates that each agent trades with the market maker sepa-rately, and they do not cooperate to make a joint purchase. { a 1 ,a 2 ,...,a T } is thus the trading queue of the market. Since there are multiple agents, we use an extra subscript to distinguish the portfolios of different agents. For exam-ple, an agent n  X  A  X  X  portfolio at time t is { w n,t ,X n,t The initial values are denoted with the subscript t = 0 . We collect all w n,t ,X n,t ,  X  X n,t into vectors w t , X t spectively. We assume that agents do not bring in any risky asset at the beginning, which is a natural assumption since only the market maker can issue securities. This assump-tion means we have X 0 = 0 and so  X  X 0 = w 0 .
 At time t , only the agent a t updates its portfolio by trading with the market maker while all the other agents keep the same portfolios as at t  X  1 . Suppose the asset that the agent a would like to purchase is  X  X a t ,t , then for all n  X  A Algorithm 2 runs a multi-period trading market.
 Algorithm 2 A multi-period market with a set A of agents and a market maker Input: initial portfolios { w , X 0 } , risk measures {  X  pricing rule c t (  X  ) , time period T for t = 1 to T do end for We can also split Algorithm 2 into the market maker rou-tine and the agent routine (details in supp.). We do this to emphasise the fact that each agent has its own objective (achieving the optimal portfolio based on its unique prefer-ence), plus a communication with the market maker. 4.1. Appropriate choice of the pricing rule c t (  X  ) There has been plenty of work on studying the pricing rule c (  X  ) of a market maker (Brahma et al., 2012; Pennock, 2004). A popular class of mechanisms is Hanson X  X  mar-ket scoring rules (Hanson, 2007). It is later formalised by Abernethy et al. (2013), who use a set of reasonable axioms to characterise the pricing mechanism. We apply their re-sult to our framework.
 Let  X  X t  X   X  X a t ,t be the trade with the market maker at time t . Consider two situations: 1) a trade happens with the market maker in  X  X ; and 2) a trade happens with the market maker in  X  X 0 and is followed by another trade  X  X 00 , where  X  X =  X  X 0 +  X  X 00 . A natural require-ment is that the cost of purchasing  X  X should be equal to the total cost of purchasing  X  X 0 and  X  X 00 . Under this condition, Abernethy et al. (2013) show that there exists a functional c : X  X  R which has the form c t ( X  X t ) = c ( X  X 1 +  X  X  X  +  X  X t  X  1 +  X  X t ) We say a pricing rule c t is path-independent if it has the form of (12), and reload the notation c to represent c t . The primary goal of this paper is to establish an intimate connection between machine learning and our new predic-tion market model. Before we start to analyse the multi-period trading markets, we introduce the machine learn-ing context for which we want our markets to be utilised. Many machine learning tasks could be interpreted under the following generic framework: given a set of data sam-pled from a space  X  , and a hypothesis space P which con-tains a class of accessible probabilities on  X  , we would like to find a probability from P that can best describe the data. Usually we use a functional F : P  X  R to characterise the  X  X est X  performance, such that the best probability is the one that minimises F . Formally, this involves an optimisation problem For specific problems in which the information comes from different parts of the data or the models, F has a form of F = P n F n , the sum of a set of functionals which share the same domain P (see examples in Section 7 for details). We will show that a multi-period market effec-tively defines and optimises a machine learning task whose F = P n F n ( P ) .
 The connection is established in two steps: first we show that the market does have a global objective, and then show that under mild conditions the market optimises the dual of a machine learning problem min P  X  X  P n F n . 5.1. The global objective of a market We show that a multi-period trading market minimises a global objective. The optimisation is done sequentially via the market trading dynamics, that is, an agent will con-tribute to minimising this global objective as long as it makes a trade with the market maker. This argument is formalised in the following Proposition 1 (The global objective of a market) . A multi-period market (Algorithm 2) with a path-independent pric-ing rule market maker aims to minimise the global objec-tive by performing a sequential optimisation algorithm, which is implemented by the market trading process (cf. (10) and c ( X  X 0 t )) and for each time t If the algorithm converges at time t 0 , i.e.  X  X t = 0 for all t &gt; t 0 , then { X n,t 0 } ,Y t 0 achieves a local minimum of the objective L in (14).
 Proof. Outline (details in supp.): recall that at time t only agent a t will trade with the market maker, so  X  X t  X  X at,t and  X  X n,t = 0 ,  X  n 6 = a t . At time t , for any agent n all quantities calculated before t can be treated as con-stants as they could no longer be modified. Therefore, the functional that is minimised in (15a) has the same optimal point as the following functional Define L T = P T t =1 l t and use the translation invariance of a risk measure and the path-independence of the pricing rule. We will end up with where Y t = P t  X  =1  X  X  X  = P n  X  A X n,t holds for  X  t &gt; 0 , and C is a constant. (17) is a sequential minimisation scheme for min L . Finally, if the market converges at time T , we have X n = X n,T and Y = Y T , leading to a local minimal point of L .
 Proposition 1 is the key to understanding the market mech-anism. Despite the fact that the market is set up to let agents behave under their own preferences, the market mechanism ensures that a global objective is established, and that the agent will contribute to optimising the global objective at the same time as it optimise its own goal. The trading pro-cess thus provides a sensible algorithm for achieving this global objective. 5.2. A primal-dual representation via convex analysis One concern is that (14) is not commonly seen in ma-chine learning problems 1 . A different view of this objective should somehow be introduced. In fact, under mild require-ments on the form of risk measures and pricing rules, the global objective forms the dual of the optimisation problem min P  X  X  P n F n ( P ) . The requirement for the risk mea-sures is convexity (6). The requirement for the pricing rules is that it is duality-based (Abernethy et al., 2013). Artzner et al. (1999) and F  X  ollmer and Schied (2002) show that a convex risk measure has a form where P is a set of probabilities on ( X  , F ) such that Q is absolutely continuous w.r.t. P and E Q [ X ] is well defined. The risk measure decreases as E Q [ X ] increases but this ef-fect is penalised by a functional  X  . (18) is in essence a Legendre-Fenchel transform with a slight change on signs (Boyd and Vandenberghe, 2004). We keep following the idea of Abernethy et al. (2013) and apply their duality-based pricing rules to our problem. The authors point out that duality-based pricing rules are well motivated as they meet some natural conditions such as no-arbitrage. A duality-based pricing rule is path-independent and has a form 2 where R  X  denotes the Legendre-Fenchel transform of R . Note that in their work R is required to be convex, but this condition could be relaxed since for any R we could define R 0  X  ( R  X  )  X  = c  X  to replace R , as R 0 is always convex (as it is a conjugate dual) and c = ( R 0 )  X  = R  X  . Now we are ready to show Proposition 2 (The primal problem) . For a multi-period market which involves agents who use convex risk measures in (18) and a duality-based pricing rule market maker in (19), its global objective is a weak dual of where F 0 and F n are functionals that share the same do-main P . Specifically, F 0 = R in (19), and F n =  X  n where  X  n is the penalty functional of agent n .
 Proof. We use the generalised Fenchel X  X  duality (Shalev-Shwartz and Singer, 2007) to derive the Lagrange dual problem of (20). Under the generalised Fenchel X  X  duality, the dual problem (weak duality) is  X  min where F  X  n denotes the Legendre-Fenchel transform. We construct the convex risk measure for each agent n . use (18) and choose  X  = F n  X  n ( X ) = sup For the pricing rule (19) we choose R = F 0 and obtain c = F  X  0 . Substitute them back to the dual problem (21) and we end up with This matches the global objective L (cf. (14)) with a dif-ferent sign. The negation sign is necessary because the La-grange dual lower bounds the primal in general If strong duality holds (Boyd and Vandenberghe, 2004), equality holds in (24) and the global objective is the equiv-alent to the primal machine learning problem.
 Proposition 2 gives us two ways of building the connection between markets and machine learning: 1) If we model a market using our framework, we could then figure out the global objective of the market and then the primal prob-lem, which can be solved using machine learning methods. 2) More interestingly, given a machine learning problem of form (20), we could transform it to a market and solve the problem by running the market, during which we could take the advantage of some market properties, such as dis-tributed environment and privacy, to gain extra benefits. The idea of building models for prediction markets and dis-cussing their relation to optimisation is not novel, and sig-nificant progress has been achieved in the past few years. We will discuss the work that is closely related to ours. In Chen and Wortman Vaughan (2010), the authors show that scoring rule market makers perform online no-regret learning. Their study focuses on the market makers while agents are not directly modelled, which motivates a frame-work for the whole market.
 Storkey (2011) defines and analyses a type of prediction markets based on definitions on the markets, securities, and agents. Agents are modelled by as maximisers of expected utility. By analysing the equilibrium status of the market the author shows that the market can aggregate beliefs from agents to output a probability distribution over the future events. The author focuses on equilibria rather than precise market mechanisms, and does not provide any global ob-jective of the market, which makes it difficult to link these markets to optimisation procedures.
 Frongillo et al. (2012) apply market scoring rules as the market mechanism to the framework of Storkey (2011). The work shows that with a large population of agents whose portfolios are drawn from a demand distribution, the whole market implements stochastic mirror descent . One concern is that they suggest using EUT to model agents but they do not use it to solve the optimal portfolios for the agents. This problem is partially solved by Premachan-dra and Reid (2013), who derives the solution for a certain type of expected utilities. A similar setting is also stud-ied by Sethi and Wortman Vaughan (2013). They focus more on the convergence of the market dynamics, and show how markets can aggregate beliefs by using numerical evi-dences. 6.1. Risk measures and EUT Here we justify the choice of risk measures as the agent decision rules. First, the output value of a risk measure can be treated as a risk-free asset and standard linear oper-ations are well defined for it. In comparison, an expected utility outputs a number that only has abstract meaning, i.e. to measure the degree of agent X  X  satisfaction. Additionally, risk measures force translation invariance by definition, but expected utility functions do not have this property in gen-eral. With the help of translation invariance, the wealth w can always be separated from the risky asset X , which im-plies that the optimal portfolio does not depend on w . This saves us from the trouble of associating w with the aggre-gation weights, as the relationship between them is highly inconsistent and varies dramatically under different utilities (Storkey et al., 2012). Finally, we could always derive con-vex a risk measure  X  u from any expected utility (F  X  ollmer and Schied, 2004) where P is the personal belief of the agent. In fact, the output of this risk measure is the risk premium , the least amount of money that one would like to borrow in order to accept this risky asset. Then a sensible decision rule should be to find an asset that minimises the premium, which leads to risk minimisation. For example, the entropic risk measure in (8) can be given by the exponential utility u =  X  exp(  X  ax ) , with  X  = a (F  X  ollmer and Schied, 2002). In this section we use three examples to illustrate the con-nections between the multi-period trading markets and ma-chine learning.
 Opinion Pooling The opinion pooling problem is a com-mon setting for prediction market models (Barbu and Lay, 2012; Storkey et al., 2012). Garg et al. (2004) show that the objective of an opinion pool is to minimise a weighted sum of a set of divergences. Particularly, for logarithmic opinion pool the objective is to where D [  X || X  ] is the KL-divergence and { w n } are weight parameters.
 Now consider an log-opinion pool of a set of A probabili-ties on a finite discrete sample space  X  with K states. To set up a market that matches the log-opinion pool, we first de-fine a market on the same space  X  and introduce K Arrow-Debreu securities. We introduce N agents, and assign a unique probability P n  X  A to agent n as its personal belief. According to (8), agent n  X  X  risk measure has the form where we let  X  n match the weight w n by  X   X  1 n = w n . For the sake of simplicity, we choose a logarithmic market scoring rule market maker (Hanson, 2007) The market can be run by using Algorithm 2. Two typical simulation results are shown in Figure 1 and 2. The primal problem of this market is (applying Proposition 1 and 2) where the domain P =  X  K is the probability simplex in K dimensions and P 0 = uniform( K ) is the discrete uni-form distribution in  X  K . In this case the optimal P can be analytically solved. Recall that  X   X  1 n = w n and we have Since we introduce the market maker, the aggregated belief P is not a pure weighted product of agents X  beliefs, but with a bias towards P 0 . However, when the population is sufficiently large such that P n  X   X  1 n  X   X  1 0 , the effect of the market maker could be ignored and we will end up with a pure aggregation of agent beliefs (Frongillo et al., 2012). Bayesian Update We give our second example by first setting up a market and then match a machine learning problem to the market. Let us build a market on a con-tinuous sample space  X  = R . We only define one security  X  (  X  ) =  X  , and so the asset X = s X  . We introduce only one agent. Again, the agent is characterised by an entropic risk measures, with coefficient  X  1 and P 1 = N (  X  1 , X  2 the normal distribution. The moment-generating function in (8) is and so the risk measure is  X  1 ( s ) =  X  s X  1 +  X  2 1  X  1 the market maker we use the quadratic market scoring rule c ( s ) =  X  0 s 2 / 2 . Now we could run this market using Algo-rithm 2 with only one agent.
 It can be shown that this market implements a Bayesian maximum a posteriori (MAP) update for the Gaussian, in which the prior is provided by the market maker and the likelihood information is provided by the agent. The MAP update in the primal form is while this update is done by the market in the dual space of the space of the mean parameter  X  (details in supp.). Logistic Regression In the third example we discuss a classical machine learning problem. Given a data set D = {{ x m , y m }| x m  X  R K , y m = { +1 ,  X  1 } ,m = 1 ,...,M } , we would like to build logistic regression model with l 2 regularisation. The objective is
L = min where k X k is the l 2 norm.
 To convert this problem to a market we use (14) and Propo-sition 1. Let the sample space be the space that generates the data  X   X  R K  X  { +1 ,  X  1 } and each future state is associated with a data in  X  ,  X  = { x ,y } . Define K se-curities, each of which is  X  k (  X  ) = yx k . We introduce N = K agents, such that the agent n = k is only inter-ested in trading in the k -th security  X  k . Thus the shares of security k held by agent n is s n,k = 1 ( n = k ) w k , and the asset is X n = s n  X   X  = w n  X  n . The market inven-tory is s 0 = P n s n = w . Let c ( w ) be the first term on the RHS of (33) and define the risk measure of agent n as  X  ( s n ) =  X  s 2 n / 2 . We end up with
L = min Now the market is ready to run under Algorithm 2. In order to show a slightly deeper connection to a specific learning method, we notice that the objective of agent n costly to solve for the exactly minimum of this objective at each time. To get rid of this problem, we could relax the condition that agents behaviour is rationally optimal, and let the agents accept a portfolio as long as it is better than its current position  X  n (  X  s n,t ) &lt;  X  n (  X  s n,t  X  1 agents can take steps towards the optimal solution. This can be achieved by the following portfolio updating rule where a &gt; 0 is adjusted such that  X  n (  X  s n,t ) &lt;  X  In practice a could be chosen by backtracking line search (Boyd and Vandenberghe, 2004). The market we designed above effectively implements a coordinate descent algo-rithm (Luo and Tseng, 1992).
 Note that, instead of introducing N = K agents, we can match the logistic regression problem by using only one agent and allowing it to trade all securities. This will result in a standard gradient descent method. This paper establishes and discusses a new model for pre-diction markets. We use risk measures instead of expected utility to model agents, which results in an analytical mar-ket framework. We show that our market as a whole op-timises certain global objective through its market dynam-ics. Based on this result, we make intimate connections between machine learning and markets.
 One area of future work would be conducting a detailed analysis of this framework using the tools of convex op-timisation. A particularly interesting topic is to find the conditions under which the market will converge. As we have observed, stochasticity plays a key part when a large population of agents are involved, as is the case in most real market settings (Frongillo et al., 2012).
 This work was supported by Microsoft Research Cam-bridge through its PhD Scholarship Programme.

