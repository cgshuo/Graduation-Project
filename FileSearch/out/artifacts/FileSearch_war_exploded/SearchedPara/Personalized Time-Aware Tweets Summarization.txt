 We focus on the problem of selecting meaningful tweets given a user X  X  interests; the dynamic nature of user interests, the sheer vol-ume, and the sparseness of individual messages make this an chal-lenging problem. Specifically, we consider the task of time-aware tweets summarization, based on a user X  X  history and collaborative social influences from  X  X ocial circles. X  We propose a time-aware user behavior model, the Tweet Propagation Model (TPM), in which we infer dynamic probabilistic distributions over interests and top-ics. We then explicitly consider novelty, coverage, and diversity to arrive at an iterative optimization algorithm for selecting tweets. Experimental results validate the effectiveness of our personalized time-aware tweets summarization method based on TPM.
 H.3.3 [ Information Search and Retrieval ]: Information filtering Twitter, tweets summarization, data enrichment, topic modeling
Twitter has amassed over half a billion users in 2012, who pro-duce ( X  X weet X ) over 300 million tweets per day. 1 Twitter users can subscribe to updates from other users by following them, es-sentially forming a unidirectional friend relationship. Moreover, tweets can be  X  X etweeted, X  basically copying a tweet posted by an-other user to one X  X  own timeline. From an information retrieval point of view, the sheer volume of users and tweets presents inter-esting challenges. On the one hand, interesting, relevant, or mean-ingful tweets can easily be missed due to a large number of fol-lowed users. On the other hand, users may miss interesting tweets when none of the users they follow retweet an interesting piece of information. http://blog.twitter.com/2012/03/ twitter-turns-six.html .

One task that is aimed at addressing this dual problem is tweets summarization [6]: to extract a group of representative tweets from a set of tweets. The task is similar to tweet recommendation, but tweets summarization pays more attention to the quality of selected results, including notions such as representativeness and diversity. So far, tweets summarization methods are typically query and user-independent. How to adapt tweets summarization to a specific user is still a topic of ongoing research [4, 5, 7, 22, 31, 36]. Current methods, whether personalized or not, also neglect to explicitly model the temporal nature of the microblogging environment; time-awareness is a key feature of Twitter in general and tweets summa-rization in particular.

We put forward a model for personalized, time-aware tweets summarization (TaTS). We investigate three key aspects of tweets summarization: (a) novelty, preventing near-duplicate tweets to be included, (b) coverage, so as to be representative to candidate tweets, (c) diversity, covering as many aspects as possible. When working with Twitter data, several methodological challenges arise. In order to perform effective tweets summarization, we require a notion of a user X  X  interest. Most Twitter users, however, mostly consume information without producing a lot of information. That is, they rarely post tweets of their own [22]. Hence, in order to in-fer a user X  X  interest in a robust manner, we need to use other signals than just the user X  X  tweets. To address the issue, we incorporate intuitions from the field of collaborative filtering and base our es-timation of a person X  X  interest on those of their friends on Twitter, following [5]. We assume that for each user there exist one or more  X  X ocial circles, X  in which three or more users follow each other and form cliques. We find that people are usually connected to specific communities and assume that each user X  X  behavior on Twitter is af-fected by: (a) a user X  X  private taste, (b) a collaborative effect from social circles, and (c) a bursty component, reflecting current events.
Clearly, a user X  X  interest can change over time. Topic modeling has proven effective for topic detection and user behavior modeling on Twitter [8, 25, 32]. As a dynamic extension of the author-topic model [26], our proposed Tweet Propagation Model (TPM) aims to track both a user X  X  interests and any topic drift arising with the pass-ing of time. Based on  X  X ocial circles", TPM derives the user X  X  in-terest from a dirichlet mixture over interests of someone who share  X  X ocial circles. X  It does so by inferring distributions over topics and interests that change over time. Following existing topic modeling approaches for Twitter [8, 37], we extend TPM and classify the top-ics as (a) personal topics, (b) common topics, or (c) bursty topics. Gibbs Expectation Maximization (EM) sampling [29] is used to infer the posterior probabilities and to estimate the value of hyper-parameters in our topic models. After inferring the probabilities of each tweet, we employ an iterative algorithm to optimize the tweet selection procedure, considering coverage, novelty, and diversity.
Our contributions in this paper are as follows. (1) We propose the task of personalized time-aware tweets summarization, select-ing personalized meaningful tweets from a collection of tweets. (2) We leverage a user X  X   X  X ollaborative influence X  in order to derive the user X  X  interests. (3) We introduce a tweet propagation model to address the potential drift in a user X  X  interests as well as topics over time. (4) We employ a tweet selection algorithm that jointly optimizes for coverage, diversity, and novelty.

The rest of this paper is organized as follows. We introduce re-lated work in Section 2. Our problem formulation is detailed in Section 3. Our strategy for tweet summary generation, is described in Section 4. Section 5 details our experimental setup and Section 6 presents and discusses the experimental results and Section 7 con-cludes the paper.
Our approach builds on earlier work in tweets summarization, tweet recommendation and topic modeling.
Several publications have focused on tweets summarization: the task of selecting a list of meaningful tweets that are most represen-tative for some topic. Most work in the literature concerns tweets as basic constituents to compose a summary. Some authors bring feature-based or graph-based summarization technologies to bear on this task [6, 27], while other methods use a term-frequency based method [28] or a strategy based on mutual reinforcement be-tween users X  influence and qualifications of tweets [9]. Recently, time-aware summarization has been studied by several authors, of-ten in the form of timeline generation on Twitter. Chakrabarti and Punera [4] separate topic related tweets into various periods as an event evolution map, and generate an update-summarization result. Yan et al. [33] propose an evolutionary timeline summarization strategy based on dynamic programming. Evolutionary summa-rization approaches segment post streams into event chains and select tweets from various chains to generate a tweet summary; Nichols et al. [21] propose an effective method to separate time-lines using Twitter. To the best of our knowledge, existing work on tweets summarization focuses on the extraction of representative tweets for specific topics, without considering personalization.
Other work integrates the task of selecting tweets with other web documents: Yang et al. [35] use mutual reinforcement to train both the selection of related web documents and tweets via a single graph factor model. Zhao et al. [37] extract representative key-words from tweets based on a topic model. Tweet ranking has also attracted attention: Weng et al. [31] proposed a graph-based rank-ing strategy for ranking tweets based on the author-topic model.
In recent years, collaborative filtering on Twitter has attracted increased attention. Yang et al. [34] address recommendation and link prediction tasks based on a joint-propagation model, FTP, be-tween social friendship and interests. Ye et al. [36] propose a gen-erative model to describe users X  behavior, given influences from social communities, for recommendation [18, 19]. To track so-cial influence of users in a social network, Xu et al. [32] propose a graphical mixture model to describe user X  X  behavior in posting tweets and analyze the original topic domain for a specific proposed tweet. Chen et al. [5] propose a collaborative filtering method to generate personalized recommendations in Twitter through a col-laborative ranking precedure. Similarly, Pennacchiotti et al. [22] Symbol Description K number of topics U number of users V the size of the vocabulary T number of time periods D t candidate tweets at time t
D t number of candidate tweets at time t , i.e., |D t | u user u on Twitter, u  X  X 
C u,t social circle for user u at t D u,t tweets posted by u at time t
D u,t number of tweets posted by u at time t , i.e., |D u,t F u,t number of friends of u at time t
C u,t number of social circles around u at time t d t tweet published at time t , d t  X  X  t w token/word present in some tweet, w  X  X  z t latent topic at t time, z t  X  Z t c u,t social circle around u at time t , c u,t  X  X  u,t  X  u,t distribution of u  X  X  interests over topics at time t  X  t distribution of topics within a tweet at time t  X  t distribution of words over topics at time t
Z classification of individual topics in  X  or  X   X , X , X ,r hyper-parameters in TPM
N maximum number of tweets returned  X  u,c,t weight of social circle c for user u at t propose a method to recommend  X  X ovel" tweets to users by follow-ing users X  interests and using the tweet content. However, many of these methods ignore the dynamic nature of the problem; with the change of time, user interests may also change.
Topic models [2, 12] are employed to reduce the high dimen-sionality of terms appearing in text into low-dimensional,  X  X atent X  topics. Ever since Hofmann [12] presented probabilistic latent se-mantic indexing (pLSI), many extensions have been proposed. In latent Dirichlet allocation (LDA, [2]) each document is generated by choosing a distribution over topics and then each word in the document is chosen from a selected topic. To handle users X  connec-tions with particular documents and topics, the author-topic model has been proposed [26]. However, for data with topic evolution the underlying  X  X ag of words X  representation may be insufficient. To analyze topic evolution, other models have been proposed, such as the Dynamic Topic Model [1], Dynamic Mixture Models [30] and the Topic Tracking Model [13]. Topic models have not yet been considered very frequently in the setting of Twitter. Twitter-LDA ground" topic and  X  X ersonal" topics [37], while an extension of Twitter-LDA has been proved to be effective in burst detection [8]. Our work is different from the related work mentioned above in the following important ways: (1) our work focuses on person-alized and time-aware tweets summarization and (2) we propose a tweet propagation model by jointly modeling time-aware prop-agation and collaborative filtering from  X  X ocial circles, X  which is different from existing topic models.
Before introducing our method for time-aware tweets summa-rization, we introduce our notation and key concepts. Table 1 lists the notation we use. Given two users u i and u j on Twitter, there are two main reasons for u i and u j to follow each other: either because Figure 1: Example of social circles on Twitter: there are two social circles (indicated using the  X  X  X ) among the five users in this graph, where each pair of vertices in each social circle is connected through the  X  X riend X  relationship. they have similar interests or they have some relationship outside Twitter [32]. If two users u i and u j follow each other, we define them to be friends on Twitter. Given this definition, we define a social circle around a user u to be a set of friends of u such that every pair of users in this set is in the friend relation. See Figure 1 for a schematic representation.
 Similar to the author-topic model [26], we assume that each Twitter user X  X  interests are represented by a multinomial distribu-tion  X  u,t , which may, however, change over time. That is, the time-aware interests of user u are represented as a multinomial distri-bution  X  u,t over topics, where each topic is represented as a prob-abilistic distribution over words [2]. Formally, we have  X  {  X  topic z i for user u at time t .

We further assume that each tweet can be represented as a prob-abilistic distribution over topics. To cater for the phenomenon of user interests changing over time, we assume that topic distribu-tions are dynamic and may differ between time periods. Given a user u , we split the topic set Z t at time t into three classes: Z t = Z u t  X  Z com t  X  Z B t : there exist  X  X rivate X  topics Z depend on the user, there are common topics Z com t that are influ-enced by friends from shared social circles, and there are topics from event-related, bursty sources, Z B t . The latter type of topic will typically transfer from initially being observed at time t into Z com at some later time t 0 .

The dynamic interests of user u at time t , reflected by  X  evolve in different ways depending on the class that a topic z belongs to. For each user,  X  u,t is affected by the following three classes. (a) If z t  X  Z u t is a  X  X rivate" topic, then  X  u u,t,z only depends on (b) If z t  X  Z com t then the topic is dependent on friends in the (c) If z t  X  Z B t is a  X  X urst X  topic,  X  B u i ,z,t is generated according Typically, traditional summarization does not cover the evolution of a specific event. Given a split of a user X  X  history into time pe-riods, the task of time-aware tweets summarization is to select the most representative tweets for each time period, covering the whole event evolution on a timeline. More precisely, given a set of tweets D , a set of time periods T , and a maximum number of tweets per period, N , time-aware tweets summarization aims to extract multi-ple sets of tweets RT t ( 1  X  t  X  T ) from D , where for each time period t , RT t = { d t,x 1 ,d t,x 2 ,...,d t,x N } is a set of representa-tive tweets that summarize the period. Furthermore, personalized time-aware tweets summarization is defined similar to time-aware tweets summarization, but in this case the tweets selected for inclu-sion in RT t need to be relevant based on u  X  X  interests  X  t .
In this section, we detail our tweets summarization method, in-cluding the required methods for joint user-tweets topic modeling, inference and parameter estimation. As input, our method has prob-abilistic distributions from topic modeling. The output is the time-aware tweets summary, i.e., a selection of tweets (per period) satis-fying the user X  X  interest.
We start by proposing the tweets propagation model (TPM) to jointly track dynamic user X  X  interests and topics. The interests of a user u are assumed to be reflected by a multinomial distribution  X  u,t over topics. We assume that the distribution of topics  X  words follows a dynamic propagation process with changes over time. Figure 2 provides a graphical overview of TPM.

In the graphical structure of TPM, we see a number of ingredi-ents. Among the variables related to user u in the graph, z ,  X  and  X  are random variables and w is the observed variable. In the can-didate tweets part,  X  , z and  X  are random variables; D u,t indicate the number of variables in the model. As usual, directed arrows in a graphical model indicate the dependency between two variables; the variables c u,t  X  1 depend on variables {  X  C u,t  X  1 } . The variables  X  com t and  X  u t depend on variables {  X   X  Now, let us give a more detailed technical account of our model. Around user u , there exist multiple social circles. For each social circle c u,t in time period t , there is a random parameter  X  cating the importance of c u,t to u at t . User u  X  X  interests  X  composed of three parts: the personal aspect, the common topic aspect and the bursty aspect, i.e.,  X  u,t =  X  com u,t , X  u the common topics are not only influenced by the user X  X  social cir-cles, but also by his own previous interests. Therefore, we use a Dirichlet distribution to derive the probability of  X  com as: which reflects user u  X  X  interests for common and burst topics at time t  X  1 . The hyperparameter  X  u,t indicates the weight of  X  1. For each topic z,z  X  Z com t  X  Z B t  X  Z u t : 2. For each candidate tweet d t  X  X  t : 3. For user u,u  X  X  : in Equation 1 that we use to calculate  X  com + B u,t . Here, the value of  X 
For private topical aspects  X  u u,t , we use a Dirichlet distribution over x u t =  X  u u,t  X  1 that is derived from values in period t  X  1 . For bursty topics in period t , we only focus on those  X  X urst" words that have a high term frequency within period t . Similar to [32], we de-fine a keyword to be  X  X ursty" if its frequency n w,t at time t is above a threshold value. We derive  X  B u,t from a Dirichlet distribution over the hyperparameter  X  B t .

For a tweet in D t that is posted during time period t , a probabilis-tic distribution  X  t over topics Z t = Z u t  X  Z com t  X  Z from a Dirichlet distribution over the hyperparameter  X  t
For each word w in tweet d t ,d t  X  {D u,t , D t } proposed dur-ing period t , we assign a specific topic z from u  X  X  interests  X  or distribution  X  t for candidate documents. For topic aspects z ( z  X  Z com t  X  Z B t  X  Z u t ), we introduce three kinds of multinomial distribution  X  com t ,  X  u t and  X  B t to reflect the probability over Z Z
B and Z u , respectively. Based on [13, 30], we assume that the common and personal topic propagations follow a Dirichlet distri-bution over the value from the previous interval X  X  distributions, with a weighted prior  X  t = {  X  com t , X  u t } : for common topics z  X  Z we use the Dirichlet distribution to infer from  X  com t  X  1 private topics z  X  Z u t ,  X  u t is derived from  X  u t  X  1
This concludes the technical account of the graphical model de-picted in Figure 2. After computing the models for period t for all users in U , we update the edge weights for the social circles (  X  u,c i ,t ), using related users X  interests  X  and current social circles. Inference for our topic modeling process will then move on to pe-riod t + 1 . The generative process for the TPM model at time interval t , 0 &lt; t &lt; T , is described in Figure 3.
Sampling-based methods for LDA rarely include methods for optimizing hyper-parameters. In the TPM model, since  X  u,t  X  z,t indicate the weight of the results for period t  X  1 for com-putations for period t , it is necessary to find an optimized process for hyper-parameters  X  u,t and  X  f l z,t during our posterior inference. Therefore, unlike many previous dynamic topic models, to infer weighted priors we use a Gibbs EM algorithm [29] to handle the approximate posterior inference step. For user u at time interval t , we first jointly sample topic z i and parameter q i from the i th word in tweet d ( d  X  D u,t ) over other variables. So for u  X  X  tweets we obtain: p ( e i = l,z i = z |W ,e  X  i ,Z  X  i ,x u,t , X , X  u t )  X  where l indicates the possible values of variable e for the i th word in tweet p , and the f l indicate the corresponding kind of topics when e i = l . For private and common topics in u , i.e., l = 0 , 1 , in Equation 2, n u,t d,l,  X  i indicates the number of times that words in d are assigned to label l except for the i th word, whereas n cates the sum of n u,t d,l,  X  i for all values of l . Furthermore, n the number of times that tweet d is assigned to topic z excluding the i th word in d , whereas n u,t w,z,  X  i indicates the number of times that word w is assigned by topic z excluding the i th word. According to Figure 3, if e i = 2 , we are dealing with a  X  X ursty" topic, so the vo-cabulary only refers to the set of  X  X ursty" keywords in {D then x B u,t in Eq. 2 equals to  X  B t .

For the process of sampling candidate tweets from D t , we have a similar procedure, as follows: p ( q i = l,z i = z |W ,d  X  i ,Z  X  i , X  t , X , X  u t )  X  Meanwhile, every time after sampling for p ( e i = l,z i = z ) and p ( q i = l,z i = z ) , we optimize b  X  u,t and b  X  f l z,t,t  X  1 the likelihood posterior distribution so we get b  X  and  X   X 
Algorithm 1 summarizes the Gibbs EM sampling inference based on the equations that we have just derived. During the Gibbs EM Algorithm 1: Gibbs EM Sampling Process during period t
Input :  X  t ,  X  B ,  X  B ,  X  t , X u,t ,  X  f t  X  1 , d t , U , D Output :  X   X  f l t , b  X  t ,  X  e,z  X  and  X  q,z  X 
Initialize  X  t ,  X  B ,  X  B ,  X  t ; Topic assignment for all words for u  X  X  do end sampling process, we estimate the parameters of user u  X  X  interests  X  u,z,t , the probability of topics over candidate tweets  X 
To compute the weight  X  c u,t , we use a Markov random walk strategy, which calculates saliency of a social circle based on  X  X ot-ing X  from others. Since each social circle can be considered as a set of users, an interest distribution  X  com + B c cle c i can be computed as P u 0  X  c a  X  u,t -based similarity matrix SIM u,t among different social circles, where each item SIM u,t i,j is computed based on the diver-gence between two items: We calculate the saliency of c i after normalizing SIM into [ SIM :
After Gibbs EM sampling, for each candidate tweet d t at time t , we have two parametric distributions  X  t and  X  t that reflect the topic-tweet distribution and the word-topic distribution, respectively. I.e., P ( z t | d t ) =  X  z t ,d t and P ( w | z t ) =  X  z,t,w t , we now derive the distribution of interests over topics  X  P ( z t | u,t ) .

Given the distribution  X  u,t , one intuitive way to get the most meaningful tweets is to extract the most similar tweets with  X  from among a candidate set D t . However, a high-degree relevance in latent topic distributions cannot be taken as the only criterion in our tweet selection. Thus after extracting a set of relevant tweets R t from D t , there are three key requirements for an ideal sum-mary [16] that we need to consider in generating a tweet summary: novelty , the coverage and the diversity .

Novelty calculates the semantic divergence between the currently selected set RT u,t and the results in previous time periods RT Our intention is to make the current results as different as possible from previous results as much as possible. Therefore, we have: where the divergence div (  X  p , X  p 0 |  X  u,t ) between  X  calculated based on Equation 7.

Furthermore, a tweet summary should contain important aspects from all related tweets and minimize the information loss with the set of all candidate tweets. Thus, given  X  u,z,t , the coverage be-tween RT and D t is calculated as follows:
L C ( RT |D t ) = X where the divergence div (  X  d,z , X  d 0 ,z |  X  u,z,t ) is calculated as fol-lows: Diversity calculates the information divergence among all tweets within the current candidate result set. Ideally, the tweet summary results have the largest possible difference in topic distributions with each other. The equation is as follows:
L D ( RT ) = X where we compute the divergence div (  X  w,z,t , X  w 0 ,z,t in the same way as Equation 11.

The exact process for generating RT u,t given user u is shown in Algorithm 2. Illuminated by a previous work [33], an iterative optimization algorithm is used to select the set RT u,t . During each iteration n , we extract tweet d x such that d x  X  X  t  X  d substitute d y  X  RT ( n ) u,t when the saliency gain S (( RT S ( RT u,t ) gets a maximum value. The algorithm will converge when S ( RT u,t ) reaches its maximum value.
For our experiments we employ a Twitter dataset that includes both social relations and tweets: we crawl tweets via the Twitter Algorithm 2: Iterative Process for RT u,t Generation.
 Input : D t , RT u,t 0 ,  X  u,t ,  X  t , N ; Output : RT u,t ; Calculate Kullback-Leibler divergence KL (  X  d,t , X  u,t ) ;
Rank and extract relevant tweets to R t by e  X  KL (  X  d,t
Initialize : Extract N tweets from R t to RT u,t ; repeat until  X   X  S d x ,d y &lt;  X  ; return RT u,t . streaming API, 2 which contains a random sample of around 10% of all items posted on Twitter. Timestamps in our dataset are from November 1, 2009 to December 31, 2010; the 2009 part contains 47,373,408 tweets and 562,361 users, while the numbers for 2010 are 295,145,421 and 5,828,356, respectively. Figure 4(a) shows the statistics of the number of tweets per user in our dataset, where we can find that most users (75.2%) in our dataset wrote fewer than 100 tweets. For crawling the social relations, we use the dataset from [15], which includes social relations for all users on Twitter until July 2009. In our experiments, we use only those tweets and users that appear in both datasets. In our experiments we assume social relations among users to remain the same over the entire time period.

Since it is impossible to evaluate the effectiveness if a user posted nothing on Twitter, sparse postings obstruct our experimental eval-uation. We therefore only consider users who posted a sufficient number of tweets for our evaluation: we collect users who post over 100 tweets in our dataset. This results in a subset containing 32,659 users. Thereafter we use social relations to build the social circles around those users. Figure 4(b) shows the number of tweets of these users (y-axis) versus the number of friends on the x-axis. We further remove non-English tweets through automatic language identification [3]. We remove stop words and apply Porter stem-ming [23].
Since each tweet is only up to 140 characters long, the amount of textual evidence to work with is very limited. To remedy this, we employ a state-of-the-art method for linking tweets to Wikipedia articles [20]. In particular, we employ the so-called CMNS method that uses the prior probability that Wikipedia article c is the target of a link with anchor text q within Wikipedia: where L q,c denotes the set of all links with anchor text q and target c .

After we have obtained three Wikipedia articles with the high-est CMNS score, we extract the most central sentences from these Wikipedia articles and append them to the tweet. In particular, we apply a query-sensitive graph-based summarization method, simi-https://dev.twitter.com/docs/streaming-apis . Figure 4: Histograms of the number of users and tweets in our dataset: the left (a) indicates the number of tweets per user in our dataset where the y-axis denotes the number of tweets; while the right (b) indicates the number of tweets per user with its number of friends in Twitter, where y-axis indicates the number of tweets the user wrote and the x-axis indicates the number of friends. lar to [10], to each Wikipedia article to ranking sentences, using the tweet d t as the query. This calculates the score of each sentence via  X  X otes X  from other sentences in a document. Figure 5 shows 4 ex-ample tweets and the appended sentences. Here, the left text box in each item is a tweet and on the right we show the identified sen-tences from the linked Wikipedia articles.
Following existing topic models [11], we set pre-defined values for the hyperparameters  X  t and  X  t in our graphical model: for the weighted parameter  X  u,t and  X  t , we set 50 /K u t to  X  u,t  X  respectively. And we set 50 /K B t to  X  B and 0 . 5 to  X  tively. For the hyperparameters  X  and  X  in TPM, as defined in [14], we set  X  u =  X  com = 0 . 5 and  X  u =  X  com = 0 . 3 . For burst topics we set  X  B =  X  B = 0 . 2 in our experiments. The initial value of  X  u,c i ,t  X  1 for each social circle of u is set to 1 /C u,t  X  is set as 0 . 85 ; and  X  in Algorithm 2 is set to 0 . 0001 . For the num-ber of topics in our topic modeling process, the default values for Z 0 and Z com 0 in our experiments are set to 100 , respectively. To optimize the number of topics, we compare performance in various values and discuss it latter.

Statistical significance of observed differences between two com-parisons is tested using a two-tailed paired t-test. In our experi-ments, statistical significance is denoted using N for significant dif-ferences for  X  = 0 . 01 , or M for  X  = 0 . 05 .
Evaluating the effectiveness of time-aware tweets summariza-tion is a challenging task, especially in the absence of explicit user feedback. One possible solution is to use evidence from users them-selves: we use a user X  X  retweeted post(s) at time t + 1 as the ground truth to evaluate performance of comparisons at time t .
We measure the quality of summaries by counting overlapping textual units between the generated results and the ground truth re-sults. In our experiments, we adopt the ROUGE evaluation metrics [17], a widely-used recall-oriented metric in the task of document summarization that evaluates the overlap between a gold standard and candidate selections. 3 In our experiments, ROUGE-1 ( unigram based method ), ROUGE-2 ( bigram based method ) and ROUGE-W ( weighted longest common sequence ) are used as evaluation met-rics.
Version 1.5.5 is used in this paper. Figure 5: Four examples for entity linking and ranking corre-sponding to four individual tweets, where the textbox on left side indicates the original tweet while the textbox on the right side shows the extracted related sentences. A mixture of the tweet and extracted wiki sentences will replace the original tweet in our experiments.
Given the TPM modeling introduced in Section 4.1, our contri-bution is twofold: (1) we introduce collaborative influence to user X  X  interests detection; (2) we adopt time-aware propagation to infer topics. To evaluate the influence of social circles and time-aware topics, besides our overall TPM-based strategy, we also evaluate the performance of the model that only includes (1) the collabora-tive influence or only the (2) time-aware propagation, respectively.
We write TPM-ALL for the overall process as described in Sec-tion 4.1, which includes both the social influence modeling and time-aware topic and interests tracking. We write TPM-SOC for the model that only considers users X  social influence (so excluding time-aware topic propagation and it doesn X  X  consider if some topic is private or not). We write TPM-TOP for the model that uses a user X  X  own tweets (without social circles but considering topic and interests propagation with the time).

To evaluate our proposed method in more detail, in our exper-iments the baselines not only include widely-used topic models, but also recent user behavior models on Twitter. For those topic models, we use the Author-Topic Model ( AT ) [26] and the Twitter-LDA [37] as baselines for topic models: (AT) focuses on various users X  interests in one static corpus. Since each tweet only has one author, AT X  X  process on Twitter coincides with the LDA modeling process on all tweets written by a specific user. As an extension of the author-topic model, Twitter-LDA (TLDA) classifies topics into private topics and background topic by introducing one bino-mial distribution. For comparison, we use one more state-of-the-art use behavior model, UBM [32]; here, a user X  X  interest is tracked by a mixture graphical model that considers background knowledge, social interests and the user X  X  own interest. The final baseline that we consider is TF-IDF , which uses TF-IDF to re-calculate S in Algorithm 2. Finally, we also use SUM-TF , a baseline used in [4] that extract tweets by ranking tf scores, and Random , which extracts tweets randomly in each period.

For the baseline topic models, we use a similar tweet selection method as in Algorithm 2 to select tweets in each time interval. For Figure 6: Performance of TPM-ALL with various granularities of time periods. static topic models, results at time t, 1  X  t  X  T are calculated after re-modeling for all past data before period t .

To evaluate the effectiveness of results to personalized aspect, we introduce several other sentence extraction procedures from the area of document summarization (without personalization) as base-lines: LexRank and Centroid are two widely-used unsupervised document summarization methods, where LexRank [26] is a graph-based method for ranking tweet as  X  X otes X  from other tweets, and Centroid [24] applies the MEAD summarization method that uses statistical and structural features in tweets selection. To test the optimal granularity of time intervals, we examine ROUGE-1 performance of TPM-ALL with different values for gran-ularities, shown in Figure 6. The performance of TPM-ALL in terms of ROUGE-1 peaks when the granularity is set to 7 days. With fewer than 7 days, performance keeps increasing because adding more days reduces sparseness; but after 7 days, due to the increase in irrelevant and noisy tweets, the ROUGE-1 score de-crease. Thus, we set the granularity to 7 days in the remainder of our experiments. Figure 7: Perplexity performance with different number of top-ics in Author topic model and TPM-SOC model;
Optimizing the number of topics is a problem shared between all topic modeling approaches. Similar to previous work [2, 11, 32], we introduce the perplexity of a held-out test set to evaluate the performance of our topic models. The perplexity, usually used in language modeling, focuses on the inverse of the geometric mean per-word likelihood, which is calculated as follows: ity score indicates a better generalization performance [2]. Figure 7 shows the results of perplexity values for the author-topic model and the TPM-SOC model with differing numbers of topics on our held-out test set. After the number of topics becomes larger than 300 , the perplexity of both approaches starts to flatten out. We find that TPM-SOC outperforms the author-topic model with bet-ter generalization performance. For TPM-ALL and TPM-TOP we set the number of  X  X rivate" topics and  X  X ommon" topics to 150 , separately.
In this section we provide an answer to the following research questions. (1) How does the TPM-based TaTS strategy perform on time-aware tweets summarization ( X 6.1)? (2) How does the TPM-based TaTS strategy perform on social-aware tweets summariza-tion? ( X 6.2)? And (3) what is the overall performance for TPM on the task of personalized TaTS ( X 6.3)?
To illustrate the performance at different time periods, the eval-uation results of the TPM-ALL, TPM-TOP, UBM and AT strate-gies at different time periods are shown in Figure 8, in terms of ROUGE-1, ROUGE-2 and ROUGE-W, respectively. We select 10 contiguous weeks from November 1, 2009 onwards as the test pe-riod and separate it into 10 periods.

In Figure 8 we observe that the AT model obtains the worst performance, while both TPM-ALL and TPM-TOP outperform all other strategies in terms of ROUGE metrics at all time intervals. This demonstrates the advantage of TPM-based strategies in time-aware comparisons. In Figure 8, we observe a  X  X old-start X  phe-nomenon, which results from the sparseness of the context in the first time period. In that condition, TPM-ALL and TPM-TOP are nearly equivalent to the UBM and AT since there are neither social circles nor burst topics during the first time period. After that, the performance of the TPM based methods keeps increasing over time until it achieves a stable performance after t = 3 . We find that TPM based strategies are sensitive to time-aware topic drifting. Mean-while, we find that TPM-ALL performs better than TPM-TOP in Figure 8. TPM-ALL detects user X  X  interests using social circles whereas TPM-TOP ignores them.
To evaluate the influence of social circles in our proposed strat-egy, we investigate the performance under various numbers of so-cial circles. From our dataset, we extract users with different num-bers of social circles and compare the performance of our methods on these data sets in terms of ROUGE. In Figure 9 we plot the val-ues of ROUGE-1, ROUGE-2 and ROUGE-W in (a) to (c), respec-tively. For each figure, we compare our strategies that do consider social circles, TPM-ALL and TPM-SOC, against the TPM-TOP and UBM methods under varying number of social circles.
 We observe from Figure 9(a) that the performance in terms of ROUGE-1 changes with the number of social circles, and the value increases and achieves a maximal value between 3 and 5 social circles. After that, the value decreases rapidly; redundant and ir-relevant  X  X elations X  seem to enter the picture. Another plausible explanation concerns the difference of user characteristics in vari-ous social circles. Since the UBM and TPM-TOP models do not consider the social influence, their ROUGE values keep constant for different numbers of social circles. We observe a similar behav-ior in Figure 9(b) and 9(c) in terms of ROUGE-2 and ROUGE-W.
To evaluate the effect of collaborative filtering in TPM for vari-ous classes of users, especially for  X  X assive X  users on Twitter who rarely write a tweet, we compare the performance of different users in terms of ROUGE metrics with varying values of the number of tweets selected per period ( 40 or 60 ). We separate users into 3 classes by counting their tweets: (1) less than 400 tweets; (2) be-tween 400 to 800; and (3) more than 800 tweets. As shown in Figure 10(a) and (c) that focusing on ROUGE-1, the difference be-tween TPM-ALL and TPM-TOP is bigger for users with up to 400 tweets than for those with more than 400. This can be explained by the fact that the collaborative filtering used in TPM-ALL becomes more effective when there is a bigger data sparseness issue to over-come. In terms of ROUGE-2, similar results can be found in Figure 10(b) and (d).
Table 2 shows the average performance of our TPM-based strate-gies and baselines, in terms of ROUGE-1, ROUGE-2 and ROUGE-W, based on all candidate tweets in all time periods. We find that our method outperforms the baselines in every case. Except for our TPM-based strategies, UBM get the best performance than others. Since summarization baselines are not sensitive to users X  interests, thus we find that Centroid, Lex-R (short for LexRank), and SUM-TF do not perform well. Among the topic models, we found that the AT-based method yields almost the worst performance. This can be explained by the fact that the topic modeling procedure in AT does not capture topic drift and users X  social circles.
We evaluated the performance of the various approaches in terms of the three ROUGE metrics for a varying number of tweets se-lected per period, i.e., N = 40 and N = 60 . As shown in Table 2, TPM-ALL performs better than all baselines on all metrics. For N = 40 , TPM-ALL achieves an increase of 10.6%, 11.6% and 8.9% over UBM in terms of ROUGE-1, ROUGE-2, and ROUGE-W respectively. For N = 60 , TPM-ALL gives an increase of 11.2%, 11.2% and 10.1% over UBM. For the dynamic version without social influence, TPM-TOP outperforms all other baselines also, which indicates the effectiveness of detecting dynamic topics. We further compare TPM-TOP with UBM: for N = 40 , TPM-TOP offers relative performance improvements of 4.1%, 6.25% and 4.8%, respectively, for the ROUGE-1, ROUGE-2 and ROUGE-W metrics, while the relative improvements are 7.8%, 6.7% and 7.3% on the same metrics for N = 60 . We find that TPM-ALL out-performs the UBM baselines with a statistical significance differ-ence at level  X  &lt; 0 . 01 in terms of all ROUGE metrics, whereas TPM-TOP and TPM-SOC outperforms UBM with a statistical sig-nificance difference at level  X  &lt; 0 . 05 .
We have considered the task of personalized time-aware tweets summarization, based on user history and influences from  X  X ocial circles. X  To handle the dynamic nature of topics and user interests along with the relative sparseness of individual messages, we have proposed a time-aware user behavior model. Based on probabilistic distributions from our proposed topic model, the tweets propaga-tion model, we have introduced an iterative optimization algorithm to select tweets subject to three key criteria: novelty, coverage and diversity. In our experiments we have verified the effectiveness of our proposed method, showing significant improvements over var-ious state-of-the-art baselines.

As to future work, we aim to employ a user-study to enhance the accuracy of interest detection, e.g., via an online evaluation. An-other future direction is to take more information and features into account for our task: our current experiments ignore, e.g., URLs appearing in tweets which could enhance our entity linking setup. It will also be interesting to consider other features for modeling, such as geographic or profile information. Finally, our current model is evaluated based on fixed time intervals, which might not accurately (c) ROUGE-1, N=60 reflect bursty topics on Twitter. Therefore, a novel graphical model that includes dynamic time bins instead of the fixed time granular-ities, will be another direction for future research.
 Acknowledgements. This research was supported by the European Community X  X  Seventh Framework Programme (FP7/2007-2013) un-der grant agreements nr 258191 (PROMISE Network of Excel-lence) and 288024 (LiMoSINe project), the Netherlands Organisa-tion for Scientific Research (NWO) under project nrs 640.004.802, 727.011.005, 612.001.116, HOR-11-10, the Center for Creation, Content and Technology (CCCT), the BILAND project funded by the CLARIN-nl program, the Dutch national program COMMIT, the ESF Research Network Program ELIAS, the Elite Network Shifts project funded by the Royal Dutch Academy of Sciences (KNAW), and the Netherlands eScience Center under project num-ber 027.012.105. [1] D. Blei and J. Lafferty. Dynamic topic models. In ICML [2] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. [3] S. Carter, W. Weerkamp, and M. Tsagkias. Microblog [4] D. Chakrabarti and K. Punera. Event summarization using [5] K. Chen, T. Chen, G. Zheng, O. Jin, E. Yao, and Y. Yu. [6] B. Connor, M. Krieger, and D. Ahn. Tweetmotif: [7] G. De Francisci Morales, A. Gionis, and C. Lucchese. From [8] Q. Diao, J. Jiang, F. Zhu, and E. Lim. Finding bursty topics [9] Y. Duan, Z. Chen, F. Wei, M. Zhou, and H. Shum. Twitter [10] G. Erkan and D. Radev. Lexrank: Graph-based lexical [11] T. Griffiths and M. Steyvers. Finding scientific topics. [12] T. Hofmann. Probabilistic latent semantic indexing. In [13] T. Iwata, S. Watanabe, T. Yamada, and N. Ueda. Topic [14] O. Jin, N. Liu, K. Zhao, Y. Yu, and Q. Yang. Transferring [15] H. Kwak, C. Lee, H. Park, and S. Moon. What is twitter, a [16] L. Li, K. Zhou, G. Xue, H. Zha, and Y. Yu. Enhancing [17] C. Lin. Rouge: A package for automatic evaluation of [18] H. Ma, I. King, and M. Lyu. Learning to recommend with [19] H. Ma, D. Zhou, C. Liu, M. Lyu, and I. King. Recommender [20] E. Meij, W. Weerkamp, and M. de Rijke. Adding semantics [21] J. Nichols, J. Mahmud, and C. Drews. Summarizing sporting [22] M. Pennacchiotti, F. Silvestri, H. Vahabi, and R. Venturini. [23] M. Porter. An algorithm for suffix stripping. Program: [24] D. Radev, H. Jing, M. Sty  X  s, and D. Tam. Centroid-based [25] D. Ramage, S. Dumais, and D. Liebling. Characterizing [26] M. Rosen-Zvi, T. Griffiths, M. Steyvers, and P. Smyth. The [27] B. Sharifi, M. Hutton, and J. Kalita. Summarizing [28] H. Takamura, H. Yokono, and M. Okumura. Summarizing a [29] H. Wallach. Topic modeling: beyond bag-of-words. In ICML [30] X. Wei, J. Sun, and X. Wang. Dynamic mixture models for [31] J. Weng, E. Lim, J. Jiang, and Q. He. Twitterrank: finding [32] Z. Xu, Y. Zhang, Y. Wu, and Q. Yang. Modeling user posting [33] R. Yan, X. Wan, J. Otterbacher, L. Kong, X. Li, and [34] S. Yang, B. Long, A. Smola, N. Sadagopan, Z. Zheng, and [35] Z. Yang, K. Cai, J. Tang, L. Zhang, Z. Su, and J. Li. Social [36] M. Ye, X. Liu, and W. Lee. Exploring social influence for [37] X. Zhao, J. Jiang, J. He, Y. Song, P. Achananuparp, E. LIM,
