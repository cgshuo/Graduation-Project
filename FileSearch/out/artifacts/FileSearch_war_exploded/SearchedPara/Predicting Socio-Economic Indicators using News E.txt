 Many socio-economic indicators are sensitive to real-world events. Proper characterization of the events can help to identify the rele-vant events that drive fluctuations in these indicators. In this paper, we propose a novel generative model of real-world events and em-ploy it to extract events from a large corpus of news articles. We introduce the notion of an event class , which is an abstract grouping of similarly themed events. These event classes are manifested in news articles in the form of event triggers which are specific words that describe the actions or incidents reported in any article. We use the extracted events to predict fluctuations in different socio-economic indicators. Specifically, we focus on food prices and predict the price of 12 different crops based on real-world events that potentially influence food price volatility, such as transport strikes, festivals etc. Our experiments demonstrate that incorpo-rating event information in the prediction tasks reduces the root mean square error (RMSE) of prediction by 22% compared to the standard ARIMA model. We also predict sudden increases in the food prices (i.e. spikes) using events as features, and achieve an average 5 -10% increase in accuracy compared to baseline models, including an LDA topic-model based predictive model.
Socio-economic indices such as commodity prices have shown high volatility in several countries over the last few years [13]. Un-predictable price fluctuations, especially of essential commodities, can have adverse effects such as food shortage, uneven distribu-tion and consumption, reduced income among producers, supply chain issues etc. Understanding the factors that impact volatility of socio-economic indicators is a fundamental problem of interest for policy-making [28] and financial institutions [16][35].

Estimation of socio-economic indices naturally relies on infor-mation from multiple sources [14]. However, in existing studies aimed at estimating such variables [26], analysis and forecasting was usually done using structured data sources, considering only a handful of driving factors, which were also chosen manually. There may be unknown factors playing an important role in the indicators X  volatility that may not be captured by such a manual process of selection. In addition, most known prediction mecha-nisms that have leveraged news content have primarily relied on predefined domain-specific features or market sentiment extraction mechanisms to predict variations in specific indices [14].
This paper builds upon the basic observation that real-world events, which manifest themselves in unstructured text streams such as news, blogs and social media, can provide strong signals of the underlying factors that drive fluctuations in socio-economic indica-tors [16]. Numerous existing studies [31][35][39][40] have shown evidence of the impact of financial news on stock market prices, further supporting the observation. Motivated by this observation, in this paper we aim to predict fluctuations in socio-economic in-dicators by automatically extracting (representations of) real-world events from unstructured news sources. More specifically, the ques-tion we address is: Given a structured time series about some socio-economic index of interest and a large corpus of real-world events extracted from news sources, can we learn a predictive model for describing the fluctuations in the socio-economic index by iden-tifying the relevant events that influence it? In the process, we also identify relationships between real-world event occurrences and variations in socio-economic indices  X  for instance, that fes-tivals in India are associated with an increase in tomato and onion prices, or transport strikes called in a region are early indicators of rise in food prices in the region.

Our work fundamentally differs from prior work on two fronts: (a) we explicitly assume no knowledge about the specific events that lead to fluctuations in any given socio-economic index and aim to automatically discover them; (b) we do not use any exter-nal knowledge base or data to build the predictive model, relying solely on the real-world events extracted.

In this paper, we propose a novel generative model to represent events surfacing in the news media, and define several event-driven predictive models for predicting fluctuations in socio-economic in-dicators. The models that we define are also flexible in the sense that they can be used together with existing mechanisms for fore-casting socio-economic indices, such as time series analysis, to im-prove the prediction performance. We present one specific applica-tion in section 7. Our event model is based on the assumption that most news articles talk about only one central (or main) event, a fact observed in prior work [27]. Further, an event is usually asso-ciated with various entities, such as people, organizations, topics as well as metadata like location and time. We introduce the notion of an event class , which represents an abstract grouping of similar events agnostic of spatio-temporal, entity or topic based features. In other words, once we strip all the extraneous details from an event, whatever is left describes the essence of the event and is termed as
We use topic in an abstract sense here and not the technical sense in which it is defined in the topic modeling literature the event class of the event. This is motivated by our belief that the factors that drive fluctuations in socio-economic indicators are more general, and specific details might bias the predictions. As an example, a transport strike happening in a region is already in-dication that a possible price hike might take place. The actual entities involved such as people names and other named entities, do not necessarily provide further evidence. Of course, it is possi-ble that because of the presence of certain entities, such as political parties, the resultant effect of the strike is different because of cer-tain steps/measures taken by the specific entities. But then those steps/measures would also be captured as a different event (more precisely event class) in our model, and therefore would influence the prediction in the end. Grouping the various events together also helps in addressing the sparsity issue mentioned in prior work [29] and helps in generalizing to unseen events more naturally.
Our event model can capture any kind of events, provided that there exists at least one article in the corpus that is about that event. So, our model overcomes two main limitations of existing frame-works  X  lack of flexibility and reliance on external knowledge bases and ontologies [29]. As our model is capable of extracting generic events from any corpus which are not specific to any domain or predefined class, our event-driven predictive models are also not restricted to predicting domain-specific variables and can, in prin-ciple, be used for any socio-economic indicator that is influenced by real-world events. This makes our framework broadly applica-ble to many scenarios.

We evaluate our event-driven predictive models to predict fluctu-ations in food prices for 12 popularly consumed food crops in India. Our experiments demonstrate that incorporating event information in the prediction tasks reduces the root mean square error (RMSE) of prediction by 22% compared to the standard ARIMA model. We also evaluate prediction of sudden increases in the food prices (spikes) using the extracted events as features. Our results show an average 5  X  10% increase in accuracy compared to baseline models, including an LDA topic-model based predictive model.
Recent advances in text mining techniques have produced many low-dimensional representational schemes for text documents. Topic models such as Probabilistic Latent Semantic Indexing (PLSI) [15] and Latent Dirichlet allocation (LDA) [2] can be used to represent a large corpus of documents with a vocabulary  X  100,000 words us-ing just a few hundred topics. These models have made knowledge acquisition from natural language text easier and more effective. In particular, online news articles are a popular source for mining real-world events using these low-dimensional representations. Trend analysis model (TAM) [17] and Temporal-LDA (TM-LDA) [38] model the temporal aspect of topics in social media streams like Twitter. MedLDA [43] uses a maximum margin classifier jointly modeled with topics to build predictive models for categorical and continuous variables. Vaca et al. [37] used a collective matrix fac-torization method to track emerging, fading and evolving topics in news streams. Shahaf et al. [32] developed a scheme to connect re-lated news articles to enable better understanding of news stories.
There have also been works that have explicitly focused on pre-diction of real-world events by mining different kinds of corpora. Radinsky and Horvitz [29] proposed a framework to predict fu-ture real-world events from News and Web data. They designed automated abstraction techniques that are able to generalize from specific entities to broader classes of observations and events. The work by Rudin et al. [30] involves predicting the next event in se-quentially organized data such as a customer X  X  online shopping cart or the winners in each round of a sports tournament, using associa-tion rule mining and Bayesian analysis. Amodeo et al. [1] proposed a hybrid model consisting of time-series analysis, to predict future events using the New York Times corpus. More recently, there has been work which has focused on relationships and dependencies between structured data streams and real-world events. FBLG [5] focused on discovering temporal dependency from time series data and applied it to a Twitter dataset mentioning the Haiti earthquake. Similar work by Luo et al. [21] showed correlations between real-world events and time-series data for incident diagnosis in online services. In most of these works, events and/or topics have just been used as a tool for knowledge acquisition or information ex-traction, whereas our goal is to use the extracted events to predict fluctuations in socio-economic indicators. To the best of our knowl-edge, there has been no previous attempt to combine such events or topics from unstructured text streams with structured data (such as a time-series) to characterize and forecast fluctuations in socio-economic indices.

However, there does exist work in predicting specific variables from news data, such as stock price. Hagenau et al. [11] proposed a new scheme to include context from financial news and market feedback to better predict stock prices. Ming et al. [24] used daily news articles from the WSJ corpus and sparse matrix factorization techniques to predict stock price movement while Gidofalvi [10] used financial news to predict volatility of stock prices based on a naive Bayes classifier. Other works which focus on predicting stock prices include [3][8][41]. Si et al. [33] propose a technique to lever-age topic based sentiments from Twitter to help predict the stock market. Similar works have been proposed for political indica-tors [9]. Our work differs from the aforementioned in that we pro-pose a framework, where we specifically connect real-world events extracted from text data (news articles) to predict external variables or indicators, driven by the assumption that there exists a depen-dency between these variables and real-world events. In a sense, our framework is similar to Google Correlate [25], in terms of general applicability, however we focus on identifying real-world events in news sources whereas Google Correlate focuses on web search logs to determine queries that are correlated with real-world phenomenon. In addition, we propose a novel generative model to identify events that drive fluctuations in socio-economic indicators, whereas Google Correlate uses standard correlation metrics.
We consider the following setup. Consider a corpus D of news articles indexed by time t , so that D t is the collection of news arti-cles published at time t . The granularity of the time index t depends on the particular application -it can be a day, week, month etc. and our formulation is agnostic to the actual granularity. The news arti-cles report real-world events and we suppose that the total number of events reported in the corpus is some fixed but unknown K . We discuss how to identify these events given a corpus of news arti-cles in section 4. In addition, suppose that there exists a function  X  t : D t  X  [0 , 1] K that maps a collection of news articles pub-lished at certain time t , to a vector  X  t ( D t ) = (  X  t 1 that specifies the  X  X ntensity X  of each of the K events at time instant t . In other words, larger the value of  X  tk , more is the proportion of event k  X  [ K ] := { 1 , 2 ,...,K } in corpus D t . Note that  X  will be a sparse vector with most of the entries being zero, corre-sponding to the fact that only a few events will be mentioned in the corpus D t . We call  X  t ( D t ) the event vector at time t and simply refer to it as  X  t in the remainder of the paper, with the collection D being defined implicitly by the time t . For the purposes of defining the problem, we suppose that the mapping  X  t is already provided and discuss how to construct such a mapping from unstructured news text in section 5.

Our objective is to build a model that can predict or forecast socio-economic indicators based on real-world event occurrences. Let y denote a time series of some socio-economic indicator of interest such that y t represents its value at a certain time t . We consider two different prediction tasks:
The above formulation can in principle use any function  X  that maps a collection of news articles into a representation of real-world events. Indeed, our evaluation section looks at different ways to construct the mapping  X  and compare the predictive performance of each of these methods. However, one major contribution of our work is the construction of a specific mapping  X   X  the event class model, which we describe in detail in the next section.
For any generic document, ranging from academic articles to blog posts, topics can be a very important and useful feature for understanding its content. However, for specialized documents like news articles whose purpose is to report stories and incidents, we claim that events , which are aimed at capturing the main  X  X ctions X  or  X  X ncidents X , are more informative than topics , which essentially capture the main themes in the document. We envision topics as being part of the event description but there are additional aspects of events that need to be captured separately.

We now define the major components of our proposed event model. As mentioned in section 1, an event is an amalgamation of many components  X  entities, topics and metadata like location and time. We focus on modeling only the underlying essence of any event, i.e. the action words that are representative of incidents reported in the article. This is in contrast to topic models that con-sider all the words mentioned in a document. These collection of words/phrases are termed as triggers and we define an event class as a collection of related or similar triggers. More concretely, we have the following: Definition 1. Event triggers are a set of words or phrases that describe an action between entities or some incident within text (e.g.  X  X rotesting X ,  X  X looded X  etc.).
 Definition 2. Event class is a broad category of events represented using a collection of related event triggers summarizing that cate-gory of events.
 In essence, event classes encapsulate synonymous words to rep-resent similarly themed events. We use these definitions of event class and event triggers to model events reported in a large col-lection of news articles. We assume that any news article reports one central or main event which is drawn from a finite set of event classes. This event class is identified through the triggers present in the article. Again note that this differs from a standard topic model like LDA which assumes each document is a distribution over dif-ferent topics. Based on the typical structure of a news article, the information to be conveyed to the readers is usually mentioned in the title and the lead (first) paragraph of the article [27]. Thus, we consider the triggers found in the title or the lead paragraph to be an indicator of the underlying event class, the central event of the article is drawn from. A news article sampled from an event class is an instance of that class  X  this instance is called an event . For ex-ample,  X  X ccident X  is an event class whereas a specific occurrence of an accident  X  reported in an article  X  is an event. This specific event also involves location(s), topics (e.g. car accident or an air crash) and other properties, such as, actors, objects etc. A particular event (drawn from an event class) with specific values of actors, objects, location is manifested in one or more news articles. However, the main essence of this event class is carried by the event triggers , which is the primary action that describes the event class. In this example, the trigger is  X  X ccident X  but other words or phrases, e.g. crash, collision, rammed etc., can also replace this trigger without losing the essence of the event class.

The description of an event can be further enriched by identify-ing other information that frequently accompanies this event class. For example, consider the title from a New York Times article after the bombing at the Boston marathon  X   X  X lasts at Boston Marathon Kill 3 and Injure 100". The event triggers in this title are  X  X last X ,  X  X ill X  and  X  X njure X . Clearly,  X  X last X  is the central event in this ar-ticle (which represents the event class related to blasts, explosion, bombing ) but additional triggers (kill and injure) are two events that are closely associated with the central event. This example can be generalized to assume that every central event covered in a news article is typically associated with other events, which are also mentioned in the article. Let us call these additional events as subsidiary events , defined as, Definition 3. Subsidiary events are events mentioned in an arti-cle in addition to the main event of the article. It represents the additional events likely to happen along with the main event. Now, going back to our original assumption that any news article is reporting one central event and if we use a collection of news articles to build an event model, an event can be defined as hav-ing one central event (i.e. triggers drawn from an event class) and mixture of closely associated events or subsidiary events (also, dif-ferent triggers for each subsidiary event drawn from separate event classes). When a news article is published, we claim that it is an instance of an event, generated from the event model. With this, we define an event as: Definition 4. Events are a combination of one central theme and a mixture of subsidiary themes, where these themes are represented as event triggers drawn from separate event classes. Variables/ Description Parameters D Number of news articles K Number of event classes
C k Event class k represented as a set of p k Prior probability of event class C k , U d Event triggers present in article d
C d Event class from which main event in article  X  Dirichlet prior to generate subsidiary events  X  d The proportion of event classes as z dj Which event class produced Finally, a news article is generated as an observable instance of an event sampled from this event model, along with additional infor-mation (e.g. location, timestamp, entities), which completes the description of a particular event instance.
In spite of the dissimilarities, our generative model is motivated by LDA. Consider a corpus of news articles D and let the total num-ber of articles be D := |D| . Suppose the set of all event triggers ex-tracted from the news corpus be given by U = { u 1 ,u 2 ,...,u and let C = { C 1 ,C 2 ,...,C K } denote the event classes, where each C i  X  U is a collection of event triggers and C i  X  C j =  X   X  i 6 = j . As stated previously, our assumption is that every news article de-scribes only one main event and consequently we can associate each news article with a single generative event class. Suppose C d  X  C denotes the (latent) event class of the main event of any news article d  X  D . Note that for ease of notation, we represent the event class of article d as a set instead of an index in [1 ...K ] . Next, suppose that each d  X  D consist of a disjoint union of two sets of words: U d  X  W d where, each u di  X  U d represents an event trigger present in d . The remaining non-trigger words are repre-sented by the set W d . The set of trigger words is further divided into two types: U d = U e d  X  U s d where U e d represents the trigger words occurring in the title and the lead paragraph of article d (viz. the event class triggers) and U s d is the set of subsidiary event trig-gers occurring in the body of article d . The words in W d other features of the news article such as topics, entities, locations, people etc. They can be considered as a description of the event, like where it happened, when it happened, people , organizations involved etc. but we assume that they are independent of the events mentioned in the news article [19]. Given the above, the generative process of the articles given a set of event classes is as follows (also shown in Figure 1). 1. For each article d  X  D , its event class C d is sampled from a 2. For each event class trigger u di  X  U e d in the article d , sam-3. After the main event class along with the main event trig-
The posterior is given by Pr[ C 1: D ,  X  1: D , z 1: D | p ,  X  , U where z d , U d are vectors. In this model, we can observe the vari-ables U d corresponding to (all) the event triggers in article d and we assume that p and  X  parameters are also known. The rest of the variables are latent. A summary of the parameters and vari-ables of this model is presented in Table 1. The posterior distri-bution is used to infer these variables given the news corpus. We used Markov Chain Monte Carlo (MCMC) approximation method to compute the posterior. Our goal is to identify which event class ( C d ) the article d belongs to, by observing the words belonging to the set U d and their positions. In the remainder of this section, we discuss how the set of event triggers U is extracted from a corpus of news articles, followed by how the event classes are constructed from the set of extracted event triggers.
The objective of Automatic Content Extraction (ACE) [7] is to develop automated content extraction techniques to support pro-cessing of natural language text from a variety of sources such as newswire, broadcast conversation, and weblogs. ACE has a spe-cific task for event extraction from news sources  X  which defines event triggers as the words (or phrases) in a sentence that specify the occurrence as well as the type of the event. For example, in the news article headline  X  FIFA Officials Arrested in Corruption Case  X  the word arrested is the trigger word for the event mentioned in the article. Usually event triggers are verbs or nouns present in the sentence that describe some notion of  X  X ction X  or  X  X ncident X . Event triggers can have different forms  X  verbs ( Traders protest over FDI in retail ), nouns ( Burglary in police station leaves cops red-faced ) and sometimes the verb or noun themselves cannot form the trigger but a combined phrase is the trigger ( Number of AIDS patients go up in MP ).

In a standard event extraction task, triggers are extracted at a sentence level to understand the type of event mentioned in the sen-tence. Our goal is to understand the  X  X est X  event type that describes an entire news article. Therefore, we identify which triggers in a news article collectively describe the central event of the article. Typically, a news article is organized as follows  X  a title or head-line which contains a one line overview of the main event; followed by the lead (or first) paragraph of the article which contains a brief description of the main event; then the rest of the article presents details of the central event along with follow-up actions of the main event. Based on this standard flow of a news article, we assume that the triggers appearing in the title and lead paragraph of the article are representative of the main event and consequently, form part of the set of all event class triggers.

Every word in the title and the first paragraph can be classi-fied either as a trigger word or not. As discussed above, a trigger can have any part-of-speech and can consist of single or multiple words. Also, in our setting, a trigger may not be restricted to a 8-class event type/33-class event sub-type specification as proposed in ACE. Thus, existing methods [20][42] are not suitable for our setting.

We implemented a conditional random field (CRF)-based super-vised method to extract the event triggers from the news articles. CRFs are probabilistic models for labeling sequence data and have been used in a variety of tasks such as POS tagging, speech detec-tion etc. Lafferty et al. [18] define the the probability of a particular (output) label sequence o = ( o 1 ,o 2 ,... ) given an (input) obser-vation sequence x = ( x 1 ,x 2 ,... ) to be a normalized product of real-valued potential functions , each of the form
F i ( o , x ) = exp( X where t j ( o i  X  1 ,o i , x ,i ) is a transition feature function of the entire observation sequence x and the labels at positions i and i + 1 in the output sequence; s k ( o i , x ,i ) is a state feature function of the label at position i and the observation sequence x ; and  X  are parameters to be estimated from training data. The probability of the label sequence o is modeled as where Z ( x ) is the normalizing constant and F i ( o , x ) is defined above. The parameters  X  ,  X  can be estimated given a training dataset of input and output sequence pairs using maximum like-lihood estimation technique. In our setting, the training data is in the form of labeled sentences in news articles, where each word in the sentence has a label T if it is a trigger word or NT otherwise. For example, the article title  X   X  X lasts at Boston Marathon Kill 3 and Injure 100" would be labeled as, where, each (word-label) pair represents ( x i ,o i ) where the input sentence x = ( x 1 ,x 2 ,...,x N ) and the trigger label sequence o = ( o 1 ,o 2 ,...,o N ) and N is the number of words in the in-put sentence. The triggers were manually labeled by an annotator to obtain the training, testing and validation datasets. We use a va-riety of features  X  both textual and non-textual  X  to build the CRF model for detecting triggers. Some examples include  X  POS tags, Named-entity tags, position of the word, preceding word, whether present in the title etc. Experiments were conducted using differ-ent feature sets and the best combination was chosen based on the performance on the validation dataset.
Now that we have identified the event triggers present in any news article, the next step is to determine the event classes using the extracted event triggers. The idea is to cluster  X  X imilar X  news articles (describing similar events) and obtain the event triggers that describe events belonging to the same event class. For example, ar-ticles talking about a bomb explosion are likely to have triggers like, explosion, blast, bombing etc. So in our model, an event class is represented by event triggers that are similar to each other. To cluster the event triggers, we need to define a suitable notion of similarity between any two triggers. We use a neural network based language model [23] to learn an embedding of each word. This technique embeds each word (or phrase) from a large corpus of text into a vector space where words appearing in very simi-lar contexts are placed in the vicinity of each other. The learned representations have been shown to have a number of interesting linguistic properties and can be used to cluster words having simi-lar meanings or those used in very similar contexts. In our context, the event triggers extracted from the news corpus (see section 4.2) were embedded in a vector space of dimension 100 and clustered using K -means with the cosine similarity metric [22] used for com-puting distance between any two trigger words. To get the optimum number of event classes, we varied the number of clusters K and used the  X  X lbow X  method [34] to determine a suitable value of K . We ended up with K = 250 event classes for our corpus consisting of articles in a 7-year duration (see section 6 for more details of the corpus).
Our goal is to forecast various socio-economic indices using our proposed event model. In this section, we describe how we con-struct the mapping  X  t (see section 3) from the event class model. After running the MCMC inference, we obtain a posterior distri-bution for the hidden event class C d of each news article d . We assign C d to the MAP estimate, i.e. choose the event class that has the maximum posterior probability for article d given the entire news corpus. Then, we define the proportion or intensity of event k  X  [ K ] at time t as: where D t is the collection of articles published at time t . Once we have the event vector  X  t , the general formulation of the predictive model is: where y t represents the socio-economic indicator whose value is being predicted using the extracted event classes. While the above formulation fully captures the relationship between y t and the co-occurring events appearing in news articles, it is somewhat un-wieldy given that K can be very large. However, we make the observation that in practice, only a subset of the K events actually influence any socio-economic indicator. We extract the relevant events based on co-occurrence patterns according to the method described next.
Our goal is to find a subset of M y  X  K events, that have a strong  X  X ssociation X  with the socio-economic indicator y , in other words, they have discriminative power in predicting fluctuations in y , such as a sudden rise in the price of a particular crop. More formally, suppose that at any time t , if y t is at least 10% higher than y t  X  1 , then we define a spike s t = 1 , otherwise s gives us a spike signal s ( y ) derived from the underlying signal y . We use the likelihood ratio test [12] to identify the events (event triggers) that co-occur with spikes in the signal s ( y ) . Specifically, we use the top 5% event triggers according to the likelihood ratio to construct the set  X  ( M y ) of events that have strong association in predicting fluctuations in y . Given an event vector  X  t at time t , we define the mapping  X  y t : D t  X  [0 , 1] M y as  X  y t = (  X  and employ it in the event-driven predictive model above.
There can be many variations of the general event-driven predic-tive model introduced above. In the rest of this section, we present two specific models.
In the formulation so far, the value of y t was assumed to be in-fluenced by only the events happening at time t . In reality, an event might have a delayed effect on y and only considering events at time t might result in loss of useful information for the purposes of prediction. To capture this dependency, we introduce an additional parameter  X  into the model that measures the window of influence of historical events. In particular, we consider events reported in articles published at times t  X   X ,...,t . The linear model that best approximates y t under this formulation is of the form: where  X  k t  X  j denotes the weight (or impact) of event k at time t  X  j on the current value of the indicator y t .
We discuss here how topics can be used to predict socio-economic indices. A set of topics learned from a large corpus of documents represents the main themes contained in the corpus. For news ar-ticles  X  which can be assumed as a source of events  X  topics can be thought of as the main themes of events covered in the news corpus. Therefore, suppose we learn an LDA topic model [2] over the entire news corpus D , with number of topics as K 0 . The LDA topic model supposes that each article is a mixture of topics, each appearing with different proportions. We construct the mapping  X  (refer to section 3) as follows: given a collection of articles D time t , let  X  di represent the proportion of topic i  X  [1 ,...,K article d  X  X  t . Then we define the topic-based mapping as where where,  X  d,i represents the proportion of topic i in article d appear-ing on day t . This is done to take the maximum proportion of a topic in a day X  X  articles to be representative of the day X  X  topic pro-portion. Alternatively, the average proportion P d  X  di / |D all the articles on day t could have been used to represent  X  design choice is based on the intuition that large presence of a topic in an article has more value than appearing in small proportions in many articles.
The design and the goals of the event model presented in this paper are different from existing event extraction tasks. Thus, it is difficult to evaluate our model using existing gold standard data which are not suitable for our purposes. So, we evaluated the model qualitatively on a corpus of news articles. Our data consists of the archive of the Times of India , the most circulated English daily published in India, between the years 2006 and 2012. The corpus had around 700,000 articles with a vocabulary of around 650,000 words. As we mentioned earlier, there were 250 distinct events classes extracted from the corpus. Table 2 presents 9 ran-domly picked event classes that were extracted from the corpus along with a subset of the subsidiary events associated with each event class. Here, we present 6 randomly chosen trigger words as-sociated with the event class. The corpus contained articles mostly from India, and hence, some words extracted are specific to In-dia. For example, aila was a cyclone that hit the eastern coast of India in 2009, dharna is a Hindi word for protest or agitation. From the table, we can observe that for every event class, the sub-sidiary events are in fact talking about related or associated events. For instance, in the event class corresponding to disease outbreak, most of the subsidiary events describe what follows an outbreak  X  treatment , admitting patients to hospitals and plans for prevention . However, there are also some subsidiary events that are precursors to an event  X  announce , nominate happen before an election. The present version of our model is incapable of differentiating between the subsidiary events that happen before or after an event. A possi-ble future direction can be to classify the subsidiary events among these 2 types, which will provide better insights about each event class.
In this section, we evaluate our event model by demonstrating its ability in predicting the value of socio-economic indicators. We have built event-driven predictive models to forecast the prices of 12 popular crops in India. Events extracted from the news corpus based on our event model (section 4) are used as features in these models. In this paper, we specifically choose food price fluctua-tions as an example scenario to demonstrate how event-based pre-dictive models can be built. However, our approach can easily be generalized to similar socio-economic indicators whose volatility are potentially influenced by events appearing in the news media.
As discussed in section 3, we consider two prediction scenarios  X  predicting the actual (real-valued) price of the crops and predicting spikes in prices. The second predictive model is a binary classifier, predicting the price on a particular day as a spike (1) or non-spike (0). We compared our approach with standard baseline systems. For the real-valued prediction, we compared the performance with a standard time series projection model  X  ARIMA [4]. We show that our event-driven predictive model built on top of the ARIMA model reduces the forecast error compared to the pure ARIMA model. In addition, our spike predictor demonstrates improvement over different baseline systems. We begin with a brief description of the data and then discuss the experiments performed for the eval-uation.
The food price data for the experiments was collected from the website of the Ministry of Agriculture of Government of India The Directorate of Marketing and Inspection under the ministry publishes daily prices of different crops which include the mini-mum, maximum and modal (the rate at which maximum sale was done) prices of these crops across many different markets in the country. In this work, we focused on 12 different crops. We con-sidered the following crops  X  onion, potato, rice, wheat, maize/corn  X  which are among the most consumed agricultural products in India. Other crops include agricultural produce across different categories, like fruits (apple, mango etc.), vegetables (eggplant, cauliflower, cabbage etc.), cash crops (cotton, jute, sugar etc.) We http://agmarknet.nic.in/ used the daily modal prices of these crops and computed the av-erage across different markets in the country to represent the daily price of the crop in India.
Any time series data is usually made up of different components  X  trend, seasonality, cyclic and error. ARIMA (Auto-Regressive Integrated Moving Average) [4] models are the most general class of models for forecasting a time series. The ARIMA forecasting equation for a stationary time series is a linear (i.e., regression-type) equation in which the predictors consist of lags of the dependent variable and/or lags of the forecast errors. For the non-seasonal ARIMA( p,d,q ) model, the projected value is computed by: where y 0 t is the differenced time series with d being the degree of first differencing, p represents the number of AR (Auto-Regressive) terms (  X  are the parameters) and q represents the number of MA (Moving Average) terms (  X  are the parameters). However, due to inherent seasonal variation in food price data, the SARIMA ARIMA) is a more suitable model to forecast food prices. We used the SARIMA (1,0,1)x(0,1,1) model, as it showed the best perfor-mance for our data. The seasonal difference is added by introduc-ing a new variable y t  X  s where s = 365 and represents the av-erage daily price for one month period, for the month 365 days prior to t , to understand the previous year X  X  trend. Figures 2and 3 show the forecasted prices for potato and wheat respectively by this model. The time series in the figures present the average daily modal value from different markets in India between January 1, 2006 and December 31, 2012. The model was trained with price values till December 31, 2010 and was tested on the predicted val-ues between January 2011 and December 2012. The figures show that this model can detect the cyclic patterns of food prices across the years and the general trend but is unable to predict the local variations in the time series. We show next that incorporating event information can help in improving the accuracy of prediction.
Volatility of food price can be attributed to many factors, in-cluding seasonal factors, inflation etc. However, there are cer-tain incidents and events that can have a sudden impact on food prices. Unfortunately, the existing models for time series projec-tion do not account for such factors. Here, we present a modified ARIMA model where information about current events are incor-porated within the model. Since not all events are equally relevant for a socio-economic indicator, we first identify the events that in-fluence fluctuations in a specific indicator of interest based on the technique described in section 5.1. Table 3 presents the top 5% (ac-cording to the likelihood ratio) event class triggers for some of the crops. We see some commonalities across crops, like disease out-breaks, violence and movements, natural calamities, festivals etc. However, there are also some unique events for each crop. For example, transportation strike or any incident affecting the trans-portation system has a more profound effect on wheat and potato (example events being attack on railways, railway strike etc.). This is probably due to the fact that wheat and potato are not cultivated uniformly across the country and heavily rely on transportation for proper distribution. Any event that affects transportation of these crops has an effect on the supply, leading to a rise in price. On the other hand, festivals influence only onion and wheat prices. These two crops have a higher consumption during festivals leading to an increased demand and thereby increasing the price.

We use the model introduced in section 3 (Eq 1) with a slight modification: instead of using all the K events, we only use the subset  X  ( M y ) of events that are identified as relevant (see above) for the socio-economic indicator y . This modified model adds event-based features on top of the standard ARIMA model to com-pute the value of socio-economic indicator at time t . The compar-ison of this model with the standard ARIMA model is shown in Table 4 where we report the RMSE of prediction. We observe that the residuals for the event-based ARIMA model is lower in most cases (apart from tomato and cabbage). In particular, the mean RMSE for the event-incorporated ARIMA is lower which supports our hypothesis that certain events can have impact on food prices. The real-world events are determined by external forces that need not have any specific (or repeating) patterns and hence, standard time series analysis methods cannot capture fluctuations caused by such factors.

In this section, we discuss the performance in predicting food price spikes. We say that a spike in price is true if the value at time t is greater than the value at time t  X  1 by more than 10%. Our event model is built using a hierarchical process, involving extraction of event triggers as the first step and adding subsidiary events at a later stage. So, the first experiment we conducted was to gauge the advantage of adding subsidiary events to the event model. We consider a naive event-trigger based model (called TRIGG ) that only utilizes the event class triggers occurring in any news article. To further understand the benefits of adding subsidiary events in our model against adding traditional topics, we implemented an-other model that combines TRIGG (event triggers) and LDA topics which we refer to as TRIGG+LDA . Finally, we consider a model that incorporates past events and current events for the purposes of prediction. We call this model EVENT_HIST (see section 5.2). As for the case of predicting the actual values in section 7.3.1, here also we only consider the subset of relevant events identified in section 5.1 for the purposes of predicting food price spikes.
Table 5 summarizes the performance of the various event-driven predictive models defined above against other baselines and popu-lar text mining techniques, where we report the accuracy of each method. Among individual crops, onion price prediction showed the best results, followed by rice, wheat and potato. A possible explanation of this observation is that the price volatility of onion is widely covered in the news articles compared to other crops, as onion price fluctuations have more adverse effects compared to the other crops [36]. Observe that both the EVENT and EVENT_HIST models have better performance compared to the baseline mod-els. Further, the improved performance of TRIGG+LDA highlights the benefits of adding subsidiary events in our probabilistic event model. The poor performance of topics ( LDA ) is due to the ubiq-uitous nature of topics in news streams  X  almost all the topics ap-peared on each day and the per-day topic distribution was approx-imately uniform. On the other hand, events are much more sparse and display a non-uniform distribution over time. As a result, events displayed more discriminating power than topics in predicting the socio-economic indicators. To summarize, the results for EVENT and EVENT_HIST demonstrate better predictive power compared to standard methods, such as LDA, showing the benefits of events as features over topics. Moreover, the results clearly demonstrates the benefits of adding subsidiary events to the model and adding historical event information as additional features. In absolute terms, the accuracies are not high but are significantly better than the basic baseline of a random guess.

A finer analysis of the EVENT model showed some interesting characteristics of the prediction performance. Figure 4 (upper) shows the average accuracy of the model in predicting food price spikes for each month across the 7 years. We see that the perfor-mance goes down in the middle of the year (Jul-Sep) and again in December and January. In these months, the seasonal effect influences the food prices and the real-world events are not able to capture this. In particular, July and August are peak monsoon months and September often suffers from a lasting effect of the monsoon, including floods, disease outbreaks etc. Similarly, dur-ing winter (Dec-Jan) prices tend to go up. Tuning our model to remove such seasonal effects can increase the accuracy for these months. Figure 4 (lower) presents the variation in prediction accu-racy across the different years. This plot shows an upward trend in the accuracy. The rise in prediction accuracy towards the end can be attributed to the fact that Times of India gradually in-creased the count of online articles. In 2006, the average number of daily articles were around 200, which increased to 600 in 2011-12. The increase in the number of articles meant more coverage of real-world events, which lead to better event-driven prediction.
The event model presented in this paper is based on the assump-tion that every news article has a main event, which is usually men-tioned in the title and/or lead paragraph of the article. In the sce-nario where two (or more) types of events are discussed in the lead paragraph of the same article, we still preserve the assumption that there is only one main event in the article by choosing the event (i.e. the corresponding triggers) appearing first among the two (or more) events in the lead paragraph, as the main event of the article. This is based on the intuition that the preceding event has more impor-tance and needs to be mentioned before introducing or explaining the other events in the lead paragraph.

In the present implementation, the subsidiary events in an article are assumed to be independent of the main event. This helps to keep our event model simple, though in practice there might be some in-herent dependencies between the main and subsidiary events men-tioned in news articles. For example, if the main event in the article is about a natural calamity, the subsidiary events typically will be related to its impact (e.g. deaths, injuries, rescue etc.). Hence, one of the goals in future work would be to redesign the model assum-ing a dependency between the main event and the subsidiary events in the articles.

For food price prediction, we implemented our event model on top of the seasonal ARIMA model. However, for the case of spike prediction, we did not consider the seasonal effects in the price spikes. Accounting for seasonality is a possible opportunity for future work. Moreover, in building the predictive models, we de-termined the events more likely to co-occur with the observed phe-nomenon (food price rise in this case) beforehand. Alternatively, all event types could have been used for this predictive analysis. This approach will involve many more parameters and will be slower to train. Also, preliminary experiments showed that the weights for most of the events were close to zero, making the adapted approach with fewer but more related events in the predictive model a better choice.

In future, we would like to augment our predictive models with more features apart from the event classes. There might be certain entities, such as people, location, organizations or topics that are also related to the observed phenomenon (food price rise or others) and incorporating them can lead to better prediction performance.
This paper is based on the premise that many socio-economic indicators are sensitive to real world events and this can be used to forecast fluctuations in their values. We presented a novel way of defining and extracting events from a large news corpus. We use these events to design and implement models to predict fluctuations in food prices. Our event-driven predictive model showed a 22% reduction in the RMSE when a standard ARIMA model is incorpo-rated with event information. A separate model was built to predict spikes in the prices, where we observed that the event-based model outperformed the other models, including an LDA based predictive model. This paper has solely focused on predictive food prices us-ing news events. However, our approach can easily be extended to predict other socio-or macro-economic indicators or phenomena, which are sensitive to events. One future direction is extending the evaluation to build predictive models for other scenarios such as stock prices, disease outbreaks, or forecasting effects of natu-ral calamities like drought, flood, cyclone etc. The present work has only focused on finding association between events and an ob-servable phenomenon. Another extension of this idea is to iden-tify causing and resulting events of any phenomenon, which can be used for finer analysis and greater clarity in understanding the observed phenomenon.
We thank the NYU Abu Dhabi Research Institute and the Cen-ter for Technology and Economic Development (CTED) in NYU Abu Dhabi for supporting Sunandan Chakraborty and Lakshmi-narayanan Subramanian on this project. We thank the NSF for supporting Ashwin Venkataraman in part on this project under the NSF CAREER grant CMMI 1454310. The authors would also like to thank Shankar Kalyanaraman for his valuable input on this pa-per, particularly for helping with the initial data collection.
