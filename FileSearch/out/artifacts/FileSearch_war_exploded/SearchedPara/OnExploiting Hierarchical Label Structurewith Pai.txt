 The goal of this work was to test whether the performance of a reg-ular pairwise classifier can be improved when additional informa-tion about the hierarchical class structure is added to the training sets. Somewhat surprisingly, the additional information seems to hurt the performance. We explain this with the fact that the struc-ture of the class hierarchy is not reflected in the distribution of the instances. The pairwise approach, which learns one classifier for each pair of classes and aggregates the results by voting, has shown a good per-formance in various learning scenarios, including classification [5] and multi-label classification [7; 14]. It is an interesting question whether additional information on the structure of the output space can be used for an improved performance.
 In this paper, we report on an experiment that aimed at improving pairwise classification in the presence of hierarchical class struc-tures. The key idea is to augment the training sets for the binary base classifiers with additional examples that utilize the hierarchi-cal structure of the class labels: each binary classifier M criminating between classes  X  i and  X  j is given additional training examples: examples of classes that are closer to  X  i in the training data are added to the examples for class  X  i , and examples of classes that are closer to  X  j are added to  X  j .
 We start with a brief recapitulation of pairwise classification (Sec-tion 2) and hierarchical classification (Section 3). Pairwise Classification is a method to solve multi-class classifica-tion problems by dividing them into several binary problems. These 2-class problems will then be solved independently of each other using a binary base classifier [4]. Contrary to the conventional one-against-all or one-vs-rest approach, the pairwise classifier trains one classifier M ij for each pair of classes (  X  i ,  X  j ) . This classifier is trained on all examples from these two classes; all other exam-ples are ignored. Thus, for c classes, one has to train c  X  ( c  X  1) / 2 binary classifiers. By aggregating the predictions of all base classi-fiers with voting, one can eventually obtain a prediction for the ac-tual multi-class task. Despite the quadratic number of classifiers, it has been shown that training is even faster than in the one-against-all approach [5], and that classification can be sped up to almost linear in the number of classes [17], making the pairwise approach competitive in terms of efficiency and superior in terms of accuracy. Figure 1: Hierarchical structure corresponding to the following par-tial order on the class labels L = {  X  1 , . . .  X  7 } :  X  In hierarchical classification, the set of labels L = {  X  is structured with a partial order relation = , which imposes a tree structure upon the label set, as shown in in Figure 1. This distin-guishes hierarchical from conventional classification, where L is an unordered set. Many real-world classification problems, in partic-ular text classification problems such as the REUTERS benchmark datasets [11; 12] or classification of Web catalogues [13], exhibit such a hierarchical structure in the labels. Several techniques have been proposed to exploit such a structure [9; 15; 1; 18]. A simple approach to hierarchical classification has become known as the Pachinko machine classifier [9]. Its key idea is to associate one classifier with each interior node of the label hierarchy tree. Its task is to decide which path will be followed. For example, in Figure 1, one classifier M 1 is trained to discriminate labels  X  and  X  5 from labels  X  6 and  X  7 . Depending on the outcome of the prediction, either classifier M 2 decides between labels  X  or another classifier M 3 decides between  X  6 and  X  7 .
 Strictly speaking, there are two different scenarios for hierarchical classification. In the first, only the leaves of the hierarchy (labels  X  ,  X  5 ,  X  6 , and  X  7 ) can be predicted, in the second the examples can be labeled with all nodes in the hierarchy. As described in the next section, both cases can be tackled with pairwise classification. In the first we only need to train a pairwise classifier for the subset of leaf labels, in the second with all labels. In many applications of hierarchical classification, the class hierar-chy corresponds to an ISA-hierarchy, where higher nodes are super-concepts of the nodes in their sub-trees. A natural assumption to be made in such a case is that the distance of classes within the class tree corresponds to the actual distances between their exam-ples in the training set. We call this the class fidelity assumption . If, e.g., we have a topic hierarchy with the concepts Politics , Econ-omy , Sports , etc., it is natural to assume that the subconcepts of the node Sports (such as Basketball , Baseball , Football ) are closer to each other than to subconcepts of Politics or Economy .
 The key idea of the proposed augmented pairwise classifier (APC) is to enforce the assumed class fidelity by using additional training examples of similar classes for the training of each classifier. For example, in Figure 1, we would add the  X  4 examples to the  X  examples when training the classifier M 5 , 6 . Our expectation is that this approach will outperform a  X  X lat X  classifier which simply ignores the hierarchical relationships between the classes because the additional training examples will improve the predictions of the pairwise classifiers on examples of other classes.
 To formalize this process, we first have to define a notion of (se-mantic) closeness relation within the hierarchy.
  X  mssc = mssc (  X  i ,  X  j ) is the most specific super-concept of two classes  X  i and  X  j iff 2. 6 X   X  s.t. (  X  =  X  i  X   X  =  X  j )  X   X  mssc =  X  Based on this, we defined the similarity or closeness between two nodes in the hierarchy as the depth of the most specific super-concept. In Figure 1,  X  4 and  X  5 have a closeness of 1, whereas  X  and  X  6 have closeness of 0.
 The key idea of our approach is to train the binary classifier M by adding all examples that are closer to  X  i to this class, and adding all examples that are closer to  X  j to that class.
 The augmented pairwise classifier (APC) consists of one classifier M ij for each pair of labels, which is trained on the examples of the following sets of positive ( P ij ) and negative ( N ij For example, for training the classifier M 56 with the class structure of Figure 1, the examples labeled as  X  4 are added to those with label  X  5 , and the examples labeled as  X  7 are added to  X  prediction task includes the interior nodes of the hierarchy, label  X  2 will also be added to  X  4 and  X  5 , and label  X  3 to  X  6 Examples with label  X  1 , which has the same mssc (itself) for both  X  5 and  X  6 , are ignored. Note that P ij trivially includes  X  N ij trivially includes  X  j , i.e., the training sets of the augmented pairwise classifier are super-sets of the regular pairwise classifier. Many hierarchical classification problems are also multi-label, i.e., each example may be associated with more than one label [19]. Pairwise classification can be easily extended to multi-label clas-sification. In this case, the binary model M ij is trained on all examples ~x for which one of the two labels  X  i and  X  j is associ-ated with ~x and the other is not. For a new example, we can then predict a ranking of all classes, just as with single-label pairwise classification [14]. The top-portion of the ranking can then be pre-dicted as a multi-label set for this example. For establishing the split-point in the ranking, separate techniques have to be used. Al-ternatively, the calibrated label ranking algorithm tightly integrates ranking and splitting [7]. In this paper, we will ignore this aspect and only compute a ranking.
 For adding hierarchical information to the multi-label pairwise clas-sifier, we adopt the approach of the previous section. In this case, the identification of additional training examples becomes a bit more complicated, because one of the multiple labels of the train-ing example might be closer to  X  i than to class  X  j but at the same time some other label from the same example might be closer to  X  than to  X  i . Thus, an example is added to the class  X  i if at least one of its classes is closer to  X  i than to  X  j , and no other class is closer to  X  j than to  X  i . After first experiments with a preliminary implementation it turned out that the predictions of the augmented pairwise classifier are the same as the predictions of the Pachinko machine classifier [9], which we briefly described in Section 3. This came unexpected to us, because while both methods, the Pachinko classifier and the augmented pairwise classifier reduce the hierarchical classification problem to an ensemble of binary classifiers, the Pachinko machine classifier uses fewer binary classifiers, which are arranged in a hi-erarchy, whereas the pairwise classifier uses one classifier for each pair of labels, each contributing one vote to the final prediction. Upon closer inspection, it turns out that the two classifiers are, in fact, equivalent. The reason lies in the fact that the augmentation process described in Section 4 makes many of the pairwise classi-fiers equivalent.

L EMMA 1. In the augmented pairwise classifier, the binary clas-sifiers M ij and M kl receive the same training examples if  X  mssc (  X  i ,  X  k ) and  X  jl  X  mssc (  X  j ,  X  l ) are in different subtrees, i.e.,  X  ik 6 =  X  jl and  X  jl 6 =  X  ik .

P ROOF . The node  X  = mssc (  X  jl ,  X  ik ) separates the two sub-trees S ik rooted in  X  ik and S jl rooted in  X  jl . From  X  and  X  jl 6 =  X  ik it follows that  X  6 =  X  jl and  X  6 =  X ik . Thus, all paths going to the labels in S ik and S jl share the same sub-path up to node  X  , and differ from then on (otherwise  X  would not be the mssc ). Similarly,  X  i and  X  k share the same path down to  X  which contains the path to  X  as a (proper) sub-path. Therefore, mssc (  X  k ,  X  j ) = mssc (  X  k ,  X  i ) must hold and  X  k ated with P ij according to Definition 2. With an analogous argu-ment we can show that  X  l must be in N ij . Thus, P kl  X  P N kl  X  N ij . By the symmetry of the arguments, it follows that P
L EMMA 2. Each binary classifier M ab , which is trained to dis-criminate between two successor branches S a and S b of a node  X  , corresponds to a binary classifier of the augmented pairwise clas-sifier, and vice versa.

P ROOF . By the previous lemma, all classifiers M ij and M for  X  i ,  X  k  X  S a and  X  j ,  X  j  X  S b are identical to each other. Thus, S  X   X  S b  X  . These are the positive and negative training sets of the Pachinko classifier at node  X  .
 Conversely, each binary classifier M ij of the APC must corre-spond to the binary classifier that discriminates between the corre-sponding two successor branches of the node  X  = mssc (  X  i By the previous lemma, we already know that all binary classifiers of the augmented pairwise classifier correspond to a classifier that discriminates between two successor branches of an interior node  X  . If the class structure is binary, i.e., each interior node has only two successors, this is the classifier trained by the Pachinko ma-chine.
 What remains to be shown is that the voting strategy of the aug-mented pairwise classifier leads to the same class label as the hier-archical path expansion of the Pachinko machine.

T HEOREM 1. For binary class hierarchies, the augmented pair-wise classifier is equivalent to the Pachinko machine.

P ROOF . Each interior node  X  of the binary class structure cor-responds to one binary classifier M ab of the Pachinko machine classifier. This classifier is identical to all pairwise classifiers M with  X  i  X  S a and  X  j  X  S b . If S a contains a nodes and S b nodes, we have a  X  b such identical binary classifiers, which all vote in the same way. Assume that M ab selects branch S a all of the above-mentioned a  X  b binary classifiers will vote for the class in S a , i.e., each class in this branch will receive b votes from these classifiers. On the other hand, each class in S b will receive 0 votes from these classifiers. Thus, classes in S b can only receive votes from the comparisons among themselves, i.e., each class in S can receive at most b  X  1 votes. Thus, all classes in S a ranked above all classes in S b , which corresponds to the decision that is taken by the binary classifier M ab .
 For general multi-class class hierarchies, the situation is a bit more complex. Assume that node  X  has successor subtrees { S a i 1 . . . s , each branch having a i nodes. Here, we need a multi-class classifier to decide which branch to follow. If this multi-class clas-sifier is realized with a pairwise classifier, then the equivalence still holds if the selected subtree S a i is predicted by all pairwise models M a i a j that compare S a i with some other branch S a j . If one such model M a i a j makes an inconsistent prediction for the subtree S i.e., if it predicts S a j even though the final selection of the pairwise classifier is S a i , then the hierarchical pairwise classifier may make a different selection ( S a j ) if a j a i . Thus, in case of unbalanced class hierarchies, the hierarchical pairwise classifier may exhibit a bias towards larger subtrees if the binary classifiers do not make consistent predictions.
 It should be noted that this result only holds for hierarchical singe-label classification. As discussed in Section 4, the technique can be straight-forwardly extended to multi-label classification. In this case, the equivalence between hierarchical pairwise classifiers and the Pachinko machine classifier no longer holds. In fact, an ex-tension of the Pachinko machine to hierarchical classification is not obvious, so that one interpretation of the above result could be that the augmented pairwise classifier is a generalization of the Pachinko machine classifier to multilabel problems. In order to evaluate the augmented pairwise classifier, we performed experiments on the REUTERS RCV1 corpus [12]. We emphasize that we were not so much interested in the absolute performance of the method, but only focused on the comparison between reg-ular pairwise classification and augmented pairwise classification. Our expectation was that additional knowledge about the class hi-erarchy should be able to improve the performance of the pairwise classifier, and we wanted to verify this hypothesis. All experiments were conducted in Weka, using its support vector machine SMO with default parameters as the base classifier.
 We used a version of the REUTERS RCV1 corpus which consists of five datasets, each containing 3000 training and 3000 test exam-ples. 1 Each example is encoded with about 40,000 attributes repre-senting the TF-IDF values of the words in the text. From these, we performed a feature selection based on document frequency on the training sets, i.e., for each of the five datasets we only kept the 5000 features which had the highest number of non-zero values in the training set. This performed quite well in the experiments reported in [20]. The dataset is a multi-label dataset, where each example is on average assigned to four label of a total of 101 labels. The class hierarchy is up to 4 levels deep. 23 of the 101 labels correspond to interior nodes in the hierarchy. http://www .csie.ntu.edu.tw/  X  cjlin/libsvmtools/datasets/multilabel.html T able 1 shows the results of pairwise classification (top) and aug-mented pairwise classification (bottom) in terms of nine evaluation measures. The first four measures assume that first four labels of the ranking are relevant and compute the precision, recall and F1-measures as well as the error (Hamming loss) on the predicted la-bels. For example, a precision value of 0.6 means that 60% of the predicted labels were actually relevant, a recall value of 0.6 means that 60% of the relevant labels were actually predicted. The remain-ing five values try to capture the quality of the ranking: margin loss is the difference in the ranking position of the first irrelevant la-bels and the last relevant label, one error is the percentage of test instances where the top rank is not a relevant class, rank loss is the fraction of label pairs for which the irrelevant label is ranked before the relevant (an adaptation of Kendall X  X  tau for multi-label problems), average precision is the averaged precision values at the position of each relevant label, and first irrelevant is the ranking po-sition of the first irrelevant label. All reported values are averaged over all test instances.
 The results show that according to all but one measures the aug-mented pairwise classifier does not improve over the regular pair-wise classifier (better results are shown in bold ). Particularly strik-ing is the large difference in margin loss, i.e., the position of the last relevant label is typically much lower for the APC. Interestingly, the APC seems to have a slight advantage in terms of the position of the first irrelevant label. However, this difference is not sig-nificant and does not change the overall result that the augmented pairwise classifier did not improve over the pairwise classifier, but, in fact, seems to perform somewhat worse. The negative result on the REUTERS data came somewhat surpris-ing and asked for an explanation. Possible explanations are: 1. Augmenting the hierarchical classifiers with additional ex-2. Datasets violate the class fidelity assumption, upon which the Figure 2: Class hierarchy (top) and spatial layout (bottom) of the artificial dataset To test these two assumptions, we generated an artificial, single-label dataset with 12 classes organized in the hierarchical structure that is shown in the upper part of Figure 2. The examples were assigned labels roughly following the spatial layout shown in the lower part of Figure 2. For each class, we generated 100 train-ing examples using a 2-dimensional Gaussian distribution with the mean in the center of the rectangle and the standard deviations pro-portional to the side lengths of the enclosing rectangles. We tried five different settings (numbered from 1 to 5), corresponding to 1 / 3 , 1 / 2 , 1 , 3 / 2 , 2 times the breadth and width of the rectangle. The motivation for generating the data in this way was primarily that we wanted to be sure that the hierarchical class structure is reflected in the instance space. This property is mostly true, but one can also find exceptions. For example, the center of class 3 is closer to the center of class 7 than to the center of class 1. Moreover, the classes in each internal node of the hierarchy should be linearly separable. This is the case for the lowest variance level, but with increasing variances this property will be weakened.
 Finally, as an additional test for the influence of the class fidelity assumption, we also generated a version of this dataset in which the classes 3 and 10 were swapped in instance space, resulting in a dataset that clearly violates the above assumption.
 Figure 3 shows the results of PC and APC over increasing variance around the class centers, on both versions of the dataset. First, we can see that the pairwise classifier dominates the augmented pair-wise classifier in both scenarios. Moreover, there is no noticeable difference in performance between the normal dataset and the one with swapped classes. This is not surprising, as PC does not ex-plicitly make use of the class hierarchy. On the other hand, for low variance levels, the performance of APC clearly depends on the class fidelity assumption: APC X  X  performance is en par with PC X  X  for the case where the hierarchy is reflected in instance space, but it is much worse in the case where this assumption is violated. Both, PC and APC suffer when the variance of the data around the center increases. Again, this is not surprising because the problem becomes less and less linearly separable and thus harder to solve. However, it seems that the advantage of PC over APC increases with increasing variance. This seems to indicate that the unaug-mented binary classifiers are easier to train, in particular when the augmentation does not respect the class fidelity.
 Based on the above observations, we want to verify the class fidelity of the REUTERS dataset. To this end, we tried to measure class fidelity in the following way: If we train a binary classifier M for discriminating classes  X  i and  X  j (without seeing examples of any of the other classes), then classes that are closer to  X   X  should be more likely to be classified as  X  j than as  X  i this for computing a class fidelity index which is simply the fraction of all examples that are assigned according to the expectation of the hierarchy, averaged over all binary classifiers of the PC (examples where the label is equally likely for both sides are ignored). For multi-label data, we use the same extension as defined in Section 4, namely that an example is assumed to be closer to class  X  least one of its labels is closer to  X  i than to  X  j , and no other class is closer to  X  j than to  X  i .
 Table 2 shows the class fidelities for all datasets. We can see that even for the artificial data, the class fidelity is not perfect, because of the minor violations in class fidelity discussed above. However, clearly, the index is worse for the dataset where two labels were swapped in instance space. Also, the class fidelity is clearly de-creasing with increasing variance around the class centers. The re-sults for REUTERS, although maybe not directly comparable be-cause this is a multi-label dataset, show an even worse class fi-delity index. Note that the expected value for the index for the case when there is no correlation between class hierarchy and location in instance space would be 0.5. Thus, it is safe to conclude that REUTERS does not exhibit the class fidelity upon which the de-sign of the augmented pairwise classifier was based.
 We think that our primarily negative results are not limited to hi-erarchical classification, but apply to any attempt to exploiting an order relation on the label structure by enriching the training ex-amples in the way outlined in this paper. For example, in ordinal classification, also called ordinal regression in statistics, the set of class labels L = {  X  1 ,  X  2 . . .  X  m } is endowed with a natural (to-tal) order relation  X  1 =  X  2 = . . . =  X  m . From a learning point of view, the ordinal structure of L is additional information that a learner should try to exploit, and this is what existing methods for ordinal classification essentially seek to do [10; 3; 2]. On the other hand, pairwise classification has been previously shown to work quite well on this problem, even though it disregards this informa-tion entirely [6].
 Obviously, the order information can be exploited in the same way as sketched above for hierarchical classification: for training the classifier M ij , the examples of class  X  i are enriched with the ex-amples of all classes  X  k for k &lt; i , and the examples of class  X  are enriched with the examples of all classes  X  l , l &gt; j because of  X  k =  X  i =  X  j =  X  l . This approach was tried in [16], but, just as the results reported here, did not yield any improvements over reg-ular pairwise classification. This is consistent with the observation of [8] that the ordering information is not as strongly reflected in the training data as one might expect.
 Recently, [21] have also observed that approaches that attempt to exploit the hierarchical class structure of a problem do not improve over approaches that ignore this structure. It remains to be seen whether these results can also be explained with a lack of class fidelity. The negative result reported in this paper, namely that the augmen-tation of pairwise classifiers with additional training examples does not improve classification performance, has lead to two interesting insights. First, we have shown that the method is essentially equiva-lent to a Pachinko-machine classifier, but can be straight-forwardly generalized to multilabel data. Second, we have seen that a key as-sumption behind the augmentation strategy, namely that examples of classes that are near-by in the class hierarchy are also close in instance space, does not always hold.
 Acknowledgments: This research was supported by the German Science Foundation (DFG). We would like to thank Eyke H  X  uller-meier for inspiring discussions on this subject. [1] L. Cai and T. Hofmann. Hierarchical document categoriza-[2] J. S. Cardoso and J. F. Pinto da Costa. Learning to classify [3] E. Frank and M. Hall. A simple approach to ordinal classifi-[4] J. H. Friedman. Another approach to polychotomous classi-[5] J. F  X  urnkranz. Round robin classification. Journal of Machine [6] J. F  X  urnkranz. Round robin ensembles. Intelligent Data Anal-[7] J. F  X  urnkranz, E. H  X  ullermeier, E. Loza Menc  X   X a, and K. Brinker. [8] J. C. H  X  uhn and E. H  X  ullermeier. Is an ordinal class structure [9] D. Koller and M. Sahami. Hierarchically classifying docu-[10] S. Kramer, G. Widmer, B. Pfahringer, and M. DeGroeve. Pre-[11] D. D. Lewis. Reuters-21578 text categorization test collec-[12] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. RCV1: A new [13] T.-Y. Liu, Y. Yang, H. Wan, H.-J. Zeng, Z. Chen, and W.-Y. [14] E. Loza Menc  X   X a and J. F  X  urnkranz. Pairwise learning of multi-[15] A. McCallum, R. Rosenfeld, T. M. Mitchell, and A. Y. Ng. [16] G. H. Nam. Ordered pairwise classification. Master X  X  thesis, [17] S.-H. Park and J. F  X  urnkranz. Efficient pairwise classification. [18] J. Rousu, C. Saunders, S. Szedm  X  ak, and J. Shawe-Taylor. [19] C. Vens, J. Struyf, L. Schietgat, S. D  X  zeroski, and H. Block-[20] Y. Yang and J. O. Pedersen. A comparative study on feature [21] A. Zimek, F. Buchwald, E. Frank, and S. Kramer. A study
