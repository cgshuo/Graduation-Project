 1. Introduction Television has been the most important communication medium of the last century. However, in the last few years the evolution of a widely recognized trend: between 75% and 85% of TV viewers use another device at the same time. screen launched in 2011, users immediately acclaimed this application as a fun way of watching TV programs. The user  X  screen is a mix of editorially curated and automatically selected one.
 news programs (newscasts). When a user is watching a newscast, they might want to delve deeper into the news airing cussed in the newscast currently airing on TV, and displays it to the user in real-time. from the streams of Closed Captions ( CC ) broadcasted along with it by television networks. tantly, news articles must be surfaced as soon as possible to be valuable to the user.
We propose a solution based on techniques from the realm of information retrieval (IR). Fig. 1 shows the conceptual schema of the components of our system and how they interact with each others. We decompose the main news matching task into two sub-tasks: find a good segmentation of the stream of problem consists in finding the boundaries of these news segments in the stream of mulating a query given a segment, and issuing the query to an underlying IR engine. While the user is watching the newscast, the system continuously processes the news article from the IR engine. When enough information has been accumulated, the system submits the query to the IR engine, retrieves the results, and shows them to the user.
 items, and (iii) the user checking a subset of the resulting items to satisfy their information need. I challenging task, which is fundamentally different from typical IR tasks.
 Second, the user sees a small number of results that are continuously changing as new ment only evaluates the amount of relevant documents ranked at the top of the result list. However, I Therefore, we evaluate the quality of the system in terms of both relevance and timeliness. bed. We build a ground truth dataset consisting of a day X  X  worth of instances of the metric that use different decay factors.
 line which we compare to in Section 6 .
 The research contributions presented can be summarized as follows: We investigate the task of matching online news articles to news airing on a newscast.
We formalize the problem, and present a framework that models the task as two separate sub-tasks: We design an evaluation testbed for the problem that takes into account the timeliness of the solution.
We provide the dataset used in our testbed to the research community to foster research on this topic.
We discuss several options to solve the segmentation and retrieval problems and we conduct a thorough experimentation for assessing the performance of our solutions.
 directions for research. 2. Related work
As mentioned in the introductory section, Henzinger et al. (2003) study the same news matching problem. They show ations of a simple tf idf scheme and all the methods work by considering non-overlapping segments of the suring how relevant a matching news is for a given portion of feedback results from the news retrieval engine.
 Rijke (2013) where they describe and approach a task of associating with semantic entities windows of mation from microblogs such as twitter ( Bauer &amp; Wolff, 2014 ).
 alies measured through the model. Aggregating anomaly scores from hundreds of users, authors show that we can detect emerging topics only based on the reply/mention relationships in social-network posts. Merlino, Morey, and Maybury (1997) analyze broadcast news from CNN to find cues of segment boundaries. While their approach relies on multimedia dow-based segmentation.
 same event together. The most prevailing approach of NED was proposed by Allan et al. (1998), Yang, Pierce, and
Carbonell (1998) and Brants, Chen, and Farahat (2003) , in which documents are processed by an on-line system. Among (2003) employ a model that updates incrementally term weights using tf idf on different data sources, and similarly
Kumaran and Allan (2004) employ an incremental variant of tf idf to detect news events. The most recent developments representation in a temporal-based event episode discovery technique.
 It is worth pointing out that NED is only loosely related to our problem of segmenting the stream of problem is to find boundaries of the text that describes an event in a stream of text containing multiple events. The
In this case, we want to detect an event as soon as possible and to build and issue a query to the underlying IR engine. 3. Problem formulation
In this section we present our notation, provide a statement of the problem, and describe a framework that decomposes the problem in smaller, more manageable tasks.
 The primary input is represented by an unbounded stream of at which the CC text is available to our system, i.e., c i
We assume that at any given time there exist a finite number of topics N , which represent noteworthy news events. We does not have access to the function L cc .
 indexed and searched via an underlying IR engine. Similarly to to a topic n 2N by a function L D : D!N . The system has no access to this function either. Let us now formally state the problem:
Problem 1. We are given as input an unbounded stream of closed caption lines C and a collection of documents D .We assume the existence of a set of topics N , and two functions L documents to topics. The problem is to find, 8 c 2C ; k documents R asks to find matching documents for each line of CC , or, equivalently, for each timestamp t . an ideal solution. The discussion of issues related to evaluation is deferred to Section 4 . needs to deal with unspecified topics that might include loose boundaries, and make online decisions based on local information.
 3.1. Proposed solution As already mentioned, we take an IR approach in designing I f
IntoNews : C!fD k g that matches to each CC line c i 2C a document list R defined in Section 4 .
 to the same topic. Rather than trying to match a list of news items to each minimize the duration of the topic mismatch between C and R k .
 that belong to the same topic. This can be thought of as identifying a pair of points in time  X  t with a function f seg : C ! fT T g . These bounds implicitly define a sequence of CC lines: S  X f X  t we need to construct a query from the sequence of lines with a function f of the query. Lastly, the system needs to rank documents in the collection for the query with a function f f rank  X  together represent the news retrieval engine in our schema.
 problem .

To build the final system we can optimize the two problems independently. However, as we detail in Section 3.4 ,we boundaries. 3.2. The segmentation problem several strategies for managing B .

The simplest strategy is to use a windowing approach to build candidate segments. We explore two different fixed-size variants of the windowing approach 5 : (i) a sliding window approach ( parameter C is the size of the window in seconds. SW C trims the oldest builds a new candidate segment of maximum duration C for each new Therefore, it proposes a candidate segment every C seconds at most.

Formally, the f seg functions implemented by the two windowing approaches are the following. The main motivation to choose these approaches is that they are computationally inexpensive and simple to implement. discriminative queries and retrieving results. 3.3. The news retrieval problem engine we consider BM25F as the retrieval model in use by f needed for very long queries may be prohibitive for a real-time retrieval application. terms with highest tf idf to build the query, where k is a parameter of f while the inverse document frequency is computed from the document collection D . 3.4. Topic change detection and we refer to this variant as plain TF-IDF . We evaluate the overhead of this method in Section 6 .
Change Detection ( TCD ). Formally, a TCD scheme is a function f otherwise it returns the same buffer B returned at the previous invocation. The new buffer is initially empty. ing ( Beeferman, Berger, &amp; Lafferty, 1999; Choi, 2000 ). Here we explore an IR approach.
Our TCD schemes leverage the underlying IR engine for feedback. They query the underlying IR engine with the current and returns the new query.
 Overlap ( RJO ), Entity Jaccard Overlap ( EJO ) and Entity Jensen X  X hannon Divergence ( their sensitivity.
 threshold.
 a topic change when the overlap falls below the threshold.
 it detects a topic change when the divergence is over the threshold. 4. Quality metrics
The problem defined in Section 3 bears some resemblance to information filtering, recommender systems and traditional used to assess the quality of our proposed methods.
 mizing the utility function / : boundaries of the segment S to be  X  0 ; C .
 performance. Conversely, providing relevant results only when the current since by then the topic has already changed. The function / has to capture this trade-off. 4.1. Time-based relevance the integral of its point-wise relevance: where m  X  X  measures the value of a single ranked list of documents R k for the segment S , independent of time. at a later time. Therefore, we use a convolution with a time discount function w  X  t  X  . that is, it has the following characteristics: an additional constraint:
The results provided by the system change at discrete times, so we can transform the integral into a discrete sum: where R k i  X  f  X  t i ; l i  X  is i -th results list R k i
We experiment with different options for the functions w C
We use four different time discount functions w C  X  t  X  . All functions are defined for 0 values computed with different time discount functions are not directly comparable.
We use Mean Average Precision (MAP) as the main measure for the value function m  X  X  . We ignore unjudged results, Normalized Discounted Cumulative Gain (NDCG) to make use of unjudged results. As also proposed by De Francisci from 0 to 4. (Section 5 explains how entities are extracted). We name RE relevance of a news article n with entities E n for a segment S as: the relevance values computed as described above. 4.3. Coverage matching. 4.4. Suggestion ratio system. 5. Dataset This section describes the dataset we used for testing the I captions by removing advertisements 6 and programs unrelated to news (e.g., talks shows). full-text content and by named entities extracted with SuperSense tagger. separately.
 mented, thus this step is fundamental. We manually segment the stream of single topic or should it be split into two different topics? the following fragment of text 8 : o a new celebrity caught up in the chris brown drake bar fight. tony parker says he suffered a scratched retina in the fight and now has to put off training with the french olympic basketball team. also new, the new york city club where the fight started has been shut down. police say eight people were injured including singer chris bro brown. witnesses told officers the fight started when drake X  X  entourage confronted brown as he was leaving that club.
 ambiguous segments are common in our dataset and it is this ambiguity that makes the task harder than it appears. problem.
 lowing the process described in Section 3.3 .

Each segment-news pair is individually assessed by expert human raters. In total about twenty expert human assessors give a positive judgement only if the news matches exactly, and to give negative judgement when in doubt.
We compute the inter-rater agreement by drawing a random sample of judgments and repeating the assessment inde-than, for instance, assessing relevant opinions.

As an example of a segment-news pair, consider the following text: o a giant leap for china. a chinese spacecraft successfully docked with a orbiting space laboratory this morning. this makes china to complete a manned space docking behind the united states and russia. the mission also sent the country X  X  first female astronaut into space.
 the same event as the one described by the captions.
 nificant fraction is longer than average. 6. Experiments k  X  10 as the parameter for TF-IDF (number of terms per query). The underlying IR engine we use is Apache Solr, to adopt the BM25F model, and we retrieve the top-100 results.
 We first observe that given the constraint in Eq. (1) for the time function w ( ORACLE ) always gets a value close to zero on any evaluation function. Indeed, the results with respect to the MAP score obtained by the oracle, i.e., 0.658. 6.1. Baseline news  X  X  X xactly on topic X  X  ( R +) on both datasets. The authors call this algorithm A 1-BASE 6.2. Segmentation strategies We compare the two segmentation methods, the tumbling window approach ( pattern. The experiments prove that the sliding window approach gets better results across various window sizes C and across most TCD variants. The reason behind this result is that between the two approaches. Therefore, in the rest of the paper we focus on the results obtained with 6.3. Topic change detection We evaluate the effectiveness of the more sophisticated Topic Change Detection ( one and the BASELINE . Table 3 shows the best variant for each the behavior of the different variants.
 EJO is clearly the best performing variant as it gets results as high as 60% of the
Finally, the EJS variant performs similarly to plain TF-IDF the detection performance.

The RJO variant seems to perform well compared to TF-IDF . Using larger windows increases the overall performance but thus it may be too late with respect to the beginning of the topic segment. 6.4. Coverage analysis
Table 4 shows the coverage and suggestion ratio for several methods. Ideally, one would like to have both measures as involved: by being too conservative, as in the case of the method seems more sensitive to its parameter, compared to nario. Note that BASELINE performs acceptably at the price, though, of a lower relevance of retrieved results. 6.5. Time functions
The relative performance of the different variants depends on the time discount function in use. Table 5 shows MAP and Linear scores increase with the parameter, the Logarithmic and Exponential scores decrease with it. values for the Step and Linear functions for larger h .
 better.
 Additionally, Table 5 shows how a more aggressive topic detection tends, in the limit, to the same behavior as other, because of the difference in the area below each curve (i.e., their integral). result is influenced by variation in coverage of the method due to its sensitivity to h .
As we already pointed out in the previous section, BASELINE meet. For this reason, the quality of BASELINE is consistently worse than the methods we propose in this work. 6.6. C and h more aggressive threshold (0.8) the MAP score is far less sensitive to variations of C . buffer becomes less relevant. From the figure it is also apparent that C  X  30 is an optimal value for h  X  0 : 2.
 most group, where we plot the First MAP score.
 sharper decrease, and for First given that they are the only part considered.
Note that given that all the methods reach a coverage higher than 0.933 the comparison among them is fair. 6.7. NDCG itative results. The best variants achieve a value of 0.70 while the 70% of the ideal one when suggesting related news.
 parameters.
 7. Conclusions and future work from a newscast. We defined and formalized the problem and proposed a range of solutions, mainly borrowing techniques the other hand the best strategy to decide whether to issue a query to retrieve news articles, was based on text with a RJO topic change detection strategy when 40% overlap between new and old result set is detected, i.e., per chunk) and a high MAP score. If the goal is high precision, the best strategy is 0.307. In all the experiments, we are able to improve consistently over the state-of-the-art baseline described in the timeliness of retrieved news items using different discount functions. 7.1. Future work window approach. This approach might underperform when the number of discriminative words in the on machine learning for ranking functions and TCD .
 In addition, considering the notion of popularity as a ranking factor for online news page to associate with and under what conditions one function would be preferred over another.
 References
