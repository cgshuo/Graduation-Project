
We present and discuss the important business problem of estimating the effect of retention efforts on the Lifetime Value of a customer in the Telecommunications industry. We discuss the components of this problem, in particular customer value and length of service (or tenure) modeling, and present a novel segment-based approach, motivated by the segment-level view marketing analysts usually employ. We then describe how we build on this approach to estimate the effects of retention on 
Lifetime Value. Our solution has been successfully implemented in Amdocs' Business Insight (BI) platform, and we illustrate its usefulness in real-world scenarios. Lifetime Value, Length of Service, Churn Modeling, Retention 
Campaign, Incentive Allocation. 
Customer Lifetime Value is usually defined as the total net income a company can expect from a customer (Novo 2001). The exact mathematical definition and its calculation method depend on many factors, such as whether customers are "subscribers" (as in most telecommunications products) or "visitors" (as in direct marketing or e-business). In this paper we discuss the calculation and business uses of 
Customer Lifetime Value (LTV) in the communication industry, in particular in cellular telephony. 
The Business Intelligence unit of the CRM division at Amdocs tailors analytical solutions to business problems, which are a high priority of Amdocs' customers in the communication industry: 
Chum and retention analysis, Fraud analysis (Murad and Pinkas 1999, Rosset et al 1999), Campaign management (Rosset et al 2001), Credit and Collection Risk management and more. LTV plays a major role in several of these applications, in particular 
Churn analysis and retention campaign management. In the context of churn analysis, the LTV of a customer or a segment is important complementary information to their churn probability, permission and/or a fee. SIGKDD "02, July 23-26, 2002, Edmonton, Alberta, Canada, 
Copyright 2002 ACM 1-58113-567-X/02/0007...$5.00. and how much effort should be concentrated on this segment. In the context of retention campaigns, the main business issue is the relation between the resources invested in retention and the corresponding change in LTV of the target segments. 
In general, an LTV model has three components: customer's value over time, customer's length of service and a discounting factor. 
Each component can be calculated or estimated separately or their modeling can be combined. When modeling LTV in the context of a retention campaign, there is an additional issue, which is the need to calculate a customer's LTV before and after the retention effort. In other words, we would need to calculate several LTV's for each customer or segment, corresponding to each possible retention campaign we may want to run (i.e. the different incentives we may want to suggest). Being able to estimate these different LTV's is the key to a successful and useful LTV application. The structure of this paper is as follows: 
Given a customer, there are three factors we have to determine in order to calculate LTV: 
Given these three components, we can write the explicit formula for a customer's LTV as follows: 
LTV = 5S (t)v(t)D(t)dt (2.1) 
In other words, the total value to be gained while the customer is still active. While this formula is attractive and straight-forward, the essence of the challenge lies, of course, in estimating the and S(t) components in a reasonable way. 
We can build models of varying structural and computational complexity for these two quantities. For example, for LOS we can use a highly simplistic model assuming constant churn rate -so if we observe 5% churn rate in the current month, we can set 0.95 t. This model ignores the different factors that can affect churn -a customer's individual characteristics, contracts and commitments, etc. On the other hand we can build a complex proportional hazards model, using dozens of customer properties as predictors. Such a model can turn out to be too complex and elaborate, either because it is modeling "local" effects relevant for the present only and not for the future, or because there is not enough data to estimate it properly. So to build practical and useful analytical models we have to find the "golden path" which makes effective and relevant use of the data available to us. We attempt to answer this challenge in the next sections. 3, PRACTICAL LTV APPROACHES 
In this section we review some of the approaches to modeling the various components of LTV from the literature and present the segment-based approach, which follows naturally from the way analyses and campaigns are usually conducted in marketing departments. The segment-based approach helps in simplifying calculations and justifies the use of relatively simple methods for estimating the functions. 
To model LTV we would naturally want to make use of the most recent data available. Therefore let us assume that we are only going to use churn data from the last available month for modeling LOS. So for the rest of this paper we assume we have a set of n customers, with covariates vectors xl,...,x, representing their "current" state and churn indicators ct ..... cn. The tenure with the company is an important churn predictor since 
LOS frequently shows a strong dependency on customer "age", in particular when contracts prevent customers from disconnecting during a specific period. Let us denote these tenures by .Additional covafiates are customer details, usage history, payment history, etc. Some of the covariates may be based on time-dependent accumulated attributes (e.g. averages over time, trends). 
Our discussion is going to view time as discrete (measured in months), and thus the ti's will be integers and f(t) probability function, rather than a distribution function. We now present a brief description of common Survival Analysis approaches and their possible use in LOS modeling. Detailed discussion of prevalent Survival Analysis approaches can be found in the literature, e.g. Venables and Ripley 1999, chapter 12. Pure parametric approaches assume S(t) has a parametric form (Exponential, Weibull etc.) with the parameters depending on the covariates, including t. As Mani et al (1999) mention, such approaches are generally not appropriate for LTV modeling, since the survival function tends to be "spiky" and non-smooth, with spikes at the contract end dates. Semi-parametric approaches, such as the Cox proportional hazards (PH) model (Cox 1972), are somewhat more flexible. The Cox PH model assumes a model for the hazard function form: or alternatively: covafiates, except time, which is accounted for in the time-varying "baseline" risk 2(0. Mani et al (1999) build a Neural Network semi-parametric model, where each possible tenure t has its own output node (the tenure is diseretized to the monthly level). They illustrate that the more elaborate NN model performs better than the PH model on their data. The data as described above, makes LOS modeling a special case of survival analysis where each subject is observed only once in time, and customers who disconnected before this month are "left censored". Consequently we can approach it either as a survival analysis problem or a standard supervised learning problem where the time (i.e. customer's tenure with the company) is one of the predictors and churn is the response. To include a "baseline hazard" effect, time can be treated as being factorial rather than numerical, thus allowing a different effect for each tenure value. In this setting, a log-linear regression model for churn prediction using left-censored data would be equivalent in representation to a Cox proportional hazards survival analysis model. To see this (since if the customer already left we would not observe him). Thus a model of the form: is obviously equivalent to (3.2). The Kaplan-Meier estimator (Kaplan and Meier 1958) offers a fully non-parametric estimate for S(t) by averaging over the data: 333  X  Ct is the number of customers who should have been at least 
The data as described above is "left censored" and does not include Ct. However it can often be calculated based on historical information found in customer databases, which are typically used for LTV calculations. 
When we are considering the use of analytical models for marketing applications, we should take into account the way they are going to be used. An important concept in marketing is that of a "segment", representing a set of customers who are to be treated as one unit for the purpose of planning, carrying out and inspecting the results of marketing campaigns. A segment is usually implicitly considered to be "homogeneous" in the sense that the customers in it are "similar", at least for the property examined (e.g. propensity to churn) or the campaign planned. 
Amdocs Business Insight tools assist marketing experts in automatically discovering, examining, manually defining and manipulating segments for specific business problems. We assume in our LTV implementation that: 
Based upon these assumptions, estimating LOS for a segment is reasonable and relatively simple. Under these assumptions we can dispense completely with the covafiate vectors x (since all customers within the segment are similar) and adopt a non-parametric approach to estimating LOS in the segment by averaging over customers in the segment. 
The Kaplan-Meier approach is reasonable here, but as we discussed before it requires the use of left-censored data referring to customers who have churned in the past. While this data is usually available it refers to churn events from the (potentially distant) past, and so may not represent the current tendencies in this segment, which may well be related to recent trends in the market, offers by competitors etc. So an alternative approach could be to calculate a non-parametric estimate of the hazards rate: 
Where:  X  ](t i = t) equals 1 if customer t's current tenure is t months  X  I(c~ = 1) equals 1 if customer i churned in the current 
This approach relies heavily on having a sufficient number of examples for each discrete time point t (usually taken in months), but has the advantage of using only current data to estimate the function. We can obtain an estimate for S(t) through the simple calculation: Where S(O) = 1, of course. 
In section 4 we describe Amdocs' LTV platform, which utilizes this approach and illustrate it on real data. 
When examining the adequacy of a modeling approach, we generally have to consider two statistical concepts: 
These concepts ihave concrete mathematical definitions for the case of squared error loss regression only (although many suggestions exist for generalized formulations for other cases -see, for example -Friedman 97). However the principles they describe apply to any problem: 
Under the segment-homogeneity assumption mentioned in the previous section, the bias of our segment-based approach should be close to zero. Furthermore, even without this assumption, if we assume that the marketing expert planning the campaign is only interested in the segment as a whole, then the quantities we want to estimate are indeed segment averages and not individual values. 
Hence the segment-based estimates are unbiased in this scenario as well. As for variance, this is obviously a function of segment size. 
Parametric estimators will tend to have smaller variance. It is an interesting research question to investigate this bias-variance tradeoff between non-parametric and parametric estimates in this case. Under the: assumption that segments are "large" (as are indeed the segments in most real-life segments encountered in the communication i~ndustry), and that there is a reasonable amount of chum in each segment, we can safely assume that the segment based non-parametric estimates will also have low variance, and hence that our approach is reasonable. 
Calculating a customer's current value is usually a straight forward calculation based on the customer's current or recent information: usage, price plan, payments, collection efforts, call center contacts, etc. In section 4 we give illustrated examples. 
The statistical techniques for modeling customer value along time include forecasting, trend analysis and time series modeling. 
However the complexity of modeling and predicting the various factors that affeet future value: seasonality, business cycles, economic situation, competitors, personal profiles and more, make future value prediction a highly complex problem. The solution in 
LTV applications is usually to concentrate on modeling LOS, while either leaving the whole value issue to the experts (Mani et for in the LOS model, as we describe below. Rosset et. al. 2001 provide a detailed explanation about the relevant inverse transformation. 
LOS is calculated on the segment level. It is calculated for each "age" group t within the segment, i.e. for each group of customers with the same tenure in the segment, there will be the same LOS. 
This calculation is based on a large amount of data (customers with the same tenure in the segment). The base for this value is the proportion of churners for each age t -Pt as defined in the following formula (this is an extended version of the calculation from equation (3.5) in section 3.3) p, = factor x Z I(t, = t)l(c, = 0)+ ~ I(t, = t)l(c i = 1)  X  El(t, = t)l(c, = 1) is the number of chumers at tenure t  X  EZ(t, = t)l(c, = 0) is the number loyal customers at tenure t  X  factor = (chum to loyal sample ratio) / (churn to loyal population ratio) 
This quantity is calculated for each tenure t in the segment. There are several assumptions underlying this calculation. First, that the current churn probabilities for customers at tenure t represent the future ones at tenure t; second, that the customers come from a "homogeneous" population and third, that both give reliable estimates ofpt. 
Now, given a customer who is currently at tenure to, we can use (4.1) to get the 'Probability of a customer to reach age t' -S(t) S(t)=(1-p,_,) X (1-Pt_2) X ...XO-Pto) (4.2) 
And then we can get the expected LOS as follows-then the sum will be over 24 months. Implementing other discounting functions, in addition to this threshold approach is planned for the future, and poses no conceptual problems. 
Finally, LTV within a segment will be the following sum over all customers in the segment is where  X  j is the index of customers in the segment  X  vj is the value ofthej-th customer Figure 2 is a screen capture of the CMS window for calculating 
LTV. It is necessary to select the customer's age (tenure), enter the horizon and enter the full population chum rate (the sample chum rate is already derived). It is also necessary to select/define the value, which may be one of three options: an equal value for this case the "average bill" was previously selected), or a new value function. The result of the LTV calculation can also be seen in Figure 1. 
The statistic measures (including LTV) of the identified segments are already transformed to the full population. In general, Loyal segments ("Class: Stay") have higher LTVs than Chum segments, 
LTV of relevant segments by proper retention efforts, which aim mainly at increasing the LOS (a secondary purpose is increasing the value). We now turn to the most useful and challenging application of 
LTV calculation: modeling and predicting the effects of a company's actions on its customer's LTV. 
An example of a desirable scenario for a LTV application would be: 
Company "A" has identified a segment of "City dwelling professionals", which is of high value and high churn rate. It wants to know the effect of each one of five possible incentives suggestions (e.g. free battery, 200 free night minutes, reduced price handset upgrade etc.), on the segment's value over time and 
LOS, and hence LTK Each incentive may have a different cost, different acceptance rate by customers, and different effect if it gets accepted. 77~e goal of the LTV application is to supply useful information about the effects of the different incentives, and help analysts to choose among them. 
From the definition of the problem it is clear that there is some information about the incentives which we must know (or estimate) before we can calculate its effect on LTV: 
Given all of the above, calculating the change in LTV of a customer from a retention campaign, in which a given incentive is suggested is a straight forward ROI calculation: 
As for the basic LTV calculation described in section 2, and even more so, the main challenge is in obtaining reasonable and usable estimates for the above quantities, in particular the functions v  X ), y0. 
We now describe two approaches to this problem: one that builds on our segment-level LTV calculation approach presented above, and another that makes further simplifying assumptions, negating the need to predict the future. 
As was mentioned before, working at the segment level allows us to "average" our information over the whole segment and avoid parametric assumptions, at the price of assuming that the segment population is "homogeneous". 
To expand the segment-level approach described in section 3.2 to estimate the effect of incentives on a segment's LTV, we need to describe how we change the LOS model per segment, and how we adjust customer value for the incentive effects. 
We define two possible effects of an incentive on LOS: 337 avLTV  X ) -avLTV = 
Where avLTI , X i) is the estimated average LTV per customer in the segment after the retention campaign and avLTV is the estimated current average LTV per customer in the segment. If this difference is positive it means we expect the retention campaign to be beneficial to the company. 
Let us now assume the following: 
Then we get the following value for customer LTV without retention: 
LTVold = v' ~(1 -p)' -_-v. ~ 1 -pt = vh(1 -p(h -1)) (5.5) where the approximation relies on p and h being reasonably small. And adding retention we get: LTVnew= P(hv -G) +(1 -P)LTVol d -C (5.6) 
Since if we succeed in giving the incentive we are guaranteed loyalty for the full relevant period of h months. So the difference in LTV due to retention is: 
LTVno w -LTVo]d~P.h(h-1).v.p-P.G-C (5.7) which, given P,G and C and ignoring the inaccuracy in our calculation gives us the elegant result that: 
LTV~c w -LTVo~ d &gt; 0 v .p &gt; (P. G -C)/(P. h(h -1)) (5.8) 
In other words, we get the intuitive conclusion, that if we have a reasonable model for v and p, we should suggest the incentive only to customers whose value weighted risk vp is big enough. displayed in section 4 we defined the LTV parameters. Recall, that the field selected as value was the monthly average bill, the selected horizon is 12 months and the population chum rate is 5% (in the sample it's about 50%). The LTV of this segment, which is already displayed in Figure 3 is $4,967,202. 
The next step is to define the possible incentives. An example of 
Figure 4 the incentive is defined and in Figure 5 the incentive is refine the segment definition. Note that the same incentive may be allocated to diffi~rent segments. 338 
Finally, we compare the change in LTV related to each of the incentives. The cost of giving a discounted handset upgrade is much higher than the cost of a free caller id (in this example we used $100 and $10 correspondingly). On the other hand, the acceptance rate will be higher since it's a more attractive offer (caller-id -10% of the chumers and 20% of the loyals, upgrade -20% of the chumers and 30% of the loyals). Actually, churners often switch providers in order to receive an improved handset promised by the competitor. So, the result of the upgrade incentive will be a higher retention rate than the caller-id incentive. Additionally, a more sophisticated handset will probably increase the usage and thus the added value, while adding a caller-id will have very little or no impact on the usage (the relative value increase for the upgrade is 10% in this example and none for the caller-id). Note that the added value affects both potential churners who accept the offer and loyal customer who will accept the offer. Furthermore, loyal customers will also be committed to 12 more months, so even though they weren't about to chum in the next month the incentive may lengthen their LOS. 
The new LTV calculation takes into account all these parameters and the result as can be seen in Figure 6 is that the estimated increase in LTV due to offering a discounted upgrade is $2,413,338 and due to offering a free caller-id is $1,982,294. 
Suppose we wanted to examine the same two incentives for a different segment, as shown in Figure 7. This is a segment with many loyal customers, comprised of older customers with stable usage and medium bill average amounts. 
In addition to the purpose of retaining the chumers in this segment, offering an incentive to this segment is done also to increase the usage / value of the loyal customers and lengthen their LOS. The original LTV as displayed on Figure 6.5 is $29,091,321. The same cost and acceptance rates were applied for the caller-id and upgrade incentives. Note that since the acceptance rate is higher for loyal customers the overall acceptance rate of this segment will be higher then in the previous churn segment. 
The result was that the increase in value and LOS wasn't large enough to cover the high cost of the upgrade offers. Thus, the estimated change in LTV due to that incentive is negative: $485,450. On the other hand, the caller-id incentive yielded an estimated LTV increase of $1,422,540 (Figure 8). 
The examples illustrate that different incentives may have different impacts on LTV of the same segment, and the same incentive may have different impacts on LTV of different segments. The calculations involved are complex enough that the differential effect of different incentives on different segments cannot be easily guessed even when all the incentive's parameters are known. Using the application's mechanism for estimating that impact, it is possible to fit the appropriate incentive (out of the given options) to selected segments. 
In this paper we have tackled the practical use of analytical models for estimating the effect of retention measures on customers' lifetime value. This issue has been somewhat ignored in the data mining and marketing literature. We have described our approach and illustrated its usefulness in practical situations. 
The approach presented here to LTV calculation is not necessarily the best approach. However our emphasis is on practical and usable solutions, which will enable us to reach our ultimate goal -to get useful and actionable information about the effects of different incentives. As our approach is modular, additional LOS and value models can certainly be integrated into the solution we presented. 
We believe that this problem, like many others that arise from the interaction between the business community and data miners, present an important and significant data mining challenge and deserve more attention than it usually gets in the data mining community. In this paper we have tried to illustrate the usefulness of combining business knowledge and analytical expertise to build practical solutions to practical problems. [1] Cox, D.R. (1972), "Regression Models and Life Tables," [2] Friedman, J.H. (1997), "On Bias, Variance, 0/l-Loss and the 
Discovery 1(1), 55-77. [3] Helsen, K. and Schnaittlein, D.C. (1993), "Analyzing 
Duration Times in Marketing: Evidence for the Effectiveness of Hazard Rate Models," Marketing Science, 11,395-414. [4] Inger, A., Vatnik, N., Rosset, S. and Neumann, E. (2000), "KDD-Cup 2000 Question 1 Winner's Report," SIGKDD 
Explorations, 2(2), 94. [5] Kaplan, E.L. and Meier, R. (1958), "Non-parametric [6] Mani, D.R., Drew, J., Betz, A. and Datta, P. (1999), [7] Murad, U. and Pinkas, G. (1999), "Unsupervised Profiling [8] Neumann, E., Vatnik, N., Rosset, S., Duenias, M., Sassoon, [9] Novo, J. (2001), "Maximizing Marketing ROI with Customer [10] Rosset, S. and Inger, A. (2000), "KDD-Cup 99: Knowledge [11] Rosset, S., Murad, U., Neumann, E., Idan, I. and Pinkas, [12] Rosset, S., Neumann, E., Eick, U., Vatnik, N. and Idan, [13] Venables, W.N. and Riple~, B.D. (1999), Modem Applied 
