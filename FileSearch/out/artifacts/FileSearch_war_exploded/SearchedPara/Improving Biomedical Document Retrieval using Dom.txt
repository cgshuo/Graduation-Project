 When research articles introduce new results or findings the y typically relate them only to knowledge entities of immedi-ate relevance. However, a large body of context knowledge related to the results is often not explicitly mentioned in t he article. To overcome this limitation the state-of-the-art in-formation retrieval approaches rely on the latent semantic analysis in which terms in articles are projected to a lower dimensional latent space and best possible matches in this space are identified. However, this approach may not per-form well enough if the number of explicit knowledge entitie s in the articles is too small compared to the amount of knowl-edge in the domain. We address the problem by exploiting a domain knowledge layer, a rich network of relations among knowledge entities in the domain extracted from a large cor-pus of documents. The knowledge layer supplies the context knowledge that lets us relate different knowledge entities and hence improve the information retrieval performance. We develop and study a new framework for i) learning and aggregating the relations in the knowledge layer from the literature corpus; ii) and for exploiting these relations t o im-prove the information-retrieval of relevant documents. We demonstrate the benefit of the method on biomedical text retrievals.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval General Terms: Algorithm, Performance Keywords: Information Retrieval, Link Analysis
Due to the complexity of scientific domains today, research documents may feasibly mention only a fraction of knowl-edge of the field. This is not a problem for humans who are armed with a general domain knowledge and hence are able to overcome the missing links and connect the information in the article to the overall body of domain knowledge. But many search and information-retrieval systems that work by analyzing and matching queries only to individual docu-ments are very likely to miss these knowledge-based connec-tions and thus fail to retrieve many relevant documents. The objective of our work is to improve the retrieval of relevant documents using a knowledge layer, a rich network of connections relating knowledge entities in the domain. The intuition is that document level analysis used for ex-ample in PLSI [2] is not sufficient to extract models rich enough to overcome the complexity of the domains and rel-ative sparseness of knowledge entities referenced in indiv id-ual documents. To overcome the limitation our approach starts by mining and aggregating associations found in mul-tiple documents in large corpora first. Our hypothesis is that globally extracted relations should provide better su p-port for inferences on hidden but closely related knowledge entities that are relevant for the query. To support infer-ences on such networks we propose and adopt link-analysis methods. The advantage of the new approach and is that it can be combined easily with existing information retrieval techniques such as PLSI[2] and BM25[4]. We demonstrate the benefit of the method on biomedical text retrievals.
The framework proposed in this work (1) extracts a knowl-edge model from scientific documents in large domain cor-pora, (2) uses the model to support inferences on domain en-tities, hence improving the retrieval of relevant document s.
The knowledge of any scientific filed can be seen as a rich network of relations among domain entities. Due to the complexity of scientific domains it is infeasible to mine all these relations from a single document, a more complete picture arises only if the information in a large corpora is aggregated. However, it is still unclear how one can use the network of relations extracted from many documents to support inferences for the information retrieval purpos es. We propose to study link analysis methods to address the problem. Our hypothesis is that closely and tightly related knowledge entities are more relevant to each other.
To perform link analysis we adopt PHITS [1]. PHITS is a probabilistic model used to study document citation and web hyperlink structure. Mathematically it is simi-lar to PLSI[2]. PHITS assumes a naive bayes decomposi-tion of documents on a latent variable z representing dif-ferent communities of documents. In our work, we use it to model relations among domain entities (terms), and not documents. We assume that each entity e i is independent of others given a latent factor z , which represents a family of closely related domain entities. In terms of the full join t probabilistic model, PHITS lets us represent the relations among entities indirectly using the relations between enti -ties and latent variables. These relations are represented as conditional probabilities P ( e i | z ) and the full joint distribu-tion over all entities is defined as:
Given the PHITS-based model we can define probabilistic relations between entities and documents as well. Each doc-ument d i is represented as a vector of domain entities that occur in it. Zero entries in the vector means some domain entities are not mentioned in the document. However, this does not mean they are irrelevant to the document. Instead we treat them as hidden variables and our ultimate goal is to figure out probable values of these hidden variables.
P ( e h | d i ) Equation 2 explains how to compute the probability of of a hidden entity e h in document d i containing entities e with the help of the PHITS model.
The relevance of a scientific document to the query is best assessed by a human expert. Unfortunately this can be a very tedious and costly process. To alleviate this problem and still demonstrate the benefit of our approach we use the following setup: we perform all knowledge-model learn-ing and retrieval analysis on documents X  abstracts only; fu ll texts and exact matches of queries on full texts serve as sur-rogate measures of relevance. Briefly, if we retrieve a doc-ument based on its abstract, the relevance of the abstract is judged based on the exact match of the query to the full document.

We evaluate our approach on a corpus of 6000 cancer study articles from PubMed. Domain-specific entities con-sidered in our analysis are names of genes and proteins. A network relating the species was extracted from a subset of 4800 training documents. The PHITs link-analysis model was then learned from the network model. The optimal model was determined with the help of the BIC criterion [5]. All experiments were performed on documents that were not included in the training stage. To demonstrate the ben-efit of our method and the knowledge layer we combine our the baseline. We run it once on abstracts only, and once on full texts.

We test the methods on 500 queries that involve random pairs of genes and proteins. Figure 1 shows the 11-point av-erage precision of different methods. It is not surprising th at Lucene indexed with full text performs the best. Original PLSI and BM25 do not outperform Lucene when it is run on abstracts. However, they both do better when combined with a knowledge layer (methods are labeled with asterisks) . The results clearly show that our approach helps to improve the retrieval. Figure 1: 11-Point Interpolated Average Precision
We present a new framework that extracts the domain knowledge from multiple documents and uses it to support document retrieval inferences. We have shown that our method leads to improved retrieval performance on biomed-ical literature. Several recent research projects [3][6] a lso use domain knowledge and demonstrate its benefit. How-ever, to our knowledge this is the first work that attempts to learn the probabilistic relations among domain entities and use them in document retrieval. In future, we would like to verify our framework on retrieval of full text docu-ments and build a more comprehensive domain knowledge that explicitly captures a variety of domain relations. [1] D. Cohn and H. Chang. Learning to probabilistically [2] T. Hofmann. Probabilistic latent semantic indexing. In [3] J. Pickens and A. MacFarlane. Term context models for [4] S. E. Robertson, S. Walker, S. Jones, [5] G. E. Schwarz. Estimating the dimension of a model. [6] W. Zhou, C. Yu, N. Smalheiser, V. Torvik, and
