 fi ers dynamically by using the parameters for positive and negative 1. Introduction
Nowadays, with increased digital images available on Internet, ef fi cient indexing and searching becomes essential for large image archives. Traditional annotation heavily relies on manual labor to label images with keywords, which unfortunately can hardly describe the diversity and ambiguity of image contents. Hence, content-based image retrieval (CBIR) ( Datta et al., 2008 ) has drawn substantial research attention in the last decade. The main idea of CBIR is to retrieve within large collections images matching a given query thanks to their visual content analysis. Visual features, such as color, texture or shape, are extracted from the images and indexed. These features can be global or extracted from regions or points of interest ( Michael et al., 2006 ) and then compiled into an index or signature. A basic way to perform retrieval consists in computing a similarity function for comparing the query index to one of the images in the collection. Although extensive studies have been conducted, fi nding desired images from multimedia databases is still a challenging and open issue. The main chal-lenges are due to two gaps in CBIR ( Zhang et al., 2012 ). The the sensor gap between the object of the world and the informa-tion represented by computers. The second one is the semantic gap between the low-level visual features and high-level human perception and interpretation.

Relevance feedback originated from text-based information retrieval is a powerful technique to improve the image retrieval performance ( Zhou and Huang, 2003 ). In order to approach the query images of an user, relevance feedback is viewed as the process of automatically altering an existing query by incorporat-ing the relevance judgments that the user provide for the previously retrieved objectives. In image retrieval, relevance feed-back will fi rst solicit the user's relevance judgments on the retrieved images returned by CBIR systems. Then, it re fi retrieval results by learning the query images from the provided relevance information. Although relevance feedback was origi-on, it attracted much more attentions in image retrieval. In fact, relevance feedback is a supervised learning technique, and it focuses on the interactions between the user and the search engine by requiring the user to label semantically positive or negative feedbacks. Most of the early relevance feedback method can be classi fi ed into the query point movement and the reweight-ing method. The query point movement method essentially tries to improve the estimation of the  X  ideal query point  X  by moving it towards positive examples and away from negative ones. The key idea behind reweighting method is to change the weight of each image feature element. However, all these methods make strong assumption that the target class has an elliptical shape, which greatly limits their performance ( Yang et al., 2012 ).
More recently, some researchers have considered relevance feedback as a classi fi cation problem in which sample images provided by the user are employed to train a classi fi er, which is then used to classify the database into images that are relevant to the query and those that are not ( Huang et al., 2006 ). Support vector machine (SVM) is a popular small sample learning method, which has a very good performance for pattern classi-fi cation problems by minimizing the Vapnik  X  Chervonenkis (VC) dimension and achieving a minimal structural risk. Within different relevance feedback schemes, SVM-based relevance feedback is popular ( Zhang et al., 2001 ) because it outperforms many other classi fi ers when the size of the training set is small.
However, for the SVM-based relevance feedback, the assumption is that positive samples cluster in a certain way but negative ones do not, as they can potentially belong to any class or group.
Although they reported good results using only a small number of positive training samples, the performance of the method relies on proper selection of some parameters. Moreover, there is no control on the relevance score of the positive samples as all of them are treated equally ( Zhang et al., 2005 ).

Active learning is close to supervised learning, except that training data are not independent and identically distributed variables. Some of them are added to the training set thanks to a dedicated process. Recently, SVM has been combined with the multimodal concept-dependent process for CBIR (Philippe and
Matthieu, 2008; Tong and Chang, 2001; Wang et al., 2011 ), but it requires users to label a lot of training images (about 20 images) in the fi rst round feedba ck procedure. Liu and Wang (2008) proposed a SVM-based active feedback in image retrieval using clustering and unlabeled data, in which a new active selection criterion to select images for user's feedback is designed, and unlabeled images are incorporated within the co-training fra-mework. To reduce computational time for training, it might be necessary to select batches of new training examples instead of single examples. Strategies for single example can be extended straightforwardly to select batches by choosing the h 4 1exam-ples that get the highest values for the individual selection criterion. Brinker (2003) presented a new approach that is especially designed to construct batches and incorporates a diversity measure. It has low computational requirements mak-ing it feasible for large scale problems with several thousands of examples. Zhou et al. (2006) proposed a co-training approach for combining semi-supervised learning and active learning for relevance feedback. Li et al. (2006) developed a new SVM-based relevance feedback approach by using the multitraining SVM (MTSVM), which combines the merits of the cotraining techni-que and a random sampling method in the feature space. Hoi et al. (2009) present a framework for batch mode active learn-ing, which selects a number of informative examples for manual labeling in each iteration. The key feature of batch mode active learning is to reduce the redundancy among the selected examples such that each example provides unique information for model updating. Although SVMs have been successfully applied in many empirical applications, they have a lot of limitations. First, the regul ar SVM is originally for binary classi fi cation problem. It may not achieve the best performance when applied in multi-class ta sks. Moreover, the regular SVM treats fairly with the positive and negative instances. If instances in one of the two-class overnumber another ones, the performance of the regular SVMs may suffer dramatically. To overcomethedrawbacksoftheregularSVM,theSVMensemble technique was proposed and has shown promising improve-ment over the regular SVMs ( Wu and Chung, 2009; Tao et al., 2006; Wu and Lu, 2010 ). In general, a SVM ensemble is a collection of several SVM classi fi ers in which the decision to classifythetestdataismadebycombiningthedecision functions of all individual classi fi ers. Although the advantages of classi fi ers ensemble have been shown, the shortages also emerged gradually along with the development of ensemble classi fi ers. For instance, the instability of the performance is useless for practical problems. In addition, not every classi bene fi cial for the classi fi cation performance, and even someone could harm the performance of an ensemble system. Hence, how to improve these shortages has been important for improv-ing the performance.

In this paper, we proposed a new SVM-based active feedback using ensemble multiple classi fi ers. Firstly, we select the most informative images by using active learning method for user to label, and quickly learn a boundary that separates the images that satisfy the user's query concept from the rest of the dataset. Then, a set of moderate accurate one-class SVM classi fi ers are trained separately by using different sub-features vectors. Finally, we compute the weight vector of component SVM classi fi ers dyna-mically by using the parameters for positive and negative samples, and combine the results of the component classi fi ers to form an output code as a hypothesized solution to the overall image retrieval problem.

The rest of this paper is organized as follows. Section 2 presents the basic theory about support vector machine (SVM). Section 3 describes the SVM active learning. In Section 4 , the SVM ensemble is discussed. Section 5 contains the description of our SVM-based active feedback using ensemble multiple classi fi ers. Simulation results in Section 6 will show the performance of our scheme.
Finally, Section 7 concludes this presentation. 2. Support vector machine (SVM) classi fi er
In this section, we brie fl y introduce the standard SVM for binary classi fi cation problems.

Support vector machine (SVM) is a universal classi fi cation algorithm proposed by Vapnik ( Zhang et al., 2001 ) in the middle of the 1990s, it is thought of a new innovation of learning machine, which uses the statistical learning theory.

The basic theory of SVM can be depicted by a typical two-dimensional case shown in Fig. 1 .InFig. 1 ,  X  and  X  denote two categories of samples. H is the separating hyperplane, H 1 parallel to H (they have the same normal) and no training points fall between them; the margin of a separating hyperplane is de fi ned as H 1  X  H 2 . The optimal separating hyperplane what you call not only can separate the two categories of samples exactly (the ratio of training errors is 0), but also has the maximal margin.
Thus the problem of optimal separating hyperplane can be transformed a constraints problem.

For the training sets: f X  x ; y 1  X  ;  X  x 2 ; y 2  X  ; ... ;  X  x n ; y n  X g x A
R , y A R to get the relation between the input x i and output y it can seek an optimal function f  X  x  X  by SVM training, so that the difference between the output value and the corresponding objective value of every input samples is not more than error
For the linear situation, the form of function is f  X  x  X  X  b A
R . In order to get an optimal function, it needs a minimum then the above problem can be described as an optimization problem: min 1 2 jj  X  jj 2 ; s : t :
To get the estimations of  X  and b , (1) can be transformed to the primal objective function (2) by introducing the positive slack variables  X  i Z 0 and  X  n i Z 0 min 1 2 jj  X  jj 2  X  C  X  n where C is the penalty parameter which controls the trade off between errors of the SVM on training data and margin maxi-mization.

Then, the optimization problem is equal to the following problem according to the Wolfe dual principle ( Cao and Tay, 2003 ): max  X   X   X  ;  X  n  X  X   X   X  n s : t :  X  n penalty parameter, and the optimal function is f  X  x  X  X  X  wx  X  X  b  X   X  n where  X  i ,  X  n i are only few non-zeros which corresponding samples are namely called support vectors, b n is a scalar which determines the position of the separating hyperplane.

It needs to be pointed out that the dual problem ( Zhang et al., 2001 ) mentioned above only refer to the inner product operation of training samples in the optimal function seeking, for the nonlinear data discussed in our scheme, it only needs to replace the inner product operation mentioned above by kernel function 3. SVM active learning Active learning ( Huang et al., 2008; Gosselin and Cord, 2008; Wu et al., 2010 ) is close to supervised learning, except that training data are not independent and identically distributed variables. Some of them are added to the training set thanks to a dedicated process. Active learning methods have been introduced to perform good classi fi cations with few training data in comparison to the standard supervised scheme ( Gosselin and Cord, 2008 ). 3.1. Example of active strategies
Fig. 2 shows the interest of a selection step. In this example, the images are represented by 2-D feature vectors, the white circles are images the user is looking for, and the black circles are the images the user is not interested in. At the beginning, the user provided two labels, represented in fi gures by larger circles (see Fig. 2 (a)).
These two labels allow the system to compute a fi rst classi
In classical relevance feedback systems, a common way of selection was to label the most relevant pictures returned by the system. As the classi fi cation is not improved. Other types of selection of new examples may be considered. For instance, in Fig. 2 (c), the active learning selection working on uncertainty is proposed: the user labels the pictures the closest to the boundary, resulting in an enhanced classi fi cation in that case ( Fig. 2 (c)). 3.2. Optimization scheme f y are determined in order to rank the whole database. New notations are introduced for the teacher s : X -f 1 ; 1 g that labels images as 1 or 1, the indexes of the labeled images I , and the unlabeled ones I .

The active learning aims at selecting the unlabeled data x will enhance the most relevance function f trained with the label s  X  x n  X  added to A y . To formalize this selection process as a mini-mization problem, a cost function gA y is introduced. According to any active learning method, the selected image is x i n minimizing gA y  X  x  X  over the pool of unlabeled images i  X  arg min 3.3. SVM active learning
In this paper, we use a SVM active learning method. Our SVM active learning system takes the simple approach of choosing the pool-queries to be the 15 images closest to its separating hyper-plane. Compared with other active learning methods ( Tong and
Chang, 2001; Huang et al., 2008 ) which are unstable during the fi rst round of querying. our system always randomly chooses 15 images for the fi rst relevance feedback round. Then it uses the simple active method on the second and subsequent rounds.
To summarize, our SVM active learning system performs the following for each round of relevance feedback: Learn a SVM on the current labeled data.

If this is the fi rst feedback round, ask the user to label 15 randomly selected images. Otherwise, ask the user to label the 15 pool images closest to the SVM boundary.

After the relevance feedback rounds have been performed, SVM active learning system retrieves the top-k most relevant images: Learn a fi nal SVM on the labeled data.

The fi nal SVM boundary separates  X  relevant  X  images from irrelevant ones. Display the k  X  relevant  X  images that are farthest from the SVM boundary. 4. SVM ensemble
An ensemble of classi fi ers is a set of classi fi ers whose individual decisions are combined in some way to classify new examples.
Presently, one of the most active research areas in supervised learning is method for constructing good ensemble of classi
The main discovery is that ensembles are often much more accurate than the individual classi fi ers that make them up ( Ma et al., 2007; Kim et al., 2003; Lei et al., 2011; Zhou, 2009 ). Assume that there is an ensemble of n classi fi ers: f f 1 ; f 2 wrong at the same data, where an ensemble will show the same performance as individual classi fi ers. However, if classi different and their errors are uncorrelated, then when f 1 wrong, most of other classi fi ers except for f 1  X  x  X  may be correct. Then, the result of Majority voting can be correct.

In recent years, a lot of researchers pay much attention to SVM ensemble ( Kim et al., 2003 ). Fig. 3 shows a general architecture of the SVM ensemble. During the training phase, each individual SVM is trained independently by its own replicated training dataset. All constituent SVMs will be aggregated by various combination strategies. During the testing phase, a test example is applied to all SVMs simultaneously and a collective decision is obtained based on the aggregation strategy.

Many methods for constructing an ensemble of classi fi ers have been developed. The most important thing in constructing the
SVM ensemble is that each individual SVM becomes different with another SVM as much as possible. This requirement can be met by using different training sets for different SVMs. Some methods for selecting the training samples are bagging, boosting, randomiza-tion, stacking and dagging etc. ( Wu and Chung, 2009; Wu and Lu, 2010 ). Among them, we put focus on the representative methods Adaboosting and Majority voting.

Adaboosting is the representative boosting algorithm, which is based on the principle of error minimization. Adaboosting can obtain the best classi fi cation results by repeatedly adjusting the weights of individual classi fi er, but it usually costs a lot of time. f(X) Another method is based on Majority voting mechanism to obtain the scores of individual classi fi er, and then, choose the one whose score is high. The disadvantage of Majority voting method is that the scores of individual classi fi er may be very similar when users focus on many classi fi ers at the same time. The common feature of the above two methods is that the individual classi fi er treats the classi fi cation ability of positive samples and negative samples equally. In this paper, we adjust the parameters of the positive and negative samples to improve the classi fi cation performance.
Suppose there are n visual feature spaces, we construct a SVM classi fi er for each visual feature space in each feedback, the SVM classi fi er is represented as P  X  C  X  S  X  t  X  ; X  X  i  X  X  ; i  X  1 ;:::; n ; t  X  1 ;:::; n  X  6  X  where t is the time of feedback, S  X  t  X  represents the training set of the image database uses X as its corresponding eigenvector, and P  X  x  X  represents the probability of the image that is relevant in the i th feature space. The probability of the image which is relevant after the feedback is represented as P  X  x  X  X   X  i P t i  X  x  X  X  7  X  where  X  t i is the weight of the corresponding classi fi er. The following describes how to compute the weight.

Based on the visual feature i for each classi fi er, the greater the accuracy of the classi fi er in the train set, that is, the smaller the training error, the higher the level of such features which users like. For the relevant images (or irrelevant images) in the training set, the value of the probability of images which are relevant images (or irrelevant images) re fl ects the correct level of the classi fi er is represented as  X   X   X  When the image X belongs to the relevant image, y  X  1; Otherwise, y  X  1.  X  i and  X  i are the importance of the relevant and the irrelevant image for the i th classi fi er. The greater more important the classi fi er to the relevant images is, the more correct the classi fi cation of the relevant images is, the higher the weight of the corresponding classi fi er is. Extremely, if shows that the classi fi er only considers the relevant images. 5. Image retrieval system
For CBIR the search engine is required to feedback the most semantically relevant images after each previous relevance feed-back iteration. The user will not label many images for each iteration and will usually do only a few iterations. Fig. 4 describes our image retrieval system framework with relevance feedback.
As shown in Fig. 4 , our image retrieval system has four main components: query; retrieval; labeling; and learning. when a query is submitted, its low-level visual features are extracted.
Then, all images in the database are sorted based on a similarity is ended. If the user is not satis fi ed, he can label some images as positive feedbacks and/or some images as negative feedbacks.
Using this feedback process, the system is trained based on machine learning using the embedded relevance feedback algo-rithm. Then, all the images are re-sorted based on the recalculated similarity metric. If the user is still not content with the result, he repeats the process.

For our relevance feedback mechanism, labeling and learning are two key components. In the user labeling, for the fi rst feedback iteration, we only select the initial returned images to label samples. After that, we use SVM active learning method (see
Section 3.3 ) to select the most informative images as the training samples. In this paper, 200 most informative images (which are close to the hyperplane) are selected for training the SVM classi fi er. Among them, 15 most informative images are returned to users for the labeled samples, the others for the unlabeled samples. In the learning unit, we construct SVM classi fi rately for three sub-feature vectors, i.e. color, texture, and edge.
Then, we use SVM ensemble method (see Section 4 ) to fuse the individual SVM classi fi er, and some images that are displayed by the interface are chosen to query the user. If the user is satis with the current retrieval result, the feedback process will be stopped; otherwise the user should provide feedback on these images and go into next round.

To summarize, our relevance feedback algorithm is presented as follows:
Let L and U denote respectively the labeled and unlabeled dataset.
 Input: User query DB: Image database
Step 1: The low-level visual features for each image in image database are extracted, and stored in the feature database. Relevance Feedback Model Selecting Informative Images
Step 2: The user gives a query image, and the low-level visual features of query image are also extracted.

Step 3: By using the Euclidean distance, the similarity between the features of query image and the features of all images in the database is computed.
 Step 4: All images in the database are sorted based on a similarity.
Step 5: The N images in the database with the highest similarity values are chosen and returned to the user.

Step 6: At the fi rst feedback iteration, the N returned images are stored to L dataset, and 200-N images are selected randomly by SVM active learning from DB-L and are stored to
U dataset. Then, the training samples dataset is constructed with L and U .

Step 7: For other feedback iterations (the second, the third, and so on), all the training samples come from the images obtained by SVM active learning, and the label method is the same as Step 6.

Step 8: Three individual SVM classi fi ers are constructed with the training samples dataset ( L and U ) by using three sub-feature vectors, i.e. color, texture, and edge.

Step 9: The SVM ensemble method is utilized to fuse the three individual SVM classi fi er, and some images that are displayed by the interface are chosen to query the user.

Step 10: If the user is satis fi ed with the current retrieval result, stops the feedback iteration; otherwise, the feedback system goes to Step 11.

Step 11: The N most informative images, which are closest to the separating boundary, are selected by SVM active learning.
Goes to Step 7. 6. Experimental results
To evaluate the performance of the proposed algorithm, we conduct an extensive set of CBIR experiments by comparing the proposed algorithm to several state-of-the-art feedback methods (Zhang et al., 2001; Tong and Chang, 2001; Liu and Wang, 2008 ) that have been used in image retrieval. 6.1. Image database
We perform experiments over 3000 images from 150 cate-gories of the COREL photo gallery, in which each category contains 100 images. Every database image is of size 256 384 or 384 256. To evaluate the retrieval performance, we need a ground truth to assess the relevance of the test query images.
We follow the previous work ( Li and Hsu, 2008 ) to construct the ground truth by merging semantically similar categories. The reorganized database consists of 71  X  semantic categories experiments, 3000 images are randomly selected out of the whole databases as test queries. We de fi ne images within the same semantic category as relevant. Fig. 5 (a) shows some image exam-ples in the COREL dataset.

We also perform experiments over 3000 images from another image dataset, which is constructed by collecting images from the
Internet. Fig. 5 (b) shows some image examples in our constructed image dataset. 6.2. Feature extraction
Generally in a CBIR relevance feedback system, images are represented by three main features: color, texture and shape (Datta et al., 2008 ). Color information is the most informative feature because of its robustness with respect to scaling, rotation, perspective, and occlusion. Texture information can be another important feature and previous studies have shown that texture structure and orientation fi t well the model of human perception, similarly with shape information.

For color, we selected the global color histogram (GCH) of image interest points. Firstly, the steady image interest points are extracted by using SIFT detector. Secondly, we convert the color space from RGB into HSV, because the RGB color space does not closely model the psychological understanding of color. Then, we quantify the HSV color space into 64 bins, and the directions of hue, saturation, and value are quantized into 8 bins, 4 bins, and 2 bins respectively (8 4 2  X  64). Finally, the global color histo-gram (GCH) of interest points is constructed as follows ( Swain and Ballard, 1991 ):
H  X  k  X  X  n k N  X  k  X  1 ; 2 ; ... ; 64  X  where n k is the total number of interest points in the k th bin, and N denotes the total number of image interest points.

For texture, a pyramidal wavelet transform (PWT) feature was extracted from the Y component in the YCrCb space. An image is transferred into an YCrCb color space, and a multilevel 2-D Haar
Wavelet transform is performed on the Y component (the number of levels is 3). Then, the mean  X  mn and standard deviation the highpass subbands D mn at scale m  X  m  X  1 ; 2 ; 3  X  and orientation n  X  n  X  LH ; HL ; HH  X  are calculated as follows ( Do and Vetterli, 2002 ):  X   X  1 MN  X  where M and N respectively denote the height and width of the highpass subbands D mn , and D mn  X  x ; y  X  is the wavelet coef within the given highpass subband D mn .

For shape, the edge direction histogram (EDH) is used as the shape features. The EDH features can capture the spatial distribu-tion of edges. The edge information contained in the images is generated and processed by using the Sobel edge detection algorithm. An image is transferred into the YCrCb color space, and the statistical edges of horizontal, 45 1 diagonal, vertical, 135 1 diagonal, and isotropic edges are calculated on the compo-nent of Y . The vector dimension of EDH is 5 ( Wang and Zhang, 2001 ).

In this paper, color, texture, and shape features are thought to be equally important, so we use the following weighing factors for color, texture, and shape features: w
C  X  w T  X  w S  X  1 = 3 where w C ; w T ; and w S denote the weighing factors for color, texture, and shape features, respectively. 6.3. Comparative performance evaluation
We report experimental results that show the feasibility and utility of the proposed algorithm and compare its performance with three state-of-the-art feedback methods ( Zhang et al., 2001;
Tong and Chang, 2001; Liu and Wang, 2008 ). To simulate the practical situation of online users, the sequence of query images used in all the experiments is generated at random.

At the beginning of image retrieval, the images in the database are ranked according to their Euclidean distances to the query, and top 15 images are labeled as the set of initially labeled data for learning system. In many interactive CBIR systems, the user is required to label more than 20 images in each round of relevance feedback, which is not practical because few users are patient to label so many images. In our system, only 15 images judged as the most informative ones are put into a pool in each round of relevance feedback. In our retrieval system, only 15 images judged as the most informative ones are put into a pool in each round of relevance feedback, which is shown in Fig. 6 . In particular, only the positive images are required to be marked by user and all the other images are automatically marked as negative by the system.
Fig. 7 shows the retrieval results by using the proposed algorithm without the relevance feedback. Here, the image at the top of left-hand corner is the query image; the other images are the retrieval results. R denotes relevant image and N denotes nonrelevant image.

Figs. 8  X  11 show the retrieval results using different SVM relevance feedback after the fi rst feedback iteration. It is not dif fi cult to see that, compared with the retrieval results without relevance feedback (see Fig. 7 ), the performance of our SVM relevance feedback retrieval system is improved, but it is not obvious. However, as the number of the feedback iteration increases, the performance of our SVM relevance feedback retrie-val system becomes better and better, and it is more effective than three state-of-the-art feedback methods. This is because that we compute the weight vector of component SVM classi fi ers dyna-mically by using the parameters for positive and negative samples, and combine the results of the component classi fi ers to form an output code as a hypothesized solution to the overall image retrieval problem.
 We use the Average Precision (AP) measure de fi ned by NIST-
TREC video (TRECVID) as our retrieval performance metric. At each query session our system re fi nes the retrievals by executing the proposed SVM relevance feedback framework for several itera-tions. The AP value that can be obtained at each iteration is de fi ned as the average of precision value obtained after each relevant picture is retrieved. The precision value is the ratio between the retrieved relevant pictures and the number of pictures currently retrieved. Let P be the AP obtained at the current feedback iteration and it is computed by P  X   X  D i where P i denotes the precision value obtained after the system retrieves i top-ranked pictures, D i is one of the relevant pictures, R is the set of all relevant pictures that belong to the same class as the query, and j R j denotes the cardinality of R . As an example, assume that one of the classes consists of six relevant pictures and our retrieval system ranks these relevant pictures at the second, fourth, seventh, 13th, and 18th places. Thus, the precision value obtained when each relevant picture is retrieved is 1, 1, 0.75, 0.57, 0.38, and 0.33, respectively. The AP computes the average of these precision values and it is 0.67. The AP calculated over all relevant pictures can avoid precision fl uctuation that is usually encountered by the traditional precision measure. Fig. 12 shows the variations of the average AP as the number of feedback iterations increases. Table 1 reports the relationship between average AP and number of the training samples along with the standard deviation values. Note that the average AP obtained at the zero feedback iteration indicates the average AP calculated at the fi rst retrieval result of each query session before activating the relevance feedback process.

From the above experimental results, we can see that the proposed SVM-based active feedback approach outperforms other well-known approaches in terms of effectiveness and ef fi two image databases. The main contribution of the proposed scheme is introducing dynamically a new and effective weight values for component SVM classi fi ers, which can improve signi -cantly the performance of SVM ensemble. 7. Conclusion
Recently, SVM active learning has been widely applied in relevance feedback, which plays an essential role in improving the performance of CBIR. The main advantage of SVM is that it can generalize better than many other classi fi ers. Despite the success, for conventional SVM active learning, the users are usually not so patient to label a large number of training instances in the relevance feedback round. To improve the conventional SVM active learning based relevance feedback, we propose a SVM-based active feedback using ensemble multiple classi fi ers. Firstly, we select the most informative images by using active learning method for user to label, and quickly learn a boundary that separates the images that satisfy the user's query concept from the rest of the dataset. Then, a set of moderate accurate one-class vectors. Finally, we compute the weight vector of component SVM classi fi ers dynamically by using the parameters for positive and negative samples, and combine the results of the component classi fi ers to form an output code as a hypothesized solution to the overall image retrieval problem. Through experiments on a subset of Corel Photo Gallery with 15,000 images and the con-structed image dataset with 3000 images, we show that our new method can improve the conventional SVM active learning based relevance feedback consistently.
 Acknowledgments This work was supported by the National Natural Science Foundation of China under Grant nos. 61472171 and 61272416, the Open Project Program of Jiangsu Key Laboratory of Image and Video Understanding for Social Safety (Nanjing University of Science and Technology) under Grant no. 30920130122006, the Open Foundation of Zhejiang Key Laboratory for Signal Processing under Grant no. ZJKL_4_SP-OP2013-01, the Open Foundation of Provincial Key Laboratory for Computer Information Processing Technology (Soochow University) under Grant no. KJS1325, the Open Project Program of the State Key Lab of CAD&amp;CG (Grant no. A1425), Zhejiang University, and Liaoning Research Project for Institutions of Higher Education of China under Grant no. L2013407. References
