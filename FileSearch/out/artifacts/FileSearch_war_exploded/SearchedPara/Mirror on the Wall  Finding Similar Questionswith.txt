 Community Question Answering (cQA) services such as Yahoo! Answers , Baidu Zhidao , Quora , StackOverflow etc. build a community of  X  X xperts X  on various topics of interest. They provide a platform where any internet user can pose a question on specific topics and get answers from other users or experts. Compared to search engines, cQA forums offer the following advantages -(a) they provide the exact answer to user questions in stead of having to sift through a list of web pages (b) they provide answers to opinion based questions which are usually answered by other users based on their personal experience. Though, the answers provided by cQA users are usually of good quality, sometimes they can be noisy and redundant too. However, the noise in the data is offset by other forum meta-data associated with each question such as user provided rat-ings, categories, best answers ratings etc. Over time, cQA forums accumulate an archive of rich knowledge encoded in the form of user question and answers on various topics of interest.
 questions, which have already been answered, in response to new questions posed by users. This helps in -(a) Saving the time and attention of experts/users by allowing them to focus on new unanswered questions in stead of repeated questions expressed in a different language. (b) Minimizing the time lag of the user waiting for an answer (c) Preventing question starvation where if a question goes unanswered for a long time, answers to similar questions could be offered to the user and (d) Generating automated answers from the answers provided to similar questions in various cQA forums. The major challenge associated with this problem is bridging the lexico-syntactic gap. Two questions can convey the same meaning even though they are syntactically and lexically different. For example:  X  X an caffeine contents be harmful to health? X  and  X  X oes coffee have adverse effects on health? X  are semantically similar.
 from cQA archives. Previous approaches in literature have relied on -(a) learning word or phrase level translation models [ 4 , 7 , 9 ] from question-answer pairs in par-allel corpora of same language. The similarity function between questions is then defined as the probability of translating a given question into another or (b) learn-ing topic models from question-answer pairs [ 2 , 5 , 8 ]. Here, the similarity between questions, is defined in the latent topic space discovered by the topic model. How-ever, they suffer from the following short-comings -(a) Large parallel sentence-aligned question corpora is usually a scarce resource. This limits the effectiveness of translation-based approaches. (b) Topic based approaches usually perform well in improving recall but sacrifice on precision. Recently, Deep Structured Semantic Models (DSSM) [ 3 ] have shown state-of-the-art performance when compared to translation models and topic models for learning latent semantic representations. DSSM leverages large volumes of click-through data available to commercial search engines to learn a low-dimensional representation of the queries and documents. This is done by discriminatively training a neural network which maximizes the conditional likelihood of the clicked documents given a query. Further, Convolu-tional DSSM (CDSSM) adds a convolutional layer to the DSSM structure that projects each word within a context window to a local contextual feature vector. Semantically similar words within a context are projected to vectors that are close to each other in the contextual feature space.
 Model (DSTM) X  which leverages the strengths of both deep learning based meth-ods and topic models. In the training phase, DSTM learns -(a) A topic model, Latent Dirichlet Allocation (LDA) [ 1 ], for discovering the latent topics from the question-answer archive and (b) CDSSM semantic model for modeling the hidden semantic similarities between question-answer pairs. Given a new user question, DSTM employs a two-step process consisting of initially retrieving similar questions that lie in the vicinity of the query in the latent topic vector space discovered by LDA and then re-ranking them using the CDSSM model. Since, topic models such as LDA are expected to have better recall, the initial step will ensure that most relevant questions are filtered from the entire corpus. Later, this filtered set is re-ranked using CDSSM such that the most semantically similar questions are ranked higher in the order. Thus, we combine the strengths of both topic models and deep semantic models. Our contributions are (1) We enhance the topic modeling approach using deep neural networks. We employ deep semantic models to capture semantic similarity between the question pairs with same topic distribution. (2) Qualitative and quantitative analysis of our results using large scale Yahoo! dataset and comparison with other state-of-the-art methods.
 The rest of the paper is organized as follows. Section 2 presents our work in the context of related work. Section 3 describes the process of filtering rel-evant questions from corpus using LDA. Section 4 gives more details on Deep Semantic Modeling. Section 5 gives details of our system such as architecture and training methodology. Section 6 describes the experimental set-up, details of the evaluation datasets, evaluation metrics and also presents the quantitative and qualitative results. Finally, Sect. 7 concludes the paper. [ 4 ] visualized question retrieval problem as word-based translation problem. They utilized the similarity between answers in the archives to estimate trans-lation probabilities. [ 7 ] incorporated query likelihood language model and word based translation model to enhance the performance. In order to capture con-textual information, [ 9 ] proposed phrase based translation model for similar question retrieval. These models use question answer pairs as parallel corpus. Another way of approaching this retrieval problem is topic modeling. [ 2 ] exploited latent topic information of the question content. They infused  X  X at-egory X (every question in cQA data have a category and a set of sub-categories) information in the topic space to find the questions semantically nearer to the query. [ 5 ] proposed Question-Answer Topic Model (QATM) to learn the latent topics aligned across the question-answer. They also introduced QATM with posterior regularization (QATM-PR) to prevent the topic vector representation of question-answer pair to be dominated by the answers which are much longer in length than the questions. [ 8 ] used supervised question-answer topic model. They infused language model with topic model for matching the questions on both term and topic levels. [ 10 ] learned word embeddings of questions with  X  X ategory X  information. They employed a fisher kernel to convert the variable length question vectors to a fixed size representation. Our work is aligned towards the topic modeling and deep semantic models [ 3 , 6 ].
 Traditionally, LDA [ 1 ] has given good results for related question selection in cQA forums [ 2 , 5 , 8 ]. LDA assumes that a document exhibits multiple topics. In this problem setting each document is a question and its best answer pair. Assume, there are M documents in the corpus and every document is composed of words W . N is the total number of words in a particular document and K is the total number of topics to be considered. LDA is a probabilistic model where observed variables are the bag of words per document and the hidden random variables are  X  ,  X  and Z ( i, j ) where  X  is the topic distribution per doc-ument,  X  is the distribution of the vocabulary per topic and Z ( i, j ) is the topic of the j th word in the i th document. It can be considered as a unsupervised model where documents are unlabeled and no information of topic distribution is known beforehand. Our goal is to calculate the posterior probability of the hid-den variables given the observations. The graphical model of LDA can be seen in Fig. 1 . Documents are represented as random mixtures over latent topics, where each topic is characterized by a distribution over words. The generative process of LDA is used to find the joint probability of the observed variables and hidden variables. It is carried out as follows: 1. Choose  X  i  X  Dir(  X  ) where i  X  X  1, ... , M } and Dir(  X  ) is the Dirichlet distrib-2. Choose  X  k  X  Dir(  X  ) where k  X  X  1, ... , K } 3. For each word position ( i , j ) where j  X  X  1, ... , N (b) Choose a word w i,j  X  Multinomial(  X  z find the posterior or conditional probability of the hidden variable given the observed one by Eq. 1 .
 each document. Thus, each document can be represented in latent topic space. But, considering the noisy and redundant nature of data found in cQA sites it would not be a good idea to assume that semantically identical questions will have similar topic distribution.
 AsshowninTable 1 , few questions retrieved for the query  X  X ow the human species evolved? X  like  X  X ho is the most mature species in planet? X  or  X  X ow old is human being? X  are not semantically identical to the query in spite of having similar topic distribution. This means that topic models may not be capturing the relevant semantic content of the query entirely. To rectify this problem we need to employ a model which takes deeper semantic similarity into account. This leads us to develop DSTM. DSSM [ 3 ] and CDSSM [ 6 ] are the deep neural networks that map raw textual features into vectors in semantic space. [ 3 ] have shown that these models work with click-through data consisting of query and set of clicked documents. It is interesting to note that the input to these networks is not high dimensional term vectors of documents. Instead, word hashing involving letter n-gram is used to reduce the dimensionality of term vectors. For a word, say,  X  X ook X  represented as (#book#) where # is the delimiter used, letter 3-grams would be #bo, boo, ook, ok#. Since the size of training data used is in millions, representing every word with one hot vector would be practically infeasible. Word hashing allows us to represent a query or a document using a lower dimensional vector (dimension equal to number of unique letter trigrams obtained in the corpus). It also takes care of out-of-vocabulary words and words with spelling errors.
 DSSM uses multiple hidden layers to project the word-hashed features into the semantic space. The semantic relatedness between query and document is scored on the basis of cosine similarity between them. DSSM proposes a super-vised training method to learn the weight matrices and the bias vectors of the deep neural network (DNN). The objective of DSSM is to maximize the condi-tional likelihood of the clicked documents given the queries or to minimize the loss function in Eq. 2 .
 where  X  denotes the set of parameters of the DNN, Q is the query, D set of documents clicked for query Q and P ( D + | Q ) is the posterior probability of a clicked document given a query from the semantic relevance score between them using a softmax function.
 CDSSM [ 6 ] introduces a convolutional layer in addition to DSSM. The advan-tage of CDSSM is that it considers words at a contextual level and projects each word within a context to a local contextual feature vector. Further, CDSSM uses a max pooling layer to extract the crucial local features to form a fixed-length global feature vector. Affine transformations and element-wise non-linear functions is then applied to the global feature vectors to extract highly non-linear and effective features. Both DSSM and CDSSM captures the non-linear semantic structures between a query and a document. These models significantly outperformed the existing Web retrieval models. Inspired by the success of DSSM and CDSSM in the fields of web retrieval, we propose DSTM or Deep Structured Topic Model which aims to capture non linear semantic relatedness and topic information between questions in cQA forums. The system architecture is showed in Fig. 2 .
 question and its best answer) in our dataset. Each question Q is represented with a topic vector of the question-best answer pair ( Q -BA ) obtained using LDA. The question Q in the document d has a topic space representation: [ t t , ... , t K ] where t j  X  [0,1] is the indicator variable denoting whether the topic t is assigned to document or not, j = { 1,2, ... ,K } and K is the total number of topics. Given a query q we find its n nearest neighbors in the topic space using cosine similarity. The candidate set is C = { r 1 , r is a relevant candidate question retrieved. Set S is the set of pairs of queried question and the retrieved candidates r i present in C .
 As explained earlier, questions with same topic distribution may not be seman-tically similar thus we employ DNN to capture non linear semantic relations between them.
 DNN. It maps the word hashed vectors to their corresponding semantic concept vectors. For testing, the term vector of retrieved question r both the question and its answer (best answer and most voted answers) pair. The similarity between the query q and a candidate question r using cosine similarity of their corresponding semantic concept vectors. Let x be the word hashed input term vector, y is the output vector and h is the number of hidden layers used. Let, H j represents the j whose weight matrix is W j and bias term is b j , where j = The relevance score between query and candidate questions is: The training of neural network is explained in the next section. After the training is complete the questions pairs in S are fed to the network. We select the questions with the highest relevance scores with the query. For a query we output those questions that are semantically similar in the topic space. The testing phase of deep neural network in DSTM is shown in Fig. 3 .
 For Convolutional Deep Structured Topic Model (CDSTM) we use a convo-lutional layer that captures local context of word within a sliding window. Every word of a document is represented by a count vector of its letter-trigrams. The word hashed vectors of the words in a window are concatenated to form a context window vector. Global feature vector of each query or document is obtained by max pooling which retains only the important features from each context win-dow. Non linear projections of global feature gives the semantic vector. The remaining operations are the same as in DSTM.
 5.1 Training the Network Large-scale standard dataset of similar questions is not available. Therefore, we cannot train the network to maximize the conditional likelihood of a similar question given the question. However, richer information is available to us in cQA data in terms of questions, associated answers and metadata associated with them. We train the network for a question while looking for semantic similarity with their best answers. We train our deep neural network with the questions and their answer pairs (we consider only best answer and most voted answers as valid answers to the question). We learn the parameters of our network W b to maximize the conditional likelihood of the corresponding answers given the question. The posterior probability of the answer given the question is: where  X  is the smoothing factor of the softmax function, A is the set of user-given answers to question Q .
 the answers are human generated there is a lot of noise involved with them. For example, a query  X  X hats the best way to delete a computer virus? X  (in Yahoo! Answers ) has answers like  X  X etup your computer. X ,  X  X hrow it out your window. X ,  X  X hrow the computer in the garbage and buy a new one. X  etc. These answers are irrelevant and do not give any valid solution to the problem. So, in order to filter out noise and redundancy, we approximate A using A contains the best answer and the most voted answers for a query Q and A which contains any five answers from a random question other than Q . Finally, the problem boils down to the minimization of the loss function in Eq. 9 . We collected Yahoo! Answers dataset from Yahoo! Labs Webscope . It has about 5 million questions where each question contains title, description, best answer, most voted answers and meta-data like categories, sub categories etc. The ques-tions in this dataset are distributed across a number of categories. Each question was pre-processed by lower-casing, stemming, stopword and special character removal.
 dataset as our test set. In order to obtain the true labels for the test set, we split the test set into 10 batches containing 100 questions each. For each question in a batch, we retrieved the top 20 similar questions as options using BM25 ranking algorithm in Lucene scoring function. Each batch of questions was distributed to three different human judges. Each judge was asked to vote for the most relevant question expressing the same intent from the provided options. Since each batch was distributed to three different annotators, majority of their votes was taken to judge relevance of a question given a query.
 On this gold data, we evaluate the performance of all the models using four evaluation criteria: Mean Average Precision (MAP), Mean Reciprocal Rank (MRR), R-Precision (R-Prec) and Precision at K (P@K). 6.1 Results In this section, a comparative study of the previous methods is done with respect to our method. The baseline methods considered are query likelihood language model (LM) and BM25. To show how translation based methods per-form we implemented the papers [ 4 , 7 , 9 ]. [ 4 ] deals with word based translation, [ 7 ] enhanced the first by adding language model to it and [ 9 ] implements phrase based translation method. As seen in Table 2 , the translation based methods out-perform the baseline significantly. The models are trained using GIZA++ tool with the question and best answer pair as the parallel corpus. We also imple-mented the papers using unsupervised and supervised topic modeling approaches presented in [ 5 , 8 ] respectively. The topic-based models form the current state-of-the-art. Again it is visible from the Table 2 topic based approaches shows comparable performance with translation based methods but they show signifi-cant improvement over baseline. We have used Sent2Vec to evaluate the results shown by DSSM and CDSSM [ 3 , 6 ]. These models outperforms the traditional methods but DSTM and CDSTM outperforms them. This proves that latent topic information enhances the deep semantic models in [ 3 , 6 ].
 We also evaluated DSTM and CDSTM models in the dataset released by [ 8 ]. The comparison of performance are shown in Table 3 . The better performance of DSTM and CDSTM on this new dataset proves their stability. Our method which combines topic modeling and deep semantic pruning outperforms the other approaches significantly. The improvement could be attributed to two factors -(1) We assume that semantically similar questions may not have similar topic distribution and (2) We model the non-linear semantic dependencies between the question and best answer pair and utilize it to output the most relevant similar questions given a query. 6.2 Qualitative Analysis In Table 1 , examples are shown to depict performance of supervised topic based method and DSTM. In Q1, the questions that DSTM outputs are semantically much closer, for example  X  X ow our society has evolved? X  or  X  X oes history of human evolution begin from two persons? X . These are very relevant to the per-son who wants to know  X  X ow the human species evolved? X . In Q2, the query is about the best way to boot a Windows CD. The questions retrieved by both the models are related to  X  X omputers X ,  X  X ooting X  etc. but DSTM really under-stands that the question is about making a  X  X indows X  CD bootable. DSTM is able to capture that Win98se, WinXP, WinProfessional are related to Windows. In Q3, the user want suggestions for buying a new bike, the supervised topic model retrieves question that deals with a bike in general i.e., queries dealing with maintenance and website of new bikes are retrieved. DSTM model output questions that are exclusive about buying a new bike, also it is interesting to note that it can capture that  X  X wo seater X  and bike are semantically similar. than DSTM. Both the models understand that the query is about making movies but most of the questions retrieved by topic model are more aligned towards how movies can be made in the least expensive way (using camrecorder, casting friends, making college life movie etc.) than DSTM. In this paper, we proposed a novel approach called  X  X eep Structured Topic Model (DSTM) X  to bridge the lexico-syntactic gap between the question posed by the user and forum questions. DSTM employs a two-step process consist-ing of initially retrieving similar questions that lie in the vicinity of the query and latent topic vector space and then re-ranking them using a deep layered semantic model. We showed that questions with same topic distribution may not be semantically identical and hence deep semantic models help in enhancing the performance of topic models. We evaluated our approach using large scale datasets from real-world cQA forums and showed that DSTM and CDSTM per-forms better than other state-of-the-art baseline approaches. Qualitative analysis of our results reveals that DSTM is indeed able to leverage the advantages of both topic modeling approaches such as LDA and also deep semantic models such as CDSSM. As part of future work, we would like to combine the metadata information and the topic vector representation of the questions to train DSTM and CDSTM to find out if metadata can enhance our existing models.

