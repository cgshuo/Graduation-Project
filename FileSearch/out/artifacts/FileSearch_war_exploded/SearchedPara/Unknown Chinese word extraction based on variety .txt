 1. Introduction
Unlike English, some languages, such as Chinese, do not have delimiters (e.g. blank space) to separate the words in sen-tences. Extracting words from a sentence in such a language is not a straightforward task. In this paper, we focus on Chinese texts. In modern Chinese texts, delimiters are only used to separate sentences. When a Chinese sentence is read by a native
Chinese, the meaningful words in the sentence can be recognized in context. However, when processed with a machine, the words of the sentence have to be extracted with a word segmentation process. Typically, Chinese word segmentation relies on a dictionary that contains commonly used Chinese words. If the Chinese text to be processed contains a lot of words which are excluded in the general dictionaries, the text cannot be segmented properly, which will significantly affect the subsequent processing operations, such as full-text searching, document clustering and classification, information filtering  X  and text summarization. This often occurs in specific domains that the text uses many words that are specific to the domains. One approach to remedy this problem is to use a list of domain specific words as an extension to the dictionary ( Ando &amp; Lee, 2003 ). However, dictionaries for domain specific words may not be always available, and it is costly and time-consuming to compile a list of domain specific words manually. Therefore, methods for automatically extracting unknown Chinese words from text corpora were developed (e.g., Chen &amp; Ma, 2002; Hong, Chen, &amp; Chiu, 2009; Peng, Feng, &amp; McCallum, 2004 ).
Typically, extraction of unknown Chinese word can be conducted in two steps: word extraction and word refinement. The word extraction step extracts all possible strings from the sentences of a given corpus and uses goodness measures to eval-uate these strings in order to identify the meaningful and representative words in the text collection. Automatic word extrac-tion is still a fundamental and critical problem in Chinese and oriental language processing. Without efficient word extraction, advanced word refinement cannot obtain satisfactory achievements. The word refinement step filters out the known words or phrases which are included in general dictionaries. Unknown keywords will then be reported. In this paper, we focus on the word extraction step. There are two main types of methods for word extraction: supervised approaches and unsupervised approaches. Supervised approaches rely very much on a pre-segmented corpus as a training data set. Unfor-tunately, such a domain-specific pre-segmented training set may not be always available. On the other hand, unsupervised approaches often use statistics-based metrics, such as mutual-information based estimation, as goodness measures to eval-uate the likelihood of a word candidate being a meaningful word. Such goodness measures assign an association score (or goodness score) to each word candidate, with high scores indicating strong attraction and low scores indicating weak attrac-tion (or even repulsion) being a meaningful word. Association scores can then be used to select  X  X  X rue words X  X  by rank the set of word candidates according to the strength of their association scores, so that  X  X  X trong X  X  words are found at the top of the list. A threshold is then specified, and the word candidates that exceed the threshold value are accepted as  X  X  X rue words X  X . We note that different goodness measures may lead to entirely different rankings of the word list. Popular goodness measures (2008a) for an empirical comparison of these measures.

Association scores as a quantitative measure of the word goodness play a crucial role in empirical finding an acceptance words set (or  X  X  X rue words X  X  set) in word extraction. For a given goodness measure, all word candidates are first ranked according to their scores. A threshold value is then specified, and the word candidates whose scores exceed the threshold value are accepted as  X  X  X rue words X  X . Another strategy is to accept the first n words from the ranked list. We note that the will accept less words but can deliver better precision performance, whilst smaller threshold (or larger n ) setting will accept more words and results in better recall performance. The choice of an appropriate threshold value (or n ) is determined in terms of the practical requirement of an application, as well as compromise between precision and recall.

The most challenging issue for word extraction is to identify low-frequency words. In general, any character n -grams ( n P 2) that co-occur at least twice (i.e., word frequency f P 2) in a corpus would be considered as a word candidate. It is not uncommon to find more than a million word candidates in a corpus, but only a small proportion of them will pass a fre-quency threshold of f P 10 or higher. Indeed, current classical goodness measures are based on observed co-occurrence fre-quency to evaluate word candidates. The top collocates according to these frequency-based measures are usually dominated by high-frequency occurrences with very common words. By contrast, these measures are not effective in distinguishing low-frequency meaningful words from meaningless words.

In this paper, we propose a new goodness measure, the overlap variety (OV), for unsupervised word extraction. Our new measure is not to consider the absolute number of occurrences of the word candidate, but to compare the goodness measures (we use the accessor variety, i.e. AV) of the candidate and those of the string overlapping the candidate. In other words, the likelihood of a word candidate (i.e., a string of Chinese characters) being a meaningful Chinese word is evaluated by consid-ering the AV of the candidate together with the AV of the strings overlapping the candidate. The candidate is likely meaningful overlapping candidates are unlikely to be meaningful. We note that our new measure does not rely on the absolute number of occurrences of the candidate, but the relative number of occurrences of the candidate and its overlapping strings. Thus, it is more effective for identifying low-frequency words. Based on our proposed measure, we have implemented an extraction sys-tem for unknown Chinese words, called UNExtract. Evaluation of our system on the CIPS-SIGHAN-2010 bake off corpora shows that the proposed OV method is able to deliver better performance than classical word extraction methods.
The rest of this paper is organized as follows. In Section 2 , we review classical goodness measures. In Section 3 , we illus-trate the issue of using classical goodness measures for separating meaningful and meaningless words. In Section 4 , we intro-duce our new goodness measure, overlap variety , and present UNExtract, the word extraction system for unknown Chinese words. In Section 5 , we discuss the experimental results. Section 6 concludes the paper. 2. Related work
In this section, we describe five classical goodness measures whose basic idea is to consider the absolute number of occur-rences of the word candidates, thereby cannot handling low-frequency words effectively. We also give some information about the data set used in the study. 2.1. Accessor Variety (AV)
Feng, Chen, Deng, et al. (2004) and Feng, Chen, Kit, et al. (2004) proposed the goodness measure, accessor variety , as fol-lows. The idea behind this measure is that if the candidate w is a meaningful word, then it should appear in many different environment. For all occurrences of the candidate, we consider the character just preceding the candidate for each occur-rence. Denote the number of such distinct characters as L a v ( w ). Similarly, for all occurrences of the candidate, we consider the character just follow the candidate in each occurrence. Denote the number of such distinct characters as R a v ( w ). Roughly speaking, these two values represent the number of different situations that this candidate can be used. Thus, the assessor variety of w is defined as g AV ( w ) = logAV( w ) where AV( w ) = min{ L a v ( w ), R a v ( w )}. 2.2. Pointwise Mutual Information (MI) MI is one commonly used approach to measure how two patterns consistently occur together in a corpus Chien (1999),
Church and Hanks (1990), and Sproat and Shih (1990) . Typically, it is derived from the log-likelihood ratio of the joint prob-
We are interested in deciding whether the MI exceeds a certain threshold, such as MI w P MI threshold . Then we can simplify the calculation without involving the log function as follows: MI w  X  f w F f that two patterns are independent, and MI w 0 indicates that the patterns frequently appear. 2.3. Branch Entropy (BE) Another popular unsupervised goodness measure is the branch entropy or contextual entropy ( Huang &amp; Powers, 2003; Jin &amp;
Tanaka-Ishii, 2006; Tung &amp; Lee, 1994 ). The idea is similar to accessor variety. For each occurrence of the candidate w ,we consider the preceding character x and the co-occurrence probability of x and w , denoted by p ( x j w ). They sum the entropy w in each occurrence. The branch entropy is defined as g BE ( w ) = min{ h L ( w ), h R ( w )}. 2.4. Description Length Gain (DLG)
This goodness measure is based on the minimum description length paradigm ( Kit &amp; Wilks, 1999 ). Given a text X , the value of the description length function L ( X ) is usually calculated by the Shannon X  X ano code or Huffman code. It is expected that if w is a meaningful word, by replacing w with a new symbol r in the whole text, denoted as X [ r ? w ], the difference 2.5. Frequency of Substring with Reduction (FSR)
Lu and Hu (2004) proposed a linear statistical substring reduction algorithm to produce a list of character n -gram strings for a given corpus, and then evaluate the character n -grams X  X  goodness according to their substrings. If two overlapped char-acter n -grams have the same frequency, then the shorter one is discarded as a redundant word candidate. The frequency of strings having the same frequency.

In the context of this paper, we will not attempt a more profound survey of the related task of word extraction. For this we refer the interested reader to Evert (2005) and Zhao and Kit (2008c) with comprehensive study of association measures for word extraction. From the above definitions of five statistical goodness measures, it seems that these measures may not work if the number of occurrences of the candidate is not large enough, thus may not work very well for low-frequency words. We conducted an empirical study to illustrate this problem (see Section 3 ).

To evaluate our approach and compare our measure with other classical measures, we use the following benchmark cor-pus. The bake off of Chinese word segmentation jointly organized by CIPS and SIGHAN (CIPS-SIGHAN-2010) 1 provides two types of Chinese text corpora: simplified Chinese corpus and traditional Chinese corpus as benchmark corpora. Each corpus has been hand-segmented into words. For unsupervised word extraction task, the word boundary annotations are not used in the learning process, but can be used to generate the correct meaningful word set for performance evaluation.
There are some other recent works for solving the word extraction and word segmentation problems. Regarding word segmentation, conventional approaches are to treat the problem as a sequential labeling task ( Peng et al., 2004; Zhao, Huang, Li, &amp; Lu, 2010 ). Most of the state-of-the-art systems model the problem using semi-Markov assumptions or latent variables ( Sun, Morency, Okanohara, &amp; Tsujii, 2008; Sun &amp; Tsujii, 2009 ). Some other approaches consider developing fast implemen-tations for semi-Markov conditional random fields or latent variable conditional random fields ( Sun, 2010 ). Regarding word extraction, many statistical approaches have been proposed. Sun, Wang, and Li (2012) presented a joint model for Chinese word segmentation and new word detection for very fast online training of large-scale datasets with high dimensional fea-tures. Wu and Jiang (2000) presented a mechanism of new word identification in Chinese text. This mechanism avoids the sparse data problem of pure statistical approaches and the over-generation problem of rule-based approaches. Cholakov and van Noord (2009, 2010) developed methods to analyze the paradigm of unknown words using syntactic grammar parser and linguistic knowledge which require some domain knowledge. Wu, Hsieh, Lin, Liu, and Yu (2011) developed methods for un-known word extraction from multilingual code-switching sentences. Xu, Wang, Tang, and Wang (2008) introduced a super-vised method to improve the effect of unknown word recognition by using Conditional Random Fields. But the main difficulty is to prepare the training corpus. Zhao and Kit (2008b, 2008c) attempted to integrate supervised and unsupervised techniques for Chinese word segmentation and named entity recognition. Pang, Fan, Gu, and Yu (2009) proposed an unsu-pervised method using the distribution characteristics of inter-domain and intra-domain of high-frequency strings to recog-nize new words, and the method can only produce high-frequency unknown keywords. 3. Performance of classical goodness measures
This section concentrates on experimental studies to evaluate the performances of classical word extraction methods. Be-fore presenting the results of our experiments, we give some information about the meaningful and meaningless word set used in the study, as well as the criteria used for evaluation. This experiment aims at investigating the effectiveness of clas-sical goodness measures to distinguish meaningful words from meaningless words, in particular for low-frequency words.
In our empirical study, we analyze the distributions of the associate scores of classical goodness measures for meaningful character n -grams and meaningless character n -grams constructed from the CIPS-SIGHAN-2010 corpora to illustrate the issue of classical methods. Regarding the meaningful character n -grams is a list of correct segmented words in the CIPS-SIGHAN-2010 corpora. Regarding the meaningless character n -grams, we generate incorrect word boundaries into the corpus. This enables us to identify a list of meaningless words. Concretely, between two consecutive correct word boundaries, we generate a incorrect boundary. All combinations of words between two consecutive incorrect boundaries are used as meaningless words. It is possible that by chance, some of these words are meaningful. We use a common word dictionary to further filter away those meaningful words. Note that there will be more meaningless words than meaningful words. In total, the number of meaningful character n -grams and meaningless character n -grams in the simplified corpus are 47,749 and 124,277 respectively, and the number of meaningful character n -grams and meaningless character n -grams in the traditional corpus are 56,093 and 168,835 respectively.

We calculate the goodness associated with different goodness measures for all character n -grams in the corpus, and nor-malize their goodness in the range of [0,1]. Now the task is to explore the effectiveness of the goodness generated by differ-ent measures in distinguishing meaningful character n -grams from meaningless character n -grams.

We first take a look at the distribution of character n -grams in the corpus. Fig. 1 a and b shows the percentage of character n -grams in terms of their frequency and character number, respectively. We can observe that the percentage of character n -grams decreases as their frequency and number of characters increases. This result indicates that there are a large portion of character n -grams, which are low-frequency or two character bi-grams.

We now experiment to find out how the character n -grams X  frequency affects the performance of classical goodness measures. Fig. 2 a and b shows the variations of the word candidates X  rankings produced by AV and MI, respectively, with different frequency values. We first observe that different goodness measures, i.e. AV and MI, produce entirely different rankings of the word candidates. Roughly speaking, the ranking according to the AV measure is be positively correlated with frequency; most of the top word candidates are high-frequency n -grams. In contrast, the ranking according to the MI measure is negatively correlated with frequency; the top word candidates are mainly dominated by low-frequency n -grams.

The meaningful and meaningless words are shown in Fig. 2 a and b using different symbols ( X   X  indicates meaningful word and  X  X  X  indicates meaningless word). It is noted that a good goodness measure should favor to separate meaningful words from meaningless words, and to assign high scores to meaningful words. Indeed, both of these two measures are sensitive to frequency. Their performances are not satisfactory, especially for low-frequency events. The AV measure is often prone to a high-frequency bias, whilst the MI measure is often prone to a low-frequency bias. One way that this behavior can be ana-lyzed is by looking at their performance in extreme cases. Regarding the AV measure, the goodness evaluation relies on the number of its adjacent characters. When a word candidate occurs repeatedly in different sentences, it tends to have different adjacent characters in Chinese language. Therefore, high-frequency word candidates will have large AV scores. Regarding the MI measure, the goodness evaluation relies on its substring components. When its two longest substrings ( w left and w right ) word candidate to be a perfectly correlated word is higher when its two longest substrings are less frequent. This means that low-frequency events tend to receive high MI scores.

A close inspection of the results in Fig. 2 a and b, we can find that meaningful words and meaningless words are mixed together. It is impossible to choose a appropriate threshold to well-separate meaningful words and meaningless words. This can observe that the distributions of meaningful words and meaningless words X  goodness scores are quite similar and over-lapped. Here, we only choose the AV and MI measure to illustrate the problem. The same situation is also observed on other classical goodness measures, such as BE, DLG and FSR. Due to page limitation, we omit the figures of these results here.
In order to gain a better understanding of the impact of word frequency on the performance of classical goodness mea-sures, we further classify the character n -grams into high-frequency (with occurrences at least 10) 2 words and low-frequency (with occurrences less than 10) words. The distribution of these low/high frequency words are shown in Fig. 4 a and b, respectively. We can see that the problem is mainly due to low-frequency words. There are 38,780 and 87,505 meaningful low-frequency words and meaningless low-frequency words, respectively. From Fig. 4 a, we can easily see that the distributions to distinguish the meaningful and meaningless character n -grams. On the other hand, Fig. 4 b shows the case for high-frequency character n -grams. The situation is better. It indicates that the scores are useful for the identification of meaningful words goodness measure leads to a considerable improvement on high-frequency words, suggesting that the poor performance of clas-sical goodness measure may, indeed, be mainly affected by low-frequency words.
 We conducted the same experiment on the other three goodness measures (BE, DLG, and FSR) and also on the traditional Chinese text of CIPS-SIGHAN-2010 corpora. They all exhibit that the classical methods are not effective for word extraction, especially for low-frequency words. Due to page limitation, we omit the figures of these results here. 4. Chinese word extraction based on variety of overlapping strings
In this section, we first describe our proposed goodness measure, the overlap variety (OV), then we will present the Chi-nese word extraction system for unknown words, UNEXTRACT, based on this measure. 4.1. The overlap variety
The overlap variety measures the likelihood of an character n -gram (as word candidate) being a meaningful Chinese word by considering the goodness of the candidate together with the goodness of the strings overlapping the candidate. The ratio-nale behind is that if the word candidate is a meaningful word, its overlapping strings are unlikely to be meaningful, thus we compare the likelihood of the candidate with those of its overlapping strings instead of considering the absolute likelihood of the candidate. The word candidates X  association scores produced by our measure are less sensitive to word frequency rela-tive to classical goodness measures. It is note that OV do not rely on the absolute frequency of the word candidate, but the relative frequency of the word candidate and its overlapping substrings.

Given a word candidate s of n characters in the (Chinese) text, the overlapping strings are the preceding strings and the lapping strings for any s .

The number of overlapping characters of the overlapping string with the string s is defined as the overlapping level. For a n character string, there are N =( n 1) overlapping levels. For instance, Fig. 5 shows the overlapping strings of a four-is higher, it is more likely that the overlapping string is meaningless when the word candidate is meaningful, thus we give a higher weight to overlapping strings with higher overlapping level.

In a text, a string s may occur in multiple sentences, the overlapping strings of s in different sentences can be different. We consider all possible overlapping strings. To measure the likelihood of a string, we simply use the Accessor Variety (AV) mea-define the overlap variety of a string s with respect to overlapping level i as follows: where u ( s , o ij ) is an indicative function showing whether AV( s ) &gt; AV( o ij ), defined as follows: variety for N overlapping levels, as follows: where w i is the weight of the overlapping strings at level i , we simply set it as w i  X  1 j s jj s \ o level the higher the weight value is, and the OV scores are in the range of [0,1]. We further discuss how to choose the param-eter in Section 5 . 4.2. A preliminary empirical study for overlap variety
Our proposed OV method evaluates the goodness of a word candidate on the basis of its overlapping strings. The rational behind OV is that if the word candidate is a meaningful word, its overlapping strings are unlikely to be meaningful. Here, we provide an empirical study to address following questions: whether the intuition of the proposed method is  X  X  X rue X  X ; how well OV function captures the difference in behaviors between word candidates and their overlapping strings; whether the association scores produced by OV has a frequency bias: for example, does OV suffer from a sensitivity to low-frequency or high-frequency words.

In our empirical study, we use the meaningful character n -grams and meaningless character n -grams of the simplified corpus from the CIPS-SIGHAN-2010 corpora, as used above in Section 3 .

We experiment to investigate whether the meaningful words X  overlapping strings are meaningful or not. Concretely, gi-ven a meaningful word w taken from the meaningful word set W , and an overlapping string o taken from the overlapping string set O derived from w , we examine a binary membership b w ( o ) that takes the value of 1 if o is meaningful and 0 other-wise. Formally, it can be defined as follows: where W is a meaningful word set taken from CIPS-SIGHAN-2010 corpora, and D is a meaningful word set including 268,100 terms taken from a general-domain lexicon.
 Based on the above definition, we are able to count the number of meaningful overlapping strings in the corpus, i.e. P the results that, in the last column, most of the overlapping strings of meaningful words are meaningless. This result sup-ports our intuition well. We perform similar experiments on low frequency ( f 6 10) meaningful words and their overlapping strings. The result is given in Table 2 . We can observe similar empirical results, which indicate that the intuition behind the proposed method is still applicable on low frequency words.

We use AV as base goodness measure in our proposed approach, thus it is instructive to investigate the effects of asso-ciation scores produced by AV measure for the character n -grams and their overlapping strings. To this end, we plotted the points for the meaningful words fall below the diagonal, i.e., the meaningful words X  AV scores are larger than their overlap-acter n -grams X  AV scores are similar to their overlapping strings X  AV scores. In summary, experimental results have demonstrated that the intuition behind the proposed method is true, and the proposed method using AV as base measure can effectively distinguish meaningful and meaningless words.
 As discussed in Section 3 , classical goodness measures, i.e. AV and MI, have explicit high-frequency or low-frequency bias. We are seeking for a more robust measure that without frequency bias. Thus, we further show the distributions of word can-didates X  rankings produced by OV measure against the word frequency in Fig. 7 . It is encouraging to observe that the plots in Fig. 7 are more evenly spreading out compared to those in Fig. 3 . This reveals that word frequency has a small impact on the association scores produced by the proposed OV measure. A close inspection of the plots of meaningful words and the plots of meaningless words shows in Fig. 7 shows that the OV measure is able to deliver superior performance in distinguishing meaningful words and meaningless words compared with those of AV and MI in Fig. 3 . We can flexibly provide an approx-imation for a threshold (as the solid line showed in Fig. 7 ) to separate the word space into meaningful word region and meaningless word region. The plots in the left region are the high ranked word candidates in the ranking list according to
OV. We can see that most of them are  X  X  X rue X  X  meaningful words. In addition, we see that the points deviate far from the diag-onal, revealing that OV assigns high ranks to both low-frequency meaningful words and high-frequency meaningful words.
In summary, we can see that the proposed OV measure is effective to distinguish meaningful words and meaningless words, and it is less biased towards high frequency words or low frequency words. 4.3. The UNExtract system
The architecture of the UNExtract system we implemented is shown in Fig. 8 . The system contains two major modules, the word extraction module that is highlighted in box (A), and the word refinement module highlighted in box (B). Given an unsegmented Chinese text corpus as input, the UWExtract system produces a list of predicted unknown words.
Following the sentence delimiters, the text is converted to a list of sentences. In these sentences, every possible string of two or more characters is taken as a word candidate that needs to be evaluated. In the UNExtract system, the list of all pos-sible strings is called the word candidate list. Each candidate, together with its overlapping strings, is submitted to the word extraction module for evaluation. In the word extraction module, we use our goodness measure, overlap variety , to evaluate each word candidate and determine whether it is a meaningful word or not. If it is a meaningful word, it is put in the ex-tracted word list. Otherwise, it is discarded. After the extracted word list is created in the word extraction module, it is submitted to the word refinement module. This module uses common dictionaries to filter out the common words in the extracted word list. It also uses other classical lists of words, either domain independent or specific, to filter out the words that are known. The remaining extracted words are put in the list of unknown words as the output of the module.

Since the goodness measure cannot guarantee that all extracted words are meaningful words, the list of unknown words is finally edited by humans to further delete the words that are not meaningful. The edited list of words can be used as new words to update the dictionary. Combined with a web crawling system to collect new corpora, we can use this system to continuously discover new words. 5. Experimental results
In this section, we first show experimental results of the proposed OV method on the CIPS-SIGHAN-2010 corpora, using the meaningful and meaningless character n -grams described above in Section 3 for evaluation. We also compare the per-formance of OV with classical methods, such as AV, BE DLG, FSR and MI, using the F-Measure criteria. In the experiments, we mainly show the results of simplified Chinese corpus. The results for traditional Chinese corpus are similar. 5.1. Performance of OV measure
First, we show the distributions of the scores of our measures on meaningful character n -grams and meaningless char-acter n -grams. The result is given in Fig. 9 . Compared to the performance of AV and MI as shown in Fig. 3 , our proposed OV measure is able to deliver a better distinguishing power. As in Section 3 , we separate the character n -grams into high-frequency words and low-frequency words. Fig. 10 shows that our measure can distinguish meaningful and meaning-less character n -grams regardless the word frequency. For low-frequency character n -grams, although our measure still can-not do a perfect job, it is much better than classical measures (e.g. compared to Fig. 3 for the AV measure).
For low-frequency character n -grams, we have done a deeper analysis and found that to distinguish bi-grams (words with two characters) is more difficult. Intuitively, this is true since it is easier for a meaningless bi-gram to appear quite a few times by random than a multi-gram (words with more than two characters). Fig. 11 shows the distributions for the case of bi-grams and multi-grams. It can be seen that for multi-grams, we can easily distinguish about 50% of mean-ingful words from those meaningless ones (e.g. by setting the threshold around 0.7). For bi-grams, with a similar thresh-old, we can only separate out about 30% meaningful words. Further research should be conducted in order to improve the results.

For the classical measures, all of them perform badly on both bi-grams and multi-grams for low-frequency character n -grams. Fig. 12 shows an example for AV measure. For other classical measures and traditional Chinese text, the results are similar. Fig. 13 shows an overall picture on the distribution (the minimum, 1st quartile, median, 3rd quartile, and the max-imum) of all scores on meaningful and meaningless character n -grams based on the simplified corpus. It is clear that the OV scores can deliver a better distinguishing power than all other scores. 5.2. Comparison experiments in terms of F-Measure
To further evaluate and compare the performance of our measure with other classical measures, we use the following metrics: precision, recall and F-Measure defined as follows. Given a correct meaningful word list W and an extracted word
In order to obtain the extracted word list W 0 , we first rank all word candidates according to their goodness scores. The first cept less words and can obtain better precision performance, whilst setting n to a larger value will accept more words and result in better recall performance. Here N is the total number of character n -grams with positive scores. We note that for different goodness measures, the number of character n -grams with positive scores is different. In the experiment, we only consider the character n -grams with positive scores as character n -grams, because candidates with negative scores are nat-urally considered as meaningless words. Our measure is able to yield more correct character n -grams with positive scores (we reported 3.5 10 5 character n -grams with positive scores, while the other measures are only about 2.5 10 5 positive scored character n -grams).

We experiment to find out how would different value of the parameter n affect the extracting performance. Fig. 14 shows how the extracting performance of compared methods varies with different n settings (for n = 100 up to the maximum num-ber of positive character n -grams reported by the measures). For each n setting, the results of each goodness measure with respects to precision, recall and F-Measure metrics are reported. It is obvious that our measure performs better than all other beginning, in particular for the OV score. Because most of the character n -grams should be correct as they have high scores. Regarding the results for the precision metric (see Fig. 14 b), we can see that the precision drops as n increases. Because there are more false positives are included when there are more words extracted. The precision of our measure (OV) decreases quite a lot when the number of character n -grams increases from about 0.2 10 5 to 0.5 10 5 and asymptotically becomes similar to the other measures (although still a little bit better). This indicates that the first 0.2 10 5 character n -grams reported by our measure should be very likely to be meaningful and the accuracy decreases if we consider more words (although still better than other measure). The F-Measure, as shown in Fig. 14 c, confirms the above observation that our method provides a list of excellent results for the first 0.2 10 5 character n -grams, thus there is a sharp increase in F-Measure in this part of the curve. Then the value of F-Measure drops as we further increase the number of character n -grams to be considered.

Here we discuss how to choose a default value for the threshold. A supervised strategy to learn an appropriate threshold value n relies on the use of a pre-segmented corpus as a training set, where meaningful words and meaningless words are setting of n , because such a training data set is usually unavailable. For a fair comparison, we follow the same strategy with respect to thresholding the word list in our experiment Feng, Chen, Deng, et al. (2004) and Zhao and Kit (2008a) . From the experimental results given in Fig. 14 , we can observe that the choice of threshold n essentially depends on the compromise between the precision and recall metric. In general, as the threshold n increases, the precision increases but the recall drops, while the F-Measure monotonically increases followed by monotonically decreasing. Indeed, this result makes sense: with a small n , only few words are extracted such that many of the meaningful words are missed; this leads to poor recall perfor-mance. On the other extreme, with a high value of n , most of words are extracted. Meaningful words and meaningless words cannot be distinguished. For a medium number of n , our proposed OV method can capture the meaningful words and avoid including many meaningless words.

In order to give a better indication of the reliability of the results, we further investigate the best results of each compared method when optimal threshold value is used. The results are shown in the subsidiary figure embedded in Fig. 14 c. In gen-eral, the best F-Measure of our measure is still better than all other classical measures. If we only consider the low-frequency n -grams or even low-frequency bi-grams, the performance of our method is significantly better than the other methods. Fig. 15 shows the comparison result with respect to F-Measure. From the figure, we can see that the F-Measure of our ap-proach is substantially better than all other classical methods. In summary, this result shows the distinguishing power of our measure and indicates that the proposed method outperforms the existing methods in terms of F-Measure.

To conclude, our measure is able to deliver better performance than compared classical measures. One can see that the overall F-Measure is still low (less than 0.4). There still a lot of room for improvement. Further research should be conducted to derive new measures in order to produce promising performance for word extraction. 5.3. Discussion of parameter setting
We experiment to investigate how different settings of the parameter w i in Eq. (3) affect the OV performance. Fig. 16 shows how the F-Measure performance of OV varies with three different parameter settings: (a) w i  X  1 j s jj s \ o w = 1; (c) w i = j s \ o ij j &gt; 1. The results show that the default parameter setting w i  X  1 j s jj s \ o sight, the results of Fig. 16 makes sense: with w i = 1, the overlapping level information is missing. On the other hand, with a the resulting OV score may be out of the range [0,1]. We conclude that w i  X  1 j s jj s \ o maximum goodness score equal to 1. 6. Conclusions
In this paper, we have examined the issue of classical goodness measures methods on separating meaningful and mean-ingless words, and proposed overlap variety as a new goodness measure. We also implemented a word extraction system,
UNEXTRACT, for unknown Chinese words based on our proposed measure. We show that the new measure performs better than all classical measures, in particular for low-frequency bi-grams. We also admit that there is still a lot of room for improvement as the overall performance (F-Measure) of all measures are still low. For further research, we will try to come up with a better and more specific approach (e.g. character tagging technique ( Xue, 2003 )) for bi-grams as this seems to be the most difficult problem.
 Acknowledgements
We thank the editor and the reviewers for their very helpful comments which make the paper clearer. Y. Ye X  X  research is supported in part by NSFC under Grant No. 61073195 and Shenzhen Strategic Emerging Industries Program under Grant No. ZDSY20120613125016389. Y. Li X  X  research is supported in part by Guangdong Natural Science Foundation under Grant No. S2011040004684 and Shenzhen Polytechnic Foundation.
 References
