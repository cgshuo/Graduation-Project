 is: {Disabll:2, Langl:2, Means:l, Mobilili:2, Perscar:2, Rlabor: 1, 
Travtim:[1..59], Work89:l); the items are about disability, lan-guage at home, means of transport, personal care, employ-ment status, travel time to work, and working or not in 1989. 
Such EPs can describe differences of population characteris-tics between different social groups. Clearly, domain experts can analyze similar EPs, and select the useful ones for fur-ther attention in their applications. I 
Example 1.3 Suppose in 1985 there were 1000 purchases of {COMPUTER, MODEMS, EDU-SOFTWARES} out of 20 million transactions, and in 1986 there were 2100 such purchases out of 21 million transactions. This purchase pattern is an EP with a growth rate of 2 from 1985 to 1986. Observe that the support for this itemset is very small even in 1986. If companies understood the significance of such EPs and took the opportunities, then they would have benefited greatly in the long run. I 
We believe that EPs with low to medium support, such as l%-20%, can give very useful new insights and guidance to experts, in even  X  X ell understood X  applications. This is because, using traditional statistics and computation methods, scientists have been confined to discovering EPs with very few (e.g. one to four) variables, or confined to known EPs which are typically folklore and have very high supports; in other words, the applications have been well understood only about contrasts which are either strong folklore or small in number of items. Example 1.4 Consider an application about cancer patients, where one dataset contains records of patients who were cured and another dataset of patients who were not cured. 
A hypothetical useful EP {Sl , Sz, Tl, Tz, Ts}, with growth rate of 9 from the not-cured to cured, may say that, among all cancer patients who had both symptoms of S1 and 5 X 2 and who had received all treatments of TI, Tz, and 
T3, the number of cured patients is 9 times the number of patients who were not cured; this may suggest that the treatment combination should be applied whenever the symptom combination occurs (if there are no better plans). 
The EP may have low support, such as 1% only; such EPs may be new knowledge to the medical field because they did not have efficient methods to find EPs with such low support and such long length. This EP may even contradict the prevailing knowledge about the effect of each treatment 
Tj on each symptom Si . A selected set of such EPs can be a useful guide to doctors in deciding what treatment should be used for a given medical situation. I 1.1 Difficulties and challenges 
Since EPs with large supports are perhaps folklore already, an interesting problem is to discover EPs with small supports (e.g. 5% or even 0.1%). This is a challenge due to these two reasons: (i) the useful Apriori property no longer holds for EPs (as can be seen from Example 1.1); (ii) there are about 228 EPs for the growth rate threshold of 2.5; these are represented by about half a million borders.) 1.3 Related work and paper organization 
Although EPs are also similar to discriminant rules [lo] (assertions true on instances of a given class but untrue on other instances) and evolution rules [lo] in that they are all about different datasets/classes, EPs are different because they are not limited by the exclusiveness constraint and because the extra information of growth rate is attached. 
Because our EPs are not restricted by the exclusiveness constraints, the value-merge based induction method of [lo] is not applicable. We note that jumping EPs (cf. Section 5) are special types of discriminant rules. 
Our definition and ways of using borders are different from those used in most of previous investigations. Our borders are defined to represent interval closed collections by their boundary elements, whereas borders of [16] are limited to subset closed collections. The two bounds of our borders are subcollections of the given collections, consisting of respectively their minimal (maximal) elements; one bound of borders of [16], the negative border, consists however of minimal elements not in the original collections. 
To eliminate the need to examine too many candidates, we introduce and use novel algorithms such as border differential, whereas [16] uses borders directly to control level-wise search over the candidate space. Max-Miner [3] only uses one bound (the right-hand) of our large borders. 
We obtained all the results without knowing [8], which is concerned with efficiency issues of ATMS (assumption-based truth maintenance system). Interestingly, that paper contained some ideas similar to ours, including the repre-sentation of interval-closed collections (called convex space there) using borders (called boundaries there), and some op-erations for extracting the border of the difference of two collections from their borders. We have made several main new contributions to borders: (a) Regarding the algebra of borders, our backbone operation of border d@erential is new. However, for the difference operation [8] only dis-cussed how to find the maximal (respectively, minimal) el-ements of the difference of two subset-closed (respectively, superset-closed) collections from the maximal (respectively, minimal) elements of the two collections. It is interesting to see if our border-differential operation can be applied to 
ATMS X  X . (b) We have brought the use of (two sided) bor-ders to the field of data mining, and we hope that this tool will be used more widely in this field. We are really happy to see that our investigations and [8], from very different ar-eas, share the use of the tool of borders, which indicates that these tools are really powerful. 
Our work is also related to the mining of regularities in time series [9, 11, 18,2, 17, 14,4, 121. Our work is different in that we look for abnormal growth, instead of regularities. 
The rest of the paper is organized as follows: Section 2 formally defines the EP mining problem and gives a decom-long patterns are present. Now, the EP mining problem can be divided into three sub-problems. 1. Finding EPs in the BCDG rectangle. In this paper, we will concentrate our effort on this subproblem. From Figure 1, we see that the EPs in the BCDG rectangle are precisely those itemsets whose supports in 2?2 are 2 &amp;in but in VI are &lt; bnain. 
The basic ideas of our novel algorithms are as fol-lows: We use the borders of LARGE~~,JD~) and of LARGE@,,, (Dz), instead of using LARGEB,,, (D1) and LARGEB,~,(&amp;) themselves, as inputs to our algorithms. 
The algorithms derive the EPs by manipulating only the two given borders and produce the border representation of the from their avoiding handling exponentially many candidates and avoiding printing a large number of EPs. As a result, our algorithms are efficient, even for discovering long EPs which the naive algorithms and Apriori-like algorithms may fail to find. 
We now briefly describe a semi-naive algorithm and analyze why it is usually inefficient: It will try to first find the supports, in Dl and in 2)~. of all itemsets in 
LARGE@,,, (Dz), and check if their growth rates are greater than p. While this is smarter than the naive algorithm given earlier and it may be quite fast for  X  X mall X  applications, it is still too inefficient to be of use in  X  X arge and wide X  applications. Indeed, for reasonable &amp;in, LARGER,,,;,, can contain around 240 itemsets in the PUMS dataset. When the datasets are big, finding the counts of those large itemsets will also take too long. 2. Finding emerging patterns in AGDE. A candidate set of EPs in this region is the set of all itemsets whose candidates is exactly LARGE~,JD~) II LARGE~~,,,@~). 
When the intersection is relative small we can find the EPs by checking the supports of all candidates in the intersection. collections is s = w3, {2,3},{l,2,3},{1,2,4}, {2,3,41,w,3,4H. 
Proposition 3.1 The collection of all large itemsets w.r.t. any fixed threshold is interval closed. 
Borders are introduced for succinct representation of very large interval-closed collections. Definition 3.2 An ordered pair &lt;C, R&gt; is called a border, 
L the lef-hand bound of this border and R the right-hand bound, if (a) each of C and R is an antichain X  collection of sets, and (b) each element of C is a subset of some element in  X  X  and each element of R is a superset of some element in 
L. The collection of sets represented by, or the set interval of, a border &lt;,C,R&gt;, is [C, R] = {Y 1 3X E C, 32 E 
R such that X c Y c 2). The collection [C, R] is said to have &lt;L, R&gt; as border. 
Example3.3 Thesetintervalof&lt;{{1},{2,3}},{{1,2,3}, {2,3,4~~&gt;is~~l~,~1,2~~~1,3~~~1,2,3~,~2,3~,~2,3,4~~. 
Thesetintervalof&lt;{{1,2}},{{1,2,3,4,5},{1,2,4,5,6}}&gt; consists of 12 itemsets: all sets that are both supersets of {1,2} and subsets of either {1,2,3,4,5} or {1,2,4,5,6}. 
Many simple borders X  set intervals are very large collections; e.g. there are 211 itemsets in the set interval of &lt;{{l}}, {{1,2,3,4,5,6,7,8,9,10,11,12}}&gt;. I 
A border &lt;L, R&gt; is a syntactic object consisting of the two collections L and R, and its semantics is [L,R] consisting of the interval of sets bounded by the sets in L (72) from below (above). Conditions (a) and (b) in the definition ensure that borders are minimal in size. Observe that &lt;8,8&gt; collection. A set interval can be viewed as a generalization of intervals over linearly ordered domains (e.g. the reals) to partially ordered domains, especially the partially ordered domain of sets. 
There is a one-to-one correspondence between borders and interval-closed collections: 
Proposition 3.4 Each interval-closed collection S of sets has a unique border &lt;L,  X  X &gt;, where L is the collection of minimal sets in S and R is the collection of maximal sets in S. 
In this paper, we prefer the  X  X ooted X  borders, to non-rooted ones, for their conceptual simplicity. A border CL, R&gt; is called left-rooted if L is a singleton set, right-rooted if R is a singleton set, and rooted if it is left-rooted or right-rooted or both. It is easy to see that the set interval of a border is the union of the set intervals of a number borders which are all left rooted (or all right rooted). Our algorithms will aim to produce such outputs as representations of emerging patterns. The following result makes borders useful in this work. even when the number of EPs in the BCDG rectangle is huge. 
We concentrate our discussion on the situation when two large borders, one from VI and one from 2)s, are available. 
We will briefly discuss the other combinations in the next section. The differential procedure, called BORDER-DIFF, is given in the first subsection. Then the main algorithm, 
MBD-LLBORDER, using BORDER-DIFF as a subroutine, is given in the second subsection for discovering EPs themselves. 4.1 Differential between borders 
BORDER-DIP aims to derive the differential between a pair of borders with a special form: Given a pair of borders c(0), {V}&gt; and &lt;{ld},Ri&gt;, BORDER-DIFF de-rives another border &lt;L2, {U}&gt; such that [L2, {U}] = [{0}, {V}] -[{0),X1] (see Figure 2). Importantly, it achieves this by manipulating only the itemsets in the bor-ders. We give two versions of the algorithm; the first version is more declarative and thus easier to understand, and the second version is more procedural and more efficient. 
Example 4.1 We now illustrate how BORDER-DIFF works ontheargumentsof&lt;{0},{1,2,3,4}&gt;and&lt;{0},{{3,4}, {2,4}, {2,3}}&gt;. (See Figure 3.) BORDER-DIFF first derives the set (The set { 1) is the result of  X  X emoving duplicates from the multiset { 1, 1, l} X .) Then it removes the non-minimal sets in 
Ltoproduce&lt;{{1},{2,3,4}},{{1,2,3,4}}&gt;.Inessence, this algorithm generates the whole  X  X artesian products X  of u -s1;.. , U -Sk before eliminating the non-minimal elements. I We argue that the algorithm is correct using Example 4.1. Let U = {1,2,3,4}, S1 = {3,4}, Sz = {2,4}, and Ss = {2,3}. Let Z denote [{0},{{1,2,3,4}}] -and remove those itemsets covered by the border &lt; {0}, {{3,4}, {2,4}, {2,3}}&gt;. On the other hand, BORDER-
DIFF is more clever by examining the border bounds only. 4.2 Emerging patterns by MBD-LLBORDER We are now ready to present the main algorithm, namely 
MBD-LLBORDER, of this paper. This algorithm can discover all EPs in the BCDG rectangle of Figure 1, and it achieves this goal by manipulating only its input borders. 
Procedurally, this algorithm derives the EPs in the BCDG rectangle by calling BORDER-DIFF a multiple number of times. Each call will use one itemset in the right-hand bound of the large border of 2)~ and the whole right-hand bound of the large border of Vr as the two argument values. Assume that we have found LARGEBORDERS and LARGEBORDERB (Da) for some 6 and 19 satisfying 6 X  = p*6. Suppose 
We first describe the basis of this algorithm. Since all EPs in the BCDG rectangle must have support 2 19 in 2)s but &lt; S in VI, they are exactly the elements of the following set3: Given j, 1 _&lt; j &lt; n, the collection (PowSet -UEIPowSet(Ci)) consists of those sets that are subsets of 
Dj but not subsets of any Ci (1 5 i 5 m); equivalently, the collection consists of those sets that are subsets of Dj but not subsets of any Ci (1 5 i 2 m), where Ci denotes 
Ci II Dj ; again equivalently, the collection consists of those sets that are subsets of Dj but not subsets of any of the maximalC,!samongC~,...,C~.Suppose{C~,C~,~~~,C~} is an enumeration of these maximal itemsets (k 5 m). 
NOW, (PowSet -U,k,,PowSet(C;I)) is the collection of all itemsets covered by a border, and that border is precisely the one derived by BORDER-DIFF(&lt;{~}, {Dj}&gt;, c(0), {Ci, Ci,. , CL}&gt;). 
Therefore, the collection of all EPs in the BCDG rectangle by calling BORDER-DIFF in this way for all j. The above approach is now formulated as our algorithm MBD-LLBORDER. MBD-LLBORDER(LARGEBORDERJ(ZJ~), ;; return all EPs in the BCDG rectangle ~)EPBORDERS+ {}; 2) for j from 1 to n do 3) if some Ci is a superset of Dj then continue; 5 Other algorithms by many users of the University of Melbourne. 
In the previous section we only discussed how to find EPs from two large borders. In this section we will give sketches (due to space limitation) of other algorithms detailed in the full paper or elsewhere. The other algorithms consider other border combinations, or discover  X  X trong X  EPs, or discover  X  X umping X  EPs. sets in ;D, and that we call the border of SMALLJ(;T)) a small border. Similar to large itemsets, small itemsets are also in-terval closed. border combinations: One large and one small borders, and two small borders. There we present border conversion algo-rithms, which can translate a large border to the correspond-ing small border and vice versa. (Recall that a large border w.r.t. a support threshold S and the small border w.r.t. 6 are complementary.) Since Max-Miner and SE-trees cannot be used to discover small borders, in the full paper we also in-troduce Min-Miner and decreasing SE-trees for discovering small borders directly. 
The discovery of strong EPs (defined as those EPs all of whose subsets are also EPs) can be done in a way similar to Apriori, by using the subset closure property. 
Another method was introduced in [6] for discovering another special type of EPs, called jumping EPs. Jumping 
EPs are special EPs whose supports increase abruptly from zero support in one dataset to non-zero support in another. 
In that method, we do not use Max-Miner to find the needed large borders. Instead, we use a new algorithm, HORIZON-
MINER, to find the large border of all itemsets with non-zero support. Then we use MBD-LLBORDER to find the jumping EPs, using the two large borders derived by HORIZON-
MINER as input. These jumping EPs were used to build very powerful classifiers [7, 131. 
We now report a performance evaluation of the algorithms proposed in this paper, showing their efficiency. 
We carried out experiments on many datasets, includ-ing two high dimensional datasets, namely the mushroom dataset and the U.S. Census dataset. The performance re-port will concentrate on our MBD-LLBORDER algorithm, and show that it is very efficient on these datasets. The large borders can be discovered very quickly4 either using 
Bayardo X  X  Max-Miner (even for very small support thresh-old such as 0.1%) or using our HORIZON-MINER [6]; con-sequently, we will not include the timing of Max-Miner or HORIZON-MINER used in discovering the large borders. All experiments were conducted on a 1SOMHz Sun 
SPARCstation-10 machine with 160M bytes of RAM, shared 6.2 MBD-LLBORDER on Mushroom The mushroom dataset (available from the UC1 Machine 
Learning Repository) consists of two classes of data: the edible class containing 4208 instances and the poisonous class containing 3916 instances. The encoded dataset contains 121 binary items after each attribute (22 in total) is mapped to a certain number of items. The large border in the edible class of data w.r.t the support threshold of l/4500 has a right-hand bound consisting of 4208 itemsets, and the large border in the poisonous class of data has a right-hand bound consisting of 3916 itemsets. These were discovered using HORIZON-MINER. Taking these two large borders, MBD-LLBORDER has found a huge number of 
EPs using about 30 minutes. We need 299811 borders to represent all such EPs from the poisonous class to the edible class and 271715 borders to represent all such EPs from the edible class to the poisonous class. On average, each border represents around 2 l8 = 262144 sets. Obviously, without the border mechanism, it is impossible to enumerate the complete EPs. Without the border mechanism, it would be very time consuming to mine the EPs. Even using the semi-naive algorithm, we would need to examine approximately 232 itemsets, requiring at least 2 X  iterations over the data. (Each itemset needs 25 bytes, assuming one byte per integer. 160Mbytes is 2 28 bytes; so 160M can hold 223 itemsets. The 232 itemsets thus would require 2 X  iterations. The CPU time, which is dominant for high dimensional datasets, would be very very long.) Among the discovered EPs, some of them are singleton itemsets; some of them can reach a cardinality of 22; many of them have a cardinality around 18. 6.3 Other datasets 
In our investigations into building EP-based classifiers [7], we applied MBD-LLBORDER to large borders extracted from a large number of datasets including breast-w, iris, pima, sonar, and wine from the UC1 machine learning repository. The time needed for MBD-LLBORDER is always very short (in fact less than 30 seconds). 
We have introduced the data mining problem of emerging patterns (EPs). EPs can capture emerging trends in times-tamped databases, or capture differentiating characteristics between classes of data. EPs have been useful: we have used 
EPs to build very powerful classifiers, including the Mush-room dataset, which are more accurate than C4.5 and CBA [ 151. We believe that they are useful in many other applica-tions. 
These patterns can be large in size, and may have very small support (e.g. a trend at the forming stage). We observed that naive algorithms are too costly, because the useful Apriori property no longer holds for EPs and because there are usually too many candidates. Indeed, since there are large itemsets with 40 items even for the 5% support [7] G. Dong, X. Zhang, L. Wong, and J. Li. CAEP: Classi-[8] Carl A. Gunter, Teow-Hin Ngair, and Devika Subrama-[9] J Han, G Dong, and Y Yin. Efficient mining of partial [lo] J. Han and Y. Fu. Exploration of the power of attribute-[ll] J. Han, W. Gong, and Y. Yin. Mining segment-wise [ 121 B Lent, R Agrawal, and R Srikank. Discovering trends [13] J. Li, G. Dong, and K. Ramamohanarao. JEP-[14] H. Lu, J. Han, and L. Feng. Stock movement and [ 151 B Liu, W Hsu, and Y Ma. Integrating classification and [16] H. Mannila, and H. Toivonen. Levelwise search [17] H. Mannila, H Toivonen, and A. I. Verkamo. Discov-[ 181 B. Ozden, S. Ramaswamy, and A. Silberschatz. Cyclic [ 191 Ron Rymon. Search through systematic set enumera-
