 As a social service in Web 2.0, folksonomy provides the users the ability to save and organize their bookmarks online with  X  X ocial annotations X  or  X  X ags X . Social annotations are hig h quality descriptors of the web pages X  topics as well as good indicators of web users X  interests. We propose a personal-ized search framework to utilize folksonomy for personaliz ed search. Specifically, three properties of folksonomy, name ly the categorization , keyword , and structure property, are ex-plored. In the framework, the rank of a web page is decided not only by the term matching between the query and the web page X  X  content but also by the topic matching between the user X  X  interests and the web page X  X  topics. In the evalu-ation, we propose an automatic evaluation framework based on folksonomy data, which is able to help lighten the com-mon high cost in personalized search evaluations. A series of experiments are conducted using two heterogeneous data sets, one crawled from Del.icio.us and the other from Do-gear. Extensive experimental results show that our person-alized search approach can significantly improve the search quality.
 H.3.3 [ Information Search and Retrieval ]: Information search and Retrieval X  Search Process Algorithms, Measurement, Experimentation, Performance Folksonomy, Personalized Search, Topic Space, Web 2.0, Au-tomatic Evaluation Framework  X  Part of this work was done while Shengliang Xu and Shenghua Bao were interns at IBM China Research Lab.
In today X  X  search market, the most popular search paradi-gm is keyword search. Despite simplicity and efficiency, key-word queries can not accurately describe what the users re-ally want. People engaged in different areas may have differ-ent understandings of the same literal keywords. Authors of [26], concluded that people differ significantly in the searc h results they considered to be relevant for the same query.
One solution to this problem is Personalized Search . By considering user-specific information [21], search engine s can to some extent distinguish the exact meaning the users want to express by the short queries. Along with the evolution of the World Wide Web, many kinds of personal data have been studied for personalized search, including user manually s e-lected interests [16, 8], web browser bookmarks [23], users  X  personal document corpus [7], search engine click-through history [10, 22, 24], etc. In all, search personalization is one of the most promising directions for the traditional search paradigm to go further.
 In recent years, there raises a growing concern in the new Web 2.0 environment. One feature of Web 2.0 that distin-guishes it from the classical World Wide Web is the social data generation mode. The service providers only provide platforms for the users to collaborate and share their data online. Such services include folksonomy, blog, wiki and so on. Since the data are generated and owned by the users, they form a new set of personal data. In this paper, we focus on exploring folksonomy for personalized search.

The term  X  X olksonomy X  is a combination of  X  X olk X  and  X  X axonomy X  X o describe the social classification phenomeno n [3]. Online folksonomy services, such as Del.icio.us , Flic kr and Dogear [19] , enable users to save and organize their bookmarks, including any accessible resources, online wit h freely chosen short text descriptors, i.e.  X  X ocial annotat ions X  or  X  X ags X , in flat structure. The users are able to collabo-rate during bookmarking and tagging explicitly or implicit ly. The low barrier and facility of this service have successful ly attracted a large number of users to participate.
The folksonomy creates a social association between the users and the web pages through social annotations. More specifically, a user who has a given annotation may be in-terested in the web pages that have the same annotation. Inspired by this, we propose to model the associations be-tween the users and the web pages using a topic space. The interests of each user and the topics of each web page can be mapped to vectors in the topic space. The personalized search is conducted by ranking the web pages in two guide-lines, term matching and topic matching. When a user u issues a query q , a web page p is ranked not only by the term similarity between q and p but also by the topic sim-ilarity between u and p . The social annotations in folkson-omy naturally form a social topic space. Three properties of folksonomy are studied for the topic space estimation:
The categorization property . Many of the social an-notations are subject descriptor keywords at various level s of specificity [17]. The selection of proper annotations for a web page is somewhat a classification of the web page to the categories represented by the annotations.

The keyword property . As discussed in [12, 4, 27], the annotations can be seen as good keywords for describing the respective web pages from various aspects.

The structure property . In folksonomy systems, users X  bookmarking actions form a cross link structure between the users and the web pages. Since all the folksonomy data are publicly available, the structure can be fully explored.
Some of the prior studies show similar ideas. In [8, 13, 22, 21, 16], they use ODP taxonomy structure to represent the topics of the web pages and the interests of the users. As a comparison, we also apply ODP in our work to show whether or not the classical web page taxonomy still perform well enough for the Web 2.0 search personalization.
As for evaluation, we propose a new evaluation framework for personalized search using folksonomy data. The frame-work is low cost. Thus it is able to help lighten the common high barrier in personalized search evaluation. Extensive experimental results show that our personalized search al-gorithm outperforms the baselines significantly.

The rest of this paper is organized as follows. Section 2 lists some related work. In Section 3, after a detailed analysis of folksonomy, the personalized search algorithm s are discussed. Section 4 presents the novel personalized search evaluation framework. In Section 5, we report the experiment results. Section 6 lists some discussions about our work. Finally, we conclude our work and list some future work in Section 7.
This paper brings together two areas, personalized search and folksonomy, both of which already exist a lot of prior efforts. In this section we present a separate review on eithe r of them.
As early as in 2000, Lawrence [15] pointed out that next-generation search engines will increasingly use context in -formation to improve search effectiveness. In 2002, Pitkow et al. further identified two primary strategies, query refin e-ment and result processing, to personalize search in [21].
Query Refinement , also called Query Expansion , refers to the modification to the original query, including augment -ing the query by other terms or changing the original weight of each query term. Much work has been done in this area, like [25, 7], etc. However, since our work focuses on result processing, these prior efforts are not relevant to us closel y. We do not review them in detail here.

Result Processing includes result reranking according to each user X  X  personal needs, result clustering for better presentation, etc. Among these, result reranking is one of the most widely used. Haveliwala in [13] proposed to cal-culate a set of PageRanks for each web page biased on the top most 16 ODP categories. The ODP categories in his work is a little similar to the topic space we will propose in the personalized search framework. But our topic space is much more general than their ODP categories. Further in [22], Qiu and Cho proposed a sophisticated approach to build user models from user click history and combine it with Haveliwala X  X  work for personalized search. In some other studies, such as [16, 8, 21] the ODP category struc-ture is also accepted for modeling the web pages X  topics and the users X  interests. The ODP categories in these studies is a little similar to the topic space we will propose in the perso n-alized search framework but our topic space is more general. In a recent study [20], Noll and Meinel proposed to rerank the non-personalized search results by considering the use r X  X  social annotations and the search results X  social annotati ons. Their work is rather simple while effective. The success they achieved is a strong support for our work. Recently, Dou et al. [10] proposed an evaluation framework for personalized search using user click-through history, which needs a lot of user click through data from a real life search engine. Though the technology sounds promising, it is unpractical for most of the researchers because the click through data of search engines are not publicly accessible.

Except the above, there are still a lot of wonderful prior studies on result refinement for personalized search, such a s [24, 25], etc. Since they are not very relevant to our work, we don X  X  present the detailed reviews here.
Existing research on folksonomy can be mainly divided into two directions. The first is the survey and analysis of th e general characteristics of folksonomy systems. The second is the exploring of folksonomy for various applications.
The semantic values of folksonomy . In [17] , the au-thors investigated two of the most famous folksonomy ser-vice providers Del.icio.us and Flickr and gave the strength s and weaknesses of annotation data. Golder &amp; Huberman gave a deep investigation of the Del.icio.us tag data in [12] . Al-Khalifa &amp; Davis analyzed the semantic value of social an-notations and got the conclusion that the folksonomy tags are semantically richer than keywords extracted using a ma-jor search engine extraction service like Yahoo TE [2].
The collaborative link structure . Several prior efforts propose to model the underlying link structure of folkson-omy by graphs. In [14], the authors viewed the tagging system as a tripartite network with users, tags and URLs as three kinds of nodes. Catutto et al. investigated the un-derlying tripartite graph of the tagging systems in [5]. The y concluded that folksonomies exhibit a small world structur e.
Applications . Many applications of social annotations have been carried out in recent years, most of which focus on exploring the semantic value of annotations. [27] and [18 ] both exploited the latent semantics under the tag literatur e. Bao et al. in [4] proposed to measure the similarity and popularity of web pages from web users X  perspective by cal-culating SocialSimRank and SocialPageRank, respectively .
In this section, we first give a short analysis of folkson-omy, and then discuss in detail the approach we propose for personalized search. What folksonomy can bring us in personalized search? The best way to answer this question is to analyze it.
Social Annotations as Category Names . In the folk-sonomy systems, the users are free to choose any social an-notations to classify and organize their bookmarks. Though there may be some noise, each social annotation represents a topic that is related to its semantic meaning [17]. Based on this, the social annotations owned by the web pages and the users reflect their topics and interests respectively.
Social Annotations as Keywords . As discussed in [2, 4, 27] the annotations are very close to human generated keywords. Thus, the social annotations usually can well de-scribe or even complement the content of the web pages.
Collaborative Link Structure . One of the most impor-tant benefits that online folksonomy systems bring is the col -laborative link structure created by the users unconscious ly. The underlying link structure of the tagging systems has been explored in many prior efforts [4, 18, 27]. The whole underlying structures of folksonomy systems are rather com -plex. Different researchers may reduce the complexity of modeling the structure by various simplified model, e.g. in [27], the structure is modeled through a latent semantic lay er while in [4] the relations between the annotations and the web pages are modeled using a bipartite graph. In our work, since the relations between the users and the web pages are very important, we model the structure using a user-web page bipartite graph as shown in Figure 1.
 where u i , i = 1 , 2 , , n denote n users, p j , j = 1 , 2 , , m denote m web pages, W k , k = 1 , 2 , , l are the weights of the links, i.e. the bookmarking actions of the users. One of the simplest implementation of the weights is the number of annotations a user assigned to a web page.
In the classical non-personalized search engines, the rel-evance between a query and a document is assumed to be only decided by the similarity of term matching. However, as pointed in [21], relevance is actually relative for each u ser. Thus, only query term matching is not enough to generate satisfactory search results for various users.

In the widely used Vector Space Model(VSM), all the queries and the documents are mapped to be vectors in a universal term space. The similarity between a query and a document is calculated through the cosine similarity be-tween the query term vector and the document term vector. Though simple, the model shows amazing effectiveness and efficiency.

Inspired by the VSM model, we propose to model the associations between the users and the web pages using a topic space . Each dimension of the topic space represents a topic. The topics of the web pages and the interests of the users are represented as vectors in this space. Further we define a topic similarity measurement using the cosine function. Let ~p ti = ( w 1 ,i , w 2 ,i , , w  X ,i ) be the topic vector of the web page p i where  X  is the dimension of the topic space and w k,i is the weight of the k th dimension. Similarly, let ~u tj = ( w 1 ,j , w 2 ,j , , w  X ,j ) be the interest vector of the user u j . The topic similarity between p i and u j is calculated as Equation 1.
Based on the topic space, we make a fundamental person-alized search assumption, i.e. Assumption 1.

Assumption 1. The rank of a web page p in the result list when a user u issues a query q is decided by two aspects, a term matching between q and p and a topic matching between u and p .

When a user u issues a query q , we assume two search processes, a term matching process and a topic matching process. The term matching process calculates the similari ty between q and each web page to generate a user unrelated ranked document list. The topic matching process calculate s the topic similarity between u and each web page to generate a user related ranked document list. Then a merge operation is conducted to generate a final ranked document list based on the two sub ranked document lists. We adopt ranking aggregation to implement the merge operation.

Ranking Aggregation is to compute a  X  X onsensus X  ran-king of several sub rankings [11]. There are a lot of rank ag-gregation algorithms that can be applied in our work. Here we choose one of the simplest, Weighted Borda-Fuse (WBF). Equation 2 shows our idea. where r term ( q, p ) is the rank of the web page p in the ranked document list generated by query term matching, r topic ( u, p ) is the rank of p in the ranked document list gen-erated by topic matching and  X  is the weight that satisfies 0  X   X   X  1.

Obviously, how to select a proper topic space and how to accurately estimate the user interest vectors and the web page topic vectors are two key points in this framework. The next two subsections discuss these problems.
In web page classification, the web pages are classified to several predefined categories. Intuitively, the categor ies of web page classification are very similar to the topics of the topic space. In today X  X  World Wide Web, there are two classification systems, the traditional taxonomy such as ODP and the new folksonomy. The two classification systems can be both applied in our framework. Since our work focuses on exploring the folksonomy for personalized search, we set the ODP topic space as a baseline.
Based on the categorization feature, we set the social an-notations to be the dimensions of the topic space. Thus, the topic vector of a web page can be simply estimated by its social annotations directly. In the same way, the intere st vector of a user can be also simply estimated by her social annotations.

Obviously, if we treat the users and the web pages as doc-uments, the social annotations as terms, the above setting is right the VSM. Since the VSM has developed for a long time, there have been a large number of mature technolo-gies to improve the VSM search effectiveness. All these can be easily applied here. One of the most important in VSM is the weighting for document terms. Similarly, the topic weighting here is also very important. The simplest while widely used one is tfidf . where tf denotes the term frequency, N denotes the total number of documents in the whole collection and n i denotes the number of documents in which the term appears. Beside this, BM25 weighting scheme is a more sophisticated alter-native, which represents state-of-the-art retrieval func tions used in document retrieval where k 1 and b are free parameters, dl denotes the document length and avgdl denotes the average document length of all the documents in the collection.
In web page taxonomy, the  X  X MOZ X  Open Directory Pro-ject (ODP) is the largest, most comprehensive human-edited directory of the web. This high quality and free web tax-onomy resource has been used in rather a number of prior researches like [21, 8, 13, 22, 16]. Some of these studies show similar idea as ours, especially [13] and [22]. They use the ODP categories as topics to calculate a set of topic biased PageRanks, which are used in personalized search. Following their steps, we can also choose ODP X  X  16 top cat-egories as the dimensions of the topic space. However, 16 categories may be too few for our personalized search task comparing to the folksonomy categories. Thus, we make another choice of totally 1171 categories, including all th e second level categories of ODP and the third level categorie s of TOP/Computers. The choice is based on the consider-ation that the data corpus we will use in experiments are mostly about computer science.

Now the question is how to estimate the topic vectors and interest vectors. ODP releases all the data in RDF format. In the RDF file, each of the web pages included in ODP attaches a short description. All the descriptions of the web pages under a category can be merged to create a term vector of the corresponding category. Then the topic vector of a web page can be calculated by cosine similarity of the category X  X  term vector and the social annotations of the web page. Similarly, the interest vector of a user can be calculated by cosine similarity of the category X  X  term vect or and the social annotations owned by the user.
In Section 3.1, we have modeled the underlying collabora-tive structure of a folksonomy system as a bipartite graph. The bipartite structure is the result of user collaboration which is one of the main advantages that online folkson-omy service over offline desktop bookmarks. Intuitively, the topics of the web pages that a user saved in social tagging systems exhibit the user X  X  interests. In return, the intere sts of the users who saved a given web page also imply the top-ics of the web page to some extent. Furthermore, it X  X  not difficult to infer that this process is actually iterative. We propose to fully explore this bipartite structure for adjus ting the initial estimation of users X  interest vectors and the we b pages X  topic vectors using an iterative algorithm. Formally, Let G = ( V, E ) be the graph, where the nodes in V represent users and web pages, and the edges E represent the bookmarking actions. The nodes in V are divided into two subsets U = { u 1 , u 2 , , u n } representing the users and P = { p 1 , p 2 , , p m } representing the web pages. In Table 1, we list all the symbols we will use in the algorithm. Table 1: Symbols used in the Topic Adjusting Algorithm
Each iteration of this algorithm is performed in two steps. 1) User interest adjusting by related web pages. where r 0 i,j is the initial value of r i,j . 2) Web page topic adjusting by related users. where t 0 i,j is the initial value of t i,j .

As we can see from the above two equations, we reserve in each iteration an  X  and a  X  weight of the initial interest value and the initial topic value respectively. The reason is that , since r 0 i,j and t 0 i,j are estimated directly from the social anno-tations X  literal contents while ( P m k =1 t k,j W i,k ) / P ture, they are two heterogeneous parts. The two weights,  X  and  X  , are to reserve the influence of the social annotations X  literal contents in the final adjusted vectors.

Besides, though the forms of the above two equations seem to be complicated, the operations are actually linear com-bination. Thus the topic vectors of the web pages and the interest vectors of the users must be in the same scale. Thus, before the running of the algorithm we normalize all the vec-tors.

Finally, the above two equations can be rewritten in the form of matrices as following:
We claim that this iterative algorithm converges to a fixed point finally. In the following we give a short proof. We don X  X  list the detailed analysis of this algorithm because o f page limitation. The interested readers can refer to some prior studies such as [30] [29], inspired from which we have the idea of this algorithm.

Proof. Without loss of generality, we only prove R i can converge to a fixed point. Let W  X  be (1  X   X  ) W rn and W be (1  X   X  ) W T cn , we can expand Equation 7 as following:
Thus,
On the one hand, consider that W rn and W T cn are both row normalized, they are actually two Markov matrices, thus W Markov matrices. On the other hand, because that 0 &lt;  X  &lt; 1 and 0 &lt;  X  &lt; 1, we can derive:
Thus, we can finally derive that lim i  X  +  X  k R i +1  X  R i.e. R i is convergent.

For convenience, we refer to this algorithm as Topic Ad-justing Algorithm in the rest of the paper.
In the community of personalized search, evaluation is not an easy task. Generally speaking, the evaluation methods used in prior personalized search studies fall into two cat-egories, user experience study [21, 25, 22, 7, 8] and search engine query logs [10, 24].

The user study approach, though widely accepted in most of the prior efforts, needs many users to involve in the ex-periments, which is a rather high cost. In addition, since th e users who take part in the experiments know that they are being tested, they may bias the experiment results. The search engine query logs approach needs a large portion of real life search logs. This is not possible for most of the researchers, including us. The search engine service providers are not willing to release their query logs becaus e they include privacy of the users. In addition, the relevanc e assumption based on user clicks is strongly biased by the search engines.

Under this condition, we propose a new evaluation frame-work for personalized search based on social annotations. The main obstacle that raises the difficulty of evaluation for personalized search is that we must have enough user-specific relevance judgement data. In the user experience study, these data are collected from the experiment partic-ipants directly. In the search log approach, the researcher s make an assumption that the user clicks reflect their rele-vance judgement. Thus they can collect a lot of experiment data without any extra user efforts. As for our evaluation framework, we make an assumption similar to the search log approach, i.e.

Assumption 2. The users X  bookmarking and tagging ac-tions reflect their personal relevance judgement. For example, if a user assigned an annotation X  java  X  X o the Apache Lucene homepage (http://lucene.apache.org) we as-sume that the user will consider this web page as relevant if she issues  X  java  X  as a query. Of course, it X  X  also the truth that a lack of an annotation doesn X  X  necessarily mean irrel-evance. However, to the best of our knowledge, this is a common problem for all the prior evaluation approaches for personalized search within the web scale.

This assumption is based on three considerations. 1) In today X  X  search technology, keyword query is the most popular query representation. According to the keyword fea-ture of folksonomy, most of the social annotations are key-words of their owner web pages. Thus, the annotations can be considered as queries to some extent. 2) As discussed in Section 3.1, a web page may contain multiple topics. Different users may be interested in differe nt topics of the same web pages. Most likely the users may choose their favorite topics of the web pages to assign some related annotations. In other words, if the social annotati ons are issued as queries, different users may consider a web page to be relevant to different queries. 3) Different users may choose various terms as social an-notations for the same web page. The annotations reflect their personal preference of daily life vocabulary. In othe r words, the data don X  X  bias for our experiments.

The above three considerations have been analyzed and explored in several prior efforts [2, 1, 4, 12, 17, 18, 19, 20, 2 7], because of page limitation, we don X  X  list the detailed analy sis here. In all, we expect this new evaluation framework to lighten the high barrier of personalized search evaluation .
To fully evaluate our personalized search model, we use two heterogeneous data sets. One is crawled from Del.icio.u s during May 2006, consisting of 90,300 web pages, 65,080 dis-tinct annotations and 9,813 users. Since this data set is fro m the web, it reflects the web users X  social bookmarking and tagging patterns. The other one is the tagging records of the Dogear tagging system [19] up to July 7th 2007. The data set consists of 179,835 web pages, 47,993 distinct anno -tations and 5,192 users. This data set reflects the enterpris e users X  social bookmarking and tagging patterns.

From each data set, we build three test beds according to the number of bookmarks owned by the users, resulting in totally 6 test beds. The 3 test beds built from the Del.icio.u s data set are: 1) 100 randomly selected users who own 5  X  10 bookmarks and their tagging records, denoted as DEL.5-10; 2) 100 random users who own 80  X  100 bookmarks and their tagging records, denoted as DEL.80-100; 3) all the 31 users who own more than 500 bookmarks and their tagging records, denoted as DEL.gt500. The 3 test beds from the Dogear data set are built in the same way as Del.icio.us, denoted as DOG.5-10, DOG.80-100 and DOG.gt500 respec-tively. The purpose of building the 6 test beds is not only to evaluate the model in the two different environments, i.e. web and enterprise, but also to evaluate it in the situations of different amount of data.

Before the experiments we perform two data preprocess-ing processes. 1)Several of the annotations are too persona l or meaningless, such as  X  X oread X ,  X  X mported IE Fa-vorites X ,  X  X ystem:imported X , etc. We remove some of them manually. 2) Some users may concatenate several words to form an annotation , e.g. javaprogramming, java/programming, etc . We split this kind of annotations with the help of a dictio-nary. Table 2 presents the statistics of the two data sets and the 6 test beds after data preprocessing where  X  num.users  X  denotes the number of users,  X  max.tags  X  denotes the maxi-mum number of distinct tags owned by each user, the rest columns have the similar meanings as  X  max.tags  X . As for Table 2: Statistics of the user owned tags and web pages of the experiment data each test bed, we randomly split them into 2 parts, a 80% training part and a 20% test part. The training parts are used to estimate the models while the test parts are used for evaluating. All the preprocessed data sets are used in the experiments. No other filtering is conducted.
Our personalized search framework needs two separated ranked lists of web pages. In practice, instead of generatin g two full ranked lists of all the web pages, an alternative ap-proach that costs less is to rerank only the top ranked result s fetched by the text matching model. In the experiments, we conduct such reranking based on two state-of-the-art text retrieval model, BM25 and Language Model for IR (LMIR). Firstly, a ranked list by a text retrieval model is generated . Then top 100 web pages in the ranked list are reranked by our personalized search model.
Before the experiments, there are three sets of parameters that must be set. The first two parameters are the  X  and  X  in the Topic Adjusting Algorithm in Section 3.4. We simply set them both 0.5 to keep the same influence for the initial social annotations X  literal contents and the link structur e. The second set of parameters are the set of  X  s in the ranking aggregation when using various search models under various test beds, i.e. Equation 2. We conduct a simple training process to estimate the  X  s as shown in Procedure 1. The concrete values of  X  under each search model and test bed
Procedure 1. Ranking aggregation parameter training process is listed in Table 3. In addition, we set the three parameters k , k 3 and b in BM25 1.2, 7 and 0.75 respectively, which are LMIR we accept jelinek-mercer smoothing [28] with  X  set to 0.3.
In the experiments we select 4 baseline models, one is the non-personalized text matching model using no extra infor-mation except for contents, the second is the model using the top 16 ODP categories as topic space which is denoted as  X  X DP1 X , the third is the model using 1171 ODP categories as topics which is denoted as  X  X DP2 X , and the last is the model proposed in [20], which is actually a simplified case of our personalized search framework when the topic space is set to be folksonomy and the topic matching function is set to simply counting the number of matched annotations. We refer to it as the  X  X C X  model.
The main evaluation metric we used in our work is mean average precision (MAP), which is a widely used evaluation metric in the IR community. More specifically, in our work, we calculate MAP for each user and then calculate the mean of all the MAP values. We refer it as Mean MAP or MMAP. where MAP i represents the MAP value of the i th user and N u is the number of users.

In addition, we perform t-tests on average precisions over all the queries issued by all the users in each experimental data set to show whether the experimental improvements are statistical significant or not.
Table 3 lists all the 120 experimental results. The columns  X  X ext X ,  X  X DP1 X ,  X  X DP2 X ,  X  X C X ,  X  X .tfidf X  and  X  X .bm25 X  de-note the non-personalized text model, the 16 top most ODP topic space personalized model, the 1171 ODP topic space personalized model, the AC model, the folksonomy topic space personalized model using tfidf weighting scheme and the folksonomy topic space personalized model using BM25 weighting scheme. The sub columns  X  X . A. X  and  X  X . A. X  de-note X  X efore Adjusting by link structure X  X nd X  X fter Adjust -ing by link structure X , respectively. The X * X  X  in the X  X MAP X  row stand for four significance levels of the t-test, satisfy ing 0.05  X  * &gt; 0.01  X  ** &gt; 0.001  X  ***.

As we can see from the table, the 5 personalized search models all outperform the simple text retrieval models sig-nificantly. Though the two ODP topic space search models have rather great improvements over the simple text search models, it is not well enough to fully utilize the folksonomy . The ODP2 model outperforms the ODP1 model in nearly all the experiments while the improvements are not so great. In contrast, even the simplest folksonomy topic space model , i.e. the AC model can beat the ODP models with great im-provements. A reason for this is that the interests of the users and the topics of the web pages are actually bound-less, thus a predefined static topic space such as ODP is not enough. However, the social annotations in folksonomy are dynamic. They can describe the topics and the interests more precisely.

As for the Topic Adjusting Algorithm, comparing the ex-perimental results of the two columns  X  X . A. X  and  X  X . A. X , it is clear that the algorithm is very effective. All the mod-els with the adjusted vectors beat the corresponding models with non-adjusted vectors.

Besides, among the three folksonomy topic space models, as we have expected, f.bm25 and f.tfidf outperform the AC model significantly. Notice that the adjusted f.bm25 reache s the optimal performance in all the experiments.

As we can see, all the experiments under various amount of data all output promising results. That means our model can handle all the situations of different amount of data. However one strange phenomenon is the search effectiveness seems to reduce when the amount of data increase. We expected the personalized models to increase performance when the amount of data increase. As to this problem, we manually analyzed the tagging data in the two data sets and find a main cause. Generally the social annotations owned by the users who own a small amount of total social anno-tations are much semantically richer than the social annota -tions owned by the users who own a relatively large amount of total social annotations. Because most of the users who own many bookmarks, especially those who have more than 500 bookmarks, directly export their desktop bookmarks into the folksonomy systems. The annotations of these book-marks are not user manually generated and many of them are obviously noise, such as  X  X mported IE Favorites X ,  X  X m-ported 1/14/06 X ,  X  X ystem:imported X ,  X  X mported X , etc.
Integrating folksonomy systems with search en-gines . One problem in implementing our personalized search algorithm in real life is how to access the folksonomy data of a user when she is searching. This won X  X  be a problem if the search engines and the folksonomy systems are owned by the same company or organization. Yahoo! has given us a solu-tion to this problem not long ago. The two most well known Web 2.0 social tagging websites, Del.icio.us and Flickr, ha ve been purchased by Yahoo!. Furthermore, many folksonomy websites provide simple search engines themselves. The per -sonalization can be implemented on these search engines.
Sparseness of social annotations . Since the social an-notations require the users to create explicitly, many user s may be reluctant to maintain such personal data. Though more and more users are now engaged in folksonomy, it X  X  still a small portion of all the search engine users. How to expand the benefit of our personalized search algorithm to all the search engine users? [9] and [6] give us two potential solutions. In [9], the authors collected tagging data autom at-ically from user click through histories by treating querie s as annotations and all the clicked web pages as bookmarks. [6] proposed to automatically generate personalized annot a-tions based on users X  personal document corpus. Both the above approaches can be incorporated in our personalized framework easily. Thus the sparseness of social bookmarks can be lightened to a certain extent.

Folksonomy topic dimension reduction . Similar to the document terms, the synonymy and polysemy problem also exist in social annotations. Dimension reduction is a technology to tackle this problem, including LSI, PLSI, etc . However, these algorithms are rather time and space con-suming. In our future work, we will study how to reduce folksonomy dimension efficiently and evaluate the effective-ness using reduced dimensions.
How to effectively use folksonomy for personalized search in Web 2.0 environment is quite a new problem. The main contributions of this paper can be summarized as following: 1) The proposal of a personalized search framework, in which the users and the web pages are associated by a topic space. 2) The proposal of using the social annotations to modeling the topic space. Specifically, three properties of folksono my, namely the categorization , the keyword and the structure property, are studied. 3) The proposal of an automatic eval-uation framework for personalized search using folksonomy data. The evaluation framework is able to lighten the com-mon high cost problem in personalized search evaluations. 4) The evaluations of our personalized search approach us-ing a Del.icio.us corpus and a Dogear corpus show that our approach outperforms the baselines significantly.
This is just our first trial of leveraging folksonomy for personalized search. There are several possible future ext en-sions as listed in the following. 1) we set text retrieval mod -els as our baselines. The purpose of this choice is to show the pure ability of folksonomy for personalized search. How -ever, today X  X  web search engines already account for much meta information such as link structure, anchor text, etc. in addition to the similarity of a query to a document when ranking. We X  X l explore some approaches to incorporate thes e information into our framework. 2) the personalized search framework uses Weighted Borda-Fuse as the rank aggrega-tion approach. This simple method is essentially a linear combination. We X  X l try more sophisticated rank aggrega-tion methods to test the personalized search framework. 3) as for the evaluation framework, we X  X l test it in some other contexts to show its detailed pros and cons.
The authors would like to thank IBM China Research Lab for its continuous support to and cooperation with Shanghai Jiao Tong University. We would also like to express our gratitude to D.R. Millen and J. Feinberg from IBM Watson Research Center for providing us the Dogear social tagging data corpus [19]. Besides, we also appreciate the valuable suggestions of Feng Yun, Mianwei Zhou, and Jinwen Guo. In the end, we would like to thank the anonymous reviewers for their elaborate and helpful comments.
