 A dependency parse tree encodes useful semantic in-formation for several language processing tasks. De-pendency parsing is a simpler task than constituent parsing, since dependency trees do not have ex-tra non-terminal nodes and there is no need for a grammar to generate them. Approaches to depen-dency parsing either generate such trees by consid-ering all possible spanning trees (McDonald et al., 2005), or build a single tree on the fly by means of shift-reduce parsing actions (Yamada &amp; Matsumoto, 2003). In particular, Nivre and Scholz (2004) and Attardi (2006) have developed deterministic depen-dency parsers with linear complexity, suitable for processing large amounts of text, as required, for ex-ample, in information retrieval applications.
We investigate a novel revision approach to dependency parsing related to re-ranking and transformation-based methods (Brill, 1993; Brill, 1995; Collins, 2000; Charniak &amp; Johnson, 2005; Collins &amp; Koo, 2006). Similarly to re-ranking, the second stage attempts to improve the output of a base parser. Instead of re-ranking n -best candi-date parses, our method works by revising a sin-gle parse tree, either the f irst -best or the one con-structed by a deterministic shift-reduce parser, as in transformation-based learning. Parse trees are re-vised by applying rules which replace incorrect with correct dependencies. These rules are learned by comparing correct parse trees with incorrect trees produced by the base parser on a training corpus. We use the same training corpus on which the base parser was trained, but this need not be the case. Hence, we define a new learning task whose output space is a set of revision rules and whose input is a set of features extracted at each node in the parse trees produced by the parser on the training corpus. A statistical classifier is trained to solve this task.
The approach is more suitable for dependency parsing since trees do not have non-terminal nodes, therefore revisions do not require adding/removing nodes. However, the method applies to any parser since it only analyzes output trees. An intuitive mo-tivation for this method is the observation that a dependency parser correctly identifies most of the dependencies in a tree, and only local corrections might be necessary to produce a correct tree. Per-forming several parses in order to generate multiple trees would often just repeat the same steps. This could be avoided by focusing on the points where at-tachments are incorrect. In the experiments reported below, on average, the revision stage performs 4.28 corrections per sentence, or one every 6.25 tokens.
In our implementation we adopt a shift-reduce parser which minimizes computational costs. The resulting two-stage parser has complexity O ( n ) , lin-ear in the length of the sentence. We evaluated our model on the treebanks of English and Swedish. The experimental results show a relative error reduction of, respectively, 16% and 11% with respect to the base parser, achieving state of accuracy on Swedish. Detection of dependency relations can be useful in tasks such as information extraction (Culotta &amp; Sorensen, 2004), lexical acquisition (Snow et al., 2005), ontology learning (Ciaramita et al., 2005), and machine translation (Ding &amp; Palmer, 2005). A dependency parser is trained on a corpus an-notated with lexical dependencies, which are eas-ier to produce by annotators without deep linguis-tic knowledge and are becoming available in many languages (Buchholz &amp; Marsi, 2006). Recent de-velopments in dependency parsing show that deter-ministic parsers can achieve good accuracy (Nivre &amp; Scholz, 2004), and high performance, in the range of hundreds of sentences per second (Attardi, 2006).
A dependency parser takes as input a sentence s and returns a dependency graph G . Let D = { d 1 , d 2 , ..., d m } be the set of permissible depen-dency types. A dependency graph for a sentence s =  X  s 1 , s 2 , ..., s n  X  is a labeled directed graph G = ( s, A ) , such that: (a) s is the set of nodes, corresponding to the to-(b) A is a set of labeled arcs ( w i , d, w j ) , w i,j  X  s , (c)  X  w i  X  s there is at most one arc a  X  A , such (d) there are no cycles; In statistical parsing a generator (e.g. a PCFG) is used to produce a number of candidate trees (Collins, 2000) with associated scores. This approach has been used also for dependency parsing, generating spanning trees as candidates and comput-ing the maximum spanning tree using discriminative learning algorithms (McDonald et al., 2005).
Yamada and Matsumoto (2003) have proposed an alternative approach, based on deterministic bottom-up parsing. Instead of learning directly which tree to assign to a sentence, the parser learns which Shift/Reduce actions to use for building the tree. Parsing is cast as a classification problem: at each step the parser applies a classifier to the features rep-resenting its current state to predict the next action to perform. Nivre and Scholz (2004) proposed a vari-ant of the model of Yamada and Matsumoto that re-duces the complexity from the worst case quadratic to linear. Attardi (2006) proposed a variant of the rules that allows deterministic single-pass parsing and as well as handling non-projective relations. Several approaches to dependency parsing on multi-ple languages have been evaluated in the CoNLL-X Shared Task (Buchholz &amp; Marsi, 2006). As a base parser we use DeSR, a shift-reduce parser described in (Attardi, 2006). The parser constructs dependency trees by scanning input sen-tences in a single left-to-right pass and performing Shift/Reduce parsing actions. The parsing algorithm is fully deterministic and has linear complexity. Its behavior can be described as repeatedly selecting and applying some parsing rules to transform its state.

The state of the parser is represented by a quadru-ple  X  S, I, T, A  X  : S is the stack, I is the list of (re-maining) input tokens, T is a stack of saved to-kens and A is the arc relation for the dependency graph, consisting of a set of labeled arcs ( w i , r, w j w , w j  X  W (the set of tokens), and d  X  D (the set of dependencies). Given an input sentence s , the parser is initialized to  X  X  X  , s,  X  ,  X  X  , and terminates when it reaches the configuration  X  s,  X  ,  X  , A  X  .
Table 1 lists all parsing rules. The Shif t rule advances on the input, while the various Lef t , Right variants create links between the next in-put token and some previous token on the stack. Extract/Insert generalize the previous rules by respectively moving one token to the stack T and reinserting the top of T into S . An essential differ-ence with respect to the rules of Yamada and Mat-sumoto (2003) is that the Right rules move back to the input the top of the stack, allowing some further processing on it, which would otherwise require a second pass. The extra Lef t and Right rules (4-7, Table 1), and the ExtractInsert rules (8 and 9, Table 1), are new rules added for handling non-projective trees. The algorithm works as follows:
Algorithm 1 : DeSR input : s = w 1 , w 2 , ..., w n begin end
The function getContext () extracts a vector x of contextual features around the current token, i.e., from a subset of I and S . estimateAction () pre-dicts a parsing action y given a trained model w and x . In the experiments presented below, we used as features the lemma, Part-of-Speech, and dependency type of the following items:  X  2 top items from S ;  X  4 items from I ;  X  2 leftmost and 2 rightmost children from the The base parser is fairly accurate and even when there are mistakes most sentence chunks are correct. The full correct parse tree can often be recovered by performing just a small number of revisions on the base parse. We propose to learn these revisions and to apply them to the single best tree output by the base parser. Such an approach preserves the deter-ministic nature of the parser, since revising the tree requires a second sequential step over the whole sen-tence. The second step may also improve accuracy by incorporating additional evidence, gathered from the analysis of the tree which is not available during the first stage of parsing.

Our approach introduces a second learning task in which a model is trained to revise parse trees. Several questions needs to be addressed: which tree transformations to use in revising the parse tree, how to determine which transformation to apply, in which order, and which features to use for learning. 4.1 Basic graph movements We define a revision as a combination of atomic moves on a graph; e.g., moving a link to the follow-ing or preceding token in the sentence, up or down the graph following the directed edges. Table 2 sum-marizes the set of atomic steps we used. 4.2 Revision rules A revision rule is a sequence of atomic steps on the graph which identifies the head of a modifier. As an example, Figure 1 depicts a tree in which the mod-ifier  X  X y X  is incorrectly attached to the head  X  X ale X  (dashed arrow), rather than to the correct head  X  X f-fered X  (continuous arrow) 1 . There are several possi-ble revision rules for this case:  X  X u X , move up two nodes;  X  3 , three tokens to the left, etc. To bound the complexity of feature extraction the maximum length of a sequence is bound to 4. A revision for a dependency relation is a link re-direction, which moves a single link in a tree to a different head. This is an elementary transformation which preserves the number of nodes in the tree.

A possible problem with these rules is that they are not tree-preserving, i.e. a tree may become a cyclic graph. For instance, rules that create a link to a descendant introduce cycles, unless the appli-cation of another rule will link one of the nodes in the path to the descendant to a node outside the cy-cle. To address these issues we apply the following heuristics in selecting the proper combination: rules that redirect to child nodes are chosen only when no other rule is applicable (upwards rule are safe), and shorter rules are preferred over longer ones. In our experiments we never observed the production of any cycles.

On Wall Street Journal Penn Treebank section 22 we found that the 20 most frequent rules are suffi-cient to correct 80% of the errors, see Table 3. This confirms that the atomic movements produce simple and effective revision rules. 4.3 Tree revision problem The tree revision problem can be formalized as fol-lows. Let G = ( s, A ) be a dependency tree for sentence s =  X  w 1 , w 2 , ..., w n  X  . A revision rule is a mapping r : A  X  A which, when applied to an arc a = ( w i , d, w j ) , returns an arc a 0 = ( w i , d, w A revised parse tree is defined as r ( G ) = ( s, A 0 ) such that A 0 = { r ( a ) : a  X  A } .

This definition corresponds to applying the revi-sions to the original tree in a batch, as in (Brill, 1993). Alternatively, one could choose to apply the transformations incrementally, applying each one to the tree resulting from previous applications. We chose the first alternative, since the intermediate trees created during the transformation process may not be well-formed dependency graphs, and analyz-ing them in order to determine features for classifi-cation might incur problems. For instance, the graph might have abnormal properties that differ from those of any other graph produced by the parser. Moreover, there might not be enough cases of such graphs to form a sufficiently large training set. We frame the problem of revising a tree as a super-vised classification task. Given a training set S = ( x i , y i ) N i =1 , such that x i  X  IR d and y i  X  Y , our goal is to learn a classifier, i.e., a function F : X  X  Y . The output space represents the revision rules, in particular we denote with y 1 the identity revision rule. Features represents syntactic and morphologi-cal properties of the dependency being examined in its context on the graph. 5.1 Multiclass perceptron The classifier used in revision is based on the per-ceptron algorithm (Rosemblatt, 1958), implemented as a multiclass classifier (Crammer &amp; Singer, 2003). One introduces a weight vector  X  i  X  IR d for each y i  X  Y , in which  X  i,j represents the weight associ-ated with feature j in class i , and learn  X  with the perceptron from the training data using a winner-take-all discriminant function: The only adjustable parameter in this model is the number of instances T to use for training. We chose T by means of validation on the development data, typically with a value around 10 times the size of the training data. For regularization purposes we adopt an average perceptron (Collins, 2002) which returns for each y ,  X  y = 1 T P T t =1  X  t y , the average of all weight vectors  X  t y posited during training. The per-ceptron was chosen because outperformed other al-gorithms we experimented with (MaxEnt, MBL and SVM), particularly when including feature pairs, as discussed later. 5.2 Features We used as features for the revision phase the same type of features used for training the parser (de-scribed in Section 3). This does not have to be the case in general. In fact, one might want to introduce features that are specific for this task. For example, global features of the full tree which might be not possible to represent or extract while parsing, as in statistical parse re-ranking (Collins &amp; Koo, 2006).
The features used are lemma, Part-of-Speech, and dependency type of the following items: the current node, its parent, grandparent, great-grandparent, of the children thereof and, in addition, the previous and next tokens of the node. We also add as features all feature pairs that occurred more than 10 times, to reduce the size of the feature space. In alternative one could use a polynomial kernel. We preferred this option because, given the large size of the training data, a dual model is often impractical. 5.3 Revision model Given a dependency graph G = ( s, A ) , for a sen-tence s =  X  w 1 , ..., w n  X  , the revised tree is R ( G ) = ( s, A 0 ) , where each dependency a 0 i is equal to F ( a In other words, the head in a i has been changed, or not, according to the rule predicted by the classifier. In particular, we assume that revisions are indepen-dent of each other and perform a revision of a tree from left to right. As Table 3 suggests, there are many revision rules with low frequency. Rather than learning a huge classifier, for rules with little train-ing data, we limit the number of classes to a value k . We experimented with values between 30 and 50, accounting for 98-99% of all rules, and even-tually used 50, by experimenting with the develop-ment portion of the data. All rules that fall outside the threshold are collected in a single class y 0 of  X  X n-resolved X  cases. If predicted, y 0 , similarly to y 1 , has no effect on the dependency.

Occasionally, in 59 sentences out of 2416 on section 23 of the Wall Street Journal Penn Tree-bank (Marcus et al., 1993), the shift-reduce parser fails to attach a node to a head, producing a dis-connected graph. The disconnected node will ap-pear as a root, having no head. The problem occurs most often on punctuations (66/84 on WSJ section 23), so it affects only marginally the accuracy scores (UAS, LAS) as computed in the CoNLL-X evalua-tion (Buchholz &amp; Marsi, 2006). A final step of the revision deals with multiple roots, using a heuristic rule it selects one of the disconnected sub-trees as root, a verb, and attaches all sub-trees to it. 5.4 Algorithm complexity The base dependency parser is deterministic and per-forms a single scan over the sentence. For each word it performs feature extraction and invokes the classi-fier to predict the parsing action. If prediction time is bound by a constant, as in linear classifiers, parsing has linear complexity. The revision pass is deter-ministic and performs similar feature extraction and prediction on each token. Hence, the complexity of the overall parser is O ( n ) . In comparison, the com-plexity of McDonald X  X  parser (2006) is cubic, while the parser of Yamada and Matsumoto (2003) has a worst case quadratic complexity. 6.1 Data and setup We evaluated our method on English using the stan-dard partitions of the Wall Street Journal Penn Tree-bank: sections 2-21 for training, section 22 for development, and section 23 for evaluation. The constituent trees were transformed into dependency trees by means of a script implementing rules pro-posed by Collins and Yamada 2 . In a second eval-uation we used the Swedish Treebank (Nilsson et al., 2005) from CoNLL-X, approximately 11,000 sentences; for development purposes we performed cross-validation on the training data.

We trained two base parsers on the Penn Tree-bank: one with our own implementation of Maxi-mum Entropy, one with the TiMBL library for Mem-ory Based Learning (MBL, (Timbl, 2003)). We parsed sections 2 to 21 with each parser and pro-duced two datasets for training the revision model:  X  X sj2-21.mbl X  and  X  X sj2-21.me X . Each depen-dency is represented as a feature vector (cf. Sec-tion 5.2), the prediction is a revision rule (cf. Sec-tion 4.2). For the smaller Swedish data we trained one base parser with MaxEnt and one with the SVM implementation in libSVM (Chang &amp; Lin, 2001) us-ing a polynomial kernel with degree 2. 6.2 Results On the Penn Treebank, the base parser trained with MBL (DeSR-MBL) achieves higher accuracy, 88.41 unlabeled accuracy score (UAS), than the same parser trained with MaxEnt (DeSR-ME), 84.96 UAS. The revision model trained on  X  X sj2-21.me X  (Revision-ME) increases the accuracy of DeSR-ME to 88.01 UAS (+3%). The revision model trained on  X  X sj2-21.mbl X  (DeSR-MBL) improves the accu-racy of DeSR-MBL from 88.42 to 89.11 (+0.7%). The difference is mainly due to the fact that DeSR-MBL is quite accurate on the training data, almost 99%, hence  X  X sj2-21.mbl X  contains less errors on which to train the revision parser. This is typi-cal of the memory-based learning algorithm used in DeSR-MBL. Conversely, DeSR-ME achieves a score of of 85% on the training data, which is closer to the actual accuracy of the parser on unseen data. As an illustration, Figure 2 plots the distri-butions of revision rules in  X  X sj2-21.mbl X  (DeSR-MBL),  X  X sj2-21.me X  (DeSR-ME), and  X  X sj22.mbl X  (DeSR-MBL) which represents the distribution of correct revision rules on the output of DeSR-MBL on the development set. The distributions of  X  X sj2-21.me X  and  X  X sj22.mbl X  are visibly similar, while  X  X sj2-21.mbl X  is significantly more skewed towards not revising. Hence, the less accurate parser DeSR-ME might be more suitable for producing revision training data. Applying the revision model trained on  X  X sj2-21.me X  (Revision-ME) to the output of DeSR-MBL the result is 90.27% UAS. A relative error reduction of 16.05% from the previous 88.41 UAS of DeSR-MBL. This finding suggests that it may be worth while experimenting with all possi-ble revision-model/base-parser pairs as well as ex-ploring alternative ways for generating data for the revision model; e.g., by cross-validation.

Table 4 summarizes the results on the Penn Tree-bank. Revision models are evaluated on the output of DeSR-MBL. The table also reports the scores ob-tained on the same data set by by the shift reduce parsers of Nivre and Scholz X  X  (2004) and Yamada and Matsumoto (2003), and McDonald and Pereira X  X  second-order maximum spanning tree parser (Mc-Donald &amp; Pereira, 2006). However the scores are not directly comparable, since in our experiments we used the settings of the CoNLL-X Shared Task, which provide correct POS tags to the parser.
On the Swedish Treebank collection we trained a revision model (Revision-ME) on the output of the MaxEnt base parser. We parsed the evalua-tion data with the SVM base parser (DeSR-SVM) which achieves 88.41 UAS. The revision model achieves 89.76 UAS, with a relative error reduc-tion of 11.64%. Here we can compare directly with the best systems for this dataset in CoNLL-X. The best system (Corston-Oliver &amp; Aue, 2006), a vari-ant of the MST algorithm, obtained 89.54 UAS, while the second system (Nivre, 2006) obtained 89.50; cf. Table 5. Parsing the Swedish evalua-tion set (about 6,000 words) DeSR-SVM processes 1.7 words per second on a Xeon 2.8Ghz machine, DeSR-ME parses more than one thousand w/sec. In the revision step Revision-ME processes 61 w/sec. Several authors have proposed to improve parsing via re-ranking (Collins, 2000; Charniak &amp; Johnson, 2005; Collins &amp; Koo, 2006). The base parser pro-duces a list of n -best parse trees for a sentence. The re-ranker is trained on the output trees, using addi-tional global features, with a discriminative model. These approaches achieve error reductions up to 13% (Collins &amp; Koo, 2006). In transformation-based learning (Brill, 1993; Brill, 1995; Satta &amp; Brill, 1995) the learning algorithm starts with a baseline assignment, e.g., the most frequent Part-of-Speech for a word, then repeatedly applies rewriting rules. Similarly to re-ranking our method aims at improving the accuracy of the base parser with an additional learner. However, as in transformation-based learning, it avoids generating multiple parses and applies revisions to arcs in the tree which it con-siders incorrect. This is consistent with the architec-ture of our base parser, which is deterministic and builds a single tree, rather than evaluating the best outcome of a generator.

With respect to transformation-based methods, our method does not attempt to build a tree but only to revise it. That is, it defines a different output space from the base parser X  X : the possible revisions on the graph. The revision model of Nakagawa et al. (2002) applies a second classifier for deciding whether the predictions of a base learner are accurate. However, the model only makes a binary decision, which is suitable for the simpler problem of POS tagging. The work of Hall and Novak (Hall &amp; Novak, 2005) is the closest to ours. Hall and Novak develop a cor-rective model for constituency parsing in order to recover non-projective dependencies, which a stan-dard constituent parser does not handle. The tech-nique is applied to parsing Czech. We presented a novel approach for improving the accuracy of a dependency parser by applying re-vision transformations to its parse trees. Experi-mental results prove that the approach is viable and promising. The proposed method achieves good ac-curacy and excellent performance using a determin-istic shift-reduce base parser. As an issue for further investigation, we mention that in this framework, as in re-ranking, it is possible to exploit global features in the revision phase; e.g., semantic features such as those produced by named-entity detection systems. We would like to thank Jordi Atserias and Brian Roark for useful discussions and comments.

