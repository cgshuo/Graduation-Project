 Guillem Rigaill  X  rigaill@evry.inra.fr Toby Dylan Hocking  X  toby.hocking@inria.fr Francis Bach francis.bach@inria.fr INRIA  X  Sierra project-team, D  X epartement d X  X nformatique de l X  Jean-Philippe Vert jean-philippe.vert@mines.org Segmentation and change-point detection problems arise in many scientific domains such as climatology, econometrics, molecular biology, machine learning or signal processing (Bai &amp; Perron, 2003; Braun et al., 2000; Venkatraman &amp; Olshen, 2007; Vert &amp; Bleakley, 2010; Harchaoui &amp; Levy-Leduc, 2008; Tibshirani &amp; Wang, 2008; Gillet et al., 2007). When the data to segment y  X  R d are a 1-dimensional series of length d and the errors are normally distibuted, maximum likelihood inference is constrained least squares: For a given number of segments k there are several efficient algorithms that recover the optimal segmen-tation (Auger &amp; Lawrence, 1989; Bai &amp; Perron, 2003; Jackson et al., 2005; Rigaill, 2010; Killick et al., 2011). However in most applications the number of segments k is not known in advance and needs to be deter-mined from the data. To solve this critical problem, many penalty functions specifically adapted to change-point models have been proposed. For example, there are many different variants of the BIC (Yao, 1988; Lee, 1995; Zhang &amp; Siegmund, 2007), the model se-lection theory of Birg  X e and Massart suggests another penalty (Birg  X e &amp; Massart, 2007; Lavielle, 2005; Lebar-bier, 2005), and Baraud et al. (2009) proposed an-other criterion. The formula of these penalties depend on assumptions such as Gaussianity or independence. These assumptions are often violated in real data, which can lead to selection of a suboptimal model. Hocking et al. (2012) proposed a different approach for selecting the number of segments k : first create a database of change-point annotations, then select a scalar penalty constant that minimizes the change-point detection error. In this article we generalize that approach by learning a multivariate penalty function that agrees with the change-point annotations. Our method proceeds in essentially two steps. In the first step, we pre-process the signals to obtain the best segmentation (1) for several model sizes k , then cal-culate a function E i that maps the penalty value to the annotation error. In the second step, we learn a function f that predicts penalty values which mini-mize the annotation error E i . Since explicitly learn-ing this function involves an intractable optimization, we instead treat it as an interval regression problem and propose a convex relaxation. We solve the result-ing non-smooth optimization problem using accelated proximal gradient methods, which permit efficient in-ference of the support and constants in the penalty function. For a new un-annotated signal, the learned penalty function can predict the optimal number of segments k . Assume we have a set of n annotated training signals. For every training signal i  X  X  1 ,...,n } , let y i  X  R d the noisy signal sampled at positions p i  X  N d i , a vector of positive integers sorted such that p i 1 &lt;  X  X  X  &lt; p As shown in the left panel of Figure 1, the positions p i may not be evenly spaced. Since the points sampled per signal d i is variable, the p 1  X  N d 1 ,...,p n  X  N vectors are not the same size.
 We use pruned dynamic programming (DP) to calcu-for each model size k  X  { 1 ,...,k max } (Rigaill, 2010). The indices where  X  y k i changes are and as shown with vertical black lines in the left panel of Figure 1, change-point positions are estimated using 2.1. Change-point annotations define a As shown in Figure 1, for every signal i , we have a set of regions R i and corresponding annotations A i . Every annotation a  X  A i is a set that specifies the ex-pected number of changes in the corresponding region r  X  R i . The annotation error e i : { 1 ,...,k max } X  R compares the estimated number of changes in each re-gion |  X  P k i  X  r | to the annotated number of changes a using the zero-one loss: For every signal i , we define the optimal number of segments as where the penalty g is a function of the segmentaton  X  y i and some features x i  X  R estimated variance. The problem we tackle in this ar-ticle is to use the n annotated signals to learn the best penalty g for change-point detection, defined as: We will consider penalty functions g that factorize as a model complexity term h ( X  y k i ,x i ) that is given, and a smoothing term  X  = exp f ( x i ) that we want to learn: the smoothing term to be positive. Many existing penalties can be written in this form (see Table 1), and it allows efficient learning by first calculating an exact representation of The function  X  k i : R +  X  X  1 ,...,k max } is used to select the number of segments for signal i . In the right panel of Figure 1, we show one function  X  k i , and its corre-sponding annotation error E i : R +  X  R + , defined as signal Note that  X  k i and E i are non-convex, piecewise con-stant functions that can be efficiently calculated prior to learning, using Algorithm 1 in Section 4.1. By definition, for a given model complexity term h , we have the following relation between the annotation error functions: Rewriting learning problem (6) using E i , we obtain 2.2. Affine smoothing functions We need to specify what kind of smoothing function f : R m  X  R we will learn. Although non-parametric models such as k -nearest neighbors could be used, there are several interesting penalties defined by sup-posing that f is affine, f ( x i ) = w 0 x i +  X  . This results in the following model selection criterion:  X  In Table 1, we compare several model selection criteria that are special cases of (12).
 For example, the well-known BIC due to Schwarz (1978) uses h ( X  y k i ,x i ) = k log d i as a complexity term, and the smoothing term exp f ( x i ) = 1 contains no parameters to learn. Instead, we can use a difference-based estimator of signal variance  X  i (Hall et al., 1990), and take x i = log  X  i . Then we can learn  X ,w 1 in the corresponding smoothing term exp f ( x i ) =  X  X  w 1 i . A similar criterion was suggested by Lebarbier (2005), and its complexity is k log(2 log( d i /k ) + 5). Again we can learn a smoothing term that depends on the noise  X  , which corresponds to choosing x i = log  X  i . As another example, Zhang &amp; Siegmund (2007) pro-posed a modified BIC (mBIC) which has a model com-plexity term of the form P r log( n r ) + (2 k  X  1) log( d where n r is the length of a segment. A default smooth-ing term with no parameters to learn is implemented in the uniseg function of R package cghseg (Picard et al., 2012). Our approach can also be used with model complexity terms of this form. If we take two features x i = log  X  i log d i , that implies a smoothing term  X  =  X  X  w 1 i d w 2 i .
 However, inferring the optimal weights w and inter-cept  X  in all these models involves an intractable op-timization. Since the annotation error E i is piecewise constant, the minimization in problem (11) can only be accomplished via exhaustive search. For one or two features this may be feasible using grid search. But for multivariate models, grid search is very inefficient. So instead of minimizing the annotation error E i directly, we propose a convex relaxation in the next section that yields an efficient interval regression algorithm for find-ing the optimal model parameters. In this section, we develop a surrogate loss l i that is a convex relaxation of the annotation error E i . In particular, we propose to make learning problem (11) tractable using these two modifications:  X  Instead of minimizing E i (  X  ) directly, we define  X  We replace the non-convex annotation error E i 3.1. The interval regression problem Recall that the goal is to learn exp f ( x i ) =  X  to mini-mize the annotation error E i (  X  ), which is a piecewise constant function that can be calculated exactly us-ing Algorithm 1. So a perfect function f would verify exp f ( x i ) = arg min  X  E i (  X  ) for all signals i . Thus we define the target interval ( L i , L i ) as the largest interval such that  X   X  = arg min  X  E i (  X  ) for all log  X   X   X  ( L The target interval may be closed as shown in the right i  X   X  R i  X   X  R d i  X   X  R d i  X   X  R w +  X  }  X  = log  X   X  R ,w  X  R m x i  X  R m panel of Figure 1, or open ( L i =  X  X  X  or L i =  X  ), as shown in the top 2 functions in Figure 3.
 regression problem since predicting any value in the target interval has the same minimal error.
 There is an equivalent geometric interpretation of the learning problem in terms of the target interval. In the middle panel of Figure 3 we plot the target intervals ( L i , L i ) as a function of one feature, a variance esti-mate x i = log  X  i . Geometrically, the learning problem corresponds to finding a line f that intersects each of the target intervals.
 Another interpretation is shown in the bottom panel of Figure 3, where we plot just the limits L i , L i of the target interval. The learning problem corresponds to finding a line f that separates the two classes of points. 3.2. Maximum margin regression line for If there are few data as in Figure 2, then it may be possible to find a regression function f ( x i ) = w 0 x i the data are separable, and in fact there are infinitely many functions f that satisfy these criteria. However, for learning it is best to use the max margin separator: Since the objective and the constraints are linear, this is a linear program (LP), so any LP solver can be used. annotation error E variance estimate feature variance estimate feature The regression function found by solving problem (13) for a small separable data set with 1 feature is shown in Figure 2. It is important to note that the geometric in-terpretation of the margin is not the same as the usual Support Vector Machine for binary classification. In fact, the margin is the distance along the log  X  axis be-tween the regression line and the closest limits L i , L i However, any sizable real data set will not be separa-ble. So in the next section, we develop a surrogate loss for interval regression on non-separable data sets. 3.3. Surrogate loss for non-separable data We relax the annotation error E i in the L = log  X  space, and consider the class of surrogate loss functions l : R  X  R + defined by where the binary classification surrogate loss function  X  : R  X  R + is a convex upper bound of the zero-one loss. The parameter  X  &gt; 0 controls the size of the margin, and we used  X  = 1 since that worked well in the data we analyzed. Using the hinge loss for  X  results in a surrogate loss similar to the -insensitive loss used for Support Vector Regression (Vapnik et al., 1997). Some other choices for  X  include log and Huber losses, but we used the squared hinge loss since it exhibited the best empirical performance: Note that l i is convex since it is the sum of two con-vex functions. This convex relaxation can clearly be seen in the top panel of Figure 3, where we plot the surrogate loss l i along with the annotation error E i for several signals i . Let the average surrogate loss be For each signal i we have features x i  X  R m . When m is large we can encourage a sparse weight vector w by using an ` 1 penalty, which yields the optimization problem where  X   X  R + is a fixed value that controls the degree of regularization. Note that the ` 1 norm encourages some entries of w to be exactly zero, which has the ef-fect of selecting which features are used in the penalty function f ( x i ) = w 0 x i +  X  . Recall that using pruned DP we obtain  X  y k i for k  X  { 1 ,...,k max } , and we use (4) to calculate the anno-tation error e i ( k ). For every signal i we then need to recover the functions  X  k i and E i so we can calculate the target intervals ( L i , L i ) and the surrogate loss l i we discuss how to calculate the exact functions  X  k i ,E i then we discuss surrogate loss optimization. 4.1. Exact annotation error as a function of  X  For a given signal i , number of segments k and model complexity h , crit k i (  X  ) = || y i  X   X  y k i || 2 2 +  X h ( X  y affine function of  X  . Thus  X  k i (  X  ) = arg min k crit the minimum of a finite set of affine functions, which we calculate exactly using path-following Algorithm 1. The result is a list of  X  values for which there is a change in the optimal number of segments  X  k i . We use the following Lemma to exclude some model sizes k 0 that will never be selected using  X  k i . Lemma 1. If k 0 &lt; k and h ( X  y k i ,x i )  X  h ( X  y k 0 for all  X   X  0 , we have  X  k i (  X  ) 6 = k 0 .
 Thus k 0 6 = arg min k crit k i (  X  ) =  X  k i (  X  ). The complexity of Algorithm 1 is O ( k 2 max ). First, the initial set of plausibleK is defined using Lemma 1. Each iteration of the while loop finds the smallest  X  for which k  X  plausibleK is preferred over the current k c . The result is an exact representation of the piecewise constant function  X  k i via its breakpoints k, X  . We then Algorithm 1 Exact recovery of  X  k i k c  X  max { plausibleK } plausibleK  X  plausibleK \ k c while plausibleK 6 =  X  do end while Output:  X  k i represented by breakpoints k c , next  X  . use definition (8) to recover the annotation error E i . 4.2. Surrogate loss optimization using FISTA The learning problem (17) is to find the affine func-tion f ( x i ) = w 0 x i +  X  that minimizes the sum of a non-smooth convex penalty and a smooth convex sur-rogate loss. So we can solve it using proximal gradient methods such as FISTA, a Fast Iterative Shrinkage-Thresholding Algorithm (Beck &amp; Teboulle, 2009). We need the partial derivatives of the surrogate loss:  X   X   X   X   X  w j where the derivative of the squared hinge loss is The proximal operator p  X  : R m +1  X  R m +1 is where s  X  is the soft-thresholding function and  X  is a Lipschitz constant of the smooth loss (Beck &amp; Teboulle, 2009). We use a constant  X  = m + is heuristic but worked well on the data we analyzed. Importantly, the assumptions of FISTA are satisfied, since the squared hinge loss is indeed Lipschitz contin-uous (Flamary et al., 2012).
 After each application of the proximal operator, we check for approximate subdifferential optimality: and for every feature j  X  X  1 ,...,m } , for some positive constant &gt; 0 that controls how far we are from an optimal solution. For learning it is not necessary to take a very small (Bottou &amp; Bousquet, 2008), and we found that = 10  X  3 is sufficient. We analyzed 3 data sets of annotated neuroblastoma DNA copy number profiles (Table 2). These data come from a set of 575 chromosomal copy number profiles of tumors taken from children when they were diag-nosed. In these data, accurate change-point detection is crucial in order to precisely characterize the genetics of these tumors.
 We defined model complexity as the number of seg-ments h ( X  y k i ,x i ) = k , which corresponds to a Lavielle penalty (Table 1). We used Algorithm 1 to calculate target intervals for 3 annotation data sets based on the neuroblastoma data, and for our annotation of some simulated data. In Figure 4, the scatterplots of target intervals show a clear dependence on the estimated noise  X  i , which is not modeled using the state-of-the-art cghseg.k model (Hocking et al., 2012).
 5.1. Annotation protocols Our penalty learning algorithms rely on the quality of the annotations, which come from either prior knowl-edge or expert visual inspection. We consider four annotation data sets (Table 2), constructed using two protocols for expert visual annotation:  X  (Systematic) For the  X  X riginal X  annotations, a  X  (Any) For the other annotation data sets, the We include these details because we conjecture that the ability of the learning algorithm may be limited by the annotation protocol. 5.2. Accuracy of annotations in simulations To assess the quality of the visual annotations, we sim-ulated Gaussian signals with different segment length, noise and change size, and annotated them using the Any protocol. By comparing the latent signal in the simulation with the manual annotations, we observed the following results:  X  Out of 697 regions annotated to have 1 change- X  Out of 147 regions annotated to have no change- X  These false-negative changes had a low signal to One may fear that the Any protocol would result in a database of  X  X asy X  annotated changes with a high signal-to-noise ratio. However, we did not observe that when comparing the distribution of annotated changes to the distribution of all changes (t-test, KS-test, and Wilcoxon test). So we concluded that visual annota-tions are indeed useful for recovering significant, de-tectable change-points. 5.3. Learned penalty functions We learned penalty functions on each of the four data sets (Table 2) using four models (Table 3). Recall the Lavielle model from Table 1: We compared 3 un-regularized versions of this model, and one ` 1 -regularized model with 117 features. The cghseg.k model uses 0 features, takes w 1 = 0 and w 2 = 1, then learns  X  by solving (11) with grid search (Hocking et al., 2012).
 The log.d model uses 1 feature log d i , takes w 1 = 0, and learns w 2 and  X  by minimizing the un-regularized surrogate loss (16).
 The log.s.log.d model uses 2 features log d i , log  X  i and learns w 1 ,w 2 , X  by minimizing the un-regularized sur-rogate loss. We report the coefficients learned in this model in Table 2, and it is interesting to note that the coefficients are clearly not the same across data sets. In Table 2 the optimal penalty for the original data contains a d 0 . 96 i term. This is in agreement with the observation that the cghseg.k model has a d 1 i term and works well in these data (Hocking et al., 2012). In Table 2 it is clear that w 1 6 = 2, which means the penalties do not contain the  X  2 i term that is suggested by model selection theory. This is evidence that the-oretical arguments are not sufficient for good change-point detection in real data, as measured by visual annotations.
 L1-reg constructs a feature vector x i  X  R 117 consist-ing of features such as variance estimates, signal size measurements ( d i , log d i , ...), model RSS and MSE, and indicator variables for each chromosome. We use points d i noise w 1 points w 2 intercept  X  V -fold cross-validation to pick the regularization  X  . For each training set we first form the standardized features X  X  R n  X  m to solve problem (17) with a small  X  &gt; 0. After finding an optimal solution, we increase  X  and use a warm restart to find the next optimal so-lution in the path. We stop after finding a  X  for which all coefficients w j = 0. The model that gives mini-mal annotation error on test fold v is saved as  X   X  v , and finally we take the mean across folds: P V v =1  X   X  v /V . 5.4. Change-point detection accuracy We used cross-validation to compare the four mod-els, and the test annotation error is shown in Table 3. First, the standard BIC and mBIC model selection cri-teria do not use the change-point annotations, so yield error rates much higher than the other models. The only exception is the mBIC in the simulated data set, which is expected since the theoretical conditions of the mBIC are perfectly met in that case.
 The log.d model that minimizes the surrogate loss shows comparable performance to cghseg.k, which uses grid search to directly minimize the non-convex an-notation error E i . Both of these methods ignore the noise  X  i , so in general yield sub-optimal change-point detection. The only exception is the high.density data set, in which all learning methods perform about the same, since the noise is relatively uniform (Figure 4 and Table 2).
 Table 3 also shows that the 117-feature L1-reg model performs comparably to the 2-feature log.s.log.d model. This suggests that the signal noise  X  i and num-ber of points d i are sufficient to learn a penalty for optimal change-point detection in these data sets. However, training the L1-reg model is very time-consuming since an internal cross-validation loop is used to select the degree of regularization  X  . So to quickly learn a penalty for data like these, we suggest learning the log.s.log.d model (24) by minimizing the un-regularized surrogate loss (16). We proposed a method to learn an optimal penalty function for change-point detection in databases of annotated signals. Our approach can accomodate most existing model complexity terms (Table 1), and chooses the smoothing term by minimizing a margin-based convex surrogate loss using FISTA. Using our method, one uses an annotation database to tune the parameters of his favorite model selection criterion, yielding penalty terms which are different from those motivated using theoretical arguments (Table 2). We showed that learning the penalty function using this method results in state-of-the-art change-point de-tection in several databases of annotated DNA copy number profiles. In particular, standard criteria such as BIC ignore the annotation data so perform much worse than the models we learned (Table 3).
 For even better performance, one could use grid search on the support of w found with the L1-reg model to directly optimize the annotation error E i rather than the surrogate loss l i . Also, it should be straightforward to apply the kernel trick to learn a penalty which is a non-linear function of the input features. Finally, we may be able to derive efficient algorithms by ex-ploring the duals of the separable and non-separable max-margin interval regression problems.
 For future work, we are considering more general penalty functions. For example, Lebarbier (2005) pro-posed k ( c 1 log( d i /k ) + c 2 ) and calibrated c 1 = 2 and c = 5 using a large set of simulated signals. It is rea-sonable to think that these values of c 1 and c 2 are not optimal for real data and one would like to learn these c , c 2 from a database of annotated signals. To learn these more general penalties we are exploring multi-dimensional interval regression.
 Acknowledgements: This work was supported by grants DIGITEO-BIOVIZ-2009-25D, SIERRA-ERC-239993, SMAC-ERC-280032, ANR-09-BLAN-0051-04. Auger, I E and Lawrence, C E. Algorithms for the op-timal identification of segment neighborhoods. Bul-letin of mathematical biology , 51(1):39 X 54, 1989. Bai, J. and Perron, P. Computation and analysis of multiple structural change models. J. Appl. Econ. , 18:1 X 22, 2003.
 Baraud, Y., Giraud, C., and Huet, S. Gaussian model selection with unknown variance. Ann. Statist. , 37 (2):630 X 672, 2009.
 Beck, A. and Teboulle, M. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM J. Imaging Sciences , 2(1):183 X 202, 2009. Birg  X e, L. and Massart, P. Minimal penalties for gaus-sian model selection. Probability Th. and Related Fields , 138:33 X 73, 2007.
 Bottou, L  X eon and Bousquet, Olivier. The tradeoffs of large scale learning. In Platt, J.C., Koller, D.,
Singer, Y., and Roweis, S. (eds.), NIPS , pp. 161 X  168. 2008.
 Braun, J. V., Braun, R. K., and Muller, H. G. Multiple changepoint fitting via quasilikelihood, with appli-cation to DNA sequence segmentation. Biometrika , 87(2):301 X 314, June 2000.
 Flamary, R., Jrad, N., Phlypo, R., Congedo, M., and
Rakotomamonjy, A. Mixed-norm regularization for brain decoding. HAL tech. report 00708243, 2012. Gillet, O., Essid, S., and Richard, G. On the correla-tion of automatic audio and visual segmentations of music videos. IEEE Trans. Cir. and Sys. for Video Technol. , 17(3):347355, March 2007.
 Hall, P., Kay, J. W., and Titterinton, D. M. Asymp-totically optimal difference-based estimation of vari-ance in nonparametric regression. Biometrika , 77 (3):521 X 528, January 1990.
 Harchaoui, Zaid and Levy-Leduc, C  X eline. Catching change-points with lasso. In Platt, J.C., Koller, D.,
Singer, Y., and Roweis, S. (eds.), NIPS , pp. 617 X  624. MIT Press, Cambridge, MA, 2008.
 Hocking, T.D., Schleiermacher, G, Janoueix-Lerosey,
I., Delattre, O., Bach, F., and Vert, J.-P. Learn-ing smoothing models using breakpoint annotations. HAL technical report 00663790, 2012.
 Jackson, B., Scargle, J.D., Barnes, D., Arabhi, S., Alt, A., Gioumousis, P., Gwin, E., San, P., Tan, L., and
Tsai, Tun Tao. An algorithm for optimal partition-ing of data on an interval. IEEE Signal Processing Letters , 12(2):105 X 108, February 2005.
 Killick, R., Fearnhead, P., and Eckley, I. A. Opti-mal detection of changepoints with a linear compu-tational cost. arXiv:1101.1438 , January 2011. Lavielle, M. Using penalized contrasts for the change-point problem. Sig. Proc. , 85(8):1501 X 1510, 2005. Lebarbier, E. Detecting multiple change-points in the mean of gaussian process by model selection. Signal Processing , 85:717 X 736, 2005.
 Lee, C.-B. Estimating the number of change points in a sequence of independent normal random variables. Statist. Proba. Lett. , 25(3):241 X 8, 1995.
 Picard, Franck, Hoebeke, Mark, Lebarbier, Emi-lie, Miele, Vincent, Rigaill, Guillem, and Robin, Stephane. cghseg: Segmentation methods for array CGH analysis , 2012. R package version 1.0.1. Rigaill, G. Pruned dynamic programming for optimal multiple change-point detection. arXiv:1004.0887, 2010.
 Schwarz, G. Estimating the dimension of a model. Ann. Statist. , 6(2):461 X 4, 1978.
 Tibshirani, Robert and Wang, Pei. Spatial smoothing and hot spot detection for CGH data using the fused lasso. Biostatistics , 9(1):18 X 29, January 2008. Vapnik, V., Golowich, S., and Smola, A. J. Support vector method for function approximation, regres-sion estimation, and signal processing. In Mozer,
M. C., Jordan, M. I., and Petsche, T. (eds.), NIPS , pp. 281 X 287, 1997.
 Venkatraman, E S and Olshen, Adam B. A faster cir-cular binary segmentation algorithm for the analysis of array CGH data. Bioinformatics , 23(6):657 X 663, March 2007.
 Vert, Jean-Philippe and Bleakley, Kevin. Fast detec-tion of multiple change-points shared by many sig-nals using group LARS. In Lafferty, J., Williams, C. K. I., Shawe-Taylor, J., Zemel, R. S., and Cullota, A. (eds.), NIPS , pp. 2343 X 2351, 2010.
 Yao, Y.-C. Estimating the number of change-points via Schwarz X  criterion. Statistics &amp; Probability Let-ters , 6(3):181 X 189, February 1988.
 Zhang, N. R. and Siegmund, D. O. A modified Bayes information criterion with applications to the analy-sis of comparative genomic hybridization data. Bio-
