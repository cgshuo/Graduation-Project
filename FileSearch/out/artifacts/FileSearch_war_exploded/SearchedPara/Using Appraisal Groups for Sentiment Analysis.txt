 Little work to date in sentiment analysis (classifying text s by  X  X ositive X  or  X  X egative X  orientation) has attempted to u se fine-grained semantic distinctions in features used for cla s-sification. We present a new method for sentiment classifi-cation based on extracting and analyzing appraisal groups such as  X  X ery good X  or  X  X ot terribly funny X . An appraisal group is represented as a set of attribute values in several task-independent semantic taxonomies, based on Appraisal Theory. Semi-automated methods were used to build a lexi-con of appraising adjectives and their modifiers. We classif y movie reviews using features based upon these taxonomies combined with standard  X  X ag-of-words X  features, and repor t state-of-the-art accuracy of 90.2%. In addition, we find tha t some types of appraisal appear to be more significant for sentiment classification than others.
 I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing X  Text analysis ; H.3.1 [ Information Storage and Re-trieval ]: Content Analysis and Indexing X  Linguistic process-ing ; H.3.3 [ Information Storage and Retrieval ]: Infor-mation Search and Retrieval X  Information filtering Algorithms,Experimentation Opinion Mining, Sentiment Analysis, Text Classification, Shallow Parsing, Review Classification, Appraisal Theory
Recent years have seen a growing interest in non-topical text analysis, in which characterizations are sought of the opinions, feelings, and attitudes expressed in a text, rath er than just the facts. The recent AAAI Spring Symposium on Exploring Attitude and Affect in Text [17], with over 60 attendees, reflects the growing importance of this area of research. A key problem in this area is sentiment classifica-tion , in which a document is labelled as a positive ( X  X humbs up X ) or negative ( X  X humbs down X ) evaluation of a target ob-ject (film, book, product, etc.). Immediate applications in -clude data and web mining, market research, and customer relationship management.

A primary testbed task for sentiment classification has been the classification of movie reviews. Reviews offer an in-teresting and difficult test case for sentiment analysis. Opi n-ions are expressed in many complex ways (including sarcasm and metaphor), and there is much unrelated and potentially misleading text such as plot synopses.

To date, most work on sentiment analysis has relied on two main approaches. The first ( X  X ag of words X ) attempts to learn a positive/negative document classifier based on oc -currence frequencies of the various words in the document; within this approach various learning methods can be used to select or weight different parts of a text to be used in classification. The other main approach ( X  X emantic orien-tation X ) classifies words (usually automatically) into two classes,  X  X ood X  and  X  X ad X , and then computes an overall good/bad score for the text.

However, such approaches miss important aspects of the task. First, a more detailed semantic analysis of attitude e x-pressions is needed, in the form of a well-designed taxonomy of attitude types and other semantic properties (as noted by Taboada and Grieve [18]). Second, the  X  X tomic units X  of such expressions are not individual words, but rather ap-praisal groups : coherent groups of words that express to-gether a particular attitude, such as  X  X xtremely boring X , o r  X  X ot really very good X .

This paper addresses both of these issues directly, by fo-cusing on the extraction and analysis of adjectival appraisal groups headed by an appraising adjective (such as  X  X eautiful X  or  X  X oring X ) and optionally modified by a sequence of mod-ifiers (such as  X  X ery X ,  X  X ort of X , or  X  X ot X ). We have adopted taxonomies for the attributes of such expressions from Mar-tin and White X  X  Appraisal Theory [10], developed within the tradition of Systemic Functional Linguistics [6]. We built a lexicon using semi-automatic techniques, gathering and cl as-sifying 1329 adjectives and modifiers to categories in sever al taxonomies of appraisal attributes. We heuristically extr act adjectival appraisal groups from texts and compute their attribute values according to this lexicon. Documents were Figure 1: Main attributes of Appraisal and their highest-level options. then represented as vectors of relative frequency features computed over these groups and a support vector machine learning algorithm [3] was used to learn a classifier discrim -inating positively from negatively oriented test document s.
We have applied this approach to movie review classifi-cation with positive results. Despite the low coverage of our current lexicon, adjectival appraisal group features a lone give decent classification performance (78%). When cover-age is improved by the simple expedient of adding in simple bag of words features, classification accuracy reaches 90%, higher than previously published results.
Appraisal denotes how language is used to adopt or ex-press an attitude of some kind towards some target. For example, in  X  X  found the movie quite monotonous X , the speaker (the Appraiser ) adopts a negative Attitude ( X  X onoto-nous X ) towards  X  X he movie X  (the Appraised ). Note that atti-tudes come in different types; for example,  X  X onotonous X  de-scribes an inherent quality of the Appraised, while  X  X oathe d X  would describe the emotional reaction of the Appraiser.
A full appraisal expression is thus a piece of text (usually a clause, but possibly larger) expressing appraisal of some sort. Appraisal expressions are the basic  X  X toms X  for analy sis of how attitudes are expressed in a text, and so extracting them is the basic task for appraisal analysis. By analogy to information extraction, we consider representing an ap-praisal expression as a frame filled with several slot values , giving (at least) the Appraiser, Appraised, Appraisal Type , and Orientation (positive/negative). For example, apprai sal in the sentence could be represented by the frame
Clearly, extracting all of this information accurately is a difficult process, requiring identifying who is talking abou t what in potentially complex texts (not to mention the need for coreference resolution, which is far from solved). We therefore first address a useful but simpler problem, that of extracting appraisal groups , defined as those groups and phrases in a text giving what kind and intensity of appraisal is expressed. We consider in this paper extraction of a main type of appraisal group, adjectival appraisal groups, which give good classification results despite seemingly low cov-erage in the corpus. We thus expect future inclusion of nominal ( X  X  total mess X ) and verbal ( X  X bsolutely loved X ) appraisal groups to further improve results.
Our first goal is to extract appraisal groups, from which we then derive useful features for machine learning. Follow -ing Martin and White [10], we will assign four main types of attributes (Fig. 1) to appraisal groups: Attitude, Orien -Attitude gives the type of appraisal being expressed as ei-Orientation is whether the appraisal is positive or negative Graduation describes the intensity of appraisal in terms Polarity of an appraisal is marked if it is scoped in a po-
From this perspective, most previous sentiment classifi-cation research has focused exclusively upon Orientation, with Attitude type addressed only indirectly, through the use of bag-of-words features. An exception is Taboada and Grieve X  X  [18] method of automatically determining top-lev el attitude types via application of of Turney X  X  PMI method [19 ]. They observed that different types of reviews contain differ-ent amounts of each attitude-type. grammatical notion  X  X xplicit negation of a quality or asser -tion within the scope of the particle  X  X ot X  or the equivalent  X ; note that this term has also been used in the literature to mean what we refer to as Orientation.
An appraisal group (in English) comprises a head adjec-tive with defined attitude type, with an optional preceding list of appraisal modifiers , each denoting a transformation of one or more appraisal attributes of the head. For example,  X  X ot extremely brilliant X , has head  X  X rilliant X  and modifie rs  X  X ot X  and  X  X xtremely X . We take advantage of typical English word-ordering and use all pre-modifiers, allowing for inter -vening articles and adverbs. This allows groups such as  X  X ot all that good X  or  X  X ruly a really horrible X , where  X  X ot X  and  X  X ruly X  modify  X  X ood X  and  X  X orrible X , respectively. We tre at modifiers as having nested scope, so that transformations shows the derivation of the appraisal attributes of  X  X ot ver y happy X . Derivation relies on a suitable lexicon of appraisa l attributes, which we describe below. curate, as in  X  X ot even good X  where  X  X ot even X  should be treated as a nested unit, we find that assuming right-nesting is a reasonable approximation for the time being.
We used a semi-automated technique to construct a lex-icon giving appraisal attribute values for relevant terms. A value for each appraisal attribute is stored for each ap-tiful X  reads: (JJR) and superlative (JJS) adjectives are assigned  X  X igh X  and  X  X aximum X  force respectively, though other lexical gra -dations of intensity (e.g.,  X  X ove X  vs  X  X ike X ) are not curren tly addressed.
Modifiers, mostly adverbs, give transformations for one or more appraisal attributes, for example: or polarity modification: Modifiers can affect multiple appraisal attributes at once; e.g.,  X  X eally X  functions both as an intensifier of force and a sharpener of focus.

To build the lexicon, we started with the example words and phrases given for various appraisal options in [10] and [11] as seed terms, using a semi-automated technique to quickly build a lexicon with decent coverage of adjectival appraisal. Modifier seed terms were generated similarly, by finding adverbs collocating with adjective seed terms in our corpus. Candidate expansions for each seed term were gen-WordNet, the members of each synset were taken as the related set; similarly, synonym and related word lists were taken from each thesaurus. Candidates were accepted only with the same part of speech as a seed term.

Candidate lists for all terms in one category were pooled and all candidate terms ranked by frequency of occurrence in the various candidate lists. This provided a coarse rank-ing of relevance, enabling more efficient manual selection. Uncommon words, unrelated words, or words arising from an incorrect sense of the seed term will tend to occur less frequently in the candidate list than those that are related to more of the seed terms and are present in more of the resources. As well as increasing coverage, using multiple thesauri allows for more confidence votes and in practice increases the utility of the ranking.

Each ranked list was manually inspected to produce the final set of terms used. In practice, terms with low confi-dence were automatically discarded, reducing the amount of manual work required. Figure 4 shows a partial example of the expansion and selection process. We note that some element of human subjectivity is inherent in this process; future work will include improving standardization of the lexicon by involving multiple lexicon builders and evaluat -ing inter-rater reliability of attribute assignment.
In total, 1329 terms were produced from 400 seed terms, in around twenty man-hours. This lexicon is by no means complete, but is large enough to investigate the usefulness of this approach. Appraisal adjectives in the lexicon cover 29.2% of adjectives in the testbed corpus, comprising 2.7% of words in the corpus. Note that the appraisal taxonomies used in this work are general purpose, and were not de-veloped specifically for sentiment analysis or movie review classification. Thus we expect appraisal group analysis to be highly portable to other related tasks.
The standard approach to representing documents as mul-tidimensional vectors as input for machine learning tech-niques is to measure the frequency of various text elements http://m-w.com and http://thesaurus.com Figure 4: Example of seed term expansion and manual selection, for Appreciation/Reaction-Impact:Positive. relative to the total number of such elements (words, e.g.) in the text. We follow that method here as well, defin-ing features as various disjunctions of lexical items or ap-praisal group attribute values as defined in our appraisal taxonomies. Raw counts are thus normalized against the This gave us the following feature sets: W:A Words by Attitude  X  Frequency of each adjective S:A Systems by Attitude  X  Total frequency of attitude ad-S:AO Systems by Attitude and Orientation  X  Total fre-G:A Appraisal Group by Attitude  X  Total frequency of ap-G:AO Appraisal Group by Attitude &amp; Orientation  X  Total G:AOF Appraisal Group by Attitude, Orientation, &amp; Force BoW Bag of Words  X  relative frequencies of all words in BoW+G:AO Union of BoW and G:AO.
 BoW+G:AOF Union of BoW and G:AOF.
 The next section describes our results for sentiment classi fi-cation using these various feature sets. within each node of the taxonomy, as in [1, 20], gave inferior results to this simpler procedure. Table 1: Estimated mean accuracy results for differ-ent feature sets using 10-fold cross-validation (CV) and 40 randomized samples (RS); N f eat gives the to-tal number of non-constant features in each feature set. For comparison,  X  X &amp;L-04 X  denotes the best re-sults obtained on this data set by Pang and Lee [14];  X  X &amp;C-03 X  denotes results obtained on the earlier movie review dataset by Mullen and Collier [12] for two feature sets.
To test the usefulness of adjectival appraisal groups for sentiment analysis, we evaluated the effectiveness of the above feature sets for movie review classification, using th e publicly available collection of movie reviews constructe d by Pang and Lee [14]. This standard testbed consists of 1000 positive and 1000 negative reviews, taken from the IMDb as three stars out of five) were removed by Pang and Lee, giving a data set with only clearly positive and negative sentences and decapitalized. We used an implementation of Brill X  X  [2] part-of-speech tagger to help us find adjectiv es and modifiers.

Classification learning was done using WEKA X  X  [23] im-plementation of the SMO [16] learning algorithm, using a linear kernel and the default parameters. It is possible tha t better results might be obtained by using a different kernel and tuning the parameter values, however such experiments would have little validity, due to the small size of the curre nt testbed corpus.
We evaluated sentiment classification accuracy using SMO with default parameters and a linear kernel. Evaluation was performed both using the standard 10-fold cross-validatio n, as well as using a sequence of 40 independently chosen ran-dom train-test partitions of the corpus with 1950 training and 50 test documents per run (enabling statistical test-ing). We trained models and evaluated test set accuracy for each of the feature sets described above. Mean accuracies 6 See http://www.cs.cornell.edu/people/pabo /movie-review-data/ world applicability of results on this dataset. An open re-search issue is how to deal effectively with such documents. for both cross-validation and random sampling are given in Table 1, with mean paired accuracy differences by random sampling in Table 2; significance was measured by two-tailed t -test.

For comparison, Table 1 also lists previous results from two previous studies. Directly comparable is the highest previous accuracy for this dataset, attained by Pang and Lee [14] via a complex combination of  X  X ubjectivity cluster -ing X  and bag-of-words classification for sentiment analysi s. We also show two results from Mullen and Collier [12], the only previous work we are aware of to use something akin to attitude type for sentiment analysis. Unfortunately, th eir results are not directly comparable with ours, as they used an earlier version of the movie review corpus (with only 1380 reviews); we show their results using only Turney Value and Semantic Differentiation features (TVO) as well as their bes t result for that corpus.

First, despite the low coverage of our lexicon, the baseline of using just attitude-bearing adjectives is reasonably hi gh. This bears out our contention that attitude-bearing adjec-tives specifically are a key feature in the expression of sen-timent. Using attitude type and orientation of these terms yields essentially the same accuracy, however. When using appraisal groups, which include the effect of appraisal modi -fiers, we see that using both Attitude Type and Orientation, we get a slightly higher accuracy (however, this is not sig-nificant). The small size of any increase is likely due to the fact that out of 41082 appraisal groups in the corpus, just 751 (1.8%) have their orientation flipped by marked polarity . While the inclusion of Force appears to bring no advantage here, this may be due to the current low granularity of Force and Focus distinctions in our lexicon.

Next, we note that all of the limited-coverage appraisal feature sets are outperformed by standard bag-of-words cla s-sification using all words (BoW), which attains a statisti-cally significant 87.0/87.6% accuracy, competitive with Pa ng and Lee X  X  [14] result on this dataset, based on classifying texts after extracting subjective passages from them. More significantly, we improve clearly on that result (attaining 90.2/90.1% accuracy) by combining appraisal group feature s (Attitude Type and Orientation) with the bag-of-words fea-tures (for coverage), demonstrating how appraisal analysi s helps sentiment classification. This improvement is signifi -cant to a 99% confidence level (see Table 2). Again we note that including Force does not seem to help.

Space does not permit listing all the features for posi-tive and negative documents, so we summarize our findings here. Of the 200 most significant features (100 for each of the positive and negative classes) in the model built from BoW+G:AO, 57 (28%) are systemic features. The vast ma-jority of those (39) are drawn from subtypes of appreciation , with 14 (six positive and eight negative) from judgement and four (three positive and one negative) from affect. Appre-ciation thus appears to be the most central type of atti-tude for sentiment analysis (at least for movie review clas-sification). In addition, while some adjectival features in BoW are included (duplicating work done by G:AO), many BoW features are clearly helping with coverage, including many nouns (e.g.,  X  X ess X ,  X  X cript X ,  X  X othing X ,  X  X ob X ,  X  X ru th X ) and some verbs ( X  X oved X ,  X  X asted X ,  X  X elivered X ), as well as Comparison *= p &lt; 0 . 05 and **= p &lt; 0 . 01 .
An early, and still common, approach to sentiment analy-sis has been to use the so-called  X  X emantic orientation X  (SO ) of terms as the basis for classification [7]. Semantic orient a-tion is derived from corpus-based collocation information ; it is common to use search engines and treat the internet as a very large corpus, estimating SO for terms based on point-wise mutual information with certain anchor terms such as  X  X ood X  and  X  X oor X  [19]. This is equivalent, in our approach, to using just Orientation values, computing a weighted sum for the whole document.

Early attempts at classifying movie reviews used stan-dard bag-of-words techniques with limited success [15]. Th e addition of typed features of semantic orientation has been shown to improve results [12]. Semantic orientation has als o been useful for classifying more general product reviews [1 9]; that work has suggested that product reviews may be easier to classify than movie reviews, as they tend to be shorter and be more explicitly evaluative.

There have been some previous attempts at using a more structured linguistic analysis of text for sentiment class ifica-tion, with mixed results. Mullen and Collier [12] produced features based on Osgood X  X  Theory of Semantic Differentia-tion, using WordNet to judge the  X  X otency X ,  X  X ctivity X , and  X  X valuative X  factors for adjectives. Using these features did not yield any reliable benefit, although it is unclear whethe r this is due to the theory or to its implementation. The same study used a small corpus of music reviews manually annotated for artist and work, and showed that knowing the Appraised can increase performance. Nasukawa and Yi [13] use POS-tagging, chunking, and manual templates to investigate  X  X entiment verbs X  and  X  X entiment transfer ver bs X  and have shown that this approach can aid high-precision analysis. Previous work on including polarity ( X  X ood X  vs.  X  X ot good X ) have given inconsistent results X  X ither a sligh t improvement [15] or decrease [5] from bag-of-word baseline s; our results show it to help slightly.

An additional problem (not addressed in this paper) fac-ing sentiment classification is determining which parts of the text are relevant. Ideally, only subjective text that is expressed by the reviewer and deals directly with the item under review should be kept, but has so far proved difficult to isolate. Subjective use of verbs, adjectives and multi-w ord expressions can be learnt automatically and used to detect itive sentiment. This may indicate that rhetorical struc-ture [9, 1] is also important for understanding sentiment. sentence-level subjectivity [21]. Adjectives play a stron g role in subjective language, especially the class of  X  X radable X  ad-jectives [8] that can take modifiers such as  X  X ery X .
More generally, Wilson et al. [22] have recently addressed learning models for finding opinion clauses and identifying their properties (mainly what we term force and orienta-tion), based on clauses X  lexical and syntactic properties. Us-ing this approach, Pang and Lee [14] have applied a clus-tering approach to extract  X  X ubjective X  passages from text s. They show that classification learning applied to such ex-tracts is more effective than classification based on the enti re document.
We have shown that use of features based on appraisal group analysis can significantly improve sentiment classi-fication, despite the low coverage of our current appraisal lexicon. Our results thus underscore the need to develop de-tailed and varied semantic tools to support sentiment analy -sis. In addition to improved accuracy, such taxonomic fea-tures can provide useful information about how language is used to express sentiment, as we observe above that one type of appraisal ( appreciation ) is more significant for classifying movie reviews. This type of insight is only enabled by a taxonomic analysis of appraisal type.

Our results show that even small hand-built ontologies can be useful, especially in combination with simpler high-coverage methods. Requiring a high level manual interven-tion is not ideal; due to the functional nature of the group-ings, system networks would appear ripe for inference using current statistical thesaurus-building techniques [4]. T his would also allow the construction of domain-specific ontolo -gies, as opposed to the generic lexicon used in this paper.
Without some form of summarization or filtering, per-formance is necessarily limited by the presence of extrane-ous and potentially misleading appraisal in the document. We have made no attempt to include existing methods such as subjectivity summarization or position-based weightin g, which we would expect to provide similar gains as have been seen in prior research.

We believe that the major challenge currently in sentiment analysis is the accurate identification of relevant full Ap-praisal Expressions including the Appraiser and Appraised in addition to appraisal type and orientation. This would enable more fine-grained analysis of the expressions of sent i-ment in a document. As applications requiring text classifi-cation grow to include far more than traditional topic-base d tasks, there is a growing need for a more structured semantic approach to feature extraction and representation. Existi ng linguistic theories such as Appraisal Theory provide possi -ble bases for new textual features which, as we have shown, can improve upon the results of traditional word-based tech -niques. [1] S. Argamon and J. T. Dodick. Conjunction and modal [2] Eric Brill. A simple rule-based part of speech tagger. [3] N. Cristianini and J. Shaw-Taylor. An Introduction to [4] J. R. Curran. Ensemble methods for automatic [5] D. Dave and S. Lawrence. Mining the peanut gallery: [6] Michael A. K. Halliday. Introduction to Functional [7] V. Hatzivassiloglou and K. R. McKeown. Predicting [8] V. Hatzivassiloglou and J. Wiebe. Effects of adjective [9] Daniel Marcu. The rhetorical parsing of unrestricted [10] J. R. Martin and P. R. R. White. The Language of [11] Christian Matthiessen. Lexico-grammatical [12] Tony Mullen and Nigel Collier. Sentiment analysis [13] T. Nasukawa and J. Yi. Sentiment analysis: Capturing [14] Bo Pang and Lillian Lee. A sentimental education: [15] Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. [16] J. Platt. Fast training of support vector machines [17] Y. Qu, J. G. Shanahan, and J. Wiebe, editors. AAAI [18] M. Taboada and J. Grieve. Analyzing appraisal [19] Peter D. Turney. Thumbs up or thumbs down? [20] Casey Whitelaw, Maria Herke-Couchman, and Jon [21] J. Wiebe. Recognizing Subjective Sentences: A [22] Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. [23] Ian H. Witten and Frank Eibe. Data Mining:
