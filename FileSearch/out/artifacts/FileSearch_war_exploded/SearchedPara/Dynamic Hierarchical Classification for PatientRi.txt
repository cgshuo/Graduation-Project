 Congestive Heart Failure (CHF) is a serious chronic condi-tion often leading to 50% mortality within 5 years. Improper treatment and post-discharge care of CHF patients leads to repeat frequent hospitalizations (i.e., readmissions). Accu-rately predicting patient X  X  risk-of-readmission enables care-providers to plan resources, perform factor analysis, and im-prove patient quality of life. In this paper, we describe a supervised learning framework, Dynamic Hierarchical Clas-sification (DHC) for patient X  X  risk-of-readmission prediction. Learning the hierarchy of classifiers is often the most chal-lenging component of such classification schemes. The nov-elty of our approach is to algorithmically generate various layers and combine them to predict overall 30-day risk-of-readmission. While the components of DHC are generic, in this work, we focus on congestive heart failure (CHF), a pressing chronic condition. Since healthcare data is di-verse and rich and each source and feature-subset provides different insights into a complex problem, our DHC based prediction approach intelligently leverages each source and feature-subset to optimize different objectives (such as, Re-call or AUC) for CHF risk-of-readmission. DHC X  X  algorith-mic layering capability is trained and tested over two real world datasets and is currently integrated into the clinical decision support tools at MultiCare Health System (MHS), a major provider of healthcare services in the northwestern US. It is integrated into a QlikView App (with EMR inte-gration planned for Q2) and currently scores patients every-day, helping to mitigate readmissions and improve quality of care, leading to healthier outcomes and cost savings.
Hospital readmissions have come to the forefront of health-care research and discussions in recent years for their rec-ognized universal negative impacts on healthcare systems X  budgets and patient loads throughout the world. Within the United States, Centers for Medicare &amp; Medicaid Services (CMS) recently began using readmission rates as a publicly c  X  reported quality metric to measure hospital care standards and reimbursements in the fee-for-service model 1 . The severity of the readmissions problem can even be measured in economic terms: the estimated cost of unplanned read-missions is roughly $17 . 9 billion per year [8]. A significant percentage of these costs are attributable to patients who are often the sickest and most vulnerable: old, critically ill, and suffering from multiple chronic disease conditions. Paradoxi-cally, more than 27% of such readmissions are avoidable [16]. Hence, predicting risk-of-readmission can guide implemen-tation of appropriate interventions to prevent such avoidable readmissions. To that end, this paper investigates the issues faced and challenges addressed in developing and deploying a framework to predict the risk-of-readmission (RoR) .
While the deployed framework is extensible by design and includes other chronic conditions, in this paper the chronic condition we focus on is Congestive Heart Failure (CHF) since CHF is one of the leading causes of hospitalization. Studies also indicate that a large percentage of CHF ad-missions are actually readmissions within a short window of time. The 2005 data for Medicare beneficiaries estimated that 12.5% of Medicare patients admitted due to CHF were followed by readmissions within 15 days, accounting for about $590 million in healthcare costs [12]. In practice, a window of 30-days after discharge for CHF is considered clinically meaningful for hospitals and medical communities to take action to reduce readmissions [11] and forms the basis of most readmission risk prediction models.

Current research treats the problem as a binary classifi-cation task, where the objective is to identify patients with CHF who are likely to be readmitted within 30 days of dis-charge as an output of a single binary classifier [21, 19, 18]. A patient readmitted within 30 days = 1 and a patient not readmitted within 30 days = 0. There are several short-comings to this approach which we address with the DHC framework: the distribution of risk of readmission is highly skewed with a few patients readmitting repeatedly and many patients readmitting once or twice over a period of a year. Traditional classifiers suffer from majority bias and tend to assign patients to the no 30-day-readmission majority class. Moreover, patient characteristics change over time. New diseases and conditions set in; age and vitals continuously change. Thus, including all patients discharged with CHF in the training set to build the classification model intro-duces noise since patients that were readmitted after a long gap can have characteristics that are very different from pa-http://www.cms.gov tients that were readmitted within a short time (30 days) for the same condition. Hence the team of data scientists and the underlying framework has to handle numerous missing values, discretize attributes, collate comorbidities, extract suitable features and employ the right learning algorithm given the constraints.

This research presents a Dynamic Hierarchical Classifica-tion (DHC) framework to predict RoR for CHF patients. The primary novelty of the solution is to undertake the pre-diction problem in several stages or layers , leading to the formation of a hierarchy of classification models as the over-all solution. Each layer aims at predicting the RoR within certain days (cut-points). For example, it may be better to predict whether a CHF patient is likely to (ever) readmit or not before calculating her readmission risk within 30 days of discharge. Each such logical consideration constitutes a classification layer . Within a given layer, the problem is of a binary classification design layer by layer 2 . Consider a 70 year old female patient suffering from primary diagnosis of congestive heart failure and various associated conditions such as diabetes and renal failure. If at layer one, DHC pre-dicts her to be likely to be readmitted (ever), then the second layer may predict likely to be readmitted within-60-days of discharge (or not). Subsequently, only when she qualifies to be readmitted with a high confidence at both these layers, would the third layer predict her likelihood to be readmitted within 30 days (or not). This may sound simple conceptu-ally, but the challenge of how many layers are sufficient and how to design the intermediate layers remain an open prob-lem. Furthermore, the effectiveness of different features may be different in various layers. Then, the question is, how to select the features? We address this by performing layer specific feature selection. The last challenge is how to per-form effective binary classification in each layer. We propose threshold tuning of the classification models for that.
In spite of algorithmic automation as proposed, it is not easy to design these layers and always get it right. Clinical teams may provide initial guidance but there is no clear clin-ical evidence for how many layers (for decisioning) are ap-propriate for a given patient population or how to define the time-window for readmission cut-points. Naturally, many of these design decisions are also dataset specific, requiring us to discover these layers for a given patient cohort. In this work, we propose an innovative approach: we design mul-tiple algorithms to discover the actual cut-points assuming that the number of layers is specified as an input. In one of our algorithms, we primarily analyze the characteristics of the underlying patient population and propose greedy algo-rithms to design the cut-points such that the two consecutive layers generated by our algorithm exhibit the highest differ-ence in the characteristics of the patient population. We also non-trivially adapt one of the frequency based popular dis-cretization algorithms, Chi-Merge [7] (that is primarily used to discretize continuous attributes based on class distribu-tion), to generate these cut-points. After that, to maximize a particular metric (such as AUC, precision, recall, accu-racy, etc.), we study how to make use of the training data and the trained classification model in a given layer. We propose novel solutions to the above mentioned problems in this work.
We present comprehensive experimental results using two real world datasets -we consider 4 years of the State Inpa-tient Dataset (SID) of Washington State as our large-scale dataset and then we use the real patient dataset provided by MultiCare Health System, a major health system in the northwestern US as the small scale dataset. We empirically evaluate the effectiveness of our proposed solutions with sta-tistical significance analysis using a variety of quality metrics and perform comparative analyses with our hierarchical clas-sifications models against several baseline algorithms. Our results demonstrate that the proposed framework is supe-rior to the baseline algorithms for all quality metrics with statistical significance.

To summarize, we make the following contributions: 1. We initiate the study of designing hierarchical classifi-2. We propose a deployed solution for Dynamic Hier-3. We perform comprehensive experiments using multiple
It is typical in clinical settings for data to be spread across various relational schemas and flat files; a series of (anonymized) patient record data for various windows of time and modali-ties of measurements are typically extracted from EMRs and secondary hospital sources to form a data warehouse with appropriate dimensions and measures. Such a schema con-tains granularities of patient measures related to admission and discharge, other diseases, demographic factors, comor-bidities, and post-discharge and follow-up-plans, which are all integrated and preprocessed. Each encounter is uniquely identified by an admission ID. Multiple admissions (i.e., read-missions) of the same patient are identified by the same pa-tient ID and different encounter ID. For a given patient and a given hospital admission, we can calculate the number of days between the current admission and her previous dis-charge and check if it is less than 30.

Problem definition 1. Given a patient record, the prob-lem of predicting the RoR within  X  days of discharge is a hierarchical classification problem. The intuition here is to first predict the readmission window for higher  X  values be-fore predicting readmission for  X  = 30 days. Each of these time intervals are cut-points, demarcating a classification layer in dynamic hierarchical classification (DHC). Since the 30 day interval is clinically meaningful and tied to reim-bursements, that interval is the last layer of risk scoring and outcomes. Each layer can constitute a specific readmission window (for example the very first layer predicts whether a patient would be readmitted at all or not for  X  &gt; 365 days in a year). Each layer design is to formulate a binary classi-fication model using historical patient data relevant to that interval to predict the RoR within that readmission interval. How many such layers are to be designed, and how to decide the readmission intervals algorithmically, is the key contri-bution of this work and described in depth in Section 4. Figure 1: Overall architecture for RoR prediction process in-
Data exploration, data pre-processing, hierarchical classi-fication model, and model evaluation are critical for a suc-cessful data mining framework, especially at healthcare do-main [21, 19, 18]. Figure 1 provides an overview of these major steps. For the DHC framework design we worked closely with cardiologists, nurse practictioners, and other members of the care team to identify critical factors influ-encing early recurrent readmission. The robustness of these factors and their availability at various points in the care process was an important DHC design consideration.
Prior research efforts have focused on the accuracy of mod-eling to predict the likelihood of patients with chronic condi-tions to readmit within 30 days[15]. Commercial efforts have been limited and mostly restricted to web based mortality tools or risk calculators where data is manually entered to compute the risk. To the best of our knowledge, ours is the first cloud based scalable EMR integrated effort reported in literature that uses data mining fundamentals to continu-ously monitor risk of patients and issue risk scores to care providers. We have enabled the platform to deliver the per-patient readmission risk score along with actionable insights, not solely as a business intelligence tool sourced from a data warehouse (see 3.1), but on real-time clinical data, delivered within the clinical workflow, at the point of care.
The DHC framework consists of three main components: a) External Layer, b) Communications Layer, c) Analytics Layer. Within these layers there are multiple subcompo-nents and processes which are tightly integrated in order to accurately and efficiently score patients for 30 day risk of readmission and deliver these risk profiles to the patients electronic medical record (EMR).
The initial deployment scenario envisioned was a single layer binary classifier exposed through a QlikView Read-mission App 3 . This would provide system-wide readmission visualization and reporting with facility level, cohort level, and patient level drill down capability. Additionally, the QlikView Readmission App was used to identify and flag patients (within targeted risk categories) for further investi-gation and focus. It enables exploration of a detailed patient risk profile (30 day risk of readmission score targeting clin-ical attributes, psychosocial factors, a composite score, and top contributing factors). With the development of the DHC framework, the QlikView risk scores are now computed by the hierarchical classification with algorithmic multi-layer design. A spapshot of the application is presented in Fig-ure 2.

Every night it scores discharged patients and creates a ranked list of readmission risk for further review.
Business intelligence tools 3.1 are useful for population level reporting and risk management but are not oriented to-wards the clinical workflow and have limited adoption within that context. To fully leverage our developed framework for CHF readmissions, cardiovascular service line leadership recognized the need to deploy DHC directly into their EMR (Epic).

After extensive user research, the team identified two tar-get Epic integration points: 1) the Heart Failure Dashboard, used by cardiology to see the overview of the patients and help drive interventions during the encounter, 2) Care Man-agement Doc Flowsheet, used to support discharge planning (which begins when the patient is admitted) and bring focus to psychosocial factors and followup care.

The EMR integration roadmap consists of: 1) publishing of a single combined score (clinical + psychosocial) as a  X  X e-sult X  4 in Epic, 2) subcomponents of that result to include discrete clinical and psychosocial scores.
DHC is available as an on premise deployment or as a series of services hosted on Microsoft Azure. The overall ar-chitecture of the system and flow of messages are illustrated in Figure 3.
We now return to our example of a 70 year old female patient. She has been admitted to the inpatient setting and within 24 hours her lab results become available. As her medical record within Epic is updated, an HL7 message 5 containing the relevant attributes is generated. This mes-sage is then sent from the External Layer (a) to the Com-munications Layer (b). For cloud deployments, where the data does not stay fully resident within the health system, the tuple of patient data is passed through an anonymization service, which sends only the attributes (+GUID) required for scoring to the API [15].

The HL7 message is then ingested by Mirth Connect ser-vice 6 which handles message queuing and translation from HL7 into JSON, used internally by the DHC Enabled Model Bank. For native JSON requests (such as from a mobile de-vice), we would bypass Mirth Connect [15].

After ensuring proper formatting and consumption of the message, it is passed to the Analytics Layer for scoring. We use the Zementis ADAPA Scoring Engine 7 and the DHC Enabled Model Bank. The use of ADAPA brings multiple benefits, among these the ability to scale up to handle a very large volume of messages, as well as the ability to import multiple models (beyond those we have developed for CHF), allowing us to score patients against a number of chronic disease conditions. Additionally, the DHC supports auto selection of cut-points, where the model is trained against MultiVariate Health Data sources outlined in Figure 3 (the significance of this is outlined in Section 4). When a patient tuple is passed to the APIs provided by the ADAPA scoring engine, it is scored against the DHC Model which has been trained for a particular cohort, such as CHF Post-Discharge.
A risk profile, consisting of a risk score as described next in section 4.3 and top correlated factors (identified using Chi-Square test) that contribute to readmission risk, is then generated and returned back to the Communications Layer. In the case of Epic deployment, the JSON response is con-verted back into HL7 for consumption. This is then returned to the anonymization service, where the risk profile is recou-pled with the patient identifier, attached to the patient visit, and published as a result within Epic. Figure 4: Tree-based hierarchical class structure for predicting
We propose Dynamic Hierarchical Classification (DHC) to predict the risk of readmission within 30 days, transform-ing the problem into a tree-structured class hierarchy. Our approach produces a hierarchical set of classifiers in top-down fashion. The hierarchical setting provides the oppor-tunity to make more specific and accurate predictions and improve knowledge about the problem using factor analy-sis (Chi-squared test). The framework also allows flexible choices of classifiers at different layers. As the distribution of data changes at each layer, DHC allows us to use the best classifier to optimize different learning objectives for each layer.

For our problem (i.e., predicting 30-day RoR), the hier-archical classification task could be restated as follows: first predict if a patient would ever be readmitted or not. For that task, a binary prediction model is designed using ap-propriate training data. Then, in the intermediate layers, a set of classifiers needs to be designed with each constituting a particular readmission window. Each of these is a subtask towards predicting RoR with a specific time window (cut-point). We design binary classification models for each of these intermediate layers. For simplicity, we assume that the number of intermediate layers is predefined and given The final layer of the classification is to predict whether a patient would be readmitted within 30 days or not. Similar to all previous layers, this sub-task is also treated as a binary classification problem and the appropriate training dataset is used for that purpose.
For the purposes of illustration, Figure 4 describes the overall process of predicting 30-day RoR using 1 intermedi-ate layer. The framework involves three stages: Readmis-sion Stage , Internal Stage , and 30-day Readmission Stage . Even though the number of layers in the internal stage are given, we still have to identify the appropriate readmission windows, i.e., cut points for those layers. Our proposed so-lutions to design cut-points are described in Section 4.2. Algorithm 1: DHC Algorithm
Algorithm 1 formalizes the DHC framework. Similar to the multistage screening in medical practice, we impose a maximum error bound while maximizing the recall and pre-cision at different stages. The error bound (i.e. false positive rate) is determined by domain experts. Table 1 provides a tabular view of Readmission Stage , Internal Stage , and 30-day Readmission Stage .
The first Readmission stage predicts whether a patient will be readmitted at all after being discharged from the hospital. The learning objective is to maximize AUC and recall [7] in order to capture all patients with readmission risk. The maximum false positive rate is set to be 50%. Since this is the root (very top level) of the hierarchical classification model, the goal is to filter out patients who are unlikely to be readmitted.
The objective is to maximize AUC and recall while con-trolling the false positive rate to be lower than 50%. We build N internal layers and, for each layer, derive a cutoff day k . Even when N is a given integer number, we still have to determine N different readmission windows (cut-points). Intuitively, what we intend to do is to choose those cut-points, such that, if one can create N non-overlapping partitions of the entire patient population based on those cut-points, patients that fall across the stratum are as divergent as possible . We propose a heuristic algorithm towards that end which iteratively creates N different cut-points.
Algorithm 2 describes the hill climbing search heuristic to identify a single cutoff day k that constitutes a layer. With-out loss of generality, to find a cut-off day k between a time window ( m,n ) (note that if N = 1, then m = 31, n = Max , where, for a given dataset D , the highest readmission day is denoted to be Max ), we call a pseudo-random number gen-erator between ( m,n ) to get a k , such that m &lt; k &lt; n . We select two candidate cut-points: k 0 = k + 5 and k 00 = k  X  5. After that, we compute two divergences: one based on k and another based on k 00 . k then gets updated based on whichever cut-point gives rise to higher divergence. We con-tinue the search until no further improvement is possible. Once a single cut-off point k is found, we run Algorithm 2 twice to find two other cut-off points, one between 31 and k and the other between k + 1 and Max . This process is repeated until all N internal layers are identified. Next, we describe two divergence calculation methods used by Algo-rithm 2.
Recall Algorithm 2 and note that to select a single cut-point between ( m,n ) window, the hill climbing algorithm needs to compute the divergence of patient population that constitutes two readmisison windows between ( m,k ) and ( k + 1 ,n ) based on any k , m &lt; k &lt; n . In order to use Entropy-based divergence methods, one has to represent each of these patient populations as a probability distribu-tion. To do that, we obtain the center of the individual pa-tient group , where the center is the average for the numeric attributes and mode for categorical attribute, as described in Algorithm 3 (DIVCAL).

In our implementation, we consider two popular diver-gence methods: Kullback-Leibler Divergence (KL) and Jensen-Shannon Divergence (JSD) [3]. The main difference between the two methods is that unlike KL, JSD is symmetric and always defined. The divergence between two centers p and q of m dimensions, for Kullback-Leibler(KL) and Jensen-Shannon(JSD) methods are calculated as follows [3]: Algorithm 2: Subroutine CutpointFinder( D,m,n ) 11: return k
In addition to Entropy-based methods, we intelligently adapt the popular frequency based Chi-Merge algorithm [10] to design the internal layers. Algorithm 3: Subroutine DIVCAL(k)
Chi-Merge is traditionally used to discretize continuous attributes based on the class distribution frequency. On the other hand, our objective is to create a set of N intermediate layers (and cut-points thereof) for the variable readmission, where this variable itself is also the class label. This pre-cludes direct adaptation of Chi-Merge in our settings. In fact, to be able to apply Chi-Merge, we need to extend our settings in the following way that we illustrate using a simple example next. Imagine that we have a population of 100 pa-tients in total. Out of these 100 patients, 20 got readmitted within 30 days and 10 never got readmitted. The remaining 70 patients create the positive instances who got readmitted within 30 and Max days. Similarly, Chi-Merge also needs negative instances. If a set of X 0 patients are readmitted on a day d , then we set the negative instances using the re-maining 70  X  X 0 patients. After this modification, we apply Chi-Merge to decide the N intermediate layers.
The final stage predicts the readmission  X  30 days. The sample size has been reduced as we move down toward this final leaf node. We use local information from this subset to train classifiers and assess the likelihood of a given pa-tient being readmitted to the hospital within 30 days  X  i.e. P ( Readmit  X  30 | Readmit  X  k ). The objective of this stage is to maximize the AUC and precision so that the medical resources can be efficiently invested on the right patients. Figure 5: Relationships of predicted probability of three stages
Figure 5 shows the relationship of predicted probability of three stages, where circle A is the final stage, circle B is the internal stage (for simplicity we consider 1 internal stage in this example), and circle C is the readmission stage. Intuitively, the predicted probability of 30-day readmission should be the highest in A , lower in B , and the lowest in C . Given the definition of the problem for predicting 30-day readmission, the goal is to estimate P (  X  30), as below. Since  X  30 is a subset of  X  k , we obtain: Therefore, Similarity, we can obtain P ( k ) as follows: Since  X  k is a subset of Readmission = Y , we obtain: Thus, Therefore,
Given the equations above, we can compute P (  X  30) for all instances in A in Figure 5. We then combine the re-sults using normalization techniques to ensure the correct sequence of instances: A  X  B  X  C , if the list is sorted in descending order by the predicted probability. In Figure 5, we identify three mutually exclusive areas  X  the dark grey area in A , the light grey area in B , and the white area in C . For all instances in A (the dark grey area), we normal-ize the predicted probability in to the range (0.7,1]. For all instances in the light grey area in B , we normalize the pre-dicted probability to the range (0.3,0.7]. Finally, we fit the predicted probability from the white area in C into [0,0.3]. We compute our evaluation metrics (e.g. AUC, recall etc.) using the combined normalized probability vector. We evaluate performance of proposed DHC framework on Washington State Inpatient Dataset and the Heart Failure cohort data from MultiCare Health Systems (MHS). The State Inpatient Databases (SID) 9 of Washington State (referred as SID-WA) is available for four years 2009-2012. It is discharge abstract data that includes inpatient discharge records from community hospitals in the State of Washington with all-payer, encounter-level information.
Each year comprises four files that are associated with hospital encounters: core file (CORE), charges file (CHGS), diagnosis and procedure groups file (DXPRGRPS), and dis-ease severity measures file (SEVERITY). Total 596 attributes for each encounter with an unique identifier KEY, that can be used to link records across files (but NOT across years). We construct a heart failure cohort with patients whose primary or secondary ICD9-CM diagnosis codes are heart failure. Our cardiology partners identified a total of 91 at-tributes to be related to CHF readmission from a mix of demographic variables such age, gender, and race; as well as comorbidities related to diagnosis information derived from primary and secondary diagnosis codes for that pa-tient. Many features related to utilization services such as thew emergency room, ICU, electrocardiograms services and so on are also included in our prediction models.

The SID-WA attribute DaysToEvent is used to compute the days between two consecutive hospital admissions for each patient. The days since previous hospital discharge is computed using the days between two hospital admissions minus the length of stay of the first admission. We exclude admission records in which the patient passed away while in the hospital, and in which the patient age is less than 1 year (age=0). The dataset then contains a total of 2 , 051 , 105 readmission instances.
The Cardiovascular datamart is our primary source within the MultiCare Health System data. It has about 8,600 pa-tients diagnosed with Heart Failure, serviced over 14 , 200 hospital encounters from 2009 to 2013. We consider only pa-tients who are discharged to home, excluding inter-hospital transfers. Encounters where the patient expired are not in-cluded. The post cleaning and processing set we used for these experiments includes 6,348 patients diagnosed with CHF and 14,170 hospital encounters. A total of 49 attributes were determined to be related to CHF admission. These are mainly clinical. The key socio-demographic factors re-lated to readmissions are: gender, race, and marital status. Other important factors pertinent to CHF are ejection frac-tion(EF) 10 , blood pressure, primary and secondary diag-nosis indicating comorbidities, and APR-DRG codes 11 for severity of illness and risk of mortality. Information about discharges, such as discharge status, discharge destination, length of stay and follow-up plans, are also found to be cor-related to CHF readmissions. In addition, we include 34 cardiovascular and comorbidity attributes.
Our modeling for SID-WA data and corresponding anal-ysis is conducted on Microsoft Azure over virtual machines with 16 cores and 112GB of RAM. For the modeling environ-ment we use R and Python both. Models are then exported in PMML and deployed using the Zementis ADAPA scoring engine. We evaluate quality using measures such as Area Under the Curve(AUC), Precision, Recall, and Accuracy [7].
Depending on the final consumption of RoR predicted score for a patient population, different evaluation measures are appropriate. AUC measure is typically interesting when the dataset is imbalanced and we want to ascertain com-parison of performance with other competing tools for risk stratification. Precision is critical if there is a high cost re-lated to incorrectly predicting patients X  risk to belong to the Readmission class with accompanying reimbursement penalties associated with the decision. Recall is relevant if using the DHC framework to identify patients who be-long to Readmission class from within an overall population for post-discharge care management. Besides these, we also compute the confusion matrix for all the experiments (each fold) consisting of true positive count (TP), false positive count (FP), true negative count (TN), and false negative count (FN).
 In general, we select the classifier that renders the highest AUC for each layer for reporting in this paper. In actual deployment we may vary this choice depending on the end-point where the score is being consumed. We also tune the threshold to optimize the selected evaluation metric for each layer in DHC.

Predictive Models: We use five different predictive mod-els in general. The first one is Logistic Regression (LR) [7], a method that models the outcomes (class labels) as a so-called logit function of the predictive variables. The second one is Naive Bayes (NB) [7], a well-known simple statistical classifier that assumes attribute independence. We also use Random Forests and Adaboost [5], as popular ensemble al-gorithms (we use 500 decision trees in random forests and 50 CART decision trees in Adaboost). The last implemented model is the Support Vector Machines (SVM) [7] using well-established RBF kernel. For each layer of DHC described in Section 4, we run a 10 fold cross-validation procedure on train set to determine the best classifier. We follow the holdout method to test the models built on SID-WA data. The data is first partitioned into two inde-pendent train and test sets. Three years of data 2009-2011 are allocated to the training set which consists of 1,543,131 admissions and the last year of data (2012), consisting of 507,974 records, is allocated to the test set.

The N internal layers are discovered using either entropy-based divergence calculation methods (Kl-divergence, Jensen Difference), or appropriately adapting frequency based dis-cretization method (Chi-merge), as described in Section 4.
Statistical Significance Test: Wherever applicable, we also perform paired t-test [7] to further understand the sta-tistical significance of the obtained results. To be able to run t-test, we partition the test population into 20 folds, then calculate the quality metric for the competing methods in each fold, and finally run the t-test to investigate whether results are significantly different from each other on each metric. Unless otherewise stated, the significance level is set to p-value &lt; 0 . 05.

Effect of Number of Internal Layers: We carry out experiments to find the best number of internal layers for each cut-point selection method. We vary the number of layers from 3 to 12. The logic for this range was simply to see if we auto-discover less than 30, 30 to 60, and more than 60 as natural layers. Based on the experiments, the best number of internal layers depends on the cut-point selection methods. However, we observe that the increase in num-ber of layers negatively affects the true positive rate. This can lead to a significant decrease in recall, while the AUC and the accuracy do not change considerably. The reason-ing behind this is as follows: with an increase in the number of layers, more patients are pruned in the initial layers (i.e., predicted readmission is  X  X o X ) and consequently less patients get promoted to the 30-day readmission layer (which has to be the last layer given the problem formulation). Empiri-cal analyses suggests Chi-Merge to propose 1 (i.e., N = 1), and Jensen Divergence optimize at 3 layers overall, while KL-Divergence shows the best performance for 5 internal layers. Table 2 demonstrates the readmission interval for the internal stages as well as the classifier chosen for each stage based on 10 fold cross-validation procedures on train-ing data. Classifiers were chosen based on performance as measured by the appropriate metric from Table 1. It can be seen that Logistic regression (LR) is the dominant classifier for most of the cut-points.
 Effect of Cut-Points Selection Algorithms: Recall Section 4 and note that given the number of internal stages as an input, we propose different algorithms to automat-ically select the N cut-points for the internal stage. The aim of these proposed solutions is to choose cutoff days that discriminates two groups of patients with distinct charac-teristics as much as possible. As described in previous sec-tions, we vary the value of N experimentally and observe its qualitative effect on different internal hierarchy selection al-gorithms (Entropy Based Divergence vs Frequencey Based Discretization) and observe that these algorithms lead to different readmission windows (cut-points) for the internal stages. Based on our exhaustive empirical analyses, diver-gence methods have more stable results in comparison with Chi-Merge, especially when we increase the number of in-ternal stages. Table 3 enlists the best result of each cutoff algorithm based on the best number of layers. The results indicates that, for Recall and AUC, KL Divergence signifi-cantly outperforms Jensen Divergence as well as Chi-Merge.
Effect of Threshold Tuning: As discussed in section 4, since the distribution of data changes from layer to layer, we run model selection algorithms at each layer in order to select the classifier that renders the highest AUC. Differ-ent data distributions and classifiers at each layer can lead to different probability distribution which may cause some inconsistency in final predictions. DHC allows us to apply scaling, as well as threshold tuning at each stage. This not only solves the problem of varied probability distributions but also enables us to optimize the selected evaluation met-ric for each stage. The default threshold is set to 0.5. In general, we expect that increasing the threshold throughout the hierarchy will lead to eliminating more patients at up-per layers as no-readmission cases. Conversely, decreasing the threshold leaves the classification decision to lower lay-ers. Among evaluation metrics, we focus on recall and AUC, as they provide insight into the performance of classifiers on skewed datasets. We tune the thresholds through the layers such that we improve the overall prediction quality, with the aim of increasing the appropriate objective (see Table 4 ).
Baseline Algorithms: For comparison, we implement five baseline solutions that employ a single classification model on the full dataset without using a hierarchical struc-ture as proposed in DHC. We consider Logistic Regression, Naive Bayes, SVM, Random Forest, and Adaboost as five classifiers to build our baseline models (prior efforts have demonstrated them to work well for risk of readmission) [21]. Comparing the results in Table 5, the Naive Bayes classifier outperforms other models -it has high AUC, and reasonable recall.

Table 5 compares the result of the baseline models and the best DHC result which was obtained by KL-divergence method with 7 layer (see Table 3 and Table 4 ). As stated above, we also report the statistical significance of quality results (significance level is set to p-value &lt; 0 . 05). It can be easily observed that our proposed framework achieves sig-nificantly better results for all metrics (AUC, recall, preci-sion and accuracy) compared to the baseline with statistical significance. It is interesting to note that the highest im-provement is for the recall and AUC, which are considered as the main metrics when dealing with skewed datasets. Readmit Stage 0.6803 0.6539 0.6000
Internal Stage 0.6014 0.5830 0.5600 30-day Stage 0.6245 0.5900 0.5833 Table 6: MHS data: Classifier Comparison based on AUC for
On MHS internal data, the presented results are repre-sentative. We primarily focus on describing the utility of the deployed DHC solution designed using KL-Divergence (as that is the best performing algorithm based on the SID dataset) and compare it with the single stage baseline clas-sification algorithms.

Based on Kl-Divergence, we select one layer in internal stage (i.e., N = 1), thereby constituting 3 layers overall (readmit, internal, and the 30-day yes no layer). After get-ting results from Algorithm 2, the readmission interval for the internal stage was determined to be 65 days. Hence, the problem of predicting 30-day readmission risk is for-malized using hierarchical classification as follows: Read-mit Stage : predicting readmission within 1200 days (based on our dataset, Max = 1200), Internal Stage : predicting readmission within 65 days, and 30-day Stage : predicting readmission within 30-days.
 DHC Internal Predictive Models for MultiCare Health System: The following three classifiers exhibit the best and somewhat comparable classification performance  X  Random Forests [2], Adaboost [5], and Naive Bayes [7] X  for each layer of DHC described in Section 4. Table 6 shows the AUC of the three classifiers in each layer. As shown in Table 6, Random Forests achieves the highest AUC for all three layers. Therefore, we present the results of Random Forests for all three stages for the rest of our experiments. Table 7 shows the experimental results for the proposed DHC approach and the prediction quality for each stage. Since, Random Forests achieves the best performance, for brevity, we therefore present our results by comparing DHC with a single-stage baseline Random Forests classifier (500 decision trees). DHC outperforms the baseline on true pos-itive count, recall, and AUC. It is noted that the highest improvement takes place in the Readmit Stage , as our pre-dictive model achieves higher AUC at that particular stage. This observation is intuitive as it appears that the quality of prediction can be improved by eliminating negative in-stances at an early stage. The overall quality improvement becomes less at the internal stage. This is due to the fact that the data in the internal stage is more homogeneous and no distinct patterns among the patients are identified.
We also have observed that for this dataset the difference in KL-divergence across different k (cut-point) values do not vary greatly (most of them approximately 0 . 057). After fur-ther analysis we realize that such low KL divergence and homogeneity arises due to our use of mean value to deter-mine the centroid of each group. In the future we explore alternatives to calculate group centroids, potentially leading to larger values of k for the internal stages. Nevertheless, based on Hill-Climbing we selected k = 65.

Factor Analysis: We apply the Chi-Squared test [7] to determine the significant factors. The p -value is set to 0 . 05 in all cases. We observe that the number of significant factors vary at each stage. There are 32 influential factors for Read-mission Stage and Internal Stage and 16 for 30-day Stage . Table 8 enlists top-10 most influential factors sorted based on increasing P -values, based on the Chi-Squared test. The importance of a particular factor is different at each stage. For example, Length of Stay is an important factor for Read-mission Stage and Internal Stage , but not for 30-day Stage . It implies that, given that a patient is likely to return to the hospital, care managers can concentrate more on risk factors closely associated to 30-day readmission. Such in-sights are tremendously useful to the domain experts and the physicians for appropriate prognosis.
To the best of our knowledge, no hierarchical classification techniques for risk of readmission risk prediction have been yet reported in literature. Very few cloud based deployed solutions exist today in healthcare and none are for scor-ing patients for their readmission risk on multiple chronic conditions, in real-time, integrated with EMRs.

Readmission Risk Prediction: An early research re-sult for predicting RoR for CHF patients was termed the Yale Model [11]. Logistic regression was used for 30-day all-cause readmission risk for 65+ year old HF patients. More recently [1], administrative claim data was used to build a regression model on 24,163 patients from 307 hospitals on patients 65 years or older. In collaboration with MultiCare Health Systems, our prior efforts have resulted in accurate solutions [15, 21, 19, 18, 20] to predict 30-day RoR. However, none of these solutions generalizes for any time-interval and Readmission Internal 30-day Severity Of Illness Risk-Of-
Risk-Of-Mortality Severity Of Ill-
Length-Of-Stay Length-Of-Stay Acute coronary
Renal Failure Secondary ICD9 Discharge Fol-
Anemia Cardio-
Ejection-Fraction Fluid Disorder Cardio-
Pneumonia Acute coronary
Fluid Disorder Discharge Fol-Dialysis Ejection Fraction Malnutrition Table 8: MHS data: Factor analysis of three different stages of automated design, which is one of the primary contributions of the proposed research.

Hierarchical Classification: Hierarchical classification is extensively used in various application areas such as in text mining for web page classification applications [4], In-formation Retrieval [6], and in signal processing [14]. The use of multistage classification for Bayesian combination of classifiers is explored in literature [13], K-Nearest Neigh-bor [17], and hierarchical SVMs [9]. Thus we turn to a hierarchical or multi-stage classification process for predict-ing risk of readmission. The design though is non-trivial to optimize overall prediction quality and ensure good general-ization, particularly for high risk patients.
Predictive models for risk of readmission can significantly improve quality of care. With an increase in the number of patients suffering from chronic conditions, demand for actionable, accurate, and cost-effective solutions to be de-ployed also increases. In this paper, we describe the al-gorithm design, deployment challenges, architecture of our cloud-based deployed framework DHC. MultiCare Health Sys-tem uses the described DHC framework to predict the 30 day post discharge risk of readmission for their heart failure col-laborative. We demonstrate that the proposed framework clearly outperforms baseline solutions for congestive heart failure (CHF). DHC automatically discovers and defines the layers by leveraging the underlying historical patient data. Detailed experimental evaluations on two sizeable real-world datasets statistically validate the utility of DHC and the de-ployed engineering efforts demonstrate the real-world impact of the framework.
We acknowledge MHS and Microsoft Azure for Research for their generous supports in this research.

