 1. Introduction
The rapid advances of information technologies have allowed for the inclusion of vast amounts of electronic information ciently, and conveniently retrieve multimedia information from the vast array available presents both an opportunity and a challenge for modern digital libraries.
 index for organizing text-based information.

Indexing multimedia information, however, is more challenging, because these data comprise opaque collections of bytes textual information for multimedia objects, traditional text-based clustering approach may not work well. Therefore, a pressing need emerges, namely, to integrate other sources of data to cluster objects in a multimedia digital library.
With the advent of the World Wide Web, an overwhelming number of digital libraries now provide interfaces that allow resource number etd-0717101-163917 was accessed on 01/Apr/2004:00:00:02 by a user with the IP address 218.165.248.55. ferent categories. Therefore, we propose to tackle the problem of indexing multimedia information by employing Web usage logs, in combination with limited keywords attached to multimedia information.
 the index. We develop two methods to construct an index for multimedia objects that employs both the (possibly limited) set show that an index constructed by considering both usage and content data better matches the predefined index than so we use it to investigate how our proposed methods perform even for a digital library with rich textual data. Compared with traditional text-based approaches, the indexes created by our proposed methods are only slightly inferior in terms of matching the predefined index. Nevertheless, our proposed indexes retain the advantages of enabling users to identify the information they need quickly. We thus conclude that the proposed methods offer promising improvements for building indexes for multimedia digital libraries.
 scribe our methods for indexing multimedia information, using textual content information and Web usage logs. We report
World Art digital library and an ETD system. Finally, in Section 5, we summarize and point to some further research directions. 2. Literature review the Michigan Digitization Project (also known as MBooks) at the University of Michigan (Vaidhyanathan, 2006 ), the SAPIR project at IBM Haifa Research Laboratory (http://www.sapir.eu/), the DELOS project by DELOS Association for Digital Li-braries in Europe (http://www.delos.info/), and the TelPlus project funded by the European Commission (http://www.the-ciates semantic concepts with some extracted, low-level content features, such as color, contrast, or texture.
The formalization of the problem thus involves three separate issues. First, the most common approach to document repre-sentation depicts each document as a multidimensional vector, in which the element of each dimension corresponds to the uments automatically into a set of clusters (Han &amp; Kamber, 2006 ).
 timedia search engines, for example, index images, video, or audio objects linked by HTML pages or embedded within them, rhythm and timbre for music/audio), to index the multimedia objects. Li, Myaeng, and Kim (2007) , for example, analyze to make recommendations.

Another important data source for forming object clusters may pertain to Web usage logs. Most previous works that em-such as distance-based methods, cannot handle such clustering because of the inherently high dimensions, such that each
Web page corresponds to one dimension. The association rule hypergraph partitioning (ARHP) technique ( Han, Karypis, Ku-
Shekhar, 1999 ). 3. Proposed methods
Most previous work employs textual information to construct document indexes, though more recent work also facili-mation and propose constructing an index of multimedia objects by employing both (textual) content and usage data. We
Traditional TF IDF measures ( Salton &amp; McGill, 1983 ) determine the weight of each keyword for each object, where w assigned to the j th keyword of the i th object: frequency on the weight for more general cases:
After this conversion, each multimedia object is represented by a vector. The content similarity csim ( a and a 2 then is defined as the cosine of the angle between the vectors of a
As mentioned in Section 1, a Web-based digital library contains a Web usage log, and each record in the Web usage log user) exceeds 30 min, we assumed that a new user session had started.

In the past, several approaches have been proposed for using either content or usage data, but not both, to construct an index. We present two index construction methods that use both content and usage data. 3.1. Multimedia categorization-based approach (MCAT)
The multimedia categorization-based approach , or MCAT, combines clustering techniques based on the Web usage log with lapping clusters based on the Web usage log by first applying the frequent itemset mining algorithm to the user sessions accessed during the same user sessions. The frequent itemsets, denoted IS ={ I where V = I 1 [ I 1 [[ I k and E=IS . (A hypergraph is an extension of a graph in which each hyperedge can connect more than two vertices.) Following the approach proposed by Mobasher et al. (2002) , we define the weight of a hyperedge f o back into a cluster, resulting in non-disjointed clusters. Specifically, for a given hyperedge I to access them in the same sessions.

Although clustering based on the Web usage log achieves some success in various application domains (e.g., recommenda-vioussteptoexistingclustersonthebasisoftheir(textual)contentinformation.Theassignmentoftheseunclusteredobjectsto identifiers of the clusters. Specifically, let the set of clusters obtained using ARHP be { C
A binary classifier CL i can be built for each cluster C i predicted by CL i to be positive. Finally, objects that are not assigned to any cluster are placed in a new cluster C clustering { C 0 , C 1 , C 2 , ... , C k } involves all objects, as depicted by the pseudo-code of MCAT in Fig. 1 . 3.2. Multimedia clustering-based approach (MCLU)
The second method, the multimedia clustering-based approach (MCLU), directly clusters multimedia objects on the basis of plete graph G =( V , E ), in which V represents the set of multimedia objects, and ( u , any two objects in Q . The hyperedges derived from the Web usage log are frequent itemsets and take the weights assigned using the same approach as described previously for MCAT.

However, locating a clique of maximum size entails an NP-complete problem, which means it is not practical to enumer-objects. For a given object v 2 V , let Ksim  X  v ; k  X  denote the k th largest similarity values between
V .If s  X  Max s  X  Max all maximal cliques. These cliques become the content-based hyperedges.

To prevent bias toward either usage or content data, we normalize the weights of the hyperedges, such that the maximum weight of the content-based hyperedges equals the maximum weight of the hyperedges generated by the Web usage log. The show the pseudo-code of MCLU in Fig. 2 . 3.3. Index updating access patterns.

Both MCAT and MCLU identify frequent itemsets from user sessions to discover sets of multimedia objects that often are frequent itemsets, at the expense of substantial time and space requirements, though most proposed algorithms intend this approach.

The stream-based frequent itemset mining algorithms also can maintain the current frequent itemsets of multimedia ob-be reconstructed using either MCAT or MCLU. Although algorithms exist for incremental clustering and incremental classi-tribution will not be subject to constant change. Moreover, these incremental algorithms do not come without price X  X hey often compromise clustering/classification accuracy. 4. Evaluation 4.1. Data sets
To evaluate our proposed methods, we collected data from two test beds: the World Art Digital Library from Airiti, Inc. brary contains a limited amount of textual information, whereas the NSYSU ETD System provides abundant textual content. effect of textual data on the performance of the constructed indexes.
 these artworks had been browsed more than 10,000,000 times, which means many Web usage log records were available. which have been further classified into the following 16 categories: 1. Art of the Middle Ages 2. Renaissance 10. Expressionism 11. Cubism 12. Surrealism 13. Abstract Expressionism 14. Symbolism 15. Pre-Raphaelite 16. Futurism The Web usage log records dated between January 1, 2005, and December 31, 2005, provide input for our experiment. From the total of 701,273 log records, using the approach we described in Section 3, we extract 60,012 user sessions.
Since its initiation in May 2000, the NSYSU ETD System has collected more than 10,000 electronic theses. Each ETD thesis
August 2003 from the departments of Computer System Engineering (CSE) and Management Information System (MIS). Two egories from the first-level ACM classification scheme (http://www.acm.org/class/1998/overview.html), as follows: 6. Theory of computation 7. Mathematics of computing 8. Information systems 9. Computing methodologies 10. Computer applications 11. Computing milieu
The experts could assign more than one category to each ETD. Three categories X  X eneral literature, mathematics of com-puting, and computing milieu X  X o not contain any ETDs, according to both experts, so our subsequent experiments involve
The Web usage log records of the NSYSU ETD system, dated between October 31, 2003 and April 30, 2004, provide further information for our experiment. We followed the same approach as described previously and thereby identified 3183 user sessions involving ETDs in the data set. 4.2. Performance benchmarks and metric
To evaluate the performance of our proposed methods, we used two content-based clustering methods, namely, K-means then treat the set of vectors as the input for the K-means and ACHP methods.

Our proposed approaches for index construction involve online frequent itemset mining and offline hypergraph partition-computation overhead is not a major concern. We focus on measuring the quality of the generated clusters, with usage en-respect to a set of clusters. For example, consider a clustering C ={ C jects of cluster C i ,1 6 i 6 k . The entropy of s , denoted E ( s ), then is given by tion searches.

The second performance metric we adopt to measure the quality of the generated clusters is content entropy , which mea-are m disjointed segments for a cluster C j of size n , and n
E ( C ), then can be defined as follows: more accurate. 4.3. Evaluation results
This section reports our experimental results using both the artwork and ETD data sets. The two proposed methods, MCAT and MCLU, and two content-based clustering methods, K-means and ACHP, are evaluated according to their usage entropy and content entropy. 4.3.1. Artwork data set The first experiment intends to measure the usage entropy of the artwork indexes constructed using the four methods.
MCLU and ACHP, we must specify a threshold s for content similarities. We set K= 17, which results in s  X  0 : 5004 ( s  X  Max Fig. 5 .

As we show in Fig. 5 , the usage entropies of the two content-based clustering methods, ACHP and K-means, do not change lower (and thus better) usage entropy than their content-based counterparts, because both MCLU and MCAT employ the Web usage logs for their clustering. As Min sup increases, MCAT tends to outperform MCLU, because the high Min smaller yet more usage-coherent itemsets for MCAT. These coherent itemsets provide the hyperedges of the hypergraph and erated by MCLU consider both content and usage. When Min Sup tent information, which results in fewer dimensions, which then favors K-means.
 In the second experiment, we measure the content entropy of the artwork indexes for all four methods. The results in Fig. 6 reveal that the content entropies of MCAT and MCLU increase with greater Min duce content entropy but rather achieves a content entropy similar to that of ACHP. Our two proposed methods incur lower case significantly improves the content entropy score.

The number of unclassified artworks for the different clustering schemes appears in Fig. 7 . K-means has no unclassified posed methods, the number of unclassified artworks increases with an increase of MIN data for clustering. With fewer positive examples in each cluster, the classifier employed by MCAT tends to assign more negative examples for the unclustered artworks, thereby causing even more unclassified objects in comparison with MCLU.
 4.3.2. ETD data set
The next experiment measures the usage entropy of the ETD indexes constructed using the four different methods. As we content-based counterparts, because both MCLU and MCAT employ the Web usage logs for their clustering. Of the two con-relative performance difference between MCAT and MCLU follows the same trend as reported in Fig. 5 for experiments using the artwork data set.

In the last experiment, we measure the content entropy of ETD clusters generated by the four methods using the clusters yield better (smaller) content entropies, and ACHP yields the best performance because of its ability to handle the high-dimensional data. Our two proposed methods generate similar (but higher) content entropies across various Min Min Sup , MCLU tends to give lower priority to usage clustering, because there are fewer usage-based hyperedges. unclassified ETDs. In contrast, K-means comes second to ACHP in terms of content entropy but has the advantage of no unclassified ETDs. 4.3.3. Summary of results content information, our two proposed hybrid methods achieve the best usage and content entropies. For the best perfor-mance, we recommend a smaller Min sup to reduce the number of unclassified multimedia objects. For example, as we show media digital library yield better performance than those that use a single data source. 5. Conclusions struction methods, MCAT and MCLU. These two methods employ primitive keywords and usage data to develop an index.
The empirical experiments reveal that compared with traditional content-based clustering methods, our methods, when ap-content entropy.

The performance of our proposed methods may depend on the quality of usage data. If the usage data contain mostly one-off searches or factoid searches, the index generated using our proposed methods may not retain good content entropy. To data structures or techniques into the proposed methods.
 References
