 ( the algorithm.
 this paper are:  X   X  without the need for a human to constitute training data.  X  models the segmented objects may be composed of heterogeneo us building blocks.  X  linkage between words and image model parameters are inferr ed nonparametrically. 2.1 Bag of image features is denoted by z where Stick  X  u &gt; 0 probability that image type i will be observed across the M images. associated with an over-segmented portion of the image). Th e L associated with image m are { x The expression F ( ) represents the feature model, and  X  Each image is assumed to be composed of a set of latent objects . An indicator variable  X  which object type the l th feature vector from image m is associated with, and it is drawn w i  X  { 1 , . . . , I } ; the k th component of w z k in image m , when image m was drawn from class z The image class z ables. The generative process for the observed data, { x is represented as where H is a base measure, usually selected to be conjugate to F ( ) . 2.2 Bag of clustered image features tive. This is because each of the  X  nothing in the model that encourages the image features, x the same image-feature atom  X   X  augmented model: where v encourage a relatively small number of objects in a given ima ge. 2.3 Linking words with images { x originally non-annotated images.
 [ y image m (typically y distribution associated with a parameter  X  simply set Namely,  X  Dir (  X  3.1 Logistic stick-breaking process (LSBP) In (5), note that once the image class z the indicator variable c is drawn i.i.d. c are proximate within the image, they are likely to be associa ted with the same object. With each feature vector x two-dimensional vector). We wish to draw where the cluster probabilities v ing v let  X  [ g impose where v where K ( s , s infer each  X  We desire that a given stick v we impose sparseness priors on parameters { W ( m )  X  process (LSBP). For notational convenience, c constructed as above is represented as a draw from LSBP generative process of the proposed model with LSBP. Figure 1: Depiction of the generative process. ( i ) A scene-class indicator z 3.2 Discussion of LSBP properties and comparison with KSBP W and extended region over which the t th LSBP layer will dominate. Specifically, c ( t ) the same for data samples located near (defined by  X  region  X  [ g t With the KSBP, rather than assuming exchangeable data, the v where K ( s ,  X  local basis location  X  smooth segments with sharp boundaries, as demonstrated in [ 2]. 4.1 Inference each over only a single hidden variable  X  imation q (  X  ) and the true joint posterior p (  X  ) . 4.2 Processing images with no words given images, through the inference of inter-relationships and c ommonalities. is associated with a latent localized object type (to which a word may now be assigned). 4.3 Joint processing of images and annotations segment out and localize words within a scene. http://vision.cs.princeton.edu/lijiali/event dataset/ ). we can infer words associated with some important G employed.
 examine our model with the proposed LSBP replaced with with K SBP. 5.1 Image preprocessing words [3, 6, 10, 11, 20, 23, 24].
 Since each superpixel is represented by three visual words, the mixture atoms The center of each superpixel is recorded as the location coo rdinate s the L superpixels.
  X  parameter,  X  5.2 Scene clustering In Figure 2, we show two example w extracted with high probability as represented by w provided with the data.
 indicator z since our experiments were performed on non-annotated imag es. distinct use of  X  X oat X  and  X  X ailboat X , which helps distingu ish rowing and sailing). 5.3 Image annotation The proposed model infers a posterior distribution for the i ndicator variables c the words we have assigned to objects in an image).
 cantly outperform Corr-LDA, especially for the precision v alues. 5.4 Object segmentation LSBP over KSBP. than without.
 PC with 1.73 GHz CPU and 4G RAM. One VB run of our model with LSBP , for 70 VB iterations, single VB run, with random initialization. AFOSR, DOE, NGA and ONR. References
