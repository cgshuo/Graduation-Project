 YANG LINGPENG, JI DONGHONG, TANG LI, AND NIU ZHENGYU Institute for Infocomm Research, Singapore ________________________________________________________________________ _______________________________________________________________________ 1. INTRODUCTION query expansion (QE) strategies have been proposed [Chien 1995; Ji et al. 2002; Mitra et al. 1998; Robertson and Walker 2001]. Chines e characters, bi-grams, n-grams (n&gt;2), and words are the most widely used indexing units. character indexing is good but not sufficiently competitive, while bi-gram indexing works surprisingly well and it X  X  as precise as short-word indexing. Nie et al. [2000] suggest that word and bi-gram indexing can achieve comparable performances, but if we consider the suggests that a combination of the longest-ma tching algorithm with single characters is a performance can be further improved. Some other researches [Chien 1995; Palmer and indexing units for Chinese IR. In our Chinese IR, we automatically extract short terms (a collections and use short terms as index units.
 behind automatic query expansion is that the high-ranked documents are likely to be documents are relevant, then the terms added to the query are mostly related to the search topic, and the expanded query matches more relevant documents and retrieves them at query topic and the quality of the documents retrieved using the expanded query is likely to be poor. Thus, the portion of actually relevant documents in retrieved documents query expansion, we use our proposed document reranking (DR) method to further retrieved documents before query expansion. propose a document reranking method based on document clusters. They build a the documents. Balinski et al. [2005] propose a document reranking method that uses the the un-stemmed words in queries to reorder documents. Xu et al. [1996; 2000] make use of global and local information to do local context analysis and then use the information retrieved documents; each term in a query topi c is expanded with a group of terms in the thesaurus. Bear et al. [1997] use manually-crafted grammars for topics to reorder documents by matching grammar rules in some segments of an article. Kamps [2004] proposes a reranking method based on assigned, controlled vocabularies. Yang et al. documents to rerank documents. In our Chinese IR, we propose a document reranking local and global distribution, including document frequency, document position, and term length. The rationale behind the choice of long terms is that they may help to improve the precision with more specific information. units from the top N documents according to some predetermined criteria and adds these query topic. rerank the top retrieved documents; third, and finally, we use the information in the top N retrieval result. document reranking method in our system. In Section 4, we describe how to get relevant Section 5, we evaluate the performance of our proposed method on the NTCIR-4 CLIR Chinese SLIR subcollection and analyze some results. In Section 6, we present the conclusions and ideas about future work. 2. TERM EXTRACTION We automatically extract terms from document collections. We regard a term whose equal to or greater than four Chinese characters as a long term. automatically extracted short terms as index units, which has the advantage that we don X  X  need a predefined dictionary. We use a seeding-and-expansion mech anism to extract terms from documents (or document clusters). The procedure for term extraction consists of two phases, seed positioning and term determination. Intuitively, a seed for a candidate term is an individual Chinese character within the term. Seed positioning is used to locate the rough position of a term in the text, while term dete rmination is used to figure out which string covering the seed in that position forms a term. significance in the text in some way. To do so, we make use of a very large corpus x (2 GB of data from the NTCIR-4 CLIR Chinese SLIR subcollection, LDC's Mandarin Chinese News Text, and news articles from www.sina.com.cn) as a reference . Suppose s is a document or a document cluster and w is an individual Chinese character in the text, respect to x [Schutze 1998], as the criteria for evaluating the seed words. We call w a seed if P s ( w ) / P x ( w )  X   X  (  X  &gt; =1). We make the following assumptions about a term: Here a maximal word string meeting (i) and (ii) refers to a word string meeting (i) and (ii), substring meeting (i) and (ii) refers to a real substring meeting (i) and (ii), while no other longer real substrings containing it meet (i) and (ii). and  X  X  X  X  X  X  (National Palace Museum) occurs three times in d , and  X  X  X  X  (Museum) occurs five times in d . If we set the parameter N in item (ii) as a two, then both strings  X  X  X  X  X  X  (National Palace Museum) and  X  X  X  X  (Museum) are terms in d ; but if we set the parameter N in item (ii) as a three, then  X  X  X  X  X  X  (National Palace Museum) is a term in d , but  X  X  X  X  (Museum) is not a term in d, because its independent occurrence is a two (excluding the three occurrences as substrings in  X  X  X  X  X  X  (National Palace Museum)). the term extraction algorithm to it. All the te rms from different document clusters form a long term. The following are some examples of some short and long terms. and hierarchical clustering are the two most commonly used approaches. In our Chinese IR system, we only need to roughly cluster the document sets into some document clusters, so we use a simple K-Means approach. First, we randomly pick up 10* K 10* K documents into K clusters; finally, we insert other documents into the K clusters. clusters, then extract the terms from each of the 2000 docu ment clusters. whole document set r . In fact, the term list can be considered an automatically acquired segmentation methods, a global term and its substrings may simultaneously be considered when segmenting the terms in the documents, we use their frequency to determine which one should be a term in the document and which shouldn X  X . For example, if cd and de in cde are both global terms, we take cd as a local term if its frequency is larger than that of de , otherwise de becomes the local term. Terms resulting from the segmentation of each document are regarded as local terms . global term t occurring in a document d may not be a local term of d . For example, in the NTCIR-4 CLIR Chinese SLIR subcollection,  X  X  X  (Institute) is a global term, but it is not a local term of query  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  (Find information on the "Art and Culture of the Han Dynasty" exhibition at the National Palace Museum.) 3. DOCUMENT RERANKING To rerank retrieved documents, we use the long terms in the documents and suppose that these long terms will contribute to the reranking. Here, we only focus on the long terms that also occur in the queries. So the long term s can also be referred to as query terms. To the term in the whole document collection. Intuitively, the more frequently a term occurs in the N documents relative to the whole collection, the more important the term tends to be. given by the following formula: whole collection C ; and DF(t,C) is the number of do cuments that contain t in C . first find out the query terms that occur in d and sum the weight of these query terms, we documents. Table I gives the pseudo-code for the re-ranking procedure. 4. RELEVANT TERM ACQUISITION AND QUERY EXPANSION from the query, the top documents in the initia l retrieval list, and the Internet. The terms consider the top 20 documents from the initia l retrieval list for the query expansion. Yahoo, with the short terms from the query as the search terms. The extraction process is list. After getting the terms, we conduct term clustering, which includes the following four substeps: based on the assumption that a feature is irrelevant if its presence obscures the separability of the data set. the dimension of feature space F . The similarity between the i-th data point and the j-th data point is given by data points. In this article the value of  X  is between the data points. Th en the entropy of data set T represented in space F is defined as CLIR Chinese SLIR subcollection, we deal with the feature subset selection problem data set T is minimized. This problem can be formulated as the clustering algorithm. lower. number of clusters using the MDL criterion. The MDL-based feature wrapper finds the optimal feature subset using the MDL crite rion. For every possible feature subset number are determined via the minimizing of the MDL value. the MDL criterion to select the optimal cluster number [Bouman et al. 1998]. We still use model. Then the likelihood of a data set generated by a mixture model is The mixture density function for sample t n is given by  X 
K ), and  X  k is the prior probability of component k . It is supposed that K is known in advance. Assuming that the component density is Gaussian, the following parameters are required to specify the model with K components:  X  k -the prior probability of component k ;  X  k -the M dimensional mean vector for component k ; and  X  k -the M-by-M covariance matrix for component k. and K . The component density function for sample t n is defined as Then the MDL-based optimal cluster selection problem is defined as: where K  X  is the optimal number of mixed components. The MDL criterion is given by term in the query topic, the parameter setting in the feature filter and the term clustering is manually assigned and verified. 
Table III lists the cluster contents of query topic 1:  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  1998  X  X  X  X  X  X  X  X  X  X  X  X  X   X  (Find articles containing Taiwan laborers' Government in 1998). retrieved documents, the short terms in the query, and their relevant terms (co-occurring satisfies some conditions, then we use the terms in the cluster to expand the term in the query. In our experiments on NTCIR-4 CLIR Chinese SLIR subcollection, 25 to 40 terms are added to the original queries to form new queries, depending on the query topic. 5. EXPERIMENTS AND EVALUATION We use the NTCIR-4 CLIR Chinese SLIR subcoll ection as our test data set. The data set contains the Chinese document set CIRB011 (132,173 documents from the China Times, China Times Express, Commer cial Times, China Daily News and Central Daily News) and CIRB20 (249,508 documents from the United Daily News). Sixty query topics were for evaluation. Each query is a simple description of a topic in the Chinese language. As an example, the following is query topic 001: query topics, where T-run only uses the field TITLE as its query and D-run only uses the field DESC as its query. We also use NTCIR-4 CLIR Chinese SLIR X  X  relaxed relevance judgment and rigid relevance judgment to measure the precision of retrieved documents. Relaxed relevance judgments consider highly relevant, relevant, and partially relevant documents, while rigid relevance judgments only consider highly relevant and relevant judgments, respectively. We use Mean Average Precision (MAP) on 59 query topics to measure the overall retrieval performance. using short terms as index units against that of using bi-grams or words as index units on different retrieval models (the vector sp ace model and OKAPI BM25 model). Our second group of experiments compares the effectiveness of document reranking on different effectiveness of our query expansion method against Rocchio standard query expansion method. following TF/IDF weight scheme: document set that contain a t . where T( t , q ) is the frequency of t in q.
 query vector. For the OKAPI BM25 model, we use the default parameter settings. 5.1 Experiments on Different Index Units (bi-grams, words, and short terms) on the vector space and OKAPI BM25 models. In the results. 90,000 Chinese words to segment Chinese doc uments into word se quences. These words are indexed for retrieval. dictionary, and then use a method similar to the segmentation method for words to segment Chinese documents into short term sequences. These short term sequences are indexed for retrieval. grams, words, and short terms. [MAP (rigid)] represents a MAP based on a rigid relevance judgment. produces comparable results for the vector space or OKAPI BM25 models, while using short terms as index units produces results with a 3%-5% improvement for MAP than combination of words and new words. The difference between words and short terms is query. than using the vector space model, with a 5%-1 0% high for MAP at different index units. because the query topic in D-run is longer an d contains more descriptive terms than T-run and produces more noisy information conducted some paired t-tests. In our experime nts, MAPs of the 59 topics are regarded as each pair of indexing units. In Table V, + and ~ correspond to th e p-value&lt;=0.05 and p-significant. 
Table V. Paired t-Test Results on Differ ent Indexing Units: the Vector Space Model Similar results are also found for rigid rele vance under the vector space model and both kinds of relevance for the OKAPI BM25 model. the later experiments. 5.2 Experiments on Document Reranking MAP values of document reranking on different initial retrieval results. In the following, we use +x% to denote improvement of x% over the baseline shown in Table IV. 23.8% against initial retrieval results. improve the performance for both T-Run and D-Run under the vector space model. both the rigid and relaxed relevance under the OKAPI BM25 model. Vector Space Model Okapi BM25 5.3 Experiments on Query Expansion To compare the effectiveness of our query e xpansion (hereafter extended QE) which also uses relevant terms acquired from the Internet, we compare the results to those using the standard Rocchio relevance feedback (hereafter standard QE). In our setting, we selected 40 words or short terms and 200 bi-grams from the top 20 retrieved documents. The selected units are added to the original queries to form new queries. Table IX gives MAP values for query expansion based on reranking. improve MAP by 8.8%-15.3% against initial search on different indexing units and retrieval models, while using extended query expansion produces better results than using standard query expansion. We also noticed that using reranked results for query document reranking can help query expansion improve precision. Vector Space Model Okapi BM25 
Table X. Paired t-test Results for Short Terms as Indexing Units: Vector Space Model other hand, document reranking makes a significant contribution to both standard QE and model and for both kinds of relevance under the OKAPI BM25 model. results for several individual topics. We found that the extended QE affects some queries, including 9, 18, 28, 33, and 58. Protein &lt;/TITLE&gt;), we got some relevant terms like: These terms, although relevant to  X  X  X  X  (Protein), are not relevant to the real topic precision of the top N ranking documents. expansion doesn X  X  capture the really relevant terms. For example, consider query 18: Some of the really relevant terms for this query include  X  X  X  (youth),  X  X  X  (youngster),  X  X  X  (young boy),  X  X  X  (young girl),  X  X  X  (drug), and  X  X  X  (smoking). However, the most relevant terms for  X  X  X  X  (young people) from the document collection are  X  X  X  (health) and  X  X  X  (nutrition). under the vector space model. We can see th at for most topics, both reranking and query Figure 2, reranking doesn X  X  help, and for five topics in Figure 1 and six topics in Figure 2, QE doesn X  X  help. 6. CONCLUSIONS AND FUTURE WORK In this article we have introduced our approach to Chinese IR and our experiments on the NTCIR-4 CLIR Chinese SLIR subcollection. Under the vector space model, the system initial retrieval by the original MAPs of 68 .7%, 60.3%, 86.4%, and 51.2%, respectively. This system also claims to outperform other participating systems in the NTCIR-4 CLIR Chinese SLIR task [Kishida et al. 2004]. terms, document reranking by long terms, and extended QE on the basis of the top retrieved documents from both the document collection and the Web. advantage of using short terms, compared to words as indexing units, is that we can avoid Chinese word segmentation, which still relies heavily on domain-specific dictionaries and suffers from the problem of domain portability. standard and extended QE. For extended QE , the experiment also shows that our approach can improve the standard QE significantly, due to its integration of information from both the document collection and the Web. relevant terms are mainly based on the co-occurrence of terms in documents and returned search results via a search engine. Experiments show that some relevant terms acquired in improvement may be to detect relevance via co-occurrence of the terms in paragraphs or sentences. Another problem is that even if so me terms are relevant to a query term, they are not relevant to the topic described by the query. For this problem, future work will be to study how to get the topic-relevant terms, and not only those relevant to query terms. and long terms, or term length more generally, in the overall performance; (ii) the impact test its robustness, and so on. REFERENCES 
