 ORIGINAL PAPER Volker M X rgner  X  Erik Cuevas  X  Ra X l Rojas Abstract In this article, our goal is to describe mathe-matically and experimentally the gray-intensity distributions of the fore-and background of handwritten historical doc-uments. We propose a local pixel model to explain the observed asymmetrical gray-intensity histograms of the fore-tion is the process of estimating such sets and, consequently, it is crucial for several applications of pattern recognition tification [ 7 , 59 ].

Binarization competitions, like (H-)DIBCO 2009, 2010, 2011, and 2012 [ 16 , 42  X  44 ] manifest the great interest and ongoing work on binarization methods specialized in degraded documents. Such methods exploit features like nected components [ 31 , 36 , 56 ], and background surface esti-mation [ 31 , 51 , 56 ].
 Among the above-mentioned methods, Hedjam X  X  [ 20 ] and Ram X rez-Orteg X n X  X  [ 46  X  48 ] methods explicitly assume that the gray intensities of both fore-and background are normally distributed ( Gaussianity or Gaussian assumptions ). Both methods estimate locally the parameters of each class distrib-ution and apply Bayes rule to classify each pixel. While Hed-jam X  X  method considers the output of the grid-based Sauvola method [ 33 ] to estimate the parameters of the class distribu-tions, Ram X rez-Orteg X n X  X  method estimates such parameters from the transition pixels (a generalization of edge pixels). Both methods, however, estimate the means and variances of gray intensities by the maximum likelihood estimators. Gaussian assumptions have been explored long before Hedjam X  X  and Ram X rez-Orteg X n X  X  methods were proposed. For example, a pioneering binarization method based on Gaussianity was proposed by Chow and Kaneko [ 11 ] in 1973. In this method, the parameters of the gray-intensity distrib-ution of the background are inferred by a region provided by the user, and the parameter estimators are computed by the maximum likelihood method. Then, the pixel classifica-tion is computed by Bayes rule. Another example is Kittler X  X  method [ 25 ], proposed in 1985, which selects a threshold that minimizes an error function under Gaussian assumptions. gray-intensity histograms. Later on, in Sect. 3 , we address the assumption of local smoothness. We experimentally prove that the fore-and background surfaces are highly smooth in a small neighborhood so that their gray-intensity histograms (excluding edges pixels) are indeed mixtures of normal dis-tributions.

We conducted two evaluations of quasi-thresholding methods in Sect. 4 whereby we show the potential appli-cations of our pixel model. The term quasi-thresholding is because our tested binarization methods compute data from the groundtruth. In concrete, these quasi-thresholding methods model the gray intensities with mixtures of nor-mal and lognormal distributions, while the means and vari-ances of gray intensities are estimated from the groundtruth. Despite these restrictions, our experiments provide experi-mental bases to develop further algorithms based on asym-metrical distributions that exclude the groundtruth as a data source.

Most of our experiments use extracted images from the handwritten images of the DIBCO 2009 and H-DIBCO 2010 benchmarks. However, we also report evaluations of the orig-inal DIBCO benchmarks in Sect. 4.4 . 2 Image model In this section, we show that the distributions of gray intensi-ties of both fore-and background are skewed by identifying three classes of pixels and their corresponding distributions. One of these three classes is asymmetrical (with skewed his-togram), while the other two classes appear to be normally distributed.

An extracted image from a historical document (300 dpi) and its corresponding binary groundtruth are shown in Fig. 2 . In part (a), we have the histogram of gray intensities, and we can observe that the gray-intensity distribution of the background is skewed. However, as Fig. 2 b shows, observe that only the left tail is decreased after removing the back-ground contour so that the new distribution is approxi-mately normally distributed. This indicates that the back-ground pixels around the contour are the cause of the left heavy tail while no-edge pixels are approximately normally distributed.

In a similar manner, the skewness of the foreground gray-intensity distribution is caused by pixels around the contour. However, it is also caused by stroke intersections that gener-ate darker pixels and by fading strokes that generate lighter pixels. These later two phenomena are beyond the scope of this article.

Motivated by our previous observations in Fig. 2 ,inthe following sections, we propose a model that not only distin-guishes the pixels around the contour, but also models their gray intensities. denotes the square neighborhood of sides with length 2 r + 1 such that it is centered at the pixel p .
 We identify three classes of pixels which are depicted in Fig. 3 : (A) The Inner foreground , denoted by F  X  ,isthesetofpixels (B) The Inner background , denoted by B  X  ,isthesetofpixels (C) The Frontier , denoted by E  X  , is the set of pixels whose (C.1) The Outer foreground , denoted by F  X  ,isthesetof (C.2) The Outer background , denoted by B  X  ,isthesetof
As we have mentioned above, the pixels are represented in Fig. 3 as disjoint square areas, but the pixels X  sampled areas may not be disjoint areas and may not be squares either. Nevertheless, our pixel model is valid regardless of the pixel X  X  shape or overlapping areas. Readers interested in how the pixel is represented may wish to consult the articles by Smith [ 52 ] and Lyon [ 32 ] where the pixel concept and scanning process are widely discussed. 2.2 Inner foreground and inner background 14 , 22 , 25 ] proposed binarization methods assuming that the gray intensities in both fore-and background are normally distributed. In handwritten historical documents, we indeed
Let D ( q ) = I ( q )  X  I ( v ) be the difference of gray intensity between q  X  P r ( p ) , and a random pixel v  X  P s ( q ) such that q = v ; see Fig. 4 . Then, D ( q ) is approximately distributed with mean zero and variance 2  X  2 and, as a consequence,  X  2 can be estimated from the sample variance of D ( q )  X  X  values within P r ( p ) : 2  X  2  X  1 where  X   X  = 1
For instance, Fig. 5 a, shows three different regions (200  X  200 pixels) from an image, and their corresponding his-tograms of gray intensities (Fig. 5 b) and gray-intensity dif-ferences in neighborhoods of radius 2 (Fig. 5 c). These histograms show that even when the gray intensities in a neighborhood of radius r widely vary, the difference of gray intensities is marginal between pixels that are within a small neighborhood of radius s .

We conduct an experiment in Sect. 3 to generalize our observations from our last example. Such an experiment empirically proves that the inner background is normally distributed in a small neighborhood having a small variance, even when the images appear to have a noisy background. 2.3 Frontier pixels Frontier pixels, defined as in Sect. 2.1 , may be classified either as foreground or as background since they are con-stituted of both regions. We elect to classify a frontier pixel ground. Following this criterion, we subclassify frontier pix-els as outer foreground pixels whose set is denoted by F  X  , ( a ) see Fig. 7 . This happens because of the plateau shape of its gray-intensity distribution. 2.4 The influence of frontier pixels Since the distribution of the fore-and background are thought to be a mixture of normal distributions, several binariza-tion methods are based on finding an optimal fitting [ 11 , 25 ], or the parameters of such a mixture [ 22 ]. Moreover, mix-tures of generalized normal distributions have been proposed to overcome the shape limitation of the normal distribu-tion; see [ 5 , 12  X  14 ]. All these methods disregard the gray-intensity distribution of frontier pixels. Observe in Fig. 8 , gray intensities of the foreground. In a similar manner, the estimated background distribution is determined by the latter two terms. Notice, however, that F  X  r ( p ) could be the empty set; this may happen in low resolution images where the width of ink strokes may be extended over one or two pixels. Similar arguments are given for the background distribution if the ink strokes are extended enough to contain P r ( p ) .

The influence of the outer foreground pixels on the distri-bution of gray-intensity differences of foreground pixels is exemplified in Fig. 9 a: The normal form at the peak is orig-inated by the inner foreground pixels, while the triangular form is caused by the outer foreground pixels. By remov-ing 8-edge pixels, we obtain a subset of pixels where the majority of pixels are inner foreground pixels (although it is not exactly the inner foreground) and, accordingly, its histogram becomes approximately normally distributed; see Fig. 9 b.

Instead of removing 8-edge pixels from the foreground, we can remove 4-edge pixels, but this leads to a subset of pixels where a high number of outer foreground pixels remain in the subset, so that the normality behavior of the gray-intensity differences of inner pixels is less noticeable; see Fig. 9 c.

This analysis points to the fact that the gray-intensity distributions of the fore-and background are neither nor-mally distributed nor lognormally distributed. Neverthe-less, mixtures of normal distributions approximate the gray-intensity distributions of the inner foreground and inner background, while mixtures of lognormal distributions may approximate better the histogram of gray intensities due to the skewed probability density function of the lognormal distribution. 3 Image smoothness In Sect. 2.2 we observed that the background is smooth and approximately normally distributed in small neighborhoods. To generalize this observation, we compute the histograms ( a ) human expert. Five tags were defined (an image may have more than one tag). (a) Smooth background (135 images). (b) Complex foreground (126 images): uneven gray inten-(c) Complex background (75 images): uneven gray inten-
Density Gonzalez [ 19 , pp. 62 X 63], fluctuations of gray intensities &lt; 8 levels are imperceptible and &lt; 16 levels are hardly notable for the human eye.

We observed that the gray-intensity differences of the inner background of an image in our database can be accu-rately approximated by the combination of two normal dis-tributions; see Fig. 10 . Hence, we fitted a mixture of two normal distributions to each histogram. The parameters of such distributions were numerically found by minimizing the absolute distance. This is,  X   X  where E ( X  D ( i ) is the frequency of differences with value i , and  X 
Figure 11 shows an overview of the standard deviations categorized by classes. In these plots, the values of  X  1 and  X  2 are ploted in pairs for each image showing that images with smooth, complex, and bilevel background have similar variances. In fact, our analysis indicates that the inner back-ground of an image is typically 99 % smooth even if it is heavily degraded or bilevel. On the contrary, Table 1 reports that about 5 % of the differences are larger than 16 gray levels 4 Mixtures models In Sect. 2.4 , we analyzed the gray-intensity distributions of the fore-and background pixels. Inspired from that analysis, this section is devoted to showing how good the mixtures of skewed distributions fit the gray-intensity histograms assum-with some state-of-the-art binarization methods under the standard DIBCO X  X  benchmarks.
Besides our previous mixture, we also propose a more complex mixture that models each of our four pixel classes with a different distribution. This mixture is given as: (2) Normal (inner foreground) + Lognormal (outer fore-
To compare our mixtures with the standard approach, we also estimated mixtures of normal distributions as: (3) Normal (foreground) + Normal (background), denoted (4) Normal (inner foreground) + Normal (outer foreground)
For the purpose of this evaluation, the means and variances of gray intensities, for each pixel class, are estimated from the groundtruth. Moreover, the frontier pixels are estimated by the 8-edge pixels of the groundtruth as in Sect. 2.4 .Inthis that our quasi-thresholding methods extract information from the groundtruth. In addition, for the sake of readability, the implementation details of the quasi-thresholds are given in Appendix 2. 4.2 Measures To evaluate the performance of binarization methods, we compute the following measures: such that F and B are the fore-and background, respectively; and their corresponding estimates are  X  F and  X  B .
We also compute the peak signal-to-noise ratio (PSNR) which is a transformed measure of the error rate (ER): PSNR = X  10 log 10 ( ER ) , where (12) ER = where P = F  X  B .

The fitting goodness of a mixture M is evaluated by the fitting error measure (FE) defined as: FE = where H ( i ) is the frequency of pixels with gray-intensity i . 4.3 Evaluation I Our first evaluation assessed the performance of our mixtures for different class images. For this goal, our test images were the same as in Sect. 3.1 and all of the thresholds were globally computed.

Our results show that mixtures based on asymmetrical dis-tributions outperform mixtures based on normal distribution. Although their means are slightly different, see Table 2 , their pairwise comparisons show that LI and NLIN surpass NN in proportions superior to 4:1 for the FM and 5:1 for the PSNR; see Fig. 14 . In similar manner, LI and NLIN sur-pass NNNN in proportions that range between 4:3 to 2:1 depending on the method and measure.
 The cumulative distribution function of fitting error, in Fig. 15 , suggests that NNNN is an overfitted model since gested, in block C the methods X  parameters were systemati-cally chosen in order to maximize the methods X  performance.
Block D groups binarization methods with pre-and post-processing steps and all are locally computed. The limitations of the thresholding approach is then assessed by comparing block D with the other blocks.
 (2) Ram X rez-Orteg X n X  X  thresholds [ 48 ] based on modeling (3) Methods with parameters may attain comparable perfor-(4) The results in block D show that global thresholds in 4.4 Evaluation II Our second evaluation assesses the performance of our mix-tures for DIBCO X  X  benchmark. Our goal is to show the poten-tial of our approach assuming that the ROI are accurately located.
 We implemented the local version of LI and NN as in Algorithm 1, where the neighborhood radius r was set to 15. Our implementation avoids dealing with empty neighbor-hoods (neighborhoods with &lt; 4 foreground pixels) because we analyze the potential of our quasi-thresholding methods within the region of interest.

The results of our evaluation are summarized in Tables 5 , 6 , 7 , and 8 ; some output examples are shown in Fig. 16 . These tables also report the results of several state-of-the-art bina-rization methods that have reported their results and the first top five methods in each competition and in each measure (FM and PSNR). However, readers should notice that the par-ticipant methods in DIBCO X  X  competitions were not aware of the test data so that their performance may be suboptimal since their parameters were automatically set.

Our evaluation suggests that the pixel classification is improved by considering our pixel model. Observe that LI outperforms NN in all the PSNR averages and in almost all the FM averages; the only two exceptions were the FM aver-ages in DIBCO 2011, where NN outperforms LI . Our results also are supported by the pairwise comparison; see Fig. 17 . Note that for both handwritten and printed documents, LI outperforms NN in proportions 3:2 or more.

Although a detailed analysis in printed documents was omitted in this article, our evaluation in DIBCO X  X  bench-
Our study shows the relevance of frontier pixels in the his-togram models. Mixtures of normal distributions, however, can attain high performance as we proved too, not because the underlying gray-intensity distributions are normally dis-tributed, but because mixtures of several normal distributions are malleable.

We also showed that the performance of our quasi-thresholds is promising so that we hope that our study provides the bases to develop further binarization methods that take into account our pixel model. Furthermore, we believe that our model can be generalized to more classes of images, such as machine-printed documents and medical images, since the skewness of the gray-intensity distributions is directly related to the number of pixels at the contour. 6 Further work At this point, we have not addressed two crucial prob-lems to fully implement a thresholding method for histor-ical documents: the detection of ROI and the estimation of the gray-intensity distributions from raw data. Although such problems are beyond the scope of this article, we would like to discuss some potential adaptations of our pixel model for previous binarization methods.

The detection of ROI is a task which has been previ-ously tackled in a great deal of binarization methods such ods have one or more sub-methods devoted to compute the ROI. Therefore, these sub-methods can be combined with our proposed mixtures such that the assumptions of our pixel model hold within a pixel neighborhood.

After detecting the ROI, the gray-intensity distributions should be estimated from the raw data. For this, we think that methods based on edge detectors, like those in [ 9 , 31 ], and on contrast measures, like those in [ 45  X  48 , 51 , 53 , 56 ], are suitable for our pixel model since such methods are focused on detecting contours, from which the gray-intensity distributions can be inferred. However, we also recommend exploring methods based on rough binarizations, like those
There are two methods that we should mention since both methods can be straightforwardly transformed: Hed-jam X  X  [ 20 ] and Ram X rez-Orteg X n X  X  [ 46  X  48 ] methods. As we mentioned in the introduction, both methods estimate the gray-intensity distribution of the fore-and background, and both methods are based on Bayes rule assuming nor-mal distributions. Consequently, both methods can be mod-ified to compute LI  X  X  threshold and, potentially, to compute NLIN  X  X  threshold.

In general, a thresholding method that models the gray-intensity histograms as normally distributed can be trans-formed to model the gray-intensity histograms as (inverted) that corresponds to a random variable that is normally dis-tributed with the specified parameters.
 Proof of 2 : From the properties of MGF X  X , we have: M where the function M W | u ( t ) denotes the moment generat-ing function of W with respect to the conditional density f Then the conditional MGF in ( 19 ) is equal to M
Without loss of generality assume that  X  1 &gt; X  2 . To obtain unconditional MGF of W we integrate the last expression over the U  X  X  domain as following: M where c = exp t  X 
If t &gt; 0, then ( 23 ) is smaller than or equal to  X  exp t  X  = exp t  X  Similarly, if t &lt; 0 then ( 23 ) is smaller than or equal to exp t  X  2 +
Since in both cases, the moment generating function is dominated by a MGF of a random variable with Normal dis-tribution and variance 3  X  2 , the conclusion follows. Proof of 3 : Based on ( 20 ) we have that M as  X  (2) Inverted lognormal: Quasi-thresholding NLIN The mixture NLIN models the gray-intensity histogram as the mixture of the gray-intensity distributions of the inner foreground, outer foreground, inner background, and outer background. Such sets are estimated as:  X  F  X  = F \ E ,  X  F  X  = F  X  E ,  X  B  X  = B \ E , and where E denotes the set of 8-edge pixels: E = { p  X  P such that F
Once the frontier pixels are estimated, the gray-intensity distribution of the foreground is modeled as the mixture of a normal distribution (corresponding to the inner foreground) and a lognormal distribution (corresponding to the outer fore-ground). On the other hand, the gray-intensity distribution of the background is modeled as the mixture of a normal distribution (corresponding to the inner background) and an inverted lognormal distribution (corresponding to the outer background).

Formally, the threshold of NLIN is defined by Bayes rule as the value x that satisfies: M
