 1. Introduction
In the last decade, ontologies have experienced an enormous development motivated by the growing interest in exploiting the contents of the World Wide Web, which is driven by global initiatives like the Semantic Web ( Berners-Lee et al., 2001 ).
Ontologies provide a formal representation of a shared concep-tualization by means of classes, instances, properties and semantic relationships ( Guarino, 1998 ); that is, they offer a structured and machine-readable representation of the semantics related to one or several domains of knowledge. Ontologies have in fact become the cornerstone of many knowledge-based engineering applica-tions that require managing and interpreting data (usually text) from a semantic perspective. Just to name a few, ontologies are extensively used to improve information retrieval ( Castells et al., 2007 ) and extraction ( S X nchez et al., 2011; Vicient et al., 2013; Wimalasuriya and Dou, 2010 ), resource classi fi cation ( Allampalli-
Nagaraj and Bichindaritz, 2009; Batet, 2011 ), to achieve interoper-ability between heterogeneous systems ( Valls et al., 2010 )orto interpret textual data semantics in areas such as automatic reasoning ( Chan et al., 2011; Wriggers et al., 2007 ) or data privacy ( Mart X nez et al., 2013; S X nchez et al., 2013; S X nchez et al., 2014 ).
Moreover, ontologies are the key to bring semantic content to electronic textual resources under the umbrella of the Semantic Web ( Berners-Lee et al., 2001 ).
 been developed and made available through the Web that cover a variety of overlapping topics and domains ( Ding et al., 2004 ).
However, the lack of consensus in ontology development ( Simperl et al., 2009; Zouag and Nkambou, 2010 ) raises the following question: which ontology, among those covering a certain domain of knowledge or modeling the same concepts, is the best one for a speci fi c task? Ontology evaluation and, more speci fi cally, our work here try to answer the previous question. 1.1. Background on ontology evaluation ontologies, either to provide feedback to ontology developers and knowledge engineers or to give insights on the adequacy of ontologies to their users ( Corcho et al., 2005; Vrandecic et al., 2005 ). The dimensions considered in ontology evaluation are, however, quite diverse. In ( Vrandecic, 2009 )acharacterizationof the quality criteria usually employed in the ontology evaluation literature is provided in terms of accuracy of the semantics repre-sented by the ontology, adaptability to different contexts, clarity for human readers, completeness , conciseness and logical consistency .
From the perspective of automated knowledge-based systems, semantic accuracy , which captures the seman tic coherency and suit-ability of the de fi nition and description of ontological components (i.e., classes, relationships, etc.), is the most important dimension because it directly in fl uences the precision of the semantic assess-ments or inferences ( Fern X ndez et al., 2009 ). More speci semantics are inherently human features, semantic accuracy is seen as the ability to properly represent semantics as understood by society, because this will enable knowledge-based systems to better mimic human reasoning, which is usually the main goal of such systems.

Ontology evaluation can be perform ed (i) manually, which requires a human expert to measure the quality of the ontology ( Lozano-Tello and G X mez-P X rez, 2004 ), (ii) automatically, in which case the ontology quality is measured according to a speci fi c criterion (i.e., a Golden
Standard ( Maedche and Staab, 2002 )), or (iii) oriented to a speci task, in which case the ontology quality is a function of the accuracy of the results provided by the application in a speci fi ctask( Sabou et al., 2007 ). However, on the one hand, manual approaches are hardly scalable given the large amount of ontologies that are currently available, whereas a task-oriented evaluation may only provide a biased assessment of ontology quality if the task is not generic enough.
Automatic methods, on the other hand, are more generic and scalable ( Burton-Jones et al., 2005; Lozano-Tello and G X mez-P X rez, 2004 ), but they require de fi ning appropriate evaluation criteria.
If we focus on the evaluation of the ontological accuracy, which is the aim of this paper, most approaches rely on the analysis of structural features of ontologies ( Fern X ndez et al., 2009; Tartir et al., 2010; Vrandecic, 2009 ). Indeed, since the same knowledge (i.e., a set of speci fi c concepts belonging to a domain) can be modeled in many different (more or less accurate) ways, and ontologies model concepts as semantic graphs, the resulting graph structures (i.e., number of classes, relationships, taxonomic depth, branching factor, etc.) can vary highly for ontologies describing the same knowledge ( Vrandecic, 2009 ). Evaluation approaches based on these features assume that, given a set of manually constructed or validated ontologies (i.e., with a minimum structural coher-ency), their structure may give insights on the accuracy of the modeled knowledge. The advantages of this kind of analysis are: (i) it provides a numerical, unambiguous and objective character-ization of the ontology, (ii) it can be easily and ef fi ciently calculated from the graph de fi ned by the semantic links modeled in the ontology, (iii) its assessment does not depend on potentially subjective, biased or domain-dependent external resources such as other knowledge sources or experts' criteria. However, the analysis of the current literature ( Alani et al., 2006; Buitelaar et al., 2004; Fern X ndez et al., 2009; Gangemi et al., 2006; Guarino and Welty, 2009; Tartir et al., 2005 ) also reveals the following drawbacks: (i) individual structural features (e.g., maximum taxo-nomic depth, number of classes, etc.) only provide a partial picture of the ontology quality, so different features are usually aggregated using ad hoc measures and weights, a solution that lacks a sound theoretical basis and, hence, generality; (ii) many methods rely on non-taxonomic structural features (e.g., non-taxonomic relation-ships, attributes, logical restrictions, etc.), which are hardly found in available ontologies (most of them only model taxonomic relationships ( Ding et al., 2004 )); and (iii) usually, it is not clear which features are the most suitable ones to quantify the semantic accuracy of ontologies. A recent study by Fern X ndez et al. (2009) has shed some light on the latter issue by identifying how certain structural features can be used to reasonably predict the semantic accuracy of ontologies. Speci fi cally, the authors manually evalu-ated the semantic correctness of the relationships modeled in a set of ontologies obtained by means of ontology alignment techniques and manually validated by knowledge experts; as a result, the set of ontologies were classi fi ed as reliable or non-reliable. Then, the authors studied which structural characteristics could be used to identify the reliable ontologies. The authors mainly focused on taxonomic features (e.g., number of classes, taxonomic depth, breadth, etc.), which are the kind of features that are available in most ontologies. They concluded that the maximum, average and variance of the taxonomic depth, and the maximum and variance of the taxonomic breadth (i.e., number of concepts at each taxonomic level) seem the best predictors of the semantic accu-racy of ontologies: the larger these features are, the higher the probability that the ontology is a reliable one. However, since there is no unique characteristic that can be used to assess the accuracy of an ontology and individual feature values may be contradictory to each other, an ad hoc aggregation or selection of features based on empirical hypotheses is still needed. Moreover, the values of these features are greatly in fl uenced by the cardin-ality (i.e., number of concepts) of the ontology, thus hampering the comparison of ontologies with signi fi cantly different sizes. Finally, such structural characteristics are used as thresholds for binary classi fi ers (i.e., reliable or non-reliable ontologies) and not as a continuous quality score. Yet the latter score is the most suitable tool for ontology evaluation, as it enables selecting the best ontology from a set of candidates modeling the same knowledge. 1.2. Contributions and plan of this paper
In this paper we present and formalize the notion of semantic variance of an ontology as an evaluation measure to quantify the ontology's semantic accuracy. In contrast to the ad hoc nature of most of the available ontology evaluation approaches, our proposal aims at measuring the semantic dispersion of an ontology by means of a mathematically coherent interpretation of the classical numerical variance of a sample, but applied to the knowledge structure of the ontology. Moreover, it solely relies on taxonomic knowledge, which is what all available ontologies have in common ( Ding et al., 2004 ). By implicitly capturing the unbalance of the taxonomic structure of the ontology, our measure aims at provid-ing a semantically coherent and numerically normalized quanti cation of the ontological dispersion, which does not depend on the cardinality of the ontology. We will also show that such dispersion correlates with the structural features that, as discussed in previous studies ( Fern X ndez et al., 2009 ), seem to be related to the accuracy of the ontology. Thus, the semantic variance measure could be used as a unique, generic, non-parameterized and quantitative score to evaluate the accuracy of ontologies modeling the same domain. Last but not least, this score is intuitive, theoretically coherent and easy to implement.

The theoretical hypotheses of this work are also empirically validated by showing the positive correlation between the rele-vant structural characteristics of several well-known ontologies and the proposed notion of semantic variance . Moreover, the suitability of the semantic variance as a tool to select the most accurate ontology from a set of ontologies covering the same domain of knowledge is also evaluated by computing the perfor-mance of these ontologies in one of the most basic and relevant ontology-based tasks: assessing the semantic similarity between concepts ( S X nchez et al., 2012 ).

The rest of this paper is organized as follows. Section 2 introduces and formalizes the notion of semantic variance and illustrates its suitability as a measure of semantic dispersion and its relationship with some relevant structural features through several examples. Section 3 details the empirical experiments performed with several well-known ontologies and shows how our measure can be of use as an intuitive score for ontology accuracy evaluation. Section 4 describes other applications of the semantic variance , such as measuring economic diversity, measuring biodiversity and also quantifying the protection of con fi dential information in database anonymization. The section gathers some conclusions. 2. Semantic variance
As mentioned above, the empirical results reported in Fern X ndez et al. (2009) suggest that the structural features that, individually, can be used to predict the ontologies with the best reliability are:  X 
Maximum depth (length of the longest taxonomic branch in the ontology, measured as the number of concepts from the root node to the leaves of the taxonomy), average depth (average length of all taxonomic branches) and depth variance (disper-sion with respect to the average depth, computed as the standard mathematical variance).  X 
Maximum breadth (width of the taxonomic level of the ontol-ogy with the largest number of concepts) and breadth variance (dispersion with respect to the average breadth).

The authors of that study argue that, among the above features, the depth and breadth variances are the best predictors (i.e., the larger they are, the higher the probability of the ontology being reliable). In contrast, other structural features commonly used in the ontology evaluation literature, such as the total number of concepts or the number of properties, do not show a signi relationship with the ontological accuracy.

These results suggest that, in general, the dispersion and unba-lance of the taxonomic structure of an ontology, which are mainly re fl ected by its variance in depth and breadth and are limited by the maximum depth/breadth of the taxonomy, are positively correlated with the semantic accuracy of the knowledge modeled in the ontology. This also suggests that a semantically accurate representa-tion of the knowledge of a domain is rarely achieved by a homo-geneous taxonomic structure. This is coherent with the inherent nature of knowledge representation, which is an ex post formalization of the de facto semantic consensus of human society ( G X mez-P X rez et al., 2004 ). Since such semantics unpredictably and informally evolve as societies develop their knowledge, the posterior formaliza-tion is unlikely to produce homogenous and balanced knowledge structures. Moreover, a very homogeneous knowledge structure indicates that concepts are evenly distributed through the taxonomy; thus, due to this homogeneity, they become less distinguishable from each other according to that structure. This goes against the main goal of knowledge modeling, which is making concepts well differentiated from each other in order to minimize the ambiguity of semantic inferences obtained from the modeled knowledge ( Pirr X , 2009 ).
Paradoxically, a problem of the above-detailed features is that they are highly dependent on the size of the ontology (especially for the maximum and average depth and breadth). Hence, large ontologies will tend to systematically provide larger values than smaller ones.
The question is, how can we measure in an integrated and semanti-cally and mathematically coherent way the degree of unbalancing or semantic dispersion of an ontology so that it can be used as a quantitative evaluation measure of ontological accuracy? To answer this question, we propose the notion of semantic variance of an ontology, which is inspired by the usual notion of numerical sample variance.

Within a numerical domain, the usual variance is used to quantify the dispersion of a sample of values with regard to the center (mean) of that sample. It is computed as the average squared difference (or distance) between each element s i of a sample S and the mean of the sample ( Parzen, 1960 )
Var  X  S  X  X  tribution of the most scattered values. In the extreme cases, a zero variance indicates that all values are identical, whereas a high variance indicates that values are very spread out from the center and from each other, hence being clearly distinguishable. the context of ontologies: we want to capture the degree of dispersion of concepts modeled in a given ontology with respect to the center of the knowledge structure of that ontology. Ideally, this should not depend on the size of the ontology, just like the numerical variance does not depend on the size of the sample.
From a taxonomic perspective, the  X  center  X  or centroid of an ontology is the root node of the taxonomic tree, since it is the concept that generalizes the meaning of all the other concepts, which are its specializations. Note that, even if the ontology incorporates several disjoint taxonomic trees, all of them can be joined by a virtual root that subsumes all of them, as it is done in most knowledge repositories (e.g., entity in WordNet, Concept in
SNOMED-CT, Top in ODP, thing in OWL ontologies, etc.). In a perfectly balanced taxonomy, in which all branches have the same depth and the branching factor is constant, this root node coin-cides with the geometric center of the graph de fi ned by the taxonomy; thus, this central node is the one that minimizes the distances with respect to all the concepts in the ontology ( Mart X nez et al., 2012 ). In contrast, when taxonomic branches present different depths (i.e., higher depth variance , which is limited by the maximum depth ) and branching factors (i.e., higher breadth variance , which is limited by the maximum breadth ), the unbalance of the ontology with respect to the root node (i.e., the center in a perfectly balanced taxonomy) increases. Thus, by measuring the degree of unbalance, we are quantifying the dispersion of concepts in the ontology that, as discussed earlier, is a direct function of the structural characteristics that are related to the ontological accuracy. We name this notion of semantic dispersion semantic variance of an ontology. Consistently with the numerical case, we de fi ne it as follows: models in a taxonomic way a set of concepts C , the semantic variance of O is computed as the average of the squared semantic distance d ( , ) between each concept c i A C in O and the taxonomic Root node of O. If we denote by | C | the cardinality of C excluding Root ( O ), the mathematical expression of the semantic variance of O is :
Semantic_Variance  X  O  X  X  variance calculation because, even though depth -related features only refer to the leaves of the taxonomy, breadth -related features also consider inner nodes.
 ontologies modeling the same domain, the a priori most accurate ontology can be selected as the one with the maximum variance.
The proposed measure can also be applied only to particular taxonomic branches of a set of ontologies. This is relevant because the different scopes and goals for which ontologies are designed may not allow comparing ontologies as a whole, but only those taxonomic branches modeling the same domains. With our method, this partial comparison can be done by using the common generalization of that branch as the root, and by computing the distances towards all of its taxonomic specializations. In this manner, we are not only able to evaluate and select entire ontologies, but also to measure if a speci fi c taxonomic branch of an ontology provides a better differentiation of concepts in that branch than its counterpart branch in another ontology. 2.1. Computing the semantic distance
The key element to measuring the semantic variance as de fi in Expression (2) is the calculation of the semantic distance d ( , ) between each concept in the ontology and the root node of the taxonomy. On the one hand, a suitable distance measure ought to accurately capture the semantic differences between concepts. On the other hand, in order to coherently compare the variances of ontologies with different number of concepts, the distance values should not depend on the cardinality of the ontology.

Within the literature of computational linguistics, a plethora of approaches have been proposed to measure the semantic distance by exploiting the knowledge modeled in the ontology ( Harispe et al., 2014 ). The simplest methods evaluate ontologies as directed graphs in which the distance between two concepts is measured as the number of edges of the shortest path between them ( Rada et al., 1989 ). Since there is no normalization, distance values tend to be larger as the ontology size increases. Thus, if we use this approach to compute the semantic variance , large ontologies will systematically yield larger variance values. Another drawback of edge-counting measures is their relatively low accuracy, which is motivated by the fact that they only consider the shortest path connecting the two concepts; in ontologies in which concept pairs are connected by several paths, a lot of explicit knowledge is omitted, which negatively in fl uences the similarity assessment accuracy ( Batet et al., 2011 ).

To solve the drawbacks of edge-counting measures, feature-based approaches are proposed. They compare concepts according to the amount of semantic evidences that they have and do not have in common. In ( Batet et al., 2011; S X nchez et al., 2012 ), a state-of-the-art feature-based measure is proposed that measures the semantic distance d ( c 1 , c 2 ) between two concepts c function of their number of non-common taxonomic ancestors divided (for normalization) by their total number of ancestors: d  X  c ; c 2  X  X  log 2 1  X  T
In the above expression T ( c i ) is the set of taxonomic ancestors of concept c i in the ontology, including itself.

From a semantic perspective, the measure of Expression (3) captures more taxonomic knowledge than edge-counting meth-ods, since it implicitly considers all the paths connecting the two concepts. Moreover, thanks to the normalizing denominator, the distance can differentiate concept pairs with the same number of shared ancestors. Finally, the non-linearity of the calculation better aggregates the semantic evidences gathered from the ontology (i.e., number of common and disjoint ancestors), because the relationship between the amount of such evidences and the semantic distance has also proven to be non-linear ( Lemaire and Denhi X re, 2006 ). As a result, Expression (3) approximates human judgments of similarity better than other ontology-based measures, as demonstrated for several standard evaluation bench-marks ( Batet et al., 2011; S X nchez et al., 2012 ).

Further, in contrast with the absolute distance values provided by edge-counting methods, Expression (3) yields positive normal-ized values in the [0,1] range. Thus, the measure does not depend on the ontology size and is therefore suitable to measure and coherently compare semantic variance s of ontologies with different cardinalities. Finally, as demonstrated in ( S X nchez et al., 2012 ) and ( Batet et al., 2010 ), Expression (3) satis fi es non-negativity, re ivity, symmetry and the triangular inequality, thereby being a distance measure in the mathematical sense. This is relevant in order to apply the semantic variance as a mathematically coherent replacement of the standard numerical variance in algorithms or methods dealing with semantic values ( Domingo-Ferrer et al., 2013; Soria-Comas et al., 2014 ). 2.2. Examples and discussion
When using Eqs. (2) and (3) , we have that the minimum semantic variance is obtained with a perfectly balanced taxonomic structure, in which the root node matches the geometric center of the graph and in which all concepts in the taxonomy are structu-rally indistinguishable from each other (i.e., they are direct specializations of the root node). Fig. 1 shows an example of such a structure in which four concepts extracted from WordNet ( Fellbaum, 1998 )( Orange , Clementine , Strawberry and Blackberry ) are modeled as direct specializations of the root node ( Fruit ). In practice, such taxonomy is equivalent to a fl at list of concepts, which gives no insight about their semantic commonalities or differences, thus failing to offer proper knowledge modeling.
Structurally, in this extreme case, the average and maximum depth of the taxonomic branches is 1 and the depth variance is 0. Regarding the breadth, the maximum breadth is 4 and the breadth variance is 0, without considering the root node that is assumed to be unique (or virtually added) in all ontologies. The low values of these structural features suggest that, according to the empirical study in ( Fern X ndez et al., 2009 ), the ontological accuracy is also low. This is coherent, since in a taxonomic structure as simple as the one shown in Fig. 1 , all concepts have the same level of speci fi city and their semantic distances are identical, which makes them structurally indistinguishable. In this case, the semantic variance of the ontology is:
Next, let us consider the ontology represented in Fig. 2 , which shows an alternative representation of the same four concepts. In this case, an inner taxonomic level ( Citrus and Berry ) has been
Semantic_Variance  X  O 1  X  X  d :;
Fruit  X  2  X  d  X  Black :; Fruit  X  2 1  X  X  1 = 2  X  2  X  log 2 1  X  X  1 = 2  X  2 added to differentiate the pair of concepts Orange and Clementine from the pair Strawberry and Blackberry .

In this case we have that the average and maximum depth of the taxonomic branches is 2 and the depth variance is 0. Moreover, by considering all the nodes in the ontology except the root node, the maximum breadth is 4 (the average breadth is 3) and the breadth variance is ((2 3) 2  X  (4 3) 2 )/2  X  1. The structural measures of taxonomic dispersion are still low and the root is still the perfect geometric center of the taxonomy, but both the maximum depth and the breadth variance have increased as a result of the better differentiation between concepts. The semantic variance of this ontology also increases accordingly:
Finally, let us consider a third sample ontology shown in Fig. 3 , in which Clementine has been more differentiated from Orange by adding a new inner node ( Mandarin ). This is precisely the way in which these concepts are modeled in WordNet.
 Due to the longer taxonomic branch de fi ned by the concept
Clementine , the maximum depth is now 3, the average depth is (2  X  3  X  2  X  2)/4  X  2.25 and the depth variance is ((2 2,25) 2,25) 2  X  (2 2,25) 2  X  (2 2,25) 2 )/4  X  0.8125. On the other hand, the maximum breadth is still 4 (breadth average is now 2,33) and the breadth variance is ((2 2,33) 2  X  (4 2,33) 2  X  (1 2,33) 2
The increase in the depth and breadth variances suggests a less balanced structure, which is re fl ected by the fact that the root node is not the perfect geometric center of the tree anymore. The semantic variance also re fl ects this dispersion increase:  X  d  X  Oran :; Fr :  X  2  X  d  X  Clem :; Fr :  X  2  X  d  X  Straw
The behavior of the semantic variance is driven by the semantic distance de fi ned in Eq. (3) that, given a set of concepts/domain to be modeled, it increases when: starting from the trivial structure shown in Fig. 1 , any possible change of the taxonomic structure in order to better differentiate concepts will either (i) maintain the geometric balance (i.e., root node as the center) but add more inner nodes that contribute to increasing the maximum and average depth and the breadth variance (like in Fig. 2 )), or (ii) introduce a degree of unbalance, which will increase the depth variance and/or the breadth variance (like in
Fig. 3 ). In both cases, the semantic variance will increase. Hence, the semantic variance quanti fi es the degree of deviation from the trivial structure in which concepts are structurally indistinguishable.
Furthermore, it is proportional to the degree of semantic dispersion and, thus, of semantic distinguishability, of concepts modeled in the ontology, which is desirable from the perspective of knowledge engineering ( Pirr X , 2009 ). Other interesting characteristics of the semantic variance are: (i) due to the squared distance calculation of the standard variance on which it relies, it increases as the unbalance of the taxonomy increases, because the increasing dis-tance of the farthest concepts to the root node will have a greater in fl uence in the calculation; (ii) the semantic distance measure d ( , ) aggregates features in a logarithmic way, which better corre-lates with the non-linear nature of semantic evidences ( Lemaire and
Denhi X re, 2006 ); (iii) the semantic variance does not depend on the cardinality of the ontology, because both the aggregation of dis-tances and the distance itself are normalized with respect to the number of concepts in the ontology; and (iv) it yields values bounded in the range [0..1] (which is the range of the distance d ( , )), thus facilitating the comparison of variance values computed from different ontologies. 3. Empirical results experiments aimed to illustrate: Fig. 3. Sample ontology O (1) How the semantic variance aggregates and positively correlates with the structural features that, as discussed above, help to identify semantically accurate ontologies. (2) How the semantic variance can be used as a quantitative ontology evaluation score to select the most accurate ontology from a set of ontologies modeling the same domain, and how this predicted accuracy is re fl ected, in practice, in the results achieved by an essential knowledge-based task.
 In the experiments, we used three well-known ontologies: Word-
Net, as a domain-independent repository, and SNOMED-CT and MeSH as domain-speci fi c ontologies modeling biomedical concepts. All three ontologies have been widely used to evaluate semantic measures ( Batet et al., 2013; Pirr X , 2009; S X nchez et al., 2012 )andtoguide knowledge-based systems ( Mart X nez et al., 2013; S X nchez et al., 2013 ).
WordNet ( Fellbaum, 1998 ) is a freely available lexical database that describes more than 80,000 general concepts, which are semantically structured in an ontological way. The taxonomic structure in WordNet corresponding to nouns is very comprehensive and represents most of the semantic relationships modeled in the ontology ( Devitt and Vogel, 2004 ). The root node of the taxonomy, which is used in the calculations of the semantic variance is entity . We used WordNet version 2.1 in all the experiments.

The Systematized Nomenclature of Medicine, Clinical Terms (SNOMED-CT) ( Spackman and SNOMED, 2004 ) is one of the largest sources included in the Uni fi ed Medical Language System (UMLS) of the U.S. National Library of Medicine. It contains around 300,000 concepts organized into 18 overlapping hierarchies. Con-cepts in SNOMED-CT typically present a high degree of multiple inheritance (i.e., they may have multiple ancestors at the same taxonomic level) and are linked with approximately 1.36 million relationships. The root node that subsumes all the hierarchies and which is used in our calculations is SNOMED -CT Concept . We used the July 2013 release of SNOMED-CT in our experiments.

The Medical Subject Headings (MeSH) ( Nelson et al., 2001 )isa hierarchy of medical and biological terms de fi ned by the U.S
National Library of Medicine to catalog books and other library materials, and to index articles for inclusion in health-related databases including MEDLINE. It consists of a controlled vocabu-lary and a hierarchical tree with 16 categories containing more than 26,000 concepts. MeSH does not explicitly include a common root to all the 16 categories. Thus, consistently with the premises of our work, we added the abstract MeSH concept as virtual root subsuming all of categories to be used in our calculations. The 2011 release of MeSH was used in our experiments. 3.1. Relationship between ontological features and semantic variance
Table 1 shows an overview of the structural features of the three ontologies with respect to their depth and breadth features, and the semantic variance obtained with Eq. (2) .Wecanseethat,forall structural features, there is a positive correlation with the semantic variance . In fact, the Spearman rank order correlation coef 1 in all cases, since the relative orde ring according to each feature and the semantic variance match perfectly. Quantitatively, the relationship between individual structural features and the semantic variance is not linear (i.e., differences in the semantic variances of the different ontologies are much lower than for t he structural features). Indeed, the structural features closely depend on the cardinality of the ontology, thus making it dif fi cult to compare ontologies with sig-ni fi cantly different sizes. Moreover, in ( Fern X ndezetal.,2009 ) structural values were not considered as fi nal ontology evaluation scores but just evidences to distinguish reliable ontologies. In contrast, the semantic variance yields values normalized in the range [0..1] that do not depend on the cardinality of the ontology, but just on the dispersion of the taxonomic structure. In the second part of this experimental study, we will analyze the behavior of the semantic variance as a quantitative ontology evaluation score.

The comparison of the three ontologies shows that SNOMED-CT has the largest semantic variance , followed by WordNet and, MeSH. However, the scopes of the three ontologies do not allow a fair comparison of the semantic accuracy because they model different domains: SNOMED-CT and MeSH are both biomedical knowledge repositories with a high degree of overlap ( S X nchez and Batet, 2013 ), whereas WordNet is a general-purpose repository that models many different domains. Thus, one would expect SNOMED-CT and MeSH to be more accurate than WordNet with regard to the modeling of medical concepts. In order to fairly compare the dispersion of three structures within the same domain, as introduced in Section 2 we computed the semantic variance of taxonomic branches of the three ontologies whose scopes match. To do so, we extracted the taxonomic branch that corresponds to a physical disease from the three ontologies. In SNOMED-CT, this corresponds to the set of specializations of the Disease ( disorder ) concept, which acts as the root node for the semantic variance calculation; for MeSH it corresponds to the third main taxonomy, C-Disease , and for WordNet it corresponds to the tree under the ill health concept. Table 2 shows the values of the structural features and the semantic variance for these taxonomic structures.
The pairwise relationship between breadth and semantic variance shows again a perfect Spearman correlation. SNOMED-CT's disease taxonomy has the largest semantic variance but it is now followed by MeSH and WordNet. If we use the semantic variance as a measure of accuracy, it turns out that, with regard to the modeling of medical entities, the two biomedical ontologies (MeSH and SNOMED-CT) are more accurate than the general-purpose WordNet, even though WordNet as a whole presents a larger dispersion than MeSH.
On the other hand, the correlation between depth and semantic variance (and thus, between depth and breadth ) is not positive in this case, even though the differences between depth-related values for the three taxonomic structures are relatively small. This mismatch shows the limitations of these structural features as individual ontology evaluation scores, which may yield contra-dictory assessments. In contrast, the semantic variance provides a semantically coherently aggregated score of taxonomic dispersion that is a function of both the depth and the breadth . In this case, the larger differences in the breadth variance between the three structures dominate the semantic variance .
 3.2. Task-oriented ontology evaluation
As discussed in the introduction, one of the goals of ontology evaluation is to facilitate the selection of the most suitable ontology for a particular task in those cases in which several ontologies modeling the same domain are available. On the other hand, task-oriented ontology evaluation consists in measuring the quality of an ontology according to the accuracy of the results that it yields for a speci fi c ontology-based task ( Sabou et al., 2007 ). In this section, we combine both lines in order to evaluate the suitability of the semantic variance as an ontology evaluation score that can be used to select the most suitable ontology (from a set of ontologies modeling the same domain) in one of the most essential ontology-based tasks: assessing the semantic similarity (or distance) between concepts.

Semantic similarity aims at mimicking the human reasoning when assessing the similarity or the distance between concepts mentioned in a context (e.g., a se ntence, a document, a database, etc.). Thus, it constitutes a key tool for understanding textual resources. Most of the semantic similarity/distance measures avail-able in the literature (such as those introduced in Section 3.1 ), exploit the knowledge modeled in one or several ontologies to obtain a numerical score for a given pair of concepts ( Batet et al., 2013;
Harispe et al., 2014; S X nchez and Batet, 2013 ). Thus, semantic similarity assessment is one of th e most general ontology-based tasks and it is the cornerstone of many applications such as document classi fi cation ( Cilibrasi and Vit X nyi, 2006 ), semantic dis-ambiguation ( McInnes and Pedersen, 2013 ) or information retrieval ( Budanitsky and Hirst, 2006 ). The evaluation of the accuracy of semantic similarity assessment i susuallytackledbycomparing human judgments of similarity against the computerized scores for asetoftermpairs( Pedersen et al., 2007 ). The correlation between both assessments objectively quanti fi es the accuracy of a given semantic measure.
 tic measures. They consist of a set of term pairs with similarity ratings provided by a set of human experts. Given the scope of the ontologies considered in this empirical study, we focused on
Pedersen et al.'s (2007) benchmark, which has become the de facto evaluation standard within the biomedical domain ( Harispe et al., 2014; McInnes and Pedersen, 2013; S X nchez and Batet, 2011 ). It consists of 30 pairs of medical terms, whose similarity has been assessed by a group of experts of the Mayo Clinic in the range [1..4]. Table 3 lists the set of term pairs and the averaged experts' similarity scores, and indicates which pairs are included in any of the three ontologies considered in this study. Also, we marked in boldface those pairs modeled as diseases in the three ontologies, as in the second part of the previous experiment ( Table 2 ). scenario. First, we de fi ned several data sets with the subsets of term pairs that can be found in the ontologies as a whole and those that were modeled as diseases . According to Table 3 ,we created the following data sets: marked with a boldface  X  yes  X  in the fourth, fi fth and sixth column of Table 3 .

After that, we computed the Pearson correlation between the set of human similarity ratings (reported in the third column of Table 3 ), and the set of semantic distance values obtained with the measure introduced in Expression (3) for the term pairs of the three data sets detailed above. In order to measure the distances, we used the different medical knowledge bases considered in this study:
SNOMED-CT and MeSH as a whole, and the taxonomic branches corresponding to diseases of SNOMED-CT, MeSH and WordNet, as detailed in the previous section. Note that, since Expression (3) mea-sures distance whereas human ratings in the benchmark quantify similarity (i.e., the opposite of distance), we needed to invert distances by changing their sign. As stated above, the correlation between both sets of values quanti fi es the accuracy of the semantic similarity assessment and, since we use the same similarity measure in all tests, it thus measures the quality of the associated ontology/ taxonomy for this particular task. As a proof of the statistical signi fi cance of the correlation values obtained for each dataset and ontology/taxonomy, we also measured the p -value of the Pearson correlation; according to Johnson (2013) ,a p -value below 0.001 is a proof of statistical signi fi cance under the strictest standards. Finally, we compared the correlation values with the semantic variances reported in the previous section for each ontology and taxonomic tree, so that we could assess whether the semantic variance was a good score for evaluating the quality of ontologies and, thus, whether it could be used to guide the selection of the most appropriate ontology for this particular task. The results of this experiment are shown in Table 4 .

It is important to note that we refrained from including WordNet in the comparison of the semantic variances of the complete ontologies. As stated above, because WordNet is a general-purpose ontology whereas both SNOMED-CT and MeSH focus on biomedical terms, this comparison is not fair for WordNet, because its semantic variance re fl ects the dispersion of concepts belonging to many different domains and not only biomedical terms. On the other hand, the three ontologies were considered when evaluating only the taxonomic trees and term pairs corresponding to diseases because the scopes of the three structures are comparable.
We can see that in most cases there is a positive correlation between the accuracy of the semantic assessment and the semantic variance of the ontology: the greater the semantic variance ,themore accurate is the assessment. In fact, the Spearman rank order correla-tion coef fi cient is 1 in all cases. Only with Dataset 3(i.e.,thesmallest one), SNOMED-CT and MeSH gave the same correlation (0.9) but different variances (0.905 and 0.785, respectively); however, this result is not as statistically signi fi cant (i.e., p -values above 0.001) as those obtained for the same ontologies with the larger Dataset 2, which also considered physical diseases and which showed a positive correlation between the accuracy of similarity assessments and the semantic variance . These results illustrate how th e semantic similarity/distance assessment bene fi ts from a knowledge structure that, due to its taxonomic unbalance (re fl ected by a larger semantic variance ), differ-entiates concepts better. Certainly, large depth and breadth variances, which increase the semantic variance asshownintheprevious experiments, provide more degrees of freedom to the semantic assessment because similarity/distance values become less homoge-neous and more fi ne-grained. This observation is also coherent with the empirical results reported in the literature on semantic similarity, in which the most accurate measures are usually those that best exploit the differences between concepts explicitly modeled in the ontological structures ( S X nchez et al., 2012 ). This also suggests that, given a certain semantic measure, the most appropriate ontology would also be the one that differentiates concepts best.
Furthermore, we can see that the numerical scales of the semantic variance and the Pearson correlation values are quite linearly proportional for each data set; this contrasts with the numerical ranges of the structural features analyzed in the previous section, which were much broader, because they depended on the cardinality of the ontologies. For example, as shown in Table 1 ,even though the values of the structural features of SNOMED-CT are much larger than those of MeSH (because SNOMED-CT has around 300,000 concepts whereas MeSH only incorporates around 22,000), their semantic variances are not that different (0.880 vs. 0.815) nor are the semantic assessment accuracies they achieve (0.69 vs. 0.66). As stated in Section 3 , this behavior is the result of the normalized results provided by Eq. (3) and the non-linear integration of semantic features. In fact, as shown in Table 4 ,the disease taxonomy of SNOMED-CT yields a semantic variance greater than the whole taxonomy (0.905 vs. 0.880), which shows how, regardless the size of the evaluated structure, the disease taxonomy of SNOMED-CT is more spread out than the whole ontology. Moreover, as shown in Tables 2 and 4 , while individual structural features (i.e., depth and breadth ) led to contradictory conclusions on the accuracy of MeSH and WordNet when evaluating the disease taxonomy, the semantic variance positively correlates with the semantic similarity accuracy. These results suggest that the semantic variance can be used as a better predictor of the accuracy of an ontology in this task, thus allowing the selection of the most appropriate ontology from a set of overlapping ones. Lastly, for a more accurate prediction in speci domains or applications, the semantic variance calculation can be applied not only to complete ontologies but also to the speci taxonomic tree(s) in the ontology that model(s) the domain of interest, as illustrated in the tests related to the disease trees. 4. Other applications of the semantic variance
Even though this work focuses on the suitability of the semantic variance as a measure for ontology evaluation, it can be also applied to other contexts. Thanks to the mathematical coherency of its formulation (inspired in the usual numerical variance) and of the distance calculation (which ful fi lls the basic metric properties), our measure can be applied to quantify the dispersion of a sample of semantic values. In this case, the  X  reference  X  root node should be replaced in Eq. (2) by the concept that acts as the actual centroid (mean) of the sample of textual values, which should be mapped to ontological concepts ( Mart X nez et al., 2012 ). The semantic variance can thus act as a replacement of the standard numerical variance in algorithms and methods dealing with textual data. In this role, it is an alternative to other taxonomic variances proposed in the literature, like Domingo-Ferrer (2012) ,
Domingo-Ferrer et al. (2013) , Domingo-Ferrer and Solanas (2008) , with the advantage that the semantic variance is more similar to the numerical variance, it is better grounded in the notion of semantic similarity and it yields values normalized within the range [0..1]. Therefore, the semantic variance can also be used for the applications of the marginality-based variance described in
Domingo-Ferrer and Solanas (2008) and Domingo-Ferrer et al. (2013) , which we review in the next subsections. 4.1. Measuring economic diversity
As explained in ( Domingo-Ferrer and Solanas, 2008 ), in of statistics companies are associated an attribute  X  Economic activity , which takes values in some hierarchical classi fi cation. Then, given a representative sample of companies in a country, let us consider the ontology  X  induced  X  by the sample, which is obtained as follows: (a) prune those nodes in the hierarchical classi fi cation that do not lie in the path from the root to any leaf corresponding to a value in the sample; (b) in case a value is repeated in the sample, consider the corresponding leaf as many times as the number of repetitions.
The semantic variance of such an induced ontology is a measure of the country's economic diversity. For example, in Europe the NACE hierarchical classi fi cation of economic activities (standardized by the
European Commission ( Eurostat, 2008 )) is used for economic activity. NACE is a hierarchy with up to four levels: from higher to lower,  X  Section  X  ,  X  Division  X  ,  X  Group  X  and  X  Class
Astandsfor  X  Agriculture, hunting and forestry  X  , Section B for  X 
Fishing  X  , Section C for  X  Mining and quarrying  X  , Section D for  X 
Manufacturing  X  , etc. Clearly, a country focusing mostly on agricul-ture is less economically diverse than a country striking a good balance among the various activities. This idea is captured and quanti fi ed by the semantic variance: if a representative sample of companies from the former country is taken, the sampled compa-nies will mostly fall in NACE Section A, whereas a representative sample from the latter country will include a good balance of companies in all sections; hence, the semantic variance of the ontology induced by the sample of the latter country will be higher than the semantic variance of the ontology induced by the sample of the former country. 4.2. Measuring biodiversity
Given a representative sample of plants and/or animals of a certain ecosystem, the semantic variance of the sample based on the taxonomy of plants/animals is a measure of the ecosystem's biodiversity. The details are analogous to the previous example on economic diversity. 4.3. Data anonymization
In database anonymization, the attributes in a database are classi fi ed as identi fi ers (to be suppressed before any release), quasi-identi fi ers and con fi dential attributes . Quasi-identi those that, in combination, can be linked with external informa-tion to re-identify (some of) the respondents to whom (some of) the records in the database refer; this is called re-identi disclosure . Example quasi-identi fi er attributes are age, job, zip code, etc. Con fi dential attributes are those conveying sensitive information on the respondent (e.g. disease, political opinion, etc.).
The k -anonymity privacy model ( Samarati and Sweeney, 1998 ) focuses on thwarting re-identi fi cation of respondents by modify-ing the quasi-identi fi er attributes before release so that any combination of their values is shared by at least k records. values also have very similar or even the same values for a con fi dential attribute (e.g. they all suffer from AIDS), then an intruder does not need to re-identify his target within the group of k records: he knows that his target suffers from AIDS. This is called attribute disclosure .
 against attribute disclosure, several extensions have been proposed, with l -diversity ( Machanavajjhala et al., 2007 ) being among the most popular. l -diversity requires that, for each con fi dential attribute in the released data, there exist at least l  X  well-represented  X  of records sharing a combination of quasi-identi fi er values. The simplest meaning of  X  well-represented  X  means just  X  different then the l values might not be different enough (e.g. imagine a con fi dential attribute  X  Disease  X  for which all values in the group are sexually transmitted diseases). The authors of l -diversity proposed other diversity measures, like entropy, etc., but none of them adequately captures the semantics of the con fi dential attribute values.
The semantic variance is clearly useful here: protection against attribute disclosure is suf fi cient only if the semantics of the values of each con fi dential attribute within each group of records sharing quasi-identi fi er values are different enough , or equivalently if their semantic variance is above a certain pre-selected threshold (the threshold is a privacy parameter analogous to l in l -diversity).
 used to distort a sample of textual data (i.e., replacing original values by other similar ones taken from their semantic neighbor-hood in an ontology) in such a way that the noise is adapted to the sample dispersion rather than being fi xed by the ontology; speci fi cally, given an original value to be anonymized, the seman-tic variance could be used to determine the range of ontology concepts around the original value among which the anonymized value is to be randomly drawn, analogously to what it is done for numerical data ( Domingo-Ferrer et al., 2004 ).
 the semantic variance of a sample will depend both on the dispersion of the values in the sample and also on the inherent dispersion of the ontology to which those values are mapped. In order to minimize the in fl uence of the ontology structure in the calculation, the semantic variance of the ontology can be used as a normalizing factor for the semantic variance of the sample. In this manner, the variances of samples mapped to ontologies with different taxonomic dispersions will become more comparable. 5. Conclusions and future work intuitive measure to quantify the degree of semantic dispersion of the taxonomic structure of an ontology (or of a speci fi c taxonomic tree within a larger ontology). Since according to previous empiri-cal studies ( Fern X ndez et al., 2009 ) this dispersion seems to be a good predictor of the ontological accuracy, the proposed semantic variance can be used as an automatic ontology evaluation score.
Thus, if several ontologies with similar scopes are available, by evaluating them with the proposed measure we are able to select the ( a priori ) most accurate ontology.
 features, it offers a numerical, unambiguous and objective char-acterization of the ontology, which is easy to implement, ef to compute and does not depend on the judgment of potentially subjective experts ( Fern X ndez et al., 2009; Tartir et al., 2010;
Vrandecic, 2009 ). Moreover, unlike other works based on struc-tural features ( Alani et al., 2006; Buitelaar et al., 2004; Fern X ndez et al., 2009; Gangemi et al., 2006; Guarino and Welty, 2009; Tartir et al., 2005 ), which mainly propose ad hoc and weighted aggregations of heterogeneous features, our measure is a seman-tically and mathematically coherent one, in that it builds on the standard notion of numerical variance and on the well-established foundations of semantic similarity/distance assessment ( Batet et al., 2011; S X nchez et al., 2012 ). Unlike approaches based on individually analyzing structural features ( Fern X ndez et al., 2009 ) and other variance measures ( Domingo-Ferrer, 2012; Domingo-
Ferrer et al., 2013; Domingo-Ferrer and Solanas, 2008 ), which provide absolute values that are greatly in fl uenced by the cardin-ality of the ontology, the results provided by our measure are normalized to the ontology size, and also constrained in the [0..1] range. This enables an intuitive and coherent comparison of ontologies with signi fi cantly different sizes. Finally, our measure can be applied to any ontology because it solely focuses on taxonomic relationships, which are available in all ontologies ( Ding et al., 2004 ).

The empirical results obtained on a set of widely used ontol-ogies support our theoretical hypotheses. On the one hand, the semantic variance positively correlates with the structural features that suggest a good ontological accuracy. On the other hand, our measure acts as an accurate predictor of the ontology quality in one of the most essential ontology-based tasks: the assessment of the semantic similarity between concepts.

As future work we plan to study other semantic evidences that could be incorporated into the assessment of the ontology accu-racy. For example the coherency of the informativeness of the concepts as modeled in the ontology with respect to their actual usage could be also used as an indication of ontological accuracy.
To do so, we can compare the informativeness of concepts in the ontology, which can be computed as a function of their speci in the taxonomy ( S X nchez and Batet, 2012; S X nchez et al., 2011 ), with the informativeness of the same concepts computed from their distribution in corpora ( Resnik, 1995 ).
 Acknowledgments and disclaimer
The authors are solely responsible for the views expressed in this paper, which do not necessarily re fl ect the position of UNESCO nor commit that organization. This work was partly supported by the
European Commission (under FP7 projects  X  DwB  X  , INFRA-2010-262608  X  Inter-Trust  X  FP7-ICT-317731 and H2020  X  CLARUS  X  ICT-2014-1-644024), by the Spanish Government (through projects
ICWT TIN2012-32757, CO-PRIVACY TIN2011-27076-C03-01 and Bal-lotNext IPT-2012-0603-430000) and by the Government of Catalo-nia (under Grant 2014 SGR 537). The last author is partially supported as an ICREA-Acad X mia researcher by the Government of
Catalonia and by a Google Faculty Research Award. This work was also made possible through the support of a Grant from the John
Templeton Foundation (TWCF0095/AB60). The opinions expressed in this paper are those of the authors and do not necessarily re the views of Templeton World Charity Foundation.
 References
