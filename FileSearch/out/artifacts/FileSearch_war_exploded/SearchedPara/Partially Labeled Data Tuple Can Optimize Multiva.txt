 Multivariate performance measure optimization refers to learn-ing predictive models such that a desired complex perfor-mance measure can be optimized over a training set, such as the F1 score. Up to now, all the existing multivariate performance measure optimization methods are limited to a completely labeled data tuple, i.e., the label tuple is com-plete. However, in real-world applications, sometimes it is difficult to obtain a complete label tuple. In this paper, we show that the multivariate performance measures can also be optimized by learning from partially labeled data tuple, when the label tuple is incomplete. We introduce a slack la-bel tuple to represent the sought complete true label tuple, and learn it jointly with a hyper predictor, so that it can be consistent to the known labels, prediction results, and is smooth in the neighborhood. We develop an iterative learn-ing algorithm to learn the slack label tuple and the hyper predictor. Its advantage over state-of-the-art multivariate performance measure optimization methods is shown by ex-periments on benchmark data sets.
 I.2.6 [ ARTIFICIAL INTELLIGENCE ]: Learning Algorithm Multivariate performance measures; Partially labeled data; Slack label tuple When solving machine learning problems, we often learn a predictive model from a training set, and then use it to pre-dict the class labels of some testing data points. To evalu-ate the prediction results, various multivariate performance measures can be employed to compare the predicted labels c  X  against the ground truth labels. For example, prediction accuracy (ACC), area under the receiver operating char-acteristic curve (AUC), the F1 score, and recall precision break even point (PRBEP) are popular multivariate per-formance measures in various applications [3, 6]. However, while those multivariate performance measures are used to evaluate the prediction results, they are ignored when the predictive model is learned from the training set. During the training procedure, traditional learning methods usual-ly employ a simple loss function to compare the true label of a training point against its corresponding predicted la-bel. Minimizing such loss functions cannot guarantee that a desired multivariate performance can be optimized directly. Recently, some works were proposed to learn predictive mod-els so that a desired multivariate performance can be opti-mized directly. For example, Joachims [3] proposed a sup-port vector method for optimizing multivariate performance measures by approximating a complex multivariate loss func-tion as its upper bound, and using a cutting-plane algrithm. Zhang et al. [8] proposed a novel smoothing strategy for multivariate performance measure by using Nesterov X  X  ac-celerated gradient method. Li et al. [4] proposed to adapt an existing classifier to optimize a desired multivariate per-formance measure, by adding an adaptation function to the existing classifier. Mao and Tsang [5] proposed a joint fea-tures selection and classifier learning method for multivari-ate performance optimization by using a two-layer cutting plane algorithm . These works minimize a loss function cor-responding to the desired multivariate performance to learn the predictive model. This loss function is a function of a data tuple of the training data points, and a label tuple of the corresponding labels.
 A very basic assumption behind these methods is that all the labels of the data points of the data tuple are available. This assumption, however, does not always hold in real-world ap-plications. In many applications, we only have a partially labeled data tuple, i.e., only the labels of a few data points in the training data tuple are available, while the labels of the remaining data points are missing. Up to now, there is no work proposed to learning predictive models from partially labeled data tuple. In this paper, we show that multivariate performance can also be optimized by learning a predictive model from a partially labeled data tuple. We propose a nov-el method to optimize a multivariate performance measure by using a partially labeled data tuple. A slack label tuple is introduced to represent the desired complete true label tuple, and it is learned jointly with a hyper predictor. The labels of slack label tuple are imposed to be consistent with the known labels, the prediction results, and smoothness over neighborhood. To learn the hyper predictor, we mini-mize a multivariate loss function to compare the slack label tuple against the prediction results of the hyper predictor. The learning problem is modeled by a unified minimization problem, and solved using an iterative algorithm.
 This paper is organized as follows: in Section 2, we describe the proposed method, in Section 3, the method is evaluated experimentally, and in Section 4, the paper is concluded. We assume we have a data tuple of n data points, denoted as x = ( x 1 ,  X  X  X  , x n ), where x i  X  R d is the d -dimensional feature vector of the i -th data point, and a corresponding label tuple y = ( y 1 ,  X  X  X  ,y n ), where y i  X  { +1 ,  X  1 } is the the binary class label of the i -th data point. However, the label tuple is incomplete, and only the first l &lt; n labels y ,  X  X  X  ,y l are known, while the remaining labels are missing. To predict the label tuple of the data tuple, we design a hyper predictor as follow, tuple, and w  X  R d is the predictor parameter. To measure the perdition results, traditional multivariate performance optimization methods use a complex multivariate loss func-tion to compare y  X  against y ,  X ( y  X  , y ), and minimize it to learn the predictor parameter, w . However, since y itself is incomplete, we cannot optimize  X ( y  X  , y ) directly any-more. To solve this problem, we propose a slack label tuple tuple, and learn z and w simultaneously. To this end, we formulate the learning problem as the following constrained minimization problem, min s.t. z  X  X  +1 ,  X  1 } n , and z i = y i ,  X  i = 1 ,  X  X  X  ,l. In this formulation, the first term 1 2 k w k 2 is minimized to reduce the complexity of the predictor. The second ter-m  X ( y  X  , z ) is minimized to optimize the loss function cor-responding to a sought multivariate performance measure. The last term is proposed to seek the smoothness of slack labels over each neighborhood. N i is the neighborhood of x , and  X  ij is the weight of x j for reconstruction of x i it is obtained by solving the following constrained quadratic program problem, The constraint z i = y i ,  X  i = 1 ,  X  X  X  ,l , is to guarantee the slack labels of the first data points are consistent to their known labels.
 Because  X ( y  X  , z ) is usually complex, and sometimes does not have a close form, it is difficult to minimize (2) directly. We seek the upper bound of  X ( y  X  , z ) and minimize it instead. According to (1), we have X  X   X ( y  X  , z )  X  replace y  X  to seek the upper bound of  X ( y  X  , z ), y 00 = arg max By replacing  X ( y  X  , z ) in (2) by its upper bound in (4), we have the following constrained minimization problem, min s.t. z  X  X  +1 ,  X  1 } n , and z i = y i ,  X  i = 1 ,  X  X  X  ,l. The problem in (6) is difficult to optimize directly. Thus we use an alternate optimization strategy to solve this problem in an iterative algorithm. Noting y 00 in (5) is also a function of w and z , and each iteration we first update it by fixing w and z as in the previous solution. Then one of w and z is updated in turn while the other one is fixed. To update w , we fix y 00 and z , and remove the terms irrele-vant to w , and obtain the following minimization problem, min We use a gradient descent method to minimize this problem, function, and  X  is the gradient step. To update z , we fix w and y 00 , remove the terms irrelevant to z , and obtain the following problem, In this problem, since the first l labels of z is constrained to be identical to the known labels, we only need to consider the remaining n  X  l labels, z l +1 ,  X  X  X  ,z n . We solve this problem by fixing z 1 ,  X  X  X  ,z l , and performing a local search in the space of ( z l +1 ,  X  X  X  ,z n ). Based on the optimization results, we develop an iterative al-gorithm to learn w and z . The developed algorithm, named as OPLD, is described in Algorithm 1.
 Algorithm 1 Iterative algorithm to Optimize multivariate performance measure from Partially Labeled Data tuple (O-PLD).

Input : Data tuple x , and labels of its first l data points, y 1 ,  X  X  X  ,y n ; Input : Tradeoff parameters C 1 and C 2 ; Input : Iteration number T .

Initialize w 0 and z 0 ; for t = 1 ,  X  X  X  ,T do end for
Output : Output the learned w T and z T . In this section, we test the proposed algorithm on optimiza-tion of various multivariate performance measures. The following data sets were used in our experiments, To conduct the experiments, we first randomly split the en-tire data set in to a training set and a test set. To do this, we randomly select 50% of the data points as the training data points, and left the remaining 50% data points as the test data points. The training set was used to train the hyper predictor to optimize a given multivariate performance mea-sure, and then the predictor was used to classify the data points in the test set, and the prediction results are evaluat-ed by the corresponding multivariate performance measure. We randomly select about 30% training data points as la-beled data points, while left the remaining training data points as unlabeled data points. The tradeoff parameters are optimized over the training set by using cross valida-tion. This procedure of random split is repeated ten times to avoid bias of each split. We compare the proposed method against several state-of-the-art multivariate performance optimization methods, in-cluding support vector machine for performance optimiza-tion (SVM perf ) [3], smoothing for multivariate scores (SM-S) [8], classifier adaptation for performance optimization (CAPO) [4], and feature selection for multivariate perfor-mance measure (FS multi ) [5]. Please note that the com-pared methods can only use the labeled training data points while ignoring the unlabeled data points. The boxplots of ten trails of experiments of optimization of ACC, F1 score, PRBEP, and AUC are given in Figure 1. From this fig-ure, we can see that the proposed algorithm outperforms the compared methods significantly over all data sets. This is not surprising because it is the only algorithm that ex-plores the entire training set and learns from the tuple with incomplete label tuple. There are two tradeoff parameters, C 1 and C 2 , in the pro-posed method, and we show the curves of optimized PRBEP against different values of C 1 and C 2 over Mitfaces data set in Figure 2. From this figure, we can see the performance is stable to both these two parameters. The performance is improved slightly when the values are larger. Table 1: Running times of compared methods (in seconds).
 We also compare the running time of different methods on optimization of various multivariate performance measures over the Splice data set. The running time is shown in Table 1. We can see that the proposed method consumes the most Figure 1: Boxplots of variouse multivariate perfor-mance measures of ten trails of experiments. training time for optimizations of different performance mea-sures. This is not surprising, since the compared algorithms can only explore a limited number of labeled data points, while our algorithm utilizes the entire training set of both labeled and unlabeled data points. In this paper, we show that partially labeled data tuple can also be used to learn predictive models to optimize a com-plex multivariate performance measure. We develop an ef-Figure 2: Sensitivity curves of parameters C 1 and C . fective algorithm to optimize multivariate performance mea-sures from partially labeled data tuple, by introducing a s-lack complete label tuple, and updating it jointly with the hyper predictor parameters. Experimental results show its significant advantage over existing multivariate performance measure optimization methods which only utilise the labeled data points.
 Research reported in this publication was supported by com-petitive research funding from King Abdullah University of Science and Technology (KAUST), Saudi Arabia. [1] M. Alvira and R. Rifkin. An empirical comparison of [2] F. Debole and F. Sebastiani. An analysis of the relative [3] T. Joachims. A support vector method for multivariate [4] N. Li, I. W. Tsang, and Z.-H. Zhou. Efficient [5] Q. Mao and I. W.-H. Tsang. A feature selection [6] G. Markovits, A. Shtok, O. Kurland, and D. Carmel. [7] M. O. Noordewier, G. G. Towell, and J. W. Shavlik. [8] X. Zhang, A. Saha, and S. Vishwanathan. Smoothing
