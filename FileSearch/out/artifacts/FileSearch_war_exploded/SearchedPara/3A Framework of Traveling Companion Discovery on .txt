 The technical advances in mobile devices and tracking technologies have generated huge amount of trajectory data recording the movement of people, vehicles, animals, and natural phenomena in a variety of applications, such as social network, trans-portation management, scientific studies, and military surveillance [Zheng and Zhou 2011]: (1) In Foursquare 1 , the users check in the sequence of visited restaurants and shopping malls as trajectories. In many GPS-trajectory-sharing Web sites like Ge-olife [Zheng et al. 2010], people upload their travel or sports routes to share with friends. (2) Many taxis in major cities have been embedded with GPS sensors. Their locations are reported to the transportation system in the format of streaming tra-jectories [Yuan et al. 2010; Tang et al. 2011]. (3) Biologists solicit the moving trajec-tories of animals like migratory birds for their research 2 . (4) The battlefield sensor network watches the designated area and collects the movement of possible intrud-ers [Tang et al. 2010]. Their trajectories are watched by military satellites all the time.

In the aforementioned applications, people usually expect to discover the object groups that move together, that is, traveling companions . For example, commuters want to discover people with the same route to share car pools. Scientists would like to study the pathways of species migration. Information about traveling companions can also be used for resource allocation, security management, infectious disease control, and so on.

Despite wide applications, the discovery of traveling companions is not efficiently supported in existing systems, partly due to the following challenges.  X  Colocation . Companions are objects that travel together. Here  X  X ravel together X  means the objects are spatially close at the same time. Many state-of-the-art tra-jectory clustering methods, retrieving the object X  X  major moving direction from their trajectories, ignore the temporal information of objects [Lee et al. 2007; Har-Peled 2003; Li et al. 2004; Yang et al. 2009; Zhang and Lin 2004; Jensen et al. 2007]. Hence they cannot be directly used for companion discovery.  X  Incremental discovery . In several applications like military surveillance, the system needs to monitor objects for a long time and discover companions as soon as possible.
Hence the algorithm should report the companions in an incremental manner, that is, output the results simultaneously while receiving and processing the trajectory data stream.  X  Efficiency . Most trajectories are generated in a format of data stream. Huge amounts of data arrive rapidly in a short period of time. The monitoring system has to cluster the data and intersect the clusters for companions. These steps involve high compu-tational overhead. The algorithm should develop efficient data structures to process large-scale data.  X  Effectiveness . The number of companions is usually large. The system should re-port the large and long-lasting companions rather than small and short-time ones.
The companion discovery algorithm should be effective to select the most important results.  X  Spatio-temporal constraints . In real applications, objects move with several spatial and temporal constraints, such as where a vehicles travel along the road network, the military objects need to follow certain orders to leave the team for a short time. The algorithm should be adapted for such constraints to improve the system feasibility and applicability.
 We are aware that several studies have retrieved object groups similar to the traveling companions, such as flock [Gudmundsson and Kreveld 2006], convoy [Jeung et al. 2008], and swarm [Li et al. 2010]. However, most of them are designed to work on static datasets on 2D Euclidean space, and some methods need multiple scans of the data, or cannot output results in an incremental manner. Hence it is still desirable to provide high-quality but less costly techniques for companion discovery on trajectory streams with spatio-temporal constraints.

In this study, we investigate the models, principles, and methodologies to discover traveling companions from trajectory streams. Since the objects keep on moving in the trajectory streams, it is hard to maintain an index for their spatial positions. However, the relationships among most objects are gradual evolutions rather than fierce mutations. The traveling buddy is proposed to store the relationship. Such a model can be easily maintained along the data streams. Thus, in this article, we explore the traveling-buddy-based companion discovery, which is able to discover companions without accessing the object details and significantly improve the system X  X  efficiency. The main contributions of this study include: (1) introducing the companion models to define the problem; (2) proposing the concepts of smart intersection and closed companions to accelerate data processing; (3) analyzing the bottleneck of the problem and proposing a traveling-buddy-based approach; (4) extending the proposed methods to complicated scenarios with spatio-temporal constraints, developing the methods to discover the road companions and loose companions; and (5) demonstrating the scalability and feasibility of the proposed methods by experiments on both real and synthetic datasets.

This article substantially extends the version on ICDE 2012 conference [Tang et al. 2012], in the following ways: (1) introducing the concepts of road companion and loose companion to model the companion discovery problems on more complicated scenar-ios; (2) analyzing the main bottleneck of road companion discovery and proposing a filtering-and-refinement-based framework; (3) designing new algorithms with the road buddy for efficient companion discovery on road networks; (4) proposing the leaving time threshold and introducing the concept of loose companion to release the time con-straints for more effective companion discovery; (5) carrying out the time complexity analysis for proposed algorithms; (6) providing complete formal proofs for lemmas and propositions; (7) covering the related work in more details and including recent ones; and (8) expanding our performance studies on datasets on road networks and battle-field. The experimental results show that the new proposed methods are an order of magnitude faster than the old ones in Tang et al. [2012].
 The rest of the article is organized as follows. Section 2 defines the problem; Section 3 introduces the general framework of companion discovery; Section 4 pro-poses the traveling-buddy-based method; Section 5 extends the proposed methods to discover companions on road networks; Section 6 discusses the techniques to discover companions with released temporal constraints; Section 7 evaluates the algorithms X  performances; Section 8 gives a survey of the related work and finally in Section 9 we conclude the work.
 In the various applications of traveling companion, there are some common principles shared in different scenarios. We illustrate the characteristics of companion discovery by the following example.

Example 1 . Ten objects are tracked by a monitoring system. Figure 1 shows their positions in four snapshots. There are three key issues to discover the companions.  X  Cluster . The companions are the objects that travel together, that is, in the same cluster. Since the people, vehicles, and animals often move and organize in arbitrary ways, the companion shape is not fixed. In Figure 1, the objects are grouped in round shape in snapshots s 1 and s 2 , while in s 3 , they are moving in a queue and the companions are formed as thin and long ellipses.  X  Consistency . The companions should be consistent enough to last for a few snapshots.
This feature makes it possible to find the companions by intersecting the clusters of different snapshots.  X  Size . Most users are only interested in object groups that are big enough. They may have requirements on the companion X  X  size. For example, if the user sets the size threshold as four and requires the companion to last for at least four snapshots, then { o To discover the traveling companions with various shapes, we employ the concepts of density-based clustering [Ester et al. 1996] in this study.

Definition 1( Direct Density Connection ). Let O be the object set in a snapshot,  X  be  X  }
Definition 2( Density Connection ). Let O be the object set in a snapshot, object o i is density connected to object o j , if there is a chain of objects { o 1 ,..., o n } X  O where o
With the concepts of density connection, we formally define the traveling companion as follows.

Definition 3( Traveling Companion ). Let  X  s be the size threshold and  X  t be the du-ration threshold, a group of objects q is called traveling companion if: (1) the members of q are density connected by themselves for a period t where t  X  t ; (2) q  X  X  size size ( q )  X  s .

Problem Definition . Let trajectory data stream S be denoted by a sequence of y data of snapshot s i arrives, the task is to discover companion set Q that contains all the traveling companions so far.

We will introduce the framework and techniques for companion discovery in the next few sections. Figure 2 lists the notations used throughout this article. A general framework of clustering and intersection is proposed in Gudmundsson and Kreveld [2006] and Jeung et al. [2008] to retrieve the convoy patterns. This framework can also be adapted to discover companions on trajectory streams: The idea is to re-trieve companion candidates by counting common objects in the clusters from different snapshots. The system keeps clustering the objects in coming snapshots and intersect-ing them with the stored candidates. In this way the candidates are gradually refined to become resulting companions.
 ration threshold, a group of objects r is a companion candidate if: (1) the members of r are density connected by themselves for a period t where t &lt; X  t ; (2) size ( r )  X  s .

Intuitively, the companion candidates are the object groups with enough size but shorter duration. The candidate X  X  size reduces when intersecting with the clusters from other snapshots, but its lasting time increases. Once a candidate X  X  time grows longer than the threshold, it will be reported as a traveling companion. Meanwhile, as soon as the candidate is not large enough, it is no longer qualified and should be removed from memory. Figure 3 lists the steps of the clustering-and-intersection algorithm.
Algorithm 1 first performs density-based clustering for all the objects in coming snapshots (lines 1 X 3). Then the system refines companion candidates by intersecting them with new clusters (lines 4 X 7). The intersection results with enough size are stored as new candidates (lines 8 X 9). The ones with enough duration are reported as traveling companions (lines 10 X 11). The new clusters are added to the candidate set (line 12). At last the candidate set R is updated to process following snapshots (line 13). P ROPOSITION 1. Let n 1 be the size of objects and n 2 be the total size of candidate set R. The time complexity of Algorithm 1 is O(n 2 1 + n 1  X  n 2 ).

P ROOF . In the clustering step, the algorithm needs O ( n 2 1 ) time to generate density-based clusters 3 . In the intersection step, suppose there are average m 1 clusters and m 2 candidates, the system carries out m 1 l  X  l Since m 1  X  l 1 = n 1 , m 2  X  l 2 = n 2 , thus the time complexity of the intersection step is
Example 2 . Figure 4 shows the running process of the clustering-and-intersection algorithm. Suppose each snapshot lasts for 10 minutes, the size threshold is 3 and the time threshold is 40 minutes. The objects are first clustered in each snapshot. Two clusters in s 1 are taken as the candidates, namely r 1 and r 2 . Then they are intersected with the clusters in s 2 , meanwhile, the cluster of s 2 is also added as a new candidate r . The clustering and intersection steps are carried out in each snapshot. Finally, the times are 29, and the largest candidate set R appears in s 3 with 23 objects involved. The computational overhead of the clustering-and-intersection method is high in both time and space. In each snapshot, the intersection is carried out in every pair of can-didate and cluster. However, most intersections cannot generate qualified results with enough size. In this section we introduce the methods to improve the efficiency: (1) the smart algorithm stops the intersection step early once it is impossible to generate qual-ified candidates, and (2) the closed candidates are used to help reduce the memory cost. intersecting r with remaining clusters will not generate any meaningful results with size larger than  X  s .
 clusters, even in the best case (all the remaining objects are in a single cluster), the intersection result will still be smaller than size ( r )  X  ( size ( r )  X   X  s ) =  X  s .
Lemma 1 can be used to improve the candidate refining process with smart intersec-tion. Once an object is found in the cluster, the algorithm removes it from the candidate. The intersection process will stop earlier if there are less than  X  s objects remaining in the candidate.

Another problem of the clustering-and-intersection method is the space efficiency; if all new clusters are added as candidates, the size of the candidate set will in-crease rapidly as the trajectory stream passes-by. Such a huge candidate set is a burden for system memory. In the worst case, all the clusters stay constant in the series of snapshots, the intersection process cannot prune any existing candidates, and all the new clusters are added to the candidate set. After m snapshots, the system needs to maintain an m  X  n size candidate set, where n is the number of objects.

In Figure 4, candidates r 3 and r 5 in s 3 contain the same objects with different lasting time. In such cases, the system only needs to store the one with longer time (e.g., r 3 ). Such candidates like r 3 are called closed candidates .

Definition 5( Closed Candidate ). For a companion candidate r i , if there does not then r i is a closed candidate .
 Armed with Lemma 1 and Definition 5, we propose the smart-and-closed algorithm. The modifications are underlined in Figure 5: the algorithm removes intersected objects from the candidate set and checks its remaining size before the next intersection (lines 5 and 9); when adding the new clusters to the candidate set, the algorithm always checks if there is already a candidate containing the same objects but with longer duration, and only the ones passing the closeness check are added as new candidates (lines 14 X 15).

In the worst case, Algorithm 2 cannot prune any candidates and the time complexity is the same as Algorithm 1. However, we find out that the smart-and-closed algorithm can save about 50% time and space in the experiments.
 Example 3 . Figure 6 shows the running process of the smart-and-closed algorithm. In snapshot s 3 , when making intersections for candidate r 1 with three clusters, the process ends early after the first round. Since the system only stores closed candidates, the largest candidate set size is only 19 in s 2 , and the total intersection time is 12, less than half of the cost in the clustering-and-intersection algorithm.
 The smart-and-closed algorithm improves the efficiency of the intersection step to generate companions, but the system still has to cluster the objects in each snap-shot. The density-based clustering costs O ( n 2 ) time without a spatial index, where n is the number of objects [Han and Kamber 2006]. Due to the dynamic nature of streaming trajectories (i.e., the objects X  positions are always changing), maintain-ing traditional spatial indexes (such as R-tree or quad-tree) at each time snapshot incurs high cost [Lee et al. 2003]. In this section, we introduce a new structure, called traveling buddy , to maintain the relationship among objects and help discover companions. In streaming trajectories, the objects keep on moving and updating their positions, however, the changes of object relationships are gradual evolutions rather than fierce mutations. The object relationships are possible to be retained in a few snapshots, that is, the objects are likely to stay together with several members of the current cluster. It is attractive to reuse such information to speed up the clustering tasks. However, the system cannot reuse it directly. The major issue is about the intrinsic feature of density-based clustering. Unlike other types of clusters, the results of density-based clustering may be quite different due to minor position changes of an individual object. This phenomenon is called individual sensitivity as illustrated in Example 4. Example 4 . Figure 7 shows two consecutive snapshots of the trajectory stream. Suppose the density threshold  X  is set to three. In snapshot s 1 , two clusters c 1 and c 2 are independent. However in s 2 , object o 1 moves a little to the south, and this movement makes the two clusters density connected and merged as one cluster c 3 . Such cases may impose important meanings in real applications, for instance, in the scenario of infected disease monitoring, the people in the two clusters should then be watched together since the disease may spread among them.

The time cost of checking individual sensitivity is quadratic to the cluster size, and in many cases the system has to generate large clusters to produce meaningful companions. Hence high computational overhead is still involved in the clustering stage.

Then is it possible to explore a smaller and more flexible structure? In the real world, there are some kinds of microgroups in a trajectory stream. For example, couples would like to stay together on trips, military units operate in teams, families of birds, deer, and other animals often move together in species migration. Such objects stay closer to each other than outside members. Even though they might not be as big as the companion, their information can be used to help clustering. Since they are way smaller than the cluster, their maintenance cost is much lower.

Definition 6( Traveling Buddy ). Let O be the object set and  X   X  be the buddy radius threshold, traveling buddy b is defined as a set of objects satisfying: (1) b  X  O ;(2)for  X  o  X  is defined as the distance from cen ( b )to b  X  X  farthest member.

The traveling buddies can be initialized by incrementally merging the objects in two steps: (1) treating all objects as individual buddies; and (2) merging them with their nearest neighbors. This process stops if the buddy X  X  radius is larger than  X  . The initialization step costs O ( n 2 )timefor n objects. However, this step only needs to be carried out once and the traveling buddies are dynamically maintained along the stream.

There are two kinds of operations to maintain buddies on the data stream, namely, split and merge , as shown in the following example.

Example 5 . Figure 8 shows the traveling buddies in two snapshots. Traveling buddy b merged as a new buddy in s 2 .

When the data of a new snapshot s t + 1 arrives, the maintenance algorithm first up-y i ) between s t + 1 and s t . And the new center is updated as
Then every object o i  X  b checks its distance to the buddy center; if the distance is larger than  X   X  , o i will be split out as a new buddy. The cen( b ) is also updated by subtracting the shift of o i .

The second operation is to merge the buddies that are close to each other. If two buddies b i and b j satisfy the following equation, they should be merged as a new buddy.
Suppose b i has m i objects and b j has m j objects, the new buddy b k  X  X  center is computed to access the detailed coordinates of each object to merge buddies; the computation can be done with the information from the old buddy X  X  center and size.

The detailed steps of buddy maintenance are shown in Figure 9. When the data of a new snapshot arrives, the algorithm first updates the center of each buddy (line 2). Then each buddy member is checked to see whether a split operation is needed (lines 3 X 7). At last, the system scans the buddy set and merges the buddies that are close to each other (lines 10 X 13).
 of objects. The time cost of Algorithm 3 is O(n + m 2 ).

P ROOF . The split operation needs to check each object and the time cost is O ( n ). The merge operation has to check the buddies pairs with time complexity O ( m 2 ). Therefore the total maintenance cost is O ( n + m 2 ).
 In the worst case, if the objects are sparse and each of them is an individual buddy, where m = n , the maintenance cost is still O ( n 2 ). However, the number of m is usually much smaller than n and the algorithm is likely to strike a relatively high efficiency. In the clustering step, the system has to check the density connectivity for each object. The traveling buddies can help the clustering process avoid accessing those object details. To bring down computational overhead, we introduce following lemmas.

L EMMA 2. Let b be a traveling buddy,  X  be the distance threshold, and  X  be the density threshold. If b X  X  size is larger than  X  + 1 and the buddy radius  X   X / 2 ,thenallthe objects in b are directly density reachable to each other. Such a traveling buddy is called a density-connected buddy .

P ROOF .Notethat  X   X / 2, thus for  X  o i , o j  X  b , dist ( o i , o j ) 2  X   X  . Then all the By Definition 1, o i and o j are directly density reachable.

Lemma 2 shows that, if a traveling buddy is tight and large by itself, then all its members can be considered as density connected. Lemma 2 also gives the directions that the radius threshold  X   X  should not be set larger than  X / 2.

L EMMA 3. Let b i and b j be two traveling buddies with radius  X  i and  X  j , and  X  be the not directly density reachable.
 b , o directly density reachable.

Lemma 3 tells us that, when searching for the directly density reachable objects for a traveling buddy, if another buddy is too far away, then the system can prune all its members without further computation. This lemma is very helpful. In the experiments it helps prune more than 80% of the objects.

For the traveling buddies that are close to each other, the detailed distance compu-tation still needs to be carried out. But with the following lemmas, the system does not need to compute distances between all the pairs. Lemma 4 provides heuristics to speed up the computation.
 If  X  o connected.
 |
N  X  ( o i ) |  X  ,if dist ( o i , o j )  X  ,then o i and o j are directly density reachable. Since all the objects in b i and b j are directly density reachable from o i and o j , respectively, therefore, all the objects in the two traveling buddies are density connected.
Based on Lemma 4, once the system finds a pair of objects close to each other, it ends the computation and considers the corresponding buddies density connected. The detailed algorithm is listed in Figure 11. The algorithm first updates the buddy set in a new snapshot (line 1). Then it randomly picks a buddy and initializes it as a new cluster (lines 2 X 4). For each buddy in the cluster, the algorithm checks its density connectivity to others (lines 5 X 18). The far-away buddies are filtered out (Lines 8 X 9). With the help of Lemma 4, the algorithm searches density reachable buddies and objects and adds them to the cluster (lines 10 X 18). Finally, the algorithm outputs clustering results when all the buddies are processed (line 20).

In the worst case, Algorithm 4 is still with O ( n 2 ) time complexity, where n is the number of objects. But in most cases, Lemmas 3 and 4 can prune the majority of buddies and save time for distance computation. The experiment results show that buddy-based clustering is an order of magnitude faster than the original clustering algorithm.
 The buddies are not only useful in the clustering step, they are also helpful for the intersection process to generate companions. When intersecting a candidate with a cluster, the system needs to check whether each candidate X  X  objects appear in the cluster or not. The information of traveling buddies can provide a shortcut to this process: If a buddy stays unchanged during the period, and it appears both in the candidate and the cluster, then the system can put all its members into the intersection result without accessing the detailed objects.

To efficiently utilize the buddy information, a buddy index is designed to keep the candidates dynamically updated with the buddies.

Definition 7( Buddy Index ). The buddy index is a triple { BID , ObjSet , CanIDs } , where BID is the buddy X  X  ID, ObjSet is comprised of the object members of the buddy, and CanIDs records the IDs of candidates containing the buddy.

As long as the buddy stays unchanged, the candidates only store the BID instead of detailed objects. While making intersections, the buddy is treated as a single object. When the buddy changes, the system updates all the candidates in CanIDs and replaces BID with the corresponding objects in ObjSet . The buddy-based companion discovery algorithm is listed in Figure 12.

When a new snapshot arrives, the algorithm performs buddy-based clustering and updates the buddy index (lines 2 X 4), then selects out the candidates with enough size (lines 5 X 6). The candidates are intersected with the generated clusters with the help of the buddy index (lines 7 X 10). The candidate X  X  duration and size are checked again after the intersection, and the qualified ones are output as the companions (lines 11 X 14). Finally, the closed candidates are added to the memory for further processing (lines 15 X 17).

Example 6 . Figure 13 shows the running process for buddy-based companion dis-covery. There are four buddies initialized in snapshot s 1 . In the candidates, the buddy ID is stored instead of detailed objects. In snapshot s 2 , the four buddies stay the same and the algorithm makes intersections by only checking their BID s. Although the total intersection time is not reduced, the time cost for each intersection operation has been brought down. It is common that different candidates contain the same objects, such as r and r 3 in s 2 . The buddy index helps to keep only one copy of the objects and add only pointers (the BID s) to candidates. Therefore, the space cost is further reduced. In s 3 , the buddy b 3 is no longer valid, then the system updates candidate r 2 , using the objects the help of the buddy index, the system can easily look up detailed objects and output the companion as { o 1 , o 2 , o 3 , o 4 } . In the previous sections, we have investigated the problem of companion discovery on 2D Euclidean space. However, many objects move on road networks in real applications. There are several unique difficulties for companion discovery on the road network. In this section we explore the problem of discovering road companions. There are several issues different from the companion discovery in 2D Euclidean space.  X  Distance computation. In the road network, the distance between two objects should be the length of the shortest path connecting them, rather than a straight line between them. As shown in the figure, o 1 and o 2 are close to each other in the
Euclidean space, but they are on different directions. The road network distance between them is actually much larger.  X  Moving direction. In most cases, the road companion moves in the shape of a line. The moving direction of the object is an important factor in determining the companion.
For example, o 7 , o 8 ,and o 9 in Figure 14 have neighboring vehicles o 10 and o 11 moving in opposite direction. Such vehicles should not be counted as the companion mem-bers. Therefore, traditional density-based clustering should be modified to model the vehicle X  X  moving directions.

Since the road companion discovery is a new type of problem, it is necessary to modify some basic concepts of the traveling companion and redefine the task with new constraints.

Definition 8( Direct Road Connection ). Let O be the object set in a snapshot, M be the road network, and  X  be the distance threshold. Object o j is directly road connected between o i and o j on M .

Note that we remove the requirements about density and replace the Euclidean distance with the road network distance in Definition 8.

Definition 9( Road Connection ). Let O be the object set in a snapshot, M be the road network, object o i is road connected to object o j on M , if there is a chain of objects { o on M .

Based on the previous definitions, we can formally define the task of road companion discovery as follows.

Definition 10 ( Road Companion ). Let M be the road network,  X  s be the size thresh-old, and  X  t be the duration threshold, a group of objects q is called road companion if: (1) the members of q are road connected on M for a period t where t  X   X  t ; (2) q  X  X  size size ( q )  X   X  s .
 Problem Definition . Let trajectory data stream S be denoted by a sequence of snapshots { s , s move on a road network M . When the data of snapshot s i arrives, the task is to discover the road companion set Q that contains all the road companions so far.

Note that we assume the system can match the spatial coordinates of the moving objects to the road network efficiently. There are many state-of-the-art studies on this map-matching problem. In our previous studies, we have developed several methods for map matching; the details can be found in Yuan et al. [2010] and Zheng et al. [2012]. The general framework of clustering and intersection can be adapted to discover road companions. In each snapshot, the system first generates the road connected clusters and intersects them with the road companion candidates . The candidates are gradually refined to be the road companions.
 size threshold, and  X  t be the duration threshold, a group of objects q is called road companion candidate if: (1) the members of q are road connected on M for a period t where t &lt; X  t ; (2) size ( q )  X   X  s .
 Similarly, the ideas of the smart-and-closed algorithm also work for this framework. To apply those algorithms on road networks, the only difference is to replace the process of density-based clustering with the following algorithm of road-connection-based clustering.

Algorithm 6 first picks a random object as the seed to initialize a cluster (lines 1 X 4), then expands the cluster (lines 5 X 10). In the expansion process, the algorithm starts from the seed, and adds in any objects that are directly road connected to the cluster member (lines 7 X 10). Once a cluster is generated, the system compares its size with the threshold, and only the ones with enough size are included in the final clustering results (lines 11 X 13).

P ROPOSITION 3. Let n be the size of object set O and N be the total node number of road network M. The time complexity of Algorithm 6 is O(n 2  X  N).

P ROOF . There are three loops in Algorithm 6 (lines 1, 5, and 7). In the worst case, no objects are road connected. Hence the algorithm has to run n times for the loops in lines 1 and 7, and 1 time for the loop in line 5 (each cluster only contains one object in such a case). The total running number is O ( n 2 ). In each run, the system has to find the shortest path between objects o i and o j to compute their road network distance. The time cost of the shortest path searching step is determined to the detailed algorithm and heuristics [Pearl 1984]. In the worst case, the algorithm has to visit all the nodes of M to find out the shortest path, hence the time complexity of Algorithm 6 is O ( n 2  X  N ).

In many applications, the road network M contains millions of nodes, that is, N is a quite large number. To make things worse, the system may not have enough memory to load in M in one time. Therefore the shortest path computation involves huge I/O overhead. The time cost of Algorithm 6 is much larger than the density-based clustering, and it is not feasible for efficient road companion discovery on trajectory streams.

The bottleneck in Algorithm 6 is searching for the directly road connected objects (lines 7 X 10). For a particular object o i , the system has to find the shortest paths between o and all unvisited objects. This computation process is the most costly step of the algorithm. However, it is actually not necessary to compute all those shortest paths, and the algorithm X  X  time cost can be reduced significantly with the following lemma.
L EMMA 5. In the road network M, if the Euclidean distance between two objects o i and o j is larger than the distance threshold  X  ,o i and o j are not directly road connected.
P ROOF . In the Euclidean space, the shortest path between o i and o j is a straight line connection. Since the road network M is also in the same Euclidean space, the Eu-clidean distance must be less than or equal to the road network distance: dist ( o i , o j )  X  are not directly road connected.

Lemma 5 can help accelerate the road connection clustering process. We develop a new clustering algorithm with the filtering-and-refinement strategy, as listed in Figure 16.

The main step of Algorithm 7 is at line 8. Since the main workload of the road-connection-based clustering is on the shortest path computation, Algorithm 7 is de-signed to reduce such computation and avoid the huge I/O cost of accessing the road network data. When searching for the directly road connected objects for object o i ,the system first computes the Euclidean distance dist ( o i , o j ), the measure whose compu-is already larger than the threshold  X  , according to Lemma 5, o j is not possible to be road connected with o j , and the system can filter it without any further computation. In such way, about 80% of the objects are pruned and the algorithm is nearly an order of magnitude faster in our experiments.

P ROPOSITION 4. Let n be the size of object set O, N be the total node number of road network M, and m be the number of objects that pass the filtering process. The time complexity of Algorithm 7 is O(n 2 + mN).

P ROOF . With the filtering-and-refinement strategy, the algorithm only needs to com-pute road network distances for the m objects which pass the filtering process. Therefore the total time complexity is O ( n 2 + mN ).

Note that m is much smaller than n with a reasonable distance threshold  X  .And the Euclidean distance computation does not need to access the road network M . The computation time and I/O overhead are reduced dramatically. The road-connection-based clustering algorithm also has the problem of individual sen-sitivity. The similar idea of traveling buddy can be applied to improve the algorithm X  X  efficiency. The road buddy is thus proposed to maintain small groups of objects moving together along the roads.
 be the buddy radius threshold, the road buddy b is defined as a set of objects satisfying: the geometry center of b on the road network M . The buddy X  X  radius  X  is defined as the road network distance from netcen ( b )to b  X  X  farthest member.

To obtain netcen ( b ), the system needs to first compute the geometry center of b ,then employ a map-matching algorithm to project the geometry center to the nearest road. In this study, we use the map matching algorithm developed in our previous works [Yuan et al. 2010].
 The road buddy has the same operations of split and merge as the traveling buddy. Their initializations are also similar. Their major difference is at the maintenance process. Because it is costly to compute the road network distance from netcen ( b ) to each member, the maintenance algorithm employs the filtering-and-refinement strategy to reduce time cost, as listed in Figure 17.

When the data of a new snapshot arrives, Algorithm 8 first computes the network center of each buddy (lines 2 X 3), then checks each road buddy to see whether a split operation is needed (lines 4 X 11), finally scans the buddy set and merges the ones that are close to each other (lines 12 X 17). The key steps of filtering-and-refinement are at lines 5, 6, 14, and 15. Before computing the road network distance between two points, the algorithm checks whether their Euclidean distance is passing the threshold and only carries out further computation on the qualified pairs.

The road buddy can be used to improve the efficiency of road-connection-based clus-tering and companion generation by avoiding accessing the object details. Similar to the traveling buddy, we propose several lemmas that are helpful for road companion discovery.

L EMMA 6. Let b be a road buddy,  X  be the distance threshold. If the buddy radius  X   X   X / 2 , then all the objects in b are directly road connected to each other. Such a road buddy is called a road connected buddy .

P ROOF .Notethat  X   X   X / 2, thus for  X  o i , o j  X  b , netd ( o i , netcen ( b ))  X   X  and o Definition 8, o i and o j are directly road connected.
 L EMMA 7. Let b i ,b j be two road connected buddies and  X  be the distance threshold. If  X  o connected.

P ROOF .If netd ( o i , o j )  X   X  ,then o i and o j are directly road connected. Since all the objects in b i and b j are directly road connected from o i and o j , respectively, therefore, all the objects in the two traveling buddies are road connected.

Lemma 6 and 7 can be used to speed up the road-connection-based clustering. The lemmas show that if two buddies are tight by themselves and close to each other, the system can consider all their members as road connected without further computation. b j are not directly road connected.
 connected.

Lemma 8 is helpful to prune most of the unconnected buddies in road-connection-based clustering. Especially the lemma does not require the system to compute any road network distance on M . The system only needs the network center of buddies and their radius as input (which are already computed), and the huge I/O cost could be saved.

The detailed algorithm is listed in Figure 18. Algorithm 9 first calls Algorithm 8 to update the road buddies with new data (line 1), then randomly picks a road buddy as the seed to form a cluster (lines 2 X 4). The algorithm searches for the buddies that are road connected and adds them to the cluster (lines 2 X 18). The buddies that are distant from the seed are filtered out directly without detailed distance computation (lines 8 X 9). The algorithm searches road connected buddies with Lemmas 6 and 7 (lines 10 X 18). Finally, the algorithm outputs the clustering results when all road buddies are processed (line 20).

The buddy index can be retrieved from road buddies and help companion genera-tion. Because this technique is actually independent from the metrics and distance computation, Algorithm 5 can be applied directly on road buddies.
 In many applications such as military object monitoring, several members may tem-porarily leave the group and go back in short time. The companion discovery algorithm will miss such companions if strictly following the time constraints.

Example 8 . Figure 19 shows the trajectory streams of a small team of military troops. At snapshot s 1 , the team members move together. They send out a member o 1 to scout around at s 2 and o 1 returns to the team at s 3 . The team then splits to two parts at s 4 to conduct a  X  X incer attack X  against enemies. Finally they reunite at s 5 . Suppose the size threshold is 6 and the duration threshold  X  t is set as 30 minutes. The system cannot discover any companion from the data if strictly following the constraints.
In most cases, the rigid time constraints may lead to no result or not the best results of discovered traveling companion. It is necessary to release the constraints for more effective discovery. To this end, we introduce the concept of loose companion as follows.
Definition 13 ( Loose Companion ). Let  X  s be the size threshold,  X  t be the duration threshold, and  X  l be the leaving time threshold, a group of objects q is called loose companion if: (1) let T be the total time that the members of q are density connected, T  X   X  t ; (2) q  X  X  size size ( q )  X   X  s ; (3) for each member o of q ,let t be the maximum period that o is not density connected
The loose companion allows the member objects temporarily leaving the companion, as long as the leaving time is less than the threshold  X  l . In Figure 19, if we set  X  l as 5 minutes, the military team could be discovered as a companion.
 Similarly we propose the definition of loose buddy .

Definition 14 ( Loose Buddy ). Let s be a snapshot of the trajectory stream,  X   X  be the buddy radius threshold, and  X  l be the leaving time threshold, loose buddy b is defined as a set of objects, for  X  o i  X  b : (1) dist ( o i , cen ( b ))  X   X   X  , where cen ( b ) is the geometry center of b ;
To discover the loose companions and maintain the loose buddies, the system can follow the same frameworks proposed in previous sections. Only minor modifications need to be carried out in the intersection and split operations. When an object leaves the companion candidate or buddy, the system does not remove that object or split the buddy immediately, instead puts the object/buddy in a buffer to be removed/split after a time period of  X  l . If the object returns in  X  l , the remove/split command will be canceled. Such modification does not influence the general frameworks of companion discovery. The other steps of the clustering-and-intersection algorithm, smart-and-closed method, and the buddy-based approach remain the same for loose companion discovery, hence we omit the details here due to space limitation. Datasets. We evaluate the proposed methods on both real and synthetic trajectory datasets. The taxi dataset ( D 1 ) is retrieved from the Microsoft GeoLife and T-Drive projects [Yuan et al. 2010; Zheng et al. 2010] with the road network of Beijing. The trajectories are generated from GPS devices installed on 500 taxis in the city of Beijing. from the CBMANET project [Krout 2007], in which an infantry battalion of 780 units, divided as 30 teams, moves from Fort Dix to Lakehurst for a mission on two routes in 3 hours. Meanwhile, to test the algorithm X  X  performance in large datasets, we also generate two synthetic datasets ( D 3 and D 4 ), being comprised of 1,000 to 10,000 objects, with more than 10 million data records.

Baselines. The proposed Smart-and-Closed algorithm (SC) and Buddy-based discov-ery algorithm (BU) are compared with Clustering-and-Intersection method (CI), which is used as the framework to find convoy patterns [Jeung et al. 2008]; and two state-of-the-art algorithms: (1) The Swarm pattern (SW) [Li et al. 2010] that captures the objects moving within arbitrary shape of clusters for certain snapshots that are possi-bly nonconsecutive; (2) the TraClu algorithm (TC) [Lee et al. 2007] that discovers the common subtrajectories with a density-based line-segment clustering algorithm.
Environments. The experiments are conducted on a PC with Intel 6400 Dual CPU 2.13 GHz and 2.00GB RAM. The operating system is Windows 7 Enterprise. All the algorithms are implemented in Java on the Eclipse 3.3.1 platform with JDK 1.6.0. The parameter settings are listed in Figure 20. In this section we conduct experiments to evaluate the efficiency of companion discov-ery algorithms in Euclidean space. Since both SW and TC cannot output the results incrementally, we take the running time of the entire dataset as the measure for time cost. The size of candidate set (number of objects) is used to measure the space cost of companion computation. The only exception is TC, where since the algorithm only car-ries out the subtrajectory clustering task and does not store any companion candidates, TC X  X  space cost is not included in the experiment.

We first evaluate the algorithm X  X  time and space costs on different datasets with default settings. Figure 21 shows the experiment results. Note that the y-axes are in logarithmic scale. BU achieves the best performances on all the datasets. In the largest dataset D 4 , BU is an order of magnitude faster than CI and SW. BU X  X  space cost is only 20% of SW and less than 5% of CI.

Figure 22 illustrates the influences of companion size threshold  X  s in the experi-ments. The experiment is carried on dataset D 3 . Based on default settings, we evaluate the algorithms with different values of  X  s . Generally speaking, when the size threshold grows larger, the filtering mechanism is more effective to prune more companion can-didates in each snapshot. The space costs reduce significantly, and the running times also decrease for fewer intersections.

We also study the influence of duration threshold  X  t . Based on default settings, the experiments are conducted on dataset D 3 . The value of  X  t is changed from 3 to 15, and the algorithm X  X  performances are shown in Figure 23. BU, SC, and CI are all faster when  X  t grows larger, because many companion candidates are not consistent enough to last for a long time. When setting  X  t as 15 snapshots, BU can process the dataset in less than 20 seconds (Figure 23(a)). It is almost an order of magnitude faster than SC and CI. TC is not influenced by  X  s and  X  t , since it is only a clustering algorithm and does not generate any companion candidates. Beside TC, SW also could not improve the performance when  X  t increases. The reason is SW utilizes the object growth strategy to prune candidates. Such heuristics could only work with the size threshold  X  s ,but cannot benefit from larger  X  t .

In summary,  X  s and  X  t are two important factors that influence the efficiency of companion discovery algorithms. When increasing the threshold, more companion can-didates are pruned and the time and space costs are reduced. BU outperforms other methods in the efficiency evaluations, especially in the scenarios of long-lasting streams with a large number of objects. Why is the buddy-based discovery algorithm more efficient? In this section we carry out the experimental analysis to reveal the advantages of the buddy-based discovery method.

In the beginning, we tune the parameters of BU to study the factors that influence its efficiency. With  X  s and  X  t set as default values, we test BU with different buddy radius threshold  X   X  from  X / 10 to  X / 2, and record the average buddy size | b | , buddy number, and algorithm X  X  running time. Their relationships are demonstrated in Figure 24. One can clearly learn from Figure 24(a) the total buddy number is inversely proportional to the average buddy size | b | . In addition, the number of unchanged buddies decreases rapidly as | b | grows larger. However, as shown in Figure 24(b), the running time of both buddy-based clustering (B-Cluster) and BU decreases with larger | b | . This phenomenon can be explained by Proposition 2, where the cost of buddy X  X  maintenance algorithm is O ( n + m 2 ), where n is the number of objects and m is the number of buddies. If n is fixed, then m is inversely proportional to | b | . Hence BU costs less time if | b | is larger. Based on the efficiency analysis, we recommend setting the buddy radius as a relatively large value (such as  X / 2). Figure 24(b) also records the time cost of the DBSCAN clustering algorithm as a reference. Even if less than 20% buddies stay unchanged (which is rare for real-world objects), as long as the average size of the buddies is larger than 3, the buddy-based clustering algorithm can still outperform DBSCAN. The experiment results show that BU is especially feasible for processing a trajectory stream with dense object clusters.

BU has three steps, namely the maintenance step (M-step, Algorithm 3), clustering step (C-step, Algorithm 4), and intersection step (I-step, Algorithm 5). To study the time cost of each step, the system carries out BU on the four datasets and records the time costs of each step, as well as their proportions in the total running time, as shown in Figure 25. The results denote that the clustering step is actually the most efficient in the three, costing less than 5% of the total running time, compared to the DBSCAN clustering which usually takes 40 X 50% of the total running time of SC. BU spends an extra 10% X 15% time in maintaining the buddies to save more time from the clustering task.

From the aforesaid experiments, one can clearly see the two key advantages of BU: (1) utilizing the buddy information to filter out most objects without accessing their details; (2) employing the buddy index to reduce the size of the candidate set, and so decrease the intersection times of companion discovery. The third part of the experiment is to evaluate the quality of the retrieved companions. In dataset D 2 , an infantry battalion of 780 units moves from Fort Dix to Lakehurst for a mission on two routes in 3 hours. The objects are organized in 30 teams, with each team having 25 to 30 units. The information of team partitioning is retrieved as the ground truth. The algorithm X  X  outputs are matched to the ground truth and the measures of precision and recall are calculated as follows.

Precision. The proportion of true companions over all the retrieved results of the algo-rithm is the precision. It represents the algorithm X  X  selectivity in finding out meaningful companions.

Recall. The proportion of detected true companions over the ground truth is the precision. This criteria shows the algorithm X  X  sensitivity for detecting traveling com-panions.

We conduct experiments with different values of the size threshold  X  s . The results of effectiveness evaluation are shown in Figure 26. BU and SC have the same precision and recall since they output identical companions. They have about 20% precision improvement over SW, and near 40% precision improvement over CI. SW generates the swarm patterns of frequently meeting objects, which is actually a superset of the companions. The swarm pattern is highly sensitive to helping find out all the companions (i.e., 100% recall), but SW also generates more false positives that bring down the algorithm X  X  selectivity. CI has the same problem with even lower precision. Since there are many redundant and nonclosed companions in the results, more than half of CI X  X  results are not useful.

Again, TC is not affected by the parameters of  X  s and  X  t . TC takes the movement direction as an important measure to compute subtrajectory clusters; its results reflect the major directions of the object movements. However, such clusters may not capture the information of companions, because the companion member X  X  moving direction might be different. As an illustration, please go back to Figure 1. From snapshot s 2 to s , the moving directions of o 8 and o 9 are different, hence they may be put in different subtrajectory clusters.

Another interesting observation is that, in Figure 26, BU, SC, CI, and SW X  X  precisions all increase when  X  s becomes larger, since fewer companions can pass a higher size threshold. However, if  X  s is set too high (more than 25), several true companions will also be filtered out and the algorithm cannot achieve 100% recall.

In the next experiment, we study the influence of time threshold  X  t . Figure 27 shows the precision and recall of the five algorithms with different  X  t on D 2 . BU and SC achieve better performance than SW and CI. When increasing  X  t , the algorithm X  X  precision increases, but they can still keep a high recall. Since all the true companions last for a long period in D 2 ,ifweset  X  t greater than 11, both BU and SC can achieve 100% precision and recall. However, if  X  t is set too high, for example, 15, no companion can be discovered since there exist no object groups moving together for such a long time.
In general, BU and SC can guarantee 100% recall (i.e., not missing any real com-panion), we suggest that in real applications, the user should set a relatively high time threshold to filter out false positives, but a moderate size threshold to guarantee the algorithm X  X  sensitivity. To test the efficiency of road companion discovery, we perform the evaluation on dataset D 1 with the road network of Beijing, which has 106,579 road nodes and 141,380 road segments. The default size threshold  X  s is set as 8 and the time threshold  X  t is set as 11. In this experiment, we compare the performance of four methods: (1) the Clustering-and-Intersection framework with road network distance computation (CI); (2) the Smart-and-Closed algorithm with road network distance computation (SC); (3) the smart-and-closed algorithm with Filtering-and-Refinement strategy (FR); and (4) The Road-Buddy-based method (RB).

We first evaluate the time and space costs of road companion discovery. The number of accessed road nodes is used as the measure for I/O cost. Based on default settings, we evaluate the algorithms with different values of  X  s . Figure 28 shows the running time and accessed node number. Generally speaking, when the size threshold grows larger, both running time and I/O costs decrease. The computation cost of road companion discovery is much larger than the traveling companion discovery on Euclidean space. This is mainly caused by the high I/O overhead in road network distance computation. Since the road network distance computation becomes the major cost, SC cannot save much time comparing to CI. However, FR and RB are an order of magnitude faster than SC and CI, because they utilize the filtering-and-refinement strategy to avoid most unnecessary road network distance computations. The effects of RB are better, since RB groups the objects in small buddies and limits the distance computation in a small region with lower I/O overhead.

The influence of duration threshold  X  t is also studied in our experiment. Based on default settings, the value of  X  t is changed from 3 to 15; the algorithms X  performances are shown in Figure 29. All the algorithms run faster when  X  t grows larger, because fewer road companion candidates can last for a long time. Again, RB and FR only cost 20% X 50% time as CI and SC.

The experiment results show that the main bottleneck of road companion discovery is at the distance computation stage. The traditional companion discovery methods, BU and SC, do not work well on the road networks. The new frameworks of RB and FR reduce the time cost on unnecessary shortest path computation, therefore they can achieve higher efficiency peformances. In the previous experiments, we set the leaving threshold  X  l as 0. In this section, we conduct experiments on loose companion discovery. We run the algorithms of BU, SC, and CI on dataset D 3 by tuning  X  l from 0 X 6 snapshots.

Figure 30 shows the algorithms X  time and space costs. With larger  X  l , all the algo-rithms X  space costs increase rapidly since they cannot prune the candidates if several objects temporarily leave the companion, hence the system has to spend more time in making intersections with a larger candidate set. However, even with large  X  l , BU still can discover the loose companions in about 20 seconds.

Finally we carry out the effectiveness experiment on the military dataset D 2 .  X  l is changed from 0 to 6 snapshots, and other parameters are set as the default values. As shown in Figure 31(a), the precision of companion discovery decreases with larger  X  , since more companions are generated and inevitably the number of false positives increases. However, the good news is that the recall increases as  X  l grows (Figure 31(b)).
The experiment results show the necessity of loose companion discovery. With a released time constraint, BU and SC can discover more meaningful companions and achieve a higher recall. The system X  X  feasibility is increased in real applications. According to the methodologies, the related works of traveling companion discovery can be loosely classified into two categories: trajectory clustering and movement pattern discovery.
 The works in this category focus on developing efficient algorithms to cluster moving objects. Gaffney and Smyth first proposed the fundamental principles of clustering moving objects based on the theories of probabilistic modeling [Gaffney and Smyth 1999; Cadez et al. 2000]. Many distance functions, such as DTW [Yi et al. 1998] and LCSS [Gunopoulos 2002] are proposed. Lee et al. proposed a novel partition-and-group framework to find the clusters based on subtrajectories [Lee et al. 2007].
In Har-Peled [2003], Har-Peled shows that the moving objects can be clustered when the resulting clusters are competitive at any time during the motion. Yang et al. pro-posed the idea of a neighbor-based pattern detection method for windows [Yang et al. 2009]. Ester et al. made the progress to generate incremental clusters [Ester et al. 1998]. Li et al. propose a microcluster [Li et al. 2004] based schema to cluster moving objects. Zhang and Lin use the k-center clustering algorithm [Gonzalez 1985] for his-togram construction. A distance function combining velocity and position differences is proposed in their work [Zhang and Lin 2004]. More recently, Jensen et al. utilize the velocity features to cluster objects for the current and near future positions [Jensen et al. 2007].

However, as pointed out in Jeung et al. [2008], most of the aforsaid methods cannot be used directly for traveling companion discovery. The major problem is that those algorithms tend to generate clusters for the entire trajectory dataset, instead of each snapshot. Hence the detailed object relationships and evolving companion patterns are all lost. In addition, some algorithms require the object X  X  velocity in advance and need to scan the data for multiple times. Such requirements are not fit for trajectory streams. Movement pattern discovery is a hot topic in recent years. The problem has been variously referred to as the search for flocks [Gudmundsson and Kreveld 2006], moving clusters [Kalnis et al. 2005], spatial-tempo joins [Bakalov et al. 2005], spatial colocations [Yoo and Shekhar 2004], meetings [Gudmundsson et al. 2004], convoys [Jeung et al. 2008], moving groups [Aung 2008], swarms [Li et al. 2010] and so on.

One of the earliest works is flock discovery [Gudmundsson et al. 2004]. A flock is defined as a group of objects moving together within a circular region [Gudmundsson and Kreveld 2006]. There are several variations of this model: Variable flock permits the members to change during the time span [Benkert et al. 2008],while meeting is a circle similar to flock but fixed in a single location all the time [Gudmundsson and Kreveld 2006]. However, such shapes are restricted to circles and the results are also sensitive to the parameter of radius.

Li et al. designed a flow scan algorithm for hot route mining [Li et al. 2007]. Liu et al. mined frequent trajectory patterns by using RF tag arrays. Their work successfully demonstrated the feasibility and the effectiveness of movement patterns in real life [Liu et al. 2007]. Tao et al. proposed the technique of spatio-temporal aggregation using a sketch index. This method can process the queries an order of magnitude faster than the previous works [Tao et al. 2004]. Giannotti et al. proposed the interest-region -based mining algorithm [Giannotti et al. 2007]. Horvitz et al. propose the models of using groups of mobile users to discover congestions in urban areas [Horvitz et al. 2005]. The shortest path problem has been studied on land surface [Xing and Shahabi 2010; Liu and Wong 2011] and this technique has been used to process the k-NN queries [Shahabi et al. 2008; Xing et al. 2009]. Tao et al. propose the techniques to find k-skip shortest paths [Tao et al. 2011]. Yuan et al. present a cloud-based system computing customized and practically fast driving routes for an end-user using traffic conditions and driver behavior, which is a milestone study in this field [Yuan et al. 2011].
Zhang et al. propose the techniques to produce intersections of streaming moving objects [Zhang et al. 2008, 2011]. This method is a big improvement from existing algorithms by the speedup of several orders of magnitude. Nutanong et al. use a safe region to report objects that do not change over time [Nutanong et al. 2008, 2010]. The proposed V*-Diagram has much smaller I/O and computation costs than previous methods. It outperforms the best existing technique by two orders of magnitude.
However, since the preceding methods focus more on discovering hot spots, regions, or routes rather than object groups, they cannot be used directly for companion discovery.
Kalnis et al. proposed the first study to automatic extraction of moving clusters from large spatial datasets [Kalnis et al. 2005]. In a recent work, Jeung et al. proposed the framework of convoy query [Jeung et al. 2008]. It is a significant step forward in the works of movement pattern mining, since it allows the objects to organize in arbitrary shapes. Li et al. further released the constraints of convoy and proposed the swarm pattern to discover object groups in a sporadic way [Li et al. 2010].
 The concepts of convoy and swarm patterns are similar to traveling companion. However, the convoy mining algorithm needs to scan the entire trajectory into memory to make trajectory simplification, and the system also needs to load the whole dataset into memory to search for swarms. It is impractical to use such a method in a data stream environment. The swarm pattern is a frequent itemset-based concept. Since it is difficult to detect large size frequent itemsets [Zhu et al. 2007], the swarm pattern has limited applicability for datasets with large-scale objects. The major advantage of the companion discovery technique is about the discovery efficiency. The buddy-based method can discover the companions of arbitrary shapes an order of magnitude faster. Hence it is a feasible method to be applied in the data stream scenarios of huge amount of trajectories.

Figure 32 compares the features of some related methods with the proposed algo-rithms to discovery of traveling companions, road companions, and loose companions. In this study we investigate the problem of traveling companion discovery on trajectory data streams. We propose the algorithms of smart-and-closed discovery to efficiently generate companions from trajectory data. The model of traveling buddy is proposed to help improve both the clustering and intersection processes for companion discov-ery. The proposed methods are extended to more complex scenarios for road compan-ion and loose companion discovery. We evaluate the proposed algorithms in extensive experiments on both real and synthetic datasets. The buddy-based method is shown to be an order of magnitude faster than existing approaches on both Euclidean space and road networks. The effectiveness of the buddy-based algorithm also outperforms other competitors in terms of precision and recall.

In the future, we are going to integrate the companion discovery methods to real application services such as battlefield monitoring systems and traffic analysis services.

