 Clustering is a fundamental problem in statistics and ma-chine learning, whose solution is commonly computed by the Expectation-Maximization (EM) method, which finds a locally optimal solution for an objective function called log-likelihood. Since the surface of the log-likelihood function is non convex, a stochastic search with Markov Chain Monte Carlo (MCMC) methods can help escaping locally optimal solutions. In this article, we tackle two fundamental con-flicting goals: Finding higher quality solutions and achiev-ing faster convergence. With that motivation in mind, we introduce an efficient algorithm that combines elements of the EM and MCMC methods to find clustering solutions that are qualitatively better than those found by the stan-dard EM method. Moreover, our hybrid algorithm allows tuning model parameters and understanding the uncertainty in their estimation. The main issue with MCMC methods is that they generally require a very large number of itera-tions to explore the posterior of each model parameter. Con-vergence is accelerated by several algorithmic improvements which include sufficient statistics, simplified model parame-ter priors, fixing covariance matrices and iterative sampling from small blocks of the data set. A brief experimental eva-luation shows promising results.
 G.3 [ PROBABILITY AND STATISTICS ]: Probabilis-tic algorithms (including Monte Carlo) Bayesian model; MCMC; Clustering; EM; Gaussian mix-tures
Clustering is a fundamental data mining technique that is frequently used as a building block for the treatment of more complex problems such as Class Decomposition and Bayesian Classifiers. Maximization algorithms X  weakness is that, if the problem to be explored has more than one pos-sible extrema, they don X  X  return the best possible solution, but only the first maximum encountered. This has been ex-tensively studied in the literature. Considerable work has gone into improving the EM algorithm and into accelerat-ing its convergence. In [11], the authors present a survey of several approaches from the Machine Learning commu-nity, with mathematical justifications for them. In this work we present a modification to the classic EM algorithm that searches for better solutions (e.g. lower log-likelihood) based on the Monte Carlo (MC) approach. MC techniques use random walks to explore the solution space. In general it is found that, even though MC algorithms take a long time to converge, they reach very good solutions avoiding been trapped in local extrema. While in recent years the prob-lem of accelerating the EM algorithm has been studied, ([6], [10] among others) not much has been done to speed-up the convergence of Gibbs Samplers for mixtures of Gaussians. In this paper we describe the FAMCEM algorithm, the hy-bridization of EM with MC for faster, more accurate results.
The Expectation-Maximization Algorithm (EM) is used to estimate the parameters of a mixture of k normal dis-tributions. The multivariate normal distribution for a d di-mensional vector x for cluster j  X  { 1 ,...,k } with mean C and covariance matrix R j is:
P ( x ; C j ,R j ) = (2  X  ) d | R j |  X  and P ( y ; C,R,W ) = P k i =1 W j P ( x ; C j ,R j ) is the probabil-ity of the mixture. W is a matrix that contains the weights of each of the clusters. Note that R j is a d  X  d matrix, however since it is diagonal, we can just keep the non-zero elements as a d  X  1 vector
The Mahalanobis Distance of a multivariate vector x from a group of variables with mean C j and covariance R j is defined as
This distance is used in EM instead of the regular Eu-clidean distance [3] since it provides an understanding, not only of how far a certain point is from the center of mass of the cluster, but also how dense the cluster is, by scaling the distance by the covariance matrix. EM takes as an in-put the data-set ( X = { x 1 ,...x n } ) and gives as an output the matrices C , R and W . The quality of the solution is measured by the L og-Likelihood , defined as: In general EM algorithms stop when the change in log-likelihood is less than a predetermined precision.
According to [12] a Markov process is a stochastic process such that the conditional probability of value x i at time t is uniquely determined by the value x i  X  1 at time t i  X  1 and not by any knowledge of the values at earlier times. In a Monte Carlo algorithm, we generate a Markov chain in which each successive state is generated by its predeces-sor and accepted (or rejected) according to an acceptance ratio determined by the probabilities of each state. This algorithm randomly attempts to sample the solution space, sometimes accepting the move and sometimes remaining in place. Gibbs Samplers are Markov Chain Monte Carlo algo-rithms for obtaining sequences of observations of the joint probability distribution of a set of random variables, when direct sampling is difficult. Gibbs Samplers are commonly used as means of Bayesian Inference instead of deterministic algorithms such as EM. In order to illustrate the computa-tional power of Monte Carlo techniques, it is customary to use examples borrowed from Physics. A common problem in the area, is to determine the minimum of the potential energy in order to find the equilibrium state of a system. Determining the global extrema of this potential function, and the state with the lowest energy is not trivial since sys-tems with more than 3 bodies are not solvable in a closed manner.

Monte Carlo algorithms (in particular the Metropolis Has-tings model) were developed to solve this kind of problems [4]. Deterministic schemes, such as the Gauss-Newton Al-gorithm and its variants (or for that matter EM) find pro-gressively better solutions in an iterative manner, with the result that, if there are several possible minima, the algo-rithm can stop at a local one, without finding the global result we are looking for. In contrast Monte Carlo iterations allow the solution to worsen, climbing out of the shallow val-leys in order to find the deep ones. In other words, Monte Carlo techniques effectively sample phase space until the best possible solution is found.
Markov Chain Monte Carlo (MCMC) methods are a set of algorithms for sampling probability distributions by con-structing a Markov Chain whose equilibrium distribution is the desired one. Since it is difficult to determine a priori the number of steps (iterations) that will result in a stable dis-tribution, MCMC models tend to overestimate the number of iterations needed, therefore requiring longer computation time. This issue is particularly important when the size of the problem is significantly large, since each step of the com-putation will be repeated a very large number of times. In this section we describe our efforts to improve EM by in-corporating ideas from Monte Carlos style algorithms. To begin we will briefly describe the FREM algorithm from [8], since we used it as our starting point. We will also analyze the time complexity of the complete algorithm.
Sufficient statistics are multidimensional functions that summarize the properties of clusters of points. One of the interesting properties of these summaries is that they are in-dependent, that is, statistics from one cluster do not depend on the values of the data points from other clusters. In this case we introduce three statistics per cluster D j : N j = | D L j = P
N stores the number of points per cluster and is a k  X  1 matrix while L stores the sum of the data points and Q stores the sum of the squares. L and Q are k  X  d matrices. FREM uses these sufficient statistics to reduce the number of reads of the dataset, allowing the periodic estimation of the parameters without resorting to extra I/O steps, signif-icantly reducing the running time of the algorithm.
A significant improvement described in [8] was the intro-duction of the parameter  X  to circumvent the weakness of EM when variances approach zero, that is, when there is very little variation in one of the dimensions. This parame-ter is a small positive constant that, multiplied by the global standard deviation, is added to the variances during its up-date in the maximization step. It is chosen small enough to avoid the real variance values, but large enough to avoid zeros that could make the results undefined.
 The formulae used in FREM (and in FAMCEM) is FREM also makes use of the fact that, for sufficiently large data sets, a portion of the data-set is representative of the whole. This  X  X ractal X  behavior of data is illustrated in Fi-gure 1. In it, we plot two dimensional synthetic data in the ( i,j ) plane. The complete data-set consists of 5500 points distributed in three clusters. In the second part of the graph we show a random sampling of 10% of the data points and it presents the same clustering behavior (albeit with a lower density). Going back to FREM, the algorithm can be accelerated by including Maximization steps before the Expectation state has finished processing the complete data-set. FREM uses a parameter  X  , that the authors fixed experimentally to  X  =  X  roughly n/ X  times during a single iteration of the algorithm, the convergence is accelerated substantially. FAMCEM introduces two significant changes to FREM. The first one is a modification to the Expectation step: In FREM, as in the regular EM algorithm, the datapoint is assigned a series of probabilities of belonging to each of the clusters. In FAMCEM we use these probabilities to find a unique cluster to which the data point belongs, this pro-d uces a decoupling between the clusters, simplifying (as we will see) the calculation of the Log-Likelihood. However, in-stead of assigning the data point to the cluster with highest probability, we use the Alias Method [5] and [2]. This is the main Monte Carlo change, since it allows the algorithm to explore the parameter space, by allowing the possibility that the data point belongs to a lower probability cluster. By letting the algorithm swim upstream , climbing over local maxima, we allow it to find possible better energetic minima.
To illustrate this step we can imagine a distribution of points in two-dimensional space: Some points are relatively easy to place within a cluster, that is to say, the proba-bilities are skewed in favor of only one cluster. However, in general this is not the case. In fact any point between two centroids could belong to either one, particularly if the standard deviations (radii) are large enough. While at some point during the procedure, the probability might favor one cluster in detriment of others it is possible that this is just an artifact of the current distribution. Allowing a certain opportunity to be included in other clusters, while making the current iteration slightly worse, could lead to an overall improvement of the solution.
 The FAMCEM divides the iterations into two main phases. In the first, burn-in phase, the algorithm uses a regular FREM Maximization step in order to calculate the initial standard deviations and variances. After the burn-in period is finished, we start a Sampling phase where, instead of using Maximization steps we use Sampling steps.
 The Sampling step is the second main difference with FREM. The initial update of the parameters is performed as in equations 4 and 5, however we add an extra step: After we have an estimate for C j we use a normal distribution to calculate C  X  j , using | R j | as the standard deviation. This al-lows for further exploration of the solution space, improving our chances of finding the global extrema. It is important to e mphasize that the Sampling phase only explores the priors of C and W but not R . R uses a non-informative prior and remains fixed during Sampling, to reduce the complexity of the problem [7].

The reason for these hybrid approach is to use the first part to estimate the covariance matrices, and use them in the sampling phase. Sampling requires knowledge of the ini-tial distribution of the priors [7] and we resort to FREM to calculate them. It is important to mention that the pos-terior probability for C arises naturally as a result of our calculations.

As we mentioned previously, choosing a unique cluster for each data point, coupled with the fact that the covariance matrices are diagonal, has the added benefit of simplifying the calculation of the log-likelihood. This quantity can be calculated using the sufficient statistics matrices, in a sin-gle step, without resorting to reading the data-set a second time, or making extra calculation steps in the Expectation subroutine.

L ( X ) =  X  d
The time complexity of this algorithm is dominated by the number of iterations of the main loop and the number of data points in the data-set. In the worst case scenario the time complexity is O ( ndk ) per iteration, as was calculated for FREM in [8]. However, while FREM reaches equilibrium in few passes, per force Monte Carlo style algorithms need a much larger number of iterations, since it much more dif-ficult to achieve stability and convergence.
We evaluated out proposed method by using a real data-set from the UCI Machine Learning Repository [1]. The data-set, represented measurements of electric power con-sumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quanti-ties and some sub-metering values were available. The data-set has 9 dimensions that include date of the measurement, time and 4 electrical measurements and 3 dimensions that represented discrete characteristics of the households.
We implemented the algorithm in C++. The data set was stored in a plain text file and the experiments were run on a machine using an Intel Core i5 CPU, running at 1.8 Ghz, with 4Gb of main memory. The computer was running a 64 Algorithm 1 T he FAMCEM Clustering Algorithm Input: X = { x 1 , x 2 ,...,x n } and k Output:  X  = { C,R,W } and L ( X ) /* Parameters (defined in the text) */  X   X  X  X  for j = 1 to k do end for
I = 0 while ( | L ( X ) I  X  L ( X ) I  X  1 | &gt;  X  and I  X  MAXITER) do end while bit version of Windows 8 operating system, and the program w as developed using Windows Visual Studio 2012 Pro. The algorithm reads the data-set into memory once and operates in main memory.

We show the results in Table1. It shows the calculation of the Log-Likelihood for the data-set, when we varied the number of clusters considered for a fixed n = 100000 and d = 5. For comparison purposes we show the results from EM runs of exactly the same data. When comparing running times, FAMCEM is 2.49 times slower than a classic EM algorithm: for 18 clusters EM took 76.11 sec, versus 189.45 sec for FAMCEM due to running about 4 times as many iterations.
Although more experimentation is required, FAMCEM shows an improvement over FREM in the quality of solu-tions, however this is counterbalanced by the considerable increase in execution time. FAMCEM could be considered as an alternative to FREM when the accurate results are more important than time efficiency.

Future work will include optimizations for storage and time efficiency, as well as the translation of the code into C#, in order to enable SQL calls and, ultimately, the creation of an UDF that can be called directly from a DBMS, as well as the possible integration with MapReduce to enable Big Data Analytics. Further development on this problem will involve programming the algorithm directly in SQL as in [9]. This research work was partially supported by National Sci-ence Foundation grants IIS 0914861 and IIS 0915196. [1] K. Bache and M. Lichman. UCI machine learning [2] L. Devroye. Sample-based non-uniform random variate [3] R. Duda and P. Hart. Pattern Classification and Scene [4] D. B. Hitchcock. A history of the Metropolis X  X astings [5] R. A. Kronmal and A. V. Peterson Jr. On the Alias [6] N. Kumar, S. Satoor, and I. Buck. Fast parallel [7] L. Liang. On simulation methods for two component [8] C. Ordonez and E. Omiecinski. Accelerating EM [9] C. Ordonez and S. Pitchaimalai. Bayesian classifiers [10] B. Thiesson, C. Meek, and D. Heckerman.
 [11] N. Ueda, R. Nakano, Z. Ghahramani, and G. Hinton. [12] N. G. Van Kampen. Stochastic processes in physics
