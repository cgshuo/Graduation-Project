 Estimating the geographic location of images is a task which has received increasing attention recently. Large numbers of images uploaded to platforms such as Flickr do not contain GPS-based latitude/longitude coordinates. Obtaining such geographic information is beneficial for a variety of appli-cations including travelogues, visual place descriptions and personalized travel recommendations. While most works in this area only exploit an image X  X  textual meta-data (tags, title, etc.) to estimate at what geographic location the im-age was taken, we consider an additional textual dimension: the image owner X  X  traces on the social Web. Specifically, we hypothesize that information extracted from a person X  X  microblog stream(s) can be utilized to improve the accuracy with which the geographic location of the images is esti-mated. In this paper, we investigate this hypothesis on the example of Twitter streams and find it to be confirmed. The median error distance in kilometres decreases by up to 67% in comparison to existing state-of-the-art. The best results areachievedwhentweetsthatwereposteduptotwodays before and after an image was taken are considered. More-over, we also find another type of additional information useful: population density data.
 Categories and Subject Descriptors: H.3.3 Information Storage and Retrieval: Information Search and Retrieval General Terms : Human Factors, Experimentation Keywords: image location estimation, image placing
Estimating the geographic location of images (also re-ferred to as geotagging, georeferencing or image placement on the world map) is a task which has received increasing attention in recent years. Large numbers of images uploaded This research has received funding from the European Union Seventh Framework Programme (FP7/2007-2013), grant agreement no ICT 257831 (ImREAL project).
 to platforms such as Flickr 1 do not contain GPS-based lati-tude/longitude coordinates. Placing those images on a world map by obtaining geographic information is not only impor-tant to aid people in the browsing and organizing of their personal image archives, but it also plays a role in applica-tion scenarios for large geographically tagged image corpora such as the automatic illustration of travelogues [16] and personalized travel recommendations [6, 7, 8].

While GPS-enabled cameras are beginning to reach the mainstream market (where an image X  X  latitude/longitude coordinates are automatically recorded as meta-data), this technology is not yet in widespread use. As an example, consider the test set of images we crawled from the photo sharing platform Flickr to test our hypotheses. Of the im-ages that were taken within the last year, more specifically between November 2010 and September 2011, only twenty percent are geo-tagged-since Flickr allows users to manu-ally add geo-information to images after uploading them, this number can be considered as an upper bound to the use of GPS-enabled devices in our data set.

Thus, there are vast amounts of images which are not ge-ographically tagged. A number of approaches, e.g. [21, 22, 23, 13], have been developed that estimate the geographic location of images based either on the textual meta-data that is available for each image (most often the tags that users assign to images), the visual features derived from the image itself, or a combination of the two. These works ex-ploit the very popular image sharing and organizing plat-form Flickr which we consider here as well. While to our knowledge the existing approaches only consider informa-tion derived directly from elements within Flickr (the im-age itself or meta-data attached to the image), we look be-yond this single platform and investigate if location estima-tion can be improved when considering traces of the image owner/uploader on other social Web platforms. We consider the exploitation of user traces across platforms an important step forward, as a myriad of social Web platforms exist and users are often active on a number of these.

In this work, we consider microblogs, and here more specif-ically we focus on the microblogging platform Twitter 2 .We hypothesize that we can improve the accuracy of the geo-graphic location estimation when we not only consider the tags the user has assigned to the image but when we also consider the utterances the user has made on Twitter in approximately the same time frame.
Flickr, http://www.flickr.com/
We chose Twitter as it is in wide-spread use around the world. Imagine a user Alice who for her holidays travelled to North America for a week in the summer. Alice visited Vancouver and Seattle. Alice is also very active on the so-cial Web, having among others a Flickr and a Twitter ac-count which she uses regularly to stay in touch with friends and family. She later uploads the pictures she took during the trip to Flickr. Instead of tagging every single picture with the correct name of the town or monument visited, to safe time, Alice decides to use the same set of tags for all images that describe the entire holiday { northamerica , seattle , vancouver , holiday } . During the holiday, Alice regu-larly tweeted about what she was doing and where she was going, e.g.:  X   X  X ancouver this weekend :) X   X   X  X ay 1 in Seattle -Been to the Space Needle. Sunny day. X   X   X  X itting in a cafe in Georgetown drinking wine with friends. X  Since posts on Twitter are always time-stamped, we can eas-ily determine which tweets Alice posted around the time of a particular image being taken (information that is read-ily available for images). We hypothesize that such tweets, where a user mentions place names, particular shops or mon-uments she has visited or is planning to visit, can improve the accuracy of the location estimation process. Eventually, our goal is the development of a framework, that automat-ically estimates latitude/longitude of each image, based on the image tags Alice provided and the traces Alice left on the social Web. Since various applications, that rely on ge-ographically tagged images are beneficial to the end user (Alice), we expect Alice to provide her online personas and user names willingly.

In this paper, we formulate and investigate the hypothesis that a user X  X  traces on Twitter can increase the accuracy of the image location estimation process. In particular, in this work we make the following contributions:  X 
We developed an extension to an existing state-of-the-art tag-based approach to location estimation [21] which is based on the language modeling framework for informa-tion retrieval. Our extension makes it possible to exploit the information extracted from the user X  X  tweets in a nat-ural way.  X 
We show that exploiting a user X  X  Twitter stream when estimating the location an image was taken at decreases the median error distance by up to 67%. We also find that the best results are obtained when tweets within two days before and after the image was taken are exploited.  X 
We find that images, which have fewer than two tags with a geographic scope (see Sec. 3.1.1) assigned to them, ben-efit the most from our cross-system approach. In our ex-periments, the median error distance decreases by 40% (57%) for images without tags (with one tag) when the user X  X  Twitter stream is employed as alternative source of information.  X 
Lastly, we also performed an investigation into the added value of using non-uniform priors in the language mod-eling approach. We utilized prior information about the population density and the climate. Our results show that a prior based on population density also improves the ac-curacy of the location estimation.

In the remainder of this paper we first outline previous research (Sec. 2) in the areas of image location estimation and users X  motives for using Twitter. The methodology of our approach is presented in Sec. 3. The experimental setup and the data sets used are described in Sec. 4, followed by the results and their discussion in Sec. 5. We conclude the paper in Sec. 6 and outline some avenues for future work.
Approaches proposed to solve the task of placing images on the world map by determining their latitude and longi-tude, have been relying on a variety of sources that are based on the image and its meta-data, the user uploading the im-age or external knowledge bases. Textual features exploited from the image are mostly the assigned tags and the title as well as the description. Visual features derived from the im-ages include a variety of types, such as color histograms or edge histograms [17]. Since photo sharing platforms such as Flickr contain a social network component as well, it is also possible to exploit such information by for example consid-ering the friends of a user or the location of the users com-menting on an image. Finally, external knowledge bases, in particular gazetteers (geographic dictionaries), may also be utilized in this task to classify terms as either being geo-graphic in scope or not.
 In [21] the tags assigned to images on Flickr are exploited. A grid is placed over the world map which results in equally sized cells. Each training image (with known location) is assigned to its correct grid cell. For each cell, a language model is created from the tags assigned by the user, and a test image is assigned to the geographic cell that produces the highest probability for generating the image X  X  tag set. In contrast to our approach, the cells are of fixed size, which may not be optimal as some regions (e.g., large cities such as London and Paris) will have a larger density of pictures than relatively remote places. We use dynamically sized grid cells, to account for these differences. To determine whether a tag is geographic in nature, in [21] GeoNames 3 is exm-ployed, a large gazetteer of geographic entities. Speficically, the weights of tags that appear in the English part of GeoN-ames are boosted.

Also based on tags is the approach proposed in [22]. In contrast to [21], the location estimation is performed on different levels of granularity (city granularity, street level granularity, etc.) and the evidence obtained over the dif-ferent granularities is combined in order to output the best match granularity location estimate. The authors evaluate their approach by creating a data set with 54 distinct loca-tions (cities in Europe) and classifying test images according to the city they were taken in. This setup is more restricted than the one we investigate in this paper: we attempt to place test images as closely to their true geographic location as possible; we are not restricted by a set of classes.
Instead of determining the correct grid cell and returning the latitude/longitude of the cell X  X  center, a text-based two-step approach is proposed in [23]: first, the most likely area is found by a language modeling approach and within the found cell, the best match images are determined by a sim-ilarity search. A test image with unknown location is then assigned the location found by interpolating the locations of the most similar images.

An approach that not only exploits textual information but also visual features was proposed in [13]. Here, textual information (tags) is the primary source of information, and visual features are used as fall-back option in instances where
GeoNames, http://www.geonames.org/ tags do not provide meaningful information. The approach works in different stages: first, the image tags are evaluated for the occurrence of at least one known geographic location (geographic lookup). If no location is found, PLSA [10] is performed on the tag data of the corpus. A failure here results in the exploitation of visual features which are used as input to a support-vector machine based classifier.
Georeferencing has not only been applied to images or videos. It has also been utilized to determine the geo-location of the subjects of Wikipedia articles (e.g. [25]) and the geo-location of Twitter messages as well as the respective home location of Twitter users [14, 4]. In [4] it was found that for 51% of Twitter users their home location on the city level could be identified within 161 kilometres (100 miles) of their true location. Based on a large training corpus of Twitter message, the authors trained models (term distri-butions) for a large number of cities in the USA. While this approach yields one location per user, we are concerned in our work with estimating one location per item (in our case an item is an image).

Finally, we also note a number of works that have con-sidered the questions of why people use Twitter and what they tweet about. Java et al. [12] developed a number of tweet categories: daily chatter (most common use of Twit-ter), shared information and hyperlinks, conversations and news. In [18] the majority of users (80%) were found to fo-cus on themselves in their tweets, while only a minority of users are driven by the sharing of information. Lastly, Zhao et al. [28] conducted interviews asking users about their mo-tivations for using Twitter; several major reasons surfaced including keeping in touch with friends and colleagues and collecting useful information for one X  X  work and spare time. Overall, these studies show that a lot of tweets are concerned with the user herself; we hypothesize that among these user-centred tweets, there are also useful ones for the derivation of the location of images that were taken by the user.
Our method is similar in spirit to the just described tag-based image location estimation approaches; differences are pointed out in detail in Sec. 3. We would like to stress that in this paper our main focus is on the question of whether a user X  X  traces on the social Web platform Twitter can of-fer valuable information for the image location estimation task. Such cross-system exploitations have recently begun to attract interest in a number of applications, e.g., [1, 3, 11]. In [1] for example, it has been investigated how users use tags on different social Web platforms (Flickr, Twitter and Delicious) in the context of personalized tag and re-source recommendation. It was found that a cross-platform approach can lead to a considerable improvement of the rec-ommendation quality.

In a preliminary study [9] we investigated the research question posed here on a very small data set in a coarse setup: we utilized the most recent tweets and most recent images (instead of aligning tweets and images according to publishing dates) in an oracle setting (instead of an auto-matic setup to combine both information sources) and found first evidence that this combination improves the image lo-cation estimation quality.
Previous works have shown that geographic location es-timation approaches exploiting textual meta-data provided by the image owner (such as image tags, title, etc.), outper-form approaches that rely mainly on visual features. Here, we investigate two additional sources of information: (i) the image owner X  X  traces on the microblogging platform Twit-ter, and, (ii) prior information about the world, in partic-ular population density and climate. We investigate two hypotheses with our experiments:  X 
In cases where little (or no) textual meta-data is available for an image, considering a user X  X  tweets as a source of additional textual information will improve the accuracy of the location estimation.  X 
Adding world knowledge as prior information will improve the estimation accuracy.

We first outline the baseline approach, which is grounded in the language modeling approach to information retrieval and then we turn to describing our proposed extensions.
Our baseline approach, which is a state-of-the-art approach we compare our Twitter-based extension against, draws in-spiration from a number of recently published works. Fol-lowing [21], we employ the language modeling approach to information retrieval [19, 15, 27, 26]. Instead of documents and queries though as in retrieval, we deal with world re-gions and image tags. A language model  X  R ,whichinthe retrieval setting is derived for each document, is derived for each region R of the world. Given a test image with tags T = { t 1 , ..., t n } and unknown latitude/longitude, the tags are considered as query terms and the region language models are ranked with respect to the probability P (  X  R which according to the Bayes theorem can be expressed as:
This is the standard query likelihood based language mod-eling setup which assumes term independence. Usually, the prior probability of a region P (  X  R ) is considered to be uni-form, that is, each region in the world is equally likely. The language models are multinomial probability distributions over the textual meta-data of all training images that were takeninregion R , that is, the textual information of all these images is concatenated and treated analogously to a single document.

Since a maximum likelihood estimate of P ( t i |  X  R )would result in a zero probability of any region that misses one or more of the tags in T , the estimate is usually smoothed with a background language model, generated over all documents in the training corpus. In accordance with [21], we found Dirichlet smoothing [26] to yield the most accurate results when evaluated on our data: Here,  X  is the smoothing parameter, c ( t i ,R ) is the count of tag t i in R and | R | is the length of the region document (derived by concatenating all tags of all training images in the region). The probability P ( t i |  X  C ) is the maximum like-lihood probability of tag t i occurring in the collection lan-guage model  X  C (derived by concatenating all region docu-ments).

Having identified the most likely region  X  R given test im-age is only the first step, as such regions often cover hun-dreds of kilometres and simply assigning the center of the region as estimated latitude/longitude to image is not suf-ficient. Thus, similar to [23], in a second step we only con-sider the training images occurring within R . A language model is generated for each of these training images, which are then ranked according to their probability of generating T . The latitude/longitude of the top ranked training image within R is assigned to test image .

In contrast to [21], we do not partition the world map into regions (or cells) of fixed size. Instead, we found cells of varying size to yield more accurate results: starting with a grid cell that spans the entire world map (if viewed as a graph, this cell is the root node), the training items are added to the cell one at a time. Once the number of items in a cell exceeds the set limit split , the cell is split into four equally sized cells, each covering a quarter of the original cell (four children nodes are added) and the training items are re-distributed to these cells. To avoid too many splits in areas where large amounts of training data are available, a cell may not be split any further if its latitude/longitude range reaches a lower limit lat lng . This process yields cells of small size in areas where the training data is dense, and cells of large size in areas where the training data is sparse (e.g. regions covering oceans).

If a test image contains no textual elements (or all terms were removed during the filtering steps described in Sec. 3.1.1), the terms in the user location are used instead, which has been proposed in [5]: if a user does not tag an up-loaded item with its location, it may have been taken at the user X  X  home location. In contrast to [5], we add the user lo-cation terms to , instead of relying on an external resource to convert the user location to geographic coordinates which is also often inaccurate due to the ambiguity of place names. Finally, if none of these steps yield a non-empty set T ,the test image is assigned the latitude/longitude coordinates of the most frequently occurring location in the training data.
In exploratory experiments, we found two strategies that filter terms from the test images X  tag sets T to lead to more robust and considerably more a ccurate estimations. Firstly, terms are removed from T that were utilized as tags by less than U users in the training corpus, in line with [22], and secondly, terms are removed that appear in many different geographic areas in the training data. Whether a term is likely to have a geographic scope can either be determined by matching the term against a geographical dictionary such as GeoNames as done in [21] or by considering how localized the term occurs in the training data. We follow the latter approach here. For example, while in our training data the term  X  X ydney X  occurs primarily in one particular region (the area containing the location of Sydney, Australia), the term  X  X owling X  appears in many different regions. This observa-tion leads to a simple yet effective filtering method: given a term t i whose spread is to be determined, a grid is placed over the world map (1 degree latitude/longitude range per cell) and the number of training items in the cell that con-tain t i are recorded. Neighbouring grid cells with a non-zero count are merged (to avoid penalizing geographic terms that cover a wide area) and the number of non-zero connected components are determined. This score is normalized by the maximum count. Thus, the smaller the score, the more localized t i occurs in the training data. While yielding com-parable results, our approach is considerably simpler than the  X  2 feature selection based geo-term filtering [23], which determines the geographic score for the tags in each cell sep-arately.
We consider the language model approach with user-based and geographic spread filtering as our baseline and attempt to improve upon it by relying on additional sources of infor-mation. When considering Equation 1, additional informa-tion can be added in this framework in three ways:  X 
The set of terms T : The bag-of-words that describe an image can be extended by not only including the tags that are assigned to image , but by also including terms from the user X  X  traces on the social Web, in particular the user X  X  Twitter stream.  X 
The prior probability P (  X  R ) : Instead of a uniform prior probability, we include knowledge about the world and, for instance, assign a higher prior probability to re-gions of high population density or regions of moderate climate.  X 
The region language model  X  R : The language model of a region R can be expanded by adding additional infor-mation, for example, information extracted from Wikipedia.
In the work presented here, we investigate the first two aspects, expanding the term set used for image location es-timation and adding informative priors. We leave the third aspect for future work. Discussed next are the usage of terms extracted from a user X  X  tweets and the usage of informative priors.
The hypothesis we investigate in this work is that traces a user leaves on Twitter can aid us in estimating the ge-ographic location of the user X  X  images on Flickr. Location estimation based on an image X  X  textual meta-data is based on the assumption that a user who uploads an image or video also spends some time on adding tags, possibly also a title and a description. Not every user though has the time or the patience to do this. In particular in instances where a user adds no or just very little extra information, we expect the user X  X  traces on Twitter to be valuable.

On Twitter, users post short messages (tweets) with up to 140 characters about anything they choose. They can be fol-lowed by other users and themselves follow users in order to receive their tweets. Tweets can be directed (at @user )and tweets can contain hashtags ( #sigir2012 or #portland ) 4 The microblogging service Twitter was chosen due to its popularity and wide-spread use today. Given the date D (day, month, year) a test image was taken at, we ex-tract the tweets by the user who posted the image to Flickr. We consider only those tweets by the user that were posted within d days of D . After the removal of URLs and user names ( @user ), we are left with a bag-of-words W = { w 1
We also note, that Twitter allows tweets to be geo-tagged directly, though this feature is rarely enabled by users and only available when using Twitter from certain devices. In [4] only 0.42% of tweets were found to be geo-tagged. The world regions are no longer only ranked according to their probability of generating the image tags (Equation 2), but also according to their probability of generating the twit-ter terms. In our implementation, we interpolate both scores for the final ranking of each world region. Formally: P (  X  R | T , W )  X  P (  X  R )  X  (4)  X  Both, P ( t i |  X  R )and P ( w i |  X  R ) are determined according to Equation 3. This interpolation approach naturally includes the original image-tag only approach when the parameter  X  is set to  X  =1 . 0. Conversely, at  X  =0 . 0, the image tags of an image are ignored an only the terms extracted from the user X  X  tweets are used to estimate P (  X  R | T , W ).
We chose this interpolation approach due to its simplic-ity. More elaborate combinations of image tags and tweet terms will be investigated in future work. Note that the term filtering steps (Sec. 3.1.1), if employed, are now not only performed on terms T but also on W . This means effectively, that only a small number of terms that originate from a user X  X  Twitter stream will be included in W .
Instead of a uniform prior, we investigate two informative priors, one based on population information and one based on climate information.

In the case of the population based prior, which we base on the population density of a region, we hypothesize that images are more likely to be taken in areas of high popula-tion density than in areas of low population density. This intuitively makes sense, we would expect that people take more images in and around New York City than in the Great Victoria Desert of Australia 5 , simply because a greater num-ber of people live or visit the former than the latter. Given a set of places (towns, cities)  X  = { p 1 ,p 2 , .., p m } geographic location and number of inhabitants (population pop ), for each region R , we sum up the population of all places that are situated within R as well as of those places that are situated within a distance of 100km (according to the Haversine formula hs ) of the region X  X  center R c .To avoid undue influence of major cities (with millions of in-habitants), we use the square root of the population. This yields the following population prior ( Z is the normalization constant):
As a second prior, we exploit climate data. Our assump-tion is that it is more likely that people live in or travel to regions with a moderate climate than regions of extreme weather conditions. We derived the climate prior by collect-ing a number of geo-tagged images and recording the average temperature in the region where the image was taken at the
On February 11, 2012, a search on http://flickr.com with the query  X  X ew York City X  returned 3 , 672 , 535 results while the query  X  X reat Victoria Desert X  returned 115 im-ages. month the image was taken. We then fitted a Weibull distri-bution[24] 6 to the data; this resulted in a prior which, given the climate (av. temperature) in a region R at month m returns the prior probability of an image being taken in R .
In Sec. 4.1 we first describe the training data and the setting of the parameters used to derive the language models of the world regions. Then, in Sec. 4.2 we introduce our methodology for deriving the test images and the Twitter messages belonging to the users who uploaded these images.
We rely on a publicly available Flickr data set for training: the MediaEval 2011 Placing Task data set [20]. The Medi-aEval Placing Task data set is a benchmark that tackles the same question we address in this work, namely the estima-tion of the geographic location of an uploaded Flickr item. It consists of approximately 3 . 2 million Flickr images and 10 , 000 Flickr videos. Meta-data is provided for all training images and videos, including their geo-location as well as the accuracy with which they were geo-tagged. There are 16 accuracy levels, ranging from 1 (world level) to 16 (street level). We utilize all training items with accuracy 11 (city level) or higher. We indexed 7 all available tags (available for the images and videos) and title terms (videos only). Each image/video is considered to be a document and the tags and titletermsareconsideredtobethedocument X  X content.

In preliminary experiments we found that an index which is neither stemmed nor has stopwords removed yields the best results. Table 1 provides the basic statistics of the index created from the training data.
Although the MediaEval benchmark also provides a test set (a set of Flickr items for which to estimate their lati-tude/longitude), we created our own for two reasons:  X 
It is very difficult to determine for arbitrary Flickr users whether they have a Twitter account unless they provide it in their Flickr user profile.  X 
To investigate our approach, we need to consider a user X  X  tweets for a substantial period of time as the average user does not take photos every day. Due to the limits imposed by the Twitter API, in our investigation we cannot for an arbitrary Twitter user retrieve all the user X  X  tweets at once, only the most recent ones are available.

Taking the above limitations into account we derived our test data by considering an existing long-term Twitter data set (TWD) and finding matching Flickr accounts. In previ-ous work [2] the TWD data set was created by monitoring
We chose this distribution as empirically it yielded the best fit to the data.
For indexing and retrieval we utilized the Lemur Toolkit, http://lemurproject.org/ . the tweets posted by 21 , 102 users over a period of eleven months (November 2010 to September 2011). Having access to such a long term profile of users suits our purposes very well. The question then remains for us, how to determine the Flickr accounts of these users (if they have one).
We approached this issue in two ways: (i) by performing a crawl of the social Web aggregator site FriendFeed and (ii) by manually assessing a subsets of the tweets posted by these users.

First, we conducted a crawl of FriendFeed 8 ,asocialWeb aggregator website, which allows users to create a unified feed of the entries on the social Web across a multitude of platforms including Twitter and Flickr. We started the ex-traction process with one highly connected FriendFeed user and crawled the profiles of all his subscribers and subscrip-tions. This process was conducted recursively, until no fur-ther profiles were discovered. In total, we found 444 , 226 profiles with at least one public entry in the feed. Of those users, 14 . 69% have listed in their profiles (among others) at least one Twitter and one Flickr account. We matched these discovered FriendFeed users with a Twitter and Flickr ac-count against the users in the TWD data set and found 131 FriendFeed profiles that listed one of the TWD Twitter ac-counts with at least 10 public tweets and 5 or more publicly accessible images in their Flickr stream.

As a second strategy, we consider the tweets of the TWD data set, accumulated within the first five month of monitor-ing and extracted all tweets containing the string X  X lickr.com X . Our intuition is, that Twitter users who tweet a link to Flickr, are likely to tweet about their own Flickr account. Since this is an overly strong assumption, one of the paper X  X  authors judged for each tweeted link whether it indeed links to the user X  X  Flickr account. This could either be inferred from the text (e.g., X  X heck out the pics of my recent trip to France X ) or from the similarity of the Twitter profile and the Flickr profile (same avatar image, the same or similar user name, etc.). Among the tweets we found 3 , 260 with a  X  X lickr.com X  string 9 . After manually investigating them, we found a total of 135 users in TWD that had tweeted their Flickr account and had posted at least 10 tweets and 5 images to Flickr.

The profiles found through these two approaches have lit-tle overlap. In total, our test data set consists of 252 users of whom we have recorded their Twitter as well as Flickr account. For these 252 users, we have collected a total of 1 , 892 , 168 tweets over the eleven month period. From the users X  Flickr accounts we collected a total of 153 , 773 images, after filtering out batch uploads 10 . Not all images were taken within the eleven month time frame of our TWD data set and not all images contain latitude/longitude values. Ta-ble 2 shows the split of the Flickr image data: there are 7 , 477 images which were taken within the time frame and have a latitude/longitude of sufficient accuracy. Since for our evaluation we can only rely as ground truth on images for which we have a geo-location, we used these 7477 images as our test set of images.
FriendFeed, http://www.friendfeed.com/
Note, we did not expand shortened URLs such as bit.ly .
We consider a set of images by the same user as a batch, if the images are identical in terms of assigned tags, the date (day/month/year) they were taken, the hour they were taken and the latitude and longitude.
The following subsections describe the parameter settings and runs we investigate. We tuned the parameters for our experiments in a grid-search manner on the 5 , 347 test items that were provided for the MediaEval 2011 benchmark. There is no overlap to our test set. We found the following param-eter settings to yield the best results with respect to the median distance error metric: indexing without stopword removal and without stemming, Dirichlet smoothing with  X  = 10000, U = 2 (filtering terms used by less than two users in the training data),  X  geo =0 . 1 (filtering terms with a geo-spread score above 0.1), split = 5000 and lat lng =0 . 01. Apart from the geo-filtering, these settings were fixed in all experiments reported in the result section. For the sake of showing the influence of geographic scope filtering, we present results for both types: with geo-filtering and with-out geo-filtering.

In this setup, there are a total of 1786 non-empty world regions. The maximum extent in terms of latitude and lon-gitude are 22 . 5and45 . 0 degrees respectively, in areas of the world map where the training data is extremely sparse. The most frequently occurring location in the training data (2834 items) was found to be at latitude/longitude 40 . 7/  X  73 . 9 (New York City, USA).
 Baselines. We report the results for two runs: BaseLine geo and BaseLine . The first is our primary baseline (geographic spread filtering is employed), while in the latter case, the terms in T are not geo-filtered. In both cases, the mixture parameter is  X  = 1 (Equation 4), i.e. only the image tags ( T ) are utilized to estimate the images X  location. proach (Sec 3.2.1), we extract all tweets from a given user X  X  Twitter stream that were posted  X  d days within the day the test image was taken on. For d =0,weonlycon-sider tweets taken at the same day as the image X  X  creation date and we label that run SameDay .Wealsotested d = { port the results for d = { 2 , 10 , 20 , 50 } (labelled  X  for d = 2 and so on). Recall, that for instance d =2means that tweets of a total of five days are considered: the two days before the image was taken, the image creation date day itself and the two following days.

The extracted tweets are pre-processed: re-tweets are re-moved (we consider them as useful for inferring something about a user X  X  interests but not about a user X  X  travels or ac-tions), URLs and @names are stripped. Apart from these steps, no further processing is performed. In particular, to align the Twitter-based W with our training data index, we performed neither stemming nor did we remove stopwords. If a user posts no tweets within the d days before/after the image X  X  creation date, W will be empty. we provide the average change in error distance in kilometres  X  performance).

Two types of runs are investigated, those with mixture pa-rameter  X  = 0 (only information from the tweets is utilized to estimate the image X  X  location) and those with 0 &lt; X &lt; 1. For the bulk of the interpolation experiments we set  X  =0 . 8. Region Priors. For the population based region prior, la-belled Population , we utilize population data available from GeoNames 11 . It contains an overview of the latitude, longi-tude and population numbers for a total of 113 , 816 towns and cities across the world (places with more than 1 , 000 in-habitants). For the climate based region prior (labelled Cli-mate ), we collected 100 , 000 geo-tagged images from Flickr (no overlap with our training/test data) and determined the average temperature in the region on the month the image was taken by relying on global historical climate data avail-able from the National Climatic Data Center 12 .Itprovides data from 7278 weather stations around the world. The ma-jority of those images were taken at temperatures between
The data is available at http://download.geonames.org/ export/dump/cities1000.zip , accessed 09/2011.
The data is available at ftp://ftp.ncdc.noaa.gov/pub/ data/ghcn/v3/ , accessed 09/2011. 10  X  and 28  X  Celsius. The lowest and highest temperature found were  X  38  X  and 37  X  Celsius respectively. Since the Weibull distribution is only defined for positive values, we shifted the temperatures by +50 which resulted in a maxi-mum likelihood fit of the Weibull distribution with parame-ters  X  =68and k =9 . 578.
The accuracy of estimating the geographic location of im-ages is commonly evaluated by reporting the percentage of test items whose estimated location is within a distance of x kilometres (km) according to the Haversine formula from the ground truth geographic location of the image. As in [21, 23], we report the accuracy for different ranges of x : { 1 , 10 , 50 , 100 , 1000 } km. We also report the median error distance (ME) in kilometres, that is, the error distance that no more than half of the test items exceed.

Additionally, we introduce two more measurements: to of-fer a comparison to the primary baseline BaseLine geo which we attempt to improve upon, we report the number of test images for which the adapted approach performed better (i.e. the error distance decreas ed), worse (the error distance increased) or exactly the same as the baseline. We also de-termine the average change in error distance in kilometres ( X  km ) for the test items that perform better or worse than BaseLine geo . A positive change indicates that the error dis-tance increases on average by  X  km kilometres, while a neg-ative change indicates that the error distance decreases on average by  X  km kilometres.
We first discuss the main results and then turn to inves-tigation particular parameters and particular subsets of the test images.

The main results of our experiments are reported in Ta-ble 3. For each run, the interpolation parameter is given and it is indicated whether geographic spread based filter-ing was employed. Shown in gray are improvements over BaseLine geo for the distance cut-off evaluation measures and the median error.

To give an example of how to interpret the numbers, we compare the two baselines now in detail: both, BaseLine and BaseLine geo neither include informative priors nor informa-tion derived from tweets (thus,  X  =1). Whencomparing the results across the various distance cut-offs, the influence of the geo-spread filtering on the accuracy becomes visible. While at the 1km cut-off there is little difference between the two runs, at the 50km cut-off already, BaseLine geo outper-forms BaseLine considerably with 48.6% accuracy compared to 34.9% of BaseLine . The results are similar for the me-dian error distance in kilometres: while for BaseLine geo median error is 61km, the median error increases to 2513km for BaseLine . However, not all test images are estimated with a greater accuracy when geo-filtering is employed. In fact, for 2521 test images BaseLine yields a more accurate estimate than BaseLine geo . Conversely, for 3017 test im-ages, BaseLine geo yields better estimation than BaseLine . These numbers do not explain the big difference observed in median error though; for this reason, we also report the average change in error distance  X  km . For the 2521 test im-ages, BaseLine outperforms BaseLine geo , the error decreases on average by 1715km, whereas for the 3017 test images where BaseLine performs worse than BaseLine geo , the error increases by 4941km on average.
 Informative Priors. Next, let us consider the impact of the informative priors in Table 3. Since these priors are de-termined over regions (which may span hundreds of kilome-tres), we do not expect an impact in accuracy in the 1-100km error distance cut-offs. If we however consider the accuracy within 1000km, the population based prior improves consid-erably over the baseline: while BaseLine geo achieves 61.4% accuracy, adding a population based prior yields 70.4% ac-curacy. For the 1015 test images that yield a decreased error with this prior, the error distance decreases on average by 4800km, while for the 252 test images that yield a larger error in this setup, the error distances increases on average by only 248km. The climate prior on the other hand has very little effect overall. One reason could be, that monthly average temperatures do not not provide a signal that is fine-grained enough.
 main research question of this paper: can the accuracy of estimating the geographic location of images be improved when taking the user X  X  utterances on Twitter in the same time period into account? We first discuss a set of experi-ments where the information provided in the image tags was ignored and only the terms extracted from the user X  X  Twit-ter stream is exploited, i.e.,  X  = 0. We report the results for d = 2, as this setting resulted in the highest accuracy in our experiments. We present the results both for runs with and without geo-filtering employed. When geo-filtering is not applied to W , the accuracy of the estimation is extremely poor with a median error of 5718km. When geo-filtering is employed, the results improve, though the median error is still high at 1974km compared to BaseLine geo . These results can be explained by the fact that users do not exclusively tweet about their personal experiences and actions but may also comment on news. We note, that again, there are test images which benefit from relying on Twitter information in-stead of image tags: 2360 test images have a lower error dis-tance when using Twitter terms compared to BaseLine geo .
While relying on Twitter alone to estimate an image X  X  location overall does not yield an improved accuracy, the information contained in a user X  X  Twitter stream is very helpful when combined with the textual meta-data obtained from the image. Consider the results that interpolate both sources with  X  =0 . 8. Across a range of time periods, the accuracy in all distance cut-offs increases and the median er-ror decreases with respect to BaseLine geo . Overall, the best setting is to consider tweets that were posted up to two days before and after the time the image was taken at: at the 1km cut-off, the accuracy improves from 7.2% to 9%, at 50km the accuracy improves from 48.6% to 54.7% and at the 100km cut-off the accuracy increases again from 52.7% to 59.9%. The median error on the other hand decreases sharply from 61km to 20.1km. Including tweets from a wider time interval (more than two days before and after the image was taken), decreases the accuracy again, though the results are still outperforming BaseLine geo . When considering the split of the test images into better/worse/same as BaseLine geo ,we notice that the inclusion of a wider set of tweets increases the number of test images that either benefit or are harmed by the inclusion of the Twitter data. This is to be expected, since not all images had tweets that were posted within d days of the time the image was taken.
 sider a combination of the well performing population den-sity based prior and the best performing Twitter setup ( d = 2,  X  =0 . 8). The result of this combination is shown in the last row in Table 3. Recall, that we can only expect the prior to influence the accura cy at the 1000km cut-off. The results show that indeed at the 1000km cut-off using the in-formative prior increases the accuracy, from 71.2% (run  X  Days) to 76%.

In Figure 1 we present an overview of the total number of unique terms used to estimate the locations of the 7477 test images. In case of BaseLine , for instance, all 5600 unique terms found as tags within the test images are utilized, whereas in the case of BaseLine geo , 466 unique t erms remain after employing geo-filtering. Shown is also the development of including Twitter terms from various days: the vast ma-jority of terms are considered to be non-geographic and thus they do not play a role. The number of geographic terms for instance for  X  2 Days is 1983, compared with 41 , 101 unique terms that are not geographic in scope (this high number is the result of neither employing stemming nor stopwording). Figure 1: Number of unique terms appearing in the tags of the 7477 test images.
In the results just described, we had fixed  X  =0 . 8for the interpolation experiments. We chose this value as it gave robust results across a range of settings. Now, we only consider the best performing setup (  X  2Days ) and plot the results when  X  is varied from 0 (no Twitter information is used) to 1 (no image information is used) in steps of 0 . 1. In Figure 2 we show the development of the accuracy for 1km and 50km. Please note that the two y-axes are on different scales: on the left (right), the results for the 1km (50km) distance cut-off are shown. The horizontal lines indicate the accuracies of BaseLine geo (  X  = 1) for both cut-offs. Figure 2: Interpolation parameter  X  varied from [0 , 1] in steps of 0 . 1 . Results are shown for  X  2Days with  X  =0 . 8 and geo-filtering employed. Note, the y-axes are on different scales.

The increase in accuracy is similar for both evaluation measures, at  X &gt; 0 . 3 (1km cut-off) and at  X &gt; 0 . 4 (50km cut-off), the interpolation approach outperforms the base-line. For this particular setup,  X  =0 . 9 yields the most accurate results with 55% of the test images being placed within 50km of their true location (compared to 49% in BaseLine geo ).
Finally, we turn to the question of what images do (not) benefit from adding information from the user X  X  Twitter stream. We consider two dimensions: (i) the number of tags Figure 3: Test set split according to the number of tags T after employing geo-filtering. Compared are BaseLine geo (  X  =1 ),  X  2Days with  X  =0 and  X  2Days with  X  =0 . 8 . In brackets, the size of each partition is shown. in T after applying geographic scope filtering, and, (ii) the distance of the image from the user X  X  home location. Number of Tags. To investigate the impact of the number of tags on the estimation accuracy, we plotted the median error in kilometres for different settings in Figure 3 for the three cases of a test image having 0, 1 or 2 tags in T .Please note, that the plot is on a logarithmic scale (y-axis) and that we consider the size of T after having employed geographic scope filtering.

Letusfirstfocuson BaseLine geo . As can be expected, if no tags are present, the median error distance is highest (with 4142km), as either the most frequent location in the training data is assigned to the test image or, if available, the user X  X  home location is added to T . Since the given home location may be geographically ambiguous (.e.g., X  X erth X  may refer to a city in Australia or the UK), underspecified (e.g., X  X SA X ) or plainly inaccurate (e.g., X  X ars X ), there is often little addi-tional value in it. If one tag is available, the median error distance decreases to 131km, at | T | = 2, the median error has fallen to 11km. The interpolation approach  X  2Days with  X  =0 . 8 improves over BaseLine geo if T contains ei-ther zero or one tag only. At zero tags, the median error distance decreases by 40%, for the test images with one tag, the median error decreases by 57%.

For the cases where | T | X  3, adding information from a user X  X  Twitter stream does not yield any more improvement in accuracy. This confirms our original hypothesis: extract-ing terms from a user X  X  tweets is valuable for images which contain less than three tags (after geographic filtering). user X  X  home location can be estimated based on the user X  X  tweets. In our experiments we found that even if tweets from a large number of days (  X  50) around the test images are used to extract terms for W , the results still improve over BaseLine geo . One potential explanation is that this Twitter based information enables us to mostly estimate those im-ages, that are close to a user X  X  home location with greater ac-curacy. To evaluate this hypothesis we conducted the follow-ing analysis. We manually transcribed/disambiguated the home location that the users who contributed the test images gave on their Flickr profile and description fields and con-verted them into latitude/longitude. For 4515 of the test im-ages, we could determine the corresponding user X  X  home lo-Figure 4: Scatter plot with test data split accord-ing to the distance, the images were taken at with respect to the corresponding user X  X  home location. Each marker stands for one image. cation with city level accuracy. We then removed all images where BaseLine geo and the run  X  2Days (  X  =0 . 8) yield the same error distance. The remaining 1330 images were par-titioned according to how far away from the user X  X  home lo-cation they were taken: within { 1 , 10 , 100 , 1000 ,&gt; 1000 of the user X  X  home location.

In Figure 4 we show a scatter plot for these 1330 images: the error in kilometres at BaseLine geo vs. the error at  X  Days (  X  =0 . 8). The images belonging to each partition are marked with different markers/colors. Many images were taken within 100km of the respective users X  home location. While for these types of images, adding information from a user X  X  Twitter stream somet imes improves and sometimes decreases the error, a clearer pictures emerges for images that were taken a greater distance from the user X  X  home location: the the vast majority of images improve when uti-lizing information extracted from Twitter.
In this paper, we have presented an approach to image lo-cation estimation that exploits a user X  X  traces on the social Web across platforms. We hypothesized that information extracted from a person X  X  Twitter stream can be utilized to improve the accuracy of the image location estimation. Our investigation was motivated by the fact that people of-ten tweet about themselves, and it is likely that they post messages which refer to their activities or travels. Further-more, we investigated the usage of informative priors, based on population data and on climate data. We developed an extension to an existing state-of-the-art tag-based approach to location estimation [21] which is based on the language modeling framework for information retrieval. Our exten-sion makes it possible to exploit the information extracted from the user X  X  tweets in a natural way. In this work, we presented a number of findings:  X 
Exploiting a person X  X  Twitter stream when estimating the location of an image decreases the median error distance by up to 67% in comparison to a state-of-the-art approach.
The best results are obtained when tweets within two days before and after the image was taken are exploited.  X 
Images, that were assigned less than two tags after geo-graphic scope filtering (Sec. 3.1.1), benefit the most from terms extracted from Twitter. Specifically, we showed a 40% (57%) decrease in median error distance for images without tags (with a single tag).  X 
We also investigated the value of informative priors in the language modeling approach. The population density prior improves the accuracy of the location estimation. These results leave a lot of potential for future work. One possibility is to not only consider the traces a user leaves on Twitter, but also on other social Web platform such as Face-book or LinkedIn. Another area of future work is to classify users X  tweets as either being about personal experiences and activities or about local vs. global news: tweets discussing global news (e.g.  X  X apan announced meltdown yesterday; sit-uation grim. X  ) are often adding noise for our purposes, while tweets discussing local news (e.g.  X  X ere in Toronto the police made multiple arrests today X  ) are useful as they can serve as indicators of the user X  X  home location. Lastly, we also consider an investigation into the similarities/differences be-tween (estimated) travel patterns of different users and user groups an interesting avenue of further work.
