 Social media like Twitter, Facebook, Google +, LinkedIn faced increasing in the num-ber of users. Twitters X  users use hashtag # sign to interact with others and express their opinions. Growing usage of social media p ersuaded researchers and companies to dis-cover valuable knowledge from this huge am ount of data. There are many ap proaches that were designed for knowledge extraction. However, among all of them , data mining approaches are the most popular and accurate poli cy for trend detection problem. More-over, among data mining techniques, Association Rule Mining (ARM) algorithms can be used for extracting knowledge from the database. Although there were some at-tempts to work with ARM approaches for trend mining, there s hould be more research in this field.
 Association rule mining has many application in different areas [1][3][4] [5] and can extract interesting and even hidden relations between items and entities. In many appli-cations, we need to extract users X  trends. As a result, applying an ARM approach can help us to solve this problem. Moreover, each trend mining approach needs to a feasible text mining technique at first. Many researches applied different text mining approaches [2]; however, we need suitable text min ing approach that can be applied t o the big da-tabases, social networks contents for instance , s uch mechanism also should be able to deal with huge amount of useless data and also scans the database for few times. In addition, since it would be applied in h uge databases, it should be an automatic proce-dure, for avoiding any needs to prede fined parameters. Finally, accu racy is one of the main important factors in trend mining. Each ARM approach should extract the most popular trends accurately. To solve the me ntioned problems, in this paper, we applied a heuristic based ARM approach on a huge twitter database. Our algorithm scans the database only once, which make it feasible for big data mining. Moreover, its text mining policy can work with complex datasets. It can extract target content s from huge databases and elimi nates the rest of the useless data. It is an automatic approach and does not need any predefined knowledge about the problem domain. We tested this approach and the experimental results illustrat e the 61% similarities between our algorithm results and google trends. The rest of the paper is organized as follows: in section 2 we have a literature review on previous researches and in section 3 we introduce ARM. Section 4 has information about Imperialism Competitive Algorithm and we introduce our approach in section 5. Data collection process is in section 6 and we discussed th e experimental results in section 7. There are Discussion and Conclusion in section 8 and 9, respectively. Many social network mining approaches were p ropose d in recent years. M. N . Injadat et.al [ 6 ] provided a survey social media studies to detect all data m ining approach in this field . They explored papers from 2003 to 2015 and 1187 papers were found; then, in order to eliminate irrelevant or duplicated papers , they applied some filtering strate-gies . Finally, 66 articles were extracted that m ost of them are in social network envi-ronments . In order to reveal eligibility of each pa per, several questions were introduced, which based on the answers , score values should be computed. Based on the results, around 36% of whole papers were under averag e score and only 6%of those were use-ful. Moreover , based on this study among 66 selected articles, 29and 26 papers have used SVM and BN techniques, respectively. They designed a chart to compare all sub-jects in big data mining in details up to 2015. Based o n the results, in the given period , social n etwork s approximately had numerous usage particularly in 2012 and 2015 with around 13% of usage. In addition, Sentiment Analysis and Content Analysis in the so-cial network had the most frequency , with 9% and 11%, res pectively.
 Demitrios E. Pournarakis et. al [ 7 ] proposed a computational method based on one of the data mining techniques, Classification, that classify all the collected data from so-cial networks to extract subjects that considerably impress customers. Their method began with providing some specific keywords that are relevant to a company such as compan y X  X  name and product . In the next step, they clean ed gathered data from Twitter; for example, they eliminated noisy and duplicated data, and broke down a sentence into the words. Following that, Vector Space Model (VSM) has been selected to turn un-structured data into a vector for applying classification. At that point, they defined a binary function for sentiment classification . Moreover, they employed GA in order to realize the average of sentiment in a particular subject . After all, it can be revealed that in each class , sentiments have been classified. They employed some techniques like t ext analyzing, modeling, sentiment classification to illustrate th at for example a user in Twitter may find it useless to have some options like Uber X  X  service s or support s . Carson Kai -Sang Leung and Fan Jiang X  X  [ 8 ] aimed to analyz e social networks, like Facebook and Twitter to discover the relationships between their us ers. They named their algorithm BigFoP, which was based on Map Reduce algorithm. It first indicates relationships between friends o n Facebook, such as A X  X , which means user A follows user B. After discovering these relationships, the first step of BigFoP i s generating a list that illustrates followers and followees. When the  X  Map  X  phase1 is finished,  X  Re-duce  X  phase1 will be started. A ll the followers who belong s to a followee would be grouped to reduce the dataset size. At that point , the minimum n umber of followers can indicate which followee is more popular . Then, MapReduce2 start s to find the  X  follow-ing  X  patterns between the followers of each followee . Hence, after applying these two followee . Therefore, interesting following patterns can be extracted .
 A. Singh [ 9 ] another two data mining techniques , clustering and association rule min-ing. They employed K -Means and Apriori to mine student X  X  interes ts to discover the most popular one. Demanded data was collected from questionnaire s, which included the amount of usage of student X  X  social media s as well as their interests. Clustered data should be analyze d with the help of association rule mi ning to hav e final result s . I n [ 10 ] three large pizza stores were selected as a case study to demonstrate how text mining in social networks can affect either competition between companies or their consumers. They gathered social network X  X  dat a to put them into several structures , like SPSS Clem entine and Nvivo 9 for analysis . Results indicate that in all of these three stores , consumers are like to use Facebook more that Twitter. Parameters that were selected for analysis were ordering and del ivering, pizza quality, f eedback on custom-ers X  purchase decision etc. I n this paper, the authors also consider ed the number of fans, pictures, and videos to have a deeper discovery of their case study. Another research that applied data mining techniques w as done in [ 11 ] . Among all kinds of social net-works , Instagram attracts lots of attentions . C. Chinchilla and R. Ferreira [ 11 ] proposed an approach, named CRISP -DM (Cross Industry Standard Process for Data Mining ) that applies classification and association rule mining on Instagram to analyze custom-ers' behavior. They c ollected photos, information about comments and like s etc. from fashion industry Instagram  X  X  pages. Then, they employing K -Means a s a clustering al-gorithm and FP -Growth as an association rule mining approach to analyze the data . They also hired Rapidminer for their analysis. Their approach clustere d all data about fashion companies and then eliminated unusable clusters. At that point, they can realize the most popular companies. At the next st ep, it requires to discover frequent patterns to find out that how long this popularity takes long .
 Another research studied finding children X  X  talents in sports from gathered data of so-cial networks [ 12 ]. They explored the well known soccer X  X  names such a s Ronaldo or Messi, which users mentioned them in their own posts or comments. Then, they applied NLP (Natural Language Process). This methodology also counts the n umber of soccer X  X  names that were mentioned in all the social networks. However, the main dr awback of this approach is that it is not reasonable to consider some one talented only if he or she in his or her posts point ed to those players . K. Patroumpas and M.Loukadakis [13] studied timeframe and geographical character-istics of topics with high trends by Twitter stream monitoring. Their technique deter-mines topics X  locality with the help of dividing the target area in to some separate parts instead of using clustering appro aches to group the messages. In their point of view, location related to a specific interest ing topic searched by people may be increased gradually after a short period of time. In the other word, when an important subject occurred in a certain area, it is more possible that the other locations also contribute t o this issue after a while. In their approach , they also applied heuristic methods to have fast estimation ability.
 J.Kalyanam et.al [14] have proposed a machine learning approach in order to detect prescription abuse d drug s . In their opinion, discovering trends in Nonmedical use of prescription of medications/drugs (NMUPD) is an opening challenge . Therefore, they collected data rel ated to this issue from Twitter. This huge amount of data may consist of irrelevant or undesirable data , which is not efficient to use. Hence, by applying their suggested method, Biterm Topic Model (BTM) in three steps, and repeating this pro-cess, they clean ed the database from noisy or unwanted data.
 P.Breen et.al [15] of fered a method for examining the Twitter to find trends due to the prevention of spreading some dangerous disease like Human Immunodeficiency Virus (HIV). They claimed that by considering a Pre -Exposure Prophylaxis (PrEP) as an im-portant parameter , this go al could be achieved. In addition, they mentioned that PrEP is an expensive process, health care organs or individuals may do not have any knowledge about it or in such case s avoid it. In their method, by monitoring twitter database from U.S and then apply ing data mining technique s and machine learning processing (NLP) , sentiment and trends could be illustrated. Consequently, the other topics , which happened related to this subject and positive and negative sentiment also could be discovered. There are several a lgorithms that a re able to mine large data base s in order to find inter-est ing items. Hence, parameters like accuracy and functionality play an important role for researchers to choose the most feasible method s that produce results with high qual-ity. In this content, both supervised and unsupervised algorithms can be hired to extract patterns. The ma in difference between them is that at the first stage of supervised meth-ods , it is more crucial to learn and then predict. In co ntrast , unsupervised algorithms regardless of any predetermined knowledge can start their work. As a result , Associa-tion Rules Mining, unsupervised algorithm s , can be chosen for data mining approach es . The concept of ARM refers article of Agrawal et al . [ 1 6 ]. The vital role of Association R ule Mining (ARM) is to evoke hidden relationships among items and discover fre-quent patterns. Assume that there is a transactional data base T, which {t1, t2,..., tn} and {i1,i2,..., in} refer to each transaction and item , res pectivel y. The task of ARM is to analyze the database and find pairs of items X and Y , which happen together. There-fore, we can consider X  X  Y ( X  X  Y=  X  ) as a discovered rule , which means with high probability Y will occur after X. Uncovering these patterns could provide an environ-ment for solving the world X  X  problem s . Most of the ARM algorithms consist of two steps; first: they detect Frequent Itemset List and after that creat e frequent rule s. More-over, t here are two main concept s in ARM a lgorithms, named support and confidence. Support is the measure s the number of repetition of items. In the other word, minimum s upport declares at least how many of an item should be in the da tabase . In addition, confidence refers to accuracy of generated rule s . For instance, if confidence of a rule is equal to 80%, it indicates that in 80 percentages of times when antecedent (the left part of the rule) occurs, the consequent (the right part of the rule) will happen . Powerful people or countries are more willing to extend their domain. Meanwhile, con-cept s like Empire and Imperialist were emerged. Empire s always like to take the others  X  X wnership and exte nd their own power . Imperialist Competitive Algorithm (ICA), is one of the metaheuristic approach es that is based on the swarm intelligence theory , which is able to model socio -political behaviors [ 17 ] . ICA was proposed by Atashpaz -Gargari and Lucas [ 18 ] . ICA begins with some initial countries, in ICA countries are meant as well as chromosome in GA algorithm. Following that, as defined below cost function should be calculated for each country [18] : Cost=f (country)
C n = max { C i }  X  c n ( 1 ) Where c n is the imperialist n X  X  cost and its normalized cost is C n . At that point, the normalized power of each imperialist can be calculated as [ 18 ]: Then, with regard s to the power of each country , some of the most powerful countries will be chosen randomly as some imperialist s . T he rest of the countries should be con-sider ed as Colony, countries with lower power, and should be divided between these imperialist s [19] . P owerful i mperialists are more likely to take more colonies, depends on their power . There is a probability that the power of a colony become more than its relevant imperialist. Therefore, Revolution will be appeared, in this process the position of colony and imper ialist should be exchanged . Revolution in ICA act s similar to mu-tation process in GA algorithm. Since this replacement happened, it needs to calculate the cost again and continues the algorithm with new value s . Empires consist of imperialists and their colonies; as a result , formula ( 3 ) can determine the total cost of each empire [ 18 ] : TCn = Cost (imperialist) + mean {Cost (colonies of empire n)} ( 3 ) Eventually, empires start to compete with each other in order to catc h the other empires X  colonies. In the competition phase, empires with lower power are not able to keep their own colonies. It means that, powerful empires absorb the weak empires X  colonies and enhance their own power. However, weaker empire s will be collap sed gradually as a result of losing their colonies. This competition continue s until finally, one empire re-mained and the final empire and its imperialist would be the answer of algorithm. In last section s , ARM and ICA were introduced. N ow we want to represent our ap-proach , named ARMICATF (ARM ICA Trend Finder) . We applied ARMICA [20] to extract the most frequent trends and also the most important relations between trends. The ARMICA is based on the ICA. In this paper, w e used an improved version of ARMICA (ARMICATF). 5.1 ARMICA ARMICA select s the most powerful countries as imperialists. Since, ARMICA selects the strongest countries as imperialist s , it is not possible that colonies reach more power than relevant imperialist. Hence, there is n o need to have r evolution. In addition, ARMICA considers the number of existence of each item in the database as the power of that item. One of the main improvement of ICA in ARMICA is after each competi-tion between empires, the weakest colony of the weake st empire would be stored in a list instead of becoming colony of the most powerful empire. At that point, ARMICA extract the frequent itemsets and also set the minimum support automatically (Apriori required to set the minimum support and confidence manua lly). At the final stage, ARMICA generates the most frequent rules accurately. 5.2 ARMICATF ARMICATF is based on ARMICA, however it improved it. The main drawback of ARMICA was scanning the database several times. However, ARMICATF scans the database only once. This feature cold be helpful is huge datasets, like our database that consists of 80 million records. Another improvement of ARMICATF compared to the ARMICA is that the text mining algorithm of ARMICATF is much more complicated than ARMICA. Because it is working with big data and should analyze huge amount of text content .
 A. Text Mining In ARMICATF we assume that the trend of each tweet can be extracted for the hashtags that are exists in each twe et. Hence, we only consider the tweets that include hashtags. In the other word, t he input data of ARMICATF is the Twitter database. Next, it read each line of the twitter database and only considers the line that consist of # (hashtag). At that point, it only consider the word (s) aft er the # sign and remove rest of the words. It is worth to mention that to have an accurate approach, we considered some factors . For instance, there is not any difference between words with uppercase and lowercase letters, wh ich can resulting in consider different forms of a same word as one word ( In our approach  X  HOLI day  X  is equal to  X  holiday  X  ) . Finally, all the ex tracted hashtags would be stored in a list for future analysis.
 B. Trend Extracting In the next step, our approach apply the improved version of ARMICA to extract the most frequent trends and most frequent rules among them. First, the algorithm analyze the hashtag  X  X  list . In this step, it calculate the frequency of each hashtag, find the mini-mum support automatically, and extract the frequent list, which consists of the most frequent hashtags. ARMICATF assume that each hashtag is a country. The frequency of each hashtag is its power. At first, it select some of the most powerful hashtags f or as imperialists and divides the rest of them between these imperialists. At this point , the empires are ready t o compete with each other. The competition goes on until only one empire be left. All stolen hashtags from the weakest empire would save in t he reserve list and if an empire have only one hashtag, the last hashtag and its imperialist would became colonies of the most powerful empire. The final step is comparing the hashtags in the reserved list with the hashtags of the last empire. If there is a hashtag that has more power compared to the power of the hashtags of the last empire, ARMICATF exchange them. Then, based on the average frequency of hashtags of the frequent list, ARMICATF determines the minimum support value and then eliminate the hash tags with the less frequency value than minimum support ( any combination with hashtags that have frequency of less than minimum support can produce itemsets with less support value ) .
 The final step would be the frequent rules generation. In this step, ARMICATF based on the minimum support value and the hashtags of frequent list extract the most fre-quent rules from the database. We will discuss the result of or experiment in the next se ctions. There are several social media sources such as Facebook, Google +, Pinterest etc. How-ever, in this paper Twitter was chosen to work on. People from all over the world can have easy and instant access to Twitter. We used a twitter d atabase with 80 millions record June 1 , 2009 to June 30, 2009 and D ecember 1 , 2009 to December 31 , 2009 from 20 millions users [ 21 ]. Each record consists of the name of the user, time that tweet was sent and the content of the tweet. We tested our approach by implementing ARMICATF with java 1.8 Netbeans IDE on a computer with characteristics of Intel (R) Core (TM) i7 6500U CPU at 2.59 GHz and 8 GB RAM. The experimental results indicated that ARMICATF was successful to extract the most frequent trends in mentioned time frame. To evaluate the accuracy of our approach, we compared our results with the US Google topic trends. .
 ARM ICATF trends. At the right side , whenever these two trends are matched, we filled the related box with the word  X  X xtracted X  and whenever they are not matched we putted  X  --- X . As Table 1 illustrates, 61.11 % of the google trends existed in the ARMICATF extracted trends. This means that wit h the accuracy of 61.11, ARMICATF work just like Google trends. However, ARMICATF also is able to find even more trends. When the most iterative hashtags were extracted , by employing ARMICATF we can detect frequent rules, which are able to reveal useful in formation about the database . In Table 2 we also compared the frequent rules of June 2009 and December 2009. As it is shown below, 7 number of extracted pattern in two mentioned time frames. As table 2 shows that 3 of the frequent rules the same in both ti me frames however, they have lower confidence in December compared to the June. The reason may be the fact that the trends in twitter are based on the time frames and trends may lose their popularity after a while. 
Frequent Rules: 01/06/2009 -30/06/2009 Frequent Rules: 01/12/2009 -31/12/2009 Analyzing social network s is a complex task that require s accurate and feasible ap-proaches. In this paper, we applied one of the recent ARM approaches, ARMICA. ARMICA is based on a heuristic algorithm (ICA). To the best of our knowledge, it is the first attempt to apply ARMICA for social network mining . One of the main problem in ARMICA was the number of its database scans. Working with huge databases, like our 80 million records twi tter database, requires an approach with the least number of database scans. Hence, we suggested ARMICATF to overcome this obstacle and im-prove ARMICA. Exploring in this repository of data is a time consuming process and such approach like ARMICA was not s uitable for this purpose.
 In addition, text mining approach of ARMICA was designed for the small transactional databases. We modified the text mining section of ARMICA and make it feasible for social network mining. The main concept of approach was to onl y consider the tweets that include hashtags and these hashtags were counted as its trends . Then, ARMICATF extract s the most frequent items and generates frequent rules base on these items. The experimental results indicate that our approach can generate th e most frequent trends and in 61.11 percentage of time, our results are match with the google trends. At that point, we also analyze the extracted rules and for analysis purposes we also extracted the frequent rules of December 2009 to compare the both res ults (Frequent rules of December and June 2009). The comparison results show that there some rules that are in common between these two time periods. However, the confidence of these common rules in Jun 2009 are less than the December 2009. The reason of t his reduction is that trends are popular in a certain time period. After a while, their popularity will be de-creased . Moreover, as it can be seen in the results , it is more possible that some trends may be totally removed from popular trends list after a time passing . In this paper, we proposed a heuristic approach to evoke frequent tends from social networks like T witter. Each trend miner algorithm should be feasible to work with the huge databases and big data. We applied an association ru le mining algorithm to: first min e the social network; then, extract the most popular trends; and finally, extract the most popular rules among them. We compared our extracted trends with google trends and figured out that at 61.11 percent of time they are the same. We also compared the extracted frequent rules in two different time periods and only few of them were matched. The reason behind of this is that topic trends remain fresh and popular in a certain period of time. In future, we have plan to test o ther databases, like Facebook and even news databases. We also should improve the accuracy of ARMICATF to ex-tract more trends that are match with the google trends. We can also study certain topics in the certain time frame to see its popularity patterns d uring the time. 
