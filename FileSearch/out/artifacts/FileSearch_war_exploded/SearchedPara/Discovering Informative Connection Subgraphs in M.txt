 Discovering patterns in graphs has long been an area of interest. In most approaches to such pattern discovery either quantitative anomalies, frequency of substructure or maximum flow is used to measure the interestingness of a pattern. In this paper we introduce heuristics that guide a subgraph discovery algorithm away from banal paths towards more  X  X nformative X  ones. Given an RDF graph a user might pose a question of the form:  X  X hat are the most relevant ways in which entity X is related to entity Y? X  the response to which is a subgraph connecting X to Y. We use our heuristics to discover informative subgraphs within RDF graphs. Our heuristics are based on weighting mechanisms derived from edge semantics suggested by the RDF schema. We present an analysis of the quality of the subgraphs generated with respect to path ranking metrics. We then conclude presenting intuitions about which of our weighting schemes and heuristics produce higher quality subgraphs. Subgraph Discovery, Multi-Relational graphs, Semantic Pattern discovery in RDF Graphs  X  X  keep six honest serving-men (They taught me all I knew); Thei r names are What and Why and When And How and Where and Who. X  X  (Rudyard Kipling, from "The Elephant's Child" in Just So Stories 1902). The six questions in this quote by Rudyard Kipling are often tools we as humans use in an attempt to gain knowledge. How two entities are related is arguably the most crucial question among these. Discovering relevant sequences of relationships between two entities answers this question. We envision a system, which supports its users in discovering ways in search engines [1] of the future will need to support such a discovery process. Applications for such a search paradigm can be found in areas such as conflict of interest detection [2] and financial risk analysis [3]. To this end, we investigate techniques that provide users with a chain of relationships between entities in response to queries of the following kind:  X  X hat are the most relevant ways in which entity X is related to entity Y? X  The notion of relevance is critical to the definition of such a query. This becomes clear when one considers the small-world phenomenon [4, 5]. Given a knowledgebase and any two entities X and Y there could be a myriad of relatively short chains (i.e. six degrees) of relationships linking the two. Hence the need for some way of semantically constraining the discovery of possible ways in which X and Y could be related. Faloutsos et.al. [6] address this issue by developing an algorithm to extract relatively small connection subgraphs. They define the Connection Subgraph Problem as follows: Given: an edge-weighted undirected graph G , vertices s and t from G and an integer budget b Find: a connected subgraph H containing s and t and at most b other vertices that maximizes a  X  goodness  X  function g(H) . Faloutsos et.al. [6] applied their techniques to a graph where nodes represented famous people and the edges between these nodes represented strength of acquaintance between them. These connection strengths were derived from name co-occurrences in Web pages. All edges in their dataset therefore have exactly the same interpretation. Clearly this weighting scheme will not work for finding relevant subgraphs in RDF [7] graphs. Also, naively using a uniform weight on each edge is insufficient, as the semantics of each property type (edge) in RDF is different. Therefore a systematic way of weighting edges based on the semantics conveyed by the ontology represented using RDF schema [8] is needed. To adapt the approach in [6] to the more general case of an RDF graph:  X  We propose heuristics for edge weighting that depend  X  We evaluate the generated subgraphs using path ranking  X  We present empirical evidence that our weighting schemes  X  We present results that support the electricity based [6] Section 2 presents related work. In sections 3 and 4 we discuss our algorithms and heuristics respectively. This is followed by a discussion of the dataset for our experiments in Section 5. Section 6 presents our results and evaluations thereof. We conclude in Section 7 with a look at future research directions. Reasoning and knowledge discovery over graph data models has been studied in the Graph Mining community and more recently in the context of the Semantic Web. The remainder of this section highlights work which is most relevant to ours. The work most directly related to graph-based knowledge discovery and reasoning for the Semantic Web is that of Semantic Associations which were first introduced in [12]. Semantic Associations (termed  X  -operators) represent meaningful directed paths in an RDF meta-base. To the best of our knowledge this is the only existing work of this type. Anyanwu and Sheth define the  X  -path operator among others. Two entities X and Y are said to be  X  -path associated if there exists a sequence of properties (relationships) starting at X connecting intermediate entities and ending at Y . The nature of web data [4] often leads to an overwhelming number of associations between two entities. To combat this problem, [9, 10] propose to rank Semantic Associations. As an alternative approach, the method in [13] filters the search space before computing associations. They adapt the HITS algorithm [14] to compute importance of Semantic Web resources and then only consider nodes with importance greater than some threshold when computing Semantic Associations. Their preprocessing step based on importance thresholds is likely to discount those paths that contain even a single unimportant node. Our approach to this information overload problem is fundamentally different from these two. We try to find the  X  X est X  set of associations which contain a visually comprehendible number of resources. There has been a considerable amount of work done in the field of Graph Mining to detect patterns in graphs. Patterns discovered are characterized either by their anomalous nature or frequent occurrence, among other things. Efficient algorithms have been developed for many variations of the frequent subgraph discovery problem [15-17]. Community and group detection is another well-studied graph mining problem which attempts to discover communities and groups based on link analysis. The problem has been studied on both the web graph [18, 19] and other data sets [20]. These graph mining problems however focus on graphs with single node types and single edge types. For the Semantic Web and Link Mining we need algorithms which take into account the semantics of different node and edge types. Community detection and mining in multi-relational networks has recently received a lot of attention [21]. Novel Link Discovery was introduced in [11] and involves finding novel paths between entities, novel loops and significantly connected nodes. The methodology used in this work considers different node and edge types but differs from ours in that importance is determined purely from rarity. Also the paths examined are considerably shorter than the ones we examine. Our method for finding a connection subgraph between two RDF resources is based on the algorithms from [6]. The authors present an algorithm for extracting a so-called candidate graph from an input graph. They also propose an algorithm based on electrical circuits to extract a display graph from the candidate for a given budget b. For our purposes we refer to these as Candidate and Display  X  -graph. We assume that the properties (edges) in the RDF graph are bidirectional ( i.e. every relationship has a corresponding inverse relationship). This assumption is necessary because two resources may not be connected by a directed path but by a path which contains inverse relations. Ignoring this path could exclude vital information about the connections between the entities. The Candidate  X  -graph generation algorithm is used to prune the search space in very large graphs. It is based on a notion of distance between two nodes. The algorithm grows a set S around referred to as the roots of their respective sets) until a cer tain threshold is met: a maximum number of expanded nodes or maximum number of cut edges between S and T . At each iteration, a pending list is maintained for each of these sets whi ch consists of those nodes n  X  S and n  X  T and adjacent to some node k  X  S or k X   X  T . The sets S and T are expanded by choosing from the pending list the node with shortest distance to either s or t . Let u X  be the predecessor of u (the node adjacent to u on the shortest path to its root) . For an edge (u, v) the distance between u and v is given by: explained in Section 4 viz. Class and Property Specificity, Instance Participation Selectivity and Span. The length of a path is the sum of the length of its edges. The aim of our initial experiments is to determine the quality of the Candidate in terms of its ability to capture the best paths between the query endpoints. The Display  X  -graph generation algorithm extracts a small connection subgraph from the input graph. In [6] the authors present a rather elegant solution to this by modeling the graph as an electrical circuit where the edge weights represent the conductance values in the circuit. They use the fact that current flows from high voltage to low voltage to impose direction on an otherwise undirected graph. Using Ohm X  X  law and Kirchoff X  X  law, a system of linear equations is created with voltages at each node as a variable in these equations. Solving this system of equations gives voltages at each node. This step takes ( ) 3 motivates the need for the Candidate  X  -graph generation. The greedy Display  X  -graph generation algorithm attempts to find a graph of at most b nodes (set to a maximum of 100 in our experiments) which maximizes the amount of total current delivered from the start node to the end node. Starting with an empty subgraph, this algorithm iteratively adds paths until meeting the budget b . At each of the iterations, a dynamic programming algorithm is used to find the path which has the maximum ratio of delivered current to number of new nodes added to the subgraph. This choice may not be globally optimal, hence the greedy nature of the algorithm. In our experiments we test this model based on current flow used to compute these display  X  -graphs . RDFS vocabulary allows users to represent classes and relationships (properties) connecting them thereby indirectly imposing meaning on resources that are instances of these classes. We define three quantities (Class and Property Specificity, Instance Participation Selectivity, and Span) indirectly based on semantics and RDF statement types and frequencies. Our aim in doing this is to use semantics suggested by the schema to systematically convert an arbitrary un-weighted RDF graph into an edge-weighted graph appropriate as input to the algorithms described previously. property types ( P ). Further, we define an RDF data store instances corresponding to the schemas. A single entity could be an instance of multiple classes belonging to different schemas in  X  . We assume that such an entity instance is uniquely identified by one URI. In other words, no data integration operation is required.
 Intuitively more specific resources (entity instances and properties) participating in a path, convey more information than general ones. For instance, it is more informative if one knows that Michael Jordan was a basketball player as opposed to knowing that he is a person . Similarly, knowing that Rudy Giuliani was an employee of New York City is less informative than the fact that he was mayor of New York City. As a result of the rdfs:subClassOf and rdfs:subPropertyOf properties provided by RDF schema it is possible to impose a partial ordering of properties and classes in the schema resulting in a wellformed hierarchy of classes and properties. For a given property p, let ( ) p H be the length of the longest path in the hierarchy tree that contains p, and for a given class c, let be the length of the longest path in the hierarchy tree from the root to c. Properties and classes at the root of their respective hie rarchy trees in the schema are considered most general while those at t he leaves of these trees are considered most specific. Therefore a measure of specificity can be associated with each class or property commensurate with its position in its hierarchy. Let the depth of an arbitrary property in its property hierarchy be d(p and the depth of an arbitrary class in its class hierarchy be d(c Therefore, the specificity of property p i and class c  X  the class c j is assigned the weight ) ( instance of k distinct classes it is assigned the and properties to be in the output subgraph. To convert this node weight into an edge weight, the value of each resource weight is equally distributed among all edges incident on the resource r. This weighting scheme favors nodes with lower degree since the node specificity is divided equally among its incident edges, therefore edges incident on nodes with high degree will get a lower weight. Another guideline we use is that rarer facts are typically more informative that frequently occurring ones [22]. Consider the example shown in Fig.1. The example shows two relationships lives_in and council_member_of defined on the classes Person and City. The instances p 1 ,p 2... p m of the class Person are members council_member_of between each p 1 ,p 2... p m to c City c 1 and therefore are related to c 1 by the relationship lives_in. From the perspective of the node c 1 , following an edge labeled lives_in will lead to one node among k-m possible nodes. In contrast, following an edge labeled council_member_of will lead to one node among m nodes. Given that rarer paths are considered more informative, the amount of information gained by choosing to traverse the council_member_of relationship to a node in the set { p ,p 2... p m } is more than the gain achieved by choosing to traverse the lives_in relationship to a node in the set { p m+1 , p k } . This is akin to choosing the hop with maximum information gain. To define this heuristic formally, we introduce the notion of the type of an RDF statement. The type of an RDF statement s,p,o  X  is defined as the triple  X  =  X  C i ,p,C j  X  where typeOf(s)= C i and typeOf(o)= C j . Further, |  X  | is thus the number of statements of type  X  in a given RDF instance base. We therefore define Instance Participation Selectivity for each RDF statement as  X   X  = 1/|  X  |. Going back to Figure 1, let  X  = City  X  and  X   X  =  X  Person, council_member_of, City  X   X  . In [9] the authors define a ranking metric known as Refraction. Given a path of the form v 1 , e 1 , v 2 , e 2 ... e n-2 v where v i  X  Resources and e i  X  Properties  X  i 1 v other words, this path passes through an instance of classes that belong to more than one schema. The number of such occurrences measures the extent to which a given path conforms to a schema. We consider resources that are instances of class es belonging to different schemas as being indicative of informative paths between the given entities, since they tie different domains together. What makes such paths interesting is the fact that these paths represent a deviation from the expected paths suggested by the schemas. For example, in our scenario in Figure 4 an instance of the class Person may be classified as both an instance of class Actor in the Entertainment domain and an instance of class SpokesPerson in the Business domain. Such an instance serves to link different schemas. As a heuristic that favors the inclusion of such refracting paths in output subgraphs, we define a Span weight for an edge based on the class types of its two endpoints. Let us consider the example in Figure 2. For every node v in a given RDF graph we can define a set called SchemaCover, which is the set of schemas to which the classes (types) of v belong. Formally, The SchemaCover for each of the nodes in the set { u X , u, v v v 5 } is shown adjacent to the respective node in Figure 2. To favor paths that span as many schemas as possible the search algorithm favors nodes that are classified under as many  X  X ew X  schemas as possible at each step. By  X  X ew X  we mean schemas tha t have been least recently encountered along a particular path. Let SDiff(u,u X ) represent the number of new schemas seen as a result of traversing the edge (u,u X ) , where the value of SDiff(u,u X ) = |SchemaCover(u X )-SchemaCover(u)| . The idea behind SDiff is to ensure that the discovery algorithm chooses the edge with maximum schema variety to traverse next. Using the absolute SchemaCover difference for one hop only, could lead to the following situation: The hop from u to u X  (based on high SDiff(u, u X ) ) is chosen. Subsequently, v i is chosen such that it maximizes SDiff(u X ,v i ) . But u X  and v i are covered by exactly the same schemas (as in node u X  and v 5 in Figure 2). Therefore SDiff alone does not ensure that search will continue along paths that have nodes classified under more diverse schemas. To reduce the chance of this problem we define the Cumulative Schema Difference ( CSDiff ) measure to compute a factor  X  We then obtain the adjusted weight given by; The effect of the factor  X  is to bias edge weights in the following way. Successor nodes that are instances of classes belonging to schemas other than those of the current and previous node are more likely to be visited, quantified by the two SDiff terms of CSDiff . More specifically, in the case of the example in Figure 2, a partial ordering is induced by the adjusted weights w X (u, v the nodes as follows v 1 f v 4 f v 3 f v 2 f v 5 . The node v therefore visited next. However, the measure  X  is not sufficient to distinguish between nodes in all cases. Consider the example in Figure 3. Nodes v 1 and v 2 have the same value of should be more desirable than v 2 because it has a larger SchemaCover value. For such cases, we define a factor called SchemaCoverFactor  X  (u, v) :  X   X  Note how the values of  X  for the two pairs of nodes that are in consideration are different even though the  X  values are the same. We therefore use  X  as a tie breaker in such cases. As per the calculations shown in Figure 3 this factor treats the node v preferentially over node v 2 i.e. v 1 f v 2 thus resolving the sequence it is query dependent and therefore cannot be pre-computed. The value of fly during the candidate generation process. The values of all the produces using all the heuristics discussed above lie in the interval (0,1]. Although different weighting could be assigned to each heuristic we give them all equal weights in our experiments. The initial weight of an edge is given by the following formula: where p u v is the property connecting the resource node u and v , and  X  is the type of the statement v p u used to adjust the weights w(u, v i ) n i i  X   X   X  1 as follows:  X  * w(u, v i ) . This is done during the candidate generation phase when the path leading to a given edge is known. We used a synthetic dataset for our experiments since we needed control over characteristics of the data. This helps us ensure that our results are not unduly affected by unknown aspects i.e. connectivity, relative instance distribution etc. of the dataset. Collection of real world data follows an almost opportunistic approach since availability often dictates design. As a result ther e is room for skew in instance data population. This skew may not always reflect real-world distributions, as was observed in our experience with SWETO [23]. To circumvent this we built a utility [24] that takes as input a set of schemas and a properties file specifying relative distributions of instances of classes and properties that would be expected in the real world. For example, consider two classes in the Business ontology (Appendix Fig. A2.): Trustee and Employee. It would be reasonable to assume that if there are 5,000 instances of the class Employee then there are unlikely to be 1,000 instances of the class Trustee. Instances of the class Trustee are more likely to be approximately 10. These numbers are domain specific. Our method for assigning values to these relative distributions is empirical and a discussion of thi s issue is beyond the scope of this paper. The result of running this utility is an RDF graph that contains nodes and edges that are instances of classes and property types belonging to any or all of the classes in the given schemas. The graph for our experiments contains 30,000 nodes and 45,000 edges. Figure 4 Example snippet of a subgraph returned for the query  X  (Actor_5567, Captain_8262) on our synthetic dataset X  (Nodes in the above graph are color-coded according to the schemas their class belongs to. White nodes for Sports schem a classes, Light Grey for Business and Dark Grey for Entertainment) As a motivation for the domains used in our dataset consider the following example. A fraud investigator with the Securities and Exchange Commission (SEC) receives the following piece of information about a week after the stock prices for EntertainmentCompany_9982 plummet. Actor_5567 sold 70% of his shares of EntertainmentCompany_9982 one week after Capt_8262 sold all of his shares in the same company. Both transactions took place two weeks before the prices plummeted. The example subgraph shown in Fig.4, might help an investigator visualize the connections between the resources: Actor_5567 and Captain_8262 . We recognize the fact that the notion  X  X est X  subgraph is very subjective and dependent on the user X  X  perspective. It is however desirable to have an objective measure that could be used to quantify the quality of a generated subgraph. The issue of judging relevance of paths i.e. path ranking has been addressed in [9] and [10]. In [11] the authors use rarity of the path as a measure of its interestingness. To the best of our knowledge these are the only three efforts that measure path relevance. We therefore use the se path ranking mechanisms to evaluate the quality of both the Candidate  X  -graph and the Display  X  -graph . In our experiments the Candidate  X  -graphs generated contained 3000 1 nodes and the Display  X  -graphs were restricted to a maximum of 100 nodes making them easy to visualize. In our data set there are over 60 million paths of length 13 between the two endpoints used in Fig. 4. Paths of this length are unlikely to be of much interest to the user. To evaluate our subgraphs, we run an exhaustive k-hop limited Depth-First Search (DFS) on the input graph between the two entities. We use a depth limit of 9 hops for our experiments for feasibility of path enumeration for ranking. Note that both the Candidate and Display  X  -graph generated do contain arbitrary length paths, but we only consider paths of length at most 9 for fairness of comparison. We represent the paths returned by the k-hop DFS as are therefore 30 distinct FGPaths 9 sets, one for each query in our experiments. We rank the paths in each of the FGPaths using the ranking mechanisms proposed in [9] and [10] in addition to what we call Rarity Rank based on the method suggested in [11]. While Rarity Rank ranks paths based only on the rarity of the edges that constitute the path, SemRank [9] uses a combination of Rarity, Specificity and Refraction (measure of conformity to schema) to rank paths. The mechanism proposed in [10] is the most flexible since it allows one to incorporate context, trust in the statements that constitute the path, path length, specificity and rarity. given by the inverse of the number of paths that share the same type as path p . Each of the ranking mechanisms applied to the set FGPaths 9 results in a list of ranked paths. Let us assume that this leads to ranking from 1  X  M where M is the rank of the least relevant path. Let this set of ranked paths be represented as FGRankedPaths 9 . We therefore have three distinct scales ( FGRankedPaths 9 sets) against which the quality of both Candidate  X  -graph and the Display  X  -graph can be measured. In all of the graphs, a table shown below the x-axis represents the 16 possible combinations of the four heuristics we use viz. Class and Property Specificity (CS and PS), Instance Particip ation Selectivity (IPS) and The Span Heuristic (SPAN) . To measure Candidate  X  -graph we compare the best paths in the entire graph to those in the Candidate  X  -graph. Let CGPaths represent the set of paths in the Candidate maximum length 9. For each path p candidate  X  CGPaths the number of paths p  X  FGRankedPaths 9 such that rank(p) &gt; Candidate  X  -graph with respect to all paths in the set FGRankedPaths 9 . The score of a path is given by: The quality of the Candidate  X  -graph is therefore given by: This was the observed number of nodes in the Candidate graph for all the 30 queries used in our experiments. Further investigation revealed that this was an artifact of the connectivity of our dataset. 
Figure 5 Quality of the Candidate  X  -graph as percentage of Figure 5 shows that the Candidate  X  -graph containing k paths obtained using our edge weighting schemes achieves between 80 X 90% of the score that can be achieved by choosing the top-k ranked paths from the full graph (entire dataset of 30,000 nodes and 45,000 edges). The Candidate  X  -graphs in our results typically contain 30-40% of the paths in the entire graph between the endpoints yet are 80-90% as  X  X ood X  as the top paths in the entire graph between the two endpoints. Similar to Candidate  X  -graph quality, we compare the paths in the DGPaths represent the paths in the Display  X  -graph . The rank of a path in the Display  X  -graph is computed exactly the same way the rank of a path in the Candidate  X  -graph is computed, as is the score. The quality of a display  X  -graph is computed by comparing its cumulative score to the best possible display that could be obtained from the ranked set of paths in the full graph. We refer to this best possible display as Pseudo-Display . In our experiments we use a budget of 100 nodes for our Display  X  -graphs . Starting with an empty Pseudo-Display graph and the path with rank 1 in the set FGRankedPaths 9 we add paths to the Pseudo-Display until 100 nodes have been added. The cumulative score of the Pseudo-Display is then computed as the sum of the scores of the paths. The quality of a Display  X  -graph is therefore given by: Figure 6 shows that starting with the Candidate  X  80 X 90% quality the Display  X  -graphs computed capture a maximum of 84% of the score that can be obtained by taking the best paths in the full graph. Our results show the quality of Display  X  -graphs with respect to SemRank [9] to be surprisingly low  X  43%. Further investigation of the methods used revealed that the difference between the ranking scheme in [10] and that in [9] is that in the former instance node degrees affect the rank of a path (nodes of lower degree being favored) whereas in the latter rank of path is determined purely by properties in the path. Our heuristics favor lower degree nodes and hence the observed trend. A personal communication with the authors of [9] revealed that extending SemRank to include the effect of nodes is an intended follow up to this work. weighting heuristics turned off results in poor graph quali ty With the intention of validating the current flow model for subgraph relevance [6] we conducted the following experiment. We computed what we term as Successive Display  X  -graphs . To construct these displays we successively run the Display generation algorithm on the candidate  X  -graph . At each successive run we discount the paths used in previous displays. This results in the next best Display  X  -graph at every successive run. This process is repeated five times in our experiments to obtain five Display  X  -graphs. The current flow in each of these Display  X  -graphs is plotted relative to the current flow in the first Display  X  -graphs is plotted relative to the quality of the first Display  X  -graph in Figure 8. There is a large difference both in the current flow and the display quality between the first display and the next display. This confirms that there is a correspondence between current flow in the Display  X  -graphs and their quality. This in turn supports the electricity based model for RDF graph relevance. Note that the plots below are averages of the relative differences of successive displays over all ranking schemes. Figure 7 Current Flow in 5 Successive Display  X  -graphs Figure 8 Quality of 5 Successive Displays relative to the best We conducted another experiment on factual data extracted from public access government websites. For this particular experiment we picked two persons of interest at random. Figures 9 and 10 compare Display  X  -graphs generated for end points: 
Arnold Schwarzenegger and Bill Clinton . In both cases the budget is set to 12 nodes. Figure 10 contains a very interesting path that connects Arnold Schwarzenegger to Bill Clinton via Maria Shriver followed by Edward Kennedy .
 Edward Kennedy and Bill Clinton both spoke at consecutive Democratic National Conventions. This indicated a strong similarity in their political ideologies. A strong familial relationship between Edward Kennedy and Arnold Schwarzenegger via Maria Shriver is also seen in the output in Figure 10. In comparison to these paths the paths in Figure 9 are rather uninteresting. This provides empirical evidence that our weighting schemes are useful. We believe that further investigation of semantic methods for subgraph discovery is warranted. 
Our results suggest that using edge weights generated by our weighting scheme results in highly relevant Candidate  X  where relevance is judged using established path ranking metrics. Further evidence supporting this claim can be seen from quality of the Display  X  -graphs . The ranking metrics proposed by Aleman-Meza et.al. [10] in our experiments show that the quality of the Display  X  -graphs are best when using Class Specificity (CS), Instance Participation Selectivity (IPS) a nd Span together. Results for the Successive Displays serve to support the electricity flow based model for RDF subgraph relevance, besides validating our edge weighting schemes. Results presented in this paper seem very promising for application domains like Ontology based Scientific Discovery where the ability to visualize relevant relationships between metadata entities is crucial. As a follow up to this work we pl an to apply our techniques to develop tools for finding correlations between Glycosylation patterns and patterns of gene expression within a cell line in the Glycomics [25] domain. We further propose to develop algorithms to support queries involving k endpoints for RDF graphs. Another interesting direction involves formalizing the notion of Context and investigating Context-Aware Subgraph Discovery algorithms. We thank all SemDIS project members especially Boanerges Aleman-Meza for his insightful comments and revision suggestions. This project is funded by NSF-ITR-IDM Award#0325464 (SemDIS: Discovering Complex Relationships in the Semantic Web) and NSF-ITR-IDM Award#0219649 (Semantic Association Identification and Knowledge Discovery for National Security Applications). [1] Guha, R.V. and E.M. Rob McCool. Semantic search . in [2] http://lsdis.cs.uga.edu/projects/semdis/coi . [3] http://lsdis.cs.uga.edu/projects/semdis/HS-brief.pdf . [4] Albert, R. and A.-L. Barabasi, Statistical mechanics of [5] Milgram, S., The Small World Problem. Psychology [6] Faloutsos, C., K.S. McCurley, and A. Tomkins. Fast [7] Lassila, O. and R.R. Swick. Resource Description [8] RDFS, http://www.w3.org/TR/rdf-schema/ . [9] Anyanwu, K., A. Maduko, and A. Sheth. SemRank: [10] Aleman-Meza, B., et al., Ranking Complex Relationships [11] Lin, S.-d. and H. Chalupsky. Unsupervised Link Discovery [12] Anyanwu, K. and A. Sheth.  X  -Queries: Enabling Querying [13] Mukherjea, S. and B. Bamba. BioPatentMiner: An [14] Kleinberg, J.M., Authoritative Sources in a Hyperlinked [15] Yan, X. and J. Han. CloseGraph: Mining Closed Frequent [16] Huan, L., W. Wang, and J. Prins. SPIN: Mining Maximal [17] Kuramochi, M. and G. Karypis, GREW: A Scalable [18] Flake, G.W., et al., Self-organization of the web and [19] Gibson, D., J. Kleinberg, and P. Raghavan. Inferring Web [20] Adibi, J., et al. The KOJAK Group Finder: Connecting the [21] Cai, D., et al. Mining Hidden Community in Heterogeneous [22] Shannon, C.E., A Mathematical Theory of Communication. [23] Aleman-Meza, B., et al. SWETO: Large-Scale Semantic [24] Perry, M. (2005) TOntoGen: A Synthetic Data Set [25] Sheth, A., et al. Semantic Web technology in support of 
