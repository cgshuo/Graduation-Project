 1. Introduction
Chemical process industries have constantly been very much concerned about the different methods and techniques for redu-cing the inconsistency of products and to guarantee a safety production so as to avoid public damage and large economic losses. Towards this objective, early and accurate reactions to process irregularities play an essential role. This task is denoted as Abnormal Event Management (AEM) which is the main com-ponent of supervisory control. AEM is composed of three major steps: fi rst, appropriate detection of an abnormal process behavior (fault detection); second, diagnosing its causal origins or root causes (fault diagnosis); and fi nally, taking proper decisions in taking the process back to the normal operating regime (process recovery).

Different methods have been established to detect and diag-nose faults in complex chemical plants employing computer aided decision-making supporting tools. These techniques can be gen-erally categorized into model based approaches and process history based approaches. Process model based methods depend on a basic understanding of the process utilizing fi rst principle knowledge which includes qualitative methods and quantitative methods ( Dash and Venkatasubramanian, 2000 ). In qualitative methods such as fault trees and signed diagrams, the process model states the relationships between the inputs and outputs in terms of qualitative functions ( Venkatasubramanian et al., 2003b ). In quantitative methods however, which are also denoted as
Analytical Redundancy (AR), mathematical expressions are used to describe the process. The crucial task in these methods is creating residual signals which essentially give the difference between the real measured outputs and the predictions gained by mathematical model of the process ( Isermann, 2005 ;
Venkatasubramanian et al., 2003a ). In contrast to the model-based methods where a priori knowledge about the model of the process is assumed, in process history based methods only the availability of large amount of historical process data is assumed ( Venkatasubramanian et al., 2003c ).

Conversely, the rise of a range of new sensors and data collecting tools enabled measurement of hundreds of variables every few seconds of real operation of chemical processes. These instrumentation developments, which offer large volume of data-sets, have inspired the development of various process history based methods to design more reliable and cost-effective fault detection and diagnosis systems. These data based techniques are more appropriate for large-scale industrial processes where pre-cise and broad quantitative or qualitative cause-effect models may be hard to design from the fi rst principles. Amongst those data based approaches, Multivariate Statistical Process Monitoring (MSPM) approaches are the most prevalent for fault detection with numerous applications over the past years ( Joe Qin, 2003 ; MacGregor and Kourti, 1995 ). Here, we can denote Principal Component Analysis (PCA), Partial Least Square (PLS), Canonical
Variate Analysis (CVA), Fisher Discriminant Analysis (FDA) ( Chiang et al., 2000 , 2001 ; Russell et al., 2000 ), Dynamic Principal
Component Analysis ( Ku et al., 1995 ), Multiway Principal Compo-nent Analysis (MPCA) ( Nomikos and MacGregor, 1994 ), Indepen-dent Component Analysis (ICA) ( Lee et al., 2006 , 2004 ),
Correspondence Analysis (CA) ( Detroja et al., 2007 , 2006 ) and nonlinear kernel-based methods including Kernel Principal Com-ponent Analysis (KPCA) ( Cho et al., 2005 ; Choi et al., 2005 ), Kernel
Partial Least Squares (KPLS) ( Zhang et al., 2010 ), Kernel Indepen-dent Component Analysis (KICA) ( Lee et al., 2007 ) and Kernel Dissimilarity Analysis (KDA) ( Zhao et al., 2009 ).
 problem in which a functional mapping from the measurement space to a fault space is computed. In pattern recognition based techniques, the accessibility of a complete historical process data for normal operation and different abnormal conditions of the process are assumed. In these methods, diverse operating situa-tions comprising normal and abnormal ones are assumed to be patterns. Then, a particular classi fi er is employed to investigate the online measurement data and to convert it to an identi fi label for normal or abnormal condition. When the process model is not known, pattern recognition methods provide a convenient approach to solve fault diagnosis problem. Several algorithms based on the pattern recognition methods, which are realized and applied to various fault diagnosis applications, include the k -Nearest Neighborhood ( k NN) ( He and Wang, 2007 ), Fisher Discriminant Analysis (FDA) ( Chiang et al., 2004 ), and the Bayesian Networks (BNs) ( Verron et al., 2006 , 2010 ).

Arti fi cial Neural Networks (ANNs) had an enormous attention in past years because of some of their motivating features such as handling nonlinearity, noise tolerance and generalization capabil-ity ( Behbahani et al., 2009 ; Eslamloueyan, 2011 ; Namdari et al., 2013 ; Power and Bahri, 2004 ; Zhang, 2006 ; Zhang and Morris, 1994 ). ANNs have demonstrated to be magni fi cent classi they need large number of samples for training, which is not always obtainable in practice and sometimes result in high generalization error because in training process, they only attempt to exploit classi fi cation performance for the training data. To resolve this problem, a new machine learning method relying on statistical learning theory called SVM is proposed in pattern recognition fi eld to accomplish higher generalization ability spe-ci fi cally for dealing with problems with low samples and high input features ( Vapnik, 1999 ). It has been shown that SVM is more effective than previously described pattern classi fi ers and in recent years have been discovered to be highly effective in numerous practical applications ( Moguerza and Mu X oz, 2006 ).

The use of SVMs in solving process engineering problems is virtually new ( Mahadevan and Shah, 2009 ; Y X lamos et al., 2009 ).
In Chiang et al. (2004) the performance of FDA as a recognized classical linear method is compared with SVM for three faulty conditions of the Tennessee Eastman Process (TEP) which gener-ates overlapping data sets. In Kulkarni et al. (2005) , a SVM with knowledge incorporation is applied to diagnose the faults in the
TEP. In Mao et al. (2007) a Fuzzy Support Vector Machine (FSVM) classi fi er with parameter tuning, which employs feature selection using recursive feature elimination, is utilized for fault diagnosis of the TEP. In Y X lamos et al. (2007) a multi-label method for dealing with simultaneous faults based on SVM is applied to the TEP.
In Monroy et al. (2010) a semi-supervised approach consisting of different methods such as Independent Component Analysis (ICA),
Gaussian Mixture Models (GMM), Bayesian Information Criterion (BIC) and SVM for fault diagnosis of the chemical processes is offered and effectively applied to the entire set of the TEP faults.
In some applications, hybrid approaches comprising of statistical process monitoring techniques and SVM classi fi er are employed. In these methods the statistical techniques are in charge of the fault detection and feature extraction. The extracted feature is then employed by SVM to achieve fault diagnosis ( Guo et al., 2003 ; Jie and Shouson, 2010 ; Xu et al., 2013 ; Zhang, 2008 , 2009 ).
In spite of the acceptance and practicality of pattern recogni-tion based fault diagnosis in many engineering branches, however, one of their key disadvantages in process industry applications is related to their static prediction for the dynamic performance of the chemical processes. Normally, the output of an ordinary pattern recognition technique is essentially an integer value which merely signi fi es the existing process operational state (Normal,
Fault 1, Fault 2, ... ) without offering any dynamical information about the process changing form one state to another. Conse-quently, the quality and depth of the faults through the actual operating time is not provided via the typical application process of classi fi cation techniques in fault diagnosis problems. For exam-ple, in a two-class SVM, in decision stage, generally a discrete decision function is employed which merely assumes two values  X  1or 1 to identify if an input vector fi ts in a speci fi However, for incipient fault mainly, while fault progressively M
TP condenser liquid holdup (kmol) q F fraction of liquid in feed
T temperature ( 1 C) t simulation time (min) TP top product fl owrate (kmol min 1 ) V boilup fl ow (kmol min 1 )
W d -dimensional weight vector x i sample vector i x
BP liquid composition of light component for bottom y i class label i y TP vapor composition of light component for top product
X i online measurement i z
F feed composition  X  i SVM slack variable advances over time and there is a changeover from normal operation to abnormal operation, utilizing discrete decision func-tion does not provide any information about the growth and severity of the fault. Several process faults, such as reactor fouling and weakening of catalyst, develop gradually and can be consid-ered as incipient faults. In this work, to deal with this matter, a continuous decision function is employed. The anticipated continuous decision function is limited between 1 and  X  1. The output value between 1 and 1 can be considered as the fuzzy indication of the severity of the corresponding fault.
In addition, based on the two common classi fi cation methods for SVM, i.e., One Versus One (OVO) and One Versus All (OVA) the proposed approach is extended to deal with multiclass classi tion problems. The anticipated method is applied to achieve online incipient fault diagnosis of a continuous binary mixture distillation column. In this work, we compared the performance of the OVO-SVM against the OVA-SVM based on the both the continuous and discrete decision based methods. The fault detection and diagnosis performance measures employed include false alarm rate, detec-tion time and diagnosis time.

The remainder of the paper is organized as follows. Section 2 describes the two-class SVM, OVO-SVM and OVA-SVM for the discrete decision function and the proposed continuous decision function based methods. Description of the case study, i.e., the continuous binary mixture distillation column, and also details about the considered fault cases are presented in Section 3 .In Section 4 the training issues of the classi fi ers are discussed. Section 5 is dedicated to represent the graphical results of the application of the diagnosis systems on the case study. In Section 6 further discussions about the diagnosis performances of the applied methods are detailed. In addition, some comparison results based on the employed quantitative performance indices are provided. Finally, conclusions are given in the last section of the paper. 2. SVM
SVM is a fairly new machine learning tool which is effectively applied in many machine learning applications such as classi tion, regression, and outlier detection. SVM was originally designed for pattern classi fi cation tasks. Pattern classi techniques classify objects into one of the given categories called classes. Classical classi fi ers such as neural networks attempt to minimize error on the training data set employing the Empirical Risk Minimization (ERM) technique. On the other hand, the SVM is based on the Structural Risk Minimization (SRM) principle rooted in the statistical learning theory. SRM offers better generalization abilities via the minimization of the upper bound of the general-ization error ( Abe, 2005 ). 2.1. Two-class SVM
SVM in its basic form is a binary classi fi er which learns a linear hyperplane that separates a set of positive examples from a set of negative examples with maximum margin. The margin is de fi by the distance of the hyperplane to the nearest of the positive and negative examples as demonstrated in Fig. 1 . This maximum margin hyperplane is called optimal separating hyperplane because the philosophies based on the statistical learning approve that allowing for maximum margin in the training process results in better generalization ability. The nearest data points are employed to de fi ne the margin and are known as support vectors.
The number of support vectors grows with the complexity of the problem.

Suppose there is a known training sample set G  X  {( x i ,y i  X  1, ... , M }, where M is the number of samples and each sample x  X 
R d is a member of a class de fi ned by y i  X  {  X  1, 1}. In the case of a linearly separable data, it is possible to de fi ne the following hyperplane that separates the given data:
W T U x  X  b  X  0  X  1  X  where W is an d -dimensional vector and b is a scalar bias term.
The vector W and scalar b are used to describe the position of separating hyperplane. It can be shown that maximizing the margin is equivalent to minimizing W .

To obtain a hyperplane with larger margin and better general-ization ability a positive slack variable  X  i for each training sample is de fi ned. This permits some of the samples to be misclassi fi ed.
So the optimal hyperplane separating the data can be determined as a solution to the following constrained quadratic optimization problem:
Minimise 1 2 : W 2 :  X  C  X  M
Subject to y i  X  W U x i  X  b Z 1  X  i ; i  X  1 ; ... ; M  X  3  X  where C is the regularization parameter that determines the trade-off between the maximization of the margin and minimization of the classi fi cation error and is used to prevent the over phenomenon.

Vectors W and b are determined through solving the optimiza-tion problem in the training procedure. Then, for or a given input data, x i , the following discrete decision function is used to classify input data in either positive class or negative class:
D  X  x i  X  X  sign  X  W T U x i  X  b  X  nonlinear classi fi cation is obtained by utilizing kernel trick where kernel functions are used to map the data from the original input space to a high dimensional feature space. A linear hyperplane is then trained to differentiate the data in the feature space which is equivalent to a nonlinear classi fi cation in the input space. Poly-nomial, Radial Basis Function (RBF) and sigmoid are the most popular kernels used for SVM ( Sanchez and David, 2003 ). 2.2. Multiclass SVM classes of data. In real world problems, however, we encounter more than two classes, for example, in fault diagnosis where various types of faults may be encountered in a real diagnosis problem. Unfortunately, there is no unique way to use SVM for multiclass problems. Currently, two general approaches for adapt-ing SVM to multiclass strategies have been developed. One method constructs and combines several binary classi fi ers while the other considers all data in an optimization problem ( Hsu and
Lin, 2002 ). Two common methods, which are considered in this paper use the fi rst approach to tackle multiclass problems, are the
OVA and OVO methods. OVA construct m binary classi fi ers where m is the number of classes. Each binary classi fi er separates the training samples of one class from all other classes. That is why it is called one versus all. So in each binary SVM separator, the training samples of all classes are used. When classifying a new example, each binary classi fi er predicts a class and the one with the highest con fi dence is then selected (i.e., the "winner takes all'' strategy).
 classi fi ers where each binary classi fi er separates the training samples of one class from another. Therefore, in the training cycle of each binary SVM, the training samples belonging to only two of the classes are used. The majority voting strategy is then utilized in classi fi cation of one new example in which m ( m 1) / 2 binary
SVM classi fi ers will vote for each class, and the winner class will be the class having the maximum votes ( Kim et al., 2003 ). 2.3. Classi fi cation based on continuous decision functions through solving the optimization problem given by Eqs. (2 ) and ( 3 ), the following hyperbolic decision function in a two-class classi fi cation problem is proposed instead of the one presented by Eq. (4) :
D  X  x i  X  X  tanh  X  k  X  W T U x i  X  b  X  X  where the parameter k can be chosen so that the decision function values for the training samples belong to the class  X  1 be closer to  X  1 and for the class 1 be closer to 1. As the value of k grows, the sensitivity of the classi fi er to the changes in the process variables is decreased. For low values of k , small variations in the faulty variables can be spotted by the classi fi er; however, the system outputs will become more sensitive to the process noises.
The value of k should be evaluated using the operator pro and the sensitivity prerequisite in monitoring of the dynamic behavior of the particular fault. The proposed continuous discri-mination approach can also be employed in the feature space by using nonlinear kernel functions.

The advantages of the continuous decision function over the discrete decision function in online fault diagnosis applications can be explained in the following manner. Consider the optimal separating hyperplane with the discrete and continuous decision functions depicted in Fig. 2 . Suppose that the class labeled as 1 contains the normal operation samples and the class with the label  X  1 contains the faulty operation samples. The increase of the value of the decision function represented in Eq. (5) from 1 toward  X  1 can be interpreted as the severity of process departure from the normal operation to the faulty operation. Therefore, by using the continuous decision function, useful information about the devel-opment of the fault can be obtained. Whereas, discrete decision function does not characterize the gradual growth of the fault. As will be discussed later, we use this information to detect and diagnosis the incipient faults in their initial stages of manifestation; in comparison with discrete based classi fi cation where a fault cannot be sensed unless the process passes completely the normal operation state into a faulty state in the classi fi cation space.
For multi-fault diagnosis, we employ the binary SVM hinged on the hyperbolic decision function and the OVO or OVA multiclass algorithms. The schematic diagram of the OVA Support Vector
Machine (OVA-SVM) with the proposed continuous decision function is represented in Fig. 3 . The continuous decision function,
D ( x ), which separates class i with the positive label from all other classes with the negative label, is de fi ned as
D  X  x  X  X  tanh  X  k i  X  W i T U x  X  b i  X  X  X  6  X  where W i and b i (as de fi ned in Eq. (1) ) are the parameters of the i th separating hyperplane. The k i parameter is identical to the parameter k used in Eq. (5) . As shown in Fig. 3 , for each input vector x we have m continuous decision values corresponding to m classes of faults.
 Fig. 4 shows the schematic diagram of the OVO Support Vector
Machine (OVO-SVM) with the proposed continuous decision function. For each two-class classi fi er, W ij and b ij are the para-the positive label from the class j with the negative label:
F  X  x  X  X  W T ij : x  X  b ij  X  7  X 
In Eq. (7) we have F ij ( x )  X  F ji ( x ). The continuous decision function, D i ( x ), for the class i can be de fi ned by a minimization operation on F ij as
D  X  x  X  X  tanh k i  X  min The k i parameter can be chosen as in the OVA approach. Therefore, similar to the OVA approach, we have m continuous decision functions for the m corresponding classes. 3. Case study
In this work a continuous binary mixture distillation column has been considered as the case study. The plant is the  X  studied by Skogestad and Morari (1988) . It has 41 stages including reboiler and total condenser, and separates a binary mixture with relative volatility of 1.5 into products of 99% purity. In developing the model the following assumptions were used: binary mixture; constant pressure; constant relative volatility; equilibrium on all stages; total condenser; constant molar fl ows; no vapor holdup; linearized liquid dynamics; and the effect of vapor fl ow (" K 2"-effect) is included.

The model consists of four manipulating inputs and four control outputs. The model is open-loop unstable. Top and bottoms product fl ows are used to achieve the corresponding level controls. The re fl ux ( L ) and boilup ( V ) fl ows can be used to obtain composition control. This structure is known as the L  X  V con fi guration. The schematic diagram of the column with the L  X  V con fi guration at the normal operating condition is shown in Fig. 5 . Further details about the model and all the MATLAB simulation fi les are available over the internet. 3.1. Simulated faults
Five malfunctions owing to the fl uctuations in feed rate ( F ), feed composition ( z F ) and fraction of the liquid in feed ( q sidered in this study and are listed in Table 1 . These process faults only result in variations in the product quality and do not lead to failures or operational hazards that might bring about equipment damage and/or plant shutdown. In implementing each fault condi-tion listed in Table 1 , step changes are introduced in each faulty variable while other variables are maintained constant at their normal values. Forty three variables are measured from the process.
These variables include the top product fl owrate ( TP ), bottom holdup ( M BP ) and thirty nine tray temperatures. Gaussian noise was added to all measured variables. An observation sample vector at a particular time instant is given by: X  X f TP ; BP ; M TP ; M BP ; T  X  1  X  ; T  X  2  X  ; ... T  X  39  X g X  9  X  normal operation and fi ve faulty conditions. Each simulation is executed for 200 min after which all measurement variables are settled to their new steady state values. Fig. 6 shows the distilla-tion column variables: product fl owrates ( TP , BP ), liquid holdups ( M BP , M TP ), bottom tray temperature ( T (1)) and the top tray temperature ( T (39)) in normal and diversely de fi ned fault situa-tions. No multiple simultaneous occurrences of faults are assumed in this work and the fault diagnosis system will be trained and validated based on single faults. 4. Training SVM models used in this work for all the SVM training tasks. Libsvm employs a
Sequential Minimal Optimization (SMO)-type decomposition method for the training algorithm of SVM ( Platt, 1999 ). Also, linear kernel function is used. This means no mapping into a high-dimensional space is performed. It should be noted that no signi fi cant improvement was achieved using nonlinear kernels in our case study. Hence, in all training actions, the regularization parameter C is the only parameter to be properly selected. tion samples are scaled using the following expression before being fed to the classi fi cation algorithm in the training or testing phases:
X where X i and X i , p are, respectively, the real and pre-processed values for the i th online measurement, respectively, X i ; normal mean value of the i th measurement under a normal operating condition, and |  X  X | i,max is the maximum absolute value of the difference value X i X i ; normal ( Zhang, 2006 ). Data scaling is required to prevent variables in greater numeric ranges dominat-ing those in smaller numeric ranges during learning and testing calculations ( Hsu et al., 2003 ).

Proper sampling time should be selected in order to choose training data from the simulated plant. Sampling time should be selected according to the kind of chemical process to obtain a good dynamic sequence of the process variables and being able to detect and diagnose any malfunctions. Since the simulation time is fi xed at 200 min for all the column operational experiments, choosing a lower sampling time results in a larger training set size and vice versa. Here, we employed an experimental search to select the optimal training set size. Different sampling times corresponding to different data set sizes are selected and used to check the SVM classi fi cation performances. Six experiments cor-responding to six different training sets are arranged. The same sampling time is used in data gathering of all six sets of data. Here, the OVO-SVM algorithm based on the majority voting algorithm is employed as the classi fi er and its performance is checked using the 5-fold cross validation on the training data. In the v validation, the training set is divided into v subsets of equal sizes.
Sequentially, one subset is tested using the classi fi er trained on the remaining v 1 subsets. The C parameter is set to 1000 in these experiments.

The results of the experiments are depicted in Fig. 7 . Note that the performance response follows an asymptotic curve that is a function of the training set size and as expected the accuracy normally growth as the training set size increases. Larger training sets will provide higher performances but will require longer training times. This discloses the trade-off decision which occurs when choosing the optimal training set size. Finally, a training size of 200 data points collected with the sampling time of 1 min is selected for each class to provide a trade-off between the training computational requirement and the classi fi cation accuracy.
After the selection of the training set, additional experiments are considered in order to tune the training parameter C .An appropriate adjustment of this parameter results in a signi improvement of the diagnosis results. Starting with an initial value of C , the classi fi ers are trained and tested based on the 5-fold cross validation on the training set obtained from the previous experi-ment. The value of C is then increased exponentially and this procedure is repeated. The value of C which resulted in the best performance (i.e., C  X  10 4 ) was then selected. This procedure is performed for both of the OVO-SVM and OVA-SVM classi fi ers and the results are presented in Fig. 8 . 5. Diagnosis results
As mentioned in Section 2 , the outputs of the trained binary classi fi ers in the OVO or OVA scheme can be combined in different ways to perform prediction task for new input samples. We discussed that the classical winner takes all and majority voting strategies for OVA-SVM and OVO-SVM, respectively. These tech-niques are based on the discrete decision functions, however, in this work new continuous decision functions are proposed. In this section, four strategies: OVO based on discrete decision functions (OVOD), OVA based on discrete decision functions (OVAD), OVO based on continuous decision functions (OVOC) and OVA based on continuous decision functions (OVAC) are investigated in the online incipient fault diagnosis of the distillation column. All these fault diagnosis approaches can be evaluated based on abrupt or incipient faults. Abrupt faults are faults modeled as stepwise function and incipient faults are faults modeled by using ramp functions (see Fig. 9 ). Since abrupt faults present larger distur-bances to the process and consequently result in sudden devia-tions of the process variables from their nominal values, they can easily be detected and diagnosed by both of the discrete and continuous based decision function approaches. Therefore, in the testing procedure only the incipient form of the fi ve malfunctions listed in Table 1 , which represents a more challenging diagnosis task, will be considered.

The column simulator is run for 100 min while each fault state listed in Table 1 is introduced in an incipient manner. As can be observed in Fig. 9 , to simulate the incipient faults, several parameters have to be de fi ned, namely: the fault starting time and the fault settling time. The fault starting time is the time at which the faulty behavior starts. The fault settling time is the time required after a change in a process to reach to its steady state. For our study, the fault starting time is considered to be at time equal to zero while fault settling time is set to be 100 min for all the fault conditions. Each fault is simulated separately without any case of combination with other faults (single fault diagnosis). Online measurements are collected with a sampling time of 1 s and initially processed using Eq. (10) before being submitted to each of the mentioned diagnosis systems. The parameter k in Eqs. (6 ) and ( 8 ) is selected as unity for all the fault cases.
The outputs of the OVOD and OVAD diagnosis systems for each fault state are shown in Figs. 10 and 11 , respectively. The value of zero in these fi gures indicates the normal state while other values correspond to their corresponding fault numbers listed in Table 1 . The outputs of the OVOC and OVAC diagnosis systems for each fault state are shown in Figs. 12 and 13 , respectively. The OVAD and OVOD outputs for an input observation are single discrete values each indicating an operational state number while the
OVAC and OVOC outputs consist of six continuous values each of which is associated to an operational state. 6. Discussion and performance evaluation
The results depicted in Figs. 12 and 13 indicate that the OVOC and OVAC classi fi cation methods have successfully detected and diagnosed all the considered fault categories. Due to the low severity of the fault in the early development stage, the fault has no noticeable impact on the process. Hence, as seen in Figs. 12 and 13 for each case during the initial times, the decision value for the normal output is positive and high; while all other outputs are negative. As the fault grows with time, the value of the normal output falls down and the output corresponding to the fault go up in a way that it represents a fuzzy indication of severity of the fault. The only exception in diagnosing performance is for fault 5 in OVO-SVM, where as seen in Fig. 12 the fault is initially diagnosed as being fault 2. However, as the time is passed the fault 5 output rises while the fault 2 output drops and fi nally the correct diagnosis is resulted.
 and 11 , at the start in the initial times of fault occurrence, the observations are classi fi ed as normal state (numbered as 0); nevertheless, after further propagation of fault into the process, fi nally the correct fault label is indicated by the systems in all fault cases. Despite the fi nal correct diagnosis for the discrete decision based approaches; however Figs. 10 and 11 reveal the fact that the fault growing behavior cannot be represented by these approaches.
 strate the superiority of the continuous decision function classi -cation over the discrete decision function classi fi cation for the online incipient fault diagnosis tasks when a qualitative assess-ment of fault trajectory into the process is required. However, in order to present a quantitative evaluation for the employed diagnosis methodologies, detection and diagnosis time indices are contemplated. For OVOD and OVAD, detection and diagnosis times for one speci fi c fault are essentially the same variable and are de fi ned as the fi rst time when the system output is deviated from zero. The diagnosis decision is then correct if the decision value equals to the occurring fault label and incorrect otherwise. How-ever, for OVAC and OVOC where there are six outputs at each time instant, further analysis is required in order to decide upon detection and diagnosis steps. The fault detection alarm is con-sidered to be based on the normal output deviations, since as seen in Figs. 12 and 13 ; the normal outputs of the both of the OVA and
OVO methods response promptly to the growth of all kind of the faults in the process. A boundary condition can be developed for the normal output. It can then be used to de fi ne the regions of fault and no fault. Consequently, a fault will be detected by the system at the particular time if the normal output violates the boundary in that time. We experimentally obtained the boundary conditions by examining the system responses under normal and different faulty operations.

For this purpose, fi rst a large number of normal operating data is generated using the column simulator which is then divided into training and test data. The normal training data is fed to the OVOC and OVAC algorithms and their normal outputs are shown in Fig. 14 . As seen in this fi gure, the normal outputs of both OVOC and OVAC are close to 1 which indicate the process data belong to the normal operating condition. The fault detection thresholds are represented by the horizontal lines in Fig. 14 which separate the normal space from faulty space so that a sample which do not lie within the boundary conditions will be considered as the faulty sample. The Bound Width (BW) value which determines the coordinates of normal thresholds can be speci fi ed by a deviation in percentage of the average value of the normal outputs for the training data. For example, BW  X  0.9 % in Fig. 14 for OVO-SVM indicates the distance between the upper threshold line and the mean line is considered to be 0.9% of the average value of the normal outputs for the training data. An identical plot for OVAC with BW  X  6% is also represented in Fig. 14 .

In determining the BW s, a trade-off arises between the detec-tion latency (the time interval between the instant a fault is initiated and detected) and the false alarm rate (the percentage of the normal data which are incorrectly recognized as faulty states). Since fast fault detection (low detection latency) requires considering lower BW s resulting in higher false alarm rates. The false alarm rate determines the robustness of one fault detection system while detection latency is associated with its sensitivity.
In order to select optimal boundary conditions, different values of BW s are selected and the false alarm rate of the training data and the mean detection time of all fault states are determined.
The corresponding results are listed in Table 2 . Note that since simulated fault are introduced at time zero, the detection time and detection latency time are equal. Finally, the BW values are considered to be equal to 1% and 7% for OVOC and OVAC, respectively, which resulted in zero false alarm rates for both of these two techniques.

The fault diagnosis time is considered as the fi rst time when a faulty output reaches to a positive value. This choice is based on the fact that in all cases for all operational states, at no time more than one faulty output has a positive value as seen in Figs. 12 and 13 .
Consequently, there will always be a single predicted fault label at each operational time. The diagnosis decision is correct if the positive faulty output indicates the true occurring fault and incorrect otherwise. For an example, the detection and diagnosis steps of fault 1 using all the methodologies are shown in Fig. 15 .
Table 3 shows the false alarm rates and also detection and diagnosis time results for all the classi fi cation strategies. These are determined based on the corresponding procedure discussed for each method in all fault cases. As stated before, for discrete based classi fi cation methods, i.e., OVAD and OVOD, if the diagnosis decision is correct, the detection and diagnosis times are the same (see Fig. 15 ). However, for continuous based approaches, due to the employed policy in the fault monitoring task, there is time latency between the detection and diagnosis alarms of each of the fault cases.

Generally, large values of diagnosis times may lead to negative judgments about the diagnosis performances of the employed methodologies. However, it is worth mentioning that for incipient faults, where fault evolves slowly through time, the abnormality should not necessarily be diagnosed until the process variables deviate signi fi cantly form their nominal values and symbolize clear faulty patterns in the classi fi cation point of view. Basically, in order to have a general examination judgment of one classi system in diagnosis of incipient faults, the diagnosis time of one fault should be compared with its settling time where fault reaches to its steady value ( Mendon X a et al., 2009 ). In our study, as stated before in Section 5 , the settling time of all the simulated faults are considered to be 100 min. Hence it can be claimed that the general diagnosis performance of the employed methodolo-gies which are represented in Table 3 , is fairly acceptable. As shown in this table, all faults are correctly detected and diagnosed successfully before their fault settling time.

Different detection and diagnosis results obtained for different faults, basically originate from the dissimilarity of their effects on the process variables. As a general fact, in classi fi cation based fault diagnosis, the success in detection and diagnosis of one speci fault is related to its severity and also exclusivity impact on the observed process variables. To investigate this fact, consider for example faults 3 and 4 listed in Table 1 are associated to the changes in the feed composition. Engineering knowledge about the column dynamical behavior reveals the fact that the variation in feed composition, among the entire observed variables intro-duced in relation 9, leads to changes in tray temperatures only and does not affect fl owrate and liquid holdup variables. This also can be checked in Fig. 6 where due to the faults 3 and 4, sluggish changes in tray temperatures are obtained while fl owrate and liquid holdup variables are remained constant close to their normal values. The column operation under faults 3 and 4 can be compared with others faults such as 1 or 2 where sudden and signi fi cant variations in liquid holdup variables are occurred as depicted in Fig. 6 . Finally, it can be concluded that the detection and diagnosis missions of the fault 1 or 2 could be achieved faster than the faults 3 and 4 by any classi fi cation system. Indeed, the diagnosis results in Table 3 con fi rm this point.

Moreover, for the OVO method especially, diagnosis times of the continuous based and discrete based decision function approaches are comparable in most cases. However, the excellent results obtained by OVOC and OVAC within short detection times, emphasize the superiority of the continuous based over the discrete based approaches if the crucial task of detection of incipient faults in their initial stages is required. Also, the OVO based approaches presented better results than the OVA based methods in both detection and diagnosis tasks. The advantage of the OVO strategy over the OVA method in terms of classi fi accuracy is also investigated in other researches ( Hsu and Lin, 2002 ; Weston and Watkins, 1999 ). However, as discussed before in
Section 2.2 , the ratio between the number of required binary classi fi ers in the OVO and OVA methods is ( m 1)/2, which is signi fi cant when m is large. Hence, in the training phase the computational load for the OVO method may become unaffordable for large values of m . In the testing procedure of the classi algorithms based on the OVO method, all the trained binary classi fi ers should be employed and their outputs are combined.
This may result in sluggish responses for diagnosis systems. Hence, the use of SVM is not recommended for solving problems with more than 10 classes by some investigators ( Chiang et al., 2004 ). 7. Conclusions
The consistency and the proper management of incipient faults is a challenging subject in process industries due to the problems encountered in online monitoring of the fault occurrences. These problems originate from the timing behavior of the incipient faults where the depth of fault grows steadily over time and the fault may exist in the process for a long time without revealing notice-able in fl uences on the process variables. In this work, for mainly detection and diagnosis of incipient faults, a SVM classi on the continuous decision function technique is proposed. In a two-class classi fi cation problem, this technique enables the deter-mination of both the label and the severity of the fault in comparison to the traditional discrete decision function approach which does not offer any information about the fault progress. For multiclass classi fi cation, two methodologies based on the
OVO-SVM and OVA-SVM approaches are proposed. These meth-odologies provide continuous outputs corresponding to each process operational status at each time instant of the process operation. These techniques are applied to the incipient fault diagnosis of a continuous binary mixture distillation column.
As expected, for all fault situations of the case study, the outputs of the proposed classi fi cation systems successfully diagnosed the faults and also reported the development of each fault over time.
Moreover, further analysis of the classi fi ers outputs provided an opportunity to detect and diagnose faults in their initial stages which is a critical task in incipient fault management. For this purpose in the proposed methodologies, fault detection and diagnosis are accomplished by de fi ning some thresholds for normal and faulty outputs so that the occurrence of the fault and also the type of the fault is reported at the moments when these thresholds are violated by the classi fi ers' outputs. diagnosis schemes, namely, OVAC, OVOC, OVAD and OVAD. The monitoring results in terms of detection time, diagnosis time, and false alarm rates con fi rmed the advantage of the proposed con-tinuous based approaches (OVOC and OVAC) over the traditional discrete based methods (OVOD and OVAD). In addition, OVOD presented superior results against the OVAD method. However, the application of the OVOD due to its heavy training calculations and also sluggish behavior in the testing phase may not be suggested for large fault diagnosis problems in online applications. Acknowledgments useful remarks which led to an improved manuscript.
 References
