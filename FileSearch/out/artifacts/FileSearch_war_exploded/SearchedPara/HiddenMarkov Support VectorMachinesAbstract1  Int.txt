 Yasemin Altun altun@cs.br own.edu Ioannis Tsochantaridis it@cs.br own.edu Thomas Hofmann th@cs.br own.edu Learning from observ ation sequences is a fundamen tal problem in machine learning. One facet of the problem generalizes supervised classi X cation by predicting label sequences instead of individual class labels. The latter is also known as label sequenc e learning . It subsumes problems like segmen ting observ ation sequences, an-notating observ ation sequences, and recovering under-lying discrete sources. The potential applications are widespread, ranging from natural language processing and speech recognition to computational biology and system identi X cation.
 Up to now, the predominan t formalism for modeling and predicting label sequences has been based on Hid-den Mark ov Models (HMMs) and variations thereof. HMMs model sequen tial dependencies by treating the label sequence as a Mark ov chain. This avoids di-rect dependencies between subsequen t observ ations and leads to an e X cien t dynamic programming for-mulation for inference and learning. Yet, despite their success, HMMs have at least three major limitations. (i) They are typically trained in a non-discriminativ e manner. (ii) The conditional indep endence assump-tions are often too restrictiv e. (iii) They are based on explicit feature represen tations and lack the power of kernel-based metho ds.
 In this paper, we prop ose an architecture for learning label sequences which combines HMMs with Supp ort Vector Machines (SVMs) in an innovative way. This novel architecture is called Hidden Mark ov SVM (HM-SVM). HM-SVMs address all of the above shortcom-ings, while retaining some of the key advantages of HMMs, namely the Mark ov chain dependency struc-ture between labels and an e X cien t dynamic pro-gramming form ulation. Our work continues a re-cent line of researc h that includes Maxim um En-tropy Mark ov Models (MEMMs) (McCallum et al., 2000; Punyakanok &amp; Roth, 2001), Conditional Ran-dom Fields (CRFs) (La X ert y et al., 2001), perceptron re-ranking (Collins, 2002; Collins &amp; Du X y , 2002) and label sequence boosting (Altun et al., 2003). The basic commonalit y between HM-SVMs and these metho ds is their discriminativ e approac h to modeling and the fact that they can accoun t for overlapping features, that is, labels can depend directly on features of past or future observ ations. The two crucial ingredien ts added by HM-SVMs are the maxim um margin principle and a kernel-cen tric approac h to learning non-linear discrim-inant functions, two prop erties inherited from SVMs. Before focusing on the label learning problem, let us outline a more general framew ork for learning map-pings to discrete output spaces of which the prop osed HM-SVM metho d is a special case (Hofmann et al., 2002). This framew ork subsumes a number of prob-lems such as binary classi X cation, multiclass classi- X cation, multi-lab el classi X cation, classi X cation with class taxonomies and last but not least, label sequence learning.
 The general approac h we pursue is to learn a w -parametrized discriminant function F : X  X Y ! &lt; over input/output pairs and to maximize this func-tion over the response variable to make a prediction. Hence, the general form for f is In particular, we are interested in a setting, where F is linear in some combined feature represen tation of inputs and outputs  X ( x ; y ), i.e.
 Moreo ver, we would like to apply kernel functions to avoid performing an explicit mapping  X  when this may become intractable, thus leveraging the theory of kernel-based learning. This is possible due to the linearit y of the function F , if we have a kernel K over the joint input/output space such that and whenev er the optimal function F has a dual represen tation in terms of an expansion F ( x ; y ) = P ples ( ~ x 1 ; ~ y 1 ) ; : : : ( ~ x m ; ~ y m ). The key idea of this approac h is to extract features not only from the input pattern as in binary classi X cation, but also jointly from input-output pairs. The compat-ibilit y of an input x and an output y may depend on a particular prop erty of x in conjunction with a particu-lar prop erty of y . This is especially relev ant, if y is not simply an atomic label, but has an internal structure that can itself be describ ed by certain features. These features in turn may interact in non-trivial ways with certain prop erties of the input patterns, which is the main di X erence between our approac h and the work presen ted in Weston et al. (2003). Learning label sequences is a generalization of the standard supervised classi X cation problem. Formally , the goal is to learn a mapping f from observ ation ues from some label set  X , i.e. y t 2  X . Since for a given observ ation sequence x , we only consider la-bel sequences y of the same ( X xed) length, the ad-missible range of f is e X ectiv ely  X nite for every x . The availabilit y of a training set of labeled sequences X  X  f ( x i ; y i ) : i = 1 ; : : : ; n g to learn the mapping f from data is assumed.
 In order to apply the above joint feature mapping framew ork to label sequence learning, we de X ne the output space Y to consist of all possible label sequenc es . Notice that the de X nition of a suitable parametric dis-criminan t function F requires specifying a mapping  X  which extracts features from an observ ation/lab el se-quence pair ( x ; y ). Inspired by HMMs, we prop ose to de X ne two types of features, interactions between attributes of the observ ation vectors and a speci X c la-bel as well as interactions between neigh boring labels along the chain. In contrast to HMMs however, the goal is not to de X ne a prop er joint probabilit y model. As will become clear later, the main design goal in de X ning  X  is to make sure that f can be computed from F e X cien tly, i.e. using a Viterbi-lik e decoding algorithm. In order for that to hold, we prop ose to restrict label-lab el interactions to nearest neigh bors as in HMMs, while more general dependencies between labels and observ ations can be used, in particular so-called \overlapping" features.
 More formally , let us denote by  X  a mapping which maps observ ation vectors x t to some represen tation  X ( x t ) 2 &lt; d . Then we de X ne a set of combined la-bel/observ ation features via Here [[ Q ]] denotes the indicator function for the pred-icate Q .
 To illustrate this point, we discuss a concrete example from part-of-sp eech tagging:  X  r ( x s ) may denote the input feature of a speci X c word like 'rain' occurring in the s -th position in a sentence, while [[ y t =  X  ]] may encode whether the t -th word is a noun or not.  X  st r X  = 1 would then indicate the conjunction of these two predicates, a sequence for which the s -th word is 'rain' (= r ) and in which the t -th word has been labeled as a noun (=  X  ). Notice that in general,  X  r may not be binary , but real-v alued; and so may  X  st r X  . The second type of features we consider deal with inter-lab el dependencies In terms of these features, a (partial) feature map  X ( x ; y ; t ) at position t can be de X ned by selecting ap-propriate subsets of the features f  X  st r X  g and f  X   X  st example, an HMM only uses input-lab el features of ing the ( X rst order) Mark ov prop erty of the chain. In the case of HM-SVMs we main tain the latter restric-tion (although it can trivially be generalized to higher order Mark ov chains), but we also include features  X  st r X  where s 6 = t , for example, s = t  X  1 or s = t + 1 or larger windo ws around t . In the simplest case, a fea-ture map  X ( x ; y ; t ) can be then speci X ed by de X ning a feature represen tation of input patterns  X  and by se-lecting an appropriate windo w size. 1 All the features extracted at location t are simply stacked together to form  X ( x ; y ; t ). Finally , this feature map is extended to sequences ( x ; y ) of length T in an additiv e manner as In order to better understand the de X nition of the feature mapping  X  and to indicate, how to possi-bly exploit kernel functions, it is revealing to rewrite the inner product between feature vectors for di X er-ent sequences. Using the de X nition of  X  with non-overlapping features (for the sake of simplicit y), a straigh tforw ard calculation yields ity between two sequences depends on the number of common two-lab el fragmen ts as well as the inner prod-uct between the feature represen tation of patterns with common label. We will  X rst focus on an on-line learning approac h to label sequence learning, which generalizes perceptron learning and was  X rst prop osed in the context of nat-ural language processing in Collins and Du X y (2002). In a nutshell, this algorithm works as follows. In an on-line fashion, pattern sequences x i are presen ted and the optimal decoding f ( x i ) is computed. This amoun ts to Viterbi decoding in order to produce the most 'likely', i.e. highest scored, label sequence ^ y . If the predicted label sequence is correct ^ y = y i , no update is performed. Otherwise, the weight vector w is updated based on the di X erence vector 4  X  =  X ( x i ; y i )  X   X ( x i ; ^ y ), namely w new  X  w old + 4  X . In order to avoid an explicit evaluation of the fea-ture map as well as a direct (i.e. primal) represen-tation of the discriminan t function, we would like to deriv e an equiv alent dual form ulation of the percep-tron algorithm. Notice that in the standard percep-tron learning case,  X ( x ; 1) =  X   X ( x ;  X  1), so it is suf- X cien t to store only those training patterns that have been used during a weight update. In the label se-quence perceptron algorithm, one also needs to store the incorrectly decoded sequence (whic h we call neg-ative pseudo-example ) ( x i ; f ( x i )). More precisely , one only needs to store how the decoded f ( x i ) di X ers from the correct y i , which typically results in a more com-pact represen tation.
 The dual form ulation of the discriminan t function is as follows. One main tains a set of dual parameters  X  i ( y ) such that Once an update is necessary for training sequence ( x i ; y i ) and incorrectly decoded ^ y , one simply incre-ments  X  i ( y i ) and decremen ts  X  i ( ^ y ) by one. Of course, as a practical matter of implemen tation, one will only represen t the non-zero  X  i ( y ). Notice that this requires to keep track of the  X  values themselv es as well as the pairs ( x i ; y ) for which  X  i ( y ) &lt; 0. The above form ulation is valid for any joint feature function  X  on label sequences and can be generalized to arbitrary joint kernel functions K by replacing the inner product with the corresp onding values of K . In the case of nearest neigh bor label interactions, one can make use of the additivit y of the sequence fea-ture map in Eq. (7) to come up with a more e X cien t scheme. One can decomp ose F into two contributions, F ( x ; y ) = F 1 ( x ; y ) + F 2 ( x ; y ), where and where
F 2 ( x ; y ) = X
 X  ( i; t;  X  ) = X This shows that it is su X cien t to keep track of how of-ten each label pair incorrectly appeared in a decoded sequence and how often the label of a particular ob-servation x s i was incorrectly decoded. The advantage of using the represen tation via  X  (  X ;  X  ) and  X  ( i; t;  X  ) is that it is indep enden t of the number of incorrect se-quences ^ y and can be updated very e X cien tly. In order to perform the Viterbi decoding, we have to compute the transition cost matrix and the observ a-tion cost matrix H i for the i -th sequence. The latter is given by The coe X cien ts of the transition matrix are simply given by the values  X  (  X ;  X  ). After the calculation of the observ ation cost matrix and the transition cost matrix, Viterbi decoding amoun ts to  X nding the argumen t that maximizes the potential function at each position in the sequence.
 Algorithm 1 Dual perceptron algorithm for learning via joint feature functions (naiv e implemen tation). 1: initialize all  X  i ( y ) = 0 2: repeat 3: for all training patterns x i do 4: compute ^ y i = arg max y 2Y F ( x i ; y ), where 5: if y i 6 = ^ y i then 6:  X  i ( y i )  X   X  i ( y i ) + 1 7:  X  i ( ^ y i )  X   X  i ( ^ y i )  X  1 8: end if 9: end for 10: until no more errors In order to prove the convergence of this algorithm, it su X ces to apply Theorem 1 in Collins (2002) which is a simple generalization of Noviko X 's theorem. Theorem 1. Assume a training set ( x i ; y i ) , i = 1 ; : : : ; n , and for each training label a set of candidate labels Y i  X Y X f y i g . If there exists a weight vector w such that k w k = 1 and h w ;  X ( x i ; y i ) i X h w ;  X ( x i ; y ) i X   X ; for all y 2Y then the numb er of update steps performe d by the above perceptron algorithm is bounde d from above by R 2 where R = max i k  X ( x i ; y ) k for y 2Y i [f y i g . Our goal in this section is to deriv e a maxim um margin form ulation for the joint kernel learning setting. We generalize the notion of a separation margin by de X n-ing the margin of a training example with respect to a discriminan t function, F , as: Then, the maxim um margin problem can be de X ned as  X nding a weight vector w that maximizes min i  X  i . Obviously , like in the standard setting of maxim um margin classi X cation with binary labels, one has to ei-ther restrict the norm of w (e.g. k w k = 1), or  X x the functional margin (max i  X  i  X  1). The latter results in the following optimization problem with a quadratic objectiv e min Each non-linear constrain t in Eq. (13) can be replaced by an equiv alent set of linear constrain ts, Let us further rewrite these constrain ts by introducing an additional threshold  X  i for every example, z i ( y ) ( F ( x i ; y ) +  X  i )  X  Then it is straigh tforw ard to prove the following: Prop osition 1. A discriminant function F ful X lls the constr aints in Eq. (14) for an example ( x i ; y i ) if and only if there exists  X  i 2&lt; such that F ful X lls the con-straints in Eq. (15).
 We have introduced the functions z i to stress that we have basically obtained a binary classi X cation prob-lem, where ( x i ; y i ) take the role of positiv e examples and ( x i ; y ) for y 6 = y i take the role of jYj X  1 neg-ative pseudo-examples. The only di X erence with bi-nary classi X cation is that the bias can be adjusted for each 'group' sharing the same pattern x i . Hence, there is some additional interaction among pseudo-examples created from the same example ( x i ; y i ).
 Following the standard procedure, we deriv e the dual form ulation of this quadratic program. The La-grangian dual is given by max W (  X  ) =  X  s.t.  X  i ( y )  X  0 ; 8 i = 1 ; : : : ; n; 8 y 2Y the equalit y constrain ts, which generalize the standard constrain ts for binary classi X cation SVMs ( P i y i  X  i = 0), result from the optimalit y conditions for the thresh-olds  X  i . In particular, this implies that  X  i ( y ) = 0, if  X  ( y i ) = 0, i.e. only if the positiv e example ( x i ; y a supp ort vector, will there be corresp onding supp ort vectors created from negativ e pseudo-examples. Although it is one of our fundamen tal assumptions that a complete enumeration of the set of all label sequences Y is intractable, the actual solution migh t be extremely sparse, since we expect that only very few negativ e pseudo-examples (whic h is possibly a very small subset of Y ) will become supp ort vectors. Then, the main challenge in terms of computational e X ciency is to design a computational scheme that exploits the anticipated sparseness of the solution.
 Since the constrain ts only couple Lagrange parameters for the same training example, we prop ose to optimize W iterativ ely, at each iteration optimizing over the subspace spanned by all  X  i ( y ) for a  X xed i . Obviously , by repeatedly cycling through the data set and opti-mizing over f  X  i ( y ) : y 2 Yg , one de X nes a coordinate ascen t optimization procedure that converges towards the correct solution, provided the problem is feasible (i.e., the training data is linearly separable). We  X rst prove the following two lemmata.
 Lemma 1. If  X   X  is a solution of the Lagrangian dual problem in Eq. (16), then  X   X  i ( y ) = 0 for all pairs ( x i ; y ) for which F ( x i ; y ;  X   X  ) &lt; max  X  y 6 = y i Proof. De X ne ~ F ( x i ;  X  ) = max y 6 = y the optimal threshold needs to ful X ll  X   X  i = Together with the assumption  X   X  i ( y ) &gt; 0 this contradicts the KKT complemen tary condition ( y )( F ( x i ; y ;  X   X  ) +  X   X  i + 1 2 ) = 0. Lemma 2. De X ne the matrix D (( x i ; y ) ; ( x j ;  X  y ))  X  z ( y ) z j (  X  y ) k i;j ( y ;  X  y ) , then  X  0 De i ( y ) = z where e i ( y ) refers to the canonic al basis vector corre-sponding to the dimension of  X  i ( y ) .
 z ( y ) F ( x i ; y ).
 We use a working set approac h to optimize over the i -th subspace that adds at most one negativ e pseudo-example to the working set at a time. We de X ne an objectiv e for the i -th subspace by which we prop ose to maximize over the argumen ts  X  i while keeping all other  X  j 's  X xed. Adopting the proof presen ted in (Osuna et al., 1997), we prove the follow-ing result: Prop osition 2. Assume a working set S  X  Y with y i 2 S is given, and that a solution for the working set has been obtaine d, i.e.  X  i ( y ) with y 2 S maximize the objective W i subje ct to the constr aints that  X  i ( y ) = 0 for all y 62 S . If there exists a negative pseudo-, then adding ^ y to the working set S 0  X  S [f ^ y g and optimizing over S 0 subje ct to  X  i ( y ) = 0 for y 62 S 0 yields a strict improvement of the objective function. Proof. Case I: If the training example ( x i ; y i ) is not a supp ort vector (yet), then all  X  i ( y ) in the working set will be zero, since  X  i ( y i ) = P y 6 = y the di X erence in cost function can be written as: W i ( X   X  i ; f  X  j : j 6 = i g )  X  W i (  X  i ; f  X  j : j 6 = i g ) = (  X e i ( y i ) +  X e i ( ^ y i )) 0 1  X   X  0 D (  X e i ( y = 2  X   X   X  ( F ( x i ; y i )  X  F ( x i ; ^ y i ))  X  O (  X  enough we can make  X   X  O (  X  2 ) &gt; 0.
 Case II: If the training example is a supp ort vec-tor, then  X  i ( y i ) &gt; 0, and there has to be a neg-ative pseudo-example  X  y with  X  i (  X  y ) &gt; 0. Consider  X   X  i =  X  i +  X e i ( ^ y i )  X   X e i (  X  y i ).

W i ( X   X  i ; f  X  j : j 6 = i g )  X  W i (  X  i ; f  X  j : j 6 = i g ) = (  X e i ( ^ y )  X   X e i (  X  y )) 0 1  X   X  0 D (  X e i ( ^ y )  X   X e =  X  ( F ( x i ; ^ y )  X  F ( x i ;  X  y ))  X  O (  X  2 ) 0 indep enden t of  X  . From the KKT conditions we know that  X  F ( x i ;  X  y )  X   X  i = 1 2 , while our assumption was that  X  F ( x i ; ^ y )  X   X  i &lt; 1 2 . Setting  X  = 1 2 +  X  concludes the proof.
 The above prop osition justi X es the optimization proce-dure for the coordinate ascen t over the i -th subspace, describ ed in Algorithm 2. Notice that in order to com-pute ^ y in step 3 one has to perform a two-best Viterbi decoding (Schwarz &amp; Chow, 1990). The de X nition of the relev ant cost matrices follows the procedure out-lined in Section 4.
 Algorithm 2 Working set optimization for HM-SVMs. 1: S  X  X  y i g ,  X  i = 0 2: loop 3: compute ^ y = arg max y 6 = y i F ( x i ; y ;  X  ) 4: if F ( x i ; y i ;  X  )  X  F ( x i ; ^ y ;  X  )  X  1 then 5: return  X  i 6: else 7: S  X  S [f ^ y g 8:  X  i  X  optimize W i over S 9: end if 10: for y 2 S do 11: if  X  i ( y ) = 0 then 12: S  X  S  X f y g 13: end if 14: end for 15: end loop In the non-separable case, one may also want to intro-duce slack variables to allow margin violations. First, we investigate the case of L 2 penalties. Notice that we only introduce a slack variable per training data point, and not per pseudo-example, since we want to penalize the strongest margin violation per sequence.
 By solving the Lagrangian function for  X  i , we get which gives us the following penalt y term: Similar to the SVM case, this term can be absorb ed into the kernel which is e X ectiv ely changed to and K C (( x i ; y ) ; ( x j ; y 0 )) = K (( x i ; y ) ; ( x j .
 Using the more common L 1 penalt y, one gets the fol-lowing optimization problem Again the slack variable  X  i is shared across all the negativ e pseudo-examples generated. The Lagrangian function for this case is with non-negativit y constrain ts on the dual variables  X   X  0 and  X  i ( y )  X  0. Di X eren tiating w.r.t.  X  i gives: The box constrain ts on the  X  i ( y ) thus take the follow-ing form In addition, the KKT conditions imply that whenev er  X  &gt; 0, P y 2Y  X  i ( y ) = C , which means that Hence, one can use the same working set approac h prop osed in Algorithm 2 with di X eren t constrain ts in the quadratic optimization of step 8. 8.1. Named Entity Classi X cation Named Entity Recognition (NER) is an information extraction problem which deals with  X nding phrases containing person, location and organization names, as well as temp oral and number expressions. Each entry is annotated with the type of its expression and its position in the expression, i.e. the beginning or the continuation of the expression.
 We generated a sub-corpus consisting of 300 sentences from the Spanish news wire article corpus which was provided for the Special Session of CoNLL2002 on NER. The expression types in this corpus are limited to person names, organizations, locations and miscel-laneous names, resulting in a total of j  X  j = 9 di X eren t labels.
 All input features are simple binary features. Most features are indicator functions for a word occurring within a  X xed size windo w centered on the word being labeled. In addition, there are features that encode not only the identity of the word, but also more detailed prop erties (e.g. spelling features). Notice that these features are combined with particular label indicator functions in the joint feature map framew ork. Some example features are: \Is the previous word ` Mr. ' and the curren t tag ` Person-Be ginning '?", \Does the next word end with a dot, and is the curren t tag ` Non-name '?", and \Is the previous tag ` Non-name ' and the curren t tag ` Location-Interme diate '?". In order to illustrate the nature of the extracted sup-port sequences, we show an example in Figure 2. The example sentence along with the correct labeling can be seen on the top of the  X gure. N stands for non-name entities. The upper case letters stand for the beginning and the lower case letters stand for the continuation of the types of name entities (e.g. M : Miscellaneous beginning, o : Organization continuation). We also presen t a subset of the supp ort sequences y ,  X rst the correct label and then the other supp ort sequences de-picted at the positions where they di X er from the cor-rect one. The supp ort sequences with maximal  X  i ( y ) have been selected. As can be seen, most of the sup-port sequences di X er only in a few positions from the correct label sequence, resulting in sparse solutions. In this particular example, there are 34 supp ort se-quences, whereas the size of Y is 16 9 . It should also be noted that there are no supp ort sequences for some of the training examples, i.e.  X  i ( y i ) = 0, since these examples already ful X ll the margin constrain ts. We compared the performance of HMMs and CRFs with the HM-P erceptron and the HM-SVM according to their test errors in 5-fold cross validation. Over-lapping features with a windo w of size 3 were used in all experimen ts. We used second degree polyno-mial kernel for both the HM-P erceptron and the HM-SVM. For soft margin HM-SVM, C = 1. Although in a generativ e model like an HMM, overlapping fea-tures violate the model, we observ ed that HMMs using the overlapping features describ ed above outp erformed the ordinary HMMs. For this reason, we only report the results of HMMs with overlapping features. The CRFs have been optimized using a conjugate gradien t metho d which has reportedly outp erformed other tech-niques for minimizing the CRF loss function (Mink a, 2001). Since optimizing log-loss functions (as is done in CRFs) may result in over X tting, especially with noisy data, we have followed the suggestion of (John-son et al., 1999) and used a regularized cost function. We refer to this CRF varian t as CRF-B .
 The results summarized in Figure 1 demonstrate the comp etitiv eness of HM-SVMs. As expected, CRFs perform better than the HM-P erceptron algorithm ( HM-PC ), since CRFs use the deriv ative of the log-loss function at every step, whereas the Perceptron algorithm uses only an appro ximation of it (cf. Collins (2002)). HM-SVMs achieve the best results, which validates our approac h of explicitly maximizing a soft margin criterion. 8.2. Part-Of-Sp eech Tagging We extracted a corpus consisting of 300 sentences from the Penn TreeBank corpus for the Part-Of-Sp eech (POS) tagging experimen ts. The features and experi-mental setup is similar to the NER experimen ts. The total number of function tags was j  X  j = 45. Figure 3 summarizes the experimen tal results obtained on this task. Qualitativ ely, the behavior of the di X eren t op-timization metho ds is comparable to the NER experi-ments. All discriminativ e metho ds clearly outp erform HMMs, while HM-SVMs outp erform the other meth-ods. We presen ted HM-SVMs, a novel discriminativ e learn-ing technique for the label sequence learning problem. This metho d combines the advantages of maxim um margin classi X er and kernels with the elegance and ef- X ciency of HMMs. Our experimen ts prove the comp et-itiveness of HM-SVMs in terms of the achieved error rate on three benchmark data sets. HM-SVMs have several advantages over other metho ds, including the possibilit y of using a larger number and more expres-sive features. We are curren tly addressing the scalabil-ity issue to be able to perform larger scale experimen ts. This work was sponsored by an NSF-ITR grant, award number IIS-0085940.
 Altun, Y., Hofmann, T., &amp; Johnson, M. (2003). Dis-criminativ e learning for label sequences via boost-ing. Advanc es in Neur al Information Processing Sys-tems 15 . Cam bridge, MA: MIT Press.
 Collins, M. (2002). Discriminativ e training metho ds for hidden mark ov models: Theory and experimen ts with perceptron algorithms. Proceedings of the Con-ference on Empiric al Metho ds in Natur al Language Processing .
 Collins, M., &amp; Du X y , N. (2002). Convolution kernels for natural language. Advanc es in Neur al Informa-tion Processing Systems 14 (pp. 625{632). Cam-bridge, MA: MIT Press.
 Hofmann, T., Tsochantaridis, I., &amp; Altun, Y. (2002).
Learning over structured output spaces via joint ker-nel functions. Proceedings of the Sixth Kernel Work-shop .
 Johnson, M., Geman, S., Canon, S., Chi, Z., &amp; Rie-zler, S. (1999). Estimators for stochastic uni X cation-based grammars. Proceedings of the Thirty-Seventh
Annual Meeting of the Association for Computa-tional Linguistics (pp. 535{541).
 La X ert y, J., McCallum, A., &amp; Pereira, F. (2001). Con-ditional random  X elds: Probabilistic models for seg-menting and labeling sequence data. Proceedings of the Eighte enth International Confer ence on Ma-chine Learning (pp. 282{289). San Francisco: Mor-gan Kaufmann.
 McCallum, A., Freitag, D., &amp; Pereira, F. (2000). Maxi-mum entropy mark ov models for information extrac-tion and segmen tation. Proceedings of the Seven-teenth International Confer ence on Machine Learn-ing (pp. 591{598). San Francisco: Morgan Kauf-mann.
 Mink a, T. (2001). Algorithms for maximum-likeliho od logistic regression (Technical Report 758). Depart-ment of Statistics, Carnegie Mellon Univ ersity. Osuna, E., Freund, R., &amp; Girosi, F. (1997). Training supp ort vector machines: an application to face de-tection. Proceeding of the Confer ence on Computer Vision and Pattern Recognition (pp. 130{136). Punyakanok, V., &amp; Roth, D. (2001). The use of clas-si X ers in sequen tial inference. Advanc es in Neur al Information Processing Systems 13 (pp. 995{1001). Cam bridge, MA: MIT Press.
 Schwarz, R., &amp; Chow, Y.-L. (1990). The n-best al-gorithm: An e X cien t and exact procedure for  X nd-ing the n most likely hypotheses. Proceedings of the IEEE International Confer ence on Acoustics, Speech and Signal Processing (pp. 81{84).
 Weston, J., Chap elle, O., Elissee X , A., Sch X olkopf, B., &amp; Vapnik, V. (2003). Kernel dependency estimation.
Advanc es in Neur al Information Processing Systems
