 Kian Ming A. Chai Christopher K. I. Williams Stefan Klanke Se thu Vijayakumar { k.m.a.chai, c.k.i.williams, s.klanke, sethu.vijayakuma r } @ed.ac.uk difficulty of modelling friction. This leads to the need to learn the inverse dynamics. In other work are discussed in  X  5, and the experimental setup and results are given in  X  6. multi-task GP model for the inverse-dynamics problem. 2.1 Linear relationship of inverse dynamics between contex ts Figure 1: Schematic of the PUMA 560 without the end-effector (to be connected to joint 6). It can be shown that the required torque for the j th joint can be written as [4] where the y physical characteristics of its corresponding link (e.g. m ass) and are independent of x . frames. Denoting the common inertial parameters of the j  X  th link by  X   X  Define  X  y that the  X  y setting z general the matrix A 2.2 Multi-task GP regression model This model learns M related functions { f m } M model is given by task similarities, and  X  2 2.3 Multi-task GP model for multiple contexts z ( , ) . With this prior over the z j s, the Gaussian process prior for  X  m j ( ) is given by where we have set P between different contexts. The rank of K  X  reflecting the fact that there are at most 11 underlying latent functions (see Figure 2). Let t m joints. Hence inference and hyperparameter learning can be done separately for each joint. 2.3.1 The relationship among task similarity matrices over all loads), then it can happen that s def = rank(  X   X )  X  min( M , 11) . It is worthwhile to investigate the relationship between K  X   X  so that rank( K  X  exact values may differ. This observation will be useful for model selection in  X  4. marginal likelihood L (  X  x , K  X  ,  X  2 ) def = p ( { t m } M or using expectation-maximization. In this paper, the form er is used. Require: Starting positions  X  x 1: Starting from  X  x 2: Calculate K 1  X  based on details in  X  3.2. 3: Starting from  X  x hence its estimation from the initial value  X  2 strategy works better than one which simultaneously optimi zes for all the parameters. 3.1 The initial choice of K  X  The choice of K  X  admit ready interpretations are the matrix of ones 11 T and the identity matrix I . For K  X  we initially assume the contexts to be indistinguishable fr om each other; while for K  X  applications there may be reasons to prefer one over the othe r. 3.2 Computation of K  X  Given estimates  X  x Let K x corresponds to the true values of the torque function  X  m ( x Then as per the EM step discussed in [3, eq. 4], we have where the expectations are taken w.r.t a GP with parameters  X   X  entry of hT i upper bounded by that of K  X  is undesirable, particularly when K  X  corresponding observed value t m ( x The second weakness is that with the commonly used covarianc e functions, K x to the diagonal of K x so that tr( K  X  aug ) = M if K x Finally, the required K  X  vectors/values; it could also be implemented using an incom plete Cholesky decomposition. 3.3 Incorporating a novel task The choice of the rank r of K  X  Criterion (BIC), but the use of Akaike or Hannan-Quinn crite ria is similar. Let L is constrained to have rank r ; let n m context, and n def = P  X  . Since the likelihood of the model factorizes over joints, w e have decomposition of rank r for an M  X  M matrix. For selecting the appropriate rank of the K  X  compute and compare BIC ( r ) for different values of r . learning with Gaussian processes.
  X  the underlying y the resulting  X  m in [7, ch. 8]), and are perhaps less complex than the method in this paper. Earlier work on multiple model learning such as Multiple Mod el Switching and Tuning (MMST) known non-linear regressor functions of x , and the number of models are assumed known. MMST eq. 1 may be used across contexts for more efficient and robust learning and control. y/ m z/ m Figure 3: The four paths p robot base is located at (0, 0, 0) .
 sets. Training set sizes given in the second row. The nMSEs ar e averaged over loads c that such decomposition is inherent in our application. different loads c Coulomb and viscous frictional forces. Figure 3 shows the pa ths p z masses range evenly from 0.2 kg for c due to space constraints.
 For each load c is partitioned into train and test sets in the manner describ ed below. be obtained along a fixed reference trajectory T typical for that load, say T are acquired at a common reference trajectory T c , denoted by interp sampled for training. The test set for this, denoted by extrap not training samples for c Results comparing GP with linear regression We first compare learning the inverse dynamics weightings among the covariates and among the components of the covariance function, and then learnt by optimizing the marginal likelihood independentl y for each context and each joint. The trained LR and sGP models are used to predict torques for t he interp the interp training sample size, especially so for the interp which have training data from different parts of the traject ory space will be advantageous. Results for multi-task GP We now investigate the merit of using MTL, using the training data tabulated in Table 1 for loads c each joint totalled across the 14 contexts. Note that trajectory ( p learning, but is included in the extrap multi-task GP model, restricting K  X  n = 1820 when r = 5 is selected instead.
 Figure 4 gives results of sGP, iGP, pGP and mGP-BIC for both th e interp Figure 4: Average nMSEs of sGP ( ), iGP ( ), pGP ( ) and mGP-BIC ( ) against n (on log 14 covariance functions. We have shown how the structure of the multiple-context inve rse dynamics problem maps onto a effectively, and how the rank of the K  X  Acknowledgments PASCAL2 ICT Programme, and in part by the EU FP6 SENSOPAC proj ect grant to SV and SK. KMAC would also like to thank DSO NL for financial support.
 References
