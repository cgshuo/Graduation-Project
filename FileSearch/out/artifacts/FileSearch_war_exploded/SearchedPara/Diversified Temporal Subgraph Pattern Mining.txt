 Many graphs in real-world applications, such as telecommunica-tions networks, social-interaction graphs and co-authorship graphs, contain temporal information. However, existing graph mining al-gorithms fail to exploit these temporal information and the resulting subgraph patterns do not contain any temporal attribute. In this pa-per, we study the problem of mining a set of diversified temporal subgraph patterns from a temporal graph, where each subgraph is associated with the time interval that the pattern spans. This prob-lem motivates important applications such as finding social trends in social networks, or detecting temporal hotspots in telecommu-nications networks. We propose a divide-and-conquer algorithm along with effective pruning techniques, and our approach runs 2 to 3 orders of magnitude faster than a baseline algorithm and obtains high-quality temporal subgraph patterns in real temporal graphs.
Many graphs in real world applications contain temporal infor-mation. For example, telecommunication companies record huge amounts of phone call and SMS records every day, where each phone call or SMS record contains attributes about the sender, the recipient, and the time when the phone call was made or the SMS was transmitted. As another example, online social networking companies keep logs about the interactions between users and the time when each interaction occurred. However, most existing graph mining algorithms do not consider temporal information in a graph, and thus fail to exploit those temporal attributes for detecting im-portant temporal patterns such as social trends, temporal commu-nication hotspots, and evolving social structures.

In this paper, we study the mining of subgraph structures with temporal information. Specifically, we define the concept of tem-poral subgraph pattern , which consists of a set of vertices S and closely interact with each other during the period of time from t to t e . Mining diversified temporal subgraph patterns motivates nu-merous new applications, two of which are introduced below. Evolving Social Groups. In an online social network, people join and leave social groups from time to time. For example, during the period of FIFA World Cup, soccer fans will actively discuss events on FIFA World Cup in an online forum. When the World Cup com-petition ends, they may interact more actively with other groups of people, e.g., to discuss projects with classmates towards the end of a semester. Such interesting social groups can be detected by min-ing temporal subgraph patterns from a temporal graph constructed from the interaction records of an online forum. Moreover, the de-tected social activities contain temporal information, which may help social media companies to recommend new apps and products to their users before a similar event happens in the future. Temporal Hotspots. In a telecommunication company, each con-nection between two users is recorded along with the time of the connection. By mining temporal subgraph patterns from a tempo-ral graph extracted from user connections, the telecommunication company can detect communication hotspots in different time pe-riods, and allocate more resources to hotspot regions in their peak time periods to improve services. The company may also use the information of hotspot for marketing or promotion activities.
In fact, temporal clustering has been extensively studied in the spatial setting [5, 11, 13, 18], which detects clusters of people or animals that move together for a reasonably long period of time. This work studies the problem in the context of a temporal graph, where the distance between two vertices are evaluated on a graph rather than in a geo-spatial setting.

Since it is important to find social groups (or subgraph patterns) where people closely interact with each other, many definitions of dense subgraph patterns have been proposed, such as k -core [3], k -truss [31],  X  -dense subgraph [9, 14] and  X  -quasi-clique [1]. Among them, k -core and k -truss can be efficiently computed, but for a spe-cific value of k , there is only one k -core and k -truss subgraph for a graph. Thus, they only provide us a global view of the dense parts of a graph, rather than individual dense groups. A better definition is  X  -dense subgraph or  X  -quasi-clique, which qualifies a subset of vertices to form a social group if each vertex interacts with most of the other vertices in the subset.

This paper follows the definition of  X  -quasi-clique. Since com-puting  X  -quasi-clique is NP-hard [25], existing solutions are ei-ther fast approximation algorithms [35], or exact algorithms with heuristic pruning rules [20]. Moreover, computing  X  -quasi-cliques becomes much harder in the context of a temporal graph, as the time information makes the problem much more challenging.
The main contributions of this paper are summarized as follows:
The rest of this paper is organized as follows. Section 2 defines some notations and the problem. Section 3 introduces the base-line algorithm. Section 4 proposes the framework of our solution, including the mining algorithms. Section 5 proposes some prun-ing rules for mining dense subgraph patterns in temporal graphs. Section 6 proposes some optimization techniques for our mining algorithms. Section 7 studies the performance of our mining al-gorithms on real datasets. Section 8 introduces the related works. Finally, Section 9 concludes the paper. Temporal Graph. In this paper, we consider an undirected tempo-ral graph without self loops. A temporal graph G = ( V, E of a vertex set V and a temporal edge set E . Each temporal edge e  X  E has the form ( u,v,I ) , indicating that there is an undirected edge between vertices u and v during the time interval I . Here, I = [ t s ,t e ] indicates that e appears in G during the time period [ t ,t e ] , and we denote the length of I by | I | = t e  X  t
A time interval I consists of a set of discrete time points or time snapshots (e.g., I can be a minute consisting of 60 seconds). Given a time snapshot t , we define the edge set of G at time t as { ( u,v ) |  X  ( u,v,I )  X  E : t  X  I } , and define the snapshot graph of
G at time t as G ( t ) = ( V, E ( t )) . Since the degree of a vertex v in a temporal graph G changes from time to time, we denote the degree of v at time t by d v ( t ) . We can view G ( t ) , as functions of t , which show how they change over time. Given G = ( V, E ) , a vertex subset V 0  X  V , and a time interval I , we define the temporal subgraph of G induced by V 0 and I temporal graph G 0 = ( V 0 , E 0 ,I 0 ) , such that for any time snapshot t  X  I 0 , G 0 ( t ) is the subgraph of G ( t ) induced by V Dense Temporal Graph. We define dense temporal graphs based on the definition of  X  -quasi-clique in a non-temporal graph [1], where 0  X   X   X  1 is a user-defined density parameter: given a non-temporal graph G = ( V,E ) , if d v  X   X   X  ( | V |  X  1) for all v  X  V , then G is a  X  -quasi-clique . When  X  = 1 , G is a clique.
Now we need to incorporate temporal information into the above definition to define dense temporal graphs as follows.

Given a temporal graph G = ( V, E ) and a parameter  X  , we say that G is a  X  -quasi-clique during the time interval I iff holds for all v  X  V and t  X  I .
 A temporal subgraph G 0 = ( V 0 , E 0 ,I 0 ) is considered  X  -dense iff G is a  X  -quasi-clique during the time interval I 0 .
 Temporal Coverage. Given a temporal graph G and its temporal subgraph G 0 = ( V 0 , E 0 ,I 0 ) , we define the coverage set of as C ( G 0 ) = { ( v,t ) | v  X  V 0 , t  X  I 0 } , whose size is | C ( | V 0 | X | I 0 | . Consider a set of temporal subgraphs of G , denoted by G = { G 1 , G 2 ,..., G k } , where G i is induced by a vertex set V and a time interval I i from G . The coverage set of G is the union of the coverage sets of individual subgraphs: and its size is denoted by | C ( G ) | . Although a pair ( v,t ) may appear in different coverage sets, i.e., ( v,t )  X  C ( G i ) ,C ( j , it is counted only once when calculating | C ( G ) | . Apparently, | C ( G ) | is larger if (1) | V i | , | I i | are larger, and (2) V from each other for i = 1 , 2 ,...,k .
 The Problem. In this paper, we study how to find k dense temporal subgraphs in a temporal graph, such that the k subgraphs are large and diversified (i.e., maximizing the coverage) . Formally, given a temporal graph G and four parameters  X  , k ,  X  and  X  , we want to find a set of  X  -dense subgraphs G = { G 1 ,..., G k } induced by V and I i ( i = 1 , 2 ,...,k ) from G , such that (1) | V i and (3) | C ( G ) | is maximized. We call G = { G 1 ,..., diversified temporal subgraph patterns in G .

E XAMPLE 1. Assume  X  = 0 . 6 ,k = 2 , X  = 4 , X  = 4 , and a temporal graph G shown in Figure 1. There are two diversi-fied temporal subgraph patterns, G 1 = ( V 1 , E 1 ,I ( V 2 , E 2 ,I 2 ) , of G , where V 1 = { a,b,c,d } ,I 1 = [0 , 4] and V { c,d,e,f } ,I 2 = [2 , 6] . Since for every vertex v and time snapshot t in G 1 , G 2 , we have d v ( t ) = 2  X  0 . 6  X  ( | 4 |  X  1) ,  X  -dense, and we have (1) | V 1 | = | V 2 | = 4  X   X  , (2) | I 4  X   X  , and (3) | C ( G ) | is maximized with G = { G 1 , C (
G 1 ) ,C ( G 2 ) overlap on vertices c,d at time t  X  [2 , 4] , we have | C ( G ) | = 2  X  (4  X  4)  X  2  X  2 = 28 as Figure 2 illustrates.
Figure 1: A temporal graph Figure 2: The coverage set
A straightforward solution to our problem is to list all qualified subgraph patterns, and find k of them that maximize the coverage. Search Space. Given a temporal graph G and a parameter  X  , a naive solution is to check every subgraph induced by any V and any I 0  X  I from G . To do so, we consider the set of discrete time points T = { t 1 ,t 2 ,... } , where t 1 ,t 2 ,... are the time points when an edge appears or disappears. If the subgraph induced by V 0 is  X  -quasi-clique at t i ,t i +1 ,...,t j , then it is  X  -dense through-out time interval [ t i ,t j ] . Thus, it suffices to examine every non-temporal subgraph G ( t ) induced by any V 0  X  V and any t  X  T . Therefore, the search space for pattern listing is 2 | V | Pruning during Subgraph Listing. Some pruning rules have been proposed to reduce the cost of listing quasi-cliques in a non-temporal graph [20]. These pruning rules check whether a subgraph can be further grown to form a larger qualified pattern. In the algo-rithm of [20], a mining task consists of a set S of selected vertices and a set C of candidate vertices . It then selects a vertex v and generates two mining tasks: (1) moving v 1 from C to S , and (2) simply removing v 1 from C . These two tasks refer to two cases, i.e., a candidate vertex v 1 is selected into (resp. excluded from) a pattern. Each task can be further expanded by checking another vertex v 2  X  C in a similar manner. In this way, a mining task is recursively processed, and meanwhile, the pruning rules may ter-minate a task from further expansion.
 Maximizing the Coverage. Selecting k subgraph patterns from all the qualified patterns can be regarded as a maximum set cover problem, which is NP-hard. Using the greedy algorithm of [23], we can obtain a solution with (1  X  1 /e ) approximation ratio. This algorithm picks k patterns greedily one by one, where each pattern is selected as the one that maximizes the current coverage. The Baseline Algorithm. The algorithm maintains a set V of vertex sets, where for each vertex set V 0  X  V , there exists a time point t  X  T such that the subgraph of G ( t ) induced by V  X  -quasi-clique. Initially, V is empty. We first use the algorithm in [20] to list all  X  -quasi-cliques with at least  X  vertices in every graph snapshot G ( t i ) (  X  t i  X  T ). For the  X  -quasi-cliques of let the set of their vertex sets be V i . We then check V from i = 1 to i = | T | , and for each V i , we use it to update V in two cases. (1) If a vertex set V 0  X  V i is not in V , then we attach V 0 with a starting time t s = t i and add V 0 to V . (2) If a vertex set V 0  X  X  is not in V i , then we attach V 0 with an ending time t output the subgraph pattern induced by V 0 and I 0 = [ t s result set R if | I 0 | X   X  , and then remove V 0 from V .
After all qualified temporal subgraph patterns have been col-lected to R , we call the greedy set-cover algorithm over R , and output the top k subgraph patterns.
 Drawbacks of the Baseline Algorithm. The baseline algorithm simply calls an existing algorithm for each graph snapshot where i = 1 , 2 ,..., | T | , which is inefficient since it incurs a lot of redundant computation when there are not many changes between consecutive graph snapshots. Moreover, we need to keep all the quasi-cliques of each snapshot graph (even if they may not last for  X  time steps), which consumes a large amount of memory.
In this section, we introduce the main framework of our algo-rithm for finding the top k diversified temporal subgraph patterns.
The high-level idea is to find qualified patterns by divide-and-conquer. We define a mining task as T = ( G ,S,I ) . Here ( V, E ) is a temporal graph, S is a subset of V that we have already selected as a subgraph pattern, and I is a time interval. The mining task aims to find all maximal dense subgraphs induced by V and I 0  X  I from G , such that V 0  X  S , | V 0 |  X   X  and | I We start with the task T = ( G ,  X  ,T ) , where we abuse T (w.r.t. to also denote the minimal time interval that contains all the time snapshots in T . We process the task T recursively as follows.
We first remove some vertices and time snapshots of G by the pruning rules to be introduced in Section 5, as they cannot be in-cluded in any qualified subgraph patterns. If all the vertices and time snapshots are removed, then G does not contain any qualified subgraph patterns, and the task is done. Otherwise, let the remain-ing graph be G 0 = ( V 0 , E 0 ) , if G 0 is dense throughout I , then we add G 0 to the result set R , and the task is also done.

If G 0 is neither empty nor dense, we divide the task T recursively into subtasks. Let I be the set of unpruned time snapshots in I , then we continue with two cases: (Case 1) If I is a consecutive interval, then we select a vertex v from V 0 \ S according to a total order on vertices (the ordering will be discussed in Section 6.1), and divide T into two subtasks. One subtask examines the subgraphs that contain v and the other examines the subgraphs that do not contain v . More specifically, T is divided into T 1 = ( G 0 ,S  X  X  v } , I ) and T 2 = ( G 0 \ { v } ,S, I ) , where G 0 \ { v } is the remaining graph after removing vertex v and all edges incident on v from G 2) Otherwise, I is disjoint, i.e., I = [ s 1 ,e 1 ]  X  [ s then let I i = [ s i ,e i ] and we divide T into ` subtasks T I ,S,I i ) , where i = 1 , 2 ,...,` and G 0  X  I i is a subgraph of induced by V 0 and I i . We then process the subtasks recursively.
We keep at most k subgraph patterns in the result set R through-out the whole mining process. To do so, we simply add the new qualified subgraphs to R when |R| &lt; k ; otherwise, we maintain R greedily to increase the coverage | C ( R ) | . More specifically, we first select a subgraph G from the result set R , where is the subgraph in R such that after removing it from R , the remain-ing coverage is maximized. Let R  X  = R\{ G } be the result set after excluding G from R . To decide whether a new qualified sub-graph G new should be included into R , we replace G with and check whether the new coverage | C ( R  X   X  X  G new } ) | becomes larger than the current coverage | C ( R ) | . To allow effective pruning (to be discussed in Section 5), we only replace G with G new In other words, we only update the result set if the coverage in-creases by more than 1 /k times after updating. According to [2], this updating rule has a guarantee of a 1 / 4 -approximation ratio w.r.t. the maximum value of | C ( R ) | .
Our mining algorithm is sketched in Algorithms 1 and 2. Algo-rithm 1 first initializes the result set R (Line 1) and then calls the  X  X earch X  procedure detailed in Algorithm 2 with the given temporal graph G , an empty set (of selected vertices) and G  X  X  time interval T (Line 2). Finally, it outputs the computed result set R (Line 3).
Algorithm 2 shows the recursive procedure of a mining task. It first applies the pruning rules (see Section 5) to prune some ver-tices and time snapshots from G (Line 1). Then, we continue to process the pruned graph (denoted as G new ) in three cases. (1) If the set of the remaining time points I is empty, then there is no qualified subgraph and the mining task is done (Lines 2-3); oth-erwise, (2) if I contains only one consecutive time interval and G new is a  X  -quasi-clique through out I , then G new is a new quali-fied subgraph, and the result set R will be updated as described in Section 4.2 before finishing the mining task (Lines 4-6); otherwise, (3) we continue with two subcases: if I is a consecutive time in-terval, the task is divided into two subtasks according to a selected vertex v  X  V \ S (Lines 7-10); otherwise, the task is divided into ` subtasks according to the disjoint time intervals of I (Lines 11-13). In both subcases, the subtasks are then processed recursively.
Compared with the baseline algorithm, we now examine the sub-graph patterns in the unit of time intervals rather than time points. We also terminate the mining task immediately once we find that no dense subgraph patterns can last for a period of length at least  X  . This pruning opportunity, however, is not utilized by the base-line algorithm. Also, we keep at most k subgraph patterns in the result set throughout our mining procedures, which is more space efficient than the baseline algorithm.
In this section, we present our five pruning rules for temporal subgraph mining, which are used in Line 1 of Algorithm 2. In the pruning procedure, we repeat the first four pruning rules to prune Algorithm 1 : Top-k Diversified Temporal Subgraph Mining Input: G = ( V, E ) ,  X  ,  X  ,  X  , k Output: R 1. R X  X  X  2. Search ( G ,  X  ,T ) 3. return R Algorithm 2 : Search ( G = ( V, E ) ,S,I ) 1. Apply the pruning rules to shrink G (see Section 5) 2. if I =  X  3. return 4. if ` = 1 and G new is a  X  -quasi-clique throughout I 5. Update R with G new (see Section 4.2) 6. return 7. if ` = 1 8. select a vertex v  X  V \ S 9. Search ( G new ,S  X  X  v } , I ) 10. Search ( G new \{ v } ,S, I ) 11. else 12. for i = 1 , 2 ,...,` 13. Search ( G new  X  I i ,S,I i ) the given temporal graph until it cannot be further pruned, and then use the last pruning rule to further prune the remaining graph. Summary of Pruning Rules. For temporal graph G of a mining task, the first rule prunes the vertices with low degrees and short durations, such that the degree of any vertex in the remaining graph remains at least  X   X  (  X   X  1) for a period with length at least  X  .
The second rule prunes the vertices that are far away from a newly selected vertex v , such that the distances from v to the re-maining vertices are within a valid range.

After calculating the bounds on the sizes of the qualified sub-graph patterns, the third (resp. fourth) rule removes the snapshot graphs (resp. vertices) that cannot be included in a qualified sub-graph pattern according to the bounds.

The last rule is applied only if the time points of the remaining snapshot graphs still form a consecutive interval after the previous pruning. In this case, the task is terminated if no qualified subgraph can increase the coverage by more than 1 /k times as the updating rule requires.
 The Pruning Operations. Before presenting the details of our pruning rules, we first introduce three pruning operations that are commonly used to shrink a temporal graph G .

Operation 1: Edge Removal. Recall that a temporal edge e = ( u,v,I ) connects vertices u and v within time interval I . After removing this edge, d u ( t ) and d v ( t ) decrease by 1 for all t  X  I . Sometimes we may only remove an edge within a given time in-terval I 0 , and then this edge becomes ( u,v,I \ I 0 ) , which will be broken into two edges if I \ I 0 is disjoint after removal. For ex-ample, let a temporal edge be ( u,v, [0 , 60]) , and if we remove this edge within time interval [20 , 50] , then this edge is broken into two edges ( u,v, [0 , 20]) and ( u,v, [50 , 60]) .
 Operation 2: Vertex Removal. If a vertex v is removed from G , then all its adjacent temporal edges are removed. Sometimes we may only remove a vertex within a given time interval I thus only its adjacent edges within the time interval I 0 Moreover, given a set of disjoint time intervals, I = { [ s [ s ,e i ] ,..., [ s ` ,e ` ] } , if we only remove v w.r.t. I , then v is only removed within time intervals [ s i ,e i ] for all i = 1 , 2 ,...,` .
Operation 3: Snapshot Graph Removal. Given a set of dis-joint time intervals, I , if we remove the snapshot graphs in I , then all the vertices of G are only removed w.r.t. I , and hence, the snap-shot graphs will be empty at any time t  X  X  .
Now we present our five pruning rules. Let T = ( G ,S,I ) be a mining task, where G = ( V, E ) . For an induced subgraph ( V 0 , E 0 ,I 0 ) of G , if V 0  X  S , | V 0 | X   X  , | I 0 | X   X  and throughout I 0 , then we say G 0 is a qualified subgraph pattern. Rule 1: Degree-and-Duration Based Pruning. We first prune the vertices with low degrees or short durations, since they cannot be included in a qualified subgraph pattern.

More specifically, let v  X  V be a vertex of G . If d v ( t ) &lt;  X   X  ( | S | X  1) , then d v ( t ) &lt;  X   X  ( | V 0 | X  1) for any superset V d ( t ) is too low for v to be included in a  X  -dense subgraph at time t . Moreover, if d v ( t ) &lt;  X   X  (  X   X  1) , then we also cannot include v in a  X  -dense subgraph with size at least  X  at time t . Based on these 1) } , then we can prune v within any time interval in I  X 
Let us define I + v = { t | t  X  I,d v ( t )  X   X   X  (max {| S | , X  } X  1) } , I . If e i  X  s i &lt;  X  for some i , where 1  X  i  X  ` , then time interval [ s ,e i ] is too short and v cannot be included in a qualified subgraph pattern at any time t  X  [ s i ,e i ] . Based on this fact, we can prune v within [ s i ,e i ] for any i = 1 , 2 ,...,` such that e i
We repeat the above operations for all vertices in G until no more vertex can be removed within any time interval.
 Rule 2: Distance Based Pruning. According to [26], if a vertex is too far away from any selected vertex, it cannot be in a  X  -quasi-clique. Thus, after a new vertex is selected, we remove vertices that are farther away than a distance threshold computed based on  X  .
Specifically, if a non-temporal graph G = ( V,E ) is a  X  -quasi-clique, then according to Theorem 1 in [26], we have  X  u,v for all u,v  X  V , where  X  u,v is the distance between vertices u and v , and f is a function of  X  . In particular, f (1) = 1 and f (  X  ) = 2 for 0 . 5  X   X  &lt; 1 . According to this property, vertices whose dis-tance are larger than f (  X  ) from any selected vertex can be removed. To do so, we define  X  u,v ( t ) as the distance between vertices u and v in of time points when the distance between u,v  X  V is larger than a given threshold f (  X  ) . Then, after adding a new vertex v to S , for every u  X  V \ S , we prune u within any time interval in I Rule 3: Pattern Size Based Pruning. Consider the current task T = ( G ,S,I ) again. For a time point t  X  I , if there does not exist any qualified subgraph pattern G 0 = ( V 0 , E 0 ,I 0 ) such that t  X  I we call t as a break point. To find break points for any t  X  I , we first calculate an upper bound ub ( t ) and a lower bound lb ( t ) for the size of any qualified subgraph pattern at time t (see Section 5.2 for t is a break point. Based on this property, we define T b I,ub ( t ) &lt;  X  or ub ( t ) &lt; lb ( t ) } as the set of break points.
Then, we can use T b to find more break points by checking the length of the time interval between any two break points in T which is detailed as follows. If t 1 ,t 2  X  T b satisfies | t then for any t  X  [ t 1 ,t 2 ] , the time span of any  X  -dense subgraph that spans across time t is broken at t 1 and t 2 , and hence, these subgraph patterns cannot last for a period with length  X  . As a result, all time points t  X  [ t 1 ,t 2 ] are also break points. We denote this expanded set of break points as follows:
T + b = { t | t  X  I,  X  t 1 ,t 2  X  T b , s.t. t 1  X  t  X  t 2 Then, we can prune the snapshot graphs in T + b .
 Rule 4: Vertex Based Pruning. Recall that V is the vertex set of G . For a vertex v  X  V and a time point t  X  I , if there does not exist any qualified subgraph pattern G 0 = ( V 0 , E 0 ,I 0 ) such that v  X  V and t  X  I 0 , then we say that v is disqualified at time t . We will show how to find disqualified vertices in Section 5.3. Moreover, if a vertex v is disqualified at both t 1 and t 2 such that | t then v is also disqualified at any time t  X  [ t 1 ,t 2 ] .
Let T v be the set of time points when v is disqualified. If v  X  S , then all the time points in T v are break points and we prune the snapshot graphs in T v ; otherwise, we prune v at any time t  X  T Rule 5: Diversity Based Pruning. This pruning rule is only called when the set of time intervals (denoted as I ) of the remaining snap-shot graphs (after repeatedly applying Rules 1-4) consists of only one consecutive time interval.

Recall from Section 4.2 that if Inequality (1) does not hold, we do not update the result set R , and thus can terminate the task ear-lier. For this purpose, we derive an upper bound on the coverage score after we update R with any subgraph pattern G 0 mined from the current task T .

Let  X ( G 0 ) = | C ( R  X   X  X  G 0 } ) | X  X  C ( R  X  ) | be the increment of the coverage after adding G 0 to R  X  . Since we have selected a set S of vertices, we can first calculate  X ( G  X  S ) , where G  X  S refers to the subgraph of G induced by S and I . Let m = max t  X  I ub ( t ) be the maximum allowed number of vertices in a qualified subgraph, and let  X  1 ,  X  2 ,...,  X  m  X  X  S | be the ( m  X  | S | ) largest values of  X (
G  X  X  v } ) among all v  X  V \ S . Then the upper bound of the coverage is C ub = | C ( R  X  ) | +  X ( G  X  S ) + P m  X  X  S | coverage after we add into R  X  a pattern G 0 , which contains S and Inequality (1) cannot hold, and we thus terminate task T directly.
Recall that Rule 3 requires the bounds ub ( t ) and lb ( t ) on the size (i.e., the number of vertices) of any qualified subgraph pattern at time t . We now derive these bounds.
The degree of a vertex provides an upper bound on the size of any quasi-clique that contains this vertex. We discuss how to derive the upper bound u ( t ) for a mining task.

Given a mining task T = ( G ,S,I ) , for any t  X  I , let d min { d v ( t ) | v  X  S } . Then, u ( t ) is given by the following lemma.
L EMMA 1. Let G 0 = ( V 0 ,E 0 ) be a subgraph of G ( t ) . If V S and G 0 is a  X  -quasi-clique, then | V 0 |  X  u ( t ) , where u ( t ) = b d min ( t ) / X  c + 1 .

P ROOF . According to the definition of  X  -quasi-clique, we have d ( t )  X   X   X  ( | V 0 | X  1) for all v  X  V 0 . Since V 0  X  S , we have d min ( t )  X   X   X  ( | V 0 |  X  1) , that is, | V 0 |  X  b d min u ( t ) .

We now derive the lower bound l ( t ) . Let N v ( t ) be the set of v  X  X  neighbors at time t . Given a set of vertices, S 0 , we first define the restricted degree of v w.r.t. S 0 at time t as d S 0 v ( t ) = | N which refers to the number of neighbors of v that are in S following lemma.

L EMMA 2. Let G 0 = ( V 0 ,E 0 ) be a subgraph of G ( t ) . If V S and G 0 is a  X  -quasi-clique, then | V 0 |  X  l ( t ) , where l ( t ) = d ( | S | X  d S min ( t )  X   X  ) / (1  X   X  ) e .

P ROOF . According to the definition of  X  -quasi-clique, we have d v ( t )  X   X   X  ( | V 0 | X  1) for all v  X  V 0 . Since V 0  X  S , we have d v ( t )  X  ( | V 0 | X  X  S | ) + d S v ( t ) , and thus, | V  X   X  ( | V 0 | X  1) for all v  X  V 0 . Since d S v ( t )  X  d | V 0 | X  X  S | + d S min ( t )  X   X   X  ( | V 0 | X  1) , and thus, | V d min ( t )  X   X  ) / (1  X   X  ) e = l ( t ) .
We now make u ( t ) and l ( t ) tighter by considering the sum of the restricted degree of individual vertices. Note that if a non-temporal graph G 0 = ( V 0 ,E 0 ) is a  X  -quasi-clique, then for any m vertices in V 0 , the sum of their degrees must be at least m  X d  X   X  ( | V
Since S  X  V 0 , for any subset of S with m vertices, denoted by S 0 , the sum of all degrees of vertices in S 0 should be at least m  X d  X   X  ( | V 0 | X  1) e . Currently, V 0 = S but the degree sum may be less than m  X d  X   X  ( | S | X  1) e , and we need to include more ver-tices into V 0 to make the requirement satisfied for the subset S We present how to derive bounds on the number of vertices that needs to be included, using restricted vertex degrees w.r.t. S vertices in S , we compute their sum of restricted degree w.r.t. S at time t as P v  X  S d S 0 v ( t ) . For vertices in V \ S (which are candi-dates to be included into V 0 ), we sort them in non-increasing order of their restricted degree d S 0 v ( t ) , and denote the sorted vertices by v ,v 2 ,...,v | V \ S | . Then, we have the following lemma.
L EMMA 3. Let G 0 = ( V 0 ,E 0 ) be a subgraph of G ( t ) , and S be a subset of S , if V 0  X  S and G 0 is a  X  -quasi-clique, then we have P ROOF . According to the definition of  X  -quasi-clique, we have P to prove that L.H.S.  X  P v  X  S 0 d V 0 v ( t ) .

Note that P v  X  S 0 d V 0 v ( t ) equals the number of edges between S prove that L.H.S.  X  P v  X  V 0 d S 0 v ( t ) .
 We divide V 0 into two sets S and V 0 \ S , then we get
Since we have sorted the vertices v  X  V \ S in descending order of their restricted degrees, we have Thus, according to Inequality (2), we have which completes the proof.

Let u S 0 ( t ) (resp. l S 0 ( t ) ) be the maximum (resp. minimum) | V (computed from S 0 ), such that
To compute u S 0 ( t ) and l S 0 ( t ) , we first compute P Then, we sort the vertices in V \ S in non-increasing order of their restricted degree d S 0 v ( t ) for every t  X  I , and hence we obtain the for i = 1 , 2 ,...,u ( t )  X  X  S | . Finally, we compare the sum with R.H.S. to get u S 0 ( t ) and l S 0 ( t ) .

According to Inequality (3), u S 0 ( t ) and l S 0 ( t ) are tighter than u ( t ) and l ( t ) . If there is no valid value of | V 0 ities (3) and (4), then we set u S 0 ( t ) =  X  1 and l S 0
Since any subset S 0  X  S can be selected to compute the bounds u 0 ( t ) and l S 0 ( t ) , we define u max S 0  X  S l S 0 ( t ) , then u m ( t ) and l m ( t ) are tighter than u l ( t ) for any S 0  X  S , and we have the following corollary. C OROLLARY 1. Let G 0 = ( V 0 ,E 0 ) be a subgraph of if V 0  X  S , | V 0 |  X   X  and G 0 is a  X  -quasi-clique, then we have l ( t )  X | V 0 | X  u m ( t ) .

For efficiency reasons, we only enumerate some subsets S 0 to compute the bounds, as we will discuss in Section 6.1.
Note that u m ( t ) and l m ( t ) are functions of t for t  X  I , we can further make them tighter using the minimum duration  X  .

L EMMA 4. If there exists t,t 1 ,t 2  X  I , such that then no dense subgraph pattern with size u m ( t ) at time t can last for a duration with length  X  .

P ROOF . According to Corollary 1, there does not exist a dense subgraph pattern with size larger than u m ( t 1 ) at time t at time t 2 . That is, there does not exist a dense subgraph pattern with size larger than max { u m ( t 1 ) ,u m ( t 2 ) } at time t any dense subgraph pattern with size u m ( t ) &gt; max { u at time t must start after t 1 and end before t 2 , and hence, cannot last for a duration with length t 2  X  t 1 &lt;  X  .

According to Lemma 4, we can make u m tighter if there exists t,t 1 ,t 2  X  I satisfying Inequalities (5)-(7). In this case, we say u is tighten-able at time t , and we tighten u m by setting u max { u m ( t 1 ) ,u m ( t 2 ) } . We repeat this operation until u tighten-able at any time t  X  I . Then, the upper bound ub ( t ) used by Rule 3 equals the tightened u m ( t ) , which can be computed in linear time as follows.

We first represent u m ( t ) in s pairs ( t 1 ,  X  1 ) , ( t where s is the number of changes of the value of u m ( t ) for t  X  I , t is the time of the i -th change, and  X  i is the difference of the value of u m ( t ) after and before time t = t i . As a special case, t is the starting time of I and  X  1 equals u m ( t 1 ) . For example, the upper bound u m ( t ) shown in Figure 3(a) can be represented in 3 pairs (0 , 8) , (20 , 6) , (40 ,  X  4) . Before explaining how to compute ub ( t ) in linear time, we need to prove the following lemma.
L EMMA 5. Let ( t a ,  X  a ) and ( t b ,  X  b ) be two consecutive pairs in the representation of u m ( t ) . If then u m ( t ) is tighten-able at any time t  X  ( t a ,t b Figure 3: An example of u m before and after improvement.
P ROOF . Since  X  a &gt; 0 , we have u m ( t ) &gt; u m ( t also, since  X  b &lt; 0 , we have u m ( t ) &gt; u m ( t b t = t a , t 2 = t b and t  X  ( t 1 ,t 2 ) , we have t 1 &lt; t &lt; t and u m ( t ) &gt; max { u m ( t 1 ) ,u m ( t 2 ) } , and thus, u at any time t  X  ( t a ,t b ) .

To compute ub ( t ) , we maintain a stack S of pairs, which is empty initially. Recall that u m ( t ) has been represented in s pairs ( t ,  X  1 ) , ( t 2 ,  X  2 ) , ... , ( t s ,  X  s ) , we push the pairs ( t one by one for i = 1 , 2 ,...,s . After we have pushed a pair into S , let the top 2 pairs of S be ( t a ,  X  a ) and ( t b ,  X  Inequalities (8) in Lemma 5. If they all hold, then u m ( t ) is tighten-able at any t  X  ( t a ,t b ) , and hence, we want to tighten u setting u m ( t ) to max { u m ( t a ) ,u m ( t b ) } for all t  X  ( t handle this operation, we first pop ( t a ,  X  a ) and ( t S . We then define  X  =  X  a +  X  b , and update S as follows, if  X  &gt; 0 , we push ( t a ,  X ) into S ; otherwise, if  X  &lt; 0 , we push ( t ,  X ) into S . We repeat the previous operations, until Inequali-ties (8) do not hold for the top 2 pairs of S . Finally, ub ( t ) is derived as the pairs in S represent. Apparently, the computation time of ub ( t ) is linear to s .

To illustrate the computation of ub ( t ) , let I = [0 , 70] ,  X  = 30 , and u m ( t ) be shown in Figure 3(a). To compute ub ( t ) , we first push the pairs (0 , 8) , (20 , 6) , (40 ,  X  4) into S one by one. After we have pushed (40 ,  X  4) into S , the top 2 pairs are (20 , 6) and (40 ,  X  4) , which satisfy 6 &gt; 0 ,  X  4 &lt; 0 and 40  X  20 &lt;  X  , and thus, u m is tighten-able at t  X  (20 , 40) . To tighten u (20 , 6) and (40 ,  X  4) out from S , and we have  X  = 6 + (  X  4) = 2 &gt; 0 , and hence, we push (20 , 2) into S . Finally, we get S = represent, which is shown in Figure 3(b).
 Similarly, we have the following lemma on the lower bounds.
L EMMA 6. If there exists t,t 1 ,t 2  X  I , such that t t , t 2  X  t 1 &lt;  X  and l m ( t ) &lt; min { l m ( t 1 ) ,l dense subgraph patterns with size l m ( t ) at time t cannot last for a duration with length  X  .

According to Lemma 6, we can make l m tighter by a similar procedure, such that t 1 &lt; t &lt; t 2 , t 2  X  t 1 &lt;  X  and l min { l m ( t 1 ) ,l m ( t 2 ) } cannot hold simultaneously for any t,t I . Finally, the lower bound lb ( t ) used by Rule 3 equals the tight-ened l m ( t ) .
After deriving the bounds lb ( t ) and ub ( t ) on the size of qualified subgraph patterns of G , we can use these bounds to check whether we can include a vertex v in a qualified subgraph pattern at time t . If we cannot include v in a qualified subgraph pattern at time t , then v is disqualified at time t , which will be pruned by Rule 4. To check whether a vertex v is disqualified at time t , we first prove the following lemma.

L EMMA 7. Let G 0 = ( V 0 ,E 0 ) be a subgraph of G ( t ) , if V S and G 0 is a  X  -quasi-clique, then we have d v ( t )  X   X   X  ( lb ( t )  X  1) for all v  X  V 0 .
P ROOF . According to the definition of  X  -quasi-clique, we have d ( t )  X   X   X  ( | V 0 | X  1) for all v  X  V 0 . Since we have | V we obtain d v ( t )  X   X   X  ( lb ( t )  X  1) .

According to Lemma 7, if we find that there exists v  X  V , t  X  I , such that d v ( t ) &lt;  X   X  ( lb ( t )  X  1) , then we cannot include v in a qualified quasi-clique at time t , and hence, v is disqualified at time t . More disqualified vertices can be found by the following lemma.
L EMMA 8. Let G 0 = ( V 0 ,E 0 ) be a subgraph of G ( t ) , if V S and G 0 is a  X  -quasi-clique, then we have ub ( t )  X  X  S | + d  X   X  ( lb ( t )  X  1) for all v  X  S and we have ub ( t )  X  X  S | X  1 + d  X   X  ( lb ( t )  X  1) for all v  X  V 0 \ S .

P ROOF . Since G 0 is a  X  -quasi-clique, we have d V 0 v ( lb ( t )  X  1) . Since we have | V 0 |  X  ub ( t ) , V ( ub ( t )  X  X  S | ) vertices that are not in S , and thus, we have d for v  X  V 0 \ S . Thus, we obtain ub ( t )  X  X  S | + d S v v  X  V 0 \ S .

According to Lemma 8, if we find that there exists v  X  S , t  X  I , include v in a qualified quasi-clique at time t , and hence, v is dis-qualified at time t . Also, if we find there exists v  X  V \ S , t  X  I , disqualified at time t .

We can further check whether a vertex w  X  V \ S can be included in a qualified subgraph pattern at time t by considering the sum of degrees as follows. If we include vertex w in the set of selected S V \ ( S  X  X  w } ) that are sorted by descending order of their restricted degrees d S 0 v ( t ) w.r.t. S 0 at time t . Let where m refers to the size of a subgraph pattern. If there does not exists m , such that (1) lb ( t )  X  m  X  ub ( t ) , and (2)  X   X  | S | X d  X   X  ( m  X  1) e , then vertex w cannot be included in a qualified subgraph pattern at time t , and hence, w is disqualified at time t .
In this section, we provide some optimization techniques that are used to further improve our algorithm.
Consider a task T = ( G ,S,I ) , let I be the set of time intervals of the remaining snapshot graphs after pruning. Recall that when I is a single consecutive time interval, we will divide T into two subtasks, T 1 = ( G ,S  X  X  v 1 } , I ) and T 2 = ( G \{ v where v 1 is a selected vertex. Since T 2 may be further divided into T 2 , 1 = ( G \{ v 1 } ,S  X  X  v 2 } , I ) and T 2 , 2 = ( G \{ v and T 2 , 2 may be further divided into T 2 , 2 , 1 = ( G { v divide the task T into | V \ S | subtasks T 1 , T 2 , ... , T I is a consecutive time interval, we need to arrange the | V \ S | vertices in order so that we can divide the task T into | V \ S | subtasks directly.
 Vertex Ordering. We order the vertices in ascending order of their degrees. That is, the vertices with smaller degrees will be selected first. Since we have selected a set S of vertices, their degrees are more important than the degrees of the vertices we have not se-lected. According to this intuition, we define a score function of a vertex as the weighted sum of its restricted degree w.r.t. S and its original degree. Formally, the score function of a vertex v in a temporal graph G at time t is defined as Then, the first selected vertex v 1 is the vertex with the smallest P t  X  I sc G v ( t ) among all v  X  V \ S , the second selected vertex v is the vertex with the smallest P t  X  I sc G \{ v 1 } v ( t ) among all v  X  V \ ( S  X  X  v 1 } ) , and so on.
 Subtasks Ordering. Since the degrees of v 1 ,v 2 ,... are smaller than the remaining vertices, the remaining graph G \{ v 1 is probably denser than the original graph G , and hence, it is eas-ier to find qualified subgraph patterns in the remaining graph. In other words, it is easier to mine dense subgraphs from subtask T with larger i intuitively. According to this intuition, we process the subtask T i in descending order of i (i.e. i = | V \ S | , | V \ S | X  1 ,..., 2 , 1 ), so that we can find some qualified subgraph patterns more quickly.

The previous discussions are based on the case that I is a con-secutive time interval. When I is disjoint, we will divide T into subtasks according to the disjoint time intervals in I . Then, we order the subtasks according to the density of their graphs, where the density is measured by the weighted sum of the degrees of the vertices. Specifically, let  X  = P v  X  V P t  X  I subtask will be processed earlier if its graph has a larger  X  value. Vertex Subsets Ordering. Recall that any subset S 0  X  S can be used to derive a bound of pattern size (see Section 5.2.2), we only take | S | subsets into consideration to achieve higher efficiency. We next specify which | S | subsets will be considered.

The first subset is S itself, then the next subset is the previous subset after excluding a vertex with the largest weighted degree. The reason is that the vertices with smaller degrees are harder to satisfy the degree threshold, and hence, they are more likely to affect the bounds of pattern sizes. Formally, let v be the list of vertices in S sorted by non-increasing order of their second subset is S \{ v 1 } , and so on.
Recall that we continue processing a task only when C (1 + 1 /k )  X | C ( R ) | holds (see Rule 5 in Section 5.1), a good result set R may help us to terminate many tasks earlier since the larger | C ( R ) | is, the less likelihood this condition holds. According to this intuition, we want to collect the first k qualified subgraph pat-terns (1) as quick as possible, and (2) with the size of the coverage set as large as possible. However, our current search strategy only achieves the first goal, but has not achieved the second goal yet. The reason is that our search is depth first, i.e., we do not proceed to the next subtask until the current subtask is done. Note that all the subgraphs mined from T = ( G ,S,I ) contain the set S of ver-tices, they overlap with each other on any vertex v  X  S , and hence, our current search strategy cannot get a large initial coverage.
To achieve both goals, we propose a quick search algorithm, which runs with a user defined parameter ` . This search strategy proceeds to the next subtask earlier according to the value of ` . To specify how the algorithm works, we first define the hardness of a task T , denoted as h ( T ) . If T can be done without dividing into subtasks, i.e., the graph is totally pruned, or is dense throughout its time interval, then h ( T ) = 0 . Otherwise, h ( T ) is defined in a recursive way as follows. Let h ( T i ) be the hardness of the i -th subtask of T , i = 1 , 2 ,...,s , where s is the number of subtasks of T . Let h m ( T ) = max { h ( T i ) | 1  X  i  X  s } be the maximum hardness of the subtasks of T , and let h c ( T ) = |{ i | h ( T h m ( T ) , 1  X  i  X  s }| be the number of subtasks of T with the max-imum hardness. Then we define h ( T ) = h m ( T ) if h c and h ( T ) = h m ( T ) + 1 otherwise.

The quick search algorithm only goes into the first subtask that has a large enough hardness, then passes through the remaining subtasks quickly. More specifically, the quick search algorithm with parameter ` works as follows. If T is divided into subtasks, it recursively calls the quick search algorithm with parameter ` to handle the subtasks T 1 , T 2 , ... , one by one. Once a subtask T finished, it checks whether h ( T i )  X  ` or not. Once h ( T holds, it passes through the remaining subtasks quickly as follows. It first checks whether ` &gt; 0 or not. If ` = 0 , it terminates immedi-ately without handling the remaining subtasks T i +1 , T i +2 erwise (i.e. ` &gt; 0 ), it handles the remaining subtasks T ... by recursively calling the quick search algorithm with parame-ter `  X  1 only. We have the following theorem on the efficiency of the quick search algorithm.

T HEOREM 1. The quick search algorithm with parameter ` han-dles at most r ` +1 max  X  s ` max tasks, where r max is the maximum depth of recursions handling a task, and s max is the maximum number of subtasks that a task is divided into.

P ROOF . We first prove that there are at most R ( ` ) = r tasks that need to be handled in a task T with hardness ` . We prove this proposition by induction. The base case is ` = 0 . According to the definition of hardness, if T needs to be divided, it must be divided into at most one subtask T 1 , and T 1 has at most one subtask T total number of tasks needs to be handled in T is at most r which proves the base case of the proposition.

For the induction case, suppose the proposition holds for the tasks with hardness `  X  1 , and the hardness of a task T is ` . Then there are at most one subtask of T with hardness ` . Without los-ing generality, let h ( T 1 ) = ` , then we have h ( T i = 2 , 3 ,... . Then there are at most one subtask of T hardness ` , and without loss of generality, let h ( T 1 , 1 we have h ( T 1 ,i )  X  `  X  1 for i = 2 , 3 ,... . Then the same ar-the total number of tasks that need to be handled in T is at most r max  X  s max  X  R ( `  X  1) = R ( ` ) , which proves the induction case and the proposition holds for all ` .

We then prove, by induction, that the quick search algorithm with parameter ` handles at most R ( ` ) = r ` +1 max  X  s ` max case is ` = 0 . According to the quick search algorithm, if T needs to be divided, it only handles the first subtask T 1 . If T divided, it only handles the first subtask T 1 , 1 , and so on. Then the total number of tasks that need to be handled in T is at most r which proves the base case of the theorem.

For the induction case, suppose the theorem holds for parameter `  X  1 , then the algorithm with parameter ` first handles some tasks with hardness at most `  X  1 , then handles a task with parameter ` , and then handles the remaining tasks with parameter `  X  1 . By sim-ilar arguments in the previous proof, the algorithm handles at most r max  X  s max  X  R ( `  X  1) = R ( ` ) tasks, which proves the induction case and the theorem holds for all ` .

Apparently, both r max and s max cannot exceed | V | + | T | . So according to Theorem 1, given a constant value ` , the running time of the quick search algorithm is a polynomial of | V | and | T | . How-ever, the quick search algorithm may miss some qualified subgraph patterns. To avoid missing any qualified subgraph pattern, we also propose a complete search algorithm, which works as follows. It calls the quick search algorithm with parameter ` = 0 , 1 , 2 ,... for the initial task T , until ` = h ( T ) holds. Then we have the follow-ing theorem on the performance of the complete search algorithm.
T HEOREM 2. The complete search algorithm achieves the 1 / 4 approximation ratio on maximizing | C ( R ) | .

P ROOF . We first show that a task with hardness ` will be com-pletely handled by the quick search algorithm with parameter ` . We prove the proposition by induction. Apparently, this proposi-tion holds for the base case ` = 0 . For the induction case, suppose the tasks with hardness `  X  1 will be completely handled by the quick search algorithm with parameter `  X  1 , and h ( T ) = ` . Re-call that the algorithm with parameter ` handles the subtasks of T by three steps: (1) first handles some subtasks whose hardness is at most `  X  1 with parameter ` , (2) then handles a subtask whose hard-ness is ` with parameter ` , (3) then handles the remaining subtasks whose hardness is at most `  X  1 with parameter `  X  1 . Appar-ently, the subtasks in step (1) and (3) will be completely handled, it remains to show that the subtask in step (2) will be completely handled. Since the same argument can be recursively applied to the smaller subtasks of the subtask in step (2), they will be completely handled. Thus the proposition holds for all cases.

Since the complete search algorithm finally calls the quick search algorithm with parameter ` = h ( T ) for the initial task T , this task will be completely handled. Then according to the updating rule described in Section 4.2 and the theoretical results in [2], the complete search algorithm achieves the 1 / 4 approximation ratio on maximizing | C ( R ) | , which completes the proof.
This section studies the performance of our algorithms. The ex-periments were conducted on a PC with Intel Core i5-3570 CPU at 3.40GHz and 32GB RAM. The operation system is Linux. Our algorithms are implemented using C++ and compiled by g++. Datasets. We used six real datasets in our experiments. Five datasets are social networks and one is hyperlinks, which are all downloaded from KONECT (http://konect.uni-koblenz.de/). In which,  X  X BLP coauthor X  dataset is the co-authorship between authors in DBLP,  X  X nron employees X  dataset is the communication between employees in Enron,  X  X acebook wall posts X  dataset is the wall posts between users in Facebook,  X  X inux kernel mails X  dataset is the emails between email addresses in Linux kernel,  X  X lashdot X  dataset is the communication between users in Slashdot, and  X  X ikipedia simple-En X  dataset is the hyperlinks between Wikipedia articles in simple English. The sizes of these datasets are shown in Table 1.
We first report the efficiency of our algorithms. We report the running time of both the complete search algorithm (denoted as  X  Complete  X ) and the quick search algorithm (denoted as  X  Quick  X ), compared with the baseline algorithm (denoted as  X  Baseline  X ) de-scribed in Section 3. We set  X  = 0 . 8 and k = 10 as the default values, while the default values of  X  and  X  for each dataset are shown in Table 2. Note that if  X  and/or  X  are too large, there will be no qualified patterns; while if  X  and/or  X  are too small, then the coverage of the top k patterns will be too small. We study the ef-fects of different values of the parameters in Section 7.3. We also set ` = 2 as the default value for the quick search algorithm.
Table 3 reports the running time of the three algorithms on each dataset. Note that we terminated an algorithm when it ran for more than 10 days (i.e., 864,000 seconds). The result shows that Quick is 2 to 3 orders of magnitude faster than Baseline. Baseline could showing the hardness of the problem studied in this paper. Com-plete also achieves good performance for 4 out of the 6 datasets. In fact, for 3 of the 4 datasets, Complete achieves the same perfor-mance as Quick, which is because the search space of Complete is already small (as reflected by the running time) and the strategy used in Quick cannot further reduce the search space. However, for the other 3 datasets that take much longer time to process, the op-timization of Quick becomes vital and significant reduction in the running time is observed compared with Complete.

Theorem 2 shows that theoretically Complete has a 1 / 4 approx-imation ratio, while Quick is heuristic. Thus, we also show practi-cally how good the results obtained by Complete and Quick are. To do this, we compare the results obtained by Complete and Quick with that obtained by an  X  Enumerate-all  X  algorithm, which lists all the qualified subgraph patterns and then computes the top-k re-sult by the greedy algorithm for the maximum set cover problem. The result set obtained by Enumerate-all is guaranteed to have a (1  X  1 /e ) approximation ratio of the optimal result. We used the default values of the parameters as in Section 7.1 for the algorithms.
Table 4 reports the coverage (i.e., | C ( G ) | ) of the top k patterns obtained by each of the three algorithms on each dataset. The re-sult shows that the top k patterns obtained by Complete achieves a coverage far better than the theoretical 1 / 4 approximation ratio, and practically the approximation ratio is over 0.8 in all the datasets and over 0.9 in 4 datasets. In fact, for 2 datasets the results of Com-plete are exactly the same as Enumerate-all and for another one the approximation ratio is 0.997.

The results obtained by Quick are exactly the same as those ob-tained by Complete for 5 out of the 6 datasets, but Quick is much faster than Complete for processing 3 datasets as shown in Table 3. Thus, the results of this experiment demonstrate that Quick is not only fast but also computes high-quality results.
In this set of experiments, we show the performance of our al-gorithm, Quick, by varying the different parameters. We first vary their default values as in Section 7.1.

Figure 4 shows that the running time of Quick can vary consid-erably with varying values of  X  . For some datasets, the running time increases when  X  increases, because it is easier to collect the first k qualified subgraph patterns into the result set with a smaller  X  , and once we have collected k patterns, we can apply Pruning Rule 5 to terminate a task earlier. However, there are also a few datasets for which the running time remains rather stable or even decreases when  X  increases, which can be explained as follows. From Lemma 1 we have u ( t ) = b d min ( t ) / X  c + 1 , which decreases if  X  increases. Since ub ( t ) is tightened from u ( t ) , and the snapshot graphs at time t will be pruned by Pruning Rule 3 if ub ( t ) &lt;  X  , more snapshot graphs will be pruned when  X  increases. Thus, the result shows that the effect of  X  on the performance of the algo-rithm varies for different datasets, but overall, even if the running time increases, it only increases linearly in terms of  X  .
Next we vary k = 5 , 10 , 15 , 20 . Figure 5 shows that the running time of Quick remains quite stable for different values of k for all quality of the patterns degrades significantly when k is larger than 20 (i.e., they do not increase the coverage much). We also vary  X  to be 0 . 6 , 0 . 8 , 1 , 1 . 2 times of the default value, i.e.,  X  The result shows that the running time of Quick decreases when  X  increases, which is because we can prune more short-duration patterns by Rule 1 and obtain a tighter bound by duration-based bounds (see Section 5.2.3).
Existing work on temporal graphs is mostly related to temporal paths and their applications [8, 15, 16, 24, 27, 28, 29, 34, 32]. More applications of temporal graphs and the sources of temporal graph data can be found in surveys on temporal graphs [8, 12, 22]. None of these works study mining dense subgraph patterns in a tempo-ral graph, and the algorithms of mining dense temporal subgraph patterns are also totally different from any of the existing works.
Many different types of subgraph structures that have high den-sity have been proposed and studied for real-world network anal-ysis, including maximal cliques [7], quasi-clique [1], densest sub-graphs [9, 14], k -core [3], k -truss [31], and so on. The well-known definition of quasi-clique was introduced by Abello et al. in [1]. Similar with exact maximal cliques, the problem of enumerating quasi-cliques is NP-hard. In [20], Liu et al. proposed several effec-tive pruning rules for mining quasi-cliques. In [30], Tsourakakis et al. showed that quasi-cliques are high-quality subgraphs. Readers can refer to the survey [17] on dense subgraphs for more compre-hensive understanding. All the above discussed works are studied in non-temporal graphs.

There has been work on temporal community detection over dy-namic networks [10, 33, 19, 21] and multi-layer networks [4, 6]. These work first identify communities in a static network, then identify the evolution of the communities from the changes of the network. To our knowledge, our work is the first one for mining quasi-cliques in a temporal graph, which can be seen as a multi-layer network or the whole history of a dynamic network.
We proposed the problem of mining the top k diversified tempo-ral subgraph patterns in a temporal graph, and presented a complete search algorithm and a quick search algorithm with effective prun-ing techniques and search strategies. Our experimental results show that our algorithms are orders of magnitude faster than a baseline algorithm and obtain high-quality results.
 Acknowledgments. We thank the reviewers for their valuable com-ments. The authors are supported by the Hong Kong GRF 2150851 and 415013, and the Key Projects of Fundamental Research Pro-gram of Shanghai Municipal Commission of Science and Tech-nology under grant No. 14JC1400300. The project is funded by Research Committee of CUHK.
