
Many data-mining applications deal with privacy-sensitive data. Financial transac-tions, health-care records, and network co mmunication traffic are some examples.
Data mining in such privacy-sensitive domains is facing growing concerns. Therefore, we need to develop data-mining techniques that are sensitive to the privacy issue.
This has fostered the development of a class of data-mining algorithms (Agrawal and Srikant 2000; Kantarcioglu and Clifton 2002) that try to extract the data pat-terns without directly accessing the origi nal data and guarantees that the mining process does not get sufficient information to reconstruct the original data.
This paper considers a class of techniques for privacy-preserving data mining by randomly perturbing the data while preser ving the underlying probabilistic proper-ties. It explores the random-value perturbation-based approach (Agrawal and Srikant 2000), a well-known technique for masking the data using random noise. This ap-proach tries to preserve data privacy by adding random noise, while making sure that the random noise still preserves the signal from the data so that the patterns can still be accurately estimated. This p aper questions the privacy-p reserving capability of the random-value perturbation-based approach. It shows that, in many cases, the original turbed data using a spectral filter that exploits some theoretical properties of random matrices. It presents the theoretical foundation and provides experimental results to support this claim.

Section 2 offers an overview of the related literature on Privacy-preserving data mining. Section 3 presents the motivation behind the framework presented in this paper. Section 4 describes the random-data perturbation method proposed in Agrawal and Srikant (2000). Section 5 presents a discussion on the eigenvalues of random matrices that builds the foundation of the technique proposed here to compromise the privacy protection introduced by the random-value perturbation-based approach.
Section 6 presents the int uition behind the theory to separate out random compon-ent from a mixture of nonrandom and random components. Section 7 describes the proposed random matrix-based filtering technique to extract the original dataset. Sec-tion 8 applies the proposed technique and reports its performance for various data sets. Finally, Sect. 9 concludes this paper and outlines future research directions.
There exists a growing body of literature on privacy-sensitive data mining. These al-gorithms can be divided into two different groups. One approach adopts a distributed framework; the other approach adds random noise to the data in such a way that the individual data values are distorted while s till preserving the underlying distribution properties at a macroscopic level. The follo wing part of this section briefly discusses these two approaches.

The distributed approach supports computation of data-mining models and ex-traction of patterns at a given node by ex changing only the minimal necessary in-formation among the participating nodes without transmitting the raw data. The field of distributed data mining (Kargupta et al. 2000; Park and Kargupta 2002) produced several distributed algorithms that are sensitive to privacy. For example, the meta-learning-based JAM system (Stolfo et a l. 1997) was designed for mining multiparty distributed sensitive data such as financi al fraud detection. The Fourier spectrum-based approach to represent and construct decision trees (Kargupta et al. 2001; Park et al. 2001) and the collective hierarchical clustering (Johnson and Kargupta n.d.) are examples of additional distributed data-mining algorithms that can be used with minor modifications for privacy-preserving mining from distributed data. In the re-cent past, several distributed techniques to mine multiparty data have been reported.
A privacy-preserving technique to construct decision trees (Quinlan 1986) proposed elsewhere (Lindell and Pinkas 2000), multip arty secured computation framework (Du and Atallah 2001), association-rule mining from homogeneous (Kantarcioglu and
Clifton 2002) and heterogeneous (Vaidya and Clifton 2002) distributed data sets are some examples. There also exists a collection of useful privacy-sensitive data-mining primitives such as secure sum computation (Schneier 1995) and secure scalar product computation (Vaidya and Clifton 2002).
 group work by first perturbing the data using randomized techniques. The perturbed data is then used to extract the patterns and models. Ruth Brand X  X  (Brand 2002) work gives a comprehensive review on microdata protection by randomized techniques. The randomized value distortion technique for learning decision trees (Agrawal and
Srikant 2000) and association-rule learning (Evfimevski 2002) are some examples of this approach. Liew et al. (1985) suggested data distortion by probability distribu-tion, where confidential variables are rep laced with a distorted set of values derived from an estimated best-fit density function. Transformation of data using generaliza-tion and suppression to hide sensitive information is suggested by Iyengar (2002).
Additional work on randomized masking of data can be found elsewhere (Traub et al. 1984).
 by adding random noise to the data set in order to hide the individual data values of different attributes. It points out that, in many cases, the noise can be separated from the perturbed data by studying the spectral properties of the data and, as a result, its privacy can be seriously compromised. Agrawal and Aggawal (2001) consider the approach in Agrawal and Srikant (2000) and provide an expectation-maximization (EM) algorithm for reconstructing the distribution of the original data from perturbed observations. They also provide information theoretic measures (mutual information) to quantify the amount of privacy provided by a randomization approach. Agrawal and Aggawal (2001) remark that the method suggested in Agrawal and Srikant (2000) does not take into account the distribution of the original data (which could be used to guess the data value to a higher level of accuracy). However, Agrawal and Ag-gawal (2001) provides no explicit procedure to reconstruct the original data values.
Evfimevski et al. (2002, 2003) and Rizvi and Haritsa (2002) have also considered the approach in Agrawal and Srikant (2000) in the context of association-rule mining and suggest techniques for limiting privacy breaches. Randomization approach may not be a reliable technique to preserve priv acy in all cases. Security analysis of this random-data perturbation technique can be found at Muralidhar and Sarathy (1999).
Our primary contribution is to provide an explicit filtering procedure, based on ran-dom matrix theory, that can be used to estimate the original data values. Before presenting the technique to do that, let us review the randomized value distortion (Agrawal and Srikant 2000) technique in detail.
As noted in the previous section, a growing body of privacy-preserving data-mining techniques are adopting randomization as a primary tool to hide information. While randomization is an important tool, it must be used very carefully in a privacy-preserving application.

Randomness may not necessarily imply uncertainty. Random events can often be analyzed and their properties can be explained using probabilistic frameworks.
Statistics, randomized computation and many other related fields are full of theorems, laws and algorithms that rely on probabilis tic characterization of random processes that often work quite accurately. The signal-processing literature (Manolakis et al. 2000) offers many filters to remove white noise from data and they often work reasonably well. Randomly generated structu res like graphs demonstrate interesting properties (Janson et al. 2000). In short, randomness does seem to have structure, and this structure may be used to compromise privacy issues unless we pay careful attention.
 For example, consider the three-dimensional data set shown in Fig. 1 (top left).
The data is nonrandom. Figure 1 (Top right) shows a randomly generated data set in the same space with uniform distribution. Figure 1 (bottom middle) shows the perturbed version of the data shown in Fig. 1 (top left) after we add the random noise to it. Figures 1 (top left) and (bottom middle) look apparently very differ-ent and it may create the perception of privacy protection. However, this may be illusive.

The larger sphere is a unit sphere. Smaller s pheres represent the different eigen-sociated eigenvector. The magnitude of the vector is the corresponding eigenvalue.
Figure 2 (bottom) shows the spectral properties of the pure random noise. Note that the eigenvalues of the random noise are all close to 1. This did not happen by chance.
In fact, eigenvalues of random noise have some properties that are responsible for this behavior. One can prove that all eigenvalues of a noise matrix with unit variance converges to 1 asymptotically. As we see, the eigenvalues of the randomly generated data are very close to the surface of the unit sphere, whereas the nonrandom data have eigenvalues that are away from the surface. Although, this distinction is not some conditions, we may be able to separate the eigenstates of the original sensitive data and the noise using a spectral analysis of the perturbed privacy-protected data. offer challenges to the designers of privacy-preserving data-mining algorithms that use randomization as a tool to hide the sensitive data.

The rest of this paper illustrates this challenge in the context of a well-known privacy-preserving technique that works using random additive noise. The following section first explains this random-value perturbation approach.
For the sake of completeness, we now briefly review the random-data perturbation method suggested in Agrawal and Srikant (2000) for hiding the data (i.e. guarantee-ing protection against the reconstruction of the data) while still being able to estimate the underlying distribution. We also discuss the procedure for reconstructing the ori-ginal density function, as suggested in Agrawal and Srikant (2000).
The random-value perturbation method attempts to preserve privacy of the data by modifying values of the sensitive attributes using a randomized process (Agrawal and Srikant 2000). The authors explore two possible approaches X  X alue X  X lass mem-bership and value distortion X  X nd emphasize the value distortion approach. In this approach, the owner of a dataset returns a value u data and v is a random value drawn from a certain distribution. Most commonly used distributions are the uniform distribution over an interval sian distribution with mean  X  = 0 and standard deviation values u 1 , u 2 ,..., u n are viewed as realizations of n independent and identically dis-tributed (i.i.d.) random variables U i , i = 1 , 2 ,..., n , each with the same distribution as that of a random variable U . In order to perturb the data, n independent samples, v ,v perturbed values u 1 + v 1 , u 2 + v 2 ,..., u n + v n and the cumulative distribution function F ( r ) of V . The reconstruction problem is to estimate the distribution F original data from the perturbed data.
The authors (Agrawal and Srikant 2000) suggest the following method to estimate the distribution F U ( u ) of U ,given n independent samples w and F V (v) . Using Bayes X  rule, the posterior distribution function F that U + V = w , can be written as which, upon differentiation with respect to u , yields the density function where f U (.) , f V (.) denote the probability density function of U and V , respectively.
If we have n independent samples u i + v i = w i , i = 1 posterior distribution can be obtained by averaging,
For a sufficiently large number of samples n , we expect the above density function to be close to the real density function f U ( u ) f ( u ) is unknown, we need to modify the right-hand side of Equation (1). The authors suggest an iterative procedure where at each step, j density f j  X  1 U ( u ) estimated at step j  X  1 is used in the right-hand side of Equation (1).
The uniform density is used to initialize the iterations. The iterations are carried out until the difference between successive es timates becomes small. In order to speed up computations, the authors also discuss approximations to the above procedure using partitioning of the domain of data values.
The random perturbation technique apparently distorts the sensitive attribute values and still allows estimation of the underlying distribution information. However, does this apparent distortion fundamentally prohi bit us from extracting the hidden informa-tion? In this section, we explore this question. We use a particular filtering technique that is designed based on properties of random matrices. This section presents a dis-cussion on the properties of random matri ces and presents some results that will be used later in this paper.
 often exploited in high-energy physics (Mehta 1991), signal processing (Silverstein and Combettes 1992) and even data mining (Kargupta et al. 2002). The random noise added to the data can be viewed as a random matrix and therefore its properties can be understood by studying the properties of random matrices. In this paper, we shall develop a spectral filter designed based on random matrix theory for extracting the hidden data from the data perturbed by random noise. Our filtering approach is based on the observation that the distribution of eigenvalues of random matrices (Mehta 1991) exhibit some well-known characteristics. The rest of this section discusses some of the important spectral properties of random matrices.
 given probability laws. The theory of random matrices deals with the statistical prop-erties of the eigenvalues of such matrices. Eigenvalues of random matrices offer many interesting properties. For example, Wigner X  X  semicircle law (Wigner 1952), which says if V is an n  X  n matrix and has i.i.d. entries with zero mean and unit variance, the distribution of eigenvalues of V + V
In this paper, we are mainly concerned about distribution of eigenvalues of the sample covariance matrix obtained from a random matrix. Let V be a random m matrix, the entries of which are V ij , i = 1 ,..., m , j variables with 0 mean and variance  X  2 . The covariance matrix of X is given by
Y of Y .Let be the empirical cumulative distribution function (c.d.f.) of the eigenvalues i  X  n ) ,where is the unit step function. In order to consider the asymptotic properties of the c.d.f.
F ( x ) , we will consider the dimensions m = m ( N ) and n be functions of a variable N . We will consider asymptotics such that, in the limit as
N  X  X  X  ,wehave m ( N )  X  X  X  , n ( N )  X  X  X  and m ( N ) these assumptions, it can be shown that (Jonsson 1982) the empirical c.d.f. F converges in probability to a continuous distribution function F probability density function (p.d.f.) of which is given by where  X  min and  X  max are as follows:
Further refinements of this result and other discussions can be found in Silver-stein and Combettes (1992), Grenander and Silverstein (1977), Marcenko and Pastur (1967), Bai et al. (1988), Geman (1980), Yin et al. (1988) and Silverstein (1989).
Consider an m  X  n data matrix U and a noise matrix V with the same dimensions. The random-value perturbation technique generates a modified data matrix U
Our objective is to extract U from U p . Although the noise matrix V may introduce seemingly significan t difference between U and U p , it may not be successful in hiding the data.
 tify the noise component of the perturbed data matrix U allows us to do exactly that.

Now note that, when the signal random vector (rows of U ) and noise random vector (rows of V ) are uncorrelated, we have E [ U T V ]= E assumption is valid in pr actice because the noise V that is added to the data U is generated by a statistically independent process. Recall that the random-value per-turbation technique discussed in the previous section introduces uncorrelated noise we have that U T V  X  0and V T U  X  0. Equation (4) can now be simplified as follows: Because the correlation matrices U T U , U T p U p and V T semidefinite, let where Q u , Q p , Q v are orthogonal matrices for which the column vectors are eigen-vectors of U T U , U T p U p , V T V , respectively, and with the corresponding eigenvalues on their diagonals.
 tionship between  X  u ,  X  v and  X  p .
Theorem 1 (Weyl 1949). Suppose  X  1 ,( a )  X   X  2 ,( a ) the eigenvalues of U T U , U T p U p and V T V , respectively. Then, for i
This theorem provides a bound on the change in the eigenvalues of the data corre-lation matrix U T U in terms of the minimum and maximum eigenvalues of the noise correlation matrix V T V . Now let us take a step further and explore the properties of the eigenvalues of the perturbed data matrix U p
Lemma 1. Let data matrix U and noise matrix V be of size m
Let Q u , Q p , Q v be orthogonal matrices and  X  u ,  X  defined in Equation (6). If m / n  X  X  X  ,then  X  p =  X  X  u  X  T Proof. Using Equations (5) and (6), we can write
Let the minimum and maximum eigenvalues of V be  X  min ,(v) tively. It follows from Equations (2) and (3) that, as m / in
 X  v become identi cal because lim (say). This implies that, as m / n  X  X  X  ,  X  v  X   X  2 I ,where I is the n tity matrix. Therefore, if the number of observations m is large enough (note that, in practice, number of features n is fixed), V T V = Therefore, any orthogonal matrix Q = Q v could serve as an eigenvector matrix for V V =  X  2 I . If we choose Q v = Q p , Equation (7) becomes
If the norm of the perturbation matrix V is small, the eigenvectors Q would be close to the eigenvectors Q T u Q u of U T U . Indeed, matrix perturbation theory provides precise bounds on the angle between ei genvectors (and invariant subspaces) of a matrix U and that of its perturbation U p = U + V , in terms of the norms of the perturbation matrix V . For example, let ( x u , X  u ) for matrix U T U and = V T V 2 =  X  max ( V T V ) be the two-norm of the perturba-tion, where  X  max ( V T V ) is the largest singular value of V eigenvalue X  X igenvector pair ( x p , X  p ) of U T p U p satisfying (Weyl 1949; Stewart 1973) where  X  is the distance between  X  u and the closest eigenvalue of U &lt; X  . This shows that the eigenvalues of U T U and U T small perturbations. Moreover, where x  X  is the conjugate-transpose of x . Consequently, the product is the matrix of inner products between the eigenvectors of U close to an identity matrix; i.e.  X  = Q T p Q u  X  I . Thus, Equation (8) becomes  X  ,( u )  X   X  X  X   X   X  k ,( u ) , with  X  i ,( u )  X  for some small value and i
This condition is true for many real-world signals. Suppose signal and noise eigenvalues  X  u ,  X  v from the eigenvalues by a simple thresholding at  X  1 ,(v) .
 design a filter based on this approximation to filter out the perturbation from the data.
Experimental results presented in the following sections indicate that this provides a good recovery of the data in many cases.
This section describes the proposed filter for extracting the original data from the noisy perturbed data. Suppose actual data U is perturbed by a randomly generated noise matrix V in order to produce U p = U + V .Let u p , be m (perturbed) data points, each being a vector of n features.
 turbed data U p . Using the distribution of eigenvalues of the covariance matrix and the theory of random matrices, the covariance matrix of U noise and the signal parts. The eigenstates corresponding to the signal part are then used to reconstruct the actual data. This can be done by simply projecting the data along the signal eigenvectors and then mapping it back to the original space. explore the case where the distribution F V (v) of the random noise V (including the variance) is known, as required by the random-value perturbation scheme (Agrawal and Srikant 2000). Next, we discuss how the noise variance can be estimated from the eigenvalue distribution of the perturbed data. The reader should note that the random-value perturbation scheme provides information about the noise distribution.
So estimation of the noise variance is not necessary. We explored that case in order to develop a broader understanding about the performance of the proposed filtering technique.
When the noise distribution F V (v) of V is completely known (as required by the random-value perturbation technique (Agrawal and Srikant 2000)), the noise vari-to calculate  X  max and  X  min , which provide the theoretical bounds of the eigenval-ues corresponding to noise matrix V . From the perturbed data, we compute the eigenvalues of its covariance Matrix, Y ,say  X  1  X   X  2 tify the noisy eigenstates  X  i  X   X  i + 1  X   X  X  X   X   X  j such that  X  max . The remaining eigenstates are the eigenstates corresponding to actual data. Let
 X  = diag (  X  ues and A v be the matrix the columns of which are the corresponding eigenvectors.
Similarly, let  X  u be the eigenvalue matrix for the actual data part and A corresponding eigenvector matrix, which is an n  X  k matrix ( k matrices, we decompose the covariance matrix Y into two parts, Y
Y = Y random noise part and Y s = A u  X  u A T u is the covariance matrix corresponding to the actual data part. An estimate  X  U of the actual data U is obtained by projecting the data
U onto the subspace spanned by the columns of A u .Inotherwords,
Using random matrix theory as described in Sect. 5, the spectral-filtering technique can even be extended to estimate the actual data when the noise variance known. For this, the noise variance is estimated first using the perturbed data and that estimated noise variance is then used to filte r the perturbed data. In order to estimate the noise variance,  X  2 , we first compute the eigenvalues of the covariance matrix Y of the perturbed data W . A histogram of the eigenvalue distribution is plotted and compared with that of the theoretical noise eigenvalue density function, f in Equation (2). Note that the density function, f Q ( x )
Typically, the theoretical density function f Q ( x ) the histogram of the computed eigenvalues, corresponding to small eigenvalues. The larger eigenvalues that do not fit this theoretical density function correspond to the actual information part of the perturbed data. An iterative procedure is employed to obtain the value of  X  that results in the best fit of f Q
In this section, we present results of our experiments with the proposed spectral filtering technique. We have compared the performance of our filtering technique with two other common filters used in the literature. This section also includes dis-method. We tested our privacy-breaching technique usin g several datasets of different sizes.
We considered both artificially generated and real data sets. Toward that end, we generated a dataset with 35 features and 300 instances. Each feature has a specific trend, like sinusoidal, square or triangular shape. The actual dataset is perturbed by adding Gaussian noise (with 0 mean and known variance), and our proposed tech-shows the result of our spectral filtering for one such feature where the actual data has a sinusoidal trend. The filtering technique appears to provide a close estimate of the individual values of the actual data. Figure 5 (bottom) shows the distribu-noise eigenvalues and the theoretical bounds  X  max and  X  min method accurately distinguishes between noi sy eigenvalues and eigenvalues corres-ponding to actual data. Note that the estimated eigenvalues of actual data are very close to eigenvalues of actual data and almost overlap with them above eigenvalues of actual data below  X  min are practically negligible. Thus, the estimated eigenvalues of the actual data capture most of the information and discard the ad-ditive noise.
 with a single feature, i.e when the dataset is a single-column vector. The data vector is perturbed with a noise vector with the same dimension. The perturbed data vector is then split into a fixed number of vectors with equal length and all of these vectors are appended to form a matrix. The spectral-filtering technique is then applied to this are concatenated to form a single vector.
 spectral filtering. The dataset used is th e scaled amplitude of the waveform of an audio tune recorded using a fixed sampling frequency. The tune recorded is fairly noise free with 10,000 sample points. We perturbed this data with additive Gaussian noise.
 of noise added to actual data to perturb it: of 1.3. We split this vector of perturbed d ata into 40 columns , each containing 250 points and applied the spectral-filtering technique to recover the actual data. The result is shown in Fig. 6. For the sake of clarity, only a fraction of dataset is shown approximation of the actual data. The estim ation performance is similar to that for multifeatured data (see Fig. 5 (Top)).
The proposed spectral-filtering technique can estimate values of individual data points from the perturbed dataset. This pointwise estimation can then be used to reconstruct the distribution of actual data as well. The methods suggested by Agrawal and Srikant (2000) and Agrawal and Aggawal (2001) can only reconstruct the distribution of the original data from the data perturbed by random-value distortion; but it does not consider estimation of the individual values of the data points. The spectral-filtering technique, on the other hand, is explicitly designed to reconstruct the individual data points and, hence, also the distribution of the actual dataset.
 our method to recover the triangular distribution. We used a vector data of 10,000 values from a triangular distribution as shown in Fig. 2 in Agrawal and Srikant (2000). The individual values of actual data are between 0 and 1. The dataset was generated by dividing the interval [ 0 , 1 ] into a number of subintervals and gener-ating a proportionate number of samples, uni formly distributed in each subinterval.
The subintervals were sorted, although the s amples inside each subinterval were not sorted. This introduces correlations between the columns when the vector data was split into 50 columns (see description below). We added Gaussian noise with mean 0 and standard deviation  X  = 0 . 25 to this data and split the data vector into 50 columns, each having 200 values. We then applied our spectral filter to recover the actual data from the perturbed data. Figure 7 shows a portion of the actual data, their values after distortion, and their estimated values. Note that the estimated values are very close to the actual values compared with the perturbed values. Using the es-
Figure 8 (Top) shows estimation of the distribution from the estimated value of in-dividual data points. The distribution of the perturbed data is very different than the actual triangular distribution, but the estimated distribution looks very similar to tual data for the whole dataset (10,000 points). The estimation error remains within  X  0 . 25 in this experiment. These results show that our method recovers the original reported in Agrawal and Srikant (2000). Agrawal and Srikant (2000) claim that pri-vacy is preserved by random perturbation b ecause their method can reconstruct only the distribution of actual data from the perturbed version, while spectral filtering questioning reliability of the randomized da ta perturbation technique as a privacy-preserving tool.
The spectral-filtering technique considered in this paper is certainly not the only filter that can be used to remove noise. In this section, we report the relative performance of the spectral technique with respect to a few other existing filters.
We compared the performance of the pr oposed spectral-filtering technique with two other well-known noise filtering techniques, viz. Moving-average filtering and
Wiener filtering (Papoulis and Pillai 2002). These two techniques are well known and widely used in signal processing to filter out noise. A moving average (MA) filter simply computes the average of the perturbed data over a window of fixed size, centered around each data point, whereas the Wiener filter uses information about the power spectral density (equivalently, autocorrelation) of the data and noise. We applied MA, Wiener, and spectral filter on the same dataset perturbed with random noise, and in most cases we observed that spectral filtering performs better than the MA and Wiener filters. Figure 9 compar es the performance of spectral filtering higher than that of the MA filter for the given dataset, which has a square trend in its values. The window size used in this experiment is 10. Figure 10 shows the comparison with respect to the Wiener filter. Clearly, for the given dataset, spectral filter does a better job compared with the Wiener filter. In this section, we compare the performance of our spectral-filtering technique with
PCA-based filtering. We also analyze the effect of batch number ( Q in Equation (2)) on the estimation error and report experiments run in batch mode.

PCA is a traditional statistical technique based on eigenanalysis of data. In this method, the sample covariance matrix of the data is calculated and its eigenstates are evaluated. Then principal eigenvalues are separated out that capture 90% and 75% of overall eigenvalues. The corresponding principal eigenvectors are used to obtain an estimation of the observed dat a as we do in our spectral filtering. and 20,000 observations. We started with first 100 observations in a batch, and kept adding 100 more observations in each run o f the experiment so that the ratio Q m / n , with m being the number of observations obtained up to the current batch, increases from 1. Experimental results for 20 batches at SNR
Fig. 11. The top figure shows the error in the estimated covariance matrix compared with the true data covariance matrix, as a function of batch number using spectral-filtering technique, traditional PCA-based method with eigenvectors capturing 90% and 75% of the total variance and a simple moving-average filter with the window size 100. The bottom figure depicts the mean-square error in estimated data for all of these filtering methods as a function of batch number. Note that, after 6 or 7 batches, filtering errors reduce to relatively stable values. From the figure, it is clear that our spectral filter provides the best noise filtering in terms of mean squared error.
Quality of the data recovery depends on the relative noise content in the perturbed data. We use the SNR (see Equation (10)) to quantify the relative amount of noise added to actual data to perturb it. As the noi se added to the actual value increases, the
SNR decreases. Our experiments show that the proposed filtering method predicts the actual data reasonably well up to a SNR value of 1.0 (i.e. 100% noise). The results shown in Fig. 5 (top) correspond to an SNR value nearly 2, i.e. noise content is about 50%. Figure 7 shows a data block where the SNR is 1 goes below 1, the estimation becomes too erroneous. Figure 12 (top) shows the difference in estimation accuracy as th e SNR increases from 1. The dataset used here has a sinusoidal trend in its values. The top graph corresponds to 23% noise (SNR = 4.3), whereas the bottom graph corresponds to 100% noise (SNR
Figure 12 (bottom) shows the variation of estimation error with SNR. As the SNR value decreases, mean error in estim ation shows an increasing trend. is the inherent noise in the actual dataset (apart from the perturbation noise added intentionally). If the actual dataset has a random component in it and random noise is added to perturb it, the spectral-filtering method does not filter the actual data ac-curately. Our experiments with some inherently noisy real-life datasets show that the eigenvalues of signal and noise no l onger remains clearly separable because the their eigenvalues may not be distributed over two nonoverlapping regimes any longer.
 sence of any random component in the actual data, Equation (9) holds closely, giving an accurate estimate of the actual data. Howe ver, the accuracy deteriorates when the original data set contains random noise in itself.
 as well as a real-world dataset containing a random component. Figure 13 (top) shows that our method gives a close estimation of actual data when the dataset has a specific trend (sinusoid) and SNR of the perturbed data is 1 our method to ionosphere data available fro m (Repository n.d.), which is inherently noisy. We perturbed the original data with random noise such that mean SNR is the same as the artificial dataset, i.e. 1 . 1. Figure 13 (bottom) shows that recovery quality is poor compared with datasets having definite trends.

However, this opens a different question: Is the random component of the original data set really important as far as data mining is concerned? One may argue that most data-mining techniques exploit only the nonrandom structured patterns of the data. Therefore, losing the inherent ra ndom component of the original data may not be important in a privacy-preserving data-mining application.
Spectral-filtering techniques can be extende d to estimate actual datasets even when distribution of noise added to perturb the actual dataset is not known. In such cases, we can use the random matrix theory described in Sect. 5 to estimate the noise vari-ance first. From the eigenvalues of the cova riance matrix of actual data, a histogram of the eigenvalue distribution is obtained, and this is compared with the best pos-sible theoretical density function given by Equation (2). The variance corresponding to the best fit gives the estimation of the noise variance.
 from the best-fit curve several times. In each trial, the variance e stimation algorithm starts with a very small variance value near 0, creates the theoretically generated distribution and measures the mean-square error between it and the histogram of eigenvalues of the actual data. It then in creases variance by a small value, again computes the mean square error and compares it with the previous error to get the minimum error and corresponding variance. The algorithm performs the op-eration up to a threshold value of variance, and stores the variance correspond-ing to minimum mean-square error between theoretically generated density func-tion curve and histogram of eigenvalues o f actual data. That value of variance is periment, we used 100 such trials for each variance estimation. After the set of estimates are calculated from all trials, t he distribution of estimated variances is checked for outliers. The mean,  X  1 , and standard deviation, are calculated, and values lying outside the regime depicted by defined threshold value of variance, it st ores that threshold value of variance as the estimation. These values are also treated as outliers at the end and are dis-carded.

After discarding the outlier estimations, a n average of the rest of the estimates are taken to get the actual estimate of noise variance. We have noticed that discarding the outliers and taking the average of the remaining number of estimates improves the estimation accuracy to a large extent . Once the noise variance is estimated, the same technique is applied as before to estimate the original data. Figure 14 (top) shows the estimation of actual data having 300 values and a sawtooth trend with
SNR value of 4.25 when distribution of noise is not known. The average over 100 estimates of noise variance after discarding the outliers gave an estimated variance of 0.83452, where the actual noise varian ce is 0.85. Although not all the estimates are always so close, on an average, the dif ference between the estimated variance and true variance remains within 10% of the actual variance in all our experiments.
Figure 14 (bottom) shows the corresponding distribution of eigenvalues of actual data, estimated noise and estimated data.
Preserving privacy in data-mining activities is a very important issue in many appli-cations. Randomization-based techniques are likely to play an important role in this domain. However, this paper illustrates some of the challenges that these techniques face in preserving the data privacy. It shows that, under certain conditions, it is rela-tively easy to breach the privacy protection offered by the random perturbation-based techniques. It provides extensive experimental results with different types of data and concern, the paper makes several other cont ributions that are discussed later in this section.
 matrix. The covariance matrix is a diagonal matrix when the data columns are com-pletely uncorrelated. This paper presented some experimental results using univariate data ( m  X  1 dimensional matrix) where the cova riance matrix is computed from the multidimensional data ( m k  X  k -dimensional matrix) where a column corresponds to one of the k consecutive subsequences with m k entries. If the observations in this uni-variate data are mutually independent, then there will be no correlation between the virtual attributes associated with the different columns. Clearly, the technique does not work when the features are independent of each other. However, a univariate data set with independent observations defines only a small fraction of the common data-mining applications. We are not claiming that the technique will work for every for the privacy-preserving technique.
 ratio (SNR). The method seems to work reasonably well with a good deal of relative noise added for preserving privacy. Our experiments show that, as long as the SNR is greater than 1 (i.e relative noise c ontent does not exceed 100% of actual data value), the method works well for the data sets considered in this paper. based privacy-preserving data mining does not specify the specific SNR values for the experiments. However, all the data values they used appear to be within to + 1 . 5. They added Gaussian noise with variance 0 report the signal-to-noise ratio, we estimated the average SNR value to be approxi-mately 2.2. Clearly, this is greater than an SNR value of 1 and therefore the level of filtering technique presented here.
 data for preserving data privacy. Therefore, it will filter out both the artificially added and the inherent random noise components. Therefore, in some cases, the estimated data may look different from the original data because the inherent noise compon-ent is taken out. However, one can argue that the inherent random component of miners apply many data preprocessing techniques just for filtering out the underly-patterns that may actually turn out to be the most relevant information as far as pri-vacy preservation and data mining are concerned. The utility of the filtered inherent noise component fundamenta lly depends on the definition of privacy in the given application.

The analysis presented in Sect. 6 makes several assumptions. We list those ex-plicitly in the following for further clarifying the technique: 1. The original data U and the perturbation V are statistically independent (actu-ally a weaker uncorrelatedness assumption would suffice). This is the same as the assumptions made in most random additive noise-based techniques for privacy-preserving data mining. Use of correlated noise is also likely to make the pattern detection (e.g. distribution estimation, association rules) process more difficult.
Our conjecture is that there may be a no-free-lunch-style theorem at large re-garding this. 2. The eigenvectors of the covariance matrix U T p U p of the perturbed data are orth-ogonal to the eigenvectors of the covariance matrix U We have addressed this in our discussion following the proof of Lemma 1.
The matrix perturbation theory provides bounds on the angle between the eigen-vectors of a matrix and that of a perturbation of the same matrix. These bounds can be used to quantify the orthogonality in terms of the norm of the perturbation matrix V T V . These bounds have also been provided in our discussion following
Lemma 1. We have determined this assumption to hold true in the experiments reported in this paper. 3. We assume that the asymptotic expressions for  X  sufficiently large, but finite, sample sizes . This is true for typical data sizes (both number of features and number of observations) encountered in data mining. In-deed, one of the useful features of the random matrix theory is that the asymp-totics are derived in the limit as both the rows M (number of observations) and columns N (number of features) go to infinity, and for any ratio Q
Therefore, the asymptotic expressions are valid for a value of M that is compa-rable with that of N . In other words, we do not require the number of observa-tions to go to infinity for a fixed number of features. A relatively small number of observations (as a function of the number of features) is usually sufficient to get good estimates. This is true for most realistic datasets encountered in data mining. 4. The range of eigenvalues of the original data (signal) matrix and those of noise do not overlap. This assumption is also tru e for most real-lif e data sets, where the signal matrix in the eigenvalue/eig envector domain is usually characterized by a small number of dominant eigenvalues. Indeed, in many interesting appli-cations, the top few eigenvalues account for more than 90% of the total signal energy (that is why principal-component analysis is so effective and popular!). It is true that there certainly may exist ex amples of signals (real-life or contrived) for which a significant portion of its eigenvalues lie in the interval the eigenvalues of a random matrix. However, that does not invalidate the main claim of our paper that perturbation by additive noise may not preserve a whole lot of privacy in many cases. If a privacy-preserving technique does not work wider application in developing a new perspective toward developing better privacy-preserving data-mining algorithms. For example, we may be able to use this frame-work to develop algorithms that explicitly guard against potential compromise on privacy through linear transformations. The current privacy-preserving data-mining algorithms do not pay adequate attention to this issue.
 random matrix-based approach to separating the information bearing and noisy eigen-states also has potential computational a dvantages. Indeed, because the upper bound  X  max of the noisy eigenvalues is known a priori, one can easily use a suitable numer-ical technique (e.g. power method (Jackson 1991)) to compute just the few largest eigenvalues. Once these eigenvalues and corresponding eigenvectors are computed, one can obtain the actual data part of the cova riance matrix, which can be subtracted from the total covariance to isolate the noise part of the covariance. white noise for privacy preservation, we should explore colored noise for this applica-tion. We have already started exploring multiplicative noise matrices in this context.
If U bethedatamatrixand V be an appropriately sized random noise matrix, then we are interested in the properties of the perturbed data U p data-mining applications. If V is a square matrix, then we may be able to extract signal using techniques like independent component analysis (Ham et al. 1999). How-ever, projection matrices that satisfy certain conditions may be more appealing for such applications. More details about th is possibility can be found elsewhere (Liu et al. 2003).

