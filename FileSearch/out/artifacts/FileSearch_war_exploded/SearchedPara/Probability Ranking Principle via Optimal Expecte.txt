 This paper presents a new pers pective of the probability ranking principle (PRP) by defining retrieva l effectiveness in terms of our novel expected rank measure of a set of documents for a particular query. This perspective is based on preserving decision preferences, and it imposes weaker conditions on PRP than the utility-theoretic perspective of PRP. H.3.0 [ Information Storage and Retrieval ]: General.
 Measurement, Performance, Experimentation. Probability ranking principle and optimization. The probability ranking principle (PRP) [1] (formalized by Cooper) has been the basis for a number of probabilistic retrieval models (e.g., [2]). Its s hortened form in [3] is: Gordon and Lenk [4] found that PRP optimizes utility under the following conditions: Later, they [5] articulated in de tails the conditions when the PRP is suboptimal in a utility theoretic sense. We propose that PRP is optimal in terms of the expecta tion value of ranking (called the expected rank), and the conditions for achieving optimal utility can be relaxed or changed completely. We have no preference for or against defining effectiveness by utility, because this depends on the specific applications. The significance of this work is that PRP can be applied to a wider c hoice of models and applications than [4] alone, where the optimality of PRP can be defined as in [4] or by the optimal expected rank as in here. Let us define the event space [6] as ( ) ) ( U card the cardinality of its argument. We hypothesize that the inquirers decide whether each document is relevant to query q . The document d to be relevant to q , where r signifies relevance. When presentation clarity, we assume that there is more than one inquirer in the rest of this paper. Following [7], the relevance judgment of an inquirer is expressed as a decision preference using the strict preference relation, inquirer prefers document d over document e on the basis of the degree of relevance for topic q . We define the expected rank, E ( D , q ), of the set, D , of documents as a measure of the system X  X  effectiveness as follows: where rank (.) returns a rank numbe r based on some ranking strategy using the given probability. We assume that at least one Otherwise, recall, R-preci sion and MAP are undefined. The ranking strategy that has the be st retrieval effectiveness is the one with the smallest expected rank value. The problem of finding the optimal ranking is solved by mapping it to an analogous problem called card(D) /1// F scheduling problem [8] that is solved by the shortest processing time rule, where: (i) d maps to a particular job, (ii) the probability of d maps to the processing time the job is counted, and (iv) the expected rank maps to the total flow time of the schedule. Table 1 shows an example where d d have processing time 0.2, 0.3 and 0.1, respectively. F total flow time of the k -th job, e.g. F 3 = 0.1 + 0.2 + 0.3 = 0.6, and rank P (.) is a function that assigns a rank number by decreasing probability. The optimal scheduling strategy turns out to be a greedy algorithm that ranks docum ents by decreasing probability. This is the same strategy as prescribed by PRP, and the proof-by-contradiction of this well-known optimal strategy is in [8]. Relating (1) to PRP, we need to rewrite the probability, p ( d | q , r ), using the conditional probability definition as follows: probability, p ( d , q ), is a constant: because each inquirer judges the relevance of each document to each query. For ranking, the probability in (3) is ignored, and (2) equivalence relation [9]. Using (1 ), the optimal expected rank is: This is the ranking prescribed by PRP that is optimal given that (3) holds. Taking the average requires condition (c) to hold. The strategy is optimal on average with respect to U , so the counter-example by Cooper (mentioned in [1]) is not applicable. The optimal expected rank meas ures the average amount of search effort of U because the rank number represents the amount of effort to read the ranked documents from the top. This average rank combines both recall and precision measures because it is defined for all documents in the collection. It is similar to the expected search length (ESL) [10] but it differs from ESL in the treatment of documents with tied ranks. In practice, we assume that we have a set of accurate probabilities { p ( d | q , r )} and a set of probabilities { p estimated by the system. Since (3) can be determined without inaccuracies, the expected rank of the system, s , is: where the rank number is derived from the system X  X  probability of relevance, and where the probability of document for the expected rank is based on the proportion of inquirers who assign d as relevant to q . Since ranking is a weak order, (4) and (5) are equal when the following holds for all document pairs, d and e , in D : Note that (6) is weaker than condition (a) and condition (b). We also do not need condition (d) since we do not optimize utility, although (d) is a more general c ondition than assigning constant utility value to all documents. This paper presents a new perspective of PRP in terms of optimizing the expected rank over a collection of documents. It does not require the probability to be reported with certainty nor well-calibrated, provided that (3), (6) and condition (c) hold, as well as the condition that every query for evaluation has at least one relevant document. Since (5 ) needs the assigned rank and not p (.), p s (.) may not necessarily be defined over  X  for p consistent with PRP. This work is supported by CERG project # PolyU 5226/05E. [1] Robertson, S.E. The probability ranking principle in IR. [2] Robertson, S.E., Sparck Jones, K. Relevance weighting of [3] Sparck Jones, K., Walker, S., Robertson, S.E. A probabilistic [4] Gordon, M., Lenk, P. A utility theoretic examination of the [5] Gordon, M., Lenk, P. When is the probability ranking [6] Robertson, S.E. On event spaces and probabilistic models in [7] Yao, Y.Y., Wong, S.K.M. Pref erence structure, inference [8] French, S. Sequencing and scheduling: an introduction to the [9] Lafferty, J., Zhai, C. Document language models, query [10] Cooper, W.S. Expected search length: a single measure of 
