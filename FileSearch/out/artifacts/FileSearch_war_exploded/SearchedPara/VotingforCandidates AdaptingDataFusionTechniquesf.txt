 In an exp ert searc h task, the users' need is to iden tify peo-ple who have relev ant exp ertise to a topic of interest. An exp ert searc h system predicts and ranks the exp ertise of a set of candidate persons with resp ect to the users' query . In this pap er, we prop ose a novel approac h for predicting and ranking candidate exp ertise with resp ect to a query . We see the problem of ranking exp erts as a voting problem, whic h we mo del by adapting elev en data fusion techniques.
We investigate the e ectiv eness of the voting approac h and the asso ciated data fusion techniques across a range of documen t weigh ting mo dels, in the con text of the TREC 2005 Enterprise trac k. The evaluation results sho w that the voting paradigm is very e ectiv e, without using any collec-tion speci c heuristics. Moreo ver, we sho w that impro ving the qualit y of the underlying documen t represen tation can signi can tly impro ve the retriev al performance of the data fusion techniques on an exp ert searc h task. In particular, we demonstrate that applying eld-based weigh ting mo dels im-pro ves the ranking of candidates. Finally , we demonstrate that the relativ e performance of the adapted data fusion techniques for the prop osed approac h is stable regardless of the used weigh ting mo dels.
 H.3.3 [ Information Storage and Retriev al ]: Information Searc h and Retriev al| search process ; H.3.4 [ Information Storage and Retriev al ]: Systems and soft ware| User pro-les and alert servic es Exp erimen tation, Measuremen t Voting, Exp ert Finding, Exp ertise Mo delling, Exp ert Searc h Information Retriev al, Ranking, Data fusion
With the adv ent of the vast pools of information and doc-umen ts in large enterprise organisations, collab orativ e users regularly have the need to nd not only documen ts, but also people with whom they share common interests, or who have speci c kno wledge in a required area.

Mertzum &amp; Pejtersen [11] found that engineers in pro duct-dev elopmen t organisations often intert wine looking for infor-mativ e documen ts with looking for informed people. People are a critical source of information because they can explain and pro vide argumen ts about why speci c decisions were made.

Yimam-Seid &amp; Kobsa [36] iden ti ed ve scenarios when people may seek an exp ert as a source of information to complemen t other sources: 1. Access to non-do cumente d information -e.g. in an 2. Speci c ation need -the user is unable to form ulate a 3. Lever aging on another's expertise (group eciency) -4. Interpr etation need -e.g. deriving the implications of, 5. Socialisation need -the user may prefer that the hu-
An expert search system is an Information Retriev al (IR) system that can aid users with their \exp ertise need" in the above scenarios. In con trast with classical documen t retriev al where documen ts are retriev ed, an exp ert searc h system supp orts users in iden tifying informed people: The user form ulates a query to represen t their topic of interest to the system; the system then ranks candidate persons with resp ect to their predicted exp ertise about the query , using available documen tary evidence.

The retriev al performance of an exp ert searc h system is an imp ortan t issue. An exp ert searc h system should aim to rank candidate exp erts while maximising the traditional evaluation measures in IR: precision , the accuracy of sug-gested candidates exp ertise; and recall , the num ber of can-didates with relev ant exp ertise retriev ed.
The creation of the exp ert searc h task in the recen t TREC 2005 Enterprise trac k [6] has increased interest in this area. An activ e researc h problem is how best to generate a rank-ing of candidates from a collection of documen ts. Systems typically use a pro le of evidence for eac h candidate that indicates their exp ertise. These pro les can be generated man ually by the candidate, or automatically by the system using documen tary evidence.

In this pap er, we consider a ranking of documents with resp ect to the exp ert searc h query . We see eac h documen t retriev ed as an implicit vote for the candidate whose pro le con tains that documen t. We prop ose sev eral ways to aggre-gate documen t votes into a ranking of candidates, based on appropriate data fusion techniques.

The techniques are evaluated across a range of probabilis-tic weigh ting mo dels, using the TREC W3C test collection and the TREC 2005 Enterprise exp ert searc h task. The ob-tained results sho w that applying the voting approac h to ex-pert searc h is very e ectiv e compared with the TREC 2005 results, while making no use of collection-sp eci c heuristics.
In order to impro ve the underlying ranking of documen ts, we further re ne the represen tation of documen ts used by the retriev al system, to tak e the structure of documen ts into accoun t. We use con ten t, title and anc hor text of incoming hyperlinks as separate elds during retriev al. Eac h docu-men t is represen ted by these elds. We demonstrate that ap-plying a weigh ting mo del that uses these elds signi can tly impro ves the performance of the prop osed voting approac h.
The structure of this pap er is as follo ws: We give an overview of exp ert searc h systems and previous related work in Section 2. In Section 3, we describ e how exp ert searc h can be mo delled as a voting problem. We prop ose the use of data fusion techniques to con vert documen t rankings into candidate rankings, and presen t the data fusion techniques adapted. We describ e our exp erimen tal setup in Section 4, and evaluate the voting approac h across a selection of doc-umen t weigh ting mo dels in Section 5. In Section 6, we use eld-based weigh ting mo dels in an exp ert searc h con text, and sho w how this signi can tly impro ves the performance of the exp ert searc h data fusion techniques adapted for the approac h. In Section 7, we demonstrate that the perfor-mance of the adapted data fusion techniques is stable across various weigh ting mo dels and settings. Finally , we pro vide concluding remarks and suggestions for future work in Sec-tion 8.
Exp ert searc h systems mak e use of textual evidence of exp ertise to rank candidates. Predominan tly, these systems work by generating a pro le of textual evidence for eac h candidate. The pro les represen t the system's kno wledge of the exp ertise of eac h candidate, and they are rank ed in resp onse to a user query [7, 9, 15, 34].

There are two requiremen ts for an exp ert searc h system: a list of candidate persons that can be retriev ed by the system, and some textual evidence of the exp ertise of eac h candi-date to include in their pro le. In most Enterprise settings, a sta list is available and this list de nes the candidate persons that can be retriev ed by the system. Candidate pro les can be created either explicitly or implicitly: can-didates may explicitly update their pro le with an abstract or list of their skills and exp ertise [9]; or alternativ ely, the exp ert searc h system can implicitly and automatically gen-erate eac h pro le from a corpus of documen ts. There are sev eral strategies for asso ciating documen ts to candidates, to generate a pro le of their exp ertise:
Having de ned pro les of exp ertise for eac h candidate, an exp ert searc h system needs to accurately rank the candi-date pro les in resp onse to a user query . There is some pre-vious work on ranking candidate pro les for exp ert searc h. Crasw ell et al. prop osed concatenating the terms of all docu-men ts in eac h pro le into \virtual documen ts", and ranking these using a traditional IR system [7].

Liu et al. [15] addressed the exp ert searc h problem in the con text of a comm unit y-based question-answ ering service. They applied three di eren t language mo dels, and exp eri-men ted with varying the size of the candidate pro les. They concluded that retriev al performance can be enhanced by in-cluding more evidence in the pro les.

Social net work analysis also features in some related work to exp ert searc h. Graph-based techniques are used to infer connections between candidates, and are particularly useful on corp ora of email comm unications [8, 20, 34]. Tw o ap-proac hes mak e use of the HITS algorithm [13] to calculate \repute" and \resourcefulness" scores for eac h candidate [5, 35]. In [21], McLean et al. use a graph structure to propa-gate exp ertise evidence between mem bers of a pro ject team. Finally , various exp ert searc h approac hes were prop osed by participan ts in the TREC 2005 Enterprise trac k [6], and techniques suc h as documen t structure and clustering were applied.

In this work, we consider a di eren t and novel approac h to ranking exp ertise. In particular, we consider that exp ert searc h is a voting pro cess. Using the rank ed list of retriev ed documen ts for the exp ert searc h query , we prop ose that the ranking of candidates can be mo delled as a voting pro cess using the retriev ed documen t ranking and the set of doc-umen ts in eac h candidate pro le. The problem is how to aggregate the votes for eac h candidate so as to pro duce the nal ranking of exp erts. In Section 3, we sho w how exist-ing data fusion techniques can be appropriately adapted to com bining votes for candidates.
Data fusion techniques -also kno wn as metasearc h tech-niques -are used to com bine separate rankings of documen ts into a single ranking, with the aim of impro ving over the per-formance of any constituen t ranking. Eac h time a documen t is retriev ed by a ranking, an implicit vote has been made for that documen t to be included higher in the com bined rank-ing. Fox &amp; Sha w [10] de ned sev eral data fusion techniques Figure 1: A simple example from exp ert searc h: the ranking R ( Q ) of documen ts (eac h with a rank and a score), must be transformed into a ranking of candi-dates using the documen tary evidence in the pro le of eac h candidate ( prof ile ( C ) ). (Com bSUM, Com bMNZ, etc.), and these have been the ob-ject of much researc h since. (For examples, see [14, 23, 33]).
Tw o main classes of data fusion techniques exist: those that com bine rankings using the ranks of the retriev ed doc-umen ts, and those that com bine rankings using the scores of the retriev ed documen ts.

As introduced in Section 2, we see exp ert searc h as a vot-ing problem: In this work, the pro le of eac h candidate is a set of documen ts asso ciated to them to represen t their ex-pertise. We then consider a ranking of documents by an IR system with resp ect to the query . Eac h documen t retriev ed by the IR system that is asso ciated with the pro le of a candidate, can be seen as an implicit vote for that candi-date to have relev ant exp ertise to the query . The ranking of the candidate pro les can then be determined from the votes. In this work, we choose to adapt well-kno wn data fu-sion techniques in IR, to aggregate the votes for candidates by the retriev ed documen ts.
 Let R ( Q ) be the set of documen ts retriev ed for query Q , and the set of documen ts belonging to the pro le of candidate C be denoted prof ile ( C ). In exp ert searc h, we need to nd a ranking of candidates, given R ( Q ). Con-sider the simple example in Figure 1 above. The ranking of documen ts with resp ect to the query has retriev ed docu-men ts f D b ; D c ; D a ; D d g . Using the candidate pro les, can-didate C 1 has then accum ulated 2 votes, C 2 2 votes, C 3 votes and C 4 no votes. Hence, if all votes are coun ted as equal, and eac h documen t in a candidate's pro le is equally weigh ted, a possible ranking of candidates to this query could be f C 3 ; C 1 ; C 2 g . By using appropriate vote aggre-gation techniques, we can have di eren t rankings of candi-dates. In the remainder of this pap er, we introduce elev en adapted data fusion techniques, and evaluate them to estab-lish how well they mo del the prop osed voting paradigm.
We determine the score of the candidate with resp ect to the query , scor e cand ( C; Q ), as the aggregation of votes of all documen ts d that are retriev ed, but whic h also belong to the pro le of the candidate (i.e. d 2 R ( Q ) \ prof ile ( C )). We consider three forms of evidence when aggregating the votes to eac h candidate: (i) the num ber of retriev ed documen ts voting for eac h candidate; (ii) the scores of the retriev ed documen ts voting for eac h candidate; and (iii) the ranks of the retriev ed documen ts voting for eac h candidate. We adapt data fusion techniques to aggregate the votes from the single ranking of documen ts into a ranking of candi-dates, using the appropriate forms of evidence. We examine and evaluate elev en data fusion techniques as they can be adapted to exp ert searc h.

Notice, however, in the normal application of data fusion techniques, sev eral ranking of documen ts are com bined into a single ranking of documen ts. In con trast, our novel ap-proac h aggregates votes from a single ranking of documen ts into a single ranking of candidates, using the documen t-to-candidate asso ciations of the candidate pro les.
We now sho w how some established data fusion techniques can be adapted for exp ert searc h. Firstly , we adapt the Re-cipro cal Rank (RR) data fusion technique [39] for exp ert searc h. In this data fusion technique, the rank of a docu-men t in the com bined ranking is determined by the sum of the recipro cal rank receiv ed by the documen t in eac h of the individual rankings. Adapting the Recipro cal Rank tech-nique to our approac h, we de ne the score of a candidate's exp ertise as: where rank d is the rank of documen t d in the documen t ranking R(Q). RR is an example of a rank aggregation data fusion technique.

In Com bSUM [10] -a score aggregation technique -the score of a documen t is the sum of the normalised scores re-ceiv ed by the documen t in eac h individual ranking. Com b-SUM can also be used in exp ert searc h. In this case, the score of a candidate's exp ertise is: scor e cand CombS UM ( C; Q ) = X where scor e d is the score of the documen t d in the documen t ranking R ( Q ). Similarly , Com bMNZ [10] can be adapted for exp ert searc h: where k R ( Q ) \ prof ile ( C ) k is the num ber of documen ts from the pro le of candidate C that are in the ranking R ( Q ).
Normally , in the Com bSUM and Com bMNZ data fusion techniques, it is necessary to normalise the scores of docu-men ts across all the rankings [23]. However, in Equations (2) and (3), no score normalisation is necessary: Indeed, in our case, as stressed above, only one ranking of documen ts is involved, and hence the scores are all comparable.
Table 1 summarises all the data fusion techniques that we adapt and evaluate in this work. In addition to the three techniques describ ed above, we also adapt and evalu-ate: a technique that we call Votes, whic h simply coun ts the num ber of retriev ed documen ts of eac h candidate pro le; BordaF use [4] -a rank aggregation technique; and sev eral Table 1: Summary of exp ert searc h data fusion tech-niques used in this pap er. D ( C; Q ) is the set of doc-umen ts R ( Q ) \ prof ile ( C ) . k k is the size of the describ ed set. other score aggregation techniques rst de ned by Fox &amp; Sha w in [10]. The nal three adapted data fusion techniques listed in the table, namely expCom bSUM, expCom bANZ and expCom bMNZ, are sligh t varian ts of Com bSUM, Com-bANZ and Com bMNZ resp ectiv ely. In these varian ts, the score of eac h documen t is transformed by applying the ex-ponen tial function ( e scor e ), as suggested by Ogilvie &amp; Callan in [25]. Applying the exp onen tial function boosts the scores of highly rank ed documen ts.

Other data fusion techniques could also have been consid-ered in this work, including one based on Condorcet voting-theory [24], a technique that mo dels score distributions [19], and a logical regression mo del [32]. However, in this work, due to the more complex nature of these techniques, we fo-cus the evaluation of our prop osed voting approac h on the techniques in Table 1.
In the follo wing, we aim to demonstrate that voting is an e ectiv e approac h for exp ert searc h and that the data fu-sion techniques adapted are suitable to implemen t the pro-posed approac h. We use three di eren t statistical documen t weigh ting mo dels to assess the exten t to whic h the perfor-mance of the adapted data fusion techniques is a ected by the choice of weigh ting mo del.

To evaluate our approac h, we use the Exp ert Searc h task of the TREC 2005 Enterprise trac k. The TREC 2005 Enter-prise test collection consists of 331,037 documen ts collected from the World Wide Web Consortium (W3C) website in 2005 [6]. For researc h purp oses, the W3C is a useful exam-ple of an enterprise organisation, as it operates almost en-tirely over the Internet. Moreo ver, its documen ts are freely available online. This allo ws researc h on an enterprise-lev el corpus, without the intellectual prop erty issues normally as-sociated with obtaining suc h a corpus. The corpus is also wide-ranging, con taining the main W3C Web presence, per-sonal homepages, standards documen ts, email discussion list archiv es, a wiki, and a source code rep ository .
The W3C test collection includes a list of 1,092 candidate exp erts. We use the 50 topics from the TREC 2005 Exp ert Searc h task. The retriev al performance is evaluated using Mean Average Precision (MAP) -to assess the overall qual-ity of the ranking -and Precision @ 10 (P@10), to assess the accuracy of the top-rank ed candidates retriev ed by the system.

We index the W3C collection using Terrier [26, 27]. Dur-ing indexing, eac h documen t is represen ted by its textual con ten t and the anc hor text of its incoming hyperlinks. Stop-words are remo ved, and as we would like to favour high precision, we use a weak stemming algorithm, whic h only applies the rst two steps of Porter's stemming algorithm.
To generate the pro le for eac h candidate, we generate queries to iden tify documen ts in whic h variations of eac h candidate's name or email address occur in the entire col-lection. The set of documen ts iden ti ed for eac h candidate C form their prof ile ( C ).

We test our prop osed voting approac h using the elev en adapted data fusion techniques listed in Table 1 with three statistically di eren t documen t weigh ting mo dels. The rst of these weigh ting mo dels is the well-established BM25 [31], where the relev ance score of a documen t d for a query Q is given by: where qtf is the frequency of the query term t in the query; k 1 and k 3 are parameters, for whic h the default setting is k = 1 : 2 and k 3 = 1000 [30]; w (1) is the idf factor, whic h is given by: N is the num ber of documen ts in the whole collection. N is the documen t frequency of term t .

The normalised term frequency tf n is given by: where tf is the term frequency of the term t in documen t d . b is the term frequency normalisation hyper-parameter, for whic h the default setting is b = 0 : 75 [30]. l is the doc-umen t length and avg l is the average documen t length in the collection.
 The remaining two weigh ting mo dels tested are from the Div ergence from Randomness (DFR) framew ork [1]. The rst of these, PL2, is robust and performs particularly well for tasks requiring high early-precision [28]. For the PL2 mo del, the relev ance score of a documen t d for a query Q is given by: scor e ( d; Q ) = X where is the mean and variance of a Poisson distribution. It is given by = F=N . F is the frequency of the query term in the collection and N is the num ber of documen ts in the whole collection. The query term weigh t qtw is given by qtf =qtf max . qtf is the query term frequency . qtf max is the maxim um query term frequency among the query terms.
The normalised term frequency tf n is given by the so-called Normalisation 2 from the DFR framew ork: where tf is the term frequency of the term t in documen t d and l is the length of the documen t. avg l is the average documen t length in the whole collection. c is the hyper-parameter that con trols the normalisation applied to the term frequency with resp ect to the documen t length. The default value is c = 1 : 0 [1].

The DLH13 documen t weigh ting mo del is a generalisation of the parameter-free hypergeometric DFR mo del in a bino-mial case [2, 16]. The hypergeometric mo del assumes that the documen t is a sample, and the population is from the collection. For the DLH13 documen t weigh ting mo del, the relev ance score of a documen t d for a query Q is given by: Note that the DLH13 weigh ting mo del has no term fre-quency normalisation comp onen t, as this is assumed to be inheren t to the mo del. Hence, DLH13 has no parameters that require tuning. Indeed, all variables are automatically computed from the collection and query statistics.
The BM25 and PL2 documen t weigh ting mo dels include parameters, and require tuning using relev ance assessmen ts. In our exp erimen ts, we assess the performance of the data fusion techniques, both using the default parameter settings for eac h weigh ting mo del, and when, for eac h fusion tech-nique, the parameters of the weigh ting mo del have been em-pirically set to maximise MAP . This allo ws assessmen t of the maxim um poten tial in the prop osed approac h. Note again that the DLH13 mo del has no parameters that need to be tuned, and therefore is deplo yed directly in the exp ert searc h task.
Table 2 sho ws the retriev al performance of the prop osed voting approac h, using the elev en adapted data fusion tech-niques, across three weigh ting mo dels, namely BM25, PL2, and DLH13 1 . In these results, the default setting is used for BM25 and PL2 (see Section 4). Table 3 sho ws the retriev al performance when the term frequency hyper-parameters of the weigh ting mo dels are empirically set, to enable the as-sessmen t of the maxim um poten tial of eac h com bination of the adapted data fusion techniques and the weigh ting mo dels. In this table, the e ectiv eness of the data fusion techniques has impro ved. The relativ e performance of eac h data fusion technique remains roughly consisten t across all weigh ting mo dels in both settings.

Examining Tables 2 and 3 in detail, we mak e the follo w-ing observ ations. Firstly , the Votes technique, whic h simply coun ts the num ber of documen t votes for eac h candidate, sho ws good performance (MAP 0.1650). The rank-based techniques, RR and BordaF use, both perform well across the three weigh ting mo dels. Note the good performance of RR on P@10 in both used settings. RR highly scores candidate pro les that have documen ts occurring at the very top of the ranking, suggesting that the highly rank ed documen ts con tribute more to the exp ertise of a candidate, and should be considered as stronger votes. In con trast, the BordaF use technique assigns linearly scaled votes across the documen t ranking to candidates, without emphasising the strength of
Equiv alen t exp erimen ts performed using full Porter stem-ming sho wed little di erences to the results in Table 2. votes by top rank ed documen ts, whic h sligh tly hinders the retriev al performance compared to RR.

On the other hand, the score-based data fusion techniques have varying e ectiv eness, dep ending on the technique used. Com bSUM and Com bMNZ and their exp onen tial varian ts are the strongest of the score-based techniques. These both tak e into accoun t the strength of the documen t votes, i.e. the magnitude of the score for eac h retriev ed documen t of the candidate's pro le. Moreo ver, Com bMNZ adds a second comp onen t, the num ber of votes for eac h candidate, explain-ing its sligh t overall performance edge over Com bSUM. The good e ectiv eness of these techniques mirrors previous stud-ies of their use in classical data fusion [22, 23]. The high performance of the exp onen tial varian ts of Com b-SUM and Com bMNZ, expCom bSUM and expCom bMNZ, can be explained in that the exp onen tial function increases the scores of the highly-scored documen ts more than the low-scored documen ts, increasing the strength of their votes. Hence a candidate with man y weak votes will be lower rank ed, while a candidate with few er stronger votes will be higher rank ed. In terms of MAP , expCom bSUM and expCom bMNZ outp erform all other techniques across all weigh ting mo dels and settings. Moreo ver, expCom bMNZ alw ays outp erforms expCom bSUM on MAP when the parameters have been em-pirically set. However, expCom bSUM gives better P@10 (e.g. 0.3720 vs. 0.3520 and 0.3260 vs. 0.3220 in Table 3). Com bMAX almost performs as well as Com bSUM and Com bMNZ, even though it does not tak e into accoun t the num ber of votes for a candidate pro le. This sho ws that the most highly rank ed documen t for eac h candidate is still a good indicator of its exp ertise.

The Com bANZ, Com bMIN, and expCom bANZ techniques do not perform well, because they focus too much on the low scoring documen ts of eac h pro le, whic h, intuitiv ely, are not good indicators of exp ertise. Interestingly , taking the me-dian of the scored documen ts in a pro le (Com bMED) out-performs taking the average (Com bANZ). This nding is in-consisten t with previous exp erimen ts using these techniques for classical data fusion [10]. A possible interpretation is that the denominator comp onen t of Com bANZ impairs the evidence in the distribution of the candidate scores.
Tables 2 and 3 also presen t the statistical signi cance of results, when compared to the median run of all participan ts of TREC 2005 (MAP 0.1402), using the Wilco xon Matc hed-Pairs Signed-Rank test 2 . Most of the adapted data fusion techniques lead to a clear increase in performance over this median run. In particular, applying expCom bSUM or ex-pCom bMNZ alw ays results in a statistically signi can t in-crease in MAP from the baseline.

From the results, we can surmise that good indicators of exp ertise of a candidate seem to be the num ber of documen ts in the candidate's pro le retriev ed for a query (num ber of votes), and the relativ e magnitude of the retriev al scores in the candidate's pro le (strength of votes). The strongly performing Com bMNZ and expCom bMNZ techniques exem-plify both these indicators.

Overall, we have sho wn that the prop osed voting approac h using adapted data fusion techniques can be e ectiv ely ap-plied to exp ert searc h, Indeed, the best performing runs in Table 2 would rank as high as the top three participan ts in TREC 2005 Enterprise trac k runs, without using any
We do not have access to the P@10 of the median run. (+25%) 0.3120 0.1792 &gt; (+28%) 0.3380 (+30%) 0.3220 0.1873 (+34%) 0.3440 weigh ting mo del is highligh ted in bold.
 tuning. collection-sp eci c heuristics, nor any parameter tuning. In addition, these techniques are low-cost, and are easy to de-ploy in an operational enterprise setting.

In the next section, we will sho w that we can signi can tly impro ve on the performance of the prop osed approac h by impro ving the qualit y of the underlying documen t ranking.
The qualit y of the underlying documen t ranking returned by the IR system in resp onse to the exp ert searc h query is imp ortan t to the success of the prop osed voting approac h. If the qualit y of the documen t ranking is impro ved, then the ranking of candidates will also likely impro ve.

Exp erimen ts in the Web and Enterprise trac k have sho wn that when the structure of documen ts ( elds) is tak en into accoun t by a retriev al system, then the retriev al performance can be impro ved [16, 38]. For example, a Web documen t can be represen ted by three elds: the body, the title, and the anc hor text of its incoming hyperlinks. Rob ertson et al. [29] sho wed impro ved retriev al e ectiv eness in Web tasks when the con tribution of eac h eld to the documen t ranking was con trolled by the use of weigh ts. We hypothesise that the retriev al performance of our prop osed voting approac h for exp ert searc h could be impro ved if the qualit y of the un-derlying documen t ranking is increased. In this section, we use eld-based documen t weigh ting mo dels that accoun t for the documen t structure to impro ve the qualit y of documen t ranking, and assess the e ect on the prop osed voting ap-proac h for exp ert searc h.

In the previous section, the best performing adapted data fusion techniques used BM25 and PL2 in an empirical set-ting (see Table 3). In the remainder of this section, we use variations of these two mo dels that tak e elds into accoun t. Next, we apply these mo dels in our voting approac h for ex-pert searc h.
The BM25 weigh ting mo del can be extended into a eld-based documen t weigh ting mo del, BM25F [38], by replacing Equation (5) with: Table 4: The num ber of tok ens (#tok ens) &amp; average documen t length (avg l) of eac h eld of the W3C collection. where tf f is the term frequency of term t in eld f of doc-umen t d , l f is the length of eld f in d , and avg l f average length of documen ts in f . The normalisation ap-plied to terms from eld f can be con trolled by the eld hyper-parameter, b f , while the con tribution of the eld is con trolled by the weigh t w f .

Similarly , we can extend the PL2 documen t weigh ting mo del to handle elds. The so-called Normalisation 2 (Equa-tion (7)) is replaced with Normalisation 2F [16, 18], so that the normalised term frequency tf n corresp onds to the weigh ted sum of the normalised term frequencies tf f for eac h used eld f : tf n = X where c f is a hyper-parameter for eac h eld con trolling the term frequency normalisation, and the con tribution of the eld is con trolled by the weigh t w f . Having de ned Normal-isation 2F, the PL2 mo del (Equation (6)) can be extended to PL2F by using Normalisation 2F.

In the follo wing exp erimen ts, we index the body, anc hor text and titles of documen ts as separate elds using Terrier. Table 4 sho ws the breakdo wn of the statistics of eac h eld on the W3C collection. As in Section 4, we remo ve stop words and apply the rst two steps of Porter's stemming algorithm. We again use the 50 exp ert searc h task topics from TREC 2005 Enterprise trac k.

We follo w [38] to optimise the involved hyper-parameter values and the eld weigh ts as follo ws. Firstly , for eac h data fusion technique, the hyper-parameter for eac h eld is tuned using a sim ulated annealing. During this, the w of that eld is set to 1, and the weigh ts of the other elds are set to 0. Once good hyper-parameter values have been found, a 3-dimensional sim ulated annealing is used to nd the optimal w f values. Con trary to Zaragoza et al. in [38] who assumed that the body eld should have a weigh t of 1, we do not assume any constrain ts on the weigh ts of any elds.
Table 5 sho ws the retriev al performance of the prop osed voting approac h using the elev en adapted data fusion tech-niques, and the BM25F and PL2F eld-based weigh ting mo dels. From the obtained results, we can see that the use of elds has led to a mark ed impro vemen t in e ectiv e-ness compared to Table 3, for both MAP and P@10. In particular, for a large num ber of cases, there is a statisti-cally signi can t impro vemen t over the corresp onding entry in Table 3. For example, expCom bMNZ sho ws a MAP of 0.2254 for BM25F, compared to only 0.2044 for BM25 -a statistically signi can t impro vemen t of 10%. The relativ e performance of the data fusion techniques remains mostly consisten t with the previous exp erimen ts.

A further insp ection of the results sho ws that while BM25F has higher e ectiv eness, the average relativ e impro vemen t in MAP of BM25F compared to BM25 and PL2F compared to PL2 are iden tical (both +13%). Notice that for the weigh t-ing scheme PL2F, the average impro vemen t in P@10 was clearly more mark ed than for BM25F (+17% vs. +1%), even though both weigh ting mo dels were tuned for MAP .
By introducing elds into the underlying documen t rank-ing technique, we are able to rank highly more documen ts that are good indicators of exp ertise for the query . This increased qualit y of the documen t ranking leads to an in-creased performance by the prop osed voting approac h, using all data fusion techniques evaluated. The obtained results are in the top three most e ectiv e techniques rep orted in [6], while not using any collection-dep enden t means, suc h as fo-cusing on the pages con taining man y of the answ ers. This is very encouraging, as our approac h could be extended to in-clude other factors, suc h as documen t and candidate priors, degree of asso ciation between documen ts and pro les etc. Our voting approac h is general, and can easily be applied in an enterprise setting indep enden t of the collection and its structure.
Our voting approac h relies on the adapted data fusion techniques to pro vide a suitable aggregation of candidate votes. In this section, we test the robustness and stabilit y of the adapted data fusion techniques used in the prop osed approac h, across the sev en weigh ting schemes and settings applied in Tables 2, 3 and 5. Using MAP as the evaluation measure, for eac h weigh ting mo del, we order the adapted data fusion techniques from the best to the worst perform-ing. For example, from Table 5, the ordering for BM25F has expCom bMNZ as the best and Com bANZ as the worst data fusion technique.

Figure 2 sho ws the performance of eac h adapted data fu-sion technique across all weigh ting schemes and settings. From the gure, we can observ e that the lines joining the performance of eac h fusion technique on the di eren t weigh t-ing mo dels are mostly parallel. This suggests that the rel-ativ e performance of the data fusion techniques is stable, since their ordering remains unc hanged regardless of the used weigh ting mo del.

To chec k that the data fusion techniques are indeed stable, we can use a statistical concordance measure. Kendall's W of concordance [12] measures the concordance of n items over a set of m rankings. W is in the range W 2 [0,1], where W = 1 are iden tical rankings, and W = 0 are completely disagreeing rankings. We use Kendall's W to measure the concordance of the sev en rankings of the elev en adapted data fusion techniques. The calculated value W = 0 : 9603 is very close to complete concordance. Moreo ver, using Table 8 in [12], we see that this value is signi can t at p &lt; = 0 : 01.
Hence we can see that there is a statistically signi can t concordance between the rankings of the data fusion tech-niques, sho wing that the relativ e performance of the vari-denoted . ous adapted data fusion techniques are indeed very stable, regardless of the weigh ting mo del used. Although we can-not predict the absolute performance of eac h adapted data fusion technique on an arbitrary weigh ting mo del, we can conclude that some data fusion techniques are alw ays more likely to perform better than others. These are the ones whic h mo del the imp ortan t sources of exp ertise evidence, as surmised in Section 5.
In this pap er, we prop osed that exp ert searc h can be seen as a voting problem, where documen ts vote for the candi-dates with relev ant exp ertise. We adapted elev en data fusion techniques to our prop osed approac h. Three statistically dif-feren t documen t weigh ting mo dels were tested, to assess the e ectiv eness and stabilit y of the data fusion techniques in our approac h. The evaluation was conducted in the con text of the exp ert searc h task of the TREC 2005 Enterprise trac k.
The results sho w that our prop osed approac h is e ec-tive when using appropriate adapted data fusion techniques. While the techniques have varying degrees of performance, some of them consisten tly outp erform others, regardless of the applied documen t weigh ting mo del. The most successful techniques usually integrate the most highly rank ed docu-men ts of the pro le (strong votes), and the num ber of re-triev ed documen ts from the pro le (num ber of votes). Our exp erimen tal results also suggest that the qualit y of the un-derlying ranking of documen ts is imp ortan t in enhancing the retriev al performance of the exp ert searc h system. Indeed, we sho wed that a recen t Web IR technique -i.e. the use of elds to represen t the documen t structure -constan tly leads to mark ed performance impro vemen ts, whic h are very often signi can t.

We also demonstrate that the relativ e performance of the data fusion techniques is stable across the various weigh t-ing mo dels and settings applied. Indeed, when the data fu-sion techniques are compared across various weigh ting mo d-els, the concordance of their relativ e performance rankings sho ws that some of the data fusion techniques are alw ays more likely to outp erform others.

The approac h prop osed in this pap er is general in the sense that it is not dep enden t on heuristics from the used en-terprise collection, and can be easily operationally deplo yed with little computational overhead. Moreo ver, we have suc-cessfully deplo yed an exp ert searc h system based on these techniques [17].

In the future, we will investigate the use of query expan-sion to enhance the underlying documen t ranking. However, query expansion has to be used with caution. Indeed, if the performance of the query is predicted to be poor, apply-ing query expansion can lead to a further degradation of retriev al performance [37].

Moreo ver, this work can be naturally extended to inte-grate prior kno wledge. For example, we believ e that not all documen ts are likely to be good indicators of exp ertise, and furthermore that not all candidates are likely to be exp erts. Designing and integrating documen t and candidate priors with our approac h could increase the retriev al e ectiv eness of the exp ert searc h system. Finally , we are keen to eval-uate our prop osed approac h on another exp ert searc h test collection. [1] G. Amati. Probabilistic Models for Information [2] G. Amati. Frequen tist and Bayesian Approac h to [3] K. Balog and M. de Rijk e. Finding exp erts and their [4] J. A. Aslam and M. Mon tague. Mo dels for [5] C. S. Campb ell, P. P. Maglio, A. Cozzi, and B. Dom. [6] N. Crasw ell, A. P. de Vries, and I. Sob oro . Overview [7] N. Crasw ell, D. Hawking, A.-M. Vercoustre, and [8] B. Dom, I. Eiron, A. Cozzi, and Y. Zhang.
 [9] S. T. Dumais and J. Nielsen. Automating the [10] E. A. Fox and J. A. Sha w. Com bination of multiple [11] M. Hertzum and A. M. Pejtersen. The [12] M. G. Kendall. Rank Corr elation Metho ds, 2nd ed . [13] J. M. Klein berg. Authoritativ e sources in a [14] J. H. Lee. Analyses of multiple evidence com bination. [15] X. Liu, W. B. Croft, and M. Koll. Finding exp erts in [16] C. Macdonald, B. He, V. Plac houras, and I. Ounis. [17] C. Macdonald and I. Ounis. Searc hing for exp ertise [18] C. Macdonald, V. Plac houras, B. He, C. Lioma, and [19] R. Manmatha, T. Rath, and F. Feng. Mo delling score [20] M. Ma ybury , R. D'Amore, and D. House. Exp ert [21] A. McLean, A.-M. Vercoustre, and M. Wu. Enterprise [22] M. Mon tague and J. A. Aslam. Metasearc h [23] M. Mon tague and J. A. Aslam. Relev ance score [24] M. Mon tague and J. A. Aslam. Condorcet fusion for [25] P. Ogilvie and J. Callan. Com bining documen t [26] I. Ounis, G. Amati, Plac houras V., B. He, [27] I. Ounis, G. Amati, Plac houras V., B. He, [28] V. Plac houras, B. He, and I. Ounis. Univ ersit y of [29] S. Rob ertson, H. Zaragoza, and M. Taylor. Simple [30] S. E. Rob ertson, S. Walker, M. Hanco ck-Beaulieu, [31] S. E. Rob ertson, S. Walker, M. Hanco ck-Beaulieu, [32] J. Savoy, A. L. Calv e, and D. Vrajitoru. Rep ort on the [33] J. A. Sha w and E. A. Fox. Com bination of multiple [34] W. Sihn and F. Heeren. Xp ert nder -Exp ert nding [35] J. Wang, Z. Chen, L. Tao, W.-Y. Ma, and L. Wenyin. [36] D. Yimam-Seid and A. Kobsa. Exp ert nding systems [37] E. Yom-T ov, S. Fine, D. Carmel, and A. Darlo w. [38] H. Zaragoza, N. Crasw ell, [39] M. Zhang, R. Song, C. Lin, S. Ma,
