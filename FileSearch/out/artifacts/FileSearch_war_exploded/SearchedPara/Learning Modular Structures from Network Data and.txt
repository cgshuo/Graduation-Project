 Elham Azizi ELHAM @ BU . EDU Bioinformatics Program, Boston University, Boston, MA 02215 USA Department of Statistics, Harvard University, Camrbdige, MA 02138 USA James E. Galagan JGALAG @ BU . EDU There is considerable interest in modeling dependency structures in a variety of applications. Examples include re-constructing regulatory relationships from gene expression data in gene networks or identifying influence structures from activity patterns such as purchases, posts, tweets, etc in social networks. Common approaches for learning dependencies include using Bayesian networks and factor analysis (Koller &amp; Friedman, 2009).
 Module networks (Segal et al., 2005; 2003) have been widely used to find structures (e.g. gene regulation) be-tween groups of nodes (e.g. genes) denoted as modules, based on measurements of node-specific variables in a net-work (e.g. gene expression). The motivation lies in that nodes that are influenced or regulated by the same par-ent node(s), have the same conditional probabilities for their variables. For example, in gene regulatory networks, groups of genes respond in concert under certain environ-mental conditions (Qi &amp; Ge, 2006) and are thus likely to be regulated by the same mechanism. In other domains, such as social networks, communities with similar inter-ests or affiliations may have similar activity in posting mes-sages (e.g. in twitter) in response to news-outbreaks or similar purchases in response to marketing advertisements (Kozinets, 1999; Aral et al., 2009).
 However, inferring dependencies merely from node-specific variables can lead to higher rate of false posi-tives (Michoel et al., 2007). For example, a dependency might be inferred between two unrelated nodes due to ex-isting confounding variables. This can introduce arbitrary or too many parents for a module. To avoid over-fitting in inferring module networks, additional structural assump-tions such as setting the maximum number of modules or maximum number of parents per module may be required. This in turn presents additional inductive bias and results become sensitive to assumptions. Moreover, searching through the entire set of candidate parents for each mod-ule is computationally infeasible.
 Alternatively, we can take advantage of existing network data and by integrating node interactions with node vari-ables, we can avoid structural assumptions. For exam-ple, to learn gene regulatory networks, we can use protein-DNA interaction data, which shows physical interactions between proteins of genes (known as Transcription Factors) with promoter regions of other genes, leading to regulation of transcription (and expression) of the latter genes. This data can be measured using chromatin immunoprecipita-tion of DNA-bound proteins, i.e. ChIP-ChIP or ChIP-Seq technologies, which have shown to be informative of regu-lation (Galagan et al., 2013; Liu et al., 2013; Celniker et al., 2009). As another example, to learn influence structures in a twitter network, we can integrate the network of who-follows-who with measurements of users activities. Identifying modules or block structures from network data has been well-studied, e.g., using stochastic blockmodels (Wang &amp; Wong, 1987; Snijders &amp; Nowicki, 1997; Airoldi et al., 2008; 2013a) in the area of social network modeling (Goldenberg et al., 2009; Azari Soufiani &amp; Airoldi, 2012; Choi et al., 2012). Stochastic blockmodels assume that nodes of a network are members of latent blocks, and de-scribe their interactions with other nodes with a parametric model. However, models for inferring modular structures from both node variables and network data are relatively unexplored and of interest in many applications. 1.1. Contributions In this paper, we propose an integrated probabilistic model inspired by module networks and stochastic blockmodels, to learn dependency structures from the combination of network data and node variables data. We consider network data in terms of directed edges (interactions) and model network data using stochastic blockmodels. Intuitively, by incorporating complementary data types, a node which is likely to have directed edges to members of a module as well as correlation with variables of module will be as-signed as parent. A shorter version of this work was pre-sented in (Azizi, 2013). The use of network data enhances computational tractability and scalability of the method by restricting the space of possible dependency structures. We also show theoretically that the integration of network data leads to model identifiability, whereas node variables alone can not, without extra structural assumptions.
 Our model captures two types of relationships between variables of modules and their parents, including small changes of variables due to global dependency structure and condition-specific large effects on variables based on parent activities in each condition.
 For estimation of parameters, we use a Gibbs sampler in-stead of the deterministic algorithm employed by Segal et al. to overcome some of the problems regarding multi-modality of model likelihood (Joshi et al., 2009). We also solve the problem of sensitivity to choice of maxi-mum number of modules using a reversible-jump MCMC method which infers the number of modules and parents based on data. The probabilistic framework infers poste-rior distributions of assignments of nodes to modules and thus does not face restrictions of non-overlapping modules (Airoldi et al., 2008; 2013b). 1.2. Related Work Other works have also proposed integrating different data types, mostly as prior information, for improvement in learning structures (Werhli &amp; Husmeier, 2007; Imoto et al., 2003; Mitra et al., 2013). It is more natural to consider additional data types also as observations from a model of dependency structures. Our model thus considers both network edges and node variables as data observed from the same underlying structure, providing more flexibility. Moreover, we utilize data integration to identify structures between groups of nodes (modules) as opposed to individ-ual nodes. Despite the similarity in the framework of our model to module networks, our model for variables has dif-ferences in relating modules to their parents, giving more accurate and interpretable dependencies. Also, the integra-tion of network data is novel. Regarding the learning proce-dure, prior work has been done on improving module net-work inference by using a Gibbs sampling approach (Joshi et al., 2009). We take a step further and use a reversible-jump MCMC procedure to learn the number of modules and parents from data as well as parameter posteriors. Our method can also allow restricting the number of modules based on context, with a narrow prior. By adjusting this prior, we have multi-resolution module detection. In the framework of module networks, dependencies are learned from profiles of node variables (e.g. gene ex-pressions) for each node (e.g. gene), as random variables { X 1 ,...,X N } . The idea is that a group of nodes with common parents (e.g. co-regulated genes) are represented as a module and have similar probability distributions for their variables conditioned on their shared parents (regula-tors). Figure 1 shows a toy example where node variable data are shown in green-to-red heatmaps and network data with dashed arrows (Airoldi, 2007). A module assignment function A maps nodes { 1 ,...,N } to K non-overlapping modules. A dependency structure function S assigns a set of parents Pa j from { 1 ,...,R } known candidate parents (possible regulators/influencers), which are a subset of the N nodes, to module M j (figure 1). In the toy example, nodes d,e are assigned to the same module M 4 and b,a are assigned as their parents. In cases where multiple par-ents drive a module, e.g. a,b affecting M 4 , combinatorial effects are represented as a decision tree (regulatory pro-gram) and each combination of parents activities, defined as a context, is assigned to a cluster of conditions (experi-ments). In figure 1, parent b has an activating effect while a represses M 4 , hence, e,d are active in context ( ii ) where only b is active and a is not. Inferring this decision tree in the context of different applications shows how multiple parents act together in influencing a group of nodes, e.g. in a gene network, multiple transcription-factors (TFs) act together to express a group of genes.
 Given this framework, our model considers variables and network data as two types of observation from the same un-derlying modular structure. This structure is encoded based on assignments to modules ( A ) and parents for each mod-ule ( S ). In the example of gene networks, in each module, TF-gene interactions are likely to be observed between TFs and upstream regions of genes in the module while combi-nations of expressions of TFs explain expressions of genes. 2.1. Modeling Node Variables We model variables for nodes { 1 ,...,N } in each condition or sample c  X  1 ,...,C with a multivariate normal repre-sented as X c  X  N (  X  c ,  X ) , where X c is a N  X  1 vector, with N being the total number of nodes. The covariance and mean capture two different aspects of the model re-garding global dependency structures and context-specific effects of parents, respectively, as described below. We define the covariance  X  to be independent of condi-tions and representing the strength of potential effects of one variable upon another, if the former is assigned as a parent of the module containing the latter. In the exam-ple of gene expressions,  X  may represent the affinity of a Transcription-Factor protein to a target gene promoter. The modular dependencies between variables imposes a struc-ture on  X  . To construct this structure, we relate node vari-ables to their parents through a regression X c = W X c + where = N ( m c ,I ) . W is a N  X  N sparse matrix in which element W nr is nonzero if variable r is assigned as a parent of the module containing variable n . Here we as-sume W nr has the same value for  X  n  X  M k ,  X  r  X  Pa k , which leads to identifiability of model (as explained in section 3. Then, assuming I  X  W is invertible, X c = ( I  X  W )  X  1 which implies  X  = ( I  X  W )  X  T ( I  X  W )  X  1 Therefore, we impose the modular dependency structure over  X  through W , which is easier to interpret based on A , S assignments.
 We define variable means  X  c , based on parents as described below. First, based on the modular structure of nodes, we can partition the mean vector as  X  c = [  X  1 c ...  X  K c ] each  X  k c for k = 1 ,...,K is a 1  X  N k vector with N k equal to the number of nodes in module k . In modules where there is more than one parent assigned, combinations of different activities of parents, creating a context, can lead to different effects. The binary state of parent r  X  Pa k defined by comparing its mean to a split-point z r k , corre-sponding to a mixture coefficient for that state  X  r Lo or  X  is a unit step function.
 The combination of different activities are represented as a decision tree for each module k (figure 1). We repre-sent a context-specific program as dependencies of variable means on parents activities in each context, such that  X  k for module k is a linear mixture of means for parents of ber of parents Pa k and  X  r c are similar for all conditions c occurring in the same context. Thus, in general we can write  X  c =  X  c  X  R c , where  X  R c contains the means of parents 1 ,...,R in condition c . The N  X  R matrix  X  c has identical rows for all variables in one module based on the assign-ment functions A , S . The graphical model is summarized in figure 2. Thus the model for object variables would be: X c  X  X  ( X  c  X  R c , ( I  X  W )  X  T ( I  X  W )  X  1 ) . Given independent conditions, the probability of data X = [ X 1 ,..., X C ] for C conditions given parameters can be written as multiplication of multivariate normal dis-tributions for each condition: P ( X |A , S ,  X  ,  X  ,Z Q c =1 P ( X c |A , S , X  c ,  X  ,Z denotes the set of condition-specific parameters  X  c {  X  R c ,  X  c } for c = 1 ,...,C and Z S denotes the set of parent split-points for all modules. Then for each condition we have: P ( X c |A , S , X  c ,  X  ,Z S Hence, this model provides interpretations for two types of influences of parents. By relating the distribution mean for variables in each module and in each condition to means of their assigned parents (figure 1.B), we model condition-specific effects of parents. Based on the states of parents in different contexts (partitions of conditions), this leads to a bias or large signal variations in node variables. Whereas, small signal changes (linear term) are modeled through the covariance matrix  X  which is independent of condition and is only affected by the global wiring imposed by depen-dency structures. 2.2. Modeling Network Data Network data, as a directed edge between a parent r  X  { 1 ,...,R } and node n  X  M k , when r is assigned as a parent of the module r  X  Pa k is defined as a directed link B r  X  n where The parameter  X  r k defines the probability of parent r influencing module M k (figure 2). In the gene network example, an interaction between a Transcrip-tion Factor protein binding to a motif sequence, up-stream of target genes, which is common in all genes of a module can be observed using ChIP data. Therefore, directed interactions from parents to all nodes in a module would be P ( B M k |A , S ,  X  Q tor of  X  r k for all r  X  Pa k and for all nodes we have: P ( B |A ,S,  X  ) = with  X  = {  X  1 ,...,  X  K } and s rk = P n  X  M sufficient statistic for the network data model and | M k the number of nodes in module k and  X  0 is the probability that any non-parent can have interaction with a module. In gene regulatory networks,  X  0 can be interpreted as basal level of physical binding that may not necessarily affect gene transcription and thus regulate a gene.
 In the context of stochastic blockmodels, the group of par-ents assigned to each module can be considered as an in-dividual block and thus our model can represented as over-lapping blocks of nodes.
 The likelihood of the model M = {A , S ,  X  ,  X  ,Z S ,  X  } given the integration of node variables and network data is: P ( X , B |M ) = P ( X |A , S ,  X  ,  X  ,Z S ) P ( B |A , S ,  X  ) . With priors for parameters M the posterior likelihood is: P ( M| X , B )  X  P ( M ) P ( X , B |M ) . Our method uses network data to avoid extra structural as-sumptions. In this section we formalize this idea through the identifiability of the proposed model. This property is important for interpretability of learned modules. Module networks and generally multivariate normal models for ob-ject variables can be un-identifiable, and imposing extra structural assumptions is necessary to overcome this. Here, we illustrate that the integrated learning proposed in this paper resolves the un-identifiability issue. First, we show that modeling node variables alone is identifiable only un-der very specific conditions. Then, we will restate some results from (Latouche et al., 2011) on the identifiability of overlapping block models. Using this result we show the identifiability of the model under some reasonable condi-tions.
 Lemma 1. Node Variables Model: For the model of node-specific variables X , if we have: P ( X |{A , S} 0 ,  X  0 P ( X |{A , S} ,  X  ,  X ) 1. Then, we can conclude:  X  0 =  X  and  X  0 =  X  . 2. If we further assume {A , S} = {A , S} 0 and that Proof presented in (Azizi et al., 2014).
 The above lemma provides identifiability for the case where the structure {A , S} is assumed to be known. How-ever, in the case where we don X  X  have the structure, the pa-rameterizations of multivariate normal (  X  and  X  ) can be written in multiple ways in terms of  X  and {A , S} . This is due to existence of multiple decompositions for the covari-ance matrix. In the following, we will use a theorem for identifiability of overlapping block models from (Latouche et al., 2011) which is an extension of the results in (Allman et al., 2009). The results provide conditions for overlapping stochastic block models to be identifiable.
 Theorem 1. Network Data Model: If we have P ( B |{A ,S } ,  X  ) = P ( B |{A ,S } 0 ,  X  0 ) , then: {A ,S } = {A ,S } 0 with a permutation and  X  =  X  0 (except in a set of parameters which have a null Lebesgue measure) (Proof direct result of Theorem 4.1 in Latouche et al. (2011) as described in Azizi et al. (2014)).
 Using the above Theorem and Lemma 1 we can have the following Theorem for the identifiability of the model. Theorem 2. Identifiability of Model: If we have: P ( B |{A ,S } ,  X  ) = P ( B |{A ,S } 0 ,  X  0 ) and P ( X |{A , S} 0 ,  X  0 ,  X  0 ) = P ( X |{A , S} ,  X  ,  X ) with as-suming that each module has at least two non-parent nodes and P k | Pa k | &lt; N and the covariance matrix  X  is invertible, then: {A ,S } = {A ,S } 0 with a permutation,  X  =  X  0 ,  X  =  X  0 and W = W 0 (except in a set of parameters which have a null Lebesgue measure) (Proof in Azizi et al. (2014)).
 This Theorem states the theoretical effect of integrated modeling on identifiability of modular structures, given that the sum of number of parents is less than the number of nodes (as is common in gene regulatory networks). We use a Gibbs sampler to obtain the posterior distribution P ( M| X , B ) and design Metropolis-Hastings samplers for each of the parameters  X  ,  X  ,  X  conditioned on the other pa-rameters and data X , B . We use Reversible-Jump MCMC (Green, 1995) for sampling from conditional distributions of the assignment and structure parameters A , S . 4.1. Learning Parameters  X  ,  X  ,Z S ,  X  .
 To update the means, we only need to sample one value for means of parents assigned to the same module. This set of means of distinct parents  X  R c are sampled with a Normal proposal (Algorithm 1). Similarly we sample the param-eters  X  r c , z r k and  X  r k , corresponding to parent r  X  Pa module k , from normal distributions. To update covariance  X  , each distinct element of the regression matrix W corre-sponding to a module k , denoted as w k , is updated. Due to the symmetric proposal distribution, the proposal is ac-The conditions required for identifiability (from Theorem 1) are enforced in each iteration. where M ( j ) = {A , S ,  X  ,  X  ,Z S  X  } ( j ) .
 Algorithm 1 RJMCMC for sampling parameters Inputs: Node Variables Data X
Network Data B for iterations j = 1 to J do end for 4.2. Learning assignments A , S .
 Learning the assignment of each node to a module, involves learning the number of modules. Changing the number of modules however, changes dimensions of the parame-ter space and therefore, densities will not be comparable. Thus, to sample from P ( A|S ,  X  ,  X  ,,Z S  X  , X , B ) , we use the Reversible-Jump MCMC method (Green, 1995), an ex-tension of the Metropolis-Hastings algorithm that allows moves between models with different dimensionality. In each proposal, we consider three close move schemes of increasing or decreasing the number of modules by one, or not changing the total number. For increasing the number of modules, a random node is moved to a new module of its own and for decreasing the number, two modules are merged. In the third case, a node is randomly moved from one module to another module, to sample its assignment (Algorithm 2 in (Azizi et al., 2014)).
 To sample from the dependency structure (assignment of parents) P ( S|A ,  X  ,  X  ,Z S  X  , X , B ) , we also implement a Reversible-Jump method, as the number of parents for each module needs to be determined. Two proposal moves are considered for S which include increasing or decreasing the number of parents for each module, by one (Algorithm 3 in (Azizi et al., 2014)). 5.1. Synthetic Data We first tested our method on synthetic node-variables and network data generated from the proposed model. A dataset was generated for N = 200 nodes in K = 4 mod-ules with C = 50 conditions for each node variable. Par-ents were assigned from a total of R = 10 number of can-didates. Parameters  X  ,  X  and W were chosen randomly, preserving parameter sharing of modules. The inference procedure was run for 20,000 samples. Exponential prior distributions were used for number of parents assigned to each module, to avoid over-fitting. Figure 3 shows the au-tocorrelation for samples of variable mean  X  n c for an ex-ample gene. The samples become independent after a lag and thus we removed the first 10 , 000 iterations as burn-in period. Samples from posteriors, including the number of modules K , exhibit standard MCMC movements around the actual value (actual K = 4 ). We also calculated the true positive rate and false positive rates based on actual dependency links. We repeated the estimation of true pos-itive and false positive rates for 100 random datasets with the same size as mentioned and computed the average ROC for the model (figure 3). As comparison, for each gener-ated dataset, we also tested the sub-model for variable data (excluding the model for network data) to infer links. We performed bootstrapping on sub-samples with size 1000 to compute variance of AUC (area under curve) and paired t-tests confirmed improved performance of integrated model compared to the variables sub-model ( p &lt; 0 . 05 ). The parameter sharing property in modular structures al-lows parallel sampling of parameters w k and  X  r ( k ) , z for each module k , in each iteration and in different con-ditions. We used Matlab-MPI for this implementation. It takes an average of 36  X  8 seconds to generate 100 samples for N = 200 , C = 50 , R = 10 on an i5 3 . 30 GHz In-tel(R). For further enhancement, module assignments were initialized by k-means clustering of variables. 5.2. M. tuberculosis Gene Regulatory Network We applied our method to identify modular structures in the Mycobacterium tuberculosis (MTB) regulatory network. MTB is the causative agent of tuberculosis disease in hu-mans and the mechanisms underlying its ability to persist inside the host are only partially known (Flynn &amp; Chan, 2001). We used interaction data identified with ChIP-Seq of 50 MTB transcription factors and expression data for different induction levels of the same factors in 87 experi-ments, from a recent study by (Galagan et al., 2013). Only bindings of factors to upstream intergenic regions were considered. We tested our method on 3072 MTB genes which had binding from at least one of these factors and performed 100,000 iterations on the combination of the two datasets. For each gene, we inferred the mode of its assign-ments to modules (after removing burn-in samples) and ob-tained 29 modules in total. The largest modules and the assigned regulators are shown in figure 4. The identified modules are enriched for functional annotations of genes (Azizi et al., 2014).
 For each module, the number of assigned genes and ex-amples of previously studied genes are presented. The identified regulators of each module and enriched annota-tions confirm known functions for some regulators, such as the role of KstR (Rv3574) in regulating lipid metabolism (Kendall et al., 2007), confirmed in modules M26 and M11; and DosR (Rv3133c) in nitrosative stress response (Voskuil et al., 2003) (module M1) and transcription (Rustad et al., 2008) (module M25). Novel functions for other regulators and the combinations of regulators acting together are also presented.
 As shown in figure 4, many modules are controlled by more than one regulator, highlighting the significance of combi-natorial regulations (see supplemantary material for inter-pretations). One inferred module is M11 shown in figure 5 which is regulated by Rv0081 and KstR (Rv3574). Rv0081 is known to be involved in hypoxic adaptation (Galagan et al., 2013) while KstR is known to be involved in choles-terol and lipid catabolism (Kendall et al., 2007) and the module is enriched for  X  X nergy production and conversion X  and  X  X ipid transport and metabolism X  COG categories (ta-ble 1 in Azizi et al. (2014)). The inferred program in figure 5 shows that either of the two regulators can repress the expression of the 48 genes assigned to this module, which include lipases and genes involved in fatty acid  X  -oxidation and triacylglycerides cycle metabolic pathways. KstR itself is also regulated by Rv0081, and thus Rv0081 regulates lipid metabolism genes through KstR. Figure 3 in supple-mantary material shows another module M25 containing 161 genes, with two hypoxic adaptation regulators mediat-ing the induction of a second hierarchy of regulators with a time delay, explaining a late hypoxic response.
 We showed in section 3 that integration of network data has theoretical advantages in terms of model identifiabil-ity. Here, we show that it can also reduce the number of false positive regulatory links in MTB data. As a gold stan-dard, we used previously validated links (by EMSA, RTq-PCR) for two MTB regulators, including 48 known links for DosR from (Voskuil et al., 2003) and 72 known links for KstR from (Kendall et al., 2007). We calculated the area under precision-recall for our method by comparing posterior probabilities for DosR and KstR links to known links (table 1). As comparison, we also applied common methods shown to have best performance in DREAM chal-lenge contests (Marbach et al., 2012) in inferring regulatory networks from gene expression only. These include Mutual Information between expression profiles (MI), CLR (Faith et al., 2007), GENIE3 (Irrthum et al., 2010). We applied these on the above MTB expression data, and compared the inferred links to the gold standard set. As the number of validated links in MTB are small, we also scored the predictions from co-expression methods to the MTB ChIP-Seq data (Galagan et al., 2013) for the same two regulators. Also, none of these methods assume modular structures. We then applied Module Networks (Segal et al., 2005) to the same expression dataset and compared predictions to known links and ChIP-Seq data (table 2). We set the maxmimum number of modules to 10 and constrained the candidate pool of regulators to the 50 ChIPped regulators only. On average 2 . 8  X  0 . 63 regulators were assigned to each module, with a mode of 3, whereas the ChIP-Seq net-work shows a mode of 1 for in-degree of genes (Galagan et al., 2013), i.e. most genes have only one regulator bind-ing. As the predicted links from module networks are de-terministic, an AUPR score can not be reported, thus we compared to precision and recall of posterior mode from our models. Note small precision values are due to small number of validated links, i.e. if a link is not validated ex-perimentally it may not be wrong. For a fair comparison of models without the effect of interaction data, we also com-pared to performance of our model for variables data only (table 2). These results show that module networks and in general co-expression methods have many false positives and integrating interaction data is necessary for inference of direct regulatory relationships.
 We proposed a model for learning dependency structures between modules, from network data and node variables data. We showed that the assumption of shared parents and parameters for nodes in a module, together with in-tegration of network data deals with under-determination and un-identifiability, improves statistical robustness and avoids over-fitting. We presented a reversible-jump in-ference procedure for learning model posterior. Our re-sults showed high performance on synthetic data and in-terpretable structures on synthetic data and real data from M. tuberculosis gene network. Results for MTB gene regulatory network revealed feed-forward loops and in-sights into condition-specific regulatory programs for lipid metabolism and hypoxic adaptation. One future direction is to propose faster algorithms based on generalized method of moments (Azari Soufiani et al., 2014; 2013; Anandku-mar et al., 2012) for estimators of this model.
 We acknowledge funding from the Hariri Institute for Computing and Computational Science &amp; Engineer-ing, the National Institute of Health under grants HHSN272200800059C and R01 GM096193, the National Science Foundation under grant IIS-1149662, the Army Research Office under grant MURI W911NF-11-1-0036, and from an Alfred P. Sloan Research Fellowship.
 Airoldi, E.M. Getting started in probabilistic graphi-cal models. PLoS Computational Biology , 3(12):e252, 2007.
 Airoldi, E.M., Blei, D.M., Fienberg, S.E., and Xing, E.P.
Mixed membership stochastic blockmodels. The Journal of Machine Learning Research , 9:1981 X 2014, 2008. Airoldi, E.M., Costa, T.B., and Chan, S.H. Stochastic blockmodel approximation of a graphon: Theory and consistent estimation. In Advances in Neural Informa-tion Processing Systems (NIPS) , volume 26, pp. 692 X  700, 2013a.
 Airoldi, E.M., Wang, X., and Lin, X. Multi-way block-models for analyzing coordinated high-dimensional re-sponses. Annals of Applied Statistics , 7(4):2431 X 2457, 2013b.
 Allman, E.S., Matias, C., and Rhodes, J.A. Identifiability of parameters in latent structure models with many ob-served variables. The Annals of Statistics , 37(6A):3099 X  3132, 2009.
 Anandkumar, A., Hsu, D., and Kakade, S.M. A method of moments for mixture models and hidden markov mod-els. arXiv:1203.0683 , 2012.
 Aral, S., Muchnik, L., and Sundararajan, A. Distinguishing influence-based contagion from homophily-driven diffu-sion in dynamic networks. Proceedings of the National Academy of Sciences , 106(51):21544 X 21549, 2009.
 Azari Soufiani, H. and Airoldi, E.M. Graphlet decomposi-tion of a weighted network. Journal of Machine Learn-ing Research , (W&amp;CP 22 (AISTATS)):54 X 63, 2012. Azari Soufiani, H., Chen, W., Parkes, D.C., and Xia, L. Generalized method-of-moments for rank aggregation.
In Advances in Neural Information Processing Systems , pp. 2706 X 2714, 2013.
 Azari Soufiani, H., Parkes, D.C., and Xia, L. Computing parametric ranking models via rank-breaking. In Pro-ceedings of The 31st International Conference on Ma-chine Learning , pp. 360 X 368, 2014.
 Azizi, E. Joint learning of modular structures from multiple data types. In NIPS Workshop of Frontiers of Network Analysis: Methods, Models, and Applications , 2013. Azizi, E., Airoldi, E.M., and Galagan, J.E. Learning mod-ular structures from network data and node variables. arXiv:1405.2566 , 2014.
 Celniker, S.E., Dillon, L., Gerstein, M.B., Gunsalus, K.C., Henikoff, S., Karpen, G.H., Kellis, M., Lai, E.C., Lieb,
J.D., MacAlpine, D.M., et al. Unlocking the secrets of the genome. Nature , 459(7249):927 X 930, 2009.
 Choi, D.S., Wolfe, P.J., and Airoldi, E.M. Stochastic block-models with a growing number of classes. Biometrika , 99(2):273 X 284, Jun. 2012.
 Faith, J.J., Hayete, B., Thaden, J.T., Mogno, I.,
Wierzbowski, J., et al. Large-scale mapping and vali-dation of escherichia coli transcriptional regulation from a compendium of expression profiles. PLoS biology , 5 (1):e8, 2007.
 Flynn, J.L. and Chan, J. Tuberculosis: latency and reacti-vation. Infection and immunity , 69(7):4195 X 4201, 2001. Galagan, J.E., Minch, K., Peterson, M., Lyubetskaya, A.,
Azizi, E., et al. The mycobacterium tuberculosis regula-tory network and hypoxia. Nature , 499(7457):178 X 183, 2013.
 Goldenberg, A., Zheng, A. X., Fienberg, S. E., and Airoldi,
E. M. A survey of statistical network models. Foun-dations and Trends in Machine Learning , 2(2):129 X 233, Feb. 2009.
 Green, P.J. Reversible jump markov chain monte carlo computation and bayesian model determination. Biometrika , 82(4):711 X 732, 1995.
 Imoto, S., Higuchi, T., Goto, T., Tashiro, K., Kuhara, S., and Miyano, S. Combining microarrays and biologi-cal knowledge for estimating gene networks via bayesian networks. Proc. Computational Systems Bioinformatics , 2003.
 Irrthum, A., Wehenkel, L., Geurts, P., et al. Inferring reg-ulatory networks from expression data using tree-based methods. PLoS One , 5(9):e12776, 2010.
 Joshi, A., De Smet, R., Marchal, K., Van de Peer, Y., and Michoel, T. Module networks revisited: compu-tational assessment and prioritization of model predic-tions. Bioinformatics , 25(4):490 X 496, 2009.
 Kendall, S.L., Withers, M., Soffair, C.N., Moreland, N.J.,
Gurcha, S., et al. A highly conserved transcriptional re-pressor controls a large regulon involved in lipid degra-dation in mycobacterium smegmatis and mycobacterium tuberculosis. Molecular microbiology , 65(3):684 X 699, 2007.
 Koller, D. and Friedman, N. Probabilistic Graphical Mod-els: Principles and Techniques . MIT Press, 2009. Kozinets, R.V. E-tribalized marketing?: The strategic im-plications of virtual communities of consumption. Euro-pean Management Journal , 17(3):252 X 264, 1999.
 Latouche, P., Birmel  X  e, E., and Ambroise, C. Overlapping stochastic block models with application to the french political blogosphere. The Annals of Applied Statistics , 5(1):309 X 336, 2011.
 Liu, Y., Qiao, N., Zhu, S., Su, M., Sun, N., Boyd-Kirkup,
J., and Han, J.-D. A novel bayesian network inference algorithm for integrative analysis of heterogeneous deep sequencing data. Cell Research , 23(3):440 X 443, 2013. Marbach, D., Costello, J.C., K  X  uffner, R., Vega, N.M., Prill,
R.J., et al. Wisdom of crowds for robust gene network inference. Nature methods , 2012.
 Michoel, T., Maere, S., Bonnet, E., Joshi, A.and Saeys, Y., et al. Validating module network learning algorithms us-ing simulated data. BMC Bioinformatics , 8(Suppl 2):S5, 2007.
 Mitra, K., Carvunis, A., Ramesh, S.K., and Ideker, T. Inte-grative approaches for finding modular structure in bio-logical networks. Nature Reviews Genetics , 14(10):719 X  732, 2013.
 Qi, Y. and Ge, H. Modularity and dynamics of cellular net-works. PLoS Computational Biology , 2(12):e174, 2006. Rustad, T.R., Harrell, M.I., Liao, R., and Sherman, D.R.
The enduring hypoxic response of mycobacterium tuber-culosis. PLoS One , 3(1):e1502, 2008.
 Segal, E., Shapira, M., Regev, A., Pe X  X r, D., Botstein, D.,
Koller, D., and Friedman, N. Module networks: iden-tifying regulatory modules and their condition-specific regulators from gene expression data. Nature genetics , 34(2):166 X 176, 2003.
 Segal, E., Pe X  X r, D., Regev, A., Koller, D., and Friedman, N.
Learning module networks. Journal of Machine Learn-ing Research , (6):557 X 588, 2005.
 Snijders, T.A.B. and Nowicki, K. Estimation and predic-tion for stochastic blockmodels for graphs with latent block structure. Journal of Classification , 14(1):75 X 100, 1997.
 Voskuil, M.I., Schnappinger, D., Visconti, K.C., Harrell,
M.I., Dolganov, G.M., Sherman, D.R., and School-nik, G.K. Inhibition of respiration by nitric oxide in-duces a mycobacterium tuberculosis dormancy program.
The Journal of experimental medicine , 198(5):705 X 713, 2003.
 Wang, Y.J. and Wong, G.Y. Stochastic blockmodels for directed graphs. Journal of the American Statistical As-sociation , 82(397):8 X 19, 1987.
 Werhli, A.V. and Husmeier, D. Reconstructing gene regula-tory networks with bayesian networks by combining ex-pression data with multiple sources of prior knowledge.
Statistical Applications in Genetics and Molecular Biol-
