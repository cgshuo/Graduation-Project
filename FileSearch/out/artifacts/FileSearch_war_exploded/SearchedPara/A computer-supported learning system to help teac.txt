 E. Herrera-Viedma  X  A. G. Lo  X  pez-Herrera  X  S. Alonso  X  J. M. Moreno  X  F. J. Cabrerizo  X  C. Porcel Abstract This paper describes a computer-supported learning system to teach students Retrieval Systems Based on Artificial Intelligence at the Faculty of Library and Information Sciences at the University of Granada. Learning of languages of weighted queries in Fuzzy different semantics that could be associated to the weights of queries together with their respective strategies of query evaluation. We have developed and implemented this computer-supported education system because it allows to support the teacher X  X  activity in the classroom to teach the use of weighted queries in FIRSs and it helps students to develop self-learning processes on the use of such queries. We have evaluated the performance of obtained in the course X  X  exams. We have observed that using this software tool the students learn better the management of the weighted query languages and then their performance in the exams is improved.
 Keywords Teaching Education Weighted queries Fuzzy connectives Fuzzy Information Retrieval 1 Introduction Due to the growth of e-business, the Web has become a critical part of many real-world systems. Thus, it is increasingly important that information technology professionals and students are proficient and knowledgeable in various Web technologies like (Baeza-Yates and Ribeiro-Neto 1999 ) Web mining, query processing, Information Retrieval (IR) models, search engines, meta-search engines, recommender systems, information filtering, Web to-date with them (Chau et al. 2003 ).

At the Faculty of Library and Information Science at the University of Granada there design of IRSs. As it is known, both are important Soft Computing tools (Bonissone 1997 ) (Crestani and Pasi 2000 ; Herrera-Viedma et al. 2006 ; Nikravesh et al. 2002 ).
Fuzzy IRSs (FIRSs) are those IRSs that use the potential of the fuzzy tools to improve ficial Intelligence X  X  is focused on models of FIRSs that use weighted queries to improve use of weighted queries and fuzzy connectives are used. However, in our teaching evaluation in a blackboard.

Researchers have found that using computer-supported learning systems in instructional contexts may provide students with opportunities to promote their understanding of phe-nomena in science and to facilitate the visualization of abstract and unobservable concepts (Alessi and Trollip 1991 ; Hegarty 2004 ; Stratford 1997 ). Computer-based instruction software allows students to develop self-learning processes which offers them more flexible learning opportunities, independent from time and place, and to learn at their own pace (Eteokleous 2008 ).

IR instruction is an obvious application for computer-supported learning systems. The advantage of using computer-supported learning systems is that the learner gets a realistic feeling of the particular IRS used and he can develop self-learning processes on typical operations of IRSs (Halttunen and Sormunen 2000 ). To do that, it is possible to use real world search engines like Google, Altavista, Lycos, etc., or to build ad-hoc training IRSs (Caruso 1981 ; Chau et al. 2003 ; Griffith and Norton 1981 ; Halttunen and Sormunen 2000 ; Markey and Atherton 1978 ).

There are very few training IRSs (Halttunen and Sormunen 2000 ) and, particularly, a fuzzy IR training system does not exist. Furthermore, existing IR training systems present several shortcomings (Halttunen and Sormunen 2000 ): (1) They do not give feedback about the performance or success of user queries, (2) it is not possible to observe or visualize how a user query is evaluated, and (3) it is not possible to compare the performance of different types of user queries and improve the teaching of FIRSs at the degree course  X  X  X nformation Retrieval Systems based teaching problems of FIRSs. The system was used as first time at the academic year 2006 X  2007. It provides an environment for demonstrating the use and performance of weighted queries with different semantics and their evaluations using different fuzzy connectives. It tance, ideal importance, quantitative) (Herrera-Viedma 2001b ; Herrera-Viedma et al. queries (maximum, minimum, Ordered Weighted Averaging (OWA) operators, Induced OWA operators, Linguistic OWA operators, and Linguistic Weighted Averaging opera-Viedma 2000 ; Herrera-Viedma 2001b ; Herrera-Viedma et al. 2007 ) to assess weights CRANSFIELD, TREC, etc.) can be used. The system presents visualization tools to better show evaluation processes of user queries. We have to point out that this system is just an educational tool that can be employed to help teachers activities, and not an independent is an important motivational factor supporting the learning process which leads to increase learning gains (Yaman et al. 1784 ). Additionally, we evaluate the performance of its use in mance in exams is improved.
 which we use our computer-supported learning system for FIRSs, the models of FIRSs that the system contains, and the problems that their teaching arises. Section 3 describes the improvements of our computerized system. And finally, in Sect. 5 some conclusions are pointed out.
 2 Preliminaries FIRSs that the learning system contains, and some problems that we have detected to teach FIRSs in blackboard classes. 2.1 Educational context postgraduate level at the Faculty of Library and Information Sciences. This paper reports on the experiences of teaching IRSs at the graduate level.
 In the graduate level we teach a course  X  X  X nformation Retrieval Systems based on Fuzzy Logic tools and Genetic Algorithms applied in the design of Information Retrieval Sciences, gained from their previous four years of study, but should also present material that is informed by the latest research ideas. This implies that the students appreciate the open problems in IR, learn about new approaches and more radical solutions that are still in the laboratory stages of development. In this course we are particularly keen that students learn about the breadth of FIRSs problems and domains as much of their current experi-ence is with Web search engines.

Some important characteristics of our educational framework are the following:  X  An adequate size of the class with respect to the number students, we should point out  X  Teaching procedure the main instruction method is lecturing supplemented with  X  Adequate technological formation of the students at the Faculty of Library and 2.2 Models of FIRSs As aforementioned, our computer-supported learning system allows us to teach different models of FIRSs which are based on weighted user queries. These models of FIRSs present the following components: a documentary archive, a query system and a query evaluation procedure. 2.2.1 Documentary archive We assume a documentary archive built like in an usual IRS (Baeza-Yates and Ribeiro-f d document d j characterized by a numeric indexing function F : DT ! X  0 ; 1 which represented as: using a tf idf scheme (Salton and McGill 1983 ). 2.2.2 Query system The implemented FIRSs present a query system based on a weighted Boolean query language. Each user query is expressed as a combination of the weighted terms which are connected by the logical operators AND  X ^ X  ; OR  X _ X  ; and NOT  X : X  : The weights asso-Herrera-Viedma 2000 ; Herrera-Viedma 2001a , b ; Herrera-Viedma et al. 2005 , 2007 ) (see Appendix 1).

In this context, a user query is any legitimate Boolean expression whose atomic com-ponents (atoms) are pairs \ t i ; w i [ ; t i 2T and being w i 2I ; I2 X  0 ; 1 or I2S the Boolean queries is defined by the following syntactic rules: (1) Atomic queries: 8 q  X  \ t i ; w i [ 2T I) q 2Q : (2) Conjunctive queries: 8 q ; p 2Q) q ^ p 2Q : (3) Disjunctive queries: 8 q ; p 2Q) q _ p 2Q : (4) Negated queries: 8 q 2Q): X  q  X 2Q : (5) All legitimate queries q 2Q are only those obtained by applying rules 1 X 4, inclusive. (Herrera-Viedma 2001b ; Kraft et al. 1994 ):  X  Relative importance semantics this semantics defines query weights as measures of the  X  Threshold semantics this semantics defines query weights as satisfaction requirements  X  Perfection semantics this semantics defines query weights as descriptions of ideal or 2.2.3 Query evaluation procedure The evaluation procedure of weighted queries acts as a constructive bottom-up process that includes two steps:  X  Firstly, the documents are evaluated according to their relevance only to atoms of the  X  Secondly, the documents are evaluated according to their relevance to Boolean We represent the query evaluation procedure using an evaluation function E : DQ! according to the following rules: (1) Evaluation of an atomic query: (2) Evaluation of a conjunctive query: (3) Evaluation of disjunctive query: (4) Evaluation of a negated query: procedure are the following: OWA operators (Yager 1988 ), Induced OWA operators (Chiclana et al. 2004 , 2007 ; Yager and Filev 1999 ), weighted aggregations MAX and MIN (Yager 1987 ), Linguistic OWA operators (Herrera et al. 1996 ), and Linguistic Weighted Averaging operators (Herrera and Herrera-Viedma 1997 ). 2.3 Teaching problems for FIRSs The main difficulties to teach FIRSs that we have detected during different academic years (we began to teach FIRSs in the academic year 1995 X 1996) are the following: (2) How to explain students the contradictions existing between different semantics? For (4) How to explain students the bottom-up evaluation procedure for weighted Boolean (6) How to explain students the use of the OWA and Linguistis OWA aggregation (7) How to explain students the use of the weighted aggregation operators to model the supported learning system of FIRSs, which is introduced in the following section. 3 A computer-supported learning system to teach FIRSs The computer-supported learning system of FIRSs that we present in this section has been designed to help us to overcome the problems mentioned in the above section. It also is useful to overcome the problems of existing IR training systems mentioned at the begin-ning. This system has been developed at the Faculty of Information and Library Science at the University of Granada as a useful training tool of FIRSs based on weighted queries (see http://sci2s.ugr.es/secabalab/software/FIRS-trainer/ ).

The goal of this software application is, on the one hand, to provide an environment for to teach the use of weighted queries.
 gramming language. It is composed of three main modules: (i) definition module of test module of weighted queries. We analyze all of them in detail in the following subsections. 3.1 Definition module of test collection assessments indicating which documents are relevant in respect to a given query. Usually, the performance of a system is measured by means of the precision and recall achieved across the whole set of queries. As in (Halttunen and Sormunen 2000 ; Hull 1996 ) our goal (ADI, CISI, CRANSFIELD, etc).
 test collections, to analyze the performance of the different weighted queries in FIRSs. In the definition of the test collection they can establish particular queries and the relevant documents of the archive of such queries. 3.2 Formulation module of weighted queries queries (see Fig. 2 ). To define a weighted query they have to choose: (1) search terms, (2) Boolean connectives (AND, OR, and NOT), (3) query structure, (4) expression domain of weights (numerical or linguistic), (5) semantics to associate with the weights, and (6) values of weights. 3.3 Visual execution module of weighted queries The execution module allows measuring and visualizing the performance of any weighted query. Before to execute any weighted query, students have to choose the fuzzy connec-tives that must be associated with the Boolean connectives of the weighted queries. Given that our system uses OWA operators, this can be done by choosing a level of orness (Yager 1988 ).
 means of visual tools. This feedback is given by showing internal aspects of evaluations of weighted queries using evaluation trees (see Fig. 3 ). Furthermore, the module allows the visual comparison of the evaluation of different weighted queries (see Fig. 4 ). 3.4 Learning step by step: an example of use In this subsection a learning session based on this software tool is briefly described.
Let us suppose a student which wants to learn a fuzzy weighted IR model based on fuzzy collection. To simplify, we suppose that this student chooses the first possibility.
Then, we suppose that he defines a small documentary archive containing a set of 17 f t semantics simultaneously, threshold and quantitative ones: AND  X ^ X  : With such a query, the user demands: (1) q 1 : The student is looking for almost all documents with a weight F for t 1 as high as (2) q 2 : The student is looking for documents with a weight F for t 5 as high as possible, To do so, the query q is built in subsequent steps as it is shown in Fig. 6 . Finally, the results of evaluating q for all relevant documents are shown. For example, query q are sorted in decreasing order of E using linguistic values.

In the following section we present an analysis of the use of our system in the teaching of FIRSs based on weighted queries. 4 Evaluation of the computerized learning system The computer-supported learning system for FIRSs was tested in the field with students, in order to evaluate its performance and influence on their learning. Although we have some provide some interesting insights into student learning and teaching about FIRSs.
Previously, we should point out that in our classes the students are allowed to interact with the system for a maximum of 60 min, 2 days by week during 4 months. This is done under the supervision of the teacher. In addition, students can use the system in their free time from both the computer laboratory or from their house using Internet, (obviously, in those cases they do not have direct supervision from the teacher).

We have used two usual evaluation methods to evaluate the contribution of this com-puter-supported learning system to the student learning (Alessi and Trollip 1991 ; Cronje and Fouche 2008 ; Eteokleous 2008 ): a student questionnaire and an analysis of exam results . 4.1 Student questionnaire learning system during the course. This questionnaire is composed of four dimensions, two focused on the exploration of the usability of our learning system and other two focused on its teaching abilities, respectively: (1) Interaction (2) Interface (3) Involvement (4) Motivation
The evaluation criteria in each dimension are adapted for our study from those proposed in (Cronje and Fouche 2008 ): (1) Interaction (2) Interface (3) Involvement (4) Motivation
A nine point checklist format was used to assess the evaluation criteria. A response of 1, 2 or 3 was taken as  X  X  X isagree X  X , a response of 4, 5 or 6 was taken as  X  X  X ot sure X  X , while a response of 7, 8 or 9 was reported as  X  X  X gree X  X .

We have applied this questionnaire in the academic year 2007 X 2008 in which we worked with 18 students. The questionnaire results are the following: 4.1.1 Interaction process with the system was not very good and adequate (see Fig. 8 a). About 50% pupils improve both aspects of our system using audio/video elements, given that when students were asked why they disagreed the statements, they responded that they  X  X  X eard nothing X  X  and  X  X  X ould like to see more different types of feedbacks X  X .

On the other hand, in the statement (c) there exists a balance between students X  opin-ions. If we analyze the scores provided by the unsure group of students, {5, 6, 6, 6}, we could understand that the most of students understood the most of answers given to their improved by means of multimedia elements. 4.1.2 Interface all and they expected more multimedia components in the learning system. On the other hand, seven students indicated that sometimes they felt completely lost.

Consequently, we think the system X  X  interface could be improved if we re-design the system and incorporate some multimedia instruction elements. 4.1.3 Involvement In general, after working with our learning system, the most of students responded posi-tively on the involvement dimension (see Fig. 8 c): (i) they preferred the computer based type of instruction, (ii) they do not find problems to understand the course material, (iii) they expressed a possitive feeling on the course material, and (iv) they admitted that the (a) (c)(d) lessons were not difficult to follow neither dull. In a interview with the six students that feedback and that was the reason why they thought that the lessons were dull. Therefore, as above, we think that we should incorporate more multimedia learning elements to facilitate the student X  X  involvement. 4.1.4 Motivation Similarly, after working with our learning system, the majority of the students answered positively on the motivation dimension. In Fig. 8 d we can definitely say that most of the students were positively motivated through the use of our learning system: students showed learning system was a waste of time. 4.2 Analysis of exam results different research studies: (1) Does the use of the computer-supported learning system improve the scores between (2) Does a strong use of computer-supported learning system improve the scores in final
In both studies, our primary concern for accuracy and to overcome problems with statistical power, is due to the very small sample size ( n = 18 for academic year 2007 X  2008 and n = 16 for academic year 2005 X 2006). For such small data sets, it is basically impossible to tell if the data comes from a variable that is normally distributed (Levin and Fox 2006 ), as with small sample sizes ( n \ 20) tests of normality may be misleading. In nonparametric methods may be necessary when data has a ranking but no clear numerical nonparametric statistical tests are introduced. 4.2.1 Comparing scores between different academic years 2007 X 2008 and 2005 X 2006 The main aim of this research study is the following:
Was the learning effect on the remembering, understanding and applying level in the pupils from the academic year 2007 X 2008 higher than in the pupils from the aca-demic year 2005 X 2006?
To do so, student scores on final exams from both academic years, 2007 X 2008 and 2005 X 2006, are directly compared by using the Mann X  X hitney X  X  nonparametric statistical test (for more detail see (Mann and Whitney 1947 ; Sheskin 2003 ) and Appendix 2). Then, we analyze the research null hypothesis: with Scores X being the scores on final exams in participants from group X ( X = 2007 X 2008 or X = 2005 X 2006). Table 1 shows the scores for participants in groups 2007 X 2008 and 2005 X 2006 (0 is the lowest possible score whilst 10 is the maximum one).
 202 ( z =-2,00119), U 2005 X 2006 = 86 ( z = 2,00119), and consequently, the null research scores in group 2007 X 2008 ( median rank = 18.06) are higher than scores in group 2005 X  2006 ( median rank = 12.69) (see Table 1 ), the alternative hypothesis: is supported. 4.2.2 Researching if a strong use of computer-supported learning system improves student (see Sheskin 2003 and Appendix 2).
 relationship, -1 in the case of a decreasing linear relationship, and some value in between in all other cases, indicating the degree of linear dependence between the variables. The closer the correlation is to either -1 or 1, the stronger the correlation between the vari-ables. If the variables are independent then the correlation is 0.

Then, pupils from the academic year 2007 X 2008 were asked for his/her level of use of used) X  X  X . In Fig. 9 , scores and declared use are plotted.

In our study, Spearman X  X  test with q = 0.81 indicates there is a high correlation (with p -value = 4.636 e -05) between scores and declared usage. This represents a statistical would be a consequence of a strong use of our computer-supported learning system (see values in Table 2 ). 5 Conclusions FIRSs based on weighted user queries has been presented. This system contributes to over-come the teaching problems of IRSs pointed out in (Halttunen and Sormunen 2000 ), and
We have evaluated its performance on students X  learning and our results reveal that the use of this tool enhances students X  learning on weighted query based FIRSs, their scores in observed that its performance could be improved if we incorporate more multimedia instruction elements in the system activity.
 Appendix 1: a fuzzy ordinal linguistic approach The ordinal fuzzy linguistic approach is a fuzzy approximate technique appropriate to deal ordinal fuzzy linguistic approach the syntactic rule is defined by considering a finite and with odd cardinality (such as 7 or 9 labels), where the mid term represents an assessment of  X  X  X pproximately 0.5 X  X , and the rest of the terms being placed symmetrically around it. The s  X  Very High  X  VH  X  ; s 7  X  Extremely High  X  EH  X  ; s 8  X  Total  X  TO  X g : linguistic information, such as:  X  Minimization operator  X  Maximization operator  X  Negation operator  X  Aggregation operators we can use aggregation operators based on symbolic Appendix 2: introduction to inferential statistical tests in this paper, i.e, Mann X  X hitney X  X  U test and Spearman X  X  Rank Correlation Coefficient. Mann X  X hitney U test This test was developed independently by Wilcoxon in 1945 and Mann and Whitney in 1947 (Sprent 1993 ). Therefore, it is known by two different names: the Wilcoxon rank-sum test and the Mann X  X hitney U test. The Wilcoxon rank-sum test only explores equal Wilcoxon rank-sum test, resolved this problem.

The Mann X  X hitney U test assesses the null hypothesis, which states that the two samples to have continuous measurements (Mann and Whitney 1947 ). For two samples X and Y , the Mann X  X hitney U test first ranks the two samples. To do so, the samples are sorted into one large sample while maintaining the information about which sample each are two or more identical values, the average of the ranks of these values is assigned as get the same rank:
It is clear that ranking the values removes the effects of the outliers present in certain tests such as parametric tests. A value large enough to be considered an outlier will have a Whitney U test calculates the sum of the ranks for all the values in each sample. Therefore, for a sample X , the sum of the ranks is: R Y is calculated the same way.
 where n X = | X |: U
Y is calculated the same way. In addition to U X and U Y , the mean and standard deviation of U must also be found using the following equations, where m U is the mean of U , r U is the standard deviation of U , and n Y = | Y |:
Finally, the following normal approximation can be used to calculate the standard normal deviate, z , also known as the standard score:
Since there are two samples X and Y , there will be two standard scores, z X and z Y . These hypothesis.

Given two methods m X and m Y , the acceptance or rejection of the null hypothesis can only identify these methods X  performance as being identical or not respectively. In the case of non-identical methods, the test does not help in identifying which method performed better. Nonetheless, in comparison of different methods it is more interesting to find the ones that performed best. Therefore, in case of two non-identical samples, which happens when the null hypothesis is rejected, another non-parametric test can augment the Mann X  Whitney U test. The simplest and most useful non-parametric test is to compare the median ranks of the two samples after the Mann X  X hitney U test considered them non-identical. In the cases where higher ratings imply better quality, if sample X has a higher median rank than sample Y , then method m X is considered better than method m Y .
 Spearman X  X  rank correlation coefficient In statistics, Spearman X  X  rank correlation coefficient or Spearman X  X  rho (Spearman 1904 ), named after Charles Spearman and often denoted by the Greek letter q , is a non-parametric measure of correlation that is, it assesses how well an arbitrary monotonic function could describe the relationship between two variables, without making any assumptions about the frequency distribution of the variables.
In principle, q is simply a special case of the Pearson product-moment coefficient in coefficient. In practice, however, a simpler procedure is normally used to calculate q . The observation on the two variables are calculated (Myers and Well 2006 ).

If there are no tied ranks, i.e. then q is given by: q  X  1 6 both sets).

If tied ranks exist, classic Pearson X  X  correlation coefficient between ranks has to be used instead of this formula:
One has to assign the same rank to each of the equal values. It is an average of their positions in the ascending order of the values.
 References
