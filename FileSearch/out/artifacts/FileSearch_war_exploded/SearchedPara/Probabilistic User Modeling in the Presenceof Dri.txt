 In this article we investigate predictio n problems in which there are multiple evolving entities, which we refer to as agents . We address two complications that frequently arise in problems that involve modeling agents: variation among (1) agents and (2) within an agent across time. Let X  X  consider the problem of estimating the probability of a movie reviewer X  X  rating. Here we have features describing the context such as genre, rele ase time, reviewer X  X  preferences etc. In this problem we may have both kinds of variation. Clearly, there will be variation among the agents, as every person is different. Also, there will be variation in the user X  X  ratings because of his ta stes, mood etc. which vary with time.
These variations pose problems to the modeler. One approach would be to learn a single model that applies to all agents. This approach has the advantage that training examples from all agents can be pooled together. Given plentiful training observations for an agent, another approach is to learn a different model for each agent from only that agent X  X  examples, and then use the appropriate agent specific model when making predictions. However, if training examples are scarce, this agent specific approach is susceptible to overfitting. Even when training data is relatively plentiful for a given agent there may be contexts that have not been observed very often.

Our approach takes the middle ground between these two extremes. Like the agent specific or heterogeneous approach, we learn a different model for each agent, but unlike it, training observations of multiple agents may have an influence on the learned probabilities for a given agent. We do this by identifying a neighborhood of agents with similar probability profiles and then combining their models if training data is scarce.

In addition to variation across agents, we consider patterns of change within a single agent over time. Problems in which class distributions change with time are said to exhibit concept drift. See, for example, Widmer [15]. Our approach to modeling concept drift utilizes hidden Markov models [12], that have found widespread use in many sequential processing tasks. We investigate the approaches to model multiple evolving users or entities over time. Our approach is closely related to previous work in Concept drift and Collaborative Filtering.
 Concept Drift has received considera ble attention both in the field of Data Mining [16,11,15,14] and Computational Learning Theory [1,5]. Previous work on concept drift have addressed the problem of concept drift over time, but concept drift across agents has not receive d particular attent ion. Incremental ( or online ) concept drift was discussed by [15]. Widmer and Kubat X  X  FLORA framework used a window based learning system. The FLORA2 algorithm and the FLORA3 algorithm addressed the issue of recurring contexts. [7], addressed concept drift with the CVFDT algorithm, which uses flexible windowing and decision trees. [11] have also used Decisi on Trees for online con cept learning, the algorithm OnlineTree2 introduces multiple flexible windows. Concept Drift has also been applied in the field of Network Security to model the user behavior and to use it for Anomaly Detection.[9].

Collaborative Filtering Methods have become a popular system on the In-ternetandareoftenusedastechniquesto complement conten t-based filtering systems [6]. [10] uses a Collaborative Framework based on Fuzzy Association Rules and Multiple-level Similarity (FARAMS). Recommender Systems often rely heavily on Collaborative filtering, where past transactions are analyzed to establish connections between users and products [8]. [8] introduces an approach which uses Neighborhood models and Latent factor models to do Collaborative Filtering. The filtering methods uses both implicit and explicit feedback from user ( agents ), to improve results. Current Recommender Systems consider the relations between the various users ( agents ), but do not consider the Concept Drift over time.
Other work similar to what we present here include approaches for training probabilistic models by combining examples from multiple contexts. Interpo-lated Markov models [3] are models that combine different order Markov mod-els based, in part, on the number of training examples observed in each case. This approach was originally developed for finding genes in microbes. More re-cently variable length HMMs [14] were introduced. These models dynamically adapt the length of an HMM memory using context trees. Interpolated hidden Markov models have also been used in many domains such as finding genes and in automatic instrument recognition [13]. Figure 1 shows diagrams of some of the graphical probability models we use here. In this example there are N agents. For each agent we have multiple observations at various time points. We use Y t a to represent the output random variable for agent a at time t .Each Y is associated with M observable features, denoted by the feature vector X .

When we are learning a classifier to predict the output Y of each agent, there can be two extreme cases, (i) the Homoge neous Case, where we learn a single model for all agents (Fig. 1 A) and (ii) the Heterogeneous Case, where we learn a model for each agent, (Fig. 1 B).

Both these approaches are flawed in many real world scenarios, as there is usually some difference between the behavior of each agent, but yet its never true that all agents are entirely different from each other. Thus to model pre-dictive classifiers close to real world scenarios, we choose an approach which is somewhere in between the two extreme cases.
 Figure 1 C and D illustrate our approach to modeling variation among agents. In this example we have three agents and a set of three features per agent. Early on during training, or when a new agent appears, and training data for individual agent is scarce, its probabilities are influenced heavily by neighboring agents. This is illustrated in the figure with dashed lines connecting the nodes. Outputs( class )ofAgent 1 and Agent 3 are similar, but X (1) of Agent 1 is closer to X (1) of Agent 2 . As we have more training data, we learn that output of Agent 1 is closely tied to Agent 2 , and closeness between X (3)  X  X  of Agent 1 and Agent 3 has grown weaker.

To model concept drifts over time, we investigate Hidden Markov Models, as shown in Fig. 2. Figure 2 A illustrates the case where we learn one HMM for each agent. Variables H t i represent the Hidden Variable for Agent i at time t.
The Hidden Variables capture the drift over time as each hidden variable relearns its probability distribution for state transitions and emissions, as new training data is encountered. Figure 2 B and C, illustrate an Interpolated HMM, in which we have a model for each agent and an agent X  X  prediction probabilities are influenced both by its own training data and that of other agent X  X  in its neighborhood similar to the static HMM explained above.

Thus, these Interpolated models attempt to capture the real world scenario, where there are varying relationships among agents. Agent 1 may be closer to Agent 2 in some ways and closer to Agent 3 in some ways. As our setting involves multiple agents over time, we assume that we have labeled data for N agents through time t . For our models in Figure 1, we estimate a naive Bayes model for each agent.

For agent a at time t we have the labeled data set { ( x t a ,y t a ) | t  X  t } where 1  X  y t x at time t .
 Assumptions  X  Throughout this article, we shall assume that each of the features X ( j )take  X  We assume the number of features and their domains are constant across  X  We use a value of 0 to denote a missing feature value.  X  We do not require the observations of different agents to be aligned in time. Homogeneous and Heterogeneous Models To learn the homogeneous model we pool all examples from all agents into a number of examples in which feature j had a value of k with class c ,and n ( c ), the total number of observations of class c . Then we compute the maximum a-posteriori (MAP) estimates with pseudo-counts of 1 for all parameters: and Here we have dropped the agent subscripts because we use the same model for each agent.

Learning in the heterogeneous case is the same as the homogeneous case with the exception that each agent X  X  model is l earned from a training set consisting of only that agent X  X  examples.
 Interpolated Model Given plentiful training data (and assuming stationary concepts) we would ex-pect the heterogeneous model  X  P a ( Y a | X a ) to be more accurate than the homo-geneous model  X  P ( Y | X ) on predictions for any agent a . On the other hand, if training data for agent a is scarce there is concern of o ver-fitting. Even if train-ing data for a is scarce, however, we may have many examples for other agents. This happens if the numbers of observations for each agent is skewed so that some agents have many observations while others have few. In this case, we X  X  like to be able to use training examples from the other agents to help estimate the model for a . Our approach is to form a model for a by combining its own MAP estimate with the MAP estimates of other agents in the neighborhood of a . We call this the interpolated approach.

Since learning naive Bayes models from complete data is just a set of separate estimation problems, one for each conditional distribution and one for the prior of the class variable, we describe our approach in terms of estimating just a single distribution for a discrete domain.
 Let W be the random variable we are estimating a distribution for ( i.e. , P ( W )iseither P a ( Y )or P ( X a ( j ) | Y a = c )) and K be the number of values in W  X  X  domain. We begin with the table of counts, where n ( a, k )isthenumberof observations of value k for agent a , and first compute the agent specific MAP estimates  X  P a ( W ) using equations analogous to Equations 1 or 2 (but of course using only a  X  X  observations). This estimate is identical to the estimate used in the heterogeneous model for a .
 We construct the interpolated distribution for a ,  X  P I a ( W )asamixtureofits MAP estimate and its  X  X eighborhood X  distribution P N a ( W )(describedbelow): where 0  X   X  a  X  1 is the mixing coefficient that det ermines the relative contri-butions of a  X  X  MAP distribution and its neighborhood distribution. We set  X  a using the logistic function so that it smoothly varies as its number of observa-tions grows. M here is a tuneable parameter that controls how fast we transition from the neighborhood distribution to the MAP distribution. A large value of M causes a slow transition. An agent X  X  neighborhood distribution is a combination of the MAP distribu-tions of its eligible neighbors and an average agent distribution. We represent the  X  X istance X  d ( a, a ) between agents a and a (for estimating W )withthe Kullback-Leibler divergence: Next, we form an  X  X verage agent X  model  X  P ( W ) that is the average of the MAP models for all agents: where the product is a normalized point-wise product of distributions. Notice that  X  P is not the same as the estimate learned by the homogeneous model be-cause  X  P is influenced equally by all agents whereas in the homogeneous model an agent X  X  influence is proportional to how many observations it has. Our rea-soning is that when little or nothing is known about an agent, which is when  X  P has influence, we believe it is more reasonable to model it more like the average agent than the average training example.

An agent a is an eligible neighbor of a if both (i)  X  a &gt; 0 . 5 and (ii) d ( a, a ) is less than the distance between a s MAP distribution  X  P a ( W ) and the agent average distribution  X  P ( W ). The first condition ensures that eligible neighbors have seen enough training examples so th at their MAP estimates are more likely to be reliable and the second condition prevents distant  X  X eighbors X  from having any influence. We define the neighborhood of a , N a ,tobeits D closest eligible neighbors. If there are less than D eligible neighbors then N a contains all eligible neighbors, which could be zero. Finally, we construct the neighborhood distri-bution P n a by taking the normalized point-wise product of the average agent distribution with the MAP distributions of all neighbors: We now compute the interpolated model with Equation 3. In this way we com-pute all distributions for all agents. Before we move on, we stress a few important details about this approach:  X  The neighborhood for a is distribution specific. It is possible that a has a  X  The neighborhood distribution behaves like an evolving bias or prior. Implicit  X  If the MAP distribution for an agent is near the center of its neighborhood Hidden Markov Models We now turn toward our approach for representing changes within an agent over time. For this we use hidden Markov models. We explore both a regular HMM with one model for each agent and an Interpolated version which applies the interpolated approach to an agent X  X  HMM.

Our HMM consists of two states. These s tate represent different modes of the agent X  X  distribution over class labels. In the domain of our dataset, the hidden states could correspond to changes in a reviewers X  calibration or even changes in actual human reviewer associated with a given user ID, though we have no definite knowledge of what these states maybe, we can learn their behavior. To learn the parameters of the HMM for agent a at time t we train an HMM using the expectation-maximization algorithm [4] using the single sequence y 1 a , ..., y t a . Thus, this approach is similar to the heterogeneous method, in which each agent X  X  model is trained using only examples from that agent. But, of course, it is differ-ent, as here we allow the agent X  X  probability distribution over the class to change with time.

In the Interpolated hidden Markov model, we learn an interpolated distribu-tion for the emissions, similar to the method explained above. For each agent, the probability distribution of the emissions are learned by using its distribution and the distributions of its  X  X eighbors X .

The HMMs we consider here, is in some ways the simplest possible in that the emissions involve a single variable. More complex HMMs in which emissions include both the class and features are possible as well. We conducted a set of experiments to assess that how well our approaches model evolving heterogeneous agent behavior in real world domains. We wish to (i) compare the predictive accu racies of the various models, (ii) investigate the effect of the training set size, and (iii) use HMMs to model concept drift over time We have have assembled a publicly available real world data set involving humans. Our set is derived from the Netflix prize 2 data. This data set contains over 100 million movie ratings (integer values 1-5) for 400,000+ users and 17,770 movies from 1999 to 2005. We use a subset of this data in our experiments. We extracted all the ratings from 2000 randomly selected users (the agents in this problem) for a total of 422,692 ratings. The rating is the class variable, and we divided ratings such that ratings (1,2,3) are classified as low or  X 0 X  and ratings (4,5) are classified as high or  X 1 X . Making it a binary class problem We have 103 features for each rating: (i) The day of week of the rating, (ii) The month of the rating (iii) The movie X  X  year of release. The remaining f eatures are the ratings (if available) of 100  X  X eavy X  users who have rated more than 1,000 movies. These 100 users are disjoint from the agents.

The first experiment was designed to see how well the interpolated method models the prior distribution P ( Y a ). In this experiment the 30% of the examples with greatest time index were held aside for evaluation. We trained models with successively more training data. We use all data from the time of the earliest instance through t where t is set so that 1%, 2%, ..., 70% of the available labeled examples are in the training set. Each trained model predicts the value of the held aside 30%. We measure the performance of each trained model with the test set log-likelihood. The parameter M was set to 20.

Figure 3 shows the results of this experiment. As expected, the heterogeneous model shows the most improvement as the size of the training set increases and the homogeneous model shows the least with the interpolated model in between. The interpolated model surprisingly continues to slightly improve throughout the whole range. Given the large amount of data it is unlikely that this trend is caused by estimation error, but suggests that drift may be present. Comparing the inter-polated curve to the others, we see that performance begins close to the homoge-neous model and then improves as the individual agent models begin to diversify.
These trends suggest high inter-agent variability. We see that the interpolated models perform best in settings with div erse agents. From these results we con-clude that the interpolated approach can lead to more accurate estimation of probability distributions, especially if agents are diverse.
 To compare the predictive accuracy of the interpolated model, we compute ROC curves (Fig. 4) for each of our static models. In this experiment we use all features (as well as class labels) to train the models with the first 70% of the data and predict the labels on the final 30%. Although the interpolated model was the most accurate in terms of test-set log likelihood this doesn X  X  translate into a clear win in the ROC curves. It is only slightly better than the homogeneous and heterogeneous models.

Our investigations into using HMMs to model concept drift focus on the pre-dicting the class values using only the priors and not the features. Similar to the first experiment, 30% of the examples with greatest time (in total, not per agent) index were held aside for evaluation. A separate HMM is trained from the first 40% using only that agent X  X  observed label sequence. We also learn an Interpo-lated HMM for each agent by applying the interpolated approach to the emission distributions. We compare the results of the HMM to the heterogeneous model and the Interpolated-HMM to the Interpolated Model. We measure the perfor-mance of each trained model with the test set log-likelihood. Figure 5 shows the results of the 2 types of HMMs learne d. The results showed strong evidence of concept drift, as the difference in the test set log likelihoods (summed over all agents) of the interpolated model and the HMMs was in favor of the HMMs. We see that initially the heterogeneous HMM starts lower than the interpolated HMM, which can be attributed to lack of training data for each agent. As more training data is made available, both models almost tie with each other, but still increasing, which suggests the presence of concept drift. Observing the agent specific log likelihoods shows that most of the difference between that static models and the HMMs is accounted for by a relatively small number of agents. It might be that these agents are strongly drifting while the others are weakly or not drifting. This suggests an alternate approach in which some agents are modeled with HMMs while others are modeled with static models. In this paper we investigated probabilistic models for multiple evolving agents. We addressed the common complications that may arise in such a setting, viz. (i) concept drift over time for a given agent, (ii) varying relationships among different agents. We compare and contra st 3 different static models, viz. (i) the homogeneous model in which we learn a single model for each agent, (ii) a heterogenous model where we learn a different model for each agent. (iii) an interpolated model where similar to the heterogeneous approach, we have a different model for each agent, but unlike it, observations from other agents can have an influence on an agent X  X  model. Then we investigate hidden Markov models to address the issue of concept drift over time. Lastly we applied the interpolated approach to HMM to get an interpolated hidden Markov model for each agent. The contribution of this paper is the introduction of a novel method for learning agent models that involves combining the models of multiple agents in the same neighborhood.

Importantly, the concept of neighborh ood is context specific, so the neigh-boring agents that combine to form one distribution may be distinct from those that combine in another. W e demonstrated the validity and need of such models in real world scenarios. In settings with diverse agents, models learned with our interpolated approach proved to be empirically better than purely homogeneous or purely heterogeneous mod els. Concept drift over time was investigated using hidden Markov models and strong evidence of concept drift was found.
Our Interpolated Hidden Markov Model , that is used in conjunction with hid-den variables, can be used to represent c ases where there are time varying con-cepts affected by unknown factors. For example, such models may find use in risk assessment in financial data such as stocks. Thus, modeling the evolving relation-ship among various agents together with accounting for time varying concepts can prove to be very useful in several fields like finance, marketing or medicine. This work can be further extended by considering models where there are more than one type of hidden variable, each type affect ing different observable features of the agent. Hence this can effectively model cases where certain features of an agent vary over time and others remain consistent. A typical setting would be a behav-ioral analysis of a multi-agent system which integrates models into an intelligent structure that improves t he efficiency of an agent[2].

