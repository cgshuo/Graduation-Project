 1. Introduction
For several decades, it has been an active area that many researchers focus on evolutionary computing. The evolutionary algorithm is an effective tool to solve optimization problems. There are many popular evolutionary algorithms, such as Genetic Algo-rithm (GA) ( Goldberg, 1989 ), Ant Colony Optimization (ACO) ( Dorigo and Di Caro, 1999 ) and Simulated Annealing ( Kirkpatrick et al., 1983 ) and so on. As a relatively new technique based on swarm intelligence algorithm, PSO attracts increasing attention. The features of PSO mainly include the improved capability of solving complex problems, high convergence speed and good generality for different problems ( Wang et al., 2010 ). Several PSO variants have been proposed, which employed many strategies and operation to informed PSO (FIPS-PSO) ( Mendes et al., 2004 ), fitness-distance-ratio based PSO (FDRW-PSO) ( Peram et al., 2003 ), cooperative based
PSO (CPSO) ( vandenBerghandEngelbrecht,2004 )andcompre-hensive learning PSO (CLPSO) ( Liang et al., 2006 ). In this paper ( Dong et al., 2008 ), a new self-adaptive PSO is proposed with a special function introduced to adjust the inertia weight adaptively, dimension size of solution space. A new hybrid self-adaptive PSO (HAMPSO) algorithm ( Zhao et al., 2006 ) based on particle swarm optimization and genetic algorithm, which employs a collaborative population-based search inspired by the social behavior of bird flocking and the optimization parameter of PSO provided by GA to get a good performance during the hybrid search process. The hybrid algorithm combines the high speed of PSO with the power-ful ability to avoid being trapped in local minimum by velocity mutation. In Goh et al. (2010a , 2010b ), a competitive and coopera-tive co-evolutionary PSO (CCPSO) is presented, which appears to have considerable potential for solving complex optimization problems by explicitly modeling the co-evolution of competing and cooperating species. Center PSO, which utilizes the addition of an extra particle called center particle, is proposed by Liu et al. (2007 ). It often attracts other particles and guides the search direction of the whole swarm due to its frequent appearances as the best particle of the swarm. Dynamic PSO (DPSO) is a modified version of the PSO proposed in Chatterjee and Siarry (2006 ), that utilizes a different update mechanism for the velocity of the particles. Multi-swarm cooperative particle swarm optimizer based on a master X  X lave model is presented in Niu et al. (2007 ), in which the slave swarms execute a single PSO or its variants independently to maintain the diversity of particles, while the master swarm evolves based on its own knowledge and also the knowledge of the slave swarms. Li and Xiao (2008 ) presented multi-swarm and multi-best particle swarm optimization algorithm, which divides initialized particles into several populations randomly. Then every population is combined into one population and continues to calculate until the stop condition is satisfied. At the same time, the novel algorithm updates particles X  velocities and positions by following multi-gbest and multi-pbest instead of single gbest and single pbest .In Rohling et al. (2006 ), an approach based on co-evolutionary particle swarm optimization formulated as min X  X ax problems is presented. The main contribution of the paper is that of a Gaussian probability distribution to generate the accelerating coefficients of PSO. Goh et al. (2010a , 2010b ) designed a competi-tive and cooperative co-evolutionary approach, which is adapted for multi-objective particle swarm optimization algorithm. The com-petitive and cooperative co-evolution model is introduced to produce the reasonable problem decompositions by exploiting any correlation, interdependency between components of the problem. The paper ( Jie et al., 2008 ) develops a knowledge-based cooperative particle swarm optimization (KCPSO), which mainly simulates the self-cognitive and self-learning process of evolution-ary agents in special environment, and introduces a knowledge billboard to record varieties of search information help to develop the local exploitation in a different local area, in which every particle follows a social learning behavior mode. The global exploration is produced from the different sub-swarms at the help of escaping behavior and the cooperative behavior of the particles. This work proposes a Multi-swarm Self-adaptive and Cooperative
Particle Swarm Optimization (MSCPSO) by combining several stra-tegies and operators. The strate gies and operators are the main contributions: (1) self-adapti ve strategy, which depends on all achieve a better balance between the local and global optimum; (2) cooperative strategy introduces a novel mechanism to strengthen the relationship with each other and share more useful information; (3) sub-swarm 1 and 2 called base sub-swarms can supply much new information to the other two sub-swarms as the evolution proceeds.
Besides,theentireswarmssharethesameglobalbestinformation, which could accelerate the algorithm achieved at the best searched record. The cooperative strategy among the four sub-warms has an influence on the sharing of information and the relationship among population. When it is processing, a guided convergence operator is employed to reduce the risk of converging to local sub-optimum.
The rest of the article is organized as follows: in Section 2 a general introduction of PSO is given. In Section 3 the proposed modification of PSO is described in detail. Section 4 presents the test functions and the discussion of the experimental results is made. Conclusions are given in Section 5. 2. General introduction of PSO
Particle Swarm Optimization (PSO) originally developed by Ken-nedy and Eberhart in 1995 ( Eberhart and Kennedy, 1995 ; Kennedy and Eberhart, 1995 ) is inspired with social behavior, such as bird flocking, fish schooling and has been widely used to solve several types of optimization problems. The standard PSO maintains a swarm of particles that represent the potential solution to the problem.
The particle is represented by P i  X  X  p i 1 , p i 2 , ... , p
D-dimension search space, and its velocity is V i  X  X  v i 1
Each particle adjusts its trajectory towards to the position of its own previous best performance ( pbest i ) and the best position discovered by the whole population ( gbest ). PSO uses a real-valued multidimensional space as search space, defines a set of particles located in that space, and evolves the position of each particle using its current velocity, the known previous best position and the global best position. The particle positions and velocities can be updated according to the following equations: v x  X  k  X  1  X   X  x id  X  k  X  X  v id  X  k  X  1  X  X  2  X  where x id is the position of the i th particle with d demotions the rate of the position change of the particle. c 1 and c positive constants, which are called as cognitive and social parameters, respectively, and rand is random numbers obtained from a uniform random distribution function in the interval [0,1]. The parameter p id represents the best previous position of the i th particle and gbest denotes the best particle among all the particles in the population.

Shi and Eberhart (1998) later introduced an inertia weight w , which control the impact of the previous velocity on the current velocity, by modifying Eq. (1) to v  X  k  X  1  X   X  wv id  X  k  X  X  c 1 rand  X  p id x id  X  k  X  X  X  c 2 w is utilized to influence the trade-off between global and local exploration abilities of the particles. w provides a mechanism for forcing the swarm to perform a global search, maintaining diversity in the population, or a local search, reducing diversity in the population. Typically w is reduced linearly during the evolution in order to keep the balance between a global search early and a local search. As a result, the particle could track the global best to achieve the better area. Therefore, the PSO algo-rithm can enforce a steady improvement in solution quality and can always reach an optimum or a solution very close to the optimum by fewer evaluations. 3. General description of MCPSO algorithm
In the original PSO, when dealing with complex optimum problems, premature convergence is still the main drawback and more likely to be trapped into local minima. Each particle in the swarm learns from the gbest even if the current gbest is not the global optimum, as a result, the particles are attracted to be trapped into a local optimum if the problem is complex with numerous local optimums ( Liang et al., 2006 ).

In this section, MSCPSO is introduced in a general description. In the presented approach, a population consists of four sub-swarms, which keep a certain relationship, which enhances the co-evolu-tionary ability, with each other when the evaluation process is conducted. The sub-swarms cooperation and communication model, as shown in Fig. 1 , is used to update fitness values and maintain algorithm synchronization. In Fig. 1 it shows the general concept of the cooperative relationship of each sub-swarm.
In Fig. 1 , each sub-swarm executes a single PSO, including the update of position and velocity according to its own equations (which will be introduced in detail in Section 3.2), and the creation of a new local optimum. When all the sub-swarms are ready with the new generation, the global best optimum is obtained from the best local individual of each sub-swarm. In addition, the particle in the sub-swarm 3 is updated according to the fitness values and velocities of the particles in the base sub-swarms. The velocity of the particle in sub-swarm 4 is refreshed only up to the velocities of particles of other sub-swarms, and three control factors are employed to update the position. In the following section, the mechanism is developed in detail.
In this paper, a novel algorithm is proposed that employs four sub-swarms and utilizes several strategies to extend the explora-tion and exploitation abilities of the standard PSO (sPSO). The pseudo-code of the algorithm is presented as follows: Algorithm MSCPSO Begin Select the size of particles for each sub-warm
Initialize the position and velocity of each particle in the population Evaluate the fitness value of each particle
Find out the local best position in each sub-swarm and global best optimum in the population
Do in parallel until the maximum number of iterations has reached
Apply diversity guided convergence strategy to current parti-cles in each sub-swarm endif } End Do
Return the best solution (the global best particle) of the algorithm The flowchart of the proposed algorithm is shown in Fig. 2 .
The optimization process starts with the initialization of the different sub-swarms. After that, adaptive strategy is described in Section 3.1. 3.1. Adaptive strategy
In tradition, PSO is mainly conducted by 3 key parameters: the inertia weight and two positive acceleration coefficients. Many works have invested on how to improve the original PSO to achieve a better goal. Shi and Eberhart (1998 ) firstly introduced the inertia weight w to balance the global convergent ability and local search capability. w is defined to decrease linearly as the following equation: w  X  w _ max i  X  w _ max w _ min  X  max _ gen  X  4  X  where w _ max and w _ min stand for the maximum and the minimum value of the inertia weight, respectively, which are of constant value. i is the current iteration number and max_ gen is the maximum iteration number.

The inertia weight controls the impact of previous flying experience, which is utilized to keep the balance between exploration and exploitation. The particle adjusts its trajectory according to its best experience and enjoys the information of its neighbors. In addition, the inertia weight is also an important convergence factor; the smaller the inertia weight, the faster the convergence of PSO performances and the easier to be trapped into local best. Conversely, it improves the diversity of the solution at the cost of no convergence. It would perform well when suitable parameters are presented, such as the adjustable number of iterations, the proper initial and final weight values.
What is more, in evaluation, it could not take advantage of the searching information to modify the inertia weight. The disad-vantage of linear decreasing is also realized in paper ( Chatterjee and Siarry, 2006 ) and a PSO algorithm with dynamic nonlinear adaptive inertia weight is developed. In the proposed approach of this paper, a novel adaptive dynamic strategy is introduced to overcome the short-back of the linearly decreasing inertia weight.
To improve the dynamic searching ability, the inertia weight is modulated as follows: w  X  8 &gt; &gt; &gt; &lt; &gt; &gt; &gt; : the current particles in all sub-swarms. In the evaluation process, the inertia weight can be modified adaptively, as shown in Eq. (5), which depends on the fitness value of current flying particles. The minimum fitness value of all particles in four sub-swarms is defined as f min , while the mean value is selected as f avg all the information searched, whatever is now or past, is utilized to update the future velocity. It is also a way to deal with the problem of falling into the local optimum. The dynamic ability is shown in Fig. 3 .

From Fig. 3 , it can be concluded that, in general, the change in inertia weight decreases linearly. In details, it is modified by the fitness information dynamically. The value of inertia weight seesaws at 0.35 frequently later. In this area, the algorithm can balance the searching and convergence ability in the search space to avoid the risk of more likely to be trapped into local minima, and improve the diversity of PSO. 3.2. MSCPSO X  X  search behavior
In the novel algorithm, each sub-swarm consists of N particles moving around in a D-dimensional search space. During a search, every sub-swarm is anticipated to search a local optimum in a local area, which not only can maintain the swarm diversity, but also can contribute to find out the global optimum based on the information about multiple local optima. In this improved adap-tive strategy, particles in sub-swarms update velocities and posi-tions according to their own equations. Particles in the basic sub-swarms of the population update their velocities by the following equation: v ij  X  k  X  1  X  X  wv
The velocity of the particle in the sub-swarm 3 called adaptive swarm is modified as follows: v  X  k  X  1  X  X  w  X  strategy is employed by comparing the fitness values of these two
What is more, the position refresh equations of particles in sub-swarms 1, 2 and 3 are defined as Eq. (2).

The velocity of a particle in the sub-swarm 4 is defined as follows: v  X  k  X  1  X  X  v 1 ij  X  k  X  1  X  X  v 2 ij  X  k  X  1  X  v 3 ij  X  k  X  1  X  X  8  X 
The velocity of the particle in sub-swarm 4 is guided by the particles in base sub-swarms and sub-swarm 3. According to the searching behavior of PSO, the gbest will be a significant clue to lead the particles to the global optimal solution. To enhance the searching ability, the position x 4 ij in sub-swarm 4 is updated by Eq. (9) as follows: x  X  k  X  1  X  X  a 1 x 4 ij  X  k  X  X  a 2 p 4  X  best  X  ij  X  a 3 gbest  X  v where a 1 , a 2 and a 3 are called impact factors, they subject to  X  a 2  X  a 3  X  1. In this algorithm, a 1 , a 2 and a 3 are equal to 1 the effect of the previous information can be found. The bigger the ( i  X  1,2,3), the more the effect of the previous information on current search. As a result, the particle in sub-swarm 4 shares all information of other particles in other sub-swarms, which generally out a fine detailed search around the captured global optimum. In the following paragraph, the cooperative mechanism described in Section 3.3 is conducted to enable the evolutionary of the particles in each sub-swarm. 3.3. Cooperative search strategy
This section starts with the description of the cooperative evolutionary mechanism. In MSCPSO, the information about the optimum searched is shared and can be perceived by all particles in different area. The basic sub-swarms affect the sub-swarm 3 with the fitness values and the current velocities. The particle in sub-swarm 3 will track the new directory as Eq. (7) shows. The current and the past velocity v 3 ij  X  k  X  decide the directory of v fitness values change the effective factor of the velocities. The cooperative evolutionary mechanism is employed in this paper. For convenient observation, two-dimensional particles X  search behavior all current particles not isolated with the other ones, but they are the swarm members sharing the useful records to adjust them-selves as the best one.

To explain the mechanism more clearly, a hypothesis graph is illustrated. The positions of the particles are renewed by the modification equations. The status of four particles in each sub-swarm in the sub-swarms at the time t and t  X  1 is illustrated in set as the left graph and the velocities are also set randomly. Following the Eqs. (2) and (3) and the modification Eqs. (6) X (9), the statuses of the particles at the time t  X  1 are updated by the mechanism of parallelogram. The new searching vectors for the unknown searching space can be obtained from the equations; the searched solutions are achieved from one circle to the other one that concludes the global optimum. As a result, the novel approach could converge to the global optimum. 3.4. Diversity strategy
In order to guide the solution exploration in the area to create more potential solutions and to explore un-searched solution space, the worst-replace operation with negative gbest is pre-sented, which are defined as follows: when the fitness values of the sub-swarms are not changed any more, the sub-swarms X  positions in the searching space are changed by the adaptive replace strategy in this section. It will lead the particles away w from a local optimum and encourage developing further explora-tion. The current particles are proposed to explicitly visit the negative of the global best when the searched optimum is no more a variable. In the evolutionary process, species diversity is conducted by the current particles (i.e. as shown in Fig. 5 ). For convenience to explain, Fig. 5 is illustrated to show the details of the dynamic update of the current particles.

From Fig. 5 , it can be concluded that the particles in sub-swarms 1 and 2 keep a better balance between the local search and the diversity of the solution; while the particles in sub-swarms 3 and the global optimum. The graph (b) illustrates the different genera-the algorithm makes more effort to avoid falling to local optimum. the convergence speed to obtain the diversity of the solutions.
The co-evolutionary process for Rastrigin function in 30-D is illustrated in Fig. 5 , in which the graphs are the result of the swarms performed smoothly searching behavior in initial itera-tions but achieve to make further progress in later iterations and the diversity is improved when the worst-replace operation is working. The experiments with the test function illustrate this point clearly. There was a smooth decrease in fitness value, in initial iterations, for the particles in the basic swarms share similar records with little difference between them. By looking at the shapes of the curves in the graph (a), it is easy to see that each particle in the basic sub-swarms can keep track of the previous best position found by the all sub-swarms, as well as find a better position based on their own knowledge. The basic sub-swarms kept finding better solutions, while the other two sub-swarms, for the relationship of Eqs. (7) and (8), started to be influenced and produce diversity improvements after the worst -14 -12 -10 -8 -6 -4 -2 0 2 4
Fitness Value (log) 01 2 1.5 2 2.5 012 1 2 3 012 -5 0 5 record was refreshed. The graph (b) shows the distance among the different particles in each sub-swarm. From the nine pictures, it is easy to know the particle in sub-swarms has most potential searching ability while the particles in sub-swarms 3 and 4 keep a good diversity. Another property is that the algorithm converges fast in the later iterations.

The above strategies increase the population X  X  diversity to improve the performance and achieve better result when solving complex multimodal problems. On the other hand, the particle shares more information with each other during the evolutionary process. 4. Experimental results and discussions
In this section, the results from the application of the proposed modifications to five variants of the PSO technique are listed. All
PSO methods have been applied to a series of test functions presented in Section 4.1. 4.1. Test function
To test the efficiency of MSCPSO, several functions ( Yao et al., 1999 ; Esquivel and Coello Coello, 2003 ) have been applied in order to check the effect of the proposed modifications in the efficiency and the convergence speed of four PSO variants. All experiments were performed 50 runs on every test problem. All functions are examined on 10 and 30 dimensions. The formulas of these functions are presented in Table 1 .
 The Sphere problem is easy to solve while the solution of
Schwefel X  X  function depends on the gap between its deep local optima and global optimum. It will be hard to find the global optimum if many particles fall into one of the deep local optima ( Liang et al., 2006 ). The Rosenbrock function is a multimodal problem and has a narrow valley from the achieved local optima to the global optimum. Ackley X  X  function has one narrow global optimum basin and a lot of minor local optima. Rastrigin X  X  function is a complex multimodal problem with a large number of local optima and easy to fall into local solutions. Griewank X  X  function has a component causing linkages among variables, thereby making it difficult to reach the global optimum ( Liang et al., 2006 ). 4.2. Parameter settings
To get the equal results of the algorithms being tested, experiments were conducted to compare four variants of PSO algorithms including the proposed MSCPSO algorithm on the test functions with 10 dimensions and 30 dimensions. The algorithms and parameters settings are listed below:
PSO with linear inertia weight (LW-PSO) ( Shi and Eberhart, 1998 ).

PSO with constriction factor (CF-PSO) ( Clerc and Kennedy, 2002 ).

PSO with random inertia weight (RW-PSO) ( Eberhart and Shi, 2001 ).
 FDRW-PSO ( Peram et al., 2003 ).
 MSCPSO.

For the sake of a fair comparison, the initial and final values of inertia weight (the update equation has been presented in Eq. (4)) for LW-PSO as 0.9 and 0.4, respectively, while random inertia weight value for RW-PSO. In CF-PSO and FDRW-PSO, the para-meters of inertia weight are set as that of in the paper Clerc and Kennedy (2002 ) and Peram et al. (2003 ). The acceleration con-stants c 1 and c 2 for LW-PSO and CF-PSO were both 2.0. For RW-PSO, c 1  X  c 2  X  1.4945 was employed. For the MCSPO method, is updated following Eq. (5), in which the initial and final values are set as 0.9 and 0.4.

The population size of LW-PSO, RW-PSO and CF-PSO is set at 30 while 6 in each sub-swarm of MSCPSO. The maximum number of fitness evaluations is set at 1000 for all algorithms. All the experiments in this paper are conducted 50 times, and the best, worst and average results throughout the optimization runs are recorded. 4.3. Results and discussions
Discussions for 10-D problems: the experimental results for each algorithm on each test function are listed in Table 2 . In the table, the best results among the algorithms are shown in bold. The graphs presented in Fig. 6 illustrate the evolution of best fitness found by five algorithms averaged for 50 runs for functions f and f 3 .

Table 2 presents the fitness values in terms of the best, worst, mean and standard deviation (Std.) of each algorithm for test function with 10-D. From Table 2 , it is observed that for all test problems, MSCPSO achieves better results than the other algo-rithms although it converges slower (i.e. as shown in Fig. 6 ).
Table 2 illustrates the comparisons of the other four algo-rithms on the benchmark functions. The proposed method is superior to any other algorithms on the optimization of the optimization problems except the Rosenbrock function at the condition of the performance indexes on  X  X  X orst X  X  and  X  X  X td. X  X  which have been presented in the table. It is deserved to note that the Rosenbrock function is an interesting multimodal problem whose complexities will be decreased with the increase in dimensions ( Goh et al., 2010a , 2010b) .

For convenience to show better search ability, Fig. 6 illustrates the comparisons just on the Sphere and Rosenbrock function in 10-D. In general, Fig. 6 shows that the MSCPSO could converge to the global optimum keeping a good diversity and high speed when it conducts the optimization of 10-Ds Sphere and Rosen-brock problems. The graph (a) means that the MSCPSO outper-forms than the other four algorithms to solve the Sphere with a good balance between local and global search. The graph (b) illustrates that the MSCPSO has overcome the optimization of the Rosenbrock problem.

From Fig. 6 , it obviously shows that the Sphere function is easy to solve while the Rosenbrock function did not achieve the result as good as that of Sphere function. Rosenbrock X  X  valley is a classic optimization problem. The global optimum is inside a long, narrow, parabolic shaped valley. To search the valley is trivial and convergence to the global optimum is difficult. Hence this problem is often used in assessing the performance of the optimization algorithms ( Peram et al., 2003 ). Considering MPSO and other methods on two problems as shown in graphs (a) and tion ability of all algorithms. In the experiment of Sphere func-tion, since Sphere function is continuous, convex and unimodal with only one single global minimum, the convergences of
LW-PSO and FDR-PSO are faster and achieve similar better results, which are superior to that of CF-PSO and RW-PSO (give almost comparable performance). The proposed algorithm keeps better searching diversity and gets the best solution although it converges the slowest. For the Rosenbrock problem, the local search capability of MSCPSO is the best in the initial process, in the later CF-PSO lost itself into the local optimum. RW-PSO kept better diversity in the search space while that of MSCPSO performances in the second place; however, it did not converge -2.5 -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 to the optimum as that of MSCPSO. The same conclusion can be made in Fig. 6 that MSCPSO has the best ability to surpass all approaches in keeping the trade-off between the local exploita-tion and the global exploration.

Discussions for 30-D problems: to illustrate the performance of the five algorithms on the test functions for 30-D, which has been included in Fig. 7 , the obtained records of the optima are shown in Table 3 .

One conclusion, which can be drawn from Fig. 7 , is that the new proposal, MSCPSO, is always either the fastest or the second fastest algorithm in reaching the target global value. MSCPSO has never fallen into local optimum and met the premature, while the others fail in at least one problem. Another characteristic is that MSCPSO keeps a better diversity in evolution. These facts clearly show the enhanced exploration capabilities of MSCPSO.

In Fig. 7 , it can be easily observed that the MSCPSO algorithm arrives at the global optimum value of 0.0 for each of the f functions and keeps the best diversity. Performances of the proposed algorithm for Ackley and Griewank functions show slightly poor convergence speed compared to LW-PSO and FDR-PSO algorithms -12 -10
Best Function Value (log) -10
Best Function Value (log) -18 -16 -14 -12 -10 Best Function Value (log) while MSCPSO performed better than all other algorithms comfor-tably for the Rosenbrock function. It has already been demonstrated how the MSCPSO method could obtain superior results for all but two benchmark functions in Table 3 . Another important point under experiments data should be noted that all the results in the MSCPSO algorithm were reported to use the least of particles among the compared algorithm.

It is deserved to note that Griewank function is an interesting multimodal problem whose complexities will be decreased with the increase in the dimensions. In the case of the function, since
MSCPSO employs two main efficient strategies to enhance the diversity of search space, though the performance of MSCPSO is worse than FDR-PSO and LW-PSO, it is better than the one of
CR-PSO and RW-PSO in the initial evolutionary. It can converge to the best fitness value with the most times in the 10-D, what proves MSCPSO owns higher optimization capability for the complex problem.

Obviously, MSCPSO takes advantage of kinds of evolution information distilled from the evolution process of swarm to guide the particles X  decision and behavior, which provides the particles of the swarm with more intelligence to search the global optimum, and contribute to the global optimization ability of PSO greatly.

According to the comparison analysis above, it is obvious to know that MSCPSO can keep a better diversity to develop the virgin space and have the best ability to reach the optimum. The relative results showed that MSCPSO is a good method to improve the global ability of PSO. 5. Conclusions
This paper presents a Multi-swarm Self-adaptive and Coop-erative PSO decomposed into four sub-swarms, which exchange information among themselves to evaluate overall fitness as the basis of the fitness adaptive equation. It also employs two novel strategies where all sub-swarms use the shared information to update current records adaptively and cooperatively. The new strategies makes the particles have more potential ability of self-control and enhance the diversity of the potential solution space.
From the analysis and experiments, the cooperative strategy, which helps to strongly discourage any premature convergence, enables the MSCPSO to make use of the shared information more effectively to guide the particle in the sub-swarm 4 to search the better quality quickly.

Based on the significantly encouraging results obtained from the experiments, it can be concluded that MSCPSO significantly improves the PSO X  X  performance and gives the best performance on most optimization problems when compared with other PSO versions. Another attractive property of the MSCPSO is that it does not introduce any complex operations to the original simple
PSO framework. The only difference from the original PSO is the introduction of self-adaptive and cooperative strategies.
The MSCPSO is also simple and easy to implement like the original PSO. Several research papers investigated in the practical problems with the modified PSO and also the presented approach could be applied to many reality optimizations, such as the optimization economic dispatch problem ( Cai et al., 2009 )in power system operation, manufacturing system ( Zhao et al., 2006 ), data mining ( Alatas and Akin, 2009 ), the fault diagnosis of mechanical system ( Liu and Pan, 2009 ) and so on. In addition, future work will emphasize on extensive study of the applications in more complex practical optimization problems to fully inves-tigate the properties and evaluate the performance of MSCPSO. Acknowledgment
This work is supported by Innovation Foundation of University of Shanghai for Science and Technology (Grant no. GDCX-T-101). References
