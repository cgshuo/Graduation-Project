 Boadilla del Monte, Madrid, Spain 1. Introduction
With the rapid growth of information technology, in fi nite fl ows of records are collected daily. These fl ows, de fi ned as data streams, pose many challenges to computing systems due to limited time and memory resources. Furthermore, they are characterizedby their concept-drifting aspect[10,27]. Concept over time. As a result, the model in use becomes out-of-date and has to be updated.

The fi eld of mining concept-drifting data streams has received increasing attention and has been intensively researched in recent years. Several approaches have been proposed [3,5,13,19,25,28] and applied to a wide range of real-world applications including network monitoring, telecommunications data management, market-basket analysis, information fi ltering, fraud and intrusion detection, etc.
However, most of these approaches are based on supervised classi fi cation algorithms assuming the of entirely labeled data streams availability is often violated in real-world problems, as labels may be scarce and not readily available.
For instance, for the malware detection problem, only a few true labels (i.e. malware or goodware) may be available immediately after the classi fi cation process, and therefore we may have to wait for a to choose between updating the classi fi er with just a few labeled data, which usually results in a poor most of the data will be outdated.

Semi-supervised learning methods have proved to be useful in such cases since they combine both labeled and unlabeled data to enhance the performance of classi fi cation algorithms [34]. However, they mainly assume that data is generated according to some stationary distribution, which is not true when learning from evolving data streams, where changes may occur over time.
 In this paper, we propose a new semi-supervised learning approach for concept-drifting data streams. the classi fi er over time even if only a few labeled data are available.

To this end, inspired by earlier work by Dasu et al. [6], we use the Kullback-Leibler (KL) diver-gence [20] to measure distribution differences between data stream batches. Then, based on a bootstrap-or not a drift occurs. However, our approach differs from Dasu X  X  work on three key points. First, we do not only detect whether or not a drift occurs, but we further distinguish and monitor three possible entirely labeled. Indeed, we detect possible drifts using both labeled and unlabeled instances. Moreover, we propose a general approach for learning from all these instances. In fact, when any of the three algorithm [7]. EM has been widely used in semi-supervised learning where it has been found to improve classi fi cation accuracy, especially when there is a small number of labeled data [24]. Otherwise, i.e. when no drift is detected, the current classi fi er is left unchanged.

Note that our approach is so general that it can be applied with different classi fi cation learning algorithms. In this paper, we consider two classi fi ers, namely naive Bayes and logistic regression. We perform experiments on rotating hyperplane and mushroom data sets using different percentages of labeled instances. Moreover, we evaluate our approach using a real-world malware detection data set, where we deal with the additional problem of imbalanced data streams and make use of two recently proposed approaches for mining skewed data streams, namely clustering-sampling [31] and SERA [5]. The results show that our approach performs well even using limited amounts of labeled data.
The remainder of this paper is organized as follows. Section 2 de fi nes the concept drift problem and three types of drift. It then goes on to brie fl y review existing approaches for learning from concept-drifting data streams. Section 3 introduces our new approach. Section 4 presents the experimental study. Finally, Section 5 rounds the paper off with some conclusions. 2. Concept drift 2.1. Problem de fi nition
In dynamic environments, the characteristic properties of data streams are often not stable but change over time. This is known as the concept drift problem [32]. According to Tsymbal [27], there are two possible types of concept drift: real concept drift ,de fi ned as a change of the target concept that distribution.

From a probabilistic point of view, concept drift can be de fi ned as the change in the joint probability possible sources of concept drifts:  X  Feature change : In this case, a change occurs in P ( x ) . Intuitively, some previously infrequent Moreover, Zhang et al. [33] proposed an additional categorization also based on the decomposition of changes in both P ( x ) and P ( c | x ) ,and loose concept drifting for changes in P ( x ) only.
To the best of our knowledge, in spite of these categorizations, all existing approaches dealing with the only whether or not there is drift, i.e. without specifying which type of concept drift occurs.
In this paper, we propose an ef fi cient approach for quantifying and detecting the three possible types of drift: feature, conditional or dual using both labeled and unlabeled data. Details are presented in Section 3.2. 2.2. Related work
Different approaches have been proposed to handle concept-drifting data streams. As pointed out intervals without considering whether changes have really occurred, and informed approaches that are used in conjunction with a detection method and only adapt the classi fi er after a change is detected. Examples of blind approaches include weighted examples [16] and fi xed size time windows [32]. to focus more on recent instances incorporating the new concepts. Fixed size time windows consider over time a fi xed number of instances over time: In this case, the choice of an appropriate window size without concept drifts.

Ensemble methods can also be considered as blind approaches. In fact, the general technique applied criteria usually based on current data block performance [4,19,28,30,31].

The adaptive size time window is an example of informed methods [32]. In fact, the window size is decreases to exclude the out-of-date instances; otherwise the window size increases to include the more recent instances [21].

Clearly, informed methods are more interesting since they are a more ef fi cient way of coping with concept drifts and avoid the uncontrolled updating of the current classi fi er. The main issue is how to detect concept drifts. Most of the existing research monitors at least one performance indicator over have also been used.

An alternative approach detecting drift is to monitor the data distribution in two different windows [13, 15,29]. It is assumed that as long as the distribution of old instances is similar to the distribution of recent ones, no concept drift occurred. A distribution difference, on the other hand, indicates a concept measure the distance between the probability distributions of two different windows to detect possible changes, and proved its generality, ef fi ciency and resilience to false alarms.

However, note that all previously presented works assume that true labels are entirely available in data streams. To the best of our knowledge, only two relevant previous works have addressed the problem of scarceness of labeled instances in concept drifting data streams.

The fi rst, proposed by Klinkenberg [17], is based on transductive support vector machines and it maintains two separate adaptive windows on labeled and unlabeled data in order to monitor, respectively, theoretically well-founded, this method has never been evaluated.

The second work was recently proposed by Masud et al. [22]. It is based on an ensemble approach where each model in the ensemble is built as micro-clusters using a semi-supervised clustering technique. In fact, the learning step of each model starts by choosing k c points from the labeled data of class C to initialize k c centroids. Then, the EM algorithm is applied by iterating the following two steps until convergence: The E-step assigns each unlabeled data point x to a cluster such that its contribution to a cluster-impurity function is minimized, and the M-step recomputes each cluster centroid by averaging cluster is saved as a micro-cluster. These micro-clusters serve as a classi fi cation model.
To cope with stream evolution, Masud et al. [22] keep an ensemble of L models. Whenever a new model is built from a new data chunk, they update the ensemble by choosing the best L models from L +1 models (previous L models and the new model), based on their individual accuracies on the labeled instances of the new data chunk. Besides, they re fi ne the existing models in the ensemble whenevera new any drift detection method. 3. Background on EM algorithm
Let D denote the data stream that arrives over time in batches. Let D s denotes the batch at step s . D s ( instances. N s = N s u + N s l denotes the total size of D s .

Learning a classi fi er from the D s data corresponds to maximizing the likelihood of D s given the parameters  X  s . Assuming that instances are independent, this likelihood is the product of all (labeled and unlabeled) instance probabilities expressed as follows [24]: where the fi rst term is derived from labeled instances, and the second one is based on unlabeled data where the sum expresses the fact that the unknown class value can be any of the existing values. Then, considering logP ( D s |  X  s )= LL ( D s |  X  s ) ,wehave: Notice that this equation contains a log of sums for the unlabeled data, which makes a maximization by partial derivatives with respect to  X  s analytically intractable.

Consider that we can have access to the class labels of all the instances, represented using a matrix of binary indicator variables z , where rows correspond to different instances and columns to different can be rewritten as follows without a log of sums , because only one term inside the sum would be non-zero: labeled data in D s l . Then, it iterates over the E-and M-steps:  X  The E-step uses the current classi fi er parameters to probabilistically assign labels to the unlabeled
These two steps are iterated until convergence as proved by Dempster et al. [7]. At convergence, EM fi nds  X   X  s that locally maximizes the log likelihood with respect to both labeled and unlabeled data. 4. New approach for mining concept-drifting data streams with a limited number of labeled regression, learnt from both labeled and unlabeled instances. Then, we will present the drift detection method. 4.1. Used classi fi ers 4.1.1. Naive bayes ( NB ) detailed. Based on the assumption that the features are all conditionally independent of one another given the class variable C , parameters  X  s denote the probability table of C ,i.e. P ( C ) ,aswellasthe conditional pr obability ta bles of each feature X r given C ,i.e. P ( X r | C ) ,r  X  X  1 ,...,n } . then, the most probable class is selected. More formally, 4.1.2. Logistic regression ( LR )
Logistic regression [11] is a discriminative classi fi er that maximizes the conditional log likelihood instead of the log likelihood. Hence, in this case, instead of (3), EM algorithm maximizes the following formula:
To classify a given instance, the posteri or probab ility of each possible class value c j is computed as follows: Then, the c j value with the maximum probability is assigned as a label.
 4.2. Detecting a concept drift
Given a new batch of data D s +1 , the objective is to detect changes whenever they occur and adapt the be indicated.

In order to detect possible changes, we use the KL divergence [20], also known as the relative entropy, has two fundamental properties, namely, non-negativity, being 0 iff the two compared distributions are the same, and asymmetry. Moreover, a higher KL value indicates a higher dissimilarity between distributions, and so, a pronounced drift.

First, in orderto monitorthe conditionalchange, we proceed to measure the KL divergence kl cc between computed as a sum of KL divergences, each of which m easuring the divergence between the conditional distributions of the class given feature instantiation, expressed as follows: In addition, to monitor the feature change, we measure the KL divergence kl fc between the feature distributions of D s +1 and D s using all the labeled and unlabeled instances except the class variable:
In order to determine whether or not the computed KL measures are statistically signi fi cant, we use the bootstrapping method [8] following previous work reported in [6]. Intuitively, this method allows us to determine, by repeated sampling with replacement from the data, whether or not a speci fi c measurement on the data is signi fi cant.

Speci fi cally, to decide whether or not the resulting kl cc value is signi fi cant, we consider the null hypothesis denoting that no conditional change has occurred. So, our objective is to determine the probability of observing the value kl cc if H 0
To this end, given the empirical distribution  X  P D s  X  P  X  P between each two samples S b 2 and S b 1 , b =1 ,...,k . The obtained estimates form an empirical percentile of the bootstrap estimates, and  X  is a desired signi fi cance level. statistically signi fi cant and invalidates H 0 detected.
 hypothesis Note that, if either a feature or conditional change is detected, we proceed to learn a new classi fi er. Otherwise, the current classi fi er is left unchanged.

To recapitulate, Al gorithm 1 outlines the whole p roposed approach . First, KL divergence and the that no change occurred, the classi fi er is left unchanged (step 6).
 Algorithm 1 5. Experimental study 5.1. Used data sets
We test our approach on the following synthetic and real data sets. 5.1.1. Rotating hyperplane data set
The rotating hyperplane data set is considered as a benchmark synthetic data set and has been widely used to simulate the concept drift problem [10,14,28,30]. In fact, this synthetic data set allows us to hence, to investigate the performance of our approach under controlled conditions.

A hyperplane in an n -dimensional space is denoted by n i =1 w i x i = w 0 ,where w =( w 1 ,...,w n ) T and w 0 values are determined so that w 0 = 1 2 n i =1 w i .

We generated x i from a Gaussian distribution with mean  X  i and variance  X  2 i . The feature change with a probability of 0.1. We generated a data stream of 10 dimensions ( n = 10) with 80,000 instances, we split the whole data stream into sets of blocks of size 2000, and from each block we considered equal training and testing subsets of size 1000, such that every training set is followed by a testing set. 5.1.2. Mushroom data set
The mushroom data set, from the UCI repository [2], is regarded as having virtual concept drift (i.e. 22 variables and 8124 instances. We split it into 6 blocks, and used 1000 instances from each block for training and 354 instances for testing. 5.1.3. Malware detection data set
The malware detection data set represents the important problem of continuously classifying received are protected against malicious code. This data set has been provided by an IT security company and consists of 40,000 records. It contains 5398 features and a binary class taking either the malware or goodware value. Due to the con fi dentiality of the data, we omit the name of the company here, as well as the detailed description of the features.

Contrary to experiments with the previous data, we do not know whether or not changes occur in this real data set; and if so, we do not know when and which kind of changes occur. Moreover, we do not fi x the percentage of labeled data in each block. Instead, we use all the available labeled data, the number may vary from one data block to another.

We also deal with two additional issues to process this malware detection data set. The fi rst is feature and redundancy and enhance classi fi er performance. In this paper, we use the conditional mutual information maximization criterion (CMIM) [9]. It iteratively picks features that maximize their mutual information with the class variable, conditionally upon the response of the already picked features. In this way, CMIM ensures weak dependency and no redundancy as it does not select a feature similar to any that have already been picked even if it is individually powerful.

In our case, feature selection is applied each time we learn a new classi fi er, i.e. each time we detect changes. Hence, a new and more informative subset of features is selected given new incoming data. In fact, some old selected features may be removed and new different features may be selected. This, consequently, allows us to build more ef fi cient classi fi ers.

Thesecondissueis imbalanced data since the number of malware instances is much higher than goodware instances. This leads to an important problem since the learned classi fi er may be biased towards the malware class, and therefore its predictive accuracy may be very poor on the goodware class. We apply two recent approaches to balance the class distribution:  X  The clustering-sampling approach proposed by Wang et al. [31] makes use of the k-means clustering  X  The selectively recursive approach (SERA) proposed by Chen and He [5] makes use of the previous
The malware detection data set is divided into sets of blocks of size 4000, and from each block, the selection, we select 50 of the 5398 features.

To summarize, the details of the three considered data sets are given in Table 1. Note fi nally that, for bootstrap parameters, we use the signi fi cance level  X  = 0.05 and samples number k = 500 in all experiments. Our choice is based on Dasu et al. X  X  work [6] where they prove that the number of samples samples. They also point out that lower  X  values make the null hypothesis harder to reject, leading to a lower change detectability. According to our experiments,  X  = 0.05 works well and can be considered as an appropriate value. 5.2. Experimental results 5.2.1. Results with rotating hyperplane data set
Table 2 represents the results for the drift detection proposal. The fi rst column represents the block numbers of the training sets. For instance, 1 X 2 denotes that the current data is the training set of the fi rst block, while the new data corresponds to the training set of the second block. Then, in columns 2 report kl cc and  X  kl  X  cc respectively, for 2% , 5% and 10% of labeled data.

As expected, a feature change is only detected between blocks 10 and 11 where the magnitude of change t goes from 0.1 to 0.2, blocks 20 and 21 where t goes from 0.2 to 0.5, and blocks 30 and 31 showing a more signi fi cant drift in the feature distributions between the data blocks.
The same applies to the conditional distributions monitored by kl cc values for both 5% and 10% of labeled data, where higher kl cc values are obtained for higher t values. However, in the case of 2% of labeled data, no conditional changes are detected. This can be explained by the fact that the true conditional distribution cannot be accurately approximated with very few labeled instances. In their experiments studying the effect of window size on the performance of the change detection scheme, Dasu et al. [6] come to the same conclusion, i.e a larger window size gives better approximation of the true underlying distribution and results in a better detection of changes.

Furthermore, Fig. 1 presents accuracy curves for NB and LR. For each curve, the x-axis represents the block number, and the y-axis represents the classi fi cation accuracy. Obviously, the performance of both NB and LR is much better when higher percentages of labeled data are considered. Note also that in this data set LR always outperforms NB, which is mainly due to the small percentages of labeled data. In fact, as also pointed out in [1], the presence of only few labeled data may lead to poor estimates of the generative approach. 5.2.2. Results with mushroom data set
According to the results in Table 3, feature changes are only detected between blocks 1 and 2, and blocks 4 and 5. However, no conditional changes are detected for any of the percentages of labeled data as expected. This proves that our detection method is resilient to false alarms.

Moreover, according to Fig. 2, using more labeled data improves the predictive accuracies of both NB and LR. Nevertheless, the improvement is negligible for LR from 5% to 10% of labeled data and the corresponding curves are almost superimposed. Notice also that LR always outperforms NB and has a more stable behavior especially when more labeled data are used. 5.2.3. Results with malware detection data set
Table 4 presents drift detection results for the malware detection data set. The fi rst column reports as previously the block numbers, while the second column represents the percentage of labeled instances observe that feature and conditional changes occur together and are detected between blocks 3 and 4, and again between blocks 8 and 9.

To evaluate classi fi er performance, we previously used only the overall classi fi cation accuracy. How-between the number of correctly classi fi ed instances of different classes.

Using balancing methods mainly aims to improve the classi fi er performance over the positive class, i.e. reduce the number of false positives. In order to appropriately monitor the behavior of NB and LR metrics based on the confusion matrix analysis.
 We observe that, in most cases, LR accuracies are slightly higher than for NB.

Furthermore, both NB and LR provide high precision values for all testing blocks, where all values are greater than 95%, and yield good results in terms of F1 and G-mean values, which is indicative of a good performance predicting the positive instances.

For the clustering-sampling balancing approach, as shown in Table 6, LR outperforms NB, except on the last two testing sets, where NB shows better accuracies, as well as better recall and F1 values.
Finally, note that the results of the two applied balancing approaches are comparable, with a slightly better performance of the clustering-sampling approach in terms of overall accuracy, recall and F1 6. Conclusion
We deal with a more realistic and important problem in data stream mining, which most existing research has failed to address assuming data streams to be entirely labeled. In our research, using both labeled and unlabeled instances, we not only assert the presence or absence of drift but we also ef fi ciently determine which kind of drift has occurred -feature, conditional or dual-using Kullback-Leibler divergence and a bootstrapping method. Then, if required, we update the classi fi er using the EM algorithm. Experimental results with naive Bayes and logistic regression show that our approach is effective for detecting different kinds of changes from data containing both labeled and unlabeled instances, as well as having a good classi fi cation performance.

In the future, it would be interesting to investigate and compare the performance of other classi fi ers with our results. Furthermore, note that in this paper we assume that labeled and unlabeled data come line of research would be to consider the scenario where labeled and unlabeled data possibly come from change detection proposal.
 Acknowledgements This work has been supported by the Spanish Ministry of Science and Innovation under projects TIN2007-62626, TIN2008-06815-C02-02, Consolider Ingenio 2010-CSD2007-00018, and by the Cajal Blue Brain project.
 References
