 Structural hints in XML-retrieval queries can be used to specify both the granularity of the search result (the target element) and where in a document to search (support elements). These hints might be interpreted either strictly or vaguely, but does it matter if an XML search engine interprets these in one way and the user in another? The performance of all runs submitted to INEX 2005 content and structure (CAS) tasks were measured for each of four different interpretations of CAS. Runs that perform well for one interpretation of target elements do so regardless of the interpreta-tion of support elements; but how to interpret the target element does matter. This suggests that to perform well on all CAS queries it is necessary to know how the target structure specification should be interpreted. We exte nd the NEXI query language to include this, and hypothesize that using this will increase the overall performance of search engines. H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  query formulation, Search process .
 Measurement, Performance, Experimentation. Element retrieval, XML retrieval, INEX. In an element retrieval system it is possible to search not only whole documents, but also docum ent elements. Considerable resources have been spent de signing and implementing query languages for exactly this purpose. Languages like XPath [2] have been designed to enable searchers to specify exactly not only which documents they are looking for but also which elements within those documents. Investigations into user beha vior on web search engines has shown that the average number of te rms per query is 2.2 [1]. It is hard to recon this result with the complex query languages seen for XML. Work done as part of the INEX initiative has shown that even expert searchers find it hard to correctly specify queries in such languages [3]. INEX c onsequently uses none of these languages but has adopted its ow n called NEXI [4], which has been shown to be effective for both expert and novice users [5,6]. Assessments were made against the narrative of the topic, the natural language description of the information need. These assessments are those that satisfy the vaguest interpretation of the query, the VVCAS assessment pool. The SVCAS (strict target) pool is a subset of thes e judgments; only those strictly matching the target element cons traint  X  computed by removing all relevant elements that did not match the target. For VSCAS and SSCAS, a relevant element must come from a document containing elements that strictly conform to all given child topics. For most topics these documents were computed as the set intersection of those relevant to all that topic X  X  children 3 . This document list is then us ed to filter the VVCAS pool. In total 10 topics have relevant elements in the pools for VVCAS and SVCAS (topics 253, 256, 257, 260, 261, 264, 265, 270, 275, and 284). Of these, th ree topics (253, 261, and 265) have no elements conforming to a strict interpretation of the support element and so were not used in VSCAS and SSCAS evaluation. Performance was measured using MAep with gener-alized quantization as is standard in XML retrieval. The performance of each run was computed for each interpreta-tion. Presented in Figure 1 is the performance of these runs for both VVCAS and the VSCAS. Regardless of the task to which a run was submitted, those that pe rform well at VVCAS also per-form well at VSCAS. The two interpretations are similar. A similar result can be seen for SVCAS and SSCAS, but not for the others (see, for example, Figure 2). Table 1 presents the Pearson product moment correlation coef-ficients for the performance of each run against each pair of interpretations  X  that is, how well the performance on one task correlates to the performance on another (irrespective of sub-mitted task). This suggests two se parate interpretations of CAS, that in which the target element is interpreted strictly and that in which it is interpreted vaguely. The interpretation of the support elements does not app ear to be important. When users supply structural hints in their query they are ex-pecting it to be interpreted in a particular way. We have shown that there is (presently) no  X  X ne an swer fits all X  interpretation of the structural hints, and that different runs (ranking algorithms) perform well for different interpre tations. It follows that to per-form well at all CAS queries an XML search engine must know how to interpret the target element structural hints. We now extend NEXI by adding an optional strict operator ($) to the end of a path specification. In this way the path //article//sec is a vague structural constraint, but //article//sec$ is a constraint requiring strict conformance. By taking this new operator into consideration an XML search engine can choose the most appropriate ranking algorithm for the query, which we hypothesize will result in a search engine precision increase. 
