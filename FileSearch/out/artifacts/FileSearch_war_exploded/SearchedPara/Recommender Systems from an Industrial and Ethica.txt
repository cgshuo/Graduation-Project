 Over the recent years, a plethora of recommender systems (RS) have been proposed by academics. The degree of adopt-ability of these algorithms by industrial e-commerce plat-forms remains unclear. To get an insight into real-world recommendation engines, we survey more than 30 existing shopping cart solutions and compare the performance of pop-ular recommendation algorithms on proprietary e-commerce datasets. Our results show that deployed systems rarely go beyond trivial  X  X est seller X  lists or very basic personalized recommendation algorithms, which nevertheless exhibit su-perior performance to more elaborate techniques both in our experiments and other related studies. We also perform chronological dataset splits to demonstrate the importance of preserving the sequence of events during evaluation, and the recency of events during training. The second part of our research is still ongoing and focuses on various ethical chal-lenges that complicate the design of recommender systems. We believe that this direction of research remains mostly neglected despite its increasing impact on RS X  quality and safety.
 industrial recommender systems; recommendation ethics; Netflix Prize; ethical recommendation framework; e-commerce; recommender systems survey
Recommender systems emerged as an independent research area of machine learning in mid-1990s and received a great deal of attention after the announcement of the Netflix Prize in 2006. The contest was set to crowdsource recommenda-tion algorithms from the large research community, whose goal was to surpass Netflix X  own algorithm by 10% in terms http://www.netflixprize.com/ of accuracy (measured in RMSE). After 10 years, the Net-flix Prize still teaches us lessons. One of them is the fact that the prize-winning algorithm was never put to real use: Netflix concluded that the measured accuracy gains  X  X id not seem to justify the engineering effort needed to bring them into a production environment X  [1]. This motivates the investigation of the receptiveness of e-commerce platforms to recent academic advances in the field of recommender systems. We trust that the high practical value of recom-mender systems in e-commerce ought to be the reason why this research field exists in the first place. As Pradel et al. [13] note,  X  X ase-studies are necessary to better understand the specificities of purchase datasets and the factors that impact recommender systems for retailers X . The first part of our work is such a case study. The specificity of purchase datasets has to do with the absence of explicit feedback (such as movie ratings) and the extreme sparsity of data (because of the severe long-tail effect). As a result, the majority of algorithms designed for rating datasets cannot be directly applied to purchase data. Furthermore, many e-commerce domains (e.g. fashion, travel, etc.) exhibit more profound seasonality effects in comparison to movie rating datasets. Therefore, we argue that the realistic offline evaluation of recommendation algorithms in industrial contexts has to be done on time-based dataset splits, as we explain in Section 2. We also present the results of the survey and our comparative study of several recommendation algorithms.
 Aside from the apparent research shift towards explicit feed-back RS, the comparably smaller amount of research on e-commerce RS may also be attributed to the lack of publicly available retail datasets. In our experience, many retailers are reluctant to release their sensitive purchase data because of the failure of anonymization [10]. This is where another motivating lesson from the Netflix Prize comes in. This time, we learn the lesson of ethics: two years after its public release, the Netflix dataset was de-anonymized via a linking attack [8], putting the privacy of 500,000 users at risk. This resulted in a lawsuit and put an end to the planned Netflix Prize sequel [7]. The problems of ethics in recommender systems certainly go far beyond anonymization and relate to areas such as data collection and filtering, algorithmic opacity and biases, behaviour manipulation, A/B testing, etc. According to the recent study by Tang &amp; Winoto [14], there exist only two publications (apart from [14]) that specifically address the problem of ethical recommendations. Therefore, this research direction deserves further attention. We discuss ethical issues briefly in Section 3. We conclude the paper and outline our future work in Section 4. Our study 2 employs mixed methodology to meet its goals. First, we conduct offline experiments to compare the per-formance of algorithms from three families of collaborative filtering (CF): Most popular and random product recommendations are used as baselines. The accuracy of algorithms is measured in terms of MAP , F1@5 , and R-precision . The optimal parameters for algorithms are estimated via golden section search. We refer the reader to [11] for the technical details of the above algorithms and evaluation metrics. The evaluation is performed both on random and chronological dataset splits. The datasets come from two real e-commerce retailers: a fashion store (denoted as D1) and a book store (denoted as D2). The summary of the two datasets is given in Table 1. The results of the experiments are presented in Section 2.3.1.
Second, we run an online survey 3 to assess recommen-dation engines of existing e-commerce platforms on three criteria: a) properties of recommendations , b) data utilized for recommendations , and c) recommendation techniques . The selection of these techniques is based on the classification by Amatriain et al. [2] (with the addition of several extra techniques). The survey results are given in Section 2.3.2.
In our experiments, we follow two data splitting strategies: 1. Traditional approach (random split) . As it is often practised in the RS literature, we discard cold-start users (having less than 10 purchases in our case) and then split user profiles into training and test sets using random sampling (50/50 ratio in our case). Finally, we divide users into 5 folds for cross-validation. 2. Proposed approach (chronological split) . To at-tempt a more realistic evaluation, we keep cold-start users in the dataset and divide it using time-based split points. In particular, we propose an expanding time window approach, where after setting the temporal split point, the recommender is trained on increasing portions of the training set, starting from the most recent events and ending with the full history. published in full in [11] http://goo.gl/forms/zFEfLLlFHO those with at least 2 events to allow per-user splitting
The motive for attempting both approaches was to deter-mine whether the commonly used random splits can reliably reproduce the ranking of algorithms coming from more real-istic temporal, cold-start splits.
The performance of algorithms in random mode is given in Tables 2 and 3. It can be seen that UserKNN and ARM outperform MF-based methods on all metrics. This is par-ticularly evident in case of D2, where BPRMF performs on the same level as the recommender of most popular items. This finding is in line with those reported in [13].
In chronological mode, the temporal dataset partitioning resulted in the following splits: From observing the accuracy measurements of algorithms for each training set 5 , we can see that the optimal training history for D1 amounts to the last 3 months of data, which appears reasonable for a fashion store. Likewise, the trend of favouring recent events was observed in D2. It was also evident that the best seller list X  X  accuracy peaked when it was trained on the most recent and smallest chunk of data. After averaging accuracy scores over all training sets (Tables 4 and 5), we noticed that the relative ranking of algorithms was very similar to that of the random split, with UserKNN and ARM being on top. In absolute terms, however, the accuracy scores dropped down significantly in the chronological mode. Whereas this can be attributed to the presence of cold-start users, in our additional experiments (not reported here) we show empirically that the random splitting itself can significantly overestimate the accuracy of algorithms.
In terms of running times, MF-based methods were either (fairly) accurate or fast, but never both. The accuracy-speed trade-off of these models is adjusted by balancing between the number of iterations and the number of factors. The best accuracy-speed ratio was achieved by ARM, which also required no parameter tuning. 20 commercial and 11 open-source e-commerce platforms participated in the survey, whose responses are summarized in Figure 1.

We can see that transactional data is used by more than 80% of respondents, which points to the clear dominance of CF over content-based filtering. Surprisingly, temporal data is mostly neglected by industrial RS, which contrasts to our empirical findings. It seems that commercial platforms tend to put more effort in personalization than their open-source rivals. We observe that neighborhood-based CF and association rules mining are the most popular personalized recommenders, which is totally in line with our experimental results. Recommending best sellers is the preferred approach for most platforms. Indeed, our experiments show that outperforming best-seller lists can be a challenging task even for personalized recommenders. Moreover, trivial random and manual recommenders appear more widespread than state-of-the-art techniques, such as MF-based algorithms. the performance charts are omitted due to limited space Table 4: Average scores for the chronological split on D1 Table 5: Average scores for the chronological split on D2
Our ongoing work focuses on another rather overlooked as-pect of recommender systems, which is the problem of ethics . This problem is multifaceted and relates to many broader ar-eas of data science. In this section, we give a brief overview of some ethical challenges in and around recommender systems.
Data collection . The lack of transparency and informed consent is what explains the great demand in  X  X o not track X  tools that would help users gain control over the data collec-tion process. Furthermore, enriching user profiles by means of tracking cookies, linked open data, social networks, and even data brokers increase the risk of user privacy breaches.
User profiling . User behaviour profiles built for serving personalized recommendations may as well be utilised for malicious purposes, such as phishing or social engineering [7]. Moreover, disclosed user profiles may reveal sensitive private information. Profile injection is another possible attack that uses fake profiles to promote or demote recommendations of certain items [3], e.g. by artificially influencing their ratings. A number of privacy preserving collaborative filtering (PPCF) algorithms have been proposed in RS literature (e.g. [15]) to protect user profiles from leakage. The major challenge in such systems is to preserve recommendation accuracy.
Data publishing . The massive research on RS would not be possible without publicly released datasets (MovieLens, Netflix, etc.), which have positive impact on both research and practice [5]. Because a public dataset typically contains private data, releasing a myriad of user records is a serious and responsible moral act. The naive assumption that the dataset remains safe as long as personally identifiable infor-mation has been disguised has long ceased to hold. Many examples of user re-identification in anonymized datasets (e.g. [9]) have been reported in the literature (recall the Net-flix case). The existence of quasi-identifiers and rich  X  X utside X  information makes de-anonymization of public datasets a per-sistent threat. On the other hand, an attempt of aggressive anonymization can render the dataset useless for a RS.
Data filtering . With very few exceptions (e.g. [14]), con-temporary RS do not employ any moral filtering of their output. This raises an issue of content censorship with all its consequent implications. As noted in [14], what is algorith-mically appropriate is not necessarily ethically appropriate. Should the RS be held liable for serving offensive or hazardous content? How to balance between commercial and moral val-ues in a RS? The ethical appropriateness of candidate items can be established by mapping potentially harmful elements in media content (drug use, nudity, etc.) to a user X  X  persona (gender, age, etc.), as explained in [14]. Authors suggest that moral values are incorporated in system requirements, with users having control over the filtering process.
Algorithmic opacity . A typical RS operates as a  X  X lack box X , with its output being the only part that is visible to a user. Collecting data and processing it into recommenda-tions is done completely behind the scenes. What are the ethical implications of not knowing the algorithm that rules recommendations? Apparently, this opacity makes it hard to reason about the political, economic, and cultural agendas behind these suggestions [12]. From the corporate ethics per-spective, however, the intentional secrecy is needed to retain company X  X  competitive advantage. Even when an algorithm is not kept in secrecy, explaining it to a user might be hardly possible because of its inherent mathematical complexity.
Biases and behaviour manipulation . In their interac-tion with RS, how can users be certain that their interests are respected and prioritized? What if the users X  behaviour is being algorithmically manipulated to meet RS X  X  own ob-jectives (e.g. selling expensive / overstocked / nearly expired products)? One example of an unethical algorithmic bias is price discrimination , i.e. charging customers different prices based on their perceived willingness to pay [4]. How to ensure that the RS is unbiased? One way to aid transparency is to implement an explanation interface [6] for recommendations.
A/B testing . Many industrial RS resort to A/B testing to assess the effects of tweaking their algorithms. In most cases, visitors are silently dragged into these experiments without their knowledge, let alone consent. Should an e-commerce interface allow users to opt out of A/B testing? Is it their moral right to demand interacting with the  X  X eal X  recommender system instead of the one being put to test?
In this paper, we have taken a closer look at industrial recommender systems in e-commerce and have touched upon certain ethical implications that affect the design and imple-mentation of these systems.

After experimenting on retail data and surveying existing e-commerce platforms, we conclude that their adoption of sophisticated RS that have been proposed by the research community over the years is rather slow. Whether it has to do with the unjustifiable  X  X ngineering efforts X  that had stopped Netflix from implementing a better algorithm, or strict real-time performance requirements of industrial shopping cart solutions, the suitability of these models to the realities of the e-commerce realm requires further investigation.
Our experiments also illustrate the importance of time-aware evaluation, where dataset splits are done chronologi-cally and the sequence of events in user profiles is preserved. Without this property, the analysis of a retail dataset is prone to significant overestimation of the algorithm performance due to capturing erroneous shopping patterns. We also show that training on all available history is in most cases subop-timal. The proposed expanding time window method can be used to establish the optimal timespan of the training set, thus improving recommendation accuracy and speed.

Finally, we observe that multiple moral dilemmas of varied severity emerge on virtually every stage of RS design. We plan to continue our work on identifying their impact and possible solutions in hope to outline an ethical framework for RS designers. [1] X. Amatriain and J. Basilico. Netflix recommendations: [2] X. Amatriain, A. Jaimes, N. Oliver, and J. Pujol. Data [3] R. Burke, M. O X  X ahony, and N. Hurley. Robust [4] N. Diakopoulos. Algorithmic accountability reporting: [5] F. M. Harper and J. A. Konstan. The movielens [6] J. L. Herlocker, J. A. Konstan, and J. Riedl. Explaining [7] A. Koene, E. Perez, C. J. Carter, R. Statache, [8] A. Narayanan and V. Shmatikov. Robust [9] A. Narayanan and V. Shmatikov. De-anonymizing [10] P. Ohm. Broken promises of privacy: Responding to [11] D. Paraschakis, B. J. Nilsson, and J. Holl  X  ander. [12] F. Pasquale. The black box society. the secret [13] B. Pradel, S. Sean, J. Delporte, S. Gu  X erif, C. Rouveirol, [14] T. Tang and P. Winoto. I should not recommend it to [15] J. Zhan, C.-L. Hsieh, I.-C. Wang, T.-S. Hsu, C.-J. Liau,
