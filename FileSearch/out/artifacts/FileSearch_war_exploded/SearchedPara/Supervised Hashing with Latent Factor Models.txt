 Due to its low storage cost and fast query speed, hashing has been widely adopted for approximate nearest neighbor search in large-scale datasets. Traditional hashing methods try to learn the hash codes in an unsupervised way where the metric (Euclidean) structure of the training data is pre-served. Very recently, supervised hashing methods, which try to preserve the semantic structure constructed from the semantic labels of the training points, have exhibited higher accuracy than unsupervised methods. In this paper, we pro-pose a novel supervised hashing method, called latent factor hashing (LFH), to learn similarity-preserving binary codes based on latent factor models. An algorithm with conver-gence guarantee is proposed to learn the parameters of LFH. Furthermore, a linear-time variant with stochastic learning optimization is proposed for training LFH on large-scale datasets. Experimental results on two large datasets with semantic labels show that LFH can achieve superior accu-racy than state-of-the-art methods with comparable training time.
 H.3.3 [ Information Storage And Retrieval ]: Informa-tion Search and Retrieval| Retrieval models Hashing; Latent Factor Model; Image Retrieval; Big Data
Nearest neighbor (NN) search plays a fundamental role in machine learning and related areas, such as pattern recog-nition, information retrieval, data mining and computer vi-sion. In many real applications, it's not necessary for an algorithm to return the exact nearest neighbors for every possible query. Hence, in recent years approximate nearest neighbor (ANN) search algorithms with improved speed and memory saving have been received more and more attention by researchers [1, 2, 7].

Over the last decades, there has been an explosive growth of data from many areas. To meet the demand of perform-ing ANN search on these massive datasets, various hashing techniques have been proposed due to their fast query speed and low storage cost [1, 4, 5, 8, 10, 16, 20, 21, 26, 27, 31, 35, 36, 37, 38, 39, 40, 41]. The essential idea of hashing is to map the data points from the original feature space into binary codes in the hashcode space with similarities between pairs of data points preserved. Hamming distance is used to measure the closeness between binary codes, which is de-ned as the number of positions at which two binary codes differ. More speci cally, when two data points are deemed as similar, their binary codes should have a low Hamming distance. On the contrary, when two data points are dis-similar, a high Hamming distance is expected between their binary codes. The advantage of binary codes representation over the original feature vector representation is twofold. Firstly, each dimension of a binary code can be stored us-ing only 1 bit while several bytes are typically required for one dimension of the original feature vector, leading to a dramatic reduction in storage cost. Secondly, by using bi-nary codes representation, all the data points within a spe-ci c Hamming distance to a given query can be retrieved in constant or sub-linear time regardless of the total size of the dataset [30]. Because of these two advantages, hashing techniques have become a promising choice for efficient ANN search on massive datasets.

Existing hashing methods can be divided into two cate-gories: data-independent methods and data-dependent meth-ods [6, 17, 18]. For data-independent methods, the hash-ing functions are learned without using any training data. Representative data-independent methods include locality-sensitive hashing (LSH) [1, 5, 7], shift-invariant kernels hash-ing (SIKH) [22], and many other extensions [4, 13, 14]. On the other hand, for data-dependent methods, their hashing functions are learned from some training data. Generally speaking, data-dependent methods often require less num-ber of bits than data-independent methods to achieve satis-factory performance.

The data-dependent methods can be further divided into two categories: unsupervised and supervised methods [17, 20, 32]. Unsupervised methods try to preserve the metric (Euclidean) structure between data points using only their feature information. Representative unsupervised methods include spectral hashing (SH) [34], principal component anal-ysis based hashing (PCAH) [33], iterative quantization (ITQ) [6], anchor graph hashing (AGH) [18], isotropic hashing (Iso-Hash) [9], multimodel latent binary embedding (MLBE) [42] and predictable dual-view hashing (PDH) [23]. Due to the fact that high level semantic description of an object of-ten differs from the extracted low level feature descriptors, known as semantic gap [25], returning nearest neighbors according to metric distances between the feature vectors doesn't always guarantee a good search quality. Hence, many recent works focus on supervised methods which try to preserve the semantic structure among the data points by utilizing their associated semantic information [17, 19]. Although there are also some works to exploit other types of supervised information like the ranking information for hashing [16, 20], the semantic information is usually given in the form of pairwise labels indicating whether two data points are known to be similar or dissimilar. Representa-tive supervised methods include restricted Boltzmann ma-chine based hashing (RBM) [24], binary reconstructive em-bedding (BRE) [12], sequential projection learning for hash-ing (SPLH) [33], minimal loss hashing (MLH) [19], kernel-based supervised hashing (KSH) [17], and linear discrimi-nant analysis based hashing (LDAHash) [28]. Additionally, there are also some semi-supervised hashing methods [32] which use both labeled data and unlabeled data to train their model. As stated in recent works [17, 19, 20], so-phisticated supervised methods, such as SPLH, MLH, and KSH, can achieve higher accuracy than unsupervised meth-ods. However, some existing supervised methods, like MLH, suffer from a very large amount of training time, making it difficult to apply to large-scale datasets.

In this paper, we propose a novel method, called latent factor hashing (LFH), for supervised hashing. The main contributions of this paper are outlined as follows:
The rest of the this paper is organized as follows: In Sec-tion 2, we will introduce the details of our LFH model. Ex-perimental results are presented in Section 3. Finally, we conclude the paper in Section 4.
In this section, we present the details of our latent factor hashing (LFH) model, including the model formulation and learning algorithms.
Suppose we have N points as the training data, each rep-resented as a feature vector x i 2 R D . Some pairs of points have similarity labels s ij associated, where s ij = 1 means x and x j are similar and s ij = 0 means x i and x j are dis-similar. Our goal is to learn a binary code b i 2 f 1 ; 1 for each x i with similarity between pairs preserved. In par-ticular, when s ij = 1, the binary codes b i and b j should have a low Hamming distance. On the other hand, when s ij = 0, the Hamming distance between b i and b j should be high. In compact form, we use a matrix X 2 R N D to denote all the feature vectors, a matrix B 2 f 1 ; 1 g N Q denote all the binary codes, and a set S = f s ij g to denote all the observed similarity labels. Additionally, we use the notation A i and A j to denote the i th row and the j th column of a matrix A , respectively. A T is the transpose of A . The similarity labels S can be constructed from the neighborhood structure by thresholding on the metric dis-tances between the feature vectors [17]. However, such S is of low quality since no semantic information is utilized. In supervised hashing setting, S is often constructed from the semantic labels within the data points. Such labels are often built with manual effort to ensure its quality.
Let ij denote half of the inner product between two bi-nary codes b i ; b j 2 f 1 ; 1 g Q : Th e likelihood of the observed similarity labels S can be de ned as follows: with where a ij = ( ij ) with being the logistic function: It is easy to prove the following relationship between the Hamming distance dist H ( ; ) and inner product of two bi-nary codes: W e can nd that the smaller the dist H ( b i ; b j ) is, the larger p ( s ij = 1 j B ) will be. Maximizing the likelihood of S (1) will make the Hamming distance between two similar points as small as possible, and that between two dissimilar points as high as possible. Hence this model is reasonable and matches the goal to preserve similarity.

With some prior p ( B ), the posteriori of B can be com-puted as follows: We can use maximum a posteriori estimation to learn the optimal B . However, directly optimizing on B is an NP-hard problem [34]. Following most existing hashing methods, we compute the optimal B through two stages. In the rst stage, we relax B to be a real valued matrix U 2 R N Q . The i th row of U is called the latent factor for the i th data point. We learn an optimal U under the same probabilistic framework as for B . Then in the second stage, we perform some rounding technique on the real valued U to get the binary codes B .

More speci cally, we replace all the occurrences of B in previous equations with U . ij is then re-de ned as: S imilarly, p ( S j B ), p ( B ), p ( B j S ) are replaced with p ( p ( U ), p ( U j S ), respectively. We put a normal distribution on p ( U ): where N ( ) denotes the normal distribution, I is an identity matrix, and is a hyper-parameter. The log posteriori of U can then be derived as: where  X   X  F denotes the Frobenius norm of a matrix, and c is a constant term independent of U . The next step is to learn the optimal U that maximizes L in (2).
Since directly optimizing the whole U can be very time-consuming, we optimize each row of U at a time with its other rows xed. We adopt the surrogate algorithm [15] to optimize each row U i . The surrogate learning algo-rithm can be viewed as a generalization of the expectation-maximization (EM) algorithm. It constructs a lower bound of the objective function, and then updates the parameters to maximize that lower bound. Just like EM algorithm, we need to derive different lower bounds and optimization pro-cedures for different models [15]. In the following content, we will derive the details of the surrogate learning algorithm for our model.

The gradient vector and the Hessian matrix of the objec-tive function L de ned in (2) with respect to U i can be derived as: I f we de ne H i as: we can prove that wh ere A  X  B means A B is a positive semi-de nite matrix.
Then we can construct the lower bound of L ( U i ), de-noted by e L ( U i ), as: Th e values of U and other parameters that depend on U change through the updating process. Here we use the no-tation x ( t ) to denote the value of a parameter x at some iteration t . We update U i to be the one that gives the maximum value of e L ( U i ). It is easy to see that e L ( U quadratic form in the variable U i , which can be proved to be convex. Hence, we can nd the optimum value of U i by setting the gradient of e L ( U i ) with respect to U i to 0. As a result, we end up with the following update rule for U i
We can then update other rows of U iteratively using the above rule.

The convergence of the iterative updating process is con-trolled by some threshold value " and the maximum allowed number of iterations T . Here " and T are both hyper-parameters. During each iteration, we update U by up-dating each of its rows sequentially. The initial value of U can be obtained through PCA on the feature space X . The pseudocode of the updating process is shown in Algorithm 1.
After the optimal U is learned, we can obtain the nal binary codes B using some rounding techniques. In this paper, to keep our method simple, the real values of U are quantized into the binary codes of B by taking their signs, that is: A lgorithm 1 Optimizing U using surrogate algorithm
In put: X 2 R N D ; S = f s ij g ; Q; T 2 N + ; ; " 2 R +
Initializing U by performing PCA on X . for t = 1 ! T do end for
Output: U 2 R N Q .
In order to perform ANN search, we need to compute the binary code b for a query x which is not in the training set. We achieve this by nding a matrix W 2 R D Q that maps x to u in the following way: We then perform the same rounding technique discussed in Section 2.3.1 on u to obtain b .
 We use linear regression to train W over the training set. The squared loss with regularization term is shown below: And the optimal W can be computed as:
At each iteration, we rst construct a lower bound at the current point U i ( t ), and then optimize it to get a new point U i ( t + 1) with a higher function value L ( U i ( t + 1)). Hence, the objective function value always increases in the new iteration. Furthermore, the objective function value L = log p ( U j S ) is upper bounded by zero. Hence, our Al-gorithm 1 can always guarantee convergence to local maxi-mum, the principle of which is similar to that of EM algo-rithm. This convergence property will also be illustrated in Figure 2. The convergence property of our surrogate algo-rithm is one of the key advantages compared with standard Newton method and rst-order gradient method. In both Newton method and rst-order gradient method, a step size, also called learning rate in some literatures, should be man-ually speci ed, which cannot necessarily guarantee conver-gence.

We can prove that, when updating U i , the total time to compute @L=@ U T i and H i for all i = 1 ; : : : ; N is O and O ( jSj Q 2 ), respectively. Since the inversion of H computed in O ( Q 3 ), the time to update U i following the rule given in (4) is O ( Q 3 ). Then the time to update U by one iteration is O ( N Q 3 + jSj Q 2 ). Therefore, the total time of the updating process is O ( T ( N Q 3 + jSj Q 2 )), where T is the number of iterations.

Besides that, the time for rounding is O ( N Q ). And the time to compute W for out-of-sample extension is O ( N D 2 D 3 + N DQ ), which can be further reduced to O ( N D 2 ) with the typical assumption that Q &lt; D  X  N . With the pre-computed W , the out-of-sample extension for a query x can be achieved in O ( DQ ).
Figure 1: Selection of S for stochastic learning.
For a given set of N training points with supervised infor-mation, there are N N pairs of similarity labels available to form S . Straightforwardly, we can choose S to include all the available similarity pairs, that is, S = f s ij j a colored cell in the i -th row and j -th column indicates that s ij is included in S . In this way, the best possible accuracy can be achieved since we use as much as available semantic information. However, according to the complexity analy-sis described in Section 2.4, if we set S to contain the full supervised information, the time cost to update U would become O ( N Q 3 + N 2 Q 2 ) per iteration, and O ( N 2 ) memory is needed to store S . Such cost in both computation and storage is unacceptable when N grows large.

Inspired by stochastic gradient descent method, we pro-pose an efficient way of updating U , called stochastic learn-ing. As illustrated in Figure 1(b), S contains a sparse subset with only O ( N Q ) entries which are randomly selected from all the available similarity pairs. The random sampling is performed for each iteration. We choose the size of S to be O ( N Q ) so that the time cost to update U is reduced to O ( N Q 3 ) per iteration. For storage efficiency, we compute only the sampled subset during each iteration. By this way, the maximum required storage reduces to O ( N Q ). We can even further reduce the time cost by sampling S in an aligned way. During each iteration, an index set I of size O ( Q ) is randomly chosen from f 1 ; : : : ; N g then construct S by using the rows and columns in I , with entries at the diagonal excluded. The resulted S is shown in Figure 1(c). Following this, the constructed S is guaranteed to be symmetric, and H i de ned in (3) can be simpli ed as: F or all i = 2 I , the set f j : s ij 2 Sg is exactly the same thanks to the alignment of S . This implies that H i remains the same for all i = 2 I . Therefore, we can compute H 1 i preprocessing step. By doing so, the time cost to update U for each i = 2 I can be reduced to O ( Q 2 ). For each i 2 I can update U i through some complicated calculations while still maintaining the O ( Q 2 ) time complexity. We can also safely skip updating U i for that iteration without much loss in performance due to the fact that Q is much smaller than N . Even though U i is not updated for some small portion of i in one single iteration, it will much likely be updated in the subsequent iterations because I changes among the iterations. As a result, the total time cost to update U is reduced to O ( N Q 2 ) per iteration. For Q up to 128, this makes our learning process two orders of magnitude faster.
Con sequently, since Q is bounded by a small constant, we can say that the cost in computation and storage of our learning algorithm are linear to the number of train-ing points N . This makes our LFH easily scalable to very large datasets.
The hyper-parameter in the objective function de ned in (2) acts as a factor weighing the relative importance be-tween the rst and the second term. However, the number of sum items in each term is different: in the rst term there are jSj sum items, while in the second term there are N sum items. Since different datasets may have different values of N and jSj , the optimal value of may vary between the datasets. To address this issue and make our method less dependent on a speci c dataset, we introduce a new hyper-parameter  X  satisfying that: By replacing with  X  in (2), we have a specialized param-eter  X  for each dataset. The optimal value for is then normalized to roughly the same range on different datasets. We can normalize e in (5) by following the same idea.
We nd that the MLH method spends most of the time on selecting the best hyper-parameters for each dataset. With the normalized hyper-parameters introduced, we can pre-compute the optimal values for the hyper-parameters on some smaller dataset, and then apply the same values to all other datasets. This saves us the time of hyper-parameter selection and makes our method more efficient on large datasets.
We evaluate our method on two standard large image datasets with semantic labels: CIFAR-10 [11] and NUS-WIDE [3].

The CIFAR-10 dataset [11] consists of 60,000 color images drawn from the 80M tiny image collection [29]. Each image of size 32 32 is represented by a 512-dimensional GIST feature vector. Each image is manually classi ed into one of the 10 classes, with an exclusive label indicating its be-longing class. Two images are considered as a ground truth neighbor if they have the same class label.

The NUS-WIDE dataset [3] contains 269,648 images col-lected from Flickr. Each image is represented by a 1134-dimensional low level feature vector, including color his-togram, color auto-correlogram, edge direction histogram, wavelet texture, block-wise color moments, and bag of vi-sual words. The images are manually assigned with some of the 81 concept tags. The ground truth neighbor is de ned on two images if they share at least one common tag.
For data pre-processing, we follow the standard way of feature normalization by making each dimension of the fea-ture vectors to have zero mean and equal variance.
For both CIFAR-10 and NUS-WIDE datasets, we ran-domly sample 1,000 points as query set, 1,000 points as val-idation set, and all the remaining points as training set. Us-ing normalized hyper-parameters described in Section 2.6, the best hyper-parameters are selected by using the valida-tion set of CIFAR-10. All experimental results are averaged over 10 independent rounds of random training / validation / query partitions.

Unless otherwise stated, we refer LFH in the experiment section to the LFH with stochastic learning. We compare our LFH method with some state-of-the-art hashing meth-ods, which include:
All the baseline methods are implemented using the source codes provided by the corresponding authors. For KSH and AGH, the number of support points for kernel construction is set to 300 by following the same settings in [17, 18]. For KSH, SPLH, and MLH, it's impossible to use all the super-vised information for training since it would be very time-consuming. Following the same strategy used in [17], we sample 2,000 labeled points for these methods.

All our experiments are conducted on a workstation with 24 Intel Xeon CPU cores and 64 GB RAM.
The convergence curve of the objective function on a sam-pled CIFAR-10 subset of 5000 points with code length 32 is shown in Figure 2. The LFH-Full method refers to the LFH that uses the full supervised information for updating, and LFH-Stochastic refers to the LFH with stochastic learning. The objective function value is computed based on the full supervised information for both methods. We can see that the objective function of LFH-Full converges to a station-ary point after a few iterations. The objective function of LFH-Stochastic has a major trend of convergence to some stationary point with slight vibration. This behavior is quite similar to stochastic gradient descent method and is empir-ically acceptable.

Figure 3 shows the mean average precision (MAP) [10, 17, 19] values computed on a validation set during the updating process. The nal MAP evaluated on a query set is 0.5237 for LFH-Full and 0.4694 for LFH-Stochastic. The reduction in MAP of LFH-Stochastic is affordable given the dramatic decrease in time complexity by using stochastic learning.
We perform Hamming ranking using the generated binary codes on the CIFAR-10 and NUS-WIDE datasets. For each query in the query set, all the points in the training set are ranked according to the Hamming distance between their binary codes and the query's. The MAP is reported to eval-uate the accuracy of different hashing methods.

Figure 4(a) and Figure 4(b) show the averaged MAP re-sults with different code lengths on the two datasets, re-spectively. We can nd that with the help of semantic infor-mation, supervised data-dependent methods can generally achieve better accuracy than data-independent and unsu-pervised data-dependent methods. Furthermore, the accu-racy of our LFH method is much higher than other methods including these supervised data-dependent methods KSH, SPLH, and MLH.

The precision-recall curves with different code lengths will be illustrated in the Appendix at the end of this paper (refer to Figure 9 and Figure 10), which will also show that our LFH method can signi cantly outperform other state-of-the-art hashing methods.
Figure 5(a) and Figure 5(b) show the average training time of different hashing methods with different code lengths on the CIFAR-10 and NUS-WIDE datasets, respectively. The reported values are in seconds in a logarithmic scale.
We can nd that the data-independent hashing meth-ods require the least amount of training time, and the su-pervised data-dependent hashing methods need the most amount of training time. Compared to other supervised data-dependent hashing methods, the training time of LFH is much smaller than that of MLH and is comparable to that of KSH and SPLH. For large code lengths, our LFH is even faster than KSH and SPLH. This is because the number of iterations needed to learn U decreases as the code length increases.
For the results reported in Section 3.4 and Section 3.5, we adopt the same strategy as that in [17] to train KSH, SPLH, and MLH by sampling only 2,000 labeled points due to their high time complexity. To get a deeper comparison, we perform another experiment on smaller datasets where the full supervised information can be used for training. We randomly sample a subset of CIFAR-10 with 5000 points for evaluation. We also include LFH with stochastic learning to better demonstrate its effectiveness. Figure 6 and Fig-ure 7 show the accuracy and computational cost for these methods. Fi gure 6: Accuracy on CIFAR-10 subset with full labels.

We can see that our LFH, even with stochastic learning, can achieve higher MAP than other methods with full labels used. The training speed of LFH with full labels is compara-ble to that of KSH and SPLH, and is much faster than that of MLH. The LFH with stochastic learning beats all other methods in training time. Fi gure 7: Computational cost on CIFAR-10 subset with full labels.

Hence, we can conclude that our LFH method can out-perform other supervised hashing methods in terms of both accuracy and computational cost.
In Figure 8, we demonstrate the hamming ranking results for some example queries on the CIFAR-10 dataset. For each query image, the top (nearest) ten images returned by different hashing methods are shown. We use red rectan-gles to indicate the images that are not in the same class as the query image. That is to say, the images with red rect-angles are wrongly returned results. It is easy to nd that our LFH method exhibits minimal errors compared to other supervised hashing methods. ( a) (b ) returned results of (c) LFH; (d) KSH; (e) MLH; (f) SPLH.
Hashing has become a very effective technique for ANN search in massive datasets which are common in this big data era. In many datasets, it is not hard to collect some supervised information, such as the tag information in many social web sites, for part of the whole dataset. Hence, su-pervised hashing methods, which can outperform traditional unsupervised hashing methods, have become more and more important. In this paper, we propose a novel method, called LFH, for supervised hashing. A learning algorithm with con-vergence guarantee is proposed to learn the parameters of LFH. Moreover, to model large-scale problems, we propose a stochastic learning method which has linear time complexity. Experimental results on two large datasets with semantic labels show that our LFH method can achieve higher accu-racy than other state-of-the-art methods with comparable or lower training cost.
This work is supported by the NSFC (No. 61100125, 61272099, 61261160502), the 863 Program of China (No. 2012AA011003), Shanghai Excellent Academic Leaders Plan (No. 11XD1402900), Scienti c Innovation Act of STCSM (No. 13511504200), and the Program for Changjiang Schol-ars and Innovative Research Team in University of China (IRT1158, PCSIRT). For a more extensive evaluation, in Figure 9 and Figure 10, we illustrate the precision-recall curves with different code lengths on the two datasets, CIFAR-10 and NUS-WIDE. Our LFH method shows clear superiority on almost all set-tings, followed by KSH, SPLH, and MLH, and then the other methods without using semantic information. The results are consistent with the MAP results given above.
