
Jennifer Listgarten y , Radf ord M. Neal y , Sam T. Ro weis y Rachel Puckrin z and Sean Cutler z Man y practical problems over a wide range of domains require synthesizing information from sev-eral noisy examples of one or more cate gories in order to build a model which captures com-mon structure and also learns the patterns of variability between cate gories. In time series anal-ysis, these modeling goals manifest themselv es in the tasks of alignment and dif fer ence detection . These tasks have diverse applicability , spanning speech &amp; music processing, equipment &amp; industrial plant diagnosis/monitoring, and analysis of biological time series such as microarray &amp; liquid/g as chromatograph y-based laboratory data (including mass spectrometry and ultra violet diode arrays). Although alignment and dif ference detection have been extensi vely studied as separate problems in the signal processing and statistical pattern recognition communities, to our kno wledge, no existing model performs both tasks in a unified way. Single class alignment algorithms attempt to align a set of time series all together , assuming that variability across dif ferent time series is attrib utable purely to noise. In man y real-w orld situations, howe ver, we have time series from multiple classes (cate gories) and our prior belief is that there is both substantial shared structure between the class distrib utions and, simultaneously , systematic (although often rare) dif ferences between them. While in some circumstances (if dif ferences are small and infrequent), single class alignment can be applied to multi-class data, it is much more desirable to have a model which performs true multi-class alignment in a principled way, allo wing for more refined and accurate modeling of the data. In this paper , we introduce a novel hierarchical Bayesian model which simultaneously solv es the multi-class alignment and dif ference detection tasks in a unified manner , as illustrated in Figure 1. The single-class alignment sho wn in this figure coerces the feature in region A for class 1 to be inappropriately collapsed in time, and the overall width of the main broad peak in class 2 to be inappropriately narro wed. In contrast, our multi-class model handles these features correctly . Furthermore, because our algorithm does inference for a fully probabilistic model, we are able to obtain quantitati ve measures of the posterior uncertainty in our results, which, unlik e the point esti-mates produced by most current approaches, allo w us to assess our relati ve confidence in dif ferences learned by the model. Our basic setup for multi-class alignment assumes the class labels are kno wn for each time series, as is the case for most dif ference detection problems. Ho we ver, as we discuss at the end of the paper , our model can be extended to the completely unsupervised case. Figure 1: Nine time series from the NASA valv e solenoid current data set [4]. Four belong to a  X  X ormal X  class, and five to an  X  X bnormal X  class. On all figures, the horizontal axis is time, or latent time for figures of latent traces and observ ed time series aligned to latent traces. The vertical axis is current amplitude. Top left: The raw, unaligned data. Middle left: Average of the unaligned data within each class in thick line, with the thin lines sho wing one standard deviation on either side. Bottom left: Average of the aligned data (over MCMC samples) within each class, using the single-class alignment version of the model (no child traces), again with one standard deviation lines sho wn in the thinner style line. Right: Mean and one standard deviation over MCMC samples using the HB-CPM. Top right: Parent trace. Middle right: Class-specific ener gy impulses with the top-most sho wing the class impulses for the less smooth class. Bottom right: Child traces superimposed. Note that if one generates more HB-CPM MCMC samples, the parent cycles between the two classes since the model has no preference for which class is seen as a modification of the other; the child classes remain stable howe ver. Building on our pre vious Continuous Profile Model (CPM) [7], we propose a Hierarchical Bayesian Continuous Profile Model (HB-CPM) to address the problems of multi-class alignment and dif fer -ence detection, together , for sets of sibling time series data  X  that is, replicate time series from several distinct, but related classes. The HB-CPM is a generati ve model that allo ws simultaneous alignment of time series and also pro vides aligned canonical representations of each class along with measures of uncertainty on these representations. Inference in the model can be used, for example, to detect and quantify similarities and dif ferences in class composition. The HB-CPM extends the basic CPM in two significant ways: i) it addresses the multi-class rather than the single-class alignment problem, and ii) it uses a fully Bayesian frame work rather than a maximum lik elihood approach, allo wing us to estimate uncertainty in both the alignments and the canonical representations. Our model, depicted in Figure 2, assumes that each observ ed time series is generated as a noisy transformation of a single, class-specific latent trace. Each latent trace is an underlying, noiseless representation of the set of replicated, observ able time series belonging to a single class. An ob-serv ed time series is generated from this latent trace exactly as in the original CPM, by mo ving through a sequence of hidden states in a Mark ovian manner and emitting an observ able value at each step, as with an HMM. Each hidden state corresponds to a  X  X atent time X  in the latent trace. Thus dif ferent choices of hidden state sequences result in dif ferent nonlinear transformations of the un-derlying trace. The HB-CPM uses a separate latent trace for each class, which we call child traces . Crucially , each of these child traces is generated from a single par ent trace (also unobserv ed), which captures the common structure among all of the classes. The joint prior distrib ution for the child traces in the HB-CPM model can be realized by first sampling a parent trace, and then, for each class, sampling a sparse  X  X if ference vector X  which dictates how and where each child trace should dif fer from the common parent. 2.1 The Prior on Latent Traces Let the vector x k = ( x k be the class label of this time series. Also, let z = ( z z z c form a canonical representation of the observ ed times series in class c , and z contains their com-mon sub-structure. Ideally , the length of the latent traces, M , would be very lar ge relati ve to N so that any experimental data could be mapped precisely to the correct underlying trace point. Aside from the computational impracticalities this would pose, great care to avoid overfitting would have to be tak en. Thus in practice, we have used M = (2 + ) N (double the resolution, plus some slack on each end) in our experiments, and found this to be suf ficient with &lt; 0 : 2 . Because the resolution of the latent traces is higher than that of the observ ed time series, experimental time can be made to effecti vely speed up or slo w down by adv ancing along the latent trace in lar ger or smaller jumps. As mentioned pre viously , the child traces in the HB-CPM inherit most of their structure from a common parent trace. The dif ferences between child and parent are encoded in a dif ference vector for each class, d c = ( d c are obtained by adding this dif ference vector to the parent trace: z c = z + d c .
 We model both the parent trace and class-specific dif ference vectors with what we call an ener gy impulse chain , which is an undirected Mark ov chain in which neighbouring nodes are encouraged to be similar ( i.e. , smooth), and where this smoothness is perturbed by a set of mar ginally independent ener gy impulse nodes, with one ener gy impulse node attached to each node in the chain. For the dif-ference vector of the c th class, the corresponding ener gy impulses are denoted r c = ( r c and for the parent trace the ener gy impulses are denoted r = ( r ener gy impulses, the probability of a dif ference vector is Here, Z chain, and c controls the influence of the ener gy impulses. Together , c and c also control the overall tightness of the distrib ution for d c . Presently , we set all c = 0 , and similarly c = 0  X  that is, these do not dif fer between classes. Similarly , the conditional probability of the parent trace is These probability densities are each multi variate Gaussian with tridiagonal precision matrix es (cor -responding to the Mark ov nature of the interactions).
 Each component of each ener gy impulse for the parent, r uni variate Gaussian, N ( r and inverse-g amma, respecti vely . The class-specific dif ference vector impulses, howe ver, are dra wn from a mixture of two zero-mean Gaussians  X  one  X  X o dif ference X  (inlier) Gaussian, and one  X  X lass-dif ference X  (outlier) Gaussian. The means are zero so as to encourage dif ference vectors to be near zero (and thus child traces to be similar to the parent trace). Letting c mixture component indicator variables for each r c Each Gaussian mixture variance has an Inverse-Gamma prior , which for the  X  X o dif ference X  variance, s , is set to have very low mean (and not overly dispersed) so that  X  X o dif ference X  regions truly have set to have a lar ger mean, so as to model our belief that substantial class-specific dif ferences do occasionally exist. The priors for c , c , , are each log-normal (in verse-g amma priors would not be conjug ate in this model, so we use log-normals which are easier to specify). Additionally , proportion that are  X  X lass dif ferences X  is lik ely to be small. 2.2 The HMM Portion of the Model Each observ ed x k is modeled as being generated by an HMM conditioned on the appropriate child trace, z w k . The probability of an observ ed time series conditioned on a path of hidden time states, , and the child trace, is given by p ( x k j z w k ; k ) = Q N emission variance for time series k , and the scale factor , u k , allo ws for constant, global, multiplica-tive rescaling. The HMM transition probabilities T k ( k range, with p k ( for ( a b ) &lt; 1 or ( a b ) &gt; J where J is the maximum allo wable number of consecuti ve time states that can be adv anced in a single transition. (Of course, P J trib ution, in turn, has a Dirichlet prior . The HMM emission variances, k , have an inverse-g amma prior . Additionally , the prior over the first hidden time state is a uniform distrib ution over a constant number of states, 1 ::Q , where Q defines how lar ge a shift can exist between any two observ ed time series. The prior over each global scaling parameter , u k , is a log-normal with fix ed variance and mean of zero, which encourages the scaling factors to remain near unity . Given a set of observ ed time series (and their associated class labels), the main computational op-eration to be performed in the HB-CPM is inference of the latent traces, alignment state paths and other model parameters. Exact inference is analytically intractable, but we are able to use Mark ov Chain Monte Carlo (MCMC) methods to create an iterati ve algorithm which, if run for suf ficiently long, produces samples from the correct posterior distrib ution. This posterior pro vides simultaneous alignments of all observ ed time series in all classes, and also, crucially , aligned canonical repr e-sentations of eac h class, along with err or bar s on these repr esentations , allo wing for a principled approach to dif ference detection in time series data from dif ferent classes.
 We may also wish to obtain a posterior estimate of some of our parameters conditioned on the data, and mar ginalized over the other parameters. In particular , we might be interested in obtaining the posterior over hidden time state vectors for each time series, k , which together pro vide a simul-taneous, multi-class alignment of our data. We may , in addition, or, alternati vely , be interested in the posterior of the child traces, z c , which together characterize how the classes agree and disagree. The former may be more of interest for visualizing aligned observ ed time series, or in expanding out aligned scalar time series to a related vector time series, while the latter would be more of interest when looking to characterize dif ferences in multi-class, scalar time series data.
 We group our parameters into blocks, and sample these blocks conditioned on the values of the other parameters (as in Gibbs sampling)  X  howe ver, when certain conditional distrib utions are not amenable to direct sampling, we use slice sampling [8]. The scalar conditional distrib utions for each distrib utions for the scalars c , c , , and u k are not tractable, and for each of these we use slice sampling (doubling out and shrinking).
 The conditional distrib ution for each of r and r c is multi variate Gaussian, and we sample directly from each using a Cholesk y decomposition of the covariance matrix. where, using I to denote the identity matrix, and has entries S 1 more efficient by using the Sherman-Morrison-W oodb ury matrix inversion lemma. For example, no longer need to invert S [or S y ] to obtain it.
 The conditional distrib utions of each of z , z c are also multi variate Gaussians. Ho we ver, because of the underlying Mark ov dependencies, their precision matrix es are tridiagonal, and hence we can use belief propag ation, in the style of Kalman filtering, follo wed by a stochastic traceback to sample from them efficiently . Thus each can be sampled in time proportional to M rather than M 3 , as required for a general multi variate Gaussian.
 Lastly , to sample from the conditional distrib ution of the hidden time vectors for each sample, k , we run belief propag ation (analogous to the HMM forw ard-backw ard algorithm) follo wed by a stochastic traceback.
 In our experiments, the parent trace was initialized by averaging one smoothed example from each class. The child traces were initialized to the initial parent trace. The HMM states were initialized by a Viterbi decoding with respect to the initial values of the other parameters. The scaling factors were initialized to unity , and the child ener gy impulses to zero. MCMC was run for 5000 iterations, with con vergence generally realized in less than 1000 iterations. We demonstrate use of the HB-CPM on two data sets. The first data set is the part of the NASA shuttle valv e data [4], which measures valv e solenoid current against time for some  X  X ormal X  runs and some  X  X bnormal X  runs. Measurements were tak en at a rate of 1ms per sample, with 1000 sam-ples per time series. We subsampled the data by a factor of 7 in time since it was extremely dense. The results of performing posterior inference in our model on this two-class data set are sho wn in Figure 1. The y nicely match our intuition of what mak es a good solution. In our experiments, we also compared our model to a simple  X  X ingle-class X  version of the HB-CPM in which we simply remo ve the child trace level of the model, letting all observ ed data in both classes depend directly on one single parent trace. The single-class alignment, while doing a reasonable job, does so by co-ercing the two classes to look more similar than the y should. This is evident in one particular region labeled on the graph and discussed in the legend. Essentially a single class alignment causes us to lose class-specific fine detail  X  the precise information we seek to retain for dif ference detection. The second data set is from a botan y study which uses reverse-phase HPLC (high performance liq-uid chromatograph y) as a high-throughput screening method to identify genes involv ed in xenobiotic uptak e and metabolism in the model plant Arabidopsis thaliana . Liquid-chromatograph y (LC) tech-niques are currently being developed and refined with the aim of pro viding a rob ust platform with which to detect dif ferences in biological organisms  X  be the y plants, animals or humans. Detected dif ferences can reveal new fundamental biological insight, or can be applied in more clinical set-tings. LC-mass spectrometry technology has recently under gone explosi ve gro wth in tackling the problem of biomark er disco very  X  for example, detecting biological mark ers that can predict treat-ment outcome or severity of disease, thereby pro viding the potential for impro ved health care and better understanding of the mechanisms of drug and disease. In botan y, LC-UV data is used to help understand the uptak e and metabolism of compounds in plants by looking for dif ferences across experimental conditions, and it is this type of data that we use here.
 LC separates mixtures of analytes on the basis of some chemical property  X  hydrophobicity , for reverse-phase LC, used to generate our data. Components of the analyte in our data set were detected as the y came off the LC column with a Diode Array Detector (D AD), yielding UV -visible spectra collected at 540 time points (we used the 280 nm band, which is informati ve for these experiments). We performed background subtraction [2] and then subsampled this data by a factor of four . This is a three-class data set, where the first class is untreated plant extract, follo wed by two classes consisting of this same plant treated with compounds that were identified as possessing rob ust uptak e in vivo , and, hence, when metabolized, pro vide a dif ferential LC-UV signal of interest.
 Figure 3 gives an overvie w of the LC-UV results, while Figure 4 zooms in on a particular area of interest to highlight how subtle dif ferences can be detected by the HB-CPM, but not by a single-class alignment scheme. As with the NASA data set, a single-class alignment coerces features across classes that are in fact dif ferent to look the same, thereby pre venting us from detecting them. Recall that this data set consists of a  X  X o treatment X  plant extract, and two  X  X reatments X  of this same plant. Though our model was not informed of these special relationships, it nevertheless ele gantly captures this structure by giving almost no ener gy impulses to the  X  X o treatment X  class, meaning that this class is essentially the parent trace, and allo wing the  X  X reatment X  classes to diverge from it, thereby nicely matching the reality of the situation.
 All averaging over MCMC runs sho wn is over 4000 samples, after a 1000 burn in period, which took around 3 hours for the NASA data, and 5 hours for the LC data set, on machines with dual 3 GHz Pentium 4 processors. While much work has been done on time series alignment, and on comparison/clustering of time series, none of this work, to our kno wledge, directly addresses the problem presented in this paper  X  simultaneously aligning and comparing sets of related time series in order to characterize how the y dif fer from one another .
 The classical algorithm for aligning time series is Dynamic Time Warping (DTW) [10 ]. DTW works on pairs of time series, aligning one time series to a specified reference time, in a non-probabilistic jointly clustered and aligned time series data from dif ferent classes. Ho we ver, their model does not attempt to put time series from dif ferent classes into correspondence with one another  X  only time series within a class are aligned to one another . Ziv Bar -Joseph et al [1] use a similar approach to cluster and align microarray time series data. Ramsay et al [9] have introduced a curv e clustering model, in which a time warping function, h ( t ) , for each time series is learned by way of learning its relati ve curv ature, parameterized with order one B-spline coef ficients. This model accounts for Figure 3: Seven time series from each of three classes of LC-UV data. On all figures, the horizontal axis is time, or latent time for figures of latent traces and observ ed time series aligned to latent traces. The vertical axis is log of UV absorbance. Top left: The raw, unaligned data. Middle left: Average of the unaligned data within each class in thick line, with the thin lines sho wing one standard deviation on either side. Bottom left: Average of the aligned data within each class, using the single-class alignment version of the model (no child traces), again with one standard deviation lines sho wn in the thinner style line. Right: Mean and one standard deviation over MCMC samples using the HB-CPM model. Top right: Parent trace. Middle right: Class-specific ener gy impulses, with the top-most sho wing the class impulses for the  X  X o treatment X  class. Bottom right: Child traces superimposed. See Figure 4 for a zoom-in in around the arro w. systematic changes in the range and domain of time series in a way that aligns curv es with the same fundamental shape. Ho we ver, their method does not allo w for class-specific dif ferences between shapes to be tak en into account. The anomaly detection (AD) literature deals with related, yet distinct problems. For example, Chan et al [3] build a model of one class of time series data (the y use the same NASA valv e data as in this paper), and then match test data, possibly belonging to another class ( e.g.  X  X bnormal X  shuttle valv e data) to this model to obtain an anomaly score. Emphasis in the AD community is on detecting abnormal events relati ve to a normal baseline, in an on-line manner , rather than comparing and contrasting two or more classes from a dataset containing examples of all classes. The problem of  X  X lastic curv e matching X  is addressed in [6], where a tar get time series that best matches a query series is found, by mapping the problem of finding the best matching subsequence to the problem of finding the cheapest path in a DAG (directed acyclic graph). We have introduced a hierarchical, Bayesian model to perform detection of rare dif ferences between sets of related time series, a problem which arises across a wide range of domains. By training our model, we obtain the posterior distrib ution over a set of class-specific canonical representations of each class, which are aligned in a way that preserv es their common sub-structures, yet retains and highlights important dif ferences.
 This model can be extended in several interesting and useful ways. One small modification could be useful for the LC-UV data set presented in this paper , in which one of the classes was  X  X o treatment X , while the other two were each a dif ferent  X  X reatment X . We might model the  X  X o treatment X  as the parent trace, and each of the treatments as a child trace, so that the direct comparison of interest would be made more explicit. Another direction would be to apply the HB-CPM in a completely Figure 4: Left: A zoom in of data displayed in Figure 3, from the region of time 100-150 (labeled in that figure in latent time, not observ ed time). Top left: mean and standard deviation of the unaligned data. Middle left: mean and standard deviation of the single-class alignment. Bottom left: mean and standard deviation of the child traces from the HB-CPM. A case in point of a dif ference that could be detected with the HB-CPM and not in the raw or single-class aligned data, is the dif ference occurring at time point 127. Right: The mean and standard deviation of the child ener gy impulses, with dashed lines sho wing correspondences with the child traces in the bottom left panel. unsupervised setting where we learn not only the canonical class representations, but also obtain the posterior over the class labels by introducing a latent class indicator variable. Lastly , one could use a model with cyclical latent traces to model cyclic data such as electrocardiogram (ECG) and climate data. In such a model, an observ ed trace being generated by the model would be allo wed to cycle back to the start of the latent trace, and the smoothness constraints on the trace would be extended to apply to beginning and end of the traces, coercing these to be similar . Such a model would allo w one to do anomaly detection in cyclic data, as well as segmentation.

