 Majid Mirmehdi A new dawn in character and text recognition is upon us! The last few years have seen a substantial increase in the use of digital cameras and webcams, and the next few years should witness a massive increase in the use of camera-enabled mobile devices such as PDAs and mo-bile phones. Indeed, 3G hand-held devices are already widely available and capable of recording and transmit-ting video. The extended functionality of these devices will become more desirable, and users will demand that they perform more intelligent tasks such as locating and extracting characters and numerals in scenes, from one-liners to paragraphs. The aim of this special issue is to consider the problems and solutions associated with doc-ument and text analysis and recognition using digital, mobile, and wearable image acquisition devices. All such devices are ideal for capturing textual and graphical in-formation, indoors or outdoors, both to save as an image and to understand further by performing OCR and ex-tracting text and figures.
 scanning of text, capturing and extracting text for stor-ing or translating notices, billboards, shop signs, phone numbers, transforming text to audio for the visually im-paired, for navigation by reading road signs, and many more. Some of the typical problem areas are the recov-ery of text in perspective views, on non-planar surfaces, and in low-resolution scenes. Also, motion blurring and unsteady hands can lead to noisier images and more complex scenarios. All these and other related problems need to be addressed, and this special issue aims to show how the document recognition community, academic and industrial, is aiming to handle document analysis and recognition for hand-held and mobile cameras.
 sented, from the general to very specialized applica-tions. The paper by Liang et al. provides a compre-hensive state-of-the-art survey of the current research in camera-based text and document analysis. This encom-passes research carried out on finding and understand-ing text, embracing single-line alphanumeric groupings to paragraphs, text found indoors and outdoors, and other scenarios. The paper by Lucas et al. presents the robust reading competition entries and results in the IC-DAR 2003 conference. This presents the type of data set used and how the results are evaluated. It reviews a va-riety of methods originally presented at the conference by the entrants and, finally, examines the quality of the results.
 Packard and by Dance and Fan from Xerox provide a fascinating read from an industrial point of view with respect to providing products that can help in capturing cleaner and optimized document images. Further, this issue includes two papers from authors at SRI Interna-tional. In the first paper, Myers et al. present a method for locating and extracting text in general indoor and outdoor scenes, including the detection and correction of the orientation of the text plane. In the second, Don-aldson and Myers obtain super-resolution text from a video sequence using a text-specific bimodal prior within a Bayesian framework.
 application-specific works dealing with some everyday scenarios where the location and understanding of text has practical value. Yamaguchi et al. present in their paper a neat approach to recognizing numerical char-acters, such as telephone numbers on shop signs, using traditional image analysis techniques, amongst them the use of the Hough transform for skew correction. Zandi-far et al. describe an approach to extracting the text in a slide show or poster presentation using a hand-held device. Key frames are initially found, and, after image rectification, text is detected in the scene. In the paper by Wienecke et al., the authors propose a method for unconstrained reading of handwritten text on a white-board from the input video stream. The method uses several features, for example position and orientation, and performs statistical modelling and recognition. 2 years, from its inception to this issue that you see in front of you. My thanks go to Dr David Doermann and Mrs Denise Best for all their efforts in helping to prepare this issue. Denise X  X  help has been invaluable in first get-ting the special issue off the ground and then maintain-ing its day-to-day administration. The review process involved over 70 referees, and I am indebted and grate-ful to every one of them. Last but not least, I would also like to sincerely thank all the authors who contributed by submitting papers, published or otherwise. Their pa-tience is much appreciated, and I wish them all success
