 JANE YUNG-JEN HSU, CHIA-CHUN LIAN, and WAN-RONG JIH National Taiwan University 1. INTRODUCTION
Human social organizations often have complex structures. The organization of a group defines the roles and functions of each individual, thereby ensuing the functions of the group as a whole. Ad hoc social organization may develop during a public gathering due to common interests or goals. For example, at an academic conference, attendees tend to interact with people who share similar background or research interests. As a result, conversation patterns among the attendees can be used to map out the human networks [Gips and Pentland 2006]. Such insights can help provide important support for timely services, for example, sending announcements to attendees with relevant interests, or tracking conversations on hot topics at the meeting.

The main challenge of chatting activity recognition in public occasions is the existence of multiple people involved in multiple activities. That is, several conversations may take place concurrently, such that different combinations of multi-activity states will impact the final observations. This difficulty would cause lots of confusion for the recognition of multiple chatting activities, left with the problem of modeling the interactions among concurrent conversations.
Therefore, we hope to provide a probabilistic framework to learn and recognize coexisting chatting activities.

Previous researchers have provided many probabilistic approaches for rec-ognizing human activities. Since daily-life activities are usually performed as regular progresses along temporal axis, such as the turn-taking behaviors of conversations, using dynamic probabilistic models to learn and infer them is intuitively reasonable. Traditionally, Hidden Markov Models (HMMs) or other complex Dynamic Bayesian Networks (DBNs) are very popular for temporal pattern recognition. However, previous work often focused on developing proba-bilistic models for individual activities, which means that they did not consider the possibility of interactions among different activity models.

This research aims to develop the methodology for recognition of concurrent chatting activities from multiple audio streams. The main challenge is the existence of multiple participants involved in multiple conversations. To model the dynamic interactions, we adopt a probabilistic framework to learn and recognize concurrent chatting activities.

This article proposes using Factorial Conditional Random Fields (FCRFs) [Sutton et al. 2007] to detect and learn from patterns of multiple chatting activities. First, we survey several related projects and technologies for chat-ting activity recognition. Section 3 defines the FCRFs model, and section 4 introduces its learning and decoding, combined with Loopy Belief Propagation (LBP) or Iterative Classification Algorithm (ICA) inference methods. Finally, we present our experiments to evaluate the performance of different models and inference methods, followed by the conclusions and future work. 2. BACKGROUND
It is intuitively reasonable to infer activities of daily living using dynamic prob-abilistic models, such as Hidden Markov Models (HMMs) and complex Dynamic Bayesian Networks (DBNs). To recognize chatting activities, researchers tried to examine the Mutual Information (MI) between each person X  X  voicing seg-ment as a matching measure [Basu 2002; Choudhury and Basu 2004]. To avoid ambiguity, model-based methods are used to monitor the chatting activities among different social groups. To capture the turn-taking behaviors of conver-sations, Brdiczka et al. [2005] used HMMs to describe the transition possibility of dynamic changes among group configurations. Wyatt et al. [2007] introduced a factored DBNs to separate speakers in a multi-person environment relying on privacy-sensitive acoustic features, where the state factorization makes it relatively simple to express complex dependencies among variables.
Conditional Random Fields (CRFs) [Lafferty et al. 2001] provide a powerful probabilistic framework for labeling and segmenting structured data by relax-ing the Markov independence assumption . Various extensions of CRFs have been successfully applied to learning temporal patterns of complex human be-haviors [Liao et al. 2007; Shimosaka et al. 2007]. Multi-Task CRFs (MCRFs), a generalization of LCRFs, are proposed to do multitasking sequence labeling for human motion recognition [Shimosaka et al. 2007]. FCRFs are proposed in Wu et al. [2007] for the recognition of multiple concurrent activities based on MIT
House n data set [Intille et al. 2006]. Researchers at MIT [Sutton et al. 2007] presented Dynamic CRFs (DCRFs) combined with factored approach to cap-ture the complex interactions between NP and POS labels in natural-language chunking task. A hierarchical CRFs model was proposed in Liao et al. [2007] for automatic activity and location inference from the traces of GPS data.

To solve inference problems on generalized CRFs with loops, LBP algorithm is proposed based on passing local messages [Yedidia et al. 2002]. Unfortu-nately, the Loopy Belief Propagation (LBP) algorithm is neither an exact infer-ence algorithm nor guaranteed to converge unless the model structure is a tree [Sutton and McCallum 2007]. In addition, its updating procedure is very time-consuming to train and decode generalized CRFs models. Other researchers from MIT presented Iterative Classification Algorithm (ICA) to iteratively in-fer the states of variables given the neighboring variables as observed informa-tion [Neville and Jensen 2000]. ICA inference was shown empirically to help improve classification accuracy and robustness of the LBP algorithm for graph structures with high link density [Sen and Getoor 2007]. 3. MODEL DESIGN Let X be the set of observed variables representing acoustic feature values and
Y be the set of hidden variables representing the chatting activity labels. In addition, let ( x , y ) denote the values assigned to the variables ( X note a given number of concurrent chatting activities, and T denote a given total time steps. The number of concurrent chatting activities N is equal to the value of 2-combinations from the total number of attendees. Suppose that the number of participants involved in our experiment is , it is necessary to annotate N = C 2 multiple chatting activity sequences. Accordingly, the con-versational interaction between two arbitrary participants will be considered as one chatting activity model.

Specifically, we use a 3-state variable Y t i  X  Y whose value is y represent the state of chatting activity i at time step t . Table I shows that y a 3-state of labels to describe the interaction states of two conversationalists.
For example, a three persons X  conversation consists of three concurrent chat-ting activity sequences, that is, the number of participant is equal to 3 and the number of concurrent chatting activities N is equal to C period chatting activity might be represented as follows: where the duration between two consecutive time steps is one second. of chatting activity i over time. Similarly, we use one observed variable X assigned with x t i to denote single observed feature value related to Y multiple feature values, each of them will be represented as an independent observed variable.

Let G = ( V , E ) be an undirected graph structure consisting of two vertex across time slices. We also build edges ( X t i , Y t i ) relationships between activity labels and acoustic observations. Most impor-relationships between any two concurrent chatting activities i and j . That is, all the hidden nodes within the same time slice are fully connected.
Second, we let C be the set of maximum cliques in G , where each clique c ( i , j , t )  X  C is composed of the vertices based on the indexes ( i activities i = j . Figure 1 presents 3 sample cliques, where the local clique consists of ( X t i , Y t i )  X  C ,the temporal clique consists of ( X and the co-temporal clique consists of ( X t i , Y t i , X non-negative potential functions are also defined on these cliques, which are shown as follows: tial function defined on every local clique, where f ( p ) tion to indicate whether the state values are equal to the p bination within this clique, and w ( p ) i is its corresponding weight assigned value.
 note the temporal potential function defined on every temporal clique, where to the q th state combination within this clique, and w ( q ) weight assigned to W ( q ) i . Particularly, f ( q ) i (  X  X  X  a numerical feature value.  X  X e use  X  ij ( x t i , y t i , x t j , y t j , t ) = exp ( co-temporal potential function defined on every co-temporal clique, where to the r th state combination within this clique, and w ( r ) weight assigned to W ( r ) ij . Particularly, f ( r ) ij ( numerical feature value.

Finally, we use W ={ W ( k ) } K k = 1 whose assigning values are denote the combined set for all of the model parameters { model parameters. In addition, we use D ={ x ( m ) , y ( m ) } M set used for learning and decoding processes, where M is the number of data.
Now we can formally define the mathematical formulation of FCRFs model as follows: where Z ( x ) is the normalization constant.
 3.1 Parallel Conditional Random Fields
To construct the graph structure, first of all, we let the hidden variable nodes which denote the same chatting activity be connected across two time slices. tion for chatting activity i . Furthermore, every observed variable node X be connected to its corresponding hidden variable node Y t relationships between labels and observations.

As a result, each conversation between two arbitrary attendees will be mod-eled as a single Linear-chain Conditional Random Fields (LCRFs) model, and the hidden variables are represented as 3-state nodes to decide who is speaking or both of them are keeping silence. Figure 2 shows an unrolled LCRFs graph structure only for the chatting activity i . In this way, a PCRFs model is built, which is composed of several LCRFs models parallelly. Figure 3 shows a sample
PCRFs model for recognition of 3 concurrent chatting activities, where each of the LCRFs models is represented in a dynamic form by unrolling the structure of two time slices. 3.2 Factorial Conditional Random Fields
To construct the FCRFs model structure, we should take into consideration the existence of connections among hidden variable nodes to represent the interactions between two arbitrary concurrent chatting activities. Different from the PCRFs model introduced in the Section 3.1, we also let all of the hidden variable nodes be fully connected in the same time slice. That is, we tionships between chatting activities i and j .Figure4showsasampleFCRFs model for recognition of three concurrent chatting activities, where the FCRFs model is represented in a dynamic form by unrolling the structure of two time slices. 4. INFERENCE METHODS
Before describing the necessary inference tasks in our FCRFs model, for sim-f ing processes in detail and how we utilize the Iterative Classification Algorithm (ICA) inference method to improve the efficiency. 4.1 Learning and Decoding Processes
The purpose of learning process is to determine the weight to each feature function f ( k ) . To do this, we can maximize the log-likelihood relying on the training data set D , where the log-likelihood function is shown as follows: which is the log value of P ( D | w ) defined as follows: assume that P ( X | W ) is a uniform distribution. As a result, we can derive the partial derivative of log-likelihood with respect to w ( k ) as follows:
In this way, we can learn the weights w by satisfying the equation  X 
L ( D | w ) / X  X  ( k ) = 0. To solve such an optimization problem, we use L-BFGS method to conduct the learning process [Sutton and McCallum 2007]. The
However, we cannot use the Forward-Backward Algorithm [Rabiner 1989] to efficiently compute it, because such a Dynamic Programming method can only be used in linear-chain graph structures like HMMs and LCRFs models.
Therefore, we decide to use LBP (Loopy Belief Propagation) sum-product algo-rithm with random schedule strategy to approximate the marginal probability [Yedidia et al. 2002]. Although LBP simply conducts approximate inference, it has been used for loopy CRFs inference in many researches [Sutton et al. 2007; Vishwanathan et al. 2006; Liao et al. 2007].
 Unfortunately, as for the objective value of log-likelihood required by the
L-BFGS optimization process, it is infeasible for LBP algorithm to calculate the normalization constant Z ( x ) in Eq. (1). Therefore, we decide to use Bethe free energy [Yedidia et al. 2005] to approximate the normalization constant.
Furthermore, to avoid the over-fitting problem, what we actually do is to maximize the penalized log-likelihood L ( w | D ) = L ( D taking into consideration a zero-mean Gaussian prior distribution P ( exp (  X  ( w ( k ) ) 2 / 2  X  2 ) with variance  X  = 1 . 5 for each parameter W the original partial derivative in Eq. (3) becomes a new penalized form which is shown as follows:
As regards the decoding process, LBP algorithm can be also used for perform-ing the MAP (Maximum A Priori) inference that can decode the most possible sequences of activity states [Yedidia et al. 2002]. To conduct the MAP inference, we simply propagate the max value during the message updating procedure in the original LBP sum-product algorithm. After such an LBP max-product algo-rithm converges and the MAP probability of each hidden variable is estimated, we can label every hidden variable by choosing the most likely value according to the MAP probability. 4.2 Decomposition
Another interpretation for FCRFs model is to separate the factored graph struc-ture into several linear-chain structures. That is, the original FCRFs model is considered to being composed of several LCRFs models, where each of them represents single chatting activity. To further maintain the co-temporal rela-tionships, each hidden node Y t i depends not only on its own observed node X but also on other hidden nodes Y t j as observations. As a result, the new form for each LCRFs model is expressed as follows: where o t i is a value set assigned to new observed variables O model parameters W i = W A i  X  W B i only for chatting activity i . Noticeably, represents the neighbor nodes of Y t i in the same time slice t . In this way, the learning process for the original FCRFs structure is to train individual LCRFs models, where each LCRFs model considers other activity states as additional observations. As a result, the main inference tasks, including the calculation of can be efficiently obtained through the use of Forward-Backward Algorithm, such that the exact inference is still likely to be applied in FCRFs learning. 4.3 ICA Inference
Other researchers presented Iterative Classification Algorithm (ICA) to infer dynamically the attributes of some objects given the neighboring objects as observed information in a iterative fashion [Neville and Jensen 2000]. Their experimental results showed that the iterative procedure may significantly improve classification accuracy when compared to a single-pass approach. An-other work empirically concluded that the ICA inference method can help in-crease classification accuracy and seems to be much more robust than the LBP algorithm for graph structures with high link density [Sen and Getoor 2007].
Most importantly, Iterative Classification Algorithm (ICA) provides another inference approach in an iterative fashion for decoding process. The basic idea of
Algorithm 1 . ICA X  X terative Classification Algorithm ( )
ICA is to decode every target hidden variable based on the assigning labels of its neighbor variables, where the labels might be dynamically updated throughout the run of iterative process. Compared with Loopy Belief Propagation (LBP) algorithm, ICA does the inference not only based on observed variables but also based on hidden variables as observations. After a given number of iterative cycles, the classification process will eventually terminate and all the hidden variables will be assigned with fixed labels.

Therefore, we can use the ICA inference method to label multiple concurrent sequences, as long as we priorly follow the decomposition procedure, letting the LCRFs model parameters W i for every chatting activity i be learned as w . Algorithm 1 formally provides the detailed ICA procedure for our FCRFs labeling, where an upper limit = 10 3 for the number of iterations is set to avoid infinite repeat.
 Noticeably, since the LCRFs model provides an efficient Forward-Backward
Algorithm, the ICA inference method also has an opportunity to help accelerate the decoding process. An ICA example with 2 concurrent chatting activities as shown in Figure 5. Compared with other classification methods, ICA does the inference not only based on observed data but also based on hidden variables as observations. After a given number of iterative cycles , the iterative classi-fication process will eventually terminate and all of the hidden variable nodes will be assigned to fixed labels.
 4.4 LBP Inference
In a traditional linear-chain CRFs model, we can derive an efficient inference method from forward-backward algorithm [Lafferty et al. 2001]. As regards a generalized CRFs graph structure which may have loops, researches [Yedidia et al. 2002, 2005; Sen and Getoor 2007] suggest that Loopy Belief Propagation (LBP) algorithm is an alternative way to solve inference problems based on passing local messages. Unfortunately, the LBP algorithm is neither an exact inference algorithm nor guaranteed to converge unless the model structure is a tree [Sutton and McCallum 2007]. Meanwhile, the iterative message updating procedure of LBP algorithm usually takes a great many iterations to achieve convergence, which is not an efficient algorithm for training generalized CRFs models.

In order to define the LBP algorithm, we simply use c ( x clique potential function of Eq (1). A rewritten formulas of function P ( y shows as follows:
Moreover, we can find that the above potential function c as c ( y c ), since the value x c  X  X c are pre-given and are fixed in CRFs models.
Furthermore, without loss of generality, we simply introduce how to use LBP algorithm to do inference in a pair-wise CRFs model, where the maximum size of arbitrary clique is only two. In this way, it is more specific to separate the original potential function c ( y c ) into two types of representation, shows in
Eq. (6). First of all, for any assigning label y i of hidden variable node Y labels ( y i , y j ) of each pair of neighboring hidden variable nodes ( Y use  X  ( y i , y j ) to denote the pair-wise potential function.
In Eq. (6), m ij ( y j ) means the message for a given state y hidden variable node Y i to another hidden variable node Y i = j ; N ( Y updated based on the neighbor of Y i during the inference process [Neville and
Jensen 2000]; the term Y k  X  N ( Y i ) \ Y j means that Y of neighboring nodes of Y i except for Y j ;  X  is a normalization term to ensure the probabilistic property.

Algorithm 2 elaborates that LBP algorithm can be used to perform MAP (maximum a posteriori) inference that decodes the most possible sequences of activity states. To conduct the MAP inference, we can simply replace the notation of summation with maximization in Eq. (6). We only propagate the maximum value among different states from other variables instead of summa-rizing them during message updating procedure, which becomes a max-product algorithm in line 7. As a result, in line 14, describes that the MAP probability b ( y i ) of each hidden variable node Y i  X  Y can be estimated after the LBP
Algorithm 2 . Loopy Belief Propagation Algorithm ( ) max-product algorithm converges. On the other hand, the b marginal probability given assign label y i  X  Y i , such that we can label every hidden variable node by choosing the most likely value according to the MAP probability.

In order to guarantee LBP algorithm can be terminated in finite steps, a threshold in line 17 is used to handle the loop condition. Furthermore, since the LBP algorithm does not guarantee convergence, we have to set an upper limit for the number of iterations to avoid infinite repeat. 5. AUDITORY FEATURE EXTRACTION
The control of speaking volume plays an important part of determining to whom he or she is speaking. For example, the speaking individuals usually talks only loud enough to be heard by their conversational partners in a social occasion. To utilize volume features, we firstly separate the audio stream into 250-sample frames with a 125-sample overlap, where the sampling frequency is 8 kHz. For the f th frame, we extract the log energy as our volume value v ( f ). Secondly, we compute a binary sequence b v ( f ) to discretely represent the temporal change for a given volume sequence v ( f ), which is defined as follows:
As a result, we can use mutual information (MI) as our matching measure to evaluate the consistency of two volume sequences v 1 ( f )and shown as follows: where x , y  X  X  0 , 1 } ,[ b v window size of 1 minute (3840 frames). Finally, we can compute the accumu-lated volume value v ( t ) and the accumulated MI I v frames (1 second) respectively, where the 64-frame periods are centered at time step t . Nevertheless, since different audio recorders may have various degrees of response to the same audio event, we also compute the derivative of volume v several binary volume features for each time step t , including b which is defined as follows: sequences.

More importantly, there are a great number of nonhuman noises around our environment, which are very likely to cause interference with the detection of human conversations. Fortunately, previous work has shown that there exists 3 key acoustic features for human voice detection [Basu 2002], including non-initial maximum autocorrelation peak (  X  ), number of autocorrelation peaks ( and spectral entropy (  X  ). Therefore, the values of [  X ,  X ,  X  each frame and the accumulated values [  X  ( t ) , X  ( t ) , X  consecutive 64 frames (1 second) respectively, where the 64-frame periods are centered at time step t .Inthisway,[  X  1 ( t ) , X  1 ( t ) used to represent the acoustic features from two specific participants.
Table II summarizes all auditory feature values extracted from two audio streams recorded by a pair of participants who can perform the chatting activity i at time step t . In practice, we not only utilize these 17 acoustic feature values at time step t but also accept the values from time steps ( t we choose a 3-time window size as our observations. As a result, each of the 51 acoustic feature values will be represented as an independent observed node
X . Furthermore, to avoid the overflow problem which might exist in CRFs learning, all the numerical feature values are normalized within the range [0 , 1]. 6. EXPERIMENTS
Before carrying out the experiments, we asked every participant to wear an audio recorder around his or her neck to collect the audio data. During a given period of time, the participants can randomly determine their conversational partners and the audio recorders can record their conversations. As a result, the collected audio recordings can be used for the annotation of participants X  conversational states as well as the extraction of acoustic feature values. To do annotation, researchers should listen very carefully to the audio recordings to know who has spoken with whom, relying on the content of what was said.
We X  X e designed two common scenarios to collect auditory data for experi-ments, which are shown as follows: (1) Meeting Activity . The data is a set of 80-minute audio streams recorded (2) Public Occasion . The data is a set of 45-minute audio streams recorded by
To evaluate the performance, we used cross-validation method to test the experimental data. However, to deal with a sequential data, this method suffers from the problem that the important activities to be recognized may only occur in specific time periods, such that the possible patterns in the testing data cannot be learned in the training data, or the learned results in training data cannot help recognize the testing data. To address the problem, the sequential data should be fragmented into several small segments and each of the adjacent segments along the temporal axis will be systematically reassigned to each fold.
In practice, we define the time duration between two consecutive time steps as 1 second and each segment contains 10 time slices ( T = 10).

Finally, we measure the recognition accuracy as the percentage of correctly predicted conversations by applying the 10-fold cross-validation to compare the performance of the various types of models and inference methods. More specifically, the comparisons for recognition accuracy include accuracy , recall , precision and F-score . In addition, to analyze the efficiency of FCRFs learn-ing and decoding by using different inference methods, including Loopy Belief
Propagation (LBP) and Iterative Classification Algorithm (ICA) inferences, we measure the learning time as the accumulated training time during the pro-cess of cross-validation on an Intel Xeon E5450 3.00GHz with 8GB DDR2 RAM for Linux operating system, and measure the decoding time as the accumu-lated decoding time in a similar way. The following sections present several experiments to verify the advantages of our FCRFs models with ICA inference method. 6.1 FCRFs Models vs. PCRFs Models
The primary purpose of this experiment is to analyze the recognition accuracy of two different FCRFs models by using LBP and ICA inference methods re-spectively. In addition, another Parallel CRFs (PCRFs) model is also trained for comparison, which is composed of several LCRFs models parallelly and no co-temporal connections between hidden nodes are built. That is, the co-temporal relationships among chatting activities in FCRFs model are eliminated. As a result, we calculate the accuracy, recall, precision and F-score for each chatting activity and then average them respectively.

In the simple scenario of meeting activity, what the microphone devices recorded is only the voices from three participants. Therefore, we simply choose the voice volume as the primary observed features. The recognition accuracy is summarized in Table III.

In the complex scenario of public occasion, the environment contains a great deal of background noise. Therefore, in addition to the feature values of volume and mutual information (MI), we consider extra features used for human voice detection. The recognition accuracy is summarized in Table IV.

In the complex public occasion, the participants are allowed to do the ac-tivities of their own, therefore, the background noise may mislead to predict a nonchatting activity as chatting activity. Moreover, the ICA inference is based on both of the observed data and hidden variables, whereas the LBP algo-rithm takes only the observed variable in FCRFs models. In addition, results of Table III and Table IV show that the recall value of LBP is higher than one of the ICA. That is, the LBP algorithm has higher probability to predict input data as chatting activity, but may not always the correct prediction, this causes the precision of LBP is not as best as the ICA one.

We can observe a consistent phenomenon, either in the meeting activity or the public occasion, all the FCRFs models significantly outperform the PCRFs model in the comparison of F-score. This result provides us the conclusion that it is helpful to utilize the co-temporal relationship for chatting activity recognition. However, the FCRFs model with Loopy Belief Propagation (LBP) inference performs even more badly than the PCRFs model in the comparison of precision, while the FCRFs model with Iterative Classification Algorithm (ICA) inference still performs the best. 6.2 CRFs-like Models vs. HMMs-like Models
In this experiment, two DBNs models are trained for our comparisons, includ-ing Parallel HMMs (PHMMs) [Vogler and Metaxas 2001] and Coupled HMMs (CHMMs) [Brand et al. 1997], which are formed as HMMs-like fashions. The
PHMMs model is very similar to the PCRFs model, where all of the multiple chatting activities are independent temporal processes and each of them is modeled as a linear-chain HMMs. Furthermore, the CHMMs model assumes that each hidden variable is conditionally dependent on all hidden variables in the previous time slice. Therefore, the CHMMs model also has the ability to capture the interactive relationships among chatting activities, which can be compared with the FCRFs model. By analyzing the audio data collected in the public occasion, the recognition accuracy of HMM-like models is sum-marized in Table V. Meanwhile, the schematic diagram for the comparison between CRFs-like models and HMMs-like models is shown in Figure 6. Taken as a whole, we can discover that all the CRFs-like models significantly out-perform the HMMs-like models in all the comparisons of recognition accuracy, which concludes that the CRFs-like models indeed have the ability to accom-modate overlapping features and are much more powerful to capture complex co-temporal relationships among multiple chatting activities. 6.3 Personalized Models vs. Generic Models
Results show in Table IV and Table VI make us consider whether different chat-ting activities can share the same features of conversational dynamics. If we can discover a generic CRFs model for conversation detection, the infrastruc-ture of sensing system for chatting activity detection can be extensively applied to different environments and no personalized models should be pre-trained for specific speakers. To train such a generic model, we can bind the same model parameters to each chatting activity model despite that these chatting activi-ties are composed of different conversationalists. The recognition accuracy for generic CRFs-like models are summarized in Table VI.

The generic model shares the same features of conversational dynamics while the personalized model does not. Consequently, results of generic models in Table VI are worse than the personalized model in Table IV. By applying the same CRFs to generic models, both of the precision and recall values are decreased, so as the F-score. The ICA in FCRFs model performs the best and the decreasing of accuracy is modest in generic models.

Results show that it is allowable for different conversationalists to share the same chatting activity model. Both of the generic FCRFs models perform better than PCRFs models. The generic FCRFs model with ICA inference performs the best, which is very similar to the experimental results in meeting activity (Table III). Meanwhile, the generic FCRFs model with ICA inference even outperforms LBP inference in the comparison of F-score. 6.4 LBP Efficiency vs. ICA Efficiency
The Loopy Belief Propagation (LBP) and Iterative Classification Algorithm (ICA) efficiency analysis based on the audio data collected in the public occasion is summarized in Figure 7. In accordance with Algorithm 1 and Algorithm 2, LBP takes at least | Y | times than the ICA in time complexity. Consequently,
Figure 7 shows that ICA and PCRFs performs faster than the LBP in the learning process. Table VII compares the learning time and decoding time by using the various types of CRFs models as well as inference methods. We choose the full size data, which has 2700 seconds, to present the corresponding learning and decoding time.

In Figure 8, we also compare the learning time of personalized model to the generic model. Even in the larger data size, both of the personalized and generic model have the similar learning time. Though the Figure 8 shows only the ICA results, in all the three FCRFs models, the difference between generic and personalized model in learning time are also very small.

In this experiment, we can come to an important conclusion that the FCRFs model with ICA inference takes much less time than LBP method to complete the learning and decoding processes. Especially in the comparison of learning time, we can observe that there is even no significant difference between the
PCRFs model and the FCRFs model with ICA inference. Given the difference in convergence property of LBP and ICA in various conversation contexts, we chose to compare them when effective convergence is reached -just to be fair.
Additional experiments may indeed offer potentially interesting observations by stopping LBP early at increasing rounds of message passing. 7. CONCLUSIONS AND FUTURE WORK
This article proposes the FCRFs model for joint recognition of multiple concur-rent chatting activities by using the Iterative Classification Algorithm (ICA) inference method. We designed the experiments based on the collected auditory data to compare our FCRFs model with other dynamic probabilistic models, in-cluding PCRFs model and HMMs-like models. The initial experiment showed that the FCRFs model with ICA inference method, which is capable of accom-modating the co-temporal relationships, can help improve the recognition accu-racy in the presence of coexisting conversations. Most importantly, the FCRFs model using ICA inference approach significantly takes much less time to con-duct the learning and decoding processes than the Loopy Belief Propagation (LBP) inference method. FCRF with ICA can be generalized to recognize more general conversations or activities among a larger group of participants with properly designed FCRF graph structure capturing co-temporal relationships.
