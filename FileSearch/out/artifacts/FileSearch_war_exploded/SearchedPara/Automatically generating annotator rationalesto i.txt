 One of the central challenges in sentiment-based text categorization is that not every portion of a given document is equally informative for in-ferring its overall sentiment (e.g., Pang and Lee (2004)). Zaidan et al. (2007) address this prob-lem by asking human annotators to mark (at least some of) the relevant text spans that support each document-level sentiment decision . The text spans of these  X  X ationales X  are then used to construct ad-ditional training examples that can guide the learn-ing algorithm toward better categorization models.
But could we perhaps enjoy the performance gains of rationale-enhanced learning models with-out any additional human effort whatsoever (be-yond the document-level sentiment label)? We hy-pothesize that in the area of sentiment analysis, where there has been a great deal of recent re-search attentiongiven to various aspects of the task (Pang and Lee, 2008), this might be possible: us-ing existing resources for sentiment analysis, we might be able to construct annotator rationales au-tomatically.

In this paper, we explore a number of methods to automatically generate rationales for document-level sentiment classification. In particular, we in-vestigate the use of off-the-shelf sentiment analy-sis components and lexicons for this purpose. Our approaches for generating annotator rationales can be viewed as mostly unsupervised in that we do not require manually annotated rationales for training.
Rather unexpectedly, our empirical results show that automatically generated rationales (91.78%) are just as good as human rationales (91.61%) for document-level sentiment classification of movie reviews. In addition, complementing the hu-man annotator rationales with automatic rationales boosts the performance even further for this do-main, achieving 92.5% accuracy. We further eval-uate our rationale-generation approaches on prod-uct review data for which human rationales are not available: here we find that even randomly gener-ated rationales can improve the classification accu-racy although rationales generated from sentiment resources are not as effective as for movie reviews. The rest of the paper is organized as follows. We first briefly summarize the SVM-based learn-ing approach of Zaidan et al. (2007) that allows the incorporation of rationales (Section 2). We next introduce three methods for the automatic gener-ation of rationales (Section 3). The experimental results are presented in Section 4, followed by re-lated work (Section 5) and conclusions (Section 6). Zaidan et al. (2007) first introduced the notion of annotator rationales  X  text spans highlighted by human annotators as support or evidence for each document-level sentiment decision. These ratio-nales, of course, are only useful if the sentiment categorization algorithm can be extended to ex-ploit the rationales effectively. With this in mind, Zaidan et al. (2007) propose the following con-trastive learning extension to the standard SVM learning algorithm.

Let ~x i be movie review i , and let { ~r ij } be the set of annotator rationales that support the posi-tive or negative sentiment decision for ~x i . For each such rationale ~r ij in the set, construct a contrastive training example ~v ij , by removing the text span associated with the rationale ~r ij from the original review ~x i . Intuitively, the contrastive example ~v ij should not be as informative to the learning algo-rithm as the original review ~x i , since one of the supporting regions identified by the human anno-tator has been deleted. That is, the correct learned model should be less confident of its classifica-tion of a contrastive example vs. the corresponding original example, and the classification boundary of the model should be modified accordingly.
Zaidan et al. (2007) formulate exactly this intu-ition as SVM constraints as follows: where y i  X  X  X  1 , +1 } is the negative/positive sen-timent label of document i , ~w is the weight vector,  X   X  0 controls the size of the margin between the original examples and the contrastive examples, and  X  ij are the associated slack variables. After some re-writing of the equations, the resulting ob-jective function and constraints for the SVM are as follows: subject to constraints: where  X  i and  X  ij are the slack variables for ~x i (the original examples) and ~x ij ( ~x ij are named as pseudo examples and defined as ~x ij = ~x i  X  ~v ij  X  ), re-spectively. Intuitively, the pseudo examples ( ~x ij ) represent the difference between the original ex-amples ( ~x i ) and the contrastive examples ( ~v ij ), weighted by a parameter  X  . C and C contrast are parameters to control the trade-offs between train-ing errors and margins for the original examples ~x i and pseudo examples ~x ij respectively. As noted in Zaidan et al. (2007), C contrast values are generally smaller than C for noisy rationales.

In the work described below, we similarly em-ploy Zaidan et al. X  X  (2007) contrastive learning method to incorporate rationales for document-level sentiment categorization. Our goal in the current work, is to generate anno-tator rationales automatically. For this, we rely on the following two assumptions: (1) Regions marked as annotator rationales are (2) The sentiment of each annotator rationale co-Note that assumption 1 was not observed in the Zaidan et al. (2007) work: annotators were asked only to mark a few rationales, leaving other (also subjective) rationale sections unmarked.

And at first glance, assumption (2) might seem too obvious. But it is important to include as there can be subjective regions with seemingly conflict-ing sentiment in the same document (Pang et al., 2002). For instance, an author for a movie re-view might express a positive sentiment toward the movie, while also discussing a negative sen-timent toward one of the fictional characters ap-pearing in the movie. This implies that not all sub-jective regions will be relevant for the document-level sentiment classification  X  rather only those regions whose polarity matches that of the docu-ment should be considered.

In order to extract regions that satisfy the above assumptions, we first look for subjective regions in each document, then filter out those regions that exhibit a sentiment value (i.e., polarity) that con-flicts with polarity of the document. Assumption 2 is important as there can be subjective regions with seemingly conflicting sentiment in the same document (Pang et al., 2002).

Because our ultimate goal is to reduce human annotation effort as much as possible, we do not employ supervised learning methods to directly learn to identify good rationales from human-annotated rationales. Instead, we opt for methods that make use of only the document-level senti-ment and off-the-shelf utilities that were trained for slightly different sentiment classification tasks using a corpus from a different domain and of a different genre. Although such utilities might not be optimal for our task, we hoped that these ba-sic resources from the research community would constitute an adequate source of sentiment infor-mation for our purposes.

We next describe three methods for the auto-matic acquisition of rationales. 3.1 Contextual Polarity Classification The first approach employs OpinionFinder (Wil-son et al., 2005a), an off-the-shelf opinion anal-ysis utility. 1 In particular, OpinionFinder identi-fies phrases expressing positive or negative opin-ions. Because OpinionFinder models the task as a word-based classification problem rather than a sequence tagging task, most of the identified opin-ion phrases consist of a single word. In general, such short text spans cannot fully incorporate the contextual information relevant to the detection of subjective language (Wilson et al., 2005a). There-fore, we conjecture that good rationales should ex-tend beyond short phrases. 2 For simplicity, we choose to extend OpinionFinder phrases to sen-tence boundaries.

In addition, to be consistent with our second op-erating assumption, we keep only those sentences whose polarity coincides with the document-level polarity. In sentences where OpinionFinder marks multiple opinion words with opposite polarities we perform a simple voting  X  if words with pos-itive (or negative) polarity dominate, then we con-sider the entire sentence as positive (or negative). We ignore sentences with a tie. Each selected sen-tence is considered as a separate rationale. 3.2 Polarity Lexicons Unfortunately, domain shift as well as task mis-match could be a problem with any opinion util-ity based on supervised learning. 3 Therefore, we next consider an approach that does not rely on su-pervised learning techniques but instead explores the use of a manually constructed polarity lexicon. In particular, we use the lexicon constructed for Wilson et al. (2005b), which contains about 8000 words. Each entry is assigned one of three polarity values: positive, negative, neutral. We construct rationales from the polarity lexicon for every in-stance of positive and negative words in the lexi-con that appear in the training corpus.

As in the OpinionFinder rationales, we extend the words found by the PolarityLexicon approach to sentence boundaries to incorporate potentially relevant contextual information. We retain as ra-tionales only those sentences whose polarity co-incides with the document-level polarity as deter-mined via the voting scheme of Section 3.1. 3.3 Random Selection Finally, we generate annotator rationales ran-domly, selecting 25% of the sentences from each document 4 and treating each as a separate ratio-nale. 3.4 Comparison of Automatic vs.
 Before evaluating the performance of the au-tomatically generated rationales, we summarize in Table 1 the differences between automatic vs. human-generated rationales. All computa-tions were performed on the same movie review dataset of Pang and Lee (2004) used in Zaidan et al. (2007). Note, that the Zaidan et al. (2007) an-notation guidelines did not insist that annotators mark all rationales, only that some were marked for each document. Nevertheless, we report pre-cision, recall, and F-score based on overlap with the human-annotated rationales of Zaidan et al. (2007), so as to demonstrate the degree to which the proposed approaches align with human intu-ition. Overlap measures were also employed by Zaidan et al. (2007).

As shown in Table 1, the annotator rationales found by OpinionFinder (F-score 49.5%) and the PolarityLexicon approach (F-score 52.6%) match the human rationales much better than those found by random selection (F-score 27.3%).

As expected, OpinionFinder X  X  positive ratio-nales match the human rationales at a significantly lower level (F-score 31.9%) than negative ratio-nales (59.5%). This is due to the fact that Opinion-Finder is trained on a dataset biased toward nega-tive sentiment (see Section 3.1 -3.2). In contrast, all other approaches show a balanced performance for positive and negative rationales vs. human ra-tionales. For our contrastive learning experiments we use SV M light (Joachims, 1999). We evaluate the use-fulness of automatically generated rationales on five different datasets. The first is the movie re-view data of Pang and Lee (2004), which was manually annotated with rationales by Zaidan et al. (2007) 5 ; the remaining are four product re-view datasets from Blitzer et al. (2007). 6 Only the movie review dataset contains human annota-tor rationales. We replicate the same feature set and experimental set-up as in Zaidan et al. (2007) to facilitate comparison with their work. 7 The contrastive learning method introduced in Zaidan et al. (2007) requires three parameters: ( C ,  X  , C contrast ). To set the parameters, we use a grid search with step 0.1 for the range of values of each parameter around the point ( 1 , 1 , 1 ). In total, we try around 3000 different parameter triplets for each type of rationales. 4.1 Experiments with the Movie Review Data We follow Zaidan et al. (2007) for the training/test data splits. The top half of Table 2 shows the performance of a system trained with no anno-tator rationales vs. two variations of human an-notator rationales. H UMAN R treats each rationale in the same way as Zaidan et al. (2007). H U -MAN R@S ENTENCE extends the human annotator rationales to sentence boundaries, and then treats each such sentence as a separate rationale. As shown in Table 2, we get almost the same per-formance from these two variations (91.33% and 91.61%). 8 This result demonstrates that locking rationales to sentence boundaries was a reasonable Table 2: Experimental results for the movie review data. choice.

Among the approaches that make use of only automatic rationales (bottom half of Table 2), the best is O PINION F INDER , reaching 91.78% accu-racy. This result is slightly better than results exploiting human rationales (91.33-91.61%), al-though the difference is not statistically signifi-cant. This result demonstrates that automatically generated rationales are just as good as human rationales in improving document-level sentiment classification. Similarly strong results are ob-tained from the P OLARITY L EXICON as well.
Rather unexpectedly, R ANDOM also achieves statistically significant improvement over N O R A -TIONALES (90.0% vs. 88.56%). However, notice that the performance of R ANDOM is statistically significantly lower than those based on human ra-tionales (91.33-91.61%).

In our experiments so far, we observed that some of the automatic rationales are just as good as human rationales in improving the document-level sentiment classification. Could we perhaps achieve an even better result if we combine the automatic rationales with human rationales? The answer is yes! The accuracy reaches 92.50%, which is statistically signifi-cantly better than H UMAN R (91.61%). In other words, not only can our automatically generated rationales replace human rationales, but they can also improve upon human rationales when they are available. 4.2 Experiments with the Product Reviews We next evaluate our approaches on datasets for which human annotator rationales do not exist. For this, we use some of the product review data from Blitzer et al. (2007): reviews for Books, DVDs, Videos and Kitchen appliances. Each dataset contains 1000 positive and 1000 negative reviews. The reviews, however, are substantially shorter than those in the movie review dataset: the average number of sentences in each review is 9.20/9.13/8.12/6.37 respectively vs. 30.86 for the movie reviews. We perform 10-fold cross-validation, where 8 folds are used for training, 1 fold for tuning parameters, and 1 fold for testing.
Table 3 shows the results. Rationale-based methods perform statistically significantly bet-ter than N O R ATIONALES for all but the Kitchen dataset. An interesting trend in product re-view datasets is that R ANDOM rationales are just as good as other more sophisticated rationales. We suspect that this is because product reviews are generally shorter and more focused than the movie reviews, thereby any randomly selected sentence is likely to be a good rationale. Quantita-tively, subjective sentences in the product reviews amount to 78% (McDonald et al., 2007), while subjective sentences in the movie review dataset are only about 25% (Mao and Lebanon, 2006). 4.3 Examples of Annotator Rationales In this section, we examine an example to com-pare the automatically generated rationales (using O
PINION F INDER ) with human annotator ratio-nales for the movie review data. In the following positive document snippet, automatic rationales are underlined, while human-annotated ratio-nales are in bold face. Table 3: Experimental results for subset of Product Review data Notice that, although O PINION F INDER misses some human rationales, it avoids the inclusion of  X  X mpossible to hate X , which contains only negative terms and is likely to be confusing for the con-trastive learner. In broad terms, constructing annotator rationales automatically and using them to formulate con-trastive examples can be viewed as learning with prior knowledge (e.g., Schapire et al. (2002), Wu and Srihari (2004)). In our task, the prior knowl-edge corresponds to our operating assumptions given in Section 3. Those assumptions can be loosely connected to recognizing and exploiting discourse structure (e.g., Pang and Lee (2004), Taboada et al. (2009)). Our automatically gener-ated rationales can be potentially combined with other learning frameworks that can exploit anno-tator rationales, such as Zaidan and Eisner (2008). In this paper, we explore methods to automatically generate annotator rationales for document-level sentiment classification. Our study is motivated by the desire to retain the performance gains of rationale-enhanced learning models while elimi-nating the need for additional human annotation effort. By employing existing resources for sen-timent analysis, we can create automatic annota-tor rationales that are as good as human annotator rationales in improving document-level sentiment classification.

