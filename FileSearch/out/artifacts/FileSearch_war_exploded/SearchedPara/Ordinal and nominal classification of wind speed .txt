 1. Introduction
Among renewable energies, wind power is one of the most promising sources of renewable energy in the world, and also the one with a stronger economic impact in developed countries ( Kaldellis and Zafirakis, 2011 ). As an example, wind power installed worldwide by the end of 2009 reaches a total of 157 GW, of which about 76 GW correspond to Europe, and 19 GW only to Spain. Thus, wind power represents over 12% of the total energy consumed in countries such as USA, Germany or Spain, and it is expected that this percentage grows up to an amazing 20% by 2025 ( Saidur et al., 2010 ). This booming of wind energy has brought together the construction of a huge number of wind farms in the last few years, and, consequently, a good number of new problems associated with the management of these facilities.

Wind speed reconstruction, long-term prediction and wind series analysis are mainly the most important problems faced by wind farm managers in daily operations. These problems are related to different important decisions about the wind farm, such as maintenance stops, production analysis and planning and even micro-sitting of new wind turbines. Existing approaches for these problems are mainly based on historic registers of wind measures, from which statistical models are constructed in order to explain the wind behaviour. These models can be then applied to future values of time in the case of long-term wind speed prediction, or to values in the past in order to reconstruct or analyse and reconstruct wind speed series. Different techniques have been used to obtain these wind speed models, such as statistical methods ( Khashei et al., 2009 ; Torres et al., 2005 ), neural net-works ( Barbounis and Theocharis, 2006 ; Costa et al., 2008 ), support vector machines ( Mohandes et al., 2004 ), Bayesian models ( Li et al., 2011 ), etc. The majority of the existing techni-ques used to construct long-term wind speed models are exclu-sively based on past wind speed data, and some of them include other atmospheric variables as input data, such as local tempera-ture, radiation or pressure at the measuring point. The problem with this approach based on wind measures is that, in some cases, these data are not available, due to fails in the measurement systems, or just because the terrain is a prospective site to install a wind farm, and there is not a meteorological tower installed yet.
This problem is even harder in the case of historic analysis or wind series reconstruction, since it is not possible to obtain any direct wind measure if it is not available.

In these problematic cases, the possibility of obtaining indirect measures of wind is currently a hot topic, in which many renew-able energy companies are investing lots of resources. In this sense, different recent works have used synoptic pressure indirect measure to study different atmospheric phenomenons such as precipitation, pollution or temperature ( Chen et al., 2008 ;
Cheng, 2001 ; Osowski and Garanty, 2006 ; Paniagua-Tineo et al., 2011 ; Paredes et al., 2006 ; Romero et al., 1999 ; Trigo and
DaCamara, 2000 ). In the case of the wind, it seems even more evident that a good source of indirect wind measures is the pressure at synoptic scale, since the wind at a given point is a direct function (when the effects of limit boundary layer are removed) of the pressure gradient. Thus, different works have related pressure patterns with local or mesoscale wind ( Carro-
Calvo et al., 2011 , 2012 ; Burlando et al., 2008 ; Hocaoglu et al., 2010 ; Soriano et al., 2006 ). Among them, the work by Hocaoglu et al. (2010) has been selected in the experimental section as one of the compared methods, given that it resembles the proposal in this paper in some ways.

Specifically, in this paper, the problem of wind speed estima-tion in a given point (wind farm), from the corresponding synoptic pressure pattern is tackled. The problem involves daily pressure patterns in a synoptic grid, in this case centred in Spain, and a wind speed module measure. The main novelty of the paper is that this wind speed is discretized into different levels of wind (classes) in order to treat it as a classification problem. The motivation behind this is that the manager of the wind farm can get enough information from the considered classes in order to set functional operations for the farm (such as wind turbines stop, for example). Note that the exact wind speed value is not usually important for this task. Additionally, higher accuracy can be obtained for a classification task, given that the problem is simplified. Four classes have been considered that cover all the wind speed spectrum of a wind farm operation.

Decision making tasks usually involve that the target variable (wind in this case) takes values in an ordinal scale, what is known as ordinal regression or ordinal classification. This relatively new machine learning field is aimed at finding a prediction rule for ordered categories. Ordinal classification problems arise in statistics ( McCullagh and Nelder, 1989 ), and have recently received a lot of attention in the machine learning field, given that it can be applied to a wide range of areas, specially those where a human being can be used to evaluate the target variable ( Bender and Grouven, 2006 ): medicine, psychology, some engi-neering fields, etc. The analysis of the problem reveals that it is different from standard regression, because a distance between the labels cannot be established. And the ordering information is the main difference with respect to nominal classification. To really exploit this order among categories, classifiers should be built including this order in the model formulation, and evalua-tion measures or metrics should be specifically designed to measure the degree of discrepancy (in the ordinal scale) between the predicted and real categories. All these considerations empha-size the importance of developing and applying ordinal regression models in the field of artificial intelligence.
 of the well known support vector machine (SVM) classifier ( Chu and Ghahramani, 2005 ; Chu and Keerthi, 2007 ), the online perceptron algorithm ( Crammer and Singer, 2005 ), the Propor-tional Odd Model (POM) ( Verwaeren et al., 2012 ), by constructing sets of distinct binary classifiers ( Frank and Hall, 2001 )orby transforming them to extended binary problems ( Cardoso and da
Costa, 2007 ). Recently, two different algorithms were proposed to generate structured and unstructured monotone ordinal datasets ( Potharst et al., 2009 ). All these algorithms can provide models to classify data where there exists an order between the different target labels considered, and generally take advantage of this order (instead of simply ignoring it as standard classifiers do). other fields, and the corresponding real problems are tackled as standard nominal classification (where no order is assumed between the classes). Note that the wind speed characteristics make that the problem can be defined as an ordinal classification problem, in which the different classes (wind speed intervals) can be ordered from the smallest to the largest, in increasing order. In this way, this paper also makes use of the ordering information for evaluating if better quality classifiers are obtained. The results of ordinal algorithms are compared with respect to nominal classi-fiers. Five wind farms in Spain are considered, and the main conclusion is that, although ordinal classification algorithms sig-nificantly ranks better than nominal ones, the differences in percentage of correctly classification ratio are quite low. section presents the definition of the problem. Section 3 presents the main characteristics of the algorithms tested for this problem. The experiments of the paper are then presented in Section 4 .
Finally, Section 5 closes the paper giving some concluding remarks. 2. Problem definition y  X f y i , i  X  1 , ... , T g be a series of daily wind speed discretized measures at a given point, in such a way that y i A Y  X f C i.e. y belongs to one out of four classes which are subjected to an ordinal order ( C 1 ! C 2 ! C 3 ! C 4 , where ! is an ordering relation-ship between the labels). In this paper, the different classes for the wind speed have been constructed taking into account the characteristics of the wind turbines, i.e. its power curve. Fig. 1 shows the four classes established in this paper, which try to model the power curve of the turbines installed in the considered wind farms. Thus, C 1 contains situations of low wind, where the wind turbine will not produce power, C 2 summarizes situations in the beginning of the wind power ramp, C 3 comprises situations in which the production of the wind turbine is significant and C models situations of high wind speed and power production. Note daily averages of wind speed are studied, so the classes are set to have enough number of samples from each class. Let
X  X f x i , i  X  1 , ... , T g be a series of daily synoptic-scale pressure measures in a grid. In this case, each component of X is a matrix of 14 13 surface pressure values (182 values), measured in a grid surrounding the Iberian Peninsula ( Fig. 2 ). The problem faced in this paper is a classification problem, consisting of obtaining a machine F by using a training set f X  x i , y i  X  , i  X  1 , ... , T part of the series), so that for a given value of x i , it estimates the associated value of y i , i.e. F  X  x i  X  -y i , in such a way that the machine F minimizes an error measure in an independent test good generalization of the machine.

Two evaluation metrics have been considered which quantify the accuracy of n predicted ordinal labels for a given dataset 2 , ... , y n n g , with respect to the true targets f y 1 1. Accuracy ( C ) is simply the fraction of correct predictions on individual samples: C  X  1 n where I  X  X  is the zero X  X ne loss function and n is the number of patterns of the dataset. 2. Mean absolute error ( MAE ) is the average deviation of the prediction from the true target, i.e.: MAE  X  1 n
These measures, commonly found in ordinal regression works ( Cardoso and da Costa, 2007 ; Chu and Keerthi, 2007 ), are aimed to evaluate two different aspects that can be taken into account when an ordinal regression problem is considered: whether the patterns are generally well classified (accuracy or C ) and whether the classifier tends to predict a class as close to the real class as possible ( MAE ). 3. Evaluated classifiers
The main objective of this paper is to test several methods to tackle wind prediction as a classification problem (as described in Section 2 ). At the same time, the possible improvement of standard classifiers when including the label ordering information is also evaluated. The classifier description has been organized in two different groups, nominal classifiers and ordinal classifiers. Support vector machine (SVM) methods receive a special atten-tion because they yield the best performance for the problem (as the reader can check out in Section 4 ). 3.1. Nominal classifiers
Very well-known standard nominal classifiers have been taken into account. Their main characteristics are briefly described in the following subsections. 3.1.1. Support vector machines
The SVM ( Boser et al., 1992 ; Cortes and Vapnik, 1995 )is perhaps the most common kernel learning method for statistical pattern recognition, widely applied to different real problems ( Kisi and Cimen 2012 ; Zarnani et al., 2012 ). An interesting way of analyzing SVMs ( Boser et al., 1992 ) is by viewing them as generalized perceptrons with radial basis functions that compute the inner product on transformed input vectors f  X  x  X  . These f  X  x  X  are denoting feature vectors x in a high dimensional reproducing kernel Hilbert space (RKHS), related to x by a specific transforma-tion. The reproducing kernel function is used, defined as k  X  x , x 0  X  X  / f  X  x  X  f  X  x 0  X  S , where / S denotes inner product in the RKHS.

The basic idea behind SVMs is to separate the two different classes  X  they are firstly defined for two classes and then extended to the multiclass case  X  through a hyperplane which is specified by its normal vector w and the bias b . The hyperplane can be given as / w f  X  x  X  S  X  b  X  0. SVMs are linear parametric models, based on a linear combination of a kernel function evaluated at the training data points. The nature of the problem makes that their parameters can be obtained as the solution of a convex optimization problem, so there is a single, global opti-mum. The sparsity is the other characteristic that has made SVM receive a lot of attention: the final number of training points present in the model is a subset of them, known as support vectors. Additionally, hard margins are replaced by soft margins to face non-separable classification sets. This way allows to handle noise, pre-labelling errors and overlapping, which often occur in practice. Slack-variables, x i , are used to construct a soft margin separating hyperplane ( Cortes and Vapnik, 1995 ). 2500 2000 1500 1000 500 Power (kW)
As Vapnik ( Cortes and Vapnik, 1995 ) shows, the optimal separating hyperplane is the one which maximizes the distance between the hyperplane and the nearest points of both classes (called margin) and results in the best prediction for unseen data. This can be formulated as a Quadratic Programming (QP) problem.
In order to deal with the multiclass case, a  X  X 1-versus-1 X  X  approach can be considered, following the recommendations of
Hsu and Lin (2002) . The idea is to construct a binary classifier per each pair of classes and joining their multiple responses to obtain a final prediction. 3.1.2. Other standard nominal classifiers
Apart from the well-known SVM, other standard machine learning classifiers have been considered. This set of classifiers have shown to report good performance in previous machine learning works ( Landwehr et al., 2005 ), and they have been selected because they cover some of the more common and accurate approaches for nominal classification (classification trees, boosting ensemble construction, and logistic regression) from those available in the well-known Weka machine learning software ( Hall et al., 2009 ). They include:
The Logistic Model Tree (LMT) classifier ( Landwehr et al., 2005 ).
 The C4.5 classification tree inducer ( Quinlan, 1993 ). The AdaBoost.M1 algorithm, using C4.5 as the base learner.
AdaBoost, short for Adaptive Boosting, is a machine learning meta-algorithm ( Freund and Schapire, 1996 ), an algorithm for constructing a  X  X  X trong X  X  classifier as linear combination of simple  X  X  X eak X  X  classifiers. The maximum number of iterations has been set to 10 and 100 iterations (Ada10 and Ada100), as done in previous studies ( Landwehr et al., 2005 ).

Multi-logistic regression methods, including the MultiLogistic (MLogistic) and SimpleLogistic (SLogistic) algorithms. 3.2. Ordinal classifiers
In an ordinal regression problem, the formal definition is the following: an example  X  x , y  X  is composed of an input vector x that of a multi-class classification problem, except that the ranks are ordered, so C 1 ! C 2 ! ! C K is an additional restriction to the problem. 3.2.1. A simple approach to ordinal regression (ASA)
Ordinal information allows ranks to be compared: one could ask  X  X  X s the rank of x greater than k ? X  X , considering a fixed rank
O  X  y k  X  X  k . This question is a binary classification problem, and, by asking this question for k  X  1 , 2, until  X  K 1  X  , the rank of a sample x can be determined. This is the approach studied in Frank and Hall (2001) , where each binary classification problem is solved inde-pendently and the binary probabilistic outputs are transformed to a rank. 3.2.2. Extended binary classification (EBC) simple, the generalization performance using the combination step cannot be easily analyzed. The EBC method ( Li and Lin, 2007 ) works differently and allows generalization analysis of the model. associated questions above. A good prediction would be the following: f  X  x , k  X  X  1 (yes) for k  X  1to k  X  y 1 (where y is the rank associated to the pattern x ) and f  X  x , k  X  X  0 (no) afterwards. answers f  X  x , k  X  is the following: r  X  x  X  X  1  X  1 U being a Boolean test which is 1 if the inner condition is true, and 0 otherwise. In summary, the EBC method is based on the following three steps: 1. Transform all training samples  X  x i , y i  X  into extended samples 2. The extended examples are jointly learned by a binary classi-3. The ranking rule (3) is used to construct a final prediction for model to estimate f  X  x , k  X  : f  X  x , k  X  X  g  X  x  X  y k ,  X  4  X  where g  X  x  X  is a non-linear function defined as g  X  x  X  X  as long as the threshold vector h is ordered, i.e. y 1 o y formed by simply defining extended kernels. In this paper, the identity matrix is used as the encoding matrix, and the absolute value cost matrix and the standard soft-margin SVM are considered. 3.2.3. Gaussian processes for ordinal regression (GPOR) algorithm, where the latent variable f  X  x  X  is modelled using
Gaussian Processes, and then all the parameters are estimated by using a Bayesian framework. The basic idea is that the values of the latent function f f  X  x i  X g are assumed to be the realizations of random variables indexed by their input vectors in a zero-mean Gaussian process. The ideal probability would be
P  X  y i 9 f  X  x i  X  X  X  the latent function is P  X  D 9 f  X  X  Q N i  X  1 P  X  y i 9 f  X  x theorem is applied to write the posterior probability P  X  f  X  1 = P  X  D  X  X  functions are contaminated by a Gaussian noise with zero mean and unknown variance s 2 . P ( f ) is easily defined as a multivariate Gaussian, by using the fact that the covariance is approximated by kernels. The vector of hyperparameters h includes the width of the Gaussian kernels, the s for the noise and the set of thresholds.
P ( D )or P  X  D 9 h  X  is known as the evidence for h and it is estimated by two different approaches in the paper: a Maximum a Posteriori approach with Laplace approximation and a Expectation Propaga-tion with variational methods. 3.2.4. Support vector machines for ordinal regression (SVOR).
The previously defined SVM formulation has been adapted to the ordinal regression setting, by simply defining a different threshold b j for each class, and specifically adapting the QP problem ( Shashua and Levin, 2003 ). Instead of simply deciding the class of the pattern by the sign of the projection w T x , the corresponding real line will be split into different intervals by using a threshold vector b . This results in parallel hyperplanes with the same w and different thresholds b j . In this paper, two different implementations for this idea are considered, taken from the work of Chu and Keerthi (2007) : SVOR with Explicit constraints (SVOREX) is based on defining a
QP problem where the last set of constraints assuring the order between the thresholds explicitly appears in the optimization problem and where the slacks for the j -th parallel hyperplane are defined for all patterns of class j and j  X  1.

SVOR with Implicit constraints (SVORIM) is based on redefining again the QP problem, following this principle: instead of considering only the errors from the samples of adjacent categories, samples in all the categories are allowed to con-tribute errors for each hyperplane. In this way, the ordinal inequalities on the thresholds are implicitly satisfied at the optimal solution. 4. Experiments
In the following subsections, the description of the datasets and the experimental design is given, together with the description of themethodsbasedonHiddenMarkovModels(HMMs),whichwill be used also for comparison purposes. Then, the details on the preprocessing of the datasets are explained, and finally the obtained results with the different considered classifiers are discussed. 4.1. Dataset description and experimental design
Five different wind farms have been considered for this study, resulting in five datasets (H, M, P, U and Z, see Fig. 3 ). Each dataset includes a series of discretized wind speed values (targets), taken in a tower at 40 m of height, and averaged over 24 h to obtain daily data values. On the other hand, a series of grids of average daily pressure maps for the same period have been obtained from the National Center for Environmental Prediction/National
Center for Atmospheric Research Reanalysis Project (NCEP/NCAR) ( Kalnay et al., 1996 ; http://www.esrl.noaa.gov/psd/data/reanalysis/ reanalysis.shtml ), which are public data profusely used in clima-tology and meteorology applications. As previously mentioned, an uniform grid in latitude and longitude has been considered, shown in Fig. 2 , with 182 measurement points, and each element of this grid is one input variable.

For each wind farm, two different sets are obtained, one for training the models and another one for assessing the perfor-mance of the algorithms. In this way, the structure of the different datasets used in this study is given in Table 1 . The structures of these datasets are challenging, because the distribution of the different classes is clearly imbalanced, with very few situations of high wind speed (class C 4 ) and lot of patterns belonging to a moderate wind speed class (class C 2 ).

Since all the tested algorithms are deterministic, they will be run once, deriving a model from the training set and evaluating its accuracy over the test set. Both training and test sets are parts of a wind series, so it is not advisable to do different random parti-tions of them.

For the selection of the SVM X  X  hyper-parameters (regulariza-tion parameter, C , and width of the Gaussian functions, g ), a grid search algorithm was applied with a 10-fold cross-validation, using the following ranges: C A f 10 3 , 10 2 , ... , 10 3 f 10 3 , 10 2 , ... , 10 3 g . This cross-validation has been applied only taking into account the training data, and then repeating the process with the lowest error parameter combination using the complete training set. 4.2. Comparison to hidden Markov models
Apart from the methods presented in Section 3 , the approach of Hocaoglu et al. (2010) based on HMMs has been also selected. Although the work has some similarities with the approach presented in this paper (given that wind speed is also estimated from pressure data), some differences have to be outlined. First of all, a complete synoptic grid, with 182 different values (14 13), is considered in our approach (see Fig. 2 ). However, the afore-mentioned paper considered one single atmospheric pressure observation. Pressure and wind speeds values are then quantized in different number of intervals in order to apply discrete HMMs to estimate wind speed. Other important fact is that in Hocaoglu et al. (2010) hourly wind speed prediction is considered, whereas in the current approach we manage average daily wind speed values. The lower variability of these daily values can make necessary to use a lower number of states for modelling.
To adapt the approach in Hocaoglu et al. (2010) to the proposal of this work, a HMM for each wind farm was constructed, considering one single-point pressure value obtained from the 182 values of the grid. Specifically, the absolute value differences between the upper left and the upper right points and between the bottom left and the bottom right ones were averaged. The number of states of each HMM was fixed to four states, consider-ing the intervals for wind speed in Fig. 1 . The observable emissions were considered to be the single-point pressure values, which were discretized in 150 values (in a similar way to
Hocaoglu et al., 2010 ). The transition probabilities are obtained and organized in a matrix form in the same way than in Hocaoglu et al. (2010) , as well as the emission matrix. 4.3. Preprocessing of the dataset
As previously stated, the vector of inputs is formed by 14 13 surface pressure values (182 values in a grid around the Iberian Peninsula), which results in a very high number of variables.
When too many inputs are presented to the standard machine learning algorithms, a very well known problem appears, the curse of dimensionality , which can decrease the performance of these algorithms and significantly increase the computational cost.

In order to alleviate this problem, a simple approach has been applied, based on the standard technique of principal component analysis (PCA) ( Jolliffe, 2002 ). This is not needed for the HMMs described in Section 4.2 , given that only one single pressure value is obtained from the grid to construct the model. PCA is the predominant linear dimensionality reduction technique, and has been widely applied to datasets in all scientific domains. Gen-erally speaking, PCA maps data points from a high dimensional space to a low dimensional space, while keeping all the relevant linear structure intact.

PCA algorithm returns so many principal components (PCs, linear combinations of the input variables) as the total number of inputs, but they are sorted in the following way: the first PC has as high variance as possible (that is, accounts for as much of the variability in the data as possible), and each succeeding compo-nent in turn has the highest variance possible under the con-straint that it will be orthogonal to (i.e. uncorrelated with) the preceding components. Note that it should be decided at a later stage how many PCs are retained when reducing the dimension-ality of the problem.

With this aim, the algorithm included in Fig. 4 has been applied. The idea is very simple: the coefficients of the PCs are obtained using the training data and all possible combinations from 1 to the number of PCs that retain a 99% of the variance are tested. A 10-fold cross-validation is applied for each combination, estimating the error with one of the simplest existing classifier (a linear discriminant analysis, LDA) in order to limit the compu-tational time. Once the best number of PCs is decided, training and test data are projected into them, and the reduced datasets are returned. 4.4. Results ered ( C and MAE , see Eqs. (1) and (2) ) are included in Tables 2 and 3 , respectively. Based on the C and MAE values, the ranking of each method in each wind farm is obtained ( R  X  1 for the best performing method and R  X  13 for the worst one). The mean accuracy and MAE ( C and M ) as well as the mean ranking ( R
R M ) are also included in Tables 2 and 3 . The first conclusion is that considerably good accuracies are obtained, what reveals that considering the problem as a classification task can provide an accurate information of the wind farm. Also, the MAE values are quite low, the algorithms doing a quite good job when ranking the patterns (a MAE value of 0.2 means that the classifier predictions are, in average, 0.2 categories lower or higher than the target ones).
 acceptable results but lower in general than those reported by the rest of methods. One possible reason is that the rest of the Deciding # of Principal Components: : Require: Training dataset ( Tr ), Test dataset ( Te ) 1: Apply PCA to Tr , without considering Te 2: Max  X  Number of PCs retaining a 99% of the total variance of the 3: for i =1  X  Max do 4: Tr i  X  Tr projected over the i first PCs. 5: Apply a ten-fold cross-validation method, considering Tr 6: e i  X  cross-validated error of the classifier. 7: end for 8: n  X  argmin i e i 9: Tr *  X  Tr projected over the n first PCs. 10: Te *  X  Te projected over the n first PCs. 11: return Tr * and Te * methods do not take into account the sequential character of wind speed and pressure values, while HMM does. Consequently, it is more difficult for HMMs to improve measures like C or MAE , than it is for the rest of more flexible methods.

From these tables, the SVM methods seem to be the most competitive ones from all the different alternatives considered. When analysing the mean ranking and performance, the
EBC(SVM) methodology obtains the better results for both mea-sures. The second best methods are SVOREX and SVORIM for C , and SVORIM for MAE . Note that high accuracy values can be masking a lower ranking performance (i.e. a high MAE value), because the classifier can tend to assign rank values far from the real ones.

To determine the statistical significance of the rank differences observed for each method in the different datasets, a non-parametric Friedman (1940) test has been carried out with the
C and MAE rankings of the different methods (since a previous evaluation of the C and MAE values results in rejecting the normality and the equality of variances hypothesis). The test shows that the effect of the method used for classification is statistically significant at a significance level of a  X  5 % , as the statistical values are F n  X  12 : 37 = 2 C 0 for C and F n  X  21 : 67 = 2 C
MAE . As a result, the test concludes that all algorithms perform statistically differently in mean ranking.

The Bonferroni X  X unn test ( Demsar, 2006 ) is an approach to compare all classifiers to a given classifier (a control method), which is more sensitive than comparing all classifiers to each other. This test has been applied to both C and MAE rankings using
EBC(SVM) as the control method. The test concludes that the differences in C and MAE values are significant:
At a significance level of a  X  5 % , when EBC(SVM) is compared to C4.5, GPOR and HMM using the C measure (with C ranking differences of 8.30, 8.10, and 9.30, respectively) and to C4.5,
ASA(C4.5), GPOR and HMM using the MAE measure (with MAE ranking differences of 8.90, 7.20, 8.80 and 10.40, respectively). Additionally, at a significance level of a  X  10 % , when EBC(SVM) is compared to ASA(C4.5) using the C measure (with C ranking difference of 6.80), and to Ada10(C4.5) using the MAE measure (with MAE ranking difference of 6.60).

It is important to outline that, although the rank differences are significant, the values obtained for the different measures (specially for accuracy, C ) are very low (see Tables 2 and 3 ).
Consequently, the study cannot clearly establish that the use of the ordering information improves the results obtained by the nominal classifiers. However, it should be mentioned that the number of ordinal methods which obtain better results is higher than in the nominal case, and that the differences for the MAE measure are generally higher. 5. Conclusions
This paper introduced a new approach for daily mean wind speed series estimation, based on synoptic pressure measures.
The problem has been stated as a classification task rather than the usual regression approach. Wind speed was discretized in four different ranges, which gather the main information needed by the experts when managing the wind farm. On the other hand, synoptic pressure measures in a grid have been considered as the input variables. The results of this preliminary study show that the best performing method is the SVM, with very high accuracy and low MAE values. Ordering information (more precisely, the
EBC and ASA algorithms) do not clearly outperform nominal methods (SVM and C4.5), given that very similar accuracies are obtained (although the differences in ranking over six datasets show to be significant).
 References
