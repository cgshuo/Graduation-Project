 PATRICK ROOS, J. RYAN CARR, and DANA S. NAU University of Maryland 1. INTRODUCTION
Empirical evidence shows that human decision making, rather than con-forming to the decision-theoretic notion of expected-value maximization, is state-dependent : the decisions are sometimes risk-averse and sometimes risk-seeking, depending on the decision maker X  X  circumstances. Much effort has been invested in describing and modeling such behavior, but these efforts have largely lacked an explicit investigation of what evolutionary pressures might have influenced the behavior X  X  spread. Thus an important open question is why state-dependent risk behavior is so prevalent.

In this article, we use tools from evolutionary game theory to investigate how agents X  risk behavior relates to different population dynamics (i.e., rules governing changes in the number of agents of each kind). In particular, we are interested in imitation dynamics , which model cultural evolution as a product of social learning by imitation. The best-known imitation dynamics are the replicator dynamic and the imitate-the-better dynamic, but there are many others.

We consider a parameterized class of imitation dynamics in which the pa-rameter 0  X   X   X  1 yields the replicator dynamic with  X  = 1andthe imitate-the-better dynamic with  X  = 0. Our study includes (1) a detailed analysis of how different imitation dynamics can affect risk behavior when agents make sequential choices, and (2) simulations, using several different imitation dy-namics, of simple evolutionary lottery games in which agents make sequential choices among lotteries that have equal expected value but different risks. Our results demonstrate that for every population dynamic in this class except for the replicator dynamic, the interplay between risk-taking and sequentiality of choices allows state-dependent risk behavior to have an evolutionary advan-tage over expected-value maximization.

Our study provides a starting point for further investigation of how popula-tion dynamics influence risk behavior in evolutionary game environments. We anticipate that state-dependent risk behavior will outperform expected-value-maximizing strategies in a wide variety of evolutionary game environments involving sequential choices of different risks.

The remainder of this article is organized as follows. Section 2 provides a brief background on human decision making under risk and evolutionary game theory. Section 3 introduces our evolutionary game model, including the lottery game we use to study risk behavior and the imitation dynamics we are expect different risk behavior to perform in different environments. Section 5 presents our experimental simulations and results. Finally, Section 6 provides concluding remarks. 2. BACKGROUND 2.1 Human Decision Making Under Risk
Human decision making under risk is the subject of much research effort in the social sciences. In most of the existing literature on models of human decision making under risk, the construction of such models is approached primarily through the analysis of a decision maker X  X  choices among lotteries that have different payoff distributions, and thus potentially different risks. Under the most traditional model of decision making, expected utility theory, a rational agent X  X  preferences can be modeled by assigning to each possible outcome a number called the outcome X  X  utility ; and a rational choice is one that maxi-mizes the expected utility of the outcomes [von Neumann and Morgenstern 1944]. Empirical evidence of human decision making under risk shows that humans are sometimes risk-averse, sometimes risk-seeking, and even behave in ways that systematically violate the axioms of expected utility [Kahneman and Tversky 1979]. Expected utility theory can account for different attitudes towards risk through certain von Neumann-Morgenstern utility functions (e.g.,
Friedman and Savage [1948]). Such risk propensities can differ greatly from simple expected-value considerations on prospective outcomes.

Researchers have invested much effort in constructing utility functions that appropriately model human decision making using risk using the expected-utility model (e.g., Friedman and Savage [1948]; Arrow [1971]; Rabin [2000]).
Related efforts in economics have aimed to describe the preferences of humans over inter-temporal lotteries, recognizing the effects of temporally successive lotteries on risk preferences [Epstein and Zin 1989, 1991]. Other studies de-fine utility functions that take into account inter-personal or population com-parisons [Abel 1990]. Yet other researchers have constructed alternative de-scriptive theories of decision making that claim to correspond more closely to how humans make decisions involving risk. Among the most popular of these models are prospect theory [Kahneman and Tversky 1979; Tversky and Kah-neman 1992], regret theory [Loomes and Sugden 1982], and SP/A (Security-
Potential/Aspiration) theory [Lopes 1987, 1990; Lopes and Oden 1999]. One ad-vantage of these models is that they more explicitly or perhaps more naturally model some of the mechanics involved in human decision-making processes.
For example, state-dependent attitudes toward risk are modeled in prospect theory by using a reference point with respect to which prospective outcomes can be interpreted as potential gains or losses, and are modeled in SP/A theory involving risk. A common theme of both Prospect theory and SP/A theory is that agents are risk-averse when they have done well relative to some reference point and risk-seeking when they have not done well relative to the reference point. 2.2 Evolutionary Game Theory and Risk Behavior
Evolutionary game theory has been used to study and explain a great vari-ety of social and cultural phenomena. Examples of such phenomena studied through evolutionary games include altruism [Axelrod and Hamilton 1981; Ri-olo et al. 2001; Bowles and Gintis 2004], trust [Fang et al. 2002; Kimbrough 2005], fairness [Binmore 1998], empathy [Page and Nowak 2002], and social examples of empirical studies showing that humans violate the strong ratio-nality assumptions of classical game theory. Evolutionary game theory is thus an attractive framework under which to model human behavior in such do-mains because the assumption of perfectly rational agents is not required.
Furthermore, most game-theoretic work in economics, the focus of our evolutionary-game-theoretic approach is not to define internal preferences and ences according to their evolutionary fitness (which is external).
Evolutionary game theory studies a population of agents making choices
After agents have played the game, they reproduce into the next generation according to a reproduction function or population dynamic that, generally the current generation. To study risk behavior in this framework, we can model lotteries of different risks. As described in Alexander [2009], these lotteries dispense resources that are considered to be an objective quantity of which (1) agents always want more than less and (2) interpersonal comparisons are meaningful. The reproduction function defining the dynamics of strategies in the population then acts directly on these resources. 2.3 Imitation Dynamics
Imitation dynamics are a class of population dynamics commonly used to model the evolution of behaviors in societies [Hofbauer and Sigmund 1998; Nowak and May 1992; Huberman and Glance 1993; Nowak et al. 1994; Eguluz et al. 2005]. The general framework for imitation dynamics is stated by Hofbauer and Sigmund [1998] as follows.

In what follows, we will call these players the  X  X bserver X  and the  X  X bserved agent, X  respectively.

Important theoretical studies have been done of two specific imitation dy-namics. One of these is the replicator dynamic [Taylor and Jonker 1978; Schlag 1998, 1999; Hofbauer and Sigmund 1998; Gintis 2000], in which the probability that the observer adopts the strategy of the observed agent is proportional to how much more successful the observer was than the observed. The other is the imitate-the-better dynamic [Blume 1993; Vega-Redondo 1997; Szab  X  oandT oke 1998; Riolo et al. 2001; Hauert and Szabo 2005; Dawid 2007; Traulsen and
Hauert 2009; Traulsen et al. 2007], 1 in which the observer always adopts the
Several experimental studies investigating social learning through imitation between humans have found experimental support for Vega-Redondo X  X  model [Huck et al. 1997, 2000; Offerman et al. 2002]. Experiments on human imitation reported by Apesteguia et al. [2007] indicate that the difference in observed the more likely imitation occurs). This is more in line with Schlag X  X  model.
Due to this evidence for both imitation models, in this article we explore a parameterized range of imitation dynamics based on a definition in Hofbauer and Sigmund [1998] that includes the replicator dynamic, the imitate-the-better dynamic, and a spectrum of other dynamics in between these two. 3. EVOLUTIONARY GAME MODEL
In previous work we have proposed the sequential lottery game, a class of games that we use to investigate risk behavior under evolutionary pressures [Roos and Nau 2009, 2010b]. In this section we describe this sequential lottery game and the particular range of imitation dynamics under which we explore the evolution of risk behavior. 3.1 Sequential Lottery Game
We consider a game in which agents acquire payoffs dispensed by lotteries. In each generation, each agent must make a sequence of n choices where each risky lottery, which one can win (a payoff of 8) with probability p ,or lose (a payoff of 0) with probability 1  X  p . 3 Note that if p = 0 expected value 4.
 Our population consists of agents that follow strategies chosen from the set
S ={ s where each x i is the proportion of agents in the population using strategy s
We let  X  ( i ) denote the payoff accumulated in a generation from the n lottery choices by agents of type i (i.e., agents following strategy s 3.2 Imitation Dynamics in Our Evolutionary Games
As we discussed in Section 2.3, we want to explore a range of population dy-namics that includes the replicator dynamic, imitate-the-better dynamic, and other dynamics intermediate between these two extremes. Hofbauer and Sig-mund [1998] give the following parameterized formula for these population dynamics: where x i is the current proportion in the population of agents of type i , imitation dynamic. Our formulation is based on theirs, but incorporates the following changes.  X  X e are interested in population dynamics based on payoff comparisons among individuals as in Blume [1993]; Szab  X  oandT oke [1998], Riolo, Co-hen, and Axelrod [2001]; Hauert and Szabo [2005]; Traulsen and Hauert [2009]; Traulsen et al. [2007]; Dawid [2007]. To model payoff comparisons among individuals, we must take into account the stochastic variability in the payoffs to individual agents. We do this by treating  X  discrete random variables representing the distributions of payoffs that an agent of type i and an agent of type j receive from their lottery choices.  X  X he imitate-the-better dynamic and the replicator dynamic correspond to  X  = 0and  X  = 1, respectively. Since the imitation dynamics that interest us are these two and and the ones that are intermediate between them, we only consider 0  X   X   X  1.
 modified version of Eq. (1) is where  X   X  ( i , j ) = r s | ( r  X  s ) |  X  sign ( r  X  s )  X  between agents of type i and j (which happens with nonzero probability if on i agents X  growth rate. If this is the case, we say i has an evolutionary advantage over j . 4. THEORETICAL PREDICTIONS These are listed in Table I. 5
Table II gives each strategy, its possible numeric payoffs, and the probabil-8. For example, P [  X  (R W S) &gt; 8] = 0 . 5and P [  X  (R
In this section, we examine how these strategies will perform against one another for different population dynamics (Sections 4.1, 4.2, and 4.3) and for briefly discusses cases where n = 2. 4.1 The Replicator Dynamic
We now show that under the replicator dynamic (  X  = 1), the switching rate
P ROPOSITION 4.1. Under the population dynamics given by Eq. (2) when discrete random variables  X  ( i ) and  X  ( j ) ).

P ROOF .Let r and s be possible payoff values acquired by agents of type i  X  = 1,
Assuming independence between payoffs,  X   X  ( i , j ) = EV (  X  EV (  X  ( j )), and the proposition follows.
 Since all strategies have the same expected payoff in this environment, evolutionarily.
 4.2 The Imitate-the-Better Dynamic of the payoff difference between two paired agents plays a role in determining the switching rate; the magnitude of the difference is irrelevant. We can com-pute the switching rate between two strategies by using the probabilities in shows these values for the R W S vs. RR pairing. We can then use these prob-follows.  X  (R W S , RR) = sign(0  X  0)  X  0 . 0625 + sign(8  X  0)  X  0 .
Using similar calculations, we see that  X  0 (R W S , SS) = 0 . 0625, and  X  0 (R W S , RS) = X  0 (R W S , SR) = 0. This suggests that R able to consistently win an evolutionary competition against RR, R and remain stable with SR and RS in this environment. The experimental results in Section 5 verify this prediction. 4.3 Arbitrary  X 
For 0  X   X   X  1, we can calculate the switching rate in a method similar to the previous section, combining the probabilities from Table II to get the values differences are now important, the calculation is slightly more complex. For instance, the switching rate for the R W S vs. RR pairing is now as follows.  X  (R W S , RR) =| 0  X  0 |  X  sign(0  X  0)  X  0 . 0625 +| 8  X  0
Figure 1 shows how the switching rate between R W S and the other strategies varies with  X  . We see that R W S has an advantage over all other strategies for 0 &lt; X &lt; 1, suggesting that R W S should be able to win any evolutionary competition in these environments. Again, this prediction is supported by the simulation results in Section 5. 4.4 Arbitrary p is any number between 0 and 1 (while the risky lottery X  X  expected value is between 0 and 8). Table IV gives the probability distributions for each pure strategy.

We can also construct a new probability matrix for each pairing such as the one for R W S vs. RR shown in Table V. We can then compute the switching rate for our pairing as before. For example, the switching rate for R the following.
Notice that when p &gt; 0 . 5, the risky lottery has a higher expected value than the safe lottery, and the opposite is true when p &lt; highest expected value when p &gt; 0 . 5, and SS has the highest expected value when p &lt; 0 . 5.

Surprisingly, even though R W S has a suboptimal expected value when p = 0 . 5, by examining the switching rates, we can see that it still has an evo-lutionary advantage over both SS and RR for many values of p and shows the values of p and  X  for which  X   X  (R W S , RR) &gt; meaning that for these values of p and  X  ,R W S has an evolutionary advantage over expected-value maximizing strategies. Under the imitate-the-better dy-namic (  X  = 0), the range is surprisingly large. For example, R SS even when p = 0 . 4, and SS has a significantly higher expected value than R
S. As  X  increases, the range shrinks at a roughly linear rate, disappearing at  X  = 1 (i.e., the replicator dynamic). 4.5 Evolutionary Stability of State-Dependent Risk Behavior
In this section, we discuss whether R W Sisan evolutionarily stable strategy (ESS) in the 2-lottery game, when p = 0 . 5and0 &lt; X &lt; lottery games when  X  = 1, and propose an intuitive modification to make it applicable. We then show that R W S fits our modified definition of an ESS. 4.5.1 Evolutionary Stability under Imitation Dynamics. In an evolution-ary game, a population of agents using an evolutionarily stable strategy (ESS) 1982]. According to Maynard Smith, strategy S is an ESS if for every strategy
T = S , one of the following conditions holds:  X  E ( S , S ) &gt; E ( T , S ),  X  E ( S , S ) = E ( T , S )and E ( S , T ) &gt; E ( T , T ), against strategy Y [Smith 1982].

This definition does not apply directly to the n -lottery game because it as-sumes we are using the replicator dynamic for which the expected payoff of a strategy pairing is all that is necessary to determine whether one strategy will perform better than the other. As shown in Section 4.4, with population dynamics other than the replicator dynamic, the expected value of a pairing is game. Thus, we will use the switching rate  X   X  ( X , Y ) rather than E ( X defining evolutionary stability for the n -lottery game under imitation dynam-ics. We believe this is appropriate because if there are many agents using X and few using Y ,then  X  than Y will grow playing against X ,so Y will not be able to gain population and will eventually die off;  X   X   X  ( X , X ) = X   X  ( Y , X )and  X   X  ( X , Y ) &gt;  X   X  ( Y same rate when playing against X ,but X grows faster than Y when playing against Y ,so Y will still not be able to gain population and will eventually die off.

These scenarios correspond to the two conditions for X to be an ESS in the classical definition.

Replacing expected value with switching rates in the preceding definition gives us the following two conditions for S to be an ESS:  X   X   X  ( S , S ) &gt;  X   X  ( T , S )or  X   X   X  ( S , S ) = X   X  ( T , S )and  X   X  ( S , T ) &gt;  X   X  ( T for all T = S .Since  X   X  ( S , S ) = 0and  X   X  ( S , T ) = X  X  X  can combine these conditions and define ESS in the n -lottery game as follows.
Definition 1 . A strategy S is an evolutionarily stable strategy (ESS) in the n -lottery game if, for any strategy T = S ,  X   X  ( S , T ) 4.5.2 RWS is Evolutionarily Stable. In this section, we show that R an ESS by Definition 1 for the 2-lottery game with p = 0 . do this, we must show that it has a positive switching rate with an arbitrary strategy. Therefore, our first step must be to devise a method for representing an agent makes and the possible lottery outcomes are arranged into a game tree as shown in Figure 3, then any strategy can be expressed as S a , b we have been dealing with thus far can be represented as follows (here, a  X  since the decision corresponding to that probability is never reached).
We can now calculate the switching rate between R W S and an arbitrary strategy S a , b , c , d in terms of a , b , c , d , and  X   X  (R W R , RR) and  X   X  (R W R , SS) in Section 4.3. This comes out to:
The three bracketed terms are all strictly greater than 0 for 0 times the switching rate between R W S and each of those strategies. Given that the bracketed terms are strictly positive, it is easy to see that 0 unless a = 1, b = 0, and c = 1. Since S 1 , 0 , 1 ,  X  is equivalent to R that  X   X  (R W R , S a , b , c , d ) &gt; 0 for all S a , b stable strategy by Definition 1. 4.6 Other Values of n
With the exception of Section 4.5.1, our theoretical development has been largely restricted to the case n = 2. We now discuss briefly what happens for other values of n .

The case n = 1 is relatively trivial: there are only two pure strategies, both are unconditional, and both perform equally well (for more details, see Roos and Nau [2010a]).

The case n &gt; 2 is very hard to analyze because the number of pure strategies exhibited by R W Sfor n = 2, namely, to play it safe when having done well and risky otherwise, should also have an advantage when n &gt; pilot experiments that support this in Section 5.3. 5. SIMULATIONS pure strategies, we ran computer simulations of agent-based models playing our two-choice evolutionary lottery game. These simulations and results are described in the next section. 5.1 Setup and Implementation
Our simulations for the two-choice lottery game environment explore popula-tion evolution under a variety of parameter combinations of parameter) and p (the probability of winning the risky lottery). The types of agents included were the six pure strategies for the two-choice game described earlier. All simulations started with an initial population of 1000 agents for each agent type.

To model the imitation dynamics given by Eq. (2) in our finite population agent-based model, we used a pairwise comparison process [Traulsen and
Hauert 2009] to model the transmission of strategies among agents. In each generation, after all agents have received payoffs from chosen lotteries, each namics given by Eq. (1) in our agent-based model, we use where  X  is the highest possible difference in payoff. Figure 4 provides pseu-docode on how this pairwise comparison imitation process was implemented. 5.2 Results
Figure 5(a,b,c) shows the results for simulations with p = (the replicator dynamic),  X  = 0 (the imitate-the-better dynamic), and
Each plot is an average over 20 simulation runs (the amount of variation from one run to another was quite small). These experiments confirm our analysis from Section 4.3, which shows that R W S has an evolutionarily advantageous risk behavior under any 0  X   X &lt; 0.

As predicted by our analysis, R W S outperformed the other strategies evolu-tionarily except when  X  = 1.  X  X or  X  = 1, all of the strategies performed equally well and remained at their initial population counts.  X  X or  X  = 0, the state-dependent strategy R W S outperformed the other strate-gies. R W S rose in population proportion relatively quickly to comprise the majority ( &gt; 2 / 3) of the population and remained there throughout subse-quent generations. Furthermore, the two unconditional strategies SR and RS remained, comprising the proportion of the population not taken over by
R W S.  X  X or  X  = 0 . 5, the R W S agent population grew similarly as for
R W S also had an advantage against SR and RS (as indicated by Figure 1) and thus continued to grow to comprise 100% of the population.

We also ran simulations with  X  = 0 . 2 , 0 . 4 , 0 . 6 , and 0  X  values are all essentially equal to the case of  X  = 0 . 5. The only difference is that the rate at which R W S grows to take over the population is inversely related to  X  (i.e., for larger  X  values, it takes longer for R population).

In order to explore lottery games in which the risky lottery has a different expected value than the safe lottery, we also ran experiments with p 0.4, 0.55, and 0.7. These values were chosen because for  X  = ( p which our analysis predicts that R W S has an evolutionary advantage over the expected-value-maximizing strategy, and the unshaded areas are regions for which our analysis predicts the reverse.

As shown in Figure 6(a,b,c,d), the simulation results confirm the theoretical predictions. More specifically:  X  X or p = 0 . 2 (Figure 6(a)), SS is the expected-value maximizing strategy and it takes over the population;  X  X or p = 0 . 7 (Figure 6(d)), RR is the expected-value maximizing strategy and it takes over the population;  X  X ven though SS is the expected-value-maximizing strategy for p (Figure 6(b)) and RR is for p = 0 . 55 (Figure 6(c)), in both cases R an evolutionary advantage and takes over the population.
 cause of the differing amounts of evolutionary advantage that different strate-gies have over others. For example, a strategy a may grow in number temporar-ily because it has an advantage over another strategy b . But once b becomes extinct (or sufficiently small in number), a will diminish because some other strategy c has an advantage over a . 5.3 Simulations for n &gt; 2 averse when it has done well and risk-seeking when it has done badly, may be advantageous in lottery games with n &gt; 2. To test this hypothesis, we ran a
For our simulations, we used an initial population of 1000 agents of each type, and the parameters p = 0 . 5 for the risky lottery and population dynamic. The results were qualitatively the same as the ones in
Figure 5(c): the RR W SS strategy dominated the other strategies and grew to comprise 100% of the population. This would seem to confirm our hypothesis, but since there are hundreds of pure strategies when n = 4 and we only looked 6. CONCLUSIONS
Our results show that for imitation dynamics other than the pure replicator dynamic, there are evolutionary game environments in which the R egy has an evolutionary advantage over expected-value maximization. Since R prominent models of human decision making, this suggests that population dy-namics other than the replicator dynamic may model an important mechanism for the emergence of those risk preferences.

There are several ways in which our work could be extended.  X  X ur study was restricted to simple lottery games in order to avoid confound-ing factors that may be present in more complex social games (e.g., trust, among reproduction dynamics, risk preferences, and social interactions such as cooperation. We have already begun some work along this line: Roos and
Nau [2010a] shows that risk behavior similar to R W S can promote the evo-lution of cooperation in a situation where the cooperation requires a risky decision (namely, choosing to cooperate).  X  X t will be important to examine other population dynamics in which a strat-egy X  X  reproductive success is not always proportional to its expected payoff.
For example, if a death rate (e.g., Nowak and Sigmund [1993]) is implemented as a payoff-dependent threshold function, we might expect risk propensities to differ depending on whether an agent is above or below that threshold in a manner similar to behavior above or below an aspiration level in SP/A theory.  X  X ur study focused on the case n = 2, that is, in each generation the agents made two decisions. We believe that state-dependent risk preferences like those of R W S should also have an advantage when n &gt; 2, and Section 5.3 discussed some pilot experiments that support this intuition. Conducting more extensive studies will be a topic for future work.  X  X e assumed a well-mixed population in which every agent was able and equally likely to imitate any other. It would be interesting to explore the possible effects of social or physical structures (that may guide or constrain imitation) on the evolution of risk behavior.  X  X inally, it may be useful to conduct empirical studies of which type of im-itation dynamics best models human imitation propensities. The insights of this article combined with such knowledge have potential application in domains where human decision making under risk is of interest, including economics, medicine, military and public policy.
 APPENDIX In this section, we present the derivation of  X   X  (R W S ,
Using Table IV and Figure 3, we can determine the probability of each pair of payoffs occurring and use them for the values of p ( r , s ) as follows.  X   X  (R W S , S p = (1  X  p ) (for ease of exposition we will wait to substitute 0.5 for p ):  X   X  (R W S , S which yields which yields  X 
Recollecting terms gives us
Substituting p = 1 2 and expanding the final term, we get  X  which yields  X 
Since ( ac  X  a ) = X  a (1  X  c ), this yields  X 
Finally, recollecting terms gives us which matches Eq. (3).
 We wish to thank the anonymous reviewers for their helpful suggestions.
