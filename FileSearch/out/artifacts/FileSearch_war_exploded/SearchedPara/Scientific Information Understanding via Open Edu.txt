 Scientific publication retrieval/recommendation has been investi-gated in the past decade. However, to the best of our knowledge, few efforts have been made to help junior scholars and graduate students to understand and consume the essence of those scien-tific readings. This paper proposes a novel learning/reading en-vironment, OER-based Collaborative PDF Reader (OCPR), that incorporates innovative scaffolding methods that can: 1. auto-characterize student emerging information need while reading a paper; and 2. enable students to readily access open educational resources (OER) based on their information need. By using meta-search methods, we pre-indexed 1,112,718 OERs, including pre-sentation videos, slides, algorithm source code, or Wikipedia pages, for 41,378 STEM publications. Based on the computational infor-mation need, we use text mining and heterogeneous graph mining algorithms to recommend high quality OERs to help students bet-ter understand the scientific content in the paper. Evaluation results and exit surveys for an information retrieval course show that the OCPR system alone with the recommended OERs can effectively assist graduate students better understand the complex STEM pub-lications. For instance, 78.42% of participants believe the OCPR system and recommended OERs can provide precise and useful information they need, while 78.43% of them believe the recom-mended OERs are close to exactly what they need when reading the paper. From OER ranking viewpoint, MRR, MAP and NDCG results prove that learning to rank and cold start solutions can effi-ciently integrate different text and graph ranking features. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval System, Algorithms, Experimentation, Measurement c  X  Scaffolding; Information Need Characterization; Education; Het-erogeneous Graph Mining; Evaluation; Information Understanding  X  X  don X  X  think I need those books... I cannot understand them anyway... X  This was a student X  X  response when I suggested that she should find some statistics methods books in the university li-brary. Actually, her response is quite representative when students face STEM (Science, Technology, Engineering, and Mathematics) readings. In the last decade, while the volume of STEM publica-tions has increased dramatically in university and digital libraries, few efforts have been made to help students/junior scholars un-derstand them. From an educational viewpoint, understanding the content of scientific publications in STEM course environments re-mains daunting [10], i.e., Information Access 6 = Information Un-derstanding . For instance, a number of search/recommendation algorithms ensure Google Scholar and Microsoft Academic give users access to the high quality scientific readings, but junior schol-ars/graduate students may not necessarily understand them. In a recent study of STEM [8], PhD students (in computer science do-main) claimed that the complex models, formulas, and methods in the readings were deemed too difficult to understand because of the students X  limited knowledge in computer science and mathematics. Students need innovative scaffolding methods/systems to better as-sist in understanding scientific publications 1 .

While the content of scientific publications is challenging and difficult for students, a large number of open educational resources (OERs) are increasingly available and have great potential to as-sist students better understand the essence of these publications. For example, scholars, organizations and institutions commonly share conference slides, video lectures, tutorials, Wikipedia pages, datasets and source codes generated from research. As these OERs are often seamlessly blended or integrated with other scholarly pub-lications or research topics, students can, we surmise, better un-derstand the papers by leveraging those OERs. In this paper, we define it as OER-based Scaffolding. In a study by Liu [8], for ex-ample, students expect that a blend of OER-based learning objects could significantly improve learning. Unfortunately, not all OERs exist in a publication as cited references; some may be scattered across different social media (e.g., TED, SlideShare, authorStream, GitHub, SourceForge, YouTube, Google Code, VideoLecture , and
In education, scaffolding refers to a variety of instructional tech-niques used to move students progressively toward stronger under-standing and, ultimately, greater independence in the learning pro-cess. http://edglossary.org/scaffolding/ Wikipedia ). While the cost of manually locating those OERs for large-scale STEM topics or publications is prohibitive, as another challenge, the existing system cannot use those innovative OERs to address students X  emerging information needs, i.e., using or rec-ommending OER(s) to address students X  questions on a particular section/paragraph/sentence/formula of a scientific publication.
Motivated by these observations, we propose a new solution and an innovative system framework to help students and scholars bet-ter understand and learn from scientific publications in a course environment by leveraging OERs, i.e., OER-based scaffolding. A new learning system, called the OER-based Collaborative PDF Reader (OCPR) , is to be implemented as a first step towards this effort. Theoretically speaking, the system is also designed to ac-commodate the needs of students in MOOCs (massive open online courses) in addition to students from varied backgrounds. As Fig-ure 1 shows, the system can auto-characterize student X  X  emerging information need while reading a paper, while recommending high quality OERs to help them understand the publication.

With the exception of using text mining for OER recommen-dation (i.e., using highlighted text to find relevant OERs), OCPR also employs heterogeneous graph mining to enhance scaffolding performance by investigating the weighted relations between OER pair; OER and paper; OER-topic association; paper-topic associa-tion; and the topic-topic relationships, which help to prioritize im-portant OERs and filter out the noisy resources. The meta-path and supervised random-walk-based graph algorithms [11] will be used to explore the important OERs (vertices) given student X  X  implicit and explicit information needs (topic and paper seed vertices). For example, we can assume that when a student is reading a paper, she can be interested in finding OERs relevant to the paper, specific sen-tences in the paper, the paper X  X  topics, or weekly teaching topics. From an information need perspective, for link-based recommen-dations, student information need is characterized by some seed vertices on the heterogeneous networks, i.e. the paper or topics that the student is currently reading, and supervised random walk algorithms can be used to recommend candidate OERs.

Evaluation result shows that, first, auto-recommended OERs can provide important and useful information to help students better un-derstand the content of the scientific publications, i.e., MRR (mean reciprocal rank) score is 0.8609 (students find the useful OERs in the 1st or 2nd position in the result ranking list). This assumption is also confirmed in the exit survey, where 78.42% of participants believe the OCPR system along with recommended OERs can pro-vide precise and useful information they need, while 78.43% of them believe the recommended OERs are close to exactly what they need. From system perspective, 80.39% of participates believe the OCPR system and real-time OER recommendation function is easy to use. Second, based on the students X  judgments, we found all the OER recommendation can be potentially useful, and the learning to rank method can be quite useful to enhance the recommenda-tion performance. As Table 5 shows, learning to rank and cold start methods significantly ( p &lt; 0 . 0001 ) outperform other methods.
The contribution of this paper is fourfold. First, we propose a novel auto-scaffolding method to help students better understand the scientific readings in a course environment by leveraging vari-ous kinds of OERs. Second, a new system, OCPR, is employed to capture student reading behavior while enabling them to ask ques-tions or highlight the confusing part of the readings. Third, novel algorithms are proposed to characterize students X  information need and recommend OERs to them while reading a paper. Last but not least, an experiment (with 51 participates) is employed to validate the usefulness of the system and to evaluate the OER recommen-dation algorithms.
Scaffolding is defined as a  X  X rocess that enables a child or novice to solve a problem, carry out a task, or achieve a goal which would be beyond his unassisted efforts X  [25]. Since 1976, the term scaf-folding has been widely used in educational research [14], and the scaffolding construct is being applied more broadly [16]. In particular, the concept of scaffolding is applied to the studies of computer-assisted learning environments, i.e. computer-mediated scaffolding [16]. Naturally, the focus of scaffolding research is on system design and usage. One of the most recent efforts is to uti-lize existing social tagging and annotation tools. Social tagging and annotation have produced positive results in a number of tasks, including promoting student learning [6, 18, 24]. For example, stu-dents were found to have positive perceptions of usefulness, ease of use, learning satisfaction, and willingness for future use towards the Personalized Annotation Management Software (PAMS) 2.0 sys-tem [18]. In Johnson X  X  et al. study [6], students achieved better reading comprehension and metacognitive skills when using a so-cial annotation approach within the context of small team collab-oration. Such tools have the advantage of allowing users to high-light learning materials in context, comment on part of a document, share ideas, and provide feedback among a group of users.
However, prior studies also found those scaffolding approaches, by leveraging social tagging or annotation, can be quite limited [13], and students cannot essentially benefit from such systems when reading a challenging text. Not until recently did researchers begin to focus on the usefulness of OER. For instance, Dennis, et al. [4] found that an additional link to video presentation had significantly positive impacts on students X  learning based on quiz scores. More recently, Liu [8, 9] found OERs, like YouTube video, dataset, and Wikipedia page, can assist students better understand the scientific readings. Meanwhile, he found information retrieval methods, i.e., language model and BM25, can help to build OER index for a large number of publications automatically. However, this research can-not address students X  emerging information need while reading a paper. For instance, existing method cannot help students to under-stand a specific sentence or paragraph. Meanwhile, existing meth-ods generate a large number of noisy OERs [8]. For instance, Liu found a large number of YouTube videos do not have high quality text descriptions, and methods based on text similarity may be not accurate.

For this study, we use text retrieval and heterogeneous graph mining plus random walk [21] to recommend OERs while filtering our the noisy data. Similar approaches have been used to recom-mend YouTube video. For instance, Baluja et al., [2] used user-video graph plus random walk to provide personalized video sug-gestions for users. A heterogeneous network is defined as a di-rected graph G = ( V , E ) with an object type mapping function  X  : V  X  A and a link type mapping function  X  : E  X  R , where each object v  X  X  belongs to one particular object type  X  ( v )  X  X  , each link e  X  E belongs to a particular relation  X  ( e )  X  R , and if two links belong to the same relation type, the two links share the same starting object type as well as the ending object type. The network schema, denoted as T G = ( A , R ) , is a meta template for the heterogeneous network G = ( V , E ) with the object type map-ping  X  : V  X  A and the link mapping  X  : E  X  R , which is a directed graph defined over object types A , with edges as relations from R [11].

The concept of meta-path was first proposed in [21], which can systematically capture the semantic relationships between objects in a heterogeneous information network scenario. A meta-path P is a path defined on the graph of network schema T G = ( A , R ) , and is denoted in the form of  X  A 1 R 1  X  X  X   X  A 2 R 2  X  X  X  ... defines a composite relation R = R 1  X  R 2  X  ...  X  R l types  X  A 1 and  X  A l +1 , where  X  denotes the composition operator on relations. Different meta-path-based mining tasks are studied, in-cluding similarity search [21], relationship prediction [19,20], user-guided clustering [22], and recommendation [11, 26, 27]. It turns out that meta-path serves as a very critical feature extraction tool for most of the mining tasks in a heterogeneous information net-work. In this paper, we also employed the supervised random walk methods which have been investigated in [7, 11] and prior studies show that the supervised random walk can significantly enhance the classical unsupervised graph mining methods.
In this section we discuss the research method in detail which includes: to collect different kinds of candidate OERs for scientific publications (3.1), to design OCPR system (3.2), and to design the text-and graph-based OER recommendation algorithms (3.3).
In order to recommend high-quality OERs to help students better understand scientific readings, we need to index different kinds of OERs. In this study, we collect four kinds of OERs, presentation video, slides, source code, and Wikipedia pages. For OER collec-tion, the most straightforward method is to search for the paper ti-tle (exact match) in different search engines. However, this method has two major limitations. First, given a relatively long publica-tion title, if we use exact string match, search engines can hardly find any results. On average, based on our experiment with some random sampled publications, only 0.35 resources were retrieved (for each testing publication). We also found that the quality of resources was not good. A large portion consisted of publisher or digital library access pages for the target publication, which are not helpful for scholars and students to understand the paper. Sec-ond, the computational cost of this method is quite high. Given the very large potential publication collection, we needed to send mul-tiple queries for each publication. However, most search engines, i.e., Google and YouTube, restrict the number of automated visits, which makes this method inefficient.

In this research, we used a more economical method to cope with this problem. We assumed each publication was composed of a list of topics with each topic represented by an author-assigned keyword. For each resource type, we first aggregated all resources retrieved using the publication keywords (topics) and then used a ranking algorithm to identify the most important resources based on publication content. By using this method, we can significantly reduce the amount of queries sent to different search engines. For instance, take ACM DL corpus as an example, for 41,378 publi-cations, we only need to collect OERs for 9,263 popular author assigned keywords (appear at least 5 times in the corpus). Such resources are highly likely to be relevant to the publication content and could help students or scholars understand the essence of the publication. For this method, we assumed that helping scholars or students understand the topics (keywords) of the paper will eventu-ally help them to understand the paper itself.

In order to effectively generate OERs for each topic, we use meta-search approaches where a Boolean query was sent to one or more search engines for each scientific keyword and OER type. The detailed query list for each resource type is listed in the Table 1. The first column is the OER type. The target query for each type was sent to one or more search engines or web services. For exam-ple, in order to get the slides OERs for a topic (keyword), the query  X  X Keyword] AND (filetype:ppt OR slides) X  (column 3) was sent to Google (column 2), where [Keyword] was replaced with the tar-get keyword content. Similarly, for video OERs, the query  X  X Key-word] X  was sent to YouTube, TED, and Videolecture. For slides and source code, different queries were sent to different search en-gines. For performance reasons, we indexed the Wikipedia page dump (2014 May) locally.

In this experiment, we used the top 15 retrieved results from each search engine to aggregate the final result collection for each re-source category. Each retrieved result is a triple of title, URL, and snippet, and we use the result URL to download the HTML page content. We then used a list of pre-defined rules (regular expres-sions) to identify the key content on the HTML page. For example, for each YouTube or Videolecture video, we extract the video de-scription and tags to represent the content of the video. However, if the pre-defined rules don X  X  work for a specific page, we just use the HTML (after removing HTML tags and script code) as the content of the target resource.

In most cases, the result collection was a combination of infor-mative resources and noisy results. Experience in information re-trieval reveals that since different search engines return very diverse and erratic results for the same or similar query, irrelevant data may pollute the search results and mislead users. To address this prob-lem, we used an information retrieval ranking algorithm, language model 2 [15, 28], to prioritize those informative resources for the target scientific keywords while filtering out the irrelevant informa-tion. In other words, we want to use ranking fusion to find out the most important resources from multiple ranking lists. Because the OERs will be used to help scholars and students better understand the essence of the readings, most retrieval resources (low ranked), at this stage, will be filtered out. We also use the paper abstract as query to search the OER content to find the candidate OERs for a publication. So, for each keyword K i , we will index top m OERs with similarity score S ( K i ,R j ) = P LM ( K i P
LM ( K i | R j ) is the language model ranking score for keyword probability given a OER, R j , content. Similarly, we also index the publication-OER similarity score, P LM ( P i | R j ) ( P represented by title and abstract content). So, for topic, K index triples { K i ,R j ,P LM ( K i | R j ) } , and for paper, P triples { P i ,R j ,P LM ( P i | R j ) } .

The performance of this method is highly dependent on the qual-ity of the OER text description. However, different kinds of OERs have varying text quality. Wikipedia pages (extracted from Wikipedia dump) have very high text quality, but a large number of YouTube/ Videolecture videos and Google/Slideshare slides do not associate with high quality text description. Consequently, a text search may generate some noisy OER data which may pollute the rec-ommendation results. In order to solve this problem, we will use heterogeneous graph mining method to recommend OERs to stu-dents (introduced in Section 3.3). The connections between OERs, then, can be important. For instance, Wikipedia pages are inter-linked via incoming/outgoing links, and each YouTube, Slideshare, Videolecture, TED, GitHub, and SourceForge OER has  X  X elated X  OERs. The related resources are provided by the target online ser-vice. While the algorithm behind that is a black box, most related resources come from 1. resource content similarity, 2. the owner-ship of these resources (i.e., if two resources uploaded by the same user), and 3. user co-visitation (or co-watched) probability [3].
In this paper, we use language model with Dirichlet smoothing for all the text match tasks.
 We index the relationships between OERs in a graph database, i.e., R
Note that, unlike other meta-search problems, the ranking lists of some OER types in this research were totally disjoint. For ex-ample, for videos, we sent queries to YouTube, TED, and Vide-olecture. Their indexes are almost disjoint (i.e. TED videos may not exist in YouTube video libraries), and some sophisticated meta-search ranking fusion algorithms are not appreciate, e.g., Borda X  X  method [1] and Markov chain methods [5].
To validate the new scaffolding hypothesis and help students bet-ter understand the scientific publications in a course environment, we design and implement the novel learning and reading system, OER-based Collaborative PDF Reader (OCPR). The new system has three main functionalities:
The first two functions focus on OER-based scaffolding, and the third one mainly addresses user incentive. For instance, students, when reading the paper, can find her colleagues X  interactions with the system (by clicking the question marks on the side of PDF read-ing), i.e., the questions or highlights with the target paper. Mean-while, students could discuss for an existing interaction by using OCPR. We will investigate the third function in the future study, and in this study, we focus on the first two.
 At the backend, the Collaborative PDF Reader has access to the OER index (created in last section), the list of assigned class read-ings, and the algorithm package, which guarantees efficient OER recommendations and different scaffolding methods.

OCPR is designed for course usage, and it can manage class readings and student information.By using the OCPR, the class in-structor can easily manage the class reading list by uploading the class syllabus (in a pre-defined format). In this syllabus, the in-structor needs to identify the weekly reading schedule and weekly teaching topic; he or she can then upload the readings for each week to the server. For instance, the following is an exemplar OCPR syl-labus snippet, which is corresponding a one week teaching sched-ule. The exemplar snippet has two topics (for teaching), and stu-dents will need to read two papers for this week. Based on the paper IDs, the system can locate the readings (in PDF format) from the database. Each reading in the database has title, abstract, full con-tent, associated topics, citation information, and associated OERs (described in the last section).
Additionally, the instructor can also upload the student roster to the system, which will automatically register each student while sending student email invitation to download the OCPR reading system. By logging into the reading system, students can access the class weekly readings and use the new scaffolding functions.
The main function of OCPR is OER based scaffolding, which captures evidence of students X  emerging implicit or explicit infor-mation needs when reading a scientific paper and recommends high quality OERs to address their information needs. As Figure 1 shows, by using OCPR, students could ask a specific question given a piece of text, which serves as evidence of an explicit information need, or highlight part of a text in the paper, as evidence of an implicit information need. In either case, the OCPR is able to capture the selected or input question and its reading context from a student in the PDF document. The evidence of students X  information needs will then be sent to the backend recommendation and ranking al-gorithms for information need characterization. For instance, as Figure 1 shows, user highlighted text is focusing on  X  X nsupervised topic modeling for citation analysis X  , and the paper content mainly addresses  X  X ynamic topic modeling and PageRank-based citation recommendation X  . The recommended Wikipedia pages (on the right) are focusing on those topics.

The algorithms presented in the next section recommend the op-timized OERs given the information need, which will be able to help students better understand the essence of the targeted reading. A student can also select the specific type of OERs in the  X  X ight click menu X , you may want use "context menu" instead, i.e., Mac is ctrl + click that he or she prefers and the system will capture and log the selected OERs. Meanwhile, students can also provide relevance and usefulness feedback for system recommended OERs. For instance, as Figure 1 shows, students can click  X  X ood X ,  X  X K X ,  X  X ad X  or  X  X ot Sure X  for each recommended OER given their in-formation need. The judgments and student click information will be saved as system logs, which will be important for OER rec-ommendation algorithms, i.e., training learning to rank model, and algorithm evaluation.

Unlike the common practice of accessing PDF documents lo-cally on one X  X  personal computer, OCPR gives students and their instructor cloud access on the server, i.e., everyone works on the same document. All users X  asynchronous interactions with the PDFs will be saved in a central database along with their user IDs, and the interactions -i.e., PDF highlighting, proposing questions, rec-ommending OERs, OER judgments to an existing information need -will be useful to characterize computational user information need and to train OER recommendation model.
As aforementioned, student X  X  emerging information needs while reading a paper can be very complex. For instance, when a student highlights a paragraph in a paper, it X  X  challenging to understand the reason and motivation. We employ multiple recommendation fea-tures to characterize students X  information need,  X ( f 1 (  X  ) ,f f (  X  )) , where each feature, f i , is a OER ranking function given input space  X  . We propose three OER ranking assumptions: 1) , straightforwardly, student X  information needs can be related to the OCPR interactions while reading, i.e., explicit questions and high-light content of the paper; 2) students X  information may be related to the target paper and paper X  X  associated topics; 3) in a course environment, student X  X  information need may address the weekly teaching schedule (in the syllabus). Because, even a single paper can cover multiple topics, the weekly topics from the course syl-labus can be important. Each assumption will be represented by a number of OER ranking features, and the input space  X  includes 1) user question or highlight text, 2) paper and paper X  X  topic, and 3) weekly topic. While we can hardly estimate the importance of each feature, in this paper, we use learning to rank to weight each of those,  X  L 2 R . The training data come from the OCPR collected OER relevance judgments. However, we also need to address the cold start problem. When training data is sparse, we assume in-formation need is a linear function,  X  cold , and the online features (assumption 1) should be more important than other offline ones.
From a performance viewpoint, the first assumption is based on online text ranking features. Since it cannot host any complex al-gorithms, we used text information retrieval algorithm to cope with this problem. The second and third assumptions are offline , and we can pre-index a number of OERs closely related to paper, paper X  X  topic and syllabus topics with higher computational cost. We use heterogeneous graph mining to implement it.

Figure 2 illustrates the graphical OER recommendation problem, where the OER recommendation is conceptualized as a random walk problem on a heterogeneous graph. Four kinds of vertices, paper, topic, weekly topic and OER, are interconnected by using different kinds of edges. More detailed information is depicted in Table 2.

The links and paths between the vertices can be important to enhance the OER recommendation performance. As section 3.1 shows, we use meta-search and crawler to index the OER by us-ing keyword search. However, this method generates noisy data which may pollute the recommendation results. For instance, given the keyword (topic),  X  X uestion Answering X  , the system may find a Wikipedia page or YouTube video  X  X uestion the Answers X  (con-tent relevant), which is a pop song. Simply using content match, this noisy resource may pollute the OER recommendation result. However, from a random walk viewpoint, via meta-path K  X  R ? , the OER, R ? , useful probability equals the random walk probability from the seed (query) topic K  X  to the candidate OER R ? (via all the related interim OERs). Given the earlier exam-ple, even though  X  X uestion the Answers X  is related to the keyword with text match, but, all its related resources are about the related music and artists (not related to the topic), and, then, the random walk probability from the seed topic to this noisy OER will be very low. Comparing with that, the correct Wikipedia page X  X  interlinked pages are more likely to be relevant to the target topic or paper, and the random walk probability (following this meta-path) can be high. Similarly, because a large number of YouTube videos or Slideshare slides do not associate with high quality textual descrip-tions, we cannot totally trust the video/slide-topic or video/slide-paper similarly, and the relationship between videos/slides can be important. For instance, if two YouTube videos X  co-watched prob-ability is high, they can be related [3], and this information may not totally depend on the video text description. For this experi-ment, we collected video, slide or source code relationships by us-ing YouTube, Videolecture, GitHub or Slideshare API. We find, in most cases, useful OER X  X  related OERs can be also relevant to the target topic/paper, and noisy video X  X  related ones are not likely to be relevant to the target keyword. Random walk can be important to filter those noisy OERs.

Explained it in another way, from the random walk perspective, user information needs are represented by different kinds of seed vertices (as input space  X  ), i.e., the paper/topic/weekly syllabus topic that student is reading with, on the graph, and different kinds of meta-paths can navigate the seeds vertices to the target OER ver-tices, instead of the noisy OER vertices. On the navigation tour, text or topical relevance is characterized as the transitioning probability between vertices, while the physical links, i.e., OER relationship and citation links, can be important to calculate the random walk probabilities.
 Table 2: Vertices and edges in the constructed heterogeneous graph
For any vertex on the graph, the sum of the same type of outgoing links equals 1. For instance, The weight of P i h  X  K j is the nor-malized LLDA (Labeled LDA) [17] probability of topic K j given the content of P i , P ( Z K j | P i ) , and K j is the keyword provided by the author of the paper P i , and the topic probability is generated by the paper title plus abstract content. All the similarity edges are calculated by using language model with Dirichlet smoothing [28]. Similarly, we also generate the edges K co  X  K and K cite connect keyword pair via co-occur and citation probability. Weekly topic, W , is a special kind of topic, and all the readings from that week connected to the target topic(s), P a  X  W .

The weight of K cont  X  P is the normalized topic authority score, which characterize the importance (or contribution) of each paper. Note that topic j is contributed by paper i ( K j cont  X  P essarily mean paper i is relevant to topic j ( P i r  X  K j ple, some  X  X atural language processing X  papers can contribute to, but not related to,  X  X nformation retrieval X  topic, which is similar to the OER links, i.e., Wikipedia page  X  X atural language processing X  is linked to  X  X nformation retrieval X  and  X  X uestion answering X  . As a result, the contribution link may be able to help to find the cor-rect OER. In order to estimate the contribution of each paper to a topic, we calculated the paper importance given a topic K by us-ing a PageRank with Prior algorithm [23]. The normalized topical PageRank authority score is used for the weights of K cont this step, we used homogeneous graphs where, on each graph, the vertex is a paper and each vertex is also characterized by a topic prior vector, i.e., on the paper graph, the paper topical prior distri-bution is P ( Z K i | paper ) . The result of PageRank (with prior) is the paper topic authority vector, Authority ( paper i | Z of K j cont  X  P i ). This link can help students to investigate the background or foundation of a topic. For instance, the feature K  X  cont  X  P s  X  R r  X  R ? explores the publications make essential contribution to topic K  X  , and the OERs related to those publica-tions can be helpful to assist students understand the target topic.
All the meta-path based OER ranking features are listed in Ta-ble 3. Each feature start from a kind of seed vertex(s)  X   X  , and the R ? is the candidate OER. The first 4 features are online or semi-online ranking, which is based on the student input highlight text or question content, also  X   X  . For performance reason, we cannot use LLDA to infer the topic of input text. Instead, greedy match is employed to extract the keyword information from the input string, i.e., H m  X  K or Q m  X  K . For example, if  X  X usic information retrieval X  existed in the user question, we won X  X  use the keyword  X  X nformation retrieval X  as the interim topic K in the meta-path.
We use meta-path plus random walk from the seed vertices to candidate OER, the random walk probability can be estimated by: where t is a tour from v (1) i to v ( l +1) j following the meta-path, and RW ( t ) is the simulated random walk probability of the tour t . is then,
For example, given meta-path K  X  s  X  R ? , the relevance score from K k  X  to R r ? can be calculated by w ( K k  X  s  X  R r w ( K k  X  s  X  R r ? ) is the weight of edge which is the similarity of K k between R r ? .

The total ranking score from a set of starting vertices to a candi-date OER vertex can be defined as:
We can also consider two or multiple parallel meta-paths leading to the same type of query nodes, for example,  X  A 1 R 1  X  X  X   X  A l +1 = A 0 t +1 . In this case, we can define similarity from different sets of objects to a result node from different meta-paths:
For instance, K  X  cont  X  P s  X  R r  X  R ? s  X  K  X  is a combined re-stricted meta-path, which combines two meta-paths: K  X  cont  X  R ? and K  X  s  X  R ? . So, based on the above formula, the rank-ing score of candidate OER, R ? , is the combination of two random walk scores for both sub-meta-paths. Theoretically, we need to tune parameter  X  for each meta-path to optimize the weight of each sub-meta-path. For this study, because of the sparseness of the training data, we set  X  = 0 . 5 . More sophisticated parameter tuning will be addressed in future work.

Based on text mining methods and meta-path based methods, we proposed 21 ranking features for OER recommendation. All the features investigated in this study are listed in table 3. Please note that, we doesn X  X  consider the edge direction, as long as the two ver-tices are connected, the meta-path can be created. There are three types of features: online feature, semi-online feature, offline fea-ture. Online features can only be calculated online, offline features are pre-calculated, while semi-online features combine online cal-culation and offline calculation results.

After we calculate all the ranking features, we need to integrate them as a OER recommendation mode,  X ( f 1 (  X  ) ,f 2 (  X  ) ...f In this study, we use two methods. First, without user judgments, we generate  X  cold ( f 1 (  X  ) ,f 2 (  X  ) ...f k (  X  )) based on a low-cost lin-ear function (cold start). We assume the online or semi-online fea-tures (No. 1-4), based on user OCPR interactions, are more im-portant then offline features. So, the online features X  weights are 3 times higher than the offline features.

When OER usefulness judgments are available (collected by OCPR system), we use learning to rank to statistically combine differ-ent ranking features,  X  L 2 R ( f 1 (  X  ) ,f 2 (  X  ) ...f manual parameter tuning. As this study is not focusing on learn-ing to rank, we used a relative simple algorithm, Coordinate As-cent [12], which iteratively optimizes a multivariate objective rank-ing function, for OER ranking feature integration and algorithm evaluation.
In this section, we describe the experimental setting, results and exit survey.
We tested this reading system and the associated OER ranking algorithms in a real learning environment. A graduate-level infor-mation retrieval course at Indiana University is used for this ex-periment. 51 students (masters and PhDs) voluntarily participated this experiment (33 male and 18 female), and they were required to use the OCPR system for 8 weeks (with 8 required readings) They could use OCPR functions to get access to the system rec-ommended OERs. Meanwhile, we asked each participant to pro-vide OER relevance judgments for the top 5 system-recommended OERs (they can rate more). There are totally valid 5,132 judgments we collected (for 1,051 student requests). We use those judgments to train the learning to rank model and to evaluate the algorithm per-formance. For all the requests, there are 77 explicit questions from students (each question is also associated with a piece of highlight
The dataset can be download in the project website http://scholarwiki.indiana.edu/OCPR text). On average, each paper got 9.36 questions, and the average character length for a question is 42.25 (with highlight character length 64.08). Based on students X  feedback, averagely, they use the system about 3 hours per week when reading the paper.

At the backend of OCPR, we created a heterogeneous graph for OER recommendation. As aforementioned, there are 4 kinds of vertices and 10 kinds of relations in this heterogeneous graph, for paper vertices, we used 41,370 publications from 1,553 venues (mainly from the ACM digital library). The paper vertices are con-nected to 9,263 keyword labeled topics. For this course, based on course syllabus, there are a total of 34 weekly topics. By using meta-search, we collected a total of 1,112,718 OERs. More de-tailed information can be found in Table 4. Note that even though we only used a small number of readings in this experiment, the keyword co-occur, keyword-paper contribution, and citation rela-tionships on the large graph will help to enhance the OER recom-mendation performance. Theoretical, user could use OCPR to read any paper in this collection.

For all the OER judgments, participants rated 21.63% of the rec-ommended OERs as  X  X ood X  , 29.36% as  X  X K X  , 40.10% as  X  X ad X  and 8.9% as  X  X ot Sure X  . For this experiment, we use the cold start solution to recommend OERs to students. From an NDCG viewpoint, we score Good = 2 ,OK = 1 , and Bad = 0 . The OER recommendation performance can be found in Table 5. As the OER recommendation is more like a QA problem, and students are more interested to find the first useful resource, we use MRR as the indicator to train the learning to rank model. For evaluation, 10-folder cross-validation was used.

The ranking feature 3, 14, and 17 are the most important fea-tures (highest feature weights in Coordinate Ascent model). Rank-ing feature 14 and ranking feature 17 were offline feature. Feature 14 ( K  X  cite  X  K s  X  R r  X  R ? s  X  K  X  ) carried the keyword ci-tation, keyword-OER similarity, keyword-OER related and OER-p &lt; 0.001, *** p &lt; 0.0001 ) OER related information. Similarly, feature 17 ( K  X  cont  X  R ? s  X  K  X  ) carries keyword-paper contribution, paper-OER similarity, keyword-OER similarity and OER-OER related infor-mation, in which, the keyword-paper contribution information is also calculated from citation information and key-paper related in-formation (via LLDA). Question-OER (feature 3) is an online fea-ture, and this indicates the question content from the student can improve the recommendation performance. From a performance viewpoint, evaluation results show that, first, auto-recommended OERs can provide important and useful information to help stu-dents better understand the content of the scientific publications, i.e., both learning to rank and cold start methods X  MRR (Good) score is higher than 0.8 (which means students are finding the use-ful OERs in the 1st or 2nd position in the result ranking list). In this table, MRR (OK) investigated the multiplicative inverse of the rank of the first OER user rated "OK" , and MRR (Good) used first user rated  X  X ood X  OER in the ranking list. This finding is also con-firmed in the exit survey where 78.42% of participants believe the OCPR system along with recommended OERs can provide precise and useful information.

Second, based on the student judgments, we found that a number of OER recommendation features, including online and offline, can be potentially useful, and the learning to rank method can be useful to enhance the recommendation performance comparing with cold start model ( p &lt; 0 . 01 ). When training instances are sparse or not available, manual parameter setup (cold start) can be a effective so-lution. Cold start significantly outperforms other ranking features ( p &lt; 0 . 0001 ), except for MRR(Good) ( p = 0 . 014 ). From a rank-ing perspective, both MAP and NDCG proved that the cold start solution and learning to rank can be efficient for OER recommen-dation. Third, we find that different kinds of seed vertices can be useful. Weekly topic, W  X  , is especially useful. For instance, fea-tures 18-21 performed well in this experiment, which means class teaching schedule can be important in helping the system better understand student information needs. The evaluation results prove that cold start solution and learning to rank significantly outperform the classic text-based or graph-based approachs.

From performance viewpoint, as the online or semi-online fea-tures are implemented via language model and greedy match and the offline features are pre-computed, the system performance is acceptable. In most cases, after students highlight text or ask a question, system can give students OER results within 5 seconds.
From a usability perspective, we used an exit survey to investi-gate the usefulness of the new reading environment and the effec-tiveness of the new OER-based scaffolding method. In the survey, we asked 13 questions for each participate. More detailed informa-tion can be found in the project website 4 . Based on students X  feed-back, 78.42% of participants believe the OCPR system along with recommended OERs can provide precise and useful information, while 78.43% believe the recommended OERs are close to what they need when reading the target paper. From a system perspec-tive, 80.39% of participates believe the OCPR (prototype) system, i.e., highlight and ask question function, is easy to use.
Meanwhile, based on students X  feedback, we found Wikipedia page and video presentation (or video lecture) are more helpful for them to understand the publication, compared with slides and source code. In this experiment, very few students actually read the source code to understand the paper content. Overall, 49.02% of students found the system can effectively help them better un-derstand the target publication, while 33.33% found the system and OERs somewhat helpful. Only 1.96% of the participants described the recommended OERs as useless.
In this study, we propose a novel task to assist students to better understand scientific publications by leveraging high-quality OERs. By using the OCPR system, a number of reading behaviors are cap-tured to characterize students X  information needs. Text and graph mining algorithms are used as ranking features to recommend high-
Project URL is http://scholarwiki.indiana.edu/OCPR quality OERs. Experiment results show that both text mining and graph mining algorithms can potentially contribute to the OER rec-ommendation. Meanwhile, different seed vertices on the heteroge-neous graph, i.e., paper, topic, weekly topic, highlights, and ques-tions, are important to characterize student information need. Learn-ing to rank is efficient to integrate different OER ranking features, when training data is available. However, when training data is sparse or unavailable, human generated ranking rules can be useful to cope with the cold start problem. We also find heterogeneous graph mining can be useful to solve this proposed problem. When OER text quality is not high (e.g. some YouTube videos have low quality descriptions), relations between the OERs become very im-portant to filter out the noisy resources. For instance, we find the relations between OERs and keyword relations are useful to en-hance the OER recommendation performance which is difficult for classical text mining methods.

From statistical analysis of student survey responses, we found only a handful of them like to propose an explicit question when us-ing the OCPR system: only 77 questions out of the 1,051 requests are found to be explicit, although proposing explicit questions can help them locate the useful OERs. Instead, most students prefer to highlight some text and ask for system help. Evaluation shows that highlighted text provides important information to find the correct OER (features 1 and 2). However, noisy OER can pollute the qual-ity of the recommendation result. In this case, graph mining meth-ods help to enhance the OER ranking accuracy as well as filtering out the noisy OERs. For instance, features 13, 18, 20, and 21 based on paper topic or weekly topic achieve good recommendation and ranking performance.
 One major limitation of this study is the lack of personalization. Intuitively, different students may have different kinds of informa-tion needs even though they pose the same question or select the same part of a text in a paper. For example, given the same piece of text in a target paper that students want to understand, some stu-dents may prefer to watch a video, while others may want to read a Wikipedia page or access the source code of the scaffolding. In or-der to tailor the recommendation results for each student, we need to generate a computational profile for each of them. However, we will also need to address the challenge of data spareness problem for personalization model training.

We also hope to have a chance to use the user comment func-tion to enhance the OER ranking and scaffolding performance in the future. Supported by OCPR, other students (classmates) and in-structors can actively contribute to the auto-learning process by rec-ommending, changing, annotating, or removing certain resources given an information need. Users can easily click the question marks on the side of PDF reading for viewing or commenting on their colleagues X  interactions with the system, which provide im-portant incentives for using the OER-scaffolding functions. In the future, we will enhance the OER recommendation by using this function and motivate students participation.

Finally, this system can serve other purposes in addition to stu-dent learning. For instance, by using OCPR, a system can help journal readers better understand the scientific content within the articles. Different experiments and ranking features need to be de-signed to achieve this goal. [1] Javed A Aslam and Mark Montague. Models for metasearch. [2] Shumeet Baluja, Rohan Seth, D Sivakumar, Yushi Jing, Jay [3] James Davidson, Benjamin Liebald, Junning Liu, Palash [4] Alan R Dennis, Kelly O McNamara, Stacy Morrone, and [5] Cynthia Dwork, Ravi Kumar, Moni Naor, and Dandapani [6] Tristan E Johnson, Thomas N Archibald, and Gershon [7] Ni Lao and William W Cohen. Relational retrieval using a [8] Xiaozhong Liu. Generating metadata for cyberlearning [9] Xiaozhong Liu and Han Jia. Answering academic questions [10] Xiaozhong Liu and Jian Qin. An interactive metadata model [11] Xiaozhong Liu, Yingying Yu, Chun Guo, and Yizhou Sun. [12] Donald Metzler and W Bruce Croft. Linear feature-based [13] Elena Novak, Rim Razzouk, and Tristan E Johnson. The [14] Roy D Pea. The social and technological dimensions of [15] Jay M Ponte and W Bruce Croft. A language modeling [16] Sadhana Puntambekar and Roland Hubscher. Tools for [17] Daniel Ramage, David Hall, Ramesh Nallapati, and [18] Addison Su, Stephen JH Yang, Wu-Yuin Hwang, and Jia [19] Y. Sun, R. Barber, M. Gupta, C. Aggarwal, and J. Han. [20] Y. Sun, J. Han, C. C. Aggarwal, and N. Chawla. When will it [21] Y. Sun, J. Han, X. Yan, P. S. Yu, and T. Wu. PathSim: Meta [22] Y. Sun, B. Norick, J. Han, X. Yan, P. S. Yu, and X. Yu. [23] Scott White and Padhraic Smyth. Algorithms for estimating [24] Joanna Wolfe. Annotations and the collaborative digital [25] David Wood, Jerome S Bruner, and Gail Ross. The role of [26] X. Yu, X. Ren, Y. Sun, B. Sturt, U. Khandelwal, Q. Gu, [27] Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley [28] Chengxiang Zhai and John Lafferty. A study of smoothing
