
A heterogeneous information network is an information network composed of multiple types of objects. Cluster-ing on such a network may lead to better understanding of both hidden structures of the network and the individual role played by every object in each cluster. However, although clustering on homogeneous networks has been studied over decades, clustering on heterogeneous networks has not been addressed until recently.

A recent study proposed a new algorithm, RankClus, for clustering on bi-typed heterogeneous networks. However, a real-world network may consist of more than two types, and the interactions among multi-typed objects play a key role at disclosing the rich semantics that a network carries. In this paper, we study clustering of multi-typed heteroge-neousnetworkswitha star network schema and propose a novel algorithm, NetClus, that utilizes links across multi-typed objects to generate high-quality net-clusters. An it-erative enhancement method is developed that leads to ef-fective ranking-based clustering in such heterogeneous net-works. Our experiments on DBLP data show that NetClus generates more accurate clustering results than the baseline topic model algorithm PLSA and the recently proposed al-gorithm, RankClus. Further, NetClus generates informative clusters, presenting good ranking and cluster membership information for each attribute object in each net-cluster. H.2.8 [ Information Systems Applications ]: Database Applications X  Data Mining
The work was supported in part by the U.S. National Sci-ence Foundation grants IIS-08-42769 and BDI-05-15813, Of-fice of Naval Research (ONR) grant N00014-08-1-0565, and the Air Force Office of Scientific Research MURI award FA9550-08-1-0265. Any opinions, findings, and conclusions expressed here are those of the authors and do not necessar-ily reflect the views of the funding agencies.
 Algorithms heterogeneous information network, clustering
Information networks, containing a large number of indi-vidual agents or components interacting with each other, are ubiquitous in many applications, e.g. , the Internet that con-sists of a gigantic network of webpages, co-author networks and citation networks extracted from bibliographic data, user networks extracted from email systems, and friendship network extracted from web sites like Facebook 1 and Mys-pace 2 . Clustering on an information network based on links between objects may give us a grand view of the huge net-work. For example, communities can be detected by cluster-ing on co-author network [11]. Most current studies [20, 17, 19, 21] on information network are on homogeneous net-works , i.e. , networks consisting of single type of objects, as shown above. However, in reality, objects could be of mul-tiple types, forming a heterogeneous network .Arecent algorithm RankClus [16] deals with bi-typed heterogeneous networks. Unfortunately, in reality there often exists more than two types of interacting objects in a network. Among them, networks with star network schema (called star network) such as bibliographic network centered with pa-pers and tagging network ( e.g. , http://delicious.com) cen-tered with a tagging event are popular and important. In fact, any n -nary relation set such as records in a relational database can be mapped into a star network, with each re-lation as the center object and all attribute entities linking to it.
 Example 1.1 (Bibliographic Information Network) A bibliographic network consists of rich information about research papers , each written by a group of authors , using asetof terms ,and published in a venue (a conference or a journal). Such a bibliographic network is composed of four types of objects: authors, venues, terms ,and papers . Links exist between papers and authors by the relation of  X  X rite X  and  X  X ritten by X , between papers and terms by the relation of  X  X ontain X  and  X  X ontained in X , between papers and venues by the relation of  X  X ublish X  and  X  X ublished by X . The topological structure of a bibliographic network is shown in the left part of Figure 1, which forms a star network schema , http://www.facebook.com/ http://www.myspace.com/ where paper is a center type and all other types of objects are linked via papers.
 Figure 1: Clustering on A Bibliographic Network
One possible way to cluster a heterogeneous network is to first extract from it a set of homogeneous networks and then apply traditional graph clustering algorithms. How-ever, such an extraction is an information reduction pro-cess: some valuable information, e.g. , paper title or venue published in, is lost in an extracted co-author network. Fur-ther, although clustering co-author network may discover author communities, a research network contains not only authors, but also venues, terms, and papers. It is impor-tant to preserve such information by directly clustering on heterogeneous networks, which may lead to generating sub-network clusters carrying rich information. This motivates us to develop NetClus , a method that discovers net-clusters , i.e. , a set of sub-network clusters induced from the original heterogeneous network (Figure 1).

The second weakness of current clustering algorithms is that they do not consider the importance of each object in the network and merely output the cluster label for each object. As a result, clusters are difficult to understand, es-pecially when the size of clusters are large. NetClus not only discovers net-clusters but also gives ranking distribution for each type of objects in each cluster, which makes the cluster so discovered quite meaningful, as shown in the following example.
 Example 1.2. (Net-cluster of Database Area) Aclus-ter of the database area consists of a set of database authors, conferences, terms, and papers, and can be obtained by Net-Clus on the bibliographic network extracted from DBLP dataset 3 . NetClus also presents rank scores for authors, conferences, and terms in its own type. With ranking dis-tribution, users can easily grab the important objects in the area. Table 1 shows the top ranked conferences, authors and terms in the area  X  database  X , generated from a 20-conf. dataset ( i.e. , a  X  X our-area X  dataset) (see details in Sec. 5) using NetClus.

Based on the above discussion, in this paper we study the problem of clustering heterogeneous information networks with star network schema and develop a novel clustering algorithm, called NetClus, with the following contributions. 1. A new kind of cluster, net-cluster , is proposed for het-erogeneous information networks comprised of multiple types of objects. In each cluster, statistical information such as the ranking distribution and membership prob-http://www.informatik.uni-trier.de/  X  ley/db/ ability for each object are derived to facilitate users to navigate in the cluster. 2. An effective and efficient algorithm, NetClus, is proposed, that detects net-clusters in a star network with arbitrary number of types, builds ranking-based generative model for each net-cluster and adjusts the membership of target objects according to their posterior probabilities in each net-cluster. 3. Our algorithm is applied to the network extracted from the DBLP dataset, which shows our algorithm can give quite reasonable clustering and ranking results. The clus-tering accuracy is much higher than the baseline meth-ods.

The rest of paper is organized as follows. Section 2 is an introduction to related work. In Section 3, we formally intro-duce several concepts related to heterogeneous networks and the clustering problem. In Section 4, we systematically de-velop the NetClus algorithm. Section 5 is experiment study and Section 6 concludes this study.
Clustering on networks and graphs has been widely stud-ied in recent years. Clustering on graphs, often called graph partition, aims at partitioning a given graph into a set of subgraphs based on different criteria, such as minimum cut, min-max cut [4] and normalized cut [14]. Spectral cluster-ing [18] provides an efficient method to get graph partitions which is in fact an NP-hard problem. Rather than inves-tigate the global structure like spectral clustering, several density-based methods [19, 21] are proposed to find clusters in networks which utilizes some neighborhood information for each object. These methods are all based on the as-sumption that the network is homogeneous and the adjacent matrix of the network is already defined.

SimRank [7] is able to calculate pairwise similarity be-tween objects by links of a given network, which could deal with heterogenous network, such as bipartite network. How-ever, when the structure of network becomes more complex such as network with star network schema, SimRank can-not give reasonable similarity measures between objects any more. Also, high time complexity is another issue of Sim-Rank, which prevents it from being applied to large scale networks.

An algorithm called RankClus [16] is newly proposed, which uses a ranking-clustering mutually enhancement method-ology to cluster one type of objects in the heterogeneous net-work. Although the algorithm is efficient comparing to other algorithms that need to calculate pairwise similarity, there are some weaknesses for RankClus: (1) it has not demon-strated the ability to clustering on networks with arbitrary number of types; and (2) the clusters generated by RankClus only contain one type of objects. In contrast, our algorithm can generate net-clusters comprised of objects from multiple types, given any star network.

Other related studies include topic model, such as PLSA [6], which purely uses text information and does not con-sider link information. Some works such as author-topic model [15] utilizes additional information other than text by designing complex generative models that include addi-tional types of objects. Other works such as [10] intend to optimize a combined objective function with both text and graph constraints. All of these studies are extensions to existing topic model framework, and treat text especially important. In our algorithm, we treat text information just as one common type of objects.

Recently, a different view of clustering on heterogeneous networks [9, 1, 2] appears, which aims at clustering objects from different types simultaneously. Given different cluster number needed for each type of objects, clusters for each type are generated by maximizing some objective function. In this paper, net-cluster follows the original network topol-ogy and resembles a community that is comprised of multiple types of objects.
In this section, we define the problem of clustering in het-erogeneous information networks and introduce several re-lated concepts and necessary notations.

Definition 1. Information Network. Given a set of ob-jects from T types X = { X t } T t =1 ,where X t is a set of objects belonging to t th type, a weighted graph G = V, E, W is called an information network on objects X ,if V = X , E is a binary relation on V ,and W : E  X  R + is a weight mapping from an edge e  X  E toarealnumber w  X  R + . Specially, we call such an information network heterogeneous network when T  X  2; and homogeneous network when T =1.

For convenience, we use X t to denote both the set of ob-jects belonging to the t th type,andthetypename. Inthe following sections, we will use W x i x j to denote the weight of an edge x i ,x j in E . V ( G ), E ( G )and W ( G ) will be de-noted as V , E and W of G , if they are not explicitly given.
Definition 2. Star Network Schema. An information network G = V, E, W on T +1 types of objects X = {
X t } T t =0 is called with star network schema ,if  X  e = x E, x i  X  X 0  X  x j  X  X t ( t = 0), or vise versa. G is then called a star network .Type X 0 is called the center type . X 0 is also called the target type and X t ( t = 0) are called attribute types .

In Example 1.1, paper is the center type in the network and other types of objects only have links to the center type. Many information networks in real applications fall into the class with star network schema. For example, we can build network for tagging website 4 ,where tagging event is the cen-ter type, user, webpage, and tag are linked to tagging events. What X  X  more, each tuple in a database table could be viewed as a center type and each entity attribute in the relation could be viewed as remaining types of objects. Actually, a center object stands for a co-occurrence of different objects, which is able to catch multi-relation instead of binary rela-tion among different objects. In this paper, our algorithm is designed on networks with such topology. e.g. , http://www.delicious.com/
During clustering, center type objects are the objects first be clustered at each iteration, and links to other types of objects are used to help clustering center objects. That is why they are called target type and attribute types.
Definition 3. Net-cluster. Given a network G ,anet-cluster C is defined as C = G ,p C ,where G is a sub-network of G , i.e. , V ( G )  X  V ( G ), E ( G )  X  E ( G ), and  X  e = x i ,x j  X  E ( G ) ,W ( G ) x i x j = W ( G ) x i x j p
C : V ( G )  X  [0 , 1] is defined on V ( G ), for all x  X  V ( G ), 0  X  p C ( x )  X  1, which denotes the probability that x belongs to cluster C , i.e. , P ( x  X  C ).
 Forconvenience,weuse V ( C ) to denote the object set V ( G )innetwork G and E ( C ) to denote the edge set E ( G ). Also, for x/  X  V ( G ), we define p C ( x ) = 0. In this definition we adopt the idea of soft clustering, which means for each object x  X  V ( C ), it can belong to several clusters with some probability p C k ( x ) ,k =1 ,...,K and K k =1 p C k ( x )=1. Though actually, for target objects x we restrict p C ( x )as either 0 or 1, and they can belong to merely one cluster. In fact, a net-cluster is a sub-network integrating statisti-cal information for objects. For each net-cluster resembling communities in real world, we argue that it has much simpler structure and can be modeled as a ranking-based generative model. Therefore, every net-cluster is corresponding to a generative model, according to which generative probabili-ties of every target object in each cluster can be calculated.
Now, we can formalize our clustering problem as: given a heterogeneous information network G , and cluster number K , find K net-clusters C 1 ,C 2 ,...,C K ,where K k =1 V ( C V ( G ) , K k =1 E ( C k )= E ( G ), and  X  x  X  V ( G ) , K 1, such that target objects within each cluster are nearest to the cluster center under the new K dimensional measure space defined by posterior probabilities.
In this section, we introduce an efficient and effective algo-rithm, NetClus, which is a ranking-based iterative method. The major difficulty that lies in clustering in heterogeneous information network is the definition and calculation of sim-ilarity between each pair of objects. The general idea of NetClus is to avoid defining and calculating pairwise simi-larity between objects but map each target object into a very low dimensional space defined by current clustering result. Then each target object in these clusters will be readjusted based on the new measure. During each iteration, clustering results will be improved under new measure space and the quality of measure will be improved since it is derived from better clusters.
Here, we first introduce the general framework of NetClus, and each part of the algorithm will be explained in detail in the following sections. The general idea of the NetClus algo-rithm given cluster number K is composed of the following steps:
According to many studies in real networks [5, 12], prefer-ential attachment and assortative mixing exist in many real networks, which means an object with a higher degree ( i.e. , high occurrences) has more probability to be attached with an edge, and in some cases higher occurrence objects are more tend to link to each other. As in DBLP dataset, 7 . 64% of the most productive authors publishes 74 . 2% of all the pa-pers, among which 56 . 72% papers are published in merely 8 . 62% of the biggest venues, which means large size con-ferences and productive authors are intended to co-appear via papers. We extend the heuristic by using ranking, which denotes the overall importance of an object in a network, in-stead of degree. The intuition is that degree may not repre-sent global importance of an object well. Examples include: webpage spammed by many low rank webpages linking to it (high-degree but low rank) will not have too much chance to get a link from a real important webpage, and authors pub-lishing many papers in junk conferences will not increase his/her chance to publish a paper in highly ranked con-ferences. Under this observation, we simplify the network structure by proposing a probabilistic generative model for target objects, where a set of highly ranked attribute objects are more likely to co-appear to generate a center object. To explain this idea, we take bibliographic information network as a concrete example and show how the model works. Bib-liographic information network as illustrated in Example 1.1 is formalized as follows. In order to simplify the complex network with multiple types of objects, we try to factorize the impact of different types of attribute objects and then model the generative behavior of target objects. The idea of factorizing a network is: we assume that given a network G , the probability to visit ob-jects from different attribute types are independent to each other. Still, the probability to visit an attribute object in G , say author a i , p ( a i | G ) can be decomposed into two parts: is the overall probability that type of author will be visited in G , and the second part p ( a i | A, G ) is the probability that an object a i will be visited among all the authors in the net-work G . Generally, given an attribute object x and its type T , the probability to visit x in G is defined as in Eq. (1): In practice, p ( T x | G ) can be estimated by the proportion of objects in T x compared with the whole attribute object set
T x for all attribute types. Later we will show that the value of p ( T x | G ) is not important and can be set to 1. How to generate ranking distribution p ( x | T x ,G ) for type T given network G will be addressed in Section 4.4.

Also, we make another independence assumption that within the same type of objects, the probability to visit two differ-ent objects is independent to each other: where x i ,x j  X  T x and T x is some attribute type.
Now, we build the generative model for target objects given the ranking distributions of attribute objects in the network G . Still using bibliographic network as an example, each paper d i is written by several authors, published in one conference, and comprised of a bag of terms in the title. Therefore, a paper d i is determined by several attribute ob-jects, say x i 1 ,x i 2 ,...,x in i ,where n i is the number of links d has. The probability to generate a paper d i is equivalent to generating these attribute objects with the occurrence number indicated by the weight of the edge. Under the in-dependency assumptions that we have made, the probability to generate a paper d i in the network G is defined as follows: where N G ( d i ) is the neighborhood of object d i in network G ,and T x is used to denote the type of object x .Intuitively, a paper is generated in a cluster with high probability, if the conference it is published in, authors writing this paper and terms appeared in the title all have high probability in that cluster.
Once we get the generative model for each net-cluster, we can calculate posterior probabilities for each target object. Now the problem becomes that suppose we know the gen-erative probabilities for each target object generated from each cluster k, k =1 , 2 ,...,K , what is the posterior prob-ability that it is generated from cluster k ? Here, K is the cluster number given by user. As some target objects may not belong to any of K net-cluster, we will calculate K +1 posterior probabilities for each target object instead of K , where the first K posterior probabilities are calculated for each real existing net-clusters C 1 ,C 2 ,...,C K , and the last one in fact is calculated for the original network G .Now, the generative model for target objects in G plays a role as background model, and target objects that are not very related to any clusters will have high posterior probability in background model. In this section, we will introduce the method to calculate posterior probabilities for both target objects and attribute objects.

According to the generative model for target objects, the generative probability for a target object d in the target type D in a sub-network G k = G ( C k ) can be calculated according to the conditional rankings of attribute types in that sub-network: where N G k ( d ) denotes for the neighborhood of object d in sub-network G k . In Eq. (2), in order to avoid zero probabili-ties in conditional rankings, each conditional ranking should be smoothed using global ranking with smoothing parame-ter  X  S , before calculating posterior probabilities for target objects: P
S ( X | T X ,G k )=(1  X   X  S ) P ( X | T X ,G k )+  X  S P ( X where  X  S is a parameter that denotes how much we should utilize the ranking distribution from global ranking.
Smoothing [22] is a well-known technology in information retrieval. One of the reasons that smoothing is required in the language model is to deal with the zero probability problem for missing terms in a document. When calculating generative probabilities of target objects using our ranking-based generative model, we meet a similar problem. For example, for a paper in a given net-cluster, it may link to several objects whose ranking score is zero in that cluster. However, if we simply assign the probability of the target object as zero in that cluster, we cannot use other informa-tive objects to decide which cluster this target object is more likely belonging to. In fact, in initial rounds of clustering, objects may be assigned to wrong clusters, if we do not use smoothing technique, they may not have the chance to go back to correct clusters (See the case of  X  S = 0 in Fig. 4(b)). Once a clustering is given on the input network G ,say C ,C 2 ,...,C K , we can calculate the probability for each target object (say paper d i ) simply by Bayesian rule: where p ( d i | k ) is the probability that paper d i generated from cluster k ,and p ( k ) denotes the relative size of cluster k , i.e. , the probability that a paper belongs to cluster k overall. Here, k =1 , 2 ,...,K,K + 1. From this formula, we can see that type probability p ( T | G ) is just a constant for calcu-lating posterior probabilities for target objects and can be neglected.

In order to get the potential cluster size p ( k )foreach cluster k , we choose cluster size p ( k ) that maximizes log-likelihood to generate the whole collection of papers and then use the EM algorithm to get the local optimum for p ( k ). We use the EM algorithm to get p ( k ) by simply using the following two iterative formulas: p Initially, we can set p (0) ( k )= 1 K +1 .

When posterior probability is calculated for each target object in each cluster C k together with the parent cluster C , where G ( C )= G , each target object d can be represented as a K dimensional vector: v ( d )=( p (1 | d ) ,p (2 | d ) ,...,p ( K The center for each cluster C k can be represented using a K dimensional vector as well, which is the mean vector of all the target objects belonging to the cluster under the new measure. Next, we calculate cosine similarity between each target object and each center of cluster, and assign the tar-get object into the cluster with the nearest center. A new sub-network G k can be induced by current target objects belonging to cluster k . Following the Net-Cluster defini-tion (Definition 3), p C k ( d )=1ifobject d is assigned to cluster C k , 0 otherwise. The adjustment is an iterative pro-cess, until target objects do not change their cluster label significantly under the current measure. Notice that, when measuring target objects, we do not use the posterior proba-bility for background model. We make such choices with two reasons: first, the absolute value of posterior probability for background model should not affect the similarity between target objects; second, the sum of the first K posterior prob-abilities reflects the importance of an object in determining the cluster center.
 The posterior probabilities for attribute objects x  X  A  X  C  X  T can be calculated as follows: It simply says, the probability of a conference belonging to cluster C k equals to the average posterior probability of pa-pers published in the conference, which is similar for authors. And p C k ( x ) in Net-Cluster definition is set to p ( k Example 4.1 (A Running Example of Posterior Change) In Table 2, we select four objects from four types in the DBLP  X  X our-area X  dataset to show their posterior probabili-ties, in four net-clusters and a background model, changing along iterations. Initially, net-clusters are generated from random partitions of papers, each of which is very similar to the original network. Therefore, conditional ranking dis-tributions of each type in each cluster are also very similar to the original ones (background). Thus, posterior proba-bilities for objects in K initial clusters are similar to each other 5 . However, as similar papers under new measure given by posteriors are grouped together, net-clusters in each area become more and more distinct and objects are gradually as-signed with a high posterior probability in the cluster that they should belong to.
Definition 4. Ranking Distribution and Ranking Func-tion. A ranking distribution P ( X ) on a type of objects X is a discrete probability distribution, which satisfies P ( X = x )  X  0(  X  x  X  X )and x  X  X P ( X = x ) = 1. A function f
X : G  X  P ( X ) defined on an information network G is called a ranking function on type X , if given an information network G , it can output a ranking distribution P ( X )on X .
Ranking is usually used to evaluate the importance or relevance of objects in a collection. For example, PageRank [3] and authority of HITS [8] stand for the static importance of webpages, while the rank of a document to a given query in text retrieval reflects the relevance of the document to that query. Here, we use ranking distribution to represent the importance or visibility of objects within their own type in a given information network G . The higher the rank is, the more possible an object will be visited.

Ranking distributions are quite distinct from each other among different clusters. For example, in computer science area, the ranking distribution of authors from the database area and the system area should be rather different. In the best case, ranking distributions should be orthogonal to each other in different clusters. As we illustrated in Section 4.2, within each cluster, by making independency assumptions between different objects, ranking distributions for each type can be used to build generative models for target objects.
We now introduce two ranking functions using the bibli-ographic network as an example, and also give some prop-erties of the two ranking functions for a simple 3-typed star network. 1. Simple Ranking
Simple ranking is namely the simple occurrence counting for each object normalized in its own type. Given a network G , ranking distribution for each attribute type of objects is defined as follows: where x is an object from type T x . For example, in biblio-graphic network, the rank score for a conference using simple ranking will be proportional to the number of its accepted papers.
Initial absolute posterior prob. to background is sensitive to prior  X  P : the higher  X  P , the larger the value. However, final posterior prob. is not significantly affected by  X  P
Property 1. Given a three-typed network with star net-work schema G = X Y Z, E, W ,where Z is the center type, and  X  z, N G ( z )= { x, y } ( x  X  X, y  X  Y ) , the expected coding error for estimating the joint probability of P ( X, Y ) by generative model for G under simple ranking P ( X ) and P ( Y ) is I ( X, Y ) ,where I ( X, Y ) is the mutual information between X and Y .

Proof. =
From the above simple case of network, intuitively for general star network, if a type of attribute objects has a small mutual information with other types of attribute ob-jects, simple ranking is good for it. For example, term type in bibliographic network has small mutual information with authors and conferences in the scale of computer science and database and information system area, and thus could use simple ranking. 2. Authority Ranking
Authority ranking for each object is a ranking function that considers the authority propagation of objects in the network, thus will represent more of the visibility over the whole network. For a general star network G , the propaga-tion of authority score from Type X to Type Y through the center type Z is defined as: where W TZ and W ZX are the weight matrices between the two types of objects as indexed, and can be normalized when necessary. Generally, authority score of one type of objects could be a combination of scores from different types of ob-jects, e.g. , that proposed in [13]. It turns out that the itera-tion method of calculating ranking distribution is the power method to calculate the primary eigenvector of a square ma-trix denoting the strength between pairs of objects in that certain type, which can be achieved by selecting a walking path (or a combination of multiple paths) in the network.
Property 2. Given a three-typed network with star net-work schema G = X Y Z, E, W ,where Z is the cen-ter type, and  X  z, N G ( z )= { x, y } ( x  X  X, y  X  Y ) , author-ity ranking P ( X ) and P ( Y ) are calculated through Equation 5 iteratively, then estimated joint distribution  X  P ( X, Y )= {  X  p ( x, y )= P ( X = x ) P ( Y = y ) ,x  X  X, y  X  Y } equals to the joint distribution represented by one rank matrix M || such that || W XZ W ZY  X  M || F is minimized.

Enlightened by this property holding for the simple net-work, we can have an intuition that authority ranking is Table 3: NMI between Attribute Types in Different Scale of DBLP network able to catch the largest component structure of a network under the constraints that the relation between objects are recovered by 1-dimensional ranking. As a result, authority ranking should have better performance than simple rank-ing in most cases. In the DBLP dataset, according to the rules that (1) highly ranked conferences accept many good papers published by many highly ranked authors and (2) highly ranked authors publish many good papers in highly ranked conferences, we determine the iteration equation as: where D DA and D DC are the diagonal matrices with the diagonal value equaling to row sum of W DA and W DC .Since all these matrices are sparse, in practice, the rank scores of objects need only be calculated iteratively according to their limited neighbors.
 Example 4.2 (Ranking Function Selection in the DBLP Network) Normalized mutual information (NMI) among pairs of two attribute types are calculated in Table 3 in dif-ferent scales of networks, namely the whole computer science network (level 1), the database and information system net-work (level 2), and the database network (level 3). Top 1000 objects by occurrence frequency are used in the calculation. If a type has low NMI with all other types, simple ranking is recommended; otherwise, authority ranking is used among types with high NMI.

In both ranking functions, prior distributions for a certain type in different clusters can be integrated. Priors for a given type X are given in the form P P ( X | T X ,k ) ,k =1 , 2 ,...,K . An User may give only a few representative objects to serve as priors, like terms and conferences in bibliographic data. First, the prior is propagated in the network in a PageRank way, to propagate scores to objects that are not given in the priors. Then, the propagated prior is linear combined with the ranking functions with parameter  X  P  X  [0 , 1]: the bigger the value, the more the final conditional ranking is dependent on prior.
Time complexity of NetClus is composed of the following parts. First, computational complexity for global ranking for attribute objects is O ( t 1 | E | ) and that for global proba-bility calculation for target objects is O ( | E | ), where number of edges in network G and t 1 is the iteration num-ber for ranking. For ranking, at each iteration, each link will be calculated once; and for global probability calculation, a link is still calculated once. Second, time complexity for con-ditional ranking for attribute objects is O ( t 1 | E k | conditional probability for target objects is O ( | E k | cluster k . When adding them together, for all sub-clusters, time complexity for one iteration of clustering should be O ( t 1 | E | + | E | ). Third, time complexity for calculating pos-terior probability for each target object is O ( t 2 ( K +1) N ), where N is the number of target objects, and t 2 is the max iteration number in the EM algorithm. Fourth, cluster ad-justment for each target object is O ( K 2 N ). Since for each target object, it has a K dimensional measure, and we have to calculate similarity to K clusters X  centers, which are also K -d. Fifth, time complexity for posterior probability for each attribute object is O ( K | E | ). For each attribute object, each link to target object should be used once to calculate the posterior probability for it. Also, for each attribute type, we have to calculate a K -d measure.
 In all, the time complexity for NetClus is O (( t 1 +1) | t (( t 1 +1) | E | + t 2 ( K +1) N + K 2 N )+ K | E | ), where t max iteration number used for clustering adjustment, which can be summarized as O ( c 1 | E | + c 2 N ). When the network is very sparse, which is a real situation in most applications, the time complexity is almost linear to the objects in the network.
We now study the effectiveness and accuracy of NetClus and compare it with state-of-the-art algorithms.
We use real data set from DBLP and build bibliographic networks according to Example 1.1. Two networks with different scales will be studied. First, a big data set ( X  X ll-area X  data set) covers all the conferences, authors, papers and terms from DBLP will be used. Second, we also ex-tract a small data set ( X  X our-area X  data set) which contains four areas that are most related to data mining, which are database, data mining, information retrieval and machine learning. Five representative conferences for each area are picked, and all authors have ever published papers on any of the 20 conferences, all these papers and terms appeared in these titles are included in the network. By using the smaller data set, we want to compare the clustering accuracy with several other methods. Also, parameter study and ranking function study will be carried on based on the  X  X our-area X  data set.
We first show the ranking distributions in net-clusters we discovered using the  X  X ll-area X  data set, which is generated by using authority ranking for conferences and authors, set-ting conference type as priors, and setting the cluster num-ber as 8. We show three net-clusters in Table 4. Also, we can recursively apply NetClus to sub-networks derived from clusters and discover finer net-clusters. Top-5 authors in a finer net-cluster about XML area, which is derived from database sub-network, are shown in Table 5.
In Section 4.4, we proposed two ranking functions, namely simple ranking and authority ranking. Here, we study how low dimensional measure derived from ranking distributions improve clustering and how clustering can improve this new measure in turn (Figure 2). Here, term is fixed to use simple ranking, and conference and author are set to use either authority ranking or simple ranking as two different settings.
First, in order to measure how dissimilar conditional rank-ing distributions are among different clusters, we calculate average KL divergence, which is denoted as avgD KL ( X ), be-tween each conditional ranking and global ranking for each attribute type X and trace the change of this measure dur-ing iterations of clustering. avgKL ( X ) is defined as: avgD KL ( X )= 1
Second, in order to measure the goodness of measure gen-erated in each round of clustering, we use the compactness, C , of target objects under each round of clustering for rank-ing function f , which is defined as the average ratio between within-cluster similarity and between-cluster similarity us-ing the new measure:
Third, we trace the accuracy of clustering results for target objects in each round of iteration, which is defined as: However, since | D | is very large even in four-area data set, we manually randomly labeled 100 papers into four clusters and use this paper set to calculate the accuracy.

Fourth, at each iteration of clustering, we calculate the posterior probability for each paper by maximizing the log-likelihood of the whole collection. Here, we also trace the log-likelihood logL along with the clustering iterations, which is defined in Equation 3. From Figure 2, we can see author-ity ranking is better in every measure than simple ranking.
As we know, in K-means like algorithm, the clustering results are sensitive to initial clustering. We kept 30 times running records and mapped the relation between observable measure of log-likelihood (and compactness) and accuracy into Figure 3 to guide user to pick the best clustering results among several runnings with different initialization. From Figure 3, we can see that linear relation exists among the two measures and accuracy. Also, majority voting among different runnings can be used.
In our algorithm, there are two parameters: prior param-eter (  X  P ) and smoothing parameter setting (  X  S ). We use clustering accuracy for sampled papers to test the impact of different settings of parameters to the algorithm. By fixing one of them, we vary the other one. From Figure 4(a) and 4(b), we find that the larger the prior parameter  X  P ,thebet-ter the results, while when  X  P &gt; 0 . 4, the impact becomes more stable 6 ; also, the impact of smoothing parameter is
Actually, the extremely poor quality when  X  P is very small Figure 2: The Change of Goodness of Ranking and Clustering along with the Iteration Number Figure 3: Relation between Log-likelihood / Com-pactness and Accuracy very stable, unless it is not too small (less than 0.1) or too big (bigger than 0.8). The results are based on 20 runnings. Priors given for each of the four areas are around 2 or 3 terms. For example,  X  X atabase X  and  X  X ystem X  are priors for database area, with uniform prior distribution.
In this section, we compare our algorithm with two other algorithms. Since all of them cannot directly applied to het-erogeneous network clustering with four types of objects, for each algorithm, we will simplify the network when necessary is partially caused by the improper accuracy measure at those occasions. When the prior is not big enough to attract the papers from the correct cluster, the clusters generated not necessary have the same cluster label with the priors. to make all the algorithms comparable. For PLSA [23], only the term type and paper type in the network are used. No-tice that we use the same term prior in both NetClus and PLSA. The accuracy results for papers are in Table 6. Table 6: Accuracy of Paper Clustering Results
Since RankClus can only cluster conferences, we choose to measure the accuracy of conference cluster. For NetClus, cluster label is obtained according to the largest posterior probability, and NMI [16] is used to measure the accuracy. The results are shown in Table 7, where d ( a ) &gt;n means we select authors that have more than n publications. Since ma-jority authors only publish a few papers, which contains lit-tle information for disclosure of the relationship between two conferences and misleads the algorithm, we run RankClus algorithm by setting different thresholds to select subsets of authors. All the results are based on 20 runnings. Table 7: Accuracy of Conference Clustering Results
In this paper, we address a new clustering problem to de-tect net-clusters on a special heterogeneous network with star network schema, which aims at splitting the original network into K layers and differs the concept from cur-rent clustering methods on heterogeneous networks. A novel ranking-based algorithm called NetClus is proposed to find these clusters. The algorithm makes assumption that within each net-cluster, target objects ( i.e. , objects from the center type) are generated by a ranking-based probabilistic gen-erative model. Each target object is then mapped into a new low dimensional measure by calculating their posterior probabilities belonging to each net-cluster through their gen-erative models. Our experiments on DBLP data show that NetClus generates more accurate clustering results than the baseline algorithms extended from the topic model and a previous ranking-based algorithm RankClus. Further, Net-Clus generates more informative clusters, presenting good ranking information and cluster membership for each at-tribute object in each net-cluster.

In future, we will study how we can automatically set the number of cluster, by which hierarchy tree with arbitrary structure can be detected. Another issue relates to the sub-space selection for attribute objects at different scales, which is critical to efficiently and effectively clustering in any com-plex network. [1] A. Banerjee, S. Basu, and S. Merugu. Multi-way [2] R. Bekkerman, R. El-Yaniv, and A. McCallum.
 [3] S. Brin and L. Page. The anatomy of a large-scale [4] C.H.Q.Ding,X.He,H.Zha,M.Gu,andH.D.
 [5] M. Faloutsos, P. Faloutsos, and C. Faloutsos. On [6] T. Hofmann. Probabilistic latent semantic analysis. In [7] G. Jeh and J. Widom. SimRank: a measure of [8] J. M. Kleinberg. Authoritative sources in a [9] B. Long, Z. M. Zhang, X. W  X  u, and P. S. Yu. Spectral [10] Q. Mei, D. Zhang, and C. Zhai. A general optimization [11] M. E. J. Newman. The structure of scientific [12] M. E. J. Newman. Assortative mixing in networks. [13] Z. Nie, Y. Zhang, J.-R. Wen, and W.-Y. Ma.
 [14] J. Shi and J. Malik. Normalized cuts and image [15] M. Steyvers, P. Smyth, M. Rosen-Zvi, and T. Griffiths. [16] Y. Sun, J. Han, P. Zhao, Z. Yin, H. Cheng, and [17] Y. Tian, R. A. Hankins, and J. M. Patel. Efficient [18] U. von Luxburg. A tutorial on spectral clustering. [19] N. Wang, S. Parthasarathy, K.-L. Tan, and A. K. H. [20] S. White and P. Smyth. A spectral clustering approach [21] X. Xu, N. Yuruk, Z. Feng, and T. A. J. Schweiger. [22] C. Zhai and J. D. Lafferty. A study of smoothing [23] C. Zhai, A. Velivelli, and B. Yu. A cross-collection
