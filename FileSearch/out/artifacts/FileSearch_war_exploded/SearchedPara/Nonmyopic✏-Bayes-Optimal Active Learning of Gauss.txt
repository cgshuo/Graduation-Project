 Active learning has become an increasingly important focal theme in many environmental sensing and monitoring ap-plications (e.g., precision agriculture, mineral prospecting ( Low et al. , 2007 ), monitoring of ocean and freshwater phe-nomena like harmful algal blooms ( Dolan et al. , 2009 ; Pod-nar et al. , 2010 ), forest ecosystems, or pollution) where a high-resolution in situ sampling of the spatial phenomenon of interest is impractical due to prohibitively costly sam-pling budget requirements (e.g., number of deployed sen-sors, energy consumption, mission time): For such appli-cations, it is thus desirable to select and gather the most informative observations/data for modeling and predicting the spatially varying phenomenon subject to some budget constraints, which is the goal of active learning and also known as the active sensing problem.
 To elaborate, solving the active sensing problem amounts to deriving an optimal sequential policy that plans/decides the most informative locations to be observed for minimiz-ing the predictive uncertainty of the unobserved areas of a phenomenon given a sampling budget. To achieve this, many existing active sensing algorithms ( Cao et al. , 2013 ; 2008 ; 2009 ; 2011 ; 2012 ; Singh et al. , 2009 ) have modeled the phenomenon as a Gaussian process (GP), which allows its spatial correlation structure to be formally character-ized and its predictive uncertainty to be formally quantified (e.g., based on mean-squared error, entropy, or mutual in-formation criterion). However, they have assumed the spa-tial correlation structure (specifically, the parameters defin-ing it) to be known, which is often violated in real-world applications, or estimated crudely using sparse prior data. So, though they aim to select sampling locations that are optimal with respect to the assumed or estimated parame-ters, these locations tend to be sub-optimal with respect to the true parameters, thus degrading the predictive perfor-mance of the learned GP model.
 In practice, the spatial correlation structure of a phe-nomenon is usually not known. Then, the predictive per-formance of the GP modeling the phenomenon depends on how informative the gathered observations/data are for both parameter estimation as well as spatial prediction given the true parameters. Interestingly, as revealed in previous cies that are efficient for parameter estimation are not nec-essarily efficient for spatial prediction with respect to the true model. Thus, the active sensing problem involves a potential trade-off between sampling the most informative locations for spatial prediction given the current, possibly incomplete knowledge of the model parameters (i.e., ex-ploitation) vs. observing locations that gain more informa-tion about the parameters (i.e., exploration): How then does an active sensing algorithm trade off be-tween these two possibly conflicting sampling objectives? To tackle this question, one principled approach is to frame active sensing as a sequential decision problem that jointly and naturally optimizes the above exploration-exploitation trade-off while maintaining a Bayesian belief over the model parameters. This intuitively means a policy that biases towards observing informative locations for spatial prediction given the current model prior may be penalized if it entails a highly dispersed posterior over the model pa-rameters. So, the resulting induced policy is guaranteed to be optimal in the expected active sensing performance. Un-fortunately, such a nonmyopic Bayes-optimal policy cannot be derived exactly due to an uncountable set of candidate observations and unknown model parameters ( Solomon &amp; Zacks , 1970 ). As a result, most existing works ( Diggle , man , 2006 ; Ouyang et al. , 2014 ) have circumvented the trade-off by resorting to the use of myopic/greedy (hence, sub-optimal) policies.
 To the best of our knowledge, the only notable nonmy-opic active sensing algorithm for GPs ( Krause &amp; Guestrin , 2007 ) advocates tackling exploration and exploitation sep-arately, instead of jointly and naturally optimizing their trade-off, to sidestep the difficulty of solving the Bayesian sequential decision problem. Specifically, it performs a probably approximately correct (PAC)-style exploration until it can verify that the performance loss of greedy ex-ploitation lies within a user-specified threshold. But, such an algorithm is sub-optimal in the presence of budget con-straints due to the following limitations: (a) It is unclear how an optimal threshold for exploration can be determined given a sampling budget, and (b) even if such a threshold is available, the PAC-style exploration is typically designed to satisfy a worst-case sample complexity rather than to be optimal in the expected active sensing performance, thus resulting in an overly-aggressive exploration (Section 4.1 ). This paper presents an efficient decision-theoretic planning approach to nonmyopic active sensing/learning that can still preserve and exploit the principled Bayesian sequential decision problem framework for jointly and naturally opti-mizing the exploration-exploitation trade-off (Section 3.1 ) and consequently does not incur the limitations of the al-gorithm of Krause &amp; Guestrin ( 2007 ). In particular, al-though the exact Bayes-optimal policy to the active sens-ing problem cannot be derived ( Solomon &amp; Zacks , 1970 ), we show that it is in fact possible to solve for a nonmy-opic  X  -Bayes-optimal active learning (  X  -BAL) policy (Sec-tions 3.2 and 3.3 ) given a user-defined bound  X  , which is the main contribution of our work here. In other words, our proposed  X  -BAL policy can approximate the optimal ex-pected active sensing performance arbitrarily closely (i.e., within an arbitrary loss bound  X  ). In contrast, the algorithm of Krause &amp; Guestrin ( 2007 ) can only yield a sub-optimal in time-critical applications, we then propose an asymp-totically  X  -optimal, branch-and-bound anytime algorithm based on  X  -BAL with performance guarantee (Section 3.4 ). We empirically demonstrate using both synthetic and real-world datasets that, with limited budget, our proposed ap-proach outperforms state-of-the-art algorithms (Section 4 ). The GP can be used to model a spatial phenomenon of in-terest as follows: The phenomenon is defined to vary as a realization of a GP. Let X denote a set of sampling lo-cations representing the domain of the phenomenon such that each location x 2 X is associated with a realized (ran-dom) measurement z x ( Z x ) if x is observed/sampled (un-observed). Let Z X , { Z x } x 2 X denote a GP, that is, every finite subset of Z X has a multivariate Gaussian distribution ( Chen et al. , 2013a ; Rasmussen &amp; Williams , 2006 ). The GP is fully specified by its prior mean  X  x , E [ Z x ] and covariance xx 0 | , cov [ Z x ,Z x 0 | ] for all x, x 0 2 X latter of which characterizes the spatial correlation struc-ture of the phenomenon and can be defined using a covari-ance function parameterized by . A common choice is the squared exponential covariance function: where [ s x ] i ([ s x 0 ] i ) is the i -th component of the rameters , the square root of noise variance, square root of signal vari-ance, and length-scales, and xx 0 is a Kronecker delta that is 1 if x = x 0 and 0 otherwise.
 Supposing is known and a set z D of realized measure-ments is available for some set D  X  X of observed lo-cations, the GP can exploit these observations to predict the measurement for any unobserved location x 2 X\D as well as provide its corresponding predictive uncertainty using the Gaussian predictive distribution p ( z x | z D , )  X  N (  X  x |D , , xx |D , ) with the following posterior mean and variance, respectively: where, with a slight abuse of notation, z D is to be perceived as a column vector in ( 1 ),  X  D is a column vector with mean components  X  x 0 for all x 0 2 D ,  X  x D| is a row vector with covariance components xx 0 | for all x 0 2 D ,  X  D x | is the transpose of  X  x D| , and  X  DD| is a covariance matrix with components ux 0 | for all u, x 0 2 D . When the spatial correlation structure (i.e., ) is not known, a probabilistic belief b D ( ) , p ( | z D ) can be maintained/tracked over all possible and updated using Bayes X  rule to the posterior belief b D [ { x } ( ) given a newly available measurement Using belief b D , the predictive distribution p ( z x | z obtained by marginalizing out : 3.1. Problem Formulation To cast active sensing as a Bayesian sequential deci-sion problem, let us first define a sequential active sens-ing/learning policy  X  given a budget of N sampling loca-tions: Specifically, the policy  X  , {  X  n } N to sequentially decide the next location  X  n ( z D ) 2 X\D to be observed at each stage n based on the current ob-servations z D over a finite planning horizon of N stages. Recall from Section 1 that the active sensing problem in-volves planning/deciding the most informative locations to be observed for minimizing the predictive uncertainty of the unobserved areas of a phenomenon. To achieve this, we use the entropy criterion ( Cover &amp; Thomas , 1991 ) to mea-sure the informativeness and predictive uncertainty. Then, the value under a policy  X  is defined to be the joint entropy of its selected observations when starting with some prior observations z D V where Z  X  ( z  X  ) is the set of random (realized) measure-ments taken by policy  X  and p ( z  X  | z D ilar manner to ( 4 ).
 To solve the active sensing problem, the notion of Bayes-possible joint entropy with respect to all possible induced sequences of future beliefs (starting from initial prior be-lief b D detailed next. Formally, this entails choosing a sequen-tial policy  X  to maximize V  X  Bayes-optimal active learning (BAL) policy  X   X  . That is, V ( z D plugged into ( 5 ), the following N -stage Bellman equations result from the chain rule for entropy:
Q ( z D ,x ) , H [ Z x | z D ]+ E H [ Z x | z D ] , for stage n =1 ,...,N where p ( z x | z D ) is defined in ( 4 ) and the expectation terms are omitted from the right-hand side (RHS) expressions of V  X  stage, the belief b D ( ) is needed to compute Q  X  in ( 6 ) and can be uniquely determined from initial prior belief b D stand how the BAL policy  X   X  jointly and naturally opti-mizes the exploration-exploitation trade-off, its selected lo-cation  X   X  n affects both the immediate payoff H future payoff E [ V  X  the information gathering option (i.e., exploration). Interestingly, the work of Low et al. ( 2009 ) has revealed that the above recursive formulation ( 6 ) can be perceived as the sequential variant of the well-known maximum entropy sampling problem ( Shewry &amp; Wynn , 1987 ) and established an equivalence result that the maximum-entropy observa-the posterior joint entropy (i.e., predictive uncertainty) re-maining in the unobserved locations of the phenomenon. Unfortunately, the BAL policy  X   X  cannot be derived ex-actly because the stage-wise entropy and expectation terms in ( 6 ) cannot be evaluated in closed form due to an uncount-able set of candidate observations and unknown model pa-rameters (Section 1 ). To overcome this difficulty, we show in the next subsection how it is possible to solve for an  X  -BAL policy  X   X  , that is, the joint entropy of its selected observations closely approximates that of  X   X  within an ar-bitrary loss bound  X  &gt; 0 . 3.2.  X  -BAL Policy The key idea underlying the design and construction of our proposed nonmyopic  X  -BAL policy  X   X  is to approximate the entropy and expectation terms in ( 6 ) at every stage us-ing a form of truncated sampling to be described next: Definition 1 (  X  -Truncated Observation) Define random measurement b Z x by truncating Z x at b  X  and b  X  as follows: Then, b Z x has a distribution of mixed type with its contin-uous component defined as f ( b Z x = z x | z D ) , p ( Z z | z D ) for b  X  &lt;z x &lt; b  X  and its discrete component de-fined as f ( b Z x = b  X  | z D ) , P ( Z x b  X  | z D )= z | z D )d z x and f ( b Z x = b  X  | z D ) , P ( Z x  X  b  X  | z 1 p ( Z x = z x | z D )d z x for some 0  X   X   X  b  X  . Then, a realized measurement of b Z is said to be a  X  -truncated observation for location x . Specifically, given that a set z D of realized measurements is available, a finite set of S  X  -truncated observations { z i can be generated for every candidate location x 2 X\D at each stage n by identically and independently sampling from p ( z x | z D ) ( 4 ) and then truncating each of them ac-cording to z i truncated observations can be exploited for approximating V Q n ( z D ,x ) for stage n =1 ,...,N such that there is no V  X  term on the RHS expression of Q  X  the BAL policy  X   X  (Section 3.1 ), the location  X   X  arg max x 2 X\D Q  X  n ( z D ,x ) selected by our  X  -BAL policy  X   X  at each stage n also jointly and naturally optimizes the trade-off between exploitation (i.e., by maximizing imme-diate payoff S 1 P S rent belief b D ) vs. exploration (i.e., by improving poste-tic BAL policy  X   X  , our  X  -BAL policy  X   X  is stochastic due to its use of the above truncated sampling procedure. 3.3. Theoretical Analysis The main difficulty in analyzing the active sensing per-formance of our stochastic  X  -BAL policy  X   X  (i.e., relative to that of BAL policy  X   X  ) lies in determining how its  X  Bayes optimality can be guaranteed by choosing appropri-ate values of the truncated sampling parameters S and  X  (Section 3.2 ). To achieve this, we have to formally under-stand how S and  X  can be specified and varied in terms of the user-defined loss bound  X  , budget of N sampling lo-cations, domain size |X| of the phenomenon, and proper-ties/parameters characterizing the spatial correlation struc-ture of the phenomenon (Section 2 ), as detailed below. The first step is to show that Q  X  imation of Q  X  are two sources of error arising in such an approximation: (a) In the truncated sampling procedure (Section 3.2 ), only a finite set of  X  -truncated observations is generated for ap-proximating the stage-wise entropy and expectation terms in ( 6 ), and (b) computing Q  X  values of V  X  To facilitate capturing the error due to finite truncated sam-pling described in (a), the following intermediate function is introduced: n ( z D ,x ) for stage n =1 ,...,N such that there is no V  X  the RHS expression of W  X  low reveals that if the error | Q  X  to finite truncated sampling can be bounded for all tuples ( n,z D ,x ) generated at stage n = n 0 ,...,N by ( 8 ) to com-pute V  X  Q Lemma 1 Suppose that a set z D 0 of observations, a budget of
N n 0 +1 sampling locations for 1  X  n 0  X  N , S 2 Z + , and &gt; 0 are given. If for all tuples ( n,z D ,x ) generated at stage n = n 0 ,...,N by ( 8 ) to compute V  X  Its proof is given in Appendix A.1 . The next two lemmas show that, with high probability, the error | Q  X  W n ( z D ,x ) | bounded from above by ( 10 ) for all tuples ( n,z D ,x ) gen-erated at stage n = n 0 ,...,N by ( 8 ) to compute V  X  1  X  n 0  X  N : Lemma 2 Suppose that a set z D 0 of observations, a budget of
N n 0 +1 sampling locations for 1  X  n 0  X  N , S 2 Z + , and &gt; 0 are given. For all tuples ( n,z D ,x ) generated at stage n = n 0 ,...,N by ( 8 ) to compute V  X  P  X  where T , O  X  = O with  X  , 2  X  , 1 + 2 max Refer to Appendix A.2 for its proof.
 Remark 1 . Deriving such a probabilistic bound in Lemma 2 typically involves the use of concentration inequalities for the sum of independent bounded random variables like the Hoeffding X  X , Bennett X  X , or Bernstein X  X  inequalities. How-ever, since the originally Gaussian distributed observations cation will generate unbounded versions of { z i consequently make each summation term log p ( z i V bounded, hence invalidating the use of these concentration inequalities. To resolve this complication, our trick is to exploit the truncated sampling procedure (Section 3.2 ) to generate bounded  X  -truncated observations (Definition 1 ) (i.e., | z i summation term log p ( z i bounded (Appendix A.2 ). This enables our use of Hoeffd-ing X  X  inequality to derive the probabilistic bound. Remark 2 . It can be observed from Lemma 2 that the amount of truncation has to be reduced (i.e., higher cho-sen value of  X  ) when (a) a tighter bound on the error | Q n ( z D ,x ) W is desired, (b) a greater budget of N sampling locations is available, (c) a larger space  X  of candidate model pa-rameters is preferred, (d) the spatial phenomenon varies with more intensity and less noise (i.e., assuming all can-didate signal and noise variance parameters, respectively, ( nal and small noise variances), and (e) its spatial corre-lation structure yields a bigger  X  . To elaborate on (e), note that Lemma 2 still holds for any value of  X  larger for all x 0 6 = u 2 X\D due to the symmetric positive-posing all candidate length-scale parameters are specified close to the true length-scales, a phenomenon with extreme length-scales tending to 0 (i.e., with white-noise process measurements) or 1 (i.e., with constant measurements) will produce highly similar x 0 x 0 |D , for all x 0 2 X\D thus resulting in smaller  X  and hence smaller  X  . Remark 3 . Alternatively, it can be proven that Lemma 2 and the subsequent results hold by setting  X  =1 if a cer-tain structural property of the spatial correlation structure (i.e., for all z D ( D  X  X ) and 2  X  ,  X  DD| is diagonally dominant) is satisfied, as shown in Lemma 9 (Appendix B ). Consequently, the  X  term can be removed from T and  X  . Lemma 3 Suppose that a set z D 0 of observations, a bud-get of N n 0 +1 sampling locations for 1  X  n 0  X  N , S 2 Z + , and &gt; 0 are given. The probability that | Q n ( z D ,x ) W pute V  X  where T is previously defined in Lemma 2 .
 Its proof is found in Appendix A.3 . The first step is con-cluded with our first main result, which follows from Lem-mas 1 and 3 . Specifically, it chooses the values of S and  X  such that the probability of Q  X  ( 6 ) poorly (i.e., | Q  X  bounded from above by a given 0 &lt; &lt; 1 : Theorem 1 Suppose that a set z D of observations, a bud-get of N n +1 sampling locations for 1  X  n  X  N , &gt; 0 , and 0 &lt; &lt; 1 are given. The probability that | Q n ( z D ,x ) Q is at least 1 by setting where T is previously defined in Lemma 2 . By assuming N , |  X  | , o , n ,  X  , and |X| as constants,  X  = O ( and hence S = O (log (1 / )) Its proof is provided in Appendix A.4 .
 Remark . It can be observed from Theorem 1 that the num-ber of generated  X  -truncated observations has to be in-creased (i.e., higher chosen value of S ) when (a) a lower probability of Q  X  | Q n ( z D ,x ) Q domain X of the phenomenon is given. The influence of , N ously reported in Remark 2 after Lemma 2 .
 Thus far, we have shown in the first step that, with high probability, Q  X  for some chosen values of S and  X  (Theorem 1 ). The next step uses this result to probabilistically bound the perfor-mance loss in terms of Q  X  selected by our  X  -BAL policy  X   X  at stage n and following the BAL policy  X   X  thereafter: Lemma 4 Suppose that a set z D of observations, a bud-get of N n +1 sampling locations for 1  X  n  X  N , &gt; 0 , and 0 &lt; &lt; 1 are given. Q  X  n ( z D ,  X   X  n Q n ( z D ,  X  1 by setting S and  X  according to that in Theorem 1 . See Appendix A.5 for its proof. The final step extends Lemma 4 to obtain our second main result. In particular, it bounds the expected active sensing performance loss of our stochastic  X  -BAL policy  X   X  relative to that of BAL pol-icy  X   X  , that is, policy  X   X  is  X  -Bayes-optimal: Theorem 2 Given a set z D get of N sampling locations, and  X  &gt; 0 , V  X  E  X  / (4 N 2 ) and =  X  / (2 N ( N log( o / n ) + log |  X  | )) S and  X  in Theorem 1 to give  X  = O ( S = O Its proof is given in Appendix A.6 .
 Remark 1 . The number of generated  X  -truncated observa-tions and the amount of truncation have to be, respectively, increased and reduced (i.e., higher chosen values of S and  X  ) when a tighter user-defined loss bound  X  is desired. Remark 2 . The deterministic BAL policy  X   X  is Bayes-optimal among all candidate stochastic policies  X  since E 3.4. Anytime  X  -BAL ( h  X  ,  X  i -BAL) Algorithm Unlike the BAL policy  X   X  , our  X  -BAL policy  X   X  can be de-rived exactly because its time complexity is independent of the size of the set of all possible originally Gaussian dis-tributed observations, which is uncountable. But, the cost of deriving  X   X  is exponential in the length N of planning horizon since it has to compute the values V  X  tional burden, we propose an anytime algorithm based on  X  -BAL that can produce a good policy fast and improve its approximation quality over time, as discussed next. The key intuition behind our anytime  X  -BAL algorithm ( exploration paths through the most uncertain regions of the state space (i.e., in terms of the values V  X  evaluating the entire state space like  X   X  . To achieve this, our h  X  ,  X  i -BAL algorithm maintains both lower and upper heuristic bounds (respectively, V  X  each encountered state ( n,z D ) , which are exploited for rep-resenting the uncertainty of its corresponding value V  X  to be used in turn for guiding the greedy exploration (or, put differently, pruning unnecessary, bad exploration of the state space while still guaranteeing policy optimality). To elaborate, each simulated exploration path (EXPLORE of Algo. 1 ) repeatedly selects a sampling location x and its corresponding  X  -truncated observation z i until the last stage N is reached. Specifically, at each stage n of the simulated path, the next states ( n +1 ,z D [ { z i with uncertainty | V  X  ceeding  X  (line 6 ) are identified (lines 7 -8 ), among which the one with largest lower bound V  X  10 ) is prioritized/selected for exploration (if more than one exists, ties are broken by choosing the one with most uncer-tainty, that is, largest upper bound V  X  11 )) while the remaining unexplored ones are placed in the set U (line 12 ) to be considered for future exploration (lines 3 -6 in h  X  ,  X  i -BAL). So, the simulated path terminates if the uncertainty of every next state is at most  X  ; the uncertainty of a state at the last stage N is guaranteed to be zero ( 14 ). Then, the algorithm backtracks up the path to up-date/tighten the bounds of previously visited states (line in h  X  ,  X  i -BAL and line 14 in EXPLORE) as follows:
V n ( z D ) min
V n ( z D ) max Algorithm 1 h  X  ,  X  i -BAL ( z D
Q n ( z D ,x )
Q for stage n =1 ,...,N such that there is no V  X  ( V N . When the planning time runs out, we provide the greedy policy induced by the lower bound:  X  h  X  ,  X  i Central to the anytime performance of our h  X  ,  X  i -BAL algorithm is the computational efficiency of deriving in-formed initial heuristic bounds V  X  V n ( z D )  X  V we have shown in Appendix A.8 how they can be derived efficiently. We have also derived a theoretical guarantee similar to that of Theorem 2 on the expected active sens-in Appendix A.9 . We have analyzed the time complexity of simulating k exploration paths in our h  X  ,  X  i -BAL algo-rithm to be O ( kNS |X| ( |  X  | ( N 3 + |X| N 2 + S |X| )+ + log( kNS |X| ))) (Appendix A.10 ) where O ( ) denotes the cost of initializing the heuristic bounds at each state. In practice, h  X  ,  X  i -BAL X  X  planning horizon can be shortened to reduce its computational cost further by limiting the depth of each simulated path to strictly less than N . In that case, Cao, N., Low, K. H., and Dolan, J. M. Multi-robot infor-mative path planning for active sensing of environmental phenomena: A tale of two algorithms. In Proc. AAMAS , pp. 7 X 14, 2013.
 Chen, J., Low, K. H., Tan, C. K.-Y., Oran, A., Jaillet, P.,
Dolan, J. M., and Sukhatme, G. S. Decentralized data fusion and active sensing with mobile sensors for mod-eling and predicting spatiotemporal traffic phenomena. In Proc. UAI , pp. 163 X 173, 2012.
 Chen, J., Cao, N., Low, K. H., Ouyang, R., Tan, C. K.-Y., and Jaillet, P. Parallel Gaussian process regression with low-rank covariance matrix approximations. In Proc. UAI , pp. 152 X 161, 2013a.
 Chen, J., Low, K. H., and Tan, C. K.-Y. Gaussian process-based decentralized data fusion and active sensing for mobility-on-demand system. In Proc. RSS , 2013b. Cover, T. and Thomas, J. Elements of Information Theory . John Wiley &amp; Sons, NY, 1991.
 Diggle, P. J. Bayesian geostatistical design. Scand. J. Statistics , 33(1):53 X 64, 2006.
 Dolan, J. M., Podnar, G., Stancliff, S., Low, K. H., Elfes, A., Higinbotham, J., Hosler, J. C., Moisan, T. A., and
Moisan, J. Cooperative aquatic sensing using the tele-supervised adaptive ocean sensor fleet. In Proc. SPIE
Conference on Remote Sensing of the Ocean, Sea Ice, and Large Water Regions , volume 7473, 2009.
 Hoang, T. N. and Low, K. H. A general framework for in-teracting Bayes-optimally with self-interested agents us-ing arbitrary parametric model and model prior. In Proc. IJCAI , pp. 1394 X 1400, 2013.
 Houlsby, N., Hernandez-Lobato, J. M., Huszar, F., and
Ghahramani, Z. Collaborative Gaussian processes for preference learning. In Proc. NIPS , pp. 2105 X 2113, 2012.
 Krause, A. and Guestrin, C. Nonmyopic active learning of Gaussian processes: An exploration-exploitation ap-proach. In Proc. ICML , pp. 449 X 456, 2007.
 Krause, A., Singh, A., and Guestrin, C. Near-optimal sen-sor placements in Gaussian processes: Theory, efficient algorithms and empirical studies. JMLR , 9:235 X 284, 2008.
 Low, K. H., Gordon, G. J., Dolan, J. M., and Khosla,
P. Adaptive sampling for multi-robot wide-area explo-ration. In Proc. IEEE ICRA , pp. 755 X 760, 2007.
 Low, K. H., Dolan, J. M., and Khosla, P. Adaptive multi-robot wide-area exploration and mapping. In Proc. AA-MAS , pp. 23 X 30, 2008.
 Low, K. H., Dolan, J. M., and Khosla, P. Information-theoretic approach to efficient adaptive path planning for mobile robotic environmental sensing. In Proc. ICAPS , pp. 233 X 240, 2009.
 Low, K. H., Dolan, J. M., and Khosla, P. Active Markov information-theoretic path planning for robotic environ-mental sensing. In Proc. AAMAS , pp. 753 X 760, 2011. Low, K. H., Chen, J., Dolan, J. M., Chien, S., and Thomp-son, D. R. Decentralized active robotic exploration and mapping for probabilistic field classification in environ-mental sensing. In Proc. AAMAS , pp. 105 X 112, 2012. Martin, R. J. Comparing and contrasting some environmen-tal and experimental design problems. Environmetrics , 12(3):303 X 317, 2001.
 M  X  uller, W. G. Collecting Spatial Data: Optimum Design of Experiments for Random Fields . Springer, 3rd edition, 2007.
 Ouyang, R., Low, K. H., Chen, J., and Jaillet, P. Multi-robot active sensing of non-stationary Gaussian process-based environmental phenomena. In Proc. AAMAS , 2014.
 Park, M. and Pillow, J. W. Bayesian active learning with localized priors for fast receptive field characterization. In Proc. NIPS , pp. 2357 X 2365, 2012.
 Podnar, G., Dolan, J. M., Low, K. H., and Elfes, A. Telesu-pervised remote surface water quality sensing. In Proc. IEEE Aerospace Conference , 2010.
 Poupart, P., Vlassis, N., Hoey, J., and Regan, K. An ana-lytic solution to discrete Bayesian reinforcement learn-ing. In Proc. ICML , pp. 697 X 704, 2006.
 Rasmussen, C. E. and Williams, C. K. I. Gaussian Pro-cesses for Machine Learning . MIT Press, 2006.
 Shewry, M. C. and Wynn, H. P. Maximum entropy sam-pling. J. Applied Statistics , 14(2):165 X 170, 1987. Singh, A., Krause, A., Guestrin, C., and Kaiser, W. J. Effi-cient informative sensing using multiple robots. J. Arti-ficial Intelligence Research , 34:707 X 755, 2009. Solomon, H. and Zacks, S. Optimal design of sampling from finite populations: A critical review and indication of new research areas. J. American Statistical Associa-tion , 65(330):653 X 677, 1970.
 Zimmerman, D. L. Optimal network design for spatial pre-diction, covariance parameter estimation, and empirical
