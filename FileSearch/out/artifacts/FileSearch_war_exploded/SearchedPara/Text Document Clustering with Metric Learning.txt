 One reason for semi-supervised clustering fail to deliver sat-isfactory performance in document clustering is that the transformed optimization problem could have many candi-date solutions, but existing methods provide no mechanism to select a suitable one from all those candidates. This pa-per alleviates this problem by posing the same task as a soft-constrained optimization problem, and introduces the salient degree measure as an information guide to control the searching of an optimal solution. Experimental results show the effectiveness of the proposed method in the im-provement of the performance, especially when the amount of priori domain knowledge is limited.
 H.3.3 [ Information Search and Retrieval ]: Clustering Algorithm, Experimentation Document Clustering, Metric Learning
As one of the most fundamental data mining tasks, clus-tering is a subjective process in nature: different users may want different clusterings when exploring the same data set. However, specifying an appropriate similarity measure in ad-vance is usually difficult for general users. Recently, semi-supervised clustering which can utilize priori pair-wise con-straints has attracted a lot of research interest [5].
For the topic of document clustering, there have been some pioneer work in applying semi-supervised clustering to increase clustering quality [3]. However, their performance is still not as good as expected, especially when the number of priori constraints is limited [2, 3]. One of the possible rea-sons is that: existing work transforms the clustering into an optimization problem, with priori constraints as hard con-straints. When the number of constraints is inadequate, there could be many candidate solutions to this optimiza-tion problem, and existing methods fail to provide a mech-anism to select a suitable one from these possible solutions. Moreover, when the priori knowledge contains some incon-sistent constraints, existing methods might even not be able to generate a feasible result because no solution can satisfy all constraints.

In order to alleviate this problem so that the document clustering can work more effectively with inadequate priori constraints, we propose a novel soft-constraint algorithm for document clustering: instead of satisfying ALL constraints, the method aims to satisfy constraints as much as possi-ble .The proportion of satisfied constraints is adopted as a heuristic to inform the search of the optimal solution. Ex-perimental results show the effectiveness of the proposed method, especially when the number of priori constraints are limited.
Let  X  X  X   X   X  stands for the data space which contains  X  data points { x 1 ,  X  X  X  X  , x n } , x  X  =[  X   X  1 ,  X  X  X  X  , X   X  X  X  [  X  1 ,  X  X  X  X  , X   X  ]  X  ,and  X   X  are the weights for attributes (  X  = 1 ,..., X  ). For document clustering, we use the weighted  X  X  X  X  X  X  X  X  X   X  wise constraints set  X  and a cannot-link pair-wise constraints set  X  , the document clustering problem can be transformed into an optimization problem with the objective as [5]: subject to
Considering the fact that any  X  X  X  X  X  X  X  X  X  similarity is within the range [0 , 1], set for the number of elements in the cannot-link set  X  )inthe algorithm which enforces that every pair in the cannot-link set  X  is exactly 1, with an aim to make sure distances of instances in the cannot-link set  X  as large as possible.
During the search for an optimal set of weights, we in-troduce a new measure, the salient degree ,toevaluatehow the current clustering result respects the priori constraints. We utilize k -means method with metric  X  w ( .,. )toparti-tion data, and get salient degree of clustering result. The centroids in clustering process of k -means are estimated as {  X  assigned to the cluster  X  . The salient degree is defined as the proportion of satisifed constraints by the clustering result here  X  X  X  X  (  X  ) means the satisfied constraints in the set  X  .
Accordingly, the document clustering can be carried out as an optimization problem, but with the salient degree as a heuristic to decide whether it is necessary to carry out further gradient descending search or not. The pseudo-code of this algorithm is provided in Algorithm 1.
 Algorithm 1: Document clustering with metric learning
Input : Dataset  X  , number of output clusters  X  ,must-
Output : Clusters obtained with metric learning.  X  =1; w  X  =[ 1 while not convergent do end
Here we compare the performance of the proposed method with k -means and the hard-constraint algorithm COP-Kmeans implemented according to [4]. The 20Newsgroup dataset is used in our experiment.

From original 20Newsgroup dataset, we randomly select 100 documents for each category, and create 2 datasets: the  X  X  X  X  X  X   X  X  X  X  X  X  3 data set (alt.athei-sm, rec.sport.baseball, sci.space) consisting of 3 clusters on 3 distinct topics, and the  X  X  X  X  X  X   X  X  X  X  X  X  3 data set (comp.graphics, comp.os.ms-windows, comp.windows.x) contains 3 clusters with large overlaps be-tween them. All the datasets have been pre-processed by removing stop-words, and words with too high or too low frequency, and each document is then represented by TF-IDF.

We run 10 trials of 2-fold cross-validation for each dataset: 50% of the dataset is used as training set to obtain pair-wise constraints, and the other half is used as input of com-pared algorithms after peering o ffits class/clustering infor-mation. The clustering results are then compared with the  X  X round truth X  X lustering using Normalized Mutual Informa-tion (  X  X  X  X  )and  X  X  X  X  X  X  X  X  X  measures.

The results are shown as Figure 1 and Figure 2. On both data sets, we can see that the proposed method outperforms the other methods in both the  X  X  X  X  and the  X  X  X  X  X  X  X  X  X  mea-sures. Additionally, the results in our method are more stable. Another important observation is that: When the amount of priori knowledge is adequate, our method per-forms similarly with the compared methods; but when the amount of priori knowledge is limited, our method can still achieve satisfactory clustering results, while the performance of other methods deterioriate significantly.
This paper proposes an efficient soft-constraint algorithm by obtaining a satisfactory clustering result so that the con-straints will be respected as many as possible. Experiments show the advantage of the proposed algorithm especially when provided with little priori domain knowledge, the pro-posed method is more robust and accurate than the existing methods.
This paper was partially supported by the National Natu-ral Science Foundati on of P.R.China (No.60802066), the Ex-cellent Young Scientist Foundation of Shandong Province of China under Grant (No.2008BS01009) and t he Science and Technology Planning Project of Shandong Provincial Edu-cation Department (No.J08LJ22). [1] S. Basu, M. Bilenko, and R. J. Mooney. A probabilistic [2] I. Davidson, K. Wagstaff, and S. Basu. Measuring [3]A.Huang,D.Milne,E.Frank,andI.H.Witten.
 [4] K. Wagstaff, C. Cardie, S. Rogers, and S. Schroedl. [5]E.P.Xing,A.Y.Ng,M.I.Jordan,andS.J.Russell.

