 considerable attention in recent years. It can be described as follows: with l labeled semi-supervised learning, and a number of algorithms have been proposed for it, including Co-training [6], random field models [7,8] and graph based approaches [9, 10]. 
However, learning from examples has been seen as an ill-posed inverse problem so in this paper we focus on regulariza tion approaches. Measur e based regularization with data density. The idea of information regularization [13] is that labels should not change too much in regions where marginal density is high, so regularization penalty that links marginal to the conditional distribution is introduced, and it is expressed in above two methods take density into consideration, and can get the decision boundary that lies in the region of low density in 2D example. However, it is difficult to apply them in high-dimensional real world data sets. 
Manifold regularization [1-4] assumes th at two points close in the input space should have the same label, and exploits the geometry of the marginal distribution to incorporate unlabeled examples within a ge ometrically motivated regularization term. regularization parameters is a new problem. with neighborhood graph. Based on modified Graph Laplacian regularizier, we one regularization parameter reflecting the tradeoff between the Graph Laplacian and Laplacian and further to adjust and optim ize the decision boundary. Experimental and is more robust than Transductive SVM and LapSVM. 
This paper is organized as follows. Sec tion 2 briefly reviews Graph Laplacian and semi-supervised learning assumption. In section 3, we define label information graph with labeled examples and propose the regularized semi-supervised classification algorithm. Experimental results on synthetic and real world data are shown in section 4, followed by conclusions in section 5. 2.1 Graph Laplacian Graph Laplacian [5] has played a crucial role in several recently developed algorithms [14,15], because it approximates the natural topology of data and is simple to compute for enumerable based classifiers. Let X  X  consider a neighborhood graph ) , ( E V G = between examples. The neighborhood of j x can be defined as those examples which measures how much f varies across the graph: where  X  where D is diagonal matrix given by  X  + 2.2 Semi-supervised Learning Assumptions In the semi-supervised learning framework, the marginal distribution X P is unknown, so we must get empirical estimates of X P using a large number of unlabeled However, there is no identifiable relation between the X P and the conditional varies smoothly along the geodesics in the intrinsic geometry of X P . 3.1 Our Motivation enough to achieve perfect classification in su pervised learning. We divide the process the marginal distribution X P using both labeled and unlabeled examples and estimate classification, while the second step is supervised learning. consideration the information carried by labeled examples. The regularization term decision boundary. Therefore for labeled examples i x and j x , if they are of the same label, they should not be separated by the decision boundary, so we can redefine the labels, we can weaken it. 3.2 Definition of Label Information Graph dimensional manifold M and this manifold can be approximated by a weighted graph constructed with all the labeled and unlabeled examples. So the performance of the learning algorithm significantly depends on how the graph is constructed. unlabeled examples. When the support of X P is a compact submanifold M , the geometry structure can be approximated using the Graph Laplacian with both labeled and unlabeled examples. The Least Squares algorithm solves the problem with the squared loss function minimizing the error on the labeled examples. It is important to observe that 
If 0 )) ( (
We define ) ( ) ( u l u l +  X  + matrix J as follows. represent appropriate pairwise label relationship between labeled examples i and j . 
According to the label information graph, the right of the equation 3 can be rewritten as follows: 
This term can be seen as label information carried by labeled examples and penalizes classifiers that separate the examples having the same labels. should not be separated by decision boundary. This relationship must not be represented only by element ij J . For example, for large scale problems, this relationship ij J can be represented by a geodesic path j k k k ik 3.3 Classifier Based on the Modified Graph Laplacian manifold is approximated by a graph constructed with all examples and f is defined stabilizers is squares of norms on reprodu cing kernel Hilbert spaces (RKHS). The squared norm 2 information graph. 
The neighborhood graph and the label information graph have the same vertices and can be incorporated together. So the optimization problem has the following objective function: is a regularization parameter that controls the complexity of the clustering function. It problem has the unique solution: where  X  can be solved by an eigenvalue method and the regularization parameter  X  can be selected by the approach of L-curve. For binary classification problem, particular class, that is } 1 , 1 {  X  = Y . 3.4 Learning Algorithm The crux of the proposed learning algorithm is to redefine the Graph Laplacian based the labeled examples. 
The complete semi-supervised learning algorithm (ReguSCoM) consists of the following five steps. label information graph ) , ( E V G  X  =  X  , and then compute the Graph Laplacian a L . function given by equation 7. Step 4. Compute  X  th labeled example where i i Step 5. Adjust the weights ij J . For the selected i th example, we can find the labeled weight ij J and re-compute the matrix a L . Goto step 2. 4.1 Synthetic Data We first conducted experiments on two moons dataset. The dataset contains 200 regularization clustering without labeled points, where the curves represent the Regularized Semi-supervised Classification on manifold (ReguSCoM) proposed in reason lies in that this dataset has regular geometry structure and the manifold regularization clustering can find this stru cture. The Graph Laplacian based algorithm separate the neighbors. 
Figure 2 shows the results of semi-supervised classification using ReguSCoM algorithm on two moons dataset with Guassian noise and 0, 1, 3, and 5 labeled points added respectively. With 0 labeled points it can be regarded as unsupervised manifold regular geometry structure when noise added. With more labeled examples added, the decision boundary can be adjusted appropriately. With only 5 labeled points for each class, the proposed algorithm can find the optimal solution shown in Figure 2. 4.2 Real World Datasets constructed the graph with 6 nearest-neighbor s and used the binary weight of the edge of the neighborhood graph, that is 1 0 or W ij = . We first used Isolet database of letters of the English alphabet spoken in isolation. We chose isolet1+2+3+4 dataset of 6238 examples and considered the task of binary rates with the increasing of number of labeled examples using ReguSCoM. We also show the results of 45 binary classification problems using USPS dataset. We used the first 400 images for each handwritten digit, and processed using PCA to with the increase of number of labeled examples. We compare the error rate of ReguSCoM with Transductive SVM and LapSVM at the precision-recall breakeven points in the ROC curves, as shown in Figure 4. We choose Polynomial kernel of accuracy than Transductive SVM and LapSVM. Learning from examples has been seen as an ill-posed inverse problem and semi-few labeled examples. We propose a novel regularized semi-supervised classification algorithm on manifold (ReguSCoM) in this paper. The regularization term not only method yields encouraging experimental results on both synthetic data and real world datasets and the results demonstrate effective use of both unlabeled and labeled data. in theory and will investigate other alternative training approaches based on manifold learning to improve performance of semi-supervised learning algorithm. To attack nonlinear ill-posed inverse problem will also be part of our future work. The research is supported by the National Natural Science Foundations of China (60373029) and the National Research Foundation for the Doctoral Program of Higher Education of China (20050004001). We would like to thank Dr. M. Belkin for useful suggestion. 
