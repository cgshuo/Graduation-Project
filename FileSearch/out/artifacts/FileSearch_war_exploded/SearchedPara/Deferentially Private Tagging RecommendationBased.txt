 The widespread success of social netwo rk web sites introduces a new concept called the tagging recommender system [9]. These social network web sites usu-ally enable users to annotate resources with customized tags, which in turn facilitates the recommendation of resources. But the issue of privacy in the rec-ommender process has generally been over looked [11]. An adversary with back-ground information may re-identify a particular user in a tagging dataset and obtain the user X  X  historical tagging records [8]. How to preserve privacy in tagging recommender systems is an emerging issue that needs to be addressed.
Over the last decade, a variety of pri vacy preserving approaches have been proposed for traditional recommender systems [11]. For example, cryptography is used in the rating data for multi-party data sharing [15]. Perturbation adds noise to the users X  ratings before rating prediction [12], and obfuscation replaces a cer-tain percentage of ratings with random values [1]. However, these approaches can hardly be applied in tagging recommender systems due to the semantic property of tags. To overcome the deficiency, the tag suppression method has recently been proposed to protect a user X  X  privacy by modeling users X  profiles and eliminating selected sensitive tags [11]. However, t his method only releases an incomplete dataset that significantly affects the recommendation performance. Moreover, most existing approaches suffer from one common weakness: the privacy notions are weak and hard to prove theoretically, thus impairing the credibility of the final results. Accordingly, a more rigid privacy notion is needed.

Recently, differential privacy provides a strict privacy guarantee for individ-uals [6]. It applies a randomized mechanism suitable for both numeric and non-numeric values and has been proven effective in recommender systems [16,17]. This paper introduces differential privacy into tagging recommender systems, with the aim of preventing re-identification of users and avoiding the association of sensitive tags (e.g., healthcare tags) with a particular user. However, although these charact eristics make differential privacy a promising method for tagging recommendation, there remain some barriers: First, the naive differential privacy mechanism only focuses on releasing statistical information that can barely re-tain the structure of the tagging dataset. this naive mechanism lists all the tags, counts the number and adds noise to the statistical output, but ignores the rela-tionship among users, resources and tags. This simple statistical information is inadequate for recommendations; Second, Di fferential privacy introduces a large amount of noise due to the sparsity of the tagging dataset. For a dataset with millions of tags, the mechanism will result in a large magnitude of noise.
Both barriers imply the naive differential privacy mechanism can not be sim-ply applied in tagging recommender systems. To overcome the first barrier, we generate a synthetic dataset retaining the relationship among tags, resources and users rather than releasing statistical information. The second barrier can be addressed by shrinking the randomized domain, because the noise will decrease when the randomized range is limited. The topic model method is a possible way to structure tags into groups and limit the randomized domain. Therefore, we propose a tailored differential privacy mechanism that optimizes the perfor-mance of recommendation with a fixed level of privacy. The contributions can be summarized as follows:  X  We maintain an acceptable utility of the tagging dataset by designing a prac- X  In PriTop , a novel private topic model-based method is proposed to structure  X  With differential privacy composition properties, a theoretical privacy and Let G be a dataset to be protected, two datasets G and G are neighbor-ing datasets if they differ in only one record. Differential privacy provides a randomization mechanism M to mask the difference between the neighboring datasets [6]. We use 9 G to represent the synthetic dataset after applying M .
In tagging recommendation, dataset G contains users U = { u 1 ,u 2 ,  X  X  X } ,re-and a resource r b  X  R , T ( u a ,r b ) represents all tags flagged by the u a on r b ,and use T ( u a ) to denote all tags utilized by u a . The recommended tags for u a on T ( u a ) ,W ( u a ) &gt; is usually modeled by his tagging records, including tag X  X  names T ( u a )= { t 1 ,...,t | T ( u
Differential privacy acquires the intuition that releasing an aggregated report should not reveal too much information about any individual in the dataset [6]. Definition 1 ( -Differential Privacy ). A randomized mechanism M gives -differential privacy if for every set of outcomes  X  , M satisfies: Pr [ M ( G )  X   X  ]  X  exp( )  X  Pr [ M ( G )  X   X  ] ,where is the privacy budget.

M is associated with the sensitivity [7], which measures the maximal change of the query f when removing one record from G .
 Definition 2 ( Sensitivity ). For f : G  X  R ,the sensitivity of f is defined as f =max G,G || f ( G )  X  f ( G ) || 1 ,
Two mechanisms are utilized in differential privacy :the Laplace mechanism and the Exponential mechanism. The Laplace mechanism is suitable for numeric output and adds controlled noise to the outcome of a query [7]: Definition 3 ( Laplace Mechanism). Given a function f : G  X  R d ,themech-anism, M ( R )= f ( R )+ Laplace (  X f ) d , provides the -differential privacy .
The Exponential mechanism focuses on non-numeric queries and pairs with an application dependent score function q ( G, ), which represents how good an output scheme is for dataset G : Definition 4 ( Exponential Mechanism). [10] An Exponential mechanism M is -differential privacy if: M ( G )= { return  X  exp( q ( G, X  )
Privacy violations in recommender systems have been well studied since 2001. The first study concerned with this issue was undertaken by Ramakr-ishnan et al. [13]. They claimed users who rated items across disjointed domains could face a privacy risk through statis tical database queries. Recently, Calan-drino et al. [4] presented a more serious privacy violation. By observing temporal changes in the public outputs of a recommender system, they inferred a partic-ular user X  X  historical rating and behavior with background information.
Several traditional privacy preserving methods have been employed in CF, in-cluding cryptographic [5,15], perturbation [12] and obfuscation [1]. Cryptographic is suitable for multiple parties but induces extra computational cost [5,15]; Ob-fuscation is easy to understand and to implement, but the utility will decrease significantly [1]. Perturbation preserves high level of privacy by adding noise to the original dataset, but the magnitude of noise is hard to control [12].
The privacy in tagging recommendation systems is more complicated due to its unique structure and semantic content. Parra-Arnau et al. [11] proposed the tag suppression by eliminating sensitive tags from users X  profile. They applied a clustering method to structure tags and suppressed the less represented ones. This approach only releases an incomplete dataset, and sensitive tags are sub-jective. When publicly sharing the dataset, users still have the potential to be identified. The privacy issue in tagging recommender systems remains largely unexplored, and we attempt to fill this void in this paper. Differential privacy assumes all tags have probabilities to appear in P ( u a ). Sup-noted as W ( u a )= { w 1 ,...,w | T | } ,where w i = 0 indicates that t i is unused. Differential privacy will add noise to the weight W ( u a ) and release a noisy noise because lots of weights will change from zero to a positive value. To reduce the noise is to shrink the randomized domain, which refers to the di-minished number of zero weights in the p rofile. Accordingl y, we structure the tags into K topics Z = { z 1 ,...z K } and define a topic-based profile P z ( u a )= &lt; T
In this section, we propose a Pri vate Top ic-based Tagging Release (PriTop) algorithm to publish users X  profiles by masking their exact tags and weights under differential privacy . As described in Alg. 1, three private operations are involved: Private Topic Model Generation creates multiple private topics by masking the topic distribution on tags. Topic Weight Perturbation masks the weights of tags to prevent inferring how many tags a user has annotated on a topic. Private Tag Selection uses privately selected tags replace the original tags. 3.1 Private Topic Model Generation This operation categorizes tags into topics to eliminate the randomization do-main. We introduce differential privacy to Latent Dirichlet Allocation (LDA) [2] to generate a private LDA model, which is constructed in three steps: LDA Model Construction , Private Model Generation and Topic-based Profile Generation . LDA Model Construction. The first step constructs the LDA model by Gibbs Sampling [14]. In this model, a resource is considered as a document and a tag is Algorithm 1. Private Topic-based Tagging Release (PriTop) Algorithm interpreted as a word. Let Z = { z 1 ,...z K } be a group of topics, Eq. 1 represents a standard LDA model to specify the distribution over tag t .
 where Pr ( t | z l ) is the probability of tag t under a topic z l and Pr ( z l | r )isthe probability of sampling a tag from topic z in the resource r .

To estimate topic-tag distribution Pr ( t | z ) and the resource-topic distribu-tion Pr ( z | r )inEq.1, Gibbs Sampling iterates multiple times over each tag t of resource r and samples the new topic z for the tag based on the posterior probability Pr ( z | t i ,r,Z  X  i ) by Eq. 2 until the model converges. where C TK is the count of topic-tag assignments and C RK counts the resource-topic assignments. Z  X  i represents topic-tag assign ment and resource-topic as-signment except the current z for t i . and  X  are parameters of Dirichlet priors. Simultaneously, the evaluation on Pr ( t | z )and Pr ( z | r ) is formulated as follows: Private Model Generation. The second step adds Laplace noise to the final counts in the LDA model. There are four difference counts in Eq. 2. If we changed the topic assignment on current t i ,the C TK tK will decrease by 1 and | T | t will increase by one. Similarly, if the C RK rK decreases by 1, the K K =1 C RK r increase by 1 accordingly. So we sample two groups of Laplace noise and add them to four count parameters. The new Pr ( z | t,r ) is evaluated by Eq. 3: where  X  1 and  X  2 are both sampled from Laplace ( 2 )withthe sensitivity as 1. Topic-based Profile Generation. The third step creates topic-based user profiles. For each user with tags T ( u a )= { t 1 ,...,t | T ( u R ( u a )= { r 1 ,...,r | R ( u according to the Pr ( z | t,r ). So the user profile can be represented by a topic-based P 3.2 Topic Weight Perturbation After generating P z ( u a ), we will add Laplace noise to mask the weights of tags in each topic: W z ( u a )= W z ( u a )+ Laplace ( 4 ) K . Noise implies the revision of the list T z ( u a ). Positive noise indicates new tags being added, while negative one indicates tags being deleted from the list. For positive noise in the topic z l ,the operation will choose the tags with the highest probability in the current topic z according to the Pr ( t | z ). For negative noise, the operation will delete the tag with the lowest probability in the current topic z l .
 noisy topic-based user profile. However, the P z ( u a ) still has the high probability to be re-identified because it retains a major part of the original tags. The next operation will replace all tags in T ( u a ) to preserve privacy. 3.3 Private Tag Selection Private Tag Selection adopts the Exponential mechanism to privately select tags from a list of candidates. Specifically, for a particular tag t i , the operation first a candidate list I . Each tag in I is associated with a probability based on a score function and the sensitivity of the function. The selection of tags is performed based on the allocated probabilities.
 The score function is defined as the Jensen-shannon ( JS ) divergence between where t j  X  I are the candidate tags for replacement and D JS refers to JS divergence. The sensitivity for q is measured by the maximal distance of two tags, which is 1. Based on the score function and sensitivity , the probability arranged to each tags t j is computed by Eq. 5 with the privacy budget 4 . where z l is the topic in which t j belongs to. 4.1 Privacy Analysis To analyze the privacy guarantee, we apply two composition properties of differ-ential privacy [10]. The sequential composition accumulates of each step when a series of private analysis is performed sequentially on a dataset. The parallel com-position ensures the maximal when each private step is applied on disjointed subsets of the dataset. The PriTop algorithm contains three private operations and the is consequently divided into three pieces: 2 , 4 and 4 , respectively.  X  Private Topic Model Generation is performed on the whole dataset with the  X  Topic Weight Perturbation preserves 4  X  differential privacy for each user. As  X  Private Tag Selection processes the Exponential mechanism successively. For
Consequently, the proposed PriTop algorithm preserves -differential privacy . 4.2 Utility Analysis Given a target user u a , the utility level of the proposed PriTop algorithm is highly dependent on the distance between P ( u a )and 9 P ( u a ), which is referred tag replacing the tag t . If we consider each private step as a query f ,wethen apply a utility definition in differential privacy suggested by Blum et al [3]. Accordingly, we demonstrate the SLoss is bounded by a certain value with a high probability.
 Definition 5 (( ,  X  )-usefulness). A mechanism M is ( ,  X  )-useful for a set of query F ,ifwithprobability 1  X   X  , for every query f  X  F and every dataset G ,for 9 G = M ( G ) , we have max f  X  F | f ( 9 G )  X  f ( G ) | X  ,where F is a group of queries. Theorem 41 For any user u  X  U , for all  X &gt; 0 , with probability at least 1  X   X  ,the SLoss 1 of the user in the perturbation is less than .When | T ( u ) | X  Proof. The perturbation adds Laplace noise with / 4 to the weight. According
The theorem 41 reveals the semantic loss of perturbation depends on the number of tags a user has. More tags results in a lower semantic loss . Theorem 42 For any user u  X  U , for all  X &gt; 0 , with probability at least 1  X   X  , the SLoss 2 of the user in the private selection is less than .When Q  X  exp( 8 ) 1  X   X  X  , where Q is the normalization factor that depends on the topic that t  X  T ( u ) belongs to, the private selection operation is satisfied with ( , X  ) -useful. Proof. According to Marlkov X  X  inequality, we get Pr ( SLoss 2 &gt; a )  X  E ( SLoss 2 )  X  For each tag t ai in 9 P a , the probability of  X  X nchange X  in the private selection is topic t ai belongs to. We then obtain E ( SLoss 2 )= t
Q i ) and estimate SLoss 2 as Pr ( SLoss 2 &gt; a ) When d ( t ai , 9 t ai )=1and Q =max Q i , it is simplified as Pr ( SLoss 2  X  a )  X  1 theorem 41, We obtain Q  X  exp( 8 ) 1  X   X  X  ,where Q i = j  X  z
The theorem 42 shows the semantic loss of private selection mainly depends on the and Q i , which measures by the total distance inside topic z to which t i belongs. The shorter distance leads to a smaller Q i and less semantic loss . We conduct experiment on three datasets: Del.icio.us , MovieLens and Last.fm . Del.icio.us dataset was retrieved from the Del.icio.us website by the Distributed Artificial Intelligence Laboratory (DAI-Labor), and includes around 132 million resources and 950 , 000 users. We extracted a subset with 3 , 000 users, 34 , 212 bookmarks and 12 , 183 tags. MovieLens and Last.fm datasets were obtained from HetRec 2011 . All datasets are structured as triples ( user , resource , tag ), and filtered by removing added tags like  X  X mported X ,  X  X ublic X , etc.
 5.1 Semantic Loss Analysis To maintain consistency with previous research, we compare the semantic loss of PriTop with tag suppression [11]. For the PriTop algorithm, we selected = topic K varies from 10 to 100 with a step of 10. In tag suppression [11], the semantic loss exhibits a linear relationship with the eliminate parameter  X  . When we choose the representative value  X  =0 . 8, the sematic loss is 0 . 2.
It can be observed from Fig. 1 that the semantic loss of the PriTop algorithm in a variety of datasets was less than 0 . 2 with different privacy budgets, which indicates that PriTop outperforms tag suppression on all configurations. Specif-ically, the PriTop obtains a considerably lower semantic loss when =1.For example, in Fig. 1a, when K =90and =1,the semantic loss is 0 . 0767, which is 62% lower than tag suppression with SLoss =0 . 2. This trend is retained when K equals other values and in other figures, such as Fig. 1b and 1c. All figures show that PriTop obtains a stable semantic loss at a lower level, and retains more utility than tag suppression . This is because PriTop retains the relationship between tags and resources, and makes the profiles of users meaningful. 5.2 Performance of Tagging Recommendation To investigates the effectiveness of PriTop in the context of tagging recommen-dations, we apply a state-of-the-art tagging recommender system, FolkRank [9], to measure the degradation of privacy preserving recommendations. We use Re-call to quantify the performance and N is the number of recommended tags. The following experiments compare the PriTop with tag suppression with N varies from 1 to 10. For PriTop ,wechose K = 100, and test the performance when =1and0 . 5. For tag suppression ,wefix  X  =0 . 8and0 . 6, corresponding to suppression rates of 0 . 2and0 . 4, respectively.

Fig. 2 presents the recall of recommendation results. It is observed that the proposed PriTop algorithm significantly outperforms the tag suppression method on both privacy budgets. Specifically, as shown in Fig. 2a, when N =1, PriTop achieves a recall at 0 . 0704 with the = 1 which outperforms the result from the tag suppression with  X  =0 . 6, 0 . 0407, by 42 . 19%. This trend is retained as the increasing of N .When N =5, PriTop achieves a recall at 0 . 1799 with the = 1 which outperforms the result from the tag suppression by 37.19% when  X  =0 . 6, 0 . 113. When N reaches 10, the PriTop still retains 36 . 09% higher on recall than tag suppression . Even we choose the lower privacy budget with =0 . 5 and a higher eliminate parameter sigma =0 . 8, the improvement is still significant. The PriTop has a recall of 0 . 1382, which is also 7 . 67% higher than tag suppression with a recall of 0 . 1276. The improvement of PriTop is more obvious when N = 10. It achieves recalls of 0 . 1882 and 0 . 2408 when =1and =0 . 5, respectively. But tag suppression only achieves recalls of 0 . 1538 and 0 . 1881 with  X  =0 . 6and  X  =0 . 8. Similar trends can also be observed in Fig. 2b and 2c. In the MovieLens dataset, when N =10and =1 . 0, the recall of PriTop is 0 . 4445, which is 27 . 33% higher than tag suppression with  X  =0 . 8. With the same configuration, PriTop is 22 . 43% and 25 . 22% higher than tag suppression in Last.fm and Bibsonomy datasets. The experimental results show the PriTop algorithm outperforms tag suppression in variety of N , which implies that PriTop can retain more useful information fo r recommendations than simply deleting the tags. In addition, the performance of PriTop is very close to the non-private baseline. For example in Fig. 2a, when =1,the recall of the De.licio.us dataset is 0 . 2408, which is only 3 . 00% lower than the non-private recommender result. Other datasets show the same trend. As shown in Fig. 2b and 2c, with the same configuration, the PriTop result is 3 . 62% lower than the non-private result on the MovieLens dataset, and 7 . 58% lower on the Last.fm dataset. The results indicate that PriTop algorithm achieves the privacy preserving objective while retaining a high accura cy of recommendations.

To show the statistical effectiveness of PriTop , we apply a paired t test (with a 95% confidence) to examine the difference on the performance of PriTop with =1 . 0and tag suppression with  X  =0 . 2. The statistics for results are shown in Table 1. All t values are greater than 6 and all p values are less than 0 . 0001, thus indicating improvement on recall are statistically significant. 5.3 Impact of Privacy Budget In the context of differential privacy , the lower represents a higher privacy level. To achieve a comprehensive examination of PriTop ,weevaluatetheperformance of recommendation under diverse privacy levels.

Fig. 3 shows the recall on the three datasets. It presents the recommendation performance achieved by PriTop when the privacy budget varies from 0 . 1to1 with a step of 0 . 1. It is clear the recall of tag recommendations is significantly affected by the required privacy budget. The recall increases as increases. For example, as plotted in Fig. 3a on the Del.icio.us dataset, when N = 10, PriTop achieves a recall at 0 . 1538 with =0 . 1and0 . 2408 with = 1. The reason is the privacy and utility issues are two opposite components of the datasets. We have to sacrifice the utility to obtain the privacy, therefore our purpose is to obtain an optimal utility when fixing the privacy at an acceptable level.

As a summary, results on a real tagging recommender system confirm the practical effectiveness of the PriTop algorithm. Privacy preserving is one of the most important aspects in recommender systems. However, when we introduce the differential privacy , the solution fails to retain the relationship among users, resources and tags; and introduces a large volume of noise, which significantly affects the recommendation performance.
This paper proposes an effective privacy tagging release algorithm PriTop with the following contributions: 1) We propose a private tagging release al-gorithm to protect users from being re-identified in a tagging dataset. 2) A private topic model is designed to reduce the magnitude of noise by shrinking the randomization domain. 3) A better trade-off between privacy and utility is obtained by taking the advantage of the differentially private composition properties. These contributions provide a practical way to apply a rigid privacy notion to a tagging recommender system without high utility costs.

