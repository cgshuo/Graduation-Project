 Niels Landwehr niels.landwehr@cs.kuleuven.be Hidden Markov models (HMMs) are among the most popular approaches for modeling time series data, and have seen widespread application in areas such as speech recognition, bioinformatics, or robotics. They assume that observed data stems from a hidden pro-cess which is stationary and Markov. However, in some application domains this single-process model is not appropriate. Consider for instance a log of web server requests, and assume we have no definite knowledge about which request has been issued by which user (e.g. because of proxy use). Clearly, there is no single hidden Markov process that accounts for the sequence of observed requests. Instead, there are multiple pro-cesses, one per user, which interleave to generate the sequence of observations. Another example, and the main motivation for the work presented in this paper, is activity recognition : the task of inferring a user X  X  current activity from a stream of dense sensor data. In many situations, users switch back and forth between multiple activities, which causes sensor observations associated with the individual activities to interleave in time. The specific scenario considered in this pa-per is that objects used in activities of daily living are equipped with small RFID tags, which are picked up by a wearable RFID reader whenever a user interacts with the object. The task is to infer the sequence of activities carried out given the observed object inter-actions. In the light of recent advances in RFID tech-nology, which allow tags to be cheaply mass-produced and readers to be made wearable, such application sce-narios are attracting increasing research interest from both academia and industry (Wang et al., 2007). HMMs have been widely used in activity recognition: activities are modeled as hidden states that emit the object tags observed by the RFID reader (Patterson et al., 2005). This is an appropriate model if activi-ties are atomic and carried out sequentially. In many domains, however, activities are hierarchically struc-tured, as sets of basic activities can be grouped into high-level activities. High-level activities typically in-terleave in time as a user is switching between them, as illustrated in Figure 1. In this example, a user is having breakfast, which consists of high-level activities makeToast, makeJuice, and getNews with correspond-ing basic activities. The domain could be modeled with a standard HMM by  X  X lattening X  the three activ-ities into one process with 7 states, but in this case part of the problem structure would be lost. Alternatively, we can model the activities as three different processes which interleave in time. This has the advantage of de-coupling transition dynamics within one high-level ac-tivity from the interleaving behavior, yielding a more concise representation with fewer parameters. In this paper, we present a probabilistic model in which observations are generated by multiple, inter-leaved hidden processes. The hidden processes are sta-tionary Markov chains, and the switching mechanism by which they interleave is again Markov. Although there exists a large body of related work, to the best of our knowledge this interleaved setting has not been addressed before. A simplified version has been dis-cussed in (Batu et al., 2004); however, tractable infer-ence algorithms are not explored in this work. Simpli-cial mixtures of Markov chains, which employ a gener-ative semantics similar to latent Dirichlet allocation, also address a similar problem (Girolami &amp; Kab  X an, 2003). However, they restrict the constituent pro-cesses to be Markov rather than hidden Markov. A fur-ther class of models assumes several hidden processes that run in parallel, and that observations stem from their joint state. Examples include factorial hidden Markov models (Ghahramani &amp; Jordan, 1997), hidden Markov decision trees (Jordan et al., 1996), coupled hidden Markov models (Brand, 1997) and mixed hid-den Markov models (Altman, 2007). In contrast to our approach, these models focus on factorizing com-plex state spaces into cross-products of simpler com-ponents, rather than modeling interleaved processes. Another related technique are switching state-space models (SSSMs) (Ghahramani &amp; Hinton, 1998), in which several processes run in parallel and an addi-tional switch variable selects one active process from which the current observation is generated. SSSMs are different in that processes run concurrently, while an interleaving of processes is characterized by the fact that an inactive process is stopped and only resumes when it becomes active again. This creates additional dependencies between processes which cannot be mod-eled in a SSSM. Finally, hierarchical hidden Markov models model hierarchical structure within the hidden process that generates the observations (Fine et al., 1998). However, the component processes cannot in-terleave, and thus the model is not appropriate in our domain.
 The next section introduces the proposed model more formally. Afterwards, we discuss the key problem of hidden state inference: given a sequence of observa-tions, find the most likely configuration of hidden pro-cesses to have generated the data. Unfortunately, ex-act inference can be shown to be NP-hard; however, efficient structured approximate inference techniques can be applied (Section 3). Finally, the proposed tech-nique is evaluated in an activity recognition domain, and shown to outperform standard HMM-based ap-proaches (Section 4). Let Y 1 , ..., Y T denote a sequence of observations, where the Y t take on one of D discrete values. A hid-den Markov model  X  (Rabiner, 1989) defines a se-quence X 1 , ..., X T of hidden state variables, with X t { 1 , ..., K } and K the number of different states the hidden process can take on. To simplify notation, assume that there is a special start state 0 the pro-cess is in at time t = 0, that is, X 0 = 0. The first transition is from X 0 to X 1  X  X  1 , ..., K } , and af-terwards the first output Y 1 is emitted. The HMM is characterized by initial state probabilities a 0 i = P ( X 1 = i | X 0 = 0), state transition probabilities a ij = P ( X t = j | X t  X  1 = i ) for t  X  2 and emission probabilities b il = P ( Y t = l | X t = i ) for t  X  1. The joint distribution of observations Y = Y 1 , ...Y T and hidden states X = X 1 , ..., X T is given by We will also refer to X as the hidden process that generated the observations Y .
 We propose a model for multiple, interleaved hidden processes. Intuitively, an additional switching process controls a token that is handed from process to pro-cess, and determines which of the processes is active at a particular point t in time. The active process tran-sitions to a new state and outputs the observation Y t , while all other processes remain  X  X rozen X  in time. More formally, let  X  1 , ...,  X  M be hidden Markov models with initial state probabilities a ( m ) 0 i , transition proba-bilities a ( m ) ij and emission probabilities b ( m ) il of notation, we assume the number of states K is iden-tical for all  X  m , but the model trivially generalizes to processes with state spaces of different size. Let fur-thermore  X   X  be a Markov process with states { 1 , ..., M } , initial state probabilities d 0 i and transition probabil-ities d ij . Let Z t denote a random variable represent-ing the state of  X   X  at time t , and S ( m ) t denote ran-dom variables representing the state of process  X  m at time t for 1  X  m  X  M . Z t  X  X  1 , ..., M } determines the active process at time t , and we will refer to  X   X  as the switching process . At every step t in time, a new active process is sampled from  X   X  with probability P ( Z t = j | Z t  X  1 = i ) = d ij . Afterwards, the states of  X  , ...,  X  M are updated according to where  X  ii = 1 and  X  ij = 0 for i 6 = j . In other words, a process  X  m transitions to a new state with probability given by its transition matrix if it is active at time t , and stays in its old state otherwise.
 Finally, the probability of emitting symbol Y t is That is, it is given by the emission probability of the process that is active at time t . Let S t = S (1) t , ..., S Z = Z 1 , ..., Z T and S = S 1 , ..., S T . Then P ( Z , S , Y ) =
Y We will refer to this model as an interleaved mixture of hidden Markov models . It is represented by the dy-namic Bayesian network structure given in Figure 2 (left). The model is structurally related to a factorial hidden Markov model (Ghahramani &amp; Jordan, 1997), shown in Figure 2 (right). However, the structure is extended by the additional chain of Z t nodes that de-termine the currently active process. Although the structure is densely connected, the set of parameters is simply the union of the parameter sets of the con-stituent HMMs  X  1 , ...,  X  M and the switching process  X   X  . The following alternative interpretation of the model can be given. Let z denote an interleaving 1 and let t , ..., t m T m denote the sequence positions for which z tion of Y to elements generated by  X  m , and S  X   X  m = S ables. It is easily verified that where P  X  m ( Y  X   X  m , S  X   X  m ) is the joint distribution of hidden states S  X   X  m and observations Y  X   X  m in the orig-inal HMM  X  m . This reformulation gives rise to an in-tuitive approach for sampling from Y : first sample an interleaving pattern z from  X   X  , and afterwards Y  X   X  m from  X  m for 1  X  m  X  M . A key task in the activity recognition domains we have in mind is hidden state inference : find for a given sequence y of observations. This involves simultaneously finding a segmentation of y into sub-sequences y  X   X  m generated by  X  m (the z  X  ), and most likely hidden states for y  X   X  m in  X  m (the s  X  ). 3.1. Exact Inference Two special cases of the problem are trivial. For M = 1, the model coincides with a hidden Markov model, and the Viterbi algorithm returns the most likely hidden states in time O ( K 2 T ). Moreover, if the output symbol sets of  X  1 , ...,  X  M are disjoint, the inter-leaving z is directly observable, and s can be obtained by running M instances of Viterbi in time O ( M K 2 T ). The more interesting case of M  X  2 and non-disjoint output symbol sets is inherently more difficult due to its combinatorial nature X  X he M constituent chains are coupled via the switching process and observa-tions, and thus cannot be handled independently. Ac-cordingly, exact graphical model inference (e.g. with the junction tree algorithm) applied to the model in Figure 2 (left) has costs exponential in M , because the cliques at Y t are of size O ( M ). In fact, for gen-eral graphical model structures of this form there is no tractable inference algorithm available. However, the conditional distributions P ( Y t | S t , Z t ) have a par-ticularly simple form, which could make the problem easier. Unfortunately, this is not the case: Theorem. Exact inference for interleaved mixtures of hidden Markov models is NP-hard.
 The theorem is proved by reduction from the strongly NP-hard 3-partition problem (Garey &amp; Johnson, 1975): Problem (3-partition problem) . Let S be a multiset of M = 3 N positive integers. Is there a partition of S into subsets S 1 , ..., S N of size 3 each such that the sum over the integers in each subset is the same? A detailed proof is omitted for lack of space. In-tuitively, the relationship is that an interleaving of  X  , ...,  X  M  X  X artitions X  a given sequence into the parts generated by the different processes (cf. Figure 1). Note that a key issue is the strong NP-hardness of 3-partition: the problem is NP-hard even if numbers in the input are given in unary notation (or, equivalently, if integers in S are polynomially bounded in M ). 3.2. Approximate Inference Approximate inference in graphical models has re-ceived much attention, and a variety of techniques are available. The most simple class of methods are Markov chain Monte Carlo (MCMC) approaches. In Gibbs sampling, for instance, iterative conditional resampling of random variables defines a Markov process whose stationary distribution X  X nder certain conditions X  X ill be the conditional distribution in Equation (4). However, MCMC is not an effective in-ference method in our case, because the Markov pro-cess defined by the Gibbs sampler is not ergodic. There can be two state configurations with positive proba-bility that cannot be transformed into each other by single-variable changes without passing through an in-valid (probability zero) configuration, such as any con-tively traps the Gibbs sampler in a subspace of all configurations and prevents MCMC convergence. The problem is that Gibbs sampling, by updating only one variable at a time, ignores the specific model struc-ture. Instead, we have to resort to approximate in-ference methods that better exploit model structure. Examples include structured variational approxima-tions (Ghahramani &amp; Jordan, 1997) and an iterative approximate inference method known as the chainwise Viterbi algorithm (Saul &amp; Jordan, 1999). These algo-rithms are used in factorial HMMs for computing EM statistics and hidden state inference. In the rest of the Section, we present an extension of chainwise Viterbi for solving the problem given by Equation (4). The idea behind chainwise Viterbi is to repeatedly solve tractable sub-problems of the (intractable) global optimization problem. For factorial hidden Markov models, the natural sub-problem to solve is to opti-mize hidden states in one chain S ( m ) = S ( m ) 1 , ..., S conditioned on the current states of the other chains: In the dynamic Bayesian network representing an in-terleaved mixture of HMMs (Figure 2, left), there are two different types of hidden chains: the chains S (1) , ..., S ( M ) representing the constituent processes  X  , ...,  X  M and the chain Z representing the switch-ing process  X   X  . Assume first that Z is kept fix, and the goal is to conditionally optimize a chain S ( m ) . This is straightforward: for a given interleaving pattern, the chains S (1) , ..., S ( M ) become independent given Z and Y due to the special form of the conditional distribu-Algorithm 1 Chainwise Viterbi for interleaved mix-tures of hidden Markov models
Input: model M , observations Y ( S , Z ) := consistent-configuration( M ) while not converged do end while return S , Z tions P ( Y t | S t , Z t ), cf. Equation (2). They can thus be optimized independently with standard Viterbi. We therefore focus on the task of optimizing Z given S (1) , ..., S ( M ) . A straightforward update is not very effective: as a process  X  m can only change state at time t if it is active, we know from S ( m ) t 6 = S that Z t = m . Thus, the joint state of S (1) , ..., S ( M ) essentially determines Z . To change the state of Z t from m to n , it is necessary to also update S ( m ) t and S t to reflect that  X  n is now active at time t . The solution is to jointly optimize two constituent chains S ( m ) , S ( n ) and the switching chain Z by Intuitively speaking, this update allows to re-assign observations that have so far been attributed to process  X  m to process  X  n , by changing some Z t from m to n and updating S ( m ) and S ( n ) accord-ingly. If it is repeatedly applied with different process indices m, n , the interleaving can be arbi-trarily revised. Algorithm 1 describes this chain-wise update scheme in pseudocode. The method consistent-configuration( M ) initializes the states of the hidden variables to some positive-probability con-figuration 2 . When choosing m, n  X  X  1 , ..., M } differ-ent strategies are possible; we assume the algorithm repeatedly cycles through all pairs n 6 = m . If the up-date step (5) is implemented exactly, P ( s , z , y ) will increase unless the hidden state configuration is left unchanged. Thus, the algorithm will always converge (though not necessarily to the true global optimum). An efficient implementation of the update step (5) is crucial for fast inference. This can be achieved by dynamic programming in the spirit of the Viterbi al-gorithm (Rabiner, 1989). Moreover, the particularly restrictive form of the model (basically, that only the active chain changes state at any point in time) can be exploited. This allows much faster inference than for general graphical models with the DAG structure given in Figure 2 (left), as will be briefly outlined now. To simplify notation, assume that n = 1 and m = 2. In analogy to the Viterbi algorithm, define  X  ijk [ t ] = max with Initialization of  X  ijk [1] is straightforward. For the re-cursive definition of  X  ijk [ t ], let C [ k ] = the fixed chains  X  3 , ...,  X  M . Now two cases have to be considered. If k  X  3, chains 1 , 2 cannot have changed state, and with s = S ( k ) t and y = Y t . This quantity can be com-puted in time O ( M ). If k  X  X  1 , 2 } , we have to take into account state changes on the chains being opti-mized. Assume without loss of generality that k = 1. Now  X  with y = Y t . This quantity can be computed in time O ( KM ). There are O ( K 2 M T ) values of the form  X  ijk [ t ] to compute. However, time for computing all values is bounded by O ( K 2 M ( M + K ) T ), as the case k  X  X  1 , 2 } only appears O ( K 2 T ) times.
 The maximum probability of a hidden state configu-ration is and a maximizing configuration is found by keeping track of where maxima occur in backtrace variables. It is instructive to compare the complexity of the out-lined chainwise Viterbi algorithm to inference in an HMM where hidden states are  X  X lattened X  into a sin-gle process. This HMM has a state space of size KM , and standard Viterbi has thus complexity O ( K 2 M 2 T ), similar to the O ( K 2 M ( M + K ) T ) for a single update step in chainwise Viterbi. However, several such up-date steps will be needed before convergence. 3.3. Parameter Estimation There are different possible settings for learning the proposed model from data. In the activity recognition setting discussed in Section 4, both sensor observa-tions and activities are given for the training set. In this fully observable case maximum-likelihood model parameters can essentially be determined by count-ing. More generally, if the interleaving is known for the training data (that is, we know which part of each sequence has been generated by which process), the problem reduces to independently estimating the pa-rameters of  X  1 , ...,  X  M with the standard Baum-Welch algorithm (Rabiner, 1989). In an unsupervised learn-ing setting, expectation-maximization including the unknown interleaving Z is a natural choice. However, for the same reasons as discussed in Section 3, exact computation of the expectation step will be infeasi-ble. In factorial hidden Markov models, this prob-lem is solved elegantly by a structured variational ap-proximation, and exploring variational inference meth-ods for the interleaved mixture model presented in this paper is an interesting direction for future work. A simple alternative is to employ hard EM : instead of computing exact expectations, hidden states are set to their max-likelihood values given the observa-tions, and expectations determined by counting. To-gether with the chainwise Viterbi algorithm discussed in Section 3.2 this yields a tractable method which is straightforward to implement. The proposed model has been evaluated in an activity of daily living (ADL) recognition domain, where the goal is to infer a user X  X  activity from a stream of dense RFID sensor data. The dataset has been collected in a real RFID environment at Intel Research Seat-tle (Landwehr et al., 2007). Objects are equipped with small RFID tags, and the user is wearing a lightweight RFID reader in a bracelet around the wrist. Whenever the reader comes close (10 X 15 centimeters) to a tagged object, the object tag is recorded. The sequence of ob-served tags thus indicates the objects a user has been interacting with while performing the activity. We recorded activities involved in making breakfast at home, as this domain showcases the kind of interleav-ing behavior we are interested in (cf. Figure 1). The dataset consists of 20 sequences of RFID tag observa-tions collected from 5 different persons having break-fast. Sequences are hand-labeled with the true current activity based on a human observer. There are 18 ba-sic activities organized into 6 high-level activities, 24 different classes of tagged objects (including nil if no object was observed), and a total of 4597 timepoints to be classified. Timepoints at which no activity is taking place and activities with a coverage of less than 1% were removed, leaving 14 activities and 3545 time-points in the dataset. The average number of segments into which a high-level activity is broken up because of interleaving is 3.95. There is significant overlap be-tween observations associated with different activities, either because the same object is used in different ac-tivities or noise in the sensor data. More specifically, the average overlap in the set of observations associ-ated with two different activities is 40 . 6%. A standard approach in ADL recognition is based on HMMs: each basic activity corresponds to a hidden state, and sensor data to observations. In the de-scribed domain this means that all activities are  X  X lat-tened X  into one hidden process, and their hierarchical structure is lost. This approach will serve as a baseline, denoted by HMM . Alternatively, high-level activities can be modeled as separate hidden processes using the model described in Section 2. Here we consider a slight extension of this model: state transition probabilities in the active hidden process  X  Z t depend not only on the previous state but also on whether or not the pro-cess has just become active; that is, Z t 6 = Z t  X  1 . The motivation for this extension is that high-level activi-ties are typically interrupted at a point where the basic activity changes as well. It is straightforward to gener-alize the model and algorithms discussed in Section 2 and Section 3 to include this dependency.
 Each high-level activity A is represented as a process  X 
A , and the state space of  X  A are the basic activi-ties associated with A . Note that the method, when applied to a given observation sequence, will auto-matically chose the (approximately) most likely subset of high-level activities that explains the observations. This model, together with the approximate inference technique discussed in Section 3.2 will be denoted as HMMmix . In the chainwise Viterbi algorithm, hid-den states are initialized to the most likely activity given the current sensor observation (as observed in the training data). Furthermore, a version with exact inference (denoted HMMmix* ) is run for comparison. The experimental study seeks to answer the following two questions: (Q1) Does reconstruction accuracy increase if high-(Q2) Does the approximate inference algorithm for The rationale behind ( Q1 ) is that modeling high-level activities as separate processes will capture transition dynamics more concisely, as it decouples dynamics within a high-level activity from the switching dy-namics. This is reflected in the number of model pa-rameters: The  X  X lattened X  HMM representation re-quires O (( M K ) 2 ) = O ( M 2 K 2 ) parameters to spec-ify transition dynamics, while HMMmix only requires O ( M 2 + M K 2 ) parameters.
 To evaluate the different approaches, we performed a leave-one-sequence-out cross-validation. On the respective training set, models are estimated from fully observable training data, i.e., information on both sensor observations and activities is available. Given a test sequence, the most likely joint state of hidden variables in the model is determined, yield-ing a prediction of the current basic activity at ev-ery point in time. This is compared against the known true activity, and average prediction accu-racy is computed. Table 1 shows reconstruction ac-curacy for HMM , HMMmix and HMMmix* . Ad-ditionally, accuracy for always predicting the most frequent activity ( Majority ), and the most fre-quent activity given a particular sensor observation (
Majority/Observation ) are shown. HMMmix significantly outperforms HMM (paired two-sided t-test, p = 0 . 05), and predictions made by HMMmix and HMMmix* are identical in this experiment. This affirmatively answers questions Q1 and Q2 . Figure 3 shows the convergence behavior of chainwise Viterbi. The normalized log-likelihood of the current configura-tion of hidden states and the reconstruction accuracy given by this configuration are plotted as a function of the algorithm iteration. As expected, both likelihood and accuracy increase as the algorithm repeatedly re-vises the current interleaving. Furthermore, conver-gence occurs after a small number of iterations. There are two sources of information for predicting the activity at a point t in time: the current sen-sor observation, and transition dynamics for activities (which capture the influence of past and future ob-servations on the current prediction). The Major-ity/Observation approach already performs well; this indicates that much information is obtained sim-ply from the current sensor observation. To further investigate the influence of transition dynamics on re-construction accuracy, the following experiment was carried out. When estimating a model from data, only a randomly selected fraction  X  of the training sequences is used to estimate transition probabilities, while all available data is used to estimate emission probabilities. Figure 4 shows reconstruction accuracy as a function of  X  . The experiment confirms that HMMmix outperforms HMM , and that approximate inference gives solutions very close to those of exact inference (solutions differ slightly, but the curves for HMMmix and HMMmix* in Figure 4 are indistin-guishable). Moreover, the difference between HMM and HMMmix is most pronounced if only 20% to 40% of training sequences are used to estimate transition parameters. This supports the hypothesis that the more concise representation of transition dynamics in HMMmix (with fewer model parameters) explains its superior performance, as a concise representation mat-ters most if training data is sparse. We have introduced a model for interleaved mixtures of hidden processes, which was shown to be superior to a single-process model in an activity recognition domain. The model should be generally applicable in situations where only the interleaved output of several independent processes can be observed. Related work includes several extensions of hidden Markov models (as discussed in Section 1), and activity recognition approaches based on HMMs such as (Patterson et al., 2005) and (Zhang et al., 2007) or dynamic Bayesian networks (Wang et al., 2007). The proposed method not only labels sequence positions but returns a struc-tured parse of the sequence in terms of a set of hid-den processes. Thus, it is also related to segmentation models, grammar-based approaches, and more gener-ally models for predicting structured data (see (Bakir et al., 2007) for an overview). Directions for future work include semi-and unsupervised learning settings, and testing the model in different domains and on larger activity recognition datasets.
 Acknowledgments The author would like to thank Matthai Philipose and Intel Research Seattle for mak-ing the activity recognition dataset available, and Luc De Raedt, Ingo Thon, Bernd Gutmann and Siegfried Nijssen for helpful discussions. The comments from the anonymous reviewers also helped to improve the paper. This work was supported by the Re-search Foundation-Flanders (FWO-Vlaanderen), and GOA/08/008 project  X  X robabilistic Logic Learning X . Altman, R. M. (2007). Mixed hidden Markov models:
An extension of the hidden Markov model to the longitudinal data setting. Journal of the American Statistical Association , 102 , 201 X 210.
 Bakir, G. H., Hofmann, T., Sch  X olkopf, B., Smola,
A. J., Taskar, B., &amp; Vishwanathan, S. V. N. (2007). Predicting Structured Data (Neural Infor-mation Processing) . The MIT Press.
 Batu, T., Guha, S., &amp; Kannan, S. (2004). Inferring Mixtures of Markov Chains. Proceedings of the 17th Annual Conference on Learning Theory .
 Brand, M. (1997). Coupled hidden Markov models for modeling interactive processes (Technical Report 405). MIT Media Lab.
 Fine, S., Singer, Y., &amp; Tishby, N. (1998). The hierar-chical hidden Markov model: Analysis and applica-tions. Machine Learning , 32 , 41 X 62.
 Garey, M. R., &amp; Johnson, D. S. (1975). Complex-ity Results for Multiprocessor Scheduling under Re-source Constraints. SIAM Jour. Comp. , 4 , 397 X 411. Ghahramani, Z., &amp; Hinton, G. E. (1998). Switching
State-Space Models (Technical Report). Department of Computer Science, University of Toronto.
 Ghahramani, Z., &amp; Jordan, M. I. (1997). Factorial Hidden Markov Models. Mach. Lear. , 29 , 245 X 273. Girolami, M., &amp; Kab  X an, A. (2003). Simplicial Mix-tures of Markov Chains: Distributed Modelling of
Dynamic User Profiles. Proc. of the 17th Ann. Con-ference on Neural Information Processing Systems . Jordan, M. I., Ghahramani, Z., &amp; Saul, L. K. (1996).
Hidden Markov Decision Trees. Proceedings of the 9th Conference on Advances in Neural Information Processing Systems .
 Landwehr, N., Gutmann, B., Thon, I., Philipose, M., &amp; De Raedt, L. (2007). Relational Transformation-based Tagging for Human Activity Recognition.
Proc. of the Intern. Workshop on Knowledge Dis-covery from Ubiquitous Data Streams .
 Patterson, D., Fox, D., Kautz, H., &amp; Philipose, M. (2005). Fine-Grained Activity Recognition by Ag-gregating Abstract Object Usage. Proc. of the 9th IEEE Intern. Symp. on Wearable Computers .
 Rabiner, L. (1989). A tutorial on hidden Markov mod-els and selected applications in speech recognition. Proceedings of the IEEE , 77 , 257 X 286.
 Saul, L. K., &amp; Jordan, M. I. (1999). Mixed Memory Markov Models: Decomposing Complex Stochastic Processes as Mixtures of Simpler Ones. Machine Learning , 37 , 75 X 87.
 Wang, S., Pentney, W., Popescu, A.-M., Choudhury, T., &amp; Philipose, M. (2007). Common Sense Based
Joint Training of Human Activity Recognizers. Pro-ceedings of the 20th International Joint Conference on Artificial Intelligence .
 Zhang, W., Chen, F., Xu, W., &amp; Cao, Z. (2007). De-composition in hidden Markov models for activity
