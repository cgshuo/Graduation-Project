 Semantic Role Labelling (SRL) is a natural la n-guage processing task which deals with se mantic analysis at sentence -level. SRL is the task of identifying arguments for a certain predicate and labelling them. The predicates are usually verbs. They establish  X  X hat happened  X  . The argu ments determine events such as  X  X ho X  ,  X  X hom X ,  X  X here X  , etc, with reference to one predicate. The possible semantic roles are pre -defined for each pre dicate. Th e set of roles depends on the corpora.

SRL is becoming an important tool for info r-mation extraction, text summarization, machine translation and question answering ( M  X  rquez, et al , 2008 ) . The data set I use d is taken from the CoNLL -2009 shared task (Haji  X  et al., 2009) and is part of Propbank. Propbank (Palmer et al, 2005) is a hand -annotated corp us . It transforms sentences into propositions. It adds a semantic layer to the Penn TreeBank (Marcus et al, 1994) and defines a set of semantic roles for each predicate. 
It is difficult to define universal semantic roles for all predicates. That is why PropBank defines a s et of semantic roles for each possible sense of each predicate (frame) [See a sample of the frame  X  X aise X  on the Figure 1 caption].
 The core arguments are labelled by numb ers. Adjuncts , which are common to all predicates, have their own labels , like: AM -LOC, TMP, NEG, etc. The four most frequent labels in the data set are: A1:35%, A0:20.86%, A2:7.88% and AM -TMP: 7.72%
Propbank was originally built using constit u-ent tree structures, but here only the dependency tree structure version was used. Note that d e-pendency tree structures have labels on the a r-rows . T he tree distance algorithm cannot work with these labelled arrows and so they are moved to the child node as an extra label.

The task performed by the Tree SRL system consists of labelling the relations (predicate a r-guments) which are assumed to be already ide n-tified. The tree distance algorithm ha s already been a p-plied to text entailment (Kouylekov &amp; Magnini, 2005) and question answering (Punyakanok et al, 2004 ; Emms, 2006 ) with positive results. 
The main contribution of this piece of work to the SRL field is the inclusion of the tree dista nce algorithm into a n SRL system, working with tree structures in contrast to the classical  X  X eature e x-traction X  and  X  X lassification  X . Kim et al (2009) developed a similar system for Information E x-traction. Table 1 : T he data
The data set is divided into three files: training (Tra), development (Dev) and evaluation (Evl). 
The following table describes the number of sentences, sub -trees and labels contained in them, and the ratios of sub -trees per sentences and relat ions per sub -tree.
Tai (1979) introduced a criterion for matching nodes between tree representations (or conver t-ing one tree into another one) and (Shasha &amp; Zhang, 1990; Zhang &amp; Shasha, 1989) developed an algorithm that finds an optimal matching tree solution for a ny given pair of trees. The adva n-tage of th is algorithm is that its computational cost is low. The optimal matching depends on the defined atomic cost of matching two nodes . For the training and testing data set, all possible sub -trees were extracted . Figure 3 and Figure 5 describe the process . Then , using the tree di s-tance algorithm , the test sub -trees are labelled using the training ones. Finally , the predicted labels get assembled on the original sentence where the test sub -tree came from. Figure 2 d e-scribes the process.

A sub -tree extracted from a sentence, contains a predicate node, all its argument nodes and all the ancestors up to the fir st common ancestor of all nodes. ( Figure 1 shows two samples of sub -tree extraction. Figure 3 describes how sub trees are obtained) Figure 1 : Alignment sample and A4).
 w h ere the core arguments are: S uppose that in Figure 1 , the bottom sentence is the query, where the grey shadow contains the sub -tree to be labelled and the top sentence co n-tains the sub -tree sample chosen to label the query. Then , an alignment b etween the sample sub -tree and the query sub -tree suggest s labelling the query sub -tree with A1, A2 and A3, where the first two labels are right but the last label , A4 , is predicted as A3, so it is wrong.

I t is not necessary to label a whole sub -tree (query) using just a single sub -tree sample. Ho w-ever , if the whole query is label led using a single answer sample, the pred iction is guaranteed to be consistent (no rep ea ted argument labels) .

S ome possible ways to label the semantic rel a-tion usin g a s orted list of alignments (with each sub -tree of the training data set) is discussed ahead . Each sub -tree contains one predicate and several semantic relations, one for each argument node. In this sub -section , the neighbouring sub -trees f or one relation of a sub -tree T refers to the nea r-Figure 5 : S ub -tree extraction Figure 4 : L abelling a relation. (approach A) Figure 3 : Sub -tree extraction sample.

Assuming that  X  X  X  ( the square node ) is a pr e-dicate node and the nodes  X  X 1 X  and  X  X 2 X  are its arguments (the arguments are defined by the semantic relations . I n this case , the semi -doted arrows.), the sub -tree extracted from the above sentence will contain the nodes:  X  X 1 X ,  X  X 2 X ,  X  X  X , all ancestors of  X  X 1 X , X  X 2 X  and  X  X  X  up to the first common one , in this case node  X  X  X , which is also included in the sub -tree.
All of the white nodes are not included in the sub -tree. The straight lines represent syntactic dependency relations.
 est sub -trees with which the match with T pr o-duces a match between two predi cate nodes and two argument nodes. A label from the nearest neighbour ( s ) can be transferred to T for labelling the relation.

The current implementation (Approach A) , described in more detail in Figure 4 , labels a r e-l a tion using the first nearest neighbour from a list ordered by ascending tree distance. If there are several nearest neighbours , the first one on the list is used . This is a naive implementation of the k -NN algorithm where in case of multiple nea r-est neighbours only one is used and the others get ignored .

A negative aspect of this strategy is that it can select a different sub -tree based on the input o r-der. This makes the algorithm indeterministic . A way to make it deterministic can be by extending the parameter  X  X  X  in case of multiple cases at the same distance or a tie in the voting (Approach B) . In this section , a sample refers to a sub -tree co n-taining all arguments and its labels. The arg u-ments for a certain predicate are re lated.

Some strategies can lead to non -consistent structures ( core argument labels cannot appear twice in the same sub -tree ) . Approach B treats the relations independently. It does not have any mechanism to keep the consistency of the whole predicate structure. 
Another way is to find a sample that contains enough information to label the whole sub -tree (Approach C) . This approach always generates consistent structures. The limitation of this model is that the required sample may not exist or the tree distance may be very high, making those samples poor predictor s . The implemented method (Approach A) indirectly attempts to find a training sample sub -tree which contains labels for all the arguments of the predicate.

I t is expected for tree distance s to be smaller than other sub -tree s that do not have information to label all the desired relations. 
The system tries to get a consistent structure us ing a simple algorithm. Only i n the case when using t he nearest tree does not lead to labelling the whole struc ture, labels are predicted using multiple samples , thereby , risking the structure consistency.

Future implementations will rank possible candidate labels for each relation (probably using multiple samples). 
A  X  X oint scoring algorithm X  , which is co m-monly use d (Marquez et al, 2008) , can be applied for consistency checking after finding the rank probability for all the ar gument labels for the same predicate (Approach D) . The cost of matching two nodes is crucial to the performance of the system. Different atomic measures (ways to measure the cost of matching two nodes) that were tested are explained ahead . Results for experiments using these atomic measures are given in Table 2 . For B inary system , t he atomic cost of matching two nodes is one if label POS or dependency r e-lations are different, otherwise the cost is zero. The atomic cost of inserting or deleting a node is always one. Note that the measure is totally based on the syntactic structure (words are not used). The next intuitive me asure is how the system would perform in case of a ternary cost (ternary system) . The atomic cost is half if POS or d e-pendency relation is different, one if POS and depende ncy relation are dif ferent or zero in all other case. For this system, Table 2 shows a very similar accuracy to the binary one. The atomic cost of matching two nodes is the sum of the following sub costs: 0.25 if POS is different. 0.25 if dependency relation is different. 0.25 if Lemma is different. 0.25 if one node is a pred icate but the other is The cost to create or delete nodes is one . Note that the sum of all costs cannot be greater than one. The anal ysis of results for the previous systems shows that the accuracy is higher for the sub -trees that are labelled using sub -trees with the same predicate node. Consequently , this st rategy attempts to force the predicate to be the same. In this system, the a tomic cost of matching two nodes is the sum of the following sub costs: The cost to create or delete nodes is one . This strategy attempt s to improve the accuracy by adding an extra label to the argument nodes and using it. 
The atomic cost of matching two nodes is the sum of the following sub costs: 0.1 for each different label (dependency rel a-0.1 for each pair of different labels (depen d-0.4 if one node is a predicat e and the other is 0.4 if both nodes are predicates and lemma is 2 if one node is marked as an argument and 
The atomic cost of deleting or inserting a node is: two if the node is an argument or predicate node and one in any other case. Table 2 shows the accuracy of all the systems . The validation data set is added to the training data set when the system is labelling the evalu a-tion data set. This is a common methodology followed in CoNLL2009 (Li et al, 2009). 
Accuracy is measure d as the percentage of s e-mantic l abels correct ly predicted .

The implementation of the Tree SRL system takes several days to run a single experiment . I t makes non viable the idea of using the develo p-men t data set for adjusting parameters and t hat is why , for the last three systems (Hamming, Pred i-cate Match and Complex) , the accuracy over the development data set is not measure d . The same reason supports adding the development data set to the training data set without over fitting the system, because the development data set is not really used for adjusting parameters.

However , the observations of the system on the development data set shows: 1. I f the complexity gets increase d (Ternary) , 2. The output of the system only contains five 3. Higher accuracy for t he relations where a 4. Some sub -trees are very small (just one 
It is surprising that the hamming measure reach es higher accuracy than the  X  predicate match  X  , which use s more informa tion, and is also surpris ing that the accuracies for  X  X amming X ,  X  X redicate Match X  and  X  X omplex X  systems are very similar .

The CoNLL -2009 SRL shared task was eval u-ated on multiple languages: Catalan, Chinese, Czech, English, German, Japanese and Spanish. Some results for those languages usi ng  X  X  ree SRL S ystem B inary  X  are shown in Table 3 .
Language Accuracy on English 64.36% 56 Spanish 57.86% 46 Catalan 58.49% 43 Japanese 50.71% 8
German These languages had been e x-Czech Chinese Table 3 : Accuracy for other languages (Binary system)
The accuracy results for multiple languages suggest that the size of the corpora ha s a strong influence on the results of the system perfor m-ance. 
The results are not comparable with the rest of the CoNLL -2009 systems because the task is different. T his system do es not identify arg u-ments and do es not perform predicate sense di s-ambiguation.
 System Evaluation Development Binary 64.36% 61.12% Ternary 64.88% 61.28% Hamming 78.01% Predicate 
Match Complex 78.98%
Table 2 : S ystem accuracy The tree distance algorithm has been applied successfully to bui ld a SRL system. Future work will focus on improving the performance of the system by : a) t r ying to extend the sub -trees which will contain more contextual information, b) using d ifferent approaches to label semantic relations discussed in Section 5 . Also, the system will be expanded to identify arguments using a tree distance algorithm .

E valuating the task of identifyin g the arg u-ments and label ling the relations separately will assist i n determining which systems to combine to cre ate a n hybrid system with better perfor m-ance. Acknowledgments This research is supported by the Science Fou n-dation Ireland (Grant 07/CE/I1142) as part of the Centre for Next Generation Localisation ( www.cngl.ie ) at Trinity College Dublin.
 Thanks are due to Dr Martin Emms for his su p-port on the development of this project .
 Martin Emms . 2006 . Variants of Tree Similarity in M ilen Kouylekov and B ernardo Magnini . 2005. Re -D ennis Shasha and K aizhong Zhang . 1990. Fast a l-K uo -Chung Tai . 1979. The Tree -to -Tree Corre c-
