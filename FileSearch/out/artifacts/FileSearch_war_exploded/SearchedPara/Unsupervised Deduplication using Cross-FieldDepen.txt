 Recent work in deduplication has shown that collective dedu-plication of different attribute types can improve perfor-mance. But although these techniques cluster the attributes collectively, they do not model them collectively. For exam-ple, in citations in the research literature, canonical venue strings and title strings are dependent X  X ecause venues tend to focus on a few research areas X  X ut this dependence is not modeled by current unsupervised techniques. We call this dependence between fields in a record a cross-field depen-dence . In this paper, we present an unsupervised gener-ative model for the deduplication problem that explicitly models cross-field dependence. Our model uses a single set of latent variables to control two disparate clustering models: a Dirichlet-multinomial model over titles, and a non-exchangeable string-edit model over venues. We show that modeling cross-field dependence yields a substantial im-provement in performance X  X  58% reduction in error over a standard Dirichlet process mixture.
 H.2.8 [ Information Systems ]: Database Applications X  data mining ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  clustering Algorithms, Experimentation
Deduplication is an important and difficult preprocess-ing step in knowledge discovery. For example, consider the venue portion of citations in the bibliographies of research papers. A single venue can be named by dissimilar strings X 
Current Address: Computer Science Division, University of California, Berkeley, CA 94720 for example, AAAI and Proceedings of the Fourteenth Na-tional Conference on Artificial Intelligence , and other vari-ants caused by typographical errors. Alternatively, different entities can be denoted by identical strings X  X or example, ISWC is a commonly-used abbreviation both for the In-ternational Semantic Web Conference , and for the Interna-tional Symposium on Wearable Computers . The deduplica-tion problem is to group a set of these noisy strings, which are called mentions , by which underlying entity they refer to. In addition, entities may have attributes (also called fields), such as the title and venue of a research paper, that can be used to improve deduplication. Given clean venue data, one can imagine computing many interesting bibliographic mea-sures, such as which venues are most concentrated around a small set of authors, which venues adopt new terminology most frequently, and so on. But such measures will always be suspect unless the deduplication problem is solved well.
Recent work has shown that collective inference X  X n which many deduplication decisions are made simultaneously and an optimal set of decisions chosen globally X  X an significantly improve performance over approaches in which individual decisions are made independently. This has been demon-strated in such areas as collective clustering over mentions [10, 15, 3], collective extraction and deduplication [18], and collective deduplication of different attribute types [13, 7, 14, 15]. But although some methods compute clusters col-lectively, there is an important sense in which they do not model clusters collectively. Current generative models fo-cus on modeling the manner in which a canonical attribute, such as a paper X  X  true title, is distorted in a noisy observa-tion, such as a citation in a later paper. Crucially, however, current models do not incorporate the fact that different at-tribute types are dependent. For example, research venues tend to focus on specific research areas, and those areas are reflected in the titles of the papers that they publish. We call this a cross-field dependence , because the values of different fields are probabilistically dependent.

In this paper, we demonstrate the benefits of modeling cross field dependencies in the task of deduplicating research paper venues. We show that modeling the dependence be-tween venue strings and paper titles yields a significant in-crease in deduplication performance from unlabeled data. In particular, we present a Dirichlet process mixture model that uses a single set of mixture components to combine two disparate clustering models: a Dirichlet-multinomial mix-ture for the titles, and a non-conjugate string-edit distortion model for the venues. In this way, each venue has a charac-teristic distribution not only of venue strings, but also of title strings. This encourages merging venue clusters with simi-lar title distributions, even if their distributions over venue strings are somewhat different.

The two different distortion models for titles and venues reflect the fact that we expect different kinds of noise in both types of fields. For observed title strings, we expect that many citations will list the canonical title, while oth-ers have small, weakly correlated typographical errors. For observed venue strings, on the other hand, the edit distance between coreferent strings is much larger: several words may be added or deleted. Furthermore, while it is reasonable to model typos in title strings as independent, in venue strings often several variants appear equally commonly.

The performance of these models depends crucially on ap-proximate inference. We describe inference based on Markov chain Monte Carlo (MCMC) methods, which are compli-cated by the nature of the string-edit distortion model that we use for venue strings. In addition, we compare an MCMC sampler based on Gibbs sampling to a recently-proposed split-merge sampler [8], and find that the split-merge sam-pler performs significantly better.

We evaluate our models on real-world citation data that is specifically designed to be hard for this task. A model that incorporates cross-field dependence performs substan-tially better than a standard DP mixture, yielding a 58% reduction in error over a standard DP mixture, and a 48% reduction in error over a reasonable heuristic baseline.
In this section, we describe our model of venue and title mentions. Each mention m contains a paper X  X  title t m and venue v m , such as from the bibliography of a citing research paper. The task is to determine which venue strings refer to the same underlying venue. The data set as a whole is a set of mentions { ( v m , t m ) } M m =1 . Each venue mention v m is a sequence of words ( v m 1 , v m 2 , . . . v m,N ( v title mention a sequence of words ( t m 1 , t m 2 , . . . t This is an unsupervised problem, in the sense that we are not provided with training mentions which are known to be either duplicates or not.

We describe our model by incrementally augmenting a simple finite mixture model. All of our models are mixture models in which each mixture component is interpreted as an underlying venue. First, we describe a finite mixture model of the venue mentions only, using a string-edit model customized for this task (Section 2.1). Second, we modify this model to allow an infinite number of components by using a Dirichlet process mixture (Section 2.2). Then, we augment this model with title mentions that are drawn from a per-venue unigram model (Section 2.3), modeling a type of cross-field dependence. Finally, we describe a venue-title model in which the titles are drawn from a latent Dirichlet allocation (LDA) model [4] (Section 2.4).
First we describe a finite mixture model, where the num-ber of venues C is chosen in advance. The main idea is that each true entity is modeled by a mixture component, where each component generates canonical strings and ob-served venue strings via a string-edit distortion model. More specifically, the mixture proportions  X  are sampled from a symmetric Dirichlet with concentration parameter  X  . Each cluster c  X  X  1 . . . C } is associated with a canonical venue string x c , which is sampled from a unigram language model with uniform emission probabilities. For each mention, the model selects a venue assignment c m (which is an index into the set of venues) according to the venue proportions  X  .
Finally, we generate the venue mentions v m = v m, 0  X  X  X  v for each mention of each cluster c . The venue mentions are generated by distorting the venue X  X  canonical string x c = x c, 0  X  X  X  x c,b by an HMM string-edit model denoted p ( v m Note that this model conditions on the canonical string of the cluster. The HMM string-edit model has three edit operations: substitute in which a token of the canonical string is replaced by a token of the observed string, in-sert which generates a token of v m , and delete which re-moves a token of x c . Each edit operation corresponds to a single state of the HMM. We choose transition probabil-ities p ( s i = insert | s i  X  1 ) = p ( s i = delete | s p ( s i = substitute | s i  X  1 ) = 0 . 4, so the model disfavors words that occur in only one of the two strings.

Now we describe the emission distributions for each state, that is, the distribution over the tokens that each state in-serts into the observed string. The delete state determinis-tically emits the empty token. The insert state has uniform emission probability over the vocabulary of venue tokens. Finally, the substitute state has a custom emission distribu-tion, to model the fact that acronyms are common in venue strings. If v m,j is the current venue token and x c,i the cur-rent canonical token, then the emission distribution is p ( v m,j | s i,j = substitute , x c,i ) = where a ( w ) is the number of words in the vocabulary that are prefixes of w , and l ( w ) is the number of words for which w is a prefix. Calculating the probability of a canonical string generating a venue mention requires summing over all sequences of edit states, which can be done efficiently using the the forward algorithm for HMMs.

In summary, the finite-mixture model is In this notation, u is a uniform vector over the vocabulary, that is, it is a vector of length V with each element u i Here we write the Dirichlet distribution with two parame-ters, a base measure which we choose to be u , and a scalar concentration parameter  X  , which we choose as described in Section 5.3. The notation Unigram denotes a unigram language model. Essentially, the prior on canonical strings x c is a uniform distribution over strings. This an improper prior, but the posterior is still well-normalized. The graphical model for the finite mixture is shown in Figure 1. This model requires choosing the number of venues in advance, which is undesirable. In the next section, we remove this requirement.
The finite mixture model requires specifying a number of clusters a priori, which is unrealistic. For this reason, recent work in unsupervised coreference [5, 9, 2] has focused on nonparametric models, and in particular the infinite limit of (2), which is the Dirichlet process (DP) mixture. A DP mixture is attractive for two reasons: first, the number of components of the mixture can be inferred from data; and second, samples from the induced cluster identities display a rich-get-richer property that is natural in many domains. For a review of modeling and inference using DPs and DP mixtures, see Teh et al. [17].

Probably the most intuitive way to understand the result-ing distribution over venue strings is the Chinese restaurant process representation. This is a metaphor for describing how samples are drawn from a DP mixture. Here we imag-ine that each venue mention corresponds to a customer at a restaurant that contains an infinite number of tables. Each table c represents a cluster of mentions (in other words, a true venue), and associated with each table is a canonical string x c (the  X  X ish X  served at that table).

Suppose we have a set of mentions that have already been generated at tables 1 . . . C , where each venue c contains N mentions. To generate a new mention, first we generate which table the mention sits at, that is, which true venue is assigned to the mention. This table c m is selected from the following distribution: The parameter  X  &gt; 0 is a parameter of the Dirichlet pro-cess, and affects how likely the model is to generate new tables. If the mention does sit at a new table, then we gen-erate a canonical string for the new venue, from a uniform distribution over strings. Once that the mention has chosen a table c m , it generates an observed venue string v m from the canonical string x c m at that table. The observed string is generated from the string-edit model of the last section. This completes the description of the model.

It can be shown that this model is actually the infinite limit of the finite mixture model, as the number of mixture elements goes to infinity. This is the infinite limit of the graphical model shown in Figure 1 (left).

To describe this more formally, consider a random variable c that ranges over partitions of the integers { 1 . . . M } . The Chinese restaurant process defines a distribution over c  X  X o see this, imagine labeling the customers 1 . . . M . Denote this distribution as CRP(  X  ). Using this representation we can describe the DP mixture model as In the above, c m refers to the index of the set in the partition c that contains the integer m .

The advantage of the DP mixture is that it automatically determines the number of clusters from the data. This state-ment might seem disingenuous, because perhaps we have swapped the problem of selecting the number of clusters for the problem of selecting the parameter  X  . In practice, however, this is typically not an issue, because usually the number of clusters selected by the model is not sensitive to  X  , which indeed is the case in our setting (see Section 5.3).
In the previous section, we presented an infinite mixture model over venue strings. But such a model can be im-proved dramatically by also considering information from paper titles, and demonstrating this is a key contribution of our work. In this section, we present a model that does this. We will call it the DP venue-title model (DPVT) .
The DPVT model jointly clusters venues and titles using a single set of latent variables that control both a string-edit model for the venues and a Dirichlet-multinomial distribu-tion for the titles. Each venue c generates a distribution  X  over title words, in other words, a probability vector with one element for each word in the vocabulary. Every men-tion m now generates all of its title word t mi by a discrete distribution with parameters  X  c m .

This model contains all of the factors in the venue-only model, and in addition: As before, u is a uniform probability vector over the vocab-ulary, and  X  is the concentration parameter of the Dirichlet.
To see how this model incorporates cross-field dependence between venues and titles, consider the graphical model in the middle of Figure 1. Note that although the canonical venues x c and title distributions  X  c are independent in the prior, they are dependent in the posterior, because they are coupled by the c m variables once the mentions are observed.
In the first venue-title model, every venue has a multi-nomial distribution over title words. But we may hope to achieve better performance by using a more flexible model over title strings, for example, one that separates out com-mon words from venue-specific words. Also, such a model allows reporting title words that are strongly associated with particular venues, which may be of interest in itself.
For this reason, in this section we describe an alterna-tive title model in which the titles are generated by latent Dirichlet allocation [4]. One topic is dedicated solely to each venue, and a single  X  X eneral English X  topic is shared across all venues. This is a simple version of the special words model of Chemudugunta, Smyth, and Steyvers [6], so call this model the DP mixture with venues and special-word ti-tle model (DPVSW) .
 This model includes all of the factors of the venue-only DP model, and in addition: Here  X  g is a single corpus-wide distribution over title words, while as before each  X  c is a venue-specific distribution over title words. For each word i of title mention m , this model includes an indicator variable z mi which is 0 if word i was generated from the global distribution  X  g , and 1 if it was generated from the venue-specific distribution  X  c . Each  X  controls how often venue c uses its venue-specific title distri-bution as opposed to the general distribution. The graphical representation of this model is shown in Figure 1.
In this section we discuss two Markov chain Monte Carlo (MCMC) samplers for our models. Given a set of observed venue mentions v = { v 1 . . . v M } , our concern will be to sam-ple from the resulting posterior distribution p ( { x c } , { c over venue assignments c m for each mention and canonical strings x c for each venue. A common choice is to resample each c m using a Gibbs sampler, but this is not straightfor-ward in our models because the distribution p ( v m | x c not conjugate to the prior over canonical strings p ( x c many applications of the DP mixture model, the analogs of those two distributions are conjugate, and in those cases inference is simplified considerably.
First we describe the samplers for the basic DP venue model. The state of the sampler is the set of all cluster indices c = { c m } for each mention m and of canonical strings x = { x c } for each cluster c from 1 . . . C . The main idea is to use a block Gibbs sampler, alternating between sampling the cluster identities and the canonical strings.
The first part of the outer block Gibbs sampler is to sam-ple the cluster identities. For this we use a Metropolis-Hastings step. We consider two different proposals: one which is only a slight modification of the Gibbs sampler (so we call it almost-Gibbs ) and another based on a split-merge proposal. The Gibbs proposal is a modification to Neal [12]. For every mention m  X  X  1 . . . M } , we propose a new cluster c m from the distribution: p ( c  X  m | c  X  m , v , x )  X  That is, if the proposed cluster is one that already exists, the proposal is proportional to the prior p ( c  X  m | c  X  m ) times the probability that the canonical string x c  X  m would be distorted into the observed string v m of the current mention. This is exactly the Gibbs proposal. If the proposed cluster is new, then the proposal is proportional to the prior times the probability that the observed string would be distorted into itself. This is the part that is different from the Gibbs proposal. Ideally, we would sample x c  X  m in this case; Neal [12] suggests using the prior p ( x ), but this would lead to a string that would hardly ever be close to v m . Here we are mainly interested in finding a high-probability configuration, which makes our choice seem reasonable.

The second proposal distribution that we use is the split-merge proposal of Dahl [8]. Here the basic idea is to pick two mentions m and m 0 at random. If the mentions are in different clusters, the proposal merges them. If the men-tions are in the same cluster, the proposal splits that cluster into two, one containing m and one containing m 0 , using a procedure similar to sequential importance sampling.
The second part of the outer block Gibbs sampler is to sample the canonical strings x c . Here we use a Gibbs step, but with the restriction that x c must be identical to one of the observed venue strings in the cluster. This restriction is a slight abuse, but seems to work well in practice. More specifically, let k in 1 . . . N c index the mentions assigned to cluster c . Then the new canonical string x  X  c is sampled from the distribution p ( x  X  c | c , v )  X  where 1 { X  X  X } is an indicator function that enforces the re-striction that canonical strings be somewhere observed.
All the MCMC methods described here require a choice of starting configuration, which can greatly impact their effec-tiveness. We initialize the samplers by placing each venue mention in its own cluster.
For the venue-title model, we use the same samplers as above, except that when we propose a new cluster assign-ment c m we must take into account the distribution over title words, integrating out the mean vector  X  c . Denote by p ( t m | c  X  m , t  X  m ) the probability of the title mention t generated by the proposed cluster, conditioned on the titles of the other mentions in that cluster, and integrating out the distribution  X  c over title words. This probability can be computed using a Polya urn scheme: p ( t m | c  X  m , t  X  m ) = precede word i and are identical to it; and N { t  X  m,c = t the number of occurrences of the token t mi in the other titles t  X  m,c in cluster c ; and V the vocabulary size. Finally, recall that N ( t m ) is the number of words in the title mention t
Now in the almost-Gibbs proposal, we sample a new clus-ter assignment c  X  m from the distribution p ( c  X  m | c  X  m , v )  X  The difference from the venue-only version is the inclusion of the term p ( t m | c  X  m ).
Finally, we describe the modifications to the sampler for the venue-special words title model. For this model, we add to the state of the sampler the indicator variables z m = { z mi } , which for each title word i in mention m , indicate whether the word is to be sampled from the venue multi-nomial with mean  X  c or from the general multinomial with mean  X  g .

The venue-special words model requires two changes to the sampler for the venue-title model. First, we add a step to the outer block Gibbs sampler that resamples all of the z variables given the cluster assignments and canon-ical strings. As before, let t mi be the title word of mention m in position i ;  X  c ( t mi ) be the element of the title mean vector  X  c for the word t mi ; and  X  g ( t mi ) be the analogous quantity in the general English multinomial vector. Then, during the additional Gibbs step, each z mi is sampled from the distribution where z mi = 1 indicates that t mi is sampled from the venue-specific distribution.

The second change is that the proposal distribution in the cluster assignment step changes slightly, because now the distribution over titles depends on z . The new proposal distribution is p ( c  X  m | c  X  m , v , z )  X 
Observe that this Gibbs sampling scheme depends cru-cially on the fact that it is reasonable to change the cluster identity c m but without changing z m . Such a move is in fact reasonable because the semantics of the z m variables do not depend on the venue identity.
The literature on deduplication is extensive. (Ironically, deduplication is also known as coreference, record linkage, and identity uncertainty.) A growing body of work has shown that incorporating global information can improve coreference. For example, McCallum and Wellner [10] show that incorporating transitive closure improves performance over making pairwise coreference decisions independently. Culotta and McCallum [7] have applied similar models to venue coreference, finding that jointly modeling coreference of records and fields improves performance. Additionally, Singla and Domingos [14, 15] perform simultaneous corefer-ence of authors, papers, and venues using conditional undi-rected models, and find a similar improvement. These mod-els are all supervised, so our approaches have the advantage of not requiring labeled training data, although they can readily exploit labeled coreference data if it is available.
Several authors have used DP mixture models for dedu-plication. The general framework of using a per-cluster mix-ture model for coreference of research papers was introduced by Pasula et al. [13]. A more detailed description of a sim-ilar model is given by Milch [11]. These models generate the number of venues from a log normal distribution. A variant of this model which models the venue assignments with a hierarchical DP was reported by Carbonetto et al. [5], although they do not report a comparison with the log normal model. Similarly, Bhattacharya and Getoor [2] use a DP mixture model to perform deduplication of authors in research papers.

None of the models above, however, incorporate cross-field dependencies. For example, in the model of Carbonetto et al., every canonical paper has a true title and distribution over observed title strings, and every canonical author has a distribution over observed author strings. But the model does not represent that canonical authors tend to favor cer-tain words in their canonical titles. Similarly, the Singla and Domingos models [15] do incorporate the constraint that if two paper mentions are identical, then so are the correspond-ing venue mentions. But they do not have weights that say if one title appears in a venue, then distinct titles with similar words are likely to also appear in that venue. The key con-tribution of our work is to explicitly model this cross-field dependence, showing that this leads to dramatically better performance on venue coreference.

Another related model is by Haghighi and Klein [9], which applies DP mixtures to noun-phrase corference, which is the problem of determining which noun phrases in a document refer to the same entity, such as George W. Bush and he . This work is in similar spirit to ours, in that it augments the basic DP mixture with additional variables tailored to a spe-cific coreference task. However, the specifics of their model are very different, because they need to model notions such as that pronouns can only refer to entities of a particular gender, and that more salient entities in the discourse are referred to using different language than less salient ones. In this section, we compare the performance of the various DP mixture models on citation data. We first obtain a list of automatically extracted citations from the Rexa database ( http://rexa.info ). The citations are first segmented au-tomatically using a conditional random field documents into plaintext. This process is imperfect, so the fields contain ex-traction errors as well as the expected typographical errors. The data consists of the resulting were mapped onto venue-title pairs, and duplicate citations (those that were string identical in both fields) were collapsed.

We choose a dozen test venues, and assemble a corpus of about 180 citations per venue, for a total of 2190 cita-tions 1 . Reflecting the coverage of a large-scale digital li-brary, the venues cover a range of topics including: artifi-cial intelligence, machine learning, computational physics, biology, the semantic web, and wearable computing. The venues are also specifically chosen to be hard for the coref-erence task; for example, several venue pairs are included that have string-identical abbreviations. After removal of stopwords and punctuation symbols, there are 262 unique venue strings. Also, in any mention that consists entirely of a string of capital letters, we treat each capital letter as a separate word. This allows the distortion model to more easily align acronyms with their full names.
 We compare four models: (i) the DPV model, which is the Dirichlet process mixture only (Section 2.2), (ii) the DPVT model (Section 2.3), (iii) the DPVSW model (Section 2.4), and (iv) a baseline heuristic STR. In this heuristic, first re-move stopwords such as  X  X n X ,  X  X f X , and  X  X roceedings X , then merge string-identical venues, and finally, merge all venue clusters that contain string-identical titles. For each of the generative models we performed 1000 iterations of block Gibbs sampling. To select the hyperparameters  X  and  X  , we perform a parameter sweep on a separate small valida-tion set.

We measure performance using the B 3 metric of Bagga and Baldwin [1]. For each mention m i , let c i be the set of predicted coreferent mentions, and t i be the set of truly coreferent mentions. The precision for m i is the number of correct mentions of entity i  X  X hat is, those that appear in both c i and t i  X  X ivided by the number of mentions in c i The recall is the number of correct mentions of entity i di-vided by the size of t i . These are averaged over all mentions in the corpus to obtain a single pair of precision and recall numbers. F1 is the harmonic mean of precision and recall.
Coreference performance for each of the four systems is shown in Table 1. The baseline STR heuristic demonstrates the difficulty of performing coreference on this dataset: string identical mentions are not necessarily coreferent, and differ-ent strings often refer to the same venue. The best perfor-
The dataset is available on the web at http://www.cs. umass.edu/~rhall/rexa/ven_coref.zip Table 1: Percent B 3 venue coreference performance for the four systems. The smaller numbers indicate the standard deviation across five independent real-izations of the Markov chain. Figure 2: Comparison of Gibbs and split/merge samplers on the DPVT model. mance overall is obtained by the DPVT system, where we set the concentration over title unigram distributions to be  X  = 0 . 6. This setting has the effect of favoring more peaked unigram distributions over title words, where the peaks cor-respond to words particular to that cluster. These results demonstrate a marked improvement in coreference perfor-mance by modeling the titles of the papers. F1 is increased from 63.8% to 84.9% by adding title modeling to the DP mixture, a 58% error reduction. The error reduction over the STR baseline is 48%.
 The DPVSW model has slightly higher precision than the DVPT model, but at a high cost to recall. Also, the data set contains two venues which share the name  X  X SWC X  (for International Semantic Web Conference and International Symposium on Wearable Computing ), which the DPVSW model is able to disambiguate more accurately, as shown in Table 3. The standard Dirchlet process mixture, on the other hand, will almost always merge identical venue strings. Shown in Table 2 are some example per-venue distribu-tions over words that were generated by the DPVSW model. While common words such as X  X  X  X nd X  X or X  X re highly weighted in these clusters, so are less frequent venue-specific words.
We test statistical significance using a stratified bootstrap sampler. Namely, we bootstrap a confidence interval for the B 3 F 1 of all the methods by, for each true venue V with n v mentions, we sample n v new mentions from V uni-formly with replacement. The performance difference be-tween DPVT and STR is highly significant ( p &lt; 0 . 01). Document Analysis and Recognition .
 Benchmarking DAML+OIL Repositories
TRIPLE -A Query, Inference, and Trans-formation Language for the Semantic Web.
 Figure 3: Sensitivity of DPVT model to title-Dirichlet parameter  X  .
We also compare the split-merge and Gibbs proposal dis-tributions, described in Section 3.1. Although in the infinite limit both techniques sample from the same distribution, for finite sample sizes one sampler might converge significantly faster to the posterior. The split-merge sampler that we use [8] has been relatively recently proposed, and has not to our knowledge been used for DP models of coreference, so it is interesting to see if it performs better than more typical inference algorithms. We measure this by the B 3 perfor-mance after each iteration of both samplers. This is shown in Figure 2. Clearly, the samples from split-merge perform much better than those of Gibbs sampling. The split-merge sampler at 300 iterations finds venue assignments that are comparable to those of the Gibbs sampler at 1000 iterations.
Interestingly, however, the split-merge sampler shows the greatest benefit for the DPVT model (see Table 4). For the other models, the improvement due to the split-merge sampler is modest.
 Table 4: Comparison of B 3 F1 performance between the two proposals used in Metropolis Hastings sam-pling. Means and standard deviations are computed from 5 independent trials.
There are two hyperparameters that must be tuned in the DP venue-topic models: the strength parameter  X  of the DP prior, and the concentration parameter  X  that con-trols how similar the per-venue title distributions are across venues. We choose these parameters by parameter sweep on a small development set of 200 mentions and 4 venues. (This is about 10% of the size of the test set.) The results of the parameter sweep are shown in Figure 3. The model is somewhat sensitive to the choice of the concentration  X  of the title Dirichlet prior. It is possible to sample  X  based on the training data [16], so that no labeled validation set is required, but we leave that to future work.

The model is, however, not sensitive to choice of the DP parameter  X  (not shown in the figure). Over 2 orders of mag-nitude, taking  X   X  X  0 . 01 , 0 . 1 , 1 . 0 } yields comparable perfor-mance (85 . 9, 84 . 9, and 85 . 6 F1 respectively).
We present an unsupervised nonparametric Bayesian model for coreference of research venues. Although related models have been applied to coreference of paper titles and authors, research venues have several unique characteristics that war-rant special modeling. By exploiting the fact that research venues have a characteristic distribution over titles, we ob-tain a dramatic increase in performance on venue corefer-ence. In particular, the model is even able to accurately split up venues that have string-identical abbreviations.
Several directions are available for future work. First, if labeled training data is available, then this model readily lends itself to semi-supervised prediction. This could be necessary to match the performance of discriminative coref-erence systems. It would also be interesting to extend this model to deduplicate papers and authors.
 This work was supported in part by the Center for Intel-ligent Information Retrieval, in part by Lockheed Martin through prime contract #FA8650-06-C-7605 from the Air Force Office of Scientific Research, in part by The Central Intelligence Agency, the National Security Agency and Na-tional Science Foundation under NSF grant #IIS-0326249, and in part by the Defense Advanced Research Projects Agency (DARPA), through the Department of the Interior, NBC, Acquisition Services Division, under contract number NBCHD030010, and AFRL #FA8750-07-D-0185. Any opin-ions, findings and conclusions or recommendations expressed in this material are the authors X  and do not necessarily re-flect those of the sponsor. [1] A. Bagga and B. Baldwin. Algorithms for scoring [2] I. Bhattacharya and L. Getoor. A latent dirichlet [3] I. Bhattacharya and L. Getoor. Collective entity [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [5] P. Carbonetto, J. Kisynski, N. de Freitas, and [6] C. Chemudugunta, P. Smyth, and M. Steyvers.
 [7] A. Culotta and A. McCallum. Joint deduplication of [8] D. B. Dahl. Sequentially-allocated merge-split sampler [9] A. Haghighi and D. Klein. Unsupervised coreference [10] A. McCallum and B. Wellner. Conditional models of [11] B. Milch. Probabilistic Models with Unknown Objects . [12] R. M. Neal. Markov chain sampling methods for [13] H. M. Pasula, B. Marthi, B. Milch, S. Russell, and [14] P. Singla and P. Domingos. Multi-relational record [15] P. Singla and P. Domingos. Entity resolution with [16] Y. W. Teh. A hierarchical Bayesian language model [17] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. [18] B. Wellner, A. McCallum, F. Peng, and M. Hay. An
