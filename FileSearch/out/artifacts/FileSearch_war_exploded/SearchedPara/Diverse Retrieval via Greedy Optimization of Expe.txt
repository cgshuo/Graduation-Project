 It has been previously observed that optimization of the 1-call@ k relevance objective (i.e., a set-based objective that is 1 if at least one document is relevant, otherwise 0) em-pirically correlates with diverse retrieval. In this paper, we proceed one step further and show theoretically that greedily optimizing expected 1-call@ k w.r.t. a latent subtopic model of binary relevance leads to a diverse retrieval algorithm sharing many features of existing diversification approaches. This new result is complementary to a variety of diverse retrieval algorithms derived from alternate rank-based rele-vance criteria such as average precision and reciprocal rank. As such, the derivation presented here for expected 1-call@ provides a novel theoretical perspective on the emergence of diversity via a latent subtopic model of relevance  X  X nidea underlying both ambiguous and faceted subtopic retrieval that have been used to motivate diverse retrieval. H.3.3 [ Information Search and Retrieval ]: Retrieval Models Algorithms diversity, set-level relevance, maximal marginal relevance
One of the basic tenets of set-b ased information retrieval is to minimize redundancy, hence maximize diversity, in the result set to increase the chance that the results will con-tain items relevant to the user X  X  query [9]. Hence, diverse retrieval can be defined as a set-level retrieval objective that takes into account inter-document relevance dependences when producing a result set relevant to a query.

Subtopic retrieval  X   X  X he task of finding documents that cover as many different subtopics of a general topic as pos-sible X  [19]  X  has often been noted as a motivating case for diverse retrieval. That is, if a query has multiple facets that should be covered by a result set, or a query has multiple ambiguous interpretations, then a retrieval algorithm should try to  X  X over X  all of these subtopics in its result set. It is this subtopic-based motivation for diverse retrieval  X  a motiva-tion which also underlies the TREC 6-8 Interactive tracks and TREC 2009-2010 Diversity subset of the Web tracks 2  X  that we draw on for the latent subtopic binary relevance model presented in this paper.

If one wants to optimize a result set to cover all possible query subtopics, the question naturally arises as to what set-level relevance objective should be optimized? Wang and Zhu [17] have shown that natural forms of diversification arise via the optimization of average precision [3] and recip-rocal rank [15]. While these results directly motivate diverse retrieval via rank-based (ordered set) relevance criteria, they do not use the subtopic motivation for diversity. We use this alternate subtopic motivation in this paper, where we define binary relevance via a latent subtopic model .Withthisdefi-nition of relevance, we then optimize the expectation of the n -call@ k set-based relevance criteria (specifically for n that takes the value 1 if at least n of k documents in a result set are relevant and 0 otherwise [6]. We conjecture that an optimal result set w.r.t. this objective and relevance model will attempt to cover all subtopics in order to ensure that at least one document is relevant, hence yielding diversity.
One may ask why we focus on the n -call@ k metric with n = 1 rather than n&gt; 1 for diverse retrieval? In [16] (Figure 2c), Wang and Zhu observed that optimizing 1-call@ k cor-relates most strongly with diverse retrieval, while as n  X  k retrieval becomes less diverse. The reasons for this are sim-ple: as n  X  k , a higher proportion of documents are required to be relevant; if the top-ranked document is deemed most relevant, similar documents are also likely to be relevant, discouraging diversity. At the other extreme, n =1encour-ages diversity since only one relevant document is needed. http://www-nlpir.nist.gov/projects/t8i/t8i.html http://trec.nist.gov/data/web09.html (also web10 ) Figure 1: Latent subtopic binary relevance model.

In the rest of this paper, we derive a diverse retrieval al-gorithm via greedy optimization of expected 1-call@ k in a latent subtopic binary relevance model and compare it to a variety of existing diversification approaches.
Given an item set D (e.g., a set of documents) where retrieved items are denoted as s i  X  D , we aim to select an optimal subset of items S  X  k  X  D (where | S  X  k | = k k&lt; | D | ) relevant to a given query q (e.g., query terms). For computational efficiency, we will build S  X  k in a greedy manner by choosing the next optimal selection s  X  k given the previous set of optimal selections S  X  k  X  1 = { s  X  1 ,...,s  X  recursively defining S  X  k = S  X  k  X  1  X  X  s  X  k } with S  X 
One of the most popular result set diversification methods is Maximal Marginal Relevance (MMR) [4] that chooses s  X  k greedily according to the following criteria: s =argmax Here, similarity metric Sim 1 measures query-item relevance, metric Sim 2 measures the similarity between two items, and the parameter  X   X  [0 , 1] trades off relevance and diversity. In the case of s  X  1 , the maximization term is vacuous (=0). We take special note of this form for MMR optimization since the results we derive next will bear a close resemblance.
To begin the derivation, we provide a directed graphical model in Figure 1 to formalize the independence assump-tions in a probabilistic subtopic model of binary relevance. Shaded nodes represent observed variables while unshaded nodes are latent. The observed variables are the vector of query terms q and selected items s i (where for 1  X  i  X  k s i  X  D ). For the subtopic variables, let T be a discrete subtopic set. Then variables t i  X  T represent subtopics for respective s i and t  X  T represents a subtopic for query q . The r i are binary variables indicating whether the respective selected items s i are relevant (1) or not (0).
 The conditional probability tables (CPTs) are as follows: P ( t i | s i )and P ( t | q ) respectively represent the subtopic dis-tribution for item s i and query q . The remaining CPTs are for relevance variables r i ,whereitem s i is deemed relevant ( r i =1) iff its subtopic t i matches query subtopic t : Here, I [  X  ] is 1 when its argument is true and 0 otherwise. We now formally define the expected 1-call@ k objective:
Exp-1-Call@ k ( S k , q )= E
Since jointly optimizing Exp-1-Call@ k ( S k , q )isNP-hard, we take a greedy approach similar to MMR where we choose the best s  X  k assuming that S  X  k  X  1 is given. Then following [6], we can greedily optimize this objective as follows: 3 s =argmax =argmax =argmax =argmax =argmax =argmax
Here, we applied a logical equivalence, exploited additivity of exclusive events, rewrote the expectation of a binary event as its probability, exploited d-separation to remove irrelevant conditions, factorized each joint into a conditional and prior, and removed terms and factors independent of s k .Thus,we need only maximize s k  X  X  probability of relevance conditioned on the query and previous selections (assumed irrelevant).
Next we evaluate the final query from (3) w.r.t. our graph-ical model of subtopic relevance from Figure 1: s =argmax =argmax =argmax =argmax Defining  X  P ( t | S  X  k  X  1 )=1  X  =1  X  this is the probability that set S  X  k  X  1 already covers topic w.r.t. a noisy-or interpretation. Substituting (1  X   X  P ( for since (1  X   X  P ( t | S  X  k  X  1 )) = 1  X  (1  X  )= ,weobtain
This final result in (4) has a clear interpretation as a di-verse information retrieval algorithm where D consists of
The notation { X } C refers to a (possibly empty) set of vari-ables (or variable assignments)  X  that meet constraints C Figure 2: MMR vs Exp-1 -call@ k on subtopic recall. documents: at each step, s k is chosen so as to maximize a similarity function while minimizing a diversity penalty that increases as S  X  k  X  1  X  X  coverage of query-relevant subtopics in document s k increases. Thus we have achieved our goal of deriving a diverse retrieval algorithm via optimization of Exp-1-call@ k in a latent subtopic model of binary relevance.
The result in (4) is strikingly similar to MMR  X  it con-tains two terms, one for query similarity and the other for result set diversification, where each term represents a simi-larity kernel  X  more specifically a probability product kernel (PPK) [11] that is an inner product of probability vectors (or more generally, functions). More formally, let T , T k ,and T
S  X  k  X  1 be respective topic probability vectors P ( t = P ( each topic t  X  T . Then the similarity and diversity terms from (4) can be respectively written as
X Here, we let  X  ,  X  denote an inner product of two vectors and  X  ,  X  v a v -reweighted inner product, defined as in (6). While having similarity and diversity terms similar to MMR, Exp-1-call@ k in (4) clearly differs from MMR: 1. While MMR X  X  definition allows for any similarity func-2. MMR uses a maximization term for diversity, whereas 3. While MMR proposes a  X  term to explicitly trade off 4. Optimizing Exp-1-call@ k introduces query-specific rel-
To verify whether the differences between MMR and Exp-1-call@ k matter empirically, we compare the two algorithms across a number of metrics on three diversity testbeds: the TREC 6-8 Interactive Track 1 (17 queries) and 2009 and 2010 ClueWeb Diversity tasks of the TREC Web Track 2 (50 queries each). On these testbeds, we evaluate mean subtopic recal l@ k [19] (fraction of total annotated aspects/subtopics covered by a result set at rank k , averaged over queries), which is an appropriate loss function for the set-level met-ric (2) [6]. We also evaluate a variety of more recent rank-based diversity evaluation metrics such as intent-aware ex-pected reciprocal rank (ERR-IA@ k )[5],  X  -nDCG@ k [7], and intent-aware mean average precision (MAP-IA) [1].

We use MMR with  X  =0 . 5 to match the equal weighting of similarity and diversity in Exp-1-call@ k . An LDA [2] topic model is trained on the top-100 OKAPI BM25 [12] results for each query (on its respective collection) and these subtopic distributions are used for the similarity and diversity ker-nels in both algorithms: for MMR we choose Sim 1 and Sim 2 kernels as in (5)  X  effectively LDA variants of latent seman-tic indexing (LSI) [8] kernels; for Exp-1-call@ k ,weusethe similarity and diversity kernels respectively defined in (5) and (6). Both MMR and Exp-1-call@ k are used to rank the top-20 documents from the top-100 OKAPI BM25 results.
Results in Table 1 and Figure 2 show the performances of MMR and Exp-1-call@ k on the three diversity testbeds across various diversity measures; although there are minor performance differences, we note that these differences are not statistically significant w.r.t. 95% confidence intervals. Nonetheless, the results appear to indicate that the struc-tural similarities in the use of MMR and the optimization of Exp-1-call@ k outweigh the differences in this evaluation.
Recent years have seen numerous proposals for diversifi-cation approaches and here we summarize the relationship between optimization of Exp-1-call@ k and representatives of these alternative approaches: Portfolio Theory: [16] motivates diversification in set-based information retrieval by a risk-minimizing portfolio selection approach. Viewing a result set as an investment portfolio with the objective to maximize return while mini-mizing risk, the derived result of [16] mimics both MMR and Exp-1-call@ k in that the similarity term may be viewed as expected portfolio payoff (relevance) and the diversity term may be viewed as expected portfolio risk ,whichincreases as the correlations between documents in the result set in-crease. One major difference in this framework is that rather than computing the diversity term via a max (MMR) or product (Exp-1-call@ k ) the portfolio theory derivation uses a summation  X  we examine the implications of this next. Set Covering: Yue and Joachims [18] propose a set cov-ering approach for training SVMs to predict diverse result sets for information retrieval. In their work, they equate subtopics with words and build a loss function for SVM training that penalizes result sets according to the sum of weights of query-relevant words not covered by the result set. While their approach provides a  X  X ard X  set-covering view of diversity, we note that an expansion of  X  P ( t | S  X  used in the diversity term of (4) provides a  X  X oft X  latent set-covering interpretation; that is, s k is chosen so as to best cover (in a probabilistic sense) the latent topic space not product in  X  P ( t | S  X  k  X  1 )= terms and writing it as a series, we arrive at a form that re-flects the inclusion-exclusion principle applied to the calcula-tion of probability that topic t is covered by { s  X  1 ,...,s  X 
This result has a natural interpretation: the first summa-tion term determines the coverage of topic t by each docu-ment s i (1  X  i  X  k  X  1) currently in the result set, the second double summation term corrects the first term by removing the joint probability mass from all pairs of documents that was double counted, and so on according to the principle of inclusion-exclusion. (7) not only provides a probabilistic set covering view of Exp-1-call@ k , but it also suggests that a portfolio approach to diversity using only the first summa-tion would overcount each document X  X  contribution to the diversity metric according to t his set covering perspective. Subtopic Relevance Models: We use a subtopic rele-vance model that is a simplified version of the model in [10] with fewer dependence assumptions. In other work, Zhai et al [19] present an empirical risk minimization view of depen-dent document retrieval from a subtopic perspective, where they derive a formalization of the greedy selection step that is similar to MMR and to a lesser extent, Exp-1-call@ k . Set-based Relevance Objectives: Chen and Karger [6], whose derivation we extended, directly optimize 1-call@ k but their intention is not to formalize MMR and instead use na  X   X ve Bayes to directly evaluate (3). Agrawal et al [1] and Santos et al (xQuad) [14] both specify set-based diver-sity metrics very similar to Exp-1-call@ k but do not provide formal derivations as we have done in this work.
 Ranking Based Objectives: Finally, returning to our in-troductory motivation, Wang and Zhu [17] have shown that natural forms of result set diversification arise via the op-timization of average precision [3] and reciprocal rank [15]. Both of these methods share the view of directly optimiz-ing a ranking-based objective, whereas this paper proposes a novel derivation from the alternate view of optimizing a set-based objective w.r.t. a subtopic model of relevance. How-ever, even though Exp-1-call@ k is a set-based objective, an indirect consequence of (and motivation for) greedily opti-mizing it is that documents added earlier yield a greater increase in objective than those added later; this yields a natural rank ordering on the greedy Exp-1-call@ k result set.
This paper presented a new derivation of diverse retrieval by directly optimizing the expected 1-call@ k set-based re-trieval objective w.r.t. a latent subtopic model of binary relevance. This result both motivates and contrasts with various related diversification approaches, providing a new theoretical basis for the investigation of diverse retrieval. [1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [3] C. Buckley and E. M. Voorhees. Evaluating evaluation [4] J. Carbonell and J. Goldstein. The use of MMR, [5] O. Chapelle, D. Metzler, Y. Zhang, and P. Grinspan. [6] H. Chen and D. R. Karger. Less is more: Probabilistic [7] C.Clarke,M.Kolla,G.Cormack,O.Vechtomova, [8] S.Deerwester,S.T.Dumaisand,G.W.Furnas,T.K.
 [9] W. Goffman. On relevance as a measure. Information [10] S. Guo and S. Sanner. Probabilistic latent maximal [11] T. Jebara, R. Kondor, and A. Howard. Probability [12] S. Robertson and S. Walker. Some simple [13] G. Salton and M. McGill. Introduction to modern [14] R. L. Santos, C. Macdonald, and I. Ounis. Exploiting [15] E. M. Voorhees. TREC-8 question answering track [16] J. Wang and J. Zhu. Portfolio theory of information [17] J. Wang and J. Zhu. On statistical analysis and [18] Y. Yue and T. Joachims. Predicting diverse subsets [19] C. Zhai, W. W. Cohen, and J. Lafferty. Beyond
