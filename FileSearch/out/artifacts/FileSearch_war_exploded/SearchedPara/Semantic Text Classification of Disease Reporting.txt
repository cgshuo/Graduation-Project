 Traditional text classification studied in the IR literature is mainly based on topics. That is, each class or category represents a particular topic, e.g., sports, po litics or sciences. However, many real-world text classification problems require more refined classification based on some semantic aspects. For example, in a set of documents about a particul ar disease, some documents may report the outbreak of the disease, some may describe how to cure the disease, some may discuss how to prevent the disease, and yet some others may include all the above information. To classify text at this semantic level, the traditional  X  X ag of words X  model is no longer sufficient. In this paper, we report a text classification study at the semantic level and show that sentence semantic and structure features are very useful for such kind of classification. Our experimental results base d on a disease outbreak dataset demonstrated the effectivene ss of the proposed approach. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  search process; H.4.m [ Information Systems Applications ]: Miscellaneous Algorithms, Experimentation. Semantics, Text Classification. In traditional topic-based text cla ssification, the  X  X ag of words X  representation of text documents is often sufficient because a topic can usually be characterized by a set of topic-specific keywords [6]. However, for sema ntic text classification, single word or even n-gram representa tions are no longer sufficient. The system needs to capture some semantic characteristics of the text from different classes in order to perform more accurate classification. In this paper, we propose to combine the  X  X ag of words X  scheme and se mantic features for semantic text classification . As a case study, we investigate the disease domain. That is, we want to classify sentences which report disease outbreaks and sentences that do not. For example, the following sentence reports a possible disease outbreak  X  10 people were diagnosed with cholera in the district hospital early today  X . The following sentence does not report an outbreak,  X  the district hospital reported today that their new cholera treatment procedure had been very successf ul in treating 120 cholera patients around the country  X . Both sentences are on the topic of cholera. However, semantically they are quite different. The problem is how to separate sentences based on the required semantic aspects or categories, i.e., reporting a possible outbreak or not reporting a possible outbreak in this case. We note that sentences rather than documents are used here because a document contains a large number of sentences and each sentence has a quite different semantic meaning. Classifying at the document level is less meaningful . Classifying at sentence or passage level is more appropriate. In this paper, we focus on the sentence level. We should also note that a sentence can belong to many semantic categories. Fo r example, the second sentence above can belong to such categor ies as  X  X ospital research X ,  X  X holera treatment X , and  X  X uccess st ories of the district hospital X . To our knowledge, limited research has been done on semantic text classification, and yet it is very important for practical applications. This paper shows that both words used in sentences and sentence semantic characteristics are important. Our experimental results confirm that their combination produces more accurate classifiers than each of them alone. As indicated above, we use both wo rds and semantic features for model building. Since words are used in the same way as in traditional classification, we will not discuss it further. Below, we only focus on the semantic features used in our task. Five categories of semantic features are extracted from the dependency tree of a sentence: center noun , center verb , adjective , modifiers of the center noun , and modifiers of the center verb . The dependency tree of a sentence is generated using MINIPAR [2]. In order to recogni ze infectious disease names, we complemented the standard MINIPAR data with infectious disease names. Figure 1 shows an example dependency tree (dependency trees have been used for paraphrasing in information extraction area [5]). This dependency tree is generated from sentence  X  Belgium has reported three cases of mad cow disease  X . ACM 978-1-59593-597-7/07/0007. Figure 1. An example dependency tree. In a dependency tree, arrow point s from the parent node toward the node that the parent node governs. Note that the disease name  X  X ad cow disease X  is a named en tity, so it is represented by a single node in spite of that it has three literal words. The center noun is the center noun word of the noun phrase containing an infectious disease name; the center verb is the verb governing the center noun. They form the basic skeleton of a sentence or phrase, and play the most important role in the sentence X  X  semantic meaning. For example, in sentence  X  Belgium has reported three cases of mad cow disease  X , the noun phrase containing the infectious disease (mad cow disease) is  X  three cases of mad cow disease  X , so the center noun is  X  cases  X , and the center verb is  X  reported  X . The center noun word or the center verb word is not used directly as f eatures; instead, we have manually compiled noun clusters and verb clus ters. Each cluster contains a group of similar words. For ex ample, a noun cluster contains  X  X ase X ,  X  X eport X , and  X  X nstance X . Each cluster is non-overlapping with other clusters. The cluster that a center noun or a center verb belongs to is actually used as its feature value. The adjective word below the center verb and above the center noun in a dependency tree is used as the third feature. For example, in  X  Thirteen employees are se riously ill with diarrhea  X , the center verb is  X  are  X  and the adjective word is  X  ill  X . Similarly, the adjective words are consolidated using precompiled adjective clusters. The adjective word is us ed together with the center verb to help refine the verb X  X  meaning, especially when the center verb such as different forms of the verb  X  be  X  is too general to contain a specific meaning. Finally, the following modifiers to the center noun and the center verb are used: negative modifiers to the center noun such as  X  X o X  and  X  X ero X , negative modifiers to the center verb such as  X  X ot X  and  X  X ever X , and modifiers to the center verb showing a subjunctive mood such as  X  X ould X  and  X  X ould X . The subjunctive mood is commonly used in desc ribing something not happened, but expected to happen, and negativ e modifiers are widely used to negate. Hence, these modifiers are often critical for determining whether a sentence is actually describing a fact, e.g., a disease outbreak, or it is just giving a hypothesis or negating a fact. If any feature described above is present in the dependency tree, it is included as a semantic feature. Note that a center noun is always present, and if an infec tious disease name is a center noun itself, then a special value is used for the feature. There are some cases that one sentence can ge nerate multiple instances of semantic features, which is because one sentence may mention multiple infectious disease names. We now report the experimental re sults. Our dataset consists of sentences related to a set of infectious diseases. Some report outbreaks and some do not, but still contain various disease names of interest. The sentences are extracted from disease reporting documents obtained from ProMED-m ail [4]. We manually labeled the sentences. Our experimental dataset consists of 604 emerging disease reporting (EDR) sentences and 1533 non-emerging disease reporting (Non-EDR) sentences. Table 1 gives the average results of precision, recall and F of various techniques. The aver ages are obtained from 6 random runs of each algorithm with 90% as the training data and 10% as the testing data in each run. Sentence features (denoted by sentences in the table) are standard word terms, i.e., they are stemmed and with stopwords rem oved. We observe that sentence semantic features (denoted by S-features in the table) are very useful. Both SVM (with linear kernel) and NB (na X ve Bayes) produce better results when sentences and semantic features are both used. NB using both sentences and S-features produces the best F 1 -score, 70.2%. Using sentences or S-features alone produce much lower F 1 -scores. Using S-feature alone, NB outperforms SVM. All tests reported in the ta ble were done using Rainbow [3] and SVM-light [1], based on 1-gram (the traditional  X  X ag of words X  model) for sentences. We al so experimented with 2, 3 and 4-grams with poorer results. Note that the combination of sentence features and S-features is done by simply appending S-features from each sentence to the sentence (with equal weights). SVM (S-features) 667 0.588 0.437 0.500 SVM (sentences) 6098 0.567 0.615 0.590 SVM (sentences + S-features) NB (S-features) 667 0.644 0.497 0.557 NB (sentences) 6098 0.656 0.669 0.662 NB (sentences + S-features) In this paper, we studied the se mantic classification of disease outbreak sentences, which shed some light on the general issue of semantic text classification. Ou r preliminary results show that sentence semantic and structure features are useful in improving classification accuracy. In our future work, we plan to improve the accuracy further and also study the general problem. This project is funded by Great Lakes Protection Fund. We thank Karl Rockne for useful discussions. [1] Joachims, T. Making large-Scale SVM Learning Practical. [2] Lin, D. and Pantel, P. Discovery of Inference Rules for [3] McCallum, A. K. Bow: A toolkit for statistical language [4] ProMED-mail. &lt;http://www.promedmail.org&gt;, 2007. [5] Shinyama, Y., and Sekine, S. Paraphrase Acquisition for [6] Yang, Y. and Liu, X. A re-examination of text categorization 
