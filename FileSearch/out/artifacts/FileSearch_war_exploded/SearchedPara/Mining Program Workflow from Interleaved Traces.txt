 Successful software maintenance is becoming increasingly critical due to the increasing dependence of our society and economy on software systems. One key proble m of software maintenance is the difficulty in understanding the evolving software systems. Program workflows can help system operators and administrators to understand system behaviors a nd verify system executions so as to greatly facilitate system maintenance. In this paper, we pro-pose an algorithm to automatica lly discover program workflows from event traces that record system events during system execu-tion. Different from existing wo rkflow mining algorithms, our approach can construct concurrent workflows from traces of inter-leaved events. Our workflow mining approach is a three-step coarse-to-fine algorithm. At first, we mine temporal dependencies for each pair of events. Then, based on the mined pair-wise tem-poral dependencies, we construc t a basic workflow model by a breadth-first path pruning algorithm. After that, we refine the workflow by verifying it with all training event traces. The re-finement algorithm tries to find out a workflow that can interpret all event traces with minimal state transitions and threads. The results of both simulation data a nd real program data show that our algorithm is highly effective. H.2.8 [ Database Management ]: Database Applications X  Data Mining ; D.2.1 [ Software Engineering ]: Requirements/ Specifica-tions  X  Tools Algorithms, Experimentation Workflow mining, graphical behavi or models, temporal properties With the increasing dependence on so ftware at all levels of our society and economy, software maintenance is becoming increa-singly critical. A key technical issue of software maintenance is the difficulty in understanding what happens to systems (and software) over time [18], e.g. ab out 50% of the maintenance cost is due to comprehending or unders tanding the code base. Program workflow can help operators and developers to understand system behaviors, to verify the system execution, and to validate the run-ning results. For example, Mariani et al. [6] indentify incompati-bilities and illegal interactions of a reused component by compar-ing its interaction workflow in the new context with that in the original system. Unfortunatel y, the knowledge of program workflow is not always available to hand. This is because soft-ware documents and specifications are often not complete, accu-rate and updated due to bad deve lopment management and tight schedule (e.g. hard product shippi ng deadlines and  X  X hort-time-to-market X ). Therefore, there is a great demand of building automatic tools for mining workflows for programs. Our motivating application is in the area of program dynamic analysis where program event traces are analyzed to mine pro-gram workflows. There are a set of existing research efforts [1, 2, 4, 5, 6, 8, 10] on mining program workflows. Most of them are variants of the classical k-Tails algorithm [2]. They learn a finite state automaton (FSA) from event traces. However, these k-Tails based algorithms cannot perform well in a complex system, in which multiple independent threads/processes generate traces of interleaved events. Because the events can be interleaved in many different ways, and a k-Tails base d algorithm tries to interpret a huge number of event sequencing patterns, the resulting FSA model often becomes very complex. Because of this, the k-Tails based algorithms assume that the traces contain thread IDs and can be analyzed thread by thre ad [6]. Although most software programs produce traces with thread IDs, there are still some ex-isting systems that do not record thread IDs in their logs or traces by default. More important, most advanced software programs are designed and implemented based on event driven architecture, in which the flow of the program is determined by events [11]. In most event driven systems, a task X  X  workflow is divided into sev-eral stages or subtasks, and each subtask is related to an event which is handled by an event handler. In these systems, a thread usually handles many different events from multiple concurrent tasks, and these events often interleave with each other. Therefore, even given the thread IDs, we still cannot learn a task workflow from the traces of such an event driven system by a k-Tails based algorithm. In this paper, we present an algorithm to discover a program workflow model from traces of interleaved events by a three-step coarse-to-fine algorithm. At first, we mine temporal dependencies for each event pair from event traces. The dependencies that we mined are always valid under any event interleaving patterns. Rather than directly constructing the workflow from the input event traces, we construct a basi c workflow model from the mined dependencies. Then, based on the different properties between a loop/shortcut structure and a thr ead spawn/sync structure, we design an algorithm to refine th e basic workflow. The refinement algorithm can find the simplest wo rkflow with a minimal number of thread types to interpret all event traces. Our approach works quite well on traces of interleaved events. To the best of our knowledge, the paper is the first work to learn workflows from traces of interleaved events produced by concurrent programs. The rest of the paper is organize d as follows. In section 2, we briefly introduce the previous work that is closely related to ours. Section 3 provides the basic ideas and concepts of our approach. In section 4, we describe an al gorithm to mine temporal depen-dencies from event traces. The detailed algorithm on constructing a workflow model based on mine d temporal dependences is pre-sented in section 5. In section 7, we validate the approach with some experimental results on bot h simulations and real event traces. Finally, we conclude the paper in section 8. There are a set of existing research e fforts [1, 2, 4, 5, 6, 8, 10, ] on learning program workflow models from execution traces for software testing and debugging. In these algorithms, Finite State Automatons (FSA) are used as workflow models. These algo-rithms are mostly extended fro m the popular k-Tails algorithm proposed by Biermann and Feldman [9]. At first, the algorithm constructs an initial FSA from input traces, and then it progres-sively refines the FSA by mergi ng equivalent states until no fur-ther merge operation is possible. Different algorithms [6, 10] use different equivalent criteria to derive different FSA depending on different desired degree of genera lization. For example, in the k-strings algorithm [10], if two states  X   X  and  X   X  generate the same k-strings (i.e. symbol sequences of length up to k that can be gener-ated from the state), they are merged. The learner modifies the k-Tails algorithm by comparing how likely two states are to gener-ate the same k-strings. L. Mariani et al [6] also proposed an in-cremental FSA learner, namely k-Learner, by modifying the k-Tails with a new merge operation. The algorithm identifies subse-quences of a new trace in the cu rrent FSA, and augments the FSA to include the new trace. Beside s the state equivalence conditions, some recent algorithms also introduce other pre-conditions for the merge operation. In [2], two equivalent states  X   X  be merged when the merged FSA does not break a set of temporal patterns that are automatically mined from the training traces. A similar steering idea is also proposed by Walkinshaw et al [8], in which user defined Linear Tempor al Logic (LTL) rules are used to determine whether two equivalent states can be merged. All these k-Tails based algorithms assume that the event traces are sequential traces [6]. However, many workflows exhibit concur-rent behavior, where a single event trace comprises a set of events produced by more than one thread of control. The sequential state machine model cannot capture the concurrent behavior of a sys-tem, and the k-Tails based algorithms will create a very complex model as they try to interpret all event sequencing patterns gener-ated by the interleaved events. Unlike these, our algorithm learns workflow models from traces of interleaved events. Some re-searches [26, 27, 28, 29, 30, 31] on mining temporal patterns from program traces are highly related to our work too. For example, Javert [28] learns simple generic patterns, such as the alternating pattern ((ab)  X  ) and the resource usage pattern ((ab  X  c)  X  ), and com-poses them using two simple rule s to construct large, complex specifications. In this paper, we construct a basic workflow model by composing simple temporal dependency patterns. The similar concept can also be found in [27]. Another set of research efforts [3, 7, 12, 13, 14, 15, 16, 17] from the area of Business Intelligence [12] are also related to our work. Rather than software system traces, they try to mine business processes (or workflows) from business activity logs. In business workflow mining algorithms, di fferent from FSA models, a process is often represented by a graph in which nodes correspond to the activities to be performed, and arcs describe the precedence or dependent relationships among th e activities. Fo r example, the authors of [14] use a directed acyclic graph (DAG) to model a workflow process. In [3] and [7 ], a constrained DAG, namely an AND/OR workflow graph (AO gra ph), is proposed to model a workflow process. Aalst et al [15] use a special class of Petri-net model, namely workflow nets (WF-net) , to model a workflow process. Among these models, the WF-net is the most powerful model that can be simplified to other models by adding some constraints. Although the busine ss process mining and software workflow mining algorithms have different application back-grounds and models, they share the same basic idea, i.e. construct-ing constrained graphic activity m odels from traces [13], and they can leverage each other [17]. For example, we can construct a DFA to mimic the beha viors of a DAG based model. Almost all business workflow mining algorithms consider the parallel prop-erty of different tasks by introducing AND split/join nodes [3, 7, 13, 14], fork/join places [12, 15, 17], or Parallel operators [16]. In order to handle the concurrent ta sk problem, similar to our ap-proach, these algorithms reconstruct the workflow graph by utiliz-ing the dependent or causal re lationships mined from workflow activity logs. For example, in [15], Aalst et al only use the order-ing relation  X   X   X   X  that describes whether on e is directly followed by the other in a trace, to discover a WF-net. Cook et al [17] use more information, such as event type counts, event entropy, and event periodicity, and combine the information into a ranking score to discover the concurrent behavior in event streams. How-ever, all of these approaches assume that an input log sequence is produced by a single case in isolation [15, 17], and they cannot handle an interleaved log sequence generated by multiple concur-rent executions of the same workflow (e.g. an event trace is pro-duced by a WF-net workflow if there are two or more tokens in the start place of a WF-net). In a ddition, their models also do not allow that multiple concurrent threads run the same sub-workflow [15, 17]. However, in a parallel ed program, a job may often be divided into several concurrent s ub-tasks, with each sub-task hav-ing the same workflow. For example, a MapReduce job is often split into many Map tasks, and each Map task follows the same execution logic. Our algorithm handles these problems by a coarse-to-fine approach. This section introduces the basic concepts and techniques used in our algorithm including our view of events, our workflow model, different types of dependency re lationships involved in our algo-rithm, and the assumptions of our mining algorithm. Similar to other methods, we view th e event logs in a log file as a trace of events being produced by a black-box system. Here, events are used to characterize the dynamic behavior of a software program. Each event trace is generated and collected during a complete execution of the program on a batch of use cases. Dur-ing an execution, the program may have simultaneous executing threads of control, with each of them producing events that form a resulting event trace. Thus, each event trace may contain inter-leaved events from all the concurrent threads (namely a trace of interleaved events ). Note here that although the term  X  X hread X  means a sequential execution control path within the workflow, it may not directly map to a proce ss/thread in the operating system in an event-driven system. We can collect many event traces by running the program many times. In software systems, events may be recorded with attributes, such as timestamp, related resources and data. Although in some systems, event attributes can help to distinguish the events from different control threads of the workflow, in this paper, we present a general approach that only utilizes the ordering of events. traces. An event trace is a sequence of events, denoted as  X   X   X ,  X   X ,...,  X   X  , where  X   X  is an event, i.e.  X  For brevity, we can also write it as  X   X   X ,  X   X ,..., trace  X  X  X   X   X ,  X   X ,...,  X  , for an event  X   X   X  X  X 1 X , , we call the subsequence  X   X  X  X   X ,  X  X  X   X ,...,  X  as the postfix of  X   X  X  X  X  X  X   X   X  , and subsequence  X   X   X ,  X   X ,...,  X  X  X  as the prefix of  X  denoted as  X  . Similarly, when  X  X  X  , we also have  X  X  X  X   X   X  Program event traces may contain some noise that is usually caused by some execution anomalies. For event traces that may contain noise, we can use the nois e filtering method [19] or ano-maly detection method [20] to filter out the noise before we learn workflow models. In addition, we assume that the temporal order-ing patterns of different events ca n be as diverse as possible. This is reasonable for event logs produced by independent concurrency. Some concurrent systems that may not display much randomness are not the targets of our method. As with most data driven ap-proaches, we also assume that we have enough event logs to make our analysis meani ngful. Because our method is based on the temporal orders of events in ev ent traces, enough log data means that we have enough instances of any possible ordering relation-ship of every event pair to make the mined dependencies statisti-cally meaningful. In this paper, our algorithm outputs a transition-labeled finite state machine to represent a workflow. In order to model the concurrent properties of workflows, we intr oduce a vector of active states instead of just a single active state so that the state machine can have multiple, concurrent threads. To create and destroy these threads, we define four new type s of states to mimic the concur-rent behavior of a Petri net: split / merge states and fork / join states. Similar to the AND split/merge nodes in papers [3, 7], a split state has multiple out transitions (i.e. tr ansitions leaving from the state), and all these transitions are take n concurrently. A merge state has multiple entering transitions, and it can transit to another state only if all its entering transitions have occurred. Informally, split states represent the points where the system will spawn one thread for each leaving transition. As a counterpart, merge states are used to represent points of synchronizat ion. That is, before the merge state can transit to another state, it has to wait for the completion fork state only has one leaving transition. At a fork state, the sys-tem will fork several threads to execute a sub-workflow starting from the state. Similar to a merge state, a join state is also a point of synchronization, and it is sp ecially designed to absorb all some sample workflows, where a square box  X   X   X  is used to represent a split/merge state node, a diamond box  X   X   X  is used to represent a fork/join state node, and a circle  X   X   X  is used to represent a switch state node. By introduci ng the split/merge and fork/join nodes, we can model the concurrent properties in a workflow. For example, a single run of the workflow of Fig.1(a) can generate event traces of  X  X BCD X  or  X  X CBD X  because B and C are two concurrent events. Furthe rmore, two concurrent runs of the workflow can generate many kinds of traces, such as  X  X B-ACDCBD X ,  X  X ACCBBDD X , and so on. The fork node in Fig.1(c) can also generate concurrent events, because the sub-workflow from the fork node to the join node will be run with multiple threads. Formally, a workflow model is defined as: Definition 3.1 A workflow model is a tuple W X   X   X , X , X  where: Definition 3.2 Given a transition from  X   X  to  X   X  , we call  X  tively. If one transition X  X  ending state is the starting state of anoth-er transition, we call the two transitions as neighboring transition s. out transitions (denoted as  X  X  X  X  X  X  X  X  X  X  ), and the transitions that ending at  X  as  X   X  X  in transitions (denoted as  X  X  X  X  X  X  X  X  X  ). For a realistic workflow, all st ates and transitions should be reachable from the initial state. It means that, for every state  X  , the same time, each state also has a path to the end state. In the context of workflow traces, the occurrence of an event may be dependent on the occurrence of another event in the trace. Our workflow model reconstruction depends on mining the temporal dependencies among events. Depe ndence means that the occur-rence of one event type depends on the occurrence of another event type. In this paper, we define four types of temporal depen-dencies. Forward dependency (FD) describes that  X  X henever an event A occurs, another event B must eventually occurs after A  X  X  occurrence X . Forward dependency is denoted as  X  X   X  ward dependency (BD) describes that  X  X henever an event B oc-curs, another event A must have occurred before B  X  X  occurrence X . Backward dependency is denoted as  X  X   X   X  . The third dependen-cy we defined is strict forward dependency (SFD), which means  X  X or each occurrence of event A , there must be at least one occur-rence of event B after A  X  X  occurrence. X  We denote it as  X  X  Different from  X  X   X   X  , which means one or more occurrences of event A will eventually cause the occurrence of event B,  X  X  means that each occurrence of event A will cause at least one oc-currence of event B . Similarly, we also define strict backward dependency (SBD) with  X  X or each occurrence of event B , there must be at least one occurrence of event A before B  X  X  occurrence. X , which is denoted as  X  X   X  X  X   X  . Unlike the dependencies defined in [15, 17], our dependencies do not requi re that one event is directly followed by another event in an event trace, and they are not in-fluenced by various inte rleaving patterns. We use  X  X  X  to denote two events A and B without any defined te mporal dependencies,. Among these four types of dependencies, FD and BD focus on the global temporal relati onship between two event types, and SFD and SBD not only look at the tem poral relationship but also take the event count information into account. It is obvious that:  X  X   X  X  X   X  X   X  X   X   X  , and  X  X   X  X  X   X  X   X  X   X   X  . Thus, for simplic-ity, if two events have a strict dependency relationship, we will not list the corresponding non-strict dependency. For each pair of events, the temporal dependency is determined by Fig.1(a), we have  X  X   X  X  X   X  and  X  X   X  X  X   X  because these two de-pendencies are always true in the traces with any potential event interleaving pattern. For the workfl ow in Fig.1(e), we always have  X  X   X  X  X   X  and  X  X   X   X  . For all simple workflows in Fig.1, we list all the dependencies between event type A and B in Table 1. Such dependencies are always true no matter how event logs interleave together. We can see that different local logical structures in a workflow often have different types of dependencies. Workflow Valid Temporal Dependencies between A and B Pair-wise temporal dependencies de scribe the causal relationships of each event pair. They can provide information for workflow reconstruction. Our basic workfl ow model constructing algorithm is based on the properties of th e mined temporal dependencies. Obviously, the dependencies have the following property: Property 3.1 Let W X   X   X , X , X   X   X , X ,  X  be a workflow. For any  X  X  X , X  , if  X  X   X   X  or  X  X   X   X  , there must be a transition path from A to B (denoted as  X  X  X  ) in the workflow. In this section, we provide the details about the method of mining temporal dependencies. As with most classical algorithms of se-quence pattern mining, we measure the significance of a temporal dependency between two events by computing the statistical me-trics of support and confidence. For event types A and B , when we mine the relationships of  X  X   X  X  X   X  , the support of  X  X  defined as the number of times that event A appears in the traces that satisfy  X  X  X  X  X  X  X  X , X  X   X | X  X  X   X   X  X  X  X  X  X , X  X  X  X  X  X  X  X  X  X  X  X   X   X   X  (see the numerator of equation (3)). In contrast to the support of  X  X   X  X  X   X  , the support of  X  X   X   X  is computed as the number of traces that contain event A and B and  X  X  X  X  X  X  X  X  X  X  . As a counter-part, the support of  X  X   X  X  X   X  and  X  X   X   X  can also be calculated similarly. The confidence values of the dependencies are defined by the corresponding conditional pr obabilities. For example, the confidence of  X  X   X   X  is calculated by  X  X conf X   X   X  X  X  Note, according to the definition of  X  X   X   X  , we only have to compute the confidence by investigating the events for traces after this trick can significantly reduce the computational cost. Similar-ly, the confidence of  X  X   X   X  can also be calculated by conf  X   X  X   X   X   X   X  The computing of  X  X   X  X  X   X  and  X  X   X  X  X   X   X  X  confidence values is a little bit complex. We take  X  X   X  X  X   X  as an example to describe the computing procedure. For each event trace  X  , we find all occur-rences of event  X   X  that satisfy  X   X   X  X  and  X  X , X  X   X | X  X  X   X  X  X  X  X  X   X   X  X  X  X  X   X , X  X  X  X  X  X  X  X  X  X  X  X   X   X   X   X   X  X  (i.e. the number of B is larger than the number of A in  X  X  X  X   X   X   X   X  ). Denoting the total num-ber of such events  X   X  in all traces as  X  X  X  X  X  X  X  X  X  X   X  X  X  calculate the confidence by As a counterpart, the dependency of  X  X   X  X  X   X  is where |  X   X  |  X  X  X  X  X   X  X  X   X  X   X  | is the number of events that satisfy  X   X  X  and  X  X  X  X  X  X  X , X  X  X  X  X  X  X   X   X  X  X  X   X , X  X  X  X  X  X  X  X  X  X  X  X   X   X   X   X   X  X  (i.e. the number of B is larger than the number of A in  X  X  X   X   X  By scanning the event traces, we can obtain the support numbers and confidence values of these dependencies for each pair of event (the pseudo code can be found in [25]). The time complexi-ty of the algorithm is  X  X  X  X  X  , where  X  is the cumulative length of all event traces. Generally, | X | X  X  (i.e. the number of distinct event types) is constant for a prog ram, and is always significantly smaller than  X  . Thus, the algorithm possesses linear complexity with respect to N . Unlike the scenarios of traditional sequence (or frequent item set) mining, where some meaningless patterns can happen by chance, in our context any occurrence of an event ordering in event traces is meaningful and reflects an asp ect of the execution behavior of the software system. In this paper, we set the support threshold as 5 (The number of observations should be at least five to make the analysis results statistically meaningful [17]), and all our events in our experiments can meet this re quirement. In addition, a depen-dency relationship is valid only if it has a perfect confidence (  X  X  X  X  =100%). In this section, we provide our main algorithm of constructing workflow from mined temporal de pendencies. We first construct an initial workflow by recovering all connection s (defined in sec-tion 5.1) based on the mined temporal dependencies. The learned basic workflow does not contain some workflow structures. In order to recover these missing stru ctures, we refine the workflow by verifying with event traces. The aim of refinement is to con-struct the simplest workflow base d on the basic workflow to in-terpret all training event traces. From section 3, we can s ee that, given dependencies  X  X   X  X   X   X  , we can conclude that there is a path from event A to event B (denoted as  X  X  X  ). In addition, for two neighboring events A and B , if  X  X  X  , we can determine a connection between A and B in the original workflow, i.e. the ending state of A is the starting state of B . In this paper, we call the dependency between two neighboring events as a direct dependency . Furthermore, supposing that we have a pair-wis e dependency for each pair of neighboring events, we can recover all connection relationships. Although a mined temporal depende ncy from event traces shows that there is a path between two events, we cannot directly estab-lish a connection between them because many dependencies are not direct dependencies (i.e. they are indirect dependencies). An indirect dependence does not correspond to a connection between two events. For example, in Fig.1 (d), we have a temporal depen-dency of  X  X   X   X  . However, there is no connection between A and C. Here, the path from A to C is composed by a path from A to B and a path from B to C . In order to handle such problems, we try to construct a compact basic workflow in which there is at most one transition path between every two events. We use a pruning strategy to remove indirect dependencies during the basic workflow construction. For each event pair  X  X , X  X  that satisfies  X  X   X   X  or  X  X   X   X  , we denote  X  as  X   X  X  successor, and  X  as  X   X  X  predecessor. For the simplicity of implementation, we first use a graph data structure to store th e obtained paths, in which each event has a predecessor list and a successor list. The algorithm starts from the events that do not have any preceding event. Then, we add events into the graph and construct preceding/succeeding relations according to the mined dependencies. For any pair of events A and C where A is a predecessor of C , if a successor event successor list. In the resulting gra ph, all indirect dependencies are removed. By converting the rema ining preceding/succeeding rela-tions to event connection s, we can construct a transition-labeled workflow, namely basic workflow . The algorithm is shown in Algorithm 1. In the algorithm, the function  X  X  X  X  X  X  X  X  X _ X  X  X  X  re-turns a set of events in which each event does not have any prede-cessor in the set  X  X  . The following theorem shows that the remaining transitional paths obtained by the above algorithm must exist in the original workflow under a certain condition. In other words, our algorithm can obtain a basic workflow skeleton. The proof of the theorem [25] is straightforward, and we ignore it in this paper. Theorem 5.1 . Let W X   X   X , X , X   X   X , X ,  X  be a workflow, with at least one temporal dependence betwee n every two neighboring events. For any  X  X  X , X  that  X  X   X   X  or  X  X   X   X  , if  X  C |  X  X  X  X  X  X  X   X   X   X  , there must be a connection from A to B in the original workflow. The above algorithm does not consider a special case where two events have dependencies with di fferent directions. For example, from the event traces generated by the workflow in Fig.1(f), we can learn both dependencies of  X  X   X   X  and  X  X   X   X  at the same time. We call it a bidirectional dependence, denoted as  X  X  X  . If we directly run the basic workfl ow construction algorithm on such dependencies, the algorithm will run into an endless loop. In order to overcome this problem, we firs t check whether there are bidi-rectional dependencies in the mi ned dependencies. If there is a bidirectional dependence, e.g.  X  X  X  , we create a new virtual event type  X  X  to replace the events of type B in all forward depen-dencies. Then, we run our basi c construction algorithm to recon-struct the basic workflow. After that, we merge the virtual events (e.g.  X  X  X  X  with their corresponding events (e.g. B ) in the basic workflow. Algorithm 1 . Pseudo Code of Basic Workflow Construction Inputs : Output : 1.  X  =  X  X  = the set of all log keys; 2.  X  = an empty FIFO queue; 3. while  X  X  is not empty 4.  X  X  X  X  X  X  X  X  X _ X  X  X  X   X   X  ; 5. Add  X  into  X  ; 6.  X  X , X  X  X  X  X  X  X  X  X  X  X  ; 7. while  X  is not empty: 8.  X  X  X  X  X  X  X  X  X _ X  X  X   X   X  ; 9. if  X  is not in  X  X  10. continue; 11. for each  X  in  X  that satisfies  X  X   X   X  or  X  X   X   X  12. if  X  has predecessor in  X  13. flag = false; 14. for each  X  in  X   X  X  predecessors: 15. if  X  X  X   X  X  16. add  X  to  X   X  X  successor list; 17. else if  X  X   X   X  or  X  X   X   X  18. remove  X  from the successor list of  X  19. add  X  to  X   X  X  successor list; 20. else 21. flag = true; 22. if (flag) 23. remove  X  from the successor list of  X  24. else 25. add  X  to  X   X  X  successor list; 26. if  X  is in  X  X  27.  X  X , X  X  X  X  X  X  X  X  X  X  X  ; 28. remove  X  from  X  X  ; 29. Covert T to a transition-labeled workflow; 30. return  X  Adding the initial&amp;end state : Each workflow contains an initial state and an end state. Thus, we need to add an initial state and an end state into the basic workflow. Obviously, the first event and the last event of each event trace are potentially an initial event and an end event of the workflow respectively. In this paper, we find out all events that have appeared as the first event in event traces. If the support number of an event appearing as the first event in event traces is larger than a certain level (we use 5% in experiments because we assume the noise level is less than 5%), we add a shortcut transition from the initial state of the workflow to the starting state of the event. Similarly, if the support number of an event appearing as the last event in event traces is larger than a certain level, we add a shortcut from the ending state of the event to the end state of the workflow. Determining the state types : According to the definition of the workflow model in section 3.2, th ere are five types of states. In the above basic workflow constr uction algorithm, we do not iden-tify the type of each state. Given an event type that has several event types following it, we have to make a decision on whether switch state) or a concurrent splitting (i.e. a split/fork state). In this subsection, we determine the state types by utilizing the in-formation of event type counts. As studied in our previous work [20], the linear relationships between the occurrence times of different event types can also provide cues for the workflow struc-event trace that:  X  X  X  X  X  X  X  X  X  X  and  X  X  X  X  X  X  X  X  X  X  X  X  , Similarly, a merge state also has a property that  X  X  X  X  X   X   X   X   X   X  X  X  X  X  X  X  X  X  for any  X  X  X  X  X  X  X  X  X  X  X  and  X  X  X  X  X  X  X  X  X  X  X  . Here,  X  X  X  X  X   X   X   X  and  X  X  X  X  X  X  X  X  X  denote the occurrence numbers of event A and event B in a trace respectively. However, fork and join states do not have such regular properties on the counts of event types. If a state satisfies equation (5), it must be a switch state. In this subsection, we first find out the split/merge states by verify-ing whether a state satisfies equa tion (6), and then find out the switch states that can be identified by equation (5). Because our model allows shortcut transitions, some sw itch states cannot be easily identified by equation (5). For all remaining states with their state types undetermined, we will determine their state types in the next sub-section. The default state type is switch . The basic workflow obtained by Algorithm 1 does not contain any shortcut transitions or loop stru ctures, because we only keep one transition path between every two dependent events. However, in a real workflow, there may be some shortcut transitions and loop structures. In addition, Algorit hm 1 also cannot identify the fork/join state types. Therefore, the basic workflow only contains a part of the real workflow, and it often cannot interpret all train-ing event traces. In fact, a mean ingful mined workflow should be able to interpret the traces. In this subsection, based on the learned basic workflow, we build a workflow to interpret all event traces by identifying fork/join states a nd recovering loop structures and shortcut transitions. We recover loop structures or s hortcut transitions based on the statistical properties of these structures. Here, we use a simple example to describe the basic idea behind our algorithm. Fig.2(a) presents a simple program workfl ow containing a loop structure. We generated event traces by running a concurrent program with different interleaving patterns in which each thread runs along the workflow in Fig.2(a). Two typical sample event traces are shown in Fig. 2(b). Our basic workflow construction algorithm can only construct a basic workflow without a loop (see Fig.2(c)). When we use the basic workflow in Fig.2(c) to interpret the first event trace are generated by two threads (denoted as  X   X  and  X  along the basic workflow. When the 6th event of the trace (i.e. B ) is being verified, the active states of  X   X  and  X  spectively, and both threads cannot produce event B from their basic workflow.). The reason why some events cannot be inter-preted is that some transitions are missing in the basic workflow. Specifically, event B is a part of the recurrence of the missing loop in Fig.2(a). However, we do not have knowledge about the loop structure and the original workflow. In order to interpret the first event trace, we now have tw o possible solutions: the event is either generated by  X   X  or generated by  X   X  . If it is generated by  X  workflow in Fig.2(a). If the event is generated by  X   X  , then there is a loop from  X   X  to  X   X  in the workflow, which is the workflow in Fig.2(d). Similarly, when we try to interpret the 8 second event trace in Fig.2(b), the active states of the threads are  X  and  X   X  . One can interpret the second event trace either by the workflow in Fig.2(a) or by that in Fig.2(e). Here, we observe that, for both event traces, when we try to interpret an event B that is a part of the recurrence of the loop, there is a thread at state  X  general, for any training event trace with a different interleaving pattern, when we verify an un-interpretable event of type B , which is a part of the recurrence of the loop, there is always at least one with active states of  X   X  or  X   X  only by chance. Therefore, if we vote for threads X  active states over all event traces once we encounter an un-interpretable event B , we will find that  X  vote value. This property can help us to detect the loop structures, a loopback transition from  X   X  to  X   X  . Although the example in Fig.2 is a simple case, this statistical property is widely valid for workflows with loop or shortcut structures. For example, Fig.3 shows the vote value histogram that is counted for the un-figure, there is a high peak value at s 2 , which indicates a loopback transition from s 2 to s 1 . Our algorithm utilizes this statistical prop-erty to detect and recover l oop structures and shortcuts. Unlike loop and shortcut structures , fork/join states do not expose any unique statistical property. We cannot use the above statistical method to identify a fork/join structure. If we perform the above method forcibly on the event traces generated by a fork/join struc-ture, then the resulting workflow is often very complex, which is caused by various event interleaving patterns. On the other hand, all event traces generated by a l oop structure can always be inter-preted by a fork/join structure. For example, all event traces pro-duced by the workflow in Fig.2(a) can always be interpreted by the workflow in Fig.2(f). Formally , the observation is described as: Property 5.1 Event traces that can be interpreted by a workflow  X  with loop structures can also be interpreted by a workflow  X  which is created based on  X   X  by replacing the loop structures with fork/join structures, and  X  X   X   X   X   X   X  X  X   X   X   X   X  , but not vice versa. Here,  X  X   X   X   X  is the complexity of a workflow  X  , which is de-fined as the sum of transition number and the number of thread types. Each thread type is define d as a pair of thread starting and ending points. Given the constant states of the basic workflow (we only add transitions or mark thread spawn/sync states in the re-finement algorithm),  X  X   X   X   X  is a good description of a workflow model X  X  complexity. Based on prope rty 5.1, we introduce a loop favorite rule in our algorithm. For two workflows that can interp-ret the event traces, we prefer the workflow with less complexity. If event traces can be interpreted by either a workflow with a loop structure or a workflow with a fork/join structure, and both of them have the same complexity, we prefer the former. In sum-mary, starting from the learned basic workflow, we try to con-struct the simplest workflow with a minimal number of threads to interpret all event traces. Figure 2. An example for the depiction of our refinement idea. Because we have no information about when a new thread starts, an un-interpretable event can be interpreted as an event log pro-duced by either a missing workfl ow structure component (i.e. shortcut or loop) or a newly started thread (i.e. fork/join states). In the algorithm, we have to make a decision to select one structure between them (i.e. loop decision or fork decision) whenever a new un-interpretable event is encountered. A workflow has a Markov property that states that the current state is what determines the next step in its behavior. Thus, an early decision will influence the later decisions, but the converse is not true. At each decision point, we first create two temporary workflows. One (denoted as  X  the algorithm) is constructed by a procedure in which we make a loop decision at the current decisi on point and make fork decision at all following decision points. The other (denoted as  X  algorithm) is constructed through a procedure with all fork deci-sions. Then, we select a decision at the current decision point based on the loop favorite rule. Si milarly, we also make the next decision with the same procedure. Note: here, the temporary workflows are only constructed fo r decision making, and they are not output as the results of the algorithm. The detailed algorithm is presented in APPENDIX A. In the algorithm, we do not count the active states with their neighboring events having strict for-ward dependencies, because such a state neither has an out-shortcut transition nor is a join state. For example, we do not have  X  X   X  X  X   X  in Fig. 1(c) and (f). The following theorem shows that the workflow learned by our refi nement algorithm is optimal in the sense of complexity defined above. The proof of the theorem can be found in [25]. Theorem 5.2 . The refinement algorithm finds out the workflow with a minimal complexity to interpret all event traces. To validate and evaluate our proposed workflow algorithm, we performed a set of experiments on simulated event traces and case studies on real event traces ge nerated by some open source pro-grams (Hadoop and JBoss). We use open source programs be-cause they are publicly available for download. The results on them are easy to be verified and reproduced by third parties. The results demonstrate the usefulne ss of our workflow mining tech-nique in recovering underlying workflows from event traces. Due to space limitation, the results on JBoss are available at [25]. The code of the simulator and our algorithm will also be available soon (after the legal review accord ing to the code release policy of Microsoft) at http://research.mic rosoft.com/apps/pubs/default.asp x? id=118640. To construct a controlled experime ntal environment, we designed a simulator that can generate synthetic program event traces ac-cording to a software workflow model. The design of the simula-tor follows the principles proposed in QUARK [21] including the guarantee of  X  X ode and branch cove rage X  and locality of reference, and so on. Unlike QUARK, our simu lator can generate traces of interleaved events based on a conc urrent workflow model. In this experiment, we measure the performance of our workflow miner by discovering workflows from the synthetic program event traces. Simulation Models: In our simulation experiments, several real application models are used to generate the event traces. In [23], Zou et al. present two workflows in the form of automata: the releases of expired allocations (Fig.4(a)) and the processing of backorders (Fig.4(b)). In [17], the authors use a paper reviewing process (Fig.5) to demonstrate their workflow mining algorithm. The models are shown in Fig.4 and Fig.5, and are referred to as WS(a) , WS(b) , and Rev respectively. By using these models, users can evaluate and compare our algorithm with other algorithms in [17] [23]. In addition, these typi cal real application workflows are complex enough to demonstrate the capability of our algorithm: the models in Fig.4 contain seve ral nested loops and many short-cut transitions, and the model in Fig.5 has a loop embraced by a fork/join structure. Evaluation Metric : In order to carry out a quantitative evaluation of the workflow miner, we adopt two metrics to measure the simi-larity from the mined workflow X and the simulator model Y in terms of their generated traces . The first metric is known as recall, the percentage of event traces generated by workflow Y that can be interpreted by workflow X . The second metric is precision , the percentage of event traces produced by workflow X that can be interpreted by workflow Y . Results: We run these models with several threads (we randomly start 1-3 threads) in our simulator to generate traces of interleaved events. From the generated traces (2000 event traces for each), we learn workflow models through the algorithm provided in the above sections. We compare the effectiveness of the k-Learner algorithm [6] and our algorithm by measuring the precision and recall of the resulting state machines. We repeat each experiment 10 times with 10 different set of traces, and computing the aver-age that shown in Table 2. Here, we round the results to keep three numbers after the decimal poi nt. For these three workflows, our algorithm can exactly rediscover the original workflow model, thus, both the recall and precision are 100%. However, the preci-sions of the models produced w ith k-Learner are very poor (2 models with a precision less than 0.1). This indicates that k-Learner cannot perform well wh en events are interleaved. Computational cost : Our algorithm is efficient, which only uses 9.9, 22.3 and 72.0 seconds (with a CPU of 2.33GHz, the code is not fully optimized) to learn the models of WS(a) , WS(b) , and Rev from 2000 event traces respectively. Table 3 shows that the com-puting time of each model grows al most linearly as the number of input event traces increases. k-Learner (k=1) 0.511 1.000 0.069 1.000 0.000 1.000 k-Learner (k=2) 0.255 1.000 0.080 1.000 0.001 1.000 Our Algorithm 1.000 1.000 1.000 1.000 1.000 1.000 Table 3. Computing Time (in se conds) vs. Event Trace Number 
Trace No. Simulation Models WS ( a ) WS ( b ) Rev Hadoop [22] (our version: 0.19) is a well-known open-source implementation of Google X  X  Ma p-Reduce computing framework and distributed file system (HD FS). It enables distributed compu-ting of large scale, data-intensive and stage-based parallel applica-tions. The logs produced by Hadoop are not sequential log mes-sage sequences. Even in the log messages of the same Map task, some messages (e.g. messages about data shuffling) are also inter-leaving. Trace collection and preprocessing : We run different Hadoop jobs of some sample applicatio ns, such as WordCount and Sort, and collect log data after each job is finished (Note: we enable the logging tool at the info level). At first, we use the log preprocess-ing method presented in [20, 24] to parse event log messages and to group log messages according to log parameters. For example, all log messages that contain a parameter ca lled MapTask ID are grouped into an event trace. Be cause several MapTasks are run-ning simultaneously, these events are highly interleaved with each other. Then, we use the error detect ion algorithm in [20] to filter out event traces that contain errors. Finally, we obtain 1767 event traces. Each trace contains about 15 concurrent map tasks and about 234 events in average. Results : After that, we learn workflow from event traces with our proposed algorithm. Fig.6 is an example of the resulting workflow that is learned from the event traces related to the parameter MapTask ID. By carefully check ing with Hadoop source code and documents, we find that the workflow can reflect the real process of MapTask with a high precision. A task is launched and then it processes the input data read fro m HDFS. After the task is done, it sends the resulting data to many Reducers concurrently (This is represented by a fork/join structure in the workflow), and finally cleans up the resources by rem oving temporary files. Hadoop has a scheduling strategy to run a small number of speculative tasks. Therefore, there may be two running instances of the same task at the same time. If one task instance finishes, the other task instance will be killed no matter which stage the task instance is running at. Some killed tasks can also report their status due to thread race conditions, therefore, events of H 13 , H 14 and H 15 As with the results of all other workflow mining algorithms [2][17][21], some resulting workflow models of our algorithm are over-generalized (i.e. having more possible routes than the real workflow). For example, in the case in section 6.2, there is a path from  X   X  X  to  X   X  X  , which does not exist in the real program. There are two main reasons for the over-generalization problem. At first, we only consider the first-order of event dependencies (i.e. the dependencies between neighboring events) in our current algo-rithm. In some real programs, there are some high-order depen-dencies, e.g. the occurrences of H 13 , H 14 and H occurrence of H 7 in Fig.6. Second, our approach assumes that there is at most one transition referring to an event type in a workflow model. In some real systems, one event type may ap-pear at multiple positions in a workflow. For example, from the event traces generated by the workflow in Fig.7(a) (This is the workflow of X11 [19]), a workflow in Fig.7(b) is learned through our algorithm which is more general than the original one. The workflow in Fig.7(b) can generate event traces such as &lt; B , E ,..., E &gt; workflow Fig.7(a). We will leave it for future work to deal with these problems. The proposed method only finds out the workflow that minimizes the defined complexity metric, and it does not provide any means to tune the precision and recall of the learned workflow. In addi-tion, the workflow with minimal complexity may not be exactly the same as the real workflow or the one a human operator wants to see. Most existing techniques for mi ning program workflow models can only learn models from sequential event traces. They cannot be applied to traces of interleaved events which are prevalent in distributed or parallel programs (or some event driven programs). In this paper, we proposed an approach to automatically discover program execution workflows from traces of interleaved events. We extend the traditional state machine to support concurrency by introducing split / merge states and fork / join states. Our mining approach is based on the statisti cal inference of temporal depen-dency relations from event traces. We then use such dependency relations to construct a basic workflow by building the connec-tion s among neighboring events. After that, we further refine the workflow by validating it with event traces. During the validation procedure, we add the shortcut transitions, loop structure, and fork/join states into the workflow model to make sure that all event traces can be interpreted by the workflow model. The expe-rimental results on both simulated event traces and real program traces demonstrate that our approach can learn the workflow with a high precision. Although our work is motivated by the purpose of software com-prehension, workflow mining is a basic research topic that has a wide range of application fields other than software engineering. We believe our approach can be widely applied in many applica-tions, such as business intelligen ce. Future research directions include integrating high order te mporal dependencies, incorporat-ing domain or existing knowledge about a program, allowing for a workflow model having an event type at multiple points. [1]. G. Ammons, R. Bodik, and J. R. Larus,  X  X ining Specifica-[2]. David Lo, L. Mariani, and M. Pezz X ,  X  X utomatic Steering of [3]. R. Silva, J. Zhang, and J. G. Shanahan,  X  X robabilistic [4]. D. Cotroneo, R. Pietrantuono, L. Mariani, and F. Pastore. [5]. D. Lorenzoli, L. Mariani, and M. Pezz X .  X  X utomatic Genera-[6]. L. Mariani, M. Pezz X .  X  X ynamic Detection of COTS Com-[7]. G. Greco, A. Guzzo, L. Pontieri, and D. Sacca.  X  X ining Ex-[8]. N. Walkinshaw, K. Bogdanov,  X  X  nferring Finite-state Models [9]. A. Biermann, J. Feldman,  X  X n the Synthesis of Finite-state [10]. Anand V. Raman, Jon D. Patr ick,  X  X he SK-strings Method [11]. S. Ferg,  X  X vent-Driven Progr amming: Introduction, Tutorial, [12]. W. van der Aalst, A. Wejters,  X  X rocess mining: a research [13]. G. Greco, A. Guzzo, G. Ma nco, L. Pontieri, and D. [14]. R. Agrawal, D. Gunopulos, and F. Leymann,  X  X ining [15]. W. van der Aalst, A. J. M. M. Weijters and L. Maruster, [16]. G. Schimm,  X  X ining Exact Models of Concurrent [17]. J. E. Cook, Z. Du, C. Liu, and A. L. Wolf,  X  X iscovering [18]. P. Grubb, A. Takang,  X  X oftware Maintenance X , World [19]. David Lo, S. C. Khoo,  X  X MArTIC: Towards Building an [20]. J.-G. Lou, Q. Fu, S. Yang, Y. Xu, and J. Li,  X  X ining Inva-[21]. David Lo, S. C. Khoo,  X  X UAR K: Empirical Assessment of [22]. Hadoop. http://hadoop.apache.org/core. 2009. [23]. Y. Zhou, T. Lau, K. Kontogia nnis, T. Tong, and R. McKeg-[24]. Q. Fu, J.-G. Lou, Y. Wang, and J. LI,  X  X xecution Anomaly [25]. J.-G. Lou, Q. Fu, S. Yang, and J. Li,  X  X ining Program [26]. M. Pradel, T. R. Gross,  X  X ut omatic Generation of Object [27]. M. Acharya, T. Xie, J. Pei, and J. Xu,  X  X ining API Patterns [28]. M. Gabel, Z. Su,  X  X avert: Fully Automatic Mining of General [29]. J. YANG, D. Evans, D. Bhardwaj, T. Bhat, and M. Das, [30]. David Lo, G. Ramalingam, V. P. Ranganath, and K. Vaswani, [31]. A. Wasylkowski, A. Zeller,  X  X ining Temporal Specifica-In this appendix, we present the detail of our refinement algorithm. For every event type  X  , and state  X  , we define two integer values  X  X  X  X  X  and  X  X , X  X  X  . Here,  X  X  X  X  X  denotes the numbe r of times that event type  X  in the training event traces cannot be inferred by the workflow during refinement.  X  X , X  X  X  records the number of workflow threads whose current state is  X  when an un-interpretable event of type  X  is encountered.  X   X  flags used to indicate whether current workflow model  X  should be refined by a loop decision or a fork decision. Their initial val-ues are both false.  X   X  and  X   X  are two temporary workflow mod-els (refer to section 5.2). The w hole refinement pr ocess contains the following steps. Step 0 . Let  X   X   X , X   X   X 0 ,  X   X   X   X   X  X  X   X  X  X  X  X   X  X  X  , and  X   X   X   X   X 0 for any  X  X  X  X  X  X  X  and  X  X  X  ;  X   X  X  X   X  X rue ; Step 1 . For an input training event trace  X  , we use the method presented in [25] to interpret the trace. Once there is an event  X  in L that cannot interpreted, we increase  X  X  X  X  X  by 1, and set  X  false . At the same time, for each workflow thread  X   X  , we increase  X , X  X  X   X   X  by 1 where  X   X  is the active state of  X  connection between two events having a strict forward depen-dence. process of Step 1 . out a state  X   X  that satisfies  X   X   X , X   X   X   X  X  X  X   X   X  to  X  X  X   X   X  . Step 4. If  X   X  X  X   X  X alse , we find an arbitrary element  X  X   X  X  X  X  X  X  X  X  X  X   X   X  |  X  X  X  X  X  X  X  X  X  X  X  X  X  X  (refer to section 5.1), and find event  X  that does not have any predecessor in  X   X   X   X  , then goto Step 5 . Otherwise, goto Step 6 . workflow model  X  . If  X   X   X  X alse , we set  X  X  =  X  ,  X  update  X  by adding a shortcut transition from  X  to  X   X  by setting  X   X  as a fork state. After that, back to Step 0 . Step 6 . If  X   X  X  X   X  X rue and  X   X   X  X alse , we mark all join states and terminate the execution of the algorithm. Otherwise, if  X  we set  X   X  =  X  and goto Step 7 ; else  X   X  =  X  and go to Step 8 . Step 7 . Set  X  =  X  X  ,  X   X   X  X rue , and then back to Step 0 . Step 8 . Set  X   X   X  X   X   X  X alse and  X  =  X  X  . If  X  X   X   X  we update  X  by adding a shortcut transition from  X  to  X  update  X  by setting  X   X  as a fork state. After that, back to Step 0 . 
