 1. Introduction
The world wide web is an extremely vast resource-thirsty field, which probably consumes a major portion of the computing resources available today. Searching, updating and examining web pages is, undoubtedly, one of the primary tasks done by both individuals and companies today. This, in turn, leads to numerous extremely interesting real-life resource allocation and scheduling problems, and in this paper, we study one such problem, the so-called  X  X  X eb polling X  X  problem.

Web page monitoring consists of repeatedly polling a selection of web pages so that the user can detect changes that occur over time. Clearly, as this task can be prohibitively expensive, in practical applications, the system imposes a constraint on the maximum number of web pages that can be polled per time unit.
This bound is dictated by the governing communication band-width, and by the speed limitations associated with the proces-sing. Since only a fraction of the web pages can be polled within a given unit of time, the problem which the system X  X  analyst encounters is one of determining which web pages are to be polled. In such cases, a reasonable choice of action is to choose web pages in a manner that maximizes the number of changes detected, and the optimal allocation of the resources involves trial-and-failure. As illustrated in Fig. 1 , web pages may change with varying frequencies (that are unknown to the decision maker), and changes appear more-or-less randomly. Furthermore, as argued elsewhere, ( Granmo and Oommen, 2006 ; Granmo et al., 2006 , 2007 ), the probability that an individual web page poll uncovers a change on its own, decreases monotonically with the polling frequency used for that web page.

Although several nonlinear criterion functions for measuring web monitoring performance have been proposed in the litera-ture (e.g., see Pandey et al., 2003 ; Wolf et al., 2002 ), from a broader viewpoint they are mainly built around the basic concept a web page results in new information being discovered. There-clarity, we will use the update detection probability as the token of interest in this paper. To further define our notion of web monitoring performance, we consider that time is discrete with the time interval length, T , to be the atomic unit of decision making. In each time interval every single web page i has a constant probability q i of remaining unchanged . 1 Furthermore, when a web page is updated/changed, the update is available for detection only until the web page is updated again. Subsequent to that event, the original update is considered to be  X  X  X ost X  X . For instance, whenever a newspaper web page is updated, the previous news items are replaced by the most recent ones. ability of a web page i as d i . Under the above conditions, d modelled using the following expression:
By way of example, consider the scenario that a web page remains unchanged in any single time step with probability 0.5. Then, polling the web page uncovers new information with probability every 2nd time step. As one can observe, increasing the polling frequency reduces the probability of discovering new information on each polling.
 have been discussed in the literature (see e.g., Pandey et al., 2003 ). The uniform policy allocates monitoring resources uni-formly across all web pages. This classical policy can be applied directly in an unknown environment. In the so-called proportional policy, the allocation of monitoring resources to web pages is proportional to the update frequencies of the web pages. Accord-ingly, this policy requires that the web page update frequencies are known. The estimator policy, on the other hand, handles unknown web update frequencies by polling web pages uniformly in a parameter estimation phase, with the purpose of estimating the update frequencies. After the parameter estimation phase, the scheme applies the proportional policy, where, however, the latter is based on the estimated update frequencies rather than the true ones. Finally, the optimal policy requires that the web page update frequencies are known, and determines the optimal solution based on the principle of Lagrange multipliers ( Pandey et al., 2003 ; Wolf et al., 2002 ).
 proceed to solve it by suggesting that it falls within the model of knapsack-based problems. Indeed, in the most general setting, we shall utilize the model of the stochastic nonlinear fractional equality knapsack (NEFK) problems to model the present pro-blem, and once such a formalization has been established, we shall allude to the learning automata (LA) ( Narendra and Thathachar, 1989 ; Thathachar and Sastry, 2004 ) solution of the
NEFK problem, proposed in Granmo and John Oommen (2010) ,to solve the web polling problem. LA have previously been used to model biological systems ( Tsetlin, 1973 ), and have attracted considerable interest in the last decade because they can learn the optimal actions when operating in (or interacting with) unknown stochastic environments. Furthermore, they combine rapid and accurate convergence with low computational complexity.

The novel learning automata knapsack game (LAKG) scheme that we proposed in Granmo et al. (2007) does not rely on estimating parameters, and can be used to solve the stochastic
NEFK problem in both static and dynamic settings. Indeed, empirical results verify that the LAKG finds the optimal solution with arbitrary accuracy, guided by the principle of Lagrange multipliers. Furthermore, the empirical results show that the performance of the LAKG is superior to that of parameter estimation-based schemes, both in static and dynamic environ-ments. Accordingly, we believe that the LAKG can be considered to represent the state-of-the-art when it concerns research on the stochastic NEFK problem. This landmark is now extended to develop the twofold resource allocation automaton (TRAA), (which, in itself is the first reported LA which is artificially ergodic), its hierarchical version, the H-TRAA  X  which is the strategy used to solve the problem being investigated. 1.1. Contributions of this paper
The contributions of this paper are the following: optimal web polling problem using a formal solution to the stochastic NEFK problem. 2. The solution we propose involves a novel scheme for the two-material resource allocation problem, namely, the twofold resource allocation automaton ( TRAA ), which is the first reported LA that is artificially rendered ergodic, and which is proven to be asymptotically optimal. 3. The solution we propose for web polling also utilizes the
H-TRAA, which is the first hierarchical solution to the stochas-tic NEFK problem, based on a hierarchy of TRAAs. 4. We verify empirically that the H-TRAA provides orders of magnitude faster convergence compared to the LAKG for the web polling problem.
 As a result of the above contributions, we believe that the
H-TRAA is the first reported viable and realistic strategy for solving the optimal web polling problem. Indeed, it can also be used for other optimal allocation of sampling resources in large scale web accessibility assessment ( Snaprud et al., 2003 ). 1.2. Paper organization
The paper is organized as follows. In Section 2, we formulate the targeted problem formally and discuss state-of-the-art solu-tions. Then, in Section 3 we present the twofold resource allocation automaton (TRAA) for the two-material problems, and prove its asymptotic optimality. We continue with proposing how TRAAs can be arranged in a hierarchy for solving multi-material stochastic NEFK problems, and in Section 4, verify empirically that the H-TRAA provides orders of magnitude faster convergence compared to the LAKG when applied to the optimal web polling problem. Indeed, we shall present results that clearly demon-strate that the H-TRAA allows us to tackle 32,768-parameter problems in real-time . The solution also permits the system to be dynamic! Finally, we offer suggestions for further work before we conclude the paper in Section 5. 2. The stochastic nonlinear equality fractional knapsack problem
We first formulate, in a fairly general setting, a set of knapsack-based problems that are, in actuality, related to the web polling to be allocated based on incomplete and noisy information. Such many cases, incomplete and noisy information render traditional optimization techniques ineffective. In this paper, we address one such model which can be translated into a family of problems:
Imagine that you have to allocate a limited amount of time among n different activities. The problem is such that spending a time instant on an activity randomly produces one of two possible outcomes  X  the time instant is either spent  X  X  X ruitfully X  X  or  X  X  X nfruitfully X  X . In this generic setting, your goal is to maximize the expected amount of fruitfully spent time.
Unfortunately, you are only given the following information regarding the activities: 1. Each instant of time spent on an activity has a certain probability of being fruitful, and 2. This probability decreases with the amount of time spent on the activity.

To render the problem even more realistic, you do not have access to the probabilities themselves. Instead, you must rely on solving the problem by means of trial-and-failure, i.e., by attempting different allocations, and observing the resulting random outcomes. 3
The above problem instances can be formulated as a stochastic fied earlier ( Granmo and Oommen, 2006 ; Granmo et al., 2006 , 2007 ). Such a formulation permits an analytically rigorous treat-ment of the problem. 2.1. Classical linear and nonlinear fractional knapsack problems
In order to appreciate the qualities of the stochastic NEFK linear fractional knapsack (FK) problem. Indeed, the stochastic
NEFK problem generalizes the latter problem in two significant ways. Both of the two problems are briefly defined below.
The linear fractional knapsack ( FK ) problem : The linear FK problem is a classical continuous optimization problem which also has applications within the field of resource allocation. The 1 r i r n , where each material is available in a certain amount x r b f  X  x
P f  X  x i  X  ( Black, 2004 ).

The nonlinear equality FK ( NEFK ) problem : One important extension of the above classical problem is the nonlinear equality
FK problem with a separable and concave objective function. The problem can be stated as follows ( Kellerer et al., 2004 ): maximize f  X  ~ x  X  X  subject to
Since the objective function is considered to be concave, the value (hereafter denoted f 0 i  X  , are nonincreasing. In other words, the material value per unit volume is no longer constant as in the linear case, but decreases with the material amount, and so the optimization problem becomes maximize f  X  ~ x  X  X  subject to
Lagrange multipliers, have been devised. In short, the optimal value occurs when the derivatives f 0 i of the material value functions are equal, subject to the knapsack constraints ( Bretthauer and Shetty, 2002 ; Fox, 1966 ):  X  x  X  X  X  f 0 n  X  x n  X  x  X  c and 8 i A f 1 , ... , n g , x i Z 0 : 2.2. The stochastic NEFK problem
In this paper we generalize the above nonlinear equality knapsack problem. First of all, we let the material value per unit time an amount x i of material i is placed in the knapsack, we are only allowed to observe an instantiation of p i  X  x i  X  at x p  X  x
 X  itself. Given this stochastic environment, we intend to devise an online incremental scheme that learns the mix of materials of maximal expected value, through a series of informed guesses. Thus, to clarify issues, we are provided with a knapsack of fixed volume c , which is to be filled with a mix of n different materials. However, unlike the NEFK, in the stochastic NEFK problem the unit volume value of a material i ,1 r i r n ,isa random quantity  X  it takes the value 1 with probability p tional complication, p i  X  x i  X  is nonlinear in the sense that it decreases monotonically with x i , i.e., x i 1 r x i 2 3 p expected unit volume values rather than the actual unit volume values themselves. With this understanding, and the above perspective in mind, the expected value of the amount x i material i ,1 r i r n , becomes f i  X  x i  X  X  expected value per unit volume 4 of material i becomes maximized as below: maximize f  X  ~ x  X  X  subject to of information available to the decision maker is limited  X  the decision maker is only allowed to observe the current unit value the decision maker. The actual outcome probabilities p i  X  x however, remain unknown . As a result of the latter, the expected value of the material mix must be maximized by means of trial-and-error, i.e., by experimenting with different material mixes and by observing the resulting random unit value outcomes.
 considerations, we shall show that our aim is to find the page polling frequencies ~ x that maximize the expected number of pollings uncovering new information per time step: maximize subject to whether the web page has been updated at least once since our last poll. 5 As such, web monitoring forms a proof-of-concept application for resource allocation in unknown stochastic environments. 2.3. State-of-the-art: the stochastic NEFK problem
Granmo et al. (2007) , the stochastic NEFK problem was not addressed in the literature before. However, several studies on related problems have been reported. For example, the works of
Dean et al. (2004) and Steinberg and Parks (1979) consider solution policies for stochastic generalizations of the so-called
NP-hard linear integer knapsack problem. In these papers, value distributions were considered known and constant, making dynamic programming a viable solution. Another variant of the knapsack problem is found in Ross and Tsang (1989) where a deterministic knapsack is used, however, with objects arriving to and departing from the knapsack at random times. The optimization problem considered was to accept/block arriving objects so that the average value of the knapsack is maximized.
The first reported generic treatment of the stochastic NEFK problem itself can be found in Granmo et al. (2007) . The approaches that represent the nonLA state-of-the-art, assume that the knapsack problem is deterministic and fully known .
However, from a web monitoring perspective the web must often be seen as a stochastic and more or less unknown environment.
Various instantiations of the problem have, however, appeared sporadically, particularly within the web monitoring domain. In these latter instantiations, the unknown parameters of the knap-sack problem are estimated by means of a tracking phase where web pages are polled mainly for estimation purposes ( Pandey approach is that the parameter estimation phase significantly delays the implementation of an optimal solution. This disadvan-tage is further aggravated in dynamic environments where the optimal solution changes over time, introducing the need for parameter re-estimation ( Granmo and Oommen, 2006 ).
With regard to the particular application domain, recent approaches to resource allocation in web monitoring attempt to optimize the performance of the system when the monitoring principle cited in the literature essentially invokes Lagrange multipliers to solve a nonlinear equality knapsack problem with
Thus, for example, a basic web monitoring resource allocation problem may involve n web pages that are updated periodically, although with different periods. Clearly, each web page can be polled with a maximum frequency  X  which would result in a sluggish system. The problem which we study involves determin-ing the web page polling frequencies (i.e., how often each web page is accessed by the monitoring system) so as to maximize the number of web page updates detected. Observe that this must be achieved without exceeding the available monitoring capaci-ty  X  e.g., the maximum number of web pages that can be accessed per unit of time as dictated by the governing communication bandwidth and processing speed limitations. 2.4. Related solutions to knapsack-family problems
In order to put our work in the right perspective, we first provide a brief review of the concepts and the solution found in
Granmo et al. (2007)  X  which are also relevant for more  X  X  X rimi-tive X  X  variants of the knapsack problem.

As indicated in the introduction, solving the classical linear FK problem involves finding the most valuable mix ~ x n  X  X  x n n materials that fits within a knapsack of fixed capacity c . The material value per unit volume for each material i is given as a constant v i , and each material is available in a certain amount x r b i ,1 r i r n . Accordingly, the value of the amount x material i , f i  X  x i  X  X  v i x i , is linear with respect to x in the knapsack, the following greedy algorithm from Black (2004) finds the most valuable mix: Take as much as possible of room , take as much as possible of the next most valuable material. Continue until the knapsack is full.

Let us now generalize this and assume that the material unit volume values are random variables with constant and known distributions. Furthermore, for the sake of conceptual clarity, let us only consider binary variables that either instantiate to the values of 0 or 1. Since the unit volume values are random, let p i ,1 r i r n , which means that the probability of the unit volume value v i  X  0becomes1 p i . With some insight, it becomes evident that under such conditions, the above greedy strategy can again be used to maximize the expected value of the knapsack, simply by selecting the material based on the expected unit volume values, E  X  v i  X  0  X  1 p i  X  X  1 p i , rather than actual unit volume values.
The above indicated solution is, of course, inadequate when the p  X  X  are unknown. Furthermore, the problem becomes even more on their respective material amounts x i ,1 r i r n .Let p probability that the current unit volume value of material i is v given that the amount x i has already been placed in the knapsack. Then, the expected value per unit volume of material i ,1 r i r n , becomes E  X  v i  X  0  X  1 p i  X  x i  X  X  1 p i  X  x i  X  X  p i  X  x the expected value of the amount x i becomes f i  X  x i  X  X 
Our aim, then, is to find a scheme that moves towards optimizing the following NEFK problem online: maximize f  X  ~ x  X  X  and p i  X  x i  X  X  f 0 i  X  x i  X  , subject to
Note that we allow only instantiations of the material values per unit volume to be observed. That is, each time an amount x material i is placed in the knapsack, an instantiation v i observed.

Because of the above intricacies, in Granmo et al. (2007) and in this present paper, we choose to approach the problem by relying on informed material mix guesses , i.e., by experimenting with different material mixes and learning from the resulting random unit volume value outcomes. We shall assume that x i is any number is that of determining how to change our current guesses on x , 1 r i r n . We shall attempt to do this in a discretized manner by subdividing the unit interval into N points f 1 l = N l , 2 l and l 4 0 determines the linearity of the discretized solution space. 6 We will see that a larger value of N will ultimately imply a more accurate solution to the knapsack problem.

At this juncture, it is pertinent to mention that although the proposed by Oommen (1997) , the two schemes are quite distinct for the following reasons: 1. The method proposed in Oommen (1997) assumes the exis-tence of an Oracle which informs the LA whether to go  X  X  X ight X  X  or  X  X  X eft X  X . In our application domain, this now has to be inferred by the system. 2. The method proposed in Oommen (1997) assumes that there is only a single LA in the picture. Here, we specifically understand that there are multiple LAs organized in a hierarchy  X  each of them being constrained to work together with the others. 7 3. In Oommen (1997) the problem of analyzing scenarios with space varying responses from the environment was left open.
This problem is tackled in Granmo et al. (2007) . 4. As opposed to the scheme in Oommen (1997) , our present approach is also applicable to dynamic (time varying) environments. 5. There is a  X  X  X uge X  X  fundamental difference between the LA which we devise here and the work of Oommen (1997) . Unlike the latter, in which the system is truly ergodic, our present LA would be absorbing if the end-states of the probability space are also included. However, to forcefully render this present machine ergodic, we have artificially made the LA ergodic by excluding these states from the set of possible probability values. This makes the analysis both distinct and quite fasci-nating. As mentioned earlier, we are not aware of any LA which, in essence are absorbing, but which have been made artificially ergodic . 3. A hierarchy of twofold resource allocation automata (H-TRAA) 3.1. Details of the TRAA solution 3.1.1. Design of the TRAA solution
We first present 8 our LA-based solution to two-material sto-chastic NEFK problems. The two-material solution forms a critical part of the hierarchic scheme for multiple materials that is presented subsequently. As illustrated in Fig. 2 , our solution to two-material problems constitutes of three modules: 1. A stochastic environment 2. The TRAA itself, and 3. An earliest deadline first (EDF) scheduler.

We first detail each of the three modules, before we analyze the overall feedback connection between them. Finally, we prove that the TRAA that we have developed in this section is asympto-tically optimal for two-material Stochastic NEFK problems.
Stochastic environment : The stochastic environment for the two-material case can be characterized by: 1. The capacity c of the knapsack; 2. Two material unit volume value probability functions p and p 2  X  x 2  X  .
 environment, the environment replies with a unit volume value v  X  1 with probability p i  X  x i  X  and a unit volume value v render the problem both interesting and nontrivial, we assume that p i  X  x i  X  is unknown to the TRAA.

Twofold resource allocation automaton ( TRAA ): The scheme which attempts to learn the optimal allocation ~ x n  X  X  x n be described as follows. A finite fixed structure automaton with resources among the two materials. Let the current state of the s  X  t  X  = N  X  1, and let r s  X  t  X  refer to the fraction: 1 q automaton X  X  current guess is ~ x  X  X  q s  X  t  X  , r s  X  t  X 
If the stochastic environment tells the automaton that the unit its state as follows: s  X  t  X  1  X  :  X  s  X  t  X  X  1 If rand  X  X  r r s  X  t  X  and v i and 1 r s i  X  t  X  o N and i  X  1  X  1  X  s  X  t  X  1  X  :  X  s  X  t  X  1 If rand  X  X  r q s  X  t  X  and v i  X  t  X  X  1 s  X  t  X  1  X  :  X  s  X  t  X  Otherwise :  X  3  X 
Fig. 3 shows the resulting stochastic transition graphs for resolu-the stochastic environment on material 1, and the graph below shows the transitions for feedback on material 2. Notice how the introduced by accessing the materials with frequencies proportional not produce any absorbing states, and is, accordingly, ergodic supporting dynamic environments. The effect of these properties is analysed in the next subsection.
 1. To provide accesses to the stochastic environment in a 2. To make sure that the unit volume value functions are
The reader should note that our scheme does not rely on accessing the unit volume value functions sequentially with frequencies proportional to ~ x for solving the knapsack problem.
However, this restriction is obviously essential for solving the problem incrementally and online (or rather in a  X  X  X eal-time X  X  manner). Note that since it, in some cases, may be essential to access each unit volume value function with a constant period and not randomly (for example, in the earlier-alluded-to problem which analyzes web page polling), we use the earliest deadline first (EDF) scheduling to access the functions according to ~ x . 3.1.2. Analysis of the TRAA solution
In this section we characterize the optimal solution to a stochastic NEFK problem. Thereafter, we analyze the feedback connection of the TRAA and the stochastic environment  X  we prove that the TRAA is asymptotically optimal in the sense that the stochastic NEFK problem.
 stochastic NEFK problem if (1) the derivatives of the expected material amount values are all equal at ~ x , (2) the mix fills the knapsack , and (3) every material amount is positive , i.e .,  X  x 1  X  X  X  f 0 n  X  x n  X  The above lemma is based on the well-known principle of
Lagrange multipliers ( Bretthauer and Shetty, 2002 ; Fox, 1966 ), and its proof is, therefore, omitted here for the sake of brevity.
Instead, we will start by analyzing the two-material problem and the TRAA. Multiple TRAAs will then be organized in a hierarchy with the aim of tackling n-material problems.

Theorem 1. The TRAA solution scheme specified by (1) X (3) is asymptotically optimal .

Proof. Our aim is to prove that as the resolution, N , is increased verges towards the solution of the problem, x n 1 , implying that: lim
We shall prove the above by analyzing the properties of the underlying Markov chain, which is specified by the EDF scheduler, the rules (1) X (3) (the TRAA), and the environment. As can be seen from (1) X (3), the states of the chain are the integers j
A
EDF Scheduler and the Environment, obey the Markov chain with transition matrix H  X  X  h ij , where h j , j 1  X  r j p 2  X  r j  X  q j , 1 o j r N  X  4  X  q r = 3/6 r 3 3 1 h h and, accordingly, h h Clearly, H represents a single closed communicating class whose periodicity is unity. The chain is ergodic, and the limiting prob-ability vector is given by the eigenvector of H T corresponding to eigenvalue unity. Let this vector be P  X  X  p 1 , p 2 , ... , p satisfies h h 2 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4
The details of solving Eq. (9) are quite cumbersome, and we undertake it now. Observe that our aim is to prove that the probability mass of P lies arbitrarily close to the solution of the through the fine details, we outline the proof strategy as follows. We first explicitly solve for the quantities f p i g by solving the underlying difference equations. We then define a function U that forms an upper bound for P . We proceed to show that the upper the resolution, N , goes to infinity. Accordingly, since P is a the resolution towards infinity moves the probability mass of P
The details of the proof follow. Our first step is to reformulate the individual row-wise equations from the matrix Eq. (9) recursively. Expanding the first row of Eq. (9) yields Expanding the second row of Eq. (9) and substituting Eq. (10) yields
Arguing in a similar way in a row-by-row manner, it can be seen that  X  for 0 o k r N , which, on reversing the recursion, yields for 0 r k o N ,  X 
Let a  X  x 1 , N  X  X b x 1 =  X  1 = N  X  1  X c and b  X  x 1 , N  X  X d x  X   X  x approximate x 1 given the resolution N . In particular, with terms of p z and p z  X  1 , using (12) X (13). More specifically, for j
A f 1 , ... , z 1 g we have  X 
Correspondingly, and arguing in an analogous manner, for j
A f z  X  2 , ... , N g we have  X 
In other words, we represent P in terms of two of its components: We are now ready to define the upper bound U for P :
U  X  i , z  X  where
M  X  max max As seen, the definition of M clearly makes U an upper bound for P .
U goes to zero outside an arbitrarily close vicinity of x n lim U  X  a  X  x 1 , N  X  , a  X  x n 1 , N  X  -0if x 1 a x n 1  X  18  X 
We shall argue that the latter is guaranteed to happen if we have 0 o  X  h k , k 1 = h k 1 , k  X  o 1 for k A f 2 , ... , z g and 0 for k
A f z  X  1 , ... , N 1 g , because then we get 0 o M o 1. We argue for any finite N . This argument can be separated into three different cases as in Oommen (1997) : maximum is quickly reached and then geometrically falls away. 2. When z = N  X  1 is close to 1, the value of p i geometrically increases but when the maximum is reached it quickly falls away. For both these cases when N -1 , most of the prob-ability mass will be centered in a small interval around z . 3. The third case is slightly more complex because it involves z = N  X  1 being away from either end. This case must be broken down into two distinct geometric series, one representing the The first series increases until it reaches the maximum at p have lim lim
Secondly, from Lemma 1 we can conclude that p 1  X  q k  X  4 p k A f 2 , ... , z g . Therefore, 0 o h k , k 1 = h k 1 , k goes to infinity.
 1 , ... , N 1 g follows analogously, and the proof is left out here for the sake of brevity.
 means that the probability mass of P will lie arbitrarily close to x n 1 . In other words, the TRAA is asymptotically optimal. &amp; 3.2. Details of the H-TRAA solution 3.2.1. Design of the H-TRAA solution material problems. The scheme takes advantage of the TRAA X  X  ability to solve two-material problems asymptotically, by orga-nizing them hierarchically.
 hereafter will refer to as H-TRAA, is constructed as follows. of all, the hierarchy is organized as a balanced binary tree with three entities: (1) a set of materials, (2) a partitioning of the material set into two subsets of equal size, and (3) a dedicated
TRAA that allocates a given amount of resources among the two subsets.

 X 
At depth D , then, each individual material can be separately assigned a fraction of the overall capacity by way of recursion, using the above allocation scheme.

Interaction of the H-TRAA with the EDF scheduler and environ-ment . As in the single TRAA case, the H-TRAA interacts with an
EDF scheduler, which suggests which unit volume value function p  X  x i  X  to access next. A response is then generated from the the TRAAs that were involved in determining the material amount x , that is, the TRAAs in the hierarchy that have allocated capacity to a material subset that contains material i . Finally, a new to the EDF scheduler.

Example 1. Consider a 4-material problem. Fig. 4 shows the associated hierarchy, constructed as described above. At the root level the TRAA T 1 , 1 divides the knapsack capacity among the two-of the capacity among material 1 and material 2, while TRAA T assigns its share of the capacity to material 3 and material 4.
Based on the present assignment at time t , the EDF Scheduler environment. The stochastic environment, in turn, responds with a randomly drawn material unit volume value, v i ( t ), using the states accordingly, and the feedback loop continues. 3.2.2. Analysis of the H-TRAA solution
In the previous section we proved that an individual TRAA is asymptotically optimal. We will now consider the H-TRAA and prove its optimality. More specifically, we shall show that if each individual TRAA in the hierarchy has solved its own two-material problem, a solution to the complete n -material knapsack problem has also been produced.
 T , in the H-TRAA has found a local solution with proportions c the overall knapsack problem involving n materials that are hier-optimum solution .
 Proof. We intend to prove the above theorem by means of induction, using the hierarchical H-TRAA structure defined in the paragraph titled construction of hierarchy .

Basis :The Basis case concerns the nodes at the leaves, which, indeed, deal with the primitive materials themselves. Let a and b since a and b are the only two materials relevant to this TRAA, by virtue of the construction of the TRAA, x a = x a  X  x b and x the conditional probabilities of choosing a and b , respectively, conditioned on the event that the knapsack had only to be filled with these primitive materials. Since, by virtue of Theorem 1, we know that the TRAA will find a local solution  X  x a , x b the solution determined by the Lagrangian yields thus proving the basis of the induction.

Induction step : Consider any interior-node TRAA T d , j whose index at depth d is j in the H-TRAA hierarchy. The TRAA associated with this node decides how to allocate an assigned capacity c among two disjoint subsets S d  X  1 , 2 j 1  X f a 1 , ... , a f b 1 , ... , b m g of composite materials, where each a i and b itself, a primitive material. To simplify notation, let ~ a  X f a g and ~ b  X f b 1 , ... , b m g . Observe that the union of the sets ~ b is the input to the present TRAA, and the task of this TRAA is to Lagrangian solution for these two mutually exclusive and exhaus-the quantities x ~ a and x ~ b . Observe that since ~ a and two materials 11 relevant to this TRAA, by virtue of the construc-tion of the TRAA, x ~ a = x ~ a  X  x ~ b and x ~ b = x ~ a event that the knapsack had only to be filled with these compo- X  x ~ a  X  X  f 0 ~ b  X  x ~ b  X  where ,  X  21  X   X  x ~ a  X  X   X  x  X  X 
Since each a i and b i is a primitive material, and we are working our way up the H-TRAA hierarchy, we can invoke the inductive hypothesis to relate x a i and x b hypothesis and the Lagrangian solution at every level up the H-TRAA till level d , we know that for both of the material subsets
S  X  x 1  X  X  X  f  X  x 1  X  X  X  f
To simplify the notation, let each of the quantities in Eq. (24)
Substituting Eqs. (24) and (25) (which represent the induction hypothesis) into Eqs. (22) and (23), the latter become  X  x  X  X  f 0 a  X  x a  X   X  x  X  X  f 0 b  X  x b  X 
The summations on the RHSs of both of the Eqs. (26) and (27) can be trivially seen to sum to unity since they represent probabilities (in the conditioned spaces), implying that 8 i : f ~ a  X  x ~ a  X  X  f 0 a i  X  x a i  X  and  X  28  X  8 i : f b  X  x ~ b  X  X  f
Combining the above with Eq. (21) yields  X  x 1  X  X  ...  X  f implying that the global optimum required by the Lagrangian has been found. Hence the theorem! &amp;
Remark 1. Theorem 2 has some very interesting consequences listed below: 1. The proof of Theorem 2 has tacitly assumed that all the automata have converged before the global convergence can be asserted. This implies that the TRAA T d , j is aware of its capacity, and that this is a known quantity to the TRAAs
T converge to their local optimum, Theorem 2 states that the global optimum is attained. Conceptually, this can pose a small implementation-related problem. The fact is that the TRAAs of the lower level are converging even while the TRAA at the higher level is attempting to find its capacity. Therefore, essentially, the lower level TRAAs are working in a nonsta-tionary environment. The strategy by which we can resolve this is to ensure that the higher level automata converge at a slower rate than the lower ones (thus guaranteeing a certain level of stationarity). In practice, however, we have observed that if the resolution parameter N is large enough (in the order of hundreds) the time varying phenomenon is marginal, and the TRAAs at all the levels tend to converge simultaneously. 2. Theorem 2 claims that the solution obtained by the conver-gence of the individual TRAAs leads to the global convergence of the overall optimization problem. But this claim means that the ordering of the materials at the leaf nodes does not carry any significance. This is, indeed, true! It turns out that if the nodes at the leaves are ordered in such a way that  X  X  X ore precious materials X  X  lie in the same sub-tree, the weight associated with the sub-tree of the composite material 4. Experimental results: optimal polling frequency determination 4.1. Problem background set the NEFK, we shall now demonstrate how we can utilize this solution for the current problem being studied, namely, the optimal web polling problem.
 update detection probability of a web page i as d i . Under the polled with, and is modelled using the following expression:
By way of example, consider the scenario that a web page remains unchanged in any single time step with probability 0.5. Then polling the web page uncovers new information with probability every 2nd time step. As seen, increasing the polling frequency reduces the probability of discovering new information on each polling.
 polling frequencies ~ x that maximize the expected number of pollings uncovering new information per time step: maximize subject to 4.2. H-TRAA solution must define the stochastic environment that the LA are to interact with. As seen in Section 3, the stochastic environment consists of the unit volume value functions F 0  X f f 0 1  X  x 1  X  , f 0 which are unknown to H-TRAA. We identify the nature of these functions by applying the principle of Lagrange multipliers to the above maximization problem. In short, after some simplification, it can be seen that the following conditions characterize the optimal solution: d 1  X  x 1  X  X  d 2  X  x 2  X  X  X  d n  X  x n  X  1 d i  X  x i  X  and to the value 1 with probability d i  X  x the web page i is polled and i has been updated since our last
And, if the web page i is unchanged, we consider f 0 i  X  x been instantiated to 0. 4.3. Empirical results 4.3.1. Experimental setup
In this section we evaluate our learning scheme by comparing data. We have implemented the following classical policies, non of which invokes the knapsack problem.

Uniform : The uniform policy allocates monitoring resources the four that can be applied directly in an unknown environment.
Proportional : In the proportional policy, the allocation of monitoring resources to web pages is proportional to the update frequencies of the web pages. Accordingly, this policy requires that the web page update frequencies are known.

Estimator : The estimator policy handles unknown web update frequencies by polling web pages uniformly in a parameter estimation phase, with the purpose of estimating update frequen-cies. After the parameter estimation phase, the proportional policy is applied, however, based on the estimated frequencies.
Optimal : This policy requires that update frequencies are known, and finds the optimal solution based on the principle of Lagrange multipliers ( Pandey et al., 2003 ; Wolf et al., 2002 ).
To evaluate web resource allocation policies, recent research The Zipf distribution can be stated as follows ( Wikipedia, 2006 ):
Z  X  k ; s , N  X  X  1 = k s P N where N is the number of elements, k is their rank, and s is a parameter that governs the skewed-ness of the distribution (e.g., for s  X  0 the distribution is uniform).

For our experiments, web pages are considered ranked accord-ing to their update frequencies, and the update probability of a web page is calculated from its rank. We use the following function to determine the update probability of each web page: q  X  a , b  X  X  a determines the skewed-ness of the distribution, while a A represents the magnitude of the update probabilities (i.e., the web page of rank 1 is updated with probability a each time step).
Without loss of generality, we normalize the web page polling capacity in our experiments to 1.0 poll per time step, and accordingly, we vary the average total number of web page updates per time step instead.

As we will see in the following, it turns that one of the strengths of the H-TRAA is its ability to take advantage of so-called spatial dependencies among materials. As mentioned ear-lier, in the above experimental setup, materials are spatially related in the sense that the updating probabilities decreases with the rank-index k . In order to starve the H-TRAA from this information, we opted to perturb this spatial structure. Each perturbation swapped the updating probabilities of a randomly selected material and the material succeeding it in the ranking.
Based on the above, we conducted our experiments with 10 3 10 5 and 10 6 perturbations.

The results of our experiments are truly conclusive and confirm the power of the H-TRAA. Although several experiments were conducted using various a , b , and number of automata, we report case from Pandey et al., 2003 ) within the following environments: a  X  0 : 3; b  X  1 : 5, where the average number of updates per time step is 0.76 and accordingly, below the web page polling capacity. The web page update distribution is highly skewed, as explored in Pandey et al. (2003) . a  X  0 : 3; b  X  1 : 0, where the average number of updates per time step is increased to 2.0 (twice the web page polling capacity) by making the web page update distribution less skewed (the normal Zipf distribution). a  X  0 : 9; b  X  1 : 5, where the average number of updates is set to 2.3 by increasing the web page update probability. Because of the high values of both a and b , this environment turns out to be the most challenging one, discriminating clearly between the optimal policy and the proportional policy.
 For these values, an ensemble of several independent replications with different random number streams was performed to mini-mize the variance of the reported results. 4.3.2. Configuring the H-TRAA
The H-TRAA can be configured by various means. First of all, the material amount space (0, 1) need not be discretized uni-formly. Instead, a nonlinear material amount space can be formed, as done for the LAKG in Granmo et al. (2007) . Further-more, the discretization resolution N must also be set for each TRAA, possibly varying from TRAA to TRAA in the hierarchy. In short, the performance achieved for a particular problem can be optimized using these different means of configuring the H-TRAA. In this section, however, our goal is to evaluate the overall performance of the H-TRAA, without fine tuning. Therefore, we will only use a linear material amount space, as specified in Section 3. Furthermore, we will use the same resolution N  X  500 for all the TRAAs in the hierarchy, independent of the specific knapsack problem at hand. Thus, our aim is to ensure a fair comparison with the present state of the art, namely, the LAKG scheme.

While the focus of the previous section was on learning only from material units of value 1 (rewards), with some simple modifications the H-TRAA scheme clearly supports the three well-established updating approaches: when a material unit volume value of  X 1 X  is given as the feedback from the stochastic environment, which is the case studied in the previous section. when a material unit volume value of  X 0 X  is given as feedback.
Here, the reader will observe that the state transitions of the individual TRAAs from Section 3 are inverted. 3. Reward-penalty : In this case, the H-TRAA updates its state in both of the above cases.

When exposed to the  X  a  X  0 : 9 , b  X  1 : 5  X  -environment, we see from Fig. 5 that the inaction-penalty updating is the most accurate of the three approaches. However, the reward-penalty updating converges more quickly, since the state is updated both on rewards and on penalties. Only relying on re wardsisslightlyinferiortothe we emphasize speed of learning in this paper, we will, in the following, only use reward-penalty updating. But we note, however, that the two other approaches produce similar results. 4.3.3. Static environments
We see from Fig. 6 that the proportional policy and the optimal policy provide more-or-less the same solution  X  a solution super-ior to the uniform policy solution. We also observe that the performance of the estimator scheme increases steadily with the length of the parameter estimation phase. The figure also shows the performance of the H-TRAA increases significantly quicker than the LAKG and the estimator schemes. However, when increasing the number of perturbations, the performance of the H-TRAA is reduced. Indeed, with 1,000,000 perturbations, the
LAKG turns out to converge both more quickly and more accu-rately than the H-TRAA. Note that even with 1,000,000 perturba-tions, the H-TRAA provides performance equal to the LAKG if each as the resolution applied by any of its children. However, then the performance advantage of the H-TRAA is lost for the less per-turbed cases. In this sense, the H-TRAA is more flexible than the
LAKG, performing either better or similarly when the H-TRAA configuration is optimized for the problem at hand. Note that, in contrast to the estimator scheme, the performance of both the
H-TRAA and the LAKG is improved online (in a real-time manner) without invoking any parameter estimation phase.

As seen in Fig. 7 , a less skewed web page update distribution function makes the uniform policy more successful, mainly because a larger number of web pages will have a significant probability of being updated. For the same reason, the estimator scheme is able to lead to an improved performance quicker. In spite of this, the H-TRAA yields a superior performance. 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Expected Value 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 Expected Value environment with a highly skewed web page update distribution  X  b  X  1 : 5  X  combined with a high update probability  X  a such an environment, the optimal policy performs significantly better than the proportional policy, and so any scheme that converge towards a proportional policy solution will not attain an optimal performance.
 performance boundary set by the proportional policy, and con-verges towards near-optimal solutions. The H-TRAA converges slightly quicker compared to the LAKG. 4.3.4. Dynamic environments ging because the optimal solution is time dependent. In such cases, the current resource allocation solution should be modified according to the environmental changes. When, additionally, the environment and its characteristics are unknown, any changes must first be learned before any meaningful modification can take place.
 ranking of the web pages at every r th web page poll  X  a single web page is selected by sampling from the current Zipf-distribution, and this web page switches rank with the succeeding web page in the ranking. As a result, the Zipf-distribution also changes. This means that the web monitor is allowed to conduct r web page polls before the environment changes. Fig. 9 demonstrates the ability of our scheme to re-learn in a switching environment for r  X  80 , 000.

As seen in the figure, the H-TRAA quickly recovers after the environment has changed, and then moves towards a new near-optimal solution. Also, the H-TRAA clearly outperforms the LAKG.
In the previous dynamic environment, the H-TRAA was able to fully recover to a near-optimal solution because of the low frequency of environmental changes. Fig. 10 demonstrates the behavior of the automata in a case when this frequency is increased to r  X  1000.

As seen, the automata still quickly and steadily improve the initial solution, but are obviously never allowed to reach an optimal solution. The reader should, however, note how the quickly-changing environment is not able to hinder the automata from stabilizing on a solution superior to the solutions found by Expected Value Expected Value the estimator scheme. Again, the H-TRAA performs better than the LAKG.

Clearly, these results demonstrate how the H-TRAA can per-form when the environment is switching with a fixed period (in this case r  X  80,000 and r  X  1000). However, we believe that similar results will be obtained if r is not fixed, but changing in such a way that the scheme has enough time to learn the parameters of the updated environment. 4.3.5. Scalability
One of the motivations for designing the H-TRAA was to obtain improved scalability by means of hierarchical learning. As seen in Fig. 11 , extending the number of materials significantly increases the convergence time of the LAKG. An increased initial learning phase may be unproblematic in cases where the system will run correspondingly longer, adapting to less dramatic changes as they occur. However, as also seen from the figure, the adaptation speed increases with the number of materials too, when the LAKG is used.

The H-TRAA, however, is far less affected by the number of materials. In Fig. 12 we observe that the initial learning phase is orders of magnitude faster than what can be achieved with the LAKG. Furthermore, the impact on adaptation speed is negligible! 5. Conclusions and further work
In this paper, we have considered the optimal web polling problem, which involves determining a strategy for monitoring the world wide web. The problem consists of repeatedly polling a selection of web pages so that changes that occur over time are detected. In particular, we have considered the case where we are constrained to poll a maximum number of web pages per unit of ing communication bandwidth, and by the speed limitations associated with the processing. Since only a fraction of the web pages can be polled within a given unit of time, our problem has been that of determining which web pages are to be polled, and we have attempted to do this in a manner that maximizes the number of changes detected is a reasonable choice. To solve the problem, we first modelled it as a stochastic nonlinear fractional knapsack problem . We then presented a completely new online learning automata (LA) system, namely, the hierarchy of twofold resource allocation automata (H-TRAA), whose primitive compo-nent is a twofold resource allocation automaton (TRAA). Both the
TRAA and the H-TRAA have been proven to be asymptotically optimal.

Comprehensive experimental results demonstrated that per-formance of the H-TRAA is superior to previous state-of-the-art schemes, and in particular, to a previously reported strategy which solves the same problem, the LAKG. We have also demon-strated that the H-TRAA scheme adapts to switching web dis-tribution functions, allowing us to operate in dynamic environments. Finally, we have also provided empirical evidence to show that the H-TRAAs possess a sub-linear scaling property.
In our further work, we aim to develop alternate LA-based solutions for different classes of knapsack problems, including the
NP-hard integer knapsack problem, which we hope to then apply to the www. Indeed, we are also currently investigating how other classes of LA can form the basis for novel knapsack-based learning problems.
 References Expected Value Expected Value
