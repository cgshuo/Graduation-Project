 Korea Institute of Science and Technology, Biomedical Research Institute, Cent er for Bionics, Seoul, Korea Department of Computer Science, Brigham Young University, Provo, UT, USA 1. Introduction
The Radial Basis Function Network (RBFN) architecture and learning algorithm were first introduced by Moody and Darken [21,22]. Although over 20 years old, RBFNs continue to be used routinely, and successfully, in modern classification applications, in areas including image processing [3,8,33], engineering [11,17,24,30] and medicine [9,18,19]. RBFNs are typically described in terms of a three-layer feed-forward network architecture. However, they differ from classical multi-layer perceptrons in three significant ways. 1. RBFNs have only one set of trainable weights, from the hidden layer to the output layer. 2. In RBFNs, the nodes of the hidden layer are local attractors that encode a set of well positioned 3. While RBFNs, like multi-layer perceptrons, may be trained in a fully supervised manner, that RBFNs can be used for both classification and regression tasks. We restrict our attention here to the use of RBFNs in classification learning. In this context, the local attractor functions computed by the hidden nodes are Gaussian functions, where means represent centroids, and standard deviations characterize strengths and reaches of influence.

During the training phase, the parameters of the Gaussian functions are usually obtained via clustering (e.g., k -means), while the values of the output weights can be obtained efficiently through conjugate gradient descent or some form of regression (e.g., ordinary least squares). The exact behavior of RBFNs depends on two major design decisions. 1. Number of basis functions or hidden nodes.
 2. Organization of basis functions in input space.

It is well known to machine learning and data mining experts that variants in implementation and pa-rameter settings may dramatically impact the behavior and performance of learning algorithms. RBFNs are, of course, no exception.
 A 2011 KDnuggets survey of usage of data mining/analytic tools revealed that the top 7 tools are RapidMiner, R, Excel, SAS, Your own code, KNIME, and Weka. As it turns out, the implementation of RBFNs is the same in RapidMiner, KNIME and Weka. The details of SAS X  implementation are not publicly available, and while R has libraries (e.g., neural) and Excel has add-ins (e.g., NeuroSolutions) that implement RBFNs, these tools are generally used for data analytics tasks other than classification. We show here that the implementation of RBFNs in Weka, and hence in the three most popular open source data mining software packages, causes the algorithm to behave like the na X ve Bayes (NB) learn-ing algorithm. This result has serious implications for both practitioners and researchers, including the following.  X  Most practitioners, who lack the needed know-how, confine their use of tools to default parameters.  X  It has long been known that the value of an ensemble resides in the diversity of its constituent learn- X  Much of the work in metalearning has focused on building models that select (or rank) classifica-researchers, must be weary of default implementations and parameters. Interestingly, it is rather unlikely that traditional perceptions about NB and RBFNs would have led to the present analysis. In addition to NB being probability-based and RBFNs being function-based, NB is a generative model while RBFN are discriminative ones. The root of the classification method subtree in the recent Data Mining Optimization ontology [13] splits on generative vs. discriminative methods, which would send NB down one branch and RBFNs down the other, thus also obfuscating any sense of similarity between them.

The paper is organized as follows. Section 2 highlights some relevant related work. Section 3 provides a brief overview of the NB and RBFN learning algorithms with particular focus on how they are imple-mented in Weka and its derivatives. Section 4 presents a comparative analysis of the behaviors of NB and RBFN, both theoretically, where possible, and empirically otherwise. Given the behaviorial similarity yet significant difference in efficiency, Section 5 shows how metalearning can be used to design a model for strategically choosing between NB and RBFN. Section 6 discusses some of the main implications of our findings, together with its limitations. Finally, Section 7 concludes the paper. 2. Related work
There are, of course, a large number of empirical studies comparing the performance of learning algo-rithms (e.g., see [7,16]). It has long been a tacit requirement for publication in the research community that anyone wishing to introduce a novel data analysis algorithm should compare it against at least a few others on some reasonable set of learning tasks. Less common are targeted comparisons involving a pair of algorithms and leveraging both empirical and analytical results, as we present here. Notable exceptions focus on broad classes of algorithms, such as the relationships between neural networks and statistical models (e.g., see [31]), and between generative (or informative) and discriminative models comparison of logistic regression and decision tree learning [25].

Most closely related to the analytical part of our study is the work comparing na X ve Bayes and logis-tic regression. Elkan shows that, for discrete inputs, na X ve Bayes is a generalization of logistic regres-sion [10]. Mitchell shows that, for continuous inputs, the form of P ( Y | X ) entailed by the assumptions of Gaussian na X ve Bayes with binary classification tasks is exactly the form used by logistic regres-sion [20]. Ng and Jordan explain that na X ve Bayes and logistic regression form what they call a genera-tive/discriminative pair [23]. They go on to demonstrate that the generative approach has higher asymp-totic error, but that two regimes of performance seem to be present. The generative approach reaches its asymptote faster than the discriminative approach, suggesting that the generative approach may be preferable for small number of examples and the discriminative approach for larger numbers. Likewise, we show that, given some restrictive assumptions on the learning tasks and parameters of RBFN, the de-cision boundaries used by NB and RBFN are of the same form. For more general, and realistic, settings the analytical approach does not generalize naturally, so that we move to an empirical study.
Our main conclusion, that NB and the classical default implementation of RBFN in Weka and its derivatives perform similarly in many situations, also confirms the early work of Specht on the design of probabilistic neural networks, where he showed that by changing the activation function of tradi-tional neural networks from sigmoids to Gaussians, it was possible to design a learning algorithm that approached Bayesian optimality [36].

Finally, metalearning has been used extensively to map learning tasks to learning algorithms [1,5,6, 27,28,34]. In doing so, one of the goals of metalearning is to increase our understanding of the nature of base-level learning algorithms and in turn our ability to apply machine learning more effectively and extensively. In that sense, metalearning is a natural complement to analytical and theoretical studies of algorithm behavior. Our use of metalearning here to build a model that discriminates between NB and RBFN follows in that tradition. 3. Preliminaries
Prior to our detailed analysis, we give a brief overview of na X ve Bayes and radial basis function network learning. 3.1. Radial basis function network
As stated above, the hidden nodes of RBFNs are local attractors whose influence decreases as the K h is such that it reaches its maximum at  X  h and decreases smoothly as d (  X  h ,x ) increases. Following produce the final network X  X  outputs.

Let H be the number of hidden nodes or kernel functions, and m be the number of target classes. The network has m  X  1 output nodes, each computing f j ( x ) ( 1 j m  X  1 ): where w 0 ,j is a bias weight. The predicted class for query instance x is then given by c RBF N q ( x )= Weka X  X  RBFN is a standard, class-sensitive implementation, as discussed in [4]. It works as follows. Note that, by default, Weka X  X  RBFN sets k =2 .
 1. Construct mk clusters by applying k -means clustering to each class independently, and fit a Gaus-2. For each cluster, create a hidden node and set its radial basis function to the Gaussian weighted by 3. Run logistic regression on the hidden nodes to obtain the weights. 3.2. Na X ve Bayes
The na X ve Bayes learning algorithm (NB) is a practical and efficient probability-based learning algo-rithm built upon the assumption that the task X  X  features are conditionally independent given the target C : probability, which using Bayes X  Theorem and the independence assumption simplifies to:
As we restrict our attention to learning tasks with continuous attributes, P ( X i = x i | C = c j ) is assumed to follow some probability distribution. The most common approach, and that also used in Gaussian, we have and it follows that 4. Analysis of algorithms
In this section, we compare RBFN and NB, as implemented in Weka and its derivatives. We rely on both analytical and empirical tools. For our empirical analyses, we study the difference (reciprocally, similarity) in predictive behavior between RBFN and NB, using Classifier Output Difference (COD), a measure originally proposed to ensure diversity in ensembles [26]. Given two learning algorithms l 1 and l as accuracy, which provide an average performance over all instances, COD captures local variations among instances. For example, even though l 1 and l 2 may have the same overall accuracy on some correctly, and vice versa. As we do not typically have access to probabilities, we use frequency-estimates t . Then, Hence,
We have shown elsewhere that 1) COD satisfies the properties of a metric, and can thus be used as a valid distance function among classification learning algorithms; and 2) COD is strictly stronger than accuracy, in the sense that if two algorithms are close based on COD, they must also have similar accuracy [14]. We average COD values over a sample of 85 datasets: 28 from the UCI Machine Learning Repository [2], 45 from the Gene Expression Machine Learning Repository [37] and 12 from the Multi-class Protein Fold Recognition Data (http://www.cs.odu.edu/  X  sji/resources/index.html). 4.1. RBFN with k =1
Recall that c NB q ( x )= argmax c we model each class with a single cluster. To fit a Gaussian to each cluster in this case, Weka uses a multivariate Gaussian for the cluster is simply the product of the univariate Gaussians for each input. 1 Hence, and the radial basis function for each hidden node is given by: Let us further assume that m =2 , i.e., there are only two target classes, c 1 and c 2 . The corresponding RBFN thus has n input nodes, 2 hidden nodes and a single output node. The outputs of the hidden nodes are given by: which we abbreviate to k 1 and k 2 respectively, for simplicity. Note that:
These values are fed into Weka X  X  logistic regression learner to obtain the weights. However, prior to are: and that best separates the two classes. Such a decision boundary is orthogonal to the line on which the  X  1 =  X   X  2 =  X  . It follows that:
Consequently, the discriminant function for RBFN, is: and k s 2 , we rewrite  X  PRBFN ( x ) in terms of k 1 and k 2 , yielding: which, in terms of discriminative ability, is equivalent to: G Hence, the discriminant function for NB is simply:
The similarity between  X  RBFN and  X  NB is obvious, with the former being a small generalization of the latter. NB X  X  resulting decision boundary, together with a possible RBFN X  X  decision boundary (when  X  =0 . 45 ) are depicted in Fig. 1. The thick segments represent the projections of the input space onto predictions of NB and RBFN are identical for all points except those that lie between the two parallel decision boundaries. It is possible that, even when the two boundaries do not coincide exactly (i.e.,  X  =0 for RBFN), this set may be empty, and the behaviors of NB and RBFN would still be identical. In general, we expect some small variations in behavior.

As an illustration, Fig. 2 shows the values of COD with respect to  X  for all 56 binary classification tasks in our selection of datasets. As expected, most points have small COD values and also congregate around small values of  X  . The two most significant outliers correspond to the UCI parkinsons dataset (COD = 0.46) and the UCI Wisconsin prognostic breast cancer dataset (COD = 0.31). A close look at these datasets reveals that in both cases they contain several attributes whose mean values are close to 0 (for both target classes). Since the multivariate Gaussians defined for each class are products of the univariate Gaussians defined over each attribute, attributes with mean around 0 tend to bring the products will be small (  X  0 ) and on either side of 0, giving rise to a somewhat random classifier. On the other learner whose predicted class depends on the signs of  X  0 and  X  (  X  is positive). It follows that in such cases, the behavior of NB and RBFN may become significantly different.

While for m =2 the inputs to logistic regression in the RBFN learning scenario lie on the line the hyperplane defined by m i =1 k s i =0 . However, the foregoing analysis of discriminant functions and geometry of decision boundaries does not generalize easily in this higher-dimensional space. Hence, we resort to an empirical analysis of the value of COD as m increases. Our selection of 85 datasets accounts for values of m between 2 and 28. However, for most of these, except for m =2 ,thereare 12 or less datasets with that value of m . Hence, we extend our selection of datasets so that each value of m ends up with 85 datasets. To do so, we use an approach inspired by the notion of datasetoids [35]. Datasetoids are transformed versions of existing datasets where the original target attribute is replaced by one of the dataset X  X  symbolic attributes. Hence, given a dataset with symbolic attributes S , one can other attributes. We make a small extension here by allowing any attribute to be selected as the new target, discretizing as needed. We also remove the original target attribute from the dataset. We thus generate a number of complementary datasetoids, so that for each value of m there are 85 datasets or datasetoids available to compute COD. The procedure is as follows for each m . 1. Let d m be the number of datasets with m target values; 2. For each of the remaining 85  X  d m datasets, create a datasetoid: 3. Run NB and RBFN against all 85 datasets/datasetoids; 4. Compute average COD.

Figure 3 shows the resulting average value of COD for several values of m between 2 and 28. The graph shows a generally increasing trend, such that the difference in behavior between RBFN and NB becomes larger as the number of target values increases. The value for m =2 is very small, as expected, with a significant qualitative jump when m =3 and beyond.

We note, however, that even though the absolute value of COD between RBFN and NB increases with m (as one may expect), the values of COD over a large set of 20 other algorithms also increase (again, as one may expect), such that across all values of m RBFN X  X  behavior remains more similar to NB X  X  than to any of these 20 other algorithms, which include multi-layer perceptron, decision tree learning, logistic regression, k -nearest neighbors, and support vector machine. In other words, while COD values increase as m increases for all considered algorithms, relatively speaking, RBFN and NB are still closest in behavior.

Clearly, few people would think of k =1 as the best setting for RBFN, as it tends to nullify the advantage offered by  X  X ocalization X  and hybrid learning. The foregoing analysis confirms that such a choice is indeed not very judicious since it causes RBFN to behave like NB, clearly a computational overkill in most cases (we return to the issue of complexity shortly). As stated above, Weka uses k =2 as its implementation X  X  default value. We thus turn to the case when k&gt; 1 . 4.2. RBFN with k&gt; 1
As with larger values of m for k =1 , a direct comparison of discriminant functions and geometry of analysis of the value of COD as k increases. We expect that for k =2 the similarity between RBFN and NB may still hold, and possibly for a few larger values of k .However,as k gets larger, it would seem that the amount of similarity should eventually decrease as RBFN is likely to begin overfitting, while NB X  X  behavior remains unchanged. Figure 4 shows how the value of COD evolves with increasing values of k .

As expected, COD increases with k . Interestingly, RBFN is closest to NB only up to k =3 .Forlarger values of k , RBFN becomes closer to Random Forest. However, notice that the value of COD seems to between RBFN and NB seems to remain constant across values of k&gt; 3 .

At this point, we must ask an important question. We have already shown that choosing k =1 is prob-ably not judicious. Weka chooses k =2 , which still maintains significant behavior similarity between RBFN and NB. So the question is, should we choose larger values of k , and if we do, what kind of improvement might we obtain in terms of predictive accuracy for RBFN? Figure 5 shows how RBFN X  X  training time and predictive accuracy are affected by the value of k .

It is clear that while the training time increases noticeably with k , there is no significant change in predictive accuracy. This behavior is likely due to the overfitting alluded to above. Large values of k choice of k =2 , which results in km basis functions, is a good compromise between training time and predictive accuracy. Hence, we are left with a relatively high degree of similarity between RBFN and NB in realistic settings for both algorithms. 4.3. Consequence
There is an important practical consequence to this, since there is a significant difference in compu-tational complexity between NB and RBFN. Let T denote the number of training instances. Then NB is O ( Tn ) [10]. Since RBFN is a hybrid learner, we must consider the complexity of each of its parts. The complexity of k -means is O ( TnkI ) ,where I is the number of iterations [38]. Since Weka X  X  RBFN performs k -means for each class separately, its complexity is O ( TnmkI ) . In Weka X  X  RBFN, the weights for logistic regression are had using the quasi-Newton method whose complexity is O ( W 2 ) ,where W is the size of the weight vector [12, p. 197]. Here, W = H ( m  X  1) = km ( m  X  1) , so that the complexity than NB X  X  complexity. as shown on Fig. 5(a). Table 1 shows the ratio of RBFN X  X  to NB X  X  training time over our selection of datasets. On several occasions, RBFN takes several hours, while NB requires only a few seconds. Overall, RBFN is more than 22 times slower than NB on half of the datasets.

If that kind of difference does not give rise to a significant difference in predictive accuracy, one may be tempted to always use NB. However, recall that our empirical analysis relies on observations averaged across many datasets. So, while the observed similarity between RBFN and NB holds in the aggregate there are noticeable local variations. As a matter of fact, the value of COD between NB and RBFN over our 85 continuous datasets ranges between 0 and 0.88 (  X  = 0.16,  X  = 0.22), while their corresponding difference in predictive accuracy ranges between 0 and 20.83% (  X  = 2.83%,  X  = 3.98%).
 We thus turn our attention to analyzing these local variations, i.e., discovering what types of tasks RBFN is likely to be superior to NB. In other words, our similarity results suggest that unless RBFN performs significantly better than NB, we should simply use NB. What we would like to know is when it makes sense to incur the extra computational complexity of RBFN, and when it can be avoided at no significant loss to predictive accuracy.
 5. To RBFN or not to RBFN
In this section, we use metalearning in an attempt at characterizing the types of tasks on which the difference of behavior between RBFN and NB is significant and gives preference to RBFN. The reason we rely on metalearning is that, while it is easy to design simple cases where the performance of RBFN is much better than the performance of NB, these are generally somewhat pathological cases, and it is difficult to come up with an analytical form for more general cases.

From a practical standpoint, in all cases where NB has significantly higher predictive accuracy, as well as those where there is no significant difference between NB X  X  and RBFN X  X  predictive accuracy, one should run NB since this will produce the best accuracy in the least amount of time. Conversely, in all other cases, where RBFN does perform significantly better than NB, one might wish to run RBFN in spite of its much greater computational cost. We propose to use metalearning to provide a general mechanism for users to make such a decision. The metamodel is built to discriminate between NB and RBFN.

As stated above, there is some variance in the performance of NB and RBFN on individual tasks. We wish to know when these differences are significant. To find out, we run an unpaired student X  X  t-test on each of our datasets using 10-fold cross-validation, with a p-value of 0.05. A summary of the results is in Table 2.

At the metalevel, each of our 85 datasets is characterized by its values over a pre-defined set of metafeatures, as in other metalearning for classification approaches (e.g., see [1,6,27]). Our set of 38 metafeatures consists of a combination of statistical measures and a small set of landmarkers, including the following.  X  lgE : log of number of examples  X  lgREA : log of the ratio of number of examples to number of attributes  X  numClasses : number of target classes  X  numInstsPerClass : ratio of number of examples to number of target classes  X  RMajorClass : probability of majority class  X  landmarkerMajorityGuesser : majority class landmarker  X  landmarker1NN : 1-NN landmarker  X  landmarkerNaiveBayes : NB landmarker  X  meanCovarianceMatrix : average over all target values of the class-dependent means of at- X  normalizedKurtosis : normalized kurtosis  X  entireEntropy : class entropy
Each thus generated meta-example it is labeled with one of two target values: rbfn when RBFN sig-nificantly outperforms NB (18 instances), and nb otherwise (67 instances). The default accuracy, i.e., the accuracy when one predicts the most frequent class, is 67 85 = 78.8%. For the sake of comprehensibility, we use Weka X  X  J48 as the metalearner, with the following parameter values:  X  confidenceFactor: 0.25  X  pruning: true  X  minNumObj: 2 (min. number of instances per leaf) Figure 6 shows the induced decision tree. Interestingly, the highest decision nodes in the tree have to do is stated that NB usually performs better for smaller number of training examples, while logistic regres-sion performs better with larger training sets. Recall that Weka X  X  RBFN uses logistic regression to learn the output layer X  X  weights. Our selector tree suggests that when there are many examples, the predicted winner is RBFN (top branch: lgE &gt; 7.3025: rbfn (10.0) ). Conversely, when there are few examples, the predicted winner is NB (top branch: lgE &lt;= 7.3025 and lgREA &lt;= 1.4032: nb (40.0) ).

The tree X  X  confusion matrix, using 10-fold cross-validation, is shown in Table 3. Its overall accuracy is 87%, a significant increase over the default, which suggests that the metamodel X  X  predictions will yield performance improvements in the practical use of RBFN and NB. However, the off-diagonal values show a false negative rate (with respect to predicting NB) of 6% (4 of 67), and a false positive rate of 39% (7 of 18).

Looking closer at the selection task, we notice that the types of error the metamodel makes have different costs. When RBFN is mistakenly predicted as NB (false positive), the user loses accuracy but saves in training time. On the other hand, when NB is mistakenly predicted as RBFN (false negative), the user loses accuracy and incurs unnecessary additional training time. Clearly, the second type of error is consider ensemble-like learning algorithms for the metalearner. Our goal is to reduce as much as possible the false negative rate while not increasing the false positive rate. Our best metamodel is obtained by applying the idea of rotation forest with J48graft as the base learner and the default 50% of instances to be removed. The model X  X  overall accuracy is 91.8%, and its improved confusion matrix is shown in Table 4. Not only is this model more accurate, it only makes one false prediction for NB (1.5% false negative rate). Interestingly, the false positive rate is also slightly reduced to 33%.
 6. Discussion
We note that it is quite by accident that we were alerted to the behavioral similarity between RBFN and NB. We were conducting an experiment in which we used COD-based clustering to see whether pre-dictive behavior might lead to interesting groupings of algorithms [14]. Overall, and even more strongly so when restricting the study to datasets with all continuous attributes, RBFN was found to be closer to NB than any of 20 other algorithms.

It is worthwhile to investigate the limits of the behavioral similarity between RBFN and NB. We first consider the assumption of Gaussian kernels and then the assumption of class-dependency of said ker-nels. In both cases, we rely on COD-based clustering. To test the impact of the choice of basis functions, we perform clustering with five additional implementations of RBFN, as follows. Each implementation is denoted by a pair consisting of 1) the unsupervised learning algorithm used to build the hidden layer (EM or k-Means) together with the type of radial basis function used in the hidden layer (Gaussian or Thin Plate Spline), and 2) the supervised learning algorithm used to compute the weights of the output layer (Logistic Regression, Single Layer Perceptron, LibLINEAR or LibSVM).

Figure 7 shows the dendrogram obtained by averaging COD over all 85 continuous datasets using complete-linkage, hierarchical agglomerative clustering. The label RBFN corresponds to Weka X  X  de-fault implementation (KG + Log). The dendrogram suggests that the similarity between RBFN and NB is affected more by the choice of basis functions (or kernels) than by the choice of the supervised weight update method. Four out of the five Gaussian kernel RBFNs, with different supervised learning algo-rithms, cluster together first, followed by NB. The fifth Gaussian kernel RBFN, with a rather different supervised learning algorithm (SVM), clusters a little later. Finally, the non-Gaussian, thin plate spline kernel RBFN, with the standard logistic regression algorithm as supervised learning algorithm, is most unlike NB. Hence, conclusions about the similarity between RBFN and NB are valid as long as both use Gaussian kernels.

The other aspect of Weka X  X  implementation of RBFN that likely impacts the observed similarity be-tween RBFN and NB is the fact that kernels are class-dependent rather than shared across classes. To verify this, we perform clustering with three variations of shared kernels: RBFN + Raw1 (single hidden node), RBFN + Raw2 (two hidden nodes), and RBFN + Raw ( m hidden nodes). This last one is similar to k =1 in the standard Weka implementation, except that here there is no one-to-one correspondence between a hidden node and a target class.

Figure 8 shows the resulting dendrogram. Again, the label RBFN corresponds to Weka X  X  default im-plementation. The dendrogram clearly shows that there is no similarity between RBFN and NB when the basis functions are shared across classes. This should not be completely surprising given the anal-ysis of Section 4. Interestingly, when considering accuracy over our 85 datasets, RBFN is significantly ( p = 0.05) better than RBFN + Raw on 27 datasets, while RBFN + Raw wins only once, and there is no significant difference on the remaining 57 datasets.

Hence, we are certainly not claiming that RBFN and NB behave similarly in general. We have simply shown that the assumptions embedded in Weka X  X  implementations of these algorithms, specifically the use of Gaussian kernels and the choice of 2 class-dependent basis functions per class, make them behave rather similarly over a broad range of datasets. Interestingly, Weka X  X  assumptions are rather reasonable.  X  Gaussian kernels seem appropriate for classification tasks.
  X  Class-dependent kernels are natural and seem to outperform kernels shared across classes. 2  X  k =1 makes little sense and k&gt; 2 incurs unnecessary computational cost for no significant gain
As a result, our findings have important practical consequences, all of which have to do with being careful about default implementations and the type of tasks under study.  X  Use of default parameter values . Most practitioners, who lack the needed know-how confine their  X  Ensemble learning . It has long been known that the value of an ensemble resides in the diversity of  X  Metalearning for algorithm selection . Much of the work in metalearning has focused on building 7. Conclusion
In this paper, we have used a combination of analytical tools and empirical results to show that the implementation of RBFN in the three most popular open source data mining software packages causes the algorithm to behave and perform similarly to NB. We have also seen that the observed similarity is a direct result of the assumptions made by Weka X  X  implementation. However, we have argued that said implementation is natural and reasonable, so that the observed similarity is of practical value.
Having established that the observed similarity in no way suggests that the two algorithms have iden-tical behavior, but is true in the aggregate, we turned to metalearning for the development of a selection metamodel that could discriminate between RBFN and NB, and in particular accurately predict when the increase in training time caused by RBFN would be worthwhile, i.e., result in higher predictive accuracy for the learning task under consideration.

Finally, we have discussed some of the consequences of our finding specific to RBFN, where 1) unin-formed users who confine themselves to RBFN X  X  default implementation may incur unnecessary compu-tational cost, as NB would have produced a similar result in a fraction of the time; 2) ensemble designers may create learning systems with less diversity than expected; and 3) metalearning researchers may miss out on opportunities to design more effective cluster-based selection systems. Other attractive properties of NB, such as comprehensibility and incrementally would also be missed by selecting RBFN. While not all algorithms may thus be paired, it is clear that relying exclusively on default implementations is fraught with dangers. While the explicit setting of parameters is a well-known source of risk, the less obvious behavioral similarity that may exist between the default implementation of a complex algorithm and a simpler algorithm (as described here) is a source of risk that has been mostly overlooked. It is our hope that the discovery of similarities (resp. differences) among learning algorithms may prove useful in algorithm selection, ensemble learning and metalearning, and will help us get a better understanding of our science.
 References
