 1. Introduction Many large corporations and government agencies routinely and continuously collect and store large amounts of data. The magnitude of data collected often requires that it be stored in a number of independent repositories distributed over a network. Furthermore, data is often stored in a variety of diverse and incompatible data storage media, including CD-ROMs, legacy databases, etc. Because of the large volumes of data stored and the large number when searching for specific data or series of interrelated data. For example, NASA X  X  Earth Science Division continuously collects and stores vast amounts of environmental data for use by a large and diverse community of research scientists, engineers, and analysts. This data comes from a wide variety of sources, including orbiting satellites, weather stations, research aircraft, and others. Various Distributed Active Archive Centers (DAACs) around the globe collect and maintain this data on behalf of NASA; each of these DAACs is responsible for a 384 DAS ET AL. particular domain and maintains its data in its own distinct format. Researchers who require data stored in these archives often spend a great deal of time locating and integrating the specific data they require.

A simple scenario will demonstrate the process a researcher must perform in order to retrieve the specific information he wants. Imagine that an environmental scientist wants to know if there is a relationship between cloud cover and polar ice cover over the North Pole during the period between 1970 and 1990. Now imagine that the polar ice levels for the years between 1970 and 1979 are stored in archive A and levels for the years 1980 to 1990 are stored in archive B. The cloud cover levels for the South Pole are located on yet another archive, C. Suppose further that the researcher is only interested in the relationship between the mean cloud cover levels for a given year and the thickness of polar ice cover. In order to determine the results of his query, he must do the following:  X 
Locate the data for cloud cover levels and polar ice cover. In the process he would discover that the polar ice levels he wants reside on two different locations.  X 
Download the data from each of the three data sources. Note that the researcher must download all of the cloud cover data for the required dates and region even though he is only interested in the yearly mean values (which he must compute himself).  X  Combine the polar ice data from the two sources (A and B) that contained this information.
This may require him to convert data formats if the two sources differ (for example, the older source may represent ice thickness in feet, while the newer source uses meters).  X 
Compute the yearly mean values of the cloud cover data.  X  Calculate the correlation between the ice levels and cloud cover means.

This brief example demonstrates the time-consuming and labor-intensive task of retriev-ing and combining data from a group of distributed data centers. The entire process would be much simpler and faster if there existed a single, homogenous data repository. In this case, the user would not need to find the location any data, since it would all appear to be located in the same place. As will be discussed below, it is often impractical to store all required data in a single, homogenous data source. Instead we have chosen to leave the data at its original distributed sites, but abstract from the user the distributed nature of the data sites.

Our on-demand approach to data retrieval requires an infrastructure for retrieving data from distributed data sources based on the query requests that are generated from the user interface. We have used a mobile agent approach for data retrieval (Yang et al. 1998, Brewington et al. 1999). Mobile agents are autonomous agents that have behavior, state, and location (Kiniry and Zimmerman 1997). Mobile agents typically require two components for implementation. The part that moves around the network, the mobile agent itself, is often referred to as an ag ent process .A s mobile agents travel from location to location, they need the other component: a place to reside where they can execute. This place is often referred to as a place process or ag ency .W e use mobile agents because of their ability to carry with them data processing code to the site of the data; this allows for a substantial reduction in the amount of unprocessed data that need to be transferred across a network. Some of the commercial-off-the-shelf (COTS) software packages for mobile agents are: MOBILE AGENTS 385 IBM X  X  Aglets, Object Space X  X  Voyager, and Mitubishi Electric ITA X  X  Concordia (Mitsubishi Electric ITA 1998). For our effort we have explored several possible COTS packages for implementing the mobile agents, and we eventually selected the Grasshopper system from IKV Corporation (www.grasshopper.de ).

In addition, we also require an intelligent interface that accepts queries from users and answers using the underlying data retrieval infrastructure. The concept of a softbot (Etzioni and Weld 1994), an intelligent program that uses software tools on a person X  X  behalf, is highly relevant in this context. In the information retrieval context, a softbot or intelligent interface agent possesses the following desirable properties:  X 
Goal-oriented :A user X  X  request to the softbot indicates only what the user wants. The softbot is responsible for deciding how and when to satisfy the request using its query retrieval planner.  X 
Integrated : The softbot provides a single, expressive, and uniform interface (domain model) to a wide variety of Internet services and utilities, thus leveraging the existing infrastructure.  X 
Balanced : The softbot balances the cost of applying planning and traditional database query optimization techniques vs. the benefit of a more efficient retrieval.
 To meet these requirements, we have developed an Agent-based Complex QUerying and Information Retrieval Engine (ACQUIRE) for heterogeneous and distributed data sources and subsequently tested the system on simulated NASA Earth Science data repositories. AC Q UIRE resolves queries in the following three stages:  X 
Accepts as an interface agent or softbot a query from a user and decomposes it appro-priately into a set of sub-queries using site and domain models of the distributed data stores  X 
Intelligently creates an optimized plan for retrieving answers to these sub-queries over the Internet and spawns a set of intelligent mobile agents to delegate these tasks  X 
Appropriately merges the answers returned by the mobile agents and then returns them to the user The query plans that are created in the second stage as stated above are generally  X  X tatic X , in that the mobile agents retrieve data in a particular order based on an itinerary that is fixed at the time the plan is generated. We have enhanced the latest version of ACQUIRE in which the advantages of mobile agents are leveraged to optimize data retrieval by  X  X ynamically X  optimizing the retrieval strategy as it is carried out. This strategy equips each spawned agent with the full query execution graph and necessary code to execute the retrieval plan at any data site in the network. The spawned agents communicate and collaborate with each other to dynamically decide where to migrate, send data, and perform necessary computations. These decisions depend on retrieval factors such as network speed, data size, and the computational capabilities of the data servers involved in the retrieval.

It is important to stress that this paper reports on the results of an early prototype of our system, which has so far returned encouraging results. Although the results are preliminary, 386 DAS ET AL. we believe that the system described here could have a wide variety of application domains, particularly if mobile agent technology becomes suitably mature to accommodate sufficient security concerns. Based on our results thus far we have begun work on the next generation of ACQUIRE, for which we hope to have a more detailed analysis of its suitability to a wide range of practical data retrieval problems.

The rest of the paper is organized as follows. In Section 2, we describe the background w ork that has been done in the areas of distributed information retrieval and mobile agents. In Section 3, we describe the architecture of our prototype system, which consists of a core ACQUIRE host application operating within a larger network of data archives. In Section 4, we describe the implementation of ACQUIRE with a series of screenshots and sample queries. We also describe the system X  X  operational characteristics and present some e xperimental results from a series of tests based on static optimization of retrieval strate-gies. Section 5 describes the dynamic retrieval strategy and experimental results showing improvements in retrieval efficiency. In addition to a local application interface, we have also recently implemented a web interface to the ACQUIRE system, which is described in Section 6. Finally, in Section 7, we conclude with a discussion of future directions for this research. A shorter version of the work without the dynamic retrieval strategy and web interface can be found in Das et al. (2002a). 2. Background and related work This section surveys the areas of distributed information retrieval and mobile agents. 2.1. Distributed information retrieval Approaches to querying distributed heterogeneous data sources, which may include tradi-tional databases, knowledge bases, programs, Web pages, and data files, can be broadly categorized into the following two approaches (Widom 1996):  X 
A lazy or on-demand approach, where information is extracted from the sources only when the queries are posed  X 
An eager or in-advance approach, where relevant information is extracted in advance in anticipation to queries and stored in a central repository Answering a query in a lazy approach involves the following steps. First a set of appropriate data sources is determined to answer a given query, and then appropriate sub-queries are generated for each data source. Results from the data sources are translated, filtered, and merged to obtain the answer to the query, and returned to the user. On the other hand, in an eager approach, data from each source that may be of interest are extracted in advance, and then translated and filtered appropriately. Extracted data from various sources are then merged and stored in a centralized repository, which is known as a data warehouse. A user query is evaluated directly in the data warehouse, without accessing the original data sources.
 MOBILE AGENTS 387
It is obvious that a lazy approach incurs inefficiency and delay in query processing, especially when queries are issued multiple times. Each time a query is issued, a system that employs a lazy approach has to decompose the queries into sub-queries and then translate, appropriate for a frequently changing list of data sources, for data sources that are changing rapidly, for users with unpredictable needs, or for queries that operate over vast amounts of data from very large numbers of distributed data sources such as the World Wide Web. It is not simply practical to create another data repository from several data sources that are already huge and maintained autonomously at various NASA Distributed Active Archive Centers (DAACs). Thus adopting an on-demand approach for distributed heterogeneous Earth science databases seems quite appropriate, and our proposal to build ACQUIRE is based on such an approach.

There are a variety of on-demand approaches that have been proposed for querying heterogeneous and distributed databases. The trend seems to be towards a federated ap-proach, where a global schema for the databases concerned is developed, and queries are posed directly against it. One such system is Pegasus (Ahmed et al. 1991) that addresses the semantic heterogeneity problem by requiring administrators to write specific programs that will reconcile semantic differences. Similarly, unified views of multiple databases are provided in UniSQL (Kim and Seo 1991), and queries are processed against them. The concept of a  X  X ediator X  in DISCO (Tomasic et al. 1996) encapsulates a representa-tion of multiple data sources. The goal of the TSIMMIS project (Chawathe et al. 1994) is to develop tools that facilitate rapid integration of heterogeneous integration sources. The approach translates information into a common Object Exchange Model (OEM). The Information Manifold (Levy et al. 1995) provides a common object-relational model for integrating various information sources. The Carnot system (Collet et al. 1991) uses the Cyc knowledge base (Lenat and Guha 1990) representing a global schema for integrating heterogeneous databases. Rather than redo the global schema each time a new resource is to be integrated, the schemas of individual resources are independently compared and merged with the Cyc knowledge base, making a global schema easier to construct and maintain.

The problem with the above approaches is that schema integration is usually difficult, and as soon as any of the information sources change or a new source is added, the process may have to be repeated. To overcome this problem, SIMS (Arens et al. 1993) provides a general object-oriented model of the application domain that can be used to describe each available information source. Queries to SIMS against the collection of information sources are posed using terms from the global domain model, and reformulation oper-ators are employed to dynamically select an appropriate set of information sources and to determine how to integrate the available information to satisfy the query. SIMS uses a general-purpose planner to produce plans for gathering information from a set of distributed heterogeneous information sources. The query planning algorithm of Occam (Kwok and W eld 1996) also determines the best way to integrate data from distributed information sources. Occam takes a library of site descriptions and user query as input, and automati-cally generates one or more plans that encode alternative ways to gather answers to the query posed. 388 DAS ET AL. 2.2. Mobile agents T raditionally, retrieval from web-accessible databases is performed via an HTML form that is filled out by the user and posted to the database server as a query. The server acts on this request and returns the result back to the user. This approach has been adopted in NASA X  X  v arious database servers including EOSDIS data search (http://redhook.gsfc.nasa.gov/  X  imswww/pub/imswelcome/plain.html). This approach restricts users to a predefined query format based on a fixed set of search criteria. But ACQUIRE, which leverages and enhances e xisting data servers, requires a more flexible approach that will perform a variety of remote database queries as a result of query planning, create temporary relations, filter the results, and return those filtered and customized results back to the system. We perform queries to remote databases by sending queries to remote data servers with proper annotations to improve the data retrieval performance. Such transportation of annotated queries to remote data servers is achieved effectively with the help of mobile agent technology.

Mobile agents (Lange and Oshima 1998, Baumann et al. 1997, Harrison et al. 1995, White 1997) are autonomous agents that have behavior, state, and location. Having behavior means that the agent contains code that allows it to conduct operations on data. Possessing a state means that the agent can retain and update internal information based on the data it acquires and the results of its operations. Having a location is another way of saying that the agent is not restricted to a specific machine or site but may move from site to site. Finally, being autonomous means that the mobile agent has the capacity to dynamically determine its ow n itinerary and which operations it will perform. Mobile agents typically require two components for implementation. The part that moves around the network, the mobile agent itself, is often referred to as an agent process. As mobile agents travel from location to location, they need the other component: a place to reside where they can execute. This place is often referred to as a place process.

In an ideal situation, mobile agents would be able to visit any host, perform the necessary computations, and then return back to their originators. In practice, however, they are restricted only to homogeneous, trusted, and controllable networks. Lack of standards in mobile agent hosts restrict an agent X  X  movement to networks of only those hosts that conform to a given manufacturer X  X  unique protocols. The current efforts for developing executing environments are mostly being carried out in Java environments. Platform independence, virtual machines, secured class loading, serialization, RMI, and multithreading are some of the powerful features of Java that have made it a very lucrative platform for developing mobile agent systems (Kiniry and Zimmerman 1997). 2.2.1. Advantages and disadvantages of mobile agents Ak ey attribute of a mobile agent advantageous if the code is smaller than the data that it is operating on because less data needs to be sent back and forth across the network. Also, by minimizing the number of transactions across the network, there is a reduced chance of communication disruption due to network failures or excessive latency. Another important attribute of a mobile agent is that because it carries its behavior and state with it is a self-contained object. This is especially important for unstable or impermanent networks. The network needs to be active MOBILE AGENTS 389 just long enough for the agent process to move to the next place process. As soon as the agent process arrives, network failures will not affect the operation of the agent until it needs to move to another place process. Wireless devices in particular can benefit from this feature of mobile agents, since they frequently operate in environments of unstable network connections (Kotz et al. 2000). Finally, because a mobile agent is autonomous, it can change its itinerary and scheduled operations based on the data it encounters without requiring feedback from the originator. The originator can send off the agent and forget about it until it returns with the requested information. The agent can, for example, change its itinerary if it discovers that a network link is down. Or perhaps an agent can skip certain sites if it determines that the data located there is now no longer relevant.

A disadvantage of mobile agents is the requirement for there to be a place process at every potential location (Nelson 1999). This is complicated by the fact that there is no established standard for mobile agents, and offerings from different vendors are typically incompatible. Security needs to be monitored carefully. Care must be taken at the place process to ensure that any incoming agents do not access private data or corrupt any data. The agent process mobile agent systems address security in some fashion, but in open environments such as the Internet, security needs to be scrutinized carefully to defend against hostile agents and hostile places.

Fo r widespread acceptability of mobile agent technology, the very real security threats that a mobile agent poses must be addressed. These threats arise not only from malicious agents but also from malicious hosts as well. There are four security issues specific to a mobile agent based system (Gray 1998, Karjoth et al. 1997): (1) protection of hosts from malicious agents; (2) protection of agents from malicious hosts; (3) protection of agents from malicious agents; and (4) protection of the underlying network. Practical techniques are being developed to address these security concerns. For example, techniques for protecting hosts from malicious mobile agents can be found in Rubin and Geer (1998).

In addition to the security risks, there are other potential problems with using mobile agents for the purposes described here. Given the number of largely unexplored security issues surrounding mobile agents, it is appropriate to ask if the benefits of mobile agents e xceed their disadvantages. As well, we should be asking if some of these benefits can, in fact, be realized without using mobile agents at all. For example, one of the primary benefits of mobile agents is that they carry computation to the data storage site. It is, in f act, possible to do this without mobile agents. Remote Procedure Calls (RPC) allows one process to invoke methods on a remote machine. The difference between RPC and mobile agents, however, is that in order to execute RPC calls the code must be located on the remote machine. Typically an administrator on that remote server installs the code; this is fundamentally different from a mobile-agent approach in which the agent itself  X  X arries X  the code; no human administrator need install or verify the code beforehand. The relative benefits of the two methods depend largely on the amount of irrelevant data filtered by a mobile agent; precise mathematical formulations of this and other factors have been derived (Strasser and Schwehm 1997).

Another question to ask is whether the benefits of remote computation are in fact worth-while for information retrieval tasks. Global network capacity has increased rapidly in the 390 DAS ET AL. last several years, and it is possible that bandwidth limitations may cease to be important f actors for most data retrieval tasks. Furthermore, it is conceivable that the remote com-putation approach may be trading one limitation for another: with several mobile agents occupying a server X  X  processing cycles, data retrieval times may suffer if a given system X  X  processing capabilities are overtaxed. These are empirical questions, however, and depend on factors such as the number of simultaneous queries on at a given data repository, the computational complexity of the algorithms used, the size of the data, etc. (Grey et al. 2000). 3. Acquire architecture Figure 1 below shows ACQUIRE accessing a network of NASA Distributed Active Archive Centers (DAACs).

The ACQUIRE application, which consists of a central server application and a catalog of data sites, is shown accessing several distributed data archives. The central ACQUIRE application directs and controls all mobile-agent based generation, plans, and optimizations. Corresponding to each sub-query generated by the host, a mobile agent is spawned, which is responsible for retrieving answers to the query from the appropriate data sources. There may be more than one data source involved in a sub-query to be answered by the spawned mobile agent. In this case, the corresponding mobile agent intelligently constructs its route MOBILE AGENTS 391 for searching the data sources and hops from one source to another according to the route to accumulate answers to the sub-query. The creation of a set of mobile agents enhances efficiency by retrieving data in parallel from several data sources located at various archive centers. For system demonstration, we simulated various NASA Distributed Active Archive Centers (ASF DAAC, EDC DAAC, GSFC DAAC, etc.) that are part of NASA X  X  Earth Observing System initiative. Figure 2 shows ACQUIRE X  X  internal architecture.

The core application architecture has three modules: Query Interface, Query Planning and Optimization, and Query Execution. In addition to these three modules, the system contains a local Site and Domain Model database. These various modules are described next. 3.1. Site and domain modeling In order to generate a suitable query retrieval plan, ACQUIRE requires a Domain Modeling scheme (Arens et al. 1993) for describing the location and description of data available 392 DAS ET AL. for retrieval. Modeling a data source involves: (1) site modeling, that is, the description of the site where the data source resides; and (2) domain modeling, that is, the description of the object types and tables in the data source. Both site and domain modeling are used by AC Q UIRE to retrieve data from available data sources.

Fo r each unique data set stored in an archive, an instance of the Repository type is created, which defines the repository. A Repository is simply a data object that contains information about a particular data set data X  X  physical location. For example: create instances r1 and r2 of type Repository with the information necessary to access a data source in various specific repositories. Because independent data archives may store the same data type in different formats, each repository object defines an Extent field that defines the semantic contents of the repository without regard to the specific data format used. Thus all archive sites that store ozone levels can be described by the same Extent (e.g., Extent.OzoneLevel )e ve ni f the sites differ on, say, the units used to represent the data. An Extent is defined as an abstract data type that contains various fields relating to ag iv en type of data. For example, the OzoneLevel e xtent corresponding to the objects in the data repository r1 can be defined as follows: It should be noted that an Extent is a high-level description of a particular data type used by AC Q UIRE to locate specific instances of data; no data archive actually stores information in this format. As mentioned above, each data site typically stores its data in its own, frequently non-standard format for its datasets. In order to extract the required data, ACQUIRE uses the concept of data wrappers to translate from the archive X  X  local schema to the high-level Extent data model. A wrapper is simply an object that maps extent X  X  high-level description of a data type to the particular representation used by the local data source. When a request is made for a particular Extent, a wrapper object translates from the local representation to the Extent schema. This scheme for separating high-level data repositories from the specific implementation of actual archives allows ACQUIRE to retrieve any arbitrary data request MOBILE AGENTS 393 while ensuring data site autonomy. For example, data access for a site can be made through SQL-type queries as the following:
Notice that the query does not require the various specific sources to be explicitly spec-ified, nor does it require that the user be aware of the specific formats in which the data is stored in each archive. From the user X  X  point of view, the data is stored in a single, ho-mogenous data site. We now describe the process of query planning, in which ACQUIRE decomposes the query into a series of sub queries to be executed by individual mobile agents. 3.2. Query interface One of the main goals of ACQUIRE is to abstract away from the user the locations of the individual data sources. The user interface therefore does not present the user with such information; instead all information is presented in such a way as to give the appearance of a single, homogenous data source. The user is given a list of the data types available to him, as well as a choice of geographical regions from which to select the data (latitudes and longitudes) and date ranges. Finally, the user may choose from a list of statistical and mathematical functions (mean, median, etc.) that may be applied to the data.

In addition to a point-and-click graphical interface, the user can opt instead to enter a query in an SQL-like syntax. The aim of this interface is to provide the most flexibility to the user, while still abstracting away the distributed nature of the actual data. It should be stressed that the project reported in this paper is a preliminary proof-of-concept prototype; thus the operations available to the user are a small subset of the complete SQL syntax. 3.3. Query planning and optimization Query planning (Knoblock 1995) involves generating a set of sub-queries from a high-level user query based on the data source locations that have parts of the required information to answer the query. We have written a parser that takes high-level queries, as described above, and decomposes them into subqueries corresponding to the various data sources that contain the required data. Query Planning is the process of decomposing the query and finding suitable agent-migration paths that will include all of the required data in the correct order. The algorithm is informally described as follows: First the query is parsed into its component clauses. Note that it does not matter if the query is posed in an SQL-like syntax or as a high-level point-and-click request. In either case, an intermediate representation is generated representing each of the component data types required. Next, the system consults its catalog of data sites to determine where each required data type is physically located 394 DAS ET AL. on the network. The system then generates a retrieval plan that assigns a single or group of mobile agents to retrieve the required data from each of these sites.

Not all retrieval plans are optimal; order of retrieval can greatly affect the size of data transferred and hence the total time for data retrieval. The Query Optimization process, therefore, involves applying various heuristics to the retrieval plan such that the total size of data transferred is minimized. For example, we have implemented a  X  X ELECT before JOIN X  optimization heuristic, in which any SELECT clause in the query is performed before and JOIN clause. This heuristic, as described below, can greatly reduce the data transferred for most queries in which both SELECT and JOIN clauses appear. This optimization works because it reduces the size of intermediate data sets that must be transferred from one site to another for the JOIN operation. Similarly, detecting the size of data to be transferred can increase query times. When two or more data sources must be merged, the system preferably transfers data from the smaller source to the larger source. Other planned optimizations for future versions of ACQUIRE will be discussed in the concluding section of this paper.
The following illustrates the concept of query planning that we have implemented for the initial ACQUIRE prototype. Suppose we have a block of satellites that has the capability of reading ozone values. Suppose an extraordinary event is observed (e.g., an ozone hole) on a certain date (e.g., 1/1/1998 )a ta certain location (e.g., latitude -86.5S and longitude 180W ). To support a comparative analysis, the scientist needs to access the ozone data from several data sources. These sources may exist in several places, but the user can specify a query in a high-level manner that does not mention the specific locations. In this example the user queries the system using an SQL-like query syntax: Note the specific location of the data is not mentioned in the query. If r1 and r2 are the only two repositories respectively which contains ozone values, then the above query will be decomposed by the Planning and Optimization module into the following internal representation: Given the fact that repositories r1 and r2 are at different locations, the following two sub-queries will be generated and a mobile agent is spawned to retrieve each one: MOBILE AGENTS 395 The above two sub-queries will be executed in parallel via two independent mobile agents. When both mobile agents return with their respective data sets, a local join is performed, and the requested data is displayed to the user.

As mentioned above, not all query plans are optimal. To illustrate the query optimization problem, suppose the scientist wants to retrieve data for a particular date (say, 1/1/98 ) from those locations where ozone layers have been suspected to be unusually thin. For the purpose of the comparison, the process requires normal ozone values at those locations on 1/1/98 . Suppose these values are stored in a table with extent OzoneNormal :
A high-level user query to answer the question posed above might look like the following: where threshold and the function  X  diff  X  are appropriately defined. Initial decomposition generates these two sub-queries in the system X  X  internal representation: 396 DAS ET AL.
 Now, there are at least two different ways these sub-queries can be executed to obtain the answers. In the first approach, the sub-queries can be executed in parallel to retrieve (by launching mobile agents) the relevant records to the client X  X  local environment and then the constraint in the join can be performed locally. If there are 10 archives, this involves retrieval of a total of (10 + 1)  X  n records from repositories corresponding to 10 archives and the central repository, where n is the number of different positions for which ozone values are recorded by each satellite. Note that launching a single mobile agent can perform the necessary retrievals from 11 repositories. The launched agent will hop from one repository to another to intelligently search the relevant data. In the second approach, the number (10 + 1)  X  n of retrievals, which is large for a large value of n, can be reduced substantially. In this approach, we first execute the OzoneNormal query to retrieve n records from a central repository and create a temporary table called filtered-ozone-normal : filtered-ozone-normal and the code for the function  X  diff  X , to execute the follow-ing query:
The retrieval graph for this query is shown in figure 3. The number of retrieved records from each location depends on the function  X  diff  X . In the worst case, the number of retrieved records will be n .

While this example demonstrates the potential to reduce query retrieval times by using a simple SELECT before JOIN heuristic, there are many more optimizations that can be made, such as prioritizing data retrieval by network latencies, computational limits at the MOBILE AGENTS 397 distributed sites, and other factors. These optimizations will be explored in more detail in future versions of the system. 3.4. Query Execution The final step in carrying out a user X  X  request for data is carried out by the Query Execution module. The Query Execution module controls all aspects of agent creation, migration, and collaboration. The module receives a list of subqueries from the Planning and Optimization systems and generates a series of mobile agents to carry out these subqueries. The module creates for each agent an  X  X tinerary X  of the various sites to be visited and the data retrieval and processing tasks to be executed at each site. In our original system, agents were spawned with fixed itineraries and retrieved data in a preplanned order. In Section 5 we will describe an ew approach to query execution in which agent migration and query retrieval order is based on locally available information, such as dataset size and computational power of each data server. In our latest system, this dynamic query retrieval mechanism has resulted in a marked improvement in retrieval times.

While at their respective sites, the mobile agents that comprise the query execution mechanism report back to the home system with updates about their various tasks. For the first prototype implementation of ACQUIRE, the user has the option of viewing these messages, which consist of updates about each agent X  X  current location, query retrieval status, etc. Since one of the goals of ACQUIRE is to abstract away from the user the physical location of the data, this feature will be hidden from the user in future versions by default, and the status updates from the mobile agents will be used primarily for system-level diagnostics.
Upon return of each mobile agent, the system performs any required data joining, pro-cessing, and formatting of the data. The final, unified results are then displayed to the user via the system X  X  User Interface. 398 DAS ET AL.
 4. Implementation and evaluation Figure 4 shows the ACQUIRE interface upon start-up. The three main panels that appear represent the user X  X  query in the upper left, the results in the lower right, and the  X  X nternal X  status of the mobile agents in the right window.

One of the project X  X  primary goals was to demonstrate the utility of the mobile agents that form the heart of ACQUIRE. As such, an interface was developed that allows the user to see the status of an agent X  X  creation, migration, data retrieval, return home, data uploading, and termination X  X ven though these aspects of the system need not be known by the average user. Each mobile agent spawned by the system can send messages back to the home server via standard Internet protocols; each such method is displayed in a unique color for each agent in the Agent Status window. In future versions of ACQUIRE, the Agent Status window will be optional for the end-user.

On the left side of the interface is the User Query window. It contains two primary panels, the Query panel in the top section of the window and the Results panel in the lower section. The Results panel displays the final synthesized results of a query that has been retrieved by the system. Above it, the Query panel is comprised of 3 tabs designed to demonstrate 3 different types of queries that can be made by a user: General Queries, SQL queries, and Database Information queries.
 General High-Level Queries. The General Queries tab is designed to simulate two main aspects of the NASA X  X  EOSDIS web-based interface. Like the EOSDIS system, this interface allows a user to specify a particular date and geographic region, as well as MOBILE AGENTS 399 allowing the user to select from a list of data types (cloud cover, ozone levels, temperature, etc.). In addition, the interface allows the user to select a mathematical operation to be carried out on the retrieved data, such as the mean or standard deviation of a retrieved set of numbers. This option is intended primarily to demonstrate the remote application of  X  X n-site X  data filtering and computation by remote agents; thus the given options are relatively simple in order to easily demonstrate the concept. More complex mathematical and filtering operations are planned for future versions of ACQUIRE.
 SQL Queries. More complex queries can be made by entering an SQL string in the  X  X QL X  tab of the User Query field. SQL (Structured Query Language) is the most popular syntactic language for specifying data to be retrieved from a database. While this manner of querying offers the most generality and specificity of any interface, it requires a user to have experience with generating such queries. This entry option, therefore, is included only so as to show that the system can accommodate any query entry format. Again, the core of the ACQUIRE system is its decomposition and mobile agent retrieval system, rather than a particular choice of interface.
 Database Info Queries. AC Q UIRE gives the user a way to know the types of data supported by a given database. For example, if a user wants to know the data fields associated with the  X  X zone X  database he would type  X  X zone X  into the field. Mobile agents would be spawned that query the several remote database sites for all databases that carry  X  X zone X  data, and return a list of fields that can be retrieved from such databases.

It is important to note that these different query types do not represent a commitment to any particular interface, rather, the intent is to demonstrate that regardless of the particular query interface used (menu-based selections, SQL strings, etc.) the underlying system will decompose and retrieve any query in the same way. Thus the implementation of the system is not directly tied to any particular interface, nor does it assume in any way how the user will enter the query. This allows for easy addition or manipulation of future user interfaces without requiring major changes to the underlying decomposition mechanism.
 Figure 5 shows the system executing an example query.

In this example, the user wants to know the cloud cover over a particular region of the w orld at a particular date and time. Furthermore, he wants to find the average of those values for that region. That information happens to be located on several different databases, each with its own database schema, and possibly in different units of measurement (for example, in SI units on a new database and Imperial units on a system containing data from many years ago). The decomposition system generates a series of mobile agents which each perform a sub-task, in this case traveling to the required database, selecting the correct data, performing an averaging operation, and returning home. Notice that each agent reports periodically back to the home system with status updates, with each agent X  X  reports displayed in a unique color. When all agents have returned and uploaded their data, the results of all the sub-queries are then combined and the results reported to the user figure 6. From the user X  X  point of view, however, a single homogenous database exists from which the user can select the data and perform mathematical operations.

This query can also be executed with a single agent. In order to demonstrate this, an option is available to force the system to utilize only one agent for the task. This option can be selected by clicking the  X  X se Single Agent X  box in the  X  X uery X  menu in the menu bar. 400 DAS ET AL.
 MOBILE AGENTS 401 The single agent retrieves the exact same result by traversing the series of data sources one by one and merging the accumulated results. 4.1. Evaluation System evaluation was conducted using a network of three simulated NASA data archives situated across a LAN. Each data archive contained several data sets of various types; these included ozone values, cloud cover levels, El Ni  X  no images, and research data from NASA X  X  Oregon Transect Ecosystem Research Project (Angelici et al. 1992). Also connected to the LAN was a server running the ACQUIRE application from which agents were spawned.
T able 1 shows the results of a series of data-retrieval tasks performed by ACQUIRE. In these experiments, three different queries were made on the simulated NASA data archives. Each of these three queries was performed under three test conditions. In the first condition, multiple mobile agents were spawned (one for each repository) using ACQUIRE X  X  de-composition and planning system. The second condition also used the standard ACQUIRE retrieval mechanism, except that the system was forced to employ a single  X  X opping X  mobile agent which retrieved the required data in series. Finally, a reference case was conducted in which all data required for the queries were retrieved; in this case data was still retrieved by ACQUIRE X  X  mobile agents but the planning, optimization, and remote data processing features were disabled. Thus all data required for the query was transferred to the host application without any remote data processing, JOIN operations, etc.

Retrieval times and data transfer sizes for each of the experimental conditions is graphed in figures 7 and 8. It is clear that in all cases the best performance came from the multiple mobile agents case. This is not surprising, since the data was processed and retrieved in parallel, whereas the single agent was required to retrieve data in a serial manner. The reference case invariably required the most time, and, more importantly, more a far larger total download size than either of the two mobile agent methods.

It is important to note that the reference case required even more time for complete query retrieval than in indicated in the chart. This is because, in the reference case, the data was retrieved unprocessed; further analysis after download would be required by actual users in order to determine the answer to the original query. For example, in the final query, the 402 DAS ET AL.
 user not only had to retrieve all of the required OTTER images and CloudCover values, but he would have had to join the two datasets himself before querying the final dataset. This join-and-query operation is handled automatically by the agents in ACQUIRE.

It should be noted that these examples are meant to demonstrate that in certain cases retrieval by mobile agents can substantially reduce network usage and total retrieval times. F ormal analyses of mobile agent retrieval have been reported by others (Strasser and Schehm 1997); we have chosen instead to focus on a concrete implementation. Although the particular examples used were chosen somewhat arbitrarily, they should nonetheless demonstrate the utility of our approach. Naturally, full-scale empirical testing of the system will require more  X  X eal-life X  test cases and should as much as possible attempt to simu-late the actual types of queries posed by users of real distributed archive systems. It is our plan to implement such tests on real NASA DAAC data sites in a future version of AC Q UIRE.
 MOBILE AGENTS 403 5. Dynamic retrieval strategy optimization The query optimization method in ACQUIRE, as presented above, involves re-writing of the query execution graph so each mobile agent retrieves its requested data in an optimized order, thus minimizing total data transfer size. While this query re-writing method can be highly effective in reducing both retrieval times and data transfer sizes, they are generally  X  X tatic X , in that the mobile agents retrieve data in a particular order based on an itinerary that is fixed at the time the plan is generated. We have enhanced ACQUIRE to optimize data retrieval by dynamically optimizing the retrieval strategy as it is carried out. This strategy equips each spawned agent with the full query execution graph and necessary code to execute the retrieval plan at any data site in the network. The spawned agents communicate and collaborate with each other to dynamically decide where to migrate, send data, and perform necessary computations in order to complete the query execution based the graph. These decisions depend on retrieval factors such as network speed, data size, and the computational capabilities of the data servers involved in the retrieval. For example, an agent that finishes retrieval earlier than other agents producing a small size dataset may decide to migrate to another agent X  X  site to facilitate the follow on computation that require the data produced by both the agents. The feasibility of this approach has been demonstrated to show further improvement in retrieval efficiency. 5.1. Optimization strategy Once a query is posed to ACQUIRE and mapped against the actual data sites accessible to the system, the optimization engine attempts to rewrite the query in a manner that minimizes whose population is between 50,000 and 80,000 people. In this case, let CITY DATA be the geographical information about cities in California, including their populations. Further, let SAT PHOTO represent the collection of all satellite photographs of cities in California. In SQL, the query may look like this: Note the specific location of the data is not mentioned in the query. If B, C, and D are the only three tables respectively which contains SAT PHOTO values, then the above query will be translated by the planning system as follows: 404 DAS ET AL.
 Given the fact that repositories B, C, and D are at different locations, and the CITY DATA repository is located at site A, figure 9 shows what the mobile-agent retrieval graph generated by ACQUIRE X  X  Query Planning module looks like.

W ithout any optimization, the retrieval would proceed as follows: Four mobile agents w ould be sent out, one to each of the four data sites. The agent sent to repository A would retrieve a list of all cities whose populations are between 50,000 and 80,000, and return this list to the home agency. The three other agents would travel to sites B, C, and D, respectively, and download all satellite photographs of all cities in California. With all required data, the system would then be able to answer the query.

Obviously, the query efficiency can be improved by first selecting the list of cities whose populations are within the desired range before retrieving their corresponding satellite im-ages. ACQUIRE X  X  query optimization does just this. By employing a series of commonplace query optimization heuristics, we can begin to reduce the size of data that must be retrieved, takes advantage of the fact that the UNION operation can be accomplished after the join operation, as shown figure 10.

Now, the retrieval is optimized such that not all of the SAT PHOTO images need to be retrieved. In this optimized plan, an agent is first sent out to retrieve all of the required names from the CITY DA TA repository before any of the other agents are sent out (figure 11). These agents are then loaded with the required population data and then sent to the photograph repositories to retrieve only the photos from towns that meet the population requirement (figures 12 and 13). Finally, the system computes and returns to the user a list of all requested satellite photographs.

In the examples shown above, all agents are sent with a set, fixed itinerary. In addition to being fixed, the itineraries are all single-hop in nature, that is, they all involve moving to a site, retrieving some data, and returning to the home agency. The first improvement to this scheme, then, is to allow agents to send data to other data repositories (via the mobile agent agencies located there) rather than sending all retrieved data  X  X ome X  to be processed. MOBILE AGENTS 405
The next improvement is to replace the  X  X ixed X  itinerary (or, in our case, set of itineraries) with a more dynamic retrieval scheme. The problem with a fixed itinerary set is that the system is unable to take into account certain factors about a retrieval that may be variable repository may encounter an unexpected slowing of its network connection. In this case, we w ould ideally want to avoid moving any data to this site. Similarly, a node may experience an unexpected heavy processing load. Or we may simply be unaware of the data size to be e xtracted at a given site, and we would not want to fix a set of itineraries if this is the case. 406 DAS ET AL.
 retrieval strategies in real-time. To do this, we require a number of changes to our agents. First, agents require the ability to detect and respond to local network conditions and data loads at a given repository. Agents also require an ability to communicate and negotiate with one another so as to coordinate their retrieval plans. Finally, agents require algorithms to determine the best retrieval strategy given the conditions at their current nodes and the states of other agents.

A static retrieval plan must decide at planning time which data sites an agent will visit and where to carry out data computations. In order to minimize retrieval time, an itinerary is ideally constructed so that data processing occurs at the fastest data sites. Additionally, data transfer sizes must be considered so that the smallest data packets are sent wherever possible. MOBILE AGENTS 407 If two data sets from different sites are required for a particular operation, the system must decide which data set to send to the other one. To do this, the system must know which data set will be smaller, which data site possesses the fastest data processing capabilities, etc. Unfortunately, much of this information is not known at the time a retrieval itinerary is constructed. Even if data sizes are known, several unknowable conditions could occur at retrieval time. For example, a particular server may receive an unusually large number of independent, external processes after a series of agents is spawned, which may affect the optimal retrieval strategy in real time. Similarly, the size of data produced by a particular operation at a given site may not be knowable at the time a retrieval is generated. These and other factors make it desirable to have a retrieval strategy that responds dynamically to current conditions at the data servers visited by a series of agents.

In a static retrieval strategy, each agent needs only enough code to carry out the particular operations that its itinerary specifies. For example, agent 3 in figure 12 needs only the code required to locally join the city population data with the satellite image data at the repository. since at any point the agent may be required to carry out any particular operation. To do this, each agent is  X  X quipped X  with the entire retrieval graph in addition to a complete list of all required data repositories and associated code. While this has the effect of increasing the size of each agent (and hence potentially increase retrieval times), this increase is generally negligible compared to the reduced data transfer sizes that this strategy typically produces. Figure 14 through figure 17 show how the new retrieval strategy works.
 In this strategy, a single agent is sent to all required data repositories for data retrieval. Each agent contains all code required to perform the entire retrieval. The agents then proceed to download their data in parallel, while simultaneously performing local system, data, and 408 DAS ET AL.
 network checks to determine any parameters that may affect the retrieval speed. As they process their data, they also interact to determine the next course of action. In this case, each agent at the SAT PHOTO data sites requires the CITY DA TA to proceed (figure 10), so the retrieval requires that both the CITY DA TA and each SAT PHOTO be joined. In this case let us assume that the size of the CITY DA TA is much smaller than the other data sets, and agent 1 finishes its retrieval first. In this case the data transfer is trivial: agent 1 moves his data to each of the other three repositories and dies (figure 15).

The next data transfer depends on the local conditions at each of the three remaining repositories. The agents in this case negotiate an optimal strategy based on the size of their data, the network transfer rate, and local server speeds. In this case, suppose that agent 2 retrieves its required data and performs its JOIN operation. Suppose further that the agents have negotiated to send their JOINed data to agent 3, based on the fact that the data size in that location is the largest of the remaining agents (figure 16).
 retrieval tree has progressed to its final data set. At this point the final data set is returned to the home agency (figure 17) and displayed to the user. 5.2. Evaluation System evaluation was conducted using a network of three simulated NASA data archives situated across a LAN. Data consisted of both statistical data on a sampling of cities in California (CITY DA TA )a s well as three sites storing satellite photographs of those cities (SAT PHOTO). Statistical data consisted of facts such as population, elevation, latitude, longitude, etc. Photo images were obtained from the Terraserver web site (www.terraserver. com). Agents were spawned from a separate application server which was running the AC Q UIRE application.
 MOBILE AGENTS 409 410 DAS ET AL.

T able 2 shows the results of the data-retrieval task performed by ACQUIRE. In these e xperiments, three different optimization levels were used when retrieving data from the archives. In the first condition, a reference case was established in which all data required for the queries were retrieved; in this case data was still retrieved by ACQUIRE X  X  mobile agents but the planning, optimization, and remote data processing features were disabled. The second condition also used the standard ACQUIRE retrieval mechanism, but the query wa s first optimized using the system X  X  query optimization feature described in Section 3.3 with no dynamic retrieval optimization. Finally, the query was conducted with both query optimization and retrieval optimization features enabled. These three optimization levels were tested on three separate queries involving various criteria for selecting the satellite imagery. Table 2 shows the results of the tests.
 Retrieval times for each of the experimental conditions are graphed in figures 18 and 19. Fo r all queries tested, the best performances came from the case with both optimizations enabled. The reference case invariably required the most time and had a far larger total download size than either of the two optimized test cases. We believe that the  X  X uery plus Retrieval optimization X  cases could improve even more over the  X  X uery optimization X  case MOBILE AGENTS 411 in more advanced queries with larger and more complex retrieval graphs. This is because large, complex queries would contain even more unknown factors and hence benefit more from a dynamic optimization approach. As the purpose of this paper was to establish feasibility, confirmation will have to wait until a future study. 6. Web interface In addition to a local application interface, we have also recently implemented a web interface to the ACQUIRE system. The web interface has several advantages over the local application one. One of the primary advantages is increased security. The local interface requires that the user X  X  local machine run the agent-hosting environment, which can be populated with any number of arbitrary agents. This clearly opens up a whole array of potential security breaches. Malicious agents can execute arbitrary code on the user X  X  local machine. In addition, it X  X  possible for a malicious user to deploy agents to the database servers that can execute arbitrary code there . Under the web interface, a user X  X  interaction with the server takes place entirely over the World Wide Web using only the standard HTTP protocol. In this scenario, the web server is itself the agent-hosting environment, or at least a gateway to an agent-hosting environment. The user is protected from malicious agents because his machine never interacts with them; queries are submitted through the web interface and then results are displayed as agents bring them back. The databases and server are protected because they can be located behind a firewall; the web server is the only server that must be publicly accessible. This means that it X  X  possible to provide assurances for which agents will be executing on the database servers.

Figure 20 demonstrates the query functionality of the web interface. In this example, a user wants to execute a SQL query, which can be entered directly into a text box. The web interface is designed to allow a user to perform other tasks while a query (or multiple queries) are executing. Thus, it X  X  possible to provide an e-mail address in addition to a query. The web interface will then notify the user when the query results have been retrieved by email. While a query is executing, it X  X  also possible to preview partial results in the Results 412 DAS ET AL.
 frame. Partial results are available for certain types of queries where a subset of all the results may be available before all the results are. This is also the frame that displays the final results once they become available.

In order to allow users to monitor the progress of a query as it is being executed the same way the local interface does, it is necessary to update the display on a frequent basis. However, this presents a software engineering challenge because HTTP is fundamentally designed to be a pull system wherein the client always initiates requests, results are returned, and the transaction is considered to be over by both sides. This is clearly not desirable in this case, however. Instead, we would like to provide live feedback to the user as events occur on the server side. Our solution is to return results to the client in a lazy manner, such that neither side considers the transaction complete until the query is done executing and final results are available. Instead, the web interface can send small pieces of client-side JavaScript as events happen on the server side to the client that cause the client X  X  display to be updated to reflect these events. This allows us to not only update text information, such as agent status and results, but also the graphical query plan, which we can display in the form of an image that is updated and refreshed on the client side when appropriate. Figure 21 displays the contents of the Results frame of a query that returned a single location as a result. It X  X  possible to click on the image hyperlink to see the picture of the location in question. The concept status area is the graphical representation of the query plan. The nodes are all green, indicating that all sub-tasks of the main query are complete. A table listing agent feedback messages is located at the bottom.

When queries are submitted through the web interface, ACQUIRE issues the user a session ID that they may then use to look up the results of the query at a later time. Thus, it X  X  possible to execute a query, shut down the client computer entirely for some period of MOBILE AGENTS 413 time, and then subsequently restart it, return to the web server, and retrieve the query results using this ID. 7. Conclusions and future directions In this paper we have presented a mobile agent based engine, ACQUIRE, for retrieving data from heterogeneous, distributed data sources. ACQUIRE acts as an interface agent or softbot by accepting a high-level user query and decomposing this query into a series of subqueries. An optimized data retrieval plan is then generated from these subqueries and a series of mobile agents is spawned that collect and return the required data from the distributed data archives. The system preserves individual data source autonomy while at the same time presenting to the  X  X aive X  user the appearance of a single, homogenous data source from which he or she can retrieve the required data. The system reduces the amount of data transferred across the network by optimizing the retrieval strategy and by utilizing a mobile agent X  X  ability to process data remotely. 414 DAS ET AL.

Based on our initial prototype, we have concluded the following:  X 
Agent-based retrieval effectively abstracts away the physical location of the data sources from the end user, thus reducing the effort required by the user to retrieve the desired data.  X 
Distributed computation can substantially reduce the amount of data that needs to be sent across a network, reducing data transfer times.  X  Dynamic retrieval optimization can significantly increase retrieval efficiency.
The original prototype X  X  query generation and user interface was a combination of various high-level query interfaces, including a simple point-and-click visual system, a text-based SQL interface, and a keyword-based metadata query interface. In the future, we will inves-tigate various COTS-based Natural Language Processing (NLP) systems for use as a more intuitive, user-friendly data request interface. As well, commercially available graphical and icon-based query languages will be investigated as another potential interface system. These systems have the potential to resolve incomplete and ambiguous user queries and to f acilitate query generation by non-technical users.

Fo r query optimization we initially used a common data-retrieval heuristic to demonstrate a query optimization. This simple rule was shown in some cases to dramatically reduce contemporary database optimization rules will be integrated into the system in order to further reduce the data size and computation time requirements of a given retrieval. Also, we have investigated a technique by which query retrieval can be dynamically optimized by a group of coordinating mobile agents. We have shown that by resolving the exact itinerary of the mobile agents at execution time, rather than planning time, agents can take advantage of local and temporal information unavailable at the time the retrieval plan was made. This information includes data transfer sizes and data site conditions, and utilizing it significantly reduces the time required to retrieve data.

There are many potential avenues for future research in the area of dynamic query retrieval strategy. In particular, we are investigating more complex strategies by which agents decide where and when to send intermediate data sets. In addition, we plan to explore more complex communication and negotiation strategies between agents, with the goal of formalizing an effective collaboration system. Finally, we plan to expand our tests to include more complex data retrieval plans. It is important to ensure that our dynamic retrieval optimization strategy scales up to larger and more complex data queries.

Under the first prototype, local computation was limited to a simple arithmetic mean function that demonstrated the viability of mobile agents for distributed computation. Under the second phase of the project, the scope and utility of pre-defined distributed functions will be increased to provide many common statistical and mathematical functions. In addition, we will investigate the use of user-defined local computation code. This feature will likely involve the use of user-supplied Java code embedded in the remote agents, although we will also investigate the potential of other high-level languages for this feature.

Using a single agent versus a series of agents revealed, not surprisingly, that a series of agents virtually always results in reduced total retrieval time. This does not necessarily MOBILE AGENTS 415 mean, however, that multiple agents are always preferable to single hopping agents. It is conceivable that multiple user queries, each exploiting multiple agents in their various retrieval tasks, may result in an overabundance of network and system resource usage. In this case, user queries may be  X  X estricted X  to a single, hopping agent to save system resources.
One of the many features of mobile agents that make them particularly attractive is that they can generate child agents dynamically and launch them from remote locations. We place little emphasis on this feature, as the home server carries out most of the planning in our model. Our emphasis, rather, is on other benefits of mobile agents, such as an agent X  X  ability to carry and execute any arbitrary code (something which is not possible with methods such as RPC), and their ability to operate on a host whose network connection has been temporarily disabled.

A further direction for future work is in the area of data and site modeling. As our intent was to produce a working mobile agent-based retrieval system, many aspects of the site and data modeling components were necessarily simplified. In our prototype, for e xample, data sites and repositories were modeled in a fairly straightforward and simplified manner where data was mapped against a simple, proprietary data model. We are currently w orking on augmenting this aspect of ACQUIRE with an ontology-based data model (Das et al. 2002). An ontology is a  X  X ormal explicit specification of a shared conceptualization X  (Gruber 1993). Ontologies are particularly appealing in our domain (NASA X  X  environmental science repositories) because there is a very large and explicit vocabulary associated with v arious sub fields of the domain. Ontologies have been defined for many of these sub fields, and ideally these would be combined integrated without the need to redefine the terms. It should be noted, however, that this is no easy task, and several researchers have pointed out significant difficulties in achieving the integration of diverse ontologies (Correa de Silva et al. 1999).

Some future directions for the web interface include allowing users to execute custom agent logic uploaded through the web interface. This is, of course, a security concern, but it can be mitigated by dividing users into privileged users and non-privileged users and only allowing the privileged users to execute custom logic.
 Acknowledgments This work was performed under contracts NAS2-01041 and NAS2-02050 with the NASA Ames Research Center in Moffett Field, California. The authors thank Jay Skiles and Jim Brass at the NASA Ames Research Center, and Greg Zacharias at Charles River Analytics for their invaluable contributions and aid during the project.
 References 416 DAS ET AL.

