 We propose private protocols implementing the Kernel Ada-tron and Kernel Perceptron learning algorithms, give pri-vate classification protocols and private polynomial ker-nel computation protocols. The new protocols return their outputs X  X ither the kernel value, the classifier or the classifications X  X n encrypted form so that they can be de-crypted only by a common agreement by the protocol par-ticipants. We show how to use the encrypted classifications to privately estimate many properties of the data and the classifier. The new SVM classifiers are the first to be proven private according to the standard cryptographic definitions. E.3 [ DATA ENCRYPTION ]: Public key cryptosystems; H.2.8 [ DATABASE MANAGEMENT ]: Database Ap-plications X  Data mining ; H.2.7 [ DATABASE MAN-AGEMENT ]: Database Administration X  Security, in-tegrity, and protection Theory, Algorithms, Security Privacy Preserving Data Mining, Kernel Methods
Private classification like ordinary classification comprises of two subtasks: learning a classifier from data with class labels X  X ften called a training data X  X nd predicting the class labels for unlabeled data using the learned classifier. However, the main emphasis is on privacy, i.e., how to dis-close only the minimal amount of data. There are two fun-damentally different ways algorithms can disclose sensitive information: algorithms can leak some side information that Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00. is not specified by desired output or the end result itself re-veals sensitive aspects of the data. As common in crypto-graphic literature, we address only the first question, i.e., we design algorithms that only reveal the desired output.
For simplicity, we assume that the data can be stored as vectors with fixed length, often called feature vectors .Asan example, consider the classification task of detecting email spam. The training data comprises of emails with labels  X  X pam X  or  X  X ospam X . More precisely, classified emails are converted to word count vectors and then the classifier is learned from these vectors. The classifier itself can be, e.g., a linear threshold function on the word frequencies in the bodies of the messages. The learned classifier is used to predict which of the unlabeled emails are spam.

Private classification considers the scenario where the training data is divided between two or more parties with possibly conflicting interests, so that they are not willing to reveal their data. However, the parties are willing to train a common classifier provided that none of them can use it without others and that their data remains private. Such examples are quite common in the case of medical studies, e.g., when finding out risk groups for a diseases without leaking the identities of infected patients and the medical data. Other similar examples include military surveillance and identity-specific content providing services.
 We derive private versions of the Kernel Perceptron and Kernel Adatron algorithms that extend the basic linear clas-sification techniques. In particular, the Kernel Adatron al-gorithm can be used to implement both hard and soft mar-gin Support Vector Machines. See [14, 13] for references. As SVMs have excellent statistical stability and sensitivity, they have been successful in many application areas. Hence, our work is an important extension of the research on cryp-tographically private classifiers [2, 8, 6, 15, 16].
Data perturbation combined with robust aggregation techniques provides also privacy-preserving methods for classification. However, there the context is completely dif-ferent: the training data is owned by a single entity and data perturbation is used to protect privacy of individual records. Basic applications are various statistical question-naires and databases that must preserve anonymity of each participant. Such techniques have several intrinsic limita-tions: privacy guarantees are somewhat heuristic and there is a tradeoff between privacy and accuracy.

By using classical results of secure multi-party computa-tion [5], any protocol can be implemented without leakage of any side information, though with  X  X olynomial X  slow-down. Thus, secure multi-party computation methods can be applied to any protocol to avoid unnecessary disclosure. However, such generic techniques are usually too resource-consuming in practice. This is especially true in the case of data mining protocols that handle enormous amount of data, and are often themselves on the verge of being (im)practical. In the current article, we combine several well-known cryp-tographic techniques such as homomorphic encryption, se-cret sharing and secure circuit evaluation to get reasonably efficient private classification algorithms. As an important restriction, all proposed algorithms are private only in the semi-honest model where all participants follow the protocol but try to deduce extra information.

We derive protocols for the three basic steps of kernel based classifiers: evaluation of the kernel matrix, prediction and training. The complexity of the algorithms depends on how the data is divided between participants. Due to the space limitations, we cover completely only the simplest case when the feature vectors are owned by Server, and Client possesses only the classification labels. General horizontal and vertical split have slightly more complex solutions, since there Client and Server must first share the kernel matrix. In this shortened version, we outline only the main differences between the simplified and the complex case.
 A few methods for privacy-preserving learning of Support Vector Machines have been proposed [18, 17] but they re-veal the kernel and the Gramm matrix of the data. Since the Gramm matrix consists of scalar products between all data vectors, such leak is extremely dangerous. If more than m linearly independent vectors leak out, where m is the dimen-sionality of the data, then all other vectors can be restored knowing only the Gramm matrix. Hence, these methods are unusable for horizontally partitioned data, where each par-ticipant possesses many complete feature vectors. Moreover, other kernel methods like the Kernel-PCA reveal statisti-cally relevant information about data points without any auxiliary knowledge beyond the kernel matrix.
Let X be the set of all possible data points and Y be the set of possible classes. Let G be a family of functions g : X X  X  that we consider being potential classifiers, and let D be a multiset of data points with class labels, i.e., comprises of pairs ( x 1 ,y 1 ) ,..., ( x n ,y n )  X  X  X Y . Usually the pairs in D are assumed to be drawn independently from the same unknown probability distribution, often referenced as i.i.d. data. We consider only the case when vectors are real, X X  R m , and there are two classes Y = { X  1 , 1 } . The classifier learning task is, given the function class and the dataset D , to find the best classifier g  X   X  X  . Ideally, one would like to have a classifier with smallest misclassifica-tion probability Pr [ g ( X ) = Y ], where X and Y are random variables with joint probability distribution over X X Y .As the actual probability distribution on X X Y is unknown, we must relay on a partial information revealed by D . We consider only linear classifiers and their extensions. Linear classifiers are described by the normals of the hyper-planes w  X  R m . The classification of a point x  X  R m is then determined by the sign of the scalar product f w ( x ):= w, x that is also known as the discriminative function .Themost common linear classification algorithm is known as Percep-tron. The idea of the Perceptron algorithm is to find a linear combination w of the points x i such that sign w, x i = y for all ( x i ,y i )  X  X  . The algorithm updates the weight vec-tor w (initially 0) by adding to w each data point x i that is misclassified by the current w . See [13, 14] for more details.
A major drawback of the Perceptron algorithm is that it assumes that the data is linearly separable, i.e., that there is an hyperplane w  X  R m that separates the positive examples from the negative ones. Therefore, data is often mapped into a higher dimensional Hilbert space H to make it linearly separable using some (nonlinear) mapping  X  : X X  X  . Such a mapping is often called a feature mapping and the Hilbert space a feature space . Common feature spaces have very high or even infinite dimensionality and computations in feature spaces are done implicitly using kernels. A kernel of a feature map  X  is a function  X  such that  X  ( x i ,x j )=  X  ( x i ) , X  ( x for all x i ,x j  X  X  . Many machine learning algorithms can be written in dual form by expressing sought feature vectors as linear combination of  X  ( x 1 ) ,..., X  ( x n ). In particular, if w =  X  1  X  ( x 1 )+  X  X  X   X  n  X  ( x n )forsome  X   X  Z n ,then i.e., it suffices to compute only the kernel values  X  ( x Furthermore, the values k ij =  X  ( x i ,x j ) have to be computed only once for a particular D and  X  .Let K =( k ij ) n i,j note the kernel matrix of D . Then the Perceptron algorithm canbewrittendownasAlgorithm1.
 Algorithm 1 Kernel Perceptron algorithm Input: Akernelmatrix K and class labels y  X  X  X  1 , 1 } n . Output: A weight vector  X   X  Z n .
 Function Kernel-Perceptron( K , y ) 1:  X   X  0 2: repeat 3: for i =1 ,...,n do 4: if y i  X  5: end for 6: until convergence end function
By Novikoff X  X  Theorem [14], the number of iterations be-fore convergence is less than R 2 / X  2  X  ,where R is the radius of the smallest origin-centered ball containing all data points, and  X   X  is the maximal margin. Recall that the margin of a given weight vector w w.r.t. the dataset D is defined as and  X   X  =max {  X  ( w ): w  X  R m } . However, the output of the Perceptron algorithm is ambiguous, as it finds some sepa-rating hyperplane for data if such exists, but basically any separating hyperplane will do. It is more natural to se-lect the separating hyperplane that maximizes the margin  X  , i.e., the maximum margin hyperplane w  X  . Intuitively, such choice minimizes the risk of misclassification. The maxi-mum margin hyperplane is justified also by the generaliza-tion error bounds [13, 14]. Learning algorithms that output a maximum margin separating hyperplane are called Sup-port Vector Machines (SVM-s in short) [14]. A particularly flexible and simple Support Vector Machine is the Adatron algorithm [13].

The Adatron algorithm has several nice properties. First, it is based on iterative gradient descent and has a simple structure. Therefore, it is a p erfect starting point for a privacy-preserving learning algorithm, since there are only a few operations that require complex cryptographic solu-tions. Second, the Adatron algorithm allows to implement both hard and soft margin Support Vector Machines with few changes. Recall that a hard margin SVM finds the max-imal margin hyperplane if the dataset is linearly separa-ble. For linearly non-separable datasets, the hard margin SVM returns a solution where outliers X  X oints that cause non-separability X  X ave large impact on classification results. Soft margin SVM-s bound these harmful disturbances: ei-ther  X  j  X  [0 ,C ]isforced( 1 -norm SVM) or a regularizing term C&gt; 0 is added to the main diagonal of the kernel ma-trix ( 2 -norm SVM). Algorithm 2 implements the 1 -norm soft margin SVM, which is the most popular SVM. We get a hard margin SVM by setting C =  X  ,anda 2 -norm SVM by adding C to the main diagonal.
 Algorithm 2 Kernel Adatron algorithm Input: Akernelmatrix K , class labels y  X  X  X  1 , 1 } n and Output: A weight vector  X   X  Z n + .
 Function Kernel-Adatron( K , y , C ) 1:  X   X  0 2: repeat 3: for i =1 ,...,n do 4:  X  i  X   X  i + 5:  X  i  X  min { max {  X  i , 0 } ,C } 6: end for 7: until convergence end function
Our main assumption is that data is divided between two parties, Client and Server, that are willing to train a com-mon classifier if nothing beyond the expected end results are revealed. In the matrix evaluation and training phase, Client and Server must learn nothing new. In the prediction phase, Client must learn only the predicted label f w ( x ) and Server must learn nothing. In case of secure aggregation, even the individual class labels must remain secret and Client should learn only the aggregate value, e.g., the training error.
Feature vectors can be divided horizontally, vertically or in a more complex way. Essentially, there is no difference in private learning algorithms, unless the data is divided be-tween Client and Server so that Client possesses the label vector y and Server has the corresponding feature vectors x . We call such scenario a restricted vertical split .Asthe vectors x i correspond to the real life objects, it is quite plau-sible that Client can still classify the objects although the features x i are not known. Examples of restricted vertical split naturally emerge when Client must use a confidential database for classification, e.g., medical and genetic studies. Since Server owns all feature vectors, the kernel matrix K can be locally computed. Recall that Algorithms 1 and 2 require efficient evaluation of linear forms f w ( x i ). If Server knows all entries of K , then an additively homomorphic en-cryption is sufficient for secure evaluation of f w ( x i
In all other data sharing models, Client and Server must use cryptographic methods to share K , such that neither of them learns anything about K . Then, for the secure eval-uation of f w ( x i ), we need a two-party homomorphic cryp-tosystem where decryption requires collaboration between Client and Server. Due to the space constraints, we con-sider only restricted vertical split. Complete treatment of all data sharing models along with corresponding security proofs are given in the full version [7].

Next, we introduce the formal security model and three basic cryptographic techniques: homomorphic encryption, secret sharing and secure circuit evaluation. Since all these techniques can natively handle only integer inputs, classifi-cation algorithms must be discretized, i.e., fixed point arith-metics must be used instead of floating point calculations. This introduces some intricate questions about numerical stability that are discussed further in the later sections.
First lets establish some notation. For a finite set X ,let x  X  X denote that x is chosen uniformly from X . For an algorithm A with inputs x 1 ,...,x n ,let A ( x 1 ,...,x n the output distribution of A .Let k be the security param-increases asymptotically not faster than k c for some c&gt; 0. decreases asymptotically faster than k  X  c for any c&gt; 0. specified distributed algorithm) between Client and Server for computing the functionality f =( f 1 ,f 2 ). Let be Client X  X  private input and  X  Server X  X  private input. Intu-itively, the protocol  X  f preserves privacy if Client learns nothing but f 1 ( ,  X  ), and Server learns nothing but f 2 This intuitive notion is formalized by using the non-uniform polynomial security model [5, p. 620 X 624, 626 X 631]. A pro-tocol is private if any probabilistic polynomial-time honest-but-curious adversary (that follows the protocol) obtains ad-ditional information with a negligible probability w.r.t. the security parameter k (e.g., the key length). That means that in this case, one can choose a sufficiently small security parameter k , such that the protocol is still efficient but the adversarial success probability is reasonably small, say 2 See the full version of the article [7] for a detailed discussion.
The next (sequential) composition property allows to sim-plify cryptographic security proofs and omit unnecessary details. Let  X  g | f denote a sequential protocol for comput-ing functionality g , where parties can access a trusted third party TTP that computes functionality f .Inotherwords, parties can send their arguments to the incorruptible TTP that privately replies with the answers f 1 and f 2 .Now,let  X  f | g  X   X  f denote the protocol, where parties execute  X  g | f instead of TTP use  X  f to compute f . Then the following sequential composition theorem [5, p. 637] holds.

Composition Theorem 1. Let protocols  X  g | f and  X  f be private in the semi-honest model. Then the combined proto-col  X  g =  X  f | g  X   X  f is also private in the semi-honest model.
If the protocol  X  g | f contains many invocations of f ,then all of them can be safely replaced by an invocation of  X  f provided that TTP always computes a single value of f . That is, we cannot run two instances of  X  f in parallel or otherwise the composition theorem might not hold.
 provide an efficient way to securely evaluate linear forms when data is divided between Client and Server as it facili-tates computations with ciphertexts. Formally, a public-key cryptosystem is a triple of algorithms (G , E , D), where the key generation algorithm G with input 1 k returns a secret key sk and a public key pk corresponding to the security parameter k , E is the encryption algorithm, and D is the decryption algorithm. Let P and C denote the plaintext and ciphertext space. Then encryption with key pk implements a function E pk : P X R X  X  ,where R denotes the random-ness space used by the encryption algorithm. For the sake of brevity, we denote E pk ( x ):=E pk ( x ; r ) for a uniformly chosen r  X  X  . It is required that always D sk (E pk ( x )) = x , i.e., it is possible to decrypt cryptograms.

A cryptosystem is additively homomorphic if for any ( sk , pk ), (a) the plaintext space P = Z N ;(b)for x, y  X  Z N and E pk ( x ; r )  X  E pk (0) has the same output distribution as E pk ( x ). Hence, given sk and E pk ( x )  X  E pk ( y )  X  E can deduce only x + y mod N . If cryptosystem is secure then Server without sk leans nothing from E pk ( x ).
Security of a cryptosystem is defined as follows. Con-sider two experiments EXP 0 and EXP 1 . In experiment EXP i  X  X  0 , 1 } ,G(1 k ) is first executed to generate a new key pair ( sk , pk ). Then an adversary A ,given pk , computes two messages x 0 ,x 1  X  X  .Next, A receives E pk ( x i ). A cryp-tosystem is IND-CPA secure , if for any polynomial-time non-uniform algorithm A , the next difference is negligible: Adv( A )= probability is taken over the random choices of G, E and A . Essentially all our security results follow from the composi-tion theorem and from the next straightforward fact.
Fa c t 1. Let  X  be an IND-CPA secure cryptosystem. As-sume Server is a polynomial-time non-uniform algorithm. If during a protocol execution, Server sees only pk and E pk ( x i ) poly ( k ) i =1 then Server learns no new information.
Several additively homomorphic cryptosystems [3, 12] are proven to be IND-CPA secure under reasonable complexity assumptions. All of them are based on modular exponenti-ations of large integers, say 1024 bits long, and thus quite resource consuming. Still thousands of encryption and de-cryption operation can be done per second, at least using dedicated hardware.
 Secret sharing. Algorithms 1 and 2 above contain vari-ables that can leak information about data points. There-fore, neither Client or Server must learn the values of these variables, however, together they must be able to manipulate with them. We use additive and multiplica-tive sharing for such variables. Let N be a public modulus. If ( s 1 ,s 2 ) are chosen uniformly from the set  X  ( s 1 ,s 2 )  X  Z 2 N : s 1 + s 2 = x mod N of s i reveals nothing about x ,as s i has uniform distri-bution. We call it the additive sharing of x .Forin-vertible elements Z  X  N = { a  X  Z N : a  X  b =1 mod N } , mul-tiplicative sharing is defined by using the set of shares  X  ( s 1 ,s 2 )  X  ( Z  X  N ) 2 : s 1  X  s 2 = x mod N private classification, we have to rely on conditional oblivi-ous transfer ( COT ), also known as secure circuit evaluation . Conditional oblivious transfer protocol for a public pred-icate  X  is defined as follows. Client has an input and Server X  X  input is a triple (  X , r 0 ,r 1 ). At the end of the proto-col, Client learns r 0 if  X  ( ,  X  ) = 0. Otherwise, Client learns r . Server learns nothing. If Sender sets r 0 =  X  s 2 mod N and r 1 =1  X  s 2 mod N for random s 2  X  Z N , and Client stores the output of COT as s 1 then they have additively shared s 1 + s 2 =  X  ( ,  X  )mod N .

In 1-out-of-2 oblivious transfer ( OT ), Server holds a two-element database ( r 0 ,r 1 ) and Client holds an index .At the end of the protocol, Client learns r if  X  X  0 , 1 } and nothing otherwise. Server learns nothing. This can be seen as a special case of COT . The protocol must be secure even if Client is malicious (deviates arbitrarily from the protocol). For efficiency reasons, the OT protocol must remain secure even if a multiple instances of it are run in parallel and still have low amortized complexity, see, e.g., [1, 9].

A COT protocol, popularized and analyzed in [11], con-sists of three phases. First, Server sends a garbled circuit E(C  X  ) to Client. Second, for each input bit, Client makes OT call to get the corresponding input for E(C  X  ). Third, Client emulates computations in E(C  X  ), and obtains k -bit string r 0 if  X  (  X ,  X  ) = 0 and string r 1 otherwise. This pro-tocol has two rounds, is private in semi-honest model, and has even a freeware Java implementation Fairplay [10]. The following facts follow from the construction of [11]. Let the circuit C  X  consist of 2 binary or duplication gates and 3 ternary gates (Unary gates are redundant, as they can be combined into binary or ternary gates). Then the size of garbled circuit E (C  X  )is(4 2 +8 3 +4log 2 ( m bits, for k  X  80. The computational complexity needed to construct and emulate computations in E(C  X  ) is linear in thesizeofthecircuit  X  . The main computational workload comes from n parallel executions of 1-out-of-2 OT protocols, i.e. bit length of must be as small as possible. Several instances of COT protocol can be run in parallel without loosing privacy in the semi-honest model.

In practice, thousands of OT protocols can be executed in parallel per second. Therefore, private comparison be-tween n -bit integers is efficient, as latter can be done with n ternary gates. Still, we will consider several techniques how to decrease the bit-size of inputs of the COT protocol.
Kernel methods are typically applied to continuous data, and therefore most kernels ope rate over the real domain, ex-cept the discrete kernels that are used for text classification. As cryptographic methods natively support discrete ranges, we have to embed kernel values in Z N = { X  L,...,L } ,where the odd integer N =2 L + 1 is sufficiently large to prevent overflows in computations.

If data points contain non-integer values then we need to map data vectors into the discrete domain. Let toint : R m  X  Z m be the corresponding embedding that, say, multiplies its arguments by some large constant and then rounds them to the nearest integer value. Let b  X  : Z m  X  Z m  X  Z N be the corresponding kernel approximation. We say that kernel approximation is  X  -precise with respect to scaling factor c&gt; 0 and domain X , if for all x, y  X  X  ,
Obviously, approximation errors can change classification results. On the other hand, numerical approximation er-rors emerge also in floating-point implementations where the precision is usually 32 bits ( float precision). Moreover, it is reasonable to assume that if approximation is sufficiently precise then the modeling error, made by the choice of ker-nel, has much larger impact on the classification errors. As linear classification requires only evaluation of linear forms  X ,  X  , then 64-bit relative precision  X   X  2  X  64 is sufficient to mimic float computations, as smaller values are rounded to zero even in case of floating-point operations. Such precision is achievable with a 64 bit modulus N , provided that  X  ( is scaled into the proper range.

If Server does not own all feature vectors x i then Client and Server have to privately share K . We consider only polynomial kernels; private evaluation of more complex ker-nels is an independent research topic. Evaluation of the scalar product kernel  X  ( x i ,x j )= x i ,x j ,widelyusedinthe text classification, reduces to private evaluation of shared scalar product for which several solutions are known [4, 15].
Higher-degree polynomial kernels  X  ( x i ,x j )= x i ,x j be efficiently evaluated using share conversion: first the ad-ditive shares s 1 + s 2 = x, y mod N are computed, then the shares are converted to multiplicative shares t 1  X  t x, y mod N and finally the exponentiated shares are con-verted back u 1 + u 2 = t d 1  X  t d 2 = x i ,x j d mod N .These share conversions are straightforward to implement with ho-momorphic encryption. (See the full version [7] for further discussion.) Compared with other methods, the computa-tional workload and communication are small, as the expo-nentiation is done locally.

Share manipulation requires that x i ,x j and N are co-prime, since otherwise multiplicative sharing modulo N does not exist. Because homomorphic encryption forces the use of N with nontrivial factors that are at least 512-bit inte-gers, then it is sufficient that x i ,x j = 0 for all  X  X easonable X  input ranges X . For many interesting cases, z 1 ,...,z m for all z  X  X  and a kernel  X  ( x i ,x j )=( x i ,x j +1) d used instead. Finally, if x i ,x j = 0 then one can escape the problem by remapping the shares of 0 to shares of a special symbol  X   X  Z  X  N , and then later mapping the shares of  X  back to shares of 0. This requires costly circuit evaluation and should be avoided if possible.
Private prediction has several interesting applications even if the classifier is directly provided by Client, e.g., in finding potential patients without revealing private medi-cal data. Then Client has to send encrypted weight vector E pk (  X  )=(E pk (  X  1 ) ,..., E pk (  X  m )) to Server before the proto-col. For brevity, denote  X  := (  X  ( x 1 ,x ) ,..., X  ( x n  X  has integer coordinates. Then f  X  ( x )=  X  1  X  1 +  X  X  X  +  X 
A private prediction protocol that works in the case of restricted vertical split is depicted by Protocol 1. There, the parties first privately compute the additive shares of a scalar product and then use circuit evaluation to determine the shares of class label. Note that Prot. 1 can be modified so that Client learns the predicted label.

Theorem 1. Assume that  X  is an IND-CPA secure addi-tively homomorphic cryptosystem and that the circuit evalu-ation step is private. Then Protocol 1 is correct and private. Recall that in the general case vector  X  is additively shared between Client and Server, i.e.,  X  =  X  1 +  X  2 mod N where Protocol 1 Private prediction for restricted split Common parameters:  X  with plaintext space Z N .
 Inputs: Client has a secret key sk . Server has the public Output: Client and Server share a predicted class label. 1. Server sends c  X  E pk (  X  s 2 )  X 
Client sets s 1  X  D sk ( c ). // I.e., they share s 1 + s 2. Client and Server use circuit evaluation to share t 1 + t 2 =sign( s 1 + s 2 )mod N .
 Z
N is the plaintext space. Hence, given E pk (  X  ) both parties can compute E pk (  X  i , X  ) similarly to Protocol 1. However, neither of them can have secret key sk or otherwise  X  or  X  i leaks out. Therefore, one needs a two-party version of additive homomorphic encryption scheme [3] where parties can only together decrypt values. Essentially, parties have to execute two copies of Protocol 1 with switched identities to share sign f  X  ( x ). The corresponding protocol along with the security proof is present in the full version of the paper [7]. Targeted optimizations. Protocol 1 relies on circuit eval-uation. We can use two-round COT protocol (described in Section 3) to evaluate say the  X  X reater than X  predicate, but additional share conversion can significantly increase the ef-ficiency. For example, to guarantee the security of homomor-phic encryption, N must usually be at least a 1024-bit inte-ger. On the other hand, if we use 64-bit precision for  X  and  X  then the shared values fit roughly into 140 bits. Hence, it is advantageous to convert random shares s 1 + s 2 = x mod N to random shares r 1 + r 2 = x mod M where M is significantly smaller, say M =2 140 .
 For clarity, Protocol 2 is depicted for the representation Z
N = { 0 ,...,N  X  1 } . The same result applies for the signed representation Z N = { X  L,...,L } where N =2 L +1. If M&lt;N and in the signed representation  X  M 4 &lt;x&lt; M then 0  X  Protocol 2 and then subtract the public value 2  X  the result. Similar techniques can be used for M&gt;N . Protocol 2 Share conversion algorithm.
 Input: Additive shares s 1 + s 2 = x mod N , N is odd. Output: Additive shares r 1 + r 2 =2 x mod M .
 We assume Z N = { 0 ,...,N  X  1 } ,0  X  x&lt; M 2 and M&lt;N . 1. Parties locally compute t i  X  2 s i mod N, i = { 1 , 2 2. Server prepares an OT -table ( m 0 ,m 1 )for r 2  X  Z M a) If t 2 is even then b) If t 2 is odd then 3. Client uses a 1-out-of-2 OT protocol to set r 1  X  m b + t where b denotes the parity of t 1 .

Theorem 2. Protocol 2 is private and correct, provided that the oblivious transfer protocol is private and correct, N is odd, 0  X  x&lt; M 2 and M&lt;N .
 The correctness of Prot. 2 is clear as t 1 + t 2 =2 x mod N . Thus if 0  X  t 1 + t 2 &lt;N then both t 1 and t 2 are either odd or even. If n  X  t 1 + t 2 &lt; 2 N then t 1 and t 2 have different parity. Hence, r 1 + r 2 =2 x mod N . Security follows from the composition theorem.

If r 1 + r 2 =2 x mod 2 then the sign of x is determined by the highest bit of the sum and latter can be evaluated using ternary gates. Hence, it is advantageous to use Protocol 2 to reduce the input size of garbled circuit. As a result, Step 2 can be implemented with ternary gates for Protocol 1 and the size of the garbled circuit is roughly O ( ). More-over, we need only +1 invocations of OT counting also the one needed for share conversation. The communication and computation costs decrease at least by a factor of 10. Secure Aggregation. Note that if Client and Server lo-cally add together shares of different class labels, they can straightforwardly count the number of positive examples. Recall that the class labels are  X  1, hence the sum of shares reveals difference between positive and negative examples. Moreover, due to the properties of the COT protocol (Sec-tion 3), all shares can be computed in parallel by first run-ning Step 1 in Prot. 1 for all feature vectors and then exe-cute Step 2. The resulting protocol takes four rounds, i.e., all protocol messages can be combined into four larger ones.
One can straightforwardly m odify Protocol 1 so that the parties obtain the shares t 1 + t 2 =0 mod N ,ifpredicted value corresponds to the true label y , and 1, otherwise. Then the sum of the shares counts the number of misclassified data points and we can privately estimate training and validation error or even do private cross-validation.
 be extended to count the number of Karush-Kuhn-Tucker violators. Recall that a feature vector x i is a KKT violator if one of the next three conditions does not hold: Circuit for detecting the KKT violators has O ( )ternary gates. The number of the KKT violators is often used as an indicator for stopping: algorithm has converged if there are no KKT violators. Alternatively, one can stop if the num-ber of the KKT violators is below some threshold or has not significantly changed during several iterations. How-ever, private counting of the KKT violators or training er-ror is resource consuming, and should be done after several iterations of the Kernel Adatron or Perceptron algorithm.
Private training algorithms have the same structure as private prediction algorithms. Whenever possible, we use homomorphic properties of the cryptosystem to compute shares directly. If this is not possible, we use circuit evalua-tion to circumvent the problem. Protocol 3, presented next, is private in the sense that Client and Server learn noth-ing except the number of iterations. Learning the latter is unavoidable in practice, since the amount of computations always provides an upper bound to the number of iterations. One can achieve better privacy by doing extra rounds but this would seriously affect the efficiency.

Due to the space limitations, we present explicitly only a secure analog of Algorithm 1, depicted by Protocol 3. The corresponding secure protocol for the Kernel Adatron algo-rithm has the same structure. We explain only how Step 2 is implemented, the rest is the same as in Prot. 3. Protocol 3 Private Kernel Perceptron Common parameters:  X  with plaintext space Z N .
 Inputs: Client has a secret key sk and labels y .Serverhas Server X  X  output: An encrypted weight vector c =E pk (  X  ). Allowed side information: the number of iterations. 1. Server sets c =E pk ( 0). 2. Client and Server execute the next cycle: for i =1 to n do a) They compute shares s 1 + s 2 = f  X  ( x i )mod N. b) They use circuit evaluation to compute shares c) Client sends d =E pk ( t 1 ), Server sets c i  X  c i d  X  end for 3. If not converged then repeat Step 2.

Theorem 3. Protocol 3 is a correct and private imple-mentation of the kernel Perceptron algorithm (Algorithm 1) provided that (1) the cryptosystem is additively homomor-phic and IND-CPA secure; (2) all substeps are implemented correctly and privately; (3) the constraints | f  X  ( x i ) |  X  | &lt; N 2 always hold.
 Correctness follows as Substep 2b) implements incremental update c i =E pk (  X  i + t 1 + t 2 mod N )=E pk (  X  i + y is incorrectly classified. Since N is at least 1024 bits long, |  X  | N/ 2 for all iterations. Similarly, there are no over-flows in computation of f  X  ( x i ) provided that kernel matrix has reasonable discretization.

The update step of the Kernel Adatron algorithm can be restated as  X  i  X   X  i + y i  X  f  X  ( x i ), where  X  =(  X  i f ( x i )= k i 1  X  1 +  X  X  X  + k in  X  n . The corresponding correction Step 5 in Algorithm 2 implements the constraint 0  X  y i  X  C . Hence, Client and Server can still use private prediction to compute shares s 1 + s 2 =  X  i + y i  X  f  X  ( x i )mod N .Then the correction step must be done with circuit evaluation Finally, Server computes E pk (  X  i )asE pk ( t 1 )E pk ( t shownthatcorrectionstepcanbeimplementedwith2 +1 ternary gates. Thus, the size of the garbled circuit is roughly O (2 ) for both the Kernel Perceptron and Kernel Adatron. The parties have to do +1 invocations of OT counting also the one needed for share conversation.
 Batch processing. Both algorithms are instances of stochastic gradient descent method, as the update changes a single coordinate of  X  . Alternatively, one can use a full gradient descent step instead, i.e., compute all values f simultaneously and the update all coordinates of  X  also si-multaneously. Such batch updates tend to stabilize gradi-ent descent methods but they also decrease the number of rounds, i.e., latency. Due to the properties of COT protocol, Substeps 2a) and 2b) can be executed in parallel and the number of rounds decreases from 6 n to 6 per iteration. We have described cryptographically secure protocols for Kernel Perceptron and kernelized Support Vector Machines. We have also provided cryptographically secure protocols for evaluating polynomial kernels and also shown how to securely aggregate encrypted classification results.
An interesting open question is how to securely hide the convergence speed of the Kernel Perceptron and the Kernel Adatron algorithms. Recall that our private implementa-tions did not leak anything but the number of rounds.
Another, more practical, question is whether there are any iterative private linear classification methods that need no costly circuit evaluation. The Widrow-Hoff classification algorithm is a good candidate, as it contains only addition and multiplication operations. Unfortunately, there one has to also round the values, so it is not clear whether one can escape circuit evaluation.

The proposed classification and classifier learning proto-cols are not limited to data represented as feature vectors, but can be used on any data with secure kernel evaluation. Hence, another relevant issue is private computation of en-crypted kernel matrices for structured data.
 We thank Matti K  X  a  X ari  X ainen, Juho Rousu and Sandor Szed-mak for valuable discussions on the nature of SVMs and the current state of the art in kernel methods. The first au-thor was supported by Finnish Academy of Sciences, and by Estonian Doctoral School in Information and Communica-tion Technologies. The second author was supported by the Estonian Science F oundation, g rant 6848. The third author was supported by the European Union IST programme, con-tract no. FP6-508861, Application of Probabilistic Inductive Logic Programming II . [1] Aiello, W., Ishai, Y., and Reingold, O. Priced [2] Chang, Y.-C., and Lu, C.-J. Oblivious Polynomial [3] Damg  X  ard, I., and Jurik, M. A Generalisation, A [4] Goethals, B., Laur, S., Lipmaa, H., and [5] Goldreich, O. Foundations of Cryptography: Basic [6] Kantarcioglu, M., and Clifton, C. Privately [7] Laur, S., Lipmaa, H., and Mielik  X  ainen, T.
 [8] Lindell, Y., and Pinkas, B. Privacy Preserving [9] Lipmaa, H. An Oblivious Transfer Protocol with [10] Malkhi, D., Nisan, N., Pinkas, B., and Sella, Y. [11] Naor, M., Pinkas, B., and Sumner, R. Privacy [12] Paillier, P. Public-Key Cryptosystems Based on [13] Shawe-Taylor, J., and Cristianini, N. Kernel [14] Va p n i k , V . N . The Nature of Statistical Learning [15] Wright, R. N., and Yang, Z. Privacy-Preserving [16] Yang, Z., Zhong, S., and Wright, R. N.
 [17] Yu, H., Jiang, X., and Vaidya, J. Privacy [18] Yu, H., Vaidya., J., and Jiang, X. ,Privacy
