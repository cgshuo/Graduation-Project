 Jae Woo Lee, Nam Hun Park, Won Suk Lee * 1. Introduction
A data stream is defined as a massive unbounded sequence of data elements continuously generated at a rapid rate. Due requirements, data stream processing sacrifices the correctness of its analysis result by allowing some errors. cell in a multi-dimensional data space.

The range of each one-dimensional cluster in an individual dimension becomes the granule of finding multi-dimensional clusters. Upon receiving a new data element e = h e 1 , e sional clusters of its corresponding dimension. For each dimensional value e the total number of data elements generated so far.
 dimensional clusters collectively.
 pre-defined threshold called insert support S ins (&lt; S of a data stream, those nodes whose supports are greater than or equal to S separately by a data distribution synopsis.
 of the proposed method. Finally, this paper is concluded in Section 6. 2. Related work data elements generated so far in the data stream. However, when the number of clusters is not known in advance, the intensive.

It employs two components: on-line and off-line components. The on-line component executes the K -means algorithm to produce micro clusters. The predefined number of micro clusters is maximized for the available space of main-memory
In the off-line component, the macro clusters of CluStream are generated by executing the K -means algorithm for the two snapshots of each micro cluster at the times t c and t from the same drawbacks of the partitioning-based clustering algorithms. since only linear searching can be possible, which degrade the performance of the method. bility on the dimensionality of a data stream. 3. One-dimensional clustering on these two parameters, a decay rate s is defined as follows: life w , the decay mechanism can control the fading rate of old information flexibly.
A data stream for d -dimensional data space N = N 1 N d is defined as an infinite set of continuously generated data elements as follows: (i) A data element generated at the t th turn is denoted by e t  X h e t (ii) The current data stream D t denotes all the data elements which have been generated so far, i.e. D (iii) The total number of data elements generated in the current data stream D carefully monitored. A grid-cell in a one-dimensional data space for the current data stream D Definition 1. Distribution Statistics of a grid-cell g ( I , c , l , r )
For a one-dimensional data space N k (1 6 k 6 d ) of the current data stream D denote those elements in D t that are in the range of the cell g , i.e., D statistics of the cell g are defined as follows: (i) c t : the decayed count of data elements in D t g (ii) l t : the decayed average of the data elements in D t (iii) r t : the decayed standard deviation of the data elements in D
Given a predefined partitioning factor h , the entire data range range ( N into h mutually exclusive equal-size initial grid-cells G
U ( i  X  j ,1 6 i , j 6 h ). In the current data stream D t to S the interval of a grid-cell. Let G ={ g 1 , g 2 , ... , g be an ordering function, i.e. g i ( I , c , l , r ) g j ( I , c , l , r ) iff g nition 2 .
 Definition 2. A sibling list S
For the data space of a dimension, a sibling list S of order m is defined as follows: 1. A sibling list S = h E 1 , E 2 , E 3 , ... , E p i is a single linked list of sibling entries E 2. Each sibling entry E i maintains a data structure E ( min , max , G [1, ... , m ], next _ ptr ). (i) The m slots in G [1, ... , m ] can hold at most m one-dimensional grid-cells. (ii) When v (&lt; m ) slots are not empty, the range of the entry E (iii) next _ ptr : a pointer to the next sibling entry of S . of the dimension N k . titioning factor h .
 [ min , max ) to locate a specific grid-cell efficiently. For the newly generated data element e follows: ing threshold S par is partitioned into h equal-size smaller grid-cells. If the grid-cell g becomes dense( g c titioned into h equal-size smaller grid-cells g 1 , ... , g more precisely monitored.

The grid-cell g is replaced by the partitioned grid-cells g should be preserved. The distribution statistics of each partitioned grid-cell g grid-cell g . More precisely, the distribution statistics of the j th partitioned grid-cell g tion function of g ; u  X  x  X  X  1 ffiffiffiffi 2 p p g
Fig. 1 shows how a sibling list of order 5 is dynamically managed when h = 4. Suppose the grid-cell g dense upon processing the newly generated data element e t g , g 22 , g 23 and g 24 . Based on the distribution statistics of g the distribution statistics of g 22 are estimated as follows:
This partitioning procedure can be recursively invoked until a unit grid-cell is found. Given the range( N grid-cell is log h ( range ( N )/ k ). A one-dimensional cluster in the dimension N current supports are greater than or equal to S min , respectively.
 j g I j = j g f g s j . The merging range of a grid-cell g is defined by an interval  X 
Given a one-dimensional cluster c formed by a set of consecutive grid-cells [ g age number of data elements per grid-cell as follows: identifier of a cluster is assigned by the following rules: 4. Multi-dimensional clustering 4.1. Overall architecture
Finally, a CS-tree monitors the density of multi-dimensional clusters continuously. 4.2. Cluster transactions
Given a d -dimensional data stream D t , let N k (1 6 k 6 domain. The range of the j th one-dimensional cluster in a dimension N f 2 Dom ( N k ). For the current datastream D t , the set of one-dimensional clusters in a dimension N sibling list S k as described in Section 4. When a new data element e erated as a cluster transaction defined in Definition 3 .
 Definition 3. Cluster Transactions
Given a sequence of dimensions q = N 1 ? N 2 ? ? N d , let S
D of a d -dimensional data space N 1 N 2 N d and let C k denote the set of one-dimensional clusters in the sibling list
S (1 6 k 6 d ). A cluster transaction CT t for the newly generated data element e t  X h e t identifiers of one-dimensional clusters, CT t = c 1 ? c 2 (i) Up to the j th dimension in the dimension sequence q , there exists a one-dimensional cluster c 2 C
For example, given a dimension sequence N 1 ? N 2 ? ? N d c , c 3 and c 4 , respectively. But the fifth dimensional value of e resulting cluster transaction for the data element e t becomes CT sional values of e t are matched or not.

Fig. 3 describes how a cluster transaction for a data element is generated. For the data element e for dimensions X , Y and Z fall within the ranges of one-dimensional clusters c responding cluster transaction is generated as CT 11 = h c transaction is generated as CT 12 = h c X 2 , / , / i regardless of the matching result on dimension Z . 4.3. Cluster statistics trees a one-dimensional cluster of its corresponding dimension. For a d -dimensional data stream, a path of length k ( k nition 4 .
 Definition 4. CS-trees
Given a sequence of dimensions N 1 ? N 2 ? ? N d for the current d -dimensional data stream D dimensional clusters for a dimension N k (1 6 k 6 d ). A CS-tree Q (i) A CS-tree Q t has a root node n root with a  X  X  null  X  value. Except the root node, each node in the k th depth (1 (ii) Given a node v corresponding to a cluster c 2 C k , let q = root ? v (iii) Except for the root node, every node v in the k th depth (1 itored separately by a one-dimensional cluster table defined in Definition 5 .
Definition 5. One-dimensional cluster table(1 D -cluster ( N
For the dimension N k of the current data stream D t , a one-dimensional cluster table 1 D -cluster ( N tuple( c , count t ( c ), tid ) where:  X  c 2 C k : the identifier of a one-dimensional cluster in N  X  count t ( c ): the decayed number of data elements that are within the interval of the cluster c  X  tid : the identifier of a transaction that has made the count
Given a predefined sequence of dimensions q = N 1 ? N 2 ? ? N dimensional cluster in CT t , its count in the one-dimensional cluster table 1 D -cluster ( N of CT t (1 6 k 6 d ) is already maintained in 1 D -cluster ( N sponding tuple c k in 1 D -cluster ( N k ) is updated as follows.
If there is no tuple for the cluster c t k , a new tuple  X  c t dimension sequence q , if the k th cluster(1 6 k 6 d )of CT
Q . According to the cluster identifiers of CT t , a single path of the CS-tree Q in the path becomes less than S prn (&lt; S ins &lt; S min that fall within the range of a d -dimensional rectangular space is greater than or equal to S was lastly updated by the p th transaction CT p is visited for a newly generated data element e t synopsis is updated as follows: where count t is maintained in the leaf node v .
 Definition 6. Data distribution synopsis range of its corresponding d -dimensional rectangular space. Its data distribution synopsis DS ( v )=( ssum by the child pointer of the node v and is defined as follows: where ssum t i ; l t i and r t i are the squared sum, average and standard deviation of the data elements in R ( v ). in CT t , a new node v ( c k +1 , count , nil ) with a cluster c child node is created only when the following two conditions are satisfied. (i) count t ( w )/ j D t j P S ins and (ii) count ( c k +1 )/ j D t j P S ins .

The support of a newly inserted node v can be estimated to any value between S determines how long a newly created node is sustained even though there is no data element whose value falls within of its resulting clusters can be improved. If the support of a newly created node in a CS-tree is initialized to S may grow too rapidly. On the other hand, if the support is set to S newly inserted node v is initialized as follows: ted in Property 1 .

Theorem 1. Given a CS-tree for the current d-dimensional data elements D path q v 1 =c 1 ? c 2 ? ? c v 1 (1 &lt; v 6 d) where c 1 ,c created at D x (x &lt; t) and a new node c v is created as a child of the node c cluster C v corresponding to the path q v =c 1 ? c 2 ? ? c
D
Proof. In a CS-tree, a new node can only be created when the support of its parent node is greater than or equal to S a new node is created at the current data stream D t , its count is initialized to j D created at D y , the following inequality should be satisfied.

The left term of the above inequality is the count of the node c child node, the count of the node c v 1 should be greater than or equal to j D 2( a S ins ) D y ={2 a ( S ins + S prn )} D x and also be expressed. D
Property 1. Given a CS-tree in the current data stream D t
Proof. Before the count of the node c v was initialized at D count of the node c v was initialized to D y ( S ins + S prn as a 1 2  X  S ins  X  S prn  X  j D y j j D t j . When t ? 1 , it becomes negligible as follows: cise steps of the proposed algorithm are presented.
 sequence N 1 ? N 2 ? N 3 , S min = 0.3, S ins = 0.1, S prn sional cluster tables, respectively. Suppose the 42nd cluster transaction CT dimension, the cluster c 33 is a new one, so that a new tuple h c cluster transaction CT 42 is modified to CT 42  X h c 13 ; c and the counts in the nodes of the path ( c 13 :11) ? ( c
If the new cluster transaction CT 42 were h c 13 , c 23 , c all the clusters in CT 42 are dense. Subsequently, each node on the path ( c reaching the node corresponding to the cluster c 23 , even if the one-dimensional cluster c no child for the cluster c 23 is created since the current support of the node is less than S ( c :3) for its modified cluster transaction CT 42  X h c 13 ; c space is created as its child as shown in Fig. 5 c. This is because the one-dimensional cluster c new data distribution synopsis for the node is also created. Subsequently, when a new cluster transaction h c erated for the next data element e 43 , its modified cluster transaction becomes h c Fig. 5 d.

When reaching a maximum-depth leaf node, if its support is greater than or equal to S the event that takes place when an occultation for two clusters occurs on the i th dimension (1 data space. The probability of occurring an occultation on every dimension is denoted by P ( O study in [21], its value is obtained as follows: sional data stream.
 the d-dimensional data space is very low when the dimensionality of the data stream is high.
Proof. Since k b c k &gt;( r 1 + r 2 ) and p &gt; 2 ;  X  r method is O  X  nd D  X  nd  X  . 4.4. Refinement the path from the root to the node v be c 1 ? c 2 ? ? c d the cluster M is the d -dimensional rectangular space range ( M )= I
According to the well-known Chebyshev X  X  Inequality Theorem [20],if l random variable X for any positive constant k , the following inequality should be satisfied. the interval that contains at least p % of the data elements in each dimension. The upper bound is l this purpose.
 dimensional clusters c 11 and c 12 on X and the three one-dimensional clusters c precise boundary of the space C corresponding to the path / ? ( c (25,35) and (21,29). Notice that the one-dimensional cluster c independently by the CS-tree, so that the ranges of the final clusters C 5. Experimental results ment is randomly selected. Most data elements are concentrated on randomly chosen 20 data regions whose sizes in each eters in most experiments are set as S min = 0.001, S ins operation is performed in every 50,000 transactions. All experiments are performed on a 3 GHz Pentium PC machine with 2 GB main memory running on Linux and all programs are implemented in C .
In Fig. 7 , the performance of the proposed method on the low-dimensional data sets is compared with those of hybrid-partition, LSEARCH and cell-trees. Since the support threshold S method is the most efficient in terms of both processing time and memory usage while its accuracy is almost the same as or better than those of the others methods. Among the four clustering methods, the proposed method uses the least amount of memory space. As the size of a stream chunk is decreased, the LSEARCH method uses less memory space. How-ever, its performance is substantially degraded in terms of processing time and accuracy. the other clustering methods remain the same.
 racy of the proposed method is compared with that of LSEARCH. The proposed method is more accurate than LSEARCH no that of the proposed method is decreased slightly since the size of k is increased. sions is increased. When the size k of a unit grid-cell becomes smaller, both memory usage and processing time are increased.
 and memory usage of the proposed method by the value of S
S increased as the value of S prn is increased for a fixed S is shown.
 Fig. 13 a shows the adaptability for the change of information in a data stream. The data set D posed of two consecutive subparts D A and D B . The front part denoted by the data set D elements while the second part denoted by the data set D B the data set D A are mutually exclusive to those of the data set D a coverage rate CR is introduced. Let P ( D i ) denote the set of clustered data elements in a data set D D
A and D B , the coverage rate CR ( D i ) of a data set D i posed method in the course of information change. As the coverage rate CR( D 500 Kth data element, the accuracy is also decreased. This is because the dense grid-cells of D However, the accuracy is increased as soon as the dense grid-cells of D quickly, so that the support of each node in a CS-tree is changed rapidly. defined parameter called spreading factor .
 of an occultation on each dimension is increased, so that the accuracy of the proposed method is degraded. 6. Conclusion greatly enhanced. Furthermore, based on several parameters like S proposed method flexibility in terms of memory usage and processing time. Acknowledgements This work was supported by the Korea Science and Engineering Foundation (KOSEF) NRL Program grant funded by the Korea Government (MEST) (No. R0A-2006-000-10225-0).

References
