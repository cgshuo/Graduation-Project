 Efficiently answering XML keyword queries has attracted much research effort in the last decade. One key factors resulting in the inefficiency of existing methods are the common-ancestor-repetition (CAR) and visiting-useless-nodes (VUN) problems. In this paper, we propose a generic top-down processing strategy to answer a given keyword query w.r.t. LCA/SLCA/ELCA semantics. By X  top-down  X , we mean that we visit all common ancestor (CA) nodes in a depth-first, left-to-right order, thus avoid the CAR problem; by X  generic  X , we mean that our method is independent of the labeling schemes and query semantics. We show that the satisfiability of a node v w.r.t. the given semantics can be determined by v  X  X  child nodes, based on which our methods avoid the VUN problem. We propose two algorithms that are based on either traditional inverted lists or our newly proposed LLists to improve the overall performance. The experimental results verify the benefits of our methods according to various evaluation metrics.
 H.2.4 [ Database Management ]: Systems X  Textual Databases ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Search process ;F.2.2[ Analysis of Algorithms and Problem Complexity ]: Nonnumerical Algorithms and Problems X  Sorting and searching Algorithms, Performance KeywordSearch;XML;LCA;LList;Top-down  X 
Keyword search on XML data has received much attention in the literature [1 X 4,7 X 10,12 X 14,18]. An XML document is typically modeled as a node-labeled tree T . For a given keyword query Q , semantics based on the notation of Lowest Common Ancestor ( LCA ), such as Exclusive LCA ( ELCA ) [1,4,6,14,18] and Smallest LCA ( SLCA ) [1,9,10,12,13] has been proposed and widely used. Finding all LCA/ELCA/SLCA nodes is the core operation for XML keyword query processing, based on which subtree results meeting certain constraints [5,6,9] can then be generated for effective identifying useful information from the underlying data. Despite many proposed algorithms to answer such queries efficiently [1, 4, 5, 10, 12 X 15, 18], they suffer from various kinds of redundancy in their computation.
Given a keyword query Q and XML document D ,let V be the set of nodes of D that contain at least one query keyword in their subtrees, we can classify all nodes of V into three categories: (1) common ancestors (CAs), each of which contains all query keywords in its subtree, such as nodes of V 1 in Figure 1 for Q (2) useless nodes (UNs), each of which is not a child of any CA node, for Q 2 , all nodes of V 2 in Figure 1 are UNs; (3) auxiliary nodes (ANs), each of which is a child node of some CA node and belongs to V  X  V 1 V 2 , such as V 3 in Figure 1. Generally speaking, the common problems that result in inefficiency for existing algorithms are the CAR [15,16] and VUN problems. The CAR problem : As first identified in [15,16], existing methods [1,4,6,9,10,12  X  14,18] assign each node v aDewey label [11], or one of its variants [1,7,12,18], based on which two basic operations are adopted to compute qualified results, i.e., ( OP 1) testing the document order of two nodes and ( OP 2) computing the LCA of two nodes. However, as each Dewey label consists of a set of components that collectively represent anode v , and each component itself corresponds to a node on the path from the root r of the XML tree to v , either OP 1 or
OP 2 operation is equal to visiting all CAs of the two involved nodes once. In practice, as v could be a CA of multiple nodes, frequently performing OP 1 and OP 2 operations will result in all CAs on the path from r to v be repeatedly visited, which is called as common-ancestor-repetition (CAR). Although some recently proposed methods [15,16] avoid this problem, they employ a flattened index structure called IDList, which makes them victim of the VUN problem presented below. The VUN problem: none of the existing methods can avoid visiting useless nodes , referred to as the VUN problem, as shown by Example 1.

DIL [4], IS [14], IL [13] and IMS [10] are OP 1 and OP 2 , they need to repeatedly select two nodes and compare their
Dewey labels. E.g., for query Q 2 in Figure 1, to get the LCA ofnodes8and9,theyneedtovisitnodes6,8and9;toget the LCA of nodes 18 and 19, they need to visit nodes 16, 18 and 19. JDewey [1] computes ELCA/SLCA results by per-forming the set intersection operation on all lists of each tree depth from the leaf to the root, they will firstly visit nodes of V 2 . For FwdSLCA, BwdSLCA, BwdSLCA + , FwdELCA and
BwdELCA [15], since the IDList of each keyword k i consists of all nodes that contain k i , the set intersection operation on all IDLists may visit any node, including UNs. For hash search based algorithms, since HC [18] needs to push each component of every IDDewey [12, 18] label of the shortest inverted list into a stack, they will process UNs if some nodes of an IDDewey label are UNs. Even though HS [12] does not need to check the satisfiability of all nodes of an IDDewey label by using binary search to select processed nodes, it still needs to visit UNs if the selected nodes are UNs.

The reason that existing methods [1,4,9,10,12  X  14,18] suffer from the VUN problem lies in that, essentially, the satisfia-bility of each node v w.r.t. LCA, SLCA or ELCA semantics is determined by v  X  X  descendant nodes, rather than its child nodes.

To address the above problems, we propose a generic top-down processing strategy to answer XML keyword queries. The  X  top-down  X  means that our methods visit CA nodes, rather than Dewey labels, in depth-first left-to-right order, thus avoid the CAR problem. The  X  generic  X  means that our methods can be used to find x LCA ( x LCA can be either LCA, SLCA and ELCA) results, and the underlying indexes can be generated based on x Dewey labeling scheme ( x Dewey can be either Dewey or one of its variants, such as JDewey [1] or IDDewey [12,18]). We then show that the satisfiability of a node v w.r.t. x LCA semantics can be determined by v  X  X  child nodes, based on which our methods avoid the VUN problem. We propose a labeling-scheme-independent inverted index, namely LList, which maintains every node in each level of a traditional inverted list only once and keeps all necessary information for answering a given keyword query without any loss. Based on LLists, our method further reduces the time complexity. A full version of this work can be found at [17].
We model an XML document as an ordered tree (Figure 1), where nodes represent elements or attributes, while edges Figure 2: Inverted IDDewey label lists of  X  X om X  ( L 1 ) and  X  X ML X  ( L 2 ) ,where pos denotes the array sub-script. represent direct nesting relationship between nodes. We say node v directly contains k or v is a keyword node w.r.t. k ,if k appears in the node name, attribute name, or text value of v ; otherwise, if k is directly contained by some descendant nodes of v ,wesay v contains k .

Given two nodes u and v , u  X  d v means that u is located before v in document order, u  X  a v means that u is an ancestor node of v , u  X  p v denotes that u is the parent node of v .If u and v represent the same node, we have u = v ,andboth u d and u a v hold.

To accelerate the query processing, existing methods [1,4, 9, 10, 12 X 15, 18] usually assign each node v a uniquely label to facilitate the testing of the positional relationships. The assigned label for each node can be an ID which is compatible with the document order [15], a Dewey label [11] or one of its variants. In Figure 1, we denote each node v by its ID, based on which its IDDewey [12,18] label can be easily got by concatenating all IDs on the path from the root node to v .E.g., the IDDewey label of node  X 5 X  is  X 1.4.5 X . For simplicity, we do not differentiate a node, its ID, and the corresponding IDDewey label henceforth. Foragivenquery Q = { k 1 ,k 2 , ..., k m } and an XML document D , inverted lists are often built to record which nodes directly contain which keywords. We use L i to denote the inverted list of k i that consists of IDDewey labels sorted in document order. Figure 2 shows the inverted lists for keywords of Q 1 in Figure 1.
Given a query Q andanXMLdocument D , the set of CA nodes of Q on D is CA ( Q )= { v | v contains each keyword of Q at least once } . E.g., for query Q 1 and D in Figure 1, CA nodes are nodes 1, 4, 6, 10, 14 and 16.

Let lca ( v 1 ,v 2 , ..., v m )bethe lowest common ancestor (LCA) of nodes v 1 ,v 2 , ..., v m ,theLCAsof Q are defined as LCA ( Q )= { v | v = lca ( v 1 ,v 2 , ..., v m ) ,v i  X  L i (1  X  i  X  m ) } nodes of Q 1 on D in Figure 1 are nodes 1, 4, 6, 10 and 16.
SLCA [10,13] is one of the widely adopted query semantics, which defines a subset of LCA ( Q ), of which no LCA is the ancestor of any other LCA. Obviously, the SLCA nodes of Q on D in Figure 1 are nodes 6, 10 and 16.
 Another widely adopted query semantics is ELCA [4,14,18]. Intuitively, a node v is an ELCA if the subtree rooted at v contains at least one occurrence of all query keywords, after excluding the occurrences of the keywords in each subtree rooted at a descendant LCA node of v , which can be formally defined as ELCA ( Q )= { v | X  v 1  X  L D 1 , ..., v m  X  L D m ( v = LCA ( v  X  i  X  [1 ,m ] , x ( x  X  LCA ( Q )  X  child ( v,v i ) a x )) } child ( v,v i )isthechildof v on the path from v to v i .E.g.,ELCA nodes of Q 1 on D in Figure 1 are nodes 1, 6, 10 and 16.
As LCA/SLCA/ELCA nodes are subset of CA nodes, the basic idea of our method is: directly compute all CA nodes in a top-down way, and check the satisfiability of each CA node w.r.t the given query semantics .

Assume that for a given query Q = { k 1 ,k 2 , ..., k m } keyword appears at least once in the given XML document. Intuitively, to get all CA nodes of Q ,ourmethodtakesall nodes in the set of inverted IDDewey label lists as leaf nodes of an XML tree T r rooted at node r , and checks whether each node of T r contains all keywords of Q in a  X  top-down  X  X ay. The  X  top-down  X  X eansthatif T r contains all keywords of Q , then r must be a CA node. We then remove r and get a forest F
T r = { T v 1 ,T v 2 , ..., T v n } of subtrees rooted at the n child nodes of r .Basedon F T r , we further find the set of subtrees keyword of Q at least once, i.e., node v i , is a CA node. If can safely skip all nodes of T r from being processed; otherwise, for each subtree T v i  X  X  CA T r ,we recursively compute its subtree contain k i in T v , S CA ch ( v ) the set of child CA nodes of v ,and CA ( T v )thesetofCAnodesin T v . Formula 1 means that the set of CA nodes of Q equals the set of CA nodes in T r , which can be recursively computed according to Formula 2. Formula 2 means that for a given CA node v ,thesetofCAnodesin T v is equal to the union of { v } and the set of CA nodes in the subtree rooted at each of v  X  X  child CA nodes, which can be further computed by Formula 3.

Example 2. Consider query Q 1 and D in Figure 1. Ac-cording to Formula 1, CA ( Q 1 )= CA ( T 1 ) .FromFigure1,we know that nodes 4 and 14 are child CA nodes of node 1, i.e., S ch (1) = { 1 } CA ( T 4 ) CA ( T 14 ) .Since S CA { 16 } and S CA ch (6) = S CA ch (10) = S CA ch (16) =  X  , we know that CA ( Q 1 )= CA ( T 1 )= { 1 , 4 , 6 , 10 , 14 , 16 } . Corollary 1. Either one of Dewey, JDewey, IDDewey, MDC and EDewey labeling schemes can be used for top-down CA computation.

The correctness of Corollary 1 lies in that each child node of a given node v is represented by a distinct ID value compared with its sibling nodes w.r.t. either one of Dewey-like labeling schemes, thus the set intersection operation can correctly return all child CA nodes of v by intersecting v  X  X  m sets of child nodes. Based on all CA nodes got by Formula 1, our method can efficiently check the satisfiability of each CA node w.r.t. the given query semantics. In the following sections, we focus on ELCA computation to illustrate the benefits of our top-down processing strategy. Our baseline algorithm uses inverted IDDewey label lists for ELCA computation (Figure 2). To recursively get all ELCA nodes in a top-down way, we need to solve two problems: ( P 1) identify the set of child CA nodes for each CA node v ,( P 2) check v  X  X  satisfiability w.r.t. ELCA semantics.

For P 1 , according to Formula 3, for query Q with m keywords, given CA node v and its subtree set F T v = { T v 1 ,T v 2 to get S CA ch ( v ), we do not need to check whether each T [1 ,n ] ,v  X  p v x ) contains all keywords of Q ; instead, we just need to check whether each node of S k min ch ( v )= { S k i [1 ,m ] ,  X  j  X  [1 ,m ] ,j = i, | S k i ch ( v ) | X | S k j S ch ( v )( j
For instance, for Q 1 and D of Figure 1, S Tom ch (4)= { 5 , 6 , 10 S ch (4) = S ch (4) = S need to check whether each node of S XML ch (4) is contained by S ch (4), then we know S CA ch (4) =
However, in Figure 2, each child node of v may repeat many times in each inverted list. E.g., even though S XML ch (4) = all nodes of S XML ch (4)appearin L 2 as 6,6,10,10 ,whichwecall as the child list of node 4 w.r.t. XML. Obviously, all nodes of S ch ( v ) are different with each other, while in the child list of v w.r.t. k i ,eachnodeof S k i ch ( v ) may repeatedly appear many times.

Therefore, even if we know the lengths of all child lists, it X  X  difficult to know which one contains the least number of child nodes. Fortunately, as all node IDs in each child list of v are sorted in ascending order, our newly proposed set intersection algorithm guarantees that the number of processed child nodes for each CA node v is bounded by | S k min ch ( v ) | .
For P 2 , we use the following Lemma to check the satisfiability of v , which is similar to [15,18].

Lemma 1. For a query Q = { k 1 ,k 2 , ..., k m } and CA node v ,let T v .N i be the number of occurrences of k i in T v ELCA node iff  X  i  X  [1 ,m ] ,T v .N i  X  u  X  S CA
According to Figure 2, T 1 .N 1 =5, T 1 .N 2 =7and S CA ch { 4 , 14 } ,since T 4 .N 1 =3, T 4 .N 2 =4, T 14 .N 1 =1and T 2, we know T 1 .N 1  X  ( T 4 .N 1 + T 14 .N 1 )=1 &gt; 0and T ( T .N 2 + T 14 .N 2 )=1 &gt; 0, thus according to Lemma 1, node 1 is an ELCA node of Q 1 .

In Algorithm 1, each inverted list L i is associated with a cursor C i pointing to some IDDewey label of L i . C i will refer to the IDDewey label that C i points to. We use pos( C i )to denote C i  X  X  position in L i ,and L i [ x ]todenotethe x label of L i .If C i points to the x th IDDewey label of L pos( C i )= x , we have the assertion that L i [ x ]= C i IDDewey label l , | l | denotes the length of l , i.e., the number of components of l , l [ j ]denotesthe j th component of l .If C points to the x th IDDewey label l , then L i [ x ][ j ]= C Besides, we use T to denote the subtree rooted at a CA node. T has five member variables: (1) T.r is the root node of T ;(2) T.l is the IDDewey label of r ;(3) T.s i is the position value of the first appearance of l in L i ;(4) T.e i is the position value of the last appearance of l in L i ; and (5) T.N i is the number of occurrences of k i in T . Obviously, T.N i = T.e i  X  T.s Note that T.s i and T.e i denote an interval of L i , in which all IDDewey labels share the same common prefix, i.e., T.l , from which we can get the child list of T.r w.r.t. k i .

As shown in Algorithm 1, our method firstly initializes the subtree rooted at the root node of the given XML tree in lines 1-4, then calls the procedure processSubTree() to recursively get all ELCA nodes in line 5.

The procedure processSubTree() works as follows. It firstly gets the depth of T.r  X  X  child nodes in line 1, then makes each C i point to the first IDDewey label l in interval [ T.s i ,T.e such that l  X  X  length is greater than T.l (lines 2-4), which equals making C i point to the first descendant node of T.r that directly contains k i . In lines 6-12, it repeatedly gets all child CA nodes of T.r . For each child CA node id ch got in line 7, it firstly gets the subtree T rooted at id ch in line 9; in line 10, it excludes the occurrences of all query keywords in T . In line 11, it calls the procedure processSubTree() to recursively process T . After processing all subtrees rooted at T.r  X  X  child CA nodes, if  X  i  X  [1 ,m ] ,T.N i &gt; 0, according to Lemma 1, we know that T.r is an ELCA node, then we output it in line 14.

Given a subtree T , the function getNextChildCA() is called in line 7 of processSubTree() to find a child CA node of T.r by intersecting m child list sof T.r . After finding a CA node id in line 7 of processSubTree(), we call the function getSubTree() in line 9 to get the subtree rooted at id ch . Note that the procedure binSearch() is used to locate the position of the first checks whether we have exhausted a list by checking the cursor positions.

Example 3. Consider Q 1 and D in Figure 1. Algorithm 1firstlyprocesses T 1 . It finds node 1 X  X  child CA nodes from its two child lists, i.e., the second level of the two inverted lists in Figure 2. Since node 1 X  X  first child CA node is node 4, we get T 4 and then find node 4 X  X  child CA nodes from its child lists in the third level of the two inverted lists. Note that for node 4, T 4 .s 1 =2 , T 4 .e 1 =4 , T 4 .s 2 =2 and T 4 .e is, we find node 4  X  X  child CA nodes from two shortened child lists, i.e., 5,6,10 and 6,6,10,10 . As node 6 does not have child CA nodes, and T 6 .N 1 =1 , T 6 .N 2 =2 ,node6isanELCA node. Similarly, we know that node 10 is an ELCA node. After that, we check the satisfiability of node 4. Since T 4 .N T .N 2 =4 , after excluding the occurrences of all query keywords in T 6 and T 10 , we have T 4 .N 2 =0 ,andaccordingtoLemma 1, node 4 is not an ELCA node. The following processing is similar. Finally, the outputted ELCA nodes by Algorithm 1 are nodes1,6,10and16.
 Corollary 2. ( Independence ) The satisfiability of each CA node v w.r.t. ELCA semantics can be determined by v  X  X  child nodes.

Corollary 2 means that compared with existing methods [4,14,15,18], our method avoids the VUN problem.

Assume that for the given query Q = { k 1 ,k 2 , ..., k m |
L 1 | X | L 2 | X  ...  X | L m | . Sincethelengthofthechildnode list of each CA node w.r.t k i is bounded by | L m | ,thecostof checking whether a node is a CA node is O ( m log | L m |
If we always process nodes of S k 1 ch ( v ) for each CA node, the number processed nodes of TDELCA is v  X  CA ( Q ) | S k 1 ch AsshownbygetNextChildCA(),ourmethodalwaysusesthe maximum ID to probe other lists to find the next CA node, it may skip many useless nodes in S k 1 ch ( v ), thus the total number of processed nodes is bounded by v  X  CA ( Q ) | S k 1 Therefore, the time complexity of the TDELCA algorithm is of the given XML tree.
Given a node may appear multiple times in each inverted list, for each processed node v , Algorithm 1 needs to use two probe operations (i.e., binSearch()) to find the first and last IDDewey labels containing v in each L i . Moreover, as shown in Figure 2, the closer v istotherootnode,themoretimes v will appear in
Algorithm 1: TDELCA( Q = { k 1 ,k 2 , ..., k m } ) the inverted list on average, thus the longer the child lists of v . Since we perform set intersection operation on the set of child lists of v , this long child list results in more processing efforts.
To address the above problems, in this section, we propose a new index, LList, and a query processing algorithm that reduces both the cost and number of invocations of binSearch().
Let L i be the inverted IDDewey label list of k i , in our method, the corresponding inverted list L i of k i consists of at most d sublists, i.e., L i = {L 1 i , L 2 i , ..., L d i i } ,where d number of components of the longest IDDewey label in L i .Each ( j  X  [1 ,d i ]) consists of entries representing the set of distinct / / / / /
Figure 3: LLists of  X  X om X  ( L 1 ) and  X  X ML X  ( L 2 ) . nodes in the j th level of L i .Eachentry e v  X  X  j i corresponds to anode v consists of two numeric values:  X   X  id  X  is the last component of v  X  X  IDDewey label, i.e., the ID value of v ,  X   X  p lc  X  X s,in L j +1 i , the position of the entry corresponding to v  X  X  last child that contains k i . When S k i ch ( v )=  X  first entry of L j i , e v .p lc =0;otherwise, e v .p lc = e e u is the last entry that precedes e v in L j i .

Hereafter, we call each L i an LList, denoting that all nodes in the same level are maintained together. Figure 3 shows the twoLListsof X  X om X  X nd X  X ML X  X asedon D in Figure 1, where  X (1,3) X  of L 1 1 means that the child list of node 1 contains the first three nodes of L 2 1 , and X (14,4) X  of L 2 1 means that the last node in the child list of node 14 is the 4 th node of L 3 16. As  X (4,3) X  is the last entry that proceeds  X (14,4) X  in know that the child list of node 14 w.r.t.  X  X om X  contains just one node, i.e., node 16.

Property 1. For each node of L i ,allnodesineachofits child lists are sorted in ascending order by their ID values.
Property 1 guarantees that for any node v , S CA ch ( v )canstillbe computed based on anyone of existing ordered set intersection algorithms . Based on LList, we have Lemma 2 to check ELCA node.

Lemma 2. For a query Q = { k 1 ,k 2 , ..., k m } and CA node v , let T v .N i be the number of nodes in the child list of v w.r.t. k L , v is an ELCA node iff S CA ch ( v )=  X  or  X  i  X  [1 ,m ] ,T | S ch ( v )
Example 4. Consider Q 1 and D in Figure 1. From Figure 3 we know that T 1 .N 1 = T 1 .N 2 =3 .Since | S CA ch (1) | 3 ,accordingtoLemma2,node1isanELCAnode.Fornode4, since T 4 .N 1 =3 , T 4 .N 2 =2 and | S CA ch (4) | = |{ 6 , 10 know T 4 .N 2  X  X  S CA ch (4) | =0 , according to Lemma 2, node 4 is not an ELCA node. We call our algorithm based on the LList index as TDELCA-L, which finds all CA nodes and checks their satisfiability in the same order as TDELCA does. The improvements of TDELCA-L over TDELCA lie in the following aspects: (1) binSearch() does not need to be called by getSubTree() anymore; (2) binSearch() is performed on a much shorter child list on average; (3) binSearch() stops immediately when it spots a value equalling the eliminator, while in TDELCA, each node may repeatedly appear in a child list many times, and binSearch() is used to find the first IDDewey label containing the eliminator . We omit the detailed description of TDELCA-L due to limited space.

Example 5. Consider Q 1 and D in Figure 1 again. To get child CA nodes of node 1, we need to compute the intersection of node 1 X  X  child lists, i.e., 2,4,14 and 3,4,14 in L 1 and respectively. As a comparison, the two corresponding child lists are 2,4,4,4,14 and 3,4,4,4,4,14,14 in L 1 and L 2 for TDELCA. Obviously, the intersection operation is performed on much shorter lists by calling binSearch () .Aseachnodein a child list of LList is distinct from others, binSearch () can stop immediately when it spots a value equalling the eliminator. For TDELCA, we need to call binSearch () in getSubTree () to get the position of the last IDDewey label containing the ID of the current node v ,suchthattogetthechildlistof v w.r.t. each query keyword. As a comparison, we do not need to call binSearch () to know each child list, which can be directly got by the p lc value of the corresponding entry of v .

As Lemma 2 is still based on the set of child nodes to check the satisfiability of each CA node, Corollary 1 and 2 still hold for the TDELCA-L algorithm.

For all nodes of the set of LLists of Q = { k 1 ,k 2 , ..., k N bethenumberofnodesinthelongestchildlistofthesenodes, N  X | L m | . As the number of processed nodes of TDELCA-L is same as that of TDELCA, the time complexity of TDELCA-L is O ( m  X  ( v  X  CA ( Q ) | S k 1 ch ( v ) | )  X  log N ).
Even though each IDDewey label in L i implicitly contains all its ancestor nodes, only the last component represents the node that directly contains k i , and directly removing all repeated appearances of each node of L i to construct L i may result in losing the information that some non-leaf nodes may directly contain k i , since in L i , we are only sure that leaf nodes are keyword nodes w.r.t. k i . E.g., for query Q = { k 1 ,k 2 XML document in Figure 4 (a), the inverted list L 1 of IDDewey labels for k 1 is shown in Figure 4 (b), from which we know that k appears four times in the two subtrees rooted at nodes 2 and 6. However, according to LList L 1 in Figure 4 (c), both nodes 2 and 6 have only one child node that contains k 1 in their subtrees. Therefore, node 6 will be incorrectly identified as a non-ELCA node.

To solve the problem, only when both v  X  X  j i and some of its descendant nodes directly contain k i , we maintain a dummy entry e dummy in L j +1 i with e dummy .id = 0 denoting that v directly contains k i ,and e dummy is inserted before the entry of v  X  X  first child node. Let e u ch be the last entry that precedes the entry of v  X  X  first child node, the value of e dummy for v is set as
Hence, we can obtain revised LList shown in Figure 4 (d), where two dummy nodes X (0,0) X  X nd X (0, 1) X  X re added to L 3 1 . Figure 5: Normalized ELCA query time (XMark)
The algorithms used in the experiments are BwdELCA [15], and our methods (TDELCA and TDELCA-L). BwdELCA has been shown to outperform other ELCA algorithms in [15].
We follow the same configuration in [15]: (1) XMark (582MB) is used; (2) and the same set of queries (QX1 to QX16 corre-sponding to Q9 to Q26 in [15]).

The metrics for evaluating these algorithms include: (1) running time, (2) the number of comparison operations between integers, which helps us understand the performance variance in an in-depth way. Specifically, the total number of comparisons, i.e., N C , can be computed as N C = M i =1 n i , where n number of search steps of a binary search operation, and M is thenumberofbinarysearchoperations.
 Figure 5 shows the running time of all algorithms for queries QX1 to QX16, from which we know that (1) TDELCA and TDELCA-L are more efficient than BwdELCA, the reason lies in that TDELCA and TDELCA-L avoid both the CAR and VUN problems, thus achieve significant performance gain; (2) TDELCA-L usually works better than the TDELCA algorithm by reducing both the cost and calling times of binary search.
The above results can be further verified according to the number of comparison operations shown in Table 1, from which we know that TDELCA-L always needs the least comparison operations. From Table 1 we also know that TDELCA may need more comparison operations than BwdELCA for some queries, e.g., QX9 and QX10, but it still works better than BwdELCA (see Figure 5), this is because the binary search of TDELCA is done on a much shorter search interval than that of BwdELCA on average, which means that the buffer hit ratio of TDELCA is higher than that of BwdELCA, thus can be done more efficiently.
In this paper, we proposed a top-down processing strategy and a new index structure, LList, that totally avoid the CAR and VUN problems that hinders the query processing efficiency of most previous methods. Our method is also general enough to work with many labeling schemes and query semantics. Our experimental results verified the performance advantages of our methods according to various evaluation metrics.
