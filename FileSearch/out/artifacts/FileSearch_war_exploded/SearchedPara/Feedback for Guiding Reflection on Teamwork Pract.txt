 Effective communication in project teams is important, but not often taught. We explore how fee dback might improve teamwork in a controlled experiment where groups interact through chat rooms. Collaborators who receive high feedback ratings use dif-ferent language than poor collabor ators (e.g. more words, fewer assents, and less affect-laden langua ge). Further, feedback affects language use. This suggests that a system could use linguistic analysis to automatically provide and visualize feedback to teach teamwork. To this end, we pr esent GroupMeter, a system that applies principles discovered in the experiment to provide feed-back both from peers and from automated linguistic analysis. H.5.3 [ Information Interfaces and Presentation ]: Group and Organization Interfaces  X  Computer-supported cooperative work . Measurement, Design, Experimentation. CSCL, feedback, peer evaluation, linguistic analysis, teamwork. Many college courses now invol ve group work. Practicing team-work in college prepares students to tackle problems upon enter-ing the workforce, where teamwork is common. Further, the im-portance of social interaction for effective learning processes has long been recognized. Groups promote critical thinking skills, involve students in the learning process, improve classroom re-sults, and model effective student problem solving techniques [9]. However, groups as learning tools also have pitfalls, such as free riding , where some members don X  X  pull their weight [9]. These problems can sabotage group activity and learning goals; students hate free riders who can sometimes achieve a passing grade while doing little work and learning little. More generally, a prerequisite to successful learning in teams is the construction of effective collaboration practices [2]. However, little attention or guidance is given to learning teamwork processes in college courses. Our goal is to find ways in which technology can be used to illu-minate the group process so that students learn collaboration skills along with course content. In this paper, we present a feasibility study to investigate how automated linguistic analysis of conver-sation style might be used in a system that provides feedback about collaboration behavior. We asked groups to perform a deci-sion-making task using a chat interface, and to provide peer feed-back on each others X  collaborative performance using a web inter-face. By collecting conversation da ta and explicit ratings of col-laboration performance, we were able to address two key ques-tions that a system that provides linguistic feedback must answer:  X  Does conversation style predict collaboration ratings?  X  Do collaboration ratings then change conversation style? We found evidence for both questions, suggesting that building a system that provides linguistic fee dback is a worthwhile thing to do. We end by presenting a prototype of the GroupMeter system which we will use to conduct further studies of how feedback from both peers and algorithms can improve group learning. Anyone who has worked in groups could produce a reasonable model of what effective collaboration entails, but that model would be generic and abstract. Most people would agree that ef-fective collaboration involves maki ng sure that all group members have the opportunity to contribute their expertise, but what can group members actually do to achieve this? Should they set aside an equal amount air time in meetings for each member? Should a leader or facilitator be given the responsibility to poll all mem-bers? How do the kind of task being performed and its progress in time affect the ways in which people should contribute? Guiding students to consider how their groups should respond to these types of questions will deve lop the skills to adapt their col-laborative techniques according to the demands of the situation. In a learning team, students can be taught lists or models of effec-tive collaboration behaviors, but they must learn to apply these behaviors concretely in a given situation. They must learn to judge, for example, when a critical comment would be construc-tive, whether a joke would be di stracting or a welcome tension reliever, or when keeping silent is more of a contribution than talking. Feedback about convers ational behavior, may increase awareness of the team process and as such serve as a tool for training collaborative skills in learning groups. The SYMLOG framework (SYstematic Multiple Level Observa-tion of Groups) [1] is commonly used to analyze group dynamics on three dimensions: dominance/ submissiveness (also labeled participation level ), individual/group orientation ( friendliness ), and task focus/socioemotional expressiveness ( task focus ). SYM-LOG proposes that members of a group influence and are influ-enced by their behaviors on these dimensions. Using SYMLOG to provide team feedback in com puter-mediated settings was shown to increase socioemotional behaviors, suggesting that feedback increases self-focus mediated by collaborative technology [7]. We used SYMLOG to collect peer feedback, asking group mem-bers to rate each other along these three dimensions. Peer evalua-tions are often used to provide feedback because unlike teachers, peers observe each other throughout the process and often have detailed knowledge of each others  X  contributions. Further, [3] found peer feedback to be superior in the quality of its results to expert-based feedback in learning environments. Peer feedback has been shown to motivate teams to alter their communication style, such as focusing more on the task at hand and using fewer words that were correlated with disliked collaborative moves [10]. However, peer feedback can be costly. Some students may be reluctant to give or receive feedback from other students, while attending to feedback during a task might be distracting. Auto-matic analysis of behavior is another approach for measuring collaborative practices. Latent Semantic Analysis (LSA) on team discourses was shown to be valuab le in predicting team perform-ance and could be used for providing real-time feedback [5]. Fur-ther, visualizing turn-taking pa tterns and participation levels based on audio input stimulates reflection [6], causing dominant contributors to become aware of their behavior [4]. Most existing research on automatic analysis of conversation focuses on high-level phenomena such as turn-taking and per-formance. In contrast, we propose using linguistic analysis tools to uncover more subtle features of conversational style that corre-spond to collaborative behaviors. We use Linguistic Inquiry and Word Count (LIWC) [8], a dictionary-based tool for analyzing language features. LIWC counts what percentage of words in a block of text occurs in various content categories such as emotion words, self-references, and assent s. These LIWC indicators can be seen as measures of conversation style. Fo r example, one could use LIWC to characterize people as self-directed versus other-directed by comparing how often they use self-references versus second-and third-person pronouns. Note that we envision LIWC-based analyses as a simple first step in linguistic analysis. Much more complex analyses of language (e.g., syntactic and pragmatic levels) can be implemented in the future. To guide reflection on group processe s, a system that uses feed-back on conversation style must at a minimum be able to identify linguistic features that correspond to effective teamwork and pro-vide useful feedback that impr oves conversation style. Figure 1 presents an overview of an experimental feasibility study that focuses on these two questions: RQ1 . What elements of communication style predict peer evalua-tions on the SYMLOG dimensions? RQ2 . How does feedback affect subsequent collaboration prac-tices, as indicated by communication style? Participants. One-hundred and four undergraduate students (62 females, 42 males) in a large northeastern university volunteered to participate in the experiment for course credit and for a chance to win $40. Participants were randomly assigned to mixed-gender 4-person groups in one of two conditions: Feedback (FB , 13 groups ) or No Feedback (no-FB , 13 groups ) . Procedure. Upon arrival, participants were seated at isolated computer workstations. Participants were informed that they would be working as a team on a decision making task and that their part is very important for the team X  X  success. The instruc-tions included a description of the three SYMLOG dimensions and behavioral propositions associated with effective teamwork on these dimensions. Groups used an iChat chatroom to complete the group task. In the task, Lost-on-the-Moon , teams need to reach a decision with re-spect to the ranking of 15 items necessary for the survival as a team of astronauts on the moon. We chose not to reveal group members X  actual names (to reduce potential gender biases); mem-bers were identified by a color: Blue, Red, Green, or Yellow. An experimenter monitored the group X  X  progress. When the group completed ranking seven items out of 15, they were prompted to pause the conversation and fill out an evaluation questionnaire. FB groups completed peer evaluations that consisted of three 7-point scales corresponding to the three SYMLOG dimensions along with open-ended responses to explain each rating they pro-vided. no-FB groups evaluated the chat user interface as a filler task. Once all group members completed the questionnaire, they continued the group task. The experimenter tallied the ratings and sent FB groups a summary. The summary was an image with three bar graphs showing the group members X  average ratings and reiterated the behavioral propositions from the initial instructions. Upon completion of the task, all participants filled out post-session peer evaluations identical to those completed by the FB groups earlier. Participants were then debriefed and thanked for their participation. The whole session lasted about 50 minutes. We divided each transcript into two segments, as shown in Figure 1. Segment 1 and segment 2 co rrespond to the conversation be-fore and after the intervention, respectively. We used LIWC to analyze language use in each segment both at the individual and at the group level. For individuals, we extracted their contribution to the conversation and used that as input to LIWC, generating a list of linguistic features and the pe rcentage of the text that corre-sponds to each feature. For groups , we submitted the entire tran-script of the conversation to LIWC, less communication to and from the experimenter. The group measurements ar e effectively an average of each individual X  X  c onversational style, weighted by the amount each individual contributed overall to the group. 
Table 1. Estimates of parameter coefficients in hierarchical linear models using lin guistic measures as covariates and peer ratings on SYMLOG dimensions as predicted variables. Each value represents the coefficient parameter estimate on a single predictor model. (Significance: *p&lt;0.1, **p&lt;0.05, ***p&lt;0.001). Our first research question was  X  X hat elements of communica-tion style predict peer evaluations on the SYMLOG dimensions? X  To address this question, we ex amined the relationship between individuals X  LIWC results in segment 2 and peer evaluations pro-vided at the end of the session. We created a number of hierarchi-cal linear models using data from all participants, with individual nested within group, and group nested within feedback condition, to control for non-independence w ithin groups. Each model used one LIWC indicator to predict the rating of one SYMLOG dimen-sion X  X hat is, does this indicator of language use correspond to higher or lower ratings? Because this is an exploratory study of the effect of language use, we examined 25 LIWC indicators. Table 1 presents a summary of the linguistic factors that were significant predictors of peer ratings. Participants X  word production was positively related to peer evaluations of group participation and task focus. Using achieve-ment words (e.g., best , goal ) and inclusive words (e.g., also , plus ) was also positively related to peer evaluations of participation and task focus. Conversely, using a ffect-laden words, particularly related to positive emotion, was ne gatively related to participation and task focus evaluations. The use of assents (e.g., yes, agree ) was also negatively related to all three evaluation dimensions. The open-ended responses in which group members explained their ratings provide insight into why team members with various language styles were rated as be tter or worse collaborators. Those who received high ratings on participation were evaluated as  X  X c-tive X ,  X  X eader X , and  X  X eeps us on track X , while those with lower ratings were evaluated as  X  X idn X  X  talk much X ,  X  X assive X , and  X  X nly responds when necessary X . Those with high ratings on task focus were evaluated as  X  X rganizes things X  and  X  X elped the group come to decisions X , while those with low ratings were evaluated as  X  X umorous X  and  X  X akes jokes X . Finally, low evaluations were also followed by comments such as  X  X eemed just to go with the flow and agree with what everybody else was saying X  and  X  X idn X  X  seem to have many insights X . The open-ended responses help explain the positive relationship between peer evaluations and word count, achievement words, and inclusive words: 1) people may interpret verbosity as contri-bution, 2) being inclusive may be interpreted as suggestive and detailed, and 3) discussing achie vement may be interpreted as being interested in the team's success. Alternatively, frequently using agreement terms may have b een perceived as passivity (i.e. passively agreeing without active contribution). Using affect terms, especially positive emotion, may have been interpreted as straying off the task at hand. Our second research question wa s  X  X ow does feedback affect subsequent collaboration practi ces, as indicated by communica-tion style? X  To answer this question, we examined whether the feedback intervention resulted in linguistic style change from segment 1 to segment 2 (RQ2, see Figure 1), comparing changes in LIWC results at the group le vel between the two conditions. Figure 2 shows three LIWC indicators where the FB and no-FB conditions differed. While FB groups did not differ from no-FB groups in segment 1 on the use of total first person pronouns ( I , me , we , us ), cognitive process terms ( cause , know , think , should ), and assents ( ok , agree , yes ), in segment 2 FB groups use signifi-cantly more first person pronouns, more cognitive process terms, and less assents. As demonstrated in Figure 2, these differences between FB and no-FB groups resulted from the FB groups not changing their communicative behavior from segment 1 to seg-ment 2, whereas the no-FB groups decreased their self pronoun use and cognitive process terms, and increased the use of assents. We argue that the pattern of change observed in the no-FB condi-tion reflects the natural communication course for this task with-out a feedback intervention. Toward the end of the session team members sought consensus, leading to fewer self pronouns and cognitive process terms and more a ssents (less  X  X  think X  and more  X  X eah, yeah, yeah X ). It appears that the feedback intervention helped groups stay on track and k eep the teamwork going with the same cognitive effort and involvement as in the first part of the conversation. This finding is also aligned with [7], suggesting that feedback increases self-focus comp ared to no feedback in a tech-nology-mediated environment. Note that the no-FB groups talked just as much as the FB groups in segment 2 (FB: mean=506.9, SD=385.4; no-FB: mean=558.1, SD =269.1; t(24)=-.393, p=.698). This shows that conversation styl e can change while word count remains the same and supports the idea of using more sophisti-cated language analysis tools to understand group dynamics. Our results are encouraging for the idea of developing systems that help people reflect on group pr ocesses. However, a number of questions remain:  X  Can feedback affect task performance? In the study, it did  X  Will giving and attending to feedback be distracting? Based  X  What are effective ways to dis till linguistic feedback into in- X  How should feedback be visualized? Should it emphasize in-Inspired by the feedback concepts and questions laid out above and the results from this feasibility study, we developed Group-Meter, a system designed to help groups reflect on their collabora-tion practices and support research into how language, feedback, and practices interact. A server runs under Apache Tomcat, sup-porting chat sessions, collecting conversational data and peer ratings, performing linguistic anal ysis on collected conversations, aggregating peer ratings, and providing access to the collected information about ratings and language behavior. Figure 3 pre-sents the GroupMeter interface. The user interface runs in a web browser and presents a synchronous chat client (main portion), augmented with features for co llecting peer ratings (right) and presenting visualizations of group behavior based on the peer ratings and linguistic analyses (bottom). We chose synchronous chat partly because it resembles instant messaging, a tool commonly used by college students, and partly because it facilitates the collection and analysis of linguistic data. We plan to leverage what we l earn through this initial version of GroupMeter as an educational tool to support group reflection in an array of collaboration media used in team learning environ-ments, including asynchronous interaction in blogs and wiki dis-cussions; and using voice recognition to support group reflection in face-to-face meetings, audio-and video-conferencing. In the experiment we demonstrated peer feedback effects on communicative style and the potential of automated linguistic analysis to measure teamwork behaviors. We then incorporated linguistic analysis into the GroupM eter system, suggesting that it can guide reflection on collaborative practices in addition to peer feedback procedures. Our next steps are to run user studies to evaluate the extent to which GroupM eter fulfills this promise, and to develop a theoretical framework that elucidates the linkages we discovered between collaboration ratings and linguistic style. We plan to deploy GroupMeter in classroom environments, where students work on group projects throughout the semester. We will examine changes not only in collaborative practices, but also in the reflective process students unde rgo, project quality and learn-ing outcomes. By this we hope to foster more educational, reflec-tive, and enjoyable teamwork learning environments. [1] Bales, R.F., &amp; Cohen, S.P. (1979). SYMLOG: A system for [2] Bransford, J. (2000). How people learn: Brain, mind, experi-[3] Cho, K., Chung, R., King, W., &amp; Schunn, C.D. (in press). [4] DiMicco, J.M., Pandolfo, A., &amp; Bender, W. (2004). Influenc-[5] Foltz, P.W., &amp; Martin, M.J. (2004). Automated team dis-[6] Karahalios, K.G., &amp; Bergstrom, T. (2006). Visualizing audio [7] Losada M., S X nchez, P., Nobl e, E.E. (1990). Collaborative [8] Pennebaker, J.W., Francis, M.E., &amp; Booth, R.J. (2001). Lin-[9] Roberts, T.S. (2005). Computer-Supported Collaborative [10] Turner, B., &amp; Schober, M.F (2007). Feedback on collabora-
