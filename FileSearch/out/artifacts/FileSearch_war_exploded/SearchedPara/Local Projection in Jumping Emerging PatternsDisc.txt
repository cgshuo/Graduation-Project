 Pattern mining is one of key tasks in contemporary knowledge discovery. Al-though recent years have brought a wide spectrum of pattern types, discovery algorithms still follow common strategies such as Apriori, operations on concise representations ([1]), pattern trees ([2]). Regardless of a particular method, pro-cessing may involve exponentially large item set collections, which makes overall feasibility very sensitive to input data. Therefore, in our opinion, it is crucial to study, how to approach datasets of certain characteristics.

Here, we look at the problem of finding jumping emerging patterns (JEPs) in classified transaction databases. A JEP refers to an itemset that is supported in one class and absent from others. This highly discriminative idea was introduced in [3], and, since then, it has been successfully applied to business and gene expression problems. Because all JEPs constitute a convex space, the task is often perceived as finding minimal patterns. In fact, these patterns have found valuable applications to classification and clustering ([3]).

Among known algorithms, JEP-Producer ([1]) is believed to be the most ef-ficient solution for finding a complete space of JEPs. It operates on concise representation of convex co llections and employs a border differentiation opera-tion to obtain a result set. In our previous works ([4]), it has been demonstrated that reducts from the rough set theory ([5]) are closely related to JEPs. Algo-rithms based on these relations appeared s uperior in experimen ts for relational data ([6]). Moreover, even if data is originally given in a transactional form, a condensed decision table can be efficiently obtained by finding an approximate graph coloring in an item-conflict graph ([7]).

Following successful results for dense, originally relational data, we decided to examine opportunities for reduct-based methods against a popular class of sparse transaction databases. Note that, for large datasets, table condensation may likely deal with adverse item distribution in transactions, which results in low dimensionality reduction and inefficient discovery. The method of local projection that is put forward in this paper ascertains average dimensionality to depend only on average transaction length, not on item distribution in a database. The problem is decomposed int o a series of per transaction local reduct computations in a locally projected decision table. For each subproblem only objects and attributes substantial for reduct induction are taken into account, which significantly improves overall effi ciency. In addition, we propose several optimization to decrease a construction overhead of discernibility matrices.
Our experiments covered efficiency com parison between JEP-Producer, table condensation and local projection with different reduct computation methods. Approaches were tested against originally relational and sparse datasets. Since actual performance depends strongly on im plementation, different structures to represent an attribute/ item set were tested.

Section 2 provides fundamentals of emerging patterns and border representa-tion.InSect.3,wepresentbasicelement s of the rough set theory. Local projec-tion is introduced and proved correct in Sect. 4. In Sect. 5 the novel algorithm is described. It also discusses optimizations for discernibility matrix computation and impact of different implementatio ns of main structures. Section 6 covers testing procedure and experimental resu lts. The paper is concluded in Sect. 7. Let a transaction system be a pair ( D , I ), where D is a finite sequence of trans-actions ( T 1 , .., T n ) (database) such as T i  X  X  for i =1 , .., n and I is a non-empty set of items (itemspa ce). The support of an itemset X  X  X  in a sequence
Let a decision transaction system be a tuple ( D , I , I d ), where ( D , I X  X  d )is a transaction system and  X  T  X  X  | T  X  X  d | =1.Elementsof I and I d are called condition and decision items, respectively. Support in a decision transaction system ( D , I , I d ) is understood as support in the transaction system ( D , I X  X  d ).
For each decision item c  X  X  d , we define a decision class sequence C c = ( T tions C c and C { c } are used interchangeably. Note that each of the transactions from D belongs to exactly one class sequence. In addition, for a database D = ( T
Given two databases D 1 ,D 2  X  X  , in particular decision classes, we define a jumping emerging pattern (JEP) from D 1 to D 2 as an itemset X  X  X  such as supp D 1 ( X )=0and supp D 2 ( X ) &gt; 0. A set of all JEPs from D 1 to D 2 is called a JEP space and denoted by JEP ( D 1 ,D 2 ).

JEP spaces can be descr ibed concisely by borders ([1]). For c  X  I d ,weusea border &lt; L c , R c &gt; to uniquely represent a JEP space JEP ( C c ,C c ). Members of the left bounds are minimal JEPs, whereas member of the right bounds are maximal JEPs, i.e. distinguishable transactions.

The problem of JEP discovery can be defined as computing { &lt; L c , R c &gt; } c  X  I d for a decision transaction system ( D , I , I d ). Since finding of right bounds is trivial ([1]) and not interesting from a practical point of view, we focus on the collection of left bounds {L c } c  X  I d . Letadecisiontablebeatriple( U , C ,d ), where U (universum) is a non-empty, finite set of objects, C is a non-empty finite set of condition attributes and d is a decision attribute. A set of all attributes is denoted by A = C X  X  d } .The domain of an attribute a  X  X  is denoted by V a and its value for an object u  X  X  is denoted by a(u). In particular, V d = { c 1 , .., c | V induces a partition of U into decision classes { U c } c  X  V d . Hereinafter, we use the term attribute to denote a condition attribute.

Consider B  X  X  . An indiscernibility relation IND ( B ) is defined as IND ( B )= { ( u, v )  X  X  X U :  X  a  X  B a ( u )= a ( v ) } .Since IND ( B ) is an equivalence relation it induces a partition of U denoted by U /IN D ( B ). Let B ( u ) be a block of the partition containing u  X  X  .A B -lower approximation of a set X  X  X  is defined as follows: B  X  ( X )= { u  X  X | B ( u )  X  X } and a B -positive region with respect to a decision attribute d is defined as POS ( B, d )= X  X  X  /IND ( { d } ) B  X  ( X ).
A local reduct for an object u  X  X  is a minimal attribute set B  X  X  such be differentiated by means of B from all objects from other classes as well as using C . The set of all local reducts for an object u is denoted by REDLOC ( u, d ). In order to apply the rough set framework to transactional data, transformation to a respective relational form is requi red. We consider two representations: a binary decision table, which already found an application to negative pattern discovery ([4]), and a loca lly projected form -introduced in this paper for efficient finding of positive patterns.

Hereinafter, we assume that our input data is represented by a decision I
A binary decision table for a decision transaction system D TS is a decision { c 1 , .., c p
Local reducts in a binary decision table correspond to jumping emerging pat-terns with negation (JEPNs, [4]). JEPNs constitute a convex space that contains JEPs for the same transaction system. Note that, although { e, g } and { d, f } are both local reducts for u 1 , the pattern eg is a minimal JEP, whereas df is not, since it is not supported by the respective transaction.

Solving a problem of a double dimensionality and filtering positive patterns is most often expensive, thus, the idea of a table condensation was proposed ([7]). Before local reduct computation, binary attributes are aggregated into multi-valued attributes by means of an approximate graph coloring. This approach is efficient for originally relational datasets, however, remains sensitive to a distri-bution of items in transactions.

The table condensation leads to an alternative representation of a decision transaction system. However, one may get much higher complexity reduction if transformation is performed independently for every transaction. The following structure demonstrates how we may lim it our interest only to items that are indispensable to compute complete discernibility information for a transaction.
A locally projected decision table for: DT S , a decision transaction system, and T i  X  X  ,where i =1 , .., |D| , a transaction, is a binary decision table
Hardness of an input decision system DT S can be characterized by average (maximal) dimensionality of subproblems, i.e. a locally projected decision table for distinguishable transactions, namely avgDim ( DT S )= {| T | : T  X  X  c  X  c  X  I } / transactions are distinguishable, these parameters refer to an average (maximal) transaction length DT S .

For the sake of convenience, we use the notation: itemP att DT S,T i ( u, B )= {
I LP DT D TS,T i =( U , C i ,d ) is a locally projected deci sion table and a transac-Whenever a decision transaction syste m is known from the context, the respec-tive subscript is omitted.

The following theorem states that the complete JEP space for the DT S and a given class can be obtained by finding a locally projected tables for each distinguishable transaction and generating patterns for the respective objects and any attribute set in the respective table.
 Theorem 1.  X  u  X  POS ( C The respective left bound of a JEP space can be found by applying local reducts for a given object instead of any attribute sets.
 Theorem 2.  X  u  X  POS ( C The proofs are omitted here due to space limitations. Minimal jumping emerging patterns in D TS =( D , I , I d ) can be computed by local reduct computation in locally condensed tables for all transactions. The actual procedure is straightforward and fully based on Theorem 2.
Identification of minimal patterns by means of local reduct induction is the most complex part of our approach. It is normally addressed with methods used for global reducts ([5]). Unfortunately, all known exact solutions are pessimisti-cally exponential.

Here, we look at two algorithms that employ a discernibility matrix. The first one reduces the problem to finding prime implicants of a monotonous boolean functions ([5], RedPrime). It loops over elements of a matrix and extends a collection of reducts for rows seen so far, so that they are sufficient to discern the current row as well. The second algorithm traverses a lattice of all subsets of an attribute space using the apriori scheme ([8], RedApriori). Successive collections of candidates are pruned basing on a degree of attribute set dependence, which is calculated by means of a discernibility matrix. Also, in order to optimize this stage, one may eliminate transactions that are not maximal JEPs and group transactions by their classes. Experiments focused on efficiency of th e new algorithm, table condensation and JEP-Producer for synthetically generated sparse data and dense data obtained from relational tables. Each result was averaged over several executions.
The testing environment and algorithms were coded in Java 5. Since the rough set methods and JEP-Producer differ significantly, it is not possible to come up with one single dominant operation for time complexity representation. There-fore, in order to provide reliable time measurements, we based their implemen-tations on mostly the same structures. In particular, all the studied approaches process large collections of attribute/item sets. To obtain results possibly in-dependent from what a data structure was used to represent such a set, three implementations were tested. The first t wo are characteris tic vectors of an at-tributes/item space, one based on a regular byte array (Array) and the other one -on java.util.BitSet (BitSet). The third structure is a balanced binary tree implemented by means of java.util.TreeSet (TreeSet). Array is generous in mem-ory allocation, but assures the most efficient access. Bit and dynamic structures are slower, however, they may take preced ence for large attr ibute/item spaces when a high number of sets is created.
 Sparse Data. In this test local projection and JEP-Producer are compared for sparse datasets. Since itemspaces are commonly much larger than average trans-action size, this kind of data is substantial for practical tasks. Unfortunately, it is hard to find publicly available classified sparse datasets, thus, the test was per-formed against synthetic data. Transaction databases were produced by means of the IBM generator ([9]) and, then, the CLUTO package was used to classify transactions (Tab. 1). The density of each database was set up at 5-15% of a respective item space. We studied behavior of the algorithms when a size of a database or an item space increases. In order to describe the actual hardness of each problem, additional measures were provided, in particular, a total number of JEPs over all classes, number of maximal transactions and average (maximal) dimensionality.

The local projection algorithm was tested with two different reduct compu-tation methods: RedPrime ([5]) and RedApriori ([8]). JEP-Producer was imple-mented according to the scheme and optimizations described in [1]. To optimize all computations a database is always reduced to contain only maximal trans-actions. Measurements for all the algorithms were taken for the aforementioned implementations of an attribute/item set.

Table 2 shows that the rough set approach outperforms JEP-Producer. In par-ticular, for RedApriori and Array, there is a difference of 1-2 orders of magnitude. In general, all the methods perform well for Array. Reduct computations are performed for locally projected tables wi th small attribute spaces, thus, slower structures significa ntly affect the overall performance. For example, for TreeSet, efficiency of RedPrime and JEP-Producer remain very close. On the other hand, JEP-Producer is sensitive to the size of a w hole item space, therefore, BitSet led to slightly better results in almost all the cases.
 Originally Relational Data. Earlier tests demonstrated that, for dense, orig-inally relational datasets, condensation successfully reduces dimensionality and performs better that JEP-Producer ([6]). Here, it is contrasted with local projec-tion. Due to space limitations, results for RedPrime and Array-based attribute set implementation are presented. Tran sactional databases for this test were generated from relational tables from UCI Repository. Average time and dimen-sionality is given for each of the methods.

According to the results in Tab. 3, table condensation and local projection lead most often to the same subproblem dimensionality. Since databases are reduced in an analogical way, both methods achieve similar efficiency. Nevertheless, the former strongly relies on optimality of graph coloring solution. An overhead of generation and filtering of additional patterns is visible for mushroom . In this paper we have proposed a rough set approach to discovery of jumping emerging patterns (JEPs) in classified transaction databases. The problem is decomposed into a series of local reduct computations performed for locally projected decision tables for each transaction.

Main benefit of our approach is that onl y the transactions and items neces-sary for each computation are considered, which results in potentially significant dimensionality reduction of subproblems. In this case, additional processing can be a significant factor. The way of discernibility matrices construction can be optimized by caching of partial per-attribute results in complementary form.
Experiments have proved that the method outperforms JEP-Producer, the most popular solution for the considered problem, for sparse, synthetically gen-erated datasets. The high efficiency is a r esult of a dramatic decrease in average dimensionality. This fact was observed independently from a reduct computation method. Nevertheless, the algorithm based on attribute set dependence behaves much better than the classical one searching for prime implicants and is faster than JEP-Producer by 1-2 orders of magnitude. On the other hand, for dense, originally relational data the new approach achieves at least the same dimen-sionality gain as the previously proposed method of table condensation and gives similar overall efficiency.

The future research will extend our method to look for derivative types of patterns and confront its efficiency with existing tree-based strategies.
