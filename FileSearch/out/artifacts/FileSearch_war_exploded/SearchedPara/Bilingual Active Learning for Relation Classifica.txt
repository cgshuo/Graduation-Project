 Semantic relation extraction between named en-tities ( aka . entity relation extraction or more con-cisely relation extraction) is an important subtask of Information Extraction (IE) as well as Natural Language Processing (NLP). With its aim to identify and classify the semantic relationship between two entities (ACE 2002-2007), relation extraction is of great significance to many NLP applications, such as question answering, infor-mation fusion, social network construction, and knowledge mining and population etc. relation extraction adopts statistical machine learning methods, which can be grouped into supervised learning (Zelenko et al., 2003; Culotta and Soresen, 2004; Zhou et al., 2005; Zhang et al., 2006; Qian et al., 2008; Chan and Roth, 2011), semi-supervised learning (Zhang et al., 2004; Chen et al., 2006; Zhou et al., 2008; Qian et al., 2010) and unsupervised learning (Hase-gawa et al., 2004; Zhang et al., 2005) in terms of the amount of labeled training data they need. Usually the extraction performance depends heavily on the quality and quantity of the labeled data, however, the manual annotation of a large-scale corpus is labor-intensive and time-consuming. In the last decade researchers have turned to another effective learning paradigm--active learning (AL), which, given a small num-ber of labeled instances and a large number of unlabeled instances, selects the most informative unlabeled instances to be manually annotated and add them into the training data in an iterative fashion. Essentially active learning attempts to decrease the quantity of labeled instances by en-hancing their quality, gauged by their informa-tiveness to the learner. Since its emergence, ac-tive learning has been successfully applied to many tasks in NLP (Engelson and Dagan, 1996; Hwa, 2004; Tomanek et al., 2007; Settles and Craven, 2008). this paper, that active learning can also alleviate the annotation burden for relation extraction in one language while retaining the extraction per-formance. However, there are cases when we may exploit relation extraction in multiple lan-guages and there are corpora with relation in-stances annotated for more than one language, such as the ACE RDC 2005 English and Chinese corpora. Hu et al. (2013) shows that supervised relation extraction in one language (e.g. Chinese) can be enhanced by relation instances translated from another language (e.g. English). This dem-onstrates that there is some complementariness between relation instances in two languages, par-ticularly when the training data is scarce. One natural question is: Can this characteristic be made full use of so that active learning can maximally benefit relation extraction in two lan-guages? To the best of our knowledge, so far the issue of joint active learning in two languages has yet been addressed. Moreover, the success of joint bilingual learning may lend itself to many inherent multilingual NLP tasks such as POS tagging (Yarowsky and Ngai, 2001), name entity recognition (Yarowsky et al., 2001), sentiment analysis (Wan, 2009), and semantic role labeling (Sebastian and Lapata, 2009) etc. ing (BAL) paradigm to relation classification with a small number of la beled relation instances and a large number of unlabeled instances in two languages (non-parallel). Instead of using a par-allel corpus which should have entity/relation alignment information and is thus difficult to obtain, this paper employs an off-the-shelf ma-chine translator to translate both labeled and unlabeled instances from one language into the other language, forming pseudo parallel corpora. These translated instances along with the original instances are then fed into a bilingual active learning engine. Findings obtained from experi-ments with relation classification on the ACE 2005 corpora show that this kind of pseudo-parallel corpora can significantly improve the classification performance for both languages in a BAL framework. Section 2 reviews the previous work on relation extraction while Section 3 describes our baseline systems. Section 4 elaborates on the bilingual active learning paradigm and Section 5 discusses the experimental results. Finally conclusions and directions for future work are presented in Sec-tion 6. While there are many studies in monolingual relation extraction, there are only a few on multi-lingual relation extraction in the literature. range of studies on relation extraction focus on monolingual resources. As far as representation of relation instances is concerned, there are fea-ture-based methods (Zhao et al., 2004; Zhou et al., 2005; Chan and Roth, 2011) and kernel-based methods (Zelenko et al., 2003; Zhang et al., 2006; Qian et al., 2008), mainly for the English language. Both methods are also widely used in relation extraction in other languages, such as those in Chinese relation extraction (Che et al., 2005; Li et al., 2008; Yu et al., 2010). only two studies related to multilingual relation extraction. Kim et al. (2010) propose a cross-lingual annotation projection approach which uses parallel corpora to acquire a relation detec-tor on the target language. However, the map-ping of two entities involved in a relation in-stance may leads to errors. Therefore, Kim and Lee (2012) further employ a graph-based semi-supervised learning method, namely Label Propagation (LP), to indir ectly propagate labels from the source language to the target language in an iterative fashion. Both studies transfer rela-tion annotations via parallel corpora from the resource-rich language (English) to the resource-poor language (Korean), but not vice versa. Based on a small number of labeled instances and a large number of unlabeled instances in both languages, our method differs from theirs in that we adopt a bilingual active learning para-digm via machine translation and improve the performance for both languages simultaneously. has become an active research topic due to its potential to significantly reduce the amount of labeled training data while achieving comparable performance with supervised learning. It has been successfully applied to many NLP applica-tions, such as POS tagging (Engelson and Dagan, 1996; Ringger et al., 2007), word sense disam-biguation (Chan and Ng, 2007; Zhu and Hovy, 2007), sentiment detection (Brew et al., 2010; Li et al., 2012), syntactical parsing (Hwa, 2004; Osborne and Baldridge, 2004), and named entity recognition (Shen et al., 2004; Tomanek et al., 2007; Tomanek and Hahn, 2009) etc. task, Reichart et al. (2008) introduce a multi-task active learning (MTAL) paradigm, where unla-beled instances are selected for two annotation tasks (i.e. named entity and syntactic parse tree). They demonstrate that MTAL in the same lan-guage outperforms one-sid ed and random selec-tion AL. From a different perspective, we pro-pose an active learning framework for the same task, but across two different languages. 
Another related study (Haffari and Sarkar, 2009) deals with active learning for multilingual machine translation, which make use of multilin-gual corpora to decrease human annotation ef-forts by selecting highly informative sentences for a newly added language in multilingual paral-lel corpora. While machine translation inherently deals with multilingual parallel corpora, our task focuses on relation extraction by pseudo parallel corpora in two languages. This section first introduces the fundamental su-pervised learning method, and then describes a baseline active learning algorithm. 3.1 Supervised Learning We adopt the feature-based method for funda-mental supervised relation classification, rather than the tree kernel-based method, since active learning needs a large number of iterations and the kernel-based method usually performs much slower than the feature-based one. Following is a list of our used features, much similar to Zhou et al. (2005): a) Lexical features of entities and their contexts b) Entity type c) Mention level d) Overlap M1&gt;M2 or M1&lt;M2: flag indicating whether M2/M1 is included in M1/M2. 3.2 Active Learning Algorithm We use a pool-based active learning procedure with uncertainty sampling (Scheffer et al., 2001; Culotta and McCallum, 2005; Kim et al., 2006) for both Chinese and English relation classifica-tion as illustrated in Fig. 1. During iterations a batch of unlabeled instances are chosen in terms of their informativeness to the current classifier, labeled by an oracle and in turn added into the labeled data to retrain the classifier. Due to our focus on the effectiveness of bilingual active learning on relation classification, we only use uncertainty sampling without incorporating more complex measures, such as diversity and repre-sentativeness (Settles and Craven, 2008), and leave them for future work. Figure 1. Pool-based active learning with uncer-tainty sampling can output probabilities assigned to the class la-bels on an instance, we have three uncertainty metrics readily available, i.e., least confidence ( LC ), margin ( M ) and entropy ( E ). The NER experimental results on multiple corpora (Settles and Craven, 2008) show that there is no single clear winner among these three metrics. This conclusion is also validat ed by our preliminary experiments on the task of active learning rela-tion extraction, thus we adopt the LC metric for simplicity. Specifically, with a sequence of K probabilities for a relation instance at some itera-tion, denoted as { p 1 , p 2 ,... p K } in the descending order, the LC metric of the relation instance can be simply picked as the first one, i.e. classes. Note that this metric actually reflects prediction reliability (i.e. reverse uncertainty) rather than uncertainty in order to facilitate joint confidence calculation for two languages (cf.  X 4.4). Intuitively, the smaller the H LC is, the less confident the prediction is. In this section, we elaborate on the bilingual ac-tive learning for relation extraction. 4.1 Problem Definition With Chinese and English (designated as c and e ) as two languages used in our study, this paper intends to address the task of bilingual relation classification, i.e., assigning relation labels to candidate instances that have semantic relation-ships. Suppose we have a small number of la-beled instances in both languages, denoted as L c and L e (non-parallel) respectively, and a large number of unlabeled instances in both languages, denoted as U c and U e (non-parallel). The test in-stances in both languages are represented as T c and T e . In order to take full advantage of bilin-gual resources, we translate both labeled and unlabeled instances in one language to ones in the other language as follows: both languages, denoted as SVM c and SVM e re-spectively, in a BAL fashion to improve their classification performance. 4.2 Bilingual Active Learning Framework Currently, AL is widely used in NLP tasks in a single language, i.e., during iterations unlabeled instances least confident only in one language are picked and manually labeled to augment the training data. The only exception is AL for ma-chine translation (Haffari et al., 2009; Haffari and Sarkar, 2009), whose purpose is to select the most informative sentences in the source lan-guage to be manually translated into the target language. Previous studies (Reichart et al., 2008; Haffari and Sarkar, 2009) show that multi-task active learning (MTAL) can yield promising overall results, no matter whether they are two different tasks or the task of machine translation on multiple language pairs. If a specific NLP task on two languages, such as relation classifi-cation, can be regarded as two tasks, it is reason-able to argue that these two tasks can benefit each other when jointly performed in the BAL framework. Yet, to our knowledge, this issue remains unexplored. how to obtain two language views for relation instances from multilingual resources. There are three solutions to this problem, i.e. parallel cor-pora (Lu et al., 2011), translated corpora ( aka . pseudo parallel corpora) (Wan 2009), and bilin-gual lexicons (Oh et al., 2009). We adopt the one with pseudo parallel corpora, using the machine translation method to generate instances from one language to the other in the BAL paradigm, as depicted in Fig. 2. Figure 2. Framework of bilingual active learning corpora, translated labeled and unlabeled in-stances are augmented in the following two ways: z For labeled Chinese instances ( L c ) and Eng-z For unlabeled Chinese instances ( U c ) and 4.3 Instance Projection via MT Among the several off-the-shelf machine transla-tion services, we select the Google Translator 1 because of its high quality and easy accessibility. Both the mentions of relation instances and the mentions of two involved entities are first trans-lated into the other language via machine transla-tion. Then, two entities in the original instance are aligned with their counterparts in the trans-lated instance in order to form an aligned bilin-gual relation instance pair. Instance translation All the positive instances in the ACE 2005 Chi-nese and English corpora are translated to an-other language respectively, i.e. Chinese to Eng-lish and vice versa. The relation instance is rep-resented as the word sequence between two enti-ties. This word sequence, rather than the whole sentence, is then translated to another language by the Google Translator. The reason is that, al-though this sequence loses partial contextual in-formation of the relation instance, its translation quality is supposed to be better. Our preliminary experiments indicate that the addition of contex-tual information fail to benefit the task. After translation, word segmentation is performed on Chinese instances translated from English while tokenization is needed for translated English in-stances. Entity alignment The objective of entity alignment is to build a mapping from the entities in the original in-stances to the entities in th e translated instances. Put in another way, entity alignment automati-cally marks the entity mentions in the translated instance, thereby the feature vector correspond-ing to the translated instance can be constructed. Entity alignment is vital in cross-language rela-tion extraction whose difficulty lies in the fact that the same entity mention as an isolated phrase and as an integral phrase in the relation instance can be translated to different phrases. For exam-ple, the Chinese entity mention  X   X  X  X   X  ( officer ) is translated to  X  X fficer X  in isolation, it is, how-ever, translated to  X  X ffici als X  when in the relation instance  X   X  X  X  X   X  X  X   X  ( Syrian officials ). Figure 3. Entity alignment algorithm entity mentions between Chinese and English. The basic idea is that the word sequence in one mention successively matches the word sequence in the other mention. Take entity alignment from English to Chinese as an example, given entity mention M e in relation instance R e in English and their respective translations M ct and R c in Chi-nese, the objective of entity alignment is to find M c , the counterpart of M e in R c . The procedure of entity alignment algorithm can be described in Fig. 3. empirically set to 0.002 where the precision and recall of entity alignment are balanced. Our lexi-con is derived from the FBIS parallel corpus (#LDC2003E14), which is widely used in ma-chine translation between English and Chinese. It should be noted that the process of relation trans-lation and entity alignment are far from perfec-tion, leading to reduction in the number of in-stances being mapping to the other language, i.e. 4.4 Bilingual Active Learning Algorithm The basic idea of our BAL paradigm is that, while unlabeled instances uncertain in one lan-guage are informative to the learner in that lan-guage, unlabeled instances jointly uncertain in both languages are informative to the learners in both languages, thus potentially improving clas-sification performance for both languages more than their individual active learners do. This idea is embodied in the BAL algorithm in Fig. 4, where n is the batch size, i.e., the number of in-stances selected, labeled and augmented at each iteration. Figure 4. Bilingual active learning algorithm and Step 6, where unlabeled instances from U c and U e are selected and labeled respectively. Take Chinese for an example, when gauging the prediction uncertainty for an unlabeled instance in U c , not only its own uncertainty measure H c predicted by SVM c is considered, but also the uncertainty measure H et for its translation coun-terpart in U et , which is predicted by SVM e , is con-sidered. Generally, in order to jointly consider these two measures, there are three methods to compute their means, namely, arithmetic mean, geometric mean and harmonic mean. Preliminary experiments show that among these three means, there is no single winner, so we simply take the geometric mean defined as follows: the uncertainty score, when an instance in U c can X  X  find its translation counterpart in U et due to translation error or entity alignment failure, H et is set to 1, i.e. the maximum. Since the bigger H is, the more confident the prediction is, the less likely the instance will be chosen, in this way we discourage the unlabeled instances without trans-lation counterparts. We have systematically evaluated our BAL para-digm on the relation classification task using ACE RDC 2005 RDC Chinese and English cor-pora. 5.1 Experimental Settings Corpora and Preprocessing We use the ACE 2005 RDC Chinese and English corpora as the benchmark data (hereafter we re-fer to them as the Chinese corpus (ACE2005c) and the English corpus (ACE2005e) respec-tively). Both corpora have the same en-tity/relation hierarchies, which define 7 entity types, 6 major relation types. However, the Chi-nese corpus contains 633 documents and 9,147 positive relation instances while the English cor-pus only contains 498 files and 6,253 positive instances. Therefore, in order to balance the cor-pus scale to fairly evaluate bilingual active learn-ing impact on relation classification, we ran-domly select 458 Chinese files and thus get 6,268 positive instances, comparable to the Eng-lish corpus. sentence splitting and tokenization (word seg-mentation for Chinese using ICTCLAS 2 ). Then, positive relation mentions with word sequences between two entities and their feature vectors are extracted from sentences while negative relation mentions are simply discarded because we focus on the task of relation classification. After entity and relation mentions in one language are trans-lated into the other language using the Google translator, entity alignment is performed between relation mentions and their translations. Finally 4,747 Chinese relation mentions are successfully translated and aligned from English and vice versa, 4,936 English relation mentions are trans-lated and aligned from Chinese. our classifier since it supports multi-class classi-fication. The training parameters C (SVM) is set to 2.4 according to our previous work on relation extraction (Qian et al., 2010). Relation classifica-tion performance is evaluated using the standard Precision (P), Recall (R) and their harmonic av-erage (F1) as well as deficiency measure (cf. lat-ter in this section.). Overall performance scores are averaged over 10 runs. For each run, 1/40 and 1/5 randomly selected instances are used as the training and test set respectively while the remaining instances are u sed as the unlabeled set for further labeling during active learning itera-tions. Methods for Comparison For fair comparison, two baseline methods of supervised learning are included to augment their training sets with labeled instances during itera-tions. However, these labeled instances are cho-sen randomly from the corpus. gual labeled instances): only the monolingual labeled instances are fed to the SVM classifiers for both Chinese and English relation classifica-tion respectively. The initial training data only contain L c and L e for Chinese and English respec-tively. lingual labeled instances): in addition to mono-lingual labeled instances ( SL-MO ), the training data for supervised learning contain labeled in-stances translated from the other language. That is, the initial training data contain L c and L Chinese, or L e and L et for English. More impor-tant, at each iteration not only the labeled in-stances are added to the training data of its own language, but their translated instances are also added to the training data of the other language. instances): labeled and un labeled data for active learning only contain monolingual instances. No translated instances are involved. That is, the data contain L c and U c for Chinese, or L e and U for English respectively. This is the normal ac-tive learning method applied to a single language. instances): both the manually labeled instances and their translated ones are added to the respec-tive training data. The initial training data con-tain L c and L ct for Chinese, or L e and L et for Eng-lish. At each iteration, the n least confidently classified instances in U c and U e are labeled and added to the Chinese/English training data re-spectively. Their tran slated instances in U et and U ct are also added to the English/Chinese training data respectively. beled and unlabeled instances): similar to AL-CR with the exception that the unlabeled in-stances are chosen not by uncertainty scores in one language, but by the joint uncertainty scores in two languages. (cf.  X 4.4) Evaluation Metric Although learning curves are often used to evalu-ate the performance for active learning, it is pref-erable to quantitatively compare various active learning methods using a statistical metric defi-ciency (Schein and Ungar, 2007) defined as: Where n is the number of iterations involved in active learning and F i is the F1-score of relation classification at the i th iteration. REF is the base-line active learning method and AL is an im-proved variant of REF , such as AL-CR or AL-BI . Essentially this deficiency metric measures the degree to which REF outperforms AL . Thus, smaller deficiency value (i.e. &lt;1.0) indicates AL outperforms REF while a larger value (i.e. &gt;1.0) indicates AL underperforms REF . 5.2 Experimental Results and Analysis Comparison of overall deficiency Table 1 compares the deficiency scores of rela-tion classification on the Chinese (ACE2005c) and English corpora (ACE2005e) for various learning methods, i.e., SL-CR , AL-MO , AL-CR and AL-BI . Particularly, SL-MO is used as the baseline system against which deficiency scores for other methods are computed. The batch size n is set to 100 and iterations stop after all the unla-beled instances have run out of. Deficiency scores are averaged over 10 runs and the best ones are highlighted in bold font. Each run has a different test set and a different seed set. learning methods, bilingual active learning ( AL-BI ) achieves the best performance for both Chi-nese and English relation classification. This demonstrates that, bilingual active learning with jointly selecting the unlabeled instances can not only enhance relation classification for its own language, but also help relation classification for the other language due to the complementary nature of relation instances between Chinese and English. Table 1. Deficiency comparison of different methods cross-lingual information for relation classifica-tion for both languages. When cross-lingual in-formation is augmented, SL-CR outperforms SL-MO and AL-CR outperforms AL-MO . Comparison of different batch sizes Figure 5(a) and 5(b) illustrate the deficiency scores for four learning methods ( SL-CR , AL-MO , AL-CR and AL-BI ) against the SL-MO method with different batch sizes ( n ), where pre-fixes  X  X  X  and  X  X  X  denote Chinese and English respectively. The horizontal axes denote the range of n (&lt;=1000) while the vertical ones de-note the deficiency scores. for three active learning methods run virtually parallel with each other while they increase mo-notonously with the batch size n . This suggests that for both Chinese and English AL-BI consis-tently performs best against other methods across a wide range of batch sizes, though the overall advantage of three active learning methods gen-erally diminish.
 Comparison of learning curves In order to gain an intuition into how the per-formance evolves when the labeled instances are added into the training data during iterations, we depict the learning curves for various learning methods on the Chinese and English corpora in Fig. 6(a) and 6(b) respectively. The horizontal axes denote learning iterations while the vertical ones denote F1-scores. For simplicity of illustra-tion the F1-scores are collected from one of the 10 runs. ance difference for both languages among five methods at the beginning of iterations while F1-scores converge at the end of iterations. Particu-larly at the very outset, AL-BI outperforms other methods, quickly jumps to a very high point comparable to its best performance. However, after the 10 th iteration the performance scores for the three AL variants tend to show trivial differ-ence probably because most highly informative instances have already been added to the training data. Comparison of annotation scale In order to better compare BAL with other AL methods Figure 7 zooms out partial data on three AL methods in Fig. 6 and rescale the data for AL-MO , where  X  X  X  and  X  X  X  denote Chinese and English respectively. Likewise, the vertical axis denotes F1-scores while the horizontal axis de-notes the number of instances labeled for AL-CR and AL-BI . However, for AL-MO that num-ber is doubled. This figure tries to answer the question: to label n respective instances in both languages for BAL or to labeled 2n instances in just one language for monolingual AL, can the former rival the latter? Figure 7. Comparison of annotation scale among three AL methods English, when the number of instances ( n ) to be labeled is no greater than 400, AL-BI with n in-stances can achieve comparable performance with AL-MO with 2n instances. It implies that when the labeled instances are limited, labeling instances, half in one language and half in the other for BAL, is competitive against labeling the same total number of instances in just one language for monolingual AL, not to mention that the former can generate two relation extrac-tors on two languages. This paper proposes a bilingual active learning paradigm for Chinese and English relation classi-fication. Given a small number of relation in-stances and a large number of unlabeled relation instances in both languag es, we translate both the labeled and unlabeled instances in one language to the other as pseudo parallel corpora. After en-tity alignment, these labeled and unlabeled in-stances in both languages are fed into a bilingual active learning engine. Experiments with the task of relation classification on the ACE RDC 2005 Chinese and English corpora show that bilingual active learning can significantly outperforms monolingual active learning for both Chinese and English simultaneously. Moreover, we demon-strate that BAL across two languages can com-pete against monolingual AL when the annota-tion scale is limited, though the overall number of labeled instances remains the same. combine uncertainty sampling with diversity and informativeness measures; on the other hand, we intend to combine BAL with semi-supervised learning to further reduce human annotation ef-forts. This research is supported by Grants 61373096, 61305088, 61273320, and 61331011 under the National Natural Science Foundation of China; P roject 2012AA011102 under the  X 863 X  Na-tional High-Tech Research and Development of China; Grant 11KJA520003 under the Education Bureau of Jiangsu, China. We would like to thank the excellent and insightful comments from the three anonymous reviewers. Thanks also go to my colleague Dr. Shoushan Li for his helpful suggestions. 
