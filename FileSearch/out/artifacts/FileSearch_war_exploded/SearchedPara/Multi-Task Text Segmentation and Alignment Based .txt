 Text segmentation is important for text analysis, while text alignment is to determine shared sub-topics among similar documents. Multi-task text segmentation and alignment is the extension of single-task segmentation to utilize informa-tion of multi-source documents. In this paper we introduce a novel domain-independent unsupervised method for multi-task segmentation and alignment based on the idea that the optimal segmentation and alignment maximizes weighted mutual information, mutual information with term weights. The experiment results show that our approach works well. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Retrieval-Clustering ; I.2.7 [Artificial Intelligence]: Natural Language Processing-Text analysis ; General Terms: Algorithms, Design, Experimentation. Keywords: Multi-task, text segmentation, text alignment, weighted mutual information.
Text segmentation tasks are to determine the boundaries of sentence sequences to captu re the latent structures. Some previous approaches consider sentence dependence, such as HMM or CRF , while others are based on sentence simi-larity[3, 7, 8], which suffer the effect of stop words. Text classification and clustering is a related area which catego-rizes documents into groups, such as LSA[4], PLSA[6], and approaches based on mutual information ( MI )[1, 5]. Tra-ditional text segmentation approaches usually focused on single tasks. Multi-task learning[2] is an potential direc-tion, but most of previous multi-task approaches focus on supervised or semi-supervised learning, instead of on clus-tering or segmentation. In this paper, we extend research from single-task to multi-task. We view the text segmen-tation issue as an optimization issue in information theory to find the optimal boundaries given the number of seg-ments which minimize the loss of MI after segmentation. Text alignment of multi-source documents can be achieved by clustering sentences about the same sub-topic into the same segment. Term weights based on entropy learned from multi-source documents and weighted MI ( WMI )isused to increase the contribution of cue words and decrease the effect of common stop words, noisy word, and document-Table 1: Error Rates of Single-task Segmentation first assume that the segment order for each d is the same. For Clu (0) t , cluster labels can be set randomly. Then there are three stages, where the first is for single tasks without term clustering, while the other two are both iterative. Stage 2 is for term clustering, while Stage 3 is for term weight es-timation. The algorithm is listed below: w  X  X  0 , 1 } . Output: Clu , Seg , Ali , w  X  and w = 0, check all segmentations of d and find the best Ali ( i ) ;(4)  X  d , check all segmentations of d with mapping s  X   X  s , i  X  1 , ..., n d and find the best Seg ( i +1) or Ali changed, i ++,goto3;otherwise,if w =2,goto Clu ;(7)  X  d , check all segmentations of d with mapping s  X   X  s , i  X  1 , ..., n d and find the best Seg ( i +1) not changed, return; else, i ++,goto6.

Dynamic programming is used for each step. We only show the steps for Step 7 below:  X  d : (1) Compute p w (  X  t ), { 1 &lt;L&lt;p ,1  X  i  X  m +1, k L  X  Set ( p, L ) , which is the set of all p ! L !( p  X  L )! combinations of L segments chosen from all p segments, j  X  k L ,thesetof L segments chosen from all p segments, and k L/j is the combination of L  X  1 segments in k combination of all segments and 1  X  i  X  n d +1 which is the optimal I w and the corresponding segmentation is the best.
In this section, we refer to the method using I as MI k , and I w as WMI k ,where k is the number of term clusters. If k = l , no term clustering is required. The first data set is used in previous research. We use the previous evaluation criterion for comparison and tested the case with the known segment number. Table 1 shows the results with different parameters and previous approaches. For single-task WMI , Obviously, our methods MI l and WMI l both outperform the previous approaches. We found using term co-clustering is worse.

The data set for multi-task has 102 samples and 2264 sentences totally. Each is the introduction of a report from
