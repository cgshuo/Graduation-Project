 Given the recent trend toward the attainment of dynamic lexical resources (Calzolari, 2008) in service-oriented Web environments, a process that can efficiently, and in some cases on-demand/on-the-fly, interlink lexical elements across resources is in high demand. In particular, an inexpensive computational method for finding possible con-ceptual mates in another language (the target lan-guage (TL)) from a lexical concept in a given lan-guage (the source language (SL)) can contribute to the realization of a virtually combined multilin-gual lexical-semantic resource on top of existing monolingual lexical-semantic resources. Here, a conceptual mate in TL means a lexical concept that denotes almost the same or a closely related concept to the one in SL.

Given this motivation, this paper proposes a method of discovering conceptual mates in the lexical-semantic resources of other languages. To accomplish this, the proposed method integrates two types of cross-lingual semantic relatedness by balancing them using a weighted sum: The first, synonym-based relatedness , estimates the proba-bilistic correspondence between sets of synonyms, while the other, gloss-based relatedness , measures the textual similarity between gloss texts.

For synonym-based relatedness, this pa-per adopts a method recently proposed by us (Hayashi, 2012), which effectively employs a sense-tagged corpus in the TL and existing bilingual dictionaries. Conversely, for gloss-based relatedness, this paper relies on the extended gloss overlap method proposed by Banerjee and Pedersen (2003). However, because their method was developed to calculate monolingual textual similarities, prior to using them, we translate glosses in one language into another language using off-the-shelf machine translation engines.
This paper empirically discusses an optimum mean for integrating synonym-based and gloss-based semantic relatednesses, while examining the range of gloss extension. In addition, this paper investigates the impact of machine trans-lation by comparing the performances with those achieved when presumably ideal gloss translations are available.

The proposed method can contribute to the real-ization of dynamically combined lexical resources in service-oriented environments (Hayashi, 2011) because it is computationally inexpensive.
 Although the proposed method is essentially lan-guage independent, we here set our current task as the discovery of English conceptual mates in Princeton WordNet (PWN) (Miller and Fell-baum, 2007), given a concept in the EDR elec-tronic dictionary (EDR) (Yokoi, 1995). Note that even though the EDR is organized bilingually in Japanese and English, in principle, we only em-ployed information given in Japanese, leaving the corresponding English information for reference purposes only. (See Appendix-A for a more de-tailed description of EDR.) 2.1 Cross-lingual semantic relatedness In order to find the best-matched conceptual mates in a TL lexical-semantic resource for a given SL lexical concept, the proposed method establishes a ranked list of candidate lexical concepts in the TL (a partial example is shown in Figure 1) by com-puting cross-lingual semantic relatedness scores score ( s, t ) , which are defined by Formula (1). Just to be safe, s and t denote lexical concepts in SL and TL, respectively. As clearly indicated in the formula, score ( s, t ) is computed as the weighted sum of pscore ( s, t ) and gscore ( s, t ) ; the former, synonym-based relatedness, refers to cross-lingual semantic relatedness based on syn-onymous words (i.e., words that jointly specify a lexical concept), while the latter, gloss-based re-latedness, measures cross-lingual semantic relat-edness based on the textual similarity between the (extended) glosses. Finally, 0 . 0  X   X   X  1 . 0 indi-cates the blending ratio of these elements. 2.2 Synonym-based relatedness: pscore ( s, t ) We adopt the method proposed by Hayashi (2012) to compute the synonym-based related-ness, pscore ( s, t ) . As defined by Formula (2), it is computed as a weighted sum of pscore  X  ( x which gives the cross-lingual semantic relatedness between x of an SL lexical concept s , and a TL lexical con-cept t . In the formula,  X  ( x tion for assigning a weight to pscore  X  ( x stated,  X  ( x count. 2.2.1 pscore  X  ( x
A probabilistic interpretation is given to pscore  X  ( x i , t ) , as shown in Formula (3).
In the formula,  X   X  W ( x ) denotes a set of translation words for  X  p ( y j | t ) dictates the posterior probability of  X  p ( y j | x ) represents the translation probability 2.2.2  X  ( x
As proposed by Hayashi (2012), we also utilize the following formula to compute  X  ( x
The terms on the right hand side of the formula are as follows:  X  n idf ( x i ) , which, inspired from the normal- X  tset ( x i , s ) , which measures the representa- X  toverlap ( s, t ) , which measures the similar-2.3 Gloss-based relatedness: gscore ( s, t ) In this paper, we propose that gloss-based relat-edness be computed by Formula (5), which incor-porates the notion of extended gloss overlap first proposed by Banerjee and Pedersen (2003).
To apply the notion of gloss overlap even for the cross-lingual cases, we utilize machine trans-lation, for which the relevant function is in the for-mula represented by  X  that translates a text string in SL to the correspond-ing one in TL. In our experiments reported below, we utilized four distinct Web service Japanese-ing Google Translate.

As explicitly represented in the formula, the score is computed by averaging over the text similarity scores ( T extSim ( x, y ) ), each resulting from a textual combination defined in R . That is, the pair ( r combination considered by a calculation of text similarity. Here, r inventory { gloss, hyper, hypo } ; while, gloss ( s ) denotes the gloss text given in the lexical resource for the lexical concept s ; and hyper ( s ) / hypo ( s ) denotes the concatenation of the gloss texts given in the lexical resource for the hypernym/hyponym concepts of s . Note that an instance of R rep-resents a particular strategy for extending gloss texts. 3.1 Test dataset We utilized the same test dataset described by (Hayashi, 2012): comprising 196 query concepts and the relevant judgment annotations. 1. Query concepts: 196 concepts were ran-2. Candidate PWN synsets: By applying the 3. Relevance judgments: We established two  X  Syn-level (almost synonymous): A PWN  X  Rel-level (related somehow): PWN synsets 3.2 Evaluation measures Because of the following obvious correspon-dences, the experimental task itself was quite sim-ilar to that of information retrieval (IR): the whole PWN is a document set; a PWN synset can be a document; and a given EDR concept corresponds to a query reflecting a user X  X  intent. We therefore adopted the following two IR-based measures to assess the performance of the proposed method.  X  S@n (success rate at rank n ): This mea- X  MAP (Mean Average Precision): This mea-3.3 Design of the experiments We organized the experiments by considering the following parameters. More specifically, we con-ducted one experimental run using a combination of these conditions.  X  Combination of extended gloss text: We con- X  Text similarity measure T extSim ( x, y ) : The  X  Blending ratio  X  : To assess the contribution 4.1 Main results 4.1.1 S@1 measure
Table 2 summarizes the S@1 results for the tex-tual combinations A through D, where the best scores at both Rel-level and Syn-level are listed. Displayed immediately below the scores are the type of vector (rV: raw frequency vector, wV: weighted vector) and the optimum blending ratio  X  .

The results at Rel-level show that textual glosses, even extended ones, are ineffective for improving the S@1 measure, because the best score (0.776) is achieved when  X  is zero. How-ever, the S@1 measures are more important in considering performance at Syn-level.

The results at Syn-level show that the best score (0.474) is achieved through combination A, which uses the weighted vectors with  X  = 0 . 2 . This combination only employs non-extended glosses. The score declined when we applied more com-plicated textual combinations (B through D), but the differences are not statistically significant (p = 0.594, 0.504, 0.166, respectively; paired t-test). The results may indicate that the task of finding a synonymous conceptual mate in the first place can be affected by the noises inevitably introduced by more extended textual glosses. 4.1.2 MAP measure
Table 3 summarizes the best results obtained for the MAP measure. Unlike the results obtained using the S@1 measure, these results in general show that extended textual glosses effectively im-prove MAP performance.

In the table, it can be seen that the best score at Rel-level (0.695) is achieved when combination C is adopted with  X  = 0 . 6 , and the differences among combinations A, B, and D are statistically significant (p = 0.011, 0.035, and 0.027, respec-tively; paired t-test). This suggests that moder-ately extending gloss texts is beneficial because combination C considers more combinations of extended-gloss texts compared to combination B, but not as lavishly as combination D.

At Syn-level, on the other hand, combination D yields the best result, and combination A the sec-ond best. Although MAP performance is vastly more important at Rel-level, we still need to closely investigate the Syn-level results because they may not correlate with the results at Rel-level.
In summary, these results suggest that extended textual glosses effectively improve the MAP mea-sure, in particular at Rel-level. However, there might also be a better solution than the current strategy: more controlled extension strategies that rather deal with the queries in a nonuniform man-ner by taking into account the characteristics of each individual query concept and its textual gloss can and should be developed. 4.1.3 Blending ratio
The proposed method can be sensitive to the blending ratio  X  . Figure 2 displays S@1 per-formance and Figure 3 displays MAP perfor-mance; both sweep the value of  X  from 0.0 to 1.0. Note that these figures display the results only for the textual combination C with tf  X  idf -based weighted vectors.
 S@1 results: Figure 2 shows that the scores at Rel-level and at Syn-level decrease sharply imme-diately after  X  departs 0.0; however, the scores are relatively stable in the range  X  = 0 . 4  X  0 . 8 . At Rel-level, the score at  X  = 0 . 4 is almost the same as that at  X  = 0 . 0 ( 0 . 775  X  0 . 770 ). At Syn-level, the maximum score (0.454) is obtained at  X  = 0 . 6 . The scores at  X  = 1 . 0 , which indicates that only gloss-based relatedness are employed, are never better than those of any other  X  s. Consequently, it can safely be said that adopting  X  somewhere between 0.4 and 0.5 is not a bad solution when we consider the simultaneous MAP performance dis-cussed below. In the figure, it can also be seen that the difference at the Syn-level performance between  X  = 0 . 0 / 0 . 6 is not statistically signifi-cant (p = 0.089), while that at the Rel-level be-tween  X  = 0 . 6 / 1 . 0 is statistically significant (p = 0.007).
 MAP results: Figure 3 shows that scores at both Rel-level and Syn-level improve as  X  increases and are almost stable in the range  X  = 0 . 2  X  0 . 6 . The best scores for both levels are achieved at  X  = 0 . 6 : 0.695 at Rel-level and 0.525 at Syn-level, respectively. In the figure, it can also be seen that the differences in performance between  X  = 0 . 0 / 0 . 6 and  X  = 0 . 6 / 1 . 0 at the Rel-level are both statistically significant (p = 0.001 and 0.000, respectively). Notably, at Rel-level, the score at  X  = 1 . 0 exceeds that at  X  = 0 . 0 ( 0 . 695 &gt; 0 . 623 This suggests that if we can adopt only one type of solution to achieve better MAP performance at Rel-level, it should be gloss-based relatedness, not synonym-based relatedness. In conclusion, we can safely say that the proposed method, balanc-ing pscore ( s, t ) and gscore ( s, t ) by the blending ratio  X  is not only effective but also relatively ro-bust, as the performances examined were not very sensitive to variations in  X  . 4.2 Impact of machine translation To assess the impact of machine translation (MT), Table 4 compares the results achieved by the machine-translated textual glosses (MT all col-umn) with those yielded by the original English glosses given in the EDR (EDR column). Assum-ing the English glosses are reasonably adequate, they simulate a situation in which we can obtain  X  X deal X  translations.

As can be imagined, the results yielded by the original glosses outperforms those of the MTed glosses in virtually all cases, but the differences are relatively minor and statistically insignificant (p = 0.257, 0.358, and 0.394, respectively; paired t-test). On the other hand, the MAP performance at Rel-level (which we consider the most impor-tant) achieved by MTed glosses is even better than that of the original EDR glosses, but again the difference is statistically insignificant (p = 0.308). These results may suggest that the issue of vocab-ulary mismatch can be partially solved by incor-porating as many translation texts from different translation engines as possible.

To examine this hypothesis, the MT GT col-umn of the table lists the results obtained when we used only Google Translate from among the four available translation engines. The figures in the related columns demonstrate that more translation engines can yield better results: the differences in the S@1 measure are not statistically significant (p = 0.089 for Rel-level and p = 0.138 for Syn-level), but the differences in the MAP measure clearly exhibited statistically significant differences (p = 0.000, 0.0426, respectively).

In summary, the use of MT to translate tex-tual glosses does not appear to be as harmful as reported in previous ontology-matching litera-ture Fu et al. (2009); McCrae et al. (2011) because the linguistic qualities of translation targets are different (a word/phrase label versus a short para-graph). Moreover, we have demonstrated that re-dundancy in the translated texts brought about by employing multiple translation engines definitely plays a role in improving performance, at least with an appropriate text-representation scheme and a proper text-similarity metric. 4.3 Extrapolated optimal performances We believe that would be able to achieve better results if we could alter the blending ratio each time we processed a query concept, rather than the current uniform one. To partly examine this idea, we calculated the somewhat extrapolated re-sults shown in Table 5, in which the best figures already shown in the previous tables are replicated in parentheses. The extrapolated figures were cal-culated a posteriori with the assumption that we could choose from { X:textual combination C with  X  = 0 . 6 , Y:textual combination A with  X  = 0 . 2 , Z:textual combination A with  X  = 0 . 0 } , the best setting on a query-by-query basis.

As promisingly shown in the table, the extrap-olated results assert that room for improvement exists. To further break down these results, we investigated the distribution of parameter settings adopted a posteriori: for 126 out of 196 queries, setting X was adopted, setting Y for 42 queries, and setting Z for 28. These figures again suggest that a query-dependent gloss expansion method would be promising, and worth being examined. Although the present work demonstrates the potential usefulness of extended textual glosses (Banerjee and Pedersen, 2003), the range of contextual neighbors for the extension and the proper weighting of the textual similarities obtained from various combinations remain unidentified. The key to solving this issue is using a machine learning (ML) approach that can capture hidden properties in the lexical resources.
The use of machine translation and its impact in terms of performance have been explored by the research community looking at ontology match-ing . Their primary focus, however, has been on the translation of conceptual/ontological labels, as typically discussed in (Fu et al., 2009). More re-cently, McCrae et al. (2011) made a similar ar-gument and presented a number of strategies that they assert could improve the performance of sta-tistical machine translation of conceptual labels. In contrast to these research attempts, the present method applies machine translation to linguisti-cally richer textual glosses. However, as the lin-guistic qualities of textual glosses may vary, at least from resource to resource, we may need to devise a method for properly assessing and adjust-ing to them.

From the perspective of multilingual terminol-ogy extraction and alignment, the presented work may not share research interests with terminolo-gists, because our work targets dynamic pairwise alignment of existing lexical concepts. Neverthe-less, we envision that the proposed method may be applicable to cross-lingual terminology align-ment if domain-specific terms are extracted from a corpus with linguistic context, including their tex-tual definitions. That is, we could robustly mea-sure the cross-lingual similarity between linguistic contexts in different languages by applying multi-ple machine translation engines. This paper demonstrated that extended textual glosses residing in lexical-semantic resources can be effectively employed even in the context of a cross-lingual task, provided multiple machine translation engines can be utilized and the resul-tant translation redundancy yields benefits. The applicability of the method could thereby increase, as the underlying resources (sense-tagged corpora for the synonym-based relatedness and translation engines for the gloss-based relatedness) would be more readily available and sophisticated.

However, improvements and extensions remain to be done in some areas of this work: the per-formance could be improved by considering the  X  X ensitivity X  (Kwong, 2012) of a lexical concept or a lexical concept type; and the multilingual-ity can be greatly enhanced by exploiting Web-based multilingual resources, as demonstrated by (Navigli and Ponzetto, 2010). Another direction that can be explored is the type discrimination of lexical-semantic correspondences. A promising solution would be an ML-based approach (e.g., (de Melo and Weikum, 2012)) that takes into ac-count more features acquirable from the lexical re-sources at hand.
 This work was supported by JSPS KAKENHI Grant Number 258201170.
 Banerjee, S. and T. Pedersen (2003). Extended gloss overlaps as a measure of semantic relat-edness. In Proc. of IJCAI 2003 , pp. 805 X 810. Calzolari, N. (2008). Approaches towards a  X  X ex-ical web X : the role of interoperability. In Proc. of ICGL 2008 , pp. 34 X 42. de Melo, G. and G. Weikum (2012). Con-structing and utilizing wordnets using statisti-cal methods. Language Resources and Evalua-tion 46 (2), 287 X 311.
 Fu, B., R. Brennnan, and D. O X  X ullivan (2009).
Cross-lingual ontology mapping -an investiga-tion of the impact of machine translation. In Proc. of ASWC 2009 .
 Hayashi, Y. (2011). A representation framework for cross-lingual/interlingual lexical semantic correspondences. In Proc. of IWCS 2011 , pp. 155 X 164.
 Hayashi, Y. (2012). Computing cross-lingual syn-onym set similarity by using princeton anno-tated gloss corpus. In Proc. of GWC 2012 , pp. 131 X 141.
 Hayashi, Y. and T. Ishida (2006). A dictionary model for unifying machine readable dictionar-ies and computational concept lexicons. In Proc. of LREC 2006 , pp. 1 X 6.
 Kwong, O. Y. (2012). New Perspectives on Com-putational and Cognitive Strategies for Word Sense Disambiguation . Springer.
 Manning, C. D., P. Raghavan, and H. Sch  X  utze (2008). Introdocution to Information Retrieval . Cambiridge University Press.
 McCrae, J., M. Espinoza, E. Montiel-Ponsoda,
G. A. de Cea, and P. Cimiano (2011). Combin-ing statistical and semantic approaches to the translation of ontologies and taxonomies. In Proc. of SSST-5 .
 Miller, G. A. and C. Fellbaum (2007). Wordnet. then and now. Language Resources and Evalu-ation 41 , 209 X 214.
 Navigli, R. and S. P. Ponzetto (2010). Babelnet:
Building a very large multilingual semantic net-work. In Proc. of ACL 2010 , pp. 216 X 225.
 Yokoi, T. (1995). The edr electronic dictionary. Communications of the ACM 38 (11), 42 X 44.
 The EDR electronic dictionary, unlike Princeton WordNet, is not a lexical database based on rela-tional lexical semantics. Instead, it can be seen as a knowledge base that is enriched with linguistic information given in both Japanese and English. Another big difference lies in the consideration of parts of speech in the conceptual organization: as is well known, PWN maintains POS-dependent lexical semantic networks, while EDR bears only a POS-independent network.

Despite these differences, the information struc-ture of EDR can be modeled in the same way as that of PWN (Hayashi and Ishida, 2006): the set of words associated with a common concept iden-tifier in one or more of the sub-dictionaries can be modeled as a kind of synset.
