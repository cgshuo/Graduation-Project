 Most learning methods assume that the training set is drawn randomly from the population to which the learned model is to be applied. However in many applications this as-sumption is invalid. For example, lending institutions cre-ate models of who is likely to repay a loan from training sets consisting of people in their records to whom loans were given in the past; however, the institution approved loan ap-plications previously based on who was thought unlikely to default. Learning from only approved loans yields an incor-rect model because the training set is a biased sample of the general population of applicants. The issue of including rejected samples in the learning process, or alternatively us-ing rejected samples to adjust a model learned from accepted samples only, is called reject inference.

The main contribution of this paper is a systematic anal-ysis of different cases that arise in reject inference, with ex-planations of which cases arise in various real-world situ-ations. We use Bayesian networks to formalize each case as a set of conditional independence relationships and iden-tify eight cases, including the familiar missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR) cases. For each case we present an overview of available learning algorithms. These algorithms have been published in separate fields of research, including epidemiology, econometrics, clinical trial evaluation, sociol-ogy, and credit scoring; our second major contribution is to describe these algorithms in a common framework.
 G.3 [ Probability and Statistics ]: statistical computing; H.2.8 [ Database Management ]: Database Applications X  data mining ; I.2.6 [ Artificial Intelligence ]: Learning X  parameter learning ; I.5.2 [ Information Storage and Re-trieval ]: Design Methodology X  classifier design and evalu-ation Algorithms, Economics, Human Factors, Theory.
 Reject inference, sample selection bias, Heckman estimator, propensity scores, expectation-maximization, Bayesian net-works.
In the typical reject inference application, the aspect of the data that is to be learned (called the outcome) cannot be observed in some of the samples, called the rejects. These rejects are usually not randomly drawn from the training set, but are related in some way to the outcome. Therefore, if a model is learned from only the data with observable out-comes (the accepts), the model will have been trained on samples with biased selection (as opposed to random selec-tion), since the accepts constitute a skewed sample of the general population. The reject inference problem is to in-clude the rejected data in the learning process to avoid this sample selection bias.

One common instance of reject inference arises in the problem of loan application approval. When people apply for a loan, their application is either accepted or rejected, de-pending on the lender X  X  guess as to how likely the applicant is to repay the loan. Then the people whose applications were accepted either eventually repay the loan or default on the loan (the outcome). We would like to use a mathemat-ical model to predict how likely a person is to repay the loan, so we can better decide whom to reject or accept, by using a database created by a financial institution; however such databases only have repay/default behavior recorded for the people whose applications were accepted, since the rejected people never had a chance to repay or default on the loan. The accepts clearly constitute a biased sample of all the applicants, so reject inference should help us develop an unbiased model.
 Another common example is that of medical treatment. We would like to develop a mathematical model for a par-ticular treatment that predicts the extent to which it will help the patient, measured perhaps by the expected lifetime increase. To create such a model, we would use a database describing many patients and their responses to the treat-ment. Any realistic database, however, will be biased by sample selection, since it only contains patients whom doc-tors recommended for the treatment; certainly whether or not a doctor recommends someone for a particular treat-ment is related to how much that treatment is expected to benefit the patient. Reject inference should be used to cre-ate an unbiased model of how well each patient is likely to respond to the treatment.

So-called active learning is the situation where a learning agent chooses which training examples should be labeled, in-stead of using a randomly sampled training set [7]. Typically the agent is given a set of unlabeled examples and repeat-edly requests labels for the members of this set for which labels are likely to be most informative. Sample selection bias arises in the context of active learning in two ways. Most obviously, a training set chosen via active learning is not a random sample from the whole population. Less obvi-ously, sample selection bias is also an issue when measuring the performance (e.g. the accuracy) of a classifier acquired via active learning. If obtaining labels for examples is ex-pensive, then we will not have the luxury of having a large randomly chosen evaluation set of examples with which to measure performance. We will need to obtain somehow un-biased performance estimates from biased evaluation sets.
Reject inference problems can have binary outcome vari-ables, as in the loan application example, or be regression problems, as in the medical example. Rejection/selection is usually binary, but in some applications it can be multi-valued. For example, we can model whether or not to make a particular investment (a binary selection choice), or how much money to invest (a multi-valued choice).
An important part of reject inference lies in the assump-tions about how the selection mechanism and the outcome mechanism are related. Bayesian networks provide a nat-ural tool for representing possible relationships, both be-cause they have intuitive causal interpretations, and because they represent knowledge about their variables in a precise way, in the form of conditional independence relationships. Bayesian networks cannot encode that the outcome is ob-servable only when a sample has been selected, but they can encode the conditional independence relationships between selection and outcome.

A Bayesian network is a graphical way to represent how a joint distribution of random variables can be factored. In general any joint probability distribution may be factored in the following way: p ( a 1 ,a 2 ,a 3 ,..., a n ) To represent such a distribution over binary variables re-quires 2 n  X  1 parameters; however, Bayesian networks en-code information about which variables are conditionally in-dependent, leading to a simpler factoring of the joint dis-tribution, and therefore simpler mathematical models. For example, consider the following Bayesian network: This network encodes the fact that b depends only on a and c depends only on b .Inotherwords, a and c are condition-ally independent given b . The general factoring of the joint distribution can now be simplified because p ( c | a,b )= p ( c Inthecasethat a , b ,and c are binary, representing the joint distribution factored in this form can be accomplished with five parameters instead of seven. This reduction in the num-ber of model parameters is possible whenever the situation is described by a Bayesian network whose skeleton (i.e. the graph with the edge directions removed) is not a complete graph. The following Bayesian network has a skeleton that is a complete graph: The joint distribution factoring implied by this graph is of any distribution over three variables, without loss of gen-erality. This generality can conflict with intuitions about Bayesian networks. Because the edges on the network are directed a particular way we might expect the network to be able to model only particular distributions (i.e. distributions arising from circumstances with the same causal relation-ships as the network implies), whereas the factoring shows that this network is completely general, for all distributions over three variables [10].

Bayesian networks are good tools for organizing sets of conditional independence relationships because those sets correspond to properties of graphs over which the joint dis-tribution factors. Two variables, A and B , in a probabil-ity distribution are conditionally independent given a set of other variables, X , if information cannot flow between their corresponding vertices in the Bayesian network describing that distribution. For information to flow between A and B , there must be an  X  X ctive path X  between them. Clearly there must be a series of edges (a path) connecting the two, but for the path to be active, every pair of two consecutive edges on that path must follow one of three patterns [11]: ...  X  X  X  C  X  X  X  ... where C is not in X ...  X  X  X  C  X  X  X  ... where C is not in X ...  X  X  X  C  X  X  X  ... where C or a descendant of C is in X . In these patterns C is the vertex between the two edges. If there is no active path between A and B ,thenwesay X  X  X -separates X  A and B (written A  X  B | X ). The last case, in which the two edges point to the same vertex, is called a v-structure, and unless the two vertices that both point to C shareanedge(inwhichcasewehaveaso-called moralized v-structure), conditioning on C or a descendant of C (a vertex with a directed path from C ) allows information to flow through the path segment [10].
In this paper, we assume that some existing model (the old model) has consistently been used to select samples for a database. We want to create a mathematical model (the new model) with this database that will hopefully better predict the outcome, and therefore be a better tool for future use. The old model can be either a formal selection model, such as a logistic regression on a feature vector, or informal, such as an interview by a loan agent. Both cases are discussed in later sections.

Bayesian networks are used to represent the relationship between the selection and outcome processes. As previously stated, the structure of the network depends on our assump-tions about conditional independence, but the random vari-ables corresponding to the vertices of the different graphs will be the same in all cases.

Following are the definition of each variable, with an ex-ample in parentheses of what the variable would represent in the case of loan applications. Our learning task can always be described by the following Bayesian network, since its skeleton is a complete graph and therefore the implied factoring of the joint distribution is completely general:
This network is a template for the different cases con-sidered in this paper; all of the conditional independence relationships in the next section will follow from subgraphs of this graph, where we require the solid edges to be present and the dashed edges are optional. This results in eight dif-ferent sets of assumptions, the first of which has no optional edges and the last of which has all the optional edges.
These constraints restrict the set of Bayesian networks to those with valid semantic interpretations (in terms of causality), even though those that lack valid causal inter-pretations may lead to equally useful statistical models. In general the x -variables are causes, and the outcome and se-lection variables, y and s , are effects, so there should never be an edge from y or s to an x variable. In the case of the selection procedure, this constraint conforms to what is done in practice: data points are selected for observation depending on features of that data point. In the case of the outcome event, this constraint conforms to our intuitive notions about causality: the outcome for a data point is influenced by the features of that data point.

We always assume the outcome, y , is dependent both on the observable variables x 1 and on the unobservable vari-ables x 2 . The edge from x 2 to x 1 conforms to our intuitive notions because observable variables, such as one X  X  credit history, are influenced by unobservable variables, such as one X  X  responsibility. This also helps in practice because it is often the case that the variables used in an old model are not present to train the new model. For example if an inter-view is part of the loan application process, the interviewer X  X  general impression of the applicant can affect the decision to select the applicant, but it is not recorded in a database and will not be present for learning a new model. In most cases there should be no edge between y and s . Even though there can be a direct influence of s on y ,forex-ample if s represents selecting someone for treatment and y represents survival, we do not add this edge into the graph. In this paper we are not trying to measure the probability of an outcome conditioned on whether or not an individual is selected, but instead to obtain an unbiased model of what the outcome would be for any individual in the general pop-ulation, if selected. It is important to distinguish [3] between modeling the average risk difference, which is a function of P (outcome | treatment) and P (outcome | no treatment), and modeling only P (outcome | treatment), which is the focus of this paper.

The reject inference problem can now be defined more formally. Note that it is actually a learning problem, not an inference (i.e. reasoning) problem. Our data set contains samples drawn independently at random from some underly-ing distribution, p ( x 1 ,x 2 ,y,s ), where each sample for which s = 0 is missing the value of y . The goal is to model the distribution of the outcome y as a function of the observable variables x 1 , i.e. to learn p ( y | x 1 ).
The subsections in this section describe different possible independence relationships between the four variables, and how these relationships change the reject inference problem. Each set of conditional independence relationships follows from a Bayesian network that is a subgraph of the tem-plate in Section 3. Also provided are real-world situations in which these cases could arise. Algorithms for learning under these different assumptions are given in Section 5.
In this case the following independence relationship holds: which implies This can be represented by a Bayesian network in which s is not connected to any other random variables. This is the most general subgraph (of the template) satisfy-ing the independence relationships because any probability distribution with the given independence relationships will factor over it; a proper subgraph G of this graph will cer-tainly have the given independence relationship, but a prob-ability distribution in which the marginal p ( x 1 ,x 2 ,y ) cannot be further factored will not factor over G but will factor over the graph of case 1.

Factoring the joint probability of x 1 ,x 2 ,y, and s once gives We find the marginal distribution p ( x 1 ,x 2 ,y ) by summing over s : p ( x 1 ,x 2 ,y )= Since s is independent of all other variables, we have Making this substitution, p ( x 1 ,x 2 ,y )= p ( x 1 ,x 2 ,y | s =1) p ( s =1) So the distribution of the selected samples, those for which s = 1, is the same as the underlying distribution of x 1 , x and y . Any learner that only uses the selected data to learn this distribution will be learning an unbiased classifier.
This situation arises in randomized studies, in which sam-ples are selected for observation completely at random. In the literature, this case is called missing completely at ran-dom (MCAR) [6].
In this case, we allow only the observable features to in-fluence the selection. Thus the outcome and selection are conditionally independent: which implies the constraints This case is less restrictive than case 1 since any distribu-tion satisfying the unconditional independence relationships of case 1 will also satisfy the conditional independence re-lationships of case 2. The most general Bayesian network that has this property and is a subgraph of the template is In this graph, observing x 1 d-separates y and s , so the con-ditional independence relationships are preserved. In this case, selection may depend on x 1 , butgiven x 1 , y adds noad-ditional information about selection, or, equivalently, given x , knowing s gives no information about the outcome (for example, whether or not someone is a bad borrower).
This situation can arise if a formal selection model is used, where s is some function of the observable variables, x 1 Rather confusingly, in the literature, this case is called miss-ing at random (MAR) [6].

An important consequence of this conditional indepen-dence relationship is that the distribution of selected sam-ples, p ( x 1 , y | s = 1), is related to the underlying distribution p ( x 1 ,y ) in the following way: Lemma 1: Under case 2, p ( x 1 ,y )= p ( s =1) p ( s =1 | if all three probabilities are non-zero.
 Proof: ApplyBayes X  rule to theright hand side of this equa-tion and then use the assumed conditional independence re-lationship:
Lemma 1 is applied in Section 5.2 to learn an unbiased model in this case. Sample weights are created to rebalance the training set so that the weighted distribution of the se-lected samples is the same as the (unweighted) distribution of the general population [16].
In this case, the selection is dependent on the outcome, but given the outcome, selection is not dependent on the covariates, observed or unobserved: or in other words The most general subgraph that has this property is The important feature of this graph is that y d-separates s and x .

If the variables s and y are binary, this situation corre-sponds to differences in the base rates of y for the selected data and the general population. This situation arises most often when the record-keeping procedure deletes outcome la-bels depending on the outcome label (also known as censor-ing). An example in medical studies is estimating expected survival time from a database in which patients who lived longer than five years do not have a survival time recorded. Section 5.3 discusses what may and may not be learned in this case.

This situation also arises when the biased selection changes the distribution of y , but the conditional distributions of x given each possible outcome y are unchanged, because in the network y d-separates x and s . For example, suppose we learn to diagnose a disease y basedonpatients x encoun-tered at one hospital. At a different hospital, the prevalence of the disease p ( y )may be different, but it is often reasonable to assume that the characteristics of affected and unaffected patients, i.e. p ( x | y =1)and p ( x | y = 0), are unchanged. This scenario has been analyzed previously [5].
In this case, the only conditional independence relation-ship asserts that the unobserved covariates cannot influence selection: or The most general graph that has this property is a com-bination of the previous two. This creates two possible v-structures, but both are moralized so there are no uncondi-tional independence relationships due to the v-structures: This situation could arise in practice if a formal selection model is used to determine s , and then in addition p ( y ) changes as discussed in the previous subsection. Learning under these assumptions is discussed in Section 5.4.
This case is a generalization of case 2 in which the unob-served features in x 2 may influence selection. This occurs in practice when a selection decision is made based on un-recorded information, such as an interviewer X  X  general im-pression, or numerical features which are not available for learning the new model. The conditional independence re-lationship describing this case is
However, x 2 can never be observed, so it is impossible to make use of any independence relationships.
This case is a special case of the previous case. All the features that influence the selection variable are in x 2 not x 1 : In this case it is impossible to learn a model of the selection mechanism. This case rarely arises. Intuitively, if the se-lection mechanism and the outcome mechanism are related (as they are in loan applications; loan approval attempts to predict loan repayment) and the outcome depends in some way on the available features in x 1 , then it is reasonable to expect the selection to depend in some way on x 1 .
This case could arise if a lending institution is just be-ginning to use statistical methods in its loan application procedure. Such an institution would have a training set consisting entirely of people whose loan applications were approved solely on the basis of an agent X  X  subjective judg-ment, and not recordable features.
This cases features a selection mechanism that is not in-fluenced by the observable features, x 1 , but is influenced by unobservable features x 2 and by the outcome y : This scenario arises if the predictive features of the selection mechanism are not present for training a new model, and in addition outcome labels are missing in a way that depends on the value of the outcome.
This case is the most general: there are no assumptions about conditional independencerelationships. The Bayesian network representing this case is Since this Bayesian network represents a completely general factoring of the joint distribution, we would be able to use it to model a situation in which any of the previous conditions hold. This model should be used in practice when nothing is known about the selection mechanism.
As stated above, Bayesian networks have no capability to encode the relationship between the outcome and selection variables, so our algorithms must learn from a heterogeneous training set, one in which there exist two different schemas for data in the training set.
Since the distribution p ( y,x 1 ,x 2 | s =1)isthesameasthe underlying distribution p ( y,x 1 ,x 2 ), any classifier that learns from only the selected samples will learn an unbiased model of the outcome. However, because this classifier is based on fewer data points, it will have increased variance.
When we want to predict y based on x , we usually have the choice of learning p ( y | x )orlearning p ( x,y ). The former is often called discriminative learning, while the latter is called learning a generative model. Under case 2, these two types of learning are very different.
 Given any particular x , the distribution of y for the selected data is the same as the distribution of y for the unselected data, because So learning a model of the outcome based only on selected data provides an unbiased estimate of p ( y | x )intheentire population.

Intuitively the samples with unobserved outcomes can contribute nothing to the model, since the values of the variable whose density we are trying to estimate are missing. This can be shown formally by looking at the contribution of each sample to the likelihood of the parameters of a model.
Assuming samples are drawn independently, the likeli-hood of the parameters given the data equals the product of the probabilities of every sample, given those parameters. If a value is missing in a particular sample, the probability of that sample equals the full joint distribution marginalized with respect to the missing feature. For example if the prob-ability of some sample i should be p ( A = a i ,B = b i ,C = c |  X ) but the value of B is missing, the probability becomes b p ( A = a i ,B = b,C = c i tuitive that the likelihood increases if features are missing; however, if we interpret the likelihood as the goodness-of-fit of our model, then with less information (due to missing fea-tures), there is less opportunity to criticize our model and the likelihood should therefore be greater.

Rejected samples are missing the value of y ,so y should be treated as a missing feature in the conditional likelihood equation: where
L j ( X ) = p ( y = i The sum equals 1 because p ( y =1)=1  X  p ( y = 0), so the contribution to the likelihood of the unselected data is an uninformative factor of 1.
 If instead of modeling p ( y | x )wewanttomodel p ( x,y ), with-out loss of generality we can use a mixture model with one mixture component for the data in which y =1andonemix-ture component for the data in which y = 0. These mixture components come from the factoring p ( x,y )= p ( y ) p ( x whichcanbewritteninthecaseofbinary y as The factors p ( y = i ) are the mixing proportions, renamed  X  , and the conditional distributions p ( x | y = i )aremodeled by the mixture components, written p ( x | y = i )= p i ( x ). Now all samples are modeled as being drawn from the two component mixture We only observe which mixture component generated a sam-ple for those samples with observed outcomes. The contri-bution to the likelihood for the observed samples is As before, the contribution to the likelihood for those sam-ples with an unobserved outcome is obtained by marginal-izing with respect to the outcome variable: Assuming there are m rejected samples and n accepted sam-ples, the full likelihood of all data is
L = where the indicator z ij equals 1 if y j = i and 0 otherwise. The log likelihood is This equation contains a logarithm of sums for the unob-served samples, which makes an analytic maximum likeli-hood approach intractable. The EM algorithm is a common algorithmic approach to this maximization. EM iteratively optimizes the so-called complete-data log likelihood that y = i for sample j . First, the E-step uses some initial estimate  X  (0) of the parameters, based only on observed data, to estimate the probabilities z (1) ij . These probabilities are then used in the M-step to learn a new set of parameters,  X  (1) , that maximizes the likelihood of the data, including z ij . The E and M steps are iterated until convergence [6]. Reweighting methods used to solve the reject inference prob-lem, sometimes called inverse probability of treatment weight-ing (IPTW), weight each selected sample so that the distri-bution of weighted samples equals the underlying distribu-tion ignoring selection [14]. These methods take advantage of Lemma 1.

The IPTW method first learns a select/reject model using the entire data set. After the model is adjusted to yield well-calibrated probabilities, sampling weights are created for each selected sample: P ( s =1) /P ( s =1 | x ). A model for P ( y | x 1 ) is then learned using the weighted (selected) samples, ignoring the unselected samples [16].

Stratified analysis (also called banded analysis) is a special case of reweighting. Like the IPTW method, the rejected samples are used only to create weights for the accepted samples. The stratified analysis presented in [4] is an ap-proximation of the IPTW method. First an accept/reject model is estimated using the entire data set. The range of the classifier X  X  output is partitioned into several strata or bands, usually so they contain similar numbers of samples. Within band j , the probability of selection is estimated as the ratio of selected samples in band j to the total number of samples in band j . This essentially bins the classifier to estimate the conditional probability of selection given x For a more adaptive binning method, see [15], which also divides the range of the classifier score into several bands (typically many more than stratified analysis) and assigns a probability to each band, estimated from the samples in that band and its neighbors. This calibration algorithm si-multaneously determines an appropriate population size for each band and enforces the monotonicity of the probability given the score.

Within each band j , all of the accepted samples are given aweightof1 /p ( s =1 | j ),whichisanestimateof1 /p ( s = 1 | x ). Here j is a function of x defined by a range of scores determined by the accept/reject model. This is the same weight used for the IPTW method, except for the constant factor p ( s = 1). Since resampling is done with probability proportional to each sample X  X  weight, and is not sensitive to constant factors, stratified analysis is equivalent to the IPTW method.

The propensity score method is a technique similar to stratified analysis, except that it is usually used to find an unbiased estimate of the average effect of some treatment on the general population, a function of p ( y | treatment) and p ( y | no treatment), as opposed to solving the reject inference problem, which is to learn a per-individual model of the effect of treatment.

The propensity score method is described here to illus-trate the similarities to stratified analysis. The propensity score is the function e ( x )= p ( s =1 | x ), the conditional probability of selection given x .Itisaspecialcaseofthe more general balancing score, any function b ( x ) such that x  X  s | b ( x ). It is shown in [13] that if selection and outcome are conditionally independent given x (i.e. case 2 applies), then y  X  s | e ( x ); for any particular value of e ( x ), the dis-tribution of the outcome variable is independent from the selection variable. Accepted samples are grouped (banded) together according to their propensity score [13]. Since the treatment effect (outcome) and selection are conditionally independent within one band, the treated population and the untreated population within the same band may be di-rectly compared. An unbiased estimate of the average treat-ment effect is the average of the average treatment effects in each band, weighted by the number of samples in that band.

When the outcome is continuous, for example, the in-crease in white blood cells, the pair matching method may be used. When one treated sample and one untreated sam-ple both have the same propensity score e ( x ), the two are called a matched pair and the difference in outcome values is an unbiased estimate of the outcome difference at e ( x ) [13].
In case 3, selection is independent of the covariates, both observed and unobserved, given the outcome: s  X  x | y .The bias only depends on the outcome label. Therefore the only difference between the distribution of selected samples and the distribution of the general population is a different prior for the outcome probability.

Without making further assumptions, it is impossible to infer the true baseline probability of a specific outcome in the general population, as can be seen by first applying Bayes X  rule and then using the conditional independence relation-ship: The quantity p ( x 1 | y =1 ,s = 1) can be estimated from only observed samples, as can p ( x 1 ), but it is impossible to estimate p ( y = 1) since this could have been arbitrarily al-tered.

If we learn separate models of the covariates of the good outcomes p ( x 1 | y = 1) and of the covariates of the bad out-comes p ( x 1 | y = 0), from the selected samples, and we have outside information that p ( y =1)= p 1 ,thenwecancreate an unbiased model of p ( y =1 | x 1 ) using Bayes X  Rule: For further discussion of this case, see [5].

Under case 4, the selection variable depends both on the observable features and theoutcome variable. Without mak-ing further assumptions about the selection mechanism, it is impossible to learn an unbiased model to predict y ,just as for case 3.
In each of these cases, the selection mechanism can de-pend, at least in part, on unobservable features. This is especially relevant when correcting for self-selection bias, an example of which is estimating something about the general population from survey results when returning the surveys is voluntary (and therefore not random). The unobservable features prevent us from building an accurate model of the selection mechanism. However, even if we make no condi-tional independence assumptions we can still estimate an unbiased model of the outcome if we are willing to assume a particular functional form of the relationship between the outcome and selection processes. The usual approach given this new assumption is the bivariate probit, which assumes a normal distribution for the outcome and selection vari-ables. Heckman X  X  two-step estimator, an approximation of the maximum likelihood estimate of the bivariate probit pa-rameters, is also explained below.
 The univariate probit model is used to represent the con-ditional distribution of a single response variable y given a vector of features, based on a linear relationship between the features and a dummy variable y  X  which is not observed [2]: Here x i is the vector of features for sample i ,  X  is a vector of parameters, and is a normally distributed random variable with zero mean and variance  X  2 . The response y i for sample i is related to y  X  i by
Given this linear relationship, we can write the functional form of p ( y =1 | x ): Here  X   X  ( . ) is the cumulative normal distribution function with variance  X  2 and mean 0, while  X ( . ) is the standard cumulative normal distribution function. Equation (2) is known as the probit equation. Given this functional form, the log likelihood of parameters  X  given data set X with n samples is log L ( X  | X )= There are iterative methods for estimating  X / X  given this model. Note that  X  and  X  are not uniquely defined since they only enter into the model as the ratio  X / X  [2]. Bivariate probit is an extension of univariate probit, in which there are two response variables (our outcome and selection variables) [6]. For all samples i =1 , 2 , ..., n and Here s  X  i and y  X  i are unobserved variables. Analogously to the univariate probit, let the binary s and y equal 1 if the associated continuous variable is nonnegative, or 0 if it is negative. The vectors  X  and  X  are the coefficients of the linear models, while i and  X  i are the errors of those models for each sample, with variances  X  1 and  X  2 respectively.
We assert the selection rule: for sample i , y i is only ob-served if s i = 1. Assume the errors are bivariate normally distributed: Each of the three possible types of observation has a different form for its contribution to the likelihood: Here  X  is the standard univariate normal cumulative distri-bution function, as above, and  X   X  is the standard bivariate normal cumulative distribution with correlation  X  =  X  12  X  1  X  2 Equation (3) holds by the definition of the probit model, p ( s =1)= X ( x i  X / X  1 ), and the fact that p ( s =0)= 1  X  p ( s = 1). Similar reasoning yields Equation (5). Equa-tion (4) holds because and applying the probit model equations yields (4). These three expressions can combined into one log likelihood func-tion: log L (  X / X  1 , X / X  2 , X  | X )=
From this equation we can derive iterative maximum like-lihood estimators of  X / X  1 ,  X / X  2 ,and  X  . The correlation  X  between the errors of the two linear models, and  X  , indi-cates how and if the samples were selected in a biased way. If  X  is zero there is no correlation, and selection is indepen-dent from the outcome given the observable features, so we can use one of the methods for case 2 to estimate an unbi-ased model. If  X  is positive, then the unobserved features do affect selection and the outcome in a way that makes them positively correlated. Similarly, if  X  is negative, then selection is an indicator of a bad outcome [6].

The maximum likelihood estimation of the outcome given the features is then p ( y =1 | x )= X ( x X / X  1 ), which is the probit equation (2). This estimate is asymptotically unbi-ased in theory, with its performance in practice depending on the correctness of the parametric assumption stated in equation (1).
 The computation of the model identified by the bivariate probit maximum likelihood equation was until recently pro-hibitively computationally intensive [12]. For this reason, Heckman developed a two step estimator to solve the reject inference problem when the outcome y is continuous [7]. Many problems with binary outcomes have a natural corre-spondence with problems with a continuous outcome. For example, the problem of estimating the probability of sur-vival, a problem with a binary outcome, can be extended to finding an unbiased estimate of the expected survival time. In the domain of credit scoring, the problem of estimating the probability of loan repayment can be cast as estimating how profitable a customer will be to the lending institution.
For consistency of notation, the outcome of sample i ,now continuous, is denoted y  X  i andisobservedinsamplesfor which s i = 1. The Heckman estimator relies on a prop-erty of the conditional distribution of y  X  i given that s (i. e. given s i = 1, the sample was selected). From [2], where  X  is the standard normal density function. The last term is usually expressed in terms of the function  X  (), known as the inverse Mills ratio: The two step Heckman procedure is as follows [9]: 1. Estimate the parameters  X / X  2 describing the proba-2. Equation (6) becomes the linear regression From the second step, we get an estimate of  X  12 / X  2 .Call this C .Let  X  V 2 i be the squared residuals from the regression in the second step, and let I 1 be the number of samples for which s =1.Nowwecanestimate  X  1 as Analogously to the bivariate probit model, the unbiased esti-mated model of the outcome given the features is E ( y  X  | x X  .

Aninteresting similarity between the reweighting methods of Section 5.2 and the Heckman procedure is that both first learn a model of the selection mechanism and then use that model to learn a model of the outcome mechanism.
The main contribution of this paper is to apply Bayesian networksto describe the different assumptions one may make in the course of developing a procedure to learn an unbi-ased model from a training set with sample selection bias (i.e. in the course of solving the reject inference problem). Our framework describes previously published cases as well as several novel ones. The use of Bayesian networks makes recognizing which case is applicable easier and more intu-itive, since conditional independence relationships are easy to spot in the simple networks involved in reject inference.
For each case, we have provided an overview of the proba-bilistic learning algorithms that are available, to the extent to which a model can be learned in each case. In some cases a provably unbiased model can be learned, while in other case selection bias is impossible to overcome. In the most general case, we can only learn an unbiased model if a par-ticular functional form for the outcome and selection models is assumed.

Future work includes investigating what algorithms exist to learn the parameters of Bayesian networks with a het-erogeneous training set, i.e. a training set that contains ex-amples with differing patterns of observed and unobserved variables.
 None of the algorithms described above are specifically Bayesian network training algorithms [8]. An important di-rection for future work is to investigate how existing Bayesian network methods perform with a heterogeneous training set, i.e. a training set that contains examples with differing pat-terns of observed and unobserved variables. These algo-rithms can be used in principle to solve the reject inference problem. A related research direction is to apply structural learning algorithms to discover which of the cases in Section 4 best describes a given data set.

Alternatively, perhaps algorithms developed specifically to solve reject inference problems can be extended to learn the parameters of Bayesian networks given a heterogeneous training set.
The authors thank Fair Isaac Corporation for funding this research through California MICRO grant 2003-024. This research was also supported by a gift from Sun Microsys-tems. [1] P. D. Allison. Missing Data . Sage Publications, Inc., [2] T. Amemiya. Advanced Econometrics .Harvard [3] D. A. Cobb-Clark and T. Crossley. Econometrics for [4] J. Crook and J. Banasik. Does reject inference really [5] C. Elkan. The foundations of cost-sensitive learning. [6] A. J. Feelders. An overview of model based reject [7] Y. Freund, H. Seung, E. Shamir, and N. Tishby. [8] D. Heckerman. A Tutorial on Learning with Bayesian [9] J. J. Heckman. Sample selection bias as a specification [10] K. Murphy. Dynamic Bayesian Networks: [11] J. Pearl. Graphical models for probabilistic and causal [12] P. A. Puhani. The Heckman correction for sample [13] P. R. Rosenbaum and D. B. Rubin. The central role of [14] B. Zadrozny. Learning and Evaluating Classifiers [15] B. Zadrozny and C. Elkan. Transforming classifier [16] B. Zadrozny, J. Langford, and N. Abe. Cost-sensitive
