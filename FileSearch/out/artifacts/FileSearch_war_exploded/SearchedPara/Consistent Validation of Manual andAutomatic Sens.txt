 Universit ` a di Roma  X  X a Sapienza X  with respect to the reference dictionary is not always guaranteed.
 divergences and support consistent decision making. 1. Introduction
Sense tagging is the task of assigning senses chosen from a computational lexicon to words in context. This is a task where both machines and humans find it difficult to inherent subjectivity of the task to the granularity of sense discretization, coverage of the reference dictionary, etc.
 acquisition interfaces like the Open Mind Word Expert (Chklovski and Mihalcea 2002), due to the unknown source of the contributions of possibly unskilled volunteers. agreement with adjudication for human sense assignments only partially solve the issue of disagreement. Especially when there is no clear preference towards a certain word sense, the final choice made by a judge can be subjective, if not arbitrary. This is a case where analyzing the intrinsic structure of the reference lexicon is essential for producing a consistent decision. A lexicographer is indeed expected to review a number of related dictionary entries in order to adjudicate a sense coherently. This work can be tedious, time-consuming, and often incomplete due to the complex structure of the resource. As a result, inconsistent choices can be made.
 and automatic sense annotations through the use of semantic graphs, particularly of semantic interconnection patterns (Navigli and Velardi 2005). 2. Semantic Networks and Semantic Interconnection Patterns
Semantic networks are a graphical notation developed to represent knowledge expli-citly as a set of conceptual entities and their interrelationships. The availability of wide-coverage computational lexicons like WordNet (Fellbaum 1998), as well as semantically exploration and exploitation of semantic graphs for several tasks like the analysis of lexical text cohesion (Morris and Hirst 1991), word sense disambiguation (Agirre and
Rigau 1996; Mihalcea and Moldovan 2001), and ontology learning (Navigli and Velardi 2004), etc.
 structural semantic interconnections (SSI, http:/ /lcl.di.uniroma1.it/ssi) (Navigli and
Velardi 2004, 2005), has been shown to provide interesting insights into the choice of word senses by providing structural justifications in terms of semantic graphs. Given a word context and a lexical knowledge base (LKB), obtained by integrating WordNet with annotated corpora and collocation resources (Navigli 2005), SSI selects a semantic graph including those word senses having a higher degree of interconnection, according to a measure of connectivity.
 cording to a context-free grammar, i.e., a path connecting a pair of word senses (dark nodes in Figure 1), possibly including a number of intermediate concepts (light nodes in Figure 1). For example, if the context of words to be disambiguated is [ cross-v , are inspired by several works on semantic relatedness and similarity (Rada et al. 1989; Hirst and St-Onge 1998; Mihalcea and Moldovan 2001).
 connection patterns for the WordNet lexicon is reported in Table 1. For further details the reader can refer to Velardi 2005. 3. Supporting Validation with Semantic Interconnection Patterns
The validation task can be defined as follows: Let w be a word in a sentence  X  , previously annotated by a set of annotators A = { a 1 , a s  X  Senses( w ) for a word w over the others. Notice that s is a word sense for w in the sense inventory, but is not necessarily in S , although it is likely to be. Also note that the annotators in A can be either human or automatic, depending upon the purpose of the exercise.
 to support the validator in the difficult task of assessing the quality and suitability of sense annotations. The tool takes as input a corpus of documents whose sentences are 274 tagged by one or more annotators with word senses from the WordNet inventory. The user can then browse the sentences and adjudicate a choice over the others in case of disagreement among the annotators. To the end of facilitating the user in the validation task, the tool highlights each word in a sentence with different colors, namely, green for words having a full agreement, red for words where no agreement can be found, and orange for those words to which a validation policy can be applied.
  X  e  X  e  X  e  X  e dation policies to be applied to those words with disagreement on which sense to assign: (  X  ) majority voting: If there exists a sense s  X  S such that (  X  ) majority voting + SSI: The same as the previous policy, with the addition (  X  ) SSI: The SSI algorithm is applied to w , and the chosen sense, if any, is (  X  ) no validation: w is left untagged.
 context of its sentence  X  by taking into account for disambiguation only the senses in S (i.e., the set of senses chosen by the annotators). In general, given a set of words with chosen for the words in  X  \ W .
 explained hereafter.
 w  X   X  with the sense chosen by the application of the SSI algorithm to  X  .Asare-sult, the selected validation policy will be applied to the new set of annotators A =
A  X  X  a no use.
 is shown, marked with colors as explained above. The main pane shows the semantic interconnections between senses for which either there is a full agreement or the chosen validation policy can be applied. When the user clicks on a word w , the left pane reports the sense inventory for w , including information about the hypernym, definition, and semantic graph shown in the main pane changes after the selection, possibly resulting in a different number and strength of semantic interconnection patterns supporting that sense choice.
 validation of manual and automatic annotations, and we discuss cases of uncertain applicability of the tool. 276 3.1 Validating Manual Annotations
In the following, we illustrate the tool by presenting two examples of validation of a manual annotation (the validation policy  X  was selected).
 (a) We crossed the street near the intersection.
 meaning that the annotators fully agreed on those choices. On the other hand, sense #2 of street is marked in orange, due to a disagreement between the annotators, one dictionary definitions of the two senses. The validator can then visualize in the same or in a new window the semantic graphs concerning conflicting sense choices, comparing the interconnection patterns available for sense #1 and #2 of street .
 confirm the human annotator X  X  choice, accept the SSI interpretation, or assess the se-mantic interconnection patterns resulting from different sense choices (reported in the left pane of Figure 1).

SemCor corpus are tagged with the first sense of street [defined as a thoroughfare (usually the thoroughfare between the sidewalks. Though questionable, this is a subtlety made explicit in the dictionary and reinforced by the usage example of sense #2 above. The tool reflects this fact, showing that both senses are connected with other word senses in context, the first sense having a smaller degree of overall connectivity. (b) Motorcycle: a motor vehicle with two wheels and a strong frame human annotators assigned the first sense to the word frame ( a structure supporting or containing something ), unintentionally neglecting that the dictionary encodes a specific shape ),andisalsopartofa motor vehicle#1 . While regular polysemy holds between sense #1 and #6, there is no justification for the former choice, as it does not refer to vehicles at all (as reflected by the lack of semantic interconnection patterns concerning frame#1 ). The tool applies the validation policy and suggests sense #6 to the validator. although acceptable, choices made by human annotators due, among others, to the fine granularity of the sense inventory and to regular polysemy. In Section 4 we present an experiment showing that this claim still holds on a larger scale. subtle distinctions, like those encoded in WordNet, are rarely useful in any NLP appli-cation, but, as a matter of fact, WordNet is at the moment the de facto standard within the research community, as no other computational lexicon of that size and complexity is freely available. 3.2 Validating Automatic Annotations
While the task of manual annotation is mostly restricted to lexicographers, automatic annotations of texts (especially Web pages) are gaining a huge popularity in the Seman-tic Web vision (Berners-Lee 1999). In order to perform automatic tagging, one or more word sense disambiguation systems are applied, resulting in a semantically enhanced resource. Unfortunately, even when dealing with restricted sense inventories or selected domains, automated systems can make mistakes in the sense assignment, also due to the difficulty in training a supervised program with a sufficient number of annotated instances and again the fine granularity of the dictionary inventory.
 consistent choice of senses throughout the discourse, a desirable condition for guaran-teeing semantic coherence. For example, semantic interconnections can help deal with instance the sentence from the Senseval-3 English all-words competition: (c) The driver stopped swearing at them, turned on his heel and went back to heel#6 is part of a driver#5 ). This can be a reasonable choice for a word sense disam-biguator, but the overall semantic graph exposes a poor structural quality. A different choice of senses pointed out by Valido ( driver as an operator of a vehicle and heel as 3.3 Weaknesses of the Approach
It can happen that semantic interconnection patterns proposed by the validation tool used to extract patterns like those in Table 1. In that case, the validator is expected to be inconsistent with the lexicon structure. Typical examples are: (d) A payment was made last week. (e) I spent three days in that hospital .
 act of paying money (sense #2). Such regular polysemy makes it hard to converge on a sense choice for payment in sentence (d). This difficulty is also manifested in the anno-tations of similar expressions involving make and payment within SemCor. Furthermore, 278 apart from the distinction between the act of doing the action and the amount of money paid, there are not many structural suggestions that allow us to distinguish between the two senses. Semantic interconnection patterns cannot help the validator here, but any choice will not violate the structural consistency of the lexicon. As for sentence (e),
WordNet encodes two senses for hospital : the building where patients receive treatment in that here WordNet encodes much information about both senses, but such  X  X oisy X  knowledge does not help discriminate. As a result, a number of semantic interconnec-tion patterns are presented to the validator, indicating the relevance of both senses for tagging, but no evidence in favor of the choice of sense #1 (which is most appropriate in the sentence). 4. Evaluation
We performed an evaluation of the tool on SemCor (Miller et al. 1993), a selection of documents from the Brown Corpus where each content word is annotated with concepts (specifically, synsets ) from the WordNet inventory.
 documents in the SemCor corpus. The average ambiguity of an arbitrary word in the sentence was 8 . 70.
 s w { s annotators agree on which sense to assign to all the words but one, where one annotator provides an appropriate sense and the other selects a different sense. The random factor guarantees an approximation to the uniform distribution in the test set of all the possible degrees of disagreement between sense annotators (ranging from regular polysemy to homonymy).
 ated the performance of the tool in suggesting the appropriate choice for the words with disagreement. We assessed precision (the number of correct suggestions over the overall number of suggestions from the Valido tool), recall (the number of correct suggestions over the total number of words to be validated), and the F1 measure adverbs, as very few interconnections can be found for them). The experiment shows good F1 measure, especially for nouns and verbs, beating the random baseline of 50%).
Notice that this test differs from the typical evaluation of word sense disambiguation tasks, like the Senseval exercises (http:/ /www.senseval.org), in that we are assessing highly polysemous (possibly, very fine grained) words. Comparing the results with a smart baseline, like the most frequent sense heuristic, is not feasible in this experiment, as the frequency of WordNet senses was calculated on the same data set (i.e., SemCor).
Notice anyway that beating a baseline is not necessarily our objective if we are not able to provide justifications (like semantic graphs) of which the human validator can take advantage in order to take the final decision.
 is due to a lack of connectivity in the lexical knowledge base, especially when dealing with connections across different parts of speech. This is a problem already discussed in
Navigli and Velardi (2005) and partially taken into account in Navigli (2005). Valido can indeed be used as a tool to collect new, consistent collocations that could grow the LKB from which the semantic interconnection patterns are extracted, possibly in an iterative process. We plan to investigate this topic in the near future. 5. Conclusions
In this article we discussed a tool, Valido, for supporting validators in the difficult task of assessing the quality of both manual and automatic sense assignments. The validator can analyze the correctness of a sense choice in terms of its structural semantic inter-connections (SSI) with respect to the other word senses chosen in context. The use of semantic interconnection patterns to support validation allows one to smooth possible divergences between the annotators and to corroborate choices consistent with the LKB.
Furthermore, the method is independent of the adopted lexicon (i.e., WordNet), in that patterns can be derived from any sufficiently rich ontological resource. Moreover, the semantic graphs analyzed in a number of experiments helped us find out that a Swiss horse should be a kind of horse, that carelessness is not a kind of attentiveness, but rather the contrary, and so on. These inconsistencies of WordNet 2.0 were promptly reported to the resource maintainers, and most of them have been corrected in the latest version of the lexicon.
 during the annotation phase by taggers looking for suggestions based on the structure of the LKB, with the result of improving the coherence and awareness of the decisions to be taken.
 References 280
