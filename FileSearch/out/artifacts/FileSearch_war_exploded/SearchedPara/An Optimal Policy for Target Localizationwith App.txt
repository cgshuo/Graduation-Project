 Raphael Sznitman raphael.sznitman@epfl.ch Ecole Polytechnique Federale de Lausanne, Switzerland Aurelien Lucchi aurelien.lucchi@epfl.ch Ecole Polytechnique Federale de Lausanne, Switzerland Peter I. Frazier pf98@cornell.edu Cornell University, Ithaca, NY 14850, USA Bruno M. Jedynak bruno.jedynak@jhu.edu Johns Hopkins University, Baltimore, MD 21218, USA Pascal Fua pascal.fua@epfl.ch Ecole Polytechnique Federale de Lausanne, Switzerland We consider the problem of quickly identifying the lo-cation and size of an object of interest by asking a series of questions about the region it occupies. This is key to speeding up the imaging of target objects, such as intracellular structures, when using scanning electron microscopes (SEM), which can focus resources on promising areas (Lucchi et al., 2011; Veeraragha-van et al., 2010). In this application, asking a ques-tion involves acquiring image data over a portion of the capture area and feeding it to a classifier that re-turns an estimate of the presence of a target within the queried region. This data can be either acquired quickly, which degrades the reliability of the estimate, or slowly, which severely impacts overall acquisition time.
 While both image acquisition and classification are subject to noise, requiring the use of statistical in-ference to estimate the target X  X  location, the heart of this work lies in the Decision Problem of what ques-tions to ask to localize the target efficiently. As in Active Learning (Dasgupta et al., 2007; Castro et al., 2005; Settles, 2009) and Sequential Experimental De-sign (DeGroot, 1970; Wetherill &amp; Glazebrook, 1986; Berry &amp; Fristedt, 1985; Srinivas et al., 2010), the de-cisions can be made adaptively, which may increase efficiency but makes the optimal decision policy more difficult to find.
 In this paper, we formulate this problem in a Bayesian framework and explicitly characterize the globally Bayes-optimal policy. Furthermore, we prove that, somewhat surprisingly, the greedy, or one-step looka-head, policy is in fact Bayes-optimal over arbitrary time horizons. The greedy policy is easy to com-pute, which is beneficial in many time-sensitive and computationally-limited applications. This optimality result is in contrast with other solutions to Bayesian active learning problems, where the greedy policy is suboptimal and can only serve as a heuristic (Brochu et al., 2009; Zhang et al., 2003).
 We demonstrate the effectiveness of this optimal greedy policy in the context of SEM imaging, where our results show that images of desired quality at tar-get locations are acquired in half the time required by other state-of-the-art methods.
 Akin to this work, (Jedynak et al., 2011) considers a related target localization task and shows that the greedy policy is also Bayes-optimal over any time hori-zon. The current work differs from the latter by con-sidering that the target X  X  = ( X  X  1 ,X  X  2 ) covers an in-terval within the search space, rather than a single point. It also differs in that questions with a variety of noise models and costs are available, while (Jedynak et al., 2011) only considered questions with a single homogeneous cost and noise model. Both aspects are important in the SEM application treated here. This paper is organized as follows: Sec. 2 surveys the related literature. Then in Sec. 3, we explicitly formu-late our problem and objective, and then present our main theoretical result in Sec. 4. In Sec. 5, we detail an embodiment of our policy in the context of SEM imaging, experimentally validating our approach and we conclude with final remarks in Sec. 6. A substantial amount of literature exists in active learning (Dasgupta et al., 2007; Srinivas et al., 2010; Castro et al., 2005; Settles, 2009) and sequential ex-perimental design (DeGroot, 1970; Wetherill &amp; Glaze-brook, 1986; Srinivas et al., 2010). Within this broad literature, many authors have considered Bayesian for-mulations (Brochu et al., 2009; Zhang et al., 2003; Chick &amp; Frazier, 2012 ; Gittins &amp; Jones, 1974) and it is well-known that the Bayes-optimal policy for a problem in sequential experimental design is the so-lution to a partially observable Markov decision pro-cess (POMDP), which is characterized by the dynamic programming equation. In a few cases authors have applied dynamic programming to explicitly calculate Bayes-optimal sequential policies for specific problems (Berry &amp; Fristedt, 1985; Gittins &amp; Jones, 1974; Chick &amp; Frazier, 2012). In many problems, however, comput-ing the Bayes-optimal sequential policy is considered to be intractable, leading many authors to use greedy policies as heuristics (Brochu et al., 2009; Zhang et al., 2003).
 Another line of closely related research is the Twenty Questions literature. The original Twenty Questions game and its noise-free answers has long been asso-ciated with notions in Information Theory (Cover &amp; Thomas, 1991) and dichotomous search. Later on, a number of works looked at cases where an unknown but bounded number of questions could be answered incorrectly, and where bounds can be computed in some of these cases (Spencer &amp; Winkler, 1992; Dhagat et al., 2004). Related to this work, is that of Dis-tilled Sensing (Haupt et al., 2011), where sparse tar-gets in white Gaussian noise were shown to be reliably found using an adaptive-sampling scheme. More re-cently, (Jedynak et al., 2011) showed that when all an-swers are noisy, with a symmetric noise model, choos-ing questions that include half the probability mass of the posterior distribution yields a globally optimal strategy with regards to the entropy after a finite num-ber of questions. This policy, more generally known as the probabilistic bisection search was first proposed by (Horstein, 1963). A number of other works have also analysed its performance, or the performance of closely related policies, under different conditions and measures of uncertainty (Castro &amp; Nowak, 2007; Ben-Or &amp; Hassidim, 2008; Novak, 2008; Chakraborty et al. , 2011; Waeber et al., 2011). In this work, we extend in the direction of (Jedynak et al., 2011) and consider the situation where X  X  is an interval (as opposed to an unconstrained parameter) and where multiple ques-tion types with varying costs can be used to optimize an entropy-based objective. Consider the continuous random vector of dimension two, X  X  = ( X  X  1 ,X  X  2 ). We denote p 0 = p 0 ( x 1 ,x the joint probability density function of X  X  and we X 1  X  X X  X  represents an interval of length | X  X  differential entropy of p 0 (or of X  X  ) is then the quan-tity, H ( p 0 ) =  X  where log is the logarithm base 2. Note that H ( p 0 ) is not necessarily positive.
 Weconsideracollectionofquestionsoftheform X  X s a  X  X  X  1 and X  X  2  X  b ? X ,indexedby a and b ,andwhere anoisyanswertothisquestionisobservedinsteadof thetrueone.Inaddition,weassumethatthereisin factafinitecollectionofsuchquestions,orquestion types ,foreachpair( a,b ).Askingaquestionoftype k , inducesaspecificcost W ( k ),andtheamountofnoise intheobservedanswersalsodependsonthetype k .
 Typically,thehigherthecost,thelowerthenoiselevel. Moreformally,aquestionisspecifiedbyatuple ( a,b,k ),with0 &lt;a&lt;b&lt; 1andatype k  X  X  1 ,...,K } . Agivenfunction k  X  W ( k )  X  R definesthecostofa questionoftype k .Thetrueanswertoaquestionisde-noted Z ( a,b,k ),where Z ( a,b,k )=1when a  X  X  X  1 and X 2  X  b ,and Z ( a,b,k )=0otherwise.Here,weassume that Z ( a,b,k )isunobserved,butthatanoisyver-sion, Y ( a,b,k )isobservedinstead.Wetreat Y ( a,b,k ) asacontinuousrandomvariablewhosedensitygiven Z ( a,b,k )=1isdenoted f k 1 = f k 1 ( y )andwhosedensity given Z ( a,b,k )=0isdenoted f k 0 = f k 0 ( y ).Notethat thequestiontypesareassumedtoaffecttheamount ofnoiseobservedinanswers,andhencenoisemodels ( i.e. f k 1 and f k 0 )areindexedby k .Intheinformation theoryliterature,themapping Z ( a,b,k )  X  Y ( a,b,k ) definesa(noisy)communicationchannelwithbinary inputalphabet.Suchachannelisassociatedwitha channelcapacity whichdefinesthemaximumamount ofinformationthatcanbetransmittedthroughthis channel(Cover&amp;Thomas, 1991).Thechannelcapac-ityisinthiscaseascalarintherange[0;1],wherethe minimumvalue(=0)isachievedwhen f k 0 = f k 1 and themaximalvalue(=1)isachievedwhen f k 0 and f k 1 havedisjointsupport.
 Wewillconsiderasequentialaccumulationofques-tionsandanswers.Welet X n =( a n ,b n ,k n )denotethe questionaskedattime n ,andlet Y n = Y ( a n ,b n ,k n ) denotethecorrespondinganswer.Startingwithan initialdistributionon X  X  (whichis p 0 ),thefirstques-tionandanswerare X 0 =( a 0 ,b 0 ,k 0 )and Y 1 = Y ( X 0 ), respectively.Theposteriordensityof X  X  given X 0 ,Y 1 isdenoted p 1 .Proceedingthisway,thehistoryof questionsandanswers,uptothe n th question,is denoted B n = { X 0 ,Y 1 ,...X n  X  1 ,Y n } .Weassume that Y 1 ,...,Y n areconditionallyindependentgiven Z ( X 0 ) ,...,Z ( X n  X  1 ),sothatifthesamequestionis askedmultipletimes,potentiallydifferentanswersare generatedduetonoise.Then,theposteriordensity of X  X  given B n isdenoted p n andcanbecomputed recursivelyusingBayesformulae, where F n ( a n ,b n )= p n ( a n  X  X  X  1 ,X  X  2  X  b n ), Q = F thelineovertheevent a n  X  u 1 ,u 2  X  b n indicatesthe complementofthatevent.From(2),weseethatthe density p n ismultipliedbyaconstantfactoroverthe domain { ( u 1 ,u 2 ); a  X  u 1 ,u 2  X  b } andbyanothercon-stantfactoroverthecomplementofthisdomain,cre-atingakindof X  X arthquake X  X othesurfacedefinedby p .Themagnitudeofthisearthquakedependsonhow different f k n 0 ( y )and f k n 1 ( y )arefromeachother. Objective: Inwhatfollows,afterhavingobserved theanswersto n questions,weareinterestedinhaving gainedinformationabout X  X  .Thiswillbequantified by H ( p n );lowervaluesbeingpreferable.Wearealso interestedinthecost(ortime)paidforachievingthis informationgain.Thisisquantifiedbythesumofthe costs(ortimes)ofeachquestion; T n = n  X  1 i =0 W ( k i ). Tocastthisproblemintotheclassicaldynamicpro-grammingsetting,wedefineavaluefunction,
V ( p,n,t )=inf where  X   X  0isaconstantusedtomodulatethe relationbetweenentropyandcost.Apolicywhich achievesthisvalueisconsideredoptimal.TheOpti-malityPrinciple(Dynkin&amp;Yushkevich, 1979),allows ustore-writetheabovevaluefunctionrecursively, V ( p,n,t )=inf wheretheoptimizationisnowonlyoverallpossible questions X n andtheexpectationisovertheanswers that may arise from the question X n . One great ben-efit of the recursive definition of the value function is that a policy which attains its minimum, for all n , p , and t , also attains the minimum of (3). With the goal of solving (3), this section begins by demonstrating how to solve the much simpler, one-step lookahead problem. The derived greedy policy is then shown to be optimal with respect to (3).
 First, we define some notation. Let  X  ( u,k ) = H ( uf k used later to quantify the mutual information, and let G ( u,k ) =  X  ( u,k )  X   X W ( k ), which is called the In (Jedynak et al., 2011), it was shown that u 7 X   X  ( u,k ) is concave, and thus this maximum is attained. Let u  X  k be the value of u attaining this maximum given k .
 We now state the following lemma, which solves the one-step lookahead problem, and thus implicitly de-fines the greedy policy.
 Lemma 4.1. For each n , min Moreover, any X n = ( a n ,b n ,k n ) attaining the min-imum in (5) satisfies F n ( a n ,b n ) = u  X  k be written as where I ( X  X  ,Y n +1 | X n ,p n ) is the mutual information between X  X  and Y n +1 given the history B n and the question X n (using the notation of (Cover &amp; Thomas, 1991)). Since H ( p n ) and T n do not de-pend on X n , (5) is equivalent to H ( p n ) +  X T n  X  sup X Letting u = F n ( a n ,b n ), we rewrite the mutual in-see that I ( X  X  ,Y n +1 | X n ,p n )  X   X W ( k n ) =  X  ( u,k  X W ( k n ) = G ( u,k n ). Hence, (5) is equivalent to Since X  X  is a continuous random vector, F n ( a n ,b n ) is a continuous function of ( a n ,b n ), and there is at least one pair ( a n ,b n ) for which F n ( a n ,b n ) = u this value for F n ( a n ,b n ), the optimal value of k Given the greedy policy defined in the previous lemma, we may now verify that it attains the minimum in (4), for each n .
 Theorem 4.2. Any policy that chooses each X n = ( a n ,b n ,k n ) to satisfy, F n ( a n ,b n ) = u  X  k and k ditionally, for each n , the value function is Proof. We proceed by backwards induction. At n = N the value function has the claimed form, and the optimal policy makes no decision, and so the claimed form for the optimal policy also holds, vacuously. For n &lt; N , we assume that the value function and optimal policy are of the form claimed at n + 1. Then, V ( p n ,n,T n ) = inf = inf = inf = H ( p n ) + T n  X  G  X   X  ( N  X  n  X  1) G  X  = H ( p n ) + T n  X  ( N  X  n ) G  X  , which is the claimed form for the value function at time n . In this sequence of equations, we used Lemma 4.1 to show that the infinimum in (7) has the form claimed on the next line. Moreover, the same lemma also shows that the infimum in (7) is attained by an X n satisfying the form claimed in the statement of the theorem, and thus, by the dynamic programming optimality princi-ple, this X n is the decision of the optimal policy at time n . Thus, by induction, the claimed form for the value function and optimal policy hold for all n . Given this last result, we have obtained an optimal policy which is also a greedy policy and hence easy to implement. It allows one to balance entropy and time for localizing an interval on a number line. Note that a single type of question, which can be computed beforehand, is used at all steps of the optimal policy. In this section, we apply our main result from Sec. 4 to a real-world application. We consider the problem of acquiring as fast as possible SEM images that are sharp at locations of interest and potentially blurrier elsewhere, and where the speed gains come from not spending imaging resources on uninteresting regions. For many biologists, SEM offers the ability to acquire detailed images of intra-cellular structures at nm res-this microscope uses an electron beam to sweep the surface of a tissue block, line-by-line, many times. At each pixel location, the average response is computed and used to produce a precise image for the user. The tissue surface is then sliced off the tissue block, and the process is repeated on a newly visible surface. While this process produces image stacks of invaluable worth, doing so is extremely time consuming, i.e. 48 hours for a 10  X m 3 tissue volume.
 Moreover, for many users, imaging the entire block accurately is unnecessary. Instead, they may only be interested in obtaining high resolution images at lo-cations of specific structures of interest. For exam-ple, mitochondria are organelles that occupy less than 8%-10% of a tissue sample and have been linked to a number of diseases. Visualizing their development is highly relevant to understanding the progression of illness and recovery. As such, we demonstrate in this section, that images with good resolution at mitochon-drion locations can be acquired much faster by our proposed policy when compared to current microscope policies. The remainder of this section details the em-bodiment of our policy within this context. 5.1. Formulation We let each slice of a tissue block be composed of a fixed number of strips : S = { S 1 ,...,S T } , where S t I is a gray scaled image to be imaged (30  X  960 pixels, policy of Sec. 4 on a strip by strip basis.
 On each strip, we are looking for a mitochondrion, denoted by X  X  = ( X  X  1 ,X  X  2 )  X  S t and which is re-stricted to be at locations { 0 , 2 d  X  1 } , with d = 5, such that each discrete location defines a 30  X  30 pixel region of the strip ( i.e. X  X  1 is the starting point and X  X  2 the end point of the target on one strip). Here, X  X  is a discrete random variable with density p ( u 1 ,u 2 ) ,u 1 ,u 2  X  X  0 , 2 d  X  1 } and where p 0 ( u for u 1 &gt; u 2 . The questions are denoted by X n ( a n ,b n ,k n ) , 0  X  a n  X  b n  X  2 d  X  1, where ( a n ,b are integers, k n  X  { 1 ,..., 4 } for 0  X  n  X  N . The answers Y n +1 are computed by first scanning the re-gion interval ( a n ,b n ), W ( k n ) times. From this, each pixel location of the interval ( a n ,b n ) receives W ( k values, which are averaged to form a noisy image de-question score, denoted y n +1  X  R . In the follow-ing subsection we detail how these scores are com-puted and what their associated noise models are. The cost associated with a question type k n is as follows: W (1) = 4 ,W (2) = 20 ,W (3) = 40 and W (4) = 60. Given that X  X  is now a discrete, and not a continuous random variable, we are no longer guaranteed to al-ways find an interval question satisfying F n ( a n ,b n ) = u previous section no longer holds. To approximate the optimal policy in this context, we select the available interval and question type that maximizes the gain function G ( u,k ) instead and compute this by perform-ing a brute force search over the ( a,b,k ). 5.2. Image Observation and Noisy Channels Given a sampled image, I a,b,k , we must evaluate a question score: y n +1 . To do this, we first evaluate if each 30 by 30 pixel block of I a,b,k is part of a mito-chondrion or not. This is achieved by first dividing a block into nine 10 by 10 regions, computing an inten-sity histogram from the center region and constructing another intensity histogram from the combined eight neighbouring regions. These histograms are concate-nated and then evaluated with a two-class RBF kernel SVM. Having done so for every block in I a,b,k , the proportion of locations where the SVM has returned 1, that is the positive class, is returned.
 Given that the number of scans performed, W ( k n ), induces significantly different noise levels in I a,b,k separate SVM must be learned and used for images with W ( k n ) scans. Each SVM was trained using five, 1032  X  1032 pixel images, where an expert provided mitochondria groundtruth segmentations.
 Learning observation models: Recall from Sec. 3 that the answer Y n +1 comes from one of two possible observation sources: f k 1 or f k 0 . We model both of these to be Gaussian with parameters (  X  k 1 , X  k 1 ) and (  X  k respectively and where the parameters are estimated from the same training data used to train the SVMs. To estimate these for any value k , we randomly gen-erated 2000 intervals ( a,b ) for each image, evaluated X = ( a,b,k ) and computed the corresponding scores from the 2000 intervals. Using the scores and the mi-tochondria expert segmentations, we then computed the parameters for f 0 and f 1 using maximum likeli-hood estimation. Finally, estimating the  X  ( u,k ), was achieved by Monte Carlo simulation and we have plot-where  X  = 4 . 5  X  10 4 (which is task specific), G (  X  ,k ) can be maximized when k = 4 or 20 ( i.e. using 20 scanswhen0 . 15 &lt;u&lt; 0 . 88andusing4scansoth-erwise)andusingotherscanningquantitieswouldbe sub-optimal. 5.3.Algorithm Theproposedpolicycanbecastasa hypothesis-and-test algorithm.Foreachstrip,weevaluatethealgo-rithmoutlinedinAlg. 1.Bytheendoftheprocedure, wereturntheposteriordistribution, p N andthesetof imageobservations, { I a Giventhatforthefirststrip S 1 ,noinformationon thetargetlocationisknown,weassign p 0 tobea discreteuniformprobabilitydistributionintherange (0,31).Thisinitialpriorindicatesthatthetargethas equalchanceofbeinganywhere.However,onceastrip hasbeenprocessedwithAlg. 1,wemaintainthepos-teriordistributionanduseitasinitialpriorforthe subsequentstrip.Thatis,theposteriorcomputedaf-ter N questionsonstrip S t ,isthethepriorusedfor strip S t +1 .Giventhatmitochondriaare2Dobjects (even3Difthevolumeistakenintoaccount),and donotmovesignificantlyfromonestriptoanother, reusingthecomputedposteriorsfrompreviousstrips effectivelyencodes2Dspatialinformation.
 Notethatinpracticemultipleornomitochondriamay Algorithm1 FastStripImaging( N,p 0 ,W, X  ) 1: for n =0 ,...,N do 2: { a n ,b n ,k n } =argmax a,b,k {  X  ( F n ( a,b ) ,k )  X  5: Computeposteriordistribution p n +1 using(2) 6: endfor bepresentonastrip.Todealwiththis,weusethe sameapproachasin( Sznitman&amp;Jedynak, 2010)and extendthehypothesisspaceof X  X  suchthatanad-ditionalpointmassindicatesthatthetargetisnot presentinthevisibledomain.Formultipletargets,we applynon-maximumsuppression(onboththeimag-ingdomainandthedensity)toregionsthathavebeen observedmorethananumberoftimes( i.e. 600scans) andproceeduntil n = N . 5.4.Experiments Wevalidateourapproachbyevaluatingourpolicy againstwhatistypicallypossiblewithcurrentmicro-scopes,andasimilarpolicytothatin( Jedynaketal., 2011)whichdoesnottakeintoaccounttimecosts.
 Thestandardpolicyscanseachlocationoftheblock surfaceafixednumberoftimes,andaveragesthere-ceivedvaluesateachlocation.Foranyscanningpol-icy,wemayquantifyitsperformanceby1)theaverage scanningtimeperpixeland2)theper-pixelestimated intensityvalueatmitochondrionlocations(measured bythePeakSignal-to-NoiseRatio(PSNR)andthe averageproportionoferrorperpixel, i.e. thediffer-encebetweenthetrueandestimatedintensityvalues, dividedbythetrueintensity).
 Welettheentropy-costfactor  X  =4 . 5  X  10 4 when evaluatingeachstripandwillvarythenumberofit-erations, N .Onceasurfaceimaged,theprocessis repeatedonthenextsurface. 5.4.1.SEMDataandImagesampling UsinganSEM,wefirstcollectedfiveimagesofsize 1032  X  1032pixels,using600scans,ofarodentbrain tissue.Theseimageswereusedfortrainingpurposes. Wethencollected160,1500  X  960imageswith600 scans(whichwhenstackedformsavolume)fortest-ingpurposes.Onboththetrainandtestdata,mi-tochondrialocationswerehandsegmentedbyanex-pert.Giventhatcurrentmicroscopesareincapable ofstoringimagesacquiredwithdifferentscancounts forentirevolumes,thefollowingscheme(similarly to( Sznitmanetal., 2012; Veeraraghavanetal., 2010)) wasusedtoacquiredatawith W ( k )scansattesttime .
 Onasinglesurface,wefirstcollected60imagesac-quiredwith10scanseach,andnotethatthecorre-sponding600scanimageistheper-pixelaverageof the60images,whichwedenote  X  p forpixel p .The standarddeviationofthepixelintensityobserved,de-notedby  X  p ,canbeestimatedasfunctionofthetrue pixelintensity,  X  p = m X  p + b ,where m and b arelinear regressionparametersandwereestimatedfromthis data.Then,withanimageof600scans,andassum-ingaGaussianmodelforthepixelintensityvalues, wecangenerateanimagewith W ( k )scansbysam-pling G (  X  p ,m X  p + b ), W ( k )times,andaveragingthe receivedvalues.Thisgeneratingprocessisusedtocre-atesamplenoisyimagesinAlg. 1 (line 3). 5.4.2.Results The X  X cannedImage X  X fFig. 3 showsanexampleofa producedimageusingourapproach.Thisimagewas producedbyspendingonly280scansperpixelonav-erage,asopposedtothetraditional600.Mitochondria locationsareshowninred,andlookingcloselyatthe indicatedyellowboxes,whichhavebeenblown-upon theleft,wenoticethattheimagenoiseatmitochondria locationsisnoticeablylowerthaninotherregions.To furthershowthis,the X  X ogPixelError X  X fFig. 3 shows thelogpixeldifferencebetweenthetrueandproduced image.Darkerregionsindicatelowerpixelerror.Sim-ilarly, X  X erPixelScanCount X  X fFig. 3 showshow manytimeseachpixelwasscanned.Noticethatin bothcasesthemitochondrialocationscorrelatehighly withlowpixelerrorandlargescancounts.Submitted withthismanuscript,asupplementaryvideoshowsthe algorithmasitproceedstoscananentireimage,strip bystrip.Wealsoshowavisualevolutionoftheposte-riordistributionaftereachiterationandtheproduced image.
 Weevaluatedeachapproachonthe160testimages, whichconsistsofrunningourpolicy8000times.Quan-titatively,ourpolicyimprovesonthetimenecessary toacquireimagesofequalqualityatmitochondrialo-cations,ascanbeseenfromTable. 1.Infact,innearly halfofthetimetypicallytaken,weacquiretheimages ofnearlyequalqualityatmitochondrialocations.In practice,thisspeedupwouldallowabiologisttoscan a10  X m 3 tissuevolumeandverifyahypothesisinone dayinsteadoftwo.Inaddition,weseethebenefitof includingtimecostinourobjectivefunction,aswe outperformintimeandaccuracythecasewhere  X  =0 and W ( k )=60.
 Finally,inadditiontohavinghighqualityimages,bi-ologistsareofteninterestedinextracting3Dsegmen-tationsofmitochondriainordertobettervisualtheir 3Dstructure.Onemethodtodothisautomatically istousetheMRFmethodof(Lucchietal., 2011), andwhichwehaveappliedtotheimagestackspro-ducedbyourscanningpolicy.Usingthefirst80im-agesforMRFtraining,weevaluatedtheremaining 80images.Wereportthatwhenimaginingwith600 scans,segmentationsof98%accuracy(andaPASCAL VOCscoreof83%)areachieved,whileourpolicy,in half that time, produces segmentations of 97% accu-racy (and a PASCAL VOC score of 81%). Please visit http://cvlab.epfl.ch/ ~ sznitman for additional re-sults and videos. This paper considered the task of finding a target when making a finite number of sequential observation, N , by evaluating intervals of chosen length, position and type. With the constraint that observations are always noisy, and that different types of questions may induce different costs, we have presented a Bayes optimal pol-icy for an entropy-cost based objective function. The use of our optimal policy, which has the particular-ity of being greedy, is demonstrated in the context of localizing mitochondria in SEM images. We show ex-perimentally that our policy provides significant speed ups in image acquisition while maintaining near equal image quality at target locations, when compared to current policies.
 This work was funded in part by the ERC MicroNano Grant. Peter Frazier acknowledges support from NSF Award 142251 and AFOSR Award FA9550-11-1-0083.
