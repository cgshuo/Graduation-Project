 1. Introduction
Current industrial development imposes an increasing demand of advanced control techniques which guarantee processes opti-mal working. Most of the available controlling algorithms are based on the existence of a model of the plant to be controlled. In these cases, the accuracy of this model is a deciding factor in the final performance. Many industrial processes are nonlinear and data are corrupted by significant noise; these issues may hinder the modelling process both in data-based identification and in first-principle modelling.

The delivery of a reliable mathematical representation of the plant behaviour, which accurately models the important dynamics around the operating range, is a difficult task. In some cases, the system can be represented by a linear model, as complex as the controller design methodology needs. The term identification for control ( Gevers, 1993 ; Van den Hof and Schrama, 1995 ) arose to deal with several issues concerning identification as a tool for control design: which is the frequency range of interest, which is the optimal complexity of the model, which is the optimal experiment (open/closed loop, online/off-line, selec-tion of plant input), etc. This is also a field of active research at present (see, for example Bombois et al., 2006 ; Gevers, 2005 ;
Hjalmarsson, 2005 ; Hildebrand and Solari, 2007 ). However, most of the above contributions are focused on linear systems, so they may fail when the issue is to obtain a model for a nonlinear plant.
Apart from the above difficulties in plant identification, using arbitrary nonlinear models to compute controllers might also encounter difficulties unless they are expressed in particular canonical forms.
 Neural networks ( Hagan et al., 2002 ; Hunt et al., 1992 ; Narendra and Parthasarathy, 1990 ) are widely used in industrial and Lightbody, 2008 ) and control purposes ( Haber and Alique, Yue et al., 2007 ; Zerkaoui et al., 2009 ). Neural networks have the ability to approximate complex nonlinear relationships without prior knowledge of the model structure (black-box models), what makes them an attractive alternative to the classical modelling and control techniques.

Given the above-mentioned difficulties in obtaining a suitable process model, plus the difficulties of finding a nonlinear con-troller for the found model, a tempting alternative is to use the available experimental data to directly tune some controller parameters. This gives rise to the direct data-based controller design approaches. Some of the most popular ones are the iterative feedback tuning (IFT) for linear systems ( Hjalmarsson et al., 1998 ) or nonlinear ones ( Sj  X  oberg et al., 2003 ), the correlation-based reference feedback tuning (VRFT).

Virtual reference feedback tuning (VRFT) is a model-free one-shot direct controller tuning methodology, introduced by Campi et al. (2002) for the linear case and extended to nonlinear systems in Campi and Savaresi (2006) . It is  X  X  X odel free X  X  because it does not need any mathematical description of the plant to be controlled (under some assumptions and approximations). It is  X  X  X ne-shot X  X  because it can be applied using a single set of data generated by the plant (a second one is needed if the data are collected in closed loop and corrupted by significant noise, see
Campi et al., 2002 ), with no need for specific experiments or iterations (which makes VRFT different and easier to apply than
IFT). Enhancements and remarks to the basic setting were proposed in Sala and Esparza (2005a) and Sala (2007) . If several experiments are possible, performance-improving iterations can be set up ( Campi and Savaresi, 2006 ; Sala, 2007 ).

The model-free nature of VRFT makes it appealing for practical plant model is needed to propagate gradients in order to achieve unbiased convergence ( Campi and Savaresi, 2006 ) if the controller parameterisation is not powerful enough. In fact, correct applica-tion of the methodology would require simultaneous plant and controller identification ( Sala, 2007 ). However, as models are only an instrument to compute gradients, if the nonlinear controller parameterisation is flexible enough, large modelling errors will still lead to almost-optimal controller parameters.

The objective of this contribution is to adapt the recent VRFT results to controllers incorporating neural networks. Prior experi-ments with nonlinear VRFT and neural networks are reported in
Previdi et al. (2004) . However, the correct computation of the gradients requires backpropagation through time ( Werbos, 1990 ), which was not carried out in the cited reference, in which it was also used a very simple linear-in-parameter neural network with least-squares fit.

This paper considers a generic virtual reference tuning (VRT) methodology, which includes open-loop ( v irtual reference feedfor-ward tuning or VRFFT) and closed-loop ( virtual reference feedback tuning or VRFT) setups. It discusses the computation of some required gradients via backpropagation through time and, addi-tionally, shows the achieved improvements over the standard 1-degree of freedom control loop when auxiliary sensors are used.
The methodology is tested by simulation on a crane model. An approximate linear model of the plant will be used to improve gradient computations, identified from the same available input X  output data later on being used to identify the controller.
The structure of the paper is as follows: Section 2 presents a brief exposition of control structures using neural networks, with the objective of comparing them with VRT approach. Then, VRT principles, both in the open-and closed-loop setups are exposed in Section 3. Sections 4 and 5 are the main contributions, as they present a nonlinear VRT approach using neural networks, devel-oping a simulated application example using two particular neural network controller structures, one of them with an addi-tional sensor. The contribution ends with the conclusions drawn from this work. 2. Preliminaries: neural networks for control
Neural networks are universal approximators able to approx-imate complex nonlinear relationships without prior knowledge of the model structure. Fig. 1 shows the use of neural networks as function approximators. The objective is to adjust the network X  X  parameters in such a way that, using the same input, its output (predicted output) is as close as possible to the output of the unknown function to be modelled. Neural networks have been used not only for identifying nonlinear plants but also for controlling them.

There are two basic network architectures, namely the feed-forward networks (FFNN), also called multilayer networks, and the recurrent ones (RNN) ( Hagan et al., 2002 ; Liu, 2001 ; Narendra and Parthasarathy, 1990 ). The former represents static mappings whereas the latter are inherently dynamic. Training FFNN is simpler (standard backpropagation, for instance, see Werbos, 1990 ) than RNN which require dynamic backpropagation algo-rithms ( Hagan et al., 1999 ; Narendra and Parthasarathy, 1990 ;
Wan and Beaufays, 1996 ). Note, however, that in many cases, such as the VRT one in this paper, dynamic backpropagation may be needed with FFNN when they are part of a larger dynamic system.

In the literature (see for example Hagan et al., 2002 ; Kasparian and Batur, 1998 ; Narendra and Parthasarathy, 1990 ), several struc-tures are used to control a nonlinear system by means of neural networks. The neural controller can either act as a feedforward controller or as a feedback one. Some of the most popular proposals on both situations will be briefly reviewed next. 2.1. Feedforward structures: neural inverse control
The main idea of inverse control is to determine the inverse of the plant and then use it as a controller. Two approaches can be followed to account for this: direct inverse control and feedforward direct control ( Narendra, 1996 ).

Fig. 2 shows the structure of the so-called direct inverse control using neural networks, where M is the reference model.
The neural network NN C is trained to model the inverse plant dynamics, as seen in Fig. 3 , using the error signal e IM stands for the  X  X  X nverse model error X  X . Once this is done, NN placed in series with the plant, being its input the desired behaviour y d (see Fig. 2 ).

The feedforward inverse control scheme is depicted in Fig. 4 .In this case, two neural networks are used. NN 1 is first trained to mimic the plant behaviour, using the prediction error e M
Then the neural controller NN 2 is trained so that ( NN 2 approximates the identity. Note that the error signal e C used to adapt online the controller NN 2 .

The feedforward scheme has several disadvantages. Of course, the first one is that it cannot be used with open-loop unstable plants. Furthermore, if the nonadaptive scheme is the one to be used, as the control is carried out in open loop, disturbances and modelling errors will degrade the system X  X  performance. r 2.2. Feedback neural model reference control Neural model reference control structure is depicted in Fig. 5 .
Its adaptive version (i.e., updating the controller at every sample) is a particular case of model reference adaptive control (MRAC). In
Fig. 5 , the signal e C is used either to train or adapt online the weights of the neural controller NN C . From a theoretical point of view, there are two approaches used to design a MRAC control for an unknown plant: direct and indirect control.

Direct control : This procedure aims at designing a controller without having a plant model. As the knowledge of the plant (or at least of an approximation of its mathematical description) is needed in order to train the neural network which corresponds to the controller ( NN C ), the problem of directly training NN complex one. Indeed, the closed-loop stabilisation of the (unknown) plant must be first assured. In Lightbody and Irwin (1995) , for example, this is carried out by placing a linear fixed-gain controller in parallel with the neural network to be trained.
More recently, Kumar et al. (2009) have dealt with this problem, developing a particular direct neural model reference adaptive control, the structure of which is depicted in Fig. 6 . In this particular case, the stabilisation of the plant has been carried out by training off-line the neural network, using Lyapunov-based synthesis and the data collected from the reference model and the unknown plant. Once trained, the neural controller NN C is adapted online to improve performance.

Indirect control : This approach uses two neural networks: one for modelling the plant dynamics ( NN M ), and another one ( NN adjusted to control the real plant so as its behaviour is as close as possible to the reference model M . This scheme is represented in Fig. 7 . As a first step, the neural network NN M is trained to approximate the plant input/output relation using the signal e is habitual to use a FFNN architecture to model the plant dynamics, as simple backpropagation algorithms can be used to train the network. This is usually done off-line, using a batch of data collected from the plant in open loop. Once the model network NN M is trained, it is used to train the network NN will act as the controller. NN C can be either FFNN or RNN, as in both cases dynamic backpropagation is needed. In order to back-propagate the gradients, the model NN M is used rather than the plant G , which is unknown. Then, as NN M is fixed, its derivatives with respect to any parameter are known and easy to compute when training NN C . See, for instance, Narendra and Parthasarathy (1990) for details.

There are other neuro-control paradigms, such as reinforcement learning ( Sutton and Barto, 1998 ), sliding controllers ( Baruch, 2007 ; Kar and Behera, 2009 ), neural feedback-predictive control ( Hagan and Demuth, 1999 ; Hagan et al., 2002 ), etc. Neural net-works appear as well as elements in higher-level learning frame-works. There are also other NN topologies (CMAC, neuro-fuzzy, Elman, etc.). Liu (2001) , for example, provides a more extensive description of the different structures and applications of neural networks and a larger amount of references. As the aforementioned options are not used for the proposals in this paper, the reader is referred to the cited references for further details. 3. Virtual reference tuning
Virtual reference tuning (VRT) is a data-based direct controller design methodology, which, under certain assumptions, does not need a plant model to obtain a controller which aims at achieving a control loop X  X  performance as close as possible to a reference model. The tuning may be for open-loop, closed-loop or even other block-diagram structures. The bibliography is quite extensive concerning a closed-loop setup (known as VRFT methodology), both for the linear and nonlinear cases. The reader the methodology. In this section, a generic framework of VRT will be outlined.

Let us denote by G the unknown plant to be controlled and let us consider that a first open-loop experiment carried out on it gives a set of input/output data named { u ex , y ex }. The  X  X  X irtual reference X  X  trick consists in, given a (usually linear) invertible reference model M , generating the following  X  X  X irtual X  X  signal: r  X  M 1 y ex  X  1  X 
Using this signal, called virtual reference , a virtual  X  X  X erfect X  X  loop can be constructed. 1 The idea can be applied both in feedforward and feedback loops. Figs. 8a and 9a show its application in open-and closed-loops, respectively. These two particular structures will be named virtual reference feedforward tuning (VRFFT) and virtual reference feedback tuning (VRFT), respectively.

In both cases, C n stands for an unknown controller, the output of which is u ex itself (and therefore, the plant X  X  output will be y
In the virtual closed-loop ( Fig. 9 a) appears an additional signal, called virtual error , which is defined as e  X  X  M 1 1  X  y ex  X  2  X 
These loops are called virtual because they do not exist and therefore they are not used to generate the data { u ex , y
Obviously, both virtual loops achieve y ex  X  Mr v , i.e., they work  X  X  X erfectly as desired X  X , and the input signals to the controller ( r open-loop and e v in closed-loop) and the plant ( u ex ) are known.
Within this environment, the controller design problem is reduced to an identification problem between the signals r u  X  in VRFFT  X  or e v and u ex  X  in a VRFT setup. Identification is usually carried out by considering a parameterised controller or e in a feedback one).
 On the sequel, the parameterised controller will be denoted by
C  X  x  X  . The ideal controller C n fulfills u ex  X  C  X  x  X  , with x  X  r
VRFFT and x  X  e v in VRFT, but it will be, possibly, nonlinear and high-order. As C y a C (actually, at startup C y will likely be very when a particular y is used, y y , will differ from the ideal one
Mr
The cost index to minimise in the identification procedure is, then, chosen to be the squared Euclidean norm (denoted by of the (possibly filtered) difference between the actual output of the loop y y , and the ideal one y ex :
J  X  1 J F  X  y y y ex  X  J 2  X  3  X 
In the expression above F is a frequency-weighting filter chosen by the designer and y y is the actual plant output which, in an open-loop setting (see Fig. 8 b) is defined as y  X  G  X  C y  X  r v  X  X  X  4  X  and in a closed-loop setting ( Fig. 9 b): y  X  G  X  C y  X  e y  X  X  X  5  X 
In this latter expression e y  X  r v y y is the (nonvirtual) tracking error.

In the remainder, the filter F will be considered the identity, for simplicity. Another sensible choice in practice would be a low-pass filter, disregarding loop errors above a predefined band-width; the role of F is analogous to the sensitivity weight in mixed-sensitivity design ( Skogestad and Postlethwaite, 2007 ). As the plant G is not known, it is not possible to minimise (3).
So, the VRT methodology proposes the following data-based cost indexes for VRFFT and VRFT, respectively: VRFFT : J VRFFT  X  1 2 J L  X  C y  X  r v  X  u ex  X  J 2  X  6  X 
VRFT : J VRFT  X  1 2 J L  X  C y  X  e v  X  u ex  X  J 2  X  7  X  where L is a linear time-variant filter designed so as to make the solution to the minimisation of (6) and (7) as close as possible to that of (3). Note that indexes (6) and (7) only use available data u ex , r v and e v , contrarily to (3) which uses the noncomputable y y .

In a general framework, which accounts both for linear and nonlinear cases, in order to minimise a cost index, under differ-entiability assumptions, most optimisation algorithms use its gradient with respect to its parameters. In particular, the gradi-dJ d y  X  y y y ex , dJ d y  X  L  X  C y  X  r v  X  u ex  X  , L dJ d y  X  L  X  C y  X  e v  X  u ex  X  , L where / , S represents the scalar product and @ C y =@ y is the partial derivative of the controller with respect to its parameters. Then, the minimisation of J VRFFT (in an open-loop setting) or J (in a closed-loop setup) will be closer to that of J as the gradient in (9) or (10), respectively, approximates more accurately the gradient in (8). As it was carried out for the linear case in Campi derived so as to make the gradient of J VRFFT or J VRFT a good approximation of the gradient of J .

Neither sides of the scalar product of expression (8) are computable, as the plant model G is not known. So it is necessary to express this gradient as a function of both the actually recorded tence of an ideal y , which is the vector of parameters which makes u ex  X  C  X  y , r v  X  in VRFFT, or u ex  X  C  X  y , e v value, for y close to y , the following approximations of the left part of expressions (8), (9) and (10) can be considered: y y
VRFFT : L  X  C y  X  r v  X  u ex  X  C L @ C y
VRFT : L  X  C y  X  e v  X  u ex  X  C L @ C y
Then, the problem will be solved if we find a filter L which approximates dy d y because in that case (11) will resemble (12) or (13) and, subse-quently, the gradients (8) will be close to (9) or (10): optimisation based on the latter gradients will approximately optimise the cost (3).

In some cases, there are some linear time-invariant approx-imations for L , see Campi and Savaresi (2006) and Sala and
Esparza (2005a) . In the neural case, the filter L will be a time-varying system obtained via backpropagation through time, as discussed in the next section.

The basics of the gradient propagation are as follows: con-sidering a system G , which can be linear or nonlinear, its output, when the plant X  X  input is u y , can be calculated as y y  X  G  X  u the derivative of y y with respect to the controller parameters can be expressed as dy d y  X  G where G is an operator used to express the (possibly time-variant) plant model partial derivative with respect its input, which in this particular case is u y , i.e.:
G  X  @ G
Then, the total derivative du y = d y will depend on the gradient of the controller parameterisation @ u y =@ y and the gradients of controller inputs.

Usually, the loops involving plants and controllers are recur-rent dynamical systems (at least in VRFT), so dynamic back-propagation ( Narendra and Parthasarathy, 1990 ) must be used to compute both G and du y d y . As backpropagation through time requires the knowledge of both the plant model and the controller structure, its derivation will be tackled in next section, where we will particularise it to a neural network controller in a predefined block diagram in order to compute an expression for filter
L above. 4. Neural virtual reference tuning
VRT applications have been largely studied in linear cases (under the assumption of a linear plant and controller, an approximation to the filter L in (9) or (10) can be found which does not depend on the model) and in closed-loop setups.
Successful applications of purely linear VRFT are reported, for instance, in Campi et al. (2003) . Furthermore, linear VRFT has proven to work even when the plant is nonlinear, whenever the nonlinear plant X  X  dynamics is not strongly relevant (see, for example Previdi et al., 2004 , 2005 ).

Obviously, when significantly nonlinear behaviour of the plant is strongly excited, a nonlinear controller can likely achieve a better performance.

In this section we will consider the nonlinear VRT setup, using neural networks for the controller. The reasons for the choice of neural networks are well-known: their capability to approximate nonlinear functions (universal function approximation property) along with the ease of computing its derivatives for parameter adjustment. Note, however, that choosing the network topology and the number of parameters must deal with problems such as the need of a large number of data and a large number of iterations, overfitting, etc. These issues are very relevant for any neural network engineering application, and not specific to the control structure here presented; the reader is referred to authoritative sources such as Hastie et al. (2001) for in-depth discussion.

Contributions Previdi et al. (2004 , 2005) have also used neural networks along with VRFT. In these cases, a particular feedfor-ward neural structure, using radial basis neurons was used and compared to a PID controller, the parameters of which were tuned using linear VRFT methodology. Taking these previous results into account, the contribution proposed in present paper is double: on the one hand, the usage of recurrent neural networks trained using dynamic backpropagation of the gradients and, on the other hand, the proposal of using additional sensors which may improve the closed-loop performance. Indeed, any feedback block diagram is amenable to dynamic backpropagation, so once the virtual reference is generated, other options apart from the pure feedforward and pure feedback are possible, as this paper exemplifies.

In this section, VRFFT and VRFT will be tackled separately, to obtain for each case a particular expression of the linear time-variant filter L which approximates the gradient of J Next, a discussion about the obtention of G will follow, finish-ing the section with an extension of the methodology to other block diagrams, as, for example, when additional sensors are available.

In this contribution, the developments will stop at the point when formulae  X  using the partial derivatives of the controller output with respect to controller inputs  X  and parameters are obtained. Discussion on how to obtain such partial derivatives is omitted, as it is well discussed since early backpropagation literature ( Narendra and Parthasarathy, 1990 ). 4.1. Virtual reference feedforward tuning
The open-loop controller implementation will now be consid-ered. In this case, the virtual loop is an open-loop one ( Fig. 8 a), where r v is the virtual reference, calculated using expression (1). The controller must be directly identified from r v and u this, the gradient in (9) must be approximated to the gradient in (8). In the previous section it was shown that this problem will be solved if we find a linear time-variant filter L which makes expression (14) true.

Let us consider as the starting point expression (15), where G is defined in (16). There are several ways of obtaining G , depend-ing on the plant model X  X  structure. Usually, both plants and controllers are described by dynamical difference equations, i.e., the actual output depends not only on the present inputs but also on an amount of past input and output values: y  X  G  X  u k , u k 1 , ... , u k q , y k 1 , ... , y k v  X  X  17  X  u  X  C  X  y , r k , r k 1 , ... , r k m , u k 1 , ... , u k n where u , y are the plant X  X  input and output signals, y is the and output signals, respectively. Note that the argument y has been removed from u and y to improve clarity.

Considering the plant model in expression (17), to compute G , it is necessary to apply the chain rule: dy d y  X  which is a linear recurrent equation (and time-variant if G is nonlinear in y or u ). This expression can be represented in a block diagram, as in Fig. 10 .

As G is a linear time-variant system, the derivative in (15) must be computed at each time instant, i.e.: dy d y  X  G where, as before, the argument y has been omitted. Using this expression, where G is defined by the recursive equations in (19) and represented graphically in Fig. 10 , to compute the gradient of
J it is then necessary to obtain an expression which relates du with @ C y =@ y . For a recurrent controller (defined in expression (18)), applying the chain rule (and noting that the controller X  X  input r v does not depend on y ), we obtain du d y  X  @ C y @ y  X 
Expressions (19) and (21) are the sensitivity equations defin-ing a recurrent linear time-variant system, being @ C y =@ y and dy = d y its input and output, respectively. Fig. 11 represents such sensitivity equations computed at the instant k . In such figure, both the block diagram input @ C y =@ y and the output dy are vectors of size p (the number of parameters y ) and G is defined in Fig. 10 . 4.2. Virtual reference feedback tuning
In this subsection, a closed-loop setup will be considered. The virtual closed loop built using the reference model M and the between this setting and the previous one is the existence of feedback, and hence the controller X  X  input is the closed-loop error.
In the virtual loop this input is the virtual error e v and in the e  X  r v y y . The plant structure is the same described in (17), so
G , represented by expression (19) and in Fig. 10 , is the same both for VRFFT and VRFT. However, as the controller X  X  input is different, its output is defined as u  X  C  X  y , e k , e k 1 , ... , e k m , u k 1 , ... , u k n where the argument y has also been omitted for u and e .
The objective is still finding the linear time-variant filter L which approximates the gradient of J VRFT in (10) to the gradient of
J in (8). This is the same issue that, starting from expression (20), to (22): du d y  X  @ C y @ y which are linear recurrent equations (and time-variant if C is tive with respect to the vector of parameters is de i = d y  X  dy as r does not depend on y .

Expressions (19) and (21) are therefore the sensitivity equa-tions defining a recurrent linear time-variant system, whose input is @ C =@ y . Fig. 12 represents such sensitivity equations computed at the instant k . In such figure, both the block diagram X  X  input @ C =@ y and output dy y = d y are vectors of size p (the number of parameters y ). Evidently, such a system should be the filter L in (10).

As it can be seen, this filter is linear time-variant, so its length). Expression (19) shows the explicit dependence of the filter L on G , which represents the plant model linearised at each time instant around its operating point.
 du d  X  4.3. Obtention of G
The dependence of L on G (both in VRFFT or in VRFT) shows the necessity of a plant model to propagate the gradients. And, indeed, the computation of G or an approximation of it ( G )is needed. A discussion on how to solve this problem follows.
Let us consider a plant with unknown dynamics G , which could be either linear or nonlinear with smooth nonlinearities.
The objective is to design a controller which minimises the cost index J defined in (3) through the minimisation of the data-based one J VRFFT in (6) or J VRFT in (7).

As highlighted in the previous subsections, a linear time-variant filter L is needed both in J VRFFT and J VRFT in order to approximate their gradients to the gradient of J . Such a filter requires obtaining a time-variant linearisation of the plant model at each time instant and at each input value, i.e., to obtain its Jacobian, which we have called G .

As the plant model is not known, the instrumental G should be approximated. There are several ways of handling the issue:
The first approach could be carried out, for example, by training (off-line) a neural network to accurately approximate the plant dynamics, which would then adapt the indirect model reference control scheme in Section 2 to the virtual reference framework. In this case, the approximation G of G can be obtained with relative ease, as the needed derivatives of the neural network with respect to its inputs are easy to compute.

A second possibility involves identification of (purposedly) only an approximate reduced-complexity model of the plant.
An appealing choice is a linearised plant model, which will be denoted by ^ G , identified using standard linear ID techniques.
A last possibility would be disregarding the model and assuming G equal to the identity.

Note that the approximation G of G is only needed as part of the filter L , which is used to make the minimisation of J close to that of J . If the controller parameterisation is flexible enough and the real controller is within the controller class J enough controller does not need a model in VRFT (nor it does in
VRFFT). The lower the controller class flexibility is, the more important role G plays in the accuracy of the identified controller. Given the above considerations, in practice, some successful applications have been reported with L  X  I or simple models of the plant.

In the proposal of this paper, the second option will be chosen, used. In this case, G  X  ^ G , and then expression (20) turns into: dy d y  X  4.4. Using additional measurements in VRFT
In some cases, the use of additional measurements can improve the control loop X  X  performance, if a good choice of additional sensors is used ( Skogestad and Postlethwaite, 2007 ; Sumana and Venkateswarlu, 2009 ).

The last contribution in this section is to develop a generic algorithm to backpropagate the gradients through the closed loop when the information from additional sensors is used to improve performance. Let us consider the closed loop depicted in Fig. 13 , where a single-input-multiple-output (SIMO) plant has been the subindex Ny stands for the number of plant X  X  outputs. In this figure, the controller X  X  inputs are a function (either linear or nonlinear, time-variant or time-invariant) of the plant X  X  outputs. To simplify the development, time-invariant functions f i plant X  X  outputs will be assumed.

Considering a recurrent controller, its output at a time instant k is u  X  C  X  y , f 1  X  y 1 , k  X  , ... , f 1  X  y 1 , k m 1  X  , ... , f
The derivative of the controller X  X  output with respect to the vector of parameters is in this case: du d y  X 
These linear (possibly) time-variant recurrent equations are the generalisation of (23). Indeed, expression (23) is obtained from (26) when Ny  X  1, y  X  y 1 and f 1 ( y 1 )  X  r v y 1 . Using this generalisation, and the linear approximation of G discussed in the previous subsection, expression (19) can be expressed as 0 B B @ and output y i obtained using common identification algorithms (or, in a general case, the differential map of a nonlinear model, as discussed before). 4.5. Stability
As in most identification-based approaches, stability cannot be guaranteed because the data used for model estimation may be incorrect or noisy and the controller order may be too low to capture all the relevant dynamics. Only with unrealistic  X  X  X nfinite data X  X  and  X  X  X rue plant in the model set X  X  assumptions, convergence to the optimal model (controller, in the VRFT case) would be possible.

From that assumptions, some heuristic tests may be carried out in order to increase the likelihood of a successful design:
Choosing a suitable reference model. The reference-to-output behaviour is also indicative of tolerance to multiplicative modelling error. Some approximate heuristics (low gain at frequencies where signal-to-noise ratio is low, etc.) might guide the choice of the reference model.

Identifying a plant model. Indeed, with the same set of data used for virtual controller tuning, a plant model may be identified. Formal analysis or simulation tests based on the acquired model might help in detecting possible instability. In a nonlinear case, formal analysis may be difficult, however.

Cautious controller modification. If a stabilising controller is known, small-gain inequalities ( Skogestad and Postlethwaite, 2007 ) may be used in the linear case to determine a bound for the new controller X  X  parameters in order to keep stability. Such bounds do not hold in the neural case but, for instance, evaluating them based on controller and auxiliary model X  X  linearisations might be useful. In successive (off-line) itera-tions, once the parameters from the original stabilising controller have reached the robustness bound, a new online experiment would be advisable.
 Identifying other  X  X  v irtual  X  X  transfer functions. As suggested in
Sala and Esparza (2005a) , the transfer function between r 0  X  C 1 u  X  y and u may be identified and its stability char-acteristics are used to validate the controller. It is straightfor-ward in SISO linear cases but generating the controller inverse in the neural case is unclear and, hence, the previously considered options seem to be better than this last one. 4.6. VRFT versus adaptive control
Both VRFT and adaptive approaches design controllers based on experimental data. VRFT uses the data in an off-line way without the controller in operation, whereas adaptive control operates with the adapted controller being online.

Fixed versus time-varying controller. The advantage of VRFT over adaptive control is that the resulting controller can be tested for different stability and performance requirements before it is placed in the loop (even if, in the nonlinear case, most of the times such tests would require simulation studies). On the other hand, adaptive controllers may undergo continuous changes which make the closed-loop behaviour difficult to predict in practice.
Performance analysis. From a theoretical point of view, adaptive control proves, in most cases, that some error signals are bounded and, under some excitation conditions, the state converges to zero. It is somehow difficult to evaluate the step-response, disturbance rejection, alternative controller structures, in an adaptive approach. Also, in many cases adaptive approaches assume that the full system state is measured with no noise in order to update regressors. In summary, most adaptive approaches do not explicitly try to optimise the referred step or frequency characteristics of the loop error and the theory (for nonlinear cases) does not consider a possibly noisy output feed-back. On the other hand, VRFT allows for detailed analytical or simulation studies with the resulting fixed controller.
Reduced-order models or controllers. VRFT uses models as instrumental variables to compute gradients. The complexity of such models is not so relevant and, in fact, if the controller is flexible enough simple models will suffice to synthesise a high-performance VRFT controller. In model-based designs or in adaptive approaches, a simple low-order model might miss too much unmodelled dynamics to be useful.

VRFT is able to synthesise suboptimal reduced-complexity controllers with a structure chosen at will (albeit if the structure is not flexible enough, a nonstabilising controller may be the result). Adaptive controllers usually must have a predefined structure of a similar complexity to that of the plant being controlled.

As a conclusion of this subsection, adaptive and VRFT approaches have a different set of underlying assumptions and goals. Even if in time-varying plant cases with good measure-ments adaptive control might be a better choice, in the authors X  opinion, VRFT may be an attractive option in applications given the above considerations for time-invariant plants in which a fixed reduced-order controller is desired and a sufficiently exciting experiment can be carried out. 4.7. Summary: step-by-step procedure
Based on the above discussion, the following step-by-step procedure is suggested towards implementation of neural virtual reference tuning strategies. 1. Collect input X  X utput data from a plant G . 2. Identify an instrumental plant model G . 3. Select a reference model M . As a suggestion, the character-istics of G might guide the selection of a sensible M , see Sala and Esparza (2005b) . 4. Generate the virtual reference signal r v  X  M 1 y ex . 5. Generate the virtual controller inputs (depending on the choice of feedforward/feedback structure, additional sensors, etc.). 6. Choose a controller parameterisation (type of approximator  X  multilayer neural in this work  X  and number of parameters). 7. Generate training/test sets for generalisation validation. 8. Obtain the gradient of the VRT cost index by using dynamic backpropagation ( Fig. 11 or 12 ), replacing the real plant by the linearised instrumental model (but, importantly, using the actual original input output data). Use the gradient in any gradient-based optimisation algorithm (pure gradient, momentum, Levenberg X  X arquardt, etc.). 9. Iteratively repeat the previous step until the cost index value converges to a (possibly local) minimum, i.e., when some well-known stopping criteria are hit. 10. Validate the learning procedure (for instance, with separate training/test sets, etc. see Hastie et al., 2001 for options). If results are not correct, change initial parameter values, training algorithm, the number of training data or the number of adjustable parameters and repeat the above optimisation. 11. Test for stability by simulating the resulting controller with the instrumental plant model; test for some performance properties by simulation or by linearisation of the resulting closed-loop. If results are not satisfying, select a different reference model or a different controller parameterisation and repeat some of the above steps. 12. Test the resulting controller on the actual plant. 13. If stable, use the new gathered data jointly with the previous ones and repeat from step 2 in order to refine the result, if so wished, with a more exact tracking of M or a new M with higher performance. If unstable, select a different reference model and controller parameterisation. 5. Case study: neural VRFT applied to a simulated crane model
In this subsection, a particularisation of the above explained methodology will be used to design a controller for a crane model operating under closed loop. 5.1. Preliminaries
This plant has two measured outputs: the hanging mass
The objective is to control y 1 . The choices made in this particular application are the following ones:
The controller will be operating in closed loop, so the VRFT methodology will be applied.

In Campi et al. (2002) , Campi and Savaresi (2006) and Sala (2007) , some approximations are carried out, in order to use a time-invariant transfer function L 0 and make the minimisa-tion process easier. In this work, the implemented filter L will be the time-variant one defined by Eqs. (27) and (26), as the required partial derivatives are easily computed for neural networks.

G will be approximated by a linear plant model ^ G , identified using standard OE prediction error algorithms. It will be only used as an instrument to build the time-variant filter L .
The controller will be implemented by a neural network, the weights of which have to be adjusted conveniently.
 controller C 2 is more powerful, as it has as an extra input a function of the system X  X  output y 2 . The extra input will provide better performance, when compared to C 1 , as discussed next.
In this particular application, for the controller C 1 , Ny  X  1 and f ( y 1 )  X  e  X  r v y 1 . On the other hand, for the controller C f
Fig. 12 and defined in Eqs. (24) and (23). For the controller X  X  structure C 2 , expression (27) gets converted into 0 @ the outputs y 1 and y 2 with the input u , respectively. In the same way, Eq. (26) turns into du d y  X 
The neural networks to be used are made up of two layers: the first one has four neurons (one linear and three with hyperbolic tangent activation function); the second layer has only one linear neuron. A bias input to each neuron is also present. For the controllers of class C 1 , the network considered is the one depicted in Fig. 15 . In this figure, the inputs u and e stand for vectors conforming a delay-line input: if the controller order considered is n and the number of delayed inputs is m , at a time instant k , u present value of the signal and its output is a vector of x elements, made up of the present value and the past ones, as shown in Fig. 16 . In the same way, the network used for the C 2 -class controllers is the one in Fig. 17 , where f ( y 2 )  X  sin( y added as a new network X  X  input. 5.2. Simulation results
As mentioned above, neural VRFT is applied to a crane model, depicted in Fig. 14 , where the plant X  X  input ( u ) and outputs ( y 1 and y 2 ) are indicated.

Simulation model and parameters : A first-principle model for simulation was found in ( Butler et al., 1991 ), being the para-meters values: Mass of the cart ( M ): 2 kg.
 Hanging mass ( m ): 1 kg.

Length of the joining bar ( L ): 0.5 m.
WI
WI WI Linear friction coefficient ( fc ): 0.05 Ns/m.
 Angular fiction coefficient ( fp ): 0.01 Ns.

As the actual model equations are not relevant to the data-based controller tuning procedures here demonstrated, the reader is referred to the above reference for details. However, an important feature of the (linearised) model when the output is y 1 is the presence of a pair of complex zeros close to the imaginary axis.
Even in a linear case, as following a reference model implies inversion of the system, such a zero will be a pole of the controller: its presence will lead to control action (and angle) oscillations which take a long time to settle. Such behaviour can also be easily expected from physical insight.

Controller expression and parameterisation : Using the neural network controller structure depicted either in Fig. 15 or 17 , the control action at an instant k can be computed as u  X 
In the above expression, F i is the hyperbolic tangent for i  X  {1,2,3} and identity for i  X  4 (linear neuron), n is the number of delays in the inputs (the same value for all the inputs has been considered), Ny  X  1 for the neural network structure of Fig. 15 and
Ny  X  2 for the one in Fig. 17 . In addition, x k is the input vector, constructed as x for Ny  X  1. For Ny  X  2, this expression turns into x where s k  X  sin( y 2 k ), i.e., the sine of the angle y 2
Finally, in expression (30) the indexes i and j stand for the neuron number and the input position in x k . Therefore, denoting by N the number of neurons ( N  X  4 in this example), the vector of parameters has  X  n  X  Ny  X  1  X  X  2  X  N  X  1 elements, and is defined as b I 1 ... b I N W O 1 ... W O N bO T  X  31  X 
Simulation scenarios : The objective of the application is to design a controller for the crane system in such a way that the controlled output y 1 follows as closer as possible a reference that goes from 0 to 1 m following a ramp with different slopes: from 0.04 to 1 m/s.

First of all, the linear version of VRFT has been applied, as this particular system presents a smooth nonlinearity which allows linear controllers to be used for low angles (slow cart speed).
Then, in order to compare and to improve the closed-loop tracking performance, both neural network structures ( Figs. 15 and 17 ) have been considered as the controller X  X  class to be used when applying nonlinear VRFT.

As the main nonlinearity in the system equations comes from trigonometric expressions depending on the angular position and speed, two situations have been envisaged: 1. A first simulation tries to adjust VRFT controllers (linear and neural) based on a set of open-loop data where the angular displacements are small. 2. A second simulation scenario uses open-loop data where angular displacements are significantly higher, due to a larger input amplitude.
WI
Intuitively, it is expected that linear and nonlinear VRFT controllers behave similarly in the first case (the nonlinearity is barely excited), but nonlinear ones improve in the second one where the nonlinearity is significant. Let us discuss each of the simulations.

Low-amplitude training data : A first open-loop experiment with a white noise input in a range of 7 0.1 N produces the signals depicted in Fig. 18 . The observed angle variation is very low ( 7 0.02 rad), so the nonlinear effect is not present.
 A linear sixth-order controller, as well as a neuronal one (type
C ), also with sixth-order delay-line inputs, are trained from the same data set.

For a slow reference change (a slope of 0.04 m/s during the transient, taking 25 s to change from zero to one), both linear and neural network controllers work well and produce a very similar output. The linear controller produces a better performance in the position of the bottom tip, which is the variable being considered in the cost index (3); indeed the big oscillations in the pendulum X  X  input and angle (see Fig. 19 ) seem to indicate that the linear VRFT controller has learned how to totally cancel the weakly damped zero dynamics.

It is foreseeable that, as long the reference X  X  slope increases, both controllers work worse, as the higher speeds of movements will demand a larger control action, and this will produce bigger beyond that learnt by the controllers identified using the weakly exciting signals in Fig. 18 .

Indeed, this is exactly what happens. When the reference X  X  slope increases, the linear controller provides a better tracking performance (the more reduced number of parameters seems to make learning more effective) until a slope of 1 m/s, when it makes the loop unstable, whereas the one using a neural network provides the response in Fig. 20 . However, the stability of the neural controller might come from pure chance (likely) or from the fact that it might have learned a somehow relevant repre-sentation of the nonlinearity.

In order to try to increase the performance in the fast-setpoint-change case, two fourth-order controllers are designed and retrained using the closed-loop error and the sine of the bar X  X  angle as inputs (the number of parameters is, hence, intentionally kept the same as in the previous example). The linear VRFT controller still produces an unstable loop, whereas the neural network one does not improve significantly over the one in Fig. 20 (results not shown for brevity). In fact, as commented above, such improvement cannot truly be expected as the data are not informative enough.

High-amplitude training data : For comparison, the signals recorded at a second open-loop experiment, with a white noise input in a range of 7 1N( Fig. 21 ), are used to design linear and neural network controllers, using either (a) only the closed-loop error or (b) this error together with the sine of the pendulum X  X  angle as inputs. All these controllers resulted in unstable loops, except the fourth-order neural network one with error and angle feedback (class C 2 ). Fig. 22 shows the closed-loop behaviour when using this neural network controller for a fast-varying reference of slope 1. The speed of the response is faster than the one obtained with the controllers from low-amplitude data. However, some of the oscillations in the control action (which are intui-tively expected, as previously in the linear case, due to the low-damped zero dynamics) remain in the output: the transient is better but the steady state is not. uex (N) y2ex (rad) y1ex (m)
Control action
Reference and
Control action
Reference and
Note : the linear controllers have been identified using output-error algorithms available in Matlab s  X  X  Identification Toolbox.
The neural network parameters have been adjusted using the Levenberg X  X arquardt ( More, 1977 ) optimisation algorithm, applied to minimise the index J by means of the time-varying gradient expressions derived in the previous sections. 6. Conclusions
This paper compares  X  X  X lassical X  X  neural network control struc-tures with nonlinear VRT ones, both in open-and closed-loop setups (VRFFT and VRFT, respectively). It is shown that successful application of the VRT paradigm to neural controllers is possible, by propagating gradients through time using an approximate linear model of the plant. Such model is instrumental, only used in a filtering stage and its accuracy becomes less relevant as the parameterisation of the controller is more flexible allowing for a lower minimum approximation error.

In simulations, and due to its clear advantages, the closed-loop approach has been the only one considered. They show that, under demanding specifications, linear VRFT controllers yield unstable loops while nonlinear neural ones plus additional sensory feedback provide a satisfactory response. The results were achieved without the need of any nonlinear plant modelling or identification: only a linear output-error estimated model was used.
 Acknowledgements
A. Esparza is grateful to the project GVPRE/2008/116 financed by Generalitat Valenciana. The authors are also grateful to the financial support of Grants dpi2008-06731-c02-01, dpi2011-27845-c02-01 (Spanish Government) and prometeo/2008/088 (Generalitat Valenciana).
 References
Control action (N)
Angle (rad)
Reference and output (m) uex (N) 3.14 3.3 y2ex (rad) y1ex (m)
