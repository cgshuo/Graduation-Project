 In tasks such as sensor placement for environmental temperature monitoring or experimental de-sign, one has to select among a large set of possible, but expensive, observations. Often, there are several different objective functions which we want to simultaneously optimize. For example, in the environmental monitoring problem, we want to minimize the marginal posterior variance of our temperature estimate at all locations simultaneously. In experimental design, we often have uncer-tainty about the model parameters, and we want our experiments to be informative no matter what the true parameters of the model are. These problems can be interpreted as a game: We select a set of observations (sensor locations, experiments), and an adversary selects an objective function (location to evaluate predictive variance, model parameters etc.) to test us on. Often, the individual objective functions (e.g., the marginal variance at one location, or the information gain for a fixed set of parameters [1, 2]) satisfy submodularity , an intuitive diminishing returns property: Adding a new observation helps less if we have already made many observations, and more if we have made few observation thus far. While NP -hard, the problem of selecting an optimal set of k observations max-imizing a single submodular objective can be approximately solved using a simple greedy forward-selection algorithm, which is guaranteed to perform near-optimally [3]. However, as we show, this simple myopic algorithm performs arbitrarily badly in the case of an adversarially chosen objective. In this paper, we address this problem. In particular: (1) We present S ATURATE , an efficient algorithm for settings where an adversarially-chosen submodular objective function must be optimized. Our algorithm guarantees solutions which are at least as informative as the optimal solution, at only a slightly higher cost. (2) We prove that our approximation guarantee is best possible and cannot be improved unless NP -complete problems admit efficient algorithms. (3) We extensively evaluate our algorithm on several real-world tasks, including minimizing the maximum posterior variance in Gaussian Process regression, finding experiment designs which are robust with respect to parameter uncertainty, and sensor placement for outbreak detection. Observation selection with a single submodular objective. Observation selection problems can often be modeled using set functions: We have a finite set V of observations to choose from, and a utility function F which assigns a real number F ( A ) to each A  X  V , quantifying its informa-tiveness. In many settings, such as the ones described above, the utility F exhibits the property of submodularity : adding an observation helps more, the fewer observations made so far [2]. Formally, F is submodular [3] if, for all A  X  B  X  V and s  X  V \B , it holds that F ( A X  X  s } )  X  F ( A )  X  F ( B X  X  s } )  X  F ( B ) ; F is monotonic if for all A  X  B  X  V it holds that F ( A )  X  F ( B ) , and F is normalized if F (  X  ) = 0 . Hence, many observation selection problems can be formalized as where F is normalized, monotonic and submodular, and k is a bound on the number of observations we can make. Since solving the problem (2.1) is generally NP -hard [4], in practice heuristics are often used. One such heuristic is the greedy algorithm . This algorithm starts with the empty set, and iteratively adds the element s  X  = argmax s  X  X \A F ( A X  X  s } ) , until k elements have been selected. Perhaps surprisingly, a fundamental result by Nemhauser et. al. [3] states that for submodular functions, the greedy algorithm achieves a constant factor approximation: The set A G obtained by the greedy algorithm achieves at least a constant fraction (1  X  1 /e ) of the objective value obtained by the optimal solution, i.e., F ( A G )  X  (1  X  1 /e ) max |A| X  k F ( A ) . Moreover, no polynomial time algorithm can provide a better approximation guarantee unless P = NP [4].
 Observation selection with adversarial objectives. In many applications (such as those dis-cussed below), one wants to simultaneously optimize multiple objectives. Here, we are given a collection of monotonic submodular functions F 1 , . . . , F m , and we want to solve Problem (2.2) can be considered a game : First, we (the max-player) select a set of observations A , and then our opponent (the min-player) selects a criterion F i to test us on. Our goal is to select a set A of observations which performs well against an opponent who chooses the worst possible F i knowing our choice A . Thereby, we try to find a pure equilibrium to a sequential game on a matrix, with one row per A , and one column per F i . Note, that even if the F i are all submodular, G ( A ) = min i F i ( A ) is not submodular. In fact, we show below that, in this setting, the simple greedy algo-rithm (which performs near-optimally in the single-criterion setting) can perform arbitrarily badly. Examples of adversarial observation selection problems. We consider three instances of adversarial selection problems. Sec. 4 provides more details and experimental results for these domains. Several more examples are presented in the longer version of this paper [5].
 Minimizing the maximum Kriging variance. Consider a Gaussian Process (GP) [6] X V defined over a finite set of locations (indices) V . Hereby, X V is a set of random variables, one variable X s for each location s  X  V . Given a set of locations A  X  V which we observe, we can compute the predictive distribution P ( X V\A | X A = x A ) , i.e., the distribution of the variables X V\A at the unobserved locations V \A , conditioned on the measurements at the selected locations, X A = x A . Let  X  2 s |A be the residual variance after making observations at A . Let  X  AA be the covariance matrix of the measurements at the chosen locations A , and  X  s A be the vector of cross-covariances between the measurements at s and A . Then, the variance  X  2 s |A =  X  2 s  X   X  s A  X   X  1 AA  X  A s depends only on the set A , and not on the observed values x A . Assume that the a priori variance  X  2 s is constant for all locations s (in Sec. 3, we show our approach generalizes to non-constant marginal variances). We want to select locations A such that the maximum marginal variance is as small as possible. Equivalently, we can define the variance reduction F s ( A ) =  X  2 s  X   X  2 s |A , and desire that the minimum variance reduction over all locations s is as large as possible. Das and Kempe [1] show that, in many practical cases, the variance reduction F s is a monotonic submodular function. Robust experimental designs. Another application is experimental design under nonlinear dynamics [7]. The goal is to estimate a set of parameters  X  of a nonlinear function y = f ( x ,  X  ) + w , by providing a set of experimental stimuli x , and measuring the (noisy) response y . In many cases, experimental design for linear models (where y = A ( x ) T  X  + w ) with Gaussian noise w can be efficiently solved [8]. In the nonlinear case, the common approach is to linearize f around an initial respect to the parameters  X  , evaluated at  X  0 . In [7], it was shown that the efficiency of the design can be very sensitive with respect to the initial parameter estimates  X  0 . Consequently, they develop an efficient semi-definite program (SDP) for E-optimal design (i.e., the goal is to minimize the maximum eigenvalue of the error covariance) which is robust against perturbations of the Jacobian V . However, it might be more natural to directly consider robustness with respect to perturbation of the initial parameter estimates  X  0 , around which the linearization is performed. We show how to find (Bayesian A-optimal) designs which are robust against uncertainty in these parameter estimates. In this setting, the objectives F  X  0 ( A ) are the reductions of the trace of the parameter covariance, F 0 ( A ) = tr( X  after linearization around  X  0 ; thus, F  X  0 is the sum of marginal parameter variance reductions, which are individually monotonic and (often) submodular [1], and so F  X  0 is monotonic and submodular as well. Hence, in order to find a robust design, we maximize the minimum variance reduction, where the minimum is taken over (a discretization into a finite subset of) all initial parameter values  X  0 . Sensor placement for outbreak detection. Another class of examples are outbreak detection prob-lems on graphs, such as contamination detection in water distribution networks [9]. Here, we are given a graph G = ( V , E ) , and a phenomenon spreading dynamically over the graph. We define a set of intrusion scenarios I ; each scenario i  X  X  models an outbreak (e.g., spreading of contamination) starting from a given node s  X  V in the network. By placing sensors at a set of locations A  X  V , we can detect such an outbreak, and incur a utility F i ( A ) (e.g., reduction in detection time or population affected). In [9], it was shown that these utilities F i are monotonic and submodular for a large class of utility functions. In the adversarial setting, the adversary observes our sensor placement A , and then decides on an intrusion i for which our utility F i ( A ) is as small as possible. Hence, our goal is to find a placement A which performs well against such an adversarial opponent. Hardness of the adversarial observation selection problem. Given the near-optimal perfor-mance of the greedy algorithm for the single-objective problem, a natural question is if the per-formance guarantee generalizes to the more complex adversarial setting. Unfortunately, this is far from true. Consider the case with two submodular functions, F 1 and F 2 , where the set of observa- X  times the number of t i contained in A . Similarly, if s 2  X  X  , we set F 2 ( A ) = 1 , otherwise  X  times the number of t i contained in A . Both F 1 and F 2 are submodular and monotonic. Optimizing for a set of 2 elements, the greedy algorithm maximizing G ( A ) = min { F 1 ( A ) , F 2 ( A ) } would choose However, the optimal solution with k = 2 is { s 1 , s 2 } , with a score of 1. Hence, as  X   X  0 , the greedy algorithm performs arbitrarily worse than the optimal solution. Our next hope would be to obtain a different good approximation algorithm. However, we can show that most likely this is not possible: Theorem 1. Unless P = NP , there cannot exist any polynomial time approximation algorithm for Problem (2.2) . More precisely: Let n be the size of the problem instance, and  X  (  X  ) &gt; 0 be any positive function of n . If there exists a polynomial-time algorithm which is guaranteed to find a set A 0 of size k such that min i F i ( A 0 )  X   X  ( n ) max |A| X  k min i F i ( A ) , then P = NP . Thus, unless P = NP , there cannot exist any algorithm which is guaranteed to provide, e.g., even an exponentially small fraction (  X  ( n ) = 2  X  n ) of the optimal solution. All proofs can be found in [5]. Since Theorem 1 rules out any approximation algorithm which respects the constraint k on the size of the set A , our only hope for non-trivial guarantees requires us to relax this constraint. We now present an algorithm that finds a set of observations which perform at least as well as the optimal set, but at slightly increased cost; moreover, we show that no efficient algorithms can provide better guarantees (under reasonable complexity-theoretic assumptions). For now we assume all F i take only integral values; this assumption is relaxed later. The key idea is to consider the following alternative formulation: We want a set A of size at most  X k , such that F i ( A )  X  c for all i , and c is as large as possible. Here  X   X  1 is a parameter relaxing the constraint on |A| : if  X  = 1 , we recover the original problem (2.2). We solve program (3.1) as follows: For each value c , we find the cheapest set A with F i ( A )  X  c for all i . If this cheapest set has at most  X k elements, then c is feasible. A binary search on c allows us to find the optimal solution with the maximum feasible c . We first show how the original function F i truncated at score level c ; these b F i,c functions are also submodular [10]. GPC ( F c , c)
A X  X  X  ; while F c ( A ) &lt; c do S
ATURATE ( F 1 , . . . , F m , k,  X  ) c Let F c ( A ) = 1 m P i b F i,c ( A ) be their average value; submodular functions are closed under convex combinations, so F c is submodular and monotonic. Furthermore, F i ( A )  X  c for all 1  X  i  X  m if and only if F c ( A ) = c . Hence, in order to determine whether some c is feasible, we solve a submodular covering problem : Such problems are NP -hard in general [4], but in [11] it is shown that the greedy algorithm ( c.f. , Algorithm 1) achieves near-optimal performance on this problem. Using this result, we find: Lemma 2. Given monotonic submodular functions F 1 , . . . , F m and a (feasible) constant c , Algo-rithm 1 (with input F c ) finds a set A G such that F i ( A G )  X  c for all i , and |A G |  X   X  |A  X  | , where A  X  is the optimal solution, and  X  = 1 + log (max s  X  X  P We can compute this approximation guarantee  X  for any given instance of the adversarial ob-servation selection problem. Hence, if for a given value of c the greedy algorithm returns a set of size greater than  X k , there cannot exist a solution A 0 with |A 0 |  X  k with F i ( A 0 )  X  c for all i ; thus, the optimal solution to the adversarial observation selection problem must be less than c . We can use this argument to conduct a binary search to find the optimal value of c . We call Algorithm 2, which formalizes this procedure, the submodular saturation algorithm (S ATURATE ), as the algorithm considers the truncated objectives b F i,c , and chooses sets which saturate all these objectives. Theorem 3 (given below) states that S ATURATE is guaranteed to find a set which achieves adversarial score min i F i at least as high as the optimal solution, if we allow the set to be logarithmically larger than the optimal solution.
 Theorem 3. For any integer k , S ATURATE finds a solution A S such that min i F i ( A S )  X  max |A| X  k min i F i ( A ) and |A S |  X   X k , for  X  = 1 + log (max s  X  X  P i F i ( s )) . The total number of submodular function evaluations is O |V| 2 m log( P i F i ( V )) .
 Note, that the algorithm still makes sense for any value of  X  . However, if  X  &lt; 1 + log (max s  X  X  P i F i ( s )) , the guarantee of Theorem 3 does not hold. If we had an exact algorithm for submodular coverage,  X  = 1 would be the correct choice. Since the greedy algorithm solves submodular coverage very effectively, in our experiments, we call S ATURATE with  X  = 1 , which empirically performs very well. The worst-case running time guarantee is quite pessimistic, and in practice the algorithm is much faster: Using a priority queue and lazy evaluations, Algo-rithm 1 can be sped up drastically ( c.f. , [12] for details). Furthermore, in practical implementations, one would stop GPC once  X k + 1 elements have been selected, which already proves that the optimal solution with k elements cannot achieve score c . Also, Algorithm 2 can be terminated once c max  X  c min is sufficiently small; in our experiments, 10-15 iterations usually sufficed. One might ask, whether the guarantee on the size of the set,  X  , can be improved. Unfortunately, this is not likely, as the following Theorem shows: Theorem 4. If there were a polynomial time algorithm which, for any integer k , is guaranteed to find a solution A S such that min i F i ( A S )  X  max |A| X  k min i F i ( A ) and |A S |  X   X k , where  X   X  (1  X   X  )(1 + log max s  X  X  P i F i ( s )) for some fixed  X  &gt; 0 , then NP  X  DTIME( n log log n ) . Hereby, DTIME( n log log n ) is a class of deterministic, slightly superpolynomial (but sub-exponential) algorithms [4]; the inclusion NP  X  DTIME( n log log n ) is considered unlikely [4]. Extensions. We now show how the assumptions made in our presentation above can be relaxed. Non-integral objectives. Most objective functions F i in the observation selection setting are not integral (e.g., marginal variances of GPs). If they take rational numbers, we can scale the objectives by multiplying by their common denominator. If we allow small additive error, we can approximate their values by their leading digits. An analysis similar to the one presented in [2] can be used to bound the effect of this approximation on the theoretical guarantees obtained by the algorithm. Non-constant thresholds. Consider the example of Minimax Kriging Designs for GP regression. Here, the F i ( A ) =  X  2 i  X   X  2 i |A denote the variance reductions at location i . However, rather than guaranteeing that F i ( A )  X  c for all i (which, in this example, means that the minimum variance re-duction is c ), we want to guarantee that  X  2 i |A  X  c for all i . We can easily adapt our approach to handle and then again perform binary search over c , but searching for the smallest c instead. The algorithm, using objectives modified in this way, will bear the same approximation guarantees.
 Non-uniform observation costs. We can extend S ATURATE to the setting where different observa-tions have different costs. Suppose a cost function g : V  X  R + assigns each element s  X  V a pos-A  X  = max A X  X  min i F i ( A ) subject to g ( A )  X  B , where B &gt; 0 is a budget we can spend on mak-ing observations. In this case, we use the rule  X  s  X  F c ( A X  X  s } )  X  F c ( A ) /g ( s ) in Algorithm 1. For this modified algorithm, Theorem 3 still holds, with |A| replaced by g ( A ) and k replaced by B . Minimax Kriging. We use S ATURATE to select observations in a GP to minimize the maximum posterior variance. We consider Precipitation data from the Pacific Northwest of the United States [13]. We discretize the space into 167 locations. In order to estimate variance reduction, we consider the empirical covariance of 50 years of data, which we preprocessed as described in [2]. In the geostatistics literature, the predominant choice of optimization algorithms are carefully tuned local search procedures, prominently simulated annealing ( c.f. , [14, 15]). We compare our S
ATURATE algorithm against a state-of-the-art implementation of such a simulated annealing (SA) algorithm, first proposed by [14]. We use an optimized implementation described recently by [15]. This algorithm has 7 parameters which need to be tuned, describing the annealing schedule, distribution of iterations among several inner loops, etc. We use the parameter settings as reported by [15], and report the best result of the algorithm among 10 random trials. In order to compare observation sets of the same size, we called S ATURATE with  X  = 1 .
 Fig. 1(a) compares simulated annealing, S ATURATE , and the greedy algorithm which greedily selects elements which decrease the maximum variance the most. We also used S ATURATE to initialize the simulated annealing algorithm (using only a single run of simulated annealing, as opposed to 10 random trials). S ATURATE obtains placements which are drastically better than the placements obtained by the greedy algorithm. Furthermore, the performance is very close to the performance of the simulated annealing algorithm. When selecting 30 and more sensors, S
ATURATE strictly outperforms the simulated annealing algorithm. Furthermore, as Fig. 1(b) shows, S ATURATE is significantly faster than simulated annealing, by factors of 5-10 for larger problems. When using S ATURATE in order to initialize the simulated annealing algorithm, the resulting performance almost always resulted in the best solutions we were able to find, while still executing faster than simulated annealing with 10 random restarts as proposed by [15]. These results indicate that S ATURATE compares favorably to state-of-the-art local search heuristics, while being faster, requiring no parameters to tune, and providing theoretical approximation guarantees. Optimizing for the maximum variance could potentially be considered too pessimistic. Hence we compared placements obtained by S ATURATE , minimizing the maximum marginal posterior variance, with placements obtained by the greedy algorithm, where we minimize the average marginal variance. Note, that, whereas the reduction of the maximum variance is non-submodular, the average variance reduction is (often) submodular [1], and hence the greedy algorithm can be expected to provide near-optimal placements. Fig. 1(c) presents the maximum and average marginal variances for both algorithms. Our results show that if we optimize for the maximum variance we still achieve comparable average variance. If we optimize for average variance however, the maximum posterior variance remains much higher. In the longer version of this paper [5], we present results on two more real data sets, which are qualitatively similar to those discussed here. Robust Experimental Design. We consider the robust design of experiments for the Michaelis-Menten mass-action kinetics model, as discussed in [7]. The goal is least-square parameter estimation for a function y = f ( x,  X  ) , where x is the chosen experimental stimulus (the initial substrate concentration S 0 ), and  X  = (  X  1 ,  X  2 ) are two parameters as described in [7]. The stimulus x is chosen from a menu of six options, x  X  { 1 / 8 , 1 , 2 , 4 , 8 , 16 } , each of which can be repeatedly chosen. The goal is to produce a fractional design w = ( w 1 , . . . , w 6 ) , where each component w i measures the relative frequency according to which the stimulus x i is chosen. Since f is nonlinear, f is linearized around an initial parameter estimate  X  0 = (  X  01 ,  X  02 ) , and approximated by its Jacobian V  X  0 . Classical experimental design considers the error covariance of the least squares estimate  X   X  , Cov(  X   X  |  X  0 , w ) =  X  2 ( V T  X  w which minimize this error covariance. E-optimality, the criterion adopted by [7], measures smallness in terms of the maximum eigenvalue of the error covariance matrix. The optimal w can be found using Semidefinite Programming (SDP) [8].
 The estimate Cov(  X   X  |  X  0 , w ) depends on the initial parameter estimate  X  0 , where linearization is per-formed. However, since the goal is parameter estimation, a  X  X ertain circularity is involved X  [7]. To avoid this problem, [7] find a design w  X  (  X  0 ) by solving a robust SDP which minimizes the error size, subject to a worst-case (adversarially-chosen) perturbation  X  on the Jacobian V  X  0 ; the robustness pa-rameter  X  bounds the spectral norm of  X  . As evaluation criterion, [7] define a notion of efficiency , which is the error size of the optimal design with correct initial parameter estimate, divided by the error when using a robust design obtained at the wrong initial parameter estimates, i.e., where w opt (  X  ) is the E-optimal design for parameter  X  . They show that for appropriately chosen values of  X  , the robust design is more efficient than the optimal design, if the initial parameter  X  0 does not equal the true parameter.
 While their results are very promising, an arguably more natural approach than perturbing the Ja-cobian would be to perturb the initial parameter estimate, around which linearization is performed. E.g., if the function f describes a process, which behaves characteristically differently in different  X  X hases X , and the parameter  X  controls which of the phases the process is in, then a robust design should intuitively  X  X edge X  the design against the behavior in each possible phase. In such a case, the uniform distribution (which the robust SDP chooses for large  X  ) would not be the most robust design. If we discretize the space of possible parameter perturbations (within a reasonably chosen interval), we can use S ATURATE to find robust experimental designs. While the classical E-optimality is not submodular [2], Bayesian A-optimality is (often) submodular [1, 2]. Here, the goal is to minimize the trace instead of eigenvalue size as error metric. Furthermore, we equip the parameters  X  with an uninformative normal prior (which we chose as diag([20 2 , 20 2 ]) ), and then minimize the expected trace of the posterior error covariance, tr( X   X  |A ) . Hereby, A is a discrete design of 20 experiments, where each option x i can be chosen repeatedly. In order to apply S ATURATE , for each  X  , we define F ( A ) as the normalized variance reduction F  X  ( A ) = 1 Z chosen such that F  X  ( A ) = 1 if A = argmax |A 0 | =20 F  X  ( A 0 ) , i.e., if A is chosen to maximize only F . S ATURATE is then used to maximize the worst-case normalized variance reduction. Figure 2: (a) Efficiency of robust SDP of [7] and S ATURATE on a biological experimental design problem. We reproduced the experiment of [7], where the initial estimate of the second component  X  02 of  X  0 was varied between 0 and 16, the  X  X rue X  value being  X  2 = 2 . For each initial estimate of  X  02 , we computed a robust design, using the SDP approach and using S ATURATE , and compared them using the efficiency metric of [7]. We first optimized designs which are robust against a small perturbation of the initial parameter estimate. For the SDP, we chose a robustness parameter  X  = 10  X  3 , as reported in [7]. For S ATURATE , we considered an interval around [  X  1 1+  X  ,  X  (1 +  X  )] , discretized in a 5  X  5 grid, with  X  = . 1 . Fig. 2(a) shows three characteristically different regions, A , B , C , separated by vertical lines. In region B which contains the true parameter setting, the E-optimal design (which is optimal if the true parameter is known, i.e.,  X  02 =  X  2 ) performs similar to both robust methods. Hence, in region B (i.e., small deviation from the true parameter), robustness is not really necessary. Outside of region B however, where the standard E-optimal design performs badly, both robust designs do not perform well either. This is an intuitive result, as they were optimized to be robust only to small parameter perturbations.
 Consequently, we compared designs which are robust against a large parameter range. For SDP, we chose  X  = 16 . 3 , which is the maximum spectral variation of the Jacobian when we consider all initial estimates from  X  02 varying between 0 and 16 . For S ATURATE , we optimized a single design which achieves the maximum normalized variance reduction over all values of  X  02 between 0 and 16 . Fig. 2(a) shows, that in this case, the design obtained by S ATURATE achieves an efficiency of 69%, whereas the efficiency of the SDP design is only 52%. In the regions A and C, the S ATURATE design strictly outperforms the other robust designs. This experiment indicates that designs which are robust against a large range of initial parameter estimates, as provided by S ATURATE , can be more efficient than designs which are robust against perturbations of the Jacobian (the SDP approach). Outbreak Detection. Consider a city water distribution network, delivering water to households via a system of pipes, pumps, and junctions. Accidental or malicious intrusions can cause contam-inants to spread over the network, and we want to select a few locations (pipe junctions) to install sensors, in order to detect these contaminations as quickly as possible. In August 2006, the Battle of Water Sensor Networks (BWSN) [16] was organized as an international challenge to find the best sensor placements for a real (but anonymized) metropolitan water distribution network, consisting of 12,527 nodes. In this challenge, a set of intrusion scenarios is specified, and for each scenario a realistic simulator provided by the EPA [17] is used to simulate the spread of the contaminant for a 48 hour period. An intrusion is considered detected when one selected node shows positive contaminant concentration. BWSN considered a variety of impact measures, including the time to detection (called Z 1 ), and the size of the affected population calculated using a realistic disease model ( Z 2 ). The goal of BWSN was to minimize the expectation of the impact measures Z 1 and Z 2 given a uniform distribution over intrusion scenarios.
 In this paper, we consider the adversarial setting, where an opponent chooses the contamination scenario with knowledge of the sensor locations. The objective functions Z 1 and Z 2 are in fact sub-modular for a fixed intrusion scenario [9], and so the adversarial problem of minimizing the impact of the worst possible intrusion fits into our model. For these experiments, we consider scenarios which affect at least 10% of the network, resulting in a total of 3424 scenarios. Figures 2(b) and 2(c) compare the greedy algorithm, S ATURATE and the simulated annealing (SA) algorithm for the prob-lem of maximizing the worst-case detection time ( Z 1 ) and worst-case affected population ( Z 2 ). Interestingly, the behavior is very different for the two objectives. For the affected population ( Z 2 ), greedy performs reasonably, and SA sometimes even outperforms S ATURATE . For the detection time ( Z 1 ), however, the greedy algorithm did not improve the objective at all, and SA performs poorly. The reason is that for Z 2 , the maximum achievable scores, F i ( V ) , vary drastically, since some scenarios have much higher impact than others. Hence, there is a strong  X  X radient X , as the adversarial objective changes quickly when the high impact scenarios are covered. This gradient allows greedy and SA to work well. On the contrary, for Z 1 , the maximum achievable scores, F ( V ) , are constant, since all scenarios have the same simulation duration. Unless all scenarios are detected, the worst-case detection time stays constant at the simulation length. Hence, many node exchange proposals considered by SA, as well as the addition of a new sensor location by greedy, do not change the adversarial objective, and the algorithms have no useful performance metric. Similarly to the GP Kriging setting, our results show that optimizing the worst-case score leads to reasonable performance in the average case score, but not necessarily vice versa. In this paper, we considered the problem of selecting observations which are informative with re-spect to an objective function chosen by an adversary. We demonstrated how this class of problems encompasses the problem of finding designs which minimize the maximum posterior variance in Gaussian Processes regression, robust experimental design, and detecting events spreading over graphs. In each of these settings, the individual objectives are submodular and can be approximated well using, e.g., the greedy algorithm; the adversarial objective, however, is not submodular. We proved that there cannot exist any approximation algorithm for the adversarial problem if the con-straint on the observation set size must be exactly met, unless P = NP . Consequently, we presented an efficient approximation algorithm, S ATURATE , which finds observation sets which are guaran-teed to be least as informative as the optimal solution, and only logarithmically more expensive. In a strong sense, this guarantee is the best possible. We extensively evaluated our algorithm on several real-world problems. For Gaussian Process regression, we showed that S ATURATE compares favor-ably to state-of-the-art heuristics, while being simpler, faster, and providing theoretical guarantees. For robust experimental design, S ATURATE performs favorably compared to SDP based approaches. Acknowledgements This work was partially supported by NSF Grants No. CNS-0509383, CNS-0625518, CCF-0448095, CCF-0729022, and a gift from Intel. Anupam Gupta and Carlos Guestrin were partly supported by Alfred P. Sloan Fellowships, Carlos Guestrin by an IBM Faculty Fellow-ship and Andreas Krause by a Microsoft Research Graduate Fellowship.

