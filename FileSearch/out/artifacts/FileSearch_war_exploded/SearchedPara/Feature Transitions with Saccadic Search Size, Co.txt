 Size, color, and orientation have long been considered elem entary features [14] that are available to guide attention and visual search [17]. Their special statu s in early visual processing is supported by a large volume of psychophysical evidence on how they can m ediate effortless texture segre-gation, recombine in illusory conjunctions, and pop out in f eature search [13, 16]. There is also physiological evidence on how these features could be extra cted with separate sets of dedicated de-tectors working in parallel across the entire space [6]. Con sequently, in schematic diagrams as well as computational models on visual saliency [13, 3, 12], imag e segmentation [5], object recognition and orientations are processed and available simultaneous ly.
 While size, color, and orientation are alike at parallel loca l detections across space, they may not be alike at serial deployment of attention across time. We inve stigate this issue in a gaze-tracked visual search experiment which often requires multiple saccades f or the subject to locate the target (Fig. 1). Figure 1: Two kinds of disks are uniformly randomly distribu ted in a fixed regular layout. Only one disk changes its kind during a repeated flickering presentat ion. For the same size of change, does it matter to visual search whether the two kinds of disks are ren dered in size, color, or orientation? Figure 2: Each trial goes through fixation, stimulus, detect ion, and localization stages. A fixation dot is displayed for 1 second before the onset of the flicker st imulus, with disk image 1, blank, disk image 2, blank repeatedly presented for 120ms each. The subj ect issues a mouse click as soon as he detects the change, and the the last seen disk image remains o n till he clicks the disk of change. A blank screen is then displayed for 2 seconds before the start of next trial.
 We present two kinds of disks in a fixed regular layout in a flick er paradigm, and the subject X  X  task is to locate the only disk that changes its kind (Fig. 2). The p aradigm induces change blindness , where a large difference between two images becomes strikin gly difficult to detect with a blank in-between, even with repeated presentations [9, 2, 8, 18] . Without the blank, the change elicits a singular motion signal which automatically draws the viewe r X  X  attention to the location of change; with the blank, the motion signal is disrupted and overwhelm ed by those motion transients between either image and the blank, effectively masking the locatio n of change.
 If the magnitude of change is comparable across feature dime nsions, does it matter whether the disks are rendered in size, color, or orientation? That is, does vi sual search vary according to whether the size, color, and orientation are processed in the same fashi on with dedicated local detectors operating 3 scenarios. The question is whether the deployment of atten tion, i.e. deciding what disks to look at next and how to look, depend on which filters produce these res ponses.
 Note that our stimuli decouple the target of feature search f rom visual saliency in the space. Our poral change of the attribute. At any time instance, the attr ibutes are uniformly random everywhere, so the target cannot draw attention to itself, but has to be di scovered with search. The effect of the attribute itself on attention can thus be studied without th e confounding factor of saliency. The focus of this paper is on how the feature space is navigate d with saccadic search. We formulate a feature descriptor for each fixation, based on which we deve lop a Markovian feature transition model for saccadic eye movements. Our model reveals that fea ture transition is attractive for size, are not alike in dynamic attribute processing over time. We investigate whether visual search for attribute change d iffers when the stimulus is rendered in size, color, or orientation with the same layout. We establi sh in a separate experiment that the change is equivalent among dimensions: Detection is equally fast a nd accurate for a change between two attributes across dimensions and for a no-change within eac h dimension across two attributes. flicker stimuli size color orientation spatial layout 1 2 1 2 1 2 1 2 1 1 2 1 2 1 2 2 2 1 1 1 1 2 2 2 2 2 2 1 1 1 1 2 1 1 2 1 2 1 2 2 2 1 1 1 1 2 2 2 2 2 2 1 1 2 The 1st image contains 12 attribute-1 disks and 12 attribute -2 disks in a uniformly random spatial distribution. The 2nd image is identical to the 1st image exc ept that 1 disk changes its attribute. It could be any of the 24 disks. The disk of change here is circled in both layout matrices. The background is of neutral gray value 0 . 5 . Here we restrict color to luminance only, as color hue processing is uniquely foveal, which would greatly confoun d explanations for search behaviours. The flicker stimuli for the 3 dimensions are rendered in an ide ntical spatial layout. Each stimulus involves a pair of 24-disk images which are identical except for one disk. These 24 disks are located centrally on a regular 4  X  6 grid, with an inter-disk distance of 5 . 4  X  , which is 4 times the maximal radius a disk could assume. The 1st image of the stimulus cons ists of uniformly randomly distributed 12 attribute-1 disks and 12 attribute-2 disks. The 2nd image changes one of the 24 disks (Fig. 3). Apparatus. The display extends 25 . 6  X   X  34 . 1  X  at a viewing distance of 5 meters. Gaze data are recorded with a Tobii x50 eye tracker at 50Hz sampling rate an d 0 . 5  X  -0 . 7  X  accuracy. Two clock-synced 3.2GHz Dell Precision computers control the eye trac ker and the stimulus presentation re-spectively. The eye tracker is calibrated at the beginning o f each data recording session. Procedure. Each trial begins with a fixation dot of radius 0 . 5  X  shown at the center of the display for 1 second. The flicker stimulus, in the sequence of disk ima ge 1, blank, disk image 2, and blank, is then repeatedly presented for 120 ms each. Once the subjec t issues a mouse click to indicate his There are 3 sets of random stimuli run in 3 sessions. Each sess ion has 3 blocks of 24 trials each, one trial for one change location and one block for one dimension . The trials are completely randomized in a block, and the blocks are also randomized and balanced am ong the subjects.
 The subject is told that two images differing in only one disk are presented repeatedly. His task is to detect and localize the changing disk. He should issue a clic k as soon as he detects the change. The flickering then stops at the last seen disk image, and he shoul d click the disk of change. Participants. A total of 24 naive subjects with normal or corrected-to-nor mal vision participated after providing informed consent and were compensated with cash. 11, 8, and 5 subjects took part in one, two and all three sessions respectively. We evaluate the task performance on both the accuracy measur ed by the percentage of correct change localizations and the reaction time measured from the flicke r stimulus onset to the subject X  X  first mouse click for indicating a detection. Fig. 4 shows that loc alizing an equivalent change among and most accurate in size, less so in orientation, and least i n color. The human visual system must accomplish change localizatio n by examining more than one disk per flicker cycle, since the mean reaction time is only about 5 , 6, and 7 cycles ( 0 . 12  X  4 = 0 . 48 seconds per cycle) for size, orientation, and color respect ively. If only one item is looked at and ruled out per cycle, on average it would require fixating 50% o f 24 disks till hitting the target disk, i.e. in 12 flicker cycles. Our average of 6 cycles suggests tha t about 2 disks are examined per cycle. When a disk is being fixated, all its 8 neighbouring disks are mo stly out of fovea, since they are either 5 . 4  X  or 7 . 7  X  apart. Some coarse information about neighbouring disks mu st be utilized in each fixation. The neighbourhood effect on change localizat ion is studied in Fig. 5 and Fig. 6. commonly best spatial layout (100%, 1.4 s) commonly worst spatial layout Figure 5: The common spatial layout that yields the best ( a,b,c ) or the worst ( d,e,f ) change local-ization performance in all 3 feature dimensions. Each pair o f numbers ( a %, b s) indicate mean accuracy a and reaction time b . Shown here is the average image of a flicker stimulus, with th e disk of change taking two attributes, except in the case of color: Since the average has the same intensity as background, the change is outlined in white instead. The c ommonly best layout has the change among uniform attributes, whereas the commonly worst layou t has a mixture of attributes. spatial layout spatial layout Figure 6: The dimension-specific spatial layout that yields the best or worst change localization performance in one dimension only, with the largest perform ance gap over the other 2 dimensions. Same convention as Fig. 5. The 3 rows of numbers below each ima ge indicate the mean accuracy and reaction time for a stimulus rendered in the same layout b ut in size, color, and orientation respectively. The localization of a flickering change is eas ier in a primarily large neighbourhood for size, in any homogeneous neighbourhood for color, and in a co llinear neighbourhood for orientation. Fig. 5 shows that a uniform neighbourhood tends to facilitat e change localization, whereas a mixed neighbourhood tends to hinder change localization, no matt er which dimension the disks are ren-dered in. Fig. 6 shows distinctions in the neighbourhood uni formity between the 3 dimensions. For size , change localization is easier in a neighbourhood populate d with large disks. If the domi-nant size is large (Fig. 6a), missing a large would be easier t o detect, whereas if the dominant size is small (Fig. 6d), missing a small would be difficult to detec t. That is, unlike color or orientation, the attributes of size are asymmetrical: small produces a sm aller response than large, with size 0 for a response of 0 in the limiting case. When neither small nor lar ge is dominant in the neighbourhood (Fig. 5d), change localization becomes most difficult. For color , change localization is easier if one color, either black or white, dominates the neighbourhood. For orientation , it is easier only if the oriented disk is part of collinear layout. Having seen that neighbourhood uniformity has an impact on t he change localization performance, we investigate how it influences the decision on which item to look at in the next fixation. We first associate a fixation with a set of f -numbers at that location, each measuring the overall attribute density in a neighbourhood defined by a Gaussian sp atial weighting function. Let loc( i ) Gaussian function of x with mean 0 and standard deviation  X  . We have: Figure 7: The f -number images of a flicker stimulus. A negative f number (in blue shades) indicates the dominance of attribute 1, whereas a positive f number (in red shades) indicates the dominance of attribute 2. The closer the f number is to 0 (in gray shades), neither attribute dominates the neigh-bourhood. f  X  measures the average attribute in a Gaussian neighbourhood with standard deviation  X  . The 3 circles on the target of change mark the  X , 2  X , 3  X  radii. While  X  = 1 covers only one disk in isolation,  X  = 2 also covers 8 adjacent disks, and  X  = 4 covers 16 adjacent disks.
 estimates the majority of attributes in a larger neighbourh ood.
 attribute homogeneity surrounding that location. Fig. 7 sh ows f for the best spatial layout in Fig. 5. and f 2 ( i )  X  0 for i in a mixed neighbourhood. At  X  = 4 , the neighbourhood is about the half size of the display, with f 4 ( i ) = 0 for i bordering two large different uniform neighbourhoods. Fig. 8 shows the distributions of f associated with all the fixations. The two peaks of f 1 in all the 3 feature dimensions demonstrate that visual search tends t o fixate disks rather than empty spaces between disks. There is also an attribute bias in each dimens ion, and the bias is weakest in ori-entation and strongest in size. This bias is not diminished i n f 2 , demonstrating that visual search tends to navigate in groups of large disks. The single peak of f 4 at value 0 not only confirms the uniform randomness of our stimuli, but also reveals that the empty spaces being fixated tend to be those borders between different attribute neighbourhoods at a coarser scale (Fig. 7 Column 4). the fixations shows a strong preference in size for large disk s as well as areas of large disks ( +1 ), a small preference in color for black disks (  X  1 ), and a slight preference in orientation for vertical disks ( +1 ). The single peak of f 4 at 0 reveals most fixations occurring near those disks separa ting large groups of uniform attributes. These statistics are ro bust with respect to subject sub-sampling validation, e.g. over 8 samplings of 10 subjects only, the ma ximal standard error is 0 . 006 . P  X  size color orientation P P P ence of jumping to a disk of the same attribute regardless of s accade distance d and neighbourhood size  X  . Each transition P ( a, b ; d,  X  ) given d and  X  is visualized as a 2D image, e.g. for size, the right lower corner of P 1 is the frequency of saccading from large to large. A darker gr ay indicates the chance is more uniformly random in orientation.
 Fig. 9 shows the joint distributions of two f numbers associated with the initiating fixations and the landing fixations of all the saccades, organized according t o the saccade distance. For a saccade from pixel i to pixel j , it contributes one count of transition from a to b in the f -space: the same attributes. At such a short distance, each saccade c ould not reach a different disk. These transitions are thus between the same disks or between the sa me inter-disk empty spaces, by e.g. micro-saccades. The bias towards a particular attribute is also clear in each dimension: There are more transitions between larges than between smalls, more b etween blacks than between whites, about the same between horizontals and between verticals. A s the saccade distance increases, disks of various attributes become viable candidates to saccade t o. It becomes more likely to saccade to another disk of the same or different attribute than to sacca de to an empty space (i.e. low probabili-ties in the middle rows or columns of P  X  images).
 at the initiating attribute a and conditional probability P ( b | a ) for the landing attribute b : sures the proportion of saccades towards b given the current fixation at a . Consistent with Fig. 8,  X  ( a ) in Fig. 10 shows more visits to large, black, vertical than to small, white, and horizontal. The most interesting finding comes from P ( b | a ) : While the attributes are uniformly random in the neighbourhood, our eyes do not act like a blind space wandere r. 1) For size , it is much more likely to size, white is not an attractor, but a repeller: Once at white , the eyes are more inclined to leave for black than staying in the group of whites. 3) For orientation , it is only slightly more likely to visit vertical than horizontal. When the eyes are on an empty space, it is in fact equally likely to visit and the two attributes are largely reversible. Such biases a lso persist over larger saccades. .43 .04 .53  X  = 0 . 15 . These statistics are validated over 13 leave-50%-subject s-out samplings, with the standard for size,  X  shows that 43% of all the fixations look at small, 4% at empty, and 53% at large, whereas the 3rd row of P shows that upon fixating at large, there is 51% chance of saccading to another large, 37% chance to a small disk and 12% chance to an empty space. The most likely action is highlighted in red. Search in size tends to be attracted to la rge, search in color tends to be repelled by white, whereas search in orientation is largely reversib le between horizontal and vertical. These results cannot be explained by visual crowding, where the perception of peripherally viewed shapes is impaired with nearby similar shapes [7]. While crit ical spacing is always roughly half the viewing eccentricity and independent of stimulus size, cro wding magnitude differs across features: Size crowding is almost as strong as orientation crowding, w hereas the effect is much weaker for color [15]. Therefore, feature crowding cannot explain the different natures of feature transitions for size, color, and orientation, or why such biases persist ove r larger saccades. Size, color, and orientation are considered elementary fea tures extracted with separate sets of detec-tors responding in parallel across space. They are modeled b y the same computational mechanism, differing only in the filters that implement their local attr ibute detectors.
 We conducted a gaze-tracked change blindness experiment, w here the subject needs to locate a flickering change among items rendered identically in space and separately in size, color, and ori-entation. If the deployment of attention during search depe nds only on the master spatial map of responses [14, 13, 3, 17, 12], regardless of which type of filt ers produces them, we should observe little differences in the search performance and behaviour s among the 3 dimensions.
 Our search performance analysis shows that change localiza tion is fastest and most accurate in size, less in orientation, worst in color. Change in a uniform neig hbourhood is easier to localize, but only if the attribute is large for size, or if the items form collin ear extension for orientation. Our feature analysis with eye movements shows that search in each dimension has an attribute bias: separating large uniform groups. However, feature transit ions with saccades have a strong attractor bias for large, and a repeller bias for white, and a very littl e bias for orientation. These biases create an interesting dynamics in serial proce ssing over time which could explain why the space, but due to their own selectivity in grouping [8, 19 , 1] over time: Focusing on the large group essentially cuts down the search space by half, wherea s excursion into the white group from the primary black group only hurts the spatial efficiency of s earch.
 Our results and analysis methods on these elementary featur es thus provide new insights into the computation of visual saliency and task-specific visual fea tures across dimensions and over time. This research is funded by NSF CAREER IIS-0644204 and a Clare Boothe Luce Professorship. I would like to thank Dimitri Lisin, Marcus Woods, Sebastian Skardal, Peter Sempolinski, David Tolioupov, and Kyle Tierney for earlier discussions and exc ellent assistance with the experiments. I am grateful for many insightful comments I have received fro m Jeremy Wolfe, Ronald Rensink, and anonymous reviewers; their valuable suggestions have grea tly improved the paper.
 [1] G. Fuggetta, S. Lanfranchi, and G. Campana. Attention ha s memory: priming for the size of [2] J. Grimes. On the failure ot detect changes in scenes acro ss saccades. 2, 1996. [3] L. Itti and C. Koch. Computational modelling of visual at tention. Nature Neuroscience , pages [4] D. G. Lowe. Distinctive image features from scale-invar iant keypoints. 2003. [5] J. Malik, S. Belongie, T. Leung, and J. Shi. Contour and te xture analysis for image segmenta-[6] J. H. R. Maunsell and W. T. Newsome. Visual processing in m onkey extrastriate cortex. Annual [7] D. G. Pelli, M. Palomares, and N. J. Majaj. Crowding is unl ike ordinary masking: distinguish-[8] R. Rensink. Visual search for change: A probe into the nat ure of attentional processing. Visual [9] R. A. Rensink, J. K. O X  X egan, and J. J. Clark. Image flicker is as good as saccades in making [10] M. Riesenhuber and T. Poggio. Hierarchical models of ob ject recognition in cortex. Nature [11] T. Serre, A. Oliva, and T. Poggio. A feedforward archite cture accounts for rapid categorization. [12] A. Torralba. Contextual influences on saliency. In L. It ti, G. Rees, and J. Tsotsos, editors, [13] A. Treisman. The perception of features and objects. In R. D. Wright, editor, Visual Attention . [14] A. Treisman and G. Gelade. A feature-integration theor y of atttention. Cognitive Psychology , [15] R. van den Berg, J. B. T. M. Roerdink, and F. W. Cornelisse n. On the generality of crowding: [16] J. M. Wolfe. Asymmetries in visual search: an introduct ion. Perception and Psychophysics , [17] J. M. Wolfe and T. S. Horowitz. What attributes guide the d eployment of visual attention and [18] J. M. Wolfe, A. Reinecke, and P. Brawn. Why don X  X  we see cha nges? the role of attentional [19] Y. Yeshurun and M. Carrasco. The effects of transient at tention on spatial resolution and the [20] H. Zhang, A. C. Berg, M. Maire, and J. Malik. SVM-KNN: Dis criminative nearest neighbor
