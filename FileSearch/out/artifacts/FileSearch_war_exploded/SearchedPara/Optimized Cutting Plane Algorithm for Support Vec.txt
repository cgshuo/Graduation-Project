 Fraunhofer Institute FIRST, Kekulestr. 7, 12489 Berlin, Germany Many applications in e.g. Bioinformatics, IT-Security and Text-Classification come with huge amounts (e.g. millions) of data points, which are indeed needed to obtain state-of-the-art results. They therefore require computation-ally extremely efficient methods capable of dealing with ever growing data sizes. Support Vector Machines (SVM) e.g. (Cortes &amp; Vapnik, 1995; Cristianini &amp; Shwawe-Taylor, 2000) have proven to be powerful tools for a wide range of different data analysis problems. Given labeled training examples { ( x 1 , y 1 ) , . . . ( x m , y m ) }  X  ( R n  X { X  and a regularization constant C &gt; 0 they learn a linear classification rule h ( x ) = sgn(  X  w  X  , x  X  + b  X  ) by solving the quadratic SVM primal optimization problem (P) or its dual formulation (D) allowing the use of kernels . ( P ) min ( D ) max Due to the central importance of SVMs, many techniques have been proposed to solve the SVM problem. As in prac-tice only limited precision solutions to (P) and (D) can be obtained they may be categorized into approximative and accurate .
 Approximative Solvers make use of heuristics (e.g. learning rate, number of iterations) to obtain (often crude) approximations to the QP-solution. They have very low per-iteration cost and low total training time. Especially for large scale problems, they are claimed to be sufficiently precise while delivering the best performance vs. training time trade-off (Bottou &amp; Bousquet, 2008), which may be attributed to the robust nature of large margin SVM solutions. However while they are fast in the beginning they often fail to achieve precise solution. Among the to-date most efficient solvers are Pegasos (Shwartz et al., 2007) and SGD (Bottou &amp; Bousquet, 2008), which are based on stochastic (sub-)gradient descent.
 Accurate Solvers In contrast to approximative solvers, accurate methods solve a QP up to a given precision  X , where  X  commonly denotes the violation of the relaxed KKT conditions (Joachims, 1999) or the (relative) duality gap. Accurate methods often have good asymptotic conver-gence properties, and thus for small  X  converge to very pre-cise solutions being limited only by numerical precision. Classical examples are off-the-shelf optimizers (e.g. MI-NOS, CPLEX, LOQO). However it is usually infeasible to use standard optimization tools for solving the SVM train-ing problems (D) on datasets containing more than a few thousand examples. So-called decomposition techniques as chunking (e.g. used in (Joachims, 1999)), or SMO (used in (Chang &amp; Lin, 2001)) overcome this limitation by exploit-ing the special structure of the SVM problem. The key idea of decomposition is to freeze all but a small number of op-timization variables ( working set ) and to solve a sequence of constant-size problems (subproblems of the SVM dual). While decomposition based solvers are very flexible as they are working in the dual and thus allow the use of kernels they become computationally intractable with a few hun-dred thousand examples. This limitation can be explained as follows: Decomposition methods exploit the fact that the optimal solution of (P) does not change if inactive con-straints at the optimum are removed, they are therefore only efficient if the number of active constraints is reason-ably small. Unfortunately, the number of active constraints is lower bound by the portion of misclassified examples, which is proportional to the number of examples m. Thus decomposition methods are computationally prohibitive for large-scale problems (empirically about 10%-30% of the training points become active constraints).
 This poses a challenging task for even current state-of-the-art SVM solvers such as SVM light (Joachims, 1999), Gra-dient Projection-based Decomposition Technique-SVM (GPDT-SVM) (Zanni et al., 2006), LibSVM (Chang &amp; Lin, 2001). As improving training times using the dual formula-tion is hard, the research focus has shifted back to the orig-inal SVM primal problem. The importance of being able to efficiently solve the primal problem for large datasets is documented by a number of very recently developed meth-ods, e.g. SVMLin (Sindhwani &amp; Keerthi, 2007; Chapelle, 2007), LibLinear (Lin et al., 2007), SVM perf (Joachims, 2006) and BMRM (Teo et al., 2007).
 In the following we will focus on finding accurate solutions of the unconstrained linear SVM primal problem 1 w  X  = argmin where R ( w ) = 1 m P m i =1 max { 0 , 1  X  y i  X  w , x i  X  X  (2) is a convex risk approximating the training error. Among the up to date most efficient accurate SVM primal problem (1) solvers are the Cutting Plane Algorithm (CPA) based methods put forward in (Joachims, 2006; Teo et al., 2007) and implemented in SVM perf and BMRM. The idea of CPAs is to approximate the risk R by a piece-wise linear function defined as the maximum over a set of linear under-estimators, in CPA terminology called cutting planes . In (Joachims, 2006; Teo et al., 2007) it was shown that their number does not depend on the number of training exam-ples m and that very few such cutting planes are needed in practice to sufficiently approximate (1). In this work we propose a new method, called the Opti-mized Cutting Plane Algorithm for SVMs (OCAS). We empirically show that OCAS converges on a wide vari-ety of large-scale datasets even considerably faster than SVM perf , BMRM and SVM light , achieving speedups of several orders of magnitude on some problems. We also demonstrate that OCAS even in the early optimization steps shows faster convergence than the so far in this domain dominating approximative methods. Finally we critically analyze all solvers w.r.t. classification performance in an extensive model selection study.
 The report is organized as follows. CPA is described in Section 2. In Section 3, we point out a source of ineffi-ciency of CPA and propose a new method, OCAS, to allevi-ate the problem and prove linear convergence. An extensive empirical evaluation is given in Section 4 and concludes the paper. Recently, the Cutting Plane Algorithm (CPA) based large-scale solvers, SVM perf (Joachims, 2006) and BMRM (Teo et al., 2007), have been proposed. SVM perf implements CPA specifically for the linear SVM problem (1). De-coupling regularizer and loss function, BMRM generalizes SVM perf to a wide range of losses and regularizers mak-ing it applicable to many machine learning problems, like classification, regression, structure learning etc. It should be noted that BMRM using the two norm regularizer k . k 2 and hinge loss (i.e. SVM problem (1)) coincides with SVM perf . It was shown that SVM perf and BMRM by far outperform the decomposition methods like SVM light on large-scale problems. The rest of this section describes the idea behind CPA for the standard SVM setting (1) in more detail.
 In CPA terminology, the original problem (1) is called the master problem. Using the approach of (Teo et al., 2007) one may define a reduced problem of (1) which reads Problem (3) is obtained from the master problem (1) by substituting a piece-wise linear approximation R t for the risk R while leaving the regularization term unchanged, i.e. only the complex part of the objective F is approxi-mated. The approximation R t is derived as follows. Since the risk R is a convex function, it can be approximated at any point w 0 by a linear under estimator
R ( w )  X  R ( w 0 ) +  X  a 0 , w  X  w 0  X  ,  X  w  X  R n , (4) where a 0 is any subgradient of R at the point w 0 . We will use a shortcut b 0 = R ( w 0 )  X  X  a 0 , w 0  X  to abbreviate (4) as R ( w )  X  X  a 0 , w  X  + b 0 . In CPA terminology,  X  a 0 , w  X  + b is called a cutting plane. A subgradient a 0 of R at the point w 0 can be obtained as a =  X  To get a better approximation of the risk R than a single cutting plane, one may use a collection of cutting planes { X  a i , w  X  + b i = 0 | i = 1 , . . . , t } at t distinct points { w 1 , . . . , w t } and take their point-wise maximum The zero cutting plane is added to the maximization as the risk R is always greater or equal to zero. It follows directly from (4) that the approximation R t lower bounds R and thus also F t lower bounds F .
 To select the cutting planes, CPA starts from t = 0 (no cutting plane) and then it iterates two steps: 1. Compute w t by solving the reduced problem (3), 2. Add a new cutting plane ( a t +1 , b t +1 ) to approximate A natural stopping condition for CPA is based on evaluat-ing the  X  -optimality condition F ( w t )  X  F t ( w t )  X   X  which, if satisfied, guarantees that F ( w t )  X  F ( w  X  )  X   X  holds. (Joachims, 2006) proved that for arbitrary  X  &gt; 0 CPA con-verges to the  X  -optimal solution after O ( 1  X  2 ) iterations, i.e. it does not depend on the number of examples m . An im-proved analysis of the CPA published recently (Teo et al., 2007) shows that the number of iterations scales only with O ( 1 only tens of iterations to reach a sufficiently precise solu-tion. We first point out a source of inefficiency appearing in CPA and then propose a new method to alleviate the problem. CPA selects a new cutting plane such that the reduced prob-lem objective function F t ( w t ) monotonically increases with w.r.t. the number of iterations t . However, there is no such guarantee for the master problem objective F ( w t ) . Even though it will ultimately converge to the minimum F ( w  X  ) , its value can heavily fluctuate between iterations. The reason for these fluctuations is the following. CPA se-lects at each iteration t the cutting plane which perfectly approximates the master objective F at the current solu-tion w t . However, there is no guarantee that such cutting plane will be an active constraint in the vicinity of the op-timum w  X  , nor must the new solution w t +1 of the reduced problem improve the master objective. In fact it often oc-curs that F ( w t +1 ) &gt; F ( w t ) .
 To speed up the convergence of CPA, we propose a new method which we call the Optimized Cutting Plane Al-gorithm for SVMs (OCAS). Unlike standard CPA, OCAS aims at simultaneously optimizing the master and reduced problem X  X  objective functions F and F t , respectively. In addition, OCAS tries to select such cutting planes that have higher chance to actively contribute to the approximation of the master objective function F around the optimum w  X  . In particular, we propose the following three changes to CPA. Change 1 We maintain the best so far solution w b t ob-forms a monotonically decreasing sequence.
 Change 2 The new best so far solution w b t is found by searching along a line starting at the previous best solution w t  X  1 crossing the reduced problem X  X  solution w t , i.e. , which can be solved exactly in O ( m log m ) time (see Ap-pendix A).
 Change 3 The new cutting plane is selected to approxi-mate the master objective F at a point w c t which lies in a vicinity of the best so far solution w b t . In particular, the point w c t is computed as where  X   X  (0 , 1] is a prescribed parameter. Having the point w c , the new cutting plane is computed using Equa-the theoretical bound on the number of iterations (see The-orem 1) does not depend on  X  its value has impact on the convergence speed in practice. We found that the value  X  = 0 . 1 works consistently well in all experiments. Algorithm 1 describes the proposed OCAS. Figure 1 shows the impact of the proposed changes to the convergence. OCAS generates a monotonically decreasing sequence of tonically strictly increasing sequence of reduced objective stopping condition for OCAS reads where  X  &gt; 0 is a prescribed precision parameter. Satisfying the condition (9) guarantees that F ( w b t )  X  F ( w  X  )  X   X  holds.
 Algorithm 1 Optimized Cutting Plane Algorithm 1: Set t = 0 (i.e. there is no cutting plane at the begin-2: repeat 3: Compute w t by solving the reduced problem (3). 4: Compute a new best so far solution w b t using the 5: Add a new cutting plane which approximates the 6: t := t + 1 7: until a stopping condition is satisfied Theorem 1 For any  X  &gt; 0 , C &gt; 0 ,  X   X  (0 , 1] , and any fies the stopping condition (9) after at most iterations where Q = max i =1 ,...,m k x i k .
 Proof The proof is along the lines of the convergence analysis of the standard CPA (Joachims, 2006). First, it can be shown that violated condition (9) guarantees that adding a new cutting plane ( a t , b t ) leads to an improvement of the reduced objective  X  t = F t +1 ( w t +1 )  X  F t ( w t is not less than min  X  2 ,  X  2 8 Q 2 . Second, by exploiting that 0  X  F t ( w t )  X  F ( w  X  ) and F ( w  X  )  X  F ( 0 ) = C one can conclude that the sum of improvements P t i =0  X  t cannot be greater than C . Combining these two results gives im-mediately the bound (10). For more details we refer to our technical report (Franc &amp; Sonnenburg, 2007). The bound on the maximal number of iterations of OCAS coincides with the bound for CPA given in (Joachims, 2006). Despite the same theoretical bounds, in practice OCAS converges significantly faster compared to CPA (cf. Table 2 in the experiments section). 3.1. Time Complexity and Parallelization By Theorem 1 the number of iterations of OCAS does not depend on the number of examples m . Hence the overall time complexity is given by the effort required per itera-tion which is O ( mn + m log m )  X  O ( mn ) (in practice log( m ) n, where n is the dimensionality of the data). The per-iteration complexity of the subtasks and the way how they can be effectively parallelized is detailed below: Output computation involves computation of the dot products  X  w t , x i  X  , i = 1 , . . . , m , which requires O ( s ) time, where s equals the number of non-zero elements in the training examples. Distributing the computation equally to p processor leads to O ( s p ) time.
 Line-search The dominant part is sorting | K | numbers ( K  X  m , see Appendix A for details) which can be done in O ( | K | log | K | ) . A speedup can be achieved by par-allelizing the sorting function to using p processors, re-ducing complexity to O | K | log | K | p . Note that our im-plementation of OCAS uses quicksort, whose worst case complexity is O ( | K | 2 ) , although its expected run-time is O ( | K | log | K | ) .
 Cutting plane computation The dominant part requires computing the sum  X  1 m P m i =1  X  i y i x i which can be done in O ( s  X  ) , where s  X  is the number of non-zero elements in the training examples for which  X  i is non-zero. Using p processors leads to O ( s  X  p ) time.
 Reduced problem The size of the reduced problem (3) is upper bound by the number of iterations which is invari-ant against the dataset size, hence it requires O (1) time. Though solving the reduced problem cannot be easily par-allelized, it does not constitute the bottleneck as the number of iterations required in practice is small (cf. Table 2). We now compare current state-of-the-art SVM solvers (SGD, Pegasos, SVM light , SVM perf , BMRM 3 on a va-riety of datasets with the proposed method (OCAS) using 5 carefully crafted experiments measuring: 1. Training time and objective for optimal C 2. Speed of convergence (time vs. objective) 3. Time to perform a full model selection 4. Scalability w.r.t. dataset size 5. Effects of parallelization To this end we implemented OCAS and the standard CPA 4 in C. We use the very general compressed sparse column (CSC) representation to store the data. Here each element is represented by an index and a value (each 64bit). To solve the reduced problem (3), we use our implementation of improved SMO (Fan et al., 2005). 4.1. Experimental Setup The datasets used throughout the experiments are summa-rized in Table 1. We augmented the Cov1, CCAT, As-tro datasets from (Joachims, 2006) by the MNIST, a arti-ficial dense and two larger bioinformatics splice datasets for worm and human. The artificial dataset was generated from two Gaussians with different diagonal covarience ma-trices of multiple scale. If not otherwise stated experiments were performed on a 2.4GHz AMD Opteron Linux ma-chine. We disabled the bias term in the comparison. As stopping conditions we use the defaults:  X  light =  X  gpdt 0 . 001 ,  X  perf = 0 . 1 and  X  bmrm = 0 . 001 . For OCAS we used the same stopping condition which is implemented in these  X  have a very different meaning denoting the maxi-mum KKT violation for SVM light , the maximum tolerated violation of constraints for SVM perf and for the BMRM the relative duality gap. For SGD we fix the number of it-erations to 10 and for Pegasos we use 100 / X  , as suggested in (Shwartz et al., 2007). For the regularization parameter C and  X  we use the following relations:  X  = 1 /C, C perf = C/ 100 , C bmrm = C and C light = Cm . Throughout ex-periments we use C as a shortcut for C light . 5 4.2. Evaluation In the following paragraphs we run and evaluate the afore-mentioned experiments 1 X 5.
 Training time and objective for optimal C We trained all methods on all except the human splice dataset using the training data and measured training time (in seconds) and computed the unconstrained objective value F ( w ) The obtained results are displayed in Table 2. The pro-posed method  X  OCAS  X  consistently outperforms all its competitors of the accurate solver category on all bench-mark datasets in terms of training time while obtaining a comparable (often the best) objective value. BMRM and SVM perf implement the same CPA algorithm but due to implementation specific details results can be different. Our implementation of CPA gives very similar results (not shown). 6 Note that for SGD, Pegasos (and SVM perf 2 . 0  X  not shown) the objective value sometimes deviates signifi-cantly from the true objective. As a result the learned clas-sifier may differ substantially from the optimal parameter w  X  . However as training times for SGD are significantly below all others it remains unclear whether SGD achieves the same precision using less time when run for further it-erations. An answer to this question is given in the next paragraph.
 Speed of convergence (time vs. objective) To address this problem we re-ran the best methods CPA, OCAS and SGD, recording intermediate progress, i.e. while optimiza-tion record time and objective for several time points. The results are shown in Figure 2. Ocas was stopped when reaching the maximum time or a precision of 1  X  F ( w  X  ) /F ( w )  X  10  X  6 and was in all cases achieving the minimum objective. In three of the six datasets OCAS not only as expected at a later time point achieves the best ob-jective but already from the very beginning. Further anal-ysis made clear that OCAS wins over SGD in cases where large C were used and thus the optimization problem is more difficult. Still plain SGD outcompetes even CPA. One may argue that practically the true objective is not the un-constrained SVM-primal value (1), but the performance on a validation set, i.e. optimization is stopped when the vali-dation error won X  X  change.
 One should however note that one in this case does not ob-tain an SVM but some classifier instead. Then a compar-ison should not be limited to SVM solvers but should be open to any other large scale approach, like on-line algo-rithms (e.g. perceptrons) too. We argue that to compare SVM solvers in a fair way one needs to compare objective values. As it is still interesting to see how the methods perform w.r.t. classification performance we analyze them under this criterion in the next paragraph.
 Time to perform a full model selection When using SVMs in practice, their C parameter needs to be tuned in model selection. We therefore train all methods using dif-ferent settings 7 for C on the training part of all datasets, evaluate them on the validation set and choose the best model to do predictions on the test set. As performance measure we use the area under the receiver operator char-acteristic curve (auROC) (Fawcett, 2003). Again among the accurate methods OCAS outperforms its competitors by a large margin, followed by SVM perf . Note that for all accurate methods the performance is very similar and has little variance. Except for the artificial dataset plain SGD is clearly fastest while achieving a similar accuracy. How-ever the optimal parameter settings for accurate SVMs and SGD are different. Accurate SVM solvers use a larger C constant than SGD. For lower C the objective function is dominated by the regularization term k w k . A potential ex-planation is that SGDs update rule puts more emphasize on the regularization term and SGD when not run for a large number of iterations does imply early stopping.
 Scalability w.r.t. Dataset Size In this section, we inves-tigate how computational time of OCAS, CPA and SGD scales with the number of examples on the worm splice dataset, for sizes 100 to 1 , 026 , 036 . We again use our im-plementation of CPA that shares essential sub-routines with OCAS. Results are shown and discussed in Figure 3. Effects of Parallelization As OCAS training times are very low on the above datasets, we also apply OCAS to the 15 million human splice dataset. Using a 2.4GHz 16-Core AMD Opteron Linux machine we run OCAS using C = 0 . 0001 on 1 to 16 CPUs and show the accumulated times for each of the subtasks, the total training time and the achieved speedup w.r.t. the single CPU algorithm in Table 4. Also shown is the time accumulated for each of the threads. As can be seen  X  except for the line search  X  computations distribute nicely. Using 8 CPU cores the speedup saturates at a factor of 4.5, most likely as memory access becomes the bottleneck (for 8 CPUs output compu-tation creates a load of 28GB/s just on memory reads). We have developed a new Linear SVM solver called OCAS, which outperforms current state of the art SVM solvers by several orders of magnitude. OCAS even in the early optimization steps shows often faster convergence than the so far in this domain dominating approximative methods. By parallelizing the subtasks of the algorithm, OCAS gained additional speedups of factors up to 4.6 on a multi-core multiprocessor machine. Using OCAS we were able to train on a dataset of size 15 million examples (it-self about 32GB in size) in just 671 seconds. As exten-sions to one and multi-class are straight forward, we plan to implement them in the near future. Furthermore OCAS can be extended to work with a bias term. Finally it will be future work to investigate how the kernel framework can be incorporated into OCAS and how the O ( 1  X  ) result of (Teo et al., 2007) can be applied to OCAS. An imple-mentation of OCAS is available within the shogun toolbox http://www.shogun-toolbox.org and as a sepa-rate library from http://ida.first.fraunhofer. de/  X  franc/ocas .
 The authors gratefully acknowledge partial support from the PASCAL Network of Excellence (EU 5 06778). VF was supported by Marie Curie Intra-European Fellowship grant SCOLES (MEIF-CT-2006-042107). We thank A. Zien, G. R  X  atsch and G. Blanchard for great discussions. The line-search (7) is an essential procedure of OCAS which is called at every iteration. We show that the line-search can be solved exactly in O ( m log m ) time. First, we introduce a more compact notation for the objective function of the line-search problem (7) F ( w b t  X  1 (1  X  k ) + w t k ) by G ( k ) = g 0 ( k ) + P k 2 A 0 + kB 0 + C 0 , g i ( k ) = max { 0 , kB i + C i } , A 1 2 y  X  x i , w b t  X  1  X  ) . Hence the line-search (7) involves solving k  X  = argmin k ) + w t k  X  . As function G is convex the unconstrained minimum of G is attained at the point k  X  at which the sub-differential  X  X  ( k ) contains zero, i.e. 0  X   X  X  ( k  X  ) . The subdifferential of G is  X  X  ( k ) = kA 0 + B 0 + P m i =1  X  X 
Note that the subdifferential is not a function as there ex-ist k for which  X  X  ( k ) is an interval. The first term of the subdifferential  X  X  ( k ) is an ascending linear function kA 0 + B 0 since A 0 must be greater than zero ( A 0 is zero only if the algorithm has converged but then the line-search is not invoked). The term  X  X  i ( k ) is either constantly zero, if B i = 0 , or it is a step-like jump whose value changes at the point k i =  X  C i B marized in Table 5. Hence the subdifferential  X  X  ( k ) is a monotonically increasing function as is illustrated in Fig-ure 4. To solve k  X  = argmin k  X  0 G ( k ) we proceed as fol-lows: If max(  X  X  (0)) is strictly greater than zero then the unconstrained minimum argmin k G ( k ) is at a point less or equal to 0 . Thus the constrained minimum is attained at the point k  X  = 0 .
 If max(  X  X  (0)) is less then zero then the optimum k  X  cor-responds to the unconstrained optimum argmin k G ( k ) at-tained at the intersection between the graph of  X  X  ( k ) and the x-axis. This point can be found efficiently by sorting K = { k i | k i &gt; 0 , i = 1 , . . . , m } and checking the condi-tion 0  X  G ( k ) for k  X  K and for k in the intervals which split the domain (0 ,  X  ) in the points K . These computa-tion are dominated by sorting the numbers K which takes
