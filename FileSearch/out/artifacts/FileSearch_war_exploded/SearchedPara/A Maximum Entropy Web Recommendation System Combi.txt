 } @cs.depaul.edu Web users display their preferences implicitly by navigating through a sequence of pages or by providing numeric rat-ings to some items. Web usage mining techniques are used to extract useful knowledge about user interests from such data. The discovered user models are then used for a vari-ety of applications such as personalized recommendations. Web site content or semantic features of objects provide an-other source of knowledge for deciphering users X  needs or interests. We propose a novel Web recommendation system in which collaborative features such as navigation or rating data as well as the content features accessed by the users are seamlessly integrated under the maximum entropy prin-ciple. Both the discovered user patterns and the semantic relationships among Web objects are represented as sets of constraints that are integrated to fit the model. In the case of content features, we use a new approach based on Latent Dirichlet Allocation (LDA) to discover the hidden seman-tic relationships among items and derive constraints used in the model. Experiments on real Web site usage data sets show that this approach can achieve better recommendation accuracy, when compared to systems using only usage infor-mation. The integration of semantic information also allows for better interpretation of the generated recommendations. H.2.8 [ Database Management ]: Database Applications X  Data Mining ; I.2.6 [ Artificial Intelligence ]: Learning; I.5.1 [ Pattern Recognition ]: Models X  Statistical Algorithms Maximum Entropy, Recommendation, Web Usage Mining, User Profiling Copyright 2005 ACM 1-59593-135-X/05/0008 ... $ 5.00.
Web recommendation systems have been widely used to help users locate information on the Web. In many cases, Web users X  interests or preferences are not directly accessi-ble; instead, they are implicitly captured during users X  in-teraction with the Web site, such as navigating through a sequence of pages, or reflected through numeric ratings to items.

Many data mining and machine learning approaches have been used in building Web recommendation systems. Such systems, generally take the Web users X  navigation or rating data as input, and applying data mining or machine learn-ing approaches to discover usage patterns that represent ag-gregate user models. When a new user comes to the site, his/her activity will be matched against these patterns to find like-minded users and select potential interesting items as recommendations.

Typically, recommendation algorithms rely only on user information (collaborative features) such as navigational his-tory or rating data, and additional information such as con-tent features of the items, which may provide valuable source of complementary knowledge about user X  X  activities, is usu-ally ignored. By incorporating content information with a user X  X  navigation or rating behavior, we may be able to gain a deeper understanding of her underlying interests. For in-stance, we may find an association pattern  X  X age A  X  page B  X  with high support and confidence in navigation data, or a pattern such as  X  X ovie C and movie D are always rated similarly X  in rating data. The discovery of such patterns, by itself, does not explain the underlying reasons for their existence.

To address this issue considerable work has been done to enhance traditional recommendation systems by integrating data from other sources such as content attributes, link-age structure, and user demographics [13, 8, 14, 17, 5]. In these approaches, content information such as keywords or attributes of items, or user demographic data is collected as well as the usage or rating data. In order to make use of available data sources, different combination methods are tried to make recommendations more effective and inter-pretable. Generally, an integrated approach is prefered dur-ing the mining or model learning phase to avoid subjective or ad hoc ways of combining evidence. This is also one of our main motivations behind the maximum entropy recom-mendation system introduced in this paper.

Maximum entropy model is a powerful statistical model which has been widely applied in many domains such as sta-tistical language learning [15], information retrieval [4] and text mining [10]. The goal of a maximum entropy model is to find a probability distribution which satisfies all the con-straints in the observed data while maintaining maximum entropy. One of the advantages of such a model is that it enables the unification of information from multiple knowl-edge sources in one framework. Each knowledge source can be considered as a set of constraints in the model. From the intersection of all these constraints, a probability distri-bution with the highest entropy can be learned. Recently, we have seen applications of maximum entropy in Web rec-ommendation systems [12, 18, 6]. In these systems, only statistics from users X  navigation or rating data are used as features to train a maximum entropy model. Therefore, the advantage of integrating multiple knowledge sources is not fully exploited.

In this paper, we propose a novel Web recommendation system, in which users X  navigational or rating data and the semantic content features associated with items are seam-lessly integrated under the maximum entropy principle. First, we discover statistics from users X  navigation data and use them as one set of constraints. Secondly, for content infor-mation, we use a new approach based on Latent Dirichlet Allocation (LDA) [1] to discover the hidden semantic rela-tionships among visited or rated items and specify another set of constraints based on these item association patterns. The LDA model is a proven approach that can uncover the hidden relationships among co-occurring objects. An exam-ple of such hidden patterns are  X  X opics X  connecting docu-ments and words [1], and the author-topic model in [9]. In our framework, the two sets of constraints are combined to fit the maximum entropy model, based on which we generate dynamic recommendations for active users.
In this section, we present our maximum entropy recom-mendation model and its algorithm. The scalability of this system is also discussed.
In this paper, we will use the following notations:
The system consists of two components. The offline com-ponent accepts constraints from the navigation/rating data and Web site content information, and estimates the model parameters. The online part reads an active user session and runs the recommendation algorithm to generate recom-mendations (a set of pages or rating predictions for unrated items) for the user.

We use the following approach to generate predictions or recommendations for active users. In case of navigation data, the conditional probability Pr ( t d | H ( u i )) of a page being visited next given a user X  X  recent navigational history H ( u i ). In case of rating data, the conditional probability Pr ( &lt;t d ,r d &gt; | H ( u i )) of an item t d receiving rating given a user X  X  recent rating history H ( u i ).

In our model, we use two sources of knowledge about Web users X  navigational behavior, namely features based on item-level usage patterns, and features based on item content associations. Features will be presented in Section 3. Based on each feature f s , we represent a constraint as: where D ( H ( u i )) denotes the page following u i  X  X  history in the training data. Each constraint specifies that the ex-pected value of each feature w.r.t. the model distribution should always equal its observation value in the training data. After defining a set of features F = { f 1 ,f 2 ,  X  X  X  ,f and generating constraints for each feature, it X  X  guaranteed that, under all the constraints, a unique distribution exists with maximum entropy [3]. This distribution has the form: where Z ( H ( u i )) = t tion constant ensuring that the distribution sums to 1, and  X  s are the parameters needed to be estimated . Thus, each source of knowledge can be represented as features (and constraints) with associated weights. By using Equation 2, all knowledge sources (represented by various features) are taken into account to make predictions about users X  next action given their past navigation.

Therehavebeenseveralalgorithmswhichcanbeapplied to estimate the  X  s. Here we use the Sequential Conditional Generalized Iterative Scaling (SCGIS) [2], which seems to be very efficient. To boost efficiency techniques such as dimen-sionality reduction using clustering [2, 11], efficient training algorithms [7], and automatic feature selection methods can be used.
After we have estimated the parameters associated with each feature, we can use Equation 2 to compute the probabil-ity of any unvisited page t i being visited next given certain user X  X  history, and then pick the pages with highest proba-bilities as recommendations, i.e. we compute the conditional probability Pr ( t i | u a ) given an active user u a .Thenwesort all pages based on the probabilities and pick the top N pages to get a recommendation set. The algorithm is as follows:
Input: an active user session u a , parameters  X  sestimated from the training data.

Output: a list of N pages sorted by probability of being visited next given u a . 1. Consider the last pages of the active user session, for 2. Using Equation 2 to compute Pr ( t i | u a ). 3. Sort all the pages in descending order of Pr ( t i | u
In case of making a rating prediction for a target item t we consider all rated items with their ratings as this user X  X  history H ( u i ). Then we consider each possible rating (1-5) for the target item and evaluate all the features. We choose the rating r d with the highest probability Pr ( &lt;t d ,r | H ( u i )) as predicted rating for t d .
Under maximum entropy principle, each knowledge source is considered as a set of features and constraints imposed on the model. Thereafter, we will introduce our methods of identifying features from both usage and content informa-tion.
Users X  interests and preferences are implicitly embedded in their navigation/rating activities on some Web pages/items. Here we discover page/item associations from users X  naviga-tion/rating data as features.
Web site content information provides another kind of in-formation of users X  interests and preferences. For example, in a university site, if a user visited several pages which con-tain frequent words like  X  X dmission X ,  X  X pplication X , we may guess this user was interested in applying for admissions into a program. In a movie site, high ratings for  X  X ndiana Jones X  and  X  X ir Force One X  may suggest that a user is a Harrison Ford X  X  fan and enjoys Action-Adventure movies. We exploit such content features in our maximum entropy model. In text-oriented Web sites, content features may be terms or phrases extracted from pages. In sites with an underlying relational schema among object (e.g, products or movies), features can be semantic attributes associated with the ob-jects.

Generally, considering all the attributes in a site is not feasible, due to the huge number of attributes and the ir-relevancy and redundancy of many features. In this paper, we propose an attribute selection method based on the La-tent Dirichlet Allocation (LDA) model [1], first proposed in the context of text mining, used to discover the hidden  X  X opics X  underlying a corpus. Here, we assume there exist a set of hidden variables underlying the item-attribute co-occurrence data. The hidden variables can be thought of as  X  X lasses X  or  X  X ypes X  of these items, with each item be-ing probabilistically associated with multiple classes. The complete probability model is: Here, z represents a set of hidden  X  X lasses X .  X  t i denotes item t i  X  X  association with multiple  X  X lasses X  and  X  z i specifies  X  X lass X  z i as a distribution over attributes.  X  and  X  are hyperparameters of the prior of  X  and  X  .
We use the Variational Bayes technique to estimate each item X  X  association with multiple  X  X lasses X  (  X  ), and the as-sociations between  X  X lasses X  and attributes (  X  ). As shown in [1], these  X  X lasses X  themselves can be used as derived at-tributes for text classification task. We observe that most items are only strongly associated with one  X  X lass X  (based on  X  vector for each user), so we assign each item to its dominant  X  X lass X . Therefore, each  X  X lass X  comprises of a set of items which are semantically similar. To better inter-pret these  X  X lasses X , we can easily identify their prominent attributes based on  X  .

After assigning each item to a  X  X lass X , we can define our features. In the case of navigation data, for each item pair &lt;t a ,t b &gt; where t a and t b both belong to the same  X  X lass X  z , we define a feature function as:
In the case of rating data, similarly, if t a and t b both belong to the same  X  X lass X  z , we define a feature as: f
In this section, we report our experiments conducted on two data sets with different characteristics. One data set is usage data associated with a real estate Web site (together with the semantic attributes associated with the real estate properties). The second data set is data set is the EachMovie rating data often used in the context of collaborative filtering (together with content attributes associated with movies).
The primary function of the Real Estate site is to allow prospective buyers to visit various pages and information related to some 300 residential properties. The portion of the Web usage data during the period of analysis contained approximately 24,000 user sessions from 3,800 unique users. The data was filtered to limit the final data set to those users that had visited at least 3 properties. We also extracted the content attributes related to each property including price, number of bedrooms, size, school district, etc. We refer to this data set as the  X  X ealty data. X  The navigation data is randomly divided into 10 training and test sets to be used for cross-validation.

Our evaluation metric for this data set is called Hit Ratio andisusedinthecontextoftop-N recommendation frame-work: for each user session in the test set, we take the first pages as a representation of an active session to generate a top-N recommendations. We then compare the recommen-dations with page K + 1 in the test session, with a match being considered a hit . We define the Hit Ratio as the total number of hits divided by the total number of user sessions inthetestset. NotethattheHitRatioincreasesasthe value of N increases. Thus, in our experiments, we pay spe-cial attention to smaller number recommendations (between 1 and 10) that result in good hit ratios.
 Figure 1: Examples of movie classes and their top at-
The Movie data set contains a total of 2,811,983 numeric ratings (rating scale 1-6) of 72916 users for 1628 different movies. We extracted movie content information from the Internet Movie Database (http://www.imdb.com), includ-ing Movie X  X  genre, director, cast, etc. We kept 900 movies that has complete content information, and chose 5000 users who had rated at least 20 movies. The evaluation metric for this data set is the standard Mean Absolute Error (MAE). Specifically, for each user-movie pair in test set, we make a prediction for the target movie and compute the absolute deviation between the actual rating and the predicted rat-ing. MAE is defined as the sum of all the deviations divided by the total number of predictions. Note that lower MAE values represent higher recommendation accuracy.
As stated in Section 3, we use LDA to identify item groups from content information. Here we run LDA on property-attribute matrix and movie-attribute matrix respectively and assign each item to one dominant class. To illustrate these item groups, we list the top attributes (based on  X  well as the items of each class.

Figure1depictstwomovieclassesfrom20classeswegen-erate. For each class, we show the movies, top attributes and corresponding probability (  X  ) associated with the class. We can see Class 8 consists of mostly Sci-Fi movies, in-cluding the Star Trek series. Naturally attributes like  X  X d-venture X ,  X  X ction X ,  X  X ci-Fi X  have dominant probabilities. Actors from Star Trek series and director Steven Spielberg also appear on top of this list. Movie Class 11 seems to be a group of romance comedy movies, acted by Hugh Grant and Meg Ryan. As we can see attributes  X  X omance X ,  X  X rama X ,  X  X ugh Grant X  and  X  X eg Ryan X  have highest probabilities.
In this example, we see that a user has given high rat-Figure 2: Examples of real estate property classes and ing (6) to  X  X ense and Sensibility X , and the system correctly predicts the user X  X  rating (6) for  X  X our Weddings and a Funeral X . From the training data, we find that these two movies have relatively high rating similarity (0.65). At the same time, the prediction algorithm notices that the con-tent features involving them also tend to have high weights, which indicate they belong to the same movie group and share some common attributes.

Similarly, Figure 2 depicts the top attributes associates with two of the discovered classes among real estate prop-erties. In each case, the (normalized) weight indicating the importance of the attribute in the class is shown on the left. It can be seen that Class 1 represents relatively new 2-story properties in $200K-$300K range with 4-5 bedrooms all of which are located in the WDM school district. On the other hand, Class 2 represents much smaller and older properties with 1-2 bedrooms. The most prominent attribute in this group is the DSM school district.
For  X  X ealty data X , to exploit the ordering information in users X  navigation data, we built another recommenda-tion system based on the standard first-order Markov model to predict and recommend which page to visit next. The Markov-based system models each page as a state in a state diagram with each state transition labeled by the condi-tional probabilities estimated from the actual navigational data from the server log data. It generates recommendations based on the state transition probability of the last page in the active user session.

Figure 3 depicts the comparison of the Hit Ratio measures for these two recommender systems in  X  X ealty data X . The experiments show that the maximum entropy recommenda-tion system has a clear overall advantage in terms of accu-racy over the first-order Markov recommendation system on this data set.
 For the movie data, we implement a standard item-based Figure 3: Recommendation accuracy: maximum en-Figure 4: Recommendation accuracy: maximum en-collaborative filtering algorithm (Item-based CF) [16] to gen-erate predictions for users in test data for comparison. For each user we took 50% of the data as training data, and the rest as test data. For Item-based CF, we tried different neighbor sizes and used the best result achieved (with 40 neighbors). For maximum entropy model, we ran LDA to generate 20 movie groups and define features as in Section 3.
The results are shown in Figure 4. By actually looking at the cases where maximum entropy system makes better prediction, we find that in most cases, item=based CF algo-rithm can not find similar item neighbors (highest similarity is only about 0.50-0.60), which makes the predictions based on item neighbors less accurate.

One of the problems associated with some traditional rec-ommendation algorithms emanated from the sparsity of data sets to which they are applied. Data sparsity has a negative impact on the accuracy and predictability of recommenda-tions. This is one area in which, we believe, the integration of semantic knowledge with ratings data can provide signifi-cant advantage. Here we created multiple training/test data sets in which the proportion of the training data to the com-plete ratings data set was changed from 90% to 10% (For each user, we randomly select certain percentage of ratings as training data and the rest as test data). These propor-tions have a direct correspondence with the level of sparsity in the ratings data.

Figure 5 indicates that the advantage of our system over the item-based CF system tends to be more distinctive when the data gets sparser. One possible explanation is that when the training data gets sparser, we are less likely to find movie neighbors with very high rating similarity and make accurate predictions based on neighbor movies X  ratings. At this time, for maximum entropy recommendation system, some fea-tures based on movie rating similarity also get lower weights, Figure 5: Impact of Data Sparsity on Recommendations but features based on movie content similarity will be less affected and still contribute remarkable weights to make ac-curate predictions.
In this paper, we have proposed a novel Web recommenda-tion system in which users X  navigation or rating data as well as the content features accessed by the users are seamlessly integrated under the maximum entropy principle. In the case of content information, we use a new approach based on Latent Dirichlet Allocation (LDA) to discover the hidden semantic relationships among items. The resulting models are used to generate dynamic recommendations for active users. Experiments show that this approach can achieve better recommendation accuracy with small number of rec-ommendations. Furthermore, the proposed framework pro-vides reasonable accuracy in predictions in the face of high data sparsity. [1] D. Blei, A. Ng, and M. Jordan. Latent dirichlet [2] J. Goodman. Sequential conditional generalized [3] F. Jelinek. Statistical Methods for Speech Recognition . [4] J. Jeon and R. Manmatha. Using maximum entropy [5] X. Jin, Y. Zhou, and B. Mobasher. A unified approach [6] X. Jin, Y. Zhou, and B. Mobasher. Task-oriented web [7] R. Malouf. A comparison of algorithms for maximum [8] B. Mobasher, H. Dai, T. Luo, Y. Sun, and J. Zhu. [9] M.Steyvers, P. Smyth, M. Rosen-Zvi, and T. Griffiths. [10] K. Nigram, J. Lafferty, and A. McCallum. Using [11] D. Pavlov, E. Manavoglu, D. Pennock, and C. Giles. [12] D. Pavlov and D. Pennock. A maximum entropy [13] M. Pazzani. A framework for collaborative, [14] A. Popescul, L. Ungar, D. Pennock, and S. Lawrence. [15] R. Rosenfeld. Adaptive statistical language modeling: [16] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [17] K. Yu, A. Schwaighofer, V. Tresp, W. Ma, and [18] C. Zitnick and T. Kanade. Maximum entropy for
