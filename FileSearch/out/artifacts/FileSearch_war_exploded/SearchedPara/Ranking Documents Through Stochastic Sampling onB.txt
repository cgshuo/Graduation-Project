 Using approximate inference techniques, we investigate in this paper the applicability of Bayesian Networks to the problem of ranking a large set of documents. Topology of the network is a bipartite. Network parameters (conditional probability distributions) are determined through an adop-tion of the weighting scheme tf -idf . Rank of a document with respect to a given query is defined as the corresponding posterior probability, which is estimated through performing Rejection Sampling. Experimental results suggest that per-formance of the model is at least comparable to the baseline ones such as BM 25. The framework of this model poten-tially offers new and novel ways in weighting documents. Integrating the model with other ranking algorithms, mean-while, is expected to bring in performance improvement in document ranking.
 Info. Retrieval; Bayesian Networks; Stochastic Sampling Probabilistic Graphical Models [10] in the form of Bayesian Networks (BN) [6] are widely used to represent knowledge with uncertainties. In the recent years, computational tech-nologies and tools for BN-based models are becoming in-creasingly powerful. That being the case, modeling prob-lems in Information Retrieval (IR), in particular for doc-ument ranking, as probabilistic inference problems in BN-based models has achieved only limited success to date. Ma-jor reasons for such relatively small progress in BN-based approaches for document ranking are, for one, conceptually it is challenging to appropriately identify causalities in doc-ument ranking (i.e., deciding network topology) and then to accurately capture the uncertainties (i.e., deciding network parameters) in order to construct a BN model for IR; and two, computationally exact inference algorithms associated with the model is bound to be intractable as practically the size of the BN model in terms of nodes representing both the number of documents and vocabulary size in words, can be easily in a few millions.

In this paper, we investigate the applicability of BNs to the problem of ranking a large set of documents. We pro-pose a model, which specifically takes into considerations both the appropriateness in the semantics of causalities, and the computational tractability of probabilistic inferences. Topology of the network is a bipartite. Conditional prob-ability distributions are determined through adopting the weighting scheme tf -idf . Experimental results, obtained from working on both computer-generated and standard doc-ument sets suggest that performance of the model is at least comparable to the baseline ones such as BM 25 ([2, 11]).
The remainder of this paper is organized as follows. Sec-tion 2 presents the background and preliminaries. Section 3 introduces the model. Experimental results are reported and analyzed in Section 4. Section 5 concludes the paper.
In this section, document ranking in IR, and BN, are briefly reviewed. One of the fundamental tasks in IR is document-ranking: Given a set of documents D such that D = { d 1 , . . . , d and |D| = M , a set of terms T = { t 1 , . . . , t N } and |T | = N , and a collection of query terms ~q such that ~q  X  T , docu-ments in D need to be ranked in a complete order according to their respective relevance to ~q (other criteria such as  X  X i-versity X  might also be considered for ranking). To do this, a typical approach is to define a score function score ( ~q, d that returns a numeric score for each document d i  X  D with respect to ~q . Documents can then be ranked on their scores in descending order. The top S elements will be selected to construct the set S , where |S| = S .

Let tf t,d denote term frequency , the number of occurrences of term t in document d ; df t denotes document frequency , the number of documents in D that contain the term t ; and idf t = log ( M/df t ) denotes inverse document frequency . Summing up on tf t,d  X  idf t for each term t  X  ~q with respect to d defines a baseline score function for document ranking: functions of tf -idf such as BM25, can be found in [11]. In addition, collection frequency in D and its subset S , are de-fined as the total number of occurrences of t in D and in S , and denoted by cf t and sf t , respectively.
A Bayesian Network is a directed acyclic graph where nodes correspond to random variables [6]. Pairs of nodes in the graph might be connected by a directed edge. For example, given two nodes X and Y in the graph, if X enters Y , it is said that X is a parent of Y . Effect of the par-ents of a node X i n the graph is quantified by a conditional probability distribution P ( X | P arents ( X )).
BNs are often used to carry out probabilistic inference: computing posterior distribution of a set of variables given a set of evidence variables  X  variables whose values are ob-served or assigned. Consider a simple example of Baby World , which consists of four random variables H , T , C , and R , corresponding to the variable facts that the baby is Hungary , Tired , Crying , and scReaming , respectively. A BN for this world is shown in Figure 1. After all four con-ditional probability distributions as listed in the figure are specified, we could compute, for example, the probability that the baby is hungry if we observe that it is crying but not screaming: P ( H is true | C is true, and R is false).
This section presents the model, explains how samplings are performed, and justifies the merits of our model.
Suppose a user specifies a set of terms as a query ~q for a set of documents D , a subset S  X  D of documents need to be retrieved and ranked in a complete order. To be explained in this section, we formulate this problem into the problems of calculating posterior probability values in a BN-based model where the original query is treated as the observed evidence.
In our model, the probability space is induced accordingly by two sets of random variables D (document random vari-ables) and T (term random variables), where D i  X  D for 1  X  i  X  M , and T j  X  T for 1  X  j  X  N . Each document D i takes two values: V al ( D i ) = { d 1 i , d 0 i } , which represents the values of  X  D i selected with respect to a query X  ( d values of term  X  T j is a query term X  ( t 1 j ) or not ( t as shown in Figure 2, is a two-layer directed graph, which contains a node in the top layer for each document variable D i and a node in the bottom layer for each term variable T In the graph, an edge from D i to T j represents that term T j appears in the document D i . We assume no edges be-tween document variables in D , and no edges between term variables in T . In addition to the graph, two types of p robabilities need to be specified to capture the nature of the dependence of variables: P ( D i ), the prior distribution over a document D i , and P ( T j | D 1 , . . . , D M ), the conditional probability distribution of T j given D 1 , D 2 , . . . , and D In our model, P ( D i ) represents the distribution that D selected in S or not, hence it is reasonable to define, for any document D i in D , the probability that D i is eventually se-lected into S equals the ratio of the size of S to the size of D , i.e., P ( d 1 i ) = S/M .

The conditional distribution P ( T j | D 1 , . . . , D M ) specifies the distribution over the term T j , which depends on the ac-tual content of S , the set of documents selected. That is to say, specifically, for each subset of D (totally 2 M of them), we need to specify a distribution for t 1 j , the event that t is actually a query term. Since the number of parents of a term in the network is not bounded by a constant, we know that exact inference here has exponential time complexity in worst cases. Nevertheless what we really need is to cal-culate, for any document variable D i where 1  X  i  X  M , the relevance of D i to evidence  X q , i.e., the posterior probabil-ity of P ( d 1 i |  X q ), the value of which can be estimated through stochastic sampling. For simplicity in explanation, we as-sume that  X q contains only one term t , without loss of gen-erality. General reasoning problems of probabilistic inference in BNs, and even their corresponding approximate versions, are NP-hard ([4], [5]). Due to this computational intractabil-ity, one often turns to randomized sampling methods (e.g., Rejection Sampling [12], which is used in our current re-search) to approximate posterior probabilities. Asymptoti-cally accuracy of these sampling methods would usually be improved as the number of samples increases.

Given a BN and its specified prior distributions for all n variables { X 1 , X 2 , . . . , X n } , where X i  X  X for 1  X  i  X  n , forward sampling samples all nodes in X in an order consis-tent with the topological structure of the BN, and the prob-ability of a specific event, written as ( x 1 , . . . , x from forward sampling equals to Q n i =1 P ( x i | parents ( X which in turn equals to the joint distribution P ( x 1 , . . . , x Suppose totally N samples are taken, and the number of oc-currences of an event ( x 1 , . . . , x n ) equals to N ( x the ratio N ( x 1 ,...,x n ) /N is an approximation to P ( x With observation of evidence e for E , where E  X  X , the con-ditional probability P ( X = x | e ) can be further estimated through Rejection : first, all samples that do not match e are rejected in N , to obtain N 1 ; second, all samples in N and compatible with X = x are put into N 2 ; third, N 2 /N is an estimate to P ( X = x | e ).

Consider our model again and suppose there are P sam-ples where |P| = P . During sampling, we dynamically main-tain a vector of counters C , where | C | = M . All counters in C are initialized to zero. Our sampling strategy say for the j th sample P j where 1  X  j  X  P : Step 1, each docu-ment variable is sampled according to the distribution S/M ; Those selected document variables are put into S j , thus the expected value of |S j | is S. Step 2, we accept this sample if and only if the collection frequency of S j with respect to term t proportionally exceeds the one of D . Formally, the sample is accepted iff sf j t cf and D i  X  S j , c i  X  C , which is the corresponding counter for D , would be increased by one.

After completion of sampling, the set P would be mutual-exclusively partitioned into two sets, the set of accepted sam-ples P accepted , and the set of rejected ones P rejected vector C would be updated for |P accepted | times. Values
T he term ( x 1 , . . . , x n ) is an abbreviation for ( X 1 = x 1 , . . . , X n = x n ). stored in the counters of C , are actually scores for their cor-responding documents with respect to the query term t . The documents can thus be ranked according to their scores.
In the literature, considerable research in investigating po-tential linkages between BNs and IR in general, has been reported (most notably [1], [7], [13], [14]). The originality and value of our research contribution lies in the following facts.

Model Semantics. The model defines 2 ( M + N ) different states, for different combinations of truth assignments to all random variables in D  X  T . A state specifies an instance of which random variables are true and which are false. For each state, its joint probability distribution theoretically can be calculated (although computationally it might be imprac-tical). We are only interested in those states where statis-tically S out of D variables are true, since we only concern about the problem of selecting S out of D documents related to a given query.

Causality. In the model, document variables in D are designed, in consistence with common perceptions, to have direct causal influence on term in T . For example, causal relation  X  D i  X  T j  X  is interpreted as: If D i is selected to be a member of S (i.e., D i  X  S ) then the term T i should be of interest to the user.

Scalability. The size of the problem of document ranking in practise is often in the magnitude of a few millions, if not more. A network built-up from these problems is large in size and multiply connected, making it dauntingly challeng-ing to perform exact probabilistic inference. Consequently, it can be seen from the literature that experiments in earlier work (e.g., [7] and [1]), are restricted to cases with maximal a few thousand documents only. The development of BNs however has reached the point where approximate inference algorithms, such as randomized sampling, loopy propaga-tion, or variational approximation, can make a practical dif-ference. We adopt a direct sampling method in this research.
Bipartite Network Structure. The underlying undirected graph of the network is a bipartite: nodes are grouped into two types, only connections between nodes from two differ-ent types are allowed. Recently, Bayesian models on bipar-tite graphs have found their ways to modeling real-world applications in social networks, with appealing properties demonstrated [3]. It remains to be investigated how these results can be utilized into our own framework of BN for IR. Nevertheless, due to this simplicity of topological struc-ture, additional features (e.g., ontological/relational/logical representation and reasoning: see [8] for a mosaic of such proposals) can be incorporated into the current model.
In this section we compare the performance of our pro-posed model with the ones of tf -idf , BM 25 and Golden (to be explained in Section 4.1). We first work on a set of computer-generated random documents ( D 1 R , D 2 R , D and D 4 R ) and then on D 1 and D 2 , which are two subsets of WT2G, a standard TREC test collection.
To simplify matters, we assume that all generated docu-ments in D R are with same document length, which equals to the size of the vocabulary T R . For any document D r  X  D occurrences of terms in D r follow a Normal Distribution N (  X ,  X  ), where the values of mean  X  and the standard de-Figure 3: An example document (created according t o a Normal Distribution with  X  = 50 and  X  = 17 ), and its variant with the center shifted to 18 (  X  = 18 ). viation  X  can be adjusted. However all documents in D R share the same  X  and  X  . Note that the smaller the value of  X  , the terms cluster more closely to  X  . The center of a given document is shifted to a random center before being stored into a vector. To illustrate the idea, an example document with  X  = 50,  X  = 17, |D R | = 10000, and |T R | = 100, and its variant with shifted center (now,  X  = 18) is respectively shown in the left subplot (and the right one) of Figure 3. Accordingly we introduce the baseline ranking method Golden . That is, given an input query q and a document d , the score ( q, d ) is defined as the difference between the center of d , and q . When the value of score ( q, d ) is smaller (greater), it means document d is more (less) related to the term q . Golden is used as one of the three methods for comparisons in Figure 4.
We first work on four sets of randomly generated docu-ments: D 1 R , where  X  = 1250, D 2 R ,  X  = 1000, D 3 R ,  X  = 833, D
R ,  X  = 416. Between these sets from D 1 R up to D 4 R , doc-uments are more closely clustered around their means, thus intuitively more reliable in the sense of IR. Collection size, document length, and vocabulary size, are set to be all equal: |D
R | = |T R | = 10000. Experiments related to a specific set is pictorially summarized in the corresponding sub-figure in Figure 4.
 Consider Figure 4.a, for example, a term is queried against D
R , three different ranking methods, i.e., Golden, BM25, and Rejection, return three different completely ordered se-quences of 500 elements (the number 500 is obtained from |D
R |  X  0 . 05, where 0.05 is the pre-specified ratio, i.e., por-tion of all documents in D 1 R need to be ranked). Results of pair-wise comparisons between these three methods are reported in Figure 4.a, where x-axis values indicate sample sizes and y-axis values indicate how many documents out of the 500 ranked ones are actually agreed between two given methods. For example, the red dot pointed by the arrow in Figure 4.a refers to the fact that totally 336 documents are shared by the 500 documents retrieved from applying BM25 on D 1 R , and the 500 elements obtained from performing Re-jection Sampling on D 1 R (with the sample size equaling to 0.1 Million).

Documents in both D 1 and D 2 (Figure 5) are drawn from dataset collection WT2G where |D 1 | = |D 2 | = 2500, |T 1 50961 and |T 2 | = 127487. First 100 elements obtained from three different ranking methods, tf -idf , BM 25, and Rejection are pair-wise compared in Figure 5.
This section draws the major observations from the present experimental study, and discusses some implications. Figure 4: Pair-wise comparisons among the ranking m ethods Golden, BM25, and Rejection on data-sets with different standard deviations. Figure 5: Pair-wise comparisons among the ranking m ethods tf-idf, BM25, and Rejection on two data-sets (2500 documents each) from WT2G.

For more closely clustered documents, in essence all meth-ods agree more on their rankings (as shown in Figure 4, they agree most on the set D 4 R , but least on D 1 R ); Following the same argument, we should claim that D 1 is more clustered than D 2 .

In our experimental settings, increasing sample size ini-tially improves the performance sharply, but it tends to be leveling off after sample size is greater than certain value (e.g., 0.5M in the subplots of Figure 4). As the sample size increases, asymptotically the Rejection method agrees at least 80% with BM25 for almost all sets except for D 2 (around 60% only). It seems that we should conclude that the proposed BN-based model can achieve competitive per-formance levels at relatively low cost in sampling.
Since in Rejection , estimating posterior probabilities are based on the tf -idf ranking scheme, Rejection is a stochastic variant to the tf -idf ranking method. BM 25, meanwhile, can be deemed as a refinement to tf -idf . Hence, it is not a surprise that BM 25 agrees largely with Rejection . The more intriguing observation is that, with standard data-sets, the two methods disagree at least on 20% of their rank-ings. The reason as we speculate is either Rejection be-haves somewhat differently from BM 25 in practise, or sam-pling with the current settings can get trapped and do not converge. In order to unravel this intricacy, a further inves-tigation is necessary and desirable.
In this paper, document ranking in IR is transformed into the problems of estimating posterior probabilities through stochastic sampling on a BN designed for IR. Experimental results from this pilot study is quite encouraging in the sense that, with moderate sampling efforts, the model demon-strates its ranking capability comparable to BM 25. Ad-ditionally, graph-based structure and probability-based pa-rameters of the model, together with other considerations in the model, suggest that new and novel weighing schemes for document ranking are conjecturally within a reach.
Among many possible avenues, our direct future research includes 1) further evaluating performance of the model on WT2G, WT10G, and other standard dataset collections; 2) testing on parametric settings other than the current one that is based on term-frequency; 3) testing other sampling strategies (e.g., Gibbs Sampling [10], and the most recent ones [9]) to improve sampling efficiency and performance.
Feedback to this work we have received encourages us to investigate in a broader context the relationships between the proposed BN model and other term weighting models ([15, 16]). With ease, most existing probability theory-based models in IR can actually be derived in this BN-based frame-work. It is thus rather promising to exploit this framework for a deeper understanding of existing term weighting mod-els, and for the developments of new and better models in Information Retrieval.
We gratefully acknowledge the anonymous reviewers for their insightful comments and suggestions. This research is supported by a Discovery grant from the Natural Sciences and Engineering Research Council of Canada (NSERC), an NSERC CREATE award in ADERSIM 2 and an ORF-RE (Ontario Research Fund -Research Excellence) award in BRAIN Alliance 3 . h ttp://www.yorku.ca/adersim http://brainalliance.ca
