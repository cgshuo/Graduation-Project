 1. Introduction
A vital phase in geotechnical foundation design is to provide a reliable estimation of the compressibility characteristics of soils. The compressibility characteristics have a key role for the analysis of the settlement of the soil layers under the applied load ( Tiwari and Ajmera, 2012; Singh and Noor, 2012 ). In general, the soil compressibility is de fi ned as the volume reduction under pressure taking place due to the drainage of pore water. The rate of drainage of pore water is a time-dependent process because it is a function of the soil permeability. Consequently, analysis of the soil com-pressibility properties is mostly important for fi ne-grained, low permeable soils. Compression index ( C c ), coef fi cient of compressi-bility ( a v ), and coef fi cient of consolidation ( C v ) are the main indicators of the soil compressibility. Among these parameters, C is often used for the direct calculation of settlement ( Carter and Bentley, 1991; Gulhati and Datta, 2005; Singh and Noor, 2012 ). Typically, the settlement associated with load increments is obtained using the logarithm of the normal compressive stress ( ') against soil void ratio ( e ) curve. A schematic representation of the e log s ' curve is illustrated in Fig. 1 . As can be seen in this fi gure, the characteristic curve has two distinct regions: (1) an elastic rebound curve and (2) a linear virgin compression curve at higher stresses. C c is the modulus of the slope of the virgin compression curve which is usually obtained from a standard consolidation (oedometer) test on an undisturbed sample ( Gregory et al., 2006 ). Subsequently, the total settlement ( S a layer of normally consolidated clay can be determined using the following equation: S  X  H C c where e 0 is the initial void ratio, s ' is the effective overburden pressure,  X  s is the applied load, H is the thickness of the layer.
Determination of C c from the oedometer test is a cumbersome, expensive and time consuming process, especially for the fi grained soils. In order to avoid the labor of conducting consolida-tion tests, several studies have been focused on the prediction of the compressibility behavior of soils using its basic physical properties (e.g., Skempton, 1944; Nishida, 1956; Cozzolino, 1961; Terzaghi and Peck, 1967 ). Most of the existing models are devel-oped based on traditional statistical analyses which notable modeling drawbacks ( Alavi and Gandomi, 2011 ). Thus, more sophisticated methods are required to capture the complex beha-vior of C c . In this context, computational intelligence (CI) techni-ques can be considered as ef fi cient alternatives to traditional methods. They determine the structure of a prediction model by automatically learning from data. CI has different well-known branches such as arti fi cial neural network (ANN), fuzzy inference system (FIS), adaptive neuro-fuzzy system (ANFIS), and support vector machines (SVM). These techniques have been successfully employed to solve problems in engineering fi eld (e.g., Kerh and Chu, 2002; Kerh and Ting, 2005a,b; Kerh and Lee, 2006; Muttil and
Chau, 2007; Traore et al., 2010; Azamathulla and Wu, 2011; Majid et al., 2011; Cheng et al., 2012; Azamathulla et al., 2012; Ismail et al., 2013; Masmoudi and Ha X t, 2013; Emamgholizadeh et al., 2013 ).
Despite the good performance of ANNs, FIS, ANFIS, SVM and many of the other CI methods, they are considered black-box models.
That is, they are not capable of generating practical prediction equations. This is a fundamental disadvantage that limits their practicability ( Alavi and Gandomi, 2011 ). In order to cope with the limitations of the existing methods, a robust CI approach, namely genetic programming (GP) has been introduced ( Koza, 1992 ). GP is an evolutionary computational (EC) approach. The EC methods use the principle of Darwinian natural selection to generate computer programs for solving a problem. GP has several advantages over the conventional and other similar techniques. A notable feature of
GP and its variants is that they can produce highly nonlinear prediction equations without a need to pre-de fi ne the form of the existing relationship ( Sette and Boullart, 2001; Javadi et al., 2006;
 X ift X i et al., 2009; Guven, 2009; Guven et al., 2009; Gandomi et al., 2010; Gandomi and Alavi, 2011; Rezania et al., 2011; Tsai, 2011; Azamathulla et al., 2011; Alavi et al., 2011; Chen et al., 2012; Azamathulla, 2012; Mahmood et al., 2013 ).
 2002 ) is new variant of GP. MEP has a special ability to encode multiple computer programs of a problem in a single program ( Alavi et al., 2010 ). In contrast with traditional GP and its variants, and also other soft computing techniques, application of MEP in the fi eld of civil engineering is totally new and original ( Baykasoglu et al., 2008; Alavi et al., 2010; Alavi and Gandomi, 2011; Gandomi et al., 2011a; Gandomi and Alavi, 2013 ). This paper proposes the MEP technique to derive a precise predictive equa-tion for the compression index of Iranian soils from basic soil parameters. A comprehensive and reliable set of data including 108 consolidation test results was established to develop the models. The robustness of the proposed model was veri fi ed through different validation phases. 2. Review of previous studies oped to correlate C c with various index properties of soils such as the liquid limit, natural water content, plasticity index, speci gravity, and void ratio ( Skempton, 1944; Nishida, 1956; Cozzolino, 1961; Terzaghi and Peck, 1967; Sowers, 1970; Azzouz et al., 1976;
Wroth and Wood, 1978; Mayne, 1980; Park and Lee, 2011 ). Table 1 presents some of the well-known empirical prediction equations in this fi eld. Nearly all these relationships were derived by performing multiple linear regression analysis. In fact, the com-monly used regression analyses can have large uncertainties. The classical regression analysis has major limitations due to the oversimpli fi cation of the complicated mechanism of the consoli-dation process. As can be seen in Table 1 , this type of analysis assumes the structure of the model in advance by a limited number of linear or nonlinear equations. Thus, such models cannot ef fi ciently consider the highly nonlinear interactions between the soil parameters and C c .

ANNs have been used to predict the C c of soil layers ( Desai et al., 2009; Jianping et al., 2010; Farkhonde and Bolouri, 2010; Daryaee et al., 2010; Kumar and Rani, 2011; Park and Lee, 2011; Kumar et al., 2012; Rani et al., 2013 ). However, this powerful method does not provide practical predictions which limit its applicability for further analysis. 3. Evolutionary computation  X  Survival of the Fittest  X  , the EC-based methods generate computer models to solve complicated problems. Some of the well-known branches of EC are genetic algorithms (GA) ( Holland, 1975 ), evolutionary strategies (ESs) ( Rechenberg, 1973 ), and evolutionary programming (EP) ( Fogel et al., 1996 ). These techniques are collectively known as evolutionary algorithms (EAs). In general, an EA consists of an initial population of random individuals improved by a set of genetic operators (e.g., reproduction, muta-tion and recombination). The individuals are encoded solutions in the form of binary strings of numbers evaluated by some fi functions ( Coello et al., 2007 ). Improvement of the population is a process to reach the fi ttest solution with the maximum conver-gence. Typically in an EA, a population of individual is randomly created and then the members are ranked according to a fi function. The members with the highest fi tness ranking are given a higher chance to become parents for the next generation (off-spring). The approach used to generate offspring from the parents is referred to as the reproduction heuristic. Then selected mem-bers are randomly transformed into new members via mutation, recombination or crossover. These steps are repeated until the convergence conditions are satis fi ed and the fi ttest member is selected ( Fogel et al., 1996; Koza, 1992; Coello et al., 2007 ). The differences between EAs are in the way that they represent the individual structures, types of selection mechanism, forms of genetic operators, and measures of performance.

GA has been shown to be a suitably robust EA for dealing with a wide variety of complex civil engineering problems (e.g. Keedwell and Khu, 2005; Castilho et al., 2007; Sanchis et al., 2010 ). GP is a specialization of GA where the encoded solutions (individuals) are computer programs rather than binary strings ( Banzhaf et al., 1998 ). Fig. 2 shows a comparison of the encoded solutions (individuals) by GA and GP. In GP, inputs and corresponding output data samples are known and the main goal is to generate predictive models relating them (see Fig. 3 )( Weise, 2009 ).
There GP solutions are represented in different ways such tree-shaped, graph-shaped and linear encodings ( Banzhaf et al., 1998; Alavi and Gandomi, 2011 ). Tree-shaped is the mostly widely used representation of the GP programs. However, the emphasis of the present study is placed on the linear-based GP techniques. 3.1. Expression programming
Recently, several linear variants of GP have been developed such as linear genetic programming (LGP) ( Brameier and Banzhaf, 2007 ), gene expression programming (GEP) ( Ferreira 2001 ), multi-expression programming (MEP) ( Oltean and Dumitrescu, 2002 ), grammatical evolution (GE) ( Ryan and O  X  Neill, 1998 ), and cartesian genetic programming (CGP) ( Miller and Thomson, 2002 ). These variants make a clear distinction between the genotype and the phenotype of an individual. Thus, the individuals are represented as linear strings that are decoded and expressed like nonlinear entities (trees) ( Oltean and Gros  X  an, 2003 ). There are some main reasons for using linear GP. Computers do not naturally run tree-shaped programs. Therefore, slow interpreters have to be used as a part of classical tree-based GP. Conversely, by evolving the binary bit patterns, the use of an expensive interpreter is avoided. Con-sequently, a linear GP system can run several orders of magnitude faster than comparable interpreting systems. The enhanced speed of the linear variants of GP (e.g., LGP and MEP) permits conducting many runs in realistic timeframes. This leads to deriving consistent and high-precision models with little customization ( Francone and Deschaine, 2004; Poli et al., 2007; Gandomi et al., 2011b ).
EP techniques such as GEP and MEP are the most common linear-based GP methods. MEP was fi rst introduced by Oltean and Dumitrescu (2002) . Linear chromosomes are used by MEP for solution encoding. This technique encodes multiple computer programs in a single chromosome. A program with the best fi represents the chromosome. The MEP decoding process is not more complicated than other GP variants storing a single program in a chromosome ( Alavi et al., 2010 ). The steady-state algorithm of MEP starts by the creation of a random population of computer programs. MEP uses the following steps to evolve the best program until a termination condition is reached ( Oltean and Gros  X  an, 2003 ; Alavi et al., 2010 ; Alavi and Gandomi, 2011 ):
I. Selection of two parents using a binary tournament procedure II. Obtaining two offspring by the recombination of two parents. III. Mutation of the offspring and replacement of the worst
The representation of the MEP solutions is similar to the procedure followed by C and Pascal to convert expressions into a machine code. Functions and terminals are a part of a population member created by MEP ( Alavi et al., 2010; Alavi and Gandomi, 2011 ). The terminal and function symbols are elements in the terminal and function sets, respectively. A function set can contain the basic arithmetic operations or any other mathematical func-tions. The terminal set can contain numerical constants, logical constants and variables. Each gene encodes a terminal or a function symbol. The fi rst symbol in a chromosome is a terminal symbol. An example of a MEP chromosome is as given below: 1: A 2: B 3: n 1, 2 4: 2, 3 and B are the elements of the terminal set. The MEP individuals are converted into programs by reading the chromosome top-down starting with the fi rst position. In this example, genes 1 and 2 encode simple expressions which are E 1  X  A and E 2  X  B . Gene 3 indicates the operation  X  n  X  on the operands located at positions 1 and 2. Therefore, gene 3 encodes the expression: E 3  X  A 4 indicates the operation  X   X  on the operands located at positions 2 and 3. Therefore, gene 4 encodes the expression: E 4  X  B ( A
Each of the above expressions can be considered as a possible solution. The MEP chromosomes can be illustrated as a forest of trees rather than a single tree because of their multi-expression representation (see Fig. 4 )( Alavi et al., 2010; Alavi and Gandomi, 2011 ). The best expression is selected after controlling the of all expression in an MEP chromosome using the following equation ( Oltean and Gros  X  an, 2003 ): f  X  min
 X  in which n is the number of fi tness cases; E j is the expected value for the fi tness case j ; O j i is the value returned for the j th case by the i th expression encoded in the current chromosome, and m is the number of chromosome genes ( Alavi et al., 2010;
Alavi and Gandomi, 2011 ). 4. Formulation for compression index of fi ne-grained soils impact of several parameters should be incorporated into the model development. The general forms of the existing prediction equations, represented in Table 1 , indicate that C c mainly depends on the soil physical properties. Referring to the form of the existing models ( Skempton, 1944; Nishida, 1956; Cozzolino, 1961; Terzaghi and Peck, 1967; Sowers, 1970; Azzouz et al., 1976; Mayne, 1980; Park and Lee, 2011 ), the proposed model for the prediction of the
C c of fi ne-grained soils was considered to be a function of the following parameters: C c  X  f  X  LL ; PL ; e 0  X  X  3
 X  where LL (%) is the liquid limit, PL (%) is the plastic limit, e initial void ratio.
 mentioning that the main purpose of this research was to prove the possibility of providing good estimations of the C c of soil by using only its basic physical properties. That is why only LL , PL and e 0 were considered as the predictor variables. Determining LL , PL and e 0 does not require complicated laboratory tests compared to the consolidation tests. Therefore, using these basic soil properties to make precise predictions of C c would result in a signi savings for many geotechnical investigations. Besides, the LL , PL and void ratio are rationally correlated to the natural water content for saturated soils ( Bartlett and Lee, 2004 ). precise model are as follows: 1. Determination of input and output variables of the model. 2. Collect data set S containing intrinsic soil properties ( LL , PL and 3. Divide S into three subsets: learning ( S Learning ), validation 4. Run the MEP algorithm to estimate relation between input and 5. Pick the best MEP model based on the following criteria ( Alavi 6. Run MEP for S Testing . 7. Calculate the parameters for evaluating the performance of the correlation coef fi cient ( R ), root mean squared error (RMSE) and mean percent error (MAE) were used:
R  X 
RMSE  X 
MAE  X  1 n  X  n where h i and t i are, respectively, the actual and predicted output values for the i th output, h i and t i are, respectively, the average of the actual and predicted outputs, and n is the number of samples. 4.1. Experimental database
The data used for the model development consist of consolidation and index property test results for samples obtained from different locations in Khorasan Razavi Province, Iran. All the tests were performed under similar conditions and using the same technique. The soil sampleswerepickedupfromtestpitsat0.5  X  1.0 m depth. The database includes a fairly wide range of soil index properties. The physical and plastic characteristics of soil were determined through extensive geotechnical laboratory tests. Conventional oedometer tests were performed to determine C c . The testing procedure was as described in Abbasim et al. (2012 ). A conventional oedometer apparatus having brass ring, 75 mm in diameter and 20 mm height was used to perform the tests. The top and bottom of the specimens were covered by saturated porous stones and fi lter papers. The cell containing ring and specimen was submerged and allowed to saturate for 24 h. Then, vertical dead load was applied using a loading device until there was no change in dial gauge reading for two consecutive hours. Other details of the test were performed in general accordance with ASTM D2435 procedure for one-dimensional consolidation properties of soils ( ASTM D2435, 2000 ). At the end of each test, the variation of void ratio versus pressure was plotted for each specimen on a semi-logarithmic scale to obtain the C values ( Abbasim et al., 2012 ). It should be noted that the one-dimensional consolidation and basic g eotechnical characterization tests are very well-known tests. Thus, for brevity, it was not within the scope of this study to provide all the details about them. The information cited in this table includes LL , PL ,and e 0 . C s is the measured compression index. The database comprises 101 test results on fi ne-grained soil samples. To develop a generalized correlation, a previously published database of seven consolidation tests was further added to the available experimental results. Different soi l types used in this study were silty clay with sand (CL  X  ML), gravelly lean clay with sand (CL), and silty, clayey sand (SC  X  SM). The descriptive statistics of the test results are given in Table 2 .

To visualize the distribution of the samples, the data are presented by frequency histograms ( Fig. 6 ). As we can observe from Fig. 6 , the distributions of the predictor variables are not uniform. The derived model provides better predictions for the cases where the densities of the variables are higher. 4.2. Data classi fi cation
Over fi tting is one of the essential problems in generalization of the CI techniques. Over fi tting is a case in which the error on the learning set is driven to a very small value, but when new data presented to the model, the error becomes very large. An approach to avoid over fi tting is to test individuals from the run on a validation set to fi nd a better generalization. Then, another data set should be used at the end of the data analysis to verify the generalization performance of the model ( Banzhaf et al., 1998; Gandomi et al., 2011b ). Accordingly, in the present study, the available data sets were randomly classi fi ed into three subsets: (1) learning, (2) validation, and (3) test subsets. The learning set was used to fi t the models and the validation set was used to estimate the prediction error for model selection. Thus, both of the learning and validation data were involved in the modeling process and were categorized into one group referred to as training data ( Alavi et al., 2011 ). Finally, the test set was employed for the evaluation of the generalization ability of the fi model. The training, validation and test data are usually taken as 50  X  70%, 15  X  25% and 15  X  25% of all data, respectively ( Shahin and Jaksa, 2005; Alavi et al., 2011 ). In the present study, about 80% of the data sets were taken for the training and validation processes (71 data vectors for the training process and 16 data sets as the validation data). The remaining 20% of the data sets were used for the testing of the obtained models. 4.3. Development of the MEP-based model
An extensive trial study was performed to select the most relevant input parameters for the MEP model. Table 3 presents various parameters involved in the MEP algorithm. There are eight parameters for MEP to be tuned. Several runs were conducted to obtain a parameterization of MEP with enough robustness and generalization. The MEP parameters were changed for different runs to fi nd the global solution. The parameters were selected on the basis of both previously suggested values ( Baykasoglu et al., 2008; Alavi et al., 2010; Alavi and Gandomi, 2011; Gandomi et al., 2011a; Gandomi and Alavi, 2013 ) and making several preliminary runs and observing the performance behavior. As shown in Table 3 , the number of generations was set to 100, 300 and 500. A fairly large number of generations were tested on each run to fi model with minimum error. For each case, the program was run until there was no longer signi fi cant improvement in the perfor-mance of the models or the runs was terminated automatically. Three different values were set for the population size. Large populations were used with the runs to guarantee suf fi cient diversity ( Alavi et al., 2010; Gandomi and Alavi, 2013 ). Two different values were considered for the crossover and mutation rates. The success of the algorithms usually increases with increasing the chromosome length in MEP. In this case, the complexity of the evolved functions increases and the speed of the algorithm decreases. Different optimal levels were considered for this para-meter as tradeoffs between the running time and the complexity of the evolved solutions ( Alavi et al., 2010; Gandomi and Alavi, 2013 ). Basic arithmetic operators and mathematical functions were uti-lized to get the optimum model. There are 3 4 2 2 3  X  144 different combinations of the parameters. All these parameter combinations were tested and three replications for each were carried out. Therefore, the overall number of optimal individual runs is equal to 144 3  X  432. The source code of MEP ( Oltean, 2004 )inC  X  X  was modi fi ed by the authors to be utilizable for the available problems.
 soils was in the form of following equation:
C c  X  7
The prediction results provided by the best solution found by MEP are illustrated in Fig. 7 . The number of generation, population size, mutation rate, crossover rate, and chromosome length for the optimal run were equal to 500, 3000, 10, 95, and 80, respectively. 5. Performance analysis and validation proposed the following statistical criteria: ( Alavi et al., 2011 ). It can be observed from Fig. 7 that the MEP model, with R 4 0.8 and low RMSE and MAE values, is able to predict the target values with an acceptable degree of accuracy.
The performance of the model on the training and testing data suggests that it has both good predictive ability and generalization performance. The reliability of the models created by MEP is notably dependant on the amount of data used for the training process ( Alavi et al., 2011 ). In this context, Frank and Todeschini (1994) argue that the minimum ratio of the number of data sets in the database over the number of predictor variables (inputs) for model acceptability is 3. Also, they suggest that considering a higher ratio equal to 5 is safer. In the present study, this ratio is higher and is equal to 108/3  X  36.

Tropsha (2002) were checked for external validation of the models on the testing data sets. It is suggested that at least one slope of regression lines ( k or k ' ) through the origin should be close to 1. k is the slope of the regression line in plot of actual ( h predicted ( t i ) values. k ' is the slope of the regression line in plot of t i against h i values ( Golbraikh and Tropsha, 2002 ). Recently, Roy and Roy (2008) introduced a con fi rm indicator of the external predictability of models ( R m ). For R m 4 0.5, the condition is satis fi ed. Either the squared correlation coef fi cient (through the origin) between predicted and experimental values ( Ro 2 ), or the coef fi cient between experimental and predicted values ( Ro ' should be close to 1. The considered validation criteria and the relevant results obtained by the models are presented in Table 4 . As it is seen, the derived model satis fi es the required conditions.
For the R m criterion, it slightly violates the condition. The valida-tion phase ensures the derived MEP model is strongly valid and it is not established by chance. Note that the proposed model was developed using the basic soil physical properties ( LL , PL , and e and, therefore, it can easily be used for prediction purposes via hand calculations.
 compared with those provided by an ANN model developed in this study. The ANN model was established upon the same data used for the development of the MEP-based model. Various training algorithms are implemented for the training of the ANN network such as gradient descent (traingd), Levenberg  X  Marquardt (trainlm), Quasi-Newton back-propagation (trainbfg), and resilient (trainrp) back propagation algorithms. The best results were obtained by the Quasi-Newton back-propagation method. Also, the transfer function between the input and the hidden layer was log-sigmoid of form 1/(1  X  e x ). A linear transfer function (purelin) was adopted between the hidden layer and the output layer. The ANN architecture that gave the best results for the prediction of C was found to contain: One invariant input layer, with three ( LL , PL and e 0 ) arguments. One invariant output layer with 1 node providing the value of One hidden layer having 7 ( m  X  7) nodes.

The R , RMSE and MAE values of the ANN model on the training data were equal to 0.933, 0.017 and 0.012, respectively. The performance of ANN on the testing data was also good ( R  X  0.927; RMSE  X  0.017; MAE  X  0.014). As it is, the ANN model slightly outperforms the MEP model on the training and testing data. However, this insigni fi cant performance difference would not question the capabilities of MEP. In fact, MEP possesses a notable advantage over ANN. MEP has a great capability in generating a transparent and structured representation of the system being studied. Due to the large complexity of the network structure, ANN does not give a transparent function relating the inputs to the corresponding outputs.

Besides, Fig. 8 presents a comparative study between the results obtained by proposed MEP and ANN models and those provided by the well-known models of Skempton (1944) , Nishida (1956) , Cozzolino (1961) , Terzaghi and Peck (1967) , Sowers (1970) , Azzouz et al. (1976) , Mayne (1980) , and Park and Lee (2011) . The performance of the models was evaluated on the entire database. As can be observed from Fig. 8 , the ANN model has the best performance followed by the MEP model. The proposed MEP formula notably outperforms the existing regression-based models. In particular, the prediction error values ( RMSE and MAE ) for the existing models are much higher than those for the MEP model. It is worth mentioning that most of the existing models are derived based on the traditional statistical analyses (e. g. regression analysis). The major limitation of this type of analysis is that the structures of the models are designated after controlling only few equations established in advance. Thus, such models cannot ef fi ciently consider the interactions between the depen-dent and independent variables ( Alavi et al., 2011 ). On the other hand, MEP introduces completely new features. Conversely from the empirical and analytical methods, a major distinction of MEP for determining C c lies in its powerful ability to model the mechanical behavior without requesting a prior form of the existing relationships or any assumptions. The best equations generated by the MEP technique are determined after controlling numerous linear and nonlinear preliminary models ( Alavi et al., 2011; Alavi and Gandomi, 2011 ). It is worth mentioning that the MEP algorithm is parameter sensitive. The performance of MEP can be improved by using any form of optimally controlling the parameters of the run ( Dimopoulos and Zalzala, 2001 ). In this context, further research can be focused on hybridizing MEP with other optimization algorithms such as GAs, simulated annealing, ant colony, or tabu search. 6. Parametric and sensitivity analyses
In order to ensure the validity of MEP-based model, a com-parative parametric analysis was performed. The parametric analysis represents the response of the C c in the MEP-based model to the variation of the input variables. The methodology is based on changing only one predictor variable at a time while the other variables are kept constant at the average values of their entire data set. This procedure is repeated using another variable until the model response is obtained for all the predictor variables ( Alavi et al., 2011 ). The robustness of the design equations is determined by examining how well the predicted values agree with the underlying physical behavior of the investigated system ( Kuo et al., 2009 ). Fig. 9 shows the tendency of the C c to the variations of the in fl uencing parameters, i.e., LL , PL and e
Fig. 9 indicates that C c notably increases with increasing e results of the parametric analysis for LL and PL are more compli-cated than those for e 0 . Depending on the ranges of e 0 behavior of the model differs. For e 0 between 0.5 and 0.7, it can be observed from Fig. 9 (a) that the model is not very sensitive to the changes of LL .For e 0 higher than 0.9, which represents the
C
C
C
C
C range for soft clay, C c increases with increasing LL up to about 36% and thereafter the increment declines for higher LL values. As shown in Fig. 9 (b), for e 0 between 0.5 and 0.7, C c increases with increasing PL up to about 18% and thereafter the increment declines for higher PL values. For e 0 higher than 0.9, the results are different. In this case, C c increases with increasing PL up to 18% and afterward it starts decreasing.

Providing an estimation of relative importance of each para-meter is an important concern for the aim of model developments or fi eld investigations. As discussed before, the effect of all the considered parameters (i.e., LL , PL and e 0 )on C c is well understood. Ignoring any of these three parameters for the model development resulted in a model with poor performance. Herein, a sensitivity analysis was conducted to provide a more in depth understanding of the contribution of these important parameters to the predic-tion of C c . A common approach for the sensitivity analysis in the GP-based modeling is to obtain the frequency values of the input parameters ( Francone, 1998-2004; Alavi et al., 2011; Gandomi et al., 2011a,b ). A frequency value equal to 100% for an input indicates that this input variable has been appeared in 100% of the best 30 programs evolved by MEP. The sensitivity analysis results are summarized in Fig. 10 . This fi gure indicates that MEP-based model is more sensitive to e 0 , LL and PL . There is a good agreement between the results of the MEP sensitivity analysis and those reported by other researchers ( Daryaee et al., 2010 ). 7. Conclusion
This paper aimed at developing a new nonlinear MEP-based model for the estimation of the C c of fi ne-grained soils using LL , PL and e 0 . A comprehensive database was used for the development of the proposed model. The optimal MEP-based model was selected after several assessment procedures. The validation of the model was veri fi ed with different criteria. The results indicate that the proposed model provides precise estimations of C derived model has a notably better performance than the existing traditional models. Although the existing linear regression-based models may yield accurate results for their relevant databases, their success for other data sets cannot be trusted. This is due to high nonlinearity in the soil compressibility behavior. Despite the slightly better performance of ANN for the investigated problem, a major advantage of MEP over ANN is that it provides simpli equations that can be readily used for the design purposed via hand calculating.

A general criticism about the GP-based models is that they are only randomly formed functions which are not based on the physical processes. This ambiguity was illuminated by the parametric and sensitivity anal yses. The consistency between the parametric and sensitivity analysis results and the known behavior of C c indicates that the derived model is a meaningful combination of the predictor variables. However, MEP uses only the experimental data to specify the model structure. Thus, the derived model mainly has a predictive capability within the data range used for its calibration. This model can be improved to make more accurate predictions for a wider range by including the data for other soil types and test conditions. In general, the models derived using this method are suggested to be used for pre-planning and pre-design purposes or to check the general validity of the laboratory or fi eld test results. Moreover, these models are good alternatives to determine C c when testing is not possible.
 References
