 Each year many ACM SIG communities will recognize an out-standing researcher through an award in honor of his or her pro-found impact and numerous research contributions. This work is the first to investigate an automated mechanism to help in selecting future award winners. We approach the problem as a researchers X  expertise ranking problem, and propose a temporal probabilistic ranking model which combines content with citation network anal-ysis. Experimental results based on real-world citation data and his-torical awardees indicate that some kinds of SIG awards are well-modeled by this approach.
 Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Performance Keywords: citation network, link analysis, temporal correlation
Each year many ACM SIG communities will recognize an out-standing researcher through an award in honor of his or her pro-found impact and numerous research contributions. The most re-cent Salton award winner (year 2009) in the SIGIR community, for example, Dr. Susan Dumais, is widely acknowledged as an IR expert due to her contributions in both theoretical development and practical implementations of Latent Semantic Indexing and question-answering. Winning such an award is thus a particularly strong indication of expertise and prestige in a given field. Even though there has been research in evaluating scientists X  reputation and thus finding experts in a certain field, no work has developed an automatic and efficient mechanism in selecting future award win-ners. This work takes the first step into this problem.
We approach the problem as a res earchers X  expertise ranking problem. In one direction of the approaches in evaluating the exper-tise of a researcher, different information probabilistic models have been provided, including language model [1], voting model [5], and discriminative model [3], which mainly emphasize evaluating the relevance between supporting documents and thus the correspond-ing authors with the query. Another direction of research, which is the research focus of this poster, takes use of social network analysis [2, 8] to boost ranking performance. However, in both of these approaches, one important factor has largely been ignored by previous research: temporal information. As the awards of a SIG community are often issued annually, the authority of a researcher varies over time. In this paper, we propose a novel temporal citation network analysis model to predict SIG-award winners.

Our weighted citation network can be represented as G=&lt;A,E&gt;, where A is a set of author nodes, and E is a set of edges. Two types of relationships (edges) between pairs of authors have been consid-ered: coauthorship and citations. Thus, ( a i ,a j )  X  E if author a coauthored with author a j or if at least one of the publications of author a i cites a publication of a j .
We introduce four temporal factors to represent an individual researcher X  X  academic activity. 1) CareerT ime : How long has a researcher been publishing papers? We assume that the longer the career time a researcher has, the higher authority he may have. 2) LastRestT ime : How many years have passed since the last publication of a researcher? We assume that a long time without academic output will negatively aff ect a researcher X  X  scholarly rep-utation. 3) PubInterval : How many years on average would a researcher take between every two consecutive publications? We assume that more frequent publication indicates more active aca-demic participation. There is one other temporal factor which con-siders the long-lasting influence of a researcher X  X  publication, and thus indirectly represents the influence of the researcher. We as-sume that if a paper continues to be cited a long time after its publi-cation, it brings higher prestige to its author (e.g., the paper PageR-ank [6] is frequently and persistently cited by subsequent papers). To model this temporal factor, we first introduce a decay function to differentiate the weight between a pair of paper citations. If pa-per p j published in year y j cites another paper p i published in year y ( y j  X  y i )  X  0 ,wedefinethe citation influence ratio of paper p on p i as: CIR ( p ji )=  X  1 (1  X   X  y j  X  y i 2 ) ,where  X  is the decay base. We now define the citation influence between a pair of authors as: CI ( a ji )= of author a j , p i is any paper of a i ,and p j cites p i
Based upon the discussion above, we define an individual tem-poral importance ( ITI ) to model the researcher X  X  academic au-thority in terms of time. The ITI of author a i can be ex-pressed as: ITI i = CareerT ime i  X  (1 /LastRestT ime i )  X  (1 /P ubInterval i ) . The weight on an edge from a i to a j then be defined as:  X  ( a ij )=( NumCo ( a ij )+ CI ( a ij where NumCo ( a ij ) is the number of times author a i coauthored with a j . We normalize the weights on edges over the whole net-work by defining the propagation probability from a i to a P ( propagate more authority to author a j if they coauthored more of-ten, if a i has greater citation influence on a j ,orif a individual temporal importance. Similar to the original PageRank Table 2: Top20%: Individual SIG Award Prediction Results [6] function, the propagation function in our model can be repre-sented as: PR ( i )=(1  X  d ) is N is the total number of author nodes.
From the ACM digital library 1 , we crawled the descriptive web pages for published papers as our experimental dataset. For each publication, we extracted and recorded the information of its pub-lishing year, authors, and citation references. We finally captured 170,897 authors and 172,890 papers. We retrieved for each year a time-based subset of all the papers and authors, which means if we aim to predict the award winners of 2009, we would first retrieve all the papers published before 2009, and their corresponding authors to build the graph.
In the portal website of Microsoft Academic Search 2 (a free computer science bibliography search engine), we found 23 cate-gories covering the main disciplines of computer science research. For 6 of them, we collected the corresponding SIG awards in the ACM community. They are the awards for SIGCSE (20), SIG-PLAN (19), SIGCOMM (18), SIGMOD (17), SIGARCH (17), SIGSOFT (15). We choose them because they have more exam-ples of award winners. We furthermore collected the award win-ners for SIGKDD (7) and SIGIR (5) community for the sake of our interests. The number in the parenthesis indicates the number of award winners from 1990 to 2009 (our predicting period) that can be found in our dataset. As a result, we used these 8 categories as testing queries, and the 118 existing award winners as ground truth.
We further generate a profile for each author a by concatenating all of his publications in terms of title, abstract and ACM cate-gories, and combine the citation network ranking results with the Okapi BM25 [7] ranking results as:  X   X  rank BM 25 ( a )+(1  X  rank CitationNetwork ( a ) .  X  is tuned between 0 and 1 to get the best outcome for each award winner. Three metrics have been used to evaluate the performance of an algorithm. 1) NumTop10 :the total number of award winners that can be ranked within the Top 10. 2) NumTop20 : the total number of award winners that can be ranked within the Top 20. 3) MRR-All : the average MRR score across all award winners.
We compared our model with several existing algorithms pre-viously used in citation network analysis work or expert-finding work. They include the ranking by 1) overall number of publica-http://portal.acm.org http://academic.research.microsoft.com tions (NumPub), 2) overall number of citations (NumCit), 3) in-domain NumPub [8], 4) in-domain NumCit [8], 5) H-index [4], 6) Language-Model based approach as introduced in [1], and 7) CoRank algorithm as introduced in [9]. We also run a weighted PageRank (referred to as PR) on the network, where when com-pared with our Temporal Authority Propagation (referred to as TAP) model, no temporal information is considered. The weights on a edge from a i to a j would then be defined as:  X  ( a NumCo ( a ij )+ NumCit ( a ij ) ,where NumCit ( a ij ) is the num-ber of times author a i cites a j . We combined each baseline algo-rithm X  X  (except 6) ranking results with the BM25 ranking results and tuned the  X  to achieve the best performance for each award winner. Parameters  X  1 and  X  2 play important roles in our TAP model. Preliminary experiments show that the best performance of our model will be achieved when  X  1 is set to 1, and  X  2 is set to 0.9. As indicated in Table 1, our model can retrieve 47 award winners within Top 20, which is 39.8% of all the existing awards winners in our data set. NumCit and in-domain NumCit give the best perfor-mance in terms of NumTop20 among all non-temporal algorithms, while our algorithm improves their performance by 17.5%. We also investigated the influence of NumCo and the four temporal factors and found that all were necessary to achieve the reported performance.

We are interested in finding out what fraction of all award win-ners in each SIG community can be ranked within Top 20. As indicated in Table 2, our model can make good predictions on sev-eral awards, such as SIGKDD, SIGMOD, and SIGIR, but compar-atively worse on others, such as SIGCOMM and SIGPLAN.
 This work was supported in part by a grant from the National Sci-ence Foundation under award IIS-0545875.
