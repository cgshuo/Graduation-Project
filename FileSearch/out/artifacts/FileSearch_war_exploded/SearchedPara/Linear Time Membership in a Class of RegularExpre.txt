 The extension of Regular Expressions (REs) with an inter-leaving ( shuffle ) operator has been proposed in many oc-casions, since it would be crucial to deal with unordered data. However, interleaving badly affects the complexity of basic operations, and, expecially, makes membership NP-hard [13], which is unacceptable for most uses of REs.
REs form the basis of most XML type languages, such as DTDs and XML Schema types, and XDuce types [16, 11]. In this context, the interleaving operator would be a natural addition to the language of REs, as witnessed by the presence of limited forms of interleaving in XSD (the all group), Relax-NG, and SGML, provided that the NP-hardness of membership could be avoided.

We present here a restricted class of REs with interleaving and counting which admits a linear membership algorithm, and which is expressive enough to cover the vast majority of real-world XML types.

We first present an algorithm for membership of a list of words into a RE with interleaving and counting, based on the translation of the RE into a set of constraints. We generalize the approach in order to check membership of XML trees into a class of EDTDs with interleaving and counting, which models the crucial aspects of DTDs and XSD schemas. H.2 [ Database Management ]: Miscellaneous Theory
Given a family L of extended, or restricted, regular ex-pressions, membership for L is the problem of determining whether a word w belongs to the language generated by an expression e in L . The problem is polynomial (in | w | + when L is the set of standard regular expressions based on union, concatenation, and Kleene star, which we denote as RE { + ,  X  ,  X  X  [12], and is still polynomial when intersection  X  is added to the operators. However, membership is NP-complete for RE { + ,  X  ,  X  , &amp; } , the set of REs extended with an interleaving operator &amp; (to be defined later) [13]. The simpler combinations RE { X  , &amp; } , RE { + , &amp; } and RE are already NP-hard [13], showing that the NP-hardness of membership with interleaving is quite robust.

We present here a restricted set of regular expressions with interleaving which admits a linear-time membership algo-rithm (using the RAM model to assess time complexity). The set contains those regular expressions where no symbol appears twice (called conflict-free or single-occurrence )and where Kleene star is only applied to symbol disjunctions. We generalize Kleene star to counting constraints such as a [2 .. 5] or a [1 ..  X  ]. We show how this approach can be gen-eralized to check membership of XML trees into a class of EDTDs with interleaving and counting, obtaining an algo-rithm whose time complexity is linear in the product of the input size with the maximal alternation depth of all the con-tent models in the schema. In this context, the restriction we are proposing is known to be met by the vast majority of schemas that are produced in practice [10].

Our approach is based on the translation of each regular expression into a set of constraints, as in [10]. We define a linear-time translation algorithm, and we then define a linear-time algorithm to check that a word satisfies the re-sulting constraints. The algorithm is based on the implicit representation of the constraints using a tree structure, and on the parallel verification of all constraints, using a residu-ation technique. The residuation technique transforms each constraint into the constraint that has to be verified on the rest of the word after a symbol has been read; this resid-ual constraint is computed in constant time. The notion of residuation is strongly reminiscent of the Brzozowski deriva-tive of REs [7].
We follow the terminology of [10], and we use the term type instead of regular expression . We consider the follow-ing type language with counting, disjunction, concatenation, and interleaving, for strings over a finite alphabet  X ; we use for the empty word and for the expression whose language is { } , while a [ m..n ], with a  X   X , contains the words com-posed by j repetitions of a ,with m  X  j  X  n .
More precisely, we define N  X  = N  X  X  X  X  , and extend the standard order among naturals with n  X  X  X  for each n  X  N  X  . In every type expression a [ m..n ]wehavethat m  X  ( N \ { 0 } ), n  X  ( N  X  \{ 0 } ), and n  X  m . Specifically, a [0 ..n ]is not part of the language, but we use it to abbreviate ( + a [1 ..n ]). The operator a [ m..n ] generalizes Kleene star, but can only be applied to symbols. Unbounded repetition of a disjunction of symbols, i.e. ( a 1 + ... + a n )  X  , can be expressed as (( a 1 [0 ..  X  ])&amp; ... &amp;( a n [0 ..  X  ])). String concatenation w 1  X  w 2 and language concatenation L  X  L 2 are standard. The shuffle ,or interleaving ,operator w &amp; w 2 is also standard, as follows.
 v, w  X   X   X  , or two languages L 1 ,L 2  X   X   X  , is defined as fol-lows; notice that each v i or w i may be the empty string . v &amp; w = def { v 1  X  w 1  X  ...  X  v n  X  w n Example 2.2 ( ab )&amp;( XY ) contains the permutations of abXY where a comes before b and X comes before Y : ( ab )&amp;( XY )= { abXY, aXbY, aXY b, XabY, XaY b, XY ab Definition 2.3 ( S ( w ) ,S ( T ) , Atoms ( T ) ) For any string w , S ( w ) is the set of all symbols appearing in w . For any type T ,Atoms ( T ) is the set of all atoms a [ m..n ] appearing in T , and S ( T ) is the set of all symbols appearing in T .
Semantics of types is defined as follows.
We will use to range over  X  and &amp; when we need to specify common properties, such as: T = T = T .

In this system, no type is empty. Some types contain the empty string (are nullable ), and are characterized as follows.
 Definition 2.4 (N ( T ) ) N ( T ) is a predicate on types, de-fined as follows: Lemma 2.5  X  T iff N ( T ) .
 We can now define the notion of conflict-free types. Definition 2.6 (Conflict-free types) Atype T is conflict-free if for each subexpression ( U + V ) or ( U V ) : S ( U ) S ( V )=  X  .

Equivalently, a type T is conflict-free if, for any two dis-tinct subterms a [ m..n ]and a [ m ..n ] that occur in T , a is different from a .
 Remark 2.7 The class of grammars we study is quite re-strictive, because of the conflict-free limitation and of the constraint on Kleene-star. However, similar, or stronger, constraints, have been widely studied in the context of DTDs and XSD schemas, and it has been discovered that the vast majority of real-life expressions do respect them.
Conflict-free REs have been studied, for example, as  X  X u-plicate-free X  DTDs in [17, 14], as  X  X ingle Occurrence REs X  (SOREs) in [5, 6], as  X  X onflict-free DTDs X  in [3, 2]. The specific limitation that we impose on Kleene-star is reminis-cent of Chain REs (CHAREs), as defined in [5], which are slightly more restrictive. That paper states that  X  X n exami-nation of the 819 DTDs and XSDs gathered from the Cover Pages (including many high-quality XML standards) as well as from the web at large, reveals that more than 99% of the REs occurring in practical schemas are CHAREs (and there-fore also SOREs) X . Barbosa et al., on the basis of a corpus of 26604 content models from xml.org , measure that 97,7% are conflict-free, and 94% are conflict-free and simple ,where simple is a restriction much stronger than our Kleene-star restriction [2]. Similar results about the prevalence of simple content models had been reported in [8].

Hereafter, we will silently assume that every type is conflict-free, although some of the properties we specify are valid for any type.

We show now how the semantics of a type T can be ex-pressed by a set of constraints. This alternative character-ization of type semantics will then be used for membership checking.
Constraints are expressed using the following logic, where a, b  X   X and A, B  X   X , m  X  ( N \{ 0 } ), n  X  ( N  X  \{ 0 } ), and n  X  m : Satisfaction of a constraint F by a word w , written w | = F , is defined as follows. w | = A +  X  B +  X  w | = A + or w | = B + w | = upper( A )  X  S ( w )  X  A We use the following abbreviations:
The next propositions specify that A  X  B encodes mu-tual exclusion between sets of symbols, and that A  X  denotes the absence of any symbol in A .
 Proposition 2.8 w | = a  X  b  X  a and b are not both in S ( w ) .
 Proposition 2.9 w | = A  X  B  X  w | = A +  X  B + Proposition 2.10 w | = A  X   X  w | = A + We can now define the extraction of constraints from types. To each typ e T , we associate a formula S + ( T )thattests for the presence of one of its symbols; S + ( T ) is defined as ( S ( T )) + .

We can now endow a type T with five sets of constraints, which hold for every word w  X  T . We start with those constraints whose definition is flat , since they only depend on the leaves of the syntax tree of T : Definition 2.11 (Flat constraints) Lower-bound: Cardinality:
Upper-bound: Flat constraints:
We add now the nested constraints , whose definition de-pends on the internal structure of T ; the quantification  X  X or any w  X  C [ T ]  X  X elow means X  X or any w  X  T where T is any type with a subterm T  X . All the nested constraints depend on the fact that T is conflict-free.
In the formal definition below, If T 2 ( S + ( T 1 )  X  S + denotes, by definition, true when N( T 2 ), and ( S ( T 1 ( S ( T 2 )) + otherwise. Observe that the exclusion constraints are actually encoded as order constraints.
 Definition 2.12 (Nested constraints) Co-occurrence: Order/exclusion: OC ( T 1 + T 2 )= def S ( T 1 )  X  S ( T 2 ) Nested constraints:
As a consequence of the above definition, nested con-straints have the following property.
 Proposition 2.13 ( NC ( T ) )
NC ( T 1 + T 2 )=( S ( T 1 )  X  S ( T 2 ))  X NC ( T 1 )  X NC
NC ( T 1 &amp; T 2 )= If T
NC ( T 1  X  T 2 )=( S ( T 1 )  X  S ( T 2 )) By definition, when either A or B is  X   X   X , b o t h A  X  B and A  X  B are true , hence the order constraint associated to a node where one child has S ( T i )=  X  is trivial; this typically happens with a subterm T + . For an example of nested constraint extraction, see the upper part of Figure 1.
The following theorem is proved in [10] and states that constraints provide a sound and complete characterization of type semantics.
 Theorem 2.14 Given a conflict-free type T , it holds that:
This theorem allows us to reduce membership in T to the verification of FC ( T )  X NC ( T ).
We first present an algorithm to decide membership of a word w in a type T in time O ( | w | X  depth ( T )), where depth ( T ) is defined as depth ( )= depth ( a [ m..n ]) = 1, depth ( T T )=1+max( depth ( T 1 ) , depth ( T 2 )), where stands for any binary operator. The algorithm verifies whether the word satisfies all the constraints associated with T , through a linear scan of w . The basic observation is that every sym-bol a of w transforms each constraint F into a residual con-straint F , to be satisfied by the subword w that follows the symbol, according to Table 1. We write F a  X  F to specify that F is transformed into F by a ;inallthecasesnotcov-ered by Table 1, we have that F a  X  F . We apply residuation to the nested constraints only, since flat constraints can be Table 1: Computing the residual of a nested con-straint checked in linear time by just counting the occurrences of each symbol in the word.

Residuation is extended from symbols to non-empty se-quences of symbols in the obvious way: When a word has been read up to the end, the residual constraint is satisfied iff it is satisfied by , that is, if it is different from A + or false . This is formalized by the relations F  X  G and F w  X   X  G , defined below, with G  X  { true , false } .
 A +  X  B +  X  true A +  X  B +  X  true A +  X  false false  X  false A  X  B  X  true A  X  B  X  true A  X   X  true true  X  true F  X  G  X  F  X   X  G
The following lemma specifies that residuation corresponds to the semantics of our constraints.
 Lemma 3.1 (Residuation) w | = F iff F w  X   X  true .
Residuation gives us immediately a membership algorithm of complexity O ( | w | X  X NC ( T ) | ): for each symbol a in w ,and for each constraint F in NC ( T ), we substitute F with the residual F such that F a  X  F .Theword w is in T iff no false or A + is in the final set of constraints.
 However, as discussed later, we can do much better than O ( | w | X  X NC ( T ) | ). First of all, we do not build the con-straints, but we keep them, and their residuals, implicit in a tree-shaped data structure with size O ( | T | ). The structure initially corresponds to the syntax tree of T ,encodedasa set of nodes and a Parent [] array, such that, for each node n ,Parent[ n ] is either null or a pair ( n p , direction ); n parent of n , while direction is left if n is the left child of n and is right if it is the right child (Figure 1).

The constraints, and their residuals, are encoded using the following arrays, defined on the same nodes: Figure 1: Syntax tree for T =(( a + )&amp; b [1 .. 5])  X  ( c + d and the corresponding algorithmic representation; the two nullable nodes have a double line in the pic-ture
Table 2 reports the constraint symbols that are initially associated with a node n that corresponds to a subterm T of the input type. The co-occurrence constraint depends on the nullability of T 1 and T 2 .

After the constraint representation has been built, the al-gorithm (Figure 3) reads each character a from the input word w , scans the ancestors of a [ m..n ] in the constraint tree, residuates all the constraints in this branch, and keeps track of all the A + constraints that are so generated. At the end of w , it checks that all the A + constraints have been fur-ther residuated into true . It also verifies that each symbol respects its cardinality constraints, using the Count [] array
Recall that a symbol appears at most once in each conflict-free type
Table 2: Initialization of constraint annotations. Figure 2: The tree for T =(( a + )&amp; b [1 .. 5])  X  ( c + d after word bbac has been read to record the cardinalities, and the CardinalityOK function to verify the constraints. This final check is clearly linear in w .
 Example 3.2 Consider the type T =(( a + )&amp; b [1 .. 5]) d ), where we use a to abbreviate a [1 .. 1] and a + to abbre-viate a [1 ..  X  ]. Its syntax tree is reported in Figure 1. Assume we read a word bbac .When b is read, the value of Count [ b ]issetto1. Thenode5isretrievedfrom NodeOf-Symbol [ b ], and its ancestors ( 2,right )and( 1,left )arevisited. The constraint CC [2] is  X  , the direction of b is right ,hence the constraint becomes true . The constraint CC [1] is  X  the direction is left , hence it becomes R + .Node1isalso pushed into ToCheck , since the algorithm must eventually check that every R + or L + has been residuated to true . Finally, OC [1] is not affected. When the next b is read, Count [ b ] becomes 2 (we will ignore Count [] for the next let-ters), and its ancestors are visited again, but this time none of them is changed. When a is read, CC [2] is true ,henceis not affected, and CC [1] is R + , hence is not affected. When c is read, its ancestors ( 3,left )and( 1,right )arevisited. OC [3] becomes R  X  and OC [1] becomes L  X  , so that the tree is now the one represented in figure 2.

The algorithm now verifies that Count [] respects the car-dinality constraints and that every A + node pushed into ToCheck has been residuated to true ;sincebothchecks succeed, it returns true . If the word had been bbacb . . . in-stead, the algorithm would now find a b , visit nodes ( 2,right ) and ( 1,left ), and, finding a L  X  in node 1, would return false immediately.

The constraint tree can be built in time O ( | T | ). Moreover, for every symbol a in w , we only search and update the nodes which are ancestors of NodeOfSymbol [ a ], and any such update has a constant cost, hence the resulting algorithm runs in O ( | T | + | w | X  depth ( T )).
 Theorem 3.3 (complexity) Member( w , T ) runs in time O ( | T | + | w | X  depth ( T )) .
 We can now prove that the algorithm is correct.
 Theorem 3.4 (soundness) Member( w , T ) yields true iff w  X  T .
The value of depth ( T ) can be quite large, in practice, for example for types with many fields, such as T 1  X  ...  X  T types with many alternatives, such as T 1 + ... + T n ;inthis last case, the type may be much larger than the word itself. This problem can be easily solved by flattening the con-straints generated by such types, as follows ( SIf ( T 1 ,...,T stands for { S + ( T i ) | not N( T i ) } ;if SIf ( T 1 ,...,T then CC ( T 1 ... T n )isjust true ). Informally, for each product type T 1 ... T n , if any symbol from any T i ap-pears in w , then every non-nullable T i must contribute at least a symbol to w ; the other cases are simple.
 Formally, we consider the three n-ary operators above in the syntax for types, and we generalize the syntax for con-straints as specified below. The constraints A 1  X  ,...,A and A 1  X  ...  X  A j are just two special cases of the con-straint A 1  X  ,...,A i  X  ,A i +1  X  ...  X  A i + j ,when j =0or i = 0 respectively; when both are zero, the constraint is writ-ten  X  true  X . As usual, false abbreviates (  X  ) + .Thesyntactic forms below are defined under the condition that i  X  0, j  X  0, and A 0  X  ( A 1  X  ...  X  A i +1 ).
 The semantics of these new constraints is fully defined by Table 3 plus the final conditions A 1 + ,...,A n +  X  false and F  X  true otherwise.

We correspondingly refine the data structures of the resid-uation algorithm, as follows. Co-occurrence constraints are represented by an array CC [] of records with the following is an array of booleans, and CC [ n ] .neededCount  X  N .Infor-mally, if we have a type T 1 T 2 T 3 ,where T 1 is the only nullable child, we have a constraint S + ( T 1 T 2 T 3 )  X  ( S + ( T 2 ) ,S + ( T 3 )), and we represent it through a record cc ifying that S + ( T 1 ) is  X  X ot needed X  (since T 1 is nullable), while S + ( T 2 )and S + ( T 3 ) are  X  X eeded X ; cc.neededCount would contain 2.

The first time we meet any children i , we switch the kind of cc from (  X  )to( A + ), and we set cc.needed [ i ]to false .For any other child i we meet, we will also set its cc.needed [ i ] value to false .Everytimeweswitcha needed [] entry from true to false ,wealsodecreasethevalueof cc.neededCount , so that any constraint of kind ( A + ) is satisfied when its cc.neededCount is down to zero.

Order constraints are represented by an array OC [] of records with fields kind  X  X   X   X  ,  X  ,A  X  , true } ,and allowed  X  N .Ifwehaveatype T 1  X  ...  X  T m , the corresponding oc record has oc.kind= (  X   X  )and oc.al lowed =1, which corre-sponds to a constraint S ( T 1 )  X  ...  X  S ( T m ). More gen-erally, oc.kind= (  X   X  )with oc.al lowed=i ,representsacon-straint A 1  X  ,...,A i  X  1  X  ,A i  X  ...  X  A m ,hence,whenwe meet a symbol in S ( T j ), if j&lt; allowed we return false ,and otherwise we just update oc.al lowed to j .

Finally, a type T 1 +  X  X  X  + T m is represented by oc with oc.kind= (  X  ), which is residuated into oc.kind= ( A  X  )and oc.al lowed=i when a symbol in S ( T i ) is met, and yields false if, later on, a symbol in S ( T i )ismetwith i = i .
To sum up, we represent these constraints, and their resid-uals, through the following two arrays; we assume that n is the node that corresponds to a type T whose children are T ,...,T m . Figure 4: Representation of T =( a &amp; b &amp; c )  X  ( d We present the modified parts of the algorithm in Figure 5. Example 4.1 Consider the type T =( a &amp; b &amp; c )  X  ( d f + g ) (Figure 4), where we use a to abbreviate a [1 .. 1] and a  X  to abbreviate a [1 ..  X  ]+ .

The record OC [3] is null since only one child has a non-empty set of symbols. Assume we read a word bcadddgdga . When b is read, nodes 2 and 1 are visited, and their corre-sponding constraints are residuated to: CC [2]=( A + ,[ t, f, t ],2), CC [1]=( A + ,[ f, f, t ],1), OC [1]=(  X   X  ,1). The constraint OC [1] is actually unaffected, because both allowed and the child position pos are equal to 1. Both 2 and 1 are inserted in ToCheck , since they have now an A + kind. When c is read, CC [2] becomes ( A + ,[ t, f, f ],1) and the constraints in node 1 are unaffected. When a is read, CC [2] becomes ( true ,[ f, f, f ],0), since its neededCount is 0. When d is read, 3and1arevisited; CC [1] is unaffected, since CC [1][2] is al-ready false , while OC [1] becomes (  X   X  ,2), which means that symbols from the first subtree are now disallowed. The next two d  X  X  require two new visits to 3 and 1, which have no effect. When g is read, OC [4] becomes ( A  X  ,3), CC [1] be-comes ( true ,[ f, f, f ],0), and OC [1] becomes (  X   X  ,3). If the word ended here, the algorithm would return true ,since both nodes in ToCheck have now kind true . But now a new d is read, which would residuate OC [1] to false ,hencethe algorithm stops with false .
 where flatdepth ( T ) is the depth of the type after all opera-tors have been flattened. In practice, flatdepth ( T )isalmost invariably smaller than three (see [4]), hence this algorithm is  X  X lmost linear X .
 Theorem 4.2 (soundness) MemberFlat( w , T ) yields true iff w  X  T .
 Theorem 4.3 (complexity) MemberFlat( w , T ) runs in time O ( | T | + | w | X  flatdepth ( T )) .
We present here an orthogonal optimization, which makes the algorithm truly linear.

The base algorithm visits all the ancestors of NodeOfSym-bol [ a ]everytime a is found in w , which is redundant. Con-sider a node n such that A 1 and A 2 are, respectively, the symbols in its left and right descendants. Whenever the constraint of n has been residuated because a symbol of A has been met, there is almost no reason to visit n again because of a symbol from A 1 (and the same holds for A 2 ). There is only one exception: if the constraint is A 1  X  A then, even after a symbol of A 1 has already been seen, a symbol from A 2 transforms the constraint into A 1  X  ,anda further symbol from A 1 cannot be ignored, but will cause the algorithm to yield  X  X alse X .
 Formally, we have the following  X  A 2 -stability X  property. For any constraint F with shape A 1 +  X  A 2 + , A 1 +  X  A A 1  X  A 2 or A 1  X  A 2 ,with A 1 disjoint from A 2 ,thefol-lowing holds: The same property holds for a  X  A 1 and a  X  A 1 for all the constraints but A 1  X  A 2 . Specifically, A 1 -stability is only violated when a letter b  X  A 2 is in w , as follows: a  X  A 1 ,b  X  A 2 ,a  X  A 1 :( A 1  X  A 2 ) ab  X  + ( A 1  X  )
The linear algorithm exploits this observation as follows: 1. whenever an upward pointer Parent [ child ], yielding 2. to deal with the A 1 -A 2 -A 1 case of the A 1  X  A 2 Example 5.1 Consider the type T =(( a + )&amp; b [1 .. 5]) d ) (Figures 1, 6, and 7), and assume we read a word bbac . Thefirsttimeweread b , when we visit the ancestor ( 2,right ), we assign Parent [5]= null and Deleted [2 , right ]=5, so that now 5 has no parent, but the fact that the right child of 2was5isrecorded(thepointerfrom5to2is X  X eversed X ).
 When we then visit ( 1,left ), we also assign Parent [2]= null and Deleted [1 , left ]=2. The second time b is read, the parent of 5 is found to be null, hence no action is taken, apart from counting b .When a is read, its UnvisitedAncerstors list only contains ( 2,left ), since the parent of 2 has been deleted. When node 2 is visited, we set Parent [4]= null and Deleted [2 , left ]=4. The situation is depicted in Figure 6.
Now, the arrival of any letter l from { a, b } would only increment Count [ l ], but no ancestor would be visited. When c is read, both Parent [6] and Parent [3] are deleted, but, since OC [1]=  X  and the direction is right , Reactivate(1,left) is invoked, which restores all pointers that are reachable Figure 6: The tree for T =(( a + )&amp; b [1 .. 5])  X  ( c + d after word bba has been read; the dotted lines are those that are represented into the Deleted array. from the left pointer of 1; the resulting tree is depicted in Figure 7. Figure 7: The tree for T =(( a + )&amp; b [1 .. 5])  X  ( c + d after word bbac has been read
The algorithm would now terminate with success. If a new a or b were read at this point, it would not be missed, but would cause the algorithm to stop with false .
No upward pointer can be deleted and rebuilt twice. As-sume that an edge e has been deleted and rebuilt; this only happens if e is in the left subtree of a node n with constraint A 1  X  A 2 ,andtwosymbolsfrom A 1 and A 2 have been met, and hence OC [ n ]isnow L  X  .Ifthesame e is deleted again, then the algorithm will return false as soon as the n ances-tor of e is reached. Hence, any edge is traversed at most three times, to be deleted, rebuilt, and deleted for good. Similarly, the linear algorithm visits any internal node of the type at most three times, arriving twice from the left subtree and once from the right subtree. Hence, the algo-rithm has an O ( | T | ) set-up cost, an O ( | w | ) cost to access NodeOfSymbol [ a ]for | w | times, and a total residuation cost which is bound by O ( | T | ), which gives a total of O (
The initialization of the algorithm is identical to the non-optimized version, apart from the construction of the empty Deleted [] array. The body of the algorithm only changes when pointers are cut, and in the management of the (  X  , right) case (Figure 8).
 Theorem 5.2 (soundness) MemberLin( w , T ) yields true iff w  X  T .
 Theorem 5.3 (complexity) MemberLin( w , T ) runs in time O ( | w | + | T | ) .

This optimization can be easily combined with flattening, obtaining a MemberFlatLin version, which would outper-form MemberFlat in situations where we have long words with repeated characters, and would outperform MemberLin when types are  X  X arge X , especially if the set-up phase can be shared by different runs of the algorithms, as discussed in the next section.

We now study the multi-words membership problem, i.e., the case where one type T is used to check m words w 1 ,...,w The repeated application of MemberFlatLin gives us an up-the words. This bound is not linear, in general, in the input size | T | +( m  X  X  w | ). In the special case when | T | X | m  X  ( | T | + | w | ) is smaller than 2 m  X  X  w | , hence the algorithm is indeed linear. In the general case, where | T | may be much bigger than | w | , we get a better result if we avoid re-building the T structure from scratch after each word is checked. To this aim, we build the Parent [], CC [], OC [], etc., structures once, and we also build two copies CCSave [], OCSave [] of CC [] and OC []. We then run a version MultiFlatLin of the MemberFlatLin algorithm with an undo-enabling line added immediately after the line
After each word is checked, we apply the following code to the root of the type, to restore Parent [], CC [], OC [], Updated [], Deleted [], and Count [] to their original state; we have first built a Symbol [] array that associates each a ?[ m..n ] node with its symbol a .
 OC[root]:= OCSave[root]; CC[root]:= CCSave[root];
RestoreChild(root,left); RestoreChild(root,right); where
RestoreChild(parent,direction) fi
This restoring phase does not visit the whole T but only hence, after a set-up phase with cost O ( | T | ), the cost of
In the  X  X asy case X , when | T | is smaller than | w | , each word up and restore the T structure, which gives the same linear complexity O ( m  X  X  w | )asif T were rebuilt from scratch. In the  X  X ard case X , when | T | is not bound by | w | ,weatleast know that this algorithms checks each word, and restores the structures, in time O ( | w i | X  flatdepth ( T )), giving a total complexity of O ( | T | + m  X  X  w | X  flatdepth ( T )). If we assume a constant upper-bound k for flatdepth ( T ), the complexity is in O ( | T | + m  X  X  w | X  k ), hence is still linear in the input size. Without the  X  X estoring X  optimization, the total cost would be O ( m  X  ( | T | + | w | )),whichismuchworse,since,in practice, we cannot reasonably assume an upper bound on either m or | T | .
We are now ready to extend our techniques from words to trees. For the purpose of this discussion, we focus on XML trees where every node is an element node, hence on forests generated by the following grammar: x ::= | a x /a x .
Following a long tradition, (see [9], for example), we model an XSD schema as an extended DTD, that is, as a quintu-ple ( X  ,  X  , X , X , X  ), where  X  is a set of labels,  X  is a set of type-names ,  X  is a function mapping each type-name to a content-model, which is a type expressed on the alphabet  X ,  X  is a function from  X  to  X , and  X   X   X istheroot type-name. Although  X  is not injective in general, the El-ement Declarations Consistent (EDC) constraint specifies that  X  must be injective when restricted to a specific con-tent model (see [16]). As a consequence, it is possible to check membership of an XML tree x into an XSD schema as follows. Membership checking happens in the context of a specific type-name  X  , which is initially the root type-name of the schema, hence of a specific content-model T =  X  (  X  ). To check whether a 1 x 1 /a 1 ... a n x n /a n satisfies T ,we retrieve the content model T i =  X  (  X   X  1  X  ( a i )) of each subele-ment, check that each x i matches T i , and check that the sequence w =  X   X  1  X  ( a 1 ) ... X   X  1  X  ( a n )matches T . Here,  X  is the inverse of  X  restricted to the type-names appearing in the content model of  X  ; this inverse function is well-defined thanks to the EDC constraint.

We assume here that each content model is expressed in our type language and satisfies the conflict-freedom con-straint. The cost of verifying whether x satisfies (  X ,  X ,  X  ) depends on the cost of checking whether a word belongs to acontentmodel  X  (  X  ), as follows. We assume that the XSD schema contains | J | content models {  X  (  X  j ) } j  X  J ,eachofsize |  X  (  X  j ) | ,that x contains (immediately or recursively) ements { e i } i  X  I ,andthat w i is the sequence of the labels of the children of e i . We assume that MultiFlatLin is used for word-membership. We have a set-up phase with cost O (
P cost O (min( |  X  (  X  i ) | + | w i | , | w i | X  flatdepth (  X  (  X  w i  X   X  (  X  i ) test. 2 If the size of each w i dominates the size of  X  (  X  i ), then the total cost is linear, by Here we exploit the optimization described in Section 5. Ob-serve that it is not true, in general, that since the set I enumerates the elements inside x ,notthe components of  X  .

This linear approximation does not hold when  X  (  X  i )may be bigger than w i ,ashappensincaseswherecomplexcon-tent models are used to check documents where each element has a small number of children. In this case, which is quite common, we still have a quasi-linear complexity, by: This upper bound is linear if we assume a constant upper bound k for flatdepth (  X  (  X  i )). Here we exploit the combined optimizations described in Section 4 and Section 6.
Since DTDs can be modeled as a special case of EDTDs, this quasi-linearity result holds for DTDs as well.
To validate the usefulness of our approach and its theo-retical properties, we built a p rototype implementation of our linear algorithm (Xelf), and briefly analyzed its scala-bility properties when used o n XML trees. To better under-stand the behaviour of our approach, we also compared our implementation with a validating SAX parser and a non-validating SAX parser.

We analyze the behaviour of Xelf on XML documents of increasing size, so to expose its scalability properties.
Our algorithm has been implemented in Java 1.5 and all experiments were performed on a 2.16 Ghz Intel Core 2 Duo machine (1 GB main memory) running Mac OSX 10.5.2. To avoid issues related to independent system activities, we ran each experiments five times, discarded both the highest (worst) and the lowest (best) processing times, and reported the average processing time of the remaining runs.
We compared our algorithm with the standard SAX parsers of Java 1.5 (based on Xerces [1]).
Although XSD-checking uses top-down recursion, its to-tal run-time can be still evaluated by just adding the time needed to verify that the w i label sequence of each element, at any depth level in the document, matches the element content model
We evaluated our system on a dataset containing 10 in-stances of XMark [15], ranging from 110 MBs to 1.09 GBs.
The experimental results we obtained are shown in Figure 9. First of all, these results show a linear behavior, hence confirming our complexity analysis. Furthermore, as illus-trated by the diagram, our approach is extremely scalable, while the validating SAX parser was unable to complete the validation process on documents of size larger than 680 MBytes, due to memory consumption; this suggests that our algorithm has a limited memory footprint and that it can be profitably used for online validation.

This suggestion has been confirmed by further experi-ments, where we measured the memory used by our ap-proach during the validation of our dataset: in these exper-iments our algorithm used no more than 301 KBytes during validation, even on very big documents.

We do not precisely know why the validating SAX parser fails in validating large XMark documents: we believe that the deep nesting of XMark documents may have caused the problem, but we have no real evidences.

As we expected, our prototype implementation is slower than the validating SAX parser; however, our implemen-tation is just a proof-of-concept, while Xerces is a long-standing and highly optimized parser.
Membership checking is NP-hard for REs with interleav-ing. We have presented here a subclass of these REs which admits a simple polynomial membership algorithm. The al-gorithm is based on the transformation of the RE into a set of constraints, and on the parallel incremental residua-tion of these constraints. We have discussed the practical relevance of this class of extended REs, and have presented some optimizations that make our algorithm linear in the size of | T | + | w | . Apart from the practical motivations, we believe that it is important to understand how far the ex-pressive power of REs can be extended with  X  X ard X  operators such as interleaving and counting before making member-ship NP-hard. Our algorithm is not linear when used to check m words { w i } i  X  1 ..m against one type T ,since T ap-pears once in the input, but it is visited m times by the algorithm. We have presented an optimization that makes the algorithm almost linear for repeated checking, that is, makes it linear in | T | +( flatdepth ( T ) is very small in practice. Repeated checking is at the heart of XML membership checking with respect to DTDs and XSD schemas, hence the same quasi-linear complexity is preserved when we use our approach for XML membership checking. Finally, we experimentally validated the scalability properties of our approach. [1] http://xerces.apache.org/ . [2] D. Barbosa, G. Leighton, and A. Smith. Efficient [3] D.Barbosa,A.O.Mendelzon,L.Libkin,L.Mignet, [4] G.J.Bex,F.Neven,andJ.V.denBussche.DTDs [5] G.J.Bex,F.Neven,T.Schwentick,andK.Tuyls.
 [6] G. J. Bex, F. Neven, and S. Vansummeren. Inferring [7] J. Brzozowski. Derivates of regular expression. Journal [8] B. Choi. What are real DTDs like? In WebDB , pages [9] W. Gelade, W. Martens, and F. Neven. Optimizing [10] G. Ghelli, D. Colazzo, and C. Sartiani. Efficient [11] H. Hosoya and B. C. Pierce. XDuce: A statically [12] J.E. Hopcroft and J.D. Ullman. Introduction to [13] A. J. Mayer and L. J. Stockmeyer. Word problems  X  [14] M. Montazerian, P. T. Wood, and S. R. Mousavi. [15] A. Schmidt, F. Waas, M. Kersten, D. Florescu, [16] H. S. Thompson, D. Beech, M. Maloney, and [17] P. T. Wood. Containment for xpath fragments under
