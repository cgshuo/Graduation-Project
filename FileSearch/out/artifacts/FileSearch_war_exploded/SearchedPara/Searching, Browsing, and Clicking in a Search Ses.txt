 There are many existing studies of user behavior in simple tasks (e.g., navigational and informational search) within a short duration of 1 X 2 queries. However, we know relatively littl e about user behavior, especially browsing a nd clicking behavior, for longer search session solving complex search tasks. In this paper, we characterize and compare user behavior in relatively long search sessions (10 minutes; about 5 queries) for search tasks of four different types. The tasks differ in two dimensions: (1) the user is locating facts or is pursuing inte llectual understanding of a topic; (2) the user has a specific task goal or has an ill-defined and undeveloped goal. We analyze how search behavior as well as browsing and clicking patterns change during a search session in these different tasks. Our results indicate that user behavior in the four types of tasks differ in va rious aspects, including search activeness, browsing style, clicking strategy, and query reformulation. As a search session progresses, we note that users shift their interests to focus less on the top results but more on results ranked at lower positions in browsing. We also found that results eventually become less and less attractive for the users. The reasons vary and include downgraded search performance of query, decreased novelty of search resu lts, and decaying persistence of users in browsing. Our study highlights the lack of long session support in existing search engines and suggests different strategies of supporting longer sessions accordi ng to different task types. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  search process. H.1.2 [ Models and Principles ]: User/Machine Systems  X  human factors.
 Experimentation, Human Factors. Session; task; search behavior; browsing; clicking; eye-tracking. 
Although some simple search problems (e.g., finding a specific homepage and locating specific fact s with known keywords) can be satisfied through a single query and one click, it usually takes multiple searches to solve more complex tasks. The reasons vary. Sometimes it is the user who adop ts a divide and conquer strategy, using each query to deal with a part of the task X  X  goal [1]. Also sometimes it may be the complexity of the solution that makes it difficult to find all the answers with one query. Moreover, the user usually does not start with a cl ear goal and needs to figure out a specific information need after many searches [30]. For whichever reason, a search process that solves a complex problem usually spans more than one query and includes rich user interaction. 
Studies of users X  search behavior provide guidance to system design and evaluation. With many studies of user behavior in simple search tasks (1 X 2 queries), we know relatively well how to tailor a system for these tasks. For example, after Joachims et al. [15] showed that users X  visual attention and clicks are biased to the top ranked results, we know systems achieving high precision are more preferable in web search than systems with high recall. 
In comparison, we know relatively little about user behavior in long sessions of complex task type s, especially those that can provide guidance to the design and evaluation of systems support-ing long session and complex tasks. For example, do users examine more result snippets and go to deeper ranks in complex tasks and long sessions? Are users looking for factual information more accurate in clicking given short result snippets? Do users become less persistent in viewing the search engine result page (SERP) after long durations of search? Wit hout knowing answers to these questions, we do not know how to design and evaluate systems to better support complex tasks and long search sessions. 
To address that gap, we conduc ted an experiment with users working on complex tasks for re latively long search session (10 minutes; about 5 queries) and recorded search behaviors including eye movement data. We study the following research questions: 
RQ1 : How do users X  search behaviors, especially browsing and clicking behaviors, vary in comp lex tasks of different types? 
Studying this question helps us understand the effects of tasks on personalization and suggests how to design systems supporting complex tasks. To the best of our knowledge, among web search user studies focusing on SERP br owsing patterns, our experiments involve the most complex tasks and the longest sessions. Joachims et al. X  X  experiments [15, 23] d ealt with only navigational and informational tasks, with on aver age 1.6 queries issued per session. Moffat et al. [24, 29] did not repo rt session length, but according to Wu et al. [31] the most complex tasks adopted by Moffat et al. involve 2.42 queries and 3.46 clicks. Cole et al. [6, 7, 21] included tasks comparably complex to our study, but they focused on how users shift between scanning and reading. 
We will show that there are very noticeable differences of behavior depending on the type of task driving the user X  X  search. Differences are present in how active users are, how they browse and click result abstracts in a SERP, and how they issue queries. 
RQ2 : How do users X  search behaviors change over time in a search session? 
Our study is also the first study with analysis of changes in SERP browsing and clicking patterns over time in relatively long search sessions (10 minutes). Answers to RQ2 may provide insights on how to support users in long sessi ons. We will show that user engagement with a search system changes substantially between the start and the end of these search sessions. The changes appear to largely reflect a loss of confidence in the results, along with shifted patterns in browsing SERP results. 
The rest of this paper introduces our experiments and findings. 
Our study is related to three areas of existing work: web search user behavior with eye-tracking data ; search task and its effects to user behavior; and search session. We review each area below. 
Early studies (before 2004) of web search user behavior are mostly based on the analysis of la rge-scale query logs, such as [13, 28]. These studies described what real life web searches are like and how users interact with search engines at the query level, but they do not provide details of user behavior on a SERP, such as how users examine result abstracts. The first work using eye-tracking for web search user behavior [11, 15, 23] discovered how users browse a SERP, examine abstracts, and click results. They found decayed visual attention on results as the rank of the result increases and biased clicks on the top ranked results. Lorigo et al. showed that task type and gender may result in differences in search behavior and browsing style [23]. Later studies with eye-tracking [3, 8, 10, 29] further confirmed that users behave diversely in different tasks. They also showed that users may react distinctly to different outlooks of search result abstracts [5, 8] and SERP elements other than result abstracts, such as ads and related searches [3, 10]. More recently [ 24] used eye tracking studies to verify models and hypotheses in IR evaluation metrics. However, due to the limited accessibility of devices, user behavior studies with eye-tracking data are limited. 
Although currently lots of work using eye movement data for user behavior studies exist, the search tasks being studied in [3, 8, 10, 11, 15, 23] are simple, e.g., the  X  X avigational X  and  X  X nformational X  tasks de fined in [2]. As reported in [23], on average 1.6 queries were issued in that work. Recently Moffat et al. [24, 29] used more complex tasks of diffe rent cognitive complexity, i.e.,  X  X emember X ,  X  X nderstand X , and  X  X nalyze X  defined in [31]. However, even the most complex task type ( X  X nalyze X ) only involves search sessions of 2.42 queries and 3.46 clicks on average [31]. To the best of our knowledge, among existing search behavior user studies with eye-tracking data, only [6, 7, 21] conducted experiments based on task s of comparable complexity to the tasks adopted in our paper. However, th ey did not study how users read result abstracts in a SERP, but focused on how they shift between scanning and reading [6, 7, 21]. Therefore, it is unclear how users behave X  X specially how they browse the result abstracts in a SERP and click results X  X n long sessions of complex tasks. 
When tasks are complex, it usually requires relatively longer search sessions to finish. Previous studies using web search logs [13, 28] discussed search sessi ons as multiple searches across certain duration of time in search logs. However, from this aspect, the multiple searches within a session are not necessarily related to a consistent topic or search task. Spink et al. [27] found that multi-tasking is very common in search sessions derived using this definition. In our study, a search session refers to consecutive searches that aim at solving a cons istent task, which is similar to the search sessions studied in [6, 7, 20 X 22]. 
We conducted an experiment to collect user beha vior data in search sessions for completing complex tasks. We collected users X  queries, their browsing of Search Engine Result Pages (SERPs) and their clicks of search results. In addition, we deliberately asked users to perform different types of search tasks. 
The search tasks involved in previous related studies mainly focused on short search sessions a nd mostly dealt with navigational and simple informational needs. For example, in Joachims et al. [15] and Lorigo et al. X  X  studies [23], users on average only issued 1.6 queries in each task, and the tasks in Cutrell and Guan X  X  studies [8, 12] were simplified so that both navigational and informational search tasks were considered to be successful once a best result page was found. Our study of sear ch behaviors, particularly the examination of changes over t ime, needs to work on relatively longer search sessions, which allo w a long exploration process and complex user interactions. We therefore adopted search tasks from the TREC 2012 session track [17], which were categorized into four types using Li and Belkin X  X  face ted classification approach [19]. We considered two facets of search tasks identified by Li and Belkin [19]: product and goal. The product of a search task can be either factual (to locate facts) or intellectual (to enhance the user X  X  understanding of a topic). The goal of a search task can be either specific (well-defined and fully developed) or amorphous (ill-defined or unclear goals that ma y evolve along with the user X  X  exploration). This yields four t ypes of tasks: known item search (KI), known subject search (KS), interpretive search (IN), and exploratory search (EX). Some examples of tasks are: 
Although these four types of tasks appear to be different from those tasks presented in previous works [8, 12, 15, 23] (navigational and information search tasks), we believe that the two classification schemes do not conflict with each ot her, but are defined at different levels. Broder defined navigational and informational search tasks [2] based on a classification of individual web search queries. Therefore, each task in this case is intrinsically only indicative of what people can finish within a si ngle query. In comparison, Li and Belkin X  X  classification scheme [19] is defined regarding the nature of people X  X  information needs and problems, and allows multiple queries in a search session. Of course, each query in the session may still fit into Broder X  X  scheme [2]. For example, in IN and EX tasks, users may issue a navigational query  X  X mazon X  to know about the different types of dehumidifiers sold on amazon.com. We built an experimental search system providing modified Google search results. First, al l ads and sponsors X  links were removed. Second, we showed 9 results each page (rather than the usual 10) to make sure that users do not need to scroll down to see Known Item (factual + specific) : Where is Bollywood located? F rom what foreign city did Bollywood derive its name? What is the B ollywood equivalent of Bever ly Hills? What is Bollywood's equivalent of the Oscars? Where does Bollywood rank in the world's film industries? Who are some of the Bollywood stars? Known Subject (factual + amorphous) : You think that one of you r f riends may have depression, and y ou want to search information about the depression symptoms and possible treatments.
 Interpretive (intellectual + specific) : You would like to buy a dehumidifier. You want to know what makes a dehumidifier goo d value for money.
 Exploratory (intellectual + amorphous) : You would like to buy a dehumidifier. On what basis should you compare differen t dehumidi f iers? all of the result items. This change made it much simpler to analyze eye-tracking data. However, previous studies [15] also reported that scrolling down affected browsing pa tterns on results shown below the screen cutoff of a search result page. This change will miss such effects. We adopted this change because Joachims et al. [15] showed that most of the users X  attention is still focused on the top ranked results which are visible before scrolling down. Third, if Google provided query suggestions (i .e.,  X  X elated searches X ) for a query (usually shown below the search results), we moved them to the right side of the search results, again, to eliminate scrolling pages. 
The system looks very similar to existing search engines except a few places specifically designed for our search tasks. It shows the task descriptions at the top of the search result page. This is because we found in our pilot study that, without showing the task description, users might constantly switch between search result pages and another page showing the task description, because they forgot details of the task. We beli eve this would cause greater issues to the collected data (e.g., more constantly switching of pages) than showing task description on the s earch result page. In addition, the system has a highlighted  X  X inish task X  link if the session exceeds the time limit (but not before th e limit is reached). Although many systems for user studies (e.g. Liu et al. X  X  systems [21]) allow users to bookmark relevant results at sear ch time, we did not adopt such settings because it may affect user s X  browsing behaviors. Instead, relevance judgments were completed after search. 
A Tobbi 1750 eye-tracker was us ed to collect eye movement data. Among the various types of eye movement data, we only focus on analyzing fixation: stably gazing at an area of the screen. Studies have shown that fixation on an area of the screen usually indicates that users are reading information displayed on the area of interest (AOI) [26]. The AOIs in our study include each search result abstract (snippet), query sugge stion, and task description. We assume that fixation on these AOIs indicate that the participant has examined the corresponding result ab stract, query suggestion, and task description. ClearView, a software accompanying the eye-tracker, was used to analyze fixations on the defined AOIs. We set the minimum duration of fixation to 100ms, a common value adopted in many previous studie s of web search behaviors using the same series of eye-tracker [8, 12]. 
In the following discussion, we say that the participant examined a result abstract if we observed fixations on its corresponding AOI when the participant was browsing s earch result pages. Similarly, we say that the participant examined the query suggestions or topic description if we observed fi xations on the corresponding AOIs. 
We recruited 20 English native sp eakers (13 female and 7 male) through flyers in the campus of University of Pittsburgh. We required the participants to be English native speakers and current students in a college or university. Considering previous studies [9] reported increased error rates of eye-tracking for participants wearing glasses or lens, we also specified in our ads that the participants should have perfect eyesight (20/25). 13 participants were aged between 25 X 30, 6 between 18 X 24, and one over 30. For the highest degree earned or exp ected, 9 reported bachelor degree, 9 master, and 2 doctoral. Eight participants were studying information related majors, while others X  majors ranged from anthropology to microbiology. The participants rated their expertise of using web search engines by a 5 point Likert scale and the mean score is 3.75 (5 m eans the highest proficiency). 
We randomly sampled five groups of search tasks developed by the TREC 2012 session track [17]. Each group has four unique tasks of different types. For each task group, four participants worked on the tasks. We rotated the sequence of tasks in each group for different participants. Table 1 shows the topics. The total experiment duration for a participant is about 2 hours. The participants were reimbursed by the rate of $15 per hour. At the beginning of the experiment, participants were introduced to the system and a training task (with all the three stages but shorter time limits). Then the participants worked on four formal tasks. After two formal tasks, they took a 10-minute break. We interviewed the participants for their search behavi ors at the end of the experiment. For each task, the participants finished the following stages: 1. Search (10 minutes) . In the search stage, the participants were introduced to the search task and were asked to use the experimental system to find information in order to solve the task. They were instructed to use the experiment system as if they were using public search engines such as Google and Bing X  X .g. they could search using textual queries, br owse search result pages, click and view results. However, they were specifically instructed not to use other search engines. We set a limit of 10 minutes for each task. After 10 minutes, the system show ed a highlighted link notifying them to terminate the search stage. However, we also allowed participants to finish the task before 10 minutes if they reported they had already learned enough to solve the task. 2. Report (5 minutes). In the report stage, the participants were asked to rate the difficulty of the task, their familiarity with the topic of the task prior to search, and their search performance using a 5 point Likert scale. Then they were asked to write a paragraph reporting their outcomes of the search task. During this stage, the system showed a countdown of 5 mi nutes to help the participants to finish in about that time. The system did not freeze after 5 minutes. We instructed the participants to make full use of the time instead of finishing as soon as possible. 3. Relevance Judgments (5 minutes). In this stage, the participants were asked to judge and rate results regarding their relevance to the search task. Due to the time limit of the experiment, it was usually impossible to judge al l returned results of all queries in a session. Therefore we generate d a pool of results for relevance judgments. The priority of select ing results (from high to low) is: clicked results, probably examined results, other results. 
The pool size was about 25 results . First, we included all the results that the user clicked on. If less than 25 results (say, N results) were clicked, we contin ued to consider some  X  X robably examined X  results. We assume the participants looked through each search result page from top to bottom. Therefore, we located the deepest position of the clicked results in each search result page and considered unclicked results ranked higher than the deepest position as  X  X robably examined results X . If there were no more than 25-N c  X  X robably examined results X , we included all into the pool; or, we randomly sampled 25-N c . If summing up all clicked results and probably examined results did not total 25, we further included a random sample of other results into the pool. 
This pooling procedure is to maximize the number of judged results among those were clicked and examined throughout the session. The participants rated each result as  X  X ighly relevant X ,  X  X omewhat relevant X , or  X  X on-rele vant X . The system forced the participants to click each result at least once before submitting judgments. Again, the system showed a countdown of 5 minutes and the participants were instructed to make full use of the time. Later, an external annotator judged the rest of the results. 
We collected user behaviors from 80 search sessions on 20 unique tasks. During a search session, the participants on average issued 4.9 queries, examined 16.1 unique result abstracts, and clicked 9.3 unique results. The av erage length of a query was 3.96 words (without removing stopwords). As with most search engines, if the participant clicks a result, the experiment system left the current search engine result page (SERP) and switched to a new tab of the browser showing the result webpage. The participants needed to switch between the SERP and result webpages. This resulted in multiple views for a SERP. We refer to the duration from showing a SERP to switching to other we bpages as a  X  X ERP view X . In our experiment, participants had 3. 6 views for a SERP on average. 
For each session, the participant on average judged 20.1 results and left 13.3 unjudged. In total this resulted in 992 unique unjudged task-URL pairs. In order to ev aluate search performance of sessions, we asked an annotator (not an author of this paper) to assess the relevance of the unjudged results. To evaluate the agreement between the annotator a nd the participants on relevance judgments, we also sampled 100 unique judged results for the annotator to assess. The annotator was not aware of which result has been judged by the participan ts. If we merge  X  X ighly relevant X  and  X  X omewhat relevant X  into one class, the annotator agreed with the participants on 77% of the cases. 
To evaluate the correctness of the fixation data, we calculated the percentage of clicked results with observed fixations. Intuitively, the user should have examined a result abstract before clicking it. Therefore, we should observe fixations on the clicked results if the data is accurate. In our experiment, the percentage is 87%, comparable to those reported by Joachims et al. [15]. 
Users interact with a search engine mainly in two ways. First, they proceed through the search process by issuing queries. Second, for each query, they examine result abstracts on the SERP and may click on results. Therefore, we first compare the  X  X earch activeness X  of users in terms of how frequently they search and how often they examine and click results in Secti on 5.1. This helps us understand the diverse weight of the two types of interactions in different tasks. Then we look into details of SERP browsing in Section 5.2 and results clicking in Section 5.3. Fi nally, we compare users X  querying reformulation behaviors in Section 5.4. 
Search activeness examines how active users are in terms of the frequency of query and result level interactions. Specifically, we compare: search frequency (# queries); the frequency of viewing SERPs (# SERP views); the number of examined result abstracts (# unique fixations) and clicked results (# unique clicks); total time of viewing a SERP or SERPs (% or # time view SERP). Table 2 shows results for a session and for an indivi dual query (labeled with  X / q X ). 
It should be noted that the length of a task session is not strictly 10 minutes. A session can be shorter if the user chooses to finish before the time limit is reached. It may also be longer than 10 minutes it the user does not reali ze the time is up. This is because the system only shows the notificat ion on the search page, but the users may be reading result webpages when the time limit expires. As shown in Table 2 ( X  X otal ta sk time X ), users spent about 10% longer in KS tasks, while the time of other tasks does not differ greatly. This is probably due to th e fact that fewer users chose to finish a KS task before 10 minutes ( X # sessions end by user X ). 
As shown in the table, users in different tasks can be active in diverse ways. For example, users in KI and EX sessions tend to search more frequently but interact less actively in each search, while KS and IN sessions involve fe wer searches in total but more activities during each search. Data in Table 2 shows that users issued 5.5 and 6.2 queries in KI and EX sessions, which is significantly more often than those in KS (4.2 queries) and IN tasks (3.6 queries) within roughly the same amount of time. However, during each individual search, users in KS and IN sessions viewed the SERP more frequently (2.96 and 3.41 SERP views) and clicked more search results (2.32 and 2. 58 unique clicked results), which are significantly more active than they did in KI and EX sessions (2.17 and 2.38 SERP views; 1.58 and 1.96 unique clicks). In addition, users in KI, KS and IN sessions spent longer total duration (12.4s X 13.9s) viewing a SERP than th ey did in EX sessions (10.7s). 
According to Table 2, EX sessions are the most active among the four tasks in terms of the frequency of search and SERP views and the number of examined/clicked results in a search session. In comparison, users in KS and IN sessions are less active. They spent significantly shorter tim e on SERP views (13.2% and 13.8% of the session) than they did in KI and EX sessions (22.0% and 21.2%). They also examined fewer abstracts during the session (13.6 and 10.7 unique fixations. KI sessions are less active than EX in that users clicked fewer results, but KI sessions are more active than KS and IN because of more examin ed result abstracts and longer durations of viewing SERPs. 
The diverse styles of search activeness suggest that we can support a task according to the popul arity of query and result level interactions in the task (once we know what types of tasks users are dealing with). For exam ple, in KI and EX tasks, we may support search sessions by assisting with query reformulation (because they search more often in a session). In comparison, with less query level interaction and more result leve l actions, KS and IN tasks should be supported by focusing on enhancing result level interaction. For example, search results for KS and IN tasks can be optimized for precision at lower ranks or of a whole page. 
This section compares different tasks based on users X  browsing styles. Results are compared from four aspects: the effort of a SERP view, the chances of examining results at different ranks, the sequence of examining result abst racts on a SERP (scan path), and the users X  attentions on visited results. 
We found that users in KI and EX sessions spent greater effort on examining result abstracts in a SERP view. As shown in Table 3, users examined significantly more unique abstracts in KI and EX tasks (2.48 and 2.59 unique fixations) than they did in KS and IN tasks (2.16 and 1.93). We further a ggregated the durations of all the fixations on result abstracts in a SERP view ( X  X ix time on results X ). Table 2. Users search activeness in different types of tasks. It shows that in a SERP view, users in KI and EX tasks also used longer durations in total on examining result abstracts (1.94s and 1.91s) comparing to those in KS and IN tasks (1.35s and 1.46s). In addition, users in KI and EX tasks examined each single result abstract for longer periods than they did in KS tasks ( X  X ix time on a result X ). 
In comparison, users in KS and IN sessions spent more time on reading result webpages. Between each SERP view, users can read and explore result webpages. Alt hough users may follow links on the result webpage and visit new webpages, the time interval of two SERP views to some degree tells the amount of time the user spent on each result webpage. As s hown in Table 3 ( X  X ERP view interval X ), it took a significantly l onger time for users in KS and IN tasks to switch back from resu lt webpages to SERP, probably indicating that they spent more time reading each result webpage. Table 2 also supports our conjec ture. The percent of time users spent on viewing SERPs ( X % time view SERP X ) is significantly less in KS and IN tasks. As users spent more effort examining result abstracts in KI and EX tasks, systems supporting these tasks should consider how to generate more informa tive result abstracts. In the same way that Cutrell et al. found that differen t lengths of result abstracts can affect performance of navigati onal and informational search differently [8], KI and EX tasks may also benefit from customized styles of result abstracts specifically trimmed for the tasks. In comparison, KS and IN tasks may benefit from various reading supports for the result webpages (e.g., highlighting query terms in a result webpage when users are redirected from a SERP). 
Previous studies [15] showed that users focus more on top ranked results when examining a SERP. Does such tendency exist in a search session and is it different in the four types of tasks? Figure 1 shows the chances of examining results (fixation rates) at different ranks (we refer to the result at rank n as Rn). The left figure counts the fixation rates only for the first view of a SERP, while the right one aggregates all SERP views in a session. Both figures show that users still examined more on results at higher ranks in a search session, but vary slightly in patterns. The results show that during the first view of a SERP, users in EX tasks were more willing to examine results at the bottom of a page comparing to other tasks. As shown in Figure 1 (left), users in EX sessions had 10% X 20% chance of examining R7 X  X 9, while this happened in less than 10% of the cases in other three tasks. However, when considering all SERP views of a query, KS, IN, and EX sessions have comparable fixation rates on lower ranked results (about 40% X 50%), but KI sessions still showed observably lower tendency to examine results at the bottom (about 35%). This may be caused by the fact that users viewed a SERP more times in KS and IN sessions than they did in KI sessions (see Table 2). As found by Lorigo et al. [23], when viewing a SERP multiple times, users shift attention to focus more on results at the bottom. Therefore, if counting all SERP views, it is not surprising that users in KS and IN sessions may increase their fixation rates on R7 X  X 9 after viewing a SERP multiple times. 
Results in Figure 1 shows that, unlike simple search that may be satisfied with one click (and therefore one SERP view if the click is accurate), in complex search tasks, results at lower rank positions of a SERP can still get substant ial visual attention (about 30% X 50% fixation rate) after multiple SERP views. This suggests that it is unnecessary to rigorously optimize re sults for precision at the very top positions in long sessions of comp lex tasks. In addition, results suggest that tasks do affect fixati on rates, and therefore systems can be tailored for different browsing styles. 
Solely looking into fixation rates is often not indicative of how users consecutively examine result abstracts in a SERP view. Therefore, we study the users X   X  X can paths X  in a SERP view. As Lorigo et al. did in their studies [23], we aggregate the examined results in a SERP view as a  X  X can path X . If the users examined the same result abstract repeatedly, we count the result only once in the scan path. For example, for an observed sequence  X  X 1 R3 R3 R1 R4 R4 X , its corresponding scan path is  X  X 1 R3 R1 R4 X . 
We refer to two adjacent examined abstracts in a scan path as a move. For example, R1 X  X 3, R3 X  X  1, and R1 X  X 4 are three moves in  X  X 1 R3 R1 R4 X . The distance of the two results in a move is referred to as a  X  X ap X , and we define the gap of a scan path as the average gap of all its moves (e.g.,  X  X 1 R3 R1 R4 X  has gap 2, 2, 3 and its average gap is 2.33). The ga p of a scan path can indicate how many results are skipped in br owsing. A scan path with gap 1 means that each move is going to an adjacent result. We define the  X  X readth X  of a scan path as the maximum gap of two examined result abstracts in the scan path (e.g., the breadth of  X  X 1 R3 R1 R4 X  is 3, the distance of R1 and R4). The breadth of a scan path can indicate the magnitude of the area being browsed in a SERP. If the users examine results from top to bottom sequentially, each move in the scan path would be  X  X oving down X  (to the results at lower ranks). If all the moves in a sc an path are  X  X oving down X , we say that the scan path is  X  X equential X  (from top to bottom). We estimate the chances of  X  X oving up X  and the chances of a scan path being sequential. Table 4 shows the results. 
Table 4 suggests that instead of scanning the whole page, users focus on an area of 3 X 4 results in a SERP view ( X  X readth X ) and usually skip results in browsing ( X  X ap X  ranges from 1.38 to 1.63). Although Table 3 shows a comparable amount of fixations in KI and EX tasks, Table 4 explains the difference between KI and EX. In EX sessions, users X  scan paths have wider breadths (4.02) than those in KI sessions (3.09). This indicates that users in EX tasks browsed larger areas and skipped more results in a SERP view, while users focused on smaller areas in KI sessions. 
As shown in Table 4, in all ta sks the chance of moving up is lower than 50%, showing that users tend to scan results in a SERP counting the first view (left) or all views (right) of each SERP. from top to bottom in general. However, the chances of going up is significantly lower in KI and KS tasks (about 30%) compared to those in IN tasks (45%). Note that 45% chance of moving up means that users in IN sessions are almost randomly moving toward either the top or the bottom. Thus it is not surprising that only 7% of the scan paths in IN tasks are sequential. 
Table 4 also show strong dimensional characteristics. Tasks looking for factual products (KI and KS) show significantly stronger tendencies of sequential browsing ( p &lt;0.01). Tasks with amorphous goals (KS and EX) have significantly greater gap and breadth in a SERP view ( p &lt;0.01). This indicates that in both dimensions, more complex tasks (e.g. informational product and amorphous goal) lead to more complex browsing behaviors  X  e.g. non-linear browsing and scanning larger areas. 
We further compare the four types of tasks based on the users X  clicking behaviors. Whether or not a result is clicked depends on two factors. First, whether the user examined the result abstract or not (though possible, it is very unlikely that users blindly open a result without examining it). The previous section examined that factor. This section focuses on the second one: after examining a result, what is the chance a user c licks on it? The results show that users do not click every result abstract they examined. The chance of clicking varies by task, by re levance of results, and by whether the result has been visited previously. 
We calculate the probability of clicking a result provided that we observe a fixation on the result abstract during a SERP view. Table 5 shows the results  X   X  X (click | examine) X . It shows that users are significantly more likely to click a result after examining it in KS and IN sessions (61% and 59%), whereas the chances are lower in KI and EX sessions (45% and 52%). This is not surprising considering the fact that users in KI and EX tasks also retrieved fewer relevant results. As shown in Table 6 (analyzed in greater detail in Section 5.4), P@10 and nDCG@10 in KI and EX sessions are significantly lower than those in KS and IN sessions. With fewer relevant results retrieved, the examined results are less likely to be relevant and therefore less likely being viewed as promising and so worth clicking by the users. We also noticed that users do not always click results during a SERP view. Sometimes they switch from a result webpage to the SERP and then switch back to the result webpage again, probably because they did not find any interesting results after examining the SERP. The chance of viewing a SE RP without clicking result ( X % SERP views w/o clicks X ) is lower in EX sessions. Users also clicked significantly more results in EX tasks during a SERP view (0.87 unique clicks) comparing to other tasks (0.77 X 0.80). 
To evaluate how relevance of results affects a user X  X  decision to click in the four types of tasks, we further calculate the chance of clicking an examined result abstract when the result is judged as relevant (either  X  X ighly relevant  X  or  X  X omewhat relevant X ). As shown in Table 5, P(click | examine, relevant), the chance of clicking increases by 6% X 16% if th e examined result abstract is relevant. When a relevant result abstract has been examined, users in KS, IN, and EX sessions have comparable chances of clicking the result (65% X 70%). However, users in KI sessions still have significantly lower chances of cl icking (56%). This may indicate that users intrinsically click more selectively in KI tasks. 
Unsurprisingly, users cannot perfectly predict whether a result is useful or not purely based on th e abstract returned by a search engine. As shown in Table 5 ( X % click relevant X ), the percentage of relevant results among all clicked results varies from task to task: over 87% clicked results in KI and KS tasks are relevant, which is a significantly higher percentage than those in IN and EX tasks. This may also indicate that it is easier for users to judge the usefulness of documents if they are searching with a factual goal. 
The lower click accuracy in tasks looking for intellectual products (IN and EX tasks) indica tes that the result abstracts provided in current search engines are probably optimized for factual search only, which is difficult to satisfy users searching for other types of information. User s may substantially benefit from systems providing customized resu lt abstracts for different tasks. 
Similar to the default settings of web search, we show visited and unvisited URLs in different co lors (purple and blue) in the experimental search system. Therefore, the users could quickly distinguish visited URLs from unvi sited ones by color. We found that about 20% of the total fixations were on previously visited result abstracts (Table 3  X % fixa tions on visited X ) and there were 30% X 40% chances that users will revisit a clicked result (Table 5  X  X (click | examine, visited) X ). This suggests that users still paid certain attention to the visited result abstract in SERP browsing rather than completely ignoring th em, indicating that users may still expect to use the visited results when necessary. 
However, results show that the chance of clicking an examined result is indeed lower than normal if the result has been previously visited by the users within the same session. In all types of tasks, the probability of clicking an examined result reduces if the result is previously visited by the us ers (comparing  X  X (click|examine) X  and  X  X (click|examine,visited) X ). However, the changes are more significant in the KS and IN tasks (decreased by 28% and 20%) compared to KI and EX tasks (by 9% and 8%). This suggests that whether the result has been visited or not has greater effects on users X  clicking decisions in KS a nd IN tasks. Among four types of tasks, users in EX sessions are slightly more willing to re-open visited results (44%) comparing to other tasks (33% X 39%), probably due to the complex nature of exploratory search tasks. 
This section provides suggestions on how to deal with previously visited results in a s earch session. It seems risky to completely remove them because there are substantial needs to re-open previously visited results. However, the reduced chance of clicking suggests we may demote th e ranking of the visited results in a new SERP. Besides, the re sults also show that we can customize systems for different task s  X  e.g., for EX search, we may demote the rank of previously visited results less. 
Finally, we show click rates of results at rank R1 X  X 9 in Figure 2. As before, we separately examine the click rates in the first view of each SERP and those in all SE RP views. The c lick rate decays with the increase of result rank, but more quickly than the drop of fixation rate on result ranks shown in Figure 1. 
As shown in Figure 2 (left), among the four tasks, we found that users in KS tasks have observably higher chance (about 10% more that on other tasks) of clicking the top one result but apparently lower chance of clicking the second top result in the first SERP view of a query. The reason is unclear, but this results in overall higher rates of clicking R1 in KS sessions compared with other tasks (as shown in the right figure ). Similar to Figure 1, we also found that the chances of clicking results at lower ranks are significantly lower in KI tasks (counting all SERP views). In fact, users in KI tasks have the lowest chance to click R3 X  X 9 among the four types of tasks, showing that in KI tasks users mainly focus their attention on the top ranked few results. The average and deepest rank of the clicked results in Table 7 also support this finding. This again suggests that we may tailor search systems by the types of tasks, e.g., generate best top few results in KI tasks. 
Finally, we compare the four types of tasks by the way users issue and reformulate search queries, which indicates how users proceed through their search session. 
Table 6 shows statistics of user queries and user behaviors for query reformulation. We notice that in different tasks, user queries vary in length, search effectiveness, and novelty. 
As shown in the table ( X # term s X ), users issued significantly shorter queries (3.54 and 3.55 words) in tasks looking for factual information (i.e., KI and KS) comparing to those with intellectual search goals such as IN and EX tasks (4.39 and 4.38 words). The queries of the four types of tasks also vary in terms of effectiveness of retrieving relevant information. We calculate P@10, nDCG@10, and Reciprocal-rank for queries of different tasks and report the mean values in Table 7: users issued queries with better search effectiveness in KS and IN tasks. However, it should be noted that the effectiveness of queries in IN tasks may be over-estimated. We further analyze the number of common results in multiple queries of the same session. For each query except the initial one of a session, we calculate the number of results retrieved by both this query and the previous query ( X # overlap results X ) and Jaccard simila rity between this query and its previous query X  X  first page of resu lts ( X  X accard similarity X ). We can see that queries in IN sessions have significantly greater overlap of results (2.61 in common and 0.23 Jaccard similarity) than other tasks (0.81 X 1.33 results in common and 0.07 X 0.1 Jaccard similarity). Therefore, it is unclear whether queries in IN tasks are truly more effective because users may not be interested in some of the previously visited relevant results. 
Where do users acquire the knowledge for formulating new queries? To study this question, we look into user attention within the SERP views where users reformulated a search query (referred to as  X  X ransit SERP views X ). We assume that if a user X  X  attention on an area of the transit SERP view is apparently higher than those of a normal SERP view, they probably acquired knowledge from that area for query reformulation. 
In Table 6, we label statistics in a transit SERP view by  X (transit) X  and those in a normal SERP view by  X (normal) X . For all the tasks, we observed increased attention of users on the task description and query suggestion in a transit SERP view. Addition-ally, users spent substantial time examining result abstracts in a transit SERP view. This indicates that task information, query suggestion, and result abstracts are possible sources of knowledge for users X  query reformulation. Note that users do not necessarily need to adopt a query suggestion to be helped by one: they can get useful terms from the suggested que ries (as suggested by Kelly et al. [18]). Results show that users examined diverse areas of the transit SERP in different tasks, indicating distin ct source of knowledge for reformulation in different tasks. 
We found that in tasks with factual goals (KI and KS), users rely mostly on task information itself for reformulating queries. As shown in Table 7, users in KI and KS tasks spent 1.67s and 1.52s in total examining task description in a transit SERP ( X  X ix time task info (transit) X ), while in a normal SERP they spent only 0.75s and 0.39s. In addition, we noticed that users spent twice as much of the time on task description in tasks with factual goals compared with those with intellectual goals during a transit SERP view (0.87s and 0.82s). Also, in KI and KS tasks, the attention users put on task descriptions surpasses that on other areas of the transit SERP, such as the result abstracts (1.06s) an d query suggestions (0.33s). All these results indicate that users in KI and KS sessions mainly focus on the task itself in query reformulation. 
In comparison, we noticed that users in IN sessions probably reformulated queries mostly base d on what they learned from the result abstracts. In KI, KS, and IN sessions, the total fixation duration on the result abstracts is shorter in a transit SERP view than those in a normal SERP view. However, in IN sessions, there is increased attention on result abstracts when reformulating queries (from 1.46s to 1.83s). Fu rther, the amount of time users spent on examining result abstracts (1.83s) is also longer than they spent on task description (0.87s) and query suggestions (0.62s) in a transit SERP view. 
Users in EX tasks are distingu ished by the longest fixation duration on query suggestions in a transit SERP view (0.88s) among the four types of tasks. We also found increased attention of EX task users on task description during a transit SERP view (0.82s) compared with those in a normal SERP view (0.11s), indicating that task information may still constitute an important source of knowledge in EX tasks for query reformulation. 
Throughout the whole session, we f ound that users have limited direct use of query suggestion (i.e ., adopting a query suggestion for search). As shown in Table 7, the number of times a query suggestion was used for search ra nges from 0.4 to 0.6 in a session. Although we observed relatively highe r frequencies of using query suggestion in exploratory search tasks, the differences are not significant and the usage frequenc y is still low (0.6). This may indicate the limited support of qu ery suggestion for long search sessions in existing search engines. counting the first view (left) or all views (right) of each query. Table 6. Average user behavior statistics for a search query. 
To conclude, results suggest distinct strategies of supporting query reformulation in different tasks. For example, as users focus a lot on result abstracts in IN tasks, it may be preferable to generate suggestions based on frequent terms in result abstracts. How do search behaviors of users change in a search session? To answer this question, we compare users X  search behavior in the initial query of a session with that in subsequent query reformulations. It should be noted that in our experiment we set a 10-minute limit for task completion. Therefore, the last query of each session was usually interrupted, and the behavior statistics may be inaccurate (e.g., with less SERP views, examined results and clicks). We did not consider th is issue in the previous section because it does not introduce bias when we compare the differences between tasks. However, when comparing different queries in a search session, the last query of a session should be removed. Therefore, in this section, we selected 48 sessions with at least 3 queries and compare behaviors in the initial query with those in subsequent query reformulations excluding the last query of the session. The 48 sessions include 13 KI sessions, 9 KS sessions, 11 IN sessions and 15 EX sessions. Due to the limited sample size, we report significance at 0.1 level when necessary. 
We noticed that as a search session progresses, search results apparently attract less of the user X  X  interest. As s hown in Table 7, the number of unique clicks per query ( X # uniq click / q X ) dropped significantly by 40% X 60% in all tasks. The number of unique fixations per query ( X # uniq fix / q X ) also decreased significantly, though by a smaller magnitude (about 20% X 30%), except in IN sessions. Also, the number of SERP views per query ( X # SERP views / q X ) reduced significantly by about 1 X 2 views per query. These all indicate that users became less and less interested in the results after a few searches. 
We hypothesize three possible re asons for the reduced interests of users in a search session: 1) le ss relevant results are retrieved in subsequent query reformulations co mparing to the initial query; 2) although as many as relevant results are returned, users lose their interests to the results because they are either highly overlap with results of previous queries or incl ude very similar information; 3) users are becoming less persistent in SERP browsing. 
We verify the first reason by comparing search effectiveness of query reformulations with those of the initial query in a session. We found that downgraded search performance may be one of the major reasons for KI and EX tasks resulting in decreased interests of users on results. Table 7 shows that the search performance of queries in KI and EX sessions are indeed decreasing, but there is no significant change of search effectiveness in KS and IN tasks. Both Reciprocal-rank and nDCG@10 declined significantly in KI and EX sessions. Due to the reduced search performance, it is not surprising that users may quickly fe el that search results are not worth clicking and it is unnecessary to continue browsing a SERP after just one or two SERP views and clicks. 
Further, we examine the validity of the second reason by the chances of clicking an examined result ( X  X (click | examine) X ) and an examined relevant result ( X  X (click | examine, rel) X ). As shown in Table 7, as the session progresse s, users in KS and IN sessions are less likely to click an examined result no matter whether it is relevant or not. For KS and IN sessions, we also did not find significant changes of queries X  s earch performance in a session. Therefore, this indicates that it is probably the users themselves who believed that the search results, even the relevant results, are becoming less useful and worth clic king in a search session. One reasonable explanation could be that either the results are exactly previously retrieved ones, or s imilar information of the results appeared in previous results and users already knew relatively enough about it. Therefore, we conc lude that dec lined novelty of search results may be one of the reasons resulting in decayed interest of users on search results in KS and IN tasks. Finally, we examine whether users become less persistent in SERP browsing in a search sessi on. Results indicate that users X  persistence of browsing probably decreased in the tasks with unclear goals (KS and EX), but no evidence supports that users become less persistent in tasks with specific goals (KI and IN). As shown in Table 7, we found that th e examined results in KS and EX tasks moved to higher ranked positions. The average rank of the examined results ( X  X vg examine rank X ) decreased from 4.20 to 3.75 in KS tasks and from 4.05 to 3.74 in EX tasks. Figure 5 also shows that, in KS and EX tasks, the chance of examining results decreased on every rank position without any exception. These all indicates that users in KS and EX tasks become less persistent and are more likely to stop browsing a SERP earlier than they did at the beginning of a search session. In comparison, the examined results in KI and IN tasks moved to lower ranked positions (the difference is significant in KI tasks). Al so, Figure 5 shows that there are increased fixation rates on the results at lower ranked positions in the SERP. None of the evidences support decreased persistence of users in KI and IN sessions. 
The decreased interests of users on search results indicate that users encountered difficulties as the search session progresses, but existing search systems did not provide supports for long sessions. It also partly confirms a hypothesis in search session performance evaluation that more weights should be put on the relevan t results found at the early stage of a session [14]. Our studies of the three reasons also suggest different wa ys of supporting search sessions. For KI and EX sessions, the strategy is straightforward, i.e., it may help simply by improving search performance of queries. For KS and IN sessions, however, it requi res systems that can retrieve novel search results without downgraded performance. For tasks with unclear search goals (KS and EX), we can optimize results for precision at higher ranked positions because users are less persistent to read lower ranked results of a SERP. 
Figure 3 X 6 shows changes of fixation and click rates in the four types of tasks, counting the first view or all SERP views. Results show different changes of browsi ng patterns in the four tasks. 
Figure 3 shows the changes of fixation rates in initial query and query reformulations, counting only the first view of each SERP. We noticed that throughout a search session, users shifted their attentions to focus less on the top 1 or 2 results but more on lower ranked results such as R3 X  X 5. Fo r example, in KI sessions, the chances of examining R4 and R5 increased, with less fixations on R1 to R3. Similarly, users move d their attentions from R1 X  X 2 to 
Table 7. Changes of search be haviors in query reformulations (excluding the last query) compared with the initial query. R3 X  X 5 in KS tasks, from R1 to R2 X  X 3 in IN sessions, and from R1 X  X 2 to R3 X  X 4 in EX sessions. However, users still mainly focused on the top results than others. Figure 5 further shows the changes of fixation rates counting all SERP views of a query. As we di scussed in the last section, the chance of examining a result decreased at every position in KS and EX tasks, but users moved their attentions from the top half of the SERP to the bottom results in KI and IN tasks. In addition, we note that there are some overall changes of browsing patterns in Figure 5. For KI and IN sessions, the slope of decreasing fixation rate by result rank is steep at the initial query of a session but less apparent in further query reformulations (t his is due to decreased fixations on the top ranked results and increased attentions on the results at the bottom). In contrast, in KS a nd EX sessions, users X  attentions are increasingly biased to the top ranked results. This is probably related to whether the goal is specific or amorphous. 
As shown in Figure 4 and 6, the chances of clicking dropped significantly in almost all pos itions in four types of tasks, supporting our findings in the prev ious section. Though the chances of examining the top one result, as shown in Figure 3 and 5, did not drop by a large magnitude, the chances of clicking the top one result in query reformulations decreased to only about 2/3 to 1/2 of chances in the initial query. 
The changing of browsing and clic king patterns indicate that, even during the session of the same tasks, we should customize the systems to support users at different time point of the search session. For example, due to the shifted pattern of fixation, in KI and IN sessions, systems may need to optimize search results for precision at very top positions at the beginning of a search session but shift to consider more on results at lower ranked positions after a few searches. 
In this paper, we studied users X  search behavior in long sessions of four different types of comp lex tasks. We found that search behavior varies distinctly by ta sk and changes significantly after time. Table 8 summarizes our fi ndings by four tasks and two dimensions. 
Although it is confirmed that users X  search behaviors will vary in different tasks, it is unexpected that only a small part of the differences show connections with the two task dimensions. In some cases, one type of task shows unique characteristics that are different from the other three. So metimes we observed similarity between tasks that are different in both dimensions (e.g., KI and EX tasks, and KS and IN tasks). In addition, some characteristics exist in all types of tasks. This indica tes that the two dimensions (product and goal) are probably still not enough to fully explain the differences of tasks and the underl ying mechanisms that make user behavior different. Currently it remains unclear what the other possible factors are and how they might be identified. 
One unique contribution of our work is that the results provide suggestions for systems to support sessions of complex search tasks. Specifically, our analysis of brow sing and clicking patterns on the basis of eye-tracking data suggests that systems should be tailored for the search task at hand and the specific time point in the session. This advocates for futures system s that can automatically detect types of search tasks and optimize systems for the corresponding tasks, with dedicated supports du ring the search session. It also challenges existing evaluation metrics with fixed parameters in browsing and clicking models [4, 25] during a search session [14, 16]. This work was supported in part by the School of Information Sciences at the University of Pittsburgh and the Center for Intelligent Information Retrieval at the University of Massachusetts Amherst. Part of the work was done when the first author was at the University of Pittsburgh. Any opinions, findings and conclusions or recommendations e xpressed in this material are those of the authors and do not necessarily reflect those of the sponsor. [1] Bates, M.J. 1989. The design of browsing and berrypicking [2] Broder, A. 2002. A taxonomy of web search. SIGIR Forum. [3] Buscher, G. et al. 2010. The good, the bad, and the random. In [4] Chapelle, O. et al. 2009. Expected reciprocal rank for graded [5] Clarke, C.L.A. et al. 2007. The influence of caption features [6] Cole, M.J. et al. 2010. Linking se arch tasks with low-level eye [7] Cole, M.J. et al. 2011. Task and user effects on reading [8] Cutrell, E. and Guan, Z. 2007. What are you looking for? In [9] Dahlberg, J. 2010. Eye Trackin g with Eye Glasses. Master [10] Dumais, S.T. et al. 2010. In dividual differences in gaze [11] Granka, L.A. et al . 2004. Eye-tracking analysis of user [12] Guan, Z. et al. 2007. An eye tracking study of the effect of [13] Jansen, B.J. et al. 2000. Real life, real users, and real needs: a [14] J X rvelin, K. et al. 2008. Discounted Cumulated Gain Based [15] Joachims, T. et al. 2005. Accu rately interpreting clickthrough [16] Kanoulas, E. et al. 2011. Evaluating multi-query sessions. In [17] Kanoulas, E. et al. 2012. Overview of the TREC 2012 Session [18] Kelly, D. et al. 2009. A co mparison of query and term [19] Li, Y. and Belkin, N.J. 2008. A faceted approach to [20] Liu, J. et al. 2012. Explori ng and predicting search task [21] Liu, J. et al. 2010. Search behavi ors in diff erent task types. In [22] Liu, J. and Belkin, N.J. 2010 . Personalizing information [23] Lorigo, L. et al. 2006. The influence of task and gender on [24] Moffat, A. et al. 2013. Us ers Versus Models: What [25] Moffat, A. and Zobel, J. 2008. Rank-biased precision for [26] Rayner, K. 1998. Eye movements in reading and information [27] Spink, A. et al. 2002. Multitasking information seeking and [28] Spink, A. et al. 2001. Searchin g the web: The public and their [29] Thomas, P. et al. 2013. What Us ers Do: The Eyes Have It. In [30] White, R.W. and Roth, R.A. 2009. Exploratory search: [31] Wu, W.-C. et al. 2012. Grannies , tanning beds, tattoos and 
