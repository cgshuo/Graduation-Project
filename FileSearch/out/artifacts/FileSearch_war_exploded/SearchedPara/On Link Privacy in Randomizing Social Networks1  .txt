 Social networks are of significant importance in various application domains such as marketing, psychology, epidemiology and homeland security. Many applications of so-cial networks such as anonymous Web browsing require relationship anonymity due to the sensitive, stigmatizing, or confidential nature of relationship. For example, most people prefer to conceal the truth regarding their illegal or unethical behaviors which are customarily disapproved of by society.

One natural approach is to publishing a node-anonymized version of the network that permits useful analysis without disclosing the identity of the individuals represented by the nodes. The recent work [1, 4] pointed out that this simple technique of anonymizing graphs by replacing the identifying information of the nodes with random ids does not guarantee privacy since the identification of the vertices can be seriously jeopardized by applying subgraph queries. Another approach is to randomizing edges to protect sensi-tive links [3, 4, 6, 8, 11]. For example, we can remove some true edges and/or add some false edges. After the randomization, the randomized graph is expected to be different from the original one. As a result, the true sensitive or confidential relationship will not be much disclosed even if the identification of the vertices is achieved by attackers. We will explore how well the edge randomization can protect those sensitive links. In [8], Ying and Wu preliminarily investigated the relationship between the amount of randomization and the attacker X  X  ability to infer the presence of a link and presented a randomization strategy that can preserve the spectral properties (and utility) of the graph. However, the effect on privacy due to randomization was quantified by consid-ering only the magnitude information of randomization. It has been well known that graph topological features have close relations with the existence of links and various proximity measures have been exploited to predict the existence of a future link [5]. In this paper, we will investigate formally how attackers may exploit proximity measure values (derived from the released randomized graph) to breach link privacy. Privacy of a sensitive link is jeopardized if attackers X  confidence of prediction is higher than some tolerated threshold or is significantly greater than the a-priori belief (without the exploit of the released randomized data). Hence it is of great importance for data owners to be aware of potential attacks and quantify the magnitude of perturbation to better protect sensitive links. Social network analysis has increasing interest in the database, data mining, and theory communities. The current state of the art is that there has been little work dedicated to privacy preserving social network analysis with the exception of some very recent work [1 X 4, 6, 8 X 11].

In [1], Backstrom and et al. described a family of attacks such that an adversary can learn whether edges exist or not between specific targeted pairs of nodes from node-anonymized social networks. Similarly in [4], Hay and et al. further observed that the structure of the graph itself (e.g., the degree of the nodes or the degree of the node X  X  neighbors) determines the extent to which an individual in the network can be distinguished.

In [6], Liu and Terzi investigated how to modify a graph via a set of edge addition (or deletion) operations in order to construct a new k -degree anonymous graph, in which every node has the same degree with at least k  X  1 other nodes. In [11], Zhou and Pei anonymized the graph by generalizing node labels and inserting edges until each neighborhood is indistinguishable to at least k  X  1 others. In [2, 10], authors applied a structural anonymization approach called edge generalization that consists of collaps-ing clusters together with their component nodes X  structure, rather than add or delete edges from the social network dataset. Although the above proposed approaches would many topological features may be lost.

The problems of how to generate a synthetic graph preserving various topological features of a real social network and how attackers may exploit the topological features of the released graph to breach link privacy were recently studied in [9]. However, the attacking model in [9] was based on the probability of existence of a link across all possible graphs in the graph space. In this paper, the attacking model is to exploit the relationship between existence of a link and the similarity measure values of node pairs in one released randomized graph.

We would point out that our problem of attacking methods on a randomized graph is different from the classic link prediction problem investigated in [5]. The classic link future link between two nodes given a snapshot of a current social network. The change due to randomization is different with that due to network evolutions. Nevertheless, various graph proximity measures used in the classic link prediction could be used by attackers. A network G ( n, m ) is a set of n nodes connected by a set of m links. The network con-sidered here is binary, symmetric, connected, and without self-loops. Let A =( a ij ) n  X  n be its adjacency matrix, a ij =1 if node i and j are connected and a ij =0 otherwise. G is the randomized graph obtained by randomly adding k false edges followed by delet-ing k true edges. This strategy keeps the total number of edges in the original graph unchanged. We denote A =(  X  a ij ) n  X  n be the adjacency matrix of G .

When it comes to link privacy, it is usually a ij =1 that people want to hide, not a ij =0 and attackers are capable of calculating posterior probabilities. Formally, we use P ( a ij =1) to denote the users X  prior belief about the event of a ij =1 and use P ( a ij =1 | G ) to denote its posterior belief about a ij =1 . The released graph G is regarded as jeopardizing the privacy if P ( a ij =1 | G ) &gt;P ( a ij =1) .
In [8], we preliminarily investigated the relationship between the amount of random-ization and the attacker X  X  ability to infer the presence of a link. The results are shown as follows. When the attacker knows only parameter m and n , the prior belief is With the released graph and perturbation parameter k , the posterior belief is Equation 2 is based on the Addition/Deletion without replacement 1 .

In this paper, we further investigate whether topological features of the released net-work can be exploited by attackers to breach the link privacy. More specifically, we focus on to what extent a given sensitive relationship can be breached by attackers who exploit proximity measure values of node pairs. Proximity measures have been shown to be effective in the classic link prediction problem (i.e., predicting the future existence of links among nodes given a snapshot of a current graph). However, link prediction in our context is to predict the likelihood of existence of original links from the random-ized graph. This is challenging since the proximity measure values calculated from the randomized graph can be varied from those of the original graph. In section 3.1, we em-pirically show the close relationship between various similarity measures of node pairs and probability of link existence between them. In section 3.2, we conduct theoretical studies and quantify how much the posterior belief can be enhanced by exploiting those similarity measures. 3.1 Existence of a Link vs. Similarity Measure Let m ij be a similarity measure on node pair ( i, j ) in graph G (a larger value of m ij indicates that nodes i and j are more similar). We apply four similarity measures in this paper. The first one is the number of common neighbors: CN ij = n k =1 a ik a kj . The second one is the Adamic/Adar measure , which is the weighted number of com-mon neighbors. The weights are assigned based on the information theory: Ad ij = sure, which is a weighted sum of the number of paths in the graph that connect two nodes, with shorter paths being given the larger weight: K ij =  X  k =1  X  k P ( k ) ij , where P ij denotes the number of paths from i to j with length equal to k while  X  is a damp-ing factor. In this paper, we take  X  =0 . 1 . The fourth one is the commute time CT ij , which is the expected steps of random walks from i to j and back to i . The commute time is a distance measure: more similar nodes have smaller CT values.

Let  X  (  X  ) denote the proportion of true edges in the set of node pairs  X  : where |  X  | denotes the number of elements in set  X  .Let S x = { ( i, j ): m ij = x } denote the set of all node pairs with the similarity measure m ij = x . Hence  X  ( S x ) denotes the proportion of true edges in the S x , which can be considered as the probability of existence of a link between node pair ( i, j ) in S x . Next, we empirically show how  X  ( S x ) varies with x in real social networks.

Figure 1 shows how the proportions of true edges in S x are varied with similarity measure values x in terms of four measures (Common neighbors, Katz, Adamic/Adar, and Commute time) in the US political books network (polbooks). The polbooks net-work 2 contains 105 nodes and 441 edges, and nodes represent books about US pol-itics sold by the online bookseller Amazon.com while edges represent frequent co-purchasing of books by the same buyers on Amazon. We can observe that  X  ( S x ) in-creases with x . In other words, the probability that a ij =1 is highly correlated with similarity measure m ij : the larger m ij is, the more likely a ij is equal to 1 .
We then perturbed the polbooks network by adding 200 false edges and deleting 200 true edges. From the perturbed graph G , we define S x = { ( i, j ):  X  m ij = x } as the set of node pairs with similarity measure  X  m ij = x . Figure 2 shows how the proportions of true edges in S x (i.e., the probability of existence of a link) are varied with similarity measure values x in terms of four measures in the randomized polbooks network. We can observe that the same pattern still holds even if the randomized graph itself is quite different from the original one (200 false edges out of 441 edges). In the next section, we will show how attackers exploit  X  m ij in the perturbed graph G to improve their posterior belief on existence of a true link between nodes ( i, j ) in the original graph. 3.2 Link Prediction by Exploiting Similarity Measure In this section, we quantify how much the posterior belief can be enhanced by exploiting similarity measure between two node ( i, j ) in the randomized graph. We present our quantification in a series of results and leave detailed proofs in Appendix.
Recall the randomization strategy is to randomly add k false edges followed by delet-ing k true edges. In other words, every true link is to be deleted independently with probability p 1 and every non-existing link is to be added independently with probabil-ity p 2 . We can easily derive p 1 = k/m and p 2 = k/ [ n 2  X  m ] .

Let  X  m ij denote the similarity measure of node i and j in G . We define S x = { ( i, j ):  X  m  X  ( S x ) denotes the proportion of true edges in the set S x derived from the perturbed graph. Also notice that P (  X  a ij =1 | a ij =1)=1  X  p 1 and P (  X  a ij =1 | a ij =0)= p 2 . With the Bayes X  theorem, the posterior belief is then given by
Equation 3 (Equation 4) shows the enhanced posterior belief that an observed (miss-of an observed link  X  a ij =1 usually has more indications to be a true link than that of  X  a Property 1. Let r denote the sparse ratio of the graph, r = m/ n 2 .If k  X  (1  X  r ) m , given a fixed x , we have the following inequality stands:
Many real-world social networks are very sparse ( r  X  0 ). Hence k  X  (1  X  r ) m is usually satisfied. We thus focus on the risk of the released links, P ( a ij =1 |  X  a ij = 1 ,  X  m ij = x ) .

One issue here is that attackers cannot know the proportion of true edges in S x from the perturbed graph. What they can know actually is the proportion of observed edges in S x . Our next result shows the maximum likelihood estimate of  X  ( S x ) can be derived from the proportion of observed edges in S x .
 Result 1. Given the perturbed graph and a fixed x , define S 1 x = S x  X  E = { ( i, j ):  X  a ij =1 ,  X  m ij = x of  X  ( S x ) is given by and the MLE is unbiased.
 By replacing  X  ( S x ) in Equation 3 with  X   X  ( S x ) (shown in Equation 6), we have derived our enhanced posterior belief P ( a ij =1 |  X  a ij =1 ,  X  m ij = x ) . Attackers may simply calculate the posterior belief of all node pairs in the perturbed graph and choose top-t node pairs as predicted candidate links.

For those similarity measures with continuous ranges (e.g., commute time), the num-ber of node pairs with similarity measure equal exactly to x is usually small. In prac-tice, we can apply histogram approximation or use the kernel estimator to smooth the estimation.

We would emphasize that our enhanced posterior belief P ( a ij =1 |  X  a ij =1 ,  X  m ij = x ) more accurately reflect the existence of a true link than the posterior belief P ( a ij = 1 |  X  a ij =1) without exploiting the similarity measure derived in previous work [8]. We can see that P ( a ij =1 |  X  a ij =1) (shown in Equation 2) is the same for all observed links. On the contrary, our enhanced posterior belief P ( a ij =1 |  X  a ij =1 ,  X  m ij = x ) tends to be larger for those observed links with higher similarity values, and tends to be smaller for links with lower similarity values. Hence, it can more accurately reflect the existence of true links. We show our theoretical explanations in Results 2 and 3 and will compare the precisions of top-t predicted links derived from these two posterior beliefs in our empirical evaluations.
 Our next result shows more clearly the relationship between a-priori belief (Equation 1), posterior belief without exploiting similarity measures (Equation 2), and our enhanced posterior belief with exploiting similarity measures (Equations 3 4).
 Result 3. Both the sum of a-priori belief over all node pairs and the sum of posterior belief (without exploiting similarity measures) overall all node pairs are equal to the number of edges: The sum of our enhanced posterior belief (with exploiting similarity measures) also approaches to the number of edges:
Figure 3 shows the relationship between the two posterior beliefs and the common neighbors for the polbooks data. We set k = 200 . We can observe that the posterior belief without exploiting the similarity measure, P ( a ij =1 |  X  a ij =1) , is 0.55 for all observed links. However, our enhanced posterior belief P ( a ij =1 |  X  a ij =1 ,  X  m ij ) are greater than 0.55 for those links with more than 2 common neighbors as shown in Figure 3(a). Figure 3(b) shows the distribution of the calculated posterior belief values. We can observe that 33.5% of released links have their posterior beliefs enhanced with similarity measures. 3.3 Privacy Protection Measure In the privacy preserving data mining, one natural question from data owner is how many perturbations we need such that we can guarantee the protection for all sensitive individual edges are above some tolerated threshold. When attackers utilize the simi-larity measure, the absolute measure of protection for an individual link ( i, j ) can be defined as where the second term denotes the maximal suspicion of existing a ij =1 . Compared with the protection under the attack without exploiting similarity measures, we define the relative measure of protection as The measures of protection (  X  a and  X  r ) are defined in terms of one individual edge. In the privacy preserving data mining, one natural question is how many perturbations we need such that we can guarantee the protection for all individual edges are above the threshold. Our next result shows the formula of the minimum number of perturbations to achieve the protection of all individual links. It is of great importance to evaluate the relationship between the required minimum number of perturbations and the utility loss of the perturbed graph. Due to space limitations, we leave this as our future work. Result 4. In the original graph, let S x = { ( i, j ): m ij = x } ,  X  max = max x  X  ( S x ) , and sparse ratio r = m/ n 2 . When the protection threshold &lt; 1  X   X  max 1  X  r , there exists the minimum k such that  X  r ( i, j )  X  stands for all the node pair ( i, j ) is given by: We used four network data sets ( polbooks, Enron, email, polblogs ) in our evaluation. The Enron network was built from email corpus of a real organization over the course covering a 3 years period. We used a pre-processed version of the dataset provided by [7]. This dataset contains 252,759 emails from 151 Enron employees, mainly senior managers. The email graph is the network of e-mail interchanges between members of the Univeristy Rovira i Virgili (Tarragona) 3 .The polblogs compiles the data on the links among US political blogs, containing over 1,000 vertices and 15,000 edges, which is based on incoming and outgoing links and posts around the time of the 2004 presidential election 4 .

For each graph G , we randomly add k false edges and delete k true edges. We set k =0 . 5 m in this paper, which corresponds to a relatively large perturbation. We also conducted evaluations with other k values and skip their results due to space limita-tions. We applied four similarity measures (Common neighbors, Katz, Adamic/Adar, Commute time) to predict top-t candidate links. We varied t values from 0 . 1 m to 0 . 5 m for all four data sets.

For each t, we calculated the precision of prediction links with different similarity measures. We also calculated the precision of prediction links using the posterior belief without exploiting the similarity measure. Figure 4 plots our results on four data sets. We can observe that for all four data sets we can achieve very high accuracy (greater than 0.8) by using our enhanced posterior belief for a subset (top 0 . 1 m ) of released links, which indicates severe privacy disclosures for those sensitive links. We can also see that our enhanced posterior belief achieve higher precisions than the previous poste-rior belief without exploiting similarity measures for most links ( 0 . 5 m ) with high sim-ilarity measure values, indicating that the network topology does indeed contain latent information from which to infer interactions. From Figure 4, we can also observe that we achieve different precisions using different similarity measures: one measure which achieves the highest precision for one data set is not necessarily the one for another data set. It is of great significance to explore what similarity measures can be exploited by attackers to achieve the highest privacy disclosure for a given social network. We will investigate this in our future work. In this paper, we have investigated how well the edge randomization approach via ad-dition/deletion can protect privacy of sensitive links. We have conducted theoretical analysis and empirical evaluations to show that node proximity measures can be ex-ploited by attackers to enhance the posterior belief and prediction accuracy of the exis-tence of sensitive links among nodes with high similarity values.

There are some other aspects of this work that merit further research. Among them, we will continue the line of this research by investigating other edge randomization approaches (e.g., edge switches). We will also investigate how the edge based random-ization affects the graph X  X  utility. We are interested in comparing theoretically and em-pirically the edge based randomization with the k -degree anonymization approaches [6, 11] in terms of the privacy vs. utility tradeoff.
 Proof of Property 1 need only guarantee that 1  X  p 1  X  p 2  X  0 . Notice that p 1 = k/m and p 2 = k/ [ n 2  X  m ] , then 1  X  p 1  X  p 2  X  0 if and only if k  X  1  X  m/ n 2 Proof of Result 1 Let N = | S x | , N 1 = | S 1 x | and  X  =  X  ( S x ) . Then, for a randomly selected node pair ( i, j ) ,  X  a ij is a Bernoulli random variable: Then the likelihood function of S x is Take derivative to ln L with respect of  X  ,wehave Proof of Result 2 Notice that P ( a ij =1 |  X  a ij =1)= m  X  k m =1  X  p 1 , and with Equation 3, it is easy to verify this result.
 Proof of Result 3 i&lt;j P ( a ij =1)= m is obvious. Notice that the number of edges does not change along the perturbation, then we have When attackers utilize the similarity measures with MLE, we first show
E With the MLE in Equation 6, we have Similarly, we have Combining Equation 11, 12 and 13 together, we have Then, due to the law of large number, we can conclude that and we prove the result.
 Proof of Result 4 When k  X  (1  X  r ) m , with Result 1 and 2, we have that  X  ( S x Then we have Substitute p 1 = k m = k rN and p 2 = k N  X  m = k (1  X  r ) N into Equation 14, we can verify k =(1  X  r ) m .

When k  X  (1  X  r ) m , we similarly have the following: when k =(1  X  r ) m .

Therefore, k min exists if and only if  X  1  X   X   X  max 1  X  r , and k min &lt; (1  X  r ) m . Then,  X  ( i, j ) is given by Equation 14. Solving the inequality  X  r ( i, j )  X  , we have that
However,  X   X  max = max x  X  ( S x ) varies from time to time due to the perturbation, and data owner can substitute it with the true maximum value  X  max = max x  X  ( S x ) , then
