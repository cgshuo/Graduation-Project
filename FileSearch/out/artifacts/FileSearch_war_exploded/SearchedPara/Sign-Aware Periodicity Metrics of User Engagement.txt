 Modern Internet companies improve evaluation criteria of their data-driven decision-making that is based on online controlled experiments (also known as A/B tests). The am-plitude metrics of user engagement are known to be well sen-sitive to service changes, but they could not be used to de-termine, whether the treatment effect is positive or negative. We propose to overcome this sign-agnostic issue by paying attention to the phase of the corresponding DFT sine wave. We refine the amplitude metrics of the first frequency by the phase ones and formalize our intuition in several novel over-all evaluation criteria. These criteria are then verified over A/B experiments on real users of Yandex. We find that our approach holds the sensitivity level of the amplitudes and makes their changes sign-aware w.r.t. the treatment effect. Categories and Subject Descriptions: H.1.2 [User/Machine Systems]: Human information processing; H.5.2 [User inter-face]: Evaluation/methodology General Terms: Measurement, Experimentation Keywords: User engagement; online controlled experiment; periodicity; DFT; sign-aware metric; A/B test
Online controlled experiments, or A/B testing, have be-come the state-of-the-art technique of improving web ser-vices based on data-driven decisions [10, 7]. An A/B test compares two variants of a service 1 at a time by exposing them to two user groups and by measuring the difference between them in terms of a key metric (e.g., the revenue, the number of visits, etc.), also known as an overall evalu-ation criterion [8]. Many existing studies were devoted to an invention of new metrics [5, 9, 3] or to improvements of existing ones [2, 4] in order to make them more consistent with the long-term goals of the company [1, 6, 7] and to e.g., a current version of the service (the control variant) and a new one (the treatment variant) c  X  make their changes more detectable. The ability of the met-ric to detect the statistically significant difference when the treatment effect exists is referred to as the sensitivity .
User engagement metrics (e.g., the number of sessions per user [9], the absence time [5], etc.) are considered to be the best ones and are popular in the A/B testing practice of many companies, because user engagement reflects how often a user solves her needs (e.g., to search for something) by means of the considered service (e.g., a search engine) [6, 7]. Hence, on the one hand, these metrics are measurable in the short-term experiment period, and, on the other hand, they are predictive of long-term goals of the company [6, 7].
Recently, several metrics of user engagement periodicity were developed and were used in A/B experiments [3]. These metrics are the amplitudes of the discrete Fourier transform (DFT) of daily time series of several standard user engage-ment metrics (e.g., the daily number of sessions). On the one hand, the amplitude metrics were found to be more sensi-tive than the state-of-the-art ones, i.e., the average values of the time series (e.g., the number of sessions per day). How-ever, on the other hand, the amplitudes (as considered in [3]) could not be used to determine, whether the treatment effect is positive or negative: if one of these metrics changes (in-creases or decreases) significantly, it just tells us that a user changes her behavior in response to the treatment variant with no insight on whether it is positive or negative for the user or for the service. Thus, these metrics are sign-agnostic with respect to an evaluated treatment effect.

In our work, we develop a novel approach, which improves several amplitude metrics by taking into account the phases of the DFT. We find that the DFT components with the first frequency detect signals of the UE measure trend along the experiment time period. Hence, these metrics could be prof-itable for delayed treatment effects (which are often caused by primacy and novelty effects [8, 6]). Our approach pro-vides an experimenter with several intuitively clear guide-lines (referred to as symptoms ), that allow him to deter-mine whether the treatment effect is positive or negative, when he or she observes changes in the periodicity compo-nents of a user engagement metric. Thus, we overcome the sign-agnostic issue of the amplitudes .

We reinforce our theoretical results by applying the pro-posed approach to evaluation of changes in a search engine. We considered 55 real large-scale online experiments (32 A/B tests and 23 A/A tests) run at Yandex, one of the pop-ular search engines. We find that, on the one hand, the novel approach is more sensitive than the state-of-the-art user en-gagement metrics (it allows us to detect the treatment ef-Figure 1: The amplitude A 1 , the phase  X  1 , and the sine wave f 1 . fect in more experiments). On the other hand, the novel approach is sign-aware (it allows us to understand, whether the detected treatment effect is positive or negative), while the classic amplitude metrics in [3] are sign-agnostic.
We briefly review the key points of the periodicity metrics, that were studied in [3]. Let us consider any user engage-ment (UE) measure calculated for an individual user, e.g., the number of sessions [9, 3]. Let x = ( x 0 ,x 1 ,..,x N  X  1 a daily time series of N numbers, that represent this UE measure calculated for N consecutive days (e.g., the daily number of sessions). Then, we apply the discrete Fourier transform (the DFT ) to x and obtain the sequence of its coordinates in the harmonic basis { f k } N  X  1 k =0 : where f k = ( e i  X  k n /N ) n  X  Z N is the sine wave (harmonic) with the frequency  X  k . From the polar form 2 of each complex number X k = | X k | e i  X  k , the amplitude A k = | X k the phase  X  k are obtained, k  X  Z N . The amplitude A represents the magnitude of the sine wave f k with the fre-quency  X  k , presented in the series x , whereas the phase  X  represents how this wave is shifted (see Fig.1).
 The amplitudes A k and the normalized ones A k /A 0 ,k  X  Z N , are found to be considerably more sensitive to different changes in a search engine than the state-of-the-art baseline metric A 0 3 . However, these metrics do not determine the sign of the treatment effect: whether the evaluated service change is negative or positive for users (i.e., these metrics are sign-agnostic ). In this study, we will show how several amplitudes could be refined in order to obtain sign-aware evaluation criteria, that will also be of high sensitivity.
In A/B testing practice, we are often faced with primacy and novelty effects [8, 6], that cause a delay in the treat-ment effect, which could not be easily detected by the state-of-the-art metrics. We supposed that the metrics aimed to detect changes in the trend of UE measures may be helpful in such and other cases. For instance, if a user is enjoyed with the treatment version, then the number of sessions should growth during the experiment. Otherwise, if the treatment harms user engagement, the number of sessions should de-crease to the end of the period. Such UE measure changes along the whole experiment period should leave traces in the first frequency 4 (i.e.,  X  1 ) of the DFT of the UE mea-sure time series. Therefore, if the treatment effect stands i.e., z = re i  X  = r cos  X  + r sin  X  i
A 0 is the average value of the source time series x of the UE measure (e.g., the average number of sessions per day).
The other frequencies (i.e.,  X  k ,k &gt; 1) are responsible for more frequent changes (e.g., the week periodicity, etc.). Figure 2: A positive, a negative, and neutral trends of the sine wave f 1 w.r.t. the phase  X  1 . out sharply in the UE trend, then the sine wave with this frequency should change. Moreover, the shift of this sine wave can help to determine the sign of the treatment effect (whether it is positive or negative).

From here on in this paper we will consider only the first amplitude A 1 and its normalized version A 1 /A 0 . In order to understand the meaning of a change in such amplitude, let us consider it together with the corresponding phase  X  1 of the sine wave f 1 with the frequency  X  1 . Let us consider the following cases (see Fig.2): (a) if  X  1  X   X / 2 (or sin  X  1  X  1), then the sine wave f (b) if  X  1  X   X   X / 2 (or sin  X  1  X   X  1), then the sine wave f (c) if  X  1  X  0 or  X  (or sin  X  1  X  0), then the sine wave f
From these cases, we see that, for instance, an increase of the amplitude A 1 may led to both negative, and positive consequences. It depends on how the sine wave is shifted: if sin  X  1 &lt; 0, then the magnitude of the sine wave with a negative trend increases; on the contrary, if sin  X  1 &gt; 0, then the magnitude of the sine wave with a positive trend in-creases. Furthermore, even through the amplitude A 1 does not change at all, a change in the phase  X  1 could shift the type of the sine wave trend: make it more or less negative or positive. Therefore, we conclude that, in order to un-derstand the positiveness or negativeness of changes in the amplitudes A 1 and A 1 /A 0 of the sine wave f 1 , we should pay attention to its phase  X  1 .

Before presenting in detail our evaluation criteria, let us dwell on two points. First, note that the equality Im X 1 NA 1 sin  X  1 holds (see Fig.1). Therefore, from here on in this paper we will study the novel 5 metric Im X 1 normalized version Im X 1 /A 0 . Second, the straightforward approach to determine the trend of the N -day time series x is just a comparison of the first half of the series with the second one. Therefore, we will consider the difference D between the average value of the time series x over the last [ N/ 2] days avg 2 x and the one over the first [ N/ 2] days avg (i.e., D = avg 2 x  X  avg 1 x ) as our baseline metric (besides the state-of-the-art metric A 0 ).

Growth and fall symptoms. We refer to a case in an A/B test, when the trend of a considered UE measure becomes more positive (or less negative), as a growth symp-tom , while we refer to a case, when the trend becomes more negative (or less positive), as a fall symptom . Let avg and avg B M be the average values of the metric M over the users, exposed to the variant A and B , respectively, and  X  M = avg B M  X  avg A M be the difference between the vari-ants. Then, we summarize all symptoms under our study The authors of [3] considered only the amplitudes A k and A /A 0 , k  X  Z N , as evaluation metrics.
Baseline (BASE): G 0  X  D &gt; 0 G n 0  X  D/A &gt; 0 F 0  X  D &lt; 0 F n 0  X  D/A 0 &lt; 0 &gt; 0 F = 0  X  A 1 = 0  X  A 1 /A 0 = 0 = 0 /A &gt; 0 avg A Im X 1 &gt; 0 avg A Im X 1 /A 0 &gt; 0 &gt; 0  X  A 1 &lt; 0  X  A 1 /A 0 &lt; 0 = 0 /A &lt; 0 avg A Im X 1 &lt; 0 avg A Im X 1 /A 0 &lt; 0 &lt; 0  X  A 1 &gt; 0  X  A 1 /A 0 &gt; 0 Table 2: The studied user engagement measures.
 in Table 1 (where all equalities and inequalities are treated as statistically significant). The growth (fall) symptoms are denoted by the letter G ( F ). The superscript n denotes the symptoms based on the normalized versions of the metrics.
We will describe only the growth non-normalized symp-toms (all other cases are similar). The baseline symptom G 0 is simple: the condition  X  D&gt; 0 means that the average value over the second part of the time period tends to growth w.r.t. the one over the first part. The novel DFT symptom G 1 : the condition  X  A 1 = 0 means that the amplitude does not change, hence, the condition  X  X m X 1 &gt; 0 infers that the phase  X  1 changes in the direction of  X / 2 (see Fig. 2), i.e., the sine wave shift changes in the positive direction. The symp-tom G 2 : the condition  X   X  1 = 0 means that the shift of the sine wave f 1 does not change, the condition avg A Im X 1 means that this shift is positive relating to the trend of x , and  X  A 1 &gt; 0 means that the magnitude of this sine wave increases. The intuition of the symptom G 3 is similar.
Note, that the sign of a symptom (growth or fall) is the sign of a change in the trend of the UE measure during an A/B test. Therefore, it should not be confused with the sign of the treatment effect (positiveness or negativeness). The latter one depends on the UE measure under consideration: whether its increase is preferable or not. For instance, the increase of the number of sessions is a positive effect, but increase in the absence time [5] is negative effect. Thus, the sign of the symptom ought to be properly translated into the treatment effect sign for each UE measure individually.
Experimental setup. In our paper, we consider 32 A/B and 23 A/A experiments conducted on real users of Yandex in order to validate our approach. Each experiment lasted two weeks ( N = 14), the user samples used in the A/B tests were all uniformly randomly selected, and the control and the treatment groups were almost of the same sizes (at least, hundreds of thousands of users). Each A/B experiment com-pared a production version of the search engine with its noticeable deterioration or its clear improvement . We ap-ply a commonly used two-sample t-test with the threshold p val = 0 . 05 for the p-value (as in [2, 9, 3]). We study the 6 main user engagement measures (Table 2) with the same definitions as in [9, 3, 4].

A/A tests. First of all, 23 control experiments (i.e., A/A tests) were conducted in order to check correctness of the ex-Table 3: The number of failed A/A tests (out of 23). Table 4: The number of A/B tests (out of 32) with detected treatment effect ( + the number of those of them, where it is not detected by A 0 ).
 perimentation [8, 1]. An A/A test, which compares the same versions of the service, should be failed about 5% of the time for our p-value threshold 0 . 05 [8, 1]. The number of failed A/A tests for each metric and each UE measure is reported in Table 3. We found that, first, the results for the metrics A , A 1 , A 1 /A 0 , Im X 1 , and Im X 1 /A 0 are acceptable (the two latter ones have the borderline number of failed A/A tests). Second, the metrics D and D/A 0 (which correspond to the baseline symptoms) failed an unacceptable number of A/A tests for the vast majority of the UE measures.
A/B tests. Table 4 summarizes the number of A/B experiments (out of 32) whose treatment effect is detected (i.e., p val &lt; 0 . 05) by each metric and each UE measure (the best result in each row is highlighted in boldface). First, the measures C and CpQ demonstrate the highest sensitivity among all measures. Second, we see that the amplitude A 1 and sometimes the amplitude A 1 /A 0 outperform the base-line metric A 0 by the number of A/B tests with detected treatment effect (i.e., they are more sensitive). Thus, we reproduce the findings of the study [3]. Moreover, we see that, in almost all cases of the UE measures, the metrics A and A 1 /A 0 detect the treatment effect in those A/B tests, where it is not detected by the baseline metric A 0 (see the values in brackets in Table 4). Unfortunately, it could be noted that the novel metrics Im X 1 and Im X 1 /A 0 are worse than both the amplitudes A 1 , A 1 /A 0 and the average one A . Thus, these novel metrics do not improve noticeably the sensitivity, but the main benefit from them will be seen further in detection of the growth/fall symptoms.

Detected symptoms: examples. We start our study from consideration of two A/B experiments as examples. For these A/B tests, the differences of all studied metrics, as well as the average values of the metrics Im X 1 and Im X 1 /A the control group A are presented in Table 5.

The first A/B test evaluates a treatment, which is an ar-tificial deterioration of the ranking algorithm of the search engine. We consider this experiment regarding the clicks per query measure CpQ and the absence time measure ATpS . We see that, first, the state-of-the-art metric A 0 detects a signif-icant increase of ATpS and CpQ for an average user (expected effects for this experiment). Second, for the measure CpQ , a statistically significant difference  X  is observed for several metrics: the baseline metric D/A 0 , the amplitude A 1 , and the novel Fourier coefficient Im X 1 /A 0 . These differences and the statistically significant positiveness of avg yields to a detection of three fall symptoms: F 3 , F n 0 F 1 (according to Table 1). Therefore, we conclude that the negative trend of the number of clicks per query per day stands out more sharply for an average user of the treat-ment variant B than of the control one. In this experiment, the novel growth symptom G 1 is also observed for ATpS .
The second A/B test evaluates a deterioration of the user interface. The treatment effect of this experiment is not de-tected by the state-of-the-art metric A 0 both for the number of sessions measure S and for the clicks per query measure CpQ (their differences are not statistically significant). How-ever, the amplitude A 1 /A 0 detects (i.e., p val &lt; 0 . 05) the treatment effect in the both measures. The statistically sig-nificant positiveness of avg A Im X 1 /A 0 helps us to conclude that we observe the fall symptom F n 2 twice: both the trend of S , and the trend of CpQ are more negative in the treatment variant B than in the control one. Thus, we demonstrated how the novel metrics helped us to understand the sign of the observed change in the amplitudes, even though the state-of-the-art metrics do not detect any treatment effect.
Detected symptoms: overall. Finally, Table 6 sum-marizes the number of detected symptoms overall 32 A/B experiments. The last three columns of this table report the number of A/B tests, whose treatment effects were detected by one of the baseline symptoms (i.e., G 0 , G n 0 , F 0 , or F the col.  X  X ASE X ), by one of the DFT symptoms (i.e., G k , G k , F k , or F n k , k = 1 , 2 , 3: the col.  X  X FT X ), or by any symptom (the col.  X  X LL X ), respectively. We conclude that, first, the novel symptoms allow us to detect noticeably more changes in the UE measure trends than the baseline symp-toms , i.e. they are more sensitive. Second, being based on the amplitudes A 1 and A 1 /A 0 , the novel symptoms are more sensitive than the state-of-the-art metric A 0 (see Table 4), and, on the contrary to the single A 1 or A 1 /A 0 usage, could explain whether the treatment effect is positive or negative .
In this paper, we considered the problem of amplitude metrics that are well sensitive, but are not sign-aware w.r.t. an evaluated treatment effect. Since the DFT sine wave with the first frequency carries signals of the UE measure trend along the experiment time period, we found out that its phase could shed light on the correct understanding of changes of its amplitudes. We combined the amplitude met-rics with the phase ones and formalized our intuition in sev-eral novel overall evaluation criteria (consisting of growth and fall symptoms of the UE measure trend). We verified our approach over 55 large-scale A/B experiments on real users of Yandex, one of the popular search engines. We found that, on the one hand, the most novel criteria out-performed the baseline and state-of-the-art metrics in terms of sensitivity. On the other hand, our approach refined the single amplitude metrics by making them sign-aware w.r.t. the treatment effect. As future work we can study the sign-awareness of the amplitudes with other frequencies.
