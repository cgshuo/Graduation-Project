 This paper studies result diversification in collaborative fil-tering. We argue that the diversification level in a recom-mendation list should be adapted to the target users X  indi-vidual situations and needs. Different users may have differ-ent ranges of interests  X  the preference of a highly focused user might include only few topics, whereas that of the user with broad interests may encompass a wide range of topics. Thus, the recommended items should be diversified accord-ing to the interest range of the target user. Such an adapta-tion is also required due to the fact that the uncertainty of the estimated user preference model may vary significantly between users. To reduce the risk of the recommendation, we should take the difference of the uncertainty into account as well.

In this paper, we study the adaptive diversification prob-lem theoretically. We start with commonly used latent fac-tor models and reformulate them using the mean-variance analysis from the portfolio theory in text retrieval. The re-sulting Latent Factor Portfolio (LFP) model captures the user X  X  interest range and the uncertainty of the user pref-erence by employing the variance of the learned user latent factors. It is shown that the correlations between items (and thus the item diversity) can be obtained by using the cor-relations between latent factors (topical diversity), which in return significantly reduce the computation load. Our mathematical derivation also reveals that diversification is necessary, not only for risk-averse system behavior (non-adpative), but also for the target users X  individual situa-tions (adaptive), which are represented by the distribution and the variance of the latent user factors. Our experiments confirm the theoretical insights and show that LFP succeeds in improving latent factor models by adaptively introducing recommendation diversity to fit the individual user X  X  needs. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering The first two authors have equal contribution to this work. Collaborative filtering, diversity, latent factor model, mean-variance, portfolio theory
Collaborative Filtering (CF) is a popular technique to provide users with personalized suggestions of information items, including movies, music, books, news articles to name just a few [1]. An intuition behind CF is that users who had similar preferences in the past are likely to have simi-lar preferences in the future; the more similar they were in the past, the more likely they will agree with each other in the future [26]. Although the underlying mechanism of CF is very different from algorithms used for text retrieval and Web search, recommendation results are often presented to users in the same form as retrieval results, i.e., as a ranked list. The list contains items that have been recommended for a given target user (profile), ranked in order of their predicted preference scores (relevance). Parallel to text re-trieval and Web search, diversification of the results list has recently been identified as a critical factor that significantly influences end-user satisfaction with a recommender system [13, 19, 29, 36].

In the past, researchers not only have investigated var-ious means to approach diversification (i.e., to answer the question,  X  X ow to diversify? X ), but, most importantly, have explored the rationale behind it (i.e., to answer the question,  X  X hy diversify the results? X ). In text retrieval, some authors regard diversifying the search results as a way of reducing redundancy and improving information novelty in the re-sults [6, 8], as in work on sub-topic retrieval [35], whereas others consider it as a means of managing uncertainty and risk in the ranked list [7, 32].

However, given the fact that there is a balance between diversification and other criteria such as relevance [6, 8, 32], the third question now emerges, that is,  X  X hen to diver-sify? X . More specifically, do we need to make diversification adaptive to different retrieval/recommendation situations? If yes, what is the appropriate diversification level in each of the situations? A recent study on Web search has found that different queries could benefit from different diversification strategies [23, 24]. In recommendation, it is even more use-ful to make the diversification adaptive to individual user X  X  tastes. The usefulness of adaptive diversification has two aspects: First, user tastes have different scope and cover-age of the underlying topics/factors, indicated by the rated items. Some users X  tastes are more specific to a few topical areas, while others are more diversified across various top-ics. To see this, consider the following example in which two movies favored by a user are chosen as a sample that serves as a reflection of the user X  X  overall movie tastes. Suppose a user favors two movies,  X  X nderworld X  and  X  X wilight X . For that user, we may provide a recommendation list contain-ing less diversified items as it is likely that the user X  X  taste is more concentrated on a few specific topical areas (likely to prefer Fantasy and Thriller kind movies). By contrast, if the user likes  X  X he Social Network X  and  X  X aken X , then a more diversified recommendation would fit the user X  X  taste better, implied by the fact that the preferred two movies are in quite different genres. These examples suggest that the diversification level should rely on the underlying topic dis-tribution and the specificity of the individual user X  X  taste. Second, a target user X  X   X  X rue X  taste is hidden and inferred from the rated items of that user (the user profile). Thus, our understanding of the target user X  X  taste varies and de-pends on the ambiguity of the provided user profile. If a user just rated a small number of items, which may not provide enough information to infer the user X  X  exact taste, a more diversified recommendation would be a safer bid.

Fig. 1 further illustrates our intuition by employing a la-tent factor model on a movie rating data set. The uncer-tainty of learned user tastes was measured by their variances (the exact definition can be found later in Section 3.1). First, we can see that the variances of the latent user factors are obviously higher for the users who favored two movies with the same genre, than for the users who favored two movies with different genres. Second, we can also see that the vari-ance of latent user factors decreases as the user rates more items 1 .

The above examples represent the typical aspects that need to be addressed in order to successfully answer the  X  X hen X  question. Taking them into account, this paper pro-poses a new recommendation framework, called Latent Fac-tor Portfolio (LFP), by connecting latent factor models [9, 17, 18, 22, 34] with portfolio retrieval [30]. Latent factor models construct latent user factors/topics from user profile data, and use them to predict the unknown ratings. They have been widely used for CF, due to their accuracy and scalability. Our focus in this paper is, however, not on pre-
It should be emphasized that more ratings in a profile may not necessarily give us more information about the user pref-erence. It also depends on what items the user has rated, since some ratings may be more informative than others [11]. dicting user ratings, but on capturing the uncertainty of latent factors and subsequently employing it to infer the di-versification level. In the proposed framework, the coverage of a user X  X  preference is modelled by the distribution of la-tent factors and the uncertainty is represented by using the variances of latent factors. Our derivation then shows that the distribution and the uncertainty of latent factors in a user profile determine the final diversity of the ranked list. If we want to control the final uncertainty at a certain level, the diversification level should reflect the variance (uncer-tainty) of latent factors in a user profile that has been given. Note that the novelty of our study does not lie only in the combination of latent factor models and portfolio retrieval, but also, importantly, in the insights and understandings of the adaptive diversification, which otherwise would not be derived from either approach independently.

The paper is organized as follows. We present the detail of the proposed LFP in Section 2, after which we discuss the related previous work in Section 3. Our experimental eval-uation is reported in Section 4, and Section 5 summarizes and concludes the paper.
In latent factor models, a rating from user u for item i is decomposed as the inner product of the latent user factors and the latent item factors, as expressed by: where V ia denotes the extent to which the i th item is associ-ated with the a th latent factor, and U ua denotes the extent that user u is interested in the a th latent factor. A is the number of latent factors that are employed in the model. Assuming that the representation of items is independent of individual users, and the latent item factors can be learned beforehand, in practice, we can regard the latent item factors as constants. In this paper, our focus is on the uncertainty of the user factors given a user profile, however, the uncer-tainty of the item factors could be analogously derived. The expected value of a rating r ui is thus expressed as:
We also derive the variance of rating r ui and the covari-ance between rating r ui and r uj as follows: where  X  2 ua denotes the variance of the a th latent factor of user u , i.e.,  X  2 ua = E [ U ua  X  E ( U ua )] 2 . The variance of each rating in terms of latent factors represents the uncertainty. Note that in the derivation of Eq. (3) and (4), we make use of the property that the user X  X  interest in different latent factors are uncorrelated, as shown: This property is a common assumption in latent factor mod-els, in which each latent factor represents one aspect inde-pendent of all the others. We have two insights from the above formulation in Eqs. (3) and (4). First, as seen in Eq. (3), the variance (uncertainty) of the user preference score (the rating) is associated with the variance in the la-tent factors, indicating that taking into account the uncer-tainty in the latent factors could contribute to modelling the user preference. Second, as seen in Eq. (4), the covariance (proportionate to the correlation) between a user X  X  prefer-ences of two items is also associated with the variance of the latent factors, indicating that it is feasible to exploit the uncertainty of latent factors to regulate the recommended items in order to satisfy the user X  X  demand on the diversity and the coverage of recommended items.

Ideally, the variance of a latent user factor, e.g.,  X  is estimated from a number of observations of U ua , which means we need to sample the rated items from user u mul-tiple times. However, this estimation could be infeasible in practice, since 1) multiple observations of user profiles are typically unavailable, thus, requiring heuristic sampling strategy, 2) it requires training the model multiple times according to different observations of user profiles, thus, in-flating the computational cost. For this reason, we propose an approximation for the variance of each latent user factor, based on the latent factors of the items that have been rated by the user, as shown below: where N u represents the set of items rated by user u , and u | denotes its cardinality. This approximation satisfies our basic assumptions about the properties of uncertainty as follows. In the case that a user prefers two or more simi-lar items, i.e., the items could be expected to be represented by similar latent factors, the estimated variance with respect to those latent factors could be low. Conversely, if two rated items are quite different, i.e., the items could be expected to be represented by far different latent factors, the corre-sponding variance of the latent user factors could be high.
Taking into account the ranking positions of the items, we can express the overall relevance of a recommendation list based on latent factors as below: in which w n is a weighting coefficient for rank position n and it is a monotonically decreasing function of the ranking position. The most common function for w n is w n = 1 / 2 [15], which is also used in this paper. Here, we introduce a rank function c ( n ) that returns the item index of the n th item in the ranking list. R uN denotes the overall relevance of N recommended items for user u .
Taking into account Eqs. (2)-(4) and (7), we obtain the expected value of the relevance of the ranked list as: and the variance of the ranked list as: where, for the readability, we skip the detailed derivation from the topic variance to the rank list variance, and leave it to Appendix A. Note that the uncertainty of the recom-mendation list is represented by the variance in terms of latent factors. We have two insights from the two terms of Eq. (9). The first term reflects that the variance of a recommendation list is also top-biased. In other words, if the variance of a latent user factor, e.g.,  X  2 ua , is given, then the latent factor of top-ranked items would have larger in-fluence on the uncertainty of the recommendation list than the low-ranked items. In this sense, in order to reduce the uncertainty of the recommendation list, we need to rank the item relatively higher if its latent factor, e.g., V c ( n ) a and the variance of the corresponding latent user factor, i.e., ua , is low. The second term indicates that the relative rank positions of any two items in the recommendation list influ-ence the overall uncertainty. For example, if the variance of a latent user factor is large and the user has shown interest in an item whose corresponding latent factor is also large, then ranking another item with also a large corresponding latent factor at the higher position leads to the larger un-certainty. Conversely, if the variance of a latent user factor is small, then ranking the two items higher would not lead to large increase of the overall uncertainty. Note that the variances of all the latent user factors need to be taken into account for an aggregated impact on the overall uncertainty. Summarizing, it is evident that by exploiting the uncertainty of the latent factors, recommendation diversification can be attained adaptively.
Following the portfolio theory of IR [32], we can attain an optimal recommendation list by taking into account the tradeoff between the mean relevance of the recommended items and the corresponding variance. As a result, the ob-jective function is expressed as: in which b is a risk-reward tradeoff parameter. As we shall see later, parameter b is a system level parameter and does not contribute to the user adaptive adjustment of the diversi-fication level. Instead, the diversification level in the ranked list will automatically be adjusted according to the uncer-tainty of the user factors and their distribution (in other words, rely on how much we understand the target user from the provided ratings). By maximizing this objective function, an optimal ranking can be achieved, which attains an optimal mean-variance balance. In this paper, we adopt the sequential ranking algorithm as used in [30] to solve the optimization problem in Eq. 10. Again, for readability, we leave the exact derivation in Appendix B and give the final item ranking rule at rank k as: where we have dropped w k from Appendix B since it is a con-stant for rank k . We call the above formulation latent factor portfolio ranking , since both the mean and the variance are defined on latent factors of users and items, as reflected in the summation over the factor space a . The most important characteristic in LFP is the introduction of the variances of the latent factors  X  2 ua , which introduces the adaptation. Combining  X  2 ua and b , topic diversity in the ranked list is adjusted in two levels. At the system level , the need for diversification is due to the risk-averse behaviour of the sys-tem and it is adjusted at parameter b . As shown in [33], the risk-averse behaviour is query (user profile)-independent and related to the utility of the system, defined by the used IR metric. At the user profile level , the need for diversification is related to the level of absolute certainty about the latent topics that the target user is interested in. The uncertainty is represented by the variances  X  2 ua of the latent factors in the formula. Combined with b , it adaptively balances the mean and reward tradeoff in the user profile level, thus making the topic diversification adapted to each individual users X  X  need.

In the next section, we position the proposed LFP with respect to related work, and discuss its contribution.
Latent factor models have become a dominating branch among CF approaches, due to their superiority in terms of accuracy and scalability, as shown in Netflix competi-tion [17]. Matrix Factorization (MF) forms a group of the most well-known latent factor models, e.g., Singular Value Decomposition (SVD) [18], SVD++ [16]. Probabilistic Ma-trix Factorization (PMF) was proposed to carry out the rating factorization from a probabilistic view [22], which leads to the most widely used regularized L2-norm regres-sion model. Additionally, logistic regression was also pro-posed to learn latent factors [2]. The latest developments in recommender systems have explored different criteria to im-prove user satisfaction based on latent factor models, such as modelling user choice process [34] and the marginal net utility [31].

From Eq. (11), we observe that: on one hand, compared to the latent factor models (e.g., [17] and [22]), LFP ranks an item at position k based on not only its rating predic-tions, i.e., the first term in Eq. (11), but also its uncertainty in terms of the latent item factors, i.e., the second term, and the correlation between this item and the items ranked be-fore it, i.e., the third term. Therefore, we can regard LFP as a general extension for latent factor models that introduces the tradeoff with respect to the uncertainty of recommended items. Note that in our derivation we only consider the un-certainty from user latent factors. One can also consider the randomness of both the user factors and items factor si-multaneously, but the study is worth a full attention and is beyond the scope of this paper. We thus leave the detailed discussion and research for future work.

Diversity is realized as one of the most important aspects for the recommendation quality [13, 19, 29, 36]. It is the key factor to help users to explore new interests that they might not discover by themselves and thus enhance user experi-ence. Ziegler et al. proposed a re-ranking algorithm to bring topic diversification, which balances the ranking list accord-ing to user X  X  complete spectrum of interests [36]. Accord-ing to their studies, diversity of a recommendation list may hamper precision to some degree, but will improve user satis-faction as a whole. Then, Zhang and Hunley formalized the intra-list topic diversification problem by addressing a multi-objective optimization problem on diversity and preference similarity [13]. On the other hand, Lathia et al. considered the recommender system as a temporally evolving system that gives diversified recommendations over time [19]. They provided a hybrid algorithm that can offer dynamic recom-mendations, and they also discovered the negative correla-tion between user profile length and the degree of recommen-dation diversity. The issue of evaluating the novelty and the diversity of recommendations has also been raised [29]. In addition, we note that diversifying search results has been extensively studied in the IR community [6, 8, 10, 20, 23, 24, 25], resulting in a fruitful set of diversification methods. It is also of interest to specifically compare the proposed LFP as in Eq. (11) with other adaptive diversification meth-ods recently proposed in text retrieval [23, 24]. In [23], the diversification trade-off of an unseen query was obtained by mapping it to the known queries whose optimal diversifi-cation level is known a priori. By contrast, our method is fully unsupervised and the diversification level is natu-rally adapted to the latent topics that the target user is interested in and also how many of them we have already obtained in the ranked list. As shown by the first term of Eq. (11), an item is promoted if it has the same topic as the user X  X . However its rank score will be penalized if the same topic has already appeared in the lower ranks (see the product V c ( k ) a V c ( m ) a in the third term). In [24], an intent-aware search result diversification method was proposed. This study was focused on the first term in our formula. In their approach, query aspect intents are classified into two categories (factors): informational and navigational, and a machine learning algorithm is used to rank documents with respect to the categories.

The other branch of research related to our work exploits portfolio theory for various information retrieval and rec-ommendation tasks. The importance of such approaches has recently been underlined in a talk by Resnick [21], who projects the usefulness and the necessity of portfolio theory in personalized systems. The application of portfolio theory in information retrieval and recommendation was first pro-posed by Wang et al. [30, 32]. Recent increasing attention to exploiting principles in economics for IR [3] may also fall under the same direction.

In the original portfolio retrieval formulation, the uncer-tainty about the overall relevance of a ranked list is linked to the co-variances between individual documents (relevancies) [30, 32]. However, as they are conditioned on a given query or user profile, exactly, how to obtain such a co-variance matrix remains an open question. In practice, the covari-ance between two relevance scores is approximated by the covariance with respect to their document term occurrences or user ratings. Computationally, this approach is expensive because every document or item pair needs to be considered. In this paper, we solve this issue by providing a better expla-nation of the correlation: document or items are correlated because of their underlying topics and latent factors. As shown in Eq. (11), LFP ranks items by taking into account item correlations based on their latent factors/topics, i.e., the products between item factors, which are not exploited in the original model. For example, when ranking a movie in position k , LFP (in the case of b &gt; 0 ) would perfer a movie with a genre (assumed to be represented by a latent factor) that was not contained by the movies ranked before position k , in order to maximize Eq. (11). In this sense, we can regard LFP as a general extension for the original re-trieval model, where when A = 1 , LFP returns to the original retrieval model in [32].
In this section we present a series of experiments to evalu-ate the proposed adaptive diversification method. We specif-ically focuse on the following aspects: 1) As discussed, user tastes have different scope and coverage, reflected by their rated items: some are more specific, while others have wider interests. The question is whether our method is able to adapt the diversification level to the taste of each user. 2) The number of rated items provided by users varies. As a result, we have different accuracy and uncertainty about the users X   X  X rue X  taste. We intend to investigate whether our method could adjust the diversification level of the ranked list to the uncertainty. 3) If we consider the overall rec-ommendation quality is an aggregated effect from both the relevance and the diversity, whether LFP could benefit for improving the overall recommendation quality?
The publicly available dataset MovieLens-1M is used in our experimental evaluation. The dataset contains 1M rat-ings (scale 1-5, 5 for the best, and 1 for the worst) from about 6K users on about 3.7K movies/items. The data sparseness is 95.5%. Each user in the dataset has at least 20 ratings. In addition, the genre information of movies is provided. There are in total 18 genres, and each movie can be asso-ciated with multiple genres. The average number of genres per movies is 1.62. Note that our focus in this paper is not on the performance comparison against the state-of-the-art baselines, but on investigating how the proposed method could diversify recommendation results under different con-ditions of user profiles (tastes). The choice of a moderate size dataset enables an efficient exploration of experimental results under various settings.

In order to create the training set (for estimating the la-tent factor models) and the test set (for evaluation), we split the data into a large set containing 80% of the users and a small set the remaining 20%. For each user profile length (UPL) that we investigate in the experiments, we create a test set containing users with that UPL, by randomly se-lecting the desired number of items (i.e., UPL=2,3,5 and 10) from each user in the small set. The remaining items from each profile in the small set are added to the complete large set to form the training set.
In our experiments, we adopt a common metric in text retrieval, Mean Average Precision (MAP), to measure the effectiveness of the ranked recommendation list. In order to calculate MAP, we set the relevance threshold as rating 4. In other words, we regard items with ratings equal to or larger than 4 as relevant.

For the investigation of the trade-off (and combination) of the relevance and the diversity in Section 4.2.4, we utilize another evaluation metric from text retrieval,  X  NDCG [8]. We use movie genres as  X  X uggets X  in calculating  X  NDCG. The exact definition of  X  NDCG is expressed below: in which, kl is an indicator function that is equal to r uc ( k ) (i.e., the rating of the k th movie in the list for user u ), if the k th movie in the recommendation list of user u contains genre l , otherwise 0. q u l,k  X  1 denotes the number of movies ranked up to position k  X  1 that contain genre l in the recommendation list for user u .  X  is a constant set to control the magnitude of penalty for the redundancy of the recommended items. The value of  X  can be within the range [0 , 1] , in which the higher value indicates the larger penalty. In our experiments, we use  X  = 0 . 5 as a moderate choice for measuring diversity.  X  IDCG@K denotes the highest possible value of  X  DCG@K in the case that the top K recommendation list contains  X  X deally X  diversified relevant items. Thus,  X  NDCG is nor-malized to be [0,1]. Note that  X  NDCG depends on both the movie ratings and genres, representing a suitable metric for our purpose of evaluating the trade-off between the rel-evance and the diversity. Since we particularly focus on the top-ranked items in recommender systems, we use K = 5 in the experiments.

To solely measure the recommendation diversity in a ranked list, we also introduce a simple diversity measure called DNG@K. It measures the number of genres in the top-K ranked list. The number is discounted according to the po-sition of the corresponding movie in order to consider the rank bias. Specifically, we define DNG@K as: in which G ( k ) denotes the number of genres that the k th movie have and that are not included in the top k  X  1 movies. k is a discount factor that is set as w k = 1 / 2 k  X  1 . Similar to  X  NDCG, we focus our evaluation with K = 5 . The reported DNG is an average across all the test users. Note that DNG is different from other proposed diversity measures that take into account the relevance of recommended items, such as the work in [29].
In collaborative filtering, there are various ways of ob-taining latent factors in Eq. (1), either by non-probabilistic approaches [16, 17, 18] or from a probabilistic viewpoint [22]. In our experiment, we choose one representative from each of the two categories, briefly described as follows:
PureSVD : It is the basic form of singular value decom-position [4], as show in Eq. (15). Supposing the user-item rating matrix R consists of M users and K items, the rating matrix R can be decomposed into three low-rank matrices,
M  X  A , S A  X  A , and Q K  X  A . Then, the latent factors of users can be denoted as U , and the latent factors of items can be denoted as V , as shown in Eq. (16). Each column vector in U (e.g., U u for user u ) or V (e.g., V i for item i ) repre-sents the corresponding user or item. Although PureSVD features the most basic latent factor model, the recommen-dation performance for top-N tasks is competitive according to a recent empirical study [9]. For this reason, we choose it as a representative of non-probabilistic latent factor models.
PMF : We use probabilistic matrix factorization [22] (PMF) as one of the state-of-the-art latent factor models in CF. PMF estimates the latent factors of users and items by max-imizing the posterior, which is the conditional probability of the latent factors given the observed ratings R and hyper-parameters  X  , as shown below: The resulting objective function of PMF is expressed as: The latent factors of users and items are learned from the user-item ratings (normalized to [0 , 1] ), and the magnitudes of latent factors are penalized in order to alleviate overfit-that serves to bound the range of the inner product of latent factors. A simplification is usually made to set  X  =  X  U =  X  which is also used in this paper.
As discussed, our LFP model implies that the need for diversification in a ranked list comes from two levels. Our first experiment is to investigate the system level diversity, which is controlled by the parameter b in Eq. (11). In our experiment, we use the training set to train the latent factor models, and for each user in the test set, we randomly select 2 rated items, i.e., User Profile Length (UPL=2), as user profiles, and use the remaining rated items as ground truth. By varying the value of parameter b in LFP, we evaluate its influence on the recommendation performance of differ-ent latent factor models, which is shown in Fig. 2. As can be seen, for both PureSVD and PMF, the diversity mea-sure DNG@5 generally increases as the value of b in LFP increases, while MAP decreases. Note the baseline latent factor models are equivalent to the case that we set b = 0 . The figures show that a positive value of b could contribute to diversifying the recommendation results, and the magni-tude of diversification is controlled by its value. However, a Table 1: The diversity DNG@5 adapted to the tar-get user profiles: the range of interests.
 positive value of b could reduce the MAP, indicating that it may degrade the end-user satisfaction when the results are over-diversified. The observation is consistent to the study in text retrieval in [33]. Because the parameter is a con-stant across target users, it serves to adjust the diversity of recommendation at the system level, and its optimal value depends on the evaluation metrics used (in other words, the utility of the recommendation system).
We have discussed in Section 1 that the observed num-bers of rated items are different across users. As illustrated in Fig. 1, the number of user rated items influences the un-certainty of the learned latent user factors X  X he more infor-mation we have about the user, the less uncertain our model is about the user X  X  hidden tastes. In the following experi-ment, we evaluate the impact of the model uncertainty on the diversity of recommended items, where the model uncer-tainty is indicated by the number of rated items provided in the user profile. We generate the user profile length (UPL) from 1 to 10, and randomly select the rated items as user profile items. As in our dataset, each user has at least rated 20 items. Setting UPL up to 10, we ensure that there are at least 10 rated items per user used for testing.

From Fig. 3, we observe that the LFP models succeed in consistently increasing the diversity of recommendation results for both PureSVD and PMF. Note that the increases are all statistically significant, according to Wilcoxon signed rank significance test with p &lt; 0.01. This indicates that LFP could effectively capture the uncertainty of latent factors and use it to diversify recommendation results.

In addition, the diversity achieved by both our LFP and each of the basic latent factor models, PureSVD and PMF, generally increases as the users rated more items. At a first glance, the result seems to contradict with the idea that adding ratings in the user profile would reduce the uncer-tainty of the user model and thus the need for diversifying the results. A closer look, however, suggests that this is intu-itively correct because when there are few rated items known from the users, the recommended items could be strongly bi-ased toward the few known items, and thus less diversified, whereas when more rated items are known from the users, the recommended items could be more likely to cover differ-ent aspects of user interest, and are thus more diversified. to Sci-Fi ,  X  X  X  to Thriller , and  X  X  X  to War . LFP with PureSVD is used.
Finally and most importantly, we also observe that the increase of diversity introduced by LFP generally decreases as the number of user rated items increases. As shown, the diversity increase brought by LFP with PureSVD tends to be constant as the UPL increases, and the diversity achieved by using LFP with PMF tends to be closer to that of us-ing only PMF as the UPL increases. When the UPL is small, LFP automatically provides relatively larger increase of diversity against the basic latent factor models. In other words, when the users rated only a few items, the basic la-tent factor models tend to recommend items based on highly uncertain latent factors. LFP addresses the risk of the basic latent factor models by providing more diversified results.
We now focus on the evaluation by considering the users with different ranges of interests. To make our study focused and controlled, we are particularly interested in two types of users, i.e., the users who rated movies with the same genre (denoted as the  X  X ocused X  type), and the users who rated movies with the non-overlapped genres (denoted as the  X  X road X  type). The first type of user profiles represents a typical situation in which the target user has a specific range of interests and as a result, the diversification is less required, while the second type represents the opposite situation in which diversification is more desired. Also as demonstrated in the previous section, LFP could be most beneficial for diversifying recommendation results for the users who only rated a limited number of items. For this reason, we use UPL 2 and 3 in this investigation. For each UPL, we classify a user into the  X  X ocused X  type if all his or her rated items contain the same genre, and into the  X  X road X  type if all rated items are associated with genres different from each other.
The results are shown in Table 1, from which we have two observations. First, for both PureSVD and PMF, the diver-sity of the  X  X ocused X  type is lower than the  X  X road X  type for most of the cases. This result is in accordance with our un-derstanding, as discussed in Section 1, that the commonality of the items in the user profile has a significant impact on the user need for diversification. In the case of the  X  X ocused X  type of user profiles, the latent user factors are learned from the items that have the same or similar topics (in this case genres), and the latent factors of those movies could be sim-ilar. As a result, the uncertainty and variance of the latent user factors could be low, and those latent user factors would promote to recommend movies with the same or similar gen-res as the movies that the user has already watched, i.e., a less diversified recommendation. By contrast, a more diver-sified recommendation would be promoted to the  X  X road X  type of user profiles.
 Second, we observe that for both PureSVD and PMF, and Table 3: Relevance vs. diversity (with PureSVD).
 for both UPL=2 and UPL=3, LFP has a significant increase of diversity for the  X  X road X  type of user profiles, while intro-ducing a slight change of diversity for the  X  X ocused X  type. The result indicates that LFP could effectively exploit the distribution of latent user factors to adaptively determine the level of diversification. This is further illustrated by the example in Table 2. We clearly see that LFP automatically adjusts the diversity of recommendations according to the different range of interests learned from the user profiles.
Our final experiment investigates how LFP can benefit the end-user satisfaction by considering both the relevance and diversity of recommended items. We test the recom-mendation performance in terms of relevance, as measured by MAP, and the performance in terms of diversity, as mea-sured by DNG@5, under two different settings of parame-ter b in LFP, i.e., b =  X  1 and 1 . Note that as shown in Section 4.2.1, a positive value of b tends to increase the recommendation diversity, while decreasing the recommen-dation relevance. The opposite results can be observed in the case of a negative value of b . The results are shown in Table 3 and 4. We first observe that LFP could im-prove the relevance of recommendations for the users who have broad interests. When b =  X  1 , LFP improves MAP for both PureSVD and PMF. This result indicates that in the case that LFP increases the similarity among the rec-ommended items based on latent item factors, it could con-tribute to improving the relevance of the recommendation. The empirical result is also consistent with the statistical mean-variance analysis of MAP conducted in [33]. Second, LFP could achieve a trade-off between the recommendation relevance and the diversity. As can be seen, when b = 1 , LFP diversifies the recommendation results and results in an improved DNG@5 for both PureSVD and PMF, while degrading the relevance performance as measured by MAP. However, on the whole,  X  NDCG is substantially improved, indicating that the degraded relevance is compensated by a payoff in the overall quality of recommendation when both relevance and diversity are taken into account. Although here  X  NDCG could only serve as an approximation of the end-user satisfaction for the recommended items, the results are evident that we can use LFP to adjust the trade-off be-tween the relevance and the diversity of recommendations from latent factor models, allowing us to give a positive an-swer to our final research question. We proposed a new recommendation framework, called Latent Factor Portfolio (LFP), specifically for adaptively di-versifying recommendation results for individual users. We exploited the variance of the latent user factors to capture the range of user interests and uncertainty of the user pro-files and use them as the basis for indicating users X  needs for diversity. Through our experiments, we demonstrated the effectiveness of LFP for adapting result diversification to the users X  needs without accessing to explicit item prop-erties. In addition, we also showed that LFP is capable of effectively adjusting the trade-off between the relevance and the diversity of recommended items, and thus could further contribute to the overall recommendation quality.

Our future work involves several possible directions. First, we are interested in alternative optimization algorithms to improve the portfolio selection process. Second, we will ex-tend the basic latent factor models and explore various ways of estimating the variances of latent factors of both users and items, possible through Bayesian approaches [5]. Third, we are also interested in investigating the possibility to develop dynamic LFP that could instantly modify recommendations through the interactions with users [14, 27]. Finally, we would like to extend our work to adaptive search result di-versification in text retrieval [28] and compare our work with other diversification approaches.
