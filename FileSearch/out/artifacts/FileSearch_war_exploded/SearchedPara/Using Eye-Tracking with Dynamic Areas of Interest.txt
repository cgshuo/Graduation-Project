 Cutrell and Guang [4] used eye-tracking to explore the ef-fects of different presentations of search results. Joachims et al. [5] examined the reliability of click-through data for implicit relevance feedback of a web search engine by com-paring them to eye-tracking data.
For our experiments, we used a collection based on a crawl of 2.7 million records from the book database of the online bookseller Amazon.com. As test subjects, we recruited 12 students of computer science, cognitive and communication science and related fields. After an introduction into the system, users had to work on three tasks, with a time limit of 20 minutes per task (rotating tasks in a Latin square design). Due to space limitations, we only discuss the results of the  X  X omplex X  task type here, where users were asked to find books about one of the following topics: 1) Trustworthy books about 9/11 terrorist attacks, 2) Controversial books discussing the climate change, 3) Highly acclaimed novels about racial discrimination.

The user interface of our system consists of four major areas: a query input field, a list of result items, a detail area showing all available data about the currently selected document, and a basket where users should place docu-ments they deemed relevant. We wanted to collect eye-tracking data for each specific result list item, even when the user is scrolling down in this list; however, standard eye-tracking software allows only for the monitoring of static  X  X reas of interest X  (AOI). Thus, we developed a framework called AOILog which automatically keeps track of position, visibility and size of all user interface objects at any point in time. Combining this information with the eye-tracking data, we always know at which object the user is currently looking. 1
Our analysis is based on the combination of logging and eye-tracking data. For the latter, as in other studies, we focus on the so-called fixations, and also consider them only if they last for at least 80 ms, since this is the minimum time required for reading anything on the screen [2].

Corresponding to the four areas of the user interface, we can distinguish four types of user actions: formulating quer-ies , looking at a result item , regarding document details ,and looking at the basket (which can be viewed as a more strate-gic action, where the user is thinking about the continuation of her search). Thus, a one-to-one mapping of eye-tracking
AOILog is an open source software; it can be easily inte-grated into any user interface based on Java Swing. 4. As mentioned above, users often compare the current Now we analyse this data with regard to the IPRP. The timings correspond to the effort e ij for evaluating a choice c , while the transition probabilities give the chances p ij of accepting it. As a possible approach for quantifying the benefit a ij of a decision, we can regard the time needed for finding the first (next) relevant document. For that, we compute the expected time for reaching the basket. Here we can apply the method for computing  X  X irst passage times X  in Markov networks, which leads to a linear equation system. As results, we get 127.9 s for the query, 123.0 s for the result list and 109.5 s for the details stage. The benefits can then be defined as the time differences between the two situations of a transition invoked by accepting a choice. As could be expected, the biggest benefits are achieved when moving to the basket X  X ut the corresponding acceptance probabilities are low. On the other hand, there are also choices with negative benefits (when going back to query reformulation or from detail to result). While the order of the benefits seems ok, negative benefits are in contradiction to the IPRP, which says that the corresponding choices are useless and thus should be avoided. This is a more general problem of parameter estimation for the IPRP: when reformulating the query, users do not really go back to the initial situation, they submit an improved query. For considering that, we would need a more complex Markov model, and a much larger number of observations.
In this paper, we extended current methodologies for ana-lyzing interactive IR by separating between eye-tracking and action level, and by implementing dynamic areas of interest. Our example study shows the findings point to possible sys-tem improvements, and that click-through rates are a poor indicator of relevance. Finally, we can immediately derive parameters for the IPRP, although open problems remain.
This work was supported by the German Science Founda-tion under grant no. FU 205/24-1. [1] L. Azzopardi. The economics in interactive information [2] G. Buscher, A. Dengel, and L. van Elst. Eye [3] N. Fuhr. A probability ranking principle for interactive [4] Z. Guan and E. Cutrell. An eye tracking study of the [5] T. Joachims, L. Granka, B. Pan, H. Hembrooke,
