 The problem of monitoring the correlations of discrete streams is to continuously monitor the temporal correlations among massive discrete streams. A temporal correlation of two streamsisdefinedasa tracking behavior, i.e., the most re-cent pattern of one stream is very similar to a historical pat-tern of another stream. The challenge is that both the track-ing stream and the tracked stream are evolving, which causes the frequent updates of the correlation-ships. The straight-forward way of monitoring correlations by brute-force subse-quence matching will be very expensive for massive streams. We propose techniques that are able to significantly reduce the number of expensive subsequence matching calls, by con-tinuously pruning and refining the correlated streams. Ex-tensive experiments on the streaming trajectories show the significant performance impro vement achieved by the pro-posed algorithms.
 H.2.8 [ Database Management ]: Database Applications-Data Mining Algorithms, Performance stream correlation, trajectory tracking
Discrete streams, the streams of discrete numbers, are ubiquitous in many applications such as digital communi-cation, logistics systems and environmental monitoring. Al-though many streams are time series of numerical data, they can however be transformed into discrete data, to improve the performance of stream processing. In this paper, we are interested in applications where a large volume of discrete streams are frequently updated when new discrete numbers continuously feed to the streams. The problem we want to address is to online monitor the lagged correlations among those evolving discrete streams, i.e., to continuously mon-itor the correlated streams of any given query stream. In this problem setting, a stream r is a correlated stream of a query stream s if s is repeating a historical pattern of r .If r is a correlated stream of s , r is called a tracked stream, and s is called a tracking stream. A pattern is a subsequence of significant length within a stream.

The problem of correlated stream detection is useful in monitoring streams that present similar evolving patterns, and making decisions timely on the tracking streams based on the past experience of the tracked streams. Exampling applications include trajectory monitoring and sensor net-works. For example, in computer games, monitoring the trajectories of characters is very useful in identifying the ob-jectives of characters. It may bring benefits such as advanced game AI and efficient sharing dynamic game contents.
This paper is mainly focused on discrete trajectory appli-cations, although the proposed techniques can also be ap-plied to other types of discrete streams. Monitoring the correlated streams is achieved by discovering the tracking behavior among streams, i.e., to find correlated (similar) patterns for the most recent pattern of each query stream. It is basically a subsequence matching problem which can be straightforwardly addressed by existing subsequence match-ing techniques [10, 12]. However, subsequence matching will be extremely expensive because an update of the query pat-tern will trigger the subsequence matching process of the query pattern against a huge number of long streams. The cost will be more expensive when approximate string match-ing distances (e.g., edit distance) are applied for evaluating the similarities between patterns. It will be not scalable if every update triggers the correlated stream detection pro-cess from scratch.

In this paper, we propose techniques that are able to effec-tively and continuously bound the distances for subsequence matching. Candidate streams are incrementally refined so that most of the complex subsequence matching processes can be postponed.
Subsequence matching attempts to locate matching sub-sequences within a long sequence with respect to a short query sequence [4]. Traditionally, it is studied by assuming that the long sequences are fixed and stored in time series database. Sliding windows of fixed width are applied to extract a large number of local patterns from the long se-quences [4, 9]. Pattern detection on streams is different from finding matching subsequences of long database sequences. It tries to detect matching subsequences within long streams. Examples are BRAID [13] and SPIRIT [11]. Streaming pat-tern detection on DTW distance has been studied in [12]. The matching subsequences are continuously monitored by cumulating DTW distances in a continuous manner. Note that, although many of the above techniques are focused on numerical streams, they can however be adapted to find matching subsequences in discrete streams. We apply the idea of [12] to the edit distance for matching discrete streams as our baseline solution.

Approximate string matching is typically preferred for matching strings because it is error tolerant. Some surveys of approximate string matching can be found in [6]. One type of string similarity measures use the set similarity (e.g., Jaccard similarity [1]) of tokens to evaluate the similarity of two strings, where the positions of tokens are ignored. An-other type of string similarity measures use the number of operations to transform one string to the other, e.g., edit dis-tance and Hamming distance. Edit distance has been widely used in many recent studies of approximate string matching [3, 8, 7], we use it as an exampling distance, although our techniques can be applied to many other distances.
Li et al. [8] showed that many string distances can be effectively bounded using the q -grams (tokens) within two strings. Many list-merging search and similarity join algo-rithms [1, 5, 7] have been proposed to speed up approximate string matching. MergeSkip [7] is one of them to efficiently retrieve similar strings of a given query by effectively prun-ing most non-similar strings in the process of merging token inverted lists. It has been shown [7] that MergeSkip is an very efficient solution for filtering approximate strings. We therefore use it as a baseline of filtering candidate correlated streams in our problem.
Astream r is a window of sequential data items most recently generated. It can be denoted as r = { r [ b ] ,r [ b + 1] ,...,r [ e ] } ,where r [ b ] is the earliest data item recorded in r , r [ e ] is the latest data item of r ,and i is the index of data item r [ i ]. As a stream, new data items will be continuously appended to r . Meanwhile, to limit the memory usage of recording historical data items in r , those outdated data items will be removed from r timely. The memory window size of the stream r is denoted as n = e  X  b +1. We consider the applications where there are a large number of discrete streams R = { r } . To capture the temporal correlation-ship, we say that the stream s is correlated to the stream r if the most recent pattern of s is similar to a historical pattern of r . We denote the most recent pattern (the most recent w data items) of a stream s as s . It implies the current tendency of a stream. In our problem, s is treated as a query pattern every time the query stream s updates.
 Definition 1 (Correlated pattern). Given the most recent pattern s of a stream s ,asubsequence  X  r ( in the mem-ory window of r )ofanotherstream r is a correlated pattern of s if the distance between s and  X  r is small enough, i.e., d ( s,  X  r )  X   X  ,where  X  is a given threshold.

Note that the distance function d () can be any distance of discrete sequences. However, in this paper, we focus on string edit distance. In our problem, to capture the tracking behavior (i.e., the lagged correlation between two patterns), temporal constraints are required between data items of s and  X  r . After the edit operations, two strings  X  s and  X  r are identical only if  X  s [ i ]=  X  r [ i ]and  X  s [ i ] .t  X  time stamp of s [ i ]), for i =1 ,..., |  X  s | = |  X  r | we modify the edit distance as a time-constraint edit dis-tance. Given two strings  X  s and  X  r of length m and n respec-tively, the time-constraint edit distance of  X  s and  X  r is defined where M [0][ j ]= j, 0  X  j  X  n ; M [ i ][0] = i, 0  X  i  X  m .For any two data items x and y , d ( x, y ) is defined as: Definition 2 (Correlated stream). Given the most re-cent pattern s of a stream s ,ifanotherstream r contains a correlated pattern of s , we say that r is a correlated stream of s , denoted as s  X  r .

Based on above definitions, the online correlated stream monitoring problem is defined as: given a set of streams R , and a query stream s ( s  X  R or not), we want to continuously monitor a subset R ( s )= { r | s  X  r, r  X  R, r = s } , whenever the query stream s updates.
Discrete streams can be treated as evolving strings. There-fore, the problem of monitoring correlated streams can then be modeled as an online substring matching problem. By applying some advanced subsequence matching techniques proposed in [12], the complexity of checking whether one stream r is the correlated stream of s can be O ( nm ). We use it as a baseline of detecting correlated streams R ( s )ofthe query stream s , which is a brute-force subsequence match-ing process shown in Algorithm 1. Given N streams, the complexity of Algorithm 1 is O ( Nnm ).
 Algorithm 1 Brute-force subsequence matching
Note that the baseline solution does not support the incre-mental computation of R ( s ) for a given stream s . Whenever a new data item feeds to s , R ( s ) has to be re-computed from scratch, although R ( s ) may change slightly due to the insertion of a new data item.
To effectively bound the edit distance, we propose to use the q -grams of streams. A q -gram of a string  X  s is a substring (of the length q )of  X  s . Given a string of  X  s ,thesetofall q -grams of  X  s is denoted as G (  X  s ). The total number of q -grams that d (  X  s,  X  r )  X  q  X  max( | G (  X  s ) | , | G (  X  r ) Lemma 1. Fo r two streams s and r ,if s  X  r ,then | G ( s ) G ( r ) | X  w +1  X  (  X  +1) q .

Proof. Since s  X  r , there must be a substring  X  r within r ,that d ( s,  X  r )  X   X  . d ( s,  X  r )  X  q  X  max( | G ( s ) G (  X  r ) | , i.e., | G ( s )  X  G ( r ) | X  max ( | G ( s ) max( | G ( s ) | , | G (  X  r ) | )  X | G ( s ) | = w  X  q +1, then w  X  q +1  X   X   X  q = w +1  X  (  X  +1)  X  q .

Lemma 1 provides a lower bound of | G ( s )  X  G ( r ) | to guar-antee that s  X  r is satisfied. It therefore allows us to ef-fectively prune the costly subsequence matching between s and r if | G ( s )  X  G ( r ) | &lt;t . To achieve such a pruning mech-anism, we therefore need to monitor the number of common q -grams between the most recent pattern s and the other streams. We denote the set of all streams having at least t common q -grams of G ( s )as C ( s )= { r || G ( s )  X  G ( r ) It is obvious that R ( s )  X  C ( s ).
As the streams evolve, the q -grams of the streams contin-uously update. Counting the number of common q -grams between the most recent patterns and streams is a stream join problem. One way to efficiently count common q -grams in stream scenario is to maintain an inverted list of streams for each q -gram g , recording the streams that recently gen-erate g . Figure 1(a) shows an example. The inverted list of a gram is a list of elements with each element consists of two parts: the id of the stream, and the position of the first data item of a gram occurrence in the stream. All the elements are sorted by their id s and positions in turn. As such, all sorted inverted lists can be maintained by a B + -tree, with the tandem of stream id and gram position ( pos )asthekey. The outdated elements of an inverted list can be removed from the index based on the pos attribute or an additional timestamp attribute.

Given a most recent pattern s , and the inverted lists of all its q -grams, the number of common q -grams that the other streams have can be computed by a merge counting algorithm (called MergeSkip in [7]) over the sorted inverted lists of G ( s ). Every time a new data item feeds to s ,anew q -gram is generated in G ( s ). In the meanwhile, an outdated gram need to be removed from G ( s ). This will trigger a new merge counting process. However, the MergeSkip algorithm is not a continuous algorithm that is able to incrementally maintain the counts for | G ( s )  X  G ( r ) | when stream updates. Each update process requires to scan and merge w  X  q +1 inverted lists, even though for two consecutive most recent patterns s 1 and s 2 ,where s 2 [ i ]= s 1 [ i +1] (for i =1 ,...,w 1), there will be w  X  q inverted lists to be repeatedly scanned.
To efficiently maintain C ( s ), we design an algorithm that is able to continuously count the number of common q -grams among streams. For each query stream s , a counting list (de-noted as A ( s )) is maintained that records all streams having common q -grams of G ( s ), sorted by the stream id s. An entry in the counting list A ( s ) corresponds to a stream r . A list of common q -grams between s and G ( r ) are maintained for each entry, sorted by the positions of grams in G ( s ). Each entry r in the counting list A ( s ) consists of the id of r and apointertoagramlist.

If g s  X  G ( s ) has a number of common q -grams in a stream r , there will be an entry for g s , in the gram list of r .The first column of the gram list records the position of g s addition to the position of g s , an entry of the gram list also records the position of the oldest common gram and that of the newest common gram of g s in the stream r .Ifthere is only one common gram of the gram g s ,thepositionsin the last two columns will be the same. Because duplicated grams from the same r have been reduced, each gram list will at most contain | G ( s ) | elements.

Upon the detection of a new q -gram from a stream s , the updates of the A ( s ) and the candidate stream set C ( s ) are conducted following the process given in Algorithm 2 (shorted as the CC algorithm). It basically merges A ( s ) with the inverted list L ( g i ) of the most recent gram of s . For a stream r that is newly discovered from L ( g i ), a new entry will be created in A ( s ). Otherwise, a new entry will be appended in the gram list of the corresponding entry of the stream r ,in A ( s ). If multiple common grams of r are detected, only the position l p is updated. When scanning each entry of A ( s ), we will check and remove its outdated grams (in terms of s p ) in its gram list. Because entries in the gram list is sorted based on s p , the outdated checking is very efficient. Once the size of a stream entry of A ( s )is no less than t , a candidate stream will be discovered. On the other hand, if all entries in the gram list are outdated, the stream entry will be removed from A ( s ). Compared to the MergeSkip algorithm where | G ( s ) | lists are merged, the CC algorithm only needs to merge two lists. It is therefore more efficient than the merge counting algorithm, especially when w is large.
 Algorithm 2 Continuous counting (CC)
The filtering algorithms discussed above generate candi-date streams ( C ( s )) that need to be further refined because they may not be true correlated streams of s . It is likely that the set C ( s ) updates slightly when stream s only up-dates a few data items. If every candidate stream in C ( s ) needs to be checked by an expensive subsequence matching process each time s is updated, there will be too much re-dundant computation. We propose an algorithm to achieve incremental refinement of the candidate streams in C ( s ).
Given a substring  X  s and a string r ,let d (  X  s, r )=min We use s [ b s : e s ] to denote a subsequence of s starting at the position b s and ending at the position e s .Wehavethe following lemmas (proof is not given due to the space limits) that support the incremental refinement of C ( s ). Lemma 2. Let s = s [ b s : e s ] , s = s [ b s +1: e s +1] which is one entry shift of the previous most recent pattern s ,we have d ( s ,r )  X  d ( s, r )  X  1 .
 Lemma 2 has the following corollary: Corollary 1. If d ( s, r )=  X &gt; X  , r can be a correlated stream of s only if after at least  X   X   X  data items feed to s . Lemma 3. Let  X  s = s [ b s : e s ] ,  X  r = r [ b r : e r e +1] ,  X  r = r [ b r +1 : e r +1] . We have d (  X  s ,  X  r ) Corollary 2. Suppose there is a correlated pattern  X  r = r [ b r : e r ] of s = s [ b s : e s ] such that d ( s,  X  r )  X  updated to s = s [ b s +1: e s +1] ,if s [ e s +1]= r [ e r [ b r +1] is not outdated, then s  X  r still remains.
 Let  X  r = r [ b r +1: e r + 1]. According to Lemma 3, in this case, d ( s ,  X  r )  X  d ( s,  X  r )  X   X  . Therefore, s  X  allows us to delay the computation of d ( s, r ) for a previously valid s  X  r ,if s [ e s +1] = r [ e r +1] and r [ b r +1] is not outdated. Moreover, such a delay can be transmitted if the condition always holds when s advances.
 Corollary 3. Suppose there is a correlated pattern  X  r = r [ b r : e r ] of s = s [ b s : e s ] such that d ( s,  X  r )  X  updated to s = s [ b s +1: e s +1] ,if s [ e s +1] = r [ e r [ b r +1] is not outdated, then d ( s ,  X  r )  X  d ( s,  X  r )+1 . Corollary 3 can be easily proved based on Lemma 3. It allows us to delay the computation of d ( s, r ) for a previously valid s  X  r if d ( s, r ) is small enough, even though s [ e r [ e r +1]doesnothold.
 Algorithm 3 Incremental refinement (IR)
Based on the above three corollaries, we propose the in-cremental refinement (IR) algorithm in Algorithm 3. It achieves the efficient incremental refinement of candidate correlated streams by delaying the actual subsequence match-ing process to the time when correlation-ship of two streams is able to change.
Because the baseline solution (Algorithm 1) of brute-force subsequence matching is very expensive, we do not plot its results in our experimental results. Therefore, the compar-ative approaches are some alternatives of the filtering and refining algorithms. For filtering, we have two alternatives: the MergeSkip algorithm (labelled as M ) and the CC algo-rithm (labelled as C ). For refining, we either use the pro-posed incremental refining (IR) algorithm (labelled as R ), or directly use the subsequence matching algorithm (labelled as S ) for refining all candidate streams. As such, we derive four alternatives by combining them: CR , MR , CS , MS .The best approach we propose to use is the CR approach, which is the combination of CC and IR.
We use trajectories generated from a road network gener-ator [2] as the original dataset. The generator can guarantee the positions of the objects are reported whenever they pass through a node of the network. As such, we are able to convert the position of a node into a discrete number. We choose the map of  X  X an Francisco Bay Area X , which is the largest map provided by the generator. For each stream (trajectory), we generate about 280 data items in average. The performance test starts when trajectories have been up-dated 100 times in average. The test lasts for a duration where 50 updates happen for a stream in average. During the test period, we treat each stream as a query stream. The performance is measured as an average update cost of an update (a new data item appended) of one stream, which is averaged over all streams during the test period. We compare the cost mainly in two types: the computa-tional cost and the ratio of subsequence matching calls. For the computational cost of each approach, we measure the running time of both the filtering (including the index up-dates) algorithm and the refining algorithm. For the ratio of subsequence matching calls, we measure the following ra-tios: | C ( s ) | / | R | , | R ( s ) | / | R | ,and# calls/ actual subsequence matching calls).

We run all experiments on an Intel Core 2.0GHz machine with 3GB memory, running Linux 2.6.28 system. The algo-rithms are implemented by GNU C++. To guarantee the efficiency, all data are maintained in memory. The default parameters are set as | R | =10 k , w = 12,  X  =2, n = 50, q =2(gramsize).
Before discussing the results of these parameters respec-tively, we should note that the performance of our baseline solution (Algorithm 1) is much more expensive (in 3-4 or-ders of magnitude) than the alternatives shown in our ex-periments. This is very reasonable because from Figure 3 we can see that most of subsequence matching calls can be pruned by applying the filtering and refining algorithms. We therefore do not show the results for the baseline algorithm in those figures showing the experimental results.
We can see from Figure 2(a) that, the CPU time of the 4 approaches linearly increases as the stream set enlarges. When considering only the refining algorithm, we can see that the approaches ( CR and MR ) with the IR algorithm can achieve around 2-3 times faster than those ( CS and MS ) without it. When considering only the filtering algorithm, we can see that the CC algorithm ( CR and CS ) is around 2.5 times faster than the MergeSkip algorithm ( MR and MS ). As a result, the CR can achieve around 3 time overall performance improvement than the MS baseline. Note that although an update of a query can be addressed in around only 1 m seconds when | R | = 100 K , if every stream need to be monitored, the total cost for an update of all streams (100K) will be around 100 seconds, which is very expensive.
Figure 3(a) shows that the filtering algorithms achieve very tight lower bound distance for pruning un-correlated streams. Almost all (more than 99.5%) un-correlated streams can be pruned during the filtering process. Figure 3(a) also shows that the IR algorithm can also prune a large per-centage of subsequence matching calls that cannot pruned in the filtering phase. This explains why the IR algorithm improves the over performance. The ratio of subsequence matching calls changes slightly when | R | changes.
Figures 2(b) and 3(b) shows the impact of query window size w . We can see that, with the enlargement of w ,the pruning power of both the filtering algorithms and the re-fining algorithm increases. As a result, the CR approach canbeasfastas4timesofthe MS baseline. Although the pruning power increases when w is enlarged, the over-all computational cost of each approach still increases. This is because, the basic computational cost of a subsequence matching call increases with the enlargement of w .Wecan also find that the relative cost of the filtering algorithms over the IR algorithm increases when w is enlarged, especially for the MergeSkip algorithm. This is because the MergeSkip al-gorithm requires to scan w  X  q + 1 inverted lists.
On another dimension, we enlarge the matching thresh-old  X  which determines the correlations of patterns and find that (Figures 2(c) and 3(c)) the computational cost of the 4 approaches increases slightly with the enlargement of  X  . Meanwhile, the pruning power of filtering and refining algo-rithms drops slightly, which is reasonable.
By varying the gram size q , we find that (Figures 2(d) and 3(d)) the best pruning power is achieved when q =2. As a result, the four alternative solutions achieve their best running performance when q = 2. This is reasonable be-cause according to Lemma 1, the larger the q ,thelessthe minimal number o f common grams t required for candidate correlated streams, and the looser the bounds derived from Lemma 1. That explains why the pruning power of q =2 is slightly better than that of q =3. However,when q =1, the pruning power is the worst. This is because the direc-tion information of trajectories is lost when q =1. Italso explains that many false positive candidates are generated by filtering algorithms when q = 1. Based on this study, we choose q = 2 as the default value of q in other experiments. (c) query thresholds
To the best of our knowledge, this is the first work on monitoring the correlations of discrete streams where both the tracked streams and the tracking streams evolve. We proposed two algorithms (CC and IR) to achieve efficiency for monitoring correlated streams. The experimental stud-ies show that based on the tight bound derived from the q -grams, the CC algorithm can effectively filter most of the un-correlated streams. In the refining phase, we propose techniques that are able to effectively postpone the expen-sive subsequence matching calls. The experimental results demonstrate the advantages of the proposed algorithms. This work is partially supported by NSFC under the grant No. 61003085, and HGJ PROJECT 2010ZX01042-002-002-03.
