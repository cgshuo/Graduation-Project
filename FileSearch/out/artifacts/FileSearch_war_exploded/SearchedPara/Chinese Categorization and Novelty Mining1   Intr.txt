 The overabundance of information leads to the proliferation of useless and redun-dant content. Novelty mining (NM) is able to detect useful and novel information from a chronologically ordered list of relevant documents or sentences. Although techniques such as dimensionality reduction [15,18], probabilistic models [16,17], and classification [12] can be used to reduce the data size, novelty mining tech-niques are preferred since they allow users to quickly get useful information by filtering away the redundant content.

The process of novelty mining consists of three main steps, (i) preprocessing, (ii) categorization, and (iii) novelty detection. This paper focuses on all three steps of novelty mining, which has rarel y been explored. In the first step, text sentences are preprocessed by removin g stop words, stemming words to their root form, and tagging the Parts-of-Speech (POS). In the second step, each in-coming sentence is classified into its relevant topic bin. In the final step, novelty detection searches through the time seq uence of sentences and retrieves only those with  X  X ovel X  information. This paper examines the link between catego-rization and novelty mining. In this tas k, we need to identify all novel Chinese text given groups of relevant sentences. Moreover, we also discuss the sentence categorization and novelty mining performance based on the retrieval results.
The main contributions of this work are the investigation of the preprocessing techniques for detecting novel Chinese t ext, the discussion of the POS filtering rule for selecting words to represent a se ntence, several experiments to compare the novelty mining performance between Chinese and English, the discovery that the novelty mining performance on Chinese can be as good as that on English if we can increase the preprocessing preci sion on Chinese text, the application of a mixed novelty metric that can effectively improves Chinese novelty min-ing performance, and a set of new novelty mining evaluation measures which can facilitate users to objectively evaluate the novelty mining results: Novelty-Precision, Novelty-Recall, Novelty-F Score, and Sensitivity.

The rest of this paper is organized as follows. The first section gives a brief overview of related work on detecting novel documents and sentences. The next section introduces the details of prepro cessing steps for English and Chinese. Next, we describe the categorization al gorithm and the mixed metric technique, which is applied in Chinese novelty mining. Traditional evaluation measures are described and new novelty evaluation measures for novelty mining are then pro-posed. Next, the experimental results are reported on the effect of preprocessing rules on Chinese novelty mining, Chinese novelty mining using mixed metric, categorization in English and Chinese, and novelty mining based on categoriza-tion using the old and newly proposed evaluation measures. The final section summarizes the research contributions and findings. Traditional sentence categorization methods use queries from topic information to evaluate similarity between an incoming sentence and the topic [1]. Then, each sentence is placed into its categor y according to the similarity. However, using queries from the topic information cannot guarantee satisfactory results since these queries can only provide some limited information. Later works have emphasized on how to expand the query so as to optimize the retrieval results [2]. The initial query, which is usually short, can be expanded based on the explicit user feedback or implicit pseudo-feedback in the target collections and the external resources, suc h as Wikipedia, search engines, etc. [2] Moreover, ma-chine learning algorithms have been applied to sentence categorization that first transform sentences, which typically are strings of characters, into a representa-tion suitable for the learning algorithms. Then, different classifiers are chosen to categorize the sentences to their relevant topic.
 Initial studies of novelty mining focus ed on the detection of novel documents. A document which is very similar to any of its history documents is regarded as a redundant document. To serve users better, novel information at the sentence level can be further highlighted. There fore, later studies fo cused on detecting novel sentences, such as those reported in TREC Novelty Tracks [11], which compared various novelty metrics [19,21], and integrated different natural lan-guage techniques [7,14,20,22].

Studies for novelty mining have been conducted on the English and Malay languages [4,6,8,24]. Novelty mining studies on the Chinese language have been performedontopicdetectionandtracking , which identifies and collects relevant stories on certain topics fr om a stream of information [25]. However, to the best of our knowledge, few studies have been reported on entire process of Chinese novelty mining, from preprocessing and categorization to the actual detection of novel information, which is the focus of this paper. 3.1 English English preprocessing first removes all stop words, such as conjunctions, prepo-sitions, and articles. After removing stop words, word stemming is performed, which reduces the inflected words to their primitive root forms. 3.2 Chinese C hinese preprocessing first needs to perfor m lexical analysis since there is n o o bvious boundary between Chinese words. Chinese word seg m entation is a ver y c hallenging proble m because of the di ffi culties in defining what constitutes a C hinese word [3]. Further m ore, there are no white spaces between Chinese word s o r expressions and there are m any a m biguities in the Chinese language, suc h a s:  X   X ( m eans  X  m ainboard and server X  in English) m ight be  X  / /  X ( m eans  X  m ainboard/and/server X  in English) or  X  / / /  X  ( m eans  X  m ainboard/ ki m ono/ task/ utensil X  in English). This a m biguity is a grea t c hallenge for Chinese word seg m entation. Moreover, since there are no obviou s d erived words in Chinese, word ste mm in g cannot be perfor m ed.

To reduce the noise from Chinese word segmentation and obtain a better word list for a sentence, we first apply word s egmentation on the Chinese text and then utilize Part-of-Speech (POS) taggi ng to select the meaningful candidate words. We used ICTCLAS for word segmentation and POS tagging because it achieves a higher precision than other Chinese POS tagging softwares [23].
Two different rules were used to select the candidate words of a sentence.  X  Rule1 : Non-meaningful words were removed, such as pronouns ( X  X  X  in the  X  Rule2 : Fewer types of words were selected to represent a sentence, such as  X  X here is a picture on the wall X . After POS filtering using Rule1, followin g words are used:  X  ( X  X  X ), ( X  X  X ), ( X  X  X ), ( X  m  X  m easure word), ( X  X  X  quanti-fier), ( X  X  X ) X . After POS filtering using Rule2, following words re m ain:  X  ( X  X  X ), ( X  X  X ), ( X  X  X ), ( X  X  X ) X . By using Rule2, we can re m ove m ore uni m portant wo r ds . From the output of the preprocessing steps on English and Chinese languages, we obtain bags of English and Chinese words. The corresponding term sen-tence matrix (TSM) can be c onstructed by counting the term frequency (TF) of each word. Therefore, each sentence can be conveniently represented by a vector where the TF value of each word is considered as one feature. Retrieving rel-evant sentences is traditionally based on computing the similarity between the representations of the topic and the sentences. The famous Rocchio algorithm [10] is adopted to categorize the sentences to their topics.

The Rocchio algorithm is popular for two reasons. First, it is computationally efficient for online learnin g. Secondly, compared to many other algorithms, it works well empirically, especially at the beginning stage of adaptive filtering where the number of training examples is very small. From the output of preprocessing, a bag of words is obtained, from which the cor-responding term-sentence matrix (TSM) can be constructed by counting the term frequency (TF) of each word. The novelty mining system compares the incoming sentence to its history sentences in this vector space. Since the novelty mining process is the same for English and Chinese, a novelty mining system designed for English can also be applied to Chinese.

The novelty of a sentence can be quantitatively measured by a novelty metric and represented by a novelty score N . The final decision on whether a sentence is novel depends on whether the novelty score falls above a threshold. The sentence that is predicted as  X  X ovel X  will be placed into the history list of sentences. 5.1 Mixed Metric on Chinese Novelty Mining The effect of sentence ordering can divide novelty metrics into two types: sym-metric and asymmetric [21], as summarized in Table 1. In order to leverage the strengths of symmetric metrics and as ymmetric metrics, we utilize a new tech-nique for measuring the novelty by a mixture of both types of novelty metrics [13]. The goal of the mixed metric is to integrate the merits of both types of metrics and hence generalize better over different topics. Two major issues for constructing a mixed metric are (i) solving the scaling problem to ensure different component metrics compar able and consistent and (ii) combining the strategy that defines the way of fusing the outputs from different component metrics. By normalizing the metrics, novelty scores from all novelty metrics range from 0 (i.e. redundant) to 1 (i.e. totally novel). Therefore, the metrics are both com-parable and consistent because they have the same range of values. For the combining strategy, we adopt a new tec hnique of measuring the novelty score N ( s t ) of the current sentence s t , by combining two types of metrics, as shown in Equation (1).
 where N sym is the novelty score using the symmetric metric, N asym is the novelty score using the asymmetric metric, and  X  is the combining parameter ranging from 0 to 1. The larger the value of  X  , the heavier the weight for the symmetric metrics.

The new word count novelty metric is a popular asymmetric metric, which was proposed for sentence-level novelty mining [1]. The idea of the new word count novelty metric is to assign the incoming sentence the count of the new words that have not appeared in its his tory sentences, as defined in Equation (2). where W ( s i ) is the set of words in the sentence s i . The values of the new word count novelty metric for an incoming sentence are non-negative integers such as 0 , 1 , 2, etc. To normalize the values of the novelty scores into the range of 0 to 1, the new word count novelty metric ca n be normalized by the total number of words in the incoming sentence s t as below.
 where the denominator | W ( d t ) | is the word count of d t . This normalized metric, N newW ord , has the range of values from 0 (i.e. no new word) to 1 (i.e. 100% new words).

In the following experiments using mixed metric,  X  is set 0.75. We chose cosine metrics as the symmetric metric and new word count defined in Equation (2) as the asymmetric metric, and the term weighting function as TF .
 5.2 Evaluation Measures Precision ( P ), recall ( R ), F Score ( F ) and precision-recall ( PR ) curves are used to evaluate the performance for novelty mining [1]. The larger the area under the PR curve, the better the algorithm. We drew the standard F Score contours [11], which indicate the F Score values when setting precision and recall from 0 to 1 with a step of 0.1. These contours can facilitate us to compare F Scores along the PR curves.

Based on all the topics X  P and R , the average P and average R can be obtained by calculating the arithmetic mean of these scores over all topics. Then, the average F Score ( F ) is obtained by the harmonic average of the average P and average R . 5.3 Novelty Evaluation Measures Although Precision, Recall, and F-Score can measure th e novelty mining perfor-mance well when sentences are correctly categorized, if there are errors in the categorization, the measures cannot obj ectively measure the novelty mining per-formance. In order to objectively measu re the novelty mining performance, we propose a set of new evaluation measures called Novelty Precision (N-Precision), Novelty Recall (N-Recall) and Novelty F S core(N-F Score). They are calculated only on correctly categorized sentences by our novelty mining system instead of all task relevant sentences. We remov e the incorrectly categorized sentences before our novelty mining evaluation.
 where NR + , NR  X  , NN + , NN  X  correspond to the number of sentences that fall into each category (see Table 2).

Our N-precision, N-recall and N-F Score do not consider the novelty mining performance of the sentences that are wrongly categorized to one topic. More-over, in order to better measure the novelty mining result of this part, we bring forward a new measure called Sensitivity (defined in Equation 7), which indi-cates whether the novelty mining system is sensitive to the irrelevant sentences. If sensitivity is high, most wrongly categorized (irrelevant) sentences are pre-dicted as novel, which will produce noise that prevent readers from finding the true novel information.
 where IC means the number of sentences that ar e incorrectly categorized by nov-elty mining system. N means the number of the wrongly categorized sentences that are predicted as novel by our system. 6.1 Dataset The public dataset from TREC Novelty Track 2004 [11] is selected as our experi-mental dataset for sentence-level novelty mining. The TREC 2004 Novelty Track data is developed from AQUAINT collect ion. Both relevant and novel sentences are selected by TREC X  X  assessors.

Since the dataset that we used is originally in English, we first translated the data into Chinese. During this proce ss, we investigated issues on machine translation vs. manually corrected translation. After comparing the results of novelty mining on the machine translation sentences and the humanly corrected translation sentences individually, we found that there is only a slight difference ( &lt; 2%) in the precision and F Score. This indicated that machine translation was sufficient for Chinese novelty mining. 6.2 Effect of Preprocessing Rules on Chinese Novelty Mining In the first experimental study, the focus was on novelty mining rather than relevant sentences categorization. Theref ore, our first experiments started with all given relevant Chinese text, from which the novel text should be identified.
For the Chinese dataset, we first segmented the sentences into words and then performed POS filtering to acquire the candidate words for the space vector. Based on the vectors of Chinese text, w e calculated the similarities between sentences and predicted the novelty for e ach sentence in the Chinese and English datasets. An incoming Chinese/English sentence will be compared with all the system-delivered 1000 novel sentences. We used threshold values between 0.05 and 0.95 with an equal step of 0.10. Then, we evaluated the Chinese/English novel text detection performance by setti ng a series of novelty score thresholds.
We adopted two different rules to select the candidate words to represent one sentence and investigated the POS filtering influence on detecting the novel Chinese text. Rule1 selects only some non-meaningful words including pronouns, auxiliary words, tone words, conjunctions, prepositions, and punctuation words, and Rule2 selects fewer kinds of words to represent a sentence.

Based on our experiments, we learn that the Chinese novelty mining per-formance is better when choosing the stricter rule (Rule2). Thus, POS filter-ing is necessary for Chinese because just removing some non-meaningful words (like stop words) may not be sufficient. POS filtering removes the less mean-ingful words so that each vector can be be tter represented. Rule2, which keeps only nouns, verbs, adjectives and adverbs, produces better results for novelty mining. Therefore, the remaining experiments used Rule2 for preprocessing the Chinese text. 6.3 Chinese Novelty Mining Using Mixed Metric In this section, we compar e the Chinese novelty mining performance after ap-plying mixed metric at the sentence level. Novelty mining using cosine similarity and term weighting function is TF is compared to results using mixed metric, which blends the cosine similarity together with new word count. When setting novelty threshold from 0.05 to 0.95 with a step of 0.1, we can draw the PR curves for sentence-level novelty mining. Figure 1 shows the novelty mining results using mixed metrics at the sentence-level.

From Figure 1, we learn that the Chinese novelty mining performance im-proves after applying mixed metric becaus e it effectively utilizes the strengths of both the symmetric and asymmetric metric. 6.4 Categorization in English and Chinese We also conducted experiments to compare the categorization performance on Chinese with that of English on TREC 2004 Novelty Track. The topic infor-mation from TREC 2004 Novelty Track data is extracted by title, description and narrative. We used topic title and topic description to construct the initial query. Each sentence will be compared with the queries from each topic. When the relevance score of a sentence is greate r than the categorization threshold, it is categorized as a relevant sentence to this topic.
 From our experiments, we observe that the categorization performance using Rocchio on Chinese is lower than that on English. This may be because of the influence of the higher preprocessing error rate on the results of Chinese cate-gorization. Li [5] also mentioned that the results of Chinese text categorization for small categories were much worse than those for English. Reducing the noise in feature vectors of the Chinese text, which needs a better preprocessing of Chinese text, may lea d to better results. 6.5 Novelty Mining Based on Categorization Based on the categorization results, we p erformed sentence novelty mining using our new evaluation measures of Novelty-Precision, Novelty-Recall, and Novelty-F Score. We chose the categorization results when the categorization threshold  X  =0.3. Then, we compare the novelty mining performance on Chinese and En-glish. We use mixed metrics and TFISF term weighting function.

Table 3 and Table 4 show the novelty mining performance using the old eval-uation measure and our new proposed measure on English and Chinese respec-tively. From Table 3 and Table 4, we learn that N-Precision is nearer to the precision of novelty mining on both English and Chinese when the sentences are perfectly categorized. In addition, sensi tivity can explain the reasons why there is a big difference between these two groups of results because most wrongly categorized sentences are labeled as nove l by our system. It is noticed that our novelty mining system is sensitive to the irrelevant sentences (Sensitivity  X  70%) and is more sensitive to the irrelevant se ntences on Chinese than that on English, which is consistent with the results.

Figure 2 shows the sentence-level novelty mining NPRF curves on Chinese and English based on the categorization results. The novelty score thresholds were chosen between 0 and 1 with a step of 0.10.

Figure 2, it is noticed that the novelty mining performance on the categoriza-tion results varies in Chinese and English. Chinese cannot achieve as same as performance as that on English because the novelty mining performance on the categorization results is not good is beca use not all the relevant sentences are correctly categorized. The assessors judge the novelty of each sentence only on the correct relevant sentences. Therefore , if the categorization of each sentence is incorrect, the following novelty mining performance will be badly influenced. This paper studied the entire process of preprocessing, categorization and novelty mining for detecting novel Chinese text, which were insufficiently addressed in previous studies. We described the Chinese preprocessing steps when choosing different Part-of-Speech (POS) filtering rules. We compared the novelty mining performance between Chinese and English and found that the novelty mining performance on Chinese can be as good as that on English by increasing the preprocessing precision on Chinese text.
Then we applied a mixed novelty metric that effectively improved the Chinese novelty mining performance at the sente nce level. Next, we compared the per-formance of categorization in English and Chinese, and found that Chinese cat-egorization was influenced by the noise in preprocessing. Finally, we discuss the categorization and the novelty mining performance based on retrieval results. In order to objectively evaluate the novelt y mining performance, we proposed a set of new novelty mining evaluation measur es, Novelty-Precision, Novelty-Recall, Novelty-F Score, and Sensitivity. The new evaluation measures can more fairly assess how the performance of novelty mining is influenced by the categorization results.

