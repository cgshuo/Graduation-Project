 The process of extracting useful knowledge from large datasets has become one of the most pressing problems in today X  X  so-ciety. The problem spans entire sectors, from scientists to in-telligence analysts and web users, all of whom are constantly struggling to keep up with the larger and larger amounts of content published every day. With this much data, it is often easy to miss the big picture.

In this paper, we investigate methods for automatically connecting the dots  X  providing a structured, easy way to navigate within a new topic and discover hidden connec-tions. We focus on the news domain: given two news arti-cles, our system automatically finds a coherent chain link-ing them together. For example, it can recover the chain of events starting with the decline of home prices (January 2007), and ending with the ongoing health-care debate.
We formalize the characteristics of a good chain and pro-vide an efficient algorithm (with theoretical guarantees) to connect two fixed endpoints. We incorporate user feedback into our framework, allowing the stories to be refined and personalized. Finally, we evaluate our algorithm over real news data. Our user studies demonstrate the algorithm X  X  effectiveness in helping users understanding the news. Categories and Subject Descriptors: I.2.6 [Artificial Intelligence] : Learning; G.3 [Probability and Statis-tics] General Terms: Algorithms, Experimentation  X  X an X  X  Grasp Credit Crisis? Join the Club X , stated David Leonhardt X  X  article in the New York Times. Credit crisis had been going on for seven months by that time, and had been extensively covered by every major media outlet throughout the world. Yet many people felt as if they did not understand what it was about.

Paradoxically, the extensive media coverage might have been a part of the problem. This is another instance of the information overload problem, long recognized in the computing industry. Users are constantly struggling to keep up with the larger and larger amounts of content that is being published every day; with this much data, it is often easy to miss the big picture.

For this reason, there is an increasing need for techniques to present data in a meaningful and effective manner. In this paper, we investigate methods for automatically connecting the dots  X  providing a structured, easy way to uncover hid-den connections between two pieces of information. We be-lieve that the ability to connect dots and form a logical, coherent story lies at the basis of understanding a topic.
We focus on the news domain: given two news articles, our system automatically finds a coherent story (chain of articles) linking them together. For example, imagine a user who is interested in the financial crisis and its effect on the health-care reform. The user vaguely recalls that the finan-cial crisis is related to the decline of home prices in 2007. The user would then choose representative articles for those two topics and feed them to our system. An output chain may look like this (parenthesized text not part of output):
The chain mentions some of the key events connecting the mortgage crisis to healthcare, including the bailout plan. Most importantly, the chain should be coherent : after read-ing it, the user should gain a better understanding of the progression of the story.

To the best of our knowledge, the problem of connecting the dots is novel. Previous research (e.g., [19, 13, 18, 17, 4, 6]) focused on organizing news articles into hierarchies or graphs, but did not address the notion of output coherence.
Our main contributions are Our methods are also directly applicable to many other do-mains. Email, research papers, and military intelligence analysis are but a few of the domains in which it would be immensely useful to discover, extract, and automatically connect the dots.
Our goal is to find a good path between two articles, s and t . A natural thing to do would be to construct a graph over the articles and find the shortest s -t path. Since there are no edges between articles, we will have to add them ourselves, e.g., by linking similar articles together.

However, this simple method does not necessarily yield a good chain. Suppose we try to find a coherent chain of events between Clinton X  X  alleged affair and the 2000 election Florida recount. We pick two representative documents, and find a shortest path between them. The result is shown on Figure 1 (left). This chain of stories is rather erratic, passing through the Microsoft trial, Palestinians, and Eu-ropean markets before returning to Clinton and American politics. Note that each transition, when examined out of context, is reasonable: for example, the first and the second articles are court-related. Those correlations are marked by dashed lines in Figure 1.

The problem seems to lie with the locality of shortest-path. Every two consecutive articles are related, but there is no global , coherent theme to the chain as a whole. Rather, shortest-path may exhibit stream-of-consciousness behaviour, linking s and t by a chain of free associations. A better chain is in Figure 1 (right). This chain tells the story of Clinton X  X  impeachment and acquittal, the effect on Al Gore X  X  cam-paign, and finally the elections and recount. In the following, we identify the properties which make this chain better.
Let us take a closer look at these two chains. Figure 1 (bottom) shows word activation patterns along both chains. Bars correspond to the appearance of a word in the articles depicted above them. For example, the word  X  X linton X  ap-peared throughout the whole right chain, but only at the beginning and the last two articles on the left. It is easy to spot the associative flow of the left chain in Figure 1. Words appear for very short stretches, often only in two neighbour-ing articles. Some words appear, then disappear for a long period and re-appear. Contrast this with the chain on the right, where the stretches are longer (some words, like Clin-ton and Lewinsky, appear almost everywhere), and transi-tions between documents are smoother. This observation motivates our definition of coherence in the next section.
Let D be a set of articles, and W a set of features (typically words or phrases). Each article is a subset of W . Given achain( d 1 , ..., d n )ofarticlesfrom D , we can estimate its coherence from its word activation patterns. One natural definition of coherence is Every time a word appears in two consecutive articles, we score a point. This objective has several attractive prop-erties; it encourages positioning similar documents next to each other and rewards long stretches of words. It is also very simple to compute. However, this objective suffers from serious drawbacks: Weak links: They say that a chain is only as strong as its A more reasonable objective would consider the minimal transition score instead of the sum.
 However, other drawbacks still exist.
 Missing words: Due to our noisy features, some words do Moreover, even if our features were not noisy, an indicator function is not informative enough for our needs.
 Importance: Some words are more important than others,
Combining Importance and Missing words , it becomes clear that we need more than a simple word-indicator. Rather, we need to take into consideration the influence of d i on d through the word w . We defer the formal definition of influ-ence to Section 2.3; intuitively, Influence ( d i ,d j | w ) is high if (1) the two documents are highly connected, and (2) w is important for the connectivity. Note that w does not have to appear in either of the documents. See Figure 2 for an example: the source document d 0 is d : Judge Lance Ito lifted his ban on live television coverage We calculated word-influence from d 0 to two other docu-ments, using methods explained in Section 2.3. The blue bars (in the back) represent word influence for document d 1 : O.J. Simpson X  X  defense lawyers told the judge they Figure 2: Word influence from an article about the OJ and the red bars (front) represent word influence for d 2 : Winning three consecutive Super Bowls would be a
First, note that the blue bars are generally higher. This means that d 1 is more relevant to the source article d 0 influential words for d 1 are mostly court-related, while d are sport-related (interestingly, the word  X  X efense X  is strong in both documents, for completely different reasons). Note that many of the influential words do not appear in either of the three articles, thereby solving the Missing words problem. With the new Influence notion, our objective can be re-defined as
Coherence ( d 1 , ..., d n ) = min This new objective, while better, still suffers from the prob-lem of Jitteriness .
 Jitteriness: the objective does not prevent jittery activa-
One way to cope with jitteriness is to only consider the longest continuous stretch of each word. This way, going back-and-forth between two topics provides no utility after the first topic switch. Remember, this stretch is not deter-mined by the actual appearance of the word along the chain; words may have a high influence in some transition even if they are missing from one (or both) of the articles. Rather, we define an activation pattern arbitrarily for each word, and compute our objective based on it. The coherence is then defined as the score under the best activation pattern:
Since influence is non-negative, the best solution is to ac-tivate all words everywhere. In order to emulate the be-haviour of the activation patterns in Figure 1, we constrain the possible activation patterns we consider: we limit the to-tal number of active words and the number of words that are active per transition. In order to avoid multiple stretches, we allow each word to be activated at most once.

Instead of using binary activations (words are either active or inactive), we propose a softer notion of continuous acti-vations. A word X  X  activation is in the range [0 , 1], signifying the degree to which it is active. This leads, quite naturally, to a formalization of the problem as a linear program.
The objective function (*) we defined in the previous sec-tion can be readily formalized as a linear program (LP). The LP is specified in Figure 3 and illustrated in Figure 4.
We are given a chain of n chronologically-ordered docu-ments, d 1 , ..., d n . First, we define variables describing word activation levels. We define a variable word-active w,i each document i = { 1 , ..., n  X  1 } and word w . Variable word-active w,i measures the activation level of w during the transition from d i to d i +1 . In Figure 4, those variables are represented by the height of the bars. When a word X  X  acti-vation level increases between two consecutive transactions ( d i  X  1  X  d i  X  d i +1 ),wesayitwas initialized in d i .Wede-fine another variable word-init w,i indicating the initialization level of w in d i . In the 0-1 case of Figure 1, word-init means that w is first activated in d i . In the continuous case of Figure 4, word-init w,i corresponds to the increase of height between two consecutive transitions.

The LP has three main parts. In Smoothness , we require that the activation patterns are smooth: First, constraint (1) requires that each word is activated at most once. Con-straint (2) links the initialization and activation variables together. It ensures that an active word w implies that ei-ther w was active in the previous transition, or it just got Figure 4: An illustration of the results of the linear pro-activated. We also set word-active w, 0 = 0 (3). Intuitively, it means that no words were active before the beginning of the chain.

In Activation Restrictions , we limit the total number of active words (4) and the number of words that can be ac-tive during a single transition (5). We use parameters kT otal and kT rans to control the number of active words. The in-terplay between those two parameters controls the length of activation segments. For example, if kT otal  X  kT rans  X  the LP might pick different words for every transition, and segments will be short.

Finally, we get to the Objective Function . For every edge i , we calculate its influence. Based on Equation (*), edge influence is the weighted influence of the active words:
Our goal is to maximize the influence of the weakest link: to do this, we define a variable minedge , which takes the minimum influence across all edges (6). Our objective is to maximize this variable.

As a sanity check, we tried the LP on real chains. Figure 5 (left) shows the best activation pattern found for a chain connecting 9/11 and Daniel Pearl X  X  murder (top five words). This pattern demonstrates some of the desired properties from Section 2: the word  X  X error X  is present throughout the whole chain, and there is a noticeable change of focus from Bin Laden to Pakistan and the kidnapped journalist. Figure 5 (right) shows activation  X  influence (rescaled). Notice that words with the same activation levels can have different levels of influence, and thus different effect on the score. Figure 5: Activation patterns found by our algorithm
The LP from the previous section required evaluation of influence ( d i ,d j | w )  X  the influence of d i on d j w.r.t. word w (refer again to Figure 2 for intuition). Several methods for measuring influence have been proposed. The vast majority of them focus on directed weighted graphs (e.g., the web, social networks, citations), where influence is assumed to propagate through the edges. Methods such as authority computation [8], random graph simulations [7] and random walks [3] all take advantage of the edge structure.
However, in our setting no edges are present. Adding ar-tificial edges (formally known as  X  X ink prediction X ) is a com-plicated and challenging task. In this section, we explore a different notion of influence; despite the fact that this notion is based on random walks, it requires no edges.
 First, we construct a bipartite directed graph, G =( V, E ). The vertices V = V D  X  V W correspond to documents and words. For every word w in document d , we add both edges ( w, d ) and ( d, w ). Refer to Figure 6 for a simple graph: there are four (square) documents, and four (circle) words. The leftmost article, about Clinton admitting Lewinsky liaison, is connected to the words  X  X linton X  and  X  X udge X .

Edge weights represent the strength of the correlation be-tween a document and a word. The tool we used for word extraction [1] assigns importance to each word; we use these weights for document-to-word edges. Alternatively, we can use TF-IDF weights. Since we interpret weights as random walk probabilities, we normalize them over all words in the document. For example, the rightmost article is mostly (.7) about Al Gore, and somewhat about  X  X udge X  (.2) and  X  X lin-ton X  (.1). The word-to-document weights are computed us-ing the same numbers, but normalized over the documents. The word  X  X ore X  can only be reached by a single document, so the edge weight is . 7 . 7 = 1. We now use this weighted graph to define influence between documents. Figure 6: A bipartite graph used to calculate influence.
As mentioned before, Influence ( d i ,d j | w ) should be high if the two documents are highly connected, and w plays an important role in this connection. Intuitively, if the two doc-uments are connected, a short random walk starting from d should reach d j frequently. We first compute the stationary distribution for random walks starting from d i . We control the expected length with a random restart probability, . The stationary distribution is the fraction of the time the walker spends on each node: where P ( v | u ) is the probability of reaching v from u . We now need to factor in the effect of w on these walks. We turn w into a sink node: let P w ( v | u ) be the same prob-ability distribution as P ( v | u ), except there is no way out Figure 7: An illustration of the results of the second of node w . Let  X  w i ( v ) be the stationary distribution for this new graph. If w was influencial, the stationary distribution of d j would decrease a lot: in Figure 6, without the word  X  X udge X  article 1 is no longer reachable from article 2.
The influence on d j w.r.t. w it defined as the difference between these two distributions,  X  i ( d j )  X   X  w i ( d j 2 shows an example of word-influence results calculated by this method. Refer to Section 2.2 for a detailed explanation.
In the previous sections we discussed a method to score a fixed chain. However, we are still left with the problem of finding a chain. One natural way is to use local search. In local search, we start from a candidate chain and iteratively move to a neighbour chain, chosen to maximize our scoring function. Local search is easy to understand and to imple-ment. However, it suffers from some known drawbacks, in particular a tendency get stuck in a local optimum. In this section we present a different approach. Instead of evalu-ating many chains along the local-search path, we jointly optimize over words and chains.
 Similarly to Section 2, we formulate this problem as an LP. The main difference is that neither the transitions nor the articles are known in advance; therefore, we have to consider all articles and edges as candidates for the chain.
Refer to Figure 7 for an illustration of the LP. The figure depicts three articles d 1 ,d 2 ,d 3 . Articles which are a part of the chain are indicated by a checkmark (in this example, d and d 3 ). In the LP, this is denoted by variables node-active (i.e., node-active 1 =1, node-active 2 = 0).

Figure 7 also shows all three possible edges between the articles (since edges are in chronological order, we ignore back-edges). In the figure, the edge from d 1 to d 3 is the only active one, marked by a solid line. (In fact, this is the only solution if d 2 is inactive but d 1 and d 3 are.) Variables next-node i,j indicate whether there is a transition from d d (i.e., next-node 1 , 3 = 1).

Words have activation levels associated with each docu-ment. Activation levels are depicted as two bars adjacent to each article, corresponding to words w 1 ,w 2 . For example, w 1 is high in d 1 and d 3 . Since d 2 is inactive, both words are inactive in it. Variables word-active w,i indicate the activa-tion level of word w in d i . Note that i previously referred to the i th transition in the chain; since we no longer know the chain in advance, we cannot do this here. Instead, the activation level per transition (bars adjacent to edges) is de-noted by variables transition-active w,i,j . The activation of w 2 along the edge is low, since it was low in d 1 .
Like before, the score of an active edge is the sum of acti-vations along transitions, weighted by influence: The LP has the same three main parts as before, plus an extra module guaranteeing that a valid chain is formed. Let us look at each of these modules in detail.

Chain Restrictions: This new module ensures a proper chain: starts with s , ends with t , has K nodes (ordered chronologically) and K  X  1 edges. In addition, every node (but s, t ) has exactly one incoming and one outgoing edge.
Smoothness: The smoothness module is very similar to the one in Figure 3, connecting the activation and initialization levels of words. The only difference is that we only do not know the transitions in advance.
Activation Restrictions: As before, we restrict the num-ber of active words per document and per chain. Moreover, if a word is active in a transition, the transition itself has to be active; the word X  X  activation level cannot exceed its activation level in the originating document.
Minmax Objective: As before, we define a variable minedge , which takes the minimum weight of all active edges. Our goal is to maximize this variable.
In order to extract the best chain from the LP optimum, we need a rounding procedure. Note that we only need to round the node-active i variables (or alternatively, next-node We now present a randomized rounding schema with proven guarantees:
First, we solve the LP. Let next-node  X  i,j be the value of next-node i,j in the optimal solution. The LP solution defines a fractional directed flow of one unit from s to t . We start from node s , and iteratively pick the next node of the chain. The next node is picked proportionally to the flow; in other words, if our current node is d i , the next node will be d that this process will stop at t . The ordering constraints ensure that it runs in polynomial time. It is equivalent to a decomposition of the flow into a collection of s -t paths, {
P i } , and picking a path proportional to its weight (flow). Claim 3.1. The expected length of a path is K .

Proof: E ( path length )= i weight i  X | P i | =
Theorem 3.2. Let the optimal value of the LP be V .The value of the rounded solution is at least (1  X  c ) V for c =
V ln( n/ X  ) with probability at least 1 n by the number of nodes with non-zero activation in the LP solution.
 Proof Sketch: Define |W| + 1 Bernoulli random variables for each edge ( i, j ) with probabilities 1  X  next-node  X  transition-active  X  w,i,j for each word w (stars denote the LP value). The edge weight is expected sum of the Bernoulli variables. We bound the probability that this weight is less than (1  X  c ) V using Chernoff bound. c was chosen so that the probability is at most  X / n 2 . Taking a union bound, we bound the probability that any edge is below (1  X  c ) V by  X  .
The joint LP from Section 3 has O ( |D| 2  X |W| ) variables, and therefore is not feasible for a large number of articles. Certainly, it cannot handle the number of news articles put out every day. In this section, we consider practical ways to speed up the computation.

Selecting an initial set of documents As mentioned, our approach may not be practical when the number of doc-uments is large. However, it can be profitably invoked on a carefully and efficiently selected subset of the documents. We consider ways to restrict the number of candidate arti-cles for the s -t chain.

Picking documents similar to s and t works well when s and t are close, but breaks down for complex chains. For example, impeachment is not an important word in s , t of Figure 1, yet we should include these articles in our candi-date subset. We propose to use the same bipartite graph from Section 2.3, run random walks starting from s and t , and pick the top-ranked articles. Since random walks start from s and t , we hope that documents which are frequently reached from both will be ranked high. The same idea may be used to restrict W , the set of words, as well.
We then solve the LP for the restricted set of articles. If the resulting chain is not strong enough, we can iteratively add articles to the set. We add articles from the time period corresponding to the weakest part of the chain, hoping to replace the weak links by stronger ones. This way, we obtain an anytime algorithm which generates a stream of chains, each one chosen from a larger set of candidate articles.
Speeding up influence calculation In Section 2.3, calculating influence required O ( |D| X |W| ) calculations of stationary distributions. We speed up the calculation by using only one set of random walks for all w . For each doc-ument d i we simulate random walks on the original graph. During each walk, we keep track of the word-nodes encoun-tered. When calculating Influence ( d i ,d j | w ), we only con-sider the number of times we reached d j without using w . Thus, we only need O ( |D| ) random walks. Note that the random walks are not independent anymore. However, the results are still exact, since we only need the expectations.
Evaluating the performance of information retrieval tasks often focuses on canonical labeled datasets (e.g., TREC com-petitions) amenable to the standard metrics of precision, recall and variants thereof. The standard methods do not seem to apply here, as they require labeled data, and we are not aware of any labeled dataset suitable for our task. As a result, we evaluated our methods by running them on real data and conducting user studies to capture the utility of our algorithms as they would be used in practice.
 We evaluate our algorithm on real news data from the New York Times and Reuters datasets (1995-2003). We prepro-cessed more than half a million articles. These articles cover a diverse set of topics, including world news and politics, economy, sports and entertainment.

We considered some of the major news stories of recent years: the OJ Simpson trial, the impeachment of Clinton, the Enron scandal, September 11th and the Afghanistan war. For each story, we selected an initial subset of 500 10 , 000 candidate articles, based on keyword-search. The size of the candidate subset depended on the search results. For example, there were a lot more articles mentioning Clin-ton than those mentioning Enron.

For each article, we extract named entities and noun phrases using Copernic Summarizer [1]. In addition, the NYT dataset includes important meta-data such as taxonomy and section. We remove infrequent named entities and non-informative noun phrases (e.g., common nouns such as  X  X ear X ).

Our goal was to construct chains representing the stories, and have users evaluate them. For each story, we chose several pairs of articles. We then tried finding stories linking each pair using the following techniques:
During each iteration, we solve the LP from Section 3. We exclude the article with the lowest activation score from the next iterations (setting node-active i = 0). We stop when exactly K of the node-active i variables are set to 1. Since at every iteration we remove one article, the process his is guaranteed to stop after |D| X  K + 1 iterations. In practice, it reaches a solution within a few iterations.
First, we presented 18 users with a pair of source and tar-get articles. We gauged their familiarity with those arti-cles, asking whether they believe they knew a coherent story linking them together (on a scale of 1 to 5). We showed the users pairs of chains connecting the two articles, generated by the above methods in a double-blind fashion. We asked the users to indicate In addition, we measured the effectiveness of the chains. We asked users to estimate how their answer to the famil-iarity question changed after reading each chain. Effec-tiveness is the fraction of the familiarity gap closed. For example, if the new familiarity is 5, this fraction is 1 (gap completely closed). If the familiarity did not change, the fraction is 0. This was meant to test whether users feel that the chain helped them gain better understanding of the big picture, which is, after all, our main goal.

Example output chains are shown in Figure 9. Figure 8 shows the results of our user-study. After analyzing the results, we identify two types of stories: simple and complex . Simple stories tend to focus around the same event, person or institution (e.g., the OJ Simpson trial/ the Enron story). Those stories can usually be summarized by a single query string. In complex stories, however, the source and target article are indirectly connected through one or more events (e.g., Lewinsky-impeachment-elections, September 11th-Afghanistan war-Daniel Pearl).

The left plot shows the effectiveness (closing the famil-iarity gap) for each of the methods. Underneath each story we display the average familiarity score before reading any chain (e.g., the Enron story is not well-known).

Our algorithm does better than the competitors on all sto-ries but Enron. The difference is especially pronounced for complex stories. In simple stories, such as Enron, it seems that the simple method of picking K evenly-spaced docu-ments from GNT was sufficient for most people. However, when the story could not be represented as a single query, the effectiveness of GNT decreased.

Surprisingly, GNT did a lot worse on the OJ story than on Enron (note that its score is lower despite the smaller gap). A closer examination revealed that there were a lot more stories about OJ, many of them esoteric at best, so picking random K documents tended to produce poor results (a book of a former juror made it to the best-selling list, etc). Furthermore, more of our users were familiar with the OJ story beforehand, so there was less room for improvement.
As expected, shortest path did badly. Event threading did somewhat better; however, for simple stories, sometimes the clusters were too big. In the Enron story, both s and t belonged to the same cluster, rendering the chain useless. Also, the fact that we pick a representative for each cluster at random might have hurt its performance.

The plot on the right shows the percentage of times each method was credited for relevance, coherence and non-redundancy. Simple stories are grouped on the left, complex  X  on the right. Users could credit one chain, both or neither. Therefore, the numbers do not sum to 100%. Our algorithm is amongst the best in all measures at a sta-tistically significant level. Most importantly, it achieves the best coherence scores (especially in the complex case). We discuss some of the interesting findings below.

Relevance and Redundancy: As expected, for all methods, relevance is good for simple stories but achieving low redundancy is harder. There is a tradeoff  X  redundancy is easy to avoid by picking random, possibly irrelevant arti-cles. Relevance is easy to achieve by picking articles similar to s or t , but then redundancy would be high.

Google News Timeline is doing well in terms of relevance for simple stories. However, the chains it generates tend to include somewhat insignificant articles, especially for com-plex stories. The clusters of Event Threading seem to reduce its redundancy, compared to shortest-path.

Coherence: Together with effectiveness ,thisisper-haps our most important metric. Our algorithm outper-forms the other methods, especially in the complex case. This indicates that the notion of coherence devised in this paper matches what the actual users perceive. Interest-ingly, event threading outperformed GNT for complex sto-ries. This is because the GNT keywords were based on s and t , and did not capture the intermediate events.
Thus far, we have defined a way to find chains connecting two endpoints. However, the user may not find the result-ing chain satisfactory. In information retrieval systems, the solution is often to let the users revise their queries; for a complex information need, users may need to modify their query many times. In this section, we propose to take ad-vantage of the structured nature of the chains, and explore more expressive forms of interaction. We explore two dif-ferent types of user feedback: refinement of a chain, and tailoring to user interests.
Refinement: When presenting a chain to a user, some of the links in the chain may not be obvious. Moreover, the user might be especially interested in a specific part of the chain. For example, a user not familiar with the details of the Lewinsky story might want to further expand the first link of Figure 1 (right). We provide the user with a mechanism to indicate areas in the chain which should be further refined; a refinement may consist of adding a new article, or replacing an article which seems out of place.
Since evaluating a single chain is quick, the refinment pro-cess is very efficient. Starting from the original chain, we try all possible replacement/insertion actions. We evaluate each chain (see Section 2), and return the best one.
 Figure 10: Chain refinement. The starred article was
In Figure 10, the starred article is the result of an inser-tion request. Adding the article strengthened the end of the chain, while maintaining the global theme.

Incorporate user interests: There can be many co-herent ways to connect s and t , especially when they are about similar topics. For example, consider the OJ Simp-son trial story. Suppose the user is interested in the racial aspects of the case, but our algorithm finds a chain focus-ing on the verdict. We provide a mechanism for the user to focus the chains around concepts they find important. In our case, the user may increase the importance of  X  X acial X  or  X  X lack X , and perhaps decrease the importance of  X  X erdict X .
In order to take user X  X  feedback into account, we augment our objective with importance weight  X  w for each word w :  X  w are initialized to 1. When a user likes a word, its im-portance is increased by a multiplicative factor. When they dislike a word, its weight is decreased by a (perhaps dif-ferent) factor. These factors were determined empirically, and may change over time (similar to online learning tech-niques). In order to avoid having to click many words, we use word co-occurrence information to distribute the effect amongst related words. E.g., when a user clicks on  X  X NA X , the words  X  X lood X  and  X  X vidence X  increase a little too.
Figure 11 shows an actual output of the system. The figure depicts four chains: for each, it shows activation levels for the most important words and a few selected articles. The top-left chain (before any interaction took place) focuses on the verdict. The other chains are derived from it by increasing the weight of  X  X lack X  (top right) or  X  X NA X  (bottom left). The bottom-right chain is the result of increasing the weight of  X  X NA X  twice. As can be seen, increasing the weight of a word causes the chain to change its focus. The  X  X lack X  chain focuses on racial issues, and the  X  X NA X  chains focus more and more on the testimony of the DNA expert.
 Another way to interpret user X  X  feedback is as a constraint . Under this interpretation, the user imposes constraints on Figure 11: A demonstration of our interactive compo-the accumulated influence of specific words in the chain. We do not describe this mechanism in detail; intuitively, if the user indicates that they want more of a word w , the resulting chain will demonstrate higher levels of influence for w , compared to the previous chain. The level of influence measures how much the chain is about w . Note that this is a property of the chain, and does not depend on the activation levels. By letting users indicate desired influece levels, they can change the focus of the chains.

Combining interaction types: The idea of personal word-preferences might also be useful for the refinement task. Suppose the user asked to replace an article d i ;if there are many articles similar to d i , local search is likely to return one of them. We can implement a mechanism similar to our work in [5] to find words which might be attributed for the user X  X  dislike of d i , and decrease their importance. This way, the replacement article will not be similar.
We conducted another user study to evaluate how well our algorithm personalizes the chains it selects in response to user feedback. We tested both aspects of feedback:
Refinement: We showed the user a chain, and asked them to perform a refinement operation (asking for inser-tion/replacement). We then returned two chains, obtained from the original chain by (1) our local search, (2) adding an article chosen randomly from a subset of candidate articles (Section 3.2), obeying chronological order. We asked the user to indicate which chain better fit their request. Users preferred the local-search chains 72% of the time.
User Interests: We showed users two chains  X  one ob-tained from the other by increasing the importance of 2-3 words. We then showed them a list of ten words containing the words whose importance we increased and other, ran-domly chosen words. We asked which words they would pick in order to obtain the second chain from the first. Our goal was to see if users can identify at least some of the words. Users identified at least one word 63 . 3% of the times.
To the best of our knowledge, the problem of connecting the dots is novel. There has been extensive work done on related topics, from narrative generation to identifying and tracking news events.

The narrative generation community [16, 14] has sought to explore the notion of narratives and the ways to model them. However, their task seems to be fundamentally differ-ent. Much of the work involves producing natural-language experiences for a user (e.g., a computer game), and focus on planning-like operators and inferences. In contrast, we do not try to generate any natural-language content, neither do we make up new plots. Our contribution lies in finding a good chain of documents within a given dataset. Never-theless, some of the work done on evaluating narratives [15] may be useful for our purposes.

For event tracking , some efforts have been made to classify news stories into broad categories using pattern matching and machine learning [11]. However, these methods assume the labels are known in advance, and thus are not applicable. Event detection [9, 19] deals with discovering new events, but does not attempt to string different events together.
In contrast, email threading [10] tries to discover connec-tions between related email messages. This is closer to the task we have in mind, but much easier, since email usually incorporates a strong structure of referenced messages.
In a work closest to ours, [13, 12] studied how to discover sub-clusters in a news event and structure them by their dependency, generating a graph structure. However, they do not address the notion of coherence at all; constructing a chain of coherent articles from the output graph is hard, as we have seen in the experimental section. In addition, it seems like the method is best-suited for simple news stories, i.e., stories that can be summarized in one or two keywords ( X  X sunami X , in [12]). It is not clear how well this method does for more complex stories.

Our work differs from most previous work in two other important aspects  X  expressing information needs and structured output and interaction . Often, users know precisely what they want, but it is not easy for them to distill this down into a few keywords. Our system X  X  input method (related articles) might facilitate this task. Our sys-tem X  X  output is interesting, too  X  instead of the common list of relevant documents, our output is more structured: a chronological chain of articles, and the flow of influences along it. Often, visually exploring a system X  X  results and in-teracting with it can reveal new and interesting phenomena.
In this paper we describe the problem of connecting the dots. Our goal is to help people fight information overload by providing a structured, easy way to navigate between top-ics. We explored different desired properties of a good story, formalized it as a linear program, and provided an efficient algorithm to connect two articles. Finally, we evaluated our algorithm over real news data via a user study, and demon-strate its effectiveness compared to other methods, such as Google News Timeline.

Our system is unique in terms of input and output, and incorporating feedback into it allows users to fully exploit its capabilities. In the future, we plan to explore richer forms of input and output, allowing for more complex tasks, e.g., creating a roadma p X  X setofint ersecting chains that covers a topic from several aspects.

In addition, we plan to explore the behaviour of our sys-tem under different query characteristics. For example, in our evaluation we considered news stories which were associ-ated with popular events. It would be interesting to test the approach would work for news articles which do not have as much coverage within the news corpus.

We believe that the system proposed in this paper may be a promising step in the battle against information overload. The ability to connect two pieces of information and form a logical, coherent story has applications in many areas. Per-haps most importantly, significant scientific discoveries can come from forming connections between different fields. We plan to extend our methods to scientific papers; we believe that tools to automatically connect the dots can be a great vehicle to enable new discoveries.

