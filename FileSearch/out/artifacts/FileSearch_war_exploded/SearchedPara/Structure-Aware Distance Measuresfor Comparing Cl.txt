 Many data are relational, including friendship graphs, communication networks and protein-protein interaction networks. An important type of analysis that is graph clustering, which involves grouping the vertices based on the similarity of their connectivity. Graph clusterings ar e used to discover communities with sim-ilar interests (for marketing) and disco vering the inherent structure of graphs. Despite the popularity of graph clustering, existing graph cluster comparison measures have focused on using membership based measures. To the best of the authors X  knowledge, there are no work th at evaluates if membership based com-parison measures are appropriate for comparing graph clusterings. This analysis is important, as comparison measures are often used for comparing algorithms [1][2], form the basis of consensus clustering [3] and tracking algorithms [4], and knowing which properties measures possess allows us to evaluate if a mea-sure is appropriate for a task, and if not, propose new ones that are. One of the important properties a measure should possess is the ability to be  X  X pa-tially X /structurally aware. In traditional clustering of points, it was found that clusterings could be similar in memberships, but their points are distributed very differently. This could lead to counter-intuitive situations where such clusterings were considered similar [5][6]. We show the same scenario occurs when compar-ing graph clusterings. Therefore, in this paper, we address the open problems of analysing and showing why membership comparison measures can be inade-quate for comparing graph clusterings and then proposing new measures that are aware of structural differences. We shortly illustrate why comparison measures should be structure aware, but we first introduce graph clustering. Clustering in Graphs  X  Community Detection and Blockmodelling: Two popu-lar approaches for graph clustering are community detection [7] and blockmod-elling [8]. These approaches are used in many important clustering applications [9][1][2][4], and hence we focus on the comparison of communities and blockmod-els in this paper. Community detectio n decomposes a graph into a community structure, where vertices from the sam e communities have many edges between themselves and vertices of different communities have few edges. Community structure has been found in many graphs, but it is only one of many alternatives for grouping vertices and possible graph structure (such as core-periphery). In contrast, an alternative approach is blockmodelling [8]. A blockmodel 1 partitions the set of vertices into groups (called positions ), where for any pair of positions, there are either many edges, or fe w edges, between the positions.

As an example of the difference between the two approaches, consider a re-ply graph between a group of experts a nd questioners in a question and an-swer (Q&amp;A) forum, illustrated in Figure 1. The vertices represent users, and the directed edges represent one user r eplying to another. If we use a popular community detection algorithm [7] to decompose the graph, all the vertices are incorrectly assigned into a single group, as its underlying structure is not of a community type, and no structure is discerned. If we use a blockmodelling decomposition, we obtain the correct decomposition into two positions, the ex-perts C 1 ( { Jan, Ann, Bob } ) and the questioners C 2 ( { May,Ed,Pat,Li } )(see Figure 1b, which illustrates the adjacency matrix rearranged according to the positions). The experts C 1 reply to questions from the questioners ( C 1 to C 2 ), the questioners C 2 have their questions answered by the experts ( C 1 to C 2 )and both groups seldom converse among themselves. The overall structure can be succinctly summarised by the image diagram in Figure 1c, which shows the po-sitions as vertices, and the position-to-position aggregated interactions as edges. As can be seen, this graph has a two position bipartite structure, which the blockmodelling decomposition can find but a community decomposition fails to discover. The similarity definition of blockmodelling actually includes the com-munity one, hence blockmodelling can be considered as a generalisation of com-munity detection and comparison measures that work with blockmodels would work with comparing communities as well. Therefore we focus on measures that compare blockmodels, since they can also compare communities.
 Comparing Communities and Blockmodels: As discussed earlier, almost all ex-isting literature compares blockmodels (and communities) based on their posi-tions and ignores any difference in the adjacency structure within positions and between positions. This can lead to unintuitive and undesirable behaviour. A blockmodel comparison measure should possess the three following properties, which we will introduce and motivate using two examples.

The first property is that the measure should be sensitive to adjacency dif-ferences in the blocks . Figures 2a (BM 11), 2b (BM 12) and 2c (BM 13) illus-trate example 1. The vertices in each bloc kmodel are ordered according to their positions, and the boundary between the positions in the adjacency matrix is illustrated with red dotted lines. This effectively divides the adjacency matrix into blocks , which represent the position to position interactions. The positional differences from BM 12 and BM 13 to BM 11 are the same. However, the dis-tribution of edges (frequency of edges a nd non-edges) are very different between BM 11 and BM 13 (there is one single dense block with all the edges in BM 11 (and BM 12), while the edges are distributed across the blocks more evenly in BM 13). Hence a measure should indicate BM 11 is more similar to BM 12 than to BM 13. Positional measures fail to achieve this.

The second property is that a measure should account for differences in the edge distributions across all blocks . In example 1, BM 11 and BM 12 have similar distributions across all blocks since their edges are concentrated in a block, while BM 13 is different because the edges are spread quite evenly across all blocks. We show that two existing comparison measu res for blockmodels fail this property.
The third property is that a measure should be sensitive to weighted edge distributions . Many graphs have weights on the vertices and edges. It might be possible to binarise the weights, but this throws away important comparison information. For example, if the graph in the blockmodels of Figures 2d to 2f (BM 21 to BM 23, dubbed example 2) were binarised, then BM 22 and 23 have exactly the same edge distribution differences from BM 21. But when the actual weights are taken into account (darker pixe ls in the figures represent larger valued weights), BM 22 will be correctly considered as more similar to BM 21, as most of the high-value edge weights in the top left block match, while in BM 23 these edges are evenly distributed among the four blocks.

These properties have important applications. For example in algorithm evalu-ation, the blockmodel output of the algorithms are compared to a gold standard. Imagine that the gold standard is BM 11 and two algorithms produced BM 12 and 13. Measures without these properties will incorrectly rank the two algo-rithms to be equally accurate since they have the same position differences to BM 11. In contrast, a measure that possess the first two properties will correctly rank the algorithm producing BM 12 as more accurate. Another application is in consensus blockmodelling, which finds a blockmodel that is the average of a set of blockmodels. If a measure does not possess the 3rd property and only considered position similarity, then the consensus blockmodel might have very different weight distribution to the other blockmodels and hence should not be considered as a consensus (e.g., BM 23 as a consensus of BM 21 and 22).
In summary, our contributions are: a) we propose three structural-based prop-erties that a blockmodel comparison mea sure should possess; b) we analyse exist-ing measures and show that they do not possess these properties; c) we propose new measures that satisfy these properties; and d) perform experiments on syn-thetic and real data to study the monotonicity of the new measures. In this section, we describe related wor k in three key areas: set comparison, spatially aware clustering comparison and subspace clustering comparison. Set Comparison: There has been extensive work in using set comparison for cluster comparison. Hence we discuss a f ew selected measures, and refer inter-ested readers to the excellent survey of [10]. The first class of measures in this area involves computing the agreement b etween two clusterings in terms of how many pairs of vertices are i n the same and different clusters. Examples include the Rand and Jaccard indices [10]. The s econd class of measures are based on set matching and information theory, where the two clusterings are compared as two sets of sets. Popular examples include Normalised and Adjusted Mutual Information (NMI, AMI) [11]. As demonstrated in Section 1, these set-based measures do not take into account any adjacency differences between the block-models, resulting in some counter-intuitive comparison behaviour.
 Spatially Aware Clustering Comparison: In [12], Zhou et al. proposed a measure that compares clusters based on membership and the distances between their centroids. In [5], Bae et al. comput ed the density of clusters using a grid, and then used the cosine similarity measure to compare the cluster distributions. Coen et al. [6] took a similar approach but used a transportation distance to com-pute the distances between clusters and between clusterings. All these measures depend on a notion of a distance between points (between clusters of the two clusterings). In blockmodel and community comparison, there are positions of vertices and the edges between them, but no notion of a distance between ver-tices across two blockmodels and hence ex isting spatial-aware measures cannot be applied for blockmodel comparison.
 Subspace Clustering Comparison: In subspace clustering, the aim is to find a group of objects that are close in a subset of the feature space. In [13], Patrikainen and Meila proposed the first subspace va lidation measure that considered both the similarities in the object clusters and in the subspaces that the clusters occupied. They treated subspace cluste rs as sets of (object, feature) pairs, and then used set-based validation measures for comparing subspace clusters. When extended to compare the sets of (vertex,ver tex) pairs between blockmodels, these measures are equivalent to comparing the positions (proof omitted due to lack of space), and hence have the same issues as the set comparison measures.
In summary, there has been much related work in cluster comparison, but none that address the unique problem of comparing blockmodels and communities. What is needed is a measure that is sens itive to differences in the adjacency structure as well as working in the relation spaces of graphs. In this section, we summarise the key ideas of blockmodelling (see [14][8] for more detail). A graph G ( V,E ) consists of a set of vertices V and a set of edges E , where E  X  X  0 , 1 } | V | X | V | for unweighted graphs and E  X  X  | V | X | V | for weighted graphs 2 . The edge relation can be represented by an adjacency matrix A whose rows and columns are indexed by the vertices of G .

We use the Q&amp;A example of Figure 1 to illustrate the notation. A blockmodel partitions a set of vertices into a set of positions C = { C 1 ,C 2 ,..., C k } .We denote the number of positions in C by k . C can be alternatively specified by  X  ( . ), a mapping function from vertices to the set of positions (i.e.,  X  : V  X  X  ). Ablock A r , c is a submatrix of A , with the rows and columns drawn from C r and C c respectively, C r ,C c  X  X  , e.g., A 1 , 1 defines the upper left submatrix in Figure 1b. Let  X  r,c denote the random variable representing the probability 1) = 2 9 . This representation allow us to model both weighted and unweighted graphs. For simplicity, we introduce  X  r,c = p (  X  r,c = 1) for unweighed graphs. We define M as the blockmodel image matrix that models inter-position densities, M : C X C X  [0 , 1], M r,c =  X  r,c . For the rest of the paper, we use a superscript notation to distinguish two different instances of a variable (e.g., G (1) and G (2) ). trix version is C ( l ) ) and its image matrix M ( l ) . The (unweighted) blockmod-elling problem can be considered as finding a blockmodel approximation of A C the distance between two blockmodels B (1) and B (2) is defined as d ( B (1) , B (2) ). 3.1 Desired Properties of Comparison Measures In this section, we formalise the properties that a blockmodel comparison mea-sure should possess (as discussed in Section 1). These properties allow us to formally evaluate the measures in the next section.

The following properties assume that there are three blockmodels with ap-can be considered as measuring the sensitivity to differences in the structure (approximation) of the blockmodels.
 P1: Approximation sensitivity: Given an unweighted graph and three P2: Block edge distribution sensitivity: Given d mKL (  X  A (2) ,  X  A (1) ) &lt; P3: Weight sensitivity: Given a weighted graph and three blockmodels 4 ,amea-In addition, we evaluate the important monotonicity property of the measures. Basically, we desire measures that increase in value as the compared blockmodels become more different. We measure  X  X  ore different X  by the minimum number of position changes to transform one blockmodel to another. In this section, we describe existing measures, propose new blockmodel com-parison approaches, and analyse their properties. Existing work for comparing blockmodels falls into two categories: positional and reconstruction measures. Positional measures compare the sets of positions associated with each block-model [10]. Reconstruction measures compare the blockmodel approximation provide details on two existing reconstruction blockmodel measures. 4.1 Edge and Block Reconstruction Distances The edge and block reconstruction distances were proposed in [4] and [8] re-spectively. The edge reconstruction distance [8] measures the difference in the expected edge probabilities across all edges (recall that V 1 = V 2 ):
The block reconstruction distance [4] measures the difference in block densities over all pairs of blocks, weighted by the overlap of the positions:
The two measures in fact differ only by a factor of 1 n 2 (we prove this new result in Theorem 1). It is easier to understand and propose new measures based on the edge than the block reconstruction distance. But in terms of computational complexity, it takes O ( k 2 ) to compute the block reconstruction distance while O ( n 2 ) for the edge distance, hence it is more efficient to compute the block distance. Therefore Theorem 1 permits us to use whichever measure that is more convenient for the task at hand. Proof. The proof involves arithmetric manipulation. We detail the proof in a supplementary 5 paper due to space limitations.

Both these reconstruction distances possess the approximation sensitivity property (P1) but fail the block edge distribution property (P2). Reconsider the example of Figures 2a to 2c. d RB ( BM 11 ,BM 12) = 0 . 21 and d RB ( BM 11 ,BM 13) =0 . 18. This means that the reconstruction distances incorrectly ranks BM 13 to be closer to BM 11 than BM 12. To explain why, we first state that the Earth Movers Distance (EMD) can be considered as a generalisation of the re-construction measures (see Section 4.3). The EMD finds the minimum amount of mass to move from one PMF (of a block) to another. What this means is that the reconstruction distance considers the cost to move a unit of mass the same, whether the source PMF is a unimodal distribution or uniformly distributed one. Hence the reconstruction distances only consider the number of total units of mass moved and do not consider the differences in distribution of edge densities across all the blocks, leading them to fail property P2. 4.2 KL Reconstruction Measure We propose to use the KL divergence [17] to compare the block densities (PMFs). Although it is similar in form to the P2 property definition, the proposed measure is in the form of the reconstruction distance and the KL divergence is a natural approach to measure distribution differences. It is defined as: Definition 1. KL Reconstruction : d
The KL reconstruction measure can be considered as using the edge distribu-tions (across the blocks) in B (2) to encode the edge distributions in B (1) .This means it is sensitive to differences in the distribution of the block densities, and it gives the correct ranking f or example 1 (see Section 5).

The KL divergence is asymmetric, hence d RKL ( . ) is also asymmetric, and can handle weighted graphs. The Jeffrey and Jenson-Shannon divergences [17] are symmetric versions of the KL divergence, and are included for comparison. Unfortunately they fail the block edge distribution property (see Section 5). 4.3 Weighted Block and Edge Reconstruction In this section, we show how the edge/block reconstruction measures can be generalised to weighted graphs. We compare the blockmodels of weighted graphs by comparing the PMFs of the blocks. We desire a measure that can compare multi-valued PMFs and consider the difference in the actual weight values. One such measure is the Earth Mover X  X  distance (EMD) [18], which also reduces to the reconstruction measures for unweighted graphs (see Theorem 2).
 Definition 2. EMD Reconstruction Measure d d ( u,w )= | u  X  w | .

We now show that the EMD reconstruction measure is in fact a generalisation of the reconstruction measures.
 Theorem 2. When we are comparing unweighted graphs, Proof. The proof involves arithmetric manipulation and reasoning on the con-straints. Due to space limitations, please refer to supplementary for details.
Theorem 2 is a useful result, as it helps to explain why the block reconstruction distance fail property P2. In addition, it means EMD reconstruction distance can be used in place of block distance, since Theorem 2 tells us that the EMD distance is a generalisation of block one for unweighted graphs. At the same time, the EMD distance satisfies property P3 while the block one does not. In this section, we evaluate the measures using the proposed properties and empirically demonstrate their monotonicity (since it is difficult to prove this an-alytically). We also show how each of the measures perform in the examples from Section 1. In the experiments, we comp are NMI, a popular and representative example of the positional measures, against the block (RB), EMD (REMD), KL (RKL), Jeffrey (RsKL) and JS (RJS) reconstruction distances. 5.1 Evaluation of the Examples Table 1 shows the comparison results between the original blockmodel (BM *1) against the two other blockmodels (BM *2 and *3) of the examples in Figure 2. As can be seen, NMI cannot dis tinguish between the three blockmodels across all the datasets. RB fails to correctly rank the blockmodels of example 1, and fails to distinguish the weighted blockmod els of example 2. As expected, REMD has the same values as RB for example 1, but correctly classifies the relative ordering of example 2. RsKL and RJS fail example 1. RKL correctly distinguishes the ordered example 1, but like the other distributional measures (RsKL and RJS) cannot distinguish the blockmodels of example 2.
 5.2 Monotonicity Analysis To evaluate monotonicity, we vary the membership of the positions for several real datasets. Each position change corresponds to a change in the membership of a vertex, and we ensure a vertex can only change membership once in each simulation. From a starting blockmodel, we generated 100 different runs, where up to 50% of the vertices change position. Table 2 shows the statistics of the three real datasets 6 on which we evaluate monotonicity.
 Figure 3 shows the results for REMD, RKL, RsKL and NMI (we plotted 1-NMI). As can be seen, all measures are monotonically increasing as the positions change. However, in the rare case wher e the adjacency approximation remains the same after a position splits into two, then the reconstruction distances can fail to distinguish the pre-split and post-split blockmodels. 5.3 Properties of the Measures Table 3 shows the measures and the properties they have. For each measure, we prove (see supplementary) whether it possesses each of the properties.
Table 3 confirms the empirical evaluation of Section 5.1. The positional mea-sures (e.g., NMI) do not consider blockm odel approximations and hence fail the structural sensitivity properties. The existing RB and RE distances cannot be applied to weighted graphs and are not block edge distribution sensitive. The proposed REMD generalises the reconstruction distances to weighted graphs, but still possesses the same assumptions as those distances, and hence fails the block edge distribution sensitivity property. The proposed KL-based distances are block edge distribution sensitive, but not weight sensitive as they measure distribution differences but ignore difference in weight values.

From these analyses, we recommend to use the KL reconstruction distance when comparing unweighted blockmodels , as it possess the first two properties. When comparing weighted graphs, the EMD distance might be preferred as it satisfies the weight sensitivity property. A further option is to combine several measures together via ideas from multi-objective optimisation, e.g., as a weighted linear sum, which we leave to future work. Blockmodel comparison measures are used for validating blockmodelling and community detection algorithms, finding consensus blockmodels and other tasks that require the comparison of blockmodels or communities. In this paper, we have shown that popular positional measures cannot distinguish important dif-ferences in blockmodel structure and approximations because they do not re-flect a number of key structural properties. We have also proposed two new measures, one based on the EMD and the other based on KL divergence. We formally proved these new measures possess a number of the desired structural properties and used empirical experiments to show they are monotonic.
Future work includes introducing new measures for evaluating mixed mem-bership blockmodels [1] and evaluating multi-objective optimisation approaches for combining measures.

