 Query expansion methods using pseudo-relevance feedback have been shown e ff ective for microblog search because they can solve vocabulary mismatch problems often seen in search-ing short documents such as Twitter messages (tweets), which are limited to 140 characters. Pseudo-relevance feedback as-sumes that the top ranked documents in the initial search re-sults are relevant and that they contain topic-related words appropriate for relevance feedback. However, those assump-tions do not always hold in reality because the initial search results often contain many irrelevant documents. In such a case, only a few of the suggested expansion words may be useful with many others being useless or even harmful. To overcome the limitation of pseudo-relevance feedback for mi-croblog search, we propose a novel query expansion method based on two-stage relevance feedback that models search in-terests by manual tweet selection and integration of lexical and temporal evidence into its relevance model. Our exper-iments using a corpus of microblog data (the Tweets2011 corpus) demonstrate that the proposed two-stage relevance feedback approaches considerably improve search result rel-evance over almost all topics.
 H.3.3 [ Information Storage and Retrieval ]: Query for-mulation, Relevance feedback Microblog search, Query expansion, Temporal dynamics
Query expansion based on relevance feedback has been shown e ff ective for improving microblog search performance [4, 19, 22, 23, 26]. That is due to the fact that query expan-sion can overcome the severe vocabulary mismatch prob-lem of microblog search. However, classical relevance feed-back, such as the Rocchio algorithm [31], requires a num-ber of judged documents. Moreover, relevance judgment is often burdensome as it requires manually reading those documents. On the other hand, query expansion based on pseudo-relevance feedback (PRF) does not require judged documents [5, 14, 17, 18, 21, 24, 38]. The assumptions be-hind PRF are that the top ranked documents in the ini-tial search results are relevant and that they include good words for query expansion. When the assumptions do not hold, PRF results in ine ff ective query expansion [25] X  X nly a few of the suggested expansion words are useful and many others are either harmful or useless [3]. To overcome these problems, we propose a simple but e ff ective query expansion method with manual selection of a single relevant document, which typically includes topic-related words. Using the se-lected document as query expansion words for a new query, we can re-retrieve more relevant documents and, based on the documents, estimate more accurate lexical and tempo-ral evidence for improving the second-stage PRF described shortly. We designate this first-stage relevance feedback as tweet selection feedback for searching Twitter messages (i.e., tweets).

Previous works have also shown that time-based language modeling and relevance feedback approaches are e ff ective for microblog search [4, 8, 9, 19, 22]. As described herein, we build on these findings and propose a novel PRF method combining lexical and document-dependent temporal evi-dence of microblog in response to a query, which relies strongly on relevance information among the re-retrieved documents, such as a word distribution and a time-stamp distribution. We assume that the proposed PRF method further improves microblog search performance in combination with tweet se-lection feedback. To demonstrate the validity of our pro-posed approach, we carry out evaluative experiments on the datasets of the TREC 2011 and 2012 real-time ad-hoc task (i.e., Tweets2011 corpus 1 ), which consist of more than 16 million tweets over a period of two weeks. The experimen-tal results of the two-stage relevance feedback show that our tweet selection feedback reduces the adverse e ff ects of PRF for di ffi cult queries and is especially e ff ective when combined with our proposed PRF.

The paper is structured as follows: In Section 2 we intro-duce the established pseudo-relevance feedback approaches. In Section 3 we present the limitation of standard relevance feedback methods. Section 4 describes details of our pro-posed method, which consists of two-stage relevance feed-back, tweet selection feedback and lexical-and-temporal-based relevance feedback. In Section 5 we demonstrate the e ff ect of the proposed PRF methods. In Section 6 we survey re-lated work. Finally, Section 7 presents a summary of this work and conclusions. Query likelihood model. Our PRF model builds on lan-guage modeling frameworks for information retrieval (IR), particularly the query likelihood model as proposed by Ponte and Croft [30]. This model assumes the probability of a query Q as being generated by the word probabilities on a document D . Based on the language modeling approach, all documents are ranked in order of the posterior probability, which is defined as P ( D | Q ). The probability of a document P ( D | Q ) by Bayes X  rule becomes where P ( Q | D ) is the query likelihood on the given document and P ( D ) is the prior probability that D is relevant to any query. To capture word frequency information in indexing a document, the multinomial model is used. This is called a uni-gram language model. We have the query likelihood P ( Q | D ) as follows: where | Q | is the number of words in the query and P ( w | D ) is the probability of a word w under the word distribution for a document D . In most cases, this probability is applied to smoothing to temper over-fitting using a given collection. Among numerous smoothing methods, the following Dirich-let smoothing [39] is often used.
 number of word counts of w in a document D , P ( w | C )is the collection language model.  X  is the Dirichlet prior. Recency-based language model. If we assume that the prior probability distribution over documents is uniform, then we rank documents in decreasing order of the query likelihood P ( Q | D ) above. However, the quality of docu-ment is changing over time. Topically relevant but obsolete documents might not satisfy the user if recent information is preferred. Consequently, Li and Croft [18] incorporated a prior distribution considering recency over documents into language model frameworks for retrieval. They proposed application of the following exponential distribution as the document prior P ( D )toEq.1.Wehave where t Q stands for the query time at which a query was issued by a user, t D signifies a time-stamp of the document D , and r denotes a rate parameter of the exponential dis-tribution. This model includes the assumption that newer documents have a higher probability than older ones do. Pseudo-relevance model. Lavrenko and Croft [17] incor-porated relevance feedback into language modeling frame-works. They estimated a relevance model, P ( w | R ), using a joint probability of observing the word w together with query words on top ranked initial search results. That rele-vance model weights words w according to the following.
P ( w | R )  X  P ( w | Q )  X  Among those expressions, R is the top M retrieved docu-ments using the query Q . This approach is called pseudo-relevance feedback. In addition, for query expansion, words w were ordered in descending order. The top K words are added to the original user query.
 Recency-based relevance model. In addition, Li and Croft [18] incorporated recency into the relevance model re-designing the document prior as follows: where P ( D | t D ) denotes the recency-based document prior in Eq. 4. This model is good at dealing with recency queries, but it is not able to accommodate any temporal variation. On microblog services, temporal dynamics of the topic varies, so that the recency-based method fails to find topic-related words having specific temporal variations consisting of an old peak that is distant from the query-time or a multi-modal temporal variation [26]. Furthermore, this model was not able to accommodate query-specific recency even though the degree of recency is topic-dependent [7, 8].
 Time-based relevance model. Keikha et al. [14] pro-posed a time-based relevance model. They assume that any topic relates to specific time and that their topic-related words are frequently used in this time. Their approach de-tects this topic-related time and incorporates this temporal property into language modeling frameworks as The previous version by Choi and Croft [4] defined the word distribution P ( w | t, Q )attime t against a query Q as where R t represents the top M documents issued in time t . Although the original work by Keikha et al. [14] as-sumed P ( w | t, Q ) was uniform, Choi and Croft assumed that P ( w | t, Q ) was equal to P ( w | Q ) and incorporated the time property into only P ( t | Q ). This equation is the same to Eq. 5 when using documents in time t except for P ( D )is set to be uniform, so that their model can consider word probability information in time t . Consequently, Eq. 7 is interpreted as the weighted sum of P ( w | t, Q ) by a temporal model P ( t | Q ). The temporal model against a given query, P ( t | Q ), is defined as Figure 1: Improvements by existing relevance feedback where P ( t | D ) is an indicator function P ( t | D ) = 1 if the date of t and a document time-stamp of D is the same; otherwise, P ( t | D ) = 0. One must recall that P ( Q | D ) is the query likelihood of a document D for Q . Z is the normalization factor. It is particularly interesting that this definition is the same as the notion of the temporal profile proposed by Jones and Diaz [12]. This model estimates topic-related time using document time-stamps and search scores (i.e. query likelihoods assuming the prior probability of document P ( D ) is uniform) of retrieved documents. This relevance model can weight the word distribution by this temporal profile, so it is able to capture general temporal variation by each topic. However, it ignores recency and document-dependent temporal information.
The previous time-based language models for IR and tem-poral relevance model based on PRF integrated into query expansion methods achieved great success for improving mi-croblog search performance [4, 8, 9, 19, 22]. They can in-corporate recency or temporal variation on microblogging platform into their model and overcome the vocabulary mis-match problem. These PRF methods assume that the pro-portion of relevant documents in initial search results is large, so that top ranked documents include good words for query expansion. However, that assumption becomes invalid and PRF fails if the initial search rank non-relevant docu-ments at the top [25]. Moreover, several words suggested by PRF model are useful and many others are either harmful or useless [3]. We assume that PRF for microblog search also *+,-./012 ./01234356007
Figure 2: Overview of two-stage relevance feedback. fails to improve search performance for some topics while enhancing the performance for other topics.

To see the performance of PRF over initial search results, we compare several PRF methods to the initial search. As the initial search, we use the language model with Dirichlet smoothing of Indri search engine 2 . We refer to this method as LM . Unless otherwise specified, all retrievals are imple-mented on top of LM . We prepare three baseline PRF meth-ods: the standard relevance model [17] (see Eq. 5), expo-nential recency-based relevance model [18] (see Eq. 6), and time-based relevance model [4, 14] (see Eq. 7), which are respectively designated as RM , EXRM , and TBRM .Thepa-rameters of these PRF models are tuned. The parameter tuning and pre-process are discussed in Section 5.1 and 5.2. Figure 1 shows the bar plots of the di ff erence in average pre-cision of existing relevance models ( RM , EXRM , and TBRM ) over initial search results ( LM ) using 108 search topics for TREC 2011 and 2012 microblog track. Results showed that all PRF methods improved search performance for many topics, but simultaneously they decrease for several topics. The results imply that we must estimate more accurate tem-poral and lexical evidence for maintaining PRF performance and to improve microblog retrieval simultaneously.
To overcome the limitation of established PRF methods and to improve retrieval further, we propose two-stage rel-evance feedback methods. They consist of tweet selection feedback ( TSF ) and query-document dependent temporal relevance model. We describe an overview of our approach in Figure 2. For the former, we only select a single relevant tweet among initial search results and re-retrieve tweets us-ing the selected tweet as expansion words of a new query. For the latter, we apply query-document dependent tempo-ral query expansion method to the re-retrieved documents, which almost all include relevant tweets at the top. The following sections show details of the respective methods.
The first relevance feedback uses a selected tweet from the initial search results. We assume that the relevant tweet se-http://www.lemurproject.org/indri/ Figure 3: Proportion that at least one relevant doc-lected by users is a good indicator to retrieve relevant tweets to a given query because the relevant tweet generally in-cludes good topic-related words. Using the selected tweet as expansion word for re-retrieving documents, we can obtain relevant tweets similar to the selected tweet at the top.
Additionally, we observed that the top ranked tweets re-trieved at the top by a standard search engine with default settings ( LM in our case) are often relevant, so that users can easily detect at least a relevant document from top ranked documents. To see the initial search performance, we define the proportion of search topics that retrieve at least a single relevant document among the top M # documents. We have where  X  (  X  ) is a function  X  ( x )=1if x&gt; 0; otherwise,  X  ( x )= 0. N # is the number of topics used and P i @ M # is the value of precision at M # for the i -th topic. Figure 3 presents the proportion across several cut o ff parameters M # using TREC 2011 and 2012 microblog track topics. Results show that users can find relevant tweets at the top without much e ff ort in the case of many TREC search topics. For example, the proportion of finding at least one relevant document among the top 30 is more than 0.95 in both datasets. Furthermore, users can read many tweets quickly because the length of the tweet content is limited to 140 characters. Consequently, users can readily detect a relevant tweet without much e ff ort.
In this section, we introduce the query-document depen-dent temporal relevance model. We assume that the search results by tweet selection feedback rank many relevant doc-uments at the top, which contains more accurate word and temporal distributions than by initial search. To use the improved pseudo-relevance information e ff ectively, we pro-pose a novel relevance feedback approach using lexical and temporal evidence.

We rely mainly on the notion of Dakka et al. [5] and Efron and Golovchinsky [8] for time-sensitive language modeling frameworks and also use a document expansion approach proposed by Efron et al. [9] to capture document-dependent temporal variation. We explain the relevance model step-by-step. First, we decompose a document part D in P ( w | Q ) into the lexical word in document D w and temporal infor-mation of document D t following Dakka et al. [5], Then, following Efron and Golovchinsky [8] X  X  work, we ap-plied the simple assumption that the temporal relevance of D t is independent of the document X  X  content, D w , and drop D t from the conditional probability in Eq. 11. Moreover, we assume that the given query consisting of query words in Q and the words w in pseudo-relevant documents are sampled identically and independently from a uni-gram distribution of R . Therefore, we have
P ( w | Q )= where P ( D t | Q ) is the query-dependent document genera-tion probability from a temporal perspective. We designate P ( D t | Q )as temporal evidence . However, P ( w | D w ) P ( Q | D is equal to a factor of the standard relevance feedback model (see Eq. 5). We designate this as lexical evidence .InEq.12, we assume that the prior probability over documents from a lexical perspective, P ( D w ), is uniform. Eq. 12 is the weighted sum of query-dependent lexical evidence by query-dependent temporal evidence with respect to each docu-ment.

Ideally, the probability P ( D t | Q ) becomes high when the query Q and the document D share a similar temporal prop-erty, so that we quantify this temporal property as the dis-tance between two temporal models of Q and D using the no-tion of temporal profile [12]. Borrowing the idea of temporal profile in Eq. 9, we define the temporal models of Q and D as P ( t | Q ) and P ( t | Q D ), respectively, where Q D is the pseudo-query of D submitted to search engines as a query based on the idea of Efron et al. [9]. Using P ( t | Q D ), we can cap-ture document-dependent temporal variation. In addition, we apply background smoothing to both temporal models and then smooth them with the model for adjacent days fol-lowing previous works [5, 12]. Additionally, we assume that the distance between two temporal models approximately follows an exponential distribution because the documents retrieved by Q D share more similar temporal property with the documents retrieved by Q than unobserved documents. We define the probability of query-dependent document X  X  temporal evidence as where d is the distance of two temporal models between P ( t | Q ) and P ( t | Q D ) and  X  is a rate parameter of exponen-tial distribution. Moreover, past works [7, 8] have shown that incorporating query-dependent recency is e ff ective for improving microblog search. Therefore, we design the rate parameter as automatically changing in response to each query X  X  temporal property, as where T Q = { t  X  T : t Q  X  t&lt;  X  } , T is a time range in a collection (days in our case), t Q denotes a query-time of query Q , and  X  is a hyper-parameter that controls the im-pact of topic-recency. The probability  X  denotes the value of complementary cumulative distribution function of tem-poral model until  X  days before the topic X  X  query-time. If the temporal profile of a given query ranks many documents generated at around its query-time at the top, then the prob-ability  X  is low. However, the probability is high if those document time-stamps are far from the query-time.
We assume that similar temporal models should share sim-ilar temporal property (e.g. temporal variation). Therefore, we compare two temporal models using the Bhattacharyya coe ffi cient, This comparison provides a similarity score between 0 and 1. Similar methods have been used to compare two associated language models using the Bhattacharyya coe ffi cient [6]. Us-ing the Bhattacharyya coe ffi cient, we can obtain the distance between two temporal models as This is called Bhattacharyya distance. When we substitute Eq. 16 into Eq. 13, we have the following final equation: This probability P ( D t | Q )becomeshighwhen P ( t | Q ) and P ( t | Q D ) are similar (i.e. Bhattacharyya coe ffi cient is high). The increase of P ( D t | Q ) approaches linear increase when  X  is high; in other words, a given topic indicates an old event. However, P ( D t | Q ) rapidly increases when a given topic indicates a recent event (i.e.  X  is low).
We evaluate our proposed methods using the test collec-tion for the TREC 2011 and 2012 microblog track (Tweets2011 corpus). This collection consists of about 16 million tweets sampled between January 23 and February 8, 2011. In ad-dition, relevance judgment is applied to the whole tweet set of each topic. The relevance levels are categorized into irrel-evant (labeled 0), minimally relevant (labeled 1), and highly relevant (labeled 2). We separately evaluate our methods as allrel and highrel , where allrel considers both minimally relevant and highly relevant tweets as relevant and highrel considers only highly relevant tweets as relevant.
We indexed tweets posted before the specific time asso-ciated with each topic by the Indri search engine with the following setting. All queries and tweets are stemmed using the Krovetz stemmer without stop-word removal. They are case-insensitive. This index was created to simulate a real-istic real-time search setting, where no future information is available when a query is issued. We built an index for each query. In our experiments, we used the titles of TREC topics numbered 1 X 50 and 51 X 110 3 as test queries, which are the o ffi cial queries in the TREC 2011 and 2012 microblog track, respectively. Additionally, we used 33 topics at TREC 2011 and 56 topics at TREC 2012, and obtained highly relevant tweets for highrel.

For retrieving documents, we used a basic query likelihood model with Dirichlet smoothing [39] (we set smoothing pa-rameter  X  = 2500 similar to Efron X  X  work [9]) implemented by the Indri search engine [34] as the language model for IR ( LM ) and all PRF used this LM as initial search re-sults. We filtered out all non-English retrieved tweets using a language detector with infinity-gram, called ldig 4 .The retweets 5 were regarded as irrelevant for evaluation in the TREC microblog track [27, 33]; however, we used retweets except in a final ranking of tweets because a set of retweets is a good source might contain topic-related words for improv-ing Twitter search performance [4]. In accordance with the track X  X  guidelines, all tweets with http status codes of 301, 302, 403, and 404 and all retweets contain the string  X  X T X  at the beginning of the tweet were removed from the final ranking. Finally, we used the top 1000 results for evaluation.
Our approach first conducts tweet selection feedback ( TSF ) described in Section 4.1. We automatically select relevant tweets from initial search results among top L tweets for TSF by each topic. We set L to 30 based on a preliminary experiment. In Section 5.4, we show that the performance is not sensitive to the choice of L when L is su ffi ciently large (e.g. L  X  30). The selected relevant tweets are minimally or highly relevant tweets. When multiple relevant tweets exist in initial search results, we use only a single relevant tweet that contains more words in it than others. We as-sume that users prefer long tweets. If relevant tweets do not exist among initial search results, we use the original user query for tweet selection feedback. All selected tweets were stopped using Indri X  X  stop words list with URL and men-tion (e.g. @trecmicroblog) removal. In the new query, the selected tweet and the original query were weighted as 1 : 1 for each method using TSF . After tweet selection feedback, we conduct the proposed query expansion method based on a query-and-document dependent temporal relevance model ( QDRM ). For QDRM , we produce a temporal profile con-sisting of the top N tweets, which were retrieved using a document among initial search results as a pseudo-query. These pseudo-queries were also pre-processed in the same mode as tweets used for TSF . We denote the combination of TSF and QDRM as TSF+QDRM .

To assess our proposed methods, TSF and TSF+QDRM , we also prepared several baseline methods. Our first base-line, RM , uses standard relevance feedback using only lexical evidence [17]. This can be compared with TSF+RM which uses tweet selection feedback before the pseudo-relevance feedback RM . QDRM di ff ers from RM in that RM does not consider temporal evidence. Actually, QDRM is equal to RM when we set  X  in QDRM to 0 (see Eqs. 12 and 13). Our sec-ond baseline, EXRM uses relevance feedback using exponen-
The topic numbered MB050 and MB076 has no minimally or highly relevant tweets. Therefore, we did not use them for our experiments. https://github.com/shuyo/ldig
Tweets re-posted by another user to share information with other users l 0.3024 l 0.4592 l 0.5475 l 0.4503 l l 0.3025 l 0.4663 l 0.5492 l 0.4520 l l 0.3139 l 0.4826 l 0.5610 l 0.4644 lq l 0.3039 l 0.4760 l 0.5542 l 0.4441 l ! 0.3198 ! 0.5309 ! 0.5763 ! 0.4559 ! tial distribution to prior probability for relevance model [18]. EXRM does not consider query-dependent recency and tem-poral variation compared to QDRM . We also prepare TSF+ EXRM , which is a combination of TSF and EXRM to assess the e ff ect of tweet selection feedback for the recency-based method. Finally, our third baseline is a time-based relevance model, TBRM , that incorporates lexical evidence and query-dependent temporal variation into its relevance model. How-ever, it ignores recency and document-dependent temporal variation. We compare this model and its tweet selection ex-tension, TSF+TBRM , to our QDRM that uses both lexical and temporal evidence with query-dependent recency. RM , EXRM , and TBRM are strong baselines in our experiments.
For all query expansion methods, we select candidate words among the top M tweets retrieved by the original query after removing the uniform resource locators (URLs), and user names starting with  X  X  X  or special characters (!, @, #,  X ,  X , etc.). All query words, candidate words, and tweets are decapitalized. The candidate words include no stop-words prepared in the Indri search engine. Then, we select K words among candidate words in descending order of the probability P ( w | Q ), respectively. The selected words con-tain no original query word, but might contain words of the selected tweet in the case of using TSF . Finally, we combined the expanded words of PRF and the original query (or the combination of the original query and the selected tweet) as an expanded query; they were weighted with 1 : 1.
For QDRM and EXRM , we tune parameters: the length of temporal profile (i.e. N ), the hyper-parameter (i.e.  X  ), and the rate parameter (i.e. r ). For all methods, we also tune their parameters: the number of pseudo-relevance feedback documents (i.e. M ) and the number of expansion words (i.e. K ). Values of the model parameters are optimized for best performance precision at 30 on training data, which is the o ffi cial measure in TREC 2011 microblog track. For example, we tune parameters of the IR model using TREC 2012 microblog track dataset and test it with TREC 2011 microblog dataset. However, we trained the model using the TREC 2012 dataset and test it on the TREC 2011 dataset. Results show that the parameter N in the proposed QDRM set to be 10 is better for both datasets. The sensitivity of other important parameters such as L in TSF and the recency control parameter  X  of QDRM is discussed in the next section.
The goal of our system is to return a ranked list of tweets using (pseudo-) relevance feedback methods. To evaluate re-trieval e ff ectiveness, we used precision at 10 and 30 (P@10, P@30, respectively), average precision (AP), and normal-ized discounted cumulative gain (nDCG) [11], nDCG con-siders graded relevance. Recall that P@30 was the o ffi cial Microblog track metric in 2011. In the TREC 2012 mi-croblog track,  X  X ighly relevant X  tweets are the required level of relevance. These measures provide a succinct summary of the quality of the retrieved tweets. We discuss the statistical significance of results obtained using a permutation test [32] throughout this paper. Overall Results. Table 1 shows the P@10, P@30, AP, and nDCG performances of 10 methods with statistical signifi-cance test results for allrel documents. Table 2 shows the P@30 and AP performances for highly relevant documents. Significant improvements by tweet selection feedback ( TSF ) are denoted with ! and " , respectively, for significance prob-abilities p&lt; 0 . 05 and p&lt; 0 . 01. In addition, among meth-ods without the use of TSF , the subscript l , r , e , t , and q respectively indicate statistically significant improvements ( p&lt; 0 . 05) over LM , RM , EXRM , TBRM , and QDRM . More-over, among methods using TSF , the subscripts l # , r # , e t , and q # respectively indicate statistically significant im-provements ( p&lt; 0 . 05) over TSF+LM , TSF+RM , TSF+ EXRM , TSF+TBRM , and TSF+QDRM . The best result per column is marked in bold typeface.

It is apparent that QDRM markedly outperforms the ini-tial search LM on most measures across both datasets, sim-ilarly to other relevance feedback approaches RM , EXRM , and TBRM with statistical significance. Moreover, QDRM outperformed the standard relevance model RM in terms of most evaluation measures across both datasets similar to other time-based relevance feedback methods EXRM and TBRM , which suggests that temporal evidence (recency or temporal variation) is important for microblog search. How-ever, none of these di ff erences is statistically significant ex-cept between RM and EXRM on AP.

When using tweet selection feedback, TSF+LM markedly outperformed LM in terms of all measures across both datasets with statistical significance, which suggests that the sim-ple query expansion method using a selected relevant tweet as expansion words is considerably e ff ective. Furthermore, relevance feedback approaches after TSF outperformed rele-vance feedback without using TSF in terms of all measures. For all using TSF , the di ff erences in AP, nDCG@10, and P@10 in the TREC 2011 dataset were statistically signifi-Table 2: Performance comparison of the proposed Figure 4: Di ff erence in average precision between TSF Figure 5: Di ff erence in average precision between TSF+ cant. Important points include the fact that TSF+QDRM markedly outperformed QDRM with regard to all evalua-tion measures across both datasets with statistical signifi-cance. For both datasets, TSF+QDRM outperformed other PRF methods using TSF : TSF+RM , TSF+EXRM , and TSF+TBRM . Particularly the di ff erence in average preci-sion on the TREC 2012 dataset is statistically significant. Results suggest that tweet selection feedback is useful for PRF methods and that incorporating query-dependent lexi-cal and temporal evidence by each document is considerably e ff ective when using improved search results by tweet selec-tion feedback.

From Table 2, it is also apparent that PRF using TSF is e ff ective for improving retrieval performance when searching highly relevant documents. In this case, TSF+QDRM out-performed other methods in all evaluation measures across both datasets. For further improvement of search perfor-mance with regard to highly relevant documents, we must consider external web-contents corresponding to URLs in a tweet, which significantly a ff ect the retrieval performance of highly relevant tweets [19].
 Table 3: Improved and decreased percentages of the val-Figure 6: Sensitivity to the number of top retrieved E ff ect of Tweet Selection Feedback. We underscore the e ff ectiveness of tweet selection feedback ( TSF ) compar-ing to initial search results ( LM ) in Figure 4. The bar plot shows the di ff erence in average precision between LM and TSF on a query-by-query basis. Compared to relevance feedback methods without tweet selection feedback shown in Figure 1, TSF not only significantly improved search re-sults over the initial search (see Table 1); it also improved the search performance of each topic without decreasing search performance over almost all topics. For example, Table 3 shows that TSF+LM improved results for about 97 topics, and decreased results for about 8 topics, whereas the results of relevance feedback methods without the use of TSF ( RM , EXRM , TBRM , and QDRM ) improved about 81 X 87 topics and decreased about 18 X 20 topics.

In addition, Figure 5 shows the results for relevance feed-back after tweet selection ( TSF+QDRM ). Table 3 shows that TSF+RM , TSF+EXRM , TSF+TBRM , similarly to TSF+QDRM also improve retrieval performance for al-most all topics without decreasing search performance com-pared to RM , EXRM and TBRM , which suggests that tweet selection feedback combined with PRF is e ff ective to im-prove retrieval performance steadily. Particularly, we found that TSF+QDRM e ff ectively uses search results refined by tweet selection feedback compared to other relevance feed-back methods. Figure 7: Sensitivity to the recency control parameter Figure 8: Bhattacharyya coe ffi cient between temporal Parameter Sensitivity. In our experiments, we selected a longest tweet among the top 30 tweets retrieved by LM (i.e. L = 30) and combined it with an original query as a new query for tweet selection feedback. We demonstrate in Figure 6 how the value of mean average precision (MAP) of TSF changes with di ff erent L parameters. Results showed that the performances of TSF+LM increase until L =30, and become insensitive to L when L is large (e.g. L  X  30) on both datasets. Those results suggest that the top ranked 30 tweets tend to contain a relevant tweet that can improve the retrieval performance via TSF , so that microblog users should read the top 30 tweets and select only a single rel-evant tweet among them when searching the Tweets2011 corpus e ff ectively.
 We also show the parameter sensitivity of  X  in QDRM . The parameter  X  controls the degree of the recency param-eter over topics. Figure 7 shows the MAP values of QDRM and TSF+QDRM for L =30, M =100, N = 10, and K = 20 across di ff erent  X  values. It is readily apparent that the performance of QDRM and TSF+QDRM on both datasets is sharply decreasing when using large  X  values. Large  X  tempers the impact of temporal evidence because  X  value tends to approach 0 (see Eqs. 14 and 17). The re-sults suggest that query and document-dependent temporal evidence in QDRM is working. The optimal value of QDRM on TREC 2012 dataset is  X  = 2, which indicates the e ff ec-tiveness of recency. However, the di ff erence of MAP values is slight. We assumed that this robustness results from the Figure 9: Temporal variations of a topic numbered short time span of the Tweets2011 corpus (about two weeks). It was also described earlier in the past work [9]. The op-timal  X  values of TSF+QDRM on both datasets were 0, which means considering only query and document X  X  tem-poral variation in temporal evidence ignoring recency is ef-fect. We assumed that TSF was able to bring more accurate temporal distributions, so that the recency e ff ect of QDRM was vanishingly small.
 Temporal Analysis. We evaluate TSF from a temporal perspective. To demonstrate the improvement of estimation of temporal evidence, we compared the time-stamp distribu-tion of relevant documents to that of the first 20 documents retrieved by a simple query likelihood model ( LM ) and tweet selection feedback ( TSF+LM ), respectively. Bhattacharyya coe ffi cient is used as the similarity between two time-stamp distributions of retrieved documents. The higher value of the Bhattacharyya coe ffi cient means that the IR system precisely estimates topic-related temporal evidence. Fig-ure 8 shows the Bhattacharyya coe ffi cients of LM and TSF +LM against relevant documents. To test the di ff erence of the Bhattacharyya coe ffi cient between LM and TSF+LM , we use two-sided Wilcoxon matched-pairs signed-ranks test with p&lt; 0 . 05. Results show that the Bhattacharyya co-e ffi cient improved after TSF and the variance was smaller than LM . For example, the coe ffi cient of TSF on TREC 2011 dataset significantly outperformed that of LM (from 0 . 7748  X  0 . 1756 to 0 . 8071  X  0 . 1566), but when using the TREC 2012 dataset, the di ff erence is not statistically sig-nificant (from 0 . 7822  X  0 . 1361 to 0 . 7988  X  0 . 1112). The co-e ffi cient values of LM and TSF on both datasets (ALL) are 0 . 7789  X  0 . 1553 and 0 . 8026  X  0 . 1338, respectively. The dif-ference is statistically significant. The point is that we can predict accurate temporal evidence using TSF .
 Query Analysis. In Table 4, we display candidate words of query expansion for the topic  X  X olland Iran envoy recall X  (MB042 6 )in RM ,in QDRM ,in TSF+RM , and in TSF+
The news that  X  X utch government is recalling its Tehran ambassador for consultations over the burial of executed Dutch X  X ranian Sahra Bahram X  was reported by BBC News on 7 February 2011. QDRM , showing improved results with TSF+QDRM .It is apparent that more topic-related words such as  X  X utch X ,  X  X ahrami X , and  X  X ranian X  appear in our approaches TSF+ RM and TSF+QDRM . That is true because TSF selected  X  X reaking: Dutch recall ambassador from #Iran over execu-tion of Dutch X  X ranian Zahra Bahrami, summon Iran Ambas-sador X  as a relevant document and used it for tweet selection feedback and refined lexical and temporal evidence for PRF. In addition, Figure 9 shows the kernel density estimate of the document age of topic MB042 using relevant tweets and top search results obtained using LM and TSF . From this figure, it is apparent that temporal variation approaches relevant estimates using TSF . Moreover, the word weights against a query, P ( w | Q ), of topic-related words of TSF+QDRM are larger than that of TSF+RM . Results show that the aver-age precision values of RM , QDRM , TSF+RM , and TSF+ QDRM improved over the initial search LM (from 0.0490 to 0.0815, 0.0427, 0.8412, and 0.8478, respectively).
However, regarding  X  X ustralian Open Djokovic vs. Mur-ray X  (MB071), the average precision of relevance methods RM , QDRM improved over LM (from 0.5704 to 0.5809 and 0.6039, respectively) although that of TSF+RM , and TSF +QDRM decreased (from 0.5704 to 0.4450 and 0.4496, re-spectively). That is true because a tweet selected by TSF about this topic,  X  X omorrow is the Australian open tennis fi-nal for men, Andy Murray vs. Navok Djokovic Who X  X  gonna win?? I X  X  a Murray fan so I say GO MURRAY!! X  , contains numerous topic-unrelated words. To improve the retrieval performance more using TSF , we must detect important con-cepts from this long query.
The proposed method combines the simple interactive query expansion method and the time-based PRF model for mi-croblog search. In earlier work, term-based interactive query expansion methods were proposed, where users manually se-lect topic-related words from suggested candidates as expan-sion words. They improved the retrieval performance [10, 35]. However, it is di ffi cult to understand the context of suggested words. Their methods require cumbersome rele-vance judgments to select expansion words. In our method TSF , users must select no topic-related word. Instead, users merely read and select a single interesting tweet among ini-tial search results.

Our approach is based on the notion of cluster-based infor-mation retrieval [13, 15, 16, 20, 36, 37] which uses clustering information to rank documents. Kurland and Lee [15] re-ranked documents using cluster information consisting of k nearest lexical similar documents. Liu and Croft [20] clus-tered all documents into several sets of similar documents using the k -means algorithm and used clusters for smooth-ing the language model with a global collection language model. Wei and Croft [37] proposed the document model using Latent Dirichlet Allocation to obtain clustering infor-mation for smoothing. Instead of smoothing for language models, Kalmanovich and Kurland [13] used cluster infor-mation with retrieved documents for creating an expanded query. In addition, Efron et al. [9] proposed a document ex-pansion method based on the idea of Tao et al. [36], which smooths document language models by similar documents gathered with k nearest-neighbor. They submit documents as pseudo-queries to obtain similar documents, assuming that short documents such as a tweet tend to mention a single topic. Our approach di ff ers from those in previous works in that we first made topic-related clusters by manu-ally selecting a single tweet among initial search results and then submitting them to obtain similar documents. Conse-quently, our language modeling framework can easily reflect user intent. Additionally, we used this cluster for query ex-pansion in the form of PRF as lexical and temporal evidence.
Microblog services often have real-time features by which many tweets are posted by crowds of people when a no-table event occurs. Many reports have described studies about time-aware information retrieval methods for incor-porating such real-time features. Dakka et al. [5] also pro-posed a general ranking mechanism integrating temporal properties into a language model identifying the important periods. Peetz et al. [29] proposed query modeling leverag-ing a temporal burst. Keikha et al. [14] proposed a time-based relevance model for improving blog retrieval. How-ever, Dakka, Peetz, and Keikha X  X  works cannot combine temporal properties of two types (recency and temporal vari-ation) by topic. Li and Croft [18] incorporated recency into the language model framework for IR [17, 30]. Peetz et al. [28] tested many temporal document priors based on cog-nitive motivation for retrieving recent documents. However, their methods were unable to consider query-dependent re-cency. The query-dependent recency model was recently discussed in many works. Amati et al. [1] incorporated tem-poral recency into the document prior using survival func-tion for microblog search. Massoudi et al. [22] proposed a query expansion method selecting words that are temporally closer to the query-time. Efron and Golovchinsky [8] pro-posed IR methods incorporating temporal properties into language modeling and showed their e ff ectiveness for re-cency queries. Efron [7] also proposed a query-specific re-cency ranking approach. In addition, Miyanishi et al. [26] combines recency and temporal variation based query ex-pansion methods in response to query-dependent temporal property. However, they did not incorporate document-dependent temporal variation into their query expansion model. Our method takes account of lexical evidence weighted by temporal evidence related to each document while simul-taneously considering recency.
In this paper, we proposed two-stage relevance feedback approaches for microblog search using tweet selection feed-back and query-document dependent temporal relevance feed-back methods. Our two-stage relevance feedback consid-erably improved retrieval performance with minimum user interaction. First, the user selects only one relevant tweet among top ranked initial search results and combines it with an original user query for tweet selection feedback ( TSF ), where the combined query is used for re-retrieving docu-ments. Second, to improve search results further, a query-dependent relevance model QDRM is applied to top ranked re-retrieved documents.

TSF is a simple and e ff ective approach to overcome the vocabulary mismatching problem and to improve microblog retrieval performance. Microblog documents are very short and tend to mention a single topic. TSF succeeds in exploit-ing the microblog feature. The user can quickly read and can readily select a relevant document among top re-retrieved search results that contain good words. A set of docu-ment time-stamps indicates the topic-related time. Using improved top search results for relevance feedback, we were able to improve search results using our proposed QDRM , which combines lexical and query-document dependent tem-poral evidence. Our two-stage relevance feedback frame-work can plug in any PRF method after TSF . We evalu-ated our approach using the Tweets2011 corpus with TREC 2011 and 2012 microblog datasets. The experimentally ob-tained results indicate that TSF markedly improves retrieval performance without decreasing over almost all queries. In addition, the proposed PRF method, QDRM , further con-siderably improved microblog search performance compared to established PRF methods. Although TSF is extremely e ff ective for microblog search, TSF sometimes fails to out-perform the initial search because of the redundancy of the tweet content, which contains meaningless words that some-times degrade search results. In future work, we plan to refine tweet selection feedback method combined with an au-tomatic key-concept extraction method for long queries [2].
