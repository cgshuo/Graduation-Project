 the quantities of interest, which amount to moments of the random variables, as the solution to an optimization problem obtained via convex duality. Since optimizing the dual is rarely an ameliora-machine learning for making principled (and unprincipled) approximations to the objective. tool for statistical inference, mainly because it applies to a wide range of problems. As remarked by Yedidia in [17], however, mean field theory often imposes unrealistic or questionable factorizations, leading to poor solutions. Advances have been made in improving the quality of mean field ap-proximations [17, 22, 26], but their applicability remains limited to specific models. Bethe-Kikuchi approximations overcome some of the severe restrictions on factorizability by decomposing the en-agation updates converge to the stationary points of the resulting optimization problem (provided they converge at all). Related variational approximations based on convex combinations of tree-structured distributions [24] have the added advantage that they possess a unique global optimum (by contrast, we can only hope to discover a local minimum of the Bethe-Kikuchi and mean field objectives). However, both these methods rely on tractable sum-product messages, hence are limited to Gaussian Markov random fields or discrete random variables. Expectation propagation projec-tions and Monte Carlo approximations to the sum-product messages get around these limitations, but can be unsuitable for dense graphs or can introduce extraordinary computational costs [5, 23]. Dirichlet allocation [5], whereby mean field remains to date the tractable approximation of choice. Several Monte Carlo methods have been proposed to correct for the discrepancy between the fac-torized variational approximations and the target distribution. These methods include importance sampling [8, 14] and adaptive Markov Chain Monte Carlo (MCMC) [6]. However, none of these mations tend to be too restrictive when used as a proposal distribution. This is corroborated by experimental results in those papers as well as theoretical results [20]. We propose an entirely new approach that overcomes the problems of the aforementioned methods by constructing a sequence a new class of conditionally-specified mean field approximations, and use sequential Monte Carlo (SMC) [7] to obtain samples from them. SMC acts as a mechanism to migrate particles from an it recovers dependencies left out by mean field. Sec. 4 explains these ideas thoroughly. The idea of constructing a sequence of distributions has a strong tradition in the literature, dating problems [12]. Recent advances in stochastic simulation have allowed practitioners to extend these ideas to general probabilistic inference [7, 11, 15]. However, very little is known as to how to come up with a good sequence of distributions. Tempering is perhaps the most widely used strategy, due to its ease of implementation and intuitive appeal. At early stages, high global temperatures smooth the modes and allow easy exploration of the state space. Afterward, the temperature is progressively weights tends to degenerate around a system X  X  critical range of temperatures, as observed in [9]. An entirely different approach is to remove constraints (or factors) from the original model, then incrementally reintroduce them. This has been a fruitful approach for approximate counting [12], simulation of protein folding, and inference in the Ising model [9]. If, however, a reintroduced constraint has a large effect on the distribution, the particles may again rapidly deterioriate. We limit our study to the Ising spin glass model [16]. Ernst Ising developed his model in order to explain the phenomenon of  X  X pontaneous magnetization X  in magnets. Here, we use it as a test bed to investigate the viability or our proposed algorithm. Our intent is not to design an algorithm arbitrary potentials. Conditional mean field raises many questions, and since we can only hope to answer some in this study, the Ising model represents a respectable first step. We hint at how our ideas might generalize in Sec. 6.
 The next two sections serve as background for the presentation of our main contribution in Sec. 4. In this study, we restrict our attention to random vectors X = ( X figurations x = ( x family [25]. A member of this family has a probability density of the form Denoting E Jensen X  X  inequality states that f ( E tion  X  on X . Using the fact that  X  log( x ) is convex, we obtain the variational lower bound where the mean statistics are defined by  X  (  X  )  X  E ational principle . We emphasize that this lower bound holds for any choice of  X  . A more rigorous treatment follows from analyzing the conjugate of the convex, differentiable function  X (  X  ) [25]. sions exist for the entropy and mean statistics. There do, however, exist particular choices of the variational parameters  X  where it is possible to compute them both. We shall examine one particular set of choices, naive mean field , in the context of the Ising spin glass model.
 At each site i  X  X  1 , . . . , n } , the random variable X in the  X  X p X  spin position, or x sites i and j . Setting  X   X  define the effect of the external magnetic field on the energy of the system. We use the undirected structure of the probability measure (there is no edge between i and j if and only if X are conditionally independent given values at all other points of the graph). Associating singleton statistics vector to be x The corresponding variational lower bound on the log-partition function  X (  X  ) then decomposes as where  X  Naive mean field restricts the variational parameters  X  to belong to {  X  | X  ( i, j )  X  E,  X  We can compute the lower bound (4) for any  X  belonging to this subset because we have tractable expressions for the mean statistics and entropy. For the Ising spin glass, the mean statistics are and the entropy is derived to be The standard way to proceed [17, 25] is to derive coordinate ascent updates by equating the deriva-tives  X  X / X  X  constrained to lie within an envelope known as the marginal polytope [25]. Alternatively, one can solve the optimization problem with respect to the unconstrained variational parameters  X  . Since it is not possible to obtain the fixed-point equations by isolating each  X  This approach, as we will see, is necessary for optimizing the conditional mean field objective. Assuming familiarity with importance sampling, this will be sufficient to explain key concepts un-derlying SMC, and does not overwhelm the reader with subscripts. See [7] for a detailed description.  X   X   X  . The unbiased importance weights on the joint space are given by K K degeneracy in the marginal space, we adopt the standard stratified resampling algorithm [13]. Choice of backward-in-time kernel. Mean field tends to be overconfident in its estimates (although optimal backward kernel [7, Sec. 3.3.2.3], the importance weights would simplify to Implicitly, this is the choice of backward kernel made in earlier sequential frameworks [11, 15]. expression (9) risks having unbounded variance. This is a problem because the weights may change Del Moral et al suggest approximating the optimal backward-in-time kernel [7, Sec. 3.3.2.1] by It offers some hope because the resulting importance weights on the joint space, following (8), are  X  ( x ) , the backward kernel (10) will rectify the problems caused by an overconfident proposal. Choice of Markov transition kernel. The drawback of the backward kernel (10) is that it limits instance, we can X  X  use the Metropolis-Hastings algorithm because its transition kernel involves an is widely applicable is a mixture of kernels based on the random-scan Gibbs sampler [18]. Denoting  X  where  X  ( x for conditional probability, we arrive at the expression for the importance weights, Normalized estimator. For almost all problems in Bayesian analysis (and certainly the one con-sidered in this paper), the densities are only known up to a normalizing constant. That is, only malized importance sampling estimator [18] yields (asymptotically unbiased) importance weights timator can recover a Monte Carlo estimate of the normalizing constant Z ? via the recursion provided we already have a good estimate of Z [7]. We start with a partition R (equivalence relation) of the set of vertices V . Elements of R , which up with a good naive mean field approximation to the conditional density p ( x equivalence class A  X  R , and then again for every configuration x the configuration x restricted to set A  X  V , and x of the matter is that for any point  X  , the functions p ( x densities if they correspond to some unique joint, as discussed in [2]. Fortunately, under the Ising model the terms p ( x generalization of the auto-logistic model [3], for which the joint is always known. As noted by Besag,  X  X lthough this is derived classically from thermodynamic principles, it is remarkable that the Ising model follows necessarily as the very simplest non-trivial binary Markov random field [4]. X  Conditional mean field forces each conditional p ( x marginals p ( x tices in subset A . Notice that we have a set of free variational parameters  X  C
R  X { ( i, j ) | X  A  X  R, ( i, j ) /  X  E ( A ) } Our variational formulation consists of competing objectives, since the conditionals p ( x share a common set of parameters. We formulate the final objective function as a linear combination partition R and linear weights  X  is of the form We extend the notion of neighbours to sets, so that N ( A ) is the Markov blanket of A . The non-negative scalars  X  Each conditional objective F partition function of the conditional density p ( x F bound in Sec. 2, except that we replace the joint by a conditional . We obtain the expression with the conditional mean statistics for i  X  A, j  X  A given by Notice the appearance of the new terms in (16). These terms account for the interaction between the random variables on the border of the partition. We can no longer optimize  X  following the standard approach; we cannot treat the  X  we optimize with respect to the parameters  X  , taking derivatives  X  F We have yet to address the question: how to select the scalars  X  ? It stands to reason that we should place greater emphasis on those conditionals that are realised more often, and set  X  may involve nearly as many terms as there are possible worlds, hence offering little improvement over the naive solution. As it turns out, a greedy choice resolves both issues. Supposing that we are at some intermediate stage in the SMC algorithm (see Sec. 4.1), a greedy but not unreasonable choice is to set  X  Happily, the number of terms in (15) is now on the order of the number of the particles. Unlike standard naive mean field, conditional mean field optimizes over the pairwise interactions  X  This choice is convenient for two reasons. First, the objective is separable on the subsets of the partition. Second, the conditional objective of a singleton subset has a unique maximum at  X  so any solution to (15) is guaranteed to recover the original distribution when | R | = n . 4.1 The Conditional mean field algorithm We propose an SMC algorithm that produces progressively refined particle estimates of the mean statistics, in which conditional mean field acts in a supporting role. The initial SMC distribution is obtained by solving (15) for R = { V } , which amounts to the mean field approximation derived Figure 1: The graphs on the left depict the Markov properties of the conditional mean field approxi-of the estimate of the log-partition function in SMC steps 1 to 4. The dashed line is the true value. function, as  X (  X  ) = P Let X  X  now suppose we are at some intermediate step in the algorithm. We currently have a parti-quence, we choose a finer partitioning of the graph, R ? , set the weights  X  ? according to (19), and use a nonlinear solver to find a local minimum  X  ? to (15). The solver is initialized to  X  ? require that the new graph partition satisfy that for every B  X  R ? , B  X  A for some A  X  R . In this manner, we ensure that the sequence is progressing toward the target (provided R 6 = R ? ), and that it is always possible to evaluate the importance weights. It is not understood how to tractably choose a good sequence of partitions, so we select them in an arbitrary manner. Next, we use the random-scan Gibbs sampler (12) to shift the particles toward the new distribution, where the Gibbs sites k correspond to the subsets B  X  R ? . We set the mixture probabilities of the Markov transition kernel to  X   X  w ( x, x 0 ) = where the single-site conditionals are  X  ( x unique subset containing B  X  R ? . The new SMC estimate of the log-partition function is  X (  X  ? )  X  We are now ready to move to the next iteration. Let X  X  look at a small example to see how this works. Example. Consider an Ising model with n =4 and parameters  X   X   X  1:4 = (0 . 09 , 0 . 03 ,  X  0 . 68 ,  X  0 . 48)  X  1:4 = (0 . 11 , 0 . 07 ,  X  0 . 40 ,  X  0 . 27) and the new conditional mean field approximation is given by  X  with potentials  X  Notice that  X   X (  X  ) happens to underestimate  X (  X  ) , but in other examples we may get overestimates. The random-scan Gibbs sampler can mix poorly, especially on a fine graph partition. Gradually choice might have been to sacrifice the quadratic convergence rate for a limited-memory Hessian approximation or conjugate gradient; the optimization routine was the computational bottleneck on dense graphs. Even though the solver is executed at every iteration of SMC, the separability of the objective (15) means that the computational expense decreases significantly at every iteration. To our knowledge, this is the only SMC implementation in which the next distribution in the sequence is constructed dynamically according to the particle approximation from the previous step. for the fully-connected graph with 26 nodes. We omitted the tree-reweighted upper bound because of the mean statistics according to the hot coupling (HC), conditional mean field algorithm (CMF), Bethe-Kikuchi variational approximation (B-K), and tree-reweighted upper bound (TRW) estimates. The maximum possible average error is 2. For the HC and CMF algorithms, 95% of the estimates fall within the shaded regions according to a sample of 10 simulations. We conduct experiments on two Ising models, one defined on a 12  X  12 grid, and the other on a fully-connected graph with 26 nodes. The model sizes approach the limit of what we can compute exactly for the purposes of evaluation. The magnetic fields are generated by drawing each  X  from [  X  1 , 1] and drawing  X  pairwise interactions, so it is expected that rudimentary MCMC methods such as Gibbs sampling will get  X  X tuck X  in local modes [9]. Our algorithm settings are as follows. We use 1000 particles (as with most particle methods, the running time is proportional to the number of particles), and we temper across successive distributions with a linear inverse temperature schedule of length 100. The with the  X  X ot coupling X  SMC algorithm described in [9] (appropriately, using the same algorithm settings), and with two sum-product methods based on Bethe-Kikuchi approximations [1] and tree-reweighted upper bounds [24]. We adopt the simplest formulation of both methods in which the regions (or junction graph nodes) are defined as the edges E . Since loopy belief propagation failed to converge for the complete graph, we implemented the convergent double-loop algorithm of [10]. partitioned into smaller and smaller pieces. Both Bethe-Kikuchi approximations and tree-reweighted upper bounds provide good approximations to the grid model. Indeed, the former recovers the log-encounter a dense, frustrated model. This is consistent with the results observed in other experi-ments [9, 24]. The SMC algorithms proposed here and in [9], by contrast, produce significantly improved estimates of the mean statistics. It is surprising that we achieve similar performance with hot coupling [9], given that we do not exploit the tractability of sum-product messages in the Ising model (which would offer guaranteed improvements due to the Rao-Blackwell theorem). We presented a sequential Monte Carlo algorithm in which each artificial distribution is the solution to a conditionally-specified mean field optimization problem. We believe that the extra expense of nonlinear optimization at each step may be warranted in the long run as our method holds promise in solving more difficult inference problems, problems where Monte Carlo and variational methods alone perform poorly. We hypothesize that our approach is superior methods that  X  X rune X  constraints on factors, but further exploration in other problems is needed to verify this theory. Beyond mean field. As noted in [22], naive mean field implies complete factorizability, which is not necessary under the Ising model. A number of refinements are possible. However, this is not a research direction we will pursue. Bethe-Kikuchi approximations based on junction graphs have many merits, but they cannot be considered candidates for our framework because they produce are appealing because they tend to be underconfident, but again we have the same difficulty. Extending to other members of the exponential family. In general, the joint is not available in For one, we can use Brook X  X  lemma [3, Sec. 2] to derive an expression for the importance weights that does not involve the joint. Furthermore, conditions for guaranteeing the validity of conditional densities have been extensively studied in multivariate [2] and spatial statistics [3]. Acknowledgments References
