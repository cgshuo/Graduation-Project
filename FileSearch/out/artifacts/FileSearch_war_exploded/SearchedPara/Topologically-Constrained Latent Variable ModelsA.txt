 Raquel Urtasun rurtasun@csail.mit.edu UC Berkeley EECS &amp; ICSI; CSAIL MIT David J. Fleet fleet@cs.toronto.edu University of Toronto Andreas Geiger geiger@mrt.uka.de Karlsruhe Institute of Technology Jovan Popovi  X c jovan@csail.mit.edu CSAIL MIT Trevor J. Darrell trevor@eecs.berkeley.edu UC Berkeley EECS &amp; ICSI; CSAIL MIT Neil D. Lawrence Neil.Lawrence@manchester.ac.uk University of Manchester Dimensionality reduction is a popular approach to dealing with high dimensional data sets. It is of-ten the case that linear dimensionality reduction, such as principal component analysis (PCA) does not ad-equately capture the structure of the data. For this reason there has been considerable interest in the ma-chine learning community in non-linear dimensionality reduction. Approaches such as locally linear embed-ding (LLE), Isomap and maximum variance unfold-ing (MVU) (Roweis &amp; Saul, 2000; Tenenbaum et al., 2000; Weinberger et al., 2004) all define a topology through interconnections between points in the data space. However, if a given data set is relatively sparse or particularly noisy, these interconnections can stray beyond the  X  X rue X  local neighbourhood and the result-ing embedding can be poor.
 Probabilistic formulations of latent variable models do not usually include explicit constraints on the embed-ding and therefore the natural topology of the data manifold is not always respected 1 . Even with the cor-rect topology and dimension of the latent space, the learning might get stuck in local minima if the initial-ization of the model is poor. Moreover, the maximum likelihood solution may not be a good model, due e.g., to the sparseness of the data. To get better models in such cases, more constraints on the model are needed. This paper shows how explicit topological constraints can be imposed within the context of probabilistic la-tent variable models. We describe two approaches, both within the context of the Gaussian process la-tent variable model (GP-LVM) (Lawrence, 2005). The first uses prior distributions on the latent space that encourage a given topology. The second influences the latent space and optimisation through constrained maximum likelihood.
 Our approach is motivated by the problem of model-ing human pose and motion for character animation. Human motion is an interesting domain because, while there is an increasing amount of motion capture data available, the diversity of human motion means that we will necessarily have to incorporate a large amount of prior knowledge to learn probabilistic models that can accurately reconstruct a wide range of motions. Despite this, most existing methods for learning pose and motion models (Elgammal &amp; Lee, 2004; Grochow et al., 2004; Urtasun et al., 2006) do not fully exploit useful prior information, and many are limited to mod-eling a single human activity (e.g., walking with a par-ticular style).
 This paper describes how prior information can be used effectively to learn models with specific topologies that reflect the nature of human motion. Importantly, with this information we can also model multiple ac-tivities, including transitions between them (e.g. from walking to running), even when such transitions are not present in the training data. As a consequence, we can now learn latent variable models with training motions comprising multiple subjects with stylistic di-versity, as well as multiple activities, such as running and walking. We demonstrate the effectiveness of our approach in a character animation application, where the user specifies a set of constraints (e.g., foot loca-tions), and the remaining kinematic degrees of freedom are infered. We begin with a brief review of the GP-LVM (Lawrence, 2005). The GP-LVM represents a high-dimensional data set, Y , through a low dimensional latent space, X , and a Gaussian process mapping from the latent space to the data space. Let Y = [ y training datum, y i  X  X  X  D . Let X = [ x 1 ,..., x N ] T de-note the matrix whose rows represent the correspond-ing positions in latent space, x i  X  X  X  d . Given a covari-ance function for the Gaussian process, k Y ( x , x  X  ), the likelihood of the data given the latent positions is, where Z 1 is a normalization factor, K Y is known as the kernel matrix, and  X   X  denotes the kernel hyperpa-rameters. The elements of the kernel matrix are de-fined by the covariance function, ( K Y ) i,j = k Y ( x i A common choice is the radial basis function (RBF), k
Y ( x , x  X  ) =  X  1 exp(  X   X  2 2 || x  X  x  X  || 2 ) + kernel hyperparameters  X   X  = {  X  1 , X  2 , X  3 } determine the output variance, the RBF support width, and the vari-ance of the additive noise. Learning in the GP-LVM consists of maximizing (1) with respect to the latent positions, X , and the hyperparameters,  X   X  . When one has time-series data, Y represents a se-quence of observations, and it is natural to aug-ment the GP-LVM with an explicit dynamical model. For example, the Gaussian Process Dynamical Model (GPDM) models the sequence as a latent stochastic process with a Gaussian process prior (Wang et al., 2008) , i.e., p ( X |  X   X  ) = where Z 2 is a normalization factor, X out = [ x constructed from X in = [ x 1 ,..., x N  X  1 ], x 1 is given an isotropic Gaussian prior and  X   X  are the kernel hyper-parameters for K X ; below we use an RBF kernel for K
X . Like the GP-LVM the GPDM provides a gen-erative model for the data, but additionally it pro-vides one for the dynamics. One can therefore predict future observation sequences given past observations, and simulate new sequences. The smooth mapping in the GP-LVM ensures that distant points in data space remain distant in la-tent space. However, as discussed in (Lawrence &amp; Qui  X nonero-Candela, 2006), the mapping in the oppo-site direction is not required to be smooth. While the GPDM may mitigate this effect, it often produces models that are neither smooth nor generalize well (Urtasun et al., 2006; Wang et al., 2008).
 To help ensure smoother, well-behaved models, (Lawrence &amp; Qui  X nonero-Candela, 2006) suggested the use of back-constraints , where each point in the latent space is a smooth function of its corresponding point in data space, x ij = g j ( y i ; a j ), where { a j } 1  X  j  X  d the set of parameters of the mappings. One possible mapping is a kernel-based regression model, where re-gression on a kernel induced feature space provides the mapping, This approach is known as the back-constrained GP-LVM. When learning the back-constrained GP-LVM, one needs to determine the hyperparameters of the ker-nel matrices (for the back-constraints and the covari-ance of the GP), as well as the mapping weights, { a j } . (Lawrence &amp; Qui  X nonero-Candela, 2006) fixed the hy-perparameters of the back-constraint X  X  kernel matrix, optimizing over the remaining parameters.
 Nevertheless, when learning human motion data with large stylistic variations or different motions, nei-ther GPDM nor back-constrained GP-LVM produce smooth models that generalize well. Fig. 1 depicts three 3 X  X  models learned from 9 walks and 10 runs. The GPDM (Fig. 1(a)) and the back-constrainted GPDM 2 (Fig. 1 (b)) do not generalize well to new runs and walks, nor do they produce realistic animations. In this paper we show that with a well designed set of back-constraints good models can be learned (Fig. 1(c)). We also consider an alternative approach to the hard constraints on the latent space arising from g j ( y i ; a j ). We introduce topological constraints through a prior distribution in the latent space, based on a neighborhood structure learned through a gener-alized local linear embedding (LLE) (Roweis &amp; Saul, 2000). We then show how to incorporate domain-specific prior knowledge, which allows us to develop motion models with specific topologies that incorpo-rate different activities within a single latent space and transitions between them. 3.1. Locally Linear GP-LVM The locally linear embedding (LLE) (Roweis &amp; Saul, 2000) preserves topological constraints by finding a representation based on reconstruction in a low dimen-sional space with an optimized set of local weightings. Here we show how the LLE objective can be combined with the GP-LVM, yielding a locally linear GP-LVM (LL-GPLVM). The locally linear embedding assumes that each data point and its neighbors lie on, or close to, a locally linear patch on the data manifold. The local geome-try of these patches can then be characterized by lin-ear coefficients that reconstruct each data point from its neighbors. This is done in a three step proce-dure: (1) the K nearest neighbors, { y j } j  X   X  point, y i , are computed using Euclidean distance in the input space, d ij = || y i  X  y j || 2 ; (2) the weights w = { w ij } that best reconstruct each data point from its neighbors are obtained by minimizing  X ( w ) = P x i best reconstructed by the weights w ij are computed by minimizing  X ( X ) = P N i =1 || x i  X  P j  X   X  In the LLE, the weight matrix w is sparse (only a small number of neighbors is used), and the two minimiza-tions can be computed in closed form. In particular, computing the weights can be done by solving,  X  j  X   X  i , the following system, where C sim kj = ( y i  X  y k ) T ( y i  X  y j ) if j,k  X   X  otherwise. Once the weights are computed, they are rescaled so that P j w ij = 1.
 The LLE energy function can be interpreted, for a given set of weights w , as a prior that forces each latent point to be locally reconstructed by its neigh-bors,i.e., p ( X | w ) = 1 Z exp  X  1  X  2  X ( X ) , where Z is a normalization constant, and  X  2 represents a global scaling of the prior. Note that strictly speaking this is not a proper prior as it is conditioned on the weights which depend on the training data. Following (Roweis &amp; Saul, 2000), we first compute the neighbors based on the Euclidean distance. For each training point y i , we then compute the weights solving Eq. (4). Learning the LL-GPLVM is then equivalent to mini-mizing the negative log posterior of the model, 3 i.e.,
L S = log p ( Y | X ,  X   X  ) p (  X   X  ) p ( X | w ) where C is a constant, and x k i is the k-th component of x i . Note that we have extended the LLE to have a different prior for each dimension. This will be use-ful below as we incorporate different sources of prior knowledge. Fig. 2 (a) shows a model of 2 walks and 2 runs learned with the locally linear GPDM. Note how smooth the latent trajectories are.
 We now have general tools to influence the structure of the models. In what follows we generalize the top-down imposition of topology strategies (i.e. back-constraints and locally linear GP-LVM) to incorporate domain specific prior knowledge. A problem for modeling human motion data is the sparsity of the data relative to the diversity of natu-rally plausible motions. For example, while we might have a data set comprising different motions, such as runs, walks etc ., the data may not contain transitions between motions. In practice however, we know that these motions will be approximately cyclic and that transitions can only physically occur at specific points in the cycle. How can we encourage a model to re-spect such topological constraints which arise from prior knowledge? We consider two alternatives to solve this problem. First, we show how one can adjust the distance metric used in the locally linear embedding to better reflect different types of prior knowledge. We then show how one can define similarity measures for use with the back-constrained GP-LVM. Both these approaches en-courage the latent space to construct a representation that reflects our prior knowledge. They are comple-mentary and can be combined to learn better models. 4.1. Prior Knowledge through Local We now turn to consider how one might incorporate prior knowledge in the LL-GPLVM framework. This is accomplished by replacing the local Euclidean distance measures used in Section 3.1 with other similarity mea-sures. That is, we can modify the covariance used to compute the weights in Eq. (4) to reflect our prior knowledge in the latent space. We consider two exam-ples: the first involves transitions between activities; with the second we show how topological constraints can be placed on the form of the latent space. Covariance for Transitions Modeling transitions between motions is important in character animation. Transitions can be infered automatically based on sim-ilarity between poses (Kovar et al., 2002) or at points of non-linearity of the dynamics (Bissacco, 2005), and they can be used for learning. For example, for mo-tions as walking or running, two types of transitions can be identified: left and right foot ground contacts. To model such transitions, we define an index on the frames of the motion sequence, { t i } N i =1 . We then define subsets of this set, {  X  t i } M i =1 , which represents frames where transitions are possible. To capture transitions in the latent model we define the elements for the co-variance matrix as follows, with  X  a constant, and  X  ij = 1 if t i and t j are in the same set {  X  t k } M k =1 , and otherwise  X  ij = 0. This covari-ance encourages the latent points at which transitions are physically possible to be close together. Covariance for Topologies We now consider co-variances that encourage the latent space to have a particular topology. Specifically we are interested in suitable topologies for walking and running data. Be-cause the data are approximately periodic, it seems appropriate to have a non-Cartesian topology. To this end one can extract the phase of the motion 4 ,  X  , and use it with a covariance to encourage the latent points to exhibit a periodic topological structure within a Cartesian space. As an example we consider a cylindri-cal topology within a 3 X  X  latent space by constraining two of the latent dimensions with the phase. In partic-ular, to represent the cyclic motion we construct a dis-tance function on the unit circle, where a latent point corresponding to phase  X  is represented with coordi-nates (cos(  X  ) , sin(  X  )). To force a cylindrical topology on the latent space, we specify different covariances for each latent dimension
C k,j = (cos(  X  i )  X  cos(  X  k )) (cos(  X  i )  X  cos(  X  j )) (7)
C k,j = (sin(  X  i )  X  sin(  X  k )) (sin(  X  i )  X  sin(  X  j )) , (8) with k,j  X   X  i . The covariance for the remaining di-mension is constructed as usual, based on Euclidean distance in the data space. Fig. 2 (b) shows a GPDM constrained in this way, and in Fig. 2 (c) the covari-ance is augmented with transitions.
 Note that the use of different distance measures for each dimension of the latent space implies that the neighborhood and the weights in the locally linear prior will also be different for each dimension. Here, three different locally linear embeddings form the prior distribution. 4.2. Prior Knowledge with Back Constraints As explained above, we can also design back-constraints to influence the topology and learn useful transitions. This can be done by replacing the ker-nel of Eq. (3). Many kernels have interpretations as similarity measures. In particular, any similarity mea-sure that leads to a positive semi-definite matrix can be interpreted as a kernel. Here, just as we define covariance matrices above, we extend the original for-mulation of back constraints by constructing similarity measures (i.e., kernels) to reflect prior knowledge. Similarity for Transitions To capture transitions between two motions, we wish to design a kernel that expresses strong similarity between points in the re-spective motions where transitions may occur. We can encourage transition points of different sequences to be proximal with the following kernel matrix for the back-constraint mapping: where k ( t i ,  X  t l ) is an RBF centered at  X  t l , and  X  if  X  t m and  X  t l are in the same set. The influence of the back-constraints is controlled by the support width of the RBF kernel.
 Topologically Constrained Latent Spaces We now consider kernels that force the latent space to have a particular topology. To force a cylindrical topology on the latent space, we can introduce similarity mea-sures based on the phase, specifying different similarity measures for each latent dimension. As before we con-struct a distance function in the unit circle, that takes into account the phase. A periodic mapping can be constructed from a kernel matrix as follows, x where k is an RBF kernel function, and x n,i is the i th coordinate of the n th latent point. These two map-pings project onto two dimensions of the latent space, forcing them to have a periodic structure (which comes about through the sinusoidal dependence of the kernel on phase). Fig. 2 (e) shows a model learned using GPDM with the last two dimensions constrained in this way (the third dimension is out of plane). The first dimension is constrained by an RBF mapping on the input space. Each dimension X  X  kernel matrix can then be augmented by adding the transition similarity of Eq.(9), resulting in the model shown in Fig. 2 (f). 4.3. Model Combination One advantage of our framework is that covariance ma-trices can be combined in a principled manner to form new covariance matrices. Covariances can be multi-plied (on an element by element basis) or added to-gether. Similarly, similarities can be combined. Mul-tiplication has, loosely speaking, an  X  X ND gate effect X , i.e. both similarity measures must agree that an ob-ject is similar for their product to express similarity. Adding them produces more of an  X  X R gate effect X , i.e. if either representation expresses similarity the result-ing measure will also express similarity.
 The two sections above have shown how to incorpo-rate prior knowledge in the GP-LVM by means of 1) local linearities and 2) back-constraints. In general, the latter should be used when the manifold has a well-defined topology, since it has more influence on the learning. When the topology is not so well defined (e.g., due to noise) one should use local linearities. Both techniques are complementary and can be com-bined straightforwardly by including priors over some dimensions, and constraining the others through back-constraint mappings. Fig. 1 shows a model learned with LL-GPDM for smoothness and back-constraints for topology. 4.4. Multiple Activities and Transitions Once we know how to ensure that transition points are close together and that the latent structure has the desired topology, we still need to address two issues. How do we learn models that have very different dy-namics? How can we simulate dynamical models that lie somewhere between the different training motions? Our goal in this section is to show how latent mod-els for different motions can be learned independently, but in a shared latent space that facilitates transitions between activities with different dynamics.
 Let Y = [ Y T 1 ,..., Y T M ] T denote training data for M different activities. Each Y m comprises several differ-ent motions. Let X = [ X T 1 ,..., X T M ] T denote the corre-sponding latent positions. When dealing with multiple activities, a single dynamical model cannot cope with the complexity of the different dynamics. Instead, we consider a model where the dynamics of each activity are modeled independently 5 . This has the advantage that a different kernel can be used for each activity. To enable interpolation between motions with different dynamics, we combined these independent dynamical models in the form of a mixture model. This allows us to produce motions that gracefully transition between different styles and motion types (Figs. 3 and 4). We demonstrate the effectiveness of our approach with two applications. First we show how models of multi-ple activities can be learned, and realistic animations can be produced by drawing samples from the model. We then show an interactive character animation ap-plication, where the user specifies a set of sparse con-straints and the remaining kinematic degrees of free-dom are infered. 5.1. Learning multiple activities We first considered a small training set comprised of 4 gait cycles (2 walks and 2 runs) performed by one subject at different speeds. Fig. 2 shows the latent spaces learned under different prior constraints. All the models are learned using two independent dynam-ical models, one for walking and one for running. Note how the phases are aligned when imposing a cylindrical topology, and how the LL-GPDM is smooth. Notice the difference between the LL-GPDM (Fig. 2 (c)) and the backconstrained GPDM (Fig. 2 (f)) when transi-tion constraints are included. Neverthess, both mod-els ensure that the transition points (shown in red and green) are proximal.
 Fig. 1 (c) shows a hybrid model learned using LL-GPDM for smoothness, and back-constraints for topol-ogy. The larger training set comprises approximately one gait cycle from each of 9 walking and 10 running motions performed by different subjects at different speeds (3 km/h for walking, 6 X 12 km/h for running). Colors in Fig. 1 (a) represent the variance of the GP as a function of latent position. Only points close to the surface of the cylinder produce poses with high certainty.
 We now illustrate the model X  X  ability to simulate dif-ferent motions and transitions. Given an initial la-tent position x 0 , we generate new motions by sam-pling the mixture model, and using mean prediction for the reconstruction. Choosing different initial con-ditions results in very different simulations (Fig. 1 (d)). The training data are shown in blue. For the first simulation (depicted in green), the model is initial-ized to a running pose with a latent position not far from walking data. The system transitions to walking quite naturally. The resulting animation is depicted in Fig. 3. For the second example (in red), we initialize the simulation to a latent position far from walking data. The system evolves to different running styles and speeds (Fig. 4). Note how the dynamics, and the strike length, change considerably during simulation. 5.2. Character animation from constraints A key problem in the film and game industry is the lack of tools to allow designers to easily generate an-imations. Traditional techniques such as keyframing are time consuming; an expert can expend days in generating a few seconds of animation. A very useful tool would provide the user with a simple way of gen-erating motions from constraints that she/he defined. Typical constraints are keyframes (i.e., specification of the position of the full body in a particular time instant), or joint trajectories. Here we use the topo-logically constrained motion models as priors over the space of possible motions.
 Our motion estimation formulation is based on a state-space model with a GPDM prior over pose and motion. Given the state,  X  t = ( y t , x t ), the goal is to estimate the state sequence  X  1: T = (  X  1 , , X  T ) that satisfies the user constraints u 1: J . Inference is performed in a Batch mode, so that the state is infered all at once. The posterior can be expressed as where we assumed that p ( u 1: J ) is uniformily dis-tributed; all the user constraints are equally probable. The prediction distribution p (  X  1: T | M ) can be further factored as follows Rather than approximating the entire posterior, we use hill-climbing to find MAP estimates. Assuming that the user constraints are noise-free, the minimization can be expressed as where f is a forward kinematics function (i.e., a function that maps joint angles to positions in the 3D world),  X  ( u ) is a function that outputs the frame where each constraint u j is defined, L pose = the pose and dynamics likelihood from the GPDM prior (Urtasun et al., 2006), and L smooth = age smooth motions, where y j t is the j-th component of y , and  X  2 j is a constant that encounters from the fact that each degree of freedom has a different variance. Initialization is important since a large number of vari-ables need to be optimised and our objective function is non-convex. In particular, we sample the model starting at each training point and use as initializa-tion the sample that is closest to the user constraints. To demonstrate the effectiveness of our approach we learned models of two different motions, walking and jumping (Fig. 5). We impose smoothness and cyclic topologies using back-constraints for the walking and local linearities for the jumping. We demonstrate the ability of the model to generalize to unseen styles. We first show how the model can produce realistic an-imations from a very small set of user defined con-straints. The user specifies the contact points of the foot with the ground (first row of Fig. 6) for walking and the foot trajectories for the jumping (third row of Fig. 6), and the rest of the degrees of freedom are infered producing very realistic animations. The model can also generalize to styles very different from the ones in the training set, by imposing con-straints that can be satisfied only by motions very dif-ferent from the training data. In particular, the user placed the foot constraints far in the coronal plane for walking. Consequently the character opens the legs to satisfy the constraints (second row of Fig. 6). In the last row of Fig. 6 the user places the foot trajectories to create a jump with a style very different from the traning data (the character opens his legs and bends his body and arms in an exaggerated way). In this paper we have proposed a general framework of probabilistic models that learn smooth latent vari-able models of different activities within a shared la-tent space. We have introduced a principled way to include prior knowledge, that allow us to learn spe-cific topologies and transitions between the different motions. Although we have learned models composed of walking, running and jumping, our framework is general, being applicable in any data sets where there is a large degree of prior knowledge for the problem domain, but the data availability is relatively sparse compared to its complexity.

