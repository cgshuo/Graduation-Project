 Customization to specific discourse domains and/or user requirements is one of the greatest challenges for today X s Information Extraction (IE) systems. While demonstrably effective, both rule-based and supervised machine learning approaches to IE customization require a substantial development effort. For example, Aone and Ramos-Santacruz (2000) present a rule-based IE system which handles 100 types of relations and events. Building such a system requires the manual construction of numerous extraction patterns supported by customized ontologies. Soderland (1999) uses supervised learning to induce a set of rules from hand-tagged training examples. While Sonderland suggests that the human effort can be reduced by interleaving learning and manual annotation activities, the creation of training data remains an onerous task. 
To reduce the knowledge engineering burden on the user in constructing and porting an IE system, unsupervised learning has been utilized, e.g. Riloff (1996), Yangarber et al. (2000), and Sekine (2006). Banko et al. (2007) present a self-supervised system that aims to avoid the manual IE customization problem by extracting all possible relations of interest from text. Stevenson and Greenwood (2005) propose a weakly supervised approach to sentence filtering that uses semantic similarity and bootstrapping to acquire IE patterns. Stevenson X s and Greenwood X s approach provides some of the best available results in weakly supervised IE to date, with 0.58 F-measure. While very good, an F-measure of 0.58 does not provide sufficient reliability to grant use in a production system. 
In this paper, we show that it is possible to provide a significant improvement over Stevenson X s and Greenwood X s results, without increasing resource requirements, by integrating fully-supervised learning techniques within a weakly supervised IE approach. 1.1 Learning Algorithm Our method is modeled on the approach developed by Stevenson and Greenwood (2005) but uses a different technique for ranking candidate patterns. Stevenson X s and Greenwood X s algorithm takes as data inputs a small set of initial seed patterns and a corpus of documents, and uses any of several semantic similarity measures (Resnik, 1995; Jiang and Conrath, 1997; Patwardhan et al., 2003) to iteratively identify patterns in the document corpus that bear a strong resemblance to the seed patterns. After each iteration, the top-ranking candidate patterns are added to the seed patterns and removed from the corpus. Our approach differs from that of Stevenson and Greenwood in that we use a supervised classifier to rank candidate patterns. This grants our system greater robustness and flexibility because the weight of classification features can be automatically determined within a supervised classification approach. 
In building supervised classifiers to rank candidate patterns at each iteration, we use both positive and negative training examples. Instead of creating manually annotated training examples, we follow an active learning approach where training examples are automatically chosen by ranking candidate patterns in terms of cosine similarity with the seed patterns. More specifically, we select patterns that have the lowest similarity with seed patterns to be the negative training examples. We hypothesized that these negative examples would contain many of the uninformative features occurring throughout the corpus and that using these examples would enable the classifier to determine that these features would not be useful. 
The pattern learning approach we propose includes the following steps. 1. An unannotated corpus is required as input. 2. The user defines a set of seed patterns, S seed 3. The cosine measure is used to determine the 4. The  X  highest ranked patterns in S cand 6. The classifier is used to score each pattern in 7. The top  X  patterns in S cand are added to S 8. If a suitable stopping point has been reached, We set  X  to 5,  X  to 20,  X  to 15,  X  to 5, and used the following linguistic processing tools: (1) the OpenNLP library (opennlp.sourceforge.net) for sentence splitting and named-entity recognition, and (2) Connexor for syntactic parsing (Tapanainen and J X  X vinen, 1997). For the classifier, we used the OpenNLP MaxEnt implementation (maxent.sourceforge.net) of the maximum entropy classification algorithm (Berger et al. 1996). We used the MUC-6 data set as the testing ground for our proposed approach. 1.2 Description of Features Used Stevenson and Greenwood (2005) use subject-verb-object triples for their features. We use a richer feature set. Our system can easily accommodate more features because we let the maximum entropy classifier determine the weight for the features. Stevenson X s and Greenwood X s approach determines weights using semantic similarity and would require significant changes to take into account various other features, especially those for which a WordNet (Fellbaum, 1998) similarity score is not available. 
We use single tokens, token combinations, and semantic information to inform our IE pattern extraction system. Lexical items marked by the named-entity recognition system as PERSON or ORGANIZATION are replaced with  X person X  and  X organization X , respectively. Number tokens are replaced with  X numeric X . Single Token Features include:  X  All words in the sentence and all hypernyms of  X  All words in the sentence with attached  X  The verb base of each nominalization and the Token Combinations include:  X  All bigrams from the sentence  X  All subject-object pairs  X  All parent-child pairs from the parse tree  X  A specially marked copy of the parent-child We also added semantic features indicating if a PERSON or ORGANIZATION was detected within the sentence boundaries. Table1 provides an example where a simple sentence is mapped into the set of features we have just described. 
The seeds we used are adapted from the seed patterns employed by Stevenson and Greenwood. As shown in Table 2, only a subset of the features described above is used in the seed patterns. We used the document collection which was initially developed for the Sixth Message Understanding Conference (MUC-6) as ground truth data set to evaluate our approach. The MUC-6 corpus ( www.ldc.upenn.edu ) is composed of 100 Wall Street Journal documents written during 1993 and 1994. Our task was to detect sentences which included management succession patterns, such as those shown in Table 2. The version of the MUC-6 corpus produced by Soderland (1999) provided us with a specification of succession patterns at the sentence level, but as shown in Table 3 did not include the source text. automatically aligning the succession patterns in the sentence structures in Soderland X s version of the MUC-6 corpus with the sentences in the original MUC-6 corpus. This alignment produced a set of 1581 sentences, of which 134 contained succession patterns. 
As shown in Figure 1, our best score of 0.688 F-measure was obtained on the 36 th iteration; at the end of this iteration, our algorithm selected 180 sentences including 108 of the sentences that contained succession patterns. This is a significant improvement over the 0.58 F-measure score reported by Stevenson and Greenwood (2005) for the same task. The use of a supervised classification approach to the ranking of candidate patterns with a richer feature set were the two determinant factors in achieving such improvement. Our results show a substantial improvement over previous efforts in weakly supervised IE methods, suggesting that weakly supervised methods can be made to rival rule-based or fully supervised approaches both in resource effectiveness and accuracy. We plan to verify the strength of our approach evaluating against other ground truth data sets. We also plan to detail how the various features in our classification model contribute to ranking of candidate patterns. An additional area of envisioned improvement regards the use of a random sub selection of negative candidate patterns as training samples to counteract the presence of sentence fragments among low-ranking candidate patterns. Finally, we intend to evaluate the benefit of having a human in the loop in the first few iterations to filter out patterns chosen by the system. 
