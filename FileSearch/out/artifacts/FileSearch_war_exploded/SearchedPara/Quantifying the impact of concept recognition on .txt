 1. Introduction
Methods for the automatic recognition of named-entities in text have been investigated for a wide range of tasks. One aim tation . These tagging methods use natural language processing to identify named-entities in the text, and assign a concept type to each entity. That is, a label from a controlled vocabulary is associated with a term or phrase in a text, thus creating an annotation. For example, the ambiguous term  X  X range X  might be tagged as fruit or color , depending on the context. Text annotation has been studied for applications such as information extraction ( Kulick et al., 2004 ); event tracking ( Jin, ( Merialdo, 1994 )  X  and how the entities are tagged.

For ad hoc IR, particularly in the context of a narrow domain where concept recognition may be reasonably accurate, it seems plausible that the assigned tags may help to improve effectiveness. Tagging can be applied to both queries and doc-uments, and provides additional evidence of similarity. Even if a particular concept term is fairly common in the collection, the use of tags may help to eliminate irrelevant documents that have the right terms but the wrong concepts, and thus boost effectiveness. These tags could be used in several ways, for example as metadata, or simply as additional document terms.
We explore these alternatives below.  X 
Application of IR to domains such as genomics, law, and chemistry has encouraged investigation of the value to IR of lan-guage processing tools such as part-of-speech taggers, named-entity recognizers, and concept mappers ( Aronson, Rindflesch, from using a tool such as a named-entity recognizer, as well as what tasks are likely to benefit and under what conditions.
In this paper, we report our investigation into the usefulness of named-entity recognition in the context of domain-spe-cific ad hoc IR tasks developed by the TREC Genomics track ( Hersh, Cohen, Roberts, &amp; Rekapalli, 2006; Hersh, Cohen, Ruslen, meaning) and polysemy (terms having more than one meaning) in the medical domain. Tagging of medical terms to their representative medical concepts, therefore, is a plausible approach to resolve ambiguity. For example, the term  X  the sentence fragment  X  X urine P 202 is an interferon-inducible primarily nuclear X  can be tagged with protein , potentially helping to retrieve this text in response to a query such as  X  X ame a protein X .

The TREC resources allow us to empirically measure the impact on effectiveness of concept recognition using a controlled vocabulary. We use tags (manual and automatic) as content terms and as metadata; in the context of passage retrieval; and as a mechanism for choosing query terms. We inspect results and relevant documents to manually assess the potential of tags. In none of these experiments could we demonstrate that tags might lead to improved effectiveness. Only in unrealistic scenarios, such as having only relevant documents manually tagged, is there a substantial improvement in effectiveness.
There are several potential causes, but the most significant is that the potential benefit of concept recognition is highly di-luted because so many documents share similar general concepts. We conclude that there is little likely benefit to further exploration of the kind of general concept tagging used in TREC Genomics and elsewhere. 2. Background
The main task of named-entity recognizers is recognition of named-entities  X  that is, locating the boundaries of a word sequence that are thought to represent a concept  X  and then assignment of a concept tag to that text span. The task of tag-ging proper names in newswire text has been successful with accuracy approaching human performance ( Zhou &amp; Su, 2001 ), but other tagging is not as advanced ( Zhao, 2004 ). For example, in the biomedical domain one of the widely used concept mappers, MetaMap Transfer (MMTx 1 ), has low accuracy ( Guy, Tse, &amp; Laura, 2004 ) and is extremely slow. MMTx maps free-text words (or phrases) to their corresponding concepts in the UMLS Metathesaurus. Pratt and Yetisgen-Yildiz (2003) also found that human usage of medical concept terminology in biomedical articles has around 60% overlap with the UMLS terminology. There-fore, tagging MEDLINE articles with MMTx is unlikely to yield enough coverage of the mentioned concepts. MMTx, focusing on micro-biology.

Biomedical information extraction studies have used this tagger to extract the relationship between different entities, such as protein X  X isease or protein X  X rotein. Note that this is a different task to information retrieval, where only broad infor-mation on what concepts are covered in a text is of importance.

A key reason that tagging of concept terms is attractive for Genomic IR is that it potentially provides disambiguation of specialized terms. For example, ICAM 1 can refer to a gene, protein, or antibody; determination of the correct sense must be discovered from the context. Resolution of ambiguity in IR has been explored in studies that investigate the impact of dif-ferent methods of sense disambiguation. Some studies examined choice of disambiguation method (such as use of a dictio-nary or WordNet) on a retrieval task and showed little or negative impact on retrieval performance. Other studies examined questions of how accurate a word sense disambiguator must be to assist retrieval, what sort of queries may need disambig-uation, and what test collections should be used in empirical studies ( Krovetz &amp; Croft, 1992; Sanderson, 1994, 2000, 2008;
Sanderson &amp; Rijsbergen, 1999; Voorhees, 1993 ). These show, in agreement with results we report later, that queries with enough details do not require disambiguation.

Tagging of proper names, such as people names, places, and organizations, has been studied for IR as a potential method ell, 1997). Another stream of IR that has actively examined the effect of disambiguation of named-entities is geographical IR (GIR). In the context of GIR, once named-entities are recognized and tagged as a location, then another level of disambigu-ation, called toponym resolution, allocates a label to differentiate them in terms of their location the world. Despite the suc-cess of toponym resolution reported in the literature ( Garbin &amp; Mani, 2005 ), application to IR tasks has not proved to be consistently beneficial, and its usability is both query-and collection-dependent ( Li, Moffat, Stokes, &amp; Cavedon, 2006 ).
Another application of tagging is to enrich text with metadata. Search in resources such as digital libraries makes use of manual or automatically extracted metadata to help resolve queries ( Deniman, Sumner, Davis, Bhushan, &amp; Fox, 2003; Kim, metadata has been shown to increase precision, when given index terms of sufficiently high quality. In full-text search, how-ever, this positive effect is not universally observed, with mixed results reported.
 In the biomedical domain, use of metadata in both text retrieval and question-answering systems has been investigated.
Much of this work concerns reformulation of queries using the MeSH (Medical Subject Headings) ontology, motivated by the availability of human-created metadata (based on the current MeSH terms) for all the bibliographical information available in
MEDLINE . As for studies in digital libraries, much of the research is focused on whether to include metadata in the search engine X  X  index and, if it is included, how to combine it with free text information in the ranking algorithm. Abdou and Savoy (2008) explored the idea of using manually assigned MeSH headings in the data (a subset of MEDLINE and 50 queries). In TREC Genomics 2004, queries were chosen from interviews with biologists on their search needs. Each query consisted of a title, need, and context. Using MeSH headings as part of the documents to be retrieved (that is, treating them as ordinary document terms) led to improvements in MAP score over the baseline of searching title and abstract only.

Lu, Kim, and Wilbur (2009) explored the use of MEDLINE metadata in the 2006 and 2007 TREC Genomics framework, by using PubMed to expand query terms, for example by addition of the terms X  MeSH subheadings. They showed that, although the use of metadata can improve recall in the PubMed set of retrieved documents, precision is largely unchanged or reduced.
Hersh and Greenes (1990) proposed a concept-finding algorithm as part of their SAPHIRE retrieval system. Terms in que-ries and documents are allocated to a concept class, using a string-matching approach to allow for robust matching with vocabulary entries in a manually created knowledge structure of medical concepts and synonym terms. In later versions of the system, this manual knowledge structure was replaced with the UMLS Metathesaurus. At retrieval time, the ranking of documents is based on the inverse document frequency of concepts, rather than full-text terms. Evaluation of SAPHIRE is reported by Hersh and Hickam (1995) . Over a series of user studies that included librarians, clinicians and medical students, it was found that concept-based automated indexing did not appear to offer benefits over the indexing of single words on average. However, failure analysis of particular searches indicated that the indexing of synonyms can lead to better retrieval performance in some cases. Generally, the benefits from the use of specific knowledge structures and concept ontologies ap-pear to be dependent on the experience of the user: for librarians who were experienced with MeSH terms, search perfor-mance was improved, while for clinicians who were less familiar with MeSH, no benefits were found.

Aronson et al. (1994) investigated biomedical information retrieval using concept mapping. The main reason of past unsuccessful concept-based information retrieval was considered to be poor mapping of the text and its concepts. Therefore, different types of matching between noun phrases and the UMLS Metathesaurus entries were investigated (exact, partial, and complex match). On a collection of 3000 MEDLINE citations and 150 queries, they showed improvements in retrieval per-formance (average precision increased by 4%) when adding the Metathesaurus concepts to the text.

Srinivasan (1996) explored query expansion using MeSH on MEDLINE and MeSH headings), best results were achieved when query expansion was based on a combination of relevance feedback and MeSH subject headings. Srinivasan (1996) also showed that using only a thesaurus for expansion is not effective, unless combined with feedback.

Horii, Imai, and Chihara (1999) investigated the impact of disambiguating query terms by using hierarchical concepts as part of the retrieval process. Using an electronic dictionary, key terms in documents are annotated with concept terms, to form a  X  X oncept space X . Queries are then similarly annotated, and retrieval is based on the overlap of entries in the respective concept sets. Evaluation of the system was carried out using a small test collection of 15 journal papers, and suggested that the system is able to achieve a high level of recall due to the inclusion of concepts, but no comparison to a baseline system that did not make use of concept annotation was included.

Concept tagging of documents was also investigated by Trieschnigg, Kraaij, and Schuemie (2006) , who added concept tags to terms in queries and documents by matching sequences of words with entries in the UMLS Metathesaurus. Document retrieval was carried out by using the concepts in a unigram language model with Jelinek X  X ercer smoothing. Results on the 2004 TREC Genomics Track collection indicated that concept matching led to worse performance than using the original terms, based on document level mean average precision. On the 2006 collection, the performance of the concept and term-based language models was equivalent. The authors conclude that concept tagging is highly sensitive to the content of the topics and collection, as well as the collection size.
 The use of automatic concept tagging for the pruning of candidate items from an initial retrieval run was explored in the
TREC Genomics Track framework by Cohen, Yang, Fisher, Roark, and Hersh (2007) . The MMTx NLP tagger was used to mark up candidate passages, which were then weighted based on how often entity phrases related to the query occurred. Passages with low occurrence rates were then removed from the ranked list. While the tag-based passage pruning step had a positive impact on retrieval performance when relevant passages (rather than documents) are evaluated, Cohen et al. (2007) point out that full NLP processing with MMTx is very expensive in terms of computation time, slowing their system from a real-time retrieval engine to requiring overnight runs. Complex tagging approaches can therefore add a non-trivial overhead to the retrieval process.
 Stokes et al. (2007) , in their experiments of TREC Genomics 2007 track, reported query expansion using relevance feedback.
The queries were expanded using entities of highly ranked passages annotated by three different tools: MMTx, BioTagger,
MutationFinder. 4 In addition, a normalized ranking method was used to differentiate the concept terms and general terms. Their results showed significant improvements only in document-level retrieval, while passage retrieval did not benefit.
Zhou, Yu, and Meng (2008) proposed a system for finding biological entities using gene symbol disambiguation, expan-sion using the UMLS Metathesaurus, passage reduction, and conceptual information retrieval. They used the PubMed search interface and Entrez Gene to expand TREC Genomics 2007 queries with MeSH headings and gene name variants. Documents were also parsed to identify concepts in fixed length windows. As in the work of Stokes et al. (2007) they define a weighted ranking function that differentiated concepts and content terms. They reported improvements in retrieval effectiveness using all these methods over a baseline of simply executing original queries with no change in documents. Overall, the improvements are due to a combination of all these methods, and not only concept identification. The contribution due to concept identification is unclear.
 Trieschnigg et al. (2009) compared the performance of different MeSH classification systems, such as MetaMap and K-
Nearest Neighbor (KNN), to produce the MeSH headings for MEDLINE expand TREC Genomics queries (2004 X 2007) with MeSH headings, and their experimental results show that using only
MeSH can hurt retrieval performance. Tuning did yield small improvements with significance in 2 out of 24 cases (they do not appear to have applied a correction for multiple comparisons). Meij, Trieschnigg, de Rijke, and Kraaij (2010) in a recent study investigated conceptual language models in domain-specific information retrieval. They proposed a con-cept-based language model based on a relevance model that uses pseudo-relevance feedback. Five collections were used for the experiments. Three of the collections were from the TREC Genomics tracks (2004 X 2006) from which the authors used human-annotated MeSH headings as document concepts. The other two collections were domain-specific CLEF 2007 and 2008 data consisting of human-annotated psychological abstracts. Query concepts were decided using an
Expectation-Maximization algorithm using documents that were selected based on pseudo-relevance feedback. Mixed results on precision and recall were reported when comparing these approaches with two baselines: a query-likelihood model, and relevance models using pseudo-relevance feedback. A statistically significant improvement is shown for re-call on the CLEF 2008 collection. Early precision improvements are also reported for TREC Genomics, depending on the baseline.
 In general, the tagging literature therefore includes instances where tagging leads to some gains in retrieval effectiveness.
However, despite a large number of varying approaches, no consistent improvements have been demonstrated. Moreover, a question that these studies leave open is the extent of improvement that concept recognition might yield in ideal conditions.
It is this question that we explore below. 3. Methods
Our aim is to establish the potential value of tagging for domain-specific information retrieval. Our experiments primarily make use of standard data collections and search methods, in particular collections that have been manually tagged. We de-fine a tag t as a label that belongs to a finite set T of labels, which is the set of concept types. In biomedical querying, the concepts might be genes, proteins, cells, DNA, and RNA; often the relations between these concepts is important ( Hatzivass-iloglou, Duboue, &amp; Rzhetsky, 2001; Kulick et al., 2004 ).

A query Q may contain two types of terms: content terms w , and tag labels t 2 T . We represent a tagged content term by content terms and tag terms. Documents are similar. For example, we might have a tag (or label) gene , which is also likely to be a content term in a query or document.
 Given queries, documents, and tags, we can explore the limits of the benefit of concept recognition in several ways: Tags can be used as document terms, or as metadata.
 The use of tags can be Boolean or weighted.
 Tags can be used as terms, but drawn from a distinct vocabulary.
 The likely selectivity of tags can be examined, by considering their prevalence in the collections.

The expressive power that tags add to the query can be explored by systematically varying the query, to see how effec-tiveness varies.
 Failure analysis can be used to see if tagging would have been likely to alter a ranking.

We consider all of these approaches in the results reported below. 3.1. Data and measurement
To investigate the use of tagging we use the TREC Genomics 2006 and 2007 testbeds. The document collection used for both consists of around 162,000 full-text articles from 49 medical journals, giving around 12 gigabytes of data ( Hersh et al., 2007 ).
The query sets used for 2006 and 2007 have different properties. TREC Genomics 2006 includes 28 queries of mixed entity in Table 1 . The queries are not marked up and thus each can be considered as a set Q ={ w
As two of the items in each query are concept terms, manual tagging of these queries by human judges leads to queries with two tags, Q 0 ={ w 1 , ... , w i : t 1 , ... , w j : t 2 , ... , w plus disease , thus the query might be tagged as  X  X hat is the role of MMS2 [GENE] in cancer [DISEASE]? X .

TREC Genomics 2007 includes 36 queries, with a set of 14 different tag (or concept) types, such as antibodies, biological substances, and cell or tissue types, also shown in Table 1 . Each query has only one concept type marked. Unlike 2006, here queries do not contain instances of those marked concepts, that is, they are in the form of Q ={ w is that we are interested in certain concepts queried in the available collection without knowing their instances. All the que-ries are questions based on the information needs of biologists ( Hersh et al., 2007 ) and the answers are named-entities of a given type or a text span representing a concept. For example, one query is  X  X hat [MUTATIONS] in the Raf gene are associ-ated with cancer? X , where the query type is mutation .

For the two testbeds, relevant passages in the documents were identified using a pooling process: all potentially relevant passages identified by search systems that participated in the 2006 and 2007 tracks were grouped together and judged by human assessors. The passages were judged for relevance, and also manually tagged by human experts ( Roberts, Cohen, &amp;
Hersh, 2009 ), though only those terms that are pertinent to the query are tagged. For example, for a document that is rel-evant to a query about finding a protein name, only the references to that protein are tagged. There are no tags in irrelevant documents. We use these concept tags directly in retrieval, and also use them to generate artificial tags in other documents, as explained in Section 4.2 . Furthermore, individual concepts (or entities) of the search topics were identified by the rele-vance assessors using controlled vocabularies. All identified relevant passages were assigned with such aspect labels (used for some evaluation measures, as explained below). For the 2006 and 2007 testbeds, there were an average of 88.9 and 40.2 relevant documents per query, respectively. For our retrieval experiments, we use the Zettair search engine
BM25 ( Walker, 1997 ) as the similarity measure. Armstrong, Moffat, Webber, and Zobel (2009) showed that BM25 is a very effec-tive similarity measure.

In the ranking function, we did not weight tag terms differently to content terms. While tuning the inclusion of concept terms is plausible and could yield improvements, it adds more parameters to the experiments that are designed to investi-gate the potential value of concept recognition. Our later results indicate that weighting is unlikely to help when the con-ceptual terms are not discriminative.

Search systems are commonly evaluated based on their precision (number of relevant documents retrieved as a propor-tion of the total number of documents retrieved) and recall (number of relevant documents retrieved as a proportion of the total number of relevant documents in the collection). Average precision is the mean of the precision values at each relevant item that is returned in response to a query. Over a set of queries, the mean of these average precision values is calculated, giving the mean average precision (MAP). In this paper, we report MAP at both the passage level (where individual passages were assessed for relevance), and at the document level (a document is defined to be relevant if it contains at least one rel-evant passage). We also report aspect MAP , which measures the average precision for the aspects of a topic; here, different paragraphs that contain information on a repeated aspect are removed from the evaluation ( Hersh et al., 2007 ). 4. Results
As described above, we use a variety of approaches to explore the potential impact of concept recognition. 4.1. Distribution of concept tag terms
As a first step, we sought to estimate the usefulness of tagging for the disambiguation of documents. From the collection, after stemming a document contained terms { w 1 , ... , w the corresponding tag. If a tag, such as biological substance , contained more than one word, we expected to see all of its con-stituent words in the document as a phrase. This process is admittedly simplistic, but does give a crude measure of the topic coverage of the collection, and it is reasonable to suppose, for example, that a good proportion of the documents that use the term  X  X rotein X  will concern the concept protein .

In the TREC collections, the large majority of documents match more than one distinct tag, with 57.4% for 2006 and 94.6% for 2007. For 2006, nearly 19% of all documents have no tag terms. In 2007, only 2.7% of the documents have no tag terms, while the maximum frequency of tag matches is 990 for one document. Therefore, before any tagging of documents is carried out, most documents (81.0% in 2006 and 97.3% in 2007) already contained at least one concept tag as a content term.
Thus, if tagging is simply used to add new content terms, the likely impact will at best be small. These terms are already common in the collection, and the likelihood is that a document that concerns a concept will have that concept as a content term. If tagging is used to add metadata that is used as an additional ranking term, the likely contribution to document scores will be small, even if only a moderate fraction of the documents with a concept term are also tagged with that term. If the metadata is used as a Boolean restriction, there is however some chance that the set of candidate documents will be reduced enough for similarity to be significantly affected, a possibility we explore in experiments reported later.
In addition to these general distribution trends, it is informative to examine how the tag terms are spread among the clas-ses of relevant and irrelevant documents. Based on the 2006 relevance judgments and set of tags, on average 46.5% of the irrelevant documents contain the tag terms, compared to 63.4% of the relevant documents. For 2007, these numbers are 47.8% and 80.3%, respectively. We can also calculate the proportion of relevant documents that would not be retrieved with-out tagging (that is, if documents are Not Tagged, no other words are in common between document and query). For the 2006 collection, this holds for only 0.4% of relevant documents; for 2007, it is only 0.005%.

Thus tag terms occur somewhat more frequently in relevant documents than in irrelevant documents, though note also that irrelevant documents outnumbers relevant documents by a factor on the order of 1000. Without annotation, the rele-vant documents would nearly all still be retrievable (though not necessarily highly scored), because of the overlap of other terms between the queries and documents.

If concept tags are useful, their presence or absence should be influenced by whether a document is relevant. Analyzing recall by sorting documents by the number of tags that they contain (for example, documents with 103 tag occurrences are ahead of those with 102, and so on) gives a broad picture of whether tags are informative. Fig. 1 shows recall against doc-uments, ordered by the overall frequency of tags in each document. On average (the dark line), tag term frequency appears to be related to relevance; recall grows rapidly at first, and then slows down after around 30,000 documents. A correlation of q = 0.84 (Pearson) confirms this observation. However, for some concept types  X  for example, drugs and genes  X  there ap-pears to be no relationship between relevance and tag frequency. A likely explanation is that, for example, 91.4% of the irrel-evant documents and 99.5% of relevant documents contain the word  X  X ene X , and the concept therefore does not help to discriminate between relevant and irrelevant documents.

We can conclude that concept tags, where they occur as content terms, do provide a weak indication of relevance. How-ever, for tags to provide a significant improvement in effectiveness here, it would be necessary for only a small proportion of the irrelevant documents to be tagged. The above analysis of tag term occurrence indicates that this is unlikely. 4.2. Tagging for ranking
To assess the impact that tagging could have on the effectiveness of an IR system, we first considered a  X  X erfect tagging X  scenario in which only the relevant documents are tagged, and that within a document only the relevant entities are tagged.
This should set an upper bound on what one would expect to achieve with annotation of concept terms that are expressed explicitly in the queries. Indeed, it is a generous upper bound: it assumes that the only tagged terms are those that are per-tinent to a given query, that tagging is only used in relevant documents, and that the tagging is error-free.
Varying any of these assumptions is likely to degrade effectiveness. Note that it is in general not feasible to automatically tag large collections, due to the cost of tagging and the lack of appropriate training resources. Nor is tagging particularly accurate in the domain we are considering. Also, note that we have not used query expansion methods, which could plau-sibly have a similar effect (for example, in an ideal case tag-equivalent terms might be added as expansion terms to a query), and thus make tagging unnecessary.

As explained above, the two sets of queries used here have very different characteristics. The first set (2006) does not explicitly name the entity type in the queries, with the types being specified by human experts. In this case, tagging docu-ments with similar tags would arguably help to associate the query with possible relevant documents.

The second set of queries (2007) explicitly specifies the main entity types, with no instance of those entities in the que-ries. For example, in the query  X  X hat [MUTATIONS] in the Raf gene are associated with cancer? X , tagging all the instances of the mutations in the document collection may increase the chance of discovering the relevant texts. However, as can also be seen in this example, other entity types are present in the query (a gene and a disease) that are not directly marked up.
Table 2 shows effectiveness results for the TREC 2006 and 2007 data sets, with tagging switched on or off in queries and documents, and tags treated as content terms. These experiments represent the best possible case for allocation of tags, which have been manually added only to relevant documents. We use both document and passage retrieval, and, in case of passage retrieval, aspect MAP is reported as well as standard MAP.

For the 2006 task, the baseline was when query and document were both untagged. Non-trivial improvement is seen when both documents and queries are tagged, in both document and passage retrieval. Other cases (documents tagged or queries tagged only) either harmed the performance or left it unchanged. The improvements, although statistically signifi-cant, are very small. That is, if we only enhance the relevant documents by adding concept tags of query terms (which is an idealized case and not possible in practice), then we can expect the MAP score to be increased by 0.026 (significant using paired t -test with 95% confidence level) in document retrieval.

The 2007 queries show different trends. Note that here tagged queries against the untagged collection are the baseline, since this is the format of the original queries, with a MAP score of 0.236. Tagging the relevant documents with ideal tags improved this baseline by 0.069 (significant at the 98% confidence level) for document retrieval. Passage-level retrieval was harmed significantly with the same setting.

To explain the problem from another angle, we also tagged the 2006 relevant documents using the MMTx concept map-per. Querying the collection using original queries (no tag) and hand-tagged queries led to MAP scores of 0.353 and 0.383 respectively, neither of which was a significant improvement over the baseline. That is, even the use of another tagging ap-proach (named-entity identification) was unhelpful.

Overall, while in some cases there are significant improvements, in other cases we observe a decline in effectiveness. Tag-ging does not lead to consistent gains, even in this unrealistic ideal case. 4.3. Tags as metadata
In contrast to some other applications of search, such as retrieval of web documents, metadata is widely used in the search of biomedical articles. For example, the MeSH ontology is used to annotate documents and is under continuous refine-ment, and many published searches (see for example the Cochrane collaboration, www.cochrane.org ) make extensive use of this metadata. These searches are on database-like resources such as nal articles in the life-sciences and biomedical domains.

From an IR perspective, it is plausible that, for example, restricting search to those documents that have an appropriate concept tag as metadata could significantly improve effectiveness. There is no text collection that is fully tagged by human of approximations to such a collection, as we explore in this section.

Our approach was to simulate, as much as the available data would allow, the situation where tags were treated as meta-data and therefore could be used for Boolean matching of the documents. Using the 2007 data, two variants of queries were used: (a) the original TREC queries that are tagged based on one main concept only, using one of the types listed in Table 1 concept types (referred to as all concepts , or AC). For example, the query  X  X hat pathways are involved in Ewing X  X  sarcoma? X  for option (a) would be transformed to  X  X hat pathways [TAG:PATHWAYS] are involved in Ewing X  X  sarcoma? X  and for option (b) would be  X  X hat pathways [TAG:PATHWAYS] are involved in Ewing X  X  sarcoma [TAG:DISEASE]? X 
The document collection was tagged with the same notation as the queries. We report three different variants for tagging documents: Only relevant documents are annotated .
 All documents are tagged .
 All documents are randomly tagged.

Results are reported in Table 3 . There is a clear improvement over the baseline (no tagging) when only relevant docu-ments are tagged  X  however, this is hardly surprising, given that the only documents that can be retrieved are those that are relevant to one of the queries. These results are not representative of any possible performance in practice. Note however the difference between the two types of queries. When all the concepts  X  in the scope of valid concepts for the task  X  are tagged, MAP score decreases from 0.513 to 0.470. This suggests that additional clarification of the concepts in a query beyond the first concept does not lead to better retrieval. The same trend was observed in the other pairs of experiments.
The next set of experiments, where tags have been simplistically added to irrelevant documents but  X  X  X erfectly X  X  added by human annotation to relevant documents, suggests that tags as metadata can indeed be helpful, with an improvement in
MAP from 0.236 to 0.322 (taking the case of all query concepts being tagged as the most realistic). This result does keep open the possibility that a tagging technique that is reasonably accurate, and that can be consistently applied to documents and queries, might lead to greater effectiveness.

Whether such a high quality of tagging is achievable is unknown. The existing concept taggers for biomedical text are not accurate for all interesting medical concepts. Named-entity (NE) recognition, a possible preprocessing step for some taggers, 2005 ) has a F -score of 71.4%. 7
Given the fact that, for most concepts, the number of pertinent documents is greatly outweighed by the number of non-pertinent ones, taggers must be highly accurate to avoid introducing more errors than they correct. In other words, a small proportion of badly labelled documents will be more numerous than the correctly labelled documents. Our experience with automatic tagging strongly suggests that such accuracy remains remote.

It is also important to note that the previous result with tags as metadata is distorted by the fact that the relevant doc-uments have been tagged by hand. When all documents, relevant and irrelevant, are consistently tagged based only on the existence of tag terms in texts, effectiveness is reduced to 0.236, which is equivalent to the baseline. Inspecting the relevant documents showed that 5.4% in total lost their tags in this process. Remarkably, this approach is little different from that achieved by random assignment of tags to documents.

We did not have a fully tagged collection to confidently conclude that in the given task, document retrieval of specialized text, tagging does not assist. However, our experiments provide strong evidence that the popularity of generic concepts in such collections limits any advantage that tagging of those concepts might confer.

To further examine whether tagging might be effective as metadata, we examined 10 highly-ranked irrelevant documents from the baseline runs, to see whether they would be likely to be annotated with the appropriate concept tags. That is, we wished to know whether a human would allocate the tags that had been allocated to the relevant documents. In total, all of these documents had at least one similar pertinent concept, and would have had the tags from the query assigned. Thus tag-ging would not have been effective in eliminating these documents from the query results.

We repeated the experiments in Table 3 allowing only one tag of each type to be allocated to each document. Even if, for example, a protein name was repeated multiple times, the tag [TAG:PROTEIN] was added only once. The first scenario, where only relevant documents were tagged using human judgments, performance was improved significantly to MAP of 0.821 and 0.799 for SC and AC queries respectively. However, for the realistic approach where all documents (relevant and irrelevant) were tagged, no improvement over the baseline is gained (0.239 and 0.233 MAP scores for
In our view this is perhaps the critical result of our paper. Although it is a simple experiment, it provides direct evidence that tags would not discriminate between relevant and irrelevant documents, in the context of what are reasonably infor-mative queries. We now explore the question of the power of the original queries. 4.4. Query content and length
If tags are not particularly helpful in selecting relevant documents, it may be because the queries are (by web search stan-dards) relatively long and informative. It is therefore interesting to explore the extent to which the individual query terms, which sit on a spectrum from specific to general, contribute to query effectiveness.
 Two example queries and, for each, some potential alternatives formed by sub-selecting query terms, are shown in Fig. 2 .
Recall is plotted against documents sorted by decreasing Okapi BM25 similarity score in Fig. 3 . These results show that the presence of concept tag terms in the queries did not contribute to the ranking of the relevant documents towards the top of the retrieved list. For example, in query 200, the only word that contributes to retrieving relevant documents is lupus . Given however, is that having long queries is not necessarily helpful  X  it may be that effectiveness is due to just a few key terms.
We further investigated query informativeness by generating all possible sub-query combinations of lengths 1 to m +1 for each query Q ={ w 1 , ... , w m , t } in the 2007 query set (after removal of a small number of stopwords). We recorded the MAP obtained by each sub-query, and the sub-query length.

A comparison of the original queries and their best sub-queries is shown in Fig. 4 . The average length of queries in the 2007 set was 9.6 words. Queries that led to maximum MAP had an average length of only 2.4 words. Literature in informa-tion retrieval has extensively investigated the impact of query length and content on retrieval effectiveness, especially com-paring the traditional TREC style queries with title, description, and narratives and real users queries submitted to search 2010 ). However, our experiments reported in this section are focused on finding which query terms and concepts are respon-sible for retrieving the relevant documents and whether or not these influential terms are potential tag terms.
Analyzing the results showed that only 6 of the 36  X  X  X est X  X  sub-queries contained a tag term. Five of the six sub-queries that had tag terms belonged to the gene query type, and one was a pathways type. Therefore, in 30 of 36 queries, the tag term was not helpful, and as can be seen in some cases, removal of terms dramatically improved effectiveness. In five cases, the most effective query consisted of a single term. For example, the ninth query from left in Fig. 4 is:
What [BIOLOGICAL SUBSTANCES] have been used to measure toxicity in response to zoledronic acid? which leads to a MAP score of 0.282. Reducing the query to one term,  X  X oledronic X , increases the MAP score to 0.478. The first retrieved over 10,000 documents and the second only 64, while both had 100% recall.

The lesson of these results is that general terms can be actively unhelpful by vastly increasing the number of candidate result documents, and have no or negative impact on effectiveness more often than they make a positive contribution. Again, we conclude that tagging is unlikely to be valuable. 5. Conclusions and future work
Concept recognition has been proposed as a mechanism for improving the effectiveness of search, in particular biomed-ical search. In the literature, while some positive results are reported, there is no demonstration of consistent performance improvement. While our analysis does show some positive results for unrealistically ideal cases, it is far from obvious that concept recognition is of benefit in this specialized domain. Tagging failed to show benefit in any of a range of scenarios, other than unrealistic  X  X  X erfect X  X  examples used to identify cases of best possible performance where only relevant documents were annotated by humans. While tagging did appear to be of potential benefit as metadata, our results  X  which in this re-spect are admittedly preliminary, as we do not have the data to support a comprehensive experiment on this use of tags  X  suggest that its benefit in practice is likely to be limited and heavily dependent on the accuracy of entity recognition and tag assignment components, and most importantly, the diversity of interesting concepts in the collection.

Other issues remain open. A key question, for example, is how queries might become tagged. Automatic tagging seems unlikely; and if a query is already informative enough to be tagged mechanically, does it need tagging? Given the compu-tational cost of tagging, the strong limits of current tagging technology, and the relatively small benefit in even unrealistic cases, in our view there is little reason to pursue concept recognition as a component of ranking in biomedical retrieval.
Although it might be suggested that these results are  X  X bvious X , and that tagging with general concepts cannot succeed, our view is that they are only obvious in the light of our experiments, in particular the key result that tagging does not dis-tinguish between relevant and irrelevant results. The lack of obviousness is further reinforced by the fact that other research-ers continue to pursue general tags as a mechanism for enhancing IR. Moreover, our work raises questions for tagging in general. We suggest that researchers should be confident that the issues we have demonstrated are not factors in their appli-cation domain and document collections before investing resources in attempting to exploit concept recognition for infor-mation retrieval.
 Acknowledgments NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the
Digital Economy and the Australian Research Council through the ICT Centre of Excellence program The authors would like to thank Nicola Stokes for useful discussions and ideas at the start of this work.
 References
