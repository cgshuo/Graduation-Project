 1. Introduction
In many cases, most engineering design problems, such as investment decision, city programming, program management, university timetable, control system design, the objectives present some degree of conflict among them in nature. That is to say, one objective cannot be improved without deterioration of at least another objective. These problems are called multi-objective opti-mization problems (MOPs), which have a set of several optimal solutions known as Pareto optimal solutions ( Deb, 2001 ). Therefore, multi-objective optimization also differs from single-objective opti-mization in that the former is composed of two different tasks to solve the problem: a searching task whose goal is to find Pareto optimal solutions, and a decision making task in which a most preferred solution is chosen from the set of Pareto optimal solu-tions. In other words, two major tasks in multi-objective optimiza-tion are to obtain a set of nondominated solutions as closely as possible to the true Pareto front (PF) and maintain a well-distributed solution set along the Pareto front. Hence, the goal of multi-objective optimization methods is to find a set of good trade-off solutions from which the decision maker want to select one.
In order to solve multi-objective problem, V. Pareto offers the most common definition of optimum i n multi-objective optimization implementation of evolutionary al gorithms to solve multi-objective problems, which it is now called multi-objective evolutionary algo-rithm (MOEA). Evolutionary computation techniques are suitable for multi-objective optimizations because of the fact that Evolutionary Algorithm (EA) deals with a set of solutions which help in the generation of well distributed Pareto optimal front more quickly and efficiently in comparison to the classical techniques. Since 1984, many researchers have proposed their own multi-objective evolu-tionary algorithms (MOEAs). Representative multi-objective evolu-tionary methods, such as NPGA ( Horn et al., 1994 ), NPGA2 ( Erickson and Mayer, 2001 ), NSGA ( Srinivas and Deb, 1994 ), NSGA-II ( Deb et al., 2000 ), SPEA ( Zitzler and Thiele, 1999 ), SPEA2 ( Knowles and Corne, 2000 ), MOPSO ( Coello Coello et al., 2004 ), MODE ( Xue and Sanderson, 2003 ), MOSaDE ( Huang et al., 2009 ), VEDA ( Larran  X  aga and Lozano, 2001 ), MOHBOA ( Pelikan et al., 2005 ), RM-MEDA ( Qingfu, 2008 ), and MOEA-D ( Zhang and Li,. 2007 ), are utilized to optimize several objectives simultaneously and some efficient results are derived.

In this paper, we propose a teaching-learning-based optimiza-tion (TLBO) algorithm based on the nondominated sorting and crowding distance sorting for MOPs. In our algorithm, we adopt the nondominated sorting concept used in NSGA-II, where the entire population is sorted into various non-domination levels. This provides the means for selecting the individuals in the better fronts, hence providing the necessary selection pressure to push the population towards PF. To maintain the diversity of the current best solutions in the external archive, the mechanism of crowding distance computation used in NSGA-II is adopted.
The teacher of the learners is selected from among current nondominated solutions with the highest crowding distance values and the centroid of the nondominated solutions from current archive is selected as the Mean of the learns. The perfor-mance of proposed algorithm is investigated on a set of some unconstrained and constrained benchmark problems and the results show that the proposed algorithm is a challenging method for multi-objective algorithms.

The remainder of this paper is organized as follows. The descrip-tion of teaching-learning-based opti mization algorithm is introduced in Sections 2 and 3 . describes the proposed algorithm. Comparison and analysis of experimental res ults of some unconstrained test problems are shown in Section 4 . Some constrained optimization examples are shown in Section 5 and some conclusions are given in
Section 6 . 2. Teaching-learning-based optimization
Rao et al. (2011 , 2012) first proposed a novel teaching-learning-based optimization (TLBO) inspired from the philosophy of teaching and learning. TLBO has emerged as one of the simple and efficient techniques for solving single-objective benchmark problems and real life application problems in which it has been empirically shown to perform well on many optimization pro-blems ( Rao et al., 2011a , 2011b , 2012 ; Rao, 2012 ; Rao and Patel, 2011 ; Rao and Kalyankar, 2012 ; Togan, 2012 ). These are precisely the characteristics of TLBO that make it attractive to extend it to solve MOPs ( Rao and Patel, 2012a , 2012b ; Niknam and Golestaneh, 2012 ; Niknam et al., 2012 ; Satapathy et al., 2012 ).
The TLBO method is based on the effect of the influence of a teacher on the output of learners in a class which is considered in terms of results or grades. The teacher is generally considered as a highly learned person who shares his or her knowledge with the learners. The quality of a teacher affects the outcome of learners.
It is obvious that a good teacher trains learners such that they can have better results in terms of their marks or grades. Moreover, learners also learn from interaction between themselves, which also helps in their results. Like other nature-inspired algorithms,
TLBO is also a population based method which uses a population of solutions to proceed to the global solution. For TLBO, the population is considered as a group of learners or a class of learners. In optimization algorithms, the population consists of different design variables. In TLBO, different design variables will be analogous to different subjects offered to learners and the learners X  result is analogous to the  X  X  X itness X  X , as in other popula-tion based optimization techniques. The teacher is considered as the best solution obtained so far.

The process of working of TLBO is divided into two parts. The first part consists of  X  X  X eacher Phase X  X  and the second part consists of  X  X  X earner Phase X  X . The  X  X  X eacher Phase X  X  means learning from the teacher and the  X  X  X earner Phase X  X  means learning through the interaction between learners. 2.1. Teaching phase
A good teacher is one who brings his or her learners up to his or her level in terms of knowledge. But in practice this is not possible and a teacher can only move the mean of a class up to some extent depending on the capability of the class. This follows a random process depending on many factors.

Let M i be the mean and T i be the teacher at any iteration i. T will try to move mean M i towards its own level, so now the new mean will be T i designated as M new . The solution is updated according to the difference between the existing and the new mean given by
Difference_Mean i  X  r i M new T F M i  X  X   X  1  X  where T F is a teaching factor that decides the value of mean to be changed, and r i is a random number in the range [0, 1]. The value of T
F can be either 1 or 2, which is again a heuristic step and decided randomly with equal probability as TF  X  round  X  1  X  rand 0 , 1  X  X  X  2  X 
This difference modifies the existing solution according to the following expression
X  X  X i  X  Difference_Mean i  X  3  X 
Learner modification is expressed as ( Pn is the number of learners), T  X  round[1  X  rand(0,1)] for p  X  1:P n endfor
Accept X new if it gives a better function value 2.2. Learning phase
Learners increase their knowledge by two different means: one through input from the teacher and other through interaction between themselves. A learner interacts randomly with other learners with the help of group discussions, presentations, formal communications, etc. A learner learns something new if the other learner has more knowledge than him or her. Learner modifica-tion is expressed as ( Pn is the number of learners), for I  X  1:P n endfor
Accept X new if it gives a better functions value 2.3. The sketch of TLBO algorithm
As explained above, the step-wise procedure for the imple-mentation of TLBO can be summarized as follows.

Step 1: Define the optimization problem and initialize the optimization parameters.
 Step 2: Initialize the population.
 Step 3: Teacher phase. Learners is learning from the teacher.
Step 4: Learner phase. Learners increase their knowledge with the help of their mutual interaction.

Step 5: Termination criterion. Stop if the maximum generation number is achieved; otherwise repeat from Step 3. 3. Description of the proposed algorithm
In the current study, we have concentrated our work on teaching-learning-based optimization (TLBO) for solving MOPs. In this paper, we proposed an improved TLBO called multi-objective teaching-learning-based optimization (MOTLBO). In our MOTLBO, we use an external archive to keep the best solutions obtained so far. We adopt the nondominated sorting concept used in NSGA-II ( Deb et al., 2000 ) to select the individuals in the better fronts in order to push the population towards PF. At the same time, to maintain the diversity of the current best solutions in the external archive, the mechanism of crowding distance computation used in
NSGA-II ( Deb et al., 2000 ) is adopted. The following sections describe these methods. 3.1. External archive
We use an external archive to keep the best solutions generated so far by the MOTLBO algorithm, that is to say, we incorporates the nondominated sorting concept and the mechanism of crowding distance computation into the algorithm specifically on Teacher selection and in the deletion method of population including an external archive of the current best solutions.

At the beginning of the process of MOTLBO, NP (the number of individuals of initial population) solutions are sorted on the basis of non-domination rank and crowding distance rank and added to the external archive. As the evolution progresses, MOTLBO applies the TLBO to create NP new solutions. It then combines the two (current &amp; external archive) populations. Note that the total size of the set after combination becomes 2NP. After that, NP solutions are selected on the basis of non-domination rank and crowding distance rank for next generation from 2NP solutions. Those solutions which are in the most crowded areas are most likely to be selected so that this method promotes diversity among the stored solutions in the archive. 3.2. Selection operator
In single-objective optimization, it is easy to decide which one is better between two individuals. But in MOPs, the decision is not so straightforward. We could use the concept of dominance that the candidate replaces the parent only if the former one dom-inates the latter one.
 The selection of the teacher of the learners is a crucial step in a
MOTLBO algorithm. It affects both the convergence capability of the algorithm as well as maintaining a good spread of nondomi-nated solutions. In MOTLBO, a bounded external archive stores nondominated solutions found in previous iteration. We note that any of the nondominated solutions in the external archive can be used as the teacher of the learners. But we want to ensure that the learners in the population move towards the sparse regions of the search space. So, the teacher of the learners is selected from among those nondominated solutions with the highest crowding distance values. Selecting different teachers for each learner in a specified top part of the external archive based on a decreasing crowding distance allows the learners in the primary population to move towards those nondominated solutions in the external archive which are in the least crowded area in the objective space.
At the same time, we select the centroid of the nondominated solutions from current archive as the Mean of the learns.
In the process of adopting the teaching phase and the learning phase typical of TLBO thus reproducing its search logic, we adopt the following operation. The candidate replaces the parent if the candidate dominates the parent, the candidate is discarded if the parent dominates the candidate, otherwise, when the candidate and parent are nondominated with regard to each other, we randomly select one to add to the population. 3.3. Nondominated sorting
In this approach ( Deb et al., 2000 ), each solution must be compared with every other solution in the population to find if it is dominated in order to sort a population according to the level of non-domination. For each solution i of a solutions set, two entities are calculated: n i , the number of solutions which dominate the At the end of this procedure, all solutions in the first nondomi-nated front F 1 have their domination count n i  X  0. Now, for each solution i with n i  X  0, it visits each member j of its set S reduces its domination count by one. While doing so, if for any member j the domination count becomes zero then it is put in a separate list P . These members belong to the second nondomi-nated front F 2 . The above procedure is continued with each member of P and the third front F 3 is identified. This process continues until all fronts are identified. 3.4. Crowding distance sorting
Crowding distance ( Deb et al., 2000 ) is used to get an estimate of the density of solutions surrounding a particular solution i in the population. The crowding degree estimation method is invoked in two situations. First, when target vector and trial vector do not dominate each other, we evaluate the crowding degree of the target vector and trial vector with respect to the nondominated solutions in the external archive. The less crowded one is chosen as the new target vector of the next generation. Secondly, when the external archive exceeds the prespecified size, the solutions located at the most crowded place should be detected and eliminated.
The crowding distance computation requires sorting the popu-lation according to each objective function value in ascending order of magnitude. Thereafter, for each objective function, the boundary solutions (solutions with smallest and largest function values) are assigned an infinite distance value. All other inter-mediate solutions are assigned a distance value equal to the absolute normalized difference in the function values of two adjacent solutions. This calculation is continued with other objec-tive functions. The overall crowding-distance value is calculated as the sum of individual distance values corresponding to each objective. Each objective function is normalized before calculating the crowding distance. 3.5. Pseudocode for MOTLBO
As previously analyzed, the pseudocode of MOTLBO is sum-marized as follows. 3.6. Computational complexity analysis
Consider the complexity of one iteration of the entire algo-rithm. We define complexity here as the total number of function value comparisons, M and NP represent the number of objective functions and population size respectively. Basic operations and their worst case complexities are as follows: 1. Selection of NP solutions out of 2NP solutions (NP Archive solutions and NP new solutions) for next generation using nondominated sorting: O(M (2NP) 2 ). 2. Selection of NP solutions out of 2NP solutions (NP Archive solutions and NP new solutions) for next generation using crowding distance sorting: O(M (2NP) log(2NP)). 3. Procedure to check the domination status of new solution with target solution in teaching phase for one iteration: O(M NP) 4. Procedure to check the domination status of new solution with target solution in learning phase for one iteration: O(M NP) Therefore, the overall computational complexity of the MOTLBO is less than or equal to O(M (2NP) 2 ), which is in well agreement with the overall computational complexity of NSGA-II ( Deb et al., 2000 ).
 4. Simulation experiments 4.1. Performance measures
To test the performance of MOTLBO, some optimization pro-blems are used in the experiments. Standard performance mea-sures of multi-objective evolutionary algorithms have been used to evaluate the performance of the proposed algorithm. They repre-sent both quantitative and qualitative comparisons with MOEAs.
For these metrics we need to know the true Pareto front for a problem. In our experiments we use 1000 uniformly spaced Pareto optimal solutions as the approximation of the true Pareto front.
The performance measures are described briefly as follows. 4.1.1. Generational distance (GD)
The metric called generational distance (GD) which is proposed by Van Veldhuizen and Lamont (1998 ) indicates the closeness of the Pareto optimal solutions obtained to the true Pareto optimal solutions. The mathematical description of GD are described as follows.

Let Q is a Pareto optimal solution set which obtained by a multi-objective evolutionary algorithm, the closeness of the Pareto optimal solution set Q obtained to the true Pareto optimal solution set (i.e. the Pareto front) PF is evaluated by GD defined by Eq. (4) :
GD  X  where 9 Q 9 is the number of the Pareto optimal solution set Q , d the Euclidean distance between each solution and the nearest member of the true Pareto optimal solution set (i.e. the Pareto front) PF. d i is defined as shown in Eq. (5) : d  X  min where M is the number of the goals, 9 PF 9 is the number of reference member of the true Pareto optimal solution set (i.e. the Pareto the Pareto optimal solution set Q.

When the result is zero, it indicates that the Pareto optimal solution set Q obtained by the algorithm is same as the true
Pareto optimal solution set (i.e. the Pareto front) PF, any other value indicates the Pareto optimal solution set Q obtained by the algorithm deviates from the true Pareto optimal solution set (i.e. the Pareto front PF). 4.1.2. Spacing metric (SP)
The spacing metric (SP) which is proposed by Schott (1995 )aims at assessing the spread (distribution) of the Pareto optimal solution set Q obtained by the algorithm. This metric is measured by evaluating the variance of the nearest distance between neighbor solutions obtained by the algorithm and it is defined by Eq. (6) :
SP  X  v u u t  X  6  X  where n is the number of solutions in the Pareto optimal solution set Q obtained by the algorithm, d i is the distance between each solution and the nearest member of the Pareto optimal solution set obtained by the algorithm, d is the average value for all d are defined by Eqs. (7) and (8) , respectively. d  X  min j d  X  1 n 1 where n is the number of solutions in the Pareto optimal solution set Q obtained by the algorithm, M is the number of the goals, f themthobjectivefunctionvalueofthe i th member of the Pareto j th member of the Pareto optimal solution set Q .

Lower value of SP indicates a more even spread of the Pareto optimal solution set Q obtained by the algorithm, and a value of zero suggests that the Pareto optimal solution set Q obtained by the algorithm are evenly spread out. 4.2. Test problems
The performance of the proposed algorithm is tested on a set of 6 unconstrained benchmark problems generally used to vali-date the performance of different MOEAs. Here GD, SP and Time (the computation time of the algorithm) have been used to evaluate the performance of the proposed algorithm and 6 bench-mark problems which we have taken are SCH, DEB, FON, ZDT1, ZDT3 and ZDT6. All these problems have two objective functions.
We describe these problems in Table 1 . also shows the number of variables, their bounds, the Pareto-optimal solutions, and the nature of the Pareto-optimal front for each problem. 4.3. Comparison of the results
In order to illustrate the efficiency of our approach, it is compared to NSGA-II, MOPSO-CD and RM-MEDA. The codes of these algorithms were programmed by the authors of the paper according to the algorithms introduced in the references. All algorithms were compiled in MATLAB 7.9 and are executed on Intel Pentium 4(R) 3.00 GHz PC with 512MB RAM,.
 In this paper, NP of all algorithms are set to 100 respectively. Maximum number of function evaluations is set to 10,000 for
SCH, DEB, FON, ZDT1, ZDT3 and 50,000 for ZDT6. NSGA-II was run using a crossover probability of 0.9, tournament selection, a mutation rate of 1/n (where n is the number of decision variables), and distribution indexes for crossover and mutation operators as Z c  X  20 and Z m  X  20, respectively. In MOPSO-CD, c  X  1.0, c 2  X  0.5, r 1 and r 2 are random values between 0 and 1, inertial weight w might a constant value. In RM-MEDA, the number of clusters of Local PCA algorithm is set to be 5. All the experiments are run 20 times for each problem. The values of the two metrics for each algorithm are presented in Table 2 .To display the difference of optimal Pareto front between the given method and the real one clearly, the best optimal Pareto fronts of NSGA-II, MOPSO-CD, RM-MEDA and MOTLBO are shown in Table 3 .
 For SCH with convex Pareto front, it can be seen from in
Table 3 that except RM-MEDA, which is based on the regularity property that the Pareto set of a continuous multi-objective optimization problem is a piecewise continuous ( m -1)-D manifold but the dimension of SCH is one, all other algorithms are able to find solutions near the global Pareto front. Considering all of the metrics from Table 2 , the average performance of our algorithm is the best with respect to GD and Time. MOPSO-CD is the best with respect to SP but the computation time required for this algo-rithm is more that the same for our algorithm.
 For DEB with disconnected Pareto front, it can be seen from in
Table 3 that all other algorithms are able to find solutions near the global Pareto front. It can be seen from Table 2 that the average performance of our algorithm ranks second with respect to SP (MOPSO-CD has the best one) and our algorithm has the worst average performance with respect to GD (MOPSO-CD has the best one), but it has the best average performance with respect to Time.
 For FON with non-convex Pareto front, it can be seen from in
Table 3 that all other algorithms are able to find solutions near the global Pareto front. Our algorithm has the best average perfor-mance with respect to GD and Time, but the average performance of our algorithm ranks second with respect to SP (MOPSO-CD has the best one).
 For ZDT1 with convex Pareto front, it can be seen from in Table 3 that both NSGA-II and RM-MEDA still failed to find its true Pareto front or its approximation within 10,000 evaluations.
MOPSO-CD has the beat performance with respect to GD and our algorithm has the best average performances with respect to SP and Time.
 For ZDT3 with disconnected Pareto front, it can be seen from in Table 3 that both NSGA-II and RM-MEDA still failed to find its true Pareto front or its approximation within 10,000 evaluations. Our algorithm has the best average performances with respect to GD and Time but but it has the worst average performance with respect to SP (MOPSO-CD has the best one).

For ZDT6 with non-convex Pareto front, RM-MEDA still failed to find its true Pareto front or its approximation within 50,000 evaluations. Our algorithm has the best average performances with respect to GD and Time but but the average performance of our algorithm ranks third with respect to SP (RM-MEDA has the best one). In addition, it can be seen from in Table 3 that NSGA-II have the most solutions which located far from the true Pareto front and our algorithm have the least. 5. Constrained optimization examples
To deeply test the performance of the given algorithm, two typical constrained optimization problems are used in experiments.
All other parameters are similar to unconstrained optimization problems.Thenumberofiterationsis100forthefourmethods. 5.1. Two-Bar truss design
This problem was originally studied using the e -constraint a certain load without elastic failure. Thus, in addition to the objective of designing the truss for minimum volume (which is equivalent to designing for minimu m cost of fabrication), there are additional objectives of minimizing stresses in each of the two members AC and BC.We construct the following two-objective optimization problem for three variables x 1 (lengthofACinm), x (lengthofBCinm)and x 3 (vertical distance between B and C in m).

The mathematical description of two bar truss design problem can be expressed by Eq. (9) :
Minimize : f 1  X  x  X  X  x 1 subject to : max s AC , s BC  X  X  r 110 5 where : s AC  X 
The original study reported only five solutions with the following spread: (0.004445 m 3 , 89,983 kPa) and (0.004833 m 83,268 kPa). Fig. 3 shows the optimized fronts obtained using NSGAII, MOPSO-CD, RM-MEDA and MOTLBO methods after 100 iterations.

It can be seen from Table 4 that the four methods have a wide variety of alternatives. If minimum volume is desired, MOPSO-CD gives a value as low as 0.004214 m 3 , and MOTLBO gives a value as low as 0.004174 m 3 . If minimization of stress is important, MOTLBO finds a solution with stress as low as 8431.376521 kPa. MOTLBO has good performance in variable domain of stress and MOPSO-CD has good performance in variable domain of volume. The MOTLBO solutions are very competitive with MOPSO-CD solutions in terms of both closeness to the true optimum front and their spread, and these two methods are all better than NSGAII and RM-MEDA. 5.2. I-beam design
The goal of the problem is to find the dimensions of the beam presented in Fig. 4 which satisfy the dimensions of the geometric and strength constraints, and at the same time minimize two objectives: cross-sectional area of the beam and static deflection of the beam under the force P ( Yang et al., 2002 ).

The mathematical description of I-beam design problem can be expressed by Eq. (10) : Minimize : f 1 x  X  X  X  2 x 2 x 4  X  x 3 x 1 2 x 4  X  X  f 2 x  X  X  X  PL subject to : gx  X  X   X  M y Z where : I  X  1 12 x 3 x 1 2 x 4  X  X  3  X  2 x 2 x 4 4 x 2 4  X  3 x
M
Z  X 
Z  X  E  X  2 10 4 kN = cm 2 , s a  X  16 kN = cm 2 P  X  600 kN , Q  X  50 kN , L  X  200 cm  X  10  X  The Pareto optimal solutions obtained using NSGAII, MOPSO-
CD, RM-MEDA and MOTLBO methods are shown in Fig. 5 after 100 iterations. The results from Table 5 indicate that the minimal cross sectional area of MOTLBO is the smallest among the four methods, and the minimal deflections of four algorithms are equal. Based on these points we can say that the MOTLBO are very competitive with other three algorithms in terms of cross-sectional area of the beam. 6. Conclusions
In this paper, we propose a teaching-learning-based optimiza-tion algorithm for multi-objective optimization problems. Our
MOTLBO adopt the nondominated sorting concept and the mechanism of crowding distance computation. The Pareto fronts of the solutions are guided by the teacher which is the best learner and the mean of learners achieved so far. The efficiency and effectiveness of the proposed MOTLBO are evaluated using 6 unconstrained benchmark test problems with convex and non-convex objective functions and 2 constrained real-word multi-objective problems. The experimental results show that the average Running Time of MOTLBO is the least for all 6 uncon-strained benchmark test problems, the average Generational Distance (GD) of MOTLBO is the least for SCH, FON, ZDT3 and ZDT6 and the average Spacing metric (SP) of MOTLBO is the least for ZDT1. It should be noted that the distribution of the Pareto optimal solution set obtained by MOTLBO need to be improved. In summary, the proposed MOTLBO algorithm is a challenging method for multi-objective optimization problems.

In the near future, we also plan to improve the distribution of the Pareto optimal solution set obtained by MOTLBO algorithm and apply it for solving dynamic multi-objective optimization problems.
 Acknowledgement This research was partially supported by National Natural Science Foundation of China (61272283, 61073091, 61100173), Social Science Foundation of Hebei Province (HB11JY006), Scien-tific Research Plan Foundation in Higher Educational Institutes of Hebei (SZ2011334).
 References
