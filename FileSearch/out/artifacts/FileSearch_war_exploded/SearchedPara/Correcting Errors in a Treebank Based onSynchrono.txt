 Annotated corpora play an important role in the fields such as theoretical linguistic researches or the development of NLP systems. However, they often contain annotation errors which are caused by a manual or semi-manual mark-up process. These errors are problematic for corpus-based re-searches.

To solve this problem, several error detection and correction methods have been proposed so far (Eskin, 2000; Nakagawa and Matsumoto, 2002; Dickinson and Meurers, 2003a; Dickinson and Meurers, 2003b; Ule and Simov, 2004; Murata et al., 2005; Dickinson and Meurers, 2005; Boyd et al., 2008). These methods detect corpus posi-tions which are marked up incorrectly, and find the correct labels (e.g. pos-tags) for those posi-tions. However, the methods cannot correct errors in structural annotation. This means that they are insufficient to correct annotation errors in a tree-bank.

This paper proposes a method of correcting er-rors in structural annotation. Our method is based on a synchronous grammar formalism, called syn-chronous tree substitution grammar (STSG) (Eis-ner, 2003), which defines a tree-to-tree transfor-mation. By using an STSG, our method trans-forms parse trees containing errors into the ones whose errors are corrected. The grammar is au-tomatically induced from the treebank. To select STSG rules which are useful for error correction, we define a score function based on the occurrence frequencies of the rules. An experimental result shows that the selected rules archive high preci-sion.

This paper is organized as follows: Section 2 gives an overview of previous work. Section 3 ex-plains our method of correcting errors in a tree-bank. Section 4 reports an experimental result us-ing the Penn Treebank. This section summarizes previous methods for correcting errors in corpus annotation and dis-cusses their problem.

Some research addresses the detection of er-rors in pos-annotation (Nakagawa and Matsumoto, 2002; Dickinson and Meurers, 2003a), syntactic annotation (Dickinson and Meurers, 2003b; Ule and Simov, 2004; Dickinson and Meurers, 2005), and dependency annotation (Boyd et al., 2008). These methods only detect corpus positions where errors occur. It is unclear how we can correct the errors.

Several methods can correct annotation errors (Eskin, 2000; Murata et al., 2005). These meth-ods are to correct tag-annotation errors, that is, they simply suggest a candidate tag for each po-sition where an error is detected. The methods cannot correct syntactic annotation errors, because syntactic annotation is structural. There is no ap-proach to correct structural annotation errors.
To clarify the problem, let us consider an exam-ple. Figure 1 depicts two parse trees annotated ac-cording to the Penn Treebank annotation 1 . The parse tree (a) contains errors and the parse tree (b) is the corrected version. In the parse tree (a), the positions of the two subtrees (, ,) are erro-neous. To correct the errors, we need to move the subtrees to the positions which are directly dom-inated by the node PRN . This example demon-strates that we need a framework of transforming tree structures to correct structural annotation er-rors. To solve the problem described in Section 2, this section proposes a method of correcting structural annotation errors by using a synchronous tree sub-stitution grammar (STSG) (Eisner, 2003). An STSG defines a tree-to-tree transformation. Our method induces an STSG which transforms parse trees containing errors into the ones whose errors are corrected. 3.1 Synchronous Tree Substitution Grammar First of all, we describe the STSG formalism. An STSG defines a set of tree pairs. An STSG can be treated as a tree transducer which takes a tree as input and produces a tree as output. Each grammar rule consists of the following elements:  X  a pair of trees called elementary trees  X  a one-to-one alignment between nodes in the For a tree pair  X  t, t  X   X  , the tree t and t  X  are called source and target , respectively. The non-terminal leaves of elementary trees are called fron-tier nodes . There exists a one-to-one alignment between the frontier nodes in t and t  X  . The rule means that the structure which matches the source elementary tree is transformed into the structure which is represented by the target elementary tree. Figure 2 shows an example of an STSG rule. The subscripts indicate the alignment. This rule can correct the errors in the parse tree (a) depicted in Figure 1.

An STSG derives tree pairs. Any derivation process starts with the pair of nodes labeled with special symbols called start symbols . A derivation proceeds in the following steps: 1. Choose a pair of frontier nodes  X   X ,  X   X   X  for 2. Choose a rule  X  t, t  X   X  s.t. label (  X  )= root ( t ) 3. Substitute t and t  X  into  X  and  X   X  , respectively. Figure 3 shows a derivation process in an STSG.
In the rest of the paper, we focus on the rules in which the source elementary tree is not identi-cal to its target, since such identical rules cannot contribute to error correction. 3.2 Inducing an STSG for Error Correction This section describes a method of inducing an STSG for error correction. The basic idea of our method is similar to the method presented by Dickinson and Meurers (2003b). Their method de-tects errors by seeking word sequences satisfying the following conditions:  X  The word sequence occurs more than once in Figure 3: A derivation process of tree pairs in an STSG  X  Different syntactic labels are assigned to the Unlike their method, our method seeks word se-quences whose occurrences have different partial parse trees. We call a collection of these word sequences with partial parse trees pseudo paral-lel corpus . Moreover, our method extracts STSG rules which transform the one partial tree into the other. 3.2.1 Constructing a Pseudo Parallel Corpus Our method firstly constructs a pseudo parallel corpus which represents a correspondence be-tween parse trees containing errors and the ones whose errors are corrected. The procedure is as follows: Let T be the set of the parse trees oc-curring in the corpus. We write Sub (  X  ) for the set which consists of the partial parse trees in-cluded in the parse tree  X  . A pseudo parallel cor-pus P ara ( T ) is constructed as follows: P ara ( T )= { X   X ,  X   X   X  |  X ,  X   X   X  Figure 4: An example of a partial parse tree pair in a pseudo parallel corpus Figure 5: Another example of a parse tree contain-ing a word sequence  X , they say , X  where yield (  X  ) is the word sequence dominated by  X  .

Let us consider an example. If the parse trees depicted in Figure 1 exist in the treebank T , the pair of partial parse trees depicted in Figure 4 is an element of P ara ( T ) . We also obtain this pair in the case where there exists not the parse tree (b) depicted in Figure 1 but the parse tree depicted in Figure 5, which contains the word sequence  X , they say , X . 3.2.2 Inducing a Grammar from a Pseudo Our method induces an STSG from the pseudo parallel corpus according to the method proposed by Cohn and Lapata (2009). Cohn and Lapata X  X  method can induce an STSG which represents a correspondence in a parallel corpus. Their method firstly determine an alignment of nodes between pairs of trees in the parallel corpus and extracts STSG rules according to the alignments.

For partial parse trees  X  and  X   X  , we define a node alignment C (  X ,  X   X  ) as follows: C (  X ,  X   X  )= { X   X ,  X   X   X  |  X   X  N ode (  X  ) where N ode (  X  ) is the set of the nodes in  X  , and yield (  X  ) is the word sequence dominated by  X  . Figure 4 shows an example of a node alignment. The subscripts indicate the alignment.

An STSG rule is extracted by deleting nodes in a partial parse tree pair  X   X ,  X   X   X   X  P ara ( T ) . The procedure is as follows:  X  For each  X   X ,  X   X   X   X  C (  X ,  X   X  ) , delete the de-For example, the rule shown in Figure 2 is ex-tracted from the pair shown in Figure 4. 3.3 Rule Selection Some rules extracted by the procedure in Section 3.2 are not useful for error correction, since the pseudo parallel corpus contains tree pairs whose source tree is correct or whose target tree is incor-rect. The rules which are extracted from such pairs can be harmful. To select rules which are use-ful for error correction, we define a score function which is based on the occurrence frequencies of elementary trees in the treebank. The score func-tion is defined as follows: where f (  X  ) is the occurrence frequency in the tree-bank. The score function ranges from 0 to 1. We assume that the occurrence frequency of an ele-mentary tree matching incorrect parse trees is very low. According to this assumption, the score func-tion Score (  X  t, t  X   X  ) is high when the source ele-mentary tree t matches incorrect parse trees and the target elementary tree t  X  matches correct parse trees. Therefore, STSG rules with high scores are regarded to be useful for error correction. To evaluate the effectiveness of our method, we conducted an experiment using the Penn Treebank (Marcus et al., 1993).

We used 49208 sentences in Wall Street Journal sections. We induced STSG rules by applying our method to the corpus. We obtained 8776 rules. We Figure 6: Examples of error correction rules in-duced from the Penn Treebank measured the precision of the rules. The precision is defined as follows:
We manually checked whether each rule appli-cation corrected an error, because the corrected treebank does not exist 2 . Furthermore, we only evaluated the first 100 rules which are ordered by the score function described in Section 3.3, since it is time-consuming and expensive to evaluate all of the rules. These 100 rules were applied at 331 positions. The precision of the rules is 71.9%. For each rule, we measured the precision of it. 70 rules achieved 100% precision. These results demon-strate that our method can correct syntactic anno-tation errors with high precision. Moreover, 30 rules of the 70 rules transformed bracketed struc-tures. This fact shows that the treebank contains structural errors which cannot be dealt with by the previous methods.

Figure 6 depicts examples of error correction rules which achieved 100% precision. Rule (1), (2) and (3) are rules which transform bracketed structures. Rule (4) simply replaces a node la-bel. Rule (1) corrects an erroneous position of a comma (see Figure 7 (a)). Rule (2) deletes a use-less node NP in a subject position (see Figure 7 (b)). Rule (3) inserts a node NP (see Figure 7 (c)). Rule (4) replaces a node label NP with the cor-rect label PP (see Figure 7 (d)). These examples demonstrate that our method can correct syntactic annotation errors.

Figure 8 depicts an example where our method detected an annotation error but could not correct it. To correct the error, we need to attach the node Figure 8: An example where our method detected an annotation error but could not correct it SBAR under the node NP . We found that 22 of the rule applications were of this type.

Figure 9 depicts a false positive example where our method mistakenly transformed a cor-rect syntactic structure. The score of the rule is very high, since the source elementary tree (TOP (NP NP VP .)) is less frequent. This example shows that our method has a risk of changing correct annotations of less frequent syn-tactic structures. This paper proposes a method of correcting er-rors in a treebank by using a synchronous tree substitution grammar. Our method constructs a pseudo parallel corpus from the treebank and ex-tracts STSG rules from the parallel corpus. The experimental result demonstrates that we can ob-tain error correction rules with high precision. Figure 9: A false positive example where a correct syntactic structure was mistakenly transformed
In future work, we will explore a method of in-creasing the recall of error correction by construct-ing a wide-coverage STSG.
 This research is partially supported by the Grant-in-Aid for Scientific Research (B) (No. 22300051) of JSPS and by the Kayamori Foundation of Infor-mational Science Advancement.
