 Query expansion has been widely used to deal with paraphrase problem in information retrieval. The expanded terms may come from feedback documents, target document collection, or outside knowledge resources [1]. WordNet [2], an electronic lexical da-tabase, has been employed to many applications [9], where query expansion is an im-portant one. Voorhees [14] utilized lexical semantic relations in WordNet to expand queries. Smeaton et al [13] added WordNet synonyms of original query terms with half of their weights. Liu et al [7] used WordNet to disambiguate word senses of query terms, and then considered the synonyms, the hyponyms, and the words from defini-tions for possible additions to a query. Roberto and Paola [10] utilized WordNet to ex-Moldovan and Mihalcea [8] applied WordNet to improve Internet searches. 
In contrast to WordNet, commonsense knowledge was only explored in retrieval in a few papers. Liu and Lieberman [5] used ConceptNet [4] to expand query with the related concepts. However, the above work did not make formal evaluation, so that we were not sure if the effects of introducing common sense are positive or negative. Hsu and Chen [3] introduced commonsense knowledge into IR by expanding con-cepts in text descriptions of images with spatially related concepts. Experiments showed that their approach was more suitable for precision-oriented tasks and for  X  X ifficult X  topics. The expansion of this work was done at document level instead of query level. Document contributes much larger contextual information than query. In the past, few papers have touched on the comparison of ConceptNet and Word-Net in query expansion under the same benchmark. We are interested in what effects condition, we are able to improve the retrieval performance further. In this paper, we design some experiments with evaluation criteria to quantitatively measure WordNet and ConceptNet in the aspect of query expansion. We employ the same algorithm, spreading activation [12], to select candidate terms from ConceptNet and WordNet for the TREC topics 301-450, which were used in TREC-6, TREC-7 and TREC-8. To of quantitative measurements including discrimination ability, concept diversity, and retrieval performance. This paper is organized as follows. In Section 2, we give brief introduction to WordNet and ConceptNet. The comparison methodology is specified in Section 3. Section 4 introduces the experiment environment and discusses the experimental re-sults. Section 5 concludes the remarks. In this section, we give brief introduction to the two resources to be compared. Frameworks and origins of the two knowledgebase are described. A surface compari-son of their similarities and differences is also presented. 2.1 WordNet WordNet appeared in 1993 and has been developed by linguistic experts at Princeton University X  X  Cognitive Science Laboratory since 1985. It is a general-purpose know-ledgebase of words, and it covers most English nouns, adjectives, verbs and adverbs. lexical unit is called as  X  X ynset X  in WordNet terminology. Synsets in WordNet are  X  X art-of X  relations. For its simple structure with words at nodes, WordNet X  X  success comes from its ease of use [2][9]. 2.2 ConceptNet ConceptNet is developed by MIT Media Laboratory and is presently the largest com-monsense knowledgebase [6]. ConceptNet is a relational semantic network that is automatically generated from about 700,000 English sentences of the Open Mind Common Sense (OMCS) corpus. Nodes in ConceptNet are compound concepts in the home X ). Because the goal of developing ConceptNet is to cover pieces of common-sense knowledge to describe the real world, there are 20 kinds of relations categorized as causal, spatial, functional, etc. ConceptNet has been adopted in many interactive applications [4]. Hsu and Chen [3] utilized ConceptNet to expand image annotations and got improvement for some difficult topics. As commonsense knowledge is deeply context-sensitive, the suitability of ConceptNet for query expansion is still not clear. 2.3 A Surface Comparison WordNet and ConceptNet have several similarities: (1) their structures are both rela-tional semantic networks; (2) both of them are general-purpose (that is, not domain-specific) knowledgebase; and (3) concepts in the two resources are both in the form of natural language. On the other hand, WordNet and ConceptNet differ from each other in some aspects: (1) as their processes of development differ (manually handcrafted vs. automatically generated), intuitively WordNet has higher quality and robustness; (2) while WordNet focuses on formal taxonomies of words, ConceptNet focuses on a richer set of semantic relations between compound concepts [6]; and (3) WordNet dif-ferentiates ambiguous meanings of a word as synsets, however, ConceptNet bears ambiguity of commonsense knowledge in its concepts and relations. To compare the two knowledgebase in the aspect of query expansion intrinsically, we perform the same algorithm to expand queries. As WordNet and ConceptNet are both relational semantic networks, i.e., useful concepts for expansion in the network are usually those related to the concepts of the query, spreading activation [12] is adopted. 
Figure 1 shows the overall procedure of the comparison. Given an original query, we perform spreading activation on WordNet and ConceptNet, respectively. Then, the two expanded queries are compared with three quantitative measurements. The first measurement computes the discrimination ability in information retrieval. The second measurement calculates the concept diversity in relevant documents. The third di-rectly evaluates the performance of retrieval, including two typical evaluation criteria for ad hoc retrieval. All of these measurements are described in Section 3.4. 
When we perform spreading activation in a semantic network to expand a query, the node of activation origin represents the concept of the given query. The activation ori-one link away from the activation origin are activated, then two links away, and so on. 
Equation (1) shown below determines the activation score of node j by three fac-tors: (i) a constant Cdd 1 (e.g., 0.5), which is called distance discount that causes a node closer to the activation origin to get a higher activation score; (ii) the activation semantic network are of different weights. Neighbor( j ) represents the nodes connected to node j . 
Since most traditional IR systems are of bag-of-words model, we select the top N words with the higher activation scores as the expanded query. For a word w , its acti-vation score is the sum of scores of the nodes (i.e., synsets in WordNet) that contain w . 3.1 Pre-processing Each query was lemmatized and POS-tagged by Brill tagger. Stop-words were re-moved and each of the remaining words with POS-tags was considered as a concept at the following stages. 3.2 Spreading Activation in ConceptNet In addition to commonsense concepts and relations, ConceptNet also provides a set of tools for reasoning over text [6]. One of these tools, get_context ( concepts ), performs spreading activation on all kinds of relations in ConceptNet, to find contextual neighborhood relevant to the concepts as parameters. Different relations are set to dif-ferent weights in default setting. For example, the weight of  X  X sA X  relation is 0.9 and panded terms. In our experiments, each word in a compound concept has the same ac-tivation score as that of the compound concept. More details about the reasoning tools in ConceptNet please refer to [6]. 3.3 Spreading Activation in WordNet Since each node in WordNet is a synset th at contains synonyms of certain sense, spreading activation in WordNet is surely performed on the unit of synset. Because ConceptNet covers most relations in WordNet, we determine the weights of relations concept (a word with POS-tag) in the query, we choose its most frequent sense (syn-disambiguate the sense of query terms in this paper for simplicity. Relation Type causes holonyms hypernyms hyponyms meronyms Pertainyms 3.4 Quantitative Measurements The following proposes three types of measurements to investigate the intrinsic dif-ferences between WordNet and Concept. They provide different viewpoints for the comparison. (1) Discrimination Ability (DA). Discrimination ability is used to measure how precisely a query describes the information need. In IR, the inverse document fre-quency (IDF) of a term denotes if it occurs frequently in individual documents but crimination ability of a term can be estimated by its IDF value. Hence the discrimina-crimination ability (DA) as follows. where N C is the number of documents in a collection, and df( q i ) is the document fre-quency of query term q i . (2) Concept Diversity (CD). This measurement helps us observe the concept di-versity of an expanded query, relative to the relevant documents. That is, we measure how much an expanded query covers the concepts occurring in the relevant docu-ments. Let tm( ) denote the function that maps the parameter (a document or a documents which are relevant to the query q in the collection. The concept diversity (CD) of a query q is defined as follows. (3) Retrieval Performance: This type of measurements includes two typical top 20 documents (P@20). We adopted the topics and the document collections in the ad hoc track of TREC-6, TREC-7 and TREC-8 as the experimental materials for the comparison. There are 556,077 documents in the collection of TREC-6 and 528,155 documents in TREC-7 and in TREC-8 . Only the  X  X itle X  part was used to simulate short query, since web identifiers 301-450. However, 4 of them (i.e., topics 312, 379, 392 and 423) are un-able to be expanded by spreading activation either in WordNet or in ConceptNet, so that these 4 topics are neglected in the experiments. For each short query, the top 100 words with the higher activation scores form the expanded query. The IR system adopted for the measurement of retrieval performance is Okapi X  X  BM25 [11]. The re-trieval performance is measured on the top 1000 documents for each topic. 
Figures 2, 3, 4, and 5 show the results of the quantitative measurements, where the x-axis represents topic number, and 301-350, 351-400, and 401-450 are topics of TREC-6, TREC-7 and TREC-8, respectively. To compare the differences between WordNet and ConceptNet, the result presented for each topic is the difference be-tween the two expanded queries, i.e., the measurement of the WordNet-expanded query subtracts that of the ConceptNet-expanded query. 4.1 Preliminary Analysis Figure 2 shows the differences of two kinds of expansions in discrimination ability (DA). The DA averaged over the 146 experimental topics is 5.676 and 4.191 for the WordNet-expanded and ConceptNet-expanded queries, respectively. From Figure 2, it is obvious that the terms in the WordNet-expanded queries have higher discrimination ability. In other words, they are more specific than those terms in ConceptNet-expanded queries. A specific term highly relevant to a topic can be considered as one of the kernel words of that topic. Figure 2 shows that the queries expanded by Word-Net are more probable to contain the kernel words. 
The average concept diversity (CD) is 0.037 and 0.048 for the WordNet-expanded and the ConceptNet-expanded queries, respectively. In contrast to the result of dis-crimination ability, Figure 3 shows that ConceptNet-expanded queries have higher concept diversity than WordNet-expanded ones do. Note that the concept diversity of an expanded query is computed according to the relevant documents. As the terms in ConceptNet-expanded queries are usually more general than those in WordNet-expanded queries, Figure 3 shows that ConceptNet-expanded queries cover more of the concepts that would usually co-occur with the kernel words in the relevant documents. We call the concepts that co-occur with the kernel words as cooperative concepts . 
Expanding a short query with the kernel words will help IR systems to find more relevant documents. On the other hand, co-occurrence of the cooperative concepts and the kernel words will help the IR system to rank truly relevant documents higher than  X  X urrogate X  and  X  X hild X  are suggested by WordNet and ConceptNet, respectively. The irrelevant documents. The detail will be discussed in Section 4.2. The overall retrieval performances of the WordNet-expanded queries in AP and P@20 are 0.016 and 0.0425, respectively. For the ConceptNet-expanded queries, the performances are 0.019 and 0.0438, in AP and P@20, respectively. These retrieval performances are low because the expanded queries are formed by the top 100 words with the higher activation scores. The simple expansion method introduces too much noise. Figure 4 and Figure 5 show the differences of AP and of P@20 for each topic. We observed that WordNet-expanded queries perform better for some topics, but ConceptNet-expanded queries perform better for some other topics. While WordNet and ConceptNet are different in discrimination ability (Figure 2) and in concept diver-retrieval. Hence, we made further experiments in the following subsection. 4.2 Further Analysis In the next experiments, we performed manual query expansion by selecting some of the top 100 words proposed by spreading activation in WordNet or in ConceptNet, to the topics of TREC-6, performed the process of manual expansion. They read the topic description in advance, and he/she had no idea about the real content or vocabu-lary in the relevant documents. This manual selection process was performed sepa-rately on the words proposed by WordNet and by ConceptNet. These manually se-lected words for expansion are called WordNet-consulted (WC) and ConceptNet-consulted (CC) terms, respectively. In this way, we compared four expansion strate-gies, i.e., original (no expansion), WordN et-consulted, Concep tNet-consulted, and combination of WC and CC. We also increased the weights of the original query terms with different degrees to observe how the performances vary with the degrees. In the experiments, we only used the topics of TREC-6 for analyses. 
Figure 6 shows the performances in mean average precision of the four expansion strategies. The x-axis represents the degrees (times) by which the weights of the original query terms are increased. The performance of the original query is 0.221 and doesn X  X  vary with the degrees since there is no expansion. CC slightly performs better than the original when the degree is larger than 3, as well as WC with the degree lar-ger than 6. The slight improvement of CC only or WC only shows that without infor-mation about the real content of the relevant documents, effective query expansion for obtained with combination of WC and CC at degree 6, and 3.94% increase to the baseline. This performance improvement on no expansion is examined as significant by a t-test with a confidence level of 95%. The corresponding p-value is 0.034. Figure 6 also shows that a careful weighting scheme is needed no matter whether WordNet only or ConceptNet only is adopted. With an unsuitable weighting scheme, combination of WC and CC performs even worse than WC only or CC only. In Fig-ure 6, CC performs stably when the degree increases larger than 3, but WC performs weights of original query terms are increased, in the aspect of ranking documents, the degree also stands for how much the weights of CC or WC terms are lightened. While the words proposed by WordNet are usually more specific and influence more heavily on the rankings of retrieved documents, it is shown that an appropriate weighting scheme is more important for WC than for CC. 
While Figure 6 shows the result averaged over all topics of TREC-6, Figure 7 shows some more strong evidences supporting the argument that WordNet and Con-ceptNet can complement each other. Using different expansion strategies with the de-gree 6, the performances (AP) of eight topics are presented. While CC only or WC eight topics benefit from the combination of WC and CC. Therefore, the overall im-provement (refer to Figure 6) of combination of WC and CC is mostly exhibited in the eight topics. 
We verify the complementary of WordNet and ConceptNet, i.e., frequent co-occurrence of WC terms and CC terms in relevant documents, by the following way. For each pair of CC term t c and WC term t w , we calculate LRP( t c , t w ) using Equation occurrence probability of t c and t w in the irrelevant documents. where R and IRR represent relevant and irrelevant documents, respectively. Table 2 shows the title, the CC terms, the WC terms and the term pairs having high LRP values for each topic in Figure 7. The term pairs with high LRP in the eight top-ics are the major evidences to support that combination of WC and CC is effective as (human, surrogate) of topic 335 have high LRP values. They also confirm the idea of kernel words and cooperative concepts mentioned in Section 4.1. In this paper, we used the technique of spreading activation to investigate the intrinsic characteristics of WordNet and of ConceptNet. Three types of quantitative measurements, i.e., discrimination ability, concept diversity, and retrieval perform-ance are used to compare the differences between the two resources. With the pre-liminary analysis and the verification of manual expansion, we have shown that WordNet is good at proposing kernel words and ConceptNet is useful to find coopera-tive concepts. With an appropriate weighting scheme, the two resources can comple-ment each other to improve IR performance. 
In future work, we will investigate an automatic query expansion method to com-bine the advantages of the two resources. Commonsense knowledge in ConceptNet is deeply context-sensitive so that it needs enough context information for automatic query expansion. Using existing methods such as pseudo relevance feedback or re-sources such as WordNet to increase the context information can be explored. We also intend to investigate whether complex techniques of word sense disambiguation (WSD) in WordNet are necessary for IR, under the existence of ConceptNet. Research of this paper was partially supported by National Science Council, Taiwan, under the contracts NSC94-2752-E-001-001-PAE and NSC95-2752-E-001-001-PAE. 
