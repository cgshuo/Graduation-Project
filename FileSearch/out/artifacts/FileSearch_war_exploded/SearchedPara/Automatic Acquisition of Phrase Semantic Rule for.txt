 Xu-Ling Zheng, Chang-Le Zhou, Xiao-Dong Shi, Tang-Qiu Li, and Yi-Dong Chen Phrase parsing is an important component of many natural language processing sys-tems in applications such as machine translation, information retrieval, or text classi-fication. The parsing quality impacts the performance of these systems. However, the existence of ambiguity is an enormous hindrance to phrase parsing. Morphology and grammar knowledge are insufficient to disambiguate, especially when parsing Chi-nese phrases for Chinese is a typical parataxis language. To improve parsing, seman-tic knowledge should be introduced. 
Currently, there are various types of manually constructed lexical semantic knowl-edge bases, such as WordNet, FrameNet, an d HowNet [1]. In contrast, efforts in constructing semantic collocation rule bases are less. For Chinese, Dong and Dong constructed the HowNet -Chinese Message Structure Base [2], Yu constructed the Phrase Structure Bank (PSB) of Contemporary Chinese [3], Zhan proposed a set of intuition-based methods. These rule bases are concentrated reflection of human ex-pert X  X  knowledge. They involve too many ar tificial factors. The coverage and granu-larity level of these rules are different, the precision of them are difficult to ensure. 
This paper reports our study on acquiring phrase semantic rules from a Chinese phrase corpus annotated with syntactic and semantic information automatically. In this paper, phrase semantic rules for Chinese are proposed to formulate the syntac-tic and semantic knowledge about words having what kind of meaning can compound a phrase in what way and what type the resulting phrase is. According to the proper-ties of the compounding rules of Chinese phrase and the Knowledge Dictionary Mark-up Language (KDML) of HowNet [1], the pattern of phrase semantic rules for Chinese is specified in the following format: &lt;Syntax-Structure-Type&gt; is a code of syntactic structure type of the phrase, &lt;Seman-tic-Relation-List&gt; shows the dependency relations between components, and &lt;DEF-the sememes for each component. If a phrase consist of n components, then the corre-sponding rule should include n &lt;DEF-Pattern&gt; X  X , called a n -gram rule. 
To strengthen the description capacity, we introduce a prefix *HYP* and limited variables in KDML. A sememe with the prefix *HYP*, called a generalizer of se-meme, denotes it can match any child of the given sememe in the sememe hierarchy of HowNet. It makes rules more recapitulative. And replacing sememes with limited variables makes it easier to describe the semantic relation between components. 3.1 Problem Description Regarding examples in the annotated corpus of Chinese phrases as transactions, and problem can be transformed into an association rules mining problem [5,6,7]. 
Each example in our corpus has three kinds of necessary tags: (1) a syntactic struc-rules also should have these three kinds of tags. And the constraint can be formulated as the following metarule (denoted P ) which is used to guide the mining process. of n -gram semantic rules of the form where B 1  X   X  1 , B 2  X   X  2 , A j  X   X  3 [ j ], j =1,2,..., n . 
Then the problem of acquiring phrase semantic rules is a problem of mining cross-level strong association rules guided by the metarule P on the universe of items I and the universe of transactions D . And it is a two-step process: the first step is to find all frequent itemsets which comply with the metarule P ; and the second step is to gener-ate strong association rules from these frequent itemsets. 3.2 Finding Frequent Itemsets Apriori is an influential algorithm for mining frequent itemsets for single-dimensional Boolean association rules. To acquire phrase semantic rules for Chinese, we proposed a variation of Apriori, named P_CLA, which is a metarule-guided algorithm for min-ing cross-level association rules. 
Similar to Apriori algorithm, P_CLA employs an iterative approach known as a level-wise search. In the first iteration of P_CLA, the find_frequent_1-itemset s proce-dure finds the set of frequent 1-itemsets L 1 . Since each itemset in L 1 complies with the set of frequent k -itemsets complying with the metarule P (denoted P quent ( k +1)-itemsets complying with the metarule P (denoted P Furthermore, to improve the efficiency of P_CLA, we take measures to reduce the number of transactions scanned in future iterations. The Find_frequent_1-itemsets Procedure A top-down strategy is employed, where counts are accumulated for the calculation of frequent items at each concept level, startin g at the highest level and working towards the lower, more specific concept levels, until no more frequent items can be found. The Gen_candidates Procedure The gen_candidates procedure performs two kinds of actions, namely join and prune, 1. The join step joinable if their first k -1 items are in common and ther e are not  X  X ncestor X  or  X  X onge-ner X  relationships between items. It ensures that not only no duplicates are generated, but also only the itemsets complying with the metarule P can be generated. 2. The prune step property [5] is used. For P_CLA, the following two derived properties should be ap-plied: (1) All non-empty subsets of a frequent itemset complying with the metarule P support for all levels, all the ancestors of a frequent itemset must also be frequent, on the contrary, any child of a non-frequent itemset cannot be frequent. 
The gen_candidates procedure prunes twice. Applying the first derived property, should be pruned. All the pruned candidates are added to a set (denoted E t ). After the join step is completed, the late pruning is performed. If any ancestor of a candidate in + is a member of E t , the candidate should be pruned. To reduce the duplicate judg-ment of ancestor relationship between itemsets, only the member of minimal cover of all known non-frequent k -itmesets is remaining in E t . Transaction Reduction In P_CLA algorithm, three transaction reducing measures are taken: (1) After the set the database D , and eliminate transactions which do not contain any frequent 1-contain any frequent k-itemsets can be remove from D k while D k is scanned to deter-candidates is greater than the threshold value, D k +1 will be reduced again. 3.3 Generating Candidate Rules frequent itemset c which is found by P_CLA. If the other items in c are denoted by a 1 , a , ... , a Through the transformation of rule form, the candidate phrase semantic rules are acquired from these strong candidate association rules. 3.4 Optimizing the Set of Phrase Semantic Rules In the candidate phrase semantic rule set, some rules are redundant due to  X  X ncestor X  relationships between items and  X  X uperset X  relationships between itemsets. If these rules are directly used in parsing Chinese phrases, it will not only increase the amount of computation, but also produce much interference and misleading. 
Let GL be the set of candidate rules which are generated in section 3.3. We define proximate degree of support count and confidence between rules and the principle of the strongest restrictions. subset rule (a rule p is an subset of a rule q , if their right hand side are same and the rule of p which is a subset rule of q . And if the support count of p and q are approxi-p  X  q ; Otherwise, we say p cover q , denoted by q  X  p . 
Since the  X  X over X  relation on GL is transitive approximately, ( GL ,  X  ) can be con-sidered as a poset. Illuminated by Hasse diagrams of poset, we propose the following method to draw the cover relation diagram of GL : (1) Each rule in GL is represented there exists r  X  GL , and p  X  r  X  q , then remove the arc from vertex q to vertex p ; (3) Remove the self-loop at each vertex. All the rules corresponding to vertexes with zero indegree in the diagram compose the optimal set of GL . 
Therefore, the major idea of our semantic rule optimization algorithm is: first, draw zero in non-descending order of the length of candidate rules; finally, add rules corre-sponding to vertexes with zero indegree to the optimal set of GL . The resulting opti-mal set of GL is the acquired set of phrase semantic rules for Chinese. phrases extracted semi-automatically from the People's Daily Corpus (PDC, 2000) and an electronic version of Reader Magazine (1995-2006). The corpus can be divided into  X  X +n X ,  X  X dj+n X ,  X  X +n X ,  X  X dj+adj X ,  X  X +adj X ,  X  X +n X  and  X  X +v+n X  eight subsets. All phrases are annotated with syntactic and semantic information, such as POS, semantic relation and etc. All word tokens are tagged by the HowNet definitions. 
Employed the method proposed in this paper to the corpus, we found 3,266 candi-date phrase semantic rules. After optimized, only 379 rules remained. 
To verify the effectiveness of the proposed method, the following three different rule sets are employed respectively to parsing Chinese phrases: R 1 , a rule set consists of rules which are adapted directly from message structures in HowNet -Chinese algorithm for mining candidate rules; R 3 , a rule set acquired by the optimization algo-phrases (POS tagged only) extracted from newspaper texts is used in open test. consistent with our assumption that a corpus-based method is more objective and comprehensive than an intuition-based one. By comparing the size of these three rule relative, and the increase of time consump tion is receivable. The recall and precision of R 2 and R 3 are similar, whereas R 2 is 8.6 times larger than R 3 , and it is even worse that the close test of R 2 spends considerable time and space. These experiments show that the acquisition algorithm and the optimization algorithm for acquiring phrase semantic rules are effective and feasible. 
Rule The semantic collocations play important roles in parsing Chinese phrases, which are useful for both semantic and syntactic disambiguation. In this paper, a representation of phrase semantic rules for Chinese is presented, and a corpus-based method was proposed to acquire phrase semantic rules from a Chinese phrase corpus annotated with syntactic and semantic information. The method is shown to be very effective in performance of the rule set. mantic tagging. Another interesting research direction is to apply phrase semantic rules to machine translation, information retrieval and other NLP applications. Acknowledgments. This work was supported by the National Nature Science Foun-dation of China (60373080). 
