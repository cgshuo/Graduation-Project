 Given huge collections of time-evolving events such as web-click logs, which consist of multiple attributes (e.g., URL, userID, times-tamp), how do we find patterns and trends? How do we go about capturing daily patterns and forecastsing future events? We need two properties: (a) effectiveness, that is, the patterns should help us understand the data, discover groups, and enable forecasting, and (b) scalability, that is, the method should be linear with the data size.

We introduce TriMine , which performs three-way mining for all three attributes, namely, URLs, users, and time. Specifically TriM-ine discovers hidden topics, groups of URLs, and groups of users, simultaneously. Thanks to its concise but effective summarization, it makes it possible to accomplish the most challenging and im-portant task, namely, to forecast future events. Extensive exper-iments on real datasets demonstrate that TriMine discovers mean-ingful topics and makes long-range forecasts, which are notoriously difficult to achieve. In fact, TriMine consistently outperforms the best state-of-the-art existing methods in terms of accuracy and ex-ecution speed (up to 74x faster ).
 Categories and Subject Descriptors: H.2.8 [ Database manage-ment ]: Database applications X  Data mining General Terms: Algorithms, Experimentation, Performance Keywords: Time-stamped events, Tensor analysis, Topic model, Forecasting
Our motivating application is to find patterns and trends in a large set of clicks, consisting of multiple attributes (URL, user ID, timestamp, access devices, http/document referrer, etc). Are there emerging topics? Can we group URLs (and users), accordingly? How many clicks should we expect from user  X  X mith X , tomorrow? We shall refer to such settings as a sequence of complex events . Each event has a timestamp, and has multiple categorical attributes associated with it -in our example, a URL, which we shall refer to as an  X  object  X , and a userID as an  X  actor  X . Such settings naturally appear in countless domains including click logs on web sites [1], social network services, location-based services [15], social tag-ging, and many more. Informally, if each event has a time stamp and two attributes, the problem we want to solve is that described below.
 a sequence of millions of triplets (object, actor, time stamp),
We can generalize for an arbitrary number of attributes (i.e., more than three attributes) and we describe this later. The ideal method should be (a) effective in finding patterns, (b) accurate in forecasting, and (c) scalable ; it should help us understand what are the major trends, it should provide an easy-to-understand summary, it should help spot anomalies (with respect to all three aspects -URLs, users, time); and to visualize the results; and of course, the processing should be fast, and ideally, linear with the input size.
We present a novel method, TriMine , which automatically finds patterns in huge collections of complex events. Specifically, it finds three-way patterns (hence the prefix): It finds hidden topics (such as,  X  X ports X ,  X  X ews X ), and correlates each topic with all three as-pects.

Preview of our results. Figure 1 shows the results we obtained with TriMine on real web-click logs, where each click is of the form (
URL , userID , timestamp ). We will see this collection of plots sooftenthatwehavegivenitaname, X  TriMine -plot X . This plot consists of two ternary plots, and a time plot, as described later.
In general, each web site may cover one or more topic(s), and each user would be associated with a few topics. Thus, we could expect both finance news and stock market sites to attract roughly the same users, with similar temporal patterns, and so those sites should be grouped under the same topic, say,  X  X usiness X .
Figure 1 shows a TriMine -plot with some of our findings, namely it detects/reveals the hidden topics of web click events. More specif-ically, the figure shows the three major topics, and how they related to each of the three aspects, namely (a) to each web site (URL), ex-pressed in the O matrix, (b) to each user (in the A matrix), and (c) to each time-tick ( C matrix). The first two are represented as trian-gular plots (also known as  X  X ernary plots X ), where each 3-d point is represented as a point in a triangle (since the sum of the 3 coordi-natesislessthan1).

TriMine successfully detects some of the hidden topics in the web click logs, and we have manually named them  X  X usiness X ,  X  X e-dia X  and  X  X rive X . The first ternary plot shows the URLs; notice that several of them focus almost exclusively on the topic  X  X rive X , sev-eral others on  X  X edia/news X , a few focus exclusively on  X  X usiness X . The ternary plot of the users shows an even clearer separation: most dots (= users) are on the spokes from the center to the vertices, indi-cating a very clear clustering of users, along the three hidden topics. Neither of the two ternary plots exhibits any striking outliers.
The third plot (Figure 1 (c)), shows the evolution of each topic over time (red, green, blue, for  X  X rive X ,  X  X edia X ,  X  X usiness X  respec-tively). Notice a clear daily periodicity for all the topics (unsurpris-ing), but also notice (1) the decline in  X  X lue X  (= X  X usiness X ) during weekends, and (2) the spiking of  X  X ed X  (= X  X rive/traveling X ) during weekends. In retrospect, both make sense. Also notice that  X  X reen X  (=  X  X edia/news X ) does not have a weekly periodicity, apparently because our users are constantly interested in news.

In contrast, Figure 1 (d) shows the original raw sequences of 100 randomly selected users (at a  X  X oney X  site). Notice that the raw data exhibits no obvious patterns, neither periodicities nor clusters of users.

Our main point is that the two  X  X ernary plots X  and a simple time-plot can give a clear, concise summary of both  X  actors  X  (users) and  X  objects  X  (URLs), as well as of the major temporal patterns. Thanks to these three building blocks, we can extend this approach to com-plex event forecasting, which is notoriously difficult to achieve.
Contrast with competitors. Table 1 compares TriMine and its forecasting method, TriMine-F , with existing methods. We illus-trate their strengths and shortcomings: a check mark ( that the corresponding method (column) fulfills the corresponding requirement (row). Only our approach has checks against all en-tries, while, Table 1: Capabilities of approaches. Only our approach meets all specifications.

Contributions. The proposed method has the following advan-tages: 1. Effectiveness: TriMine operates on large collections of com-2. Accuracy: as we will show, our approach is accurate in fore-3. Scalability: TriMine is linear with the input size, and thus
The rest of the paper is organized in a typical way: Next we de-scribe related work, followed by definitions, the proposed method, experiments and conclusions.
Recently significant progress has been made on understanding the theoretical issues surrounding learning mixture distributions in theoretical computing and machine learning [9, 28, 22]. La-tent Dirichlet allocation (LDA) [4] and probabilistic latent seman-tic analysis (PLSA) [5] are well-known latent variable models for analyzing large sets of categorical data, such as bags of words for text, and bags of features for images. A number of methods have been proposed for analyzing the time evolution of topics in doc-ument collections, such as the dynamic topic model (DTM) [3], topics over time (TOT) [24], and more [25, 2, 27, 7, 8, 6]. For example, DTM employs a fixed length of window size, and takes account of capturing only the current epoch distribution. Similarly, TOT handles a single window size, and it uses Beta distributions to capture time-evolving topics. Very recently, Hong et al. presented a new topic model for predicting the volume of terms in documents (i.e., aggregate count of each keyword). These models do not fo-cus on finding multiscale and/or periodical trends, which means that it is difficult to employ them for the long-term forecasting of complex time-stamped events. On the other hand, as shown in the introduction section (see Table 1), our method finds cyclic patterns with different timescales, which allows it to predict future events effectively and efficiently.
 For web-click analysis, Agarwal et al. [1] exploit the Gamma-Poisson model to estimate click-through rates (number of clicks per display) in the context of content recommendation, which does not focus on trend discovery of time-stamped events.

The work on tensors is also related. Kolda et al. [10] provide a powerful tool for tensor analysis on a web link structure. Rendle et al. [19] propose a method for tag recommendation based on tensor factorization. Unlike our method, these methods are not intended to predict future events.
 Remotely related is the work on large-scale time-series mining. Similarity search and pattern discovery in time sequences have also attracted huge interest [20, 14]. Papadimitriou et al. [17] propose an algorithm for discovering multi-scale local patterns, which con-cisely describes the main trends in data streams. Skewed stream problems have been studied in the context of summarization and modeling [11]. Sakurai et al. [21] proposed BRAID, which effi-ciently detects lag correlations between data streams. AWSOM [16] is one of the first streaming methods for forecasting and is designed to discover arbitrary periodicities in single time sequences.
In this section, we formally define related concepts and the task of event forecasting. Consider that we receive time-stamped event entries of the form (object, actor, timestamp) .Wethenhaveacol-lection of entries with u unique objects and v unique actors. As-sume that we are given time intervals t ( =1 , 2 ,...,n )oflength l (e.g., one hour). It is convenient to treat our complex-event se-quence as a 3rd-order tensor, i.e., X X  N u  X  v  X  n ,where duration of events.
 order tensor of complex time-stamped events. The element x X shows the total number of event entries of the i -th object and the j -th actor at time interval t .

After we decide on some time granularity (say, one hour) then we have (actor, object, time-stamp; count), for example, ( X  X mith X ,  X  X nn.com X ,  X 3am June 1, 2003 X ; 23). Unless otherwise specified, our time granularity is one hour. Thus, the example tuple above means that  X  X mith X  visited  X  X nn.com X  23 times, between 3am-4am on June 1, 2003.

For a particular event collection, we assume that an event entry has a certain  X  latent topic  X . We model such hidden topics in terms of three aspects, namely,  X  object  X ,  X  actor  X , and  X  X ime X . In that case, the original tensor will be decomposed in three matrices O with the following definitions and properties: shows the participation strength of object i for topic j . Our upcoming TriMine forces that the participation weights be non-negative, and they sum up to 1, for each object ( j 1 ). The definitions of A and C are analogous, and omitted for brevity. We shall refer to O , A and C as participation matrices , exactly because they show how strongly each actor , object , time stamp participates in topics #1, #2, ... ,# k , respectively. Figure 1 plots the visualization of the three matrices for a real dataset (we show three major topics).

We also consider a case where every event has more than three attributes (i.e., M&gt; 3 ). We provide an M th-order tensor, which is decomposed in M matrices, O , A (1) , ... , A ( M  X  2) mainly focus on a 3rd-order tensor for simplicity throughout this paper, our method however can be applied to higher order ten-sors. Table 2 summarizes the notation correspondences for the time-stamped events.
Our goal is to extract the main trends and hidden patterns of an event tensor X , and forecast future events. Specifically, the sub-problem that we want to solve is as follows: Given atensor X of complex events of (actor, object, time stamp) triplets, Find the hidden topics that best summarize the events in X , and the corresponding actor-and object-groupings.

Once we have the main trends from X , we can proceed to solve the forecasting problem: complex events, Forecast future traffic.
 More specifically, we want to forecast, e.g., how many clicks user  X  X mith X  will generate tomorrow; or how many clicks  X  X ww.cnn.com X  will attract over the next seven days; or we want to generate a realistic-looking set of clicks, for, say, next Sunday.

As mentioned in the introduction, the ideal method should be ef-fective (capturing trends that make sense), accurate in its forecasts, and scalable , to handle millions or billions of events.
There are many applications for time-stamped events. Here, we briefly describe application domains and provide some illustrative, intuitive examples of the usefulness of our approach.

Access analysis. Web content such as blogs, on-line news, web mail and SNS has been attracting considerable interest for business purposes as well as personal use. Consider a large number of clicks on web sites, where each click has a list of attributes, e.g., access (url_id, user_id, time) . Suppose that we can record all these at-tributes on an hourly basis for all users of the web sites. For this huge collection of web-click logs, we would like to find patterns of user behavior to allow us to perform a sociological and behavioral analysis. For example, web masters and web-site owners could find daily access patterns and forecast the subsequent week to aid the design of advertisements.

E-commerce. Let us assume an online service such as onde-mand TV, which records the TV programs viewed by every user; each record is an online viewing event of form view (channel_id, user_id, time) . Discovering groups in such data and forecasting future viewing events would assist with tasks such as content tar-geting.
In this section we describe our method, TriMine , for dealing with the pattern discovery problem (Problem 1). In the next section we show how to employ TriMine results for forecasting (Problem 2).
There are two main ideas behind TriMine : Figure 1(a)-(c) illustrates the O , A and C matrices, respectively, for the WebClick dataset. objects and actors are categorical, and the O and A matrices are visualized as ternary plots, where each dot is an object / actor . The three columns of the time matrix are plotted in (c), illustrating the temporal evolution of the three discovered topics.

Single-level analysis -TriMine-single . Figure 2 (dotted-line rect-angle) gives a pictorial description of the 3-way analysis. The ob-ject matrix O takes account of all the objects over the entire time range, which produces an accurate summary of the object-topic re-lationship. The actor matrix A shows the frequency of entries over actors for the i -th topic ( i =1 ,...,k ). The time matrix scribes the degree to which the time stamp is associated with the i -th topic.

Multiple-level analysis -TriMine . Figure 2 (solid-boundary rectangle) also shows an example to explain how to perform the multi-level analysis. Instead of handling only a single window size, we introduce a multiple time window approach to capture the main trends of multiple scales. Starting with the window size l first level h =0 , we compute the time matrix C (0) , then increase the window size l h , and repeatedly obtain C ( h ) for various sizes. This enables the forecasting method (discussed later in Section 5) to exploit the relationship between C ( h ) across different scales.
Given an M th-order complex event tensor X , our goal is to find a meaningful summary with k hidden topics that best describes Figure 2: Illustration of TriMine . TriMine-single (dotted-line rectangle): We extract k topics from an event tensor X with respect to three aspects, i.e., objects O ,actors A , and time TriMine (full, solid-boundary rectangle): We perform a 3-way analysis for multiple window sizes l 0 , l 1 , l 2 , ... to capture the multi-scale dynamics of X . Notethatwereusethe O and A matrices for all scale levels to provide an efficient solution. More specifically, we want to compute the  X  X nterpretable features X  with respect to all M aspects. We propose using the concept of topic modeling to extract the major factors automatically. TriMine infers the M matrices, i.e., the object matrix O ,the actor matrices A (1) , ... , A ( M  X  2) , and the time matrix C , and then identifies the relationship between the properties of these matrices. It can also discard many redundancies (e.g., noise) from the events, and focus on what really matters.
The task is to infer the M matrices over the hidden topics. We assume that each event entry has its own  X  X atent topic X , and thus we propose using collapsed Gibbs sampling [18] to assign a latent topic for each event entry. The generative process for a set of event entries is as follows: 1. For each topic r =1 ,...,k : 2. For each object i =1 ,...,u : Here,  X  ,  X  ( m ) and  X  are the hyperparameters for O , A ( m ) respectively.
 For simplicity, hereafter we focus on a 3rd-order tensor (i.e., M =3 ). For each non-zero element x i,j,t in X ,wedraw x i,j,t tent variables with probability p (Equation 1), and decide the latent variable for every event entry. The latent variable z i,j,t for element x i,j,t in the following manner: p ( z i,j,t = r |X , O , A , C , X , X , X  ) (1) where o i,r , a r,j ,and c r,t are the total counts that topic to the i -th object , j -th actor , and time-tick t , respectively. Note that the prime (e.g., o i,r ) indicates that the current datum has been excluded from the count summations, that is, it indicates the count with the entry of the i -th object and the j -th entry at time Here,  X  ,  X  ,and  X  are the parameters of the Dirichlet priors for A ,and C , respectively. After the sampler has burned-in, we can produce estimates of  X  O ,  X  A ,and  X  C as follows: The time complexity of each sampling iteration is O ( N ) ,where is the total number of event entries in X (i.e., i,j,t x i,j,t
Until now, we have assumed that the window size (say, l )was given. In reality, it is up to us to choose it. What is the right value for it? minute? hour? day? This is a difficult choice -our approach is to not make a choice, and use all of the above. More specifically, we use several window sizes. Our approach makes the algorithm slightly more complicated, but it pays off significantly in terms of long-term forecasting accuracy, as our experiments show (see Fig-ures 7 and 8).

In short, as a typical choice, we use a set of all such window sizes, i.e., an hour, a day, a week, a month. Another reasonable idea is that we use a geometric progression of window sizes, that is l := l 0  X  L h for h =0 , 1 , 2 , ..., log n ,where l 0 is the shortest window, and L is the growth factor, typically L =2 . Thus, in either case, the count of the window set L that we need to examine is greatly reduced, as compared, say, to an arithmetic progression.
Here, we explain how to perform the necessary computations for multi-scale trend discovery. The straightforward solution is that we consider a set of tensors {X (0) , X (1) ... } for all window sizes, and compute TriMine-single , for each level. We refer to this approach as TriMine (naive). Still, this is computationally expensive because we need an inference for each window.

Efficient solution. We propose reusing the inference results of the first level to approximate the inference for the other levels. We show how our method performs the computations in Figure 2. For level h =0 , we compute the matrices, O , A ,and C (0) the tensor X (0) (= X ). For the other levels ( h  X  1 ), we reuse the results of the sampling in the first level, and compute the current matrices, i.e., (a) we share O and A for all levels, and (b) compute the time matrix C ( h ) by using the set of sampling results for the first level, as follows: where l h denotes the window size at level h . The justification is that the assignment for each event entry is probabilistically equivalent for all levels, which means that the latent topics of every level are computed by the same procedure. Compared with TriMine (naive), which needs O ( N log n ) time to update the parameters for all lev-els of the structure, the efficient version of TriMine is linear with the input size, i.e, O ( N ) .

The overall procedure of TriMine is given by Algorithm 1. For each entry in X (0) at the first level, we assign a hidden variable z according to Equation (1). After the sampling, we compute the triplet matrices O , A ,and C (0) given a set of hidden variables. For each window size level, we approximate the matrices from their first level. Our method maintains the multi-scale window structure, which allows us to provide the output of an arbitrary window scale. Algorithm 1 TriMine( X (0) ) We have already presented some of our meaningful features (see Figure 1, ternary plots of O , A , time-topic sequences C visually and numerically, extracted from complex time-stamped events. While clustering, visualization and anomaly detection are provided straightforwardly by our output, we focus on the most challenging problem of TriMine , namely, complex event forecast-ing (Problem 2). We refer to this extension of TriMine for forecast-ing as TriMine-F .

Individual-sequence forecasting. Once we decide a time-window length l , we can turn the problem into u  X  v forecasting problems, one for each ( actor , object ) time sequence. Then we can use any forecasting method. This approach requires at least space and O ( uvn ) time, to predict the future event counts of all sequences. Here, one subtle, but important issue is that most of the ( object , actor ) pairs have very sparse sequences, which derails all typical forecasting methods because they look like noise (e.g., { 0 how can we avoid this issue? We propose using the  X  hidden top-ics  X  to achieve much better forecasting. Our proposed TriMine-F method can avoid the sparsity problem, because  X  X opics X  have non-trivial activities, even if some of the actors (or objects) of these topics have sparse activity.
Given the results of TriMine , we can forecast the dynamics of activities C for each topic r ( r =1 ,...k ), and then translate it to URL ( object ), or user ( actor ) activity, using the participation matrices O and A , respectively.

Preliminary: single-level equation. If we had a single time granularity (say, window width l 0 ), then we would do auto regres-sion (AR), and we could forecast the activity c r,t for topic t as a function of the w previous activity levels c r,t  X  1 plus, (filtered) noise t : Figure 3: Illustration of multi-scale forecasting (here, 1 ,l =2 ). The gray cells indicate the variables we use to fore-cast c r,t . Notethatweuse w variables ( w =2 in this example) from each level. where  X  is a regression coefficient.

Multi-scale dynamics. How should we operate multi-scale pro-portions for event forecasting? Real time-stamped events typically include bursty patterns, noise, spikes, and dips, as well as the event trends of multi-scale periods, all of which are unknown in advance. Long-term patterns are included in the time matrix at the top level while short and sharp fluctuations appear at the first level. Thus, instead of using a single level of window size, we fit a model to the time matrices of multiple levels, (i.e., C (0) , C (1) ,... level case, our forecasting method uses log n additional levels (see Figure 3). Thus, we try to fit models of the following form:
Here we answer two questions: Clearly, the second question is more general. if we can answer that, we can easily give the count estimate for the first question (and also the variance etc, since we can generate many event samples).
A few clarifications, first: (a) without loss of generality, we as-sume that we have agreed on the aggregation length l , and each time-tick is l seconds long. (b) We can easily extend our solu-tions to long-term forecasting such as estimate the number of clicks from user  X  X mith X  to URL  X  X NN.com X , for the next 30 days , i.e., x i,j,t ,( t =1 , 2 , ..., 30) . (c) We can easily extend our answers to marginals (or  X  X on X  X  cares X ), for example, estimate the number of clicks from user  X  X mith X , to any URL, for tomorrow , i.e., estimate x  X  ,j,t where we follow the Unix convention and  X * X  means  X  X on X  X  care X .

Count estimation. The  X  X ount X  question can be answered easily by using following steps: (a) forecasting the strength c r,t topic r =1 ,...,k at time-tick t , and (b) using the participation matrices O and A to translate from topic activity to URL-and-user activity (= clicks). We can then estimate the count of an element ( x i,j,t )ofthe i -th object and the j -th actor at time t : where n is the duration of forecasted events, and  X  x i is the average number of events per time-tick for the i -th object .

Complex event generation. For the event-generation problem, the answer is more elaborate, and is illustrated by Algorithm 2. The idea is again to forecast the future activity  X  c t,r multinomial samples using the participation matrices O , A  X  C . To generate a set of event entries, our sampling-based approach obtains an appropriate number of independent samples of the statis-tic directly from the underlying generative model. The samples can then be organized into a set of entries of form { object , actor , time } simply by gathering all the event entries together.
 Algorithm 2 EventGeneration (  X  x 1 ,...,  X  x u ,n, O , A ,  X  C
To evaluate the effectiveness of TriMine , we carried out exper-iments on real datasets. Our experiments were conducted on an Intel Core 2 Duo 1.86GHz with 4GB of memory, running Linux. The experiments were designed to answer the following questions: 1. Effectiveness: How successful is TriMine in capturing time-2. Forecasting accuracy: How well does our method forecast 3. Scalability: How does our method scale with the dataset size
Datasets. We performed experiments on two real datasets:
WebClick dataset. For a few users (or URLs), human could eye-ball them, and derive meaningful patterns. But, how can we ac-complish this automatically for thousands of users? Some of the results obtained with for our method for the WebClick dataset have already been presented in Section 1 (see Figure 1), which shows that TriMine effectively and efficiently discovers the three-way patterns (i.e., TriMine -plot). Figure 4 also shows a TriMine -plot on WebClick in relation to three different topics,  X  X ommunication X ,  X  X log X , and  X  X ood X . ) (c) Time evolution of topics ( C ) (d) Original sequence periodicity etc, see (c)). Raw data (d), appears bursty and noisy.
Ondemand TV dataset. Figure 5 shows the major topics,  X  X ports X ,  X  X ction X , and  X  X omance X  (namely,  X  X oap operas X ).
We demonstrate how our forecasting method, TriMine-F , works well for time-stamped events, specifically, we evaluate our method using a real dataset, WebClick , in terms of long-term forecasting, which is a challenging task. We should note that generating more than, say, 10 steps ahead is very rare: most reported methods [26] generate one step ahead, obtain the correct value of time-tick only then try to generate t +1 . Nevertheless, our goal is to capture long-term behavior, and we will show that our method achieves this, unlike the alternative methods.

Experimental setup. In our setting, we first trained our models by using the click entries of the first two weeks, and then forecasted the following weeks. We selected the window size l 0 =2 ,thatis, (a) URL ternary plot ( object -topic) (b) time evolution of topics Figure 5: Effectiveness of TriMine on the Ondemand TV dataset. Rather clear separation of URLs into  X  X ction X ,  X  X ports X  and  X  X o-mance X  (see (a)); clear daily periodicity for all topics (see (b)), with weekly periodicity for  X  X ports X  and  X  X ction X , but not for  X  X omance X . the length of the training set X (0) was n = 168 . We chose the total forecasting coefficients as 40 , and the hidden topics k =30 .
We compared our algorithm with state-of-the-art methods with respect to forecasting the number of  X  X uture X  clicks for all possi-ble URL and user combinations. (a) AR : This is a straightforward solution to the forecasting problem. We turned the event tensor X into a set of u  X  v sequences for each URL and user. Af-ter obtaining the sequence set, we applied standard AR modeling for each sequence individually. For a fair comparison, we used 40 regression coefficients. (b) PLiF : We compared our algorithm with PLiF [13], which is based on Linear Dynamical Systems (also known as Kalman filters). It captures the correlations between mul-tiple sequences, and has the ability to forecast sequences. The orig-inal signals are bursty, thus we take their logarithm according to [13]. (c) T2 : Very recently, Hong et al. present a new topic model for tracking trends [6]. We refer to it as T2 in this paper. We used the model parameters of T2 , which can capture the evolution of topics in data collections. In our setting, we inferred the model pa-rameters using entries of duration n . At time-tick n , we stopped the inference, and the latest model parameters were used to predict all of the future events.
Temporal perplexity. We first evaluate the forecasting accuracy of our method in terms of perplexity. Here, we compare TriMine-F with T2 . A lower perplexity indicates a higher predictive accuracy. The perplexities per time-tick are shown in Figure 6. TriMine-F captures the general periodic trend, with a desirable slight confu-Figure 6: Perplexity at each time-tick. TriMine achieves the lower perplexity; we can appropriately forecast the dynamics of hidden patterns. sion about the period in both datasets (i.e., WebClick and Onde-mand TV ). T2 , on the other hand, is not intended to capture long-term trends. The figure shows that T2 fails to predict the future events.

Accuracy of event forecasting. We also compared our algo-rithm with the standard AR method and the state-of-the-art meth-ods, PLiF and T2 , with respect to forecasting a number of  X  X uture X  events. Figure 7 (a)-(b) shows the root mean square error ( between the original and the forecasted event sets of each URL and each user (we call it  X  X ndividual forecasts: x i,j,t  X ). Similarly, Fig-ure 7 (c)-(d) describes the results of  X  X arginal X  forecasts: that is we forecast the aggregated counts of each user j at every time-tick t . A lower value indicates a better forecasting accuracy. Note that cyclic dips occur in the middle of the night, because we have only a few click entries at this time interval. T2 was partially successful in generating the future clicks, however, it frequently failed to forecast future event entries. The alternative forecasting methods, AR and PLiF also failed to forecast the entries, because each sequence was too sparse to capture the cyclic patterns. Un-like the alternative methods, our method achieves high forecasting accuracy for every time-tick. TriMine-F outperforms the state-of-the-art methods in terms of forecasting accuracy, and similar trends were observed with the other dataset. We omit the results due to space limitations.
In this subsection, we discuss how TriMine-F captures the pat-tern dynamics. To evaluate the effort from the properties of mul-tiple time scales in our model, we implement a special version of TriMine-F by removing this property. Specifically, we use only a single regression coefficient set, (i.e., Equation (4)). We refer to it as TriMine-F (single). We used the same coefficients ( =40 ) for a fair comparison. Figure 8 shows the temporal evolution of two major topics for the WebClick dataset. We trained our mod-els with click events over a period of two weeks (dotted lines in the figure), and then forecasted the following two weeks. The top, middle and bottom rows of this figure show the output of TriM-ine , TriMine-F (single), and TriMine-F , respectively. In this figure, TriMine does not undertake forecasting, it simply shows the current topic weights at each time. TriMine-F is our full solution for event forecasting, which includes multi-scale analysis. The figure shows that our forecasting method, TriMine-F , successfully forecasts the subsequent weeks. Specifically, TriMine-F (single) failed to cap-ture the dynamics and moved towards convergence. On the other hand, our full solution successfully captured cyclic patterns and pe-Figure 7: Forecasting accuracy for individual x i,j,t (top) and marginal x  X  ,j,t (bottom): TriMine-F consistently outperforms the state-of-the-art methods with respect to accuracy (root mean square error ( RMSE ) between real values and fore-casts). WebClick dataset, long-term forecasts starting at t=168 (i.e., after two weeks) (also see Figure 8). Lower is better. We omit the AR results for hourly error (a) and (c), due to high er-ror values. Notice that TriMine-F gives the lowest error. Also see the text for more observations. riodicity. Consequently, using multi-scale analysis has a significant advantage, which leads to high forecasting accuracy.
We now evaluate the efficiency of TriMine-F for event forecast-ing. Figure 9 compares our method with the AR method in terms of wall clock time when duration n is varied. We use the WebClick dataset for this experiment, where the numbers of URLs and users are u =1 , 000 ,and v =10 , 000 . The wall clock time is the pro-cessing time needed to compute statistics/coefficients and provide the output (i.e., forecasts). Note that T2 and PLiF are based on the Kalman filter and are not scalable for large datasets. These meth-ods need more than 10 6 seconds to compute even at n = 100 , thus we omit the results. We present our efficient approach for multi-scale analysis in Section 4.2.2. To evaluate the efficiency of this approach, we also show the basic approach, which we call TriMine-F (naive). The empirical results in these figures fully substantiate the superiority of TriMine-F (i.e., our full solution). We observed that TriMine-F achieved a dramatic reduction in computation time that can be up to 7 times faster than TriMine-F (naive), and 74 times faster than AR.
We addressed the problem of finding patterns and trends, for  X  X omplex X  events of the form ( URL, userID, timestamp ), and, in general ( object , actor , time).

We presented TriMine , which has all of the following properties: Figure 8: Benefit of multiple time scales. Top: the two main trends of the WebClick dataset, namely,  X  X usiness X  (blue) and  X  X edia X  (red). Middle and bottom: TriMine-F clearly outper-forms TriMine-F (single). Both methods start long-term fore-casting at t=168 (i.e., after two weeks). Our multi-scale TriMine-F reflects reality better, while TriMine-F (single) quickly con-verges to the mean (red), and even worse, predicts near-zero for (blue), blinded by the low activity during weekends.
We also demonstrated the practicality of TriMine , by applying it to several real datasets, both for pattern discovery and forecasting. Figure 9: Scalability of event forecasting: wall clock time vs. dataset size (= duration n ). Our methods are linear (i.e, slope 1, in log log). TriMine-F is 7x times faster than TriMine-F (naive), and 74x faster than AR . We omit the T2 and PLiF results due to the high computation cost.
