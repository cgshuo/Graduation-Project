 Recent advances in click model have positioned it as a n effective approach to estimate document relevance based on user behavior in web search. Yet, few works have been conducted to explore the use of click model to help web se arch ranking. In this paper, we focus on learning a ranking function by taking the results from a click model into account. Thus, besides the editorial relevance data arising from the explicit manually labeled search result by experts, we also have the est imated relevance data that is automatically inferred from click models based on user search behavior. We carry out extensive experiments on large -scale commercial dataset s and demonstrate the effectiveness of the proposed methods . H.3.3 [ Information Systems ]: Information Search and Retrieval; I.2.6 [ ARTIFICIAL INTELLIGENCE ]: Learning Algorithms, Design, Experimentation, Theory Click Model, Search Ranking, Log Mining Since cl ick -through logs encode user preferences on search results, utilizing a user  X  s click -through behavior on search results to automatically estimate document relevance has attracted more and more research attention recently . This task is challenging due to th e well -known positional bias problem [ 4]. A number of studies [ 3, 5, 6, 8] have attempted to address this problem so as to infer unbiased relevance . Most of these works attempt to model user behaviors on search results and accurately predict future user activities. These kinds of methods are also called click model s . For example, [5 ] proposed a User Browsing Model (UBM) by extending the examination hypothesis. [ 6] proposed a Click Chain Model (CCM) and [3 ] proposed a Dynamic Bayesian Model (DBN) by analyzing user behaviors in a chain -style network. These c lick models have been considered as one of the most effective approaches to interpret user clicks and infer search relevance, and recen t advances in click models have moved forward aggressively . Yet, few works have been conducted to explore the estimated relevance to learn a ranking function. Existing works o n learning to rank [ 1, 2] mostly rely on editorial relevance dat a. However, colle cting editorial relevance data is very expensive because it is indispensable to cover a diverse set of queries in the context of web search . In contrast to the scarcity of editorial relevance data , terabytes of click -through logs are generated every day and user preference s are encoded inside the data . They ca n be collected at a very low cos t and used by click models to automatically infer the document relevance. Thus, it would be very desirable if we can replace the editorial relevance data by estimated relevance data when learning a ranking function. 
Figure 1. The correlation between estimated relevance and In our study, we observe that t here are strong correlations between editorial relevance and estimated relevance . Figure 1 shows the box plot between editorial relevance and estimated relevance. The x -axis is human label ing, which has five grades. Perfect means the most relevant document and Bad means the most irrelevant document. The y -axis indicates the estimated relevance computed in the General Click Model (GCM) [8]. In this paper, we propose three methods to better explore the estimated relevance in learning a ranking function. Since there are bunches of works investigating learning a relevance function from cli ck-through logs, this paper does not argue that the proposed method can outperform each of them . Instead, this paper aims to give a study on how to leverage the estimated relevance inferred from a click model to learn a good ranking function.
 The remai nder of the paper is organized as follows. Firstly, we describe the background in Section 2. Then we propose several ranking models in Section 3 and conduct several experiments in Section 4. Finally, w e conclude the paper in Section 5. Here we introduce some background from two categories: one is click model and the other is search ranking . Click models were p roposed to model user s X  search behaviors, and compute the estimated relevance for each document query pair . In this pa per, we assume that click log stores a lot of search sessions. I n a session, a user submits a query to the search engine, and gets a set of document s * + . The user might examine the search result s, click s on some search results relevant to his query and then finish the session.
 For a document corresponding to a query , click model can automatically infer an estimated relevance based on the user click behavior . Thi s relevance value indicates the degree of correlation between a document and a query . For example, the estimated relevance in CCM and UBM can be represented as: Here indicates that the user clicks on document and Recently, GCM proposed a more general representation of the estimated relevance and demonstrates that most of the previous works, including DBN, CCM and UBM, can be reduced to GCM as special cases of the general representation. In GCM , the author s assume that a user chooses to click a document in search result s after exa mining it according to a distribution. This distribution is represented as a random variable ( ) . Then the click event will happen if and the estimated relevance is defined as ( ) . In the learning to rank area , there are documents for a query and the th document is . T he objective of learning to rank is to train a ranking function: Here the input of the ranking function is the feature vector of correspond s to query . The output of the function is a score indicating the predicted relevance of a document to a query.
 To train this ranking functi on, we provide each query document pair a label . This label is an editorial relevance value with in five grades and indicate s the relevance degree between and . Then a ranking algorithm is adopted to minimize a given cost function . For example, RankNet [2 ], a pairwise ranking model , defines the probability that should rank higher than with probability as: The cost function here is defined as the cross entropy cost : Here . For the target probability ,  X   X   X  if should rank higher than in the training data,  X   X   X  otherwise. The derivative of RankNet cost is: We use NDCG [7] to measure the performance of ranking algorithm. The NDCG is often truncated at a rank position as: Here is chosen such that the perfect ranking would result in . In this section, we first introduce the basic pairwise ranking model and then design three methods to exploit the estimated relevance when learning a ranking function. Our proposed ranking models are based on Neural Network and we can combine it wi th LambdaRank for editorial dataset. We firstly outline the approach leverag ing estimated relevance in the experimental Section of the DBN [3]. To the best of our knowledge, it is the only work which incorporates the estimated relevance inferred from click model to train a ranking function. This work assumes that a preference pair that should rank higher than is generated if . After all the pairs are generated, a ranking model may be adopted to learn a rankin g function to minimize the pair -wise error. In this paper, we use the GCM to calculate the estimated relevance of document as: Referring to the definition of RankNet in Section 2. 2, the proba bility of more relevant than is defined in equation (4) . The cost function to optimize is the cross entropy as (5a). The target probability  X   X   X  if and the target probability is  X   X   X  otherwise. We adopt RankNet as training model and optimize cross entropy loss in t raining data by the gradient descent algorithm. In above ranking model, the target probability of each preference pair is  X   X   X  if However, this approach neglects the value of . This va lue might encode the magnitude of each pair. Therefore, we propose Distribution -based Pairwise Rank aim ing to comput e a more reasonable target probability of each preference.
 Thus, f or a pair of ( ) , we have the estimated relevance distribution defined as and , and the target probability is: Then, we define the new cross entropy cost function as: Here we present an example in Figure 2 to illustrate the basic idea. Given three documents , and , we use ( ) ( ) and ( ) to indicate the estimated relevance distribution. We show their distribution difference in lower part of Figure 2. We can see that the probability ( ) is larger than ( that is superior than , while the low confidence for saying is superior than . The traditional pairwise ranking algorithm defines a smooth cost function to approximate the target evaluation measure. However, despite its merits , the pairwise ranking algorithm un necessarily neglect s the position effects in the rank list, while the evaluation measure NDCG is strongly related with the position in this list. In this section, we propose Value -based Lambda Rank to optimize search rank with estimated relevance data. In this ranking method, we change the cumulative gains as (11a): Therefore, the evaluation metrics for each query with estimate d relev ance is defined as: Here indicate s the estimated relevance of document ranked at position , and is a normalization factor that normalizes between 0 and 1. In order to maximize the score computed by , we adopt -gradient , which is similar to the one used in LambdaRank equal to the RankNet cost scaled by the difference in found by swapping two documents. For example, the -gradient for and rank at the position and can be defined as (1 3a), and the gradient of can be defined as (1 4a): As we introduce in Section 3.2, characterizing the estimated relevance as a distribution is more advantageou s than as a deterministic value. It is possible to derive more information . Simultaneously, designing a ranking algorithm by taking the position effect into consideration is important to optimize the NDCG. Thus, we take advantages of both the superiority in Section 3.2 and 3.3 to design a Distribution -based Lambda Rank. Considering estimated relevance as a random variable , the cumulative gain formula in (11a) becomes : Therefore , we refine our evaluation function for query as: Similar to (13 a) and ( 14a), suppose document rank s at the position , and document is ranked at position . The new lambda function is ( 15b), and the gradient is (16b): Here if both and ( ) ( ) , otherwise. The datasets we use for training and testing are extracted from two sources: an editorial relevance dataset labeled by human experts and an estimated relevance dataset inferred by GCM model. We carry out several experiments in order to answer following questions: 1. When it is only trained with the estimated relevance 2. Suppose we have a small amount of editorial data, can we 3. Can we combine both types of relevance dataset to achieve First and foremost, we conduct an experiment to show the results of ranking model s with estimated relevance only . The experime ntal result is shown in Figure 3 . Compar ing our three estimated relevance ranking models with the state -of-the -art model VP Rank, we find that our results are better in all positions and the improvements are consistent and significant. Among all our three proposed models, DL performs the best while VL is the worse in term of NDCG. This superiority is consistent in all position s. However, we find that LambdaRank trained on editorial relevance data still achieve the best NDCG value in most of positions. To answer the second question, we conduct an experiment wi th different size of the editorial data. We use the estimated relevance dataset as the basic training data and editorial judgment data as supplementary data in this experiment. The result is shown in Figure 4 . The four lines illustrate the changes of NDCG@ 5 value with the increase of editorial relevance data. Moreover, we add a black horizontal line indicat ing the NDCG@5 score of LambdaRank trained on 100% editorial judgment data only. estimated relevance dataset and editorial relevance dataset With the DL model , the percentage value to achieve the same NDCG@5 is 30%, while this value is about 70% for VL model. From this perspective , it show s that DL is much better in terms of the effectiveness of leveraging the data. We think this experiment shows that DL can bring huge benefit for commercial search engines for a lot of small market/language, there is always insufficient editorial relevance data due to the high cost. To answer the last question , we evaluate our click models on combined dataset s. We define a parameter to measure the ratio between estimated relevance data editorial judgment data. In general, suppose is the number of editorial judgment training pair s and is number of the estimated relevance training pair s. The whole training data with parameter is defined as: Here and | | | | . From the result in Figure 5 , we can see that the DP Rank and VL Rank could improve NDCG@5 with a particular ratio , and our DL Rank could improve NDCG@5 for 1 percent and the result on combinational data is consistently better than LambdaRank based on editorial relevance dataset only. Moreover, to verify this improvement in other position, we draw the best NDCG results in Figure 6 , which doubly verify that as compared with the LambdaRank trained with 100% percent of editor ial relevance data, introducing the estimated relev ance data can improve the NDCG@1, and this improvement is consistent. 
Figure 6. Best NDCG @1 among LambdaRank, DL and VL In this paper, we focus on the approaches to incorporate the estimated relevance generated by click model to learn a ranking function. To achieve this objective , we propose three methods and compare them with a state -of-the -art method . Our Distribution -based Rank model which regards estimated relevance as a distribution and uses lambda gradient to learn the ranking function perform significantly the best in all our experiments. Secondly, we combine two types of relevance data , which is applied to demonstrate that with about 30% of the editorial relevance dat a and estimated relevance data, we can achieve the same accuracy as that trained on 100% editorial relevance data. Finally, we learn a better ranking function of two types of dataset. The result show that with the introducing of estimated relevance data, t he accuracy can be improve d about 1 point in terms of both NDCG@1 and NDCG@5. [1] Burges C.J.C., Ragno R., and Le Q.V. Learning to rank [2] Burges C.J.C., Shaked T., Renshaw E., Lazier A. Deed s M. [3] Chapelle O. and Zhang Y. A Dynamic Bayesian network [4] Craswell N., Zoeter O., Taylor M., and Ramsey B. An [5] Dupret G. and Piwowarski B. User browsing model to [6] Gu o F., Liu C., Kannan A., Minka T., Taylor M., Wang Y., [7] Jarvelin, K., and Kekalainen, J. (2000). IR evaluation [8] Zhu Z.A., Chen W., Minka T., Zhu C., and Chen Z. A 
