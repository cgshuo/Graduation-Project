 Among all the marketing channels, word-of-mouth marketing (a.k.a. viral mar-keting) has been widely accepted as peopl e are more likely to believe the infor-mation obtained from their friends[1], and viral marketing has become as the most effective marketing strategy. Along with the increasing popularity of social networks, they provide opportunities for enabling online viral marketing.
In this paper, we study the problem of  X  X nfluence maximization X  [2], especially the topic-aware influence maximization problem, which aims to identify k nodes to maximize the influence on the given topics. This problem is proposed by Barbieri et. al. [3]. However it has two limitations. First, it only considers a single topic. Second, it focuses on how to define the topic-aware influences and does not provide effective algorithms to identify the k nodes.

To summarize, we make the following contributions. (1) We study the topic-aware influence maximization problem and devise an efficient algorithm. (2) We propose effective techniques to estimate the influence bound and utilize the bound to do pruning. We also incorporate the topics into our pruning technique to further improve the pruning power. (3) We have conducted extensive exper-iments on real datasets and the results show that our method achieves high performance and significantly outperforms state-of-the-art algorithms. Paper Organization. We formulate the problem in Section 2. Section 3 in-troduces the parameter assignments and the algorithm model and Section 4 il-lustrates the algorithm. We show the experimental studies in section 5. Related works are reviewed in Section 6. We conclude in Section 7. In this section, we first introduce the propagation model, and then formulate the problem of topic-aware influence maximization. 2.1 Independent Cascade(IC) Model Given a network G ( V,E ), for each edge ( u,v )  X  E , p ( u,v ) (0  X  p ( u,v )  X  1) is the influence propagation probability from u to v . There are different models to compute the probability. Independent cascade (IC) model [4,5,6] is the rep-resentative and widely used influence diffusion model. In the IC model, a node has two states: active or inactive. The act ive node is either an initial activated node (called  X  X eed X ) or activated by its in-neighbours, while the inactive state means the node has not yet had a chance to be activated by its in-neighbours. Formally, the IC model in graph G works in an inductive way. At the initial stage 0, a seed set S  X  V is selected to start the spread. Let A t denote the set of activated nodes at stage t and A 0 = S . At stage t +1,eachnode u in A t has only one chance to active its out-neighbours v/  X  The process terminates until A t +1 =  X  . The nodes influenced by S are denoted as  X  ( S ), where  X  ( S )= 2.2 Problem Formulation where z i (1  X  i  X  n )isatopic.Let V Z denote the nodes that have interest in any topics in Z . The influence maximization on topic set is to find a node set S with k nodes to maximize the influence in V Z . The nodes influenced by S are called the influence spread . Accordingly, the influence spread of S on Z is denoted as  X  ( S,Z ), and the topic-aware influence maximization is defined as definition 1. Definition 1 (Topic-Aware Influence Maximization). Given a directed graph G =( V,E ) and a query Q =( Z,k ) , the topic-aware influence maximiza-tion problem aims to find a k -node set S such that for any k-node set K X  V ,  X  ( S,Z )  X   X  ( K ,Z ) . S is called the seed set and node in S is called a seed.
The topic-aware influence maximization problem can be proved to be NP-hard by a reduction from the influence maximization problem[4] and computing the exact topic-aware influence spread can be proved to be #P-hard by a reduction from the influence spread problem[5]. In this section, we first introduce how to assign propagation probability on topics, and then introduce the tree-based algorithm model. 3.1 Topic-Aware Propagation Probability In propagation network, an edges X  X  weight (i.e., propagation probability) is the probability a node influences another. In previous works[5,2,7], propagation probability is defined either by the predefined constants or the reverse of the in-degree. While each user ha s different interests on di fferent topics. Formally, each node v  X  V has a T-dimensional topic distributions  X  v  X  R T and  X  v | z represents the probability of v on topic z i . T i =1  X  v | z
We combine the topic distribution and influence weight to compute the prop-agation probability between nodes on diff erent topics, as shown in Formular 1: p
In Equation 1, IN v is the in-neighbours of v ,and w ( u,v ) is the original weight between u and v . The influence from u to v on topic set Z equals to the percentage that u has taken among the overall influence of v  X  X  neighbours to v . We normalize the result by dividing the number of topic. 3.2 Tree-Based Approximate Model In this paper, we extend the tree-based algorithm proposed in [5] to approximate the influence spread on topic.

Given a network G =( V,E ) and a topic set Z , the propagation probability of path P =( u = n 1 ,n 2 ,  X  X  X  ,v = n m ) is denoted by p ( P| Z )where p ( P| Z )is computed as p ( P| Z )= m  X  1 i =1 p ( n the path with maximum propagation probability from u to v on topic set Z .
Given a node set S , the influence of S to node v can not be simply added up, because the paths with maximum influence probability from each u  X  S to v may have intersection. To address this problem,we treat node v as the root, and construct a tree by combing the path from each u  X  S to v with MPP ( u,v ) | Z as the weight. The influence of S to v on topic set Z can be computed as: Where C v is the children of v in the tree, and when v  X  S ,MPP ( S,v ) | Z =1. According to equation 2,  X  ( S,Z ) can be approximately computed as below:
Since  X  ( S,Z ) is submodular and monotone[5], and it satisfies the  X  X iminishing marginal utility X  1 law. By exploiting this law, a simple greedy algorithm can be used to find k nodes that maximize the influence on the given topic set Z . However this method is expensive and e xperimental studies in Section 5 show that it needs more than 15 hours to find top-100 nodes on a small-scale network. We introduce an efficient method on this problem in Section 4. In this section, we introduce two strategies to reduce the size of candidate nodes and propose an optimized algorithm to accelerate the seed selection. 4.1 Candidate Seeds Selection We introduce two strategies to reduce the candidate set (denoted as C ,which contains all the possible seeds) as much as possible.

We use a predefined threshold  X  to differentiate the influence strength between node, and u won X  X  be chosen into C .
 influence u on Z ,and u can be added to C only when | I u | Z | &gt; 0.
Moreover, topic distribution can be used to select candidate nodes. Variable  X  (0  X   X   X  1) is used to differentiate the topic strength. That is if n i =1  X  u | z u is a candidate node. 4.2 Seed Selection Optimization To avoid redundant calculation, we use an upper bound to select the next seed without recalculating the influence of all nodes that have co-influence with the selected ones.
 We use a max-heap(denoted as H ) to maintain the remainder candidate nodes. For each node u , we record its id , gain and status ,where id means node X  X  identifier, and gain is its marginal benefit, status records the state when its gain value has been recalculated.

Given node u and v ,if | I u | Z otherwise, they co-influence the node in I u | Z  X  ( u  X  v,Z ), we use an upper bound to approximately compute it.
 Considering two node u and v , if they independently influence node s :
We use the condition independence assumption as the upper bound to ap-proximately calculate their influence spread, denoted as 1  X  ( u  X  v,Z ):
Given a seed set S , the upper bound of marginal benefit of u on topic set Z based on S can be approximately computed as:
Algorithm 1. 2 gain ( u | Z )
To compute the marginal benefit of u based on S , the co-influence of each co-influence will be still repeatedly computed in the same round. To avoid the redundant computation, a map M is used to cache the nodes influenced by S (as the key) and its co-influence value by S (as the value) on topic set Z .Thusfora candidate node u ,its gain can be calculated as Algorithm 1.

In Algorithm 1, M [ v ] caches the co-influence of v influenced by the selected seeds. If v has already been influenced by S , the co-influence of a new node u to v based on S can be deduced from equation 5 as shown in line 6.

By using the bounds, we describe the seed selection as follow. For each iter-ation, we take the top element of heap H ,ifits status equals to 0 (indicates it is the original value and hasn X  X  been selected as candidate seed), we set its gain as computed in Algorithm 1, and update the status as 1; if its status equals to 1, we update its gain according to equation 3 and set status as 2; if its status equals to 2, we pop it out and add it to S and terminate this iteration. The full algorithm is illustrated as algorithm 2 (we call it  X  X eat X  for short, since it uses max Hea pand T ree structure to obtain the seeds).
 We pre-compute the prop agation probability on the given query topic set Z and the MPP ( u,v ) | Z for each pair of nodes in the network via a Dijkstra shortest-path algorithm. We first select the candidate nodes according to the basedonthethresholdof  X  (line 2). The max-heap H is built based on the original influence spread of each node(line 4), and for each turn, we get the top element Algorithm 2. Heat algorithm of H (line 7), if the node u has no interaction with map M (line 8), we add u to S and update map M ; otherwise, according to its status, we decide whether to update its gain value(line 11-13) or pop it out(line 15). This process terminates until k seeds selected. In this section, we report our experimen tal studies, we compare our algorithm with the state-of-the-art algorithms PMIA and MIA[5]. Besides, we also run the exact greedy algorithm improved by CELF[6] on the film dataset, which took more than 15 hours to find the top-100 IM seeds, while our method took only 3.12 seconds on average. For the influence spread, our method( 6970.772 )was only 2.82% lower than it( 7173.53 ). Since the exact greedy algorithm is much slower than our method, we omit it in the figures. 5.1 Datasets Experiments are conducted on two real datasets:  X  X BLP X , a citation network, the topic distributions of each node are discovered by using the author topic model[8], and the original weight of edge is the cite frequency; another one is a film dataset, which was used in[9], we use the way in[9] to assign the topic distribution, and the original weight is the link frequency. The propagation prob-abilities of the two datasets are computed according to part 3.1. Both of the two datasets are directed graph, details of datasets are shown in Table 1. 5.2 Evaluating Different Algorithms All the algorithms use 2000 Monte Carlo si mulations to estimate its influence spread. In Figure 1 we fix threshold  X  to evaluate the influence spread under different k , and in Figure 2 we fix k to evaluate the influence spread under different  X  . The experiments show that our algorithm has similar influence spread withMIA,andhigherthanPMIA.Andwiththeincreaseof k or decrease of  X  , the influence spread will increase. Since the bigger  X  is, the more candidate nodes will be reduced. And the elapsed time will be reduced as shown in Figure 4(a).
In Figure 3 we fix  X  and compare the elapsed time under different k . In Fig-ure 4 we fix k and compare the elapsed time under different  X  . The results indicate that our algorithm significantly outperforms PMIA and MIA. For ex-ample, in Figure 3(a) we set  X  as 0.01, when k is 20, our algorithm took 1.55 seconds while PMIA took 324.83 seconds and MIA took 355.26 seconds, which means that our method is more than 200 times than PMIA and MIA. Besides, our method scales well along the network size grows, that X  X  because our method avoids redundant calculation by caching the pre-computed results. Influence Maximization. The influence maximization problem was proposed in[2,10]. Kempe et. al.[4] proved the influence maximization problem is NP-hard, and a greedy algorithm approximated 1  X  1 /e ratio of the optimal solution. Kimura et al.[10] proposed the shortest path to estimate the influence spread. Leskovec et al.[6] used  X  X azy-forward X  algorithm which faster than the greedy algorithms. Chen et al.[11] used the property of the independent cascade model; Wang et al. [12] broke the whole social network into several communities; and Chen et al.[5] used the local arborescence to estimate the influence of nodes. Kim et al.[13] proposed independent path algorithm for the IC model and Jung et al.[7] proposed linear equations to approximate the real influence, Tang et al.[14] studied the IM problem by taking the relationship into consideration. Topic-Aware Influence Analysis. To the best of our knowledge, only few pa-Tang et al.[9] used the factor graph to learn user-to-user topic-wise influence strength. Lu liu et al.[15] proposed a probabilistic model to learn topic-wise in-fluence strength, Lin et al.[16] studied the joint modeling of influence and topics by adopting textual models. Weng et al.[17] analyzed the topic-aware influence on twitter. None of works mentioned above except[3] studied the influence maximiza-tion on topic. Barbieri et al.[3] studied the influence maximization on topic-aware, they introduced the topic-aware propagation model and devised a method to learn model parameters from a log of past propagations, however, they did not pay much attention on influence maximization study. In this paper, we study the topic-aware influence maximization problem. We devise an efficient algorithm which extends the tree-based approximate model to identify k nodes to maximize the influence on a given topic set. To achieve high performance, we further introduce two strategies to reduce the candidate nodes. Extensive experiments on real datasets demonstrate our method significantly outperforms the state-of-art algorithms.

