 Nicholas J. Bryan njb@ccrma.stanford.edu Gautham J. Mysore gmysore@adobe.com Adobe Research Over the past several years, there has been a surge of research on single-channel sound source separation methods. Such methods focus on the task of sepa-rating a single monophonic recording of a mixture of sounds into its respective sources. The problem is mo-tivated by many outstanding issues in signal processing and machine learning, such as speech denoising, speech enhancement, audio-based forensics, music transcrip-tion, and music remixing.
 One of the most promising and effective class of ap-proaches found for these purposes thus far is based on non-negative matrix factorization (NMF) (Lee &amp; Seung, 2001; Smaragdis &amp; Brown, 2003; Virtanen, 2007; F  X evotte et al., 2009) and its probabilistic latent variable model counterparts (Raj &amp; Smaragdis, 2005; Smaragdis et al., 2006). These methods model spectro-gram data or equivalently the magnitude of the short-time Fourier transform (STFT) of an audio recording as a linear combination of prototypical spectral com-ponents over time. The prototypical spectral compo-nents and their gains are then used to separate out each source within the mixture.
 In many cases, these methods can achieve good sep-aration results using supervised or semi-supervised techniques, where isolated training data is used to learn individual models of distinct sound sources, and then separate an unknown mixture of similar sound-ing sources (Smaragdis et al., 2007). When no training data is available, however, the methods are not useable without further assumptions.
 Initial work to overcome this issue has been proposed which allows a user to annotate a time-frequency dis-play of sound to inform the separation process without training. In Durrieu et al. (2012), a user is asked to annotate the fundamental frequency on a pitch-based display to inform a non-negative source-filter model to remove vocals from background music. In Lef  X evre et al. (2012), a user is asked to annotate binary time-frequency patches to perform semi-supervised separa-tion with the intention of using the annotations to train an automatic, user-free system. While promis-ing, these methods motivate further work for more general, flexible, and powerful solutions. In particu-lar, the first method is limited to separating a pitched source from background music and the second method only allows for binary time-frequency annotations, dis-allowing a user to express a confidence level in the an-notations.
 To overcome these issues, we propose a new source separation method to separate arbitrary sounds with-out explicit isolated training data. The method allows a user to interactively constrain a probabilistic latent variable model used for separation by roughly paint-ing on a spectrogram display of sound as shown in Fig. 1. Once an initial separation is performed, fur-ther annotations are used to refine the outputs and iteratively improve results, akin to the interactive clus-tering work of Cohn et al. (2003). To incorporate the constraints, we use the framework of posterior regu-larization (PR) and derive in an efficient expectation-maximization (EM) algorithm with closed-form multi-plicative updates that allows for interactive-rate sep-aration. For evaluation, a user-interface was devel-oped and tested on several mixture sounds, showing the proposed method can achieve state-of-the-art re-sults without explicit training data. To perform separation, we build off of the symmet-ric probabilistic latent component analysis model pro-posed by Smaragdis et al. (2006; 2007) as discussed in Section 3. Instead of performing supervised or semi-supervised separation requiring the use of train-ing data such as proposed by Smaragdis et al. (2007), we allow a user to weakly guide the separation pro-cess by interactively providing intuitive annotations that, in turn, control regularization parameters in our model. This technique allows us to perform separation in the scenario when no training data is available. More specifically, we first allow a user to annotate time-frequency features within a mixture recording that appear to correspond to one source or another as shown in Fig. 1a, using color to denote source and opacity as a measure of confidence. We then perform an initial separation given the annotations and allow the user to listen to the separated output. If the results are unsatisfactory, the user can then annotate errors in the output estimates as shown in Fig. 1b, and iter-atively re-run the process X  X nteractively updating the separation estimates until a desired result is achieved. To algorithmically achieve the proposed interaction, a new method of injecting constraints into our model as a function of time, frequency, and sound source is out-lined in Section 4. Moreover, the method must allow for interactive-rate (on the order of seconds) separa-tion, making the issue of computational cost central to our goal. As a result, the proposed approach is carefully designed with these requirements in mind. The complete separation process is then discussed in Section 5, with evaluation and conclusions in Section 6 and Section 7 respectively. Probabilistic latent component analysis (PLCA) is a straightforward extension of probabilistic latent se-mantic indexing (PLSI) or equivalently probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) for arbitrary dimensions. The general PLCA model is de-fined as a factorized probabilistic latent variable model of the form where P ( x ) is an N-dimensional distribution of a ran-dom variable x = x 1 ,x 2 ,...,x N , P ( z ) is the dis-tribution of the latent variable z , P ( x j | z ) are one-dimensional distributions, and the parameters of the distributions  X  are implicit in the notation.
 When employed for source separation, typically a two-dimensional variant of the PLCA model is used to approximate a normalized audio spectro-gram X , where the two-dimensions correspond to time and frequency ( f  X  x 1 and t  X  x 2 ). The random vari-ables f , t , and z are discrete and can take on N f N , and N z possible values respectively. P ( f | z ) is a multinomial distribution representing frequency ba-sis vectors or dictionary elements for each source, and P ( t | z ) and P ( z ) are multinomial distributions, which together represent the weighting or activations of each frequency basis vector. N z is typically chosen by a user and N f and N t are a function of the overall recording length and STFT parameters (transform length, zero-padding size, and hop size).
 To model multiple sources N s within a mixture, non-overlapping values of the latent variable are associ-ated or grouped with each source and estimated using an expectation-maximization algorithm. Fig. 2 shows an example where two values of z are ideally asso-ciated with one source and the remaining three val-ues to another, segmenting each distribution into two non-overlapping groups ( N s = 2 and N z = 2 + 3). Unfortunately, such ideal segmentation rarely occurs, requiring supervised or semi-supervised methods (and isolated training data) to estimate P ( f | z ) a priori for each source, motivating the proposed approach. 3.1. Parameter Estimation Given our model and observed data X , we can use an expectation-maximization (EM) algorithm to find a maximum likelihood solution to our model param-eters  X  . We follow the standard approach of lower bounding the log-likelihood via for any discrete distribution Q ( Z ), denoted by Q for compactness, where KL( Q || P ) is the Kullback-Leibler divergence and F ( Q,  X  ) is the lower bound as a result of KL( Q || P ) being non-negative (Bishop, 2006). With an initial guess of our model parameters, we then solve a two-stage coordinate ascent optimization. We first maximize the lower bound F ( Q,  X  ) or equiva-lently minimize KL( Q || P ) with respect to Q and then maximize the lower bound with respect to  X  and repeat the process until convergence (the super-script n denotes the iteration). As known in the liter-ature, such process guarantees parameter estimates  X  to monotonically increase the lower bound F ( Q,  X  ), and consequently the likelihood until convergence to a local stationary point. Also note that, in many cases, the expectation step only involves computing the pos-terior distribution P ( Z | X ,  X  ) because Q ( Z ) is opti-mal when equal to the posterior, making it common to implicitly define Q ( Z ). When we discuss the idea of posterior regularization below, however, an explicit representation of Q ( Z ) is needed. 3.2. PLCA Algorithm When we apply the above procedure to solve for the maximum likelihood parameters of our sound model, we get an iterative EM algorithm with closed-form up-dates at each iteration. The algorithm is outlined in Algorithm 1, where the subscript ( f,t ) is used to index X as a function of time and frequency. Given proper initialization and normalization, these update equa-tions can be further rearranged using matrix notation (Smaragdis &amp; Raj, 2007) are numerically identical to the multiplicative update equations for NMF with a KL divergence cost function as derived by Lee and Se-ung (2001).
 Algorithm 2 shows the multiplicative update rules where W is a matrix of probability values such that Algorithm 1 PLCA in Basic Form Procedure PLCA-BASIC ( ) initialize: feasible P ( z ), P ( f | z ), and P ( t | z ) repeat until convergence return: P ( f | z ), P ( t | z ), P ( z ), and Q ( z | f,t ) P ( f | z ) is the f th row and z th column, H is a matrix row and t th column, 1 is an appropriately sized ma-trix of ones, is element-wise multiplication, and the division is element-wise. Incorporating the user-annotations into our latent variable model can be done in several ways. As men-tioned above, we need a method to incorporate group-ing constraints as a function of source, time, and fre-quency. Given our factorized model, this is not eas-ily accomplished using standard priors, motivating the use of posterior regularization, which is well suited for our task.
 Posterior regularization for EM algorithms was first introduced by Gra  X ca, Ganchev, and Taskar (2007; 2009; 2009) as a way of injecting rich, typically data-dependent, constraints on the posterior distributions of latent variable models. The method has found suc-cess in many natural language processing tasks such as statistical word alignment, part-of-speech tagging, and similar tasks.
 Algorithm 2 PLCA in Multiplicative Form Procedure PLCA-MF ( ) repeat until convergence return: W and H The basic idea is to constrain the distribution Q in some way when computing the expectation step of an EM algorithm. This can be seen by modifying the expectation step discussed in Section 3.1, resulting in where  X ( Q ) constrains the possible space of Q . To denote the use of constraints in this context, the term  X  X eakly-supervised X  was introduced by Gra  X ca (2009) and is similarly adopted here.
 This method of regularization is in contrast to prior-based regularization, where the modified maximization step is where  X (  X  ) constrains the model parameters  X  . Now, given the general framework, we can introduce the spe-cific form of the regularization used for our purpose. 4.1. Linear Grouping Expectation Constraints To efficiently incorporate the user-annotated con-straints into our latent variable model, we need to define a meaningful penalty  X ( Q ). This is done by ap-plying non-overlapping linear grouping constraints on the latent variable z , encouraging distinct groupings of the model factors to explain distinct sound sources. The strength of the constraints are then interactively tuned by a user as a function of the observed variables in our model f and t . As a result, we no longer can assign Q to simply be the posterior, and need to solve a separate constrained optimization problem.
 To do so, we rewrite all values of Q and P ( z | f,t ) for a given value of f and t in vector notation as q and p , and solve independently for each time-frequency ( N f  X  N t ) value in our model at each expectation step. We then define is a matrix transpose, is element-wise greater than or equal to, and 1 is a column vector of ones. To impose the penalties as a function of source, we partition the values of z to correspond to different sources or groups as described above and then set the corresponding penalty coefficients in  X  to be identical within each group (e.g.  X  = [  X , X , X , X , X  ] for some  X , X   X  R ). The entire set of real-valued grouping by frequency, time, and latent component or, alterna-tively,  X  s  X  R N f  X  N t ,  X  s  X  { 1 ,..,N s } , indexed by frequency, time, and source (group of latent compo-nents). Positive-valued penalties are used to decrease the probability of a given source, while negative-valued coefficients are used to increase the probability of a given source. Fig. 3 illustrates an example set of penal-ties (  X  1 ,  X  2 ) as image overlays for two sources. To solve the above optimization problem, we form the Lagrangian
L ( q , X  ) =  X  q T ln p + q T ln q + q T  X  +  X  (1  X  q T 1 ) with  X  being a Lagrange multiplier, take the gradient with respect to q and  X   X  q L ( q , X  ) =  X  ln p + 1 + ln q +  X   X   X  1 = 0 (18)  X   X  L ( q , X  ) = (1  X  q T 1 ) = 0 (19) set equations (18) and (19) equal to zero, and solve for q , resulting in where exp {} is an element-wise exponential function. Notice the result is computed in closed-form and does not require any iterative optimization scheme as may be required in the general posterior regularization framework (Gra  X ca et al., 2007), limiting the computa-tional cost when incorporating the constraints as our design objective requires. 4.2. Posterior Regularized PLCA Knowing the posterior-regularized expectation step optimization, we can derive a complete EM algorithm for a posterior-regularized two-dimensional PLCA model (PR-PLCA). The modification becomes only a small change to the original PLCA algorithm, which replaces equation (8) with Q ( z | f,t )  X  where  X   X  = exp { X   X  } . The entire algorithm is out-lined in Algorithm 3. Notice, we continue to maintain closed-form E and M steps, allowing us to optimize further and draw connections to multiplicative non-negative matrix factorization algorithms. 4.3. Multiplicative Update Equations To compare the proposed method to the multiplica-tive form of the PLCA algorithm outlined in Al-gorithm 2, we can rearrange the expressions in Al-gorithm 3 and convert to a multiplicative form fol-lowing similar methodology to Smaragdis and Raj (2007). Rearranging the expectation and maximiza-tion steps, in conjunction with Bayes X  rule, and Z ( f,t ) = P z P ( z ) P ( f | z ) P ( t | z )  X   X  ( f,t,z ) Rearranging further, we get Algorithm 3 PR-PLCA with Linear Grouping Ex-pectation Constraints in Basic Form Procedure PR-PLCA-BASIC ( ) initialize: feasible P ( z ), P ( f | z ), and P ( t | z ) precompute:  X   X   X  exp { X   X  } repeat until convergence return: P ( f | z ), P ( t | z ), P ( z ), and Q ( z | f,t ) which fully specifies the iterative updates. By putting equations (26) and (27) in matrix notation, we spec-ify the multiplicative form of the proposed method in Algorithm 4. The subscript notation ( s ) with paren-thesis is used as an index operator that picks off the appropriate column or rows of a matrix assigned to a given source, and the subscript s without parenthesis as an enumeration of similar variables. 4.4. Computational Cost Neglecting the pre-computation step in Algorithm 4, we consider the increase in computational cost at each EM iteration of the proposed method over the stan-dard PLCA update equations in Algorithm 2. We no-tice that only equations (34) and (35) add computation compared to their counterpart of equation (12) in Al-gorithm 2 as a result of careful indexing of equations (36) and (37). Additionally, equation (12) of Algo-rithm 2 consists of an O ( N f N t N z ) matrix multiplica-tion and an O ( N f N t ) element-wise matrix division. Algorithm 4 PR-PLCA with Linear Grouping Ex-pectation Constraints in Multiplicative Form Procedure PR-PLCA-MF ( ) precompute: for all s do end for repeat until convergence return: W and H In contrast, equations (34) and (35) of Algorithm 4 consist of an O ( N f N t N z ) matrix multiplication, and an O ( N s N f N t ) element-wise matrix multiplication, di-vision, and addition. In total, the difference is only an O ( N f N t N s ) element-wise matrix multiplication, divi-sion, and addition per EM iteration. As a result, the entire added cost per EM iteration for small N s (typi-cally two) is low and found to be acceptable in practice. To perform the complete separation process, we need to run Algorithm 4 in conjunction with pre-and post-computation. This involves first computing the short-time Fourier transform of the mixture record-ing, eliciting user-annotated penalties, running Algo-rithm 4, and then reconstructing the distinct sound sources from the output. To reconstruct the distinct sources from the output, we take the output poste-rior distribution and compute the overall probability of each source p ( s | f,t ). This is done by summing Algorithm 5 Complete PR-PLCA Source Separation
Procedure PR-PLCA-SEPARATION ( ) precompute: ( X , 6 X )  X  STFT( x , P ) repeat until satisfied return: time-domain signals x s ,  X  s  X  X  1 ,...,N s } over the values of z that correspond to the source P ( s | f,t ) = P z  X  s P ( z | f,t ) or equivalently by comput-ing W ( s ) H ( s ) / W H . The probability of each source is then used to filter the mixture recording by element-wise multiplication with the input mixture spectro-gram X according to standard practice (Benaroya et al., 2003). The result is then converted to a time-domain audio signal via an inverse STFT using the input mixture phase 6 X .
 The complete method is outlined in Algorithm 5, where we additionally define the forward short-time Fourier transforms ( X , 6 X )  X  STFT( x ,P ) as an al-gorithm that inputs a time-domain mixture signal x and STFT parameters P and returns the magnitude X matrix and phase matrix 6 X . The inverse short-time Fourier transform x  X  ISTFT( X , 6 X ,P ) then inputs a magnitude matrix, phase matrix, and param-eters P and returns a time-domain signal x . For a reference on the short-time Fourier transform, please see Smith (2011). To test the proposed method, a prototype user in-terface was built similar to Fig. 1 and tested on two sets of sound examples. For the first comparison, five mixture sounds of two sources each were tested. The original ground truth sources for each example were normalized to have a maximum of 0 dB gain and summed together to create the mixture sound. The mixture sounds were then separated using the pro-posed method over the course of five minutes each. The five mixture sounds include: ambulance siren + speech (S), cell phone ring + speech (C), drum + bass loop (D), orchestra + coughing (O), and piano chords + incorrect piano note (P). For a second comparison, four example rock/pop songs (S1, S2, S3, S4) from the Signal Separation Evaluation Campaign (SiSEC) database (SiSEC, 2011) were tested with the challenge of removing vocals from background music over the course of thirty minutes, similar to the evaluation of (Lefevre et al., 2012).
 The results for both datasets were then compared against a baseline PLCA algorithm and an oracle al-gorithm. The baseline algorithm uses unsupervised PLCA with no training data or user-interaction to provide an approximate empirical lower bound on the results. The oracle algorithm uses the ground truth spectrogram data to compute the source probability masking filter p ( s | f,t ) directly as the ratio of the ground truth source spectrogram divided by the mix-ture spectrogram to provide an approximate empirical upper bound on the results. In addition to the base-line and oracle results, the four rock/pop song results were compared against the method of Lef  X evre (2012) and Durrieu (2012), which, to our knowledge, are the only comparable methods that have some form of user-input and allow separation without training data. For both test sets, the standard BSS-EVAL suite of metrics were used to evaluate performance (Vin-cent et al., 2006). The suite includes three sepa-rate metrics including the Source-to-Interference Ratio (SIR), Source-to-Artifacts Ratio (SAR), and Source-to-Distortion Ratio (SDR). The SIR measures the level of suppression of the unwanted sources, the SAR mea-sures the level of artifacts introduced by the separation process, and the SDR gives an average measure of sep-aration quality that considers both the suppression of the unwanted sources and level of artifacts introduced by the separation algorithm compared to ground truth. All three metrics have units of decibels (dB) and con-sider higher values to be better.
 We illustrate two example sets of input and output spectrograms in Fig. 4 and display the complete eval-uation results in Table 1 and 2. For both tests, a fixed number of basis vectors N z = 100 + 100 were used. As shown, our proposed method outperforms the baseline, the method of Lef  X evre, and the method of Durrieu in all metrics for all examples. Note, the method of Dur-rieu previously ranked best SDR on average for the 2011 SiSEC evaluation campaign for removing vocals. In addition, in certain cases, the proposed method even performs near the quality of the ideal mask. Au-dio and video demonstrations can be found at https: //ccrma.stanford.edu/ ~ njb/research/iss .
 Finally, to show how the proposed method behaves when varying the number of basis vectors per source, we performed separation for the first set of example sounds, then with the annotations fixed, varied the number of basis vectors and recomputed the results. Fig. 5 displays the SDR for the experiment, which shows that the method is relatively insensitive N z , as long as the size is sufficiently large. This is notable in that the proposed method does not require the use of model selection to decide the number of basis vectors to use for a given separation task.
 To perform source separation when no isolated train-ing data is available, we propose an interactive, weakly supervised separation technique. The method em-ploys a user to interactively constrain a latent variable model by way of a new efficient posterior regularized EM algorithm. The use of PR allows for constraints that would be difficult to achieve using standard prior-based regularization and adds minimal additional com-putational complexity. A prototype user interface was developed for evaluation and tested on several exam-ple mixture sounds, showing the proposed method can achieve state-of-the-art results on real-world examples. This work was performed, in part, while Nicholas J. Bryan was an intern at Adobe Research.
 Benaroya, L., Donagh, L.M., Bimbot, F., and Gri-bonval, R. Non negative sparse representation for wiener based source separation with a single sen-sor. In Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP  X 03). 2003 IEEE In-ternational Conference on , volume 6, april 2003. Bishop, C. M. Pattern Recognition and Machine
Learning . Springer-Verlag New York, Inc., Secau-cus, NJ, USA, 2006.
 Cohn, D., Caruana, R., and Mccallum, A. Semi-supervised clustering with user feedback. Technical report, 2003.
 Durrieu, J.-L. and Thiran, J.-P. Musical audio source separation based on user-selected f0 track. In The 10th International Conference on Latent Variable
Analysis and Signal Separation (LVA/ICA) , pp. 438 X 445, 2012.
 F  X evotte, C., Bertin, N., and Durrieu, J.-L. Nonnega-tive matrix factorization with the itakura-saito di-vergence: With application to music analysis. Neu-ral Computation , 21(3):793 X 830, March 2009.
 Gra  X ca, J., Ganchev, K., and Taskar, B. Expecta-tion maximization and posterior constraints. In Ad-vances in Neural Information Processing Systems (NIPS) , 2007.
 Gra  X ca, J., Ganchev, K., Taskar, B., and Pereira, F.
C. N. Posterior vs parameter sparsity in latent vari-able models. In Advances in Neural Information Processing Systems (NIPS) , pp. 664 X 672, 2009. Hofmann, T. Probabilistic latent semantic indexing. In Proceedings of the 22nd annual international ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR  X 99, pp. 50 X 57, New York, NY, USA, 1999. ACM.
 Lee, D. D. and Seung, H. S. Algorithms for non-negative matrix factorization. In Advances in Neural
Information Processing Systems (NIPS) , pp. 556 X  562. MIT Press, 2001.
 Lefevre, A., Bach, F., and F  X evotte, C. Semi-supervised nmf with time-frequency annotations for single-channel source separation. In In the Proceedings of The International Society for Music Information Retrieval (ISMIR) Conference , 2012.
 Raj, B. and Smaragdis, P. Latent variable decomposi-tion of spectrograms for single channel speaker sepa-ration. In IEEE Workshop on Applications of Signal
Processing to Audio and Acoustics (WASPAA) , pp. 17  X  20, oct. 2005.
 SiSEC, 2011. Professionally produced music record-ings. In Signal Separation Evaluation Campaign (SiSEC) , 2011. http: http://sisec.wiki.irisa.fr/tiki-index.php //sisec.wiki.irisa.fr/tiki-index.php . Smaragdis, P. and Brown, J.C. Non-negative matrix factorization for polyphonic music transcription. In
IEEE Workshop on Applications of Signal Process-ing to Audio and Acoustics (WASPAA) , pp. 177  X  180, oct. 2003.
 Smaragdis, P. and Raj, B. Shift-Invariant Probabilistic
Latent Component Analysis. MERL Tech Report , 2007.
 Smaragdis, P., Raj, B., and Shashanka, M. A Proba-bilistic Latent Variable Model for Acoustic Model-ing. In Advances in Neural Information Processing
Systems (NIPS), Workshop on Advances in Model-ing for Acoustic Processing , 2006.
 Smaragdis, P., Raj, B., and Shashanka, M. Super-vised and semi-supervised separation of sounds from single-channel mixtures. In International Confer-ence on Independent Component Analysis and Sig-nal Separation , pp. 414 X 421, Berlin, Heidelberg, 2007. Springer-Verlag.
 Smith, J. O. Spectral Audio Signal Process-ing . http: http://ccrma.stanford.edu/ jos/sasp/ //-ccrma.stanford.edu/~jos/sasp/ , 2011. online book.
 Vincent, E., Gribonval, R., and Fevotte, C. Perfor-mance measurement in blind audio source separa-tion. IEEE Transactions on Audio, Speech, and Language Processing , 14(4):1462  X 1469, july 2006. Virtanen, T. Monaural Sound Source Separation by Nonnegative Matrix Factorization With Temporal
Continuity and Sparseness Criteria. IEEE Trans-actions on Audio, Speech and Language Processing
