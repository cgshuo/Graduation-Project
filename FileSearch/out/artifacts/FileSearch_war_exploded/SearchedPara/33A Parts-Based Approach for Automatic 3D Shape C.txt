 MOHAMED DAOUDI, JEAN-PHILIPPE VANDEBORRE , TELECOM Lille 1 The representation of objects in three dimensions (3D) has recently gained great pop-ularity in computer vision communities and has become an integral part of modern computer graphics applications, such as computer-aided design, game development, and more recently, film production. At the same time, 3D data have become widely used in diverse fields including computer vision, computational geometry, molecular biology, and medicine. The availability of low-cost 3D scanners and the rapid evolu-tion in graphics hardware and software has greatly facilitated 3D model acquisition, creation, and manipulation. The content-based analysis becomes a necessary solution for structuring, managing, and organizing 3D objects from large collections. In this context, the aim of this article is to propose a fully automatic framework for 3D object categorization based on the content. Through the state-of-the-art, we can find mainly two different families of related work. The first family deals with the 3D shape retrieval and the second family is concerned by the 3D shape classification.

In the first family, many systems have been proposed for efficient information re-trieval from digital collection of 3D objects. Kazhdan et al. [2003] present a general approach based on spherical harmonics for obtaining rotation-invariant representa-tions and show its application in the retrieval task. Antini et al. [2005] present an approach relying on curvature correlograms to perform description and retrieval by content of 3D objects. Funkhouser et al. [2003] present a Web-based search engine system that supports queries based on 3D sketches, 2D sketches, 3D models, and/or text keywords. For the shape-based queries, they have developed a matching algorithm that uses spherical harmonics to compute discriminating similarity measures without requiring repair of model degeneracies or alignment of orientations. Filali Ansary et al. [2007] propose a method for 3D object indexing based on 2D views. In their paper, they present an adaptive nearest-neighbor-like algorithm to select the most relevant char-acteristic views from the 3D object. A Bayesian approach is used in order to improve the retrieval rate. Assfalg et al. [2007] present an adaptive spin images approach for 3D retrieval by content. Hilaga et al. [2001] propose a technique, called Topology Matching, in which similarity between polyhedral models is calculated by comparing Multires-olutional Reeb Graphs (MRGs) based on the Reeb graph computation of a 3D object. Bronstein et al. [2008, 2009] also propose to consider the 3D matching problem as a multicriterion optimization problem trying to simultaneously maximize the similarity and the significance of the matching parts.

Compared to the work on 3D object retrieval where objects are compared together in pair, 3D classification, which consists in affecting an object query to one category, is still an open problem. Few papers such as Huber et al. [2004] and Donamukkala et al. [2005] have addressed this issue. The method is used for classifying vehicles into a set of predetermined object classes. For that, parts are extracted from training objects and grouped into part classes. A mapping from part classes to object classes is derived from the learned part classes and known object classes. For a 3D object, after local shape features are computed, the object class is determined using the learned part classes and the part-to-object mapping. The decomposition in the approach is just to divide objects into front, middle, and back parts. The method is based on a Bayesian classifier and it is limited to specific datasets, which should respect the decomposition constraint. In this article we present a fully automatic framework for 3D object categorizing based on the belief functions. The categorization is addressed with a parts-based approach. It consists of capturing a compact model of a given category by building a set of repre-sentative parts. For this purpose, the objects in the same category are partitioned into several parts. These parts are then used to construct a set of representative ones with which objects in the same category can be described. A straightforward way to build this set is using vector quantization techniques. Here, we use a variation of the evi-dential k-nearest-neighbors algorithm. The centroids of the resulting clusters are used as representative parts of the category. This process is iterated for all the categories in the training set.
 The labeling of unknown 3D objects is achieved by labeling their associated parts. Here, we assume that each part can help to predict the category of the whole object. More specifically, each part of the object to be labeled is considered as an item of evidence supporting certain hypotheses concerning the category membership of that object. Based on this evidence, the object parts are compared with category repre-sentative parts and basic belief masses are assigned to each category. As a result of considering each object part in turn, we obtain a set of Basic Belief Assignments (BBAs) that can be combined using the Dempster X  X  rule of combination to form a resulting BBA synthesizing a final belief regarding the category of the whole object.

Another issue is dealt with in this article is when labeling an unknown 3D object, one can be faced with the problem of handling an unclassifiable object (reject). Here we show that we are able to handle this issue using a belief-theory-based data association method. Using a specific modeling of belief functions, this is done by detecting and managing a portion of a conflict, which originates from the nonexhaustivity of the frame of discernment.

The remainder of the article is organized as follows. In Section 2 the training stage is presented. Then, in Section 3 the labeling stage is detailed. Section 4 presents experimental results. Conclusions and future developments end the work. From a training set of 3D objects, the procedure we suggest for obtaining the model of each category is based on the assumption that 3D objects in the same category have the same parts More specifically, we assume that each category can be represented by a set of representative parts with which shapes in that category can be described. In this section, we focus on constructing the set of representative parts for each category. Figure 1 presents the different steps of the training process. Given a set of J categories, the figure shows four main steps applied for each category: (1) object partitioning; (2) part description; (3) part clustering; (4) representative part computation. 3D partitioning, which consists to extract a set of parts that share the same character-istics from a 3D object, is a deeply studied domain as the reader may realize through a recent comprehensive survey [Shamir 2008]. In our method, we adopt a fully automatic topology-driven 3D mesh segmentation algorithm [Tierny et al. 2007] where feature boundaries and feature hierarchy are both computed in a semantic-oriented manner. The main steps of this approach are shown in Figure 2. First, a set of feature points is extracted from the 3D object as shown in Figure 2(a). Then the enhanced topological skeleton of the input triangulated surface is constructed (Figure 2(b)). Finally, it is used to delimit the core of the object and to identify junction areas. This final step results in a fine segmentation of the object (Figure 2(c)).

After the object partitioning, parts are represented by local descriptors which capture the geometry of the part. It is well-known that the performance of all data classifiers depends critically on the ability of the descriptors to discriminate among the various classes. Choosing the right set of features is a difficult problem. The descriptors must be sufficiently rich to discriminate between different parts of shapes, and at the same time be invariant to different transformations that a shape can undergo. There exists several part description algorithms, and next we overview some of them.  X  GD2 . The GD2 is a local distribution of geodesic distances. It has been used for shape recognition by Osada et al. [2002] as a global shape distribution, which measures Euclidean distances of random surface points.
  X  Gcords . Geodesic cords-based descriptors is defined as a distribution of geodesic distances from one source point to others. First, an Euclidean cords-based descriptors was introduced by Paquet and Rioux [1999] for global 3D shape matching. We have adapted this approach to the local feature descriptor.  X  HSI. Histogram of Shape Index is defined as the histogram of shape index values, calculated over the mesh part. The shape index, first introduced by Koenderink and van Doorn [1992], is defined as a function of the two principal curvatures on continuous surfaces. Here, we attempt to find representative parts of each category. For this end, we devel-oped an evidential clustering method based on the Transferable Belief Model (TBM) concept [Shafer 1976; Zouhal and Denoeux 1998]. 2.2.1. Transferable Belief Model Concept. The TBM is based on a two-level model: a credal level where beliefs are entertained, combined, and updated, and a pignistic level where beliefs are converted into probabilities to make decisions.  X  Credal level .Let denote a finite set called the frame of discernment. A Basic
Belief Assignment (BBA) or mass function is a function m :2 subsets A of such that m ( A ) &gt; 0 are called focal elements.

Given two BBAs m 1 and m 2 defined over the same frame of discernment and induced by two distinct pieces of information, we can combine them using the Dempster X  X  combination rule [Shafer 1976] given by for all A  X  .  X  Pignistic level . When a decision has to be made, the beliefs held at the credal level induce a probability measure at the pignistic level. Hence, a transformation from belief functions to probability functions must be done. This transformation is called the pignistic transformation. Let m be a BBA defined on , the probability function induced by m at the pignistic level, denoted by Be t P and also defined on , is given by for all  X   X  and where | A | is the number of elements of in A. 2.2.2. Clustering Algorithm. Let us consider a category C in the training set. All objects in C are processed (each object is partitioned) and the sets of parts are extracted. Let P
C = { P 1 ,..., P N } be the collection of all object parts in C . We assume that these parts can be classified into M classes W = { W 1 ,..., W M } (for the choice of M see Algorithm 1) and each part P i will be assumed to possess a class label indicating with certainty its membership to one class in W .Let P s be an incoming part to be classified. Classifying P s means assigning it to one class in W . Using the vocabulary of the evidential theory, W can be called the frame of discernment of the problem.

Let us denote by s the set of the k-nearest neighbors of P distance measure D (in this article, D represents the L 2 Let P k  X  s a 3D part classed in W l . The pair ( P k , W evidence that increases our belief that P s also belongs to W evidence does not by itself provide 100% certainty. In the evidential formalism, this can be expressed by saying that only some parts of our belief are committed to W the fact that P k  X  W l does not point to any other particular hypothesis, the rest of our belief cannot be distributed to anything else than W , the whole frame of discernment. This item of evidence can therefore be represented by a Basic Belief Assignment (BBA) m k verifying Here  X  is a parameter such that 0  X   X   X  1.  X  l is obtained by an optimization procedure proposed by Zouhal and Denoeux [1998]. We set  X  = 0 . 9. For each of the k-nearest neighbors of P s , a BBA depending on both its class label and its distance to P therefore be defined. In order to make a decision regarding the class assignment of P these BBAs can be combined using Dempster X  X  rule [Shafer 1976] into one BBA m a result, P s will take the label of the class maximizing the pignistic probability induced by m s . Algorithm 1 summarizes this method.

Once the clustering process is achieved, we compute the centroid of each cluster. The centroid is a part whose parameter values are the mean of the parameter values of all the parts in the cluster. Centroids, in this article, are called representative parts and denoted by R . In this section, we focus on the labeling of 3D objects. Figure 3 shows the various steps of this process. First, giving an object O to be labeled (Figure 3 step a), the algorithm begins by partitioning this object (Figure 3 step b). Second, an invariant descriptor is associated to each extracted part of that object (Figure 3 step c). The partitioning and the description of these parts are done in the same way as in the training process. The labeling of the object O is achieved based on its parts. Here, we assume that each part can help to predict the category of the whole object. In the context of belief functions, we can say that each part represents an evidence source which provides information regarding the category of the object. By considering all parts, we obtain a set of evidence sources that can be combined to produce a final decision concerning the category of the object.
 Recall here that, after the training process, each category contains a set of represen-tative parts. Given a part extracted from the object to be labeled (for example, P Figure 3 step c), we select in each category the representative part that is the closest to P (Figure 3 step d-1). Then, from the selected representative part a mass function that quantifies the degree of belief given to the assumption  X  P category C j  X  is derived (Figure 3 step d-2). As a result of considering each category in turn we obtain a set of BBAs that can be combined using Dempster X  X  rule of combina-tion to form a resulting BBA. This BBA synthesizes a final belief regarding the relation between the part and the categories (Figure 3 step d-3).
 More formally, let us denote by { P i } 1  X  i  X  I the set of I parts composing the object O . From the training set, we enumerate J categories c ={ contains a set of representative parts. Let R j P the part P i in the category C j . Each pair ( P i , R j P item of evidence regarding the category membership of P i one will be inclined to believe that both parts belong to the same category. On the contrary if their dissimilarity is very large then we consider that P the complement of the C j in c . Consequently this item of evidence may be postulated to induce a basic belief assignment BBA m ij over c defined by S ( P i , C j ) = e (  X  D ( P i , R j P i )) is a function of the distance between the part P representative part R j P associated with the category C j . In practice, we set  X  =
As a result of considering each category we obtain J BBAs as shown in Figure 3 step d-2. These masses are combined using Dempster X  X  rule of combination to form a resulting BBA m i synthesizing a final belief regarding the attachment of P category. Figure 3 step d-3 shows the resulting BBA m i . In order to get a final decision about the category of the unknown 3D object, all masses m
A decision can be made regarding the category membership of the 3D object by examining the pignistic probability deduced from the resulting mass m (Figure 3 step d-5). The labeling process is summarized in Algorithm 2. Introducing a reject option is very useful, yet a difficult problem in data classification. Instead of Bayesian classifiers where the reject is modeled empirically by comparing the posteriori probability with a threshold (T) [Vailaya et al. 2001], the reject in the belief theory is modeled in natural way. It can be deducted from the conflict on each mass distribution in Figure 3 step d-3. The idea consists to divide the conflict into two components, a conflict due to the nonexhaustivity of the frame of discernment represented by the reject and an unknown conflict. In order to illustrate this idea, let us consider a two-element frame of discernment c ={ C represented by { C 1 , C 1 } or { C 2 , C 2 } . Given two BBA m C 1 or we are in a situation of almost complete ignorance concerning the category of that C 2 or we are in a situation of almost complete ignorance concerning the category of that part.

Here, m 1 and m 2 are considered as two independent sources of information to be combined in order to decide with which category the object is associated. The evi-dence combination of these two beliefs using Dempster X  X  rule of combination can be represented by Table I.

The last row and the first column of this table are named by the subsets of of the squares in the table corresponds to the intersection of the subset of each source of information m 1 and m 2 . The value of BBA taken for the resulting subset is obtained by the multiplication of the BBA values of the subsets constituted we can see that the conflict (the mass of the empty set) is represented by two grids. Its value is given by
The first portion of the conflict m 1 ( C 1 ) . m 2 ( C 2 of information m 1 and m 2 related respectively to category C 3D object corresponds to the two categories at the same time. In contrast, the second confirm that the 3D object does not correspond to any category and thus the frame of discernment is not exhaustive. Hence, in our view, the separation between the first and the second portion of the conflict must be done because they do not have the same origin. We define a reject when sources of information confirm that the 3D object does not correspond to any category. The reject is added to the frame of discernment as a new element and its belief degree is given by: m 12 ( reject ) in our case and through multiple sources of information in the table in Figure 3 step d-2, the mass value of the reject is given by Finally, according to the pignistic probability deduced from the mass function computed in Section 3.2, a decision can be taken about the reject of the 3D object. We present results from three experiments. In the first we evaluate the performance of the belief-based classifier and explore the impact of the choice of descriptors on classifier accuracy. The accuracy is computed as the percentage of object models which are correctly classified. We then compare the performance of the belief-based classifier with the Bayesian classifier [Huber et al. 2004] on the same problem. In the penulti-mate experiment we describe results with comparison to some state-of-the-art retrieval methods. The last experiment shows the contribution of the reject modeling option of our framework.
 The experiments were conducted on two different datasets. The first dataset is the Shrec07 database. It contains 400 3D objects classified into 20 classes. It is a challenging dataset, not only because of the large number of classes, but also because it contains shapes with highly variable poses and nonrigid or isometric transformations. Figure 4 shows some examples from this dataset. Each object in the figure represents one class. The second dataset is composed of shapes from the Tosca and the Sumner datasets. The Tosca dataset has been proposed by Bronstein et al. [2007] for nonrigid shape correspondence measures. The Sumner dataset has been proposed by Sumner and Popovic [2004] for deformable shape correspondence. The total set size is 380 shapes. Figure 5 shows some examples from this dataset. Each object in the figure represents one class.
 From a qualitative point of view, Figures 6 and 7 give a good overview of the efficiency of the framework on the Shrec07 dataset. Figure 6 presents a confusion matrix. Rows in this matrix correspond to query parts extracted from a human 3D object, and columns correspond to the different categories shown in Figure 4 (ordered from left to right and from top to bottom). The lightness of each element ( i ; j ) is proportional to the magnitude of the similarity between the part i and its closest representative one in the category j . Lighter elements represent better matches, while hot elements indicate worse matches. One can notice in this visualization that the parts of the human object tend to match with the 12th object category which corresponds to the human one in Figure 4. This result confirms our assumption that 3D objects in the same category have the same parts.

Figure 7 shows another confusion matrix. In this matrix rows correspond to 3D object queries and columns correspond to the categories shown in Figure 4. The lightness of the diagonal squares of the matrix proves the effectiveness of our classifier.
More quantitatively, Table II and Table III show the classification results of our framework using different descriptors. On the Shrec07 dataset (Table II), HSI and Gcords descriptors yield an accuracy of around 73%, while the GD2 leads to a much higher accuracy of around 93.5%. These results show that GD2 is more suited for local shape description. A combination of the GD2 and HSI features yields a better accuracy than the GD2 feature alone 94.8% (the combination is based on the mean distance). On the Tosca-Sumner dataset (Table III), the combination of the GD2 and HSI features also gives the highest accuracy rate 97.9%.
 Table IV and Table V show a comparison accuracy between the belief classifier and the Bayesian classifier on respectively the shrec07 and the Tosca-Sumner datasets. On the shrec07 dataset, our classifier shows an accuracy of 96.7% and 92.9% on the training set and an independent test set, respectively, that is to say 94.8% accaracy over the entire dataset. Using a Bayesian classifier we report only 66.63% accurancy. On the Tosca-Sumner dataset, results comfirm the contribution of the use of the belief framework instead of the Bayesian one. The belief classifier reports 97.9% while the Bayesian one reports only 75.65%. In this experiment we compare our method effectiveness to methods proposed by Biasotti et al. [2006]. In their work, authors compared the performance of five similarity measures on four different shape descriptors in classifying 3D objects. The four different shape descriptors used in their paper are: the Spherical Harmonics (SH) in Kazhdan et al. [2003] which is a volume-based descriptor, the Light-Field descriptor (LF) in Chen et al. [2003] which is an image-based descriptor and two topological matching methods, the Multiresolution Reeb Graph (MRG) in Hilaga et al. [2001] and the Extended Reeb Graph (ERG) in Biasotti and Marini [2005].The five similarity measures are: the Minimum Distance Classifier (MinDC) which coincides with the nearest-neighbor classifier, Maximum Distance Classifier (MaxDC) which classifies a query by taking into account the most dissimilar descriptor belonging to the class, the Average Distance Classifier (AvgDC) which is defined as the average distances between the query and the members of the class, the Centroid Distance Classifier (CDC) where the query is classified according to its dissimilarity with a representative member of a class, and the Atypicity Distance Classifier (ADC), which evokes the notion of typicity to represent how much a descriptor is typical of the class it belongs to with respect to the elements in the other classes.

In order to demonstrate the effectiveness of our method compared with Biasotti et al. X  X  classifiers, we tested our method on the same dataset used by Biasotti et al. This dataset is a subset of the SHREC07 dataset composed of 280 3D objects classified into 14 classes. The results of the experiment are shown in Table VI. Each entry is related to the performance of a given shape descriptor (enumerated in the second row) for a given classifier (reported in the first column of the table). The classification accuracy of our method is given in the last row. While Biasotti et al. concluded that the MinDC (nearest neighbor) similarity measure performed the best for all four different shape descriptors in their work, one can notice that our classifier shows the highest classification rate of 97.6%. Moreover, the nearest-neighbor-based approaches require to compare each object to be classified to all objects in the dataset, which seems to be impractical with huge databases where our method is preferred, while it requires matching of only the representative parts. Please note that using a PC with a 3Ghz Core 2 Duo processor with 3GB memory, and a Matlab implementation of our algorithms, the running time of the labeling process depends on the quality of the meshes and their number of vertices. The full processing time of a query (from the Shrec07 or the Tosca-Sumner datasets) varies from 2 to 25 seconds. Table VII shows the accuracies for 3D classification with and without the reject option on the Shrec07 dataset. One can notice that the classification accuracy improves from 94.8% to 96.5%. For the Bayesian classifier, the 3D object whose maximum a posteriori probability is below the threshold (T) in Table VII is rejected. When T notice that the Bayesian classifier rejects much more than our classifier. However, our accuracy is still higher. In this article, we have presented a parts-based method for categorizing 3D objects using a new evidential classifier. The categorization process is completely automated and consists of two different stages. The training stage lies on the category model building and is based on the belief function theory goes into two steps: (1) 3D object partitioning and (2) representative parts construction. The second stage is the labeling, in which belief functions have been also used. In the labeling process, we have intro-duced a reject option which can be used to handle the labeling of unknown 3D objects. The classifier has been evaluated on two databases of 400 and 380 3D models. Our system achieves a classification accuracy over 94.8% and 97.9%, respectively, on the two datasets. The reject option has also been evaluated and the experimental results obtained on the Shrec07 dataset show that this option efficiently improves the classi-fication accuracy from 94.8% to 96.5%. However, the surface partitioning method used in our framework introduces a bias in the categorizing process. To guarantee stability and performance, this partitioning has to be stable within a same class of objects. In practice, with the Shrec07 and Tosca-Sumner datasets, partitioning turns out to be homogeneous within most classes. Furthermore, since we have focused our interest to propose a meta-algorithm for a relevant categorizing approach, some parts of the method can be changed and tested (3D partitioning, local descriptors). For example, in order to deal with imperfect meshes, we can use volume-based partitioning approaches [Mademlis et al. 2008] which are preferred over surface-based approaches. In the fu-ture, we would like to investigate the integration of the spatial relation between parts in the matching process.

