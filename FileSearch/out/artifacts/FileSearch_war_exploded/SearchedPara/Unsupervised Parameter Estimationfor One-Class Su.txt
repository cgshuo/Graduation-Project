 Abnormal patterns in a data set, which are inconsistent with the majority of the data, are commonly referred to as outliers or anomalies. In many applications, such as fraud detection, environmental monitoring, and medical diagnosis, one of the main tasks is to detect such instances or to remove them [ 10 ]. The two major underlying assumptions of many existing outlier detection methods are the rarity of outliers and the distinctive differences between them and the normal data [ 1 ].
 semi-supervised or unsupervised learning methods [ 1 , 7 ]. The former case assumes that both negative and positive labels are available to train a binary classifier, while the latter one does not make any assumption regarding the avail-ability of a labeled data set [ 7 ]. In comparison with these two approaches, semi-supervised methods assume that only the normal examples are available during training, which makes it possible to build a model of normality that rejects anomalous instances [ 1 , 7 ]. For unsupervised and semi-supervised methods, if it is assumed that the majority of the training data is normal, the methods are also categorised as one-class classification. In this paper, we mainly focus on one-class classification, and interested readers are referred to [ 1 , 7 ] for more comprehensive surveys.
 The OCSVM [ 14 ] and SVDD [ 19 ] algorithms are two widely used one-class the OCSVM and SVDD algorithms handle small fractions of outliers in the train-ing set [ 14 , 19 ], but if a considerable proportion of such examples exist, both algo-rithms may end up producing models that are skewed towards outliers [ 10 ]. Unfor-tunately, the availability of a (nearly) clean training data to avoid this problem is not guaranteed in many real applications. Moreover, contributing  X  X ood X  exam-ples of outliers, i.e., ones that do not lie on normal regions and are far from the nor-mal data points, is sometimes necessary to boost the performance of the OCSVM and SVDD algorithms [ 19 ], but we may have no prior knowledge about such exam-ples. Finally, both algorithms have some data dependent parameters whose value can substantially affect the accuracy of the method, and estimating these para-meters in an efficient and unsupervised way is an open research problem. Usually, the feature space is searched via grid-search and cross-validation, which are com-putationally expensive and require labeled examples from both the normal and outlier classes.
 This paper addresses the aforementioned problems in the following ways: (i) we propose two fully unsupervised methods to analyse the structure of the data and make a near-optimal estimation of the parameter settings in an efficient way in comparison with existing methods, (ii) we show how our methods can be used to restrict the domain of search in grid-search and improve its efficiency, (iii) we show the application of our proposed methods in pre-processing an unclean data set, comprising a considerable fraction of outliers, and building a labeled data set comprising the normal data and good examples of outliers. In this section, a brief explanation of the OCSVM and SVDD algorithms is presented, followed by a review of the related works that have been proposed to find optimal parameter settings for OCSVM or SVDD training. 2.1 One-Class Support Vector Machines The OCSVM or  X  -SVM [ 14 ] algorithm is a semi-parametric one-class classifica-tion method that finds a boundary around dense areas comprising the normal projected to a potentially higher dimensional space using a feature map  X  . Then, the algorithm finds a hyper-plane that separates the projected examples from the origin with the maximum possible margin. The primal quadratic problem that the OCSVM classifier solves is as follows: where  X   X  R d and 0 &lt; X   X  1. In addition,  X  i  X  0 are slack variables that relax the problem constraints and allow some examples to fall outside the model boundary. Any given solution for this optimization problem has three separate sets of examples: examples that fall inside the boundary (non-support vectors), examples that lie on the boundary (border support vectors), and examples that fall outside the boundary (outliers or bounded support vectors). One of the important properties of OCSVM is that the user-defined parameter  X  is an upper bound on the fraction of outliers and a lower bound on the fraction of support vectors. Using a kernel function as  X  , like a Gaussian kernel ( k ( x, y )= e with the kernel parameter  X  , it is possible to apply the kernel trick and separate normal data points and outliers that are not linearly separable in the input space. After the training phase, the label of any unseen data x is simply predicted using the decision function f ( x )= sign ((  X . X  ( x ))  X   X  ).
 plane, it minimizes the radius R of a hyper-sphere that encompasses almost all normal samples: where a is the center of the hyper-sphere and C is a user-defined regularization parameter that has a similar effect as the  X  parameter in a OCSVM.
 on x  X  y , i.e., the kernel is stationary, the SVDD and OCSVM algorithms result in equal solutions [ 14 ]. As we use the RBF kernel throughout this paper, which is stationary based on the proposed definition, and the  X  and C parameters can be defined based on each other using the  X  = 1 Cl formula [ 18 ], hereafter, we assume that the discussions made for a OCSVM are also valid for a SVDD. 2.2 Estimating Parameter Settings for the OCSVM Algorithm The choice of the values for  X  (the kernel width parameter) and  X  (the regular-isation parameter) has a major influence on the accuracy of a model generated by the OCSVM or SVDD algorithms [ 12 , 18 ]. To illustrate the effect of the para-meters, we have designed an experiment with a toy problem named Half Kernel, that includes 4,000 normal samples and 5 % outliers, which were added to the normal data at random using a uniform distribution. Figure 1 shows the differ-ent models that have been generated using the OCSVM algorithm with different values of the  X  and  X  parameters. The best model, i.e., Fig. 1 (b), has been built using the optimal parameter settings (  X   X  ,  X   X  ). Figure 1 (a), (c) show that choos-ing  X  values less than the optimal value results in building overly general and simple models with a high false positive rate (FPR) with respect to the target class, whereas larger values are prone to building poor models with a high false negative rate (FNR). The  X  parameter affects the results in the same manner as shown in Fig. 1 (d), (e). To illustrate how the optimal value of this parameter depends on the data, in Fig. 1 (f) we have added another 5 % anomalies to the Half Kernel data set and used the same setting as in Fig. 1 (b) to train a OCSVM model. This figure shows how dramatically the model may deviate towards out-liers, if the  X  parameter is not set correctly. Consequently, the optimal  X  and  X  parameter values depend on the given data set, and thus we require a method to select these parameter values from the data. We now summarize two families of approaches to this problem, namely, supervised and unsupervised learning approaches.
 Supervised Learning of the Parameters: If ground truth labels are avail-able, it is possible to optimize the choice of values for the  X  and  X  parameters via n -fold cross-validation. Zhuang et al. [ 21 ] suggested that the most reliable approach to search the parameter space in this manner is to use grid-search, and due to its considerable computational requirements, an efficient parameter search algorithm should be used. To this end, they have first applied a coarse-grained search over the entire parameter space and then performed two further fine-grained searches to reduce the complexity by restricting the search space. Unsupervised Learning of the Parameters: A major drawback of super-vised learning in this context is the need for ground truth labels. Consequently, several heuristic unsupervised approaches have been proposed to estimate the  X  and  X  parameters when the training set is not clean and no ground truth labels are available to find an optimal parameter setting. Emmott et al. [ 5 ]have assumed prior knowledge about the value of the  X  parameter. Then, the value of the  X  parameter has been increased until a predefined proportion of the data has been rejected. Since there is usually more than one pair of parameters that result in approximately this predefined proportion of outliers, this approach may not be successful in finding an optimal parameter setting. Since the proportion of outliers might be unknown, R  X  atsch et al. [ 12 ] proposed a heuristic to find an appropriate  X  value for a OCSVM. Their main assumptions are that outliers are far enough from normal samples and the  X  parameter is known, and the idea is to increase  X  over the range (0, 1) to find a value that maximizes the separa-tion distance between the normal class and the rejected samples. The distance is defined by the following equation: where N + and N  X  are the number of samples in the target and outlier classes, respectively. R  X  atsch et al. have reported that if there is no clear separation between negative and positive samples, the proposed heuristic may come up with extreme solutions, i.e., 0 or 1. Moreover, the choice of the  X  parameter and its effect on finding a good value for the  X  parameter has not been discussed in their work. Liu et al. [ 10 ] have estimated the  X  parameter as x j 2 /l 2 , which can be used in combination with R  X  atsch X  X  method to estimate both the  X  and  X  parameters in a fully unsupervised manner. Hereafter, we call this method Duplex Max-margin Model Selection (DMMS) as it is based on the max-margin principle and maximizes the separation between the two classes. for a SVDD in a fully unsupervised manner. Their proposed heuristic optimizes the estimated FP and FN rates by solving the following minimization problem: where SV and s max represent the set of support vectors and the maximum distance in the training set, respectively. SV b indicates the set of border support vectors (i.e., those with 0 &lt; X  i &lt;C ), and  X  is a regularizer. The first term ( is an estimate of the error on the target class, and the second term controls the error on the outlier class. Since the RBF kernel has been used for this heuristic, it is also possible to use the same parameter setting to train a OCSVM. Hereafter, we refer to this heuristic as Duplex Error-minimisation Model Selection (DEMS) as its objective is to minimize FPR and TPR.
 soft labeling mechanism to train a one-class classifier, different from the OCSVM and SVDD methods, by applying the soft labels directly in the optimization problem of the studied one-class classification algorithm, which is very different from the aim of this paper and so is not discussed here.
 [ 19 ] have proposed to use samples from the outlier class directly in the opti-mization function of a OCSVM or a SVDD to boost the accuracy. However, Tax et al. [ 19 ] have shown that choosing  X  X oor X  outlier examples, i.e., outliers that fall inside or very close to the target class, reduces the accuracy of the trained model to be similar to a random classifier. They have also discussed that if only examples from the target class are available, generating synthetic outliers in low density regions can help tighten the data description and enhance accuracy, but an automatic method to generate such examples has not been proposed.
 We summarize the shortcomings of the existing methods as follows: 1. Even a moderately high resolution grid-search may incur a substantial number of iterations and high time-complexity. Moreover, the granularity of the search can have a major effect on the final result. 2. In many applications, examples from the outlier class are not available for use in finding an optimal parameter setting via cross-validation. Moreover, it is not assured that a nearly clean data set of normal samples is available during training. These problems have not been studied by the existing approaches. 3. Even if negative examples are available as well as positive ones, based on the work presented by Tax et al. [ 19 ], it is not guaranteed that their contribution improves the accuracy of the trained model, unless they are far enough from the target class. None of the existing methods resolves this problem. 4. All the existing unsupervised parameter estimation methods (except DEMS) assume prior knowledge of either  X  or  X  , but both parameters may be unknown in many applications. This makes it impossible to optimise one parameter based on knowing the other one. 5. The DEMS method is a fully unsupervised method, but it requires a mecha-nism like grid-search to search over the parameter space and suffers from the time-complexity problem in point 1 above. Moreover, this approach has been examined on only a limited number of data sets. We are given an unlabeled data set DS comprising unlabeled data points x R ( i =1 , 2 , ..., l ) from the normal and outlier classes. Like [ 16 ], we assume that outliers are uniformly distributed in the feature space. Our aim is to find a compact region in the search space for the parameters  X  and  X  that contains the optimal parameter settings  X   X  and  X   X  for a OCSVM with RBF kernel. Once such a compact region has been found, we can either directly estimate the optimal settings, or efficiently apply a grid-search method within this compact region. In this way, we can estimate the optimal parameter settings for training a OCSVM (or SVDD) without requiring ground truth labels or resorting to exhaustive grid-search, even when the fraction of outliers in DS is high.
 In addition, we aim to develop a method of pre-processing the data set DS that can: (1) filter  X  X order-line X  data points that can affect the accuracy of the learned OCSVM model; and (2) add synthetic outliers in low density regions of nearly clean data sets to enhance the accuracy of the trained OCSVM by generating labeled data sets.
 cally estimate optimal parameter values  X   X  and  X   X  , which address the shortcom-ings that were identified in Sect. 2 for the existing methods to this problem. We divide the problem of finding optimal parameter settings into two steps: (1) estimating the  X  parameter, and (2) estimating the  X  parameter.
 Estimation of  X  : Recall from Sect. 2 that the  X  parameter is the bandwidth parameter of the RBF kernel, which acts as a scaling factor to smooth the learned density estimate to reflect the true data density. Lihi et al. [ 20 ]proposed a method that estimates a local scaling factor for each sample x matrix A  X  R l  X  l ( A ij = exp (  X   X  i  X  j d 2 ( x i ,x j metric). They used the distance between x i and its K th nearest neighbor to obtain an estimate of  X  i , and showed that setting K = 7 results in good estimates even for high-dimensional data sets.
 point x i in the training set DS : where KNN i is the set of the K nearest neighbors of x i inclusive. The density measure s i K reflects the density of points around point x find the value s i  X  K of a point x i  X  that corresponds to the  X  X imit X  of the density of normal points, and can thus be used to estimate the  X  parameter. To do this, we define an ordered set S K = { s i K ,  X  i =1 ..l | S m can be used to fit a function FS ( m ) to visualize the densities of points in DS . It can be shown that for data sets that follow the definition of DS in Sect. 3 , the function FS ( m ) is similar to Fig. 2 . We propose that the knee-point in this monotonically increasing function, which is shown in Fig. 2 by a circle, carries important information that can be used to set the  X  parameter. The knee-point actually represents a sudden change in the densities where we have the normal points near to the data boundaries followed by the outliers.
 with maximum curvature. The curvature at each point x of the function f ( x )is defined below as C f ( x )[ 13 ], hence a knee-point can be formulated as Eq. 6 . works reasonably well for a variety of data sets with different inherent structures. We now propose two variants of our heuristic that provide a means of estimating the  X  parameter.
 Quick Model Selection (QMS): The information gained via the knee-point of FS ( m ) can be utilized to estimate the  X  parameter as well. As the knee-point is an indicator of a sudden change in FS ( m ), it shows that densities s greater than m max C samples x i with this property are good representatives of outliers, which leads us to set  X  = NN) method to detect outliers in a data set, with the key difference that we use this unsupervised method just once in the pre-processing step to estimate an optimal parameter setting for a OCSVM, and after training the OCSVM, unlike the K -NN method, there is no need to compute distances for the test instances. Another important property of QMS is that it can be used to automatically select good examples of outliers for training purposes. To this end, we introduce a shrinking factor  X  in the range (0, 1] that can be used to safely divide samples into three groups:  X  Normal ( s i K &lt; X   X  FS ( m max C  X  Outlier ( s i K &gt; (2  X   X  )  X  FS ( m max C  X  Border-line (  X   X  FS ( m max C Now, we can remove the border-line samples from the data set and label the out-lier examples as they are sufficiently far from the normal samples. This process is shown in Fig. 3 for a Banana data set comprising 10,000 normal instances and 20 % anomalies, which were generated using a uniform distribution. This exam-ple also illustrates the robustness of our method to the percentage of outliers in the training set.
 Revised DMMS (RDMMS): We also propose to use our heuristic to estimate the  X  parameter for the DMMS method, which was explained in Sect. 2 .We further modify the distance metric D  X  (Eq. 3 )asEq. 7 below, for we have found it to be a more practical metric in our experiments: complexity of grid-search, by providing an initial guess for the optimal parame-ter setting and substantially reducing the search space. In the next section, we evaluate our heuristics on a variety of data sets in terms of their accuracy and run-time, and compare them with supervised grid-search and several existing unsupervised approaches. We evaluated our proposed methods in comparison to the DEMS and DMMS methods. Similar to [ 20 ], we set K = 7 in our proposed approaches. Since Tax et al. [ 18 ] have reported that the DEMS method is not sensitive to the value of the  X  parameter, its default value (  X  = 1) was used in our experiments. We also implemented a supervised grid-search method, including two phases of coarse-grained and fine-grained search based on the proposed method by Hsu et al. [ 8 ], to make sure that the time-complexity is kept low. This method applies a 10-fold cross validation to find optimal parameter settings.
 time-complexity of the methods. To evaluate accuracy, we used the Receiver Operating Characteristic (ROC) curve and the corresponding Area Under the Curve (AUC) as it is insensitive to class balance. The reported AUC values were averaged over 200 runs. The experiments were conducted on a machine with an Intel Core i7CPU at 3.40 GHz and 16 GB RAM. MATLAB LIBSVM toolbox (version 3.20) [ 2 ] was used to implement the OCSVM method. 5.1 Data Sets We ran our experiments on 7 real data sets from the UCI Machine Learning Repository, namely Contraceptive Method Choice (CMC), Cardiotocography (Cardio), Breast Cancer Wisconsin (Cancer), Ozone Level Detection (Ozone), Forest CoverType (Forest), Shuttle, and Vowel. We also generated 3 synthetic data sets: a Banana, a C-shape and a Smile (including a mixture of two Gaussians and one C-shaped distribution). These combinations enable us to examine our proposed heuristics on a variety of data structures. All data sets were scaled in the range [0, 1] using feature scaling technique. For all data sets, 5 % anomalies in the range [0, 1] were added using a uniform distribution, and test and training sets were randomly selected from the data with the ratio of 1 to 4. In this way we know the actual labels and we are able to evaluate the methods.
 We empirically observed that the data should be scaled in the range [0, 1] to make it possible to estimate the  X  parameter based on our heuristics. 5.2 Results and Discussion Table 1 reports the accuracy and run-time of the examined methods. As the traditional supervised grid-search (S-Grid-S) method has considerable computa-tional requirements, we set an upper-bound equal to 10,000 data points on the size of the whole data set in all the experiments reported in this table. Based on the reported results in Table 1 , our proposed methods outper-form the existing unsupervised parameter estimation methods (i.e., DEMS and DMMS). In comparison with the S-Grid-S method, on 3 real data sets (Can-cer, CMC, and Vowel) our methods result in considerably higher accuracy and lower time complexity, while the S-Grid-S method outperforms our QMS method only on Forest and Ozone, and for the rest of the data sets their accuracy is almost the same. To identify the statistical significance of results between the two approaches with highest AUC, i.e., QMS and S-Grid-S, we conducted a t  X  test with a level of significance of  X  =0 . 05. The returned p =0 . 63 for the accuracy measure fails to reject the null hypothesis with a level of significance, i.e., the difference between the AUC of the two approaches is not statistically significant. Moreover, the returned p =0 . 034 for the training time indicates that the time-complexity of our method is significantly lower than the S-Grid-S method. Since l d in our experiments, the time-complexity of S-Grid-S using traditional matrix inverse is O ( l 3 )[ 3 ], while the most expensive part of our QMS method, i.e., finding the K nearest neighbors, requires O ( l S requires a labeled data set to find the optimal parameter settings, but our proposed methods are completely unsupervised, i.e., learning of the parameter settings is performed without having access to the labels (the labels have been used only for testing purposes).
 To compare the scalability of the two methods with the best accuracy, i.e., S-Grid-S and QMS, we have conducted another experiment with the Forest data set. The number of data points has been increased between 10 K and 500 K, and we have given both methods at most 6 h to find the optimal parameter settings. As shown in Fig. 4 , our QMS method successfully finds the parameter settings in this time limit, but the running time of the S-Grid-S method exceeds the limit even for a data set of 20 K samples.
 We proposed two parameter estimation algorithms, namely QMS and RDMMS, for the OCSVM and SVDD algorithms, which estimate optimal parameter set-tings without any need for ground truth labels or exhaustive grid-search over the parameter space. Our experimental evaluation showed that our methods outperformed existing heuristic approaches that found the parameter settings in an unsupervised manner. Moreover, our QMS method had comparable accuracy to the supervised grid-search method, while it was in average more than 900 times faster than the supervised-grid search method on the examined real and synthetic data sets. The QMS method also outperformed all the existing meth-ods in terms of time-complexity. In future work, we aim to use this heuristic in training OCSVMs for concept-drifting data streams, where we need to train a new model using the recent data.
