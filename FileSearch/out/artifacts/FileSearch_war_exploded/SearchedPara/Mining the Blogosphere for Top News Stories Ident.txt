 The analysis of query logs from blog search engines show that news-related queries occupy a significant portion of the logs. This raises a interesting research question on whether the blogosphere can be used to identify important news sto-ries. In this paper, we present novel approaches to identify important news story headlines from the blogosphere for a given day. The proposed system consists of two components based on the language model framework, the query likeli-hood and the news headline prior. For the query likelihood, we propose several approaches to estimate the query lan-guage model and the news headline language model. We also suggest several criteria to evaluate the news headline prior that is the prior belief about the importance or news-worthiness of the news headline for a given day. Experimen-tal results show that our system significantly outperforms a baseline system. Specifically, the proposed approach gives 2.62% and 10.19% further increases in MAP and P@5 over the best performing result of the TREC X 09 Top Stories Iden-tification Task.
 H.3.3 [ Information Search and Retrieval ]: Information Search and Retrieval  X  Retrieval models Algorithms, Experimentation, Performance Blog Retrieval, Blogosphere, Top News Stories Identification
A blog,  X  X eb log X , is a special type of website in which users (individuals or groups) express their opinions or thoughts on several subjects. Blog posts consist of a wide variety of topics. As the number of blog users increase, the popular-ity and the importance of blogs are growing, and several commercial search engines such as Google 1 and Technorati have provided blog search services.

Users X  information needs for blog search differ from those for general web search. A large portion of the query logs from blog search engines are news-related queries [21, 22]. In other words, many users find information about news stories in the blogosphere. This implies that the blogosphere may be helpful when locating news stories.

A large number of news stories from various news chan-nels are generated and updated day after day. However, a relatively few news among huge number of them receive attention from users. Therefore, it is one of the most impor-tant issues to evaluate the importance of news stories and rank them.

We investigate how to take advantage of the blogosphere for identifying top news stories. To this end, given a certain day, we retrieve and rank news headlines according to their importance or newsworthiness, using the blogosphere. Fur-thermore, this task is worthwhile in that it identifies the top news stories from blog users X  point of view, instead of the news providers. The task is also called Top Stories Identifi-cation Task (TSIT) which was first introduced at the TREC 2009 Blog Track [21].

TSIT is a new pilot task that aims to  X  X ddress the news dimension in the blogosphere X  [21]. The task uses a date (day) as a query. For a date query, the system for the task ranks the news headlines in the order of their importance. Furthermore, for each news headline, the task requires a certain number of blog posts that capture diverse aspects relevant to the news headline.

TSIT has some characteristics that distinguish it from previous news-related studies such as Topic Detection and Tracking (TDT). First, the data given for TSIT contains only news headlines but no news contents. Therefore, the system for the task should rank news headlines utilizing the blogosphere (i.e. Blog08 corpus) instead of the contents of news articles. Second, unlike the corpus of news stories, blog posts are generally neither well-written articles nor topically coherent. They also include a lot of non-topical contents such as spam blogs and blog comment spam that advertise commercial products and services [16], making the task dif-ficult.

In this paper, we present novel approaches to identify the top news stories in the blogosphere. The proposed ap-proaches are based on the language model framework, which is widely used in information retrieval tasks. We propose a http://blogsearch.google.com/ http://www.technorati.com/ series of approaches to estimate a query language model and a news headline language model based on the blogosphere, and to rank the news headlines according to the distance be-tween two language models. We also suggest several criteria to evaluate the prior probability that a news headline will be a top news story for a given day, and verify that these crite-ria are useful to identify top n ews stories. The experimental results show that our approach significantly improves the best performance submitted in the TREC 2009 Top Stories Identification Task.

The rest of the paper is organized as follows. In section 2, we briefly survey related work on new event detection. In section 3, we address the framework of our system, and pro-pose several approaches to identify the top news headlines. In section 4, we conduct several experiments to evaluate the performances of our approach. Finally, we conclude the pa-per and discuss future work in section 5.
As a new pilot task, TSIT aims to identify top news sto-ries in the blogosphere, and to provide a ranked list of news headlines. There are few researches for identifying and rank-ing top news stories in the blogosphere. One of the research directions closely related to TSIT may be the New Event Detection.

New Event Detection, one of the five tasks in TDT, aims to detect whether a given news story is concerned with al-ready known events to a system or not. For the event de-tection problem, many approaches have been based on clus-tering or classification to estimate the similarity between the events and documents (e.g. the news stories); these approaches differ in the ways by which they evaluate the similarity [3, 5, 17, 25, 28, 29]. All of them compare each document with existing events. If the similarity between the document and the events is lower than some predefined cri-teria, the document is considered to address a new event. Otherwise, the document is assigned to the event to which it is most similar.

Various features have been proposed, including timeline analysis, burstiness and named entities. Chen et al proposed an aging theory to capture the life cycle of a news event, and improved the performance for event detection [7]. Chen et al used an aging theory and a sentence modeling to extract hot topics from news documents [8]. They analyzed the timeline to identify the key terms. The burstiness of terms was used by many researchers for the event detection [9, 12, 15, 24]. Kleinberg proposed an approach to identify the bursty features for the event detection from e-mail streams [15]. They used the infinite-state automaton to model the stream. He et al identified bursts of (a)periodic features using a Gaussian distribution, and then used them to detect (a)periodic events [12]. Kumaran and Allan used named entities for the event detection [17]. They showed that the usefulness of named entities can change according to certain situations. Kuo et al classified terms within news stories based on named entity type and parts-of-speech tags, and assigned a different weight to each term according to the type and class of news story [28].

The main difference between previous work for the event detection and our approach stems from the difference in source data for identifying events or news stories. In con-trast with previous work, we identify the top news headlines using only the unorganized blogosphere, not the well-defined contents of news articles.
To identify the top news stories, we rank them according to their importance or newsworthiness on a specific day. The newsworthiness of a news story can be decided by several criteria 3 as follows:
We assume that a news story mentioned in more blog posts or comments is more important or newsworthy on a specific day, because a top news story satisfying the above criteria may receive attention from many blog users, who express their thoughts or opinions about the news story in their blogs.

To measure the importance of a news story using the blo-gosphere, we adopt the language model framework, which is widely used in information retrieval tasks. Motivated by our assumption, we evaluate the importance of a news headline using the probability that blog posts published on a query day generate the headline. Let H be a news headline and let Q d and Q p be a given (date) query and a set of blog posts published on the query day Q d ,respectively.

Importance score of a news headline
In the language model framework, the query likelihood means the probability that a document generates a given query. TSIT uses a date (day) as a query. Therefore, we regard the query likelihood as the probability that a news headline generates blog posts published on the query day (i.e. Q p ).
 To this end, we should estimate two language models, the Query Language Model (QLM) and the News Headline Lan-guage Model (NHLM). Both of the language models are es-timated, based on blog posts.
For a query day Q d , we estimate the QLM using blog posts Q p . However, the blog posts may discuss various top-ics from individual daily affairs to important events recently happened. If we model the blog posts using a single lan-guage model, the language model cannot correctly capture http://www.mediacollege.com/journalism/news/ newsworthy.html the contents of the blog posts. As a result, we will get the wrong QLM.

To solve this problem, we divide the documents into K clusters. We assume that each cluster can accurately reflect one of the various topics mixed in the blog posts. To esti-mate the QLM, we first gather blog posts which are pub-lished on a query day. Then, we cluster them using the K-means algorithm. We represent each document using the term vector d : w i = tf i  X  idf i ,where tf i indicates the fre-quency of term w i within a document d ,and idf i =log( | means inverse document frequency: | TD | is the total number of documents in a collection and df i is document frequency of a term w i . We use the cosine similarity as the distance function between two documents.
 where | d i | and | d j | indicate the length of d i and d tively.

After clustering, we can generate the QLMs from the K document sets. Let D k = { d k 1 ,d k 2 ,  X  X  X  ,d k n } be the k th document set,  X  QLM k be the k th QLM. The document set D k contains information relevant to a topic of the document set, but also contains background information. We assume that the documents are generated by a mixture model of  X 
QLM k and the collection language model  X  C that reflects the background information.
 P ( D k )= where c ( w ; d k i )isthenumberoftimesterm w occurred in adocument d k i , P ( w |  X  C )= ctf w | C | : ctf w is the number of times term w occurred in the entire collection, | C | is the length of the collection, and  X  is a weighting parameter. In our experiments, we set  X  as 0 . 8.

Then, we can estimate  X  QLM k using the EM algorithm [11]. The EM updates for p ( w |  X  QLM k ) are as follows:
To estimate the NHLM, for each news headline, we first retrieve blog posts relevant to its topic using the news head-line itself as query. To this end, we evaluate the relevance between a news headline H and a blog post d using the the KL-divergence language model [18] with Dirichlet smoothing [27].
 where P ( w | H ) is the maximum likelihood estimates of the news headline, and P ( w | d )= c ( w ; d )+  X  d P ( w |  X  the number of times a term w occurred in a blog post d ,and  X  d is a smoothing parameter, and | d | is the length of the document d .

Among the search results, we use only the blog posts whose issued date is within a certain period from a query day, because the time gap between the issued day of a blog post and a query day often means that the blog post is men-tioning an event different from those that happened on that day [25]. In other words, the blog post is likely to be relevant to a topically similar, but different news headline.
We gather only the blog posts between -3 and +28 days from a query day. Then, we choose 10 blog posts that can provide as diverse aspects about the news headline as possi-ble. We call the 10 blog posts the supporting relevant posts of the news headline.

We propose two approaches to make the supporting rel-evant posts reflect the diverse aspects relevant to the news headline: Relevance-Based Selection (RBS), Feed-Based Se-lection (FBS).

RBS is an intuitive but naive approach to choose the sup-porting relevant posts. This approach selects the supporting relevant posts according to a relevance score of each blog post obtained from Eq. 6. We define this approach as a baseline for our experiments.

FBS chooses the supporting relevant posts based on blog feeds which belong to each of them. Individual blog users may have different interests and tendencies for the same events, and these differences can be represented through their blog feed [19]. That is, for a given news headline, blog posts from different blog feeds can provide different as-pects, even if they address information on the same news story. Therefore, to increase the diversity of the support-ing relevant posts, we select them from as wide a range of blog feeds as possible. In a similar way to RBS, FBS also chooses blog posts according to their relevance score, but FBS selects only one blog post from one blog feed.
We estimate the NHLM using the maximum likelihood es-timate of the 10 supporting relevant posts and the Dirichlet smoothing [27]. Let  X  NHLM and  X  C be the NHLM and the collection language model, respectively, and let SRP be a set of the 10 supporting relevant posts.
 where c ( w ; SRP )isthenumberoftimesaterm w occurred in SRP and  X  h is a smoothing parameter.
To evaluate the query likelihood, we use the KL-divergence language model [18], one of the-state-of-the-art information retrieval models, to rank news headlines in response to a given query. We use the maximum value among scores be-tween the QLMs and the NHLM as the relevance score of a news headline.

Let Score QLH ( Q d ,H ) be the relevance score of a news headline H with respect to a given query Q d . We define Score QLH ( Q d ,H ) as follows: Score QLH ( Q d ,H )=max
We suggest two criteria to estimate the news headline prior P ( H ) that is the prior belief about the importance or newsworthiness of a news headline for a given day: Tempo-ral Profiling and Term Importance. Although the proposed approaches depend on a date such as the query day, we re-gard them as the priors of a news headline in that they are independent of the query language model.
The Temporal Profiling criterion uses the temporal infor-mation of blog posts relevant to a news headline. We assume that if a news headline is important for a query day, many blog posts relevant to its topic will be posted on that day.
To generate the temporal profile of each news headline, we use a temporal profiling approach proposed in [14] with some modifications. The temporal profile of a news headline H is defined as follows: where t is a date (day), and R is a document set that consists of 500 blog posts selected by an order of a relevance score Score ( H,d ) from Eq. 6, and We then smoothed the temporal profile P ( t | H )usingthe background model as follows: where P ( t | C )= 1 | TD | d  X  C P ( t | d ): | TD | is the total num-ber of documents in the collection, and  X  is a smoothing parameter. In our experiments, we set  X  =0 . 5.

This temporal profile is defined on each single day. How-ever, if a news story is important for a query day Q d , the blog posts relevant to it may be published over a certain period following the day due to the bursty nature [15]. Therefore, we smooth the temporal profile model with the model for adjacent days. Let Score TP ( Q d ,H )beascoreofanews headline estimated using the temporal profile of the news headline.
 where  X  indicates a period from Q d ,and Z w = t  X   X  w ( t, Q We define a weight function for w ( t, Q d )usingtheCosine (Hamming) kernel function [20] as follows: w ( t, Q d )=
The Term Importance criterion uses term information of a news headline. We believe that each term has a different importance for a given day. If a news headline consists of important terms, it is likely to be a top news story and vice-versa. For example, a news headline that consists of common words or stopwords may not be a top news story.
We only consider named entities, not all terms in a news headline. Named entities were used by many event detection systems, improving the performance of the systems [17, 26, 28]. We extract named entities from each news headline using the Stanford Named Entity Recognizer 4 . Then, we gather all n-gram ( n  X  3) from the named entities. http://nlp.stanford.edu/software/CRF-NER.shtml
We evaluate the importance of the n-gram terms based on the TF  X  IDF approach that is widely used for term weighting in many information retrieval tasks.

Let nt be the extracted n-gram term and TF ( nt, Q d )be a term frequency of the term nt for a query day Q d .Intu-itively, if a term nt occurs frequently within news headlines issued on a query day, it is likely to be important. In a sim-ilar way to the bursty nature of blog posts, news headlines relevant to important events that happen on the query day may be published over several subsequent days. Therefore, we define the term frequency TF ( nt, Q d )asthenumberof aterm nt within news headlines that are issued during a certain interval containing a query day Q d .
 where  X  indicates the period, and c ( nt ; t ) means the number of a term nt occurring in news headlines issued on day t .
Let IDF ( nt ) be the inverse  X  X ate X  frequency, and TND be the total number of days that the news headline corpus spans. We define IDF ( nt ) as follows: where DF ( nt ) indicates the number of days on which nt occurs in news headlines, and  X  is a constant which controls the influence of DF ( nt )on IDF ( nt ).

The inverse date frequency IDF ( nt ) corresponds to the inverse document frequency. In other words, a term nt with ahigh IDF ( nt ) value may be a keyword that distinguishes important events that happened on a query day from those that happened on other days.
 Let Score TI ( Q d ,H ) be the importance of a news headline H evaluated using the term importance.

We proposed several approaches for the query likelihood and the news headline prior in section 3.1 and 3.2. They capture the different characteristics of important news head-lines. For the query likelihood, we analyze the contents of the blog posts, and model the dominant topics buried in them. Then, we rank the news headlines according to the probability that each headline generates one of the topics. For the news headline prior, we proposed two criteria to re-flect the properties of important news headlines, Temporal Profiling and Term Importance.

To identify the top news headline, we integrate the query likelihood with the news headline prior. To achieve this, we first adjust each score from 0 to 1.
 min i =min where Score i ( H ) indicates one score of Score QLH ( Q d Score TP ( Q d ,H )and Score TI ( Q d ,H ). Finally, we define the ranking function as follows: where  X  1 is the weighting parameter that adjusts the impor-tance between the query likelihood and the news headline prior, and  X  2 is the parameter that controls the weights be-tween two criteria for the news headline prior.
We conducted several experiments to evaluate our system for TSIT. We measured the performance of the query like-lihood and the news headline prior, respectively. We also investigated the influence of the combination of two compo-nents on the performance of TSIT, with a varying weight parameter  X  1 .
The Blogs08 corpus and the news headline corpus from the New York Times (NYT) [21] were used for experiments. The Blogs08 corpus was created by monitoring 1 million blogs from January 14, 2008 to February 10, 2009, and con-sisted 808GB of feeds, 1445GB of permalink documents and 56GB of homepages. The news headline corpus consisted of headlines of articles published by NYT during the interval covered by the Blogs08 corpus.

Our experiments were performed using only Blog08 and the news headline corpus without resorting to any other re-sources. For the evaluation, we used the 55 topics and rele-vance judgments from the TREC 2009 Top Stories Identifi-cation Task.

We only used the permalinks (blog post) for the experi-ments. We discarded the HTML tags of each blog post, and applied the DiffPost algorithm [23] to remove non-relevant contents 5 of each blog post. Each blog post was also pro-cessed by stemming using the Porter stemmer and eliminat-ing stopwords using the INQUERY words stoplist [2].
In response to each query, we retrieved 100 news headlines according to their importance on that day, and provide 10 supporting relevant posts for each news headline, as in TSIT.
The evaluation consists of two phases. In the first phase, we assess the performances of the proposed approaches for identifying the top news headlines for a query day. For each query, we considered only the news headlines corresponding to Q d  X  1 days as ranking candidates, because of the time discrepancy between the day on which the headline was and the day Q d on which the news story actually happened [21]. We used the mean average precision (MAP) and the preci-sion at rank 5 and 10 (P@5 and P@10) as the evaluation measures.

In the second phase, the supporting relevant posts are evaluated. The posts should provide diverse aspects rele-vant to their news headline. To assess the diversity of the supporting relevant posts, we used the  X  -nDCG [10] and IA-Precision [1] measures.
In [23], the non-relevant contents of a blog post means the Figure 1: The MAP scores of the query likelihood accordingtovaryingthenumberofclusters K .The NHLM is estimated using the RBS.
 Table 1: The performances of the query likelihood estimated using the RBS and the FBS approaches for the NHLM. The number of clusters K is set to 500 for the QLM estimation.

We conducted several experiments to evaluate the per-formance of the query likelihood for TSIT. The aim of the experiments is to determine (1) how correctly the QLMs re-flect the various topics buried in blog posts; and (2) how the proposed approaches for NHLM estimation affect the performance of the query likelihood.

The query likelihood has a few parameters, the number of clusters K for QLMs and the smoothing parameter  X  h for NHLM. For our experiments, the smoothing parameter  X  h is set to 2000 without further parameter tuning.
To determine how correctly the QLMs the reflect various topics buried in blog posts, we evaluated the performance of the query likelihood according to varying K values. For the NHLM estimation, the supporting relevant posts were chosen using the RBS approach.

Figure 1 shows the MAP scores according to varying K values. We set the baseline using K = 1. This means that blog posts are modeled using a single QLM.

Compared with the baseline, the performances for all K&gt; 1 were significantly improved, and the best performance was obtained when using K = 500. From these results, we can confirm that a single QLM cannot correctly capture the con-tents of the blog posts, because of the topical diversity of the blog posts. This weakness reduced its ability for identifying the top news headlines. useless contents for the blog search, such as menu, banner and site description Table 2: The performances of the news headline prior estimated using Temporal Profiling, Term Im-portance and their combination (  X  2 =0 . 8 ). The best performances are shown in bold.

As the number of clusters K increased to 500, the respec-tive topics buried in the blog post were captured by the K clusters. The QLM estimated using each cluster led to the improved performance of the query likelihood. When K  X  500, the clusters have been overfitted, and did not pro-vide enough information relevant to each topic. As a result, the performance decreased.

To investigate how the proposed approaches for NHLM estimation affect the performance of the query likelihood, we measured the performances with two approaches to select the supporting relevant posts. For these experiments, we set K = 500 to estimate the QLMs.

Let QLH RBS and QLH FBS be the query likelihood using the NHLM estimated using RBS and FBS approaches, re-spectively. Table 1 shows the performances of QLH RBS and QLH FBS . The performances of QLH FBS are better than those of QLH FBS for all measures. These results means that the supporting relevant posts selected using FBS provide more diverse aspects of a news headline than those chosen using RBS. As a result, the performance of the query likeli-hood increased.
We proposed two criteria to estimate the news headline prior: Temporal Profiling and Term Importance. We exper-imentally confirmed the usefulness of the proposed criteria to estimate the news headline prior.

First, we evaluated the performance of each approach ac-cordingtovaryingtheperiod  X  . The approaches consider a certain period from a query day to gather evidence for the news headline prior. Generally, blog posts and news head-linesrelatedtoeventsthathappenedonaquerydayare published on that day or in the following days. However, they can be published on preceding days, because of the time discrepancy described in section 4.1.2.

We defined several periods as follows:
Let PRI TP and PRI TI be the news headline prior esti-mated using the Temporal Profiling and Term Importance, respectively. Table 2 shows the performances of each ap-proach according to varying periods and those obtained from the combination of the two approaches. For the experiments, we set the parameters,  X  in Eq.12 and  X  in Eq.14, by maxi-mizing the MAP using an exhaustive search in the following Figure 2: The Map scores of the news headline prior according to varying the parameter  X  2 (  X  1 =1 ). Table 3: The performances of systems integrating the query likelihood and the news headline prior, and  X  2 =0 . 8 ). uogTrTStimes: The best perfor-mance in TREC X 09 Top Stories Identification Task, QLH FBS : the best performance of the query likeli-hood, PRI TP + TI : the best performance of the news headline prior. The best performances are shown in bold. Statistical significance at the 0.05 and 0.01 level is indicated by  X  and  X  for improvement from the query likelihood, respectively,  X  and  X  for im-provement from the news headline prior, respec-tively.
 QLH RBS + PRI TP + TI 0.2081  X  X  0.4145  X  X  0.3455  X 
QLH FBS + PRI TP + TI 0.2124  X  X  0.4255  X  X  0.3527  X  X  values.
For both approaches, as we consider a longer period, we obtain better results. This observation confirms our assump-tion that if a news story is important for a given day, blog posts and news headlines relevant to it will be posted dur-ing several days. Although Temporal Profiling resulted in good performance, the performances of the Term Impor-tance were relatively low. For event detection, the useful-ness of the named entities can change depending on which circumstances they are used in [17]. We think that the poor performance of Term Importance is because we used the named entities without considering the circumstances. How-ever, the combination of the two approaches led to the best performance (  X  =50and  X  = 40). Compared with the best performance of Temporal Profiling, we achieved 1.57% and 6.18% improvement in MAP and P@5, respectively. These results verify the usefulness of the named entities for identi-fying important news stories.

To explore the influence of two criteria when identifying the top news story, we measured the MAP score according to varying the weighting parameter  X  2 (  X  1 = 1, i.e. we are utilizing only the news headline prior to evaluate the per-formance), in Figure 2. The weight parameter  X  2 controls therelativeimportanceofTemporalProfilingandTermIm-portance as the news headline prior. The best performance was obtained when  X  2 =0 . 8. From these results, we can again confirm that Temporal Profiling and Term Importance should be considered together to improve the performance.
Finally, we measured the performance of our system that integrates the query likelihood and the new headline prior. To integrate these components, we used QLH RBS and QLH FBS for the query likelihood, and PRI TP + TI for the news head-line prior.
 Table 3 shows the performances of our systems, QLH RBS + PRI TP + TI and QLH FBS + PRI TP + TI . In addition, for com-parison purposes, we reported the best performing results of the TREC-2009 Top Stories Identification Task [21], and the best performances of the query likelihood and the news head-line prior. We performed the Wilconxon signed rank test to examine whether the improvement of the performance over that of each component was statistically significant.
Integrating the two components significantly improved the performance of TSIT. For the MAP, the best performance was 8.09% and 1.67% higher than those of the query likeli-hood and the news headline prior, respectively. Specifically, our system achieved 2.62%, 10.19% and 4.00% further in-creasesinMAP,P@5andP@10overthebestperformance of TREC X 09 TSIT.

This result implies that the performance can be improved by combining the query likelihood and the news headline prior. They reflect different characteristics that important news headlines should be satisfying. The query likelihood identifies the important news headlines based on modeling the dominant topics in blog posts, but the news headline prior identifies them using various features such as the num-ber of relevant posts, and the importance of terms within news headlines.

Figure 3 shows the MAP scores of QLH FBS + PRI TP + TI according to varying the parameter  X  1 (  X  2 =0 . 8). The weight parameter  X  1 controls the relative importance of the query likelihood and the news headline prior. The best performance was obtained when  X  1 =0 . 8. From these re-sults, we can again verify that the performance for TSIT can be improved when integrating the query likelihood and the news headline prior. We do not show the graph for QLH RBS + PRI TP + TI , because it was almost identical to that
The supporting relevant posts should provide the diverse aspects relevant to a news headline. We proposed two ap-proaches to choose the supporting relevant posts, the RBS and the FBS. We evaluated the diversity of the supporting Figure 3: The Map scores of the integrated system according to varying the parameter  X  1 (  X  2 =0 . 8 ) relevant posts selected by each approach and displayed the results in Table 4.

FBS performed better than RBS. We can verify that the supporting relevant posts of FBS provided more diverse as-pects of a news headline than those of RBS. These results confirm that the use of blog feeds can improve the diver-sity of the supporting relevant posts. Furthermore, these results agree with the results from identifying the top news headlines in Table 3. That is, compared with RBS, FBS chose the supporting relevant posts that provide more cor-rect and diverse aspects of a news headline. As a result,
In this study, we presented several approaches for identify-ing top news stories in the blogosphere. Our system utilizes the query likelihood and the news headline prior, based on the language model framework. For the query likelihood, we proposed several approaches to estimate the QLM and the NHLM. The QLM can be estimated using blog posts issued on the query day. We divided the blog posts into K clusters so that each cluster can accurately contain one of the various topics buried in blog posts. Then, we estimated the K number of QLMs respective to their clusters. We also proposed two approaches to choose the supporting relevant posts for a news headline. The posts were also able to cover many different aspects of the news headline.

Furthermore, for the news headline prior, we suggested two criteria, Temporal Profiling and Term Importance. They measure the importance of a news headline in two different ways. Temporal profiling measures it using the temporal in-formation of blog posts relevant to the news headline. Term Importance measures it using the meaningfulness of terms in the news headline.

We obtained the best performance for TSIT by consid-ering the query likelihood and the news headline prior at the same time. From experimental results, we can verify the the proposed approaches are effective in identifying top news headlines.

Many studies remain for future work. We used K-means clustering to model various topics buried in blog posts. It would be interesting to utilize several approaches such as PLSA [13] and LDA [4] to capture topics of blog posts. To improve the diversity of the supporting relevant posts, various ways such as MMR [6] are also worthy of research. Furthermore, we believe that various features such as com-ments or tags can be used to improve the performance when identifying top news stories. This work was supported in part by MKE &amp; IITA through IT Leading R&amp;D Support Project and also in part by the BK 21 Project in 2010. [1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. [2] J. Allan, M. E. Connell, W. B. Croft, F.-F. Feng, [3] J. Allan, R. Papka, and V. Lavrenko. On-line new [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [5] T. Brants, F. Chen, and A. Farahat. A system for new [6] J. Carbonell and J. Goldstein. The use of mmr, [7] C. C. Chen, Y.-T. Chen, Y. Sun, and M. C. Chen. Life [8] K.-Y. Chen, L. Luesukprasert, and S.-c. T. Chou. Hot [9] H. L. Chieu and Y. K. Lee. Query based event [10] C. L. Clarke, M. Kolla, G. V. Cormack, [11] A. P. Dempster, N. M. Laird, and D. B. Rubin. [12] Q. He, K. Chang, and E.-P. Lim. Analyzing feature [13] T. Hofmann. Probabilistic latent semantic indexing. In [14] R. Jones and F. Diaz. Temporal profiles of queries. [15] J. Kleinberg. Bursty and hierarchical structure in [16] P. Kolari, A. Java, and T. Finin. Characterizing the [17] G. Kumaran and J. Allan. Text classification and [18] J. Lafferty and C. Zhai. Document language models, [19] Y. Lee, S.-H. Na, and J.-H. Lee. An improved [20] Y. Lv and C. Zhai. Positional language models for [21] C. Macdonald, I. Ounis, and I. Soboroff. Overview of [22] G. Mishne and M. de Rijke. A study of blog search. In [23] S.-H. Nam, S.-H. Na, Y. Lee, and J.-H. Lee. Diffpost: [24] C. Wang, M. Zhang, L. Ru, and S. Ma. Automatic [25] Y. Yang, T. Pierce, and J. Carbonell. A study of [26] Y. Yang, J. Zhang, J. Carbonell, and C. Jin. [27] C. Zhai and J. Lafferty. A study of smoothing [28] K. Zhang, J. Zi, and L. G. Wu. New event detection [29] Y. Zhang, J. Callan, and T. Minka. Novelty and
