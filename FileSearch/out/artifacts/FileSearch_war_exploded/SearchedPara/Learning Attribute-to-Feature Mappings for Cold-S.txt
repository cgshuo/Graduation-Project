
Matrix and tensor factorization are well-suited methods for solving several problems in the field of recommender systems, like rating prediction for a given user and item (e.g. a movie or a book) [14], recommending a set of items to a given user [3], or predicting tags for a certain item to a user [23]. Because predictions from factorization models rely on the computation of simple dot products of latent feature vectors representing users, items, and possibly other entities in the application domain, they usually have good runtime performance. Training with regard to suitable optimization objectives usually leads to good predictive accuracy.
The downside of standard factorization methods is that feature vectors are only available for entities observed in the training data, e.g. users who rated a movie or bought a book, or movies rated by at least one user. Thus for entirely new users and items, such methods are not capable of computing meaningful recommendations. Even many hybrid systems that rely on both collaborative and content information cannot provide useful predictions for entirely new entities, i.e. ones that have no collaborative information associated with them.

In real-world recommender systems, such cold-start prob-lems 1 are often solved by switching to a different, purely content-based method when encountering entirely new enti-ties; other options are to present just the most popular items to new users and to randomly present new items to the users in order to gather collaborative information about those new entities.

Our approach is a modular one, with well-defined inter-faces between its components: At the core of our model is a standard factorization model that only works for entities with collaborative training data. This factorization model is optimized for the given recommendation task. The additional components are mapping functions that compute adequate latent feature representations for new entities from their attribute representations.

For example, in the classical recommendation task of movie rating prediction, this approach would handle new users and new items by computing first the latent feature vectors for the unknown entities from attributes like the user X  X  age or location and a movie X  X  genres or main cast, and then by using those estimated latent feature vectors to compute the rating from the underlying matrix factorization (MF) model.

The training of such a combined model consists of learn-ing the underlying standard model from the collaborative data, and then learning the mapping functions from the pairs of latent feature vectors and attribute vectors belonging to entities that are present in the collaborative data.
Note that this mapping approach is applicable to a va-riety of prediction tasks, underlying factorization models, and families of mapping functions. In the following, we describe the use of this framework for the task of item recommendation from implicit, positive-only feedback using a matrix factorization model optimized for Rendle et al. X  X  Bayesian Personalized Ranking (BPR) [22], and demonstrate its usefulness for the new-item recommendation task with a set of experiments.

The main contributions of this work are 1) a general, simple and straightforward method to 2) based on that method, an extension of matrix factor-3) We also show empirically that it is worth training
In a classical recommender system, there are two types of entities, users (e.g. customers) and items (e.g. movies, books, songs). Throughout this paper, we use U = { 1 ,..., | U |} and IDs, respectively. For simplicity, we will not differentiate between the integer ID representing an entity and the entity itself.

We have different kinds of information about the entities: 1) information pertaining to one entity, content informa-2) information that is linked to a user-item pair, collabo-
There are several types of collaborative information. One important distinction is between explicit (e.g. ratings, up-and downvotes) and implicit expressions of user preferences (e.g. clicks, purchases). Depending on the type of system, implicit information may be positive-only , i.e. there may be no recorded negative preference observations.

We represent positive-only implicit feedback as a binary matrix S  X  X  0 , 1 } | U | X | I | , where s ui is 1 iff user u has given positive feedback about item i . A U  X  R | U | X  m be the matrix of user attributes where a U ul is 1 iff user u has attribute l , A I  X  R | I | X  n be the matrix of item attributes, where a is 1 iff item i has attribute l . There are m different user attributes, and n item attributes. We assume that attributes are known for all users and items, e.g. because all items are movies where attributes like genre, participating actors etc. are known.
 Suspects , American Beauty , The Godfather , and Road Trip in our recommender system. Each of those items is assigned to one or several of the genres Crime , Thriller , Comedy , Drama , and Action . If we assign consecutive IDs to the movie and genres, we can create the following item attribute matrix from the contents of Table I: where the rows refer to the different movies, and the columns refer to the different genres. We will use this data in the following examples.
 A. Item Recommendation from Implicit Feedback
The task of item recommendation from implicit, positive-only feedback [9], [10], [16], [17], [22] is to rank the items from a candidate set I cand according to the probability of being viewed/purchased by a given user, based on the feedback matrix S and possibly additional data A U , A I .
We use I + u := { i  X  I : s ui = 1 } to refer to the items for which user u has provided feedback and I  X  u := { i  X  I : s ui = 0 } to refer to the items for which that user has not provided feedback.

Note that item recommendation is related to, but distinct from, rating prediction , where the task is to predict how much a user will like an item  X  or rather, what explicit rating the user will assign to the item.
 Christine . None of them has watched The Usual Suspects ; Christine has watched all three other movies, while Alice and Ben each have only watched American Beauty and The Godfather , respectively. If we assign IDs to all entities in order of their appearance, we have From S , we can deduce the sets I + 1 = { 2 } and I  X  { 1 , 3 , 4 } for Alice (user 1). Note that we only see positive feedback here: We cannot deduce that Alice and Ben do not like the other movies only because they have not watched them.
 B. Cold-Start Scenarios
In a wider sense, cold-start scenarios are those situations where we want to compute predictions for users or items that have few collaborative information [7], [21]; in the narrow sense, cold-start scenarios are exactly those scenarios in which there is no collaborative information at all for the given users or items [9], [10], [18]. In this article, we use the term in the latter sense.
 would be a new (cold-start) item.

In this section, we describe the framework we have sketched in the introduction, and use it for the task of item recommendation from implicit, positive-only feedback. A. High-Level Framework
In factorization models, every entity (e.g. users, items, tags) is represented by a latent feature vector f  X  Usually, the latent features of an entity can only be set to meaningful values during training if the entity occurs in the (collaborative) training data.

If this is not the case, one way to still make use of the factorization model for new entities is to estimate their latent features from the existing content data: to map from the attribute space to the latent feature space. The recommender system could then use the factorization model to compute scores for all kinds of entities; latent feature vectors for new entities would be computed from the content attributes and further on used as if they were normally trained latent features.

The mapping functions could theoretically take any form, although for practical purposes we will limit them to families of functions that allow the learning of useful mapping functions.

The training of a factorization model with a mapping extension consists of the following steps: 1) training the factorization model using the data S , and 2) learning the mapping functions from the latent features Figure 1 illustrates the framework for a domain involving users and items: The rectangles on the left-hand side rep-resent the factor matrices, the ones on the right-hand side the attribute matrices. Attributes are supposed to be known for all entities (vertical hatching), while factors are initially only known for those entities that occur in the training data (vertical hatching). Entities without collaborative data have no factors (blank). The unknown entity factors are estimated using the corresponding mapping function. The mapping functions are learned from the factor and attribute values of the entities with complete information (thin arrows). Note that this framework can be extended to application domains with additional entity types besides users and items. B. Matrix Factorization Model
To exemplify how attribute-to-feature mappings can be used for item recommendation from implicit data, we use BPR-MF, a matrix factorization model based on the Bayesian Personalized Ranking (BPR) framework [22]. Bear in mind that the general framework presented here can be applied to other matrix factorization models, as well as to any other model where the entities of the application domain are represented by latent feature vectors, like Tucker decomposition [27] or PARAFAC [11]. In the examples and experiments, we focus on new items; new users (or other kinds of entities) can be handled analogously. 1) Bayesian Personalized Ranking: BPR is a framework for optimizing different kinds of models based on training data containing implicit feedback or other kinds of im-plicit and explicit (partial) ranking information. It has been successfully applied to k-nearest-neighbor (kNN), matrix factorization, and different tensor factorization models for the tasks of item recommendation [22] and personalized tag prediction [23]. BPR X  X  key ideas are to consider entity pairs instead of single entities in its loss function, which allows the interpretation of positive-only data as partial ranking data, and to learn the model parameters using a generic algorithm based on stochastic gradient descent. 2) Matrix Factorization based on BPR: BPR-MF approx-imates the score matrix  X  Y by the product of two low-rank matrices W  X  R | U | X  k and H  X  R | I | X  k . For a specific user u and item i , the score estimation is For estimating whether a user prefers one item over another, we optimize for the BPR-O PT criterion: where  X  x uij :=  X  y ui  X   X  y uj and D S = { ( u,i,j ) | i  X  I I } .  X  = ( W , H ) represents the parameters of the model and  X  is a regularization constant.  X  denotes the logistic function: 1: procedure L EARN BPR( D S ) 2: initialize  X  3: repeat 4: draw ( u,i,j ) from D S 7: until convergence 8: return  X  9: end procedure 3) Learning Algorithm: For learning the MF model, we use the L EARN BPR algorithm [22], which is a variant of stochastic gradient descent that samples from D S . To apply L
EARN BPR to MF, only the gradient of  X  x uij with respect to every model parameter has to be derived. The pseudocode of the generic algorithm is shown in Figure 2;  X  is the learning rate (step size). A more detailed description of BPR-MF and its theoretical background can be found in [22].
 with k = 2 yields two matrices consisting of the user and item factor vectors, respectively: Every row in W corresponds to one user, which means that row 1 represents Alice , row 2 Ben , and row 3 Christine . In H , each row corresponds to exactly one movie. Suppose that The Usual Suspects has not yet been added to the content catalog, so row 1 does not contain any meaningful values. We can compute item recommendations for Alice by ranking her previously unseen movies according to their predicted scores: Because the score for Road Trip is 1.46, the system would put it further on top of the result list than The Godfather , which only has a score of 0.46. If we want to make a prediction for The Usual Suspects , we need to estimate its factors from its attributes.
 C. Attribute-to-Feature Mappings
In this section, we show how to design attribute-to-feature mappings for items; user-attribute-to-feature mappings can be designed accordingly.

The general form of score estimation by mapping from item attributes to item factors is where  X  f : R n  X  R denotes the function that maps the item attributes to the factor with index f , and  X  : R k denotes the vector-valued function that maps the item attributes to all item factors. 1) K-Nearest-Neighbor Mapping: One approach to map the attribute space to the factor space is to use weighted k -nearest-neighbor (kNN) regression [12] for each factor.
We determine the k nearest neighbors N k as the most similar items according to the cosine similarity [15] of the attribute vectors. Each factor is then estimated by
The cosine similarity is given by
Note that for other kinds of attribute data (e.g. strings, real numbers), other similarity metrics could be employed. items are given in Table II. The factors of The Usual Suspects , estimated by 1-NN, would be With this estimation, we can compute a score for the new item: This result means that we would still recommend Road Trip to Alice . 2) Linear Mapping: For score estimation with a linear mapping to the item factors, we plug linear functions into equation (4): Each item factor is expressed by a weighted sum of the item attributes.
 model with the following weights: The rows in matrix M correspond to the different latent features, while the columns denote the influence of each at-tribute to the latent features. Then the latent feature estimates are  X  h , and the score for Alice and The Usual Suspects is suitable parameters for the linear mapping functions is optimizing the model for the (regularized) squared error on the latent features, i.e. straightforward ridge regression [12]. Because the number of input variables (attributes) can be in the tens of thousands, we use stochastic gradient descent for training. This simple approach did not yield optimal results (see section IV-D), so we investigated another mapping method, which is explained next.
 of the linear functions,  X  = M  X  R k  X  n , for the BPR-O criterion (of the prediction model in equation 4) is a more suitable approach, because it fits the parameters leading to optimal model performance, rather than just accurately approximating the latent feature values. As stated above, when optimizing for BPR-O PT , we are interested in the difference between two item scores for the same user:  X  y
Note that introducing a bias term m 0 f (via an artificial attribute that is always set to 1) does not make sense for item mappings, because the bias part would be exactly the same for both sums.

This can be simplified to  X  y
For training with L EARN BPR (see section III-B3), we need the partial derivative with respect to m lf for f  X  { 1 ...k } ,l  X  X  1 ...n } :
The resulting learning algorithm for the linear mapping model optimized for BPR-O PT is shown in Figure 3.
 1: procedure L EARN BPR( D S , W , H , A I ) 2: initialize M 3: repeat 4: draw ( u,i,j ) from D S 6: for 1  X  f  X  k do 8: end for 9: until convergence 10: return M 11: end procedure D. Run-Time Overhead
Generally, the runtime overhead of adding mapping func-tions to an existing factorization model is low. For each new entity, the factors need to be estimated once, and can be either be stored in the pre-existing factor matrices, or in special data structures. After that, the computation of a prediction takes the same time as with just the underlying model. Note that factorization models themselves are among the fastest state-of-the-art methods. The experimental part of this paper contains a comparison in section IV-F that shows the method X  X  advantage over classical content-based filtering.

We performed experiments to confirm that our approach is able to produce useful new-item cold-start recommendations. We compare the two mapping methods described in section III to other approaches capable of solving the new-item cold-start problem (section IV-D). We also investigated how the number of attributes affects the prediction accuracy (section IV-E).
 A. Datasets
For the experiments, we use the MovieLens 1M dataset 2 , which is a commonly-used rating dataset [10], [18]. Like [10], we do not use the rating values, but just binary rating events, assuming that users tend to rate movies they have watched. To evaluate the performance of recommender algorithms in the presence of new items, we randomly split the items in the dataset into 5 groups of roughly equal size, and assign all corresponding rating events, to perform 5-fold cross-validation.

As attributes, we use the genre information included with the MovieLens dataset, and additional information from the Internet Movie Database (IMDB) 3 . Table III gives an overview of the attribute sets. All attributes used in the evaluation are nominal (set-valued), their representation is binary, i.e. every possible attribute is represented by one number that is 1 if the item has the attribute, and 0 if not. Number refers to the number of attributes in the set, and Sparsity refers to the relative number of zero values in the movies X  attribute representations, the matrix A I that the methods described in this paper also would work for real-valued attributes. The credits attribute set contains actors, directors, producers, writers, cinematographers, etc. involved with the movies; it is a superset of the other two IMDB attribute sets.
 B. Compared Methods
We compared three mapping methods with two baseline methods. For the mapping methods, we computed BPR-MF models (see section III-B) with k = 32 factors using hyperparameters that yielded satisfactory results in non-cold-start evaluations. 4
We also performed the experiments with different num-bers of factors ( k  X  X  32 , 56 , 80 , 120 , 160 } ), and got similar results. in section III-C1; we determined suitable values for k using 4-fold cross-validation on the training data. 5 regression to estimate the latent features from the attributes, described in section III-C2. We determined suitable values for the hyperparameters (learning rate, regularization con-stant) using 4-fold cross-validation on the training data. mized for BPR-O PT is described in section III-C2; Again, we determined suitable values for the hyperparameters (learning rate, regularization constant) using 4-fold cross-validation on the training data. used in [5]; we used the cosine similarity between the items X  binary attribute vectors as the similarity measure. We set k =  X  , so scores for user u and item i are computed by summing up the similarities of the item i with the items previously seen by user u : Note that this is content-based filtering using kNN, not attribute-to-factor mapping via kNN as mentioned in section III-C. also included the results for predicting a random set of items.
We do not compare against just recommending the most popular items, because in our evaluation protocol there are only previously unseen items in the test set, thus there is no popularity information about any of the candidate items. cite experimental results by Gunawardana and Meek [10], who used a comparable evaluation protocol.
 C. Evaluation Metrics prec@n (precision at n ) measures the number of cor-rectly predicted items in the top-n recommendations. It is commonly used in the area of information retrieval [15], is relevant to practice and easy to interpret. We report results for prec@5. We also measured prec@10 in all experiments, which gave the same results regarding the ranking of the methods. Additionally, we report AUC (the area under the ROC curve), which is a more general ranking measure. where z u and  X  are defined as D. Experiment 1: Method Comparison
The comparison of the aforementioned methods on the attribute sets genres , directors , and a combination of the two sets can be seen in Figures 4 and 5. [10] used a similar evaluation protocol in their cold-start experiments  X  the same dataset, also an 80-20 split, but only evaluate on 500 randomly selected users, instead of all users. For genres , they report about 25% prec@5 for their primary method (Unified Boltzmann Machines). As you can see in Figure 4, the results for map-bpr also fall into this region, while map-knn and the two baseline methods perform considerably lower. For directors , map-bpr , map-knn , and cbf-knn are roughly on par. The comparison of map-lin and map-bpr shows that is really worth training the mapping function for overall recommendation perfor-mance, instead of least squares error on the latent features. Regarding the AUC metric (Figure 4), the results are similar.
Note that for cbf-knn , the results deteriorate when the two attribute sets are combined, while the two mapping methods, and in particular map-bpr , profit from the ad-ditional data. We think that cbf-knn  X  X  suboptimal results could be fixed by computing separate item similarities for the different attribute sets and then combining them, but doubt that this will be a stronger method than map-bpr . E. Experiment 2: Large Attribute Sets
Next, we investigated the methods X  performance on larger attribute sets (several thousand attributes). We notice (see Figure 6 and 7) that for large attribute sets the baseline method cbf-knn performs better than the mapping meth-ods. Gunawardana and Meek [10] observed similar behavior for their models, Unified Boltzmann Machines and Tied Boltzmann Machines [9]: using only the genre data led to better results than using actor data (there: about 8,000 attributes) or the combined genres+actors data.

Again the combination of attribute sets leads to a dete-rioration of the prediction quality for cbf-knn , while the mapping methods do not suffer from more data.
 F. Run-Time Comparison
Figure 8 shows the test times per user for the different methods. The number of factors per entity is again 32 for map-bpr and map-knn . One can clearly see that the mapping methods profit from the underlying fast matrix factorization model, while the kNN-based content-based filtering cbf-knn takes several times longer to compute the predictions.
 G. Discussion
The experiments have shown that for the new-item recom-mendation task, BPR-MF in combination with an attribute-to-feature mapping function yields accuracies comparable to state-of-the-art methods like Unified Boltzmann Machines (section IV-D).

The performance on large attribute sets could still be improved over content-based filtering with cosine similar-ity, however this is a problem that other methods in the literature also suffer from (section IV-E). One reason for this could be that cosine similarity works particularly well for high-dimensional sparse data, and that linear models like map-bpr and simple models like map-knn (without much adaption to the data) are not powerful enough to make use of large, sparse attribute sets. A remedy may be using a non-linear learned mapping function, e.g. based on multi-layer neural networks, or support vector regression [26].

Additionally, the mapping approaches have the advantage of being much faster (section IV-F) than content-based filtering using kNN.
 H. Reproducibility of the Experiments We have implemented all presented algorithms in the MyMediaLite recommender system algorithm library, which is available for download under http://ismll.de/mymedialite. The library is free/open source software, distributed under the terms of the GNU General Public License.

Pazzani and Billsus [20] give an overview of content-based methods that can be used for new-item scenarios.
One of the MF variants described in [14] takes attributes into account for the rating prediction task; however it is assumed that for every entity there is also collaborative information available, which makes the model unsuitable for cold-start scenarios in the narrower sense.

Pilaszy and Tikk [21] propose an MF model for rating prediction that maps attributes to the factor space using a lin-ear transformation, based on a method proposed by Paterek [19]. The method (NSVD1) can either handle user or item attributes; predictions are computed from item attributes by This rating prediction method is similar to a special case of the framework presented here, but there are several differences, considering the concrete application as well as the model:  X  NSVD1 is for rating prediction, while the models  X  Pilaszy and Tikk X  X  learning algorithm estimates all  X  If NSVD1 uses user and item attributes at the same Pilaszy and Tikk learn the factors of one entity (e.g. the users) simultaneously with the mapping to the factors of the other entity (e.g. the items), which only exist implicitly via the mapping; the model is not based on a completely trained standard MF model, which is augmented by attribute-to-factor mappings like in our framework. In [21] there is also a generalization of NSVD1 that takes both user and item attributes into account, and which has free latent features. Because of the free latent features, this generalization is not capable of generating cold-start recommendations; it could, however, be enabled to do that using our framework. fLDA [2] uses content data for rating prediction. It combines one-way and two-way user-item interactions and jointly learns the parameters for those interactions. The authors assume a bag-of-words-like structure for the content attributes of items such that latent feature extraction based on LDA [6] is possible. Thus, the fLDA approach is restricted to bag-of-word-features (i.e. nominal) whereas our approach can deal with any type of attributes (i.e. nominal, ordinal, metric); it is not applicable to new-user scenarios. The same authors also proposed Regression-based Latent Factor Models (RLFM) [1], a similar hybrid collaborative filtering method for rating prediction, which works also in cold-start scenarios. According to the authors, by assuming Bernoulli-distributed observations, fLDA and RLFM would also be suitable for item recommendation with positive and negative feedback; nevertheless, the suitability of the approach for that task is not shown empirically.

Pairwise Preference Regression [18] is a regression model for rating prediction optimized for a personalized pairwise loss function. The two-way aspect model [25] is a variant of the aspect model [13] for the item recommendation and the rating prediction task. Filterbots [24] are a heuristic method to augment collaborative filtering systems with content data. Unified Boltzmann Machines [10] are probabilistic models that learn from collaborative and content information by combining Untied Boltzmann Machines, that capture corre-lations between items, with Tied Boltzmann Machines [9], that take content information into account.

We presented a general and straightforward framework to make factorization models attribute-aware. The framework is applicable to both user and item attributes, and can deal with nominal/binary and real-valued attributes. We demonstrated the usefulness of the method by an extension of matrix factorization optimized for Bayesian Personalized Ranking (BPR) that is capable of making item recommendations for new items. The experimental evaluation on two different types of mappings  X  kNN and linear mappings optimized for BPR  X  showed that the method produces accurate predictions on par with state-of-the-art methods, and that it carries little run-time overhead.

We also showed empirically that it is worth training the mapping function for optimal model performance with respect to application-specific losses, instead of just trying to map the latent features as accurately as possible.
An appealing property of our framework is its simplicity and modularity: Because its components are only loosely coupled, it can be used to enhance existing factorization models to support new-user and new-item cold-start scenar-ios.

In the future, we will extend this work in several direc-tions, among others with experiments on user attributes and real-valued (instead of binary) attributes. We also want to see whether the method produces similarly good results for other applications like rating or tag prediction. As stated before, we will investigate how to improve mapping and prediction accuracy for large attribute sets by employing non-linear learned mapping functions like multi-layer neural networks or support vector regression.

We thank the anonymous reviewers for their comments and suggestions. This work was co-funded by the EC FP7 project  X  X ynamic Personalization of Multimedia X  (My-Media) under the grant agreement no. 215006. The second author is supported by a scholarship of CNPq, an institution of the Brazilian government for scientific and technological development.

