 In this paper, we consider the problem of recognizing human a ctions from video sequences on a recognition.
 nition tasks.
 recognition. The goal of this work is to address this gap.
 Ke et al. [10], the parts in our model are initialized automat ically. ponents of optical flow vectors F 4 separate channels F + combination of part-based and large-scale template featur es improves the final results. sumption commonly used in the bag-of-words approaches of ob ject recognition. order to alleviate this restriction.
 to find discriminative local patches, rather than using a gen eric interest-point operator. 2.1 Motion features classification, motion synthesis, etc.
 into two scalar fields F ther half-wave rectified into four non-negative channels F + and F normalized to obtain the final four channels Fb + 2.2 Hidden conditional random field(hCRF) Now we describe how we model a frame I in a video sequence. Let x be the motion feature of Y patches { I images and subscripts to index patches) for t = 1 , 2 ,...,n , where y t  X  X  and x t = ( x t x patch I t variables h = { h Intuitively, each h variables of the model.
 We assume there are certain constraints between some pairs o f ( h  X  X aving-two-hands X , two patches h we consider h h Sec. 3. sponds to a factor in the model.
 conditional random field is defined as p ( y, h | x ;  X  ) = exp( X ( y, x , h ;  X  )) We assume  X ( y, h , x ) is linear in the parameters  X  = {  X , X , X , X  } :
 X ( y, h , x ;  X  ) = X where  X  (  X  ) and  X  (  X  ) are feature vectors depending on unary h on pairs of ( h The details of these feature vectors are described in the fol lowing. Unary potential  X   X   X   X  ( x the part label h where we use [ f a ( x f simply the concatenation of four channels of the motion feat ures at patch x of the patch x of all zeros with a single one for the bin occupied by x the measurement of compatibility between feature vector [ f a ( x The parameter  X  is simply the concatenation of  X  Unary potential  X   X   X   X  ( y,h y and part label h It is parameterized as where  X  Pairwise potential  X   X   X   X  ( y,h between class label y and a pair of part labels ( h contains a pair of patches with part labels h the graph. It is parameterized as where  X  class label y and the large-scale global feature of the whole image. It is p arameterized as of  X  a for all a  X  X  .
 We will demonstrate this experimentally in Sec. 4. images:  X   X  = arg max the t -th training image ( x t ,y t ) can be calculated as: time using belief propagation.
 Now we describe several details about how the above ideas are implemented. solving the following optimization problem: class label a , we apply the root filter  X  G = ( V,E ) is formed by running a minimum spanning tree algorithm over t he ten patches. obtained by initializing the patches on x using the root filter  X  obtained as y  X  = arg max nition: Weizmann human action dataset [2], and KTH human mot ion dataset [17]. Performance on subtraction masks that come with this dataset.
 ground truths, and vertical columns are predictions. per-frame and per-video classification in Fig. 3.
 fair, since [13] does not use any tracking or background subt raction. Fig. 4(b).
 so that all the figures appear in the center of the field of view. on these images. For each image with class label c , we apply the root filter  X  energies, i.e., areas that are discriminative for this clas s. truths, and vertical columns are predictions. our approach outperforms the two baselines systems.
 The comparison with other approaches is summarized in Table 4. We should emphasize that we do provide the results only to show that our approach is compara ble to the state-of-the-art. features performs significantly better than using either of them alone.
