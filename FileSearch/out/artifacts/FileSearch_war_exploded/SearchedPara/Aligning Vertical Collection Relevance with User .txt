 Selecting and aggregating different types of content from multiple vertical search engines is becoming popular in web search. The user vertical intent , the verticals the user ex-pects to be relevant for a particular information need, might not correspond to the vertical collection relevance , the ver-ticals containing the most relevant content. In this work we propose different approaches to define the set of relevant verticals based on document judgments. We correlate the collection-based relevant verticals obtained from these ap-proaches to the real user vertical intent, and show that they can be aligned relatively well. The set of relevant verticals defined by those approaches could therefore serve as an ap-proximate but reliable ground-truth for evaluating vertical selection, avoiding the need for collecting explicit user ver-tical intent, and vice versa.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval] Keywords: aggregated search, federated search, vertical relevance, evaluation, user intent
Due to the increasing diversity of data on the web, most of the current search engines aggregate search results from a set of vertical search engines (e.g. News, Images). This search paradigm is called aggregated search [1]. The verti-cals are associated with content dedicated to either a topic (e.g.  X  X ports X ), a media type (e.g.  X  X mages X ), or a genre (e.g.  X  X ews X ). For a given user information need, only a subset of verticals will potentially provide the most relevant results to satisfy it. For example, relevant verticals for a query such as  X  X lowers X  X ight include X  X mage X  X nd X  X ncyclopedia X  X erticals. Vertical selection (VS), a subtask, deals with selecting a sub-set of the most relevant verticals to a given user information need and improves the search effectiveness while reducing the load of querying a large set of multiple verticals.
The relevance of a vertical could depend on the relevance of the documents within the vertical collection [3, 7] and on the user X  X  intent (orientation) to the vertical [9]. For evaluation purposes, from the collection perspective, Gra-vano et al. [3] assumed that any collection (vertical) with at least one relevant document for a query is relevant. Pow-ell et al. [7] refined and formalized this notion by assuming that the relevance level of the collection (vertical) depends on the number or relevant documents within. In this work, we call this the collection-based vertical relevance . On the other hand, from the user intent perspective, researchers [6, 9] found that user orientation (intent), or how oriented each vertical is to a user X  X  information need (i.e., expecta-tion), also plays an important role in user preference of the aggregated search page. We refer to this as the user verti-cal intent . Most of the previous work either assumes that the relevance of the vertical solely depends on the collection (i.e., its recall of relevant documents) or the user intent (the user X  X  orientation to issue the query to the given vertical).
Although previous work [9] has shown that user vertical intent and result relevance are both correlated for influenc-ing user experience, it fails to connect both criteria within the context of evaluation in this area. The key question is whether we could align the collection-based vertical rele-vance with the user vertical intent for evaluation purposes. This can be further split up into two sub-questions:
In this paper, we propose and test different approaches to derive the collection-based vertical relevance based on doc-ument relevance judgments as are widely used in the IR evaluation community (e.g., TREC). The approaches differ in how they quantify the relevance of a vertical and how the ultimate set of relevant verticals is derived. By conducting user studies to collect the user vertical intent, we compare those approaches on deriving collection-based vertical rele-vance and investigate which approach best aligns with the actual user intent.

The contributions of this paper are twofold: (i) . We exten-sively study different approaches to derive collection-based vertical relevance in the context of over a hundred hetero-geneous resources (search engines). The scale and diversity of the resources used has not been studied previously for o ur task. (ii) . We conduct a user study to verify that the collection-based vertical relevance derived from document judgments can be aligned with the user vertical intent. This is novel to verify that the Cranfield evaluation paradigm used in TREC could also be useful to line up with user ex-perience [5] for evaluation in the heterogeneous environment .
The main elements of this paper are summarized in Ta-ble 1. We first describe different approaches to obtain both the vertical ranking and a set of relevant verticals using the collection-based document judgments (Sec. 2). We then con-duct a user study (Sec. 3) to obtain the vertical ranking and relevant vertical sets from the user (as the ground-truths). Finally, we evaluate different approaches proposed in Sec. 2 and study how well they can be aligned with the user intent (Sec. 4), after which the paper is concluded (Sec. 5).
Formally, given a set of verticals V = { v 1 , v 2 , ...v collection-based vertical relevance I C t derived from the col-lection C for topic t is represented by a weighted vector I t = { i 1 , i 2 , ...i n } , where each value i k indicates the rele-vance of the given vertical v k to topic t . A vertical could contain multiple resources (search engines). For example, an  X  X mage X  vertical could contain resources such as Flickr and Picasa. Therefore, each vertical v i consists of a set of resources v i = { r 1 , r 2 , ...r m } while each resource r of a set of documents r j = { d 1 , d 2 , ...d k } . Given all the rel-evance judgments rel ( d l , t ) between any document d l topic t , we aim to derive I C t .
 Ultimately, given the collection-based vertical relevance I , we aim to threshold it in order to obtain the final bi-nary verticle relevance vector S C t = { s 1 , s 2 , ...s value s k is either 1 (indicating corresponding vertical v relevant and should be selected in VS) or 0 (indicating irrel-evant and should not be selected).
We describe approaches to derive the vertical ranking, fol-lowed by methods to infer the set of relevant verticals.
The strategies to derive the collection-based vertical rel-evance I C t (i.e., the vertical score) from the document rel-evance judgments rel ( d l , t ) vary in two aspects: (1). (Re-source Relevance) the way to estimate the relevance of each resource within a given vertical; and (2). (Vertical Relevance Aggregation) the way to aggregate scores of the resources within the vertical to derive the vertical score.
Following previous work [2, 3], we propose two approaches to estimate resource relevance : (a). K (Key): using the recall of  X  X ey X  (most relevant) documents in the resource and (b). G (Graded precision): the graded precision of doc-uments in the resource [4]. The K approach is similar to the assumption made in Gravano et al [3] and using  X  X ey X  is to reflect the relevance of the resource to return the most rel-evant results that maintain high impacts on user search experience [5]. The G approach is following the evaluation essential idea is to characterize the effectiveness of each re-source to  X  X ecall X  relevant documents in a similar fashion as in previous work [7] when graded relevance judgments are available. Then given the estimated resource relevance scores, we test two ways to aggregate those scores in or-der to obtain the vertical scores (rankings) I C t : (a). (MR) Maximal Resource score and (b). (AR) Average Resource score. The MR approach reflects most of current web search setting that one vertical solely contains one best performing resource while the AR approach represents the averaged vertical performance.

By combining the different resource relevance and aggre-gation methods, we obtain four approaches to quantify I C KMR , KAR , GMR , GAR . Since we could also apply the same technique to the whole vertical (rather than resource), we propose another approach GV by using graded precision
To infer the set of relevant verticals S C t from the obtained collection-based vertical relevance I C t , we argue that the strategies could vary in two aspects: (3). ( Vertical Depen-dency ): assumption of whether vertical relevance is depen-dent on each other; and (4). ( Thresholding Criterion ): assumption of which is the criterion of thresholding. For vertical dependency , we tested both assumptions. By as-suming (a). (D) Dependent, we normalize the vertical scores across all verticals following previous work [1]. By assum-ing (b). (I) Independent, we simply use the original vertical scores I C t .

For thresholding criterion , we tested two different ap-proaches. The differences between them are the criterion that the thresholding is based on: (a). (I) Individual verti-cal score: the individual vertical relevance scores; (b). (O) Overall relevance of the vertical set. The I approach basi-cally assumes that the individual vertical requires a certain relevance to remain in the relevant vertical set while the O approach assumes that the relevant vertical set is required to maintain a certain percentage of relevance of the whole vertical set. By combining vertical dependency and thresh-olding criterion , we obtain four different approaches to infer S t from I C t : DI , DO , II , IO .
In this study, we use the TREC 2013 FedWeb track data [2]. The dataset contains 50 test topics and 157 crawled r esources. It also categorizes the resources into different verticals and provides a set of 24 verticals, as shown in Ta-ble 2. Each vertical consists of a set of resources (search engines). For each resource, the top 10 retrieved document results are returned. The relevance judgments are made on each document with five graded relevance levels.

The 50 test topics were chosen in such a way to avoid a strong bias towards general web search engines. For the most important verticals (in terms of number or size of re-sources, e.g. Video, Blogs), many topics provide a significant number of relevant results. In addition, at least a few topics targeting smaller verticals (e.g., Recipes) are also selected. Table 2: 24 verticals used in FedWeb X 13: a vertical consists of a set of resources (search engines), each retrieving one unique type of documents.

G iven a set of verticals V = { v 1 , v 2 , ...v n } , the vertical user intent I U t for topic t is represented by a weighted vector I { i , i 2 , ...i n } , where each value i k indicates the relevance of the given vertical v k to topic t . To obtain I U t , we conducted a user study, asking assessors U = { u 1 , u 2 , ..., u m binary decisions over all verticals V : A = { a 1 , a 2 , ..., a Therefore, we have a m  X  n matrix M t for topic t . We aim to derive I U t by aggregating M t and ultimately obtain a binary vector indicating the set of relevant verticals S { s 1 , s 2 , ...s n } where each value s k is either 1 or 0.
We conducted this user study following previous work on gathering user vertical intent [9]. Basically, two assumptions were made in guiding the assessment. Firstly, instead of asking assessors to associate an absolute score to each verti-cal, we asked them to make pairwise preference assessments , comparing each vertical in turn to the reference  X  X eneral web X  vertical (i.e.  X  X s adding results from this vertical likely to improve the quality of the ten blue links ? X ). Secondly, instead of providing actual vertical results to the assessors, we only provided the vertical names (with a description of their characteristics presented before their assessments). Al-though this may not be ideal from an end-user perspective (as different assessors might have different views on the per-ceived usefulness of a vertical, especially as the vertical items are hidden), this assumption helped to lower the assessment burden, and yet reflects the perceived vertical user intent (orientation). We used the same FedWeb X 13 data as de-scribed in Sec. 2.2. Most of the assessors are university stu-dents who were recruited to participate via a web interface. To eliminate order bias, we randomized all topics into a set of pages (with five topics per page) and provided each as-sessor the option to assess as many pages as he/she wished. A screenshot of one examplar task is presented in Figure 1.
In total, we collected 20 assessment sessions (i.e., asses-of relevant verticals per topic and per session is 2.64, with a standard deviation of 1.28. Similar to previous findings [9], the mean of inter-annotator Fleiss X  Kappa is moderate (0.48), showing that assessors might have different prefer-ences over the relevance of verticals, despite the clearly de-scribed query information need (as seen from the description and narrative shown in Figure 1).

To derive I U t , we use the fraction of majority user prefer-ences for each vertical v k over  X  X eneral Web X  as the vertical score i k . To further obtain S U t , we threshold the majority user preference for each vertical i k in I U t . It has been shown in our data (moderate inter-annotator Fleiss X  Kappa agree-ment) and previous work [8] that the user X  X  preferred num-ber of verticals varies significantly and different users tend to have different risk-levels. By thresholding 30%, 60% and 90% of majority user preference, we obtain three different types of S U t , representing three types of users respectively: risk-seeking , risk-medium and risk-averse . The risk-seeking users prefer diversity of verticals presented (with a mean of 3.08 relevant verticals) while the risk-averse users are more careful when selecting verticals (with a mean of 0.52 rele-vant verticals): they only select verticals (as relevant) when highly confident (large fraction of user X  X  preferences). The risk-medium is an average user, with a mean of 1.68 relevant verticals (following a similar distribution as shown in [1]).
We evaluate the alignment between collection and user, on both vertical rankings and ultimate relevant vertical sets. relevance I C from GMR approach against user vertical intent I
G iven the collection-based vertical relevance I C t derived from document relevance judgments and user vertical intent I t obtained from user preference judgments, we evaluate whether they align with each other. We aim to evaluate five different approaches of utilizing relevance judgments for ranking verticals, as described in Sec 2.1.1. Specifically, we utilize the nonparametric Spearman Rank Correlation Co-efficient as our main metric to measure the correlation be-tween a collection-based vertical ranking and a user-based one. Since we are more concerned with highly ranked verti-cals (potentially relevant), we also investigate whether there are overlaps between the top-3 and top-5 ranked verticals in the collection-based and user-based rankings. The evalua-tion results of different approaches are shown in Table 3.
Several trends can be observed. Firstly, all the collection-based approaches have a moderate correlation (0.6-0.7) with the user-based vertical ranking. We also study whether this correlation is statistically significant (against random) by performing a permutation test. We found that the corre-lation for all the five approaches are statistically significant (with p &lt; 0.05). Note that the performance difference be-tween different approaches is marginal while the approaches using the graded precision metric outperforms the others. Secondly, we observed that there tends to be some overlap between the top ranked verticals from both collection-based and user-based vertical rankings, albeit moderate (0.4-0.5). However, it is interesting to see that when using simple met-rics on document-based relevance judgements, around half of the top-ranked verticals are aligned with the user intent.
In summary, our experiments suggest that collection-based vertical relevance can be utilized as an approximate surro-gate for measuring user X  X  vertical intent, and vice versa.
We study whether the obtained set of relevant verticals after thresholding is aligned with the ones derived from the user perspectives. For simplicity, we only present results on thresholding with one collection-based vertical ranking ap-proach GMR (Graded precision of Maximal Resource) since we found similar results across all those different approaches.
As we have mentioned, we defined three types of ground-truths, representing three different types of users: risk-seeking users prefer a large set of diverse verticals, while the risk-averse users prefer selecting verticals only when they are Table 3: Spearman correlation and overlap of top-k verticals between vertical rankings from collection-based vertical relevance I C and user intent I U . most relevant, and risk-medium are in between. We test d ifferent thresholding approaches for these user settings.
For each thresholding approach, its numerical threshold was determined based on iterative data analysis, such that the maximum number of relevant verticals for any test topic could not exceed five. In addition, since almost all the Fed-Web X 13 test topics target verticals, we also make sure that at least 80% of the topics have at least one relevant vertical using the selected threshold.

The results are shown in Table 4. We observe similar per-formance trends for different thresholding approaches un-der different user settings (risk-level). II (Independent In-dividual) thresholding approach performs best in terms of precision and F-measure while DI (Dependent Individual) thresholding approach generally would achieve better recall. Generally, an F-measure of around 0.4 could be achieved by mapping the estimated collection-based relevant vertical set with the users X  relevant (intended) vertical set. Although not particularly high, this still shows that vertical collection relevance could be aligned relatively well with users X  verti-cal intent and therefore this could serve as a surrogate of ground-truths for evaluating vertical selection.
In this paper, we propose a set of different approaches to utilize document judgments to derive the set of relevant ver-ticals. We evaluate the effectiveness of those approaches by correlating with the user vertical intent obtained from a user study. We found that collection-based vertical relevance can be aligned relatively well with users X  vertical intent. This implies that we could reliably use document relevance judg-ments to evaluate vertical selection for capturing user intent in heterogeneous federated web search, and vice versa.
