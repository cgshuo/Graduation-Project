 job seekers to find job postings on the Web promptly. The task is made unique due to the following two characteristics. Firstly, job names are usually used as search queries directly in job IR. However, they can be expressed by numerous alternatives in natu-ral language. For example, manager can be worded as  X   X   X   X , X   X  X  X   X ,  X   X  X   X  and  X   X  X  X   X  in Chinese. As an extreme case, the job name  X   X  X  X  ( art designer ) X  holds nine semanti-necessarily with literally same job name in the query. 
Secondly, job posting usually comprises of two fields, i.e. title and description. The title field is pretty short (1 to 6 words) and presents the most important points for the quirements of the job. The most interesting point is that, the job name is usually con-title and description depict the same job but share very few common words. 
Problems arising from the two characteristics of job IR are two-fold. First, the title posting full text (title and description) yields very little performance gain over search-then how could we make use of job description properly? 
In this paper we propose to make use of document similarity to locate relevant job postings. The basic assumption is that job description usually provides sufficient and unambiguous information, referred to as semantic clues behind the job name. We argue that the semantic clues can be used to find similarity job postings. In our job IR ries are used to locate literally relevant job names. In the second step, the job posting combined ranking model is proposed, which considers query-document relevance score and document-document similarity score in one formula. The rest of the paper is organized as follows. The unique job IR task is described in Section 2. Then the two-step method for finding the similar job postings is presented in Section 3. In Section 4, experiments and discussions are presented. We summarize the related works in Section 5 and conclude this paper in Section 6. Job information retrieval system aims to facilitate job seekers to find job postings in a large scale online job posting collection. Basically, the job seekers type in job names as the queries directly. 
The job posting is a piece of natural language text that contains two fields, title and job description. Two typical example job postings are given as follows. Job posting example 1: &lt;title&gt;  X  X  X  X  X  X  X  (Software Engineer)&lt;/title&gt; &lt;descrtion&gt;  X   X  X  X  X  Java,j2EE  X  X  X  X  Eclipse  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  ,  X   X  X  X  X  X  X  (Strong in programming with Java  X  J2EE; Priority to nese)&lt;/description&gt; Job posting example 2: &lt;title&gt;  X  X  X   X  (Programmer)&lt;/title&gt; &lt;description&gt;  X  X  X  Java  X  X  X  X  Eclipse  X  X  X   X  X  X  X  X  X  X  X  X  X  X  RFT  X  X  X   X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  (Experienced in Java programming  X  Experience in Eclipse plug-in development, Priority to those familiar with RFT; Master of Com-puter Science or related) &lt;/description&gt; Since most users use job name as query keywords directly, only job postings contain-who are interested in the one may also be interested in the other. Unfortunately, they literally different. clues cannot be properly used in the VSM based query-document relevance measur-ing scheme, but helpful in finding semantically relevant job postings. 
Our observations on job postings provide two assumptions: 1) similar job names hold semantically similar job descriptions; 2) semantically similar job descriptions in turn determine similar items. Enlightened by the two assumptions, we designed a two-step framework for job IR. The traditional VSM is applied on the title field in the first step, and similarity between job postings over full text is calculated to find the seman-tically similar job postings in the second step. 3.1 The Two-Step Framework and the Combined Ranking Model The key ideas of the two-step framework are summarized as follows. relevance score. Then job postings with relevance scores bigger than the threshold are seed ones. 
To re-rank the relevant job postings, a combined ranking model is proposed as fol-lows, considering query-document relevance and document-document similarity in one formula as follow: second step. 3.2 The First Step Job Information Retrieval Based on VSM In the first step, we retrieve job postings using the VSM. Two query-document rele-very short string. So the inner product might be a good choice in our case. We calcu-late the classical tf-idf value as term weight. setup a threshold to get the seed job postings for further process in the second step. 3.3 Expanding Relevant Jobs Using Similarity between Job Postings In this step, we use full text of each job posting to construct a tf-idf weighted feature ones by document similarity within the VSM. Features and Similarity Measures by [3] to be the best feature types for Chinese text classification. We apply stop word list and finally obtain 25,000 word features and 140,000 character bi-gram features. 
Two similarity measures are implemented in this paper, i.e. cosine and the ex-and commonly used in Chinese text processing. Feature Selection A major characteristic of VSM is the high dimensionality rendering spare data prob-lem. This problem is usually addressed by some automatic feature selection schemes. Yang and Pedersen [4] prove that feature selection technology can improve perform-ance of text classification. In our work, two feature selection schemes are imple-mented, i.e. DF (document frequency) and  X  2 statistics (Chi-square) [4]. 
DF is the number of documents where a feature occurs. Terms with low DF score will be eliminated in this feature selection scheme. text classification. For our case, we apply a clustering algorithm to generate the class defined as follows. where A denotes the number of documents with class label c and containing feature t , the number of documents without class label c and containing feature t , D is the num-number of documents. Finally goodness score for each feature is defined as the maxi-mum cluster-specific  X  2 score as follows. 
We compute DF and  X  2 score for each unique feature and remove a certain propor-tion of features. Feature Re-weighting for Ad-hoc Retrieval The document similarity measure discussed above is independent from query thus can be calculated off-line. However, query contributes more or less to feature weighting. features. 
In our case, we use the top N job postings obtained in the first step to select useful features. The usefulness score is calculated by the Rocchio X  X  formula [7] as follows. where R denotes the pseudo-feedback job posting sets retrieved in the first step, w iq document d j ,  X  and  X  are two constants. 
The top K features with high score are deemed useful and their weights are doubled in our work. 3.4 Some Critical Issues the IR model and the similarity measure of two piece of document into one model. In several similarity measures for relevant job expansion are implemented, most of which are independent from the query thus can be calculated off-line. The exception lected features, rather than be re-calculated between every pairs of documents on-line. Therefore, computational complexity of our method can be appropriately controlled. 
The second issue is retrieval quality. In the two-step framework, quality of the first retrieval is crucial. We set an appropriate threshold to get enough number of the rele-bined ranking model (see Section 3.1) is helpful to discard the false job postings. 4.1 Setup Data from job-hunting websites including ChinaHR (www.chinahr.com) and 51Job (www.51job.com). Title and description filed of each job posting can be detected by an HTML document parser. The query set contains 100 random queries, which in real applications are actually job names. Evaluation Criteria experiments. That is, for each of the 100 queries, we compute searching precision as percentage of job postings correctly retrieved in top ranked N feedbacks . To be prac-tical, we set N as 1, 5, 10, 20, 30 and 40 our evaluation. Around 5000 job postings are judged manually whether they are relevant to the 100 queries. 4.2 Experiment 1: The First VSM Retrieval In this experiment, we evaluate job IR methods on the title field vs. the full text using VSM. We use words as features and two query-document relevance measures, i.e. cosine and inner product. Experimental results are shown in Fig. 1. over that on title only. Two conclusions can be drawn. First, search intension can be reflected by the title rather than the description. Second, the description filed contrib-lates the idea to make use of the description in other manners. 
Note that we use the VSM based on  X  title + inner product  X  as our baseline in the in Fig. 1. 4.3 Experiment 2: Relevant Job Expansion seed job postings using document similarity. bi-grams, with cosine as similarity measure. Experimental results are shown in Fig. 2. 
It is shown that 1) using similar job posting as expansion for seed job postings can improve searching quality; 2) word outperforms character bi-gram as feature type for document similarity measuring. 
Using word as feature type, we then compare two document measures, i.e. cosine and the extended Jaccard. Experimental results are presented in Fig. 3. It is shown that cosine outperforms the extended Jaccard at all points. 4.4 Experiment 3: Feature Selection In the following experiment, two feature selection schemes on word features are com-clustering method by the CLUTO package [8] to generate class labels. The experi-mental results are presented in Fig. 4. improves searching quality.  X  2 statistics on word improves most over baseline by 0.06 and over all-words by 0.011 at p@40. 
It should be pointed out that the motivation to incorporate the clustering technique in our method is to separate the data set into a finite set of  X  X atural X  structure, namely separation, rather than accurate characteriza tion or class label predefined as classifica-tion, so that the  X  2 statistics based supervised feature selection methods can make use of the labels to estimate goodness score of each feature. We have tried several cluster-ing algorithms in CLUTO to obtain these labels. It is disclosed in our experiments that goodness of the clusters does not bias the feature selection much. 4.5 Experiment 4: Feature Re-weighting In this experiment we investigate on the feature re-weighting scheme. We apply Roc-chio X  X  formula to select features with high usefulness score and double their weights if they are determined as useful. Experimental results are presented in Fig. 5. method, feature re-weighting scheme improves most by 0.06 at p@40. 4.6 Experiment 5: The All-in-One System In this experiment, we evaluate our all-in-one job IR system which uses word as fea-scheme and Rocchio X  X  formula based feature re-weighting scheme. 
To compare our method against the traditional query expansion method, the method based on traditional pseudo-relevance feedback is implemented. The method documents, referred as pseudo-relevance feedback. Second, a number of terms are selected and reweighed from the feedback documents using certain scoring criteria to expand the initial query. Third, the expanded query is used to perform new search to get relevant documents. Corresponding to the first step within our method, we imple-ment two methods to perform the initial search, i.e. using cosine as similarity measure on full text and inner product on job posting title. We do not perform query expansion In this experiment, we implement several term-scoring functions [6][11] such as The experimental results are presented in Fig. 6. expansion schemes at most points, in which p@40 is improved most by around 0.08325. This provides sufficient proof for the claim that our method for job IR is effective. 
The second finding is that both query expansion methods outperform the baseline, in which the QE(title) outperforms the QE(full text). This accords to our results in the Experiment 1 where the  X  X itle+inner product X  method outperforms  X  X ull text+cosine X  at most points. The two-step framework we present in this paper is enlightened by the query expan-pseudo-feedback documents to find the semantically similar job postings. categorization/cluster field. Term weighting in query-document relevance measuring is gram in Chinese text categorization. Yang and Pedersen evaluate five feature selection document categorization. In this work, we select DF and CHI as our feature selection method because it is an unsupervised method and CHI yields best performance in Yang X  X  experiments. Strehl et al. compare four similarity measures on web-page clus-tering [5], we use the cosine and e-Jaccard in our work which lead to best performance in their work. Besides, Liu et al. make use of clustering results as class labels so that the supervised feature selection methods can be applied in unsupervised way [10]. model and the similarity measure schemes of two semi-structure documents together. In this work, we investigate on the most popular IR model, i.e.VSM, in job IR. Sev-eral document similarity measures commonly used in NLP fields are implemented our all-in-one system outperforms all other methods in performing the task of job IR. type than character bi-gram. Secondly, cosine is a better document similarity measure than the extended Jaccard here. Thirdly, fe ature selection schemes are helpful to im-special job IR task. Several future works are described as follows. Firstly, we will investigate on other IR models for the job IR task, such as the probabilistic models and language models. Secondly, we will investigate on information extraction techniques for the job IR task because the job postings are semi-structured and some job related information such as company information, responsibility, requirements, etc. can be easily recognized. We measuring. Research work in this paper is partially supported by NSFC (No. 60703051) and Tsinghua University under the Basic Research Foundation (No. JC2007049). 
