 Quantitative notions of diversity have been explored across a variety of disciplines ranging from conservation biology to economics. However, there has been relatively little work on measuring the diversity of text documents via their content. In this paper we present a text-based framework for quanti-fying how diverse a document is in terms of its content. The proposed approach learns a topic model over a corpus of documents, and computes a distance matrix between pairs of topics using measures such as topic co-occurrence. These pairwise distance measures are then combined with the dis-tribution of topics within a document to estimate each doc-ument X  X  diversity relative to the rest of the corpus. The method provides several advantages over existing methods. It is fully data-driven, requiring only the text from a corpus of documents as input, it produces human-readable expla-nations, and it can be generalized to score diversity of other entities such as authors, academic departments, or journals. We describe experimental results on several large data sets which suggest that the approach is effective and accurate in quantifying how diverse a document is relative to other documents in a corpus.
 Diversity; Interdisciplinarity I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing; I.2.7 [ Artificial Intelligence ]: Learning
The quantification of diversity has been widely studied in areas such as ecology [9], genetics [12], linguistics [8], and sociology [5]. The typical context is where one wishes to measure the diversity of a population, where a population consists of a set of individual elements that have been cat-egorized into T types (such as species), with proportions  X  = { p 1 ,...,p T } and P T i =1 p i = 1.

A relatively simple measure of diversity is variety , how many different species are present in a population, or the number of non-zero proportions in  X  . One can alternatively measure diversity as a function of the relative balance among the proportions (also referred to as  X  X venness X  in ecology [13] or  X  X oncentration X  in economics [4]), using measures such as Shannon entropy H (  X  ) =  X  P T i =1 p i log p i or variance-based quantities such as P T i =1 p i (1  X  p i ) = 1  X  P T [20]). The intuition is that higher entropy or variance implies greater population diversity (e.g., see [19]).

From a more general perspective, Stirling [22] proposed that there are three distinct aspects to diversity: variety , balance , and disparity . Disparity is the extent to which the categories that are present are different from each other, based for example on distance within a known taxonomy [21]. For example, a population with 5 beetles and 5 ele-phants would be considered more diverse than a popula-tion with 5 beetles and 5 spiders, given that beetles and elephants are more taxonomically distant than beetles and spiders. Stirling argued that each of these three properties is a necessary (but non-sufficient) component in any quan-titative characterization of diversity, arriving at a relatively simple mathematical formulation for diversity, a formulation originally proposed in earlier work by Rao [18]: where p i ,p j are the proportions of category i and j in the population,  X  ( i,j ) is the distance between categories i and j ,  X  is a T  X  T matrix of such distances, and  X  t is the transpose of the T  X  1 vector of proportions  X  .

This diversity measure div has a simple and intuitive in-terpretation as the expected distance between two randomly selected elements of the population. The probability of se-lecting a pair of elements with replacement from categories i and j is p i p j . Thus, div can be interpreted as the expected value of the categorical distance, E [  X  ( i,j )], where the expec-tation is with respect to the distribution of pairs of elements.
The contribution of this present paper is to investigate di-versity in the context of text documents, using Rao X  X  mea-sure a starting point. In particular, we will use words as elements, topics as word categories, and documents as col-lections (or  X  X opulations X ) of words. Specifically, we address the following task: given a corpus of documents, assign a diversity score to each document, where this diversity score can be used to rank documents from most to least diverse.
There are a number of different practical problems where quantifying the topical diversity of documents in this man-ner is potentially useful. One specific area of application is in science policy. There is broad interest among science pol-icy experts in diversity and interdisciplinarity in scientific research. In particular, there is interest in the hypothesis that interdisciplinary research can lead to new discoveries at a rate faster than that of traditional research projects con-ducted within single disciplines. Indeed, the United States National Science Foundation (NSF) encourages interdisci-plinary proposals, and has put out solicitations for propos-als that include specific combinations of disciplines. One such example was the recent NSF program  X  X ollaboration in Mathematical Geosciences X  (CMG), which was focused on research at the intersection of mathematics and geoscience. In this context an automated diversity measure would be potentially helpful in evaluating the diversity of submitted proposals during the review process. Furthermore, being able to quantify the diversity of papers that resulted from funding under such a program, compared to papers funded by traditional single-discipline programs, would be useful as a component in overall evaluation of the effectiveness of in-terdisciplinary research programs.

Similarly in scientometrics and bibliometrics, there is sig-nificant interest in developing quantitative measures of in-terdisciplinarity for both individual scientific articles as well as collections of articles such as journals (e.g., [23]). Fur-ther afield, one can envision tools that allow researchers to explore and rank the diversity of individual papers and journals, and for administrators (such as department chairs, deans, and heads of research labs) to quantify the diver-sity of the research in their departments and labs relative to other institutions.

We begin in Section 2 by discussing related work. Section 3 outlines a number of possible diversity measures based on topic models. Section 4 describes the text corpora and the topic modeling approach we use in the paper. In Section 5 we describe a set of experiments based on pseudo-documents which serve as a proxy for ground truth and allow us to eval-uate the performance of different text-based diversity mea-sures. Section 6 discusses several examples of both high and low diversity scientific articles and grant abstracts detected by our approach, and Section 7 concludes the paper.
There has been a significant amount of work in the field of scientometrics on quantifying notions of interdisciplinar-ity as reflected in the output of scientific research (e.g., via published scientific articles). The 2005 National Academies Committee on Facilitating Interdisciplinary Research defined interdisciplinarity from an operational viewpoint as a  X  X ode of research that integrates .... concepts ... tools ... data ... from two or more bodies of knowledge or research practice X  [15]. Diversity in this context (e.g., diversity of citations or diversity of text content) can be thought of as a broader construct than interdisciplinarity, but one which serves as a useful proxy for it. Indeed, diversity as defined via co-citation counts is the most widely-used approach to quan-tify interdisciplinarity in practice, based on the notion that disciplines that are co-cited more often by the same article are  X  X loser X  than disciplines that are less frequently co-cited. Journal subject categories are typically used to capture the notion of a discipline , typically using the manually-defined 244 ISI subject categories from Thomson Reuters, with ar-ticles being assigned to a subject category associated with the journal the article is published in (e.g., [15, 14, 17, 23]).
Rafols and Porter [14] used journal subject categorizations of citations to analyze how interdisciplinarity has changed between 1975 and 2005 for six specific subject-categories. They concluded that although the number of citations and co-authors per paper was increasing significantly over time, the degree of interdisciplinarity was increasing at a much slower rate, as reflected by citation patterns between subject categories. As a component in their analysis, Rafols and Porter used Rao X  X  diversity index based on a count matrix of D documents by T categories derived from citations: p i was the proportion of citations made by an article to other articles that were published in journals belonging to subject category i , and  X  ( i,j ) was defined as 1 minus the cosine distance between citation count vectors (across documents) of subject categories i and j .

Our work differs from this earlier work and related threads in scientometrics in two specific ways. First, in our approach the categories and distances,  X  ( i,j ), are learned directly from the text content, rather than being based on manu-ally predefined schema such as the ISI subject categories. There are obvious limitations to relying on pre-defined tax-onomies, as pointed out by Rafols and Porter [15]. Subject categories can change over time and no longer necessarily reflect current disciplinary boundaries. In addition, in some contexts such as analysis of proposals and grants, there may be very limited or no categorizations available. For analysis of narrow domains (say the field of data mining and ma-chine learning) existing categorization schemes may be too coarse-grained to be useful. In this context, a corpus-driven approach to learning the categories, such as the topic-based method we describe here, is a useful alternative, and in some cases may be the only option.

The second major difference in our approach is our use of word counts rather than citation counts (which are the basis of most prior work in scientometrics on quantifying interdis-ciplinarity). We expect that using text content will comple-ment citation-based approaches, as both words and citations carry useful signal. There has long been debate over whether citations accurately reflect the content of a scientific article [2, 1] X  X rguably the words in an article may provide a more accurate reflection of the author X  X  intentions than the cita-tions the author uses. A systematic approach to the use of both word-based and citation-based measures of diversity would also be worth exploring in future work X  X n this pa-per, however, we limit our attention to the exploration of word-based measures.
Another field which is related to our current work is that of outlier detection. If we consider documents as being rep-resented by T -dimensional vectors of counts, then one ap-proach to quantifying diversity is to look for documents that are outliers in this T -dimensional space, using a multivariate outlier detection algorithm. Typically these algorithms rely on a notion of global or local density, e.g., by finding data points that have low-probability under a global distribution or that are relatively distant from their nearest neighbors.
In addition to the usual issues associated with estimating distances and densities in high dimensions, a further com-plication in diversity characterization is that we are seeking low-probability data points with the constraint that we are not interested in solutions where all of the probability mass is on a single component, i.e., where p i  X  1 ,p j  X  0 ,j 6 = i . Equivalently, since the p i are the components of a probabil-ity vector in a T  X  1 dimensional simplex, we can think of high diversity documents as points that lie in the interior of the simplex (in at least 2 of the dimensions) rather than at the edge.

Although it might be possible to develop a principled ap-proach to characterizing diversity in this way, e.g., by a constraint-based approach to outlier detection, the use of Rao X  X  measure bypasses both the problem of estimating a high-dimensional distribution and the problem of constrain-ing points of interest to lie in the interior of the simplex. In particular, we can view Rao X  X  measure as a form of out-lier detection based on second-order information, focusing on pairwise dependencies among the columns of the count matrix, via the  X  ( i,j ) term, combined with a term p i p penalizes count vectors consisting of a single dominant com-ponent.
A third potentially relevant source of prior work is in infor-mation retrieval and search where one wishes to generate a diverse list of search results in response to a user query (e.g., to avoid showing similar items in a list of search results). This work has a somewhat different motivation than the one we pursue in this paper. In the typical search context, di-versity is closely aligned with making inferences about users X  goals, i.e., trying to find a diverse group of documents such that the probability is maximized that at least one of the documents matches a user X  X  implicit goals (e.g., [24]) or max-imizing some notion of coverage (e.g., [6]). In contrast, the focus in this paper is on characterizing the inherent topical diversity of single documents, rather than finding a group of documents that best fulfill a user X  X  information need.
In the general case we consider a count-matrix represen-tation for a corpus of D documents, where each row in-dexed by d, 1  X  d  X  D, represents a document, each column j, 1  X  j  X  T, represents a category, and each entry indexed by ( d,j ) in the matrix represents how many elements in doc-ument d belong to category j . In particular, in this paper we focus on word tokens as the elements of a document, and a learned set of topics as the categories to which elements have been assigned.

We use the Latent Dirichlet Allocation (LDA) topic model with collapsed Gibbs sampling to learn T topics for the D documents in the corpus [7]. A single iteration of the col-lapsed Gibbs sampler consists of iterating through the word tokens in the corpus, sequentially sampling topic assign-ments for each word token in each document while keeping all other topic-word assignments fixed. Using the topic-word assignments from the final iteration of the Gibbs sampler
An alternative approach would be to average over multi-ple samples and use expected counts in the document-topic we create a D  X  T document-topic count matrix with entries n dj corresponding to the number of word tokens in document d that are assigned to topic j .

In this context we can define Rao X  X  diversity measure for each document d as where P ( j | d ) is the proportion of word tokens in document d that are assigned to topic j (estimated as n dj n the number of word tokens in d ) and  X  ( i,j ) is a measure of the distance between topic i and topic j . Note that  X  ( i,j ) is constant across all documents, and P ( i | d ) and P ( j | d ) vary from document to document.

The interpretation of Equation 2 is intuitive: if we ran-domly select a pair of words from document d (with replace-ment), then div ( d ) is the expected topical distance between a pair of words in document d . Thus, a document that has two topics that are far away from one another, each with a large proportion of the word tokens assigned to them, will have a high diversity score. Conversely, documents whose word tokens are assigned to topics that are all relatively close to one another, or whose word tokens predominantly fall into a single topic, will earn a lower diversity score.

There are a number of possible approaches to defining dis-tances between topics  X  ( i,j ). We explore below a number of different pairwise measures of similarity between topics, s ( i,j ), as well as different methods of transforming these similarities into distances. We begin with topic similarity functions based on topic co-occurrence in documents, as de-fined by the D  X  T matrix of document-topic counts. An alternative approach that we also explore is topic similarity based on the similarity of topic-word distributions using the W  X  T word-topic count matrix.
A straightforward measure of topic similarity based on co-occurrence within documents is the cosine distance of columns in the D  X  T matrix of document-topic counts. This is defined as where i and j represent two column indices (two topics) and P d is a sum over all documents indexed by d .

Other similarity measures can also be used. For example, consider randomly selecting two word tokens with replace-ment from within a randomly selected document d in the corpus. Let s ( i,j ) = P ( w 1 = i,w 2 = j ) be the probability that the first word token w 1 is assigned to topic i and the second word token w 2 is assigned to topic j : where P ( d ) is the probability of a random word belonging to document d and is estimated using n d N where N is the num-ber of word tokens in the corpus. In estimating P ( j | d ) and count matrix rather than actual counts from the final sam-ple. P ( i | d ) above we use smoothed maximum a posteriori esti-mates, with hyperparameter values from the Dirichlet prior on the document-topic multinomials in the topic model. The use of smoothed estimates produces non-zero similarities P ( w 1 = i,w 2 = j ) for all pairs of topics i and j , avoiding singularities in the corresponding distances  X  ( i,j ) and di-versity measures. The conditional version of the expression above, P C ( w 2 = j | w 1 = i ) can be viewed as a topic-based version of the contextual word distribution defined by Dillon et al. [3], defined as the probability that one word is present in a document given that another word is also in the same document.
An alternative strategy to using topic co-occurrence is to consider topic similarity based on topic-word distributions. Similarity can be defined in exactly the same manner as above, but now using the W  X  T word-topic count matrix instead of the D  X  T document-topic count matrix, where W is the number of words in the model X  X  vocabulary. In the context of measuring diversity, it is interesting to con-sider whether the document-topic or topic-word similarity is likely to be more useful. One can imagine situations where two topics have relatively different distributions over words (low similarity in topic-word distributions), yet the same two topics co-occur relatively frequently across documents (high similarity in document-topic ). From a diversity perspective, documents that contain these two topics should in principle not be diverse, yet the word-topic similarity measure would indicate that they are since their word distributions are dif-ferent. In our experimental results we explore this further and report results using diversities computed from both the document-topic (DT) and word-topic (WT) matrices.
We empirically investigated two different transformations to convert each similarity measure into a distance measure: tigated the effectiveness of  X  ( i,j ) =  X  log s ( i,j ) but found that it did not provide a performance gain over the other transformations.
The PubMed Central Open Access dataset (PubMed) is comprised of articles published in biomedical journals which are freely available under a creative commons license [11]. We collected approximately 228k articles which were pub-lished between the dataset X  X  inception in 1996 and our col-lection date in mid-2010. We focused our efforts on a subset of approximately 165k articles for which full text was avail-able. Each document contained a title, the name of the journal in which it was published, its year of publication, and names of its authors. We eliminated approximately 20k documents which had either fewer than 600 words or more than 10,000 words, yielding a collection of approximately 145k documents.

Our second data set is a collection of 74k NSF Awards from 2007 to 2012 gathered from www.nsf.gov/awardsearch. Each record includes the title and abstract of the award, as well as various metadata such as the NSF Directorate, Division and Program that funded the award. We eliminated approximately 12k documents which had duplicate titles, followed by an additional 10k which had fewer than 70 words or more than 1,000, resulting in a final set of 52k documents.
As a third data set we used the Association of Compu-tational Linguistics Anthology Network (ACL) [16], consist-ing of papers published in selected computational linguistics conferences. This corpus contains the full-text of approx-imately 19k papers appearing at these conferences over a time span of more than four decades, in addition to each document X  X  title, year, and conference of publication. We eliminated approximately 7k documents which were pub-lished as workshop papers, and an additional 1k which had fewer than 600 words or more than 10,000 words, yielding a collection of approximately 11k documents.
We performed simple tokenization and topic modeling on each of the three text corpora using MALLET [10]. This involved splitting on whitespace, removing punctuation and lowercasing, and converting into a bag-of-words representa-tion using MALLET X  X  default stopword list.

We then learned an LDA topic model with a fixed symmet-ric prior  X  over the word-topic distributions, and optimized the prior  X  over the document-topic distributions. The  X  prior was set to 0 . 01 and we initialized the  X  prior over the document-topic distributions at 0 . 05 N DT , where N is the number of tokens in the dataset, D is the number of docu-ments in the dataset, and T is the number of topics defined in the model. We enabled hyperparameter optimization ev-ery 10 iterations, and ran each Gibbs sampler for a total of 5,000 iterations, keeping only the final sample in the chain. For each dataset, we learned models with T = 10, 30, 100 and 300 topics.
A significant challenge in evaluation is that there is no ground-truth measure for a document X  X  diversity. To address this problem, we created artificial  X  X seudo-documents, X  half of which were designed to have high diversity and half of which were designed to have low diversity.

We create each pseudo-document by combining two ac-tual documents into one pseudo-document in the following fashion. We begin by manually selecting two journals A and B with relatively unrelated (e.g., The Journal of Cell Biology and The Journal of Foot and Ankle Research ). A pseudo-document is created by randomly selecting one ar-ticle from journal A and one article from journal B , which we denote as parent documents . A child pseudo document is then created by computing the average of each parent doc-ument X  X  bag of topic counts, rounded to the nearest count. If the parent journals, A and B , are relatively dissimilar in content, we expect the resulting pseudo-documents to be relatively diverse. We can also create low-diversity pseudo-documents by repeating the above process but now select-ing both parent articles from the same journal. By labeling pseudo-documents as having high or low diversity in this manner, we can create a proxy for ground truth diversity for evaluation purposes. This approach will not necessarily be perfect: for example, it is possible that if one of the jour-nals contains documents that span diverse topics (relative to the corpus as a whole) some of the pseudo-documents la-d(i,j) = 1 X  X (i,j)
Frequency d(i,j) = 1/s(i,j) Frequency Figure 1: Histograms of topic-topic distances for  X  ( i,j ) = 1  X  s c ( i,j ) and  X  ( i,j ) = 1 /s c ( i,j ) . beled as low-diversity by this method could have relatively high actual diversity. However, even though such misla-beling could occur in theory, our assumption is that this pseudo-document approach will allow us to accurately mea-sure relative performance across different diversity measures.
We manually selected ten pairs of journals from PubMed, where each pair appeared to have unrelated content (see Table 2 for a list of journal pairs). Using the process out-lined above, for each pair of journals, we generated 50 high-diversity pseudo-documents and for each individual journal in the pair generated an additional 25 low-diversity pseudo-documents. Each parent document was drawn without re-placement, meaning that no real document served as a par-ent of more than one pseudo-document across the entire set. This process yielded a total of 1,000 pseudo-documents, half of which were designed to have high diversity, and half of which were designed to have low diversity.
We first tested whether our diversity scores could be used to differentiate the two classes of pseudo-documents.
We started by learning a set of topic distances on the document-topic count matrix for the 145k PubMed docu-ments. We then used this distance matrix to assign a diver-sity score to each pseudo-document using the method de-scribed in section 3. We computed an area under the curve (AUC) value for the ROC curve generated from the set of diversity scores produced by our method based on the de-signed ground truth  X  X igh X  and  X  X ow X  diversity values for each pseudo-document.

Table 1 lists AUC values for multiple diversity formulas across topic models with 10, 30, 100, and 300 topics. Chance performance will yield AUC values of 0.50, and perfect clas-sification accuracy will yield an AUC of 1.

First, it is clear from these results that different distance measures yield significantly different results. For example, distance measures with  X  ( i,j ) = 1 /s ( i,j ) perform signifi-cantly better than distance measures with  X  ( i,j ) = 1  X  s ( i,j ) (see Table 1).

This is because s ( i,j ) is close to 0 for most pairs of topics, with large values being on the order of 0.2. As a result, most Figure 2: Pseudo-document ROC curves for PubMed data with 100 topics comparing Rao di-versity to alternate methods. See also Table 1. distances are  X  1 when  X  ( i,j ) = 1  X  s ( i,j ) (see figure 1), making this method more akin to a  X  X alance method X  than Rao X  X  diversity (as discussed in Section 1). On the other hand, when  X  ( i,j ) = 1 /s ( i,j ), small similarity values create very large distances, making the distance term appropriately dominant.

A second general observation from Table 1 is that dis-tance formulas based on the document-topic matrix outper-form distance formulas based on the word-topic matrix (see Table 1). This may indicate that topic co-occurrences in documents are generally more useful in characterizing di-versity than are similarities in topic-word distributions. As mentioned in section 3.2, two topics with very different word distributions may still frequently co-occur within documents in the corpus, which is one possible explanation for why sim-ilarity based on topic-word distributions performs relatively poorly on this task.

A third observation is that Rao diversity significantly out-performs alternative approaches (see Figure 2 and Table 1). This supports Stirling X  X  arguments [22] that taking each of balance , variety , and distance is important for measuring di-versity, compared to methods such as entropy which don X  X  take all three aspects into account.

Overall, Rao diversity with the distance measures we have termed  X  X T-PI X  or  X  X T-CI X  perform the best, where DT refers to a document-topic based similarity measure, P to probability-based similarity, C to cosine-based similarity, and I to the inverse transformation of similarity. In addition to yielding high pseudo-document classification accuracies, these methods also appear to be largely invariant to the number of topics in the model (see Table 1), and show con-sistent performance across pseudo-documents drawn from different pairs of journals (Table 2). Since the  X  X T-PI X  and  X  X T-CI X  methods are very close in performance overall, we use  X  X T-CI X  as our default measure of diversity from this point forward.
In this section we show examples of the most diverse and least diverse documents detected by our algorithm for each of our three corpora: PubMed Open Access, NSF Grant Awards, and the ACL Anthology. For each corpus we built a topic model with 100 topics, and computed diversity scores using Rao diversity with the DT-CI distance measure as de-fined in Table 1. We scaled the distances  X  ( i,j ) to have a mean value of 1 within each corpus, putting the distances and diversity scores on roughly the same scale across cor-pora. We also manually assigned names to topics to aid in interpreting the results.

Figure 3 shows two of the most diverse NSF awards (from a corpus of approximately 52k abstracts of awards) detected by the algorithm. The first award is a collaborative re-search project between mathematicians and geoscientists. As shown in Figure 3, the releatively large distances (6 times larger than the mean pairwise topic distance) between ALGEBRA and each of the GEOSCIENCE and EARTH-QUAKE topics drive a significant portion of the total score. The distances between these topics is reflected in the de-scription of the project in the abstract: The second of the two awards in Figure 3 is considered di-verse because of the combination of the topic ARCHAEOL-OGY and the two biology-related topics PROTEINS and CELLS. Again, the relatively large distances (2.4 and 2.6) between these topics and their relative strength within the document yield a particularly high diversity score for this document.

The two examples of low-diversity documents in Figure 4 tell a different story. The first grant is somewhat narrowly focused, dominated by topics that are relatively close such as CHEMISTRY, MASS SPECTROMETRY, and FLUID DYNAMICS. The second grant is an example of a document that gets a topical diversity score of 0 because all of its words are assigned to the single topic of ALGEBRA.
 Figure 5 shows two the most diverse articles from the PubMed corpus. The diversity score for the first article is dominated by the combination of the PSYCHIATRY and FUNGI topics, which have a distance of 16.91 times the mean topic distance. The diversity score of the second docu-ment is largely driven by the fact that the BONES/JOINTS topic is relatively distant from each of the HIV/AIDS and VIRUSES topics. Low diversity PubMed documents showed similar patterns to low diversity NSF grants.

Finally, Figure 6 shows examples of one high diversity document and one low diversity document from the ACL corpus. The high diversity document achieves its score be-cause the SUMMARIZATION topic is usually associated with text, but here it co-occurs with a set of topics related to SPEECH RECOGNITION. Thus, this paper is unusual in that it applies summarization techniques to non-text data (as indicated in the title). The other paper in Figure 6 is a typical example of a low-diversity document which is com-posed of a combination of topics that are very close together.
We presented an approach for quantifying the diversity of individual documents in a corpus based on their text con-tent. Empirical results illustrated the effectiveness of the method on multiple large corpora. This text-based approach for assigning diversity scores has several potential advan-tages over previous alternatives, such as methods that de-fine diversity based on citations categorized into predefined journal subject categories. The text-based approach is more data-driven, performing the equivalent of learning journal categories by learning topics from text, and can be run on any collection of text documents, even without a prior cate-gorization scheme. In addition, it produces human-readable explanations and can be easily generalized to score the di-versity of other entities such as authors, departments, or journals (e.g., by aggregating counts across such entities).
A possible direction for future work is that of temporal document diversity, for example, using topics and topic-based distance measures that only depend on documents in the corpus with earlier time stamps. This would allow for distances and diversities that change over time and the de-tection of documents that are highly diverse relative to the time-period they were published in. An example would be early papers in bioinformatics, combining machine learning and biological concepts, which co-occur relatively frequently in the current literature but far less so 20 years ago. KB was supported by an NSF Graduate Research Fellow-ship, DN was supported by NSF awards 1158699 and 1250452, and PS was supported by a Google Faculty Research Award. PS and DN were also supported by the Intelligence Ad-vanced Research Projects Activity (IARPA) via Dept. of Interior National Business Center contract #D11PC20155. The U.S. government is authorized to reproduce and dis-tribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/NBC, or the U.S. Government. [1] R. N. Broadus. An investigation of the validity of [2] D. Davies. Citation idiosyncrasies. Nature , 228:1356, [3] J. Dillon, Y. Mao, G. Lebanon, and J. Zhang.
 [4] M. O. Finkelstein and R. M. Friedberg. The [5] J. Gibbs and W. Martin. Urbanization, technology, [6] J. Gillenwater, A. Kulesza, and B. Taskar. Discovering [7] T. L. Griffiths and M. Steyvers. Finding scientific [8] S. Lieberson. Measuring population diversity.
 [9] A. Magurran and A. Magurran. Ecological Diversity [10] A. K. McCallum. Mallet: A machine learning for [11] National Center for Biotechnology Information, U.S. [12] M. Nei. Analysis of gene diversity in subdivided [13] E. C. Pielou. An Introduction to Mathematical [14] A. L. Porter and I. Rafols. Is science becoming more [15] A. L. Porter, D. J. Roessner, and A. E. Heberger. How [16] D. Radev, P. Muthukrishnan, V. Qazvinian, and [17] I. Rafols and M. Meyer. Diversity and network [18] C. Rao. Diversity and dissimilarity coefficients: a [19] C. Ricotta and L. Szeidl. Towards a unifying approach [20] E. Simpson. Measurement of diversity. Nature , page [21] A. Solow, S. Polasky, and J. Broadus. On the [22] A. Stirling. A general framework for analysing [23] C. Wagner, J. Roessner, K. Bobb, J. Klein, K. Boyack, [24] M. J. Welch, J. Cho, and C. Olston. Search result
