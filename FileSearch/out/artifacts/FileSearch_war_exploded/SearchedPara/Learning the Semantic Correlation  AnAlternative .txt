 assume that the unlabeled data belong to the same classes or s hare the generative distri-[8, 13], and graph-based methods [3]. As indicated in [11], u nlabeled data in real-world semi-supervised learning algorithms that give up this assu mption have wider applicability resentation from unlabeled data and use it to encode the labe led examples [4, 1, 11]. at hand. This assumption might be problematic. Many functio ns can be defined over an input space and a specific task corresponds to only one of them . The feature extraction on unlabeled data is an unsupervised process and thus a  X  X lin dly X  learned representation are learned by principal component analysis on the weights o f several models, and these models are trained from some  X  X uxiliary X  tasks constructed by domain knowledge. from unlabeled text without information about the task to be enhanced. This knowledge is represented as the semantic correlation structure of the words in the text domain and is shown to be transferable among documents of different the mes. This structure is ex-tracted using a latent topic model combined with a bootstrap ping procedure. The rationale the structural information of the language, represented by the semantic correlation among to control the joint shrinkage of model parameters through i nformative regularization. task [12] or inferred from meta-features [9]. In fact, one wa y to view the present work is: 1) we automatically construct a large number of diverse b ut meaningful  X  X asks X  from unlabeled text without using external knowledge, where eac h  X  X ask X  is actually extracted applicable semi-supervised learning framework. 2.1 Latent Topics and Semantic Structure composition of these topics in terms of word distribution re veals information about the semantic structure of the language. Assume a latent topic mo del [7, 2] of the word space X , or more generally, a latent variable model characterizing the input space X : where x = [ x [ z 1 , z 2 , . . . , z k ] T p  X  k matrix, representing a generative process from a probabili stic view or a projection from a deterministic view. For a latent topic model, x corresponds to the bag-of-words in this formula including PCA, ICA, sparse coding, and non-n egative matrix factorization. dimensional column vector of A denotes the word distribution in a latent topic, and serves as an  X  X bservation X  in the p dimensional word space, indicating the semantic roles of p tors { a Let A denote the matrix formed by treating each vector a and let a semantic covariance of word i and word j is defined as: where a 2.2 Comparing Semantic Correlation and Data Correlation Suppose we observe a set of n documents in word space X , denoted by an n  X  p data matrix D counts. We refer to the correlation between words computed d irectly from D from different themes may have distinct topic distribution s and word distributions, which lead to different word correlations in data space.
 Here we show intuitively why we expect the data correlation t o have limited use across distinct tasks, while we expect the semantic correlation to be transferable. Consider the latent variable model in eq. (1), which relates A to data space X . We focus on semantic covariance and data covariance, and assume that the bag-of-words vector is divided by the x word j can be expressed as:
Thus, data covariance is directly related to the covariance among latent topics. Documents documents may not be transferable to another class of documents. On the other h and, the semantic covariance in eq. (2) is completely determined by t he structure of A . distributed and have the same variance (denoted as  X  2 ), eq. (4) can be written as: Algorithm 1 Estimation of semantic correlation structure
Input: data D = D
Output: semantic correlation matrix  X  Parameters:  X  , k , N
Initialize V  X  X  X  repeat until | V | X  kN
Compute  X  covariance. In fact, our empirical study shows that data cor relation from unlabeled text does contain useful information, but is not as informative a s semantic correlation. Consider a set of n for regression. Also assume that a large set of n from unlabeled text. Section 3.1 proposes an approach to lea rning the semantic structure 3.1 Learning the Semantic Correlation The semantic correlation among words can be estimated using eq. (3) by observing a large [5] can be combined with a chosen latent variable model, whic h provides a principled way to estimate the semantic correlation. The procedure is give n in Algorithm 1, which uses all the available data D = D algorithm repeats N iterations. In each iteration it draws an  X  percentage sample 1 from the data and extracts k latent topics from the sample by applying the model M . After N iterations, the p  X  p semantic correlation matrix  X  as necessary to obtain a reliable estimation. 3.2 Knowledge Transfer by Informative Regularization This section discusses how to use the semantic structure  X  defined on the input space X . For the prediction model, we mainly consider regularized b , we minimize a loss function L on the training examples plus a regularization term on w : regularization term  X  w T w =  X  w T I  X  1 w is well known to be equivalent to the Bayesian approach that imposes a Gaussian prior with zero mean and an i dentity correlation matrix. word space, the prior can be more informative [12]. Incorpor ating  X  prior leads to a new regularization term and the resulting mo del is: eq. (7) can be easily solved by three steps. First, transform the training examples by Second, learn the standard linear model in the transformed s pace: Finally, the optimal solution for (7) is obtained by: This equivalence is derived from w T x l eq. (8) before training on the labeled examples, which is ver y scalable. testing documents are divided by date and denoted as D represented by bag-of-words vectors. The vocabulary is bui lt to include the most frequent 200 words in each of the 20 newsgroups, while the 20 most frequent words over all 20 newsgroups are removed. This yields an input space X with p = 1443 features (words). Documents come from 20 newsgroups, so we construct 190 binary classification tasks, one for each pair of newsgroups. For each task, a few documents in the two newsgroups are selected from D documents in D to work very well. The test data for each binary task are all th e relevant documents in D i.e., documents in D always have D correlation structure  X  The documents are well distributed over the 20 newsgroups and thus there are large num-bers of training documents in D examples for each binary prediction task, we use 5% , 10% , 20% of the relevant documents in
D tr as the labeled examples D l , and the rest of the relevant and all irrelevant docu-ments in D 20% -Test. The result of each test is averaged over 10 random runs, with D l randomly selected from D in
D ts , which is invariant for a task among different tests and rand om runs. Methods for comparison are as follows. (1) Comparison based on SVM. For each classification task, we compare: SVM di-rectly trained on labeled examples D topic space extracted by latent dirichlet allocation on D SVM trained on D SV M P CA ), SVM trained on D l via informative regularization with semantic correlation  X  data correlation in the prior (denoted SV M mated from bag-of-words vectors of documents in D (2) Comparison based on L-2 Regularized Logistic Regression. Analogous to the SVM comparison with logistic regression (denoted LGR) as the ba se classifier. (3) Comparison based on ridge regression. Ridge regression (denoted RR) is used as the (4) Comparison to semi-supervised SVM. Recently a fast semi-supervised SVM using L-2 loss was proposed [13], which makes it possible to handle lar ge-scale unlabeled doc-uments. We compare: L2-SVM directly trained on D SVM trained on D larization with semantic correlation ( L 2 -SV M  X  X racle X  semi-supervised SVM, using labeled examples toge ther with unlabeled examples coming only from the two relevant newsgroups ( L 2 -S 3 V M method, Algorithm 1 uses latent dirichlet allocation with k = 30 topics per sampling, re-peats N = 100 iterations, and  X  (code available as SVMlin [13]) has a second parameter  X  is set to 1 as in [13]. Unlabeled data for L 2 -S 3 V M is downsampled to 3000 documents for each run to make training (and cross-validation) feasib le.
 Empirical results are shown in Tables 1-4. For each semi-sup ervised learning algorithm, we report two performance measures: the average classificat ion error over all 190 tasks, and the gain/loss ratio compared to the corresponding super vised learning method. The former measures the effectiveness of using the unlabeled da ta, while the latter measures tic correlation significantly outperform standard supervi sed learning, LDA based methods, PCA based methods, and is also generally more effective than IR with data correlation. The LDA based algorithms slightly improve the prediction perfo rmance when using SVM or lo-to irrelevant latent features extracted from mixed unlabel ed documents. The PCA based methods are generally worse than standard supervised learn ing, which indicates they are data outside the target task. We can also see that the L 2 -SV M oracle version of semi-supervised SVM ( L 2 -S 3 V M that information can be gained from other tasks even in exces s of what can be gained from a significant amount of unlabeled data on the task at hand. In c onclusion, the empirical to be enhanced, and the base prediction model used.
 It is interesting to directly compare the semantic correlat ion  X   X  matrices learned from the data. We make three observations: 1) The average value
Table 5: Top 10 distinct word pairs in terms of semantic correlation vs. dat a correlation palestin/lebanes cage/ama toyota/mileag mileag/mustang brave/batter have 1617834 entries with higher data correlation and 462972 entries with higher semantic between the two correlations, they all have very high semantic correlation and low data Table 5. The words are indeed quite related. In conclusion, e ntries in  X  a power-law distribution where a few pairs of words have very high correlation and the rest have low correlation, which is consistent with our intu ition about words. However, the data correlation not being transferable among document s of different themes. When the is affected by the fact that the mixture of input documents is not consistent. Acknowledgments This work was supported by the Centers of Disease Control and Prevention (award R01-PH 000028) and by the National Science Foundation (grant IIS-0 325581).

