 REGULAR PAPER Peter Haase  X  Ronny Siebes  X  Frank van Harmelen Abstract Peer-to-Peer systems have proven to be an effective way of sharing data. Modern protocols are able to efficiently route a message to a given peer. However, determining the destination peer in the first place is not always trivial. We propose a model in which peers advertise their expertise in the Peer-to-Peer network. The knowledge about the expertise of other peers forms a semantic topology. Based other peers, a peer can select appropriate peers to forward queries to, instead of broadcasting the query or sending it to a random set of peers. To calculate our semantic similarity measure, we make the simplifying assumption that the peers share the same ontology. We evaluate the model in a bibliographic scenario, where peers share bibliographic descriptions of publications among each other. In sim-ulation experiments complemented with a real-world field experiment, we show how expertise-based peer selection improves the performance of a Peer-to-Peer system with respect to precision, recall and the number of messages.
 Keywords P2P  X  Routing  X  Semantic overlays  X  Ontologies 1 Introduction Peer-to-Peer systems are distributed systems without centralized control or hierar-chical organization, in which each node runs software with equivalent functional-ity. A review of the features of recent Peer-to-Peer applications yields a long list: redundant storage, permanence, selection of nearby servers, anonymity, search, authentication, and hierarchical naming. Despite this rich set of features, scalabil-ity is a significant challenge: Peer-to-Peer networks that broadcast all queries to all peers do not scale X  X ntelligent query routing and network topologies are required to be able to route queries to a relevant subset of peers. Modern routing proto-cols like Chord [ 25], CAN [ 22] and Pastry [ 23] are based on Distributed Hash Tables for efficient query routing, but little effort has been made with respect to rich semantic representations of metadata and query functionalities beyond simple keyword searches.
 is given well-defined meaning, better enabling computers and people to work in cooperation [ 4]. In a Peer-to-Peer system, Semantic Web techniques can be used for expressing the knowledge shared by peers in a well-defined and formal way. In the simple model that we propose, peers use a shared ontology to advertise their expertise in the Peer-to-Peer network. The knowledge about the expertise of other peers forms a semantic overlay network, independent of the underlying network topology. If a peer receives a query, it can decide to forward it to peers about which it knows that their expertise is similar to the subject of the query. The advantage of this approach is that queries will not be forwarded to all or a random set of known peers, but only to those that have a good chance of answering it.
 nario, in which researchers share bibliographic metadata about publications. We present results of both simulation experiments and a real-world field experiment.
  X  the proposed model of expertise-based peer selection considerably improves  X  ontology-based matching with a similarity measure improves the system com- X  the performance of the system can be improved further, if the semantic overlay  X  a  X  X erfect X  semantic overlay network imposed on the network using global plicability and performance of the model for real-world systems.
 formal model for expertise-based peer selection (Sect. 3), instantiate this model for the bibliographic scenario (Sect. 4), define evaluation criteria (Sect. 5), present results of the simulation experiments (Sect. 6) and the field experiment (Sect. 7), and conclude with some directions for future work (Sect. 8). 2 Background and related work Peer-to-Peer systems are typically characterized by the absence of a single central instance of control. This has consequences for the network organization and the coordination to route requests to the experts able to respond to the request. Peer selection plays a role in all Peer-to-Peer systems that are dealing with document discovery. By definition, any such system must have a strategy for peer selection (even if it is only a trivial network strategy), and many systems try to improve on this in order to avoid network congestion.
 domly, and broadcasting mechanisms are used to distribute queries. In structured networks networks, a distributed index is built to route search requests. This struc-ture can involve various degrees of central coordination or global knowledge, e.g. relying on super-peers. Further, we can distinguish whether the indexing struc-ture relies on exact (syntactic) matches of keys to route requests, or whether they consider the semantics of the request.
 make use of approaches that combine developments from different research techniques: 2.1 Broadcasting Although a very simple technique, broadcasting has already proven its usefulness in small networks and in larger Peer-to-Peer file-sharing systems [ 14 ]. The idea is that peers keep forwarding a query to their neighbors until a sufficient number of answers is found or till maximum number of forwards (hops) are reached. This approach is not very scalable, because a query can result in a large number of messages which consumes an unacceptable usage of network capacity. Also, it is possible that even if the data is somewhere in the network it will not be found due to the maximum number of hops. The big advantage of broadcasting approaches is that they have very low maintenance costs and dependency, meaning that almost no messages are needed to keep the network alive and that the network is very robust to frequent peer drops and joins (network dynamics). In case where broad-casting really is needed, Hypercup [ 24] guarantees that only O ( N  X  1 ) messages and O ( log ( N )) hops are needed to reach all peers, where N is the number of peers in the network. Moreover, they show how their scheme can be made even more ef-ficient by using a global semantic network to determine the organization of peers in the graph topology. Namely, when peers describe their content in terms of this shared data-structure, peers are able to cluster themselves with similar peers. This approach based on a structured hypercube overlay has more maintenance over-head and is therefore also more sensitive to network dynamics than traditional broadcasting approaches. 2.2 Central registries An easy but not very robust approach is to have a single register where systems can advertise their expertise descriptions or to have the registry itself search the network for expertise descriptions. A well-known example from the Peer-to-Peer community, but only partially Peer-to-Peer, is Napster. 1 This system has one large repository which combines filenames with peers that offer those files for down-loading. Such a repository can be seen as yellow pages, where each member in the network can look up the person or system that fulfills its needs. In small organi-zations, such an approach could work very well because the network is small and stable, so that the registry does not have to do much query processing and updates. In larger networks the approach is not very robust and has the same disadvantages as completely centralized approaches: undisclosed content, scalability problems, lack of privacy and censor possibilities. 2.3 Brokering The Multi-Agent community suggested the concept of  X  X roker agents X  like in In-foSleuth [ 13], which semantically match information needs (specified in terms of some shared data-structure, e.g. an ontology) with currently available resources which are found by the broker itself or registered by the providing agents. In In-foSleuth, agents advertise their services to the broker via the KQML [ 10]lan-guage. Broker agents respond to an agent X  X  request for service with information about the other agents that have previously advertised relevant services. The lit-finding web-services which are semantically described [ 19]. One thing where the literature is not clear about is on how scalable and robust this approach is. In a network where millions of agents offer their services, one broker agent probably will not be enough and will have the same problems as with a central registry. 2.4 Super-peers/nodes mind, comes from the Peer-to-Peer research community. The technique, which works well for file sharing, makes use of the different capacities of the nodes in a Peer-to-Peer network: Peers that have more processing power, memory or net-work bandwidth than other peers are assigned additional tasks in the network. For example, KaZaa [ 16] lets peers voluntary act as super-peers that maintain large (comparable to yellow pages). Relying on super-peers, this approach introduces a form of centralization in the system. Although better than broadcasting in a net-work without super-nodes, this remains essentially broadcasting and therefore can be improved by techniques that do more efficient routing described in the next paragraphs.
 super-peer-based topologies for these networks, in which peers are organized in hypercubes. This topology guarantees that each node is queried exactly once for each query. L  X  oser et al. [ 18] shows how this schema-based approach can be used to create Semantic Overlay Clusters in a scientific Peer-to-Peer network with a small set of metadata attributes that describe the documents in the network. In contrast, the approach in our system is completely decentralized in the sense that it does not rely on super-peers. 2.5 Distributed hash tables and distributed search trees Another technique that comes from the Peer-to-Peer research community makes use of Distributed Hash Tables (DHT). DHTs are based on the idea to route con-tent (or a pointer to the content) to the peer whose identifier lies closest to the unique identifier of the content. This technique assumes that all peers have the which could be anything like documents, music, URLs or words. The character-istic of this technique is that it allows to route content and queries in O ( log ( n )) systems that do routing based on DHTs, such as Chord [ 25] and Pastry [ 23], are robust with respect to rapid join and leaves of peers. A disadvantage of most DHT approaches is that they have high maintenance costs, due to the frequent changes in the overlay network as a result of peers continuously joining and leaving. P-Grid [ 1] is a Peer-to-Peer search system based on a virtual distributed search tree, similarly structured as standard distributed hash tables, but with an unstructured way of building the DHT-overlay. Namely, P-Grid uses randomized algorithms for constructing the access structure, updating the data and performing search. In this way, probabilistic estimates can be given for the success of search requests, and search is more robust than the previously described DHT approaches against fail-ures of nodes. A disadvantage of all DHT approaches is that objects that are not hashed cannot be found, which is a problem for full-text searching. To be specific, in a document sharing case, one could roughly do two things: (1) The file itself is hashed to a unique key. The disadvantage is that the user has to know this key too, which is highly unrealistic. (2) The title of the document is hashed. This is still a problem because one type error would result in a complete different hash key. (3) All the words in the document are hashed and the document or the location of the document is stored at the peers on which the identifiers are closest to the hash keys of the words. Although now someone is able to find the documents that contain the keywords, the procedure of distributing the hash keys is not efficient because all these keys have to be distributed to the right peers in the network. An-other disadvantage of a pure DHT-based approach is that load-balancing is not an emergent property of the topology. Due to the fact that content and queries fol-low a power law distribution, some peers (responsible for popular keys) are much more loaded than other peers that accidently are responsible for less popular ones. Therefore, active load-balancing strategies have to be developed on top of DHT, which is not needed for broadcast-based and expertise-based (described in next paragraph) alike approaches. Also, a pure DHT-based approach is less robust than broadcast-based and expertise-based approaches, because normally only one peer is responsible for one key, and if that peer does not respond to queries (for exam-ple, behind a fire-wall or due to overload), no content can be found that is hashed to that key. The work of Byers et al. [ 6] confirms the load-balancing and bottleneck problem and describes an alternative DHT approach to solve it by introducing re-dundancy of content pointers in the network, which however generates significant additional maintenance costs. 2.6 Semantic overlay networks Peers that keep pointers to other peers which have similar content to themselves form a Semantic Overlay Network (SON). Gridvine [ 2] provides semantic overlay network on top of PGrid: While PGrid as a structured Peer-to-Peer network for efficient routing of messages provides the  X  X hysical X  layer, Gridvine introduces a semantic overlay for managing and mapping data and metadata schemas as the by smart forwarding queries based on the semantic overlay, but by applying the underlying DHT approach for mapping terms to peers.
 at systems where the goal is an efficient search mechanism based on routing queries to peers that are semantically closest to the content of the query. topic vector where each element in the vector contains the relevance for that given peer for the respective topic. pSearch [ 26], is such an example where documents in the network are organized around their vector representations (based on mod-ern document ranking algorithms) such that the search space for a given query is organized around related documents, achieving both efficiency and accuracy. In pSearch, for each element in the topic vector, each peer has a responsibility vectors that fall in that range are routed to that peer, meaning that, following the [ 0 . 13 , 0 . 19 ] not. Besides, the responsibility for a vector range, a peer also knows the list of neighbors which are responsible to vector ranges close to itself. The characteristic of pSearch is that the way that peers know about close neighbors is very efficient. A disadvantage of pSearch is that all documents have to be mapped into the same (low dimensional) semantic search space and that the dimensional-ity on the overlay is strongly dependent of the dimensionality of the vector, with the result that each peer has to know many neighbors when the vectors have high a dimension.
 similar content are going to know each other. The assumption is that queries posted by (the users of) peers are semantically closely related to the content of the peer itself. This results in a high probability that the neighbors of the peer (the peers in the cluster of that peer) have answers to the query. The problem of this approach in the domain of full-text searches, is what information a peer has to tell to another peer so that they are able to determine if they are related or not. When there is no shared data-structure (like a fixed set of terms) in which they can describe their content, the whole content has to be shared. This results in the fact that much data has to be shared between peers for determining closeness.
 Freenet [ 7]. In short, when a node forwards a request for a particular key to another node in the network, and that node is successful in retrieving the data, the address of an upstream node (possibly the one where the data originated) is included in the reply. The requester makes a note of the requested key, and the source node passed back with that reply. It is assumed that the upstream node is a good place to route future requests for keys closest to the previously requested key. about the reachable content from its neighbors. For example, the work of [ 8]de-scribes a method where peers summarize their knowledge in a set of topics and advertise this with the number of documents that they can reach to their direct neighbors. With  X  X eaching X  the authors mean that the peer itself has documents on that topic, or knows other peers that have such documents. The problem with this approach is that either these index tables are very large (resulting in expensive maintenance because these indexes are sent to neighbors when updates occur) or are not rich enough to have an overlap of tables between peers, resulting in dead-ends a forwarding process.
 here lets peers describe their content in a shared set of terms. Mostly, these terms are organized in a topic network or hierarchy making it able to determine the se-mantic similarity between terms. Each peer is characterized by a set of topics that describe its expertise. A peer knows about other peer X  X  expertise topics by analyz-ing advertisement messages [ 12] or answers [ 27]. In this way, peers form clusters of semantic related expertise descriptions. Given a query, a shared distance metric allows to forward queries (described by a shared set of terms) to neighbors whose expertise description is semantically closely related to the query. The advantages of this approach are threefold:  X  Peer autonomy Each peer can, in principle, have its own distance measure,  X  Automatic load-balancing When some content is provided by many peers also  X  Robustness/fault tolerance When peers leave the network or do not respond found. For example, imagine that a peer has some documents containing the phrase  X  X atabase languages X , but the shared data-structure only contains the term  X  X atabases X , then two things can be done (1) extend the shared data-structure with the word  X  X atabase languages X  so that peers are able to query and describe their expertise with that term or (2) the functions that extracts the expertise descrip-tion and abstract the queries should be intelligent enough to see that  X  X atabases X  is a good replacement for  X  X atabase languages X . Note that in this case the origi-nal query still contains  X  X atabase languages X , but the routing mechanism uses the shared term  X  X atabases X  to route it to the peer that registered itself on that term. Both solutions have their own problems, the first one will lead eventually to very large data-structures, the second one depends very heavily on the quality of the extraction and abstraction algorithms. 3 A model for expertise-based peer selection In the model that we propose, peers advertise their expertise in the network. The peer selection is based on matching the subject of a query and the expertise ac-cording to their semantic similarity. Figure 1 below shows the idea of the model in one picture. Our model is deliberately simple, in order to make as few assumptions as possible about the architecture of both the network and the individual peers, so as to make our work as widely applicable as possible.
 of peers and how peers promote their expertise as advertisement messages in the network. Second, we describe how the received advertisements allow a peer to select other peers for a given query based on a semantic matching of query subjects against expertise descriptions. The third part describes how a semantic overlay network can be formed by advertising expertise. 3.1 Semantic description of expertise 3.1.1 Peers The Peer-to-Peer network consists of a set of peers P . Every peer p  X  P has a knowledge base that contains the knowledge that it wants to share. 3.1.2 Common ontology The peers share an ontology O , which provides a common conceptualization of their domain by defining a set of terms and the relations between them. The on-tology is used for describing the expertise of peers and the subject of queries. Al-though we assume that all peers share the same ontology, it can be expected that a partial overlap between different ontologies would give similar results. Distribut-ing the ontology to all peers can be done when the user downloads the application. 3.1.3 Expertise An expertise description e  X  E is a abstract, semantic description of the knowl-edge base of a peer based on a set of terms from the common ontology O .This expertise can either be extracted from the knowledge base automatically or speci-fied in some other manner. 3.1.4 Advertisements Advertisements A  X  P  X  E are used to promote descriptions of the expertise of peers in the network. An advertisement a  X  A associates a peer p with an expertise description e . 3.1.5 Advertisement distribution algorithm Peers decide autonomously, without central control, whom to promote advertise-ments to and which advertisements to accept. This decision can be based on the semantic similarity between expertise descriptions. 3.2 Matching and peer selection We now turn to the discussion how peers are selected based on a given query using a similarity function to rank peers. 3.2.1 Queries Queries q  X  Q are posed by a user and are evaluated against the knowledge bases of the peers. First, a peer evaluates the query against its local knowledge base and then decides which peers the query should be forwarded to. Query results are returned to the peer that originally initiated the query. 3.2.2 Subjects A subject s  X  S is an abstraction of a given query q expressed in a set of terms from the common ontology O . The subject can be seen as a complement to an expertise description, as it specifies the required expertise to answer the query. 3.2.3 Similarity function The similarity function SF S : S  X  E  X  X  0 , 1 ] yields the semantic similarity between a subject s  X  S and an expertise description e  X  E . An increasing value indicates increasing similarity. If the value is 0, s and e are not similar at all, if the value is 1, they match exactly. SF S is used for determining to which peers a query should be forwarded. Analogously, a same kind of similarity function SF E : E  X  E  X  X  0 , 1 ] can be defined to determine the similarity between the expertise of two peers. 3.2.4 Peer selection algorithm The peer selection algorithm returns a ranked set of peers. The rank value is equal to the similarity value provided by the similarity function.
 all peers whose rank value is above a certain threshold, etc. 3.3 Semantic overlay network The knowledge of the peers about the expertise of other peers is the basis for a se-mantic topology. It is important to state that this semantic topology is independent of the underlying network topology. At this point, we make no assumptions about the topology of the network.

Knows  X  P  X  P ,where Knows ( p 1 , p 2 ) means that p 1 knows about the expertise its advertisements to and from which peers a peer accepts advertisements. The semantic overlay network in combination with the expertise-based peer selection is the basis for intelligent query routing. The intuition of the overlay network is to establish acquaintances between peers with similar expertise in order to be able to route queries along a short path of increasing similarity between the subject of the query and the expertise of the peers. Different strategies for establishing such acquaintances will be presented and evaluated in the following sections. 3.4 Consequences of the model An important value of the model described above is that it dictates which design decisions must be made when equipping a Peer-to-Peer network with expertise-based peer selection. These decisions are as follows:  X  We must define the ontology as a set of terms and a set of relations between  X  We must define two abstraction functions : one to abstract the contents of peers  X  We must define two advertisement policies : to which peers should advertise- X  We must define two similarity functions : one to compare subjects with exper- X  We m u s t d e fi n e a peer selection algorithm to decide to which peers queries models with semantic query routing. 4 The bibliographic scenario In this section, we instantiate the general model for expertise-based peer selection from previous section. We use a real-life scenario for knowledge sharing in a Peer-to-Peer environment.
 tions or their correct bibliographic metadata. Currently, people do these searches with search engines like Google and CiteSeer, via university libraries or by simply asking other people that are likely to know how to obtain the desired information. bibliographic metadata via a Peer-to-Peer system. The data may have been ob-tained from BibTeX files or from a bibliography server such as the DBLP database. 2 A similar scenario is described in [ 3], where data providers, i.e. re-search institutes, form a Peer-to-Peer network which supports distributed search over all the connected metadata repositories.
 in the previous section. 5 Peers A researcher is represented by a peer p  X  P . Each peer has an RDF [ 15] knowl-edge base, which consists of a set of bibliographic metadata items that are clas-sified according to the ACM topic hierarchy. 3 The following example shows a fragment of a sample bibliographic item based on the Semantic Web Research Community Ontology (SWRC) 4 : 5.1 Common ontology The ontology O that is shared by all the peers is the ACM topic hierarchy. The main and relations ( T  X  T ) between them: SubTopic and seeAlso . It is impor-tant to state that this topic hierarchy is not an  X  X SA X  hierarchy, but a generaliza-tion/specialization organized tree structure. If it were an ISA hierarchy, experts on a topic would also be experts on all sub-topics. This is not the case in our sit-uation, because experts could have expertise on a very specific topic, but do not have much generic knowledge on a super-topic standing high in the hierarchy. For example, imagine an expert on Robot Sensoring by using Bayesian Classifiers , which is a sub-topic of Artificial Intelligence . This expert does not need to have any expertise on AI in general at all. This means that our topic hierarchy cannot be used for inferring expertise by inheritance over the sub-topic relation. Instead, we use a similarity measure to calculate the semantic distance between topics. 5.2 Expertise The ACM topic hierarchy is the basis for our expertise model. Expertise E is defined as E  X  2 T , where each e  X  E denotes a set of ACM topics, for which a peer provides classified instances. 5.3 Advertisements Advertisements associate peers with their expertise: A  X  P  X  E . A single ad-expert. 5.4 Advertisement distribution algorithm To keep the set of simulation parameters within acceptable boundaries, we choose the simple solution of letting a peer to send its advertisement only to its direct neighbors. We therefore do not use any advertisement forwarding policy. We do however simulate different advertisement acceptance policies, which are described in one of the paragraphs from the next section on the simulation settings. The average maintenance costs of a semantic overlay can be derived by multiplying network. 5.5 Queries We use the RDF query language SeRQL [ 5] to express queries against the RDF knowledge base of a peer. The following sample query asks for the titles of publi-cations whose ACM topic is Information Systems / Database Management : 5.6 Subjects Analogously to the expertise, a subject s  X  S is an abstraction of a query q .In our scenario, S  X  2 T each s is a set of ACM topics, thus s  X  T . For example, the extracted subject of the query above would be { Information Systems/Database Management } . 5.7 Similarity function In this scenario, we use one similarity function SF ( SF = SF E = SF S ), which is based on the idea that topics which are close according to their positions in the topic hierarchy are more similar than topics that have a larger distance. For example, an expert on ACM topic Information Systems/Information Storage and Retrieval has a higher chance of giving a correct answer on a query about Infor-mation Systems/Database Management than an expert on a less similar topic like Hardware/Memory Structures . To be able to define the similarity of a peer X  X  ex-pertise and a query subject, which are both represented as a set of topics, we first define the similarity for individual topics. Reference [ 17] have compared different similarity measures between words in WordNet, based on the hyponym relations between them. Given that the hyponym structure is a hierarchically structured gen-erality/specificity network, we assume that this metric also applicable to our ACM topic hierarchy. Their best performing similarity measure that gave the best results on their data set is as follows: Here l is the length of the shortest path between topic t 1 and t 2 in the graph spanned by the SubTopic relation. h is the level in the tree of the lowest common subsumer from t 1 and t 2 ;  X   X  0and  X   X  0 are parameters scaling the contribution of shortest path length l and depth h , respectively. Based on benchmark data from [17 ], the optimal values are:  X  = 0 . 2,  X  = 0 . 6. Using the shortest path between two topics is a measure for similarity because Rada et al. [ 21] have proven that the minimum number of edges separating topics t 1 and t 2 is a metric for measuring the conceptual distance of t 1 and t 2 . The intuition behind using the depth of the direct common subsumer in the calculation is that topics at upper layers of hierarchical semantic nets are more general and are semantically less similar than topics at lower levels. Our sub-topic hierarchy is a tree structure, but the metric from [ 17 ] is also able to deal with DAG (Directed Acyclic Graph) structures in general, by selecting the shortest path between two topics of interest.
 vidual topics, we define SF as: This function iterates over all topics t i of the subject s and averages their similar-ities with the most similar topic of the expertise e . 5.8 Peer selection algorithm The peer selection algorithm ranks the known peers according to the similarity function described above. Therefore, peers that have an expertise more similar to that of the subject of the query will have a higher rank. From the set of ranked peers, we now only consider a selection algorithm that selects the best n peers. To prevent cycles in the forwarding loop, each query message is identified by a unique identifier and each peer only responds to each unique query only once. The costs of the algorithm in terms of the number of forwarded query messages is an experimental variable, for which the results are shown in the next sections on the simulation and field experiment.
 model from the previous section: a common ontology, expertise and query-subject descriptions, advertisement-contents, and similarity functions. Still missing are the advertisement policy, used for propagating expertise, and the abstraction func-tions, used for describing content and queries. These are experimental variables because we test different policies, and therefor will be discussed in Sect. 6, where we describe the details of our experiments. 6 Evaluation criteria In this section, we define a number of criteria for a Peer-to-Peer system, which will be the basis for the evaluation of our proposed model for peer selection. These criteria are mainly based on those described in [ 9]. We distinguish between input parameters affect the performance of the system, and output parameters that are affected and serve as measures for the performance of the system. 6.1 Input parameters The following input parameters are important criteria that influence the perfor-mance of a Peer-to-Peer system: 6.1.1 Number of peers The size of the Peer-to-Peer network is represented by this number. Typically, the scalability of the system is measured in terms of number of peers. The number of peers varies depending on the distribution of documents. 6.1.2 Number of documents number of shared resource items, e.g. documents. 6.1.3 Document distribution The document distribution in Peer-to-Peer networks is rarely completely random, but often has certain properties. With this input parameter, we want to evaluate how the proposed model behaves with different document distributions. 6.1.4 Network topology The performance of a Peer-to-Peer system is strongly influenced by the network topology and its characteristics. Possible topologies could for example be super-peer based, star or ring-shaped, or simply a random graph. 6.1.5 Advertisement policy The advertisements are responsible for building the semantic overlay network. There are various variables involved, e.g. whom to send the advertisements to and which received advertisements to accept based on the semantic similarity between the own expertise and that of the advertisement. 6.1.6 Peer selection algorithm The peer selection algorithm determines which peers a query should be forwarded to. This could be a naive algorithm, which simply broadcasts a query, or a more advanced one, as the proposed expertise-based peer selection. 6.1.7 Maximum number of hops The maximum number of hops specifies how many times a query is allowed to be forwarded. It determines how much the network will be flooded by a single query. 6.2 Output parameters To evaluate a Peer-to-Peer system, we use precision and recall measures known from classical Information Retrieval. Here, we distinguish measures on the docu-ment level (query answering) and the peer level (peer selection). Note that for our simulation of the bibliographic scenario we disregard the actual documents (i.e. papers) and only distribute their metadata (i.e. their bibliographic descriptions). These measures are defined as follows: indicates how many of the returned documents are relevant, with Doc relevant be-ing the set of relevant documents in the network, meaning that the terms in the query match their metadata description, and Docs returned being the set of returned documents. We determine the set of relevant documents Docs relevant by evaluat-ing the query against a centralized database which contains the complete data set. In our model, we work with exact queries, therefore only relevant documents are returned. The precision will hence always be one,meaning that the document pre-cision is not a useful measure to use: The recall on the document level states how many of the relevant documents are returned.
 For a given query, how many of the peers that were selected had relevant infor-Peers reached is the set of peers that were reached.
 indicates for a given query, how many of the peers that had relevant information were reached. 6.2.1 Further parameters Another important output parameters is: flooded by one query. The number of messages does not only affect the network traffic, but also CPU consumption, such as for the processing of the queries in the case of query messages.
 evaluation criteria. Examples are the size of messages between peers, the response times on queries to the network, CPU load of individual peers, etc. However, we do not report on these as they are not relevant to our evaluation hypotheses and therefore also not captured by our simulation software. 7 Simulation experiments In this section, we describe the simulation of the scenario presented in Sect. 4.The evaluations are based on the criteria defined in Sect. 6. With the experiments we validate the following hypotheses: Hypothisis 1 (Expertise-based selection) The proposed approach of expertise-based peer selection yields better results than a naive approach based on random selection. The higher precision of the expertise-based selection results in a higher recall of peers and documents, while reducing the number of messages per query. Hypothisis 2 (Ontology-based matching) Using a shared ontology with a met-ric for semantic similarity improves the recall rate of the system compared with an approach that relies on exact matches, such as a simple keyword based approach. Hypothisis 3 (Semantic overlay network) The performance of the system can be improved further, if the semantic topology is built according to the semantic similarity of the expertise of the peers. This can be realized, for example, by ac-cepting advertisements that are semantically similar to the own expertise. Hypothisis 4 (The  X  X erfect X  overlay network) Perfect results in terms of preci-sion and recall can be achieved, if the semantic overlay network coincides with a distribution of the documents according to the expertise model. 7.1 Setup of the simulation experiments In the following, we describe the setup of the simulation experiments performed: the data sets used, the distribution of the data, the simulation environment, and the individual experimental settings. 7.2 Data set To obtain a critical mass of bibliographic data, we used the DBLP data set, which consists of metadata for 380,440 publications in the computer science domain. topic hierarchy using a simple classification scheme based on lexical analysis: A publication is said to be about a topic, if the label of the topic occurs in the title of the publication. For example, a publication with the title  X  X he Capabilities of Relational Database Management Systems. X  is classified into the topic Database Management . Topics with labels that are not unique (e.g. General is a sub-topic of both General Literature and Hardware ) have been excluded from the classifica-tion, because typically these labels are too general and would result in publications classified into multiple, distant topics in the hierarchy. Obviously, this method of classification is not as precise as a sophisticated or manual classification. How-ever, a high precision of the classification is not required for the purpose of our simulations. As a result of the classification, about one third of the DBLP publi-cations (126,247 out of 380,440) have been classified, against 553 out of the 1287 ACM topics. The classified DBLP subset has been used for our simulations. 7.3 Document distribution We have simulated and evaluated the scenario with two different distributions, which we describe in the following. Note that for the simulation of the scenario we disregard the actual documents and only distribute the bibliographic metadata of the publications. 7.4 Topic distribution In the first distribution, the bibliographic metadata are distributed according to their topic classification. There is one dedicated peer for each of the 1287 ACM topics. The distribution is directly correlated with the expertise model, each peer is an expert on exactly one ACM topic and contains all the corresponding pub-lications. This also implies that there are peers that do not contain publications, because not all topics have classified instances. 7.5 Proceedings distribution In the second distribution, the bibliographic metadata are distributed according to conference proceedings and journals in which the according publications were published. For each of the conference proceedings and journals covered in DBLP, there is a dedicated peer that contains all the associated publication descriptions (in the case of the 328 journals) or inproceedings (in the case of the 2006 con-ference proceedings). Publications that are published neither in a journal nor in conference proceedings are contained by one separate peer. The total number of peers therefore is 2335( = 328 + 2006 + 1). With this distribution, one peer can be an expert on multiple topics, as a journal or conference typically covers multiple ACM topics. Note that there is still a correlation between the distribution and the expertise, as a conference or journal typically covers a coherent set of topics. we see them as given in our simulations. One way to distribute content in this way is via DHT where the keys are topics or conference identifiers, so that each of them is mapped to a unique peer in the network. We already mentioned some problems with DHT approaches such as no load-balancing and single points of failures. Our experiments can be seen as a way to investigate how semantic methods can be used to mitigate some of these problems. 7.6 Simulation environment To simulate the scenario we have developed and used a controlled, configurable Peer-to-Peer simulation environment. A single simulation experiment consists of the following sequence of operations: 1. Setup network topology: In the first step, we create the peers with their knowl-2. Advertising knowledge: In the second step, the semantic overlay network is 3. Query Processing: The peers randomly initiate queries from a set of randomly needed to show how our system behaves in a dynamic environment. This clearly is future work. However, we can already say that the only effect of unreachable peers is that advertisement messages and query messages will not arrive. The con-sequence would be that other peers need to be selected, resulting in an increase of the number of messages and/or a sparser semantic overlay network, both gradually decreasing the performance of our system. We expect that the costs will remain to be low in a dynamic network, because the advertisement process does not con-sume many messages. This means that restoring the semantic overlay would not have a dramatic effect on the network load. 7.7 Experimental settings In our experiments, we have systematically simulated various settings with differ-ent values of input variables. In the following, we describe an interesting selected subset of the settings to prove the validity of our hypotheses. 7.8 Setting 1 In the first setting, we use a naive peer selection algorithm, which selects n random peers from the set of peers that are known from advertisements received, but disre-garding the content of the advertisement. This means that peers only have pointers to peers without knowing their expertise, so peer selection would be identical to random selection like in the Gnutella approach. In the experiments, we keep n = 2 fixed in every setting, as a rather arbitrary choice. Different values for n yield sim-ilar results, but degenerate to a sequence in the case of n = 1 and to a broadcast in the case where n is the number of all known peers. 7.9 Setting 2 In the second setting, we apply the expertise-based selection algorithm. The best n ( n = 2) peers are selected for query forwarding. Here, the peer selection algorithm only considers exact matches of topics, which means that a peer only is selected when its expertise description contains at least one of the topics from the query abstraction. In this setting, all advertisements are accepted. 7.10 Setting 3 In the third setting, we modify the peer selection algorithm to use the ontology-based similarity measure, instead of only exact matches. The peer selection only selects peers whose expertise is equally or more similar to the topics from the query abstraction than the expertise of the forwarding peer itself. This method guarantees that queries are forwarded to equal or better experts than the forward-ing peer. The danger of this approach is that some of the forwarding branches get stuck in a local maximum because it does only know, if any, peers which are worse matches than itself. In this setting, all advertisements are accepted. 7.11 Setting 4 In the fourth setting, we modify the peer to only accept advertisements that are semantically similar to its own expertise. The threshold for accepting advertise-ments was set to accept on average half of the incoming advertisements. The peer selection algorithm is identical to the previous setting, namely select peers based on the ontology-based similarity measure. 7.12 Setting 5 In this setting, we assume global knowledge to impose a perfect overlay network on the peer network. In this perfect overlay network, the knows relation coincides with the ACM topic hierarchy: Every peer knows exactly those peers that are ex-perts on the neighboring topics of its own expertise. This setting is only applicable for the distribution of the publications according to their topics, as it assumes ex-actly one expert per topic. A way to achieve this overlay network is via DHT, where for each key (i.e. topic) only one peer is responsible. This means that in this setting we build the semantic overlay on top of the assumed DHT overlay. Clearly, this setting suffers from some limitations as DHT like load-balancing problems in case of popular content, or unreachable content classified on a topic when the peer on the topic does not respond. In this setting, an advertisement is accepted only when the contained expertise description is similar to the receivers own expertise description, thus like in setting 4.
 scribed settings. 7.13 Results Figures 2 through 5 show the results for the different settings and distributions. The simulations have been run with a varying number of allowed hops. In the results, we show the performance for a maximum of up to eight hops. Zero hops means that the query is processed locally and not forwarded. Please note that the diagrams for the number of messages per query and recall (i.e. Figs. 3 X 5)present cumulative values, i.e. they include the sum of the results for up to n hops. The diagram for the precision (Fig. 2) of the peer selection displays the precision for a particular number of hops. settings described above with respect to our hypotheses H1 through H4. 7.13.1 R1: Expertise-based selection The results of Fig. 2, Setting 1, show that the naive approach of random peer se-lection gives a constant low precision of 0.03% for the topic distribution and 1.3% for the proceedings distribution. This results in a fairly low recall of peers and doc-uments despite a high number of messages, as shown in Figs. 3 X 5, respectively. With the expertise-based selection, either exact or similarity based matching, the precision can be improved considerably by about one order of magnitude. For ex-ample, with the expertise-based selection in Setting 3, the precision of the peer selection (Fig. 2) can be improved from 0.03 to 0.15% for the topic distribution and from 1.3 to 15% for the proceedings distribution. With the precision, also the recall of peers and documents rises (Figs. 3 and 5). At the same time, the number of messages per query can be reduced. The number of messages sent is influenced by two effects. The first effect is message redundancy: The more precise the peer selection, the higher is the chance of a peer receiving a query multiple times on different routes. This redundancy is detected by the receiving peer, which will for-ward the query only once, thus resulting in a decreasing number of queries sent across the network. The other effect is caused by the selectivity of the peer se-lection: It only forwards the query to peers whose expertise is semantically more or equally similar to the query than that of the own expertise. With an increasing number of hops, as the semantic similarity of the expertise of the peer and the query increases, the chance of knowing a qualifying peer decreases, which results in a decrease of messages. 7.13.2 R2: Ontology-based matching The result of Fig. 2, Setting 2, shows that the exact match approach results in a maximum precision already after one hop, which is obvious because it only selects peers that match exactly with the query X  X  subject. However, Fig. 3 shows that the recall in this case is very low in the case of the topic distribution. This can be explained as follows: For every query subject, there is only one peer that exactly matches in the entire network. In a sparse overlay network, the chance of knowing that relevant peer is very low. Thus, the query cannot spread effectively across the network, resulting in a document recall of only 1%. In contrary, Setting 3 shows that when semantically similar peers are selected, it is possible to improve the recall of peers and documents, to 62% after eight hops. Also in the case of the proceedings distribution, where multiple exact matches are possible, we see an improvement from 49% in the case of exact matches (Setting 2), to 54% in the case of ontology based matches (Setting 3). Naturally, this approach requires to send more messages per query and also results in a lower precision. 7.13.3 R3: Semantic overlay network In Setting 4, the peers only accept semantically similar advertisements. This has proven to be a simple, but effective way for creating a semantic overlay network that correlates with the expertise of the peers. This allows to forward queries along the gradient of increasing semantic similarity. When we compare this approach with that of Setting 3, the precision of the peer selection can be improved from 0.15 to 0.4% for the topic distribution and from 14 to 20% for the proceedings distribution. The recall of documents can thus be improved from 62 to 83% for the topic distribution and from 54 to 72% for the proceedings distribution. similarity based matching decreases slightly after seven hops (Fig. 2). The reason is that after seven hops the majority of the relevant peers has already been reached. Thus, the chance of finding relevant peers decreases, resulting in a lower precision of the peer selection. 7.13.4 R4: The  X  X erfect X  overlay network The results for Setting 5 show how one could obtain the maximum recall and precision, if it were possible to impose an ideal semantic overlay network. All relevant peers and thus all bibliographic descriptions can be found in a determin-istic manner, as the query is simply routed along the route which corresponds to the shortest path in the ACM topic hierarchy. At each hop, the query is forwarded to exactly one peer until the relevant peer is reached. The number of messages required per query is therefore the length of the shortest path from the topic of expertise of the originating peer to that of the topic of the query subject. The pre-cision of the peer selection increases to the maximum when arriving at the eighth hop, which is the maximum possible length of a shortest path in the ACM topic hi-erarchy. Accordingly, the maximum number of messages (Fig. 4) required is also eight. 8 The Bibster field experiment In addition to the simulation experiments, we have evaluated the methods of expertise-based peer selection in a realistic field-experiment, as part of the Bib-ster system. The Bibster system 5 [11] was developed as part of the EU-funded SWAP project, with contributions by many of the project team. We have imple-mented the methods for expertise-based peer selection in the Bibster system, and performed a public field experiment to evaluate the model in a real-world setting. We are aware that the data obtained in the field experiment does not allow to make statements about statistical significant. It therefore should be seen as an addition to our simulation results and a case study for a real-life deployment. graphic data among researchers. Bibster exploits ontologies in data storage, query formulation, query routing and answer presentation: When bibliographic entries are made available for use in Bibster, they are structured via the SWRC ontology and classified according to the ACM topic hierarchy, both earlier mentioned in this paper. This ontological structure is then exploited to help users formulate their queries. Subsequently, the ontologies are used to improve query routing across the Peer-to-Peer network. Finally, the ontologies are used to post-process the returned answers in order to do duplicate detection. Bibster is a fully implemented open source solution built on top of the JXTA platform. 8.1 Setup of the field experiment The Bibster system was made publicly available and advertised to researchers in the Computer Science domain. The evaluation was based on the analysis of system activity that was automatically logged to log files on the individual Bibster clients. In Bibster, two different peer selection algorithms ran at the same time, namely our expertise-based peer selection and a random query forwarding algorithm. We have analyzed the results for a period of three months (June X  X ugust 2004).
 mainly from Europe and North America participated in the field experiment and used the Bibster system.
 average of 248 entries per peer. However, the distribution had a high variance (cf. Fig. 6): shared at least 1000 entries each, accounting for 79% of the total shared content. With respect to the variance, the distribution is similar to that of the topic distri-bution from the simulation experiments, where many peers provided no entries (those whose topic had no classified instances) and few peers provided many en-tries (those with popular topics such as  X  X atabase Management X ). The users per-formed a total of 3319 queries. With respect to the scope of the queries, Fig. 7 shows that the users mainly performed queries on their local peers and automatic search across the entire network. Only in few cases, the queries were directed to a manually selected peer. This confirms the need for efficient peer selection algo-rithms. For the 3319 queries, the users received a total of 36,960 result entries, i.e. around 11 result entries per query. Result entries were actively used 801 times, i.e. copied or stored locally. 8.2 Results With respect to query routing and the use of the expertise-based peer selection, we were able to reduce the number of query messages by more than 50%, while retaining the same recall of documents compared with a naive broadcasting ap-proach. Figure 8 shows the precision of the peer selection (the percentage of expertise-based peer selection results in an almost constant high precision of 28%, the naive algorithm results in a lower precision decreasing from 22% after one hop to 14% after four hops. 7 can be seen that with an increasing number of hops, the number of messages sent with the expertise-based peer selection is considerably lower than with the naive algorithm. Although we have shown an improvement in the performance, the results also show that with a network of the size as in the field experiment, a naive approach is also acceptable. On the other hand, with a growing number of peers, query routing and peer selection becomes critical. In the previous discussed simulation experiments, networks with thousands of peers improve in the order of one magnitude in terms of recall of documents and relevant peers. 8.3 Comparison with results from simulation experiments Overall, the results of the simulation experiments have been validated: We were able to improve the precision of the peer selection and thus reduce the number of sent messages. However, the performance gain by using the expertise-based peer selection was not as significant as in the simulation experiments. 8  X  Size of the network The size of the network in the field experiment was consid- X  Network topology In the field experiment, we built the semantic overlay net- X  Distribution of the content In the simulation experiments, we distributed the 9 Conclusions and future work In this paper, we have presented a model for expertise-based peer selection, in which a semantic overlay network among the peers is created by advertising the expertise of the peers. We have shown how the model can be applied in a bib-liographic scenario. Simulation experiments that we performed with this biblio-graphic scenario show the following results:  X  Using expertise-based peer selection can increase the performance of the peer  X  However, if expertise-based peer selection uses simple exact matching, the  X  An advertising strategy where peers only accept advertisements that are se- X  The above results depend on how closely the semantic overlay network of the of the peer selection and thus reduce the number of sent messages. However, the performance gained by using the expertise-based peer selection was not as sig-nificant as in the simulation experiments. Summarizing, in both the simulation experiments and the field experiments, we have shown that expertise-based peer selection combined with ontology-based matching outperforms both random peer selection and selection based on exact matches, and that this performance increase grows when the semantic topologies more closely mirrors the domain ontology. as the assumption that all peers agree on the use of a single ontology, which is not realistic in all cases. We already have work in progress which allows us to relax this constraint. We expect that differences in ontologies used by different peers will lower our results, since the computation of the semantic distance between peers becomes less reliable across different ontologies. Currently, we are working on an approach where expertise descriptions are not described in terms from a global shared ontology. Instead, routing is based on overlap between sets of locally extracted terms.
 once, during an initial advertising round, and was not adapted any further during the lifetime of one experiment. In our field experiment, this assumption was not madeandalsotheworkin[ 27] shows how the overlay network can be adjusted based on the exchange of queries and answers. More research has to be done to show that such a self-adjusting network will improve the results. We think this will be the case since the semantic overlay network will converge better towards the structure of the underlying ontology than our current one-shot advertising allows. Currently, we submitted a paper containing results on simulations with a network where content is distributed dynamically and peers update and re-advertise their expertise descriptions. In that paper, we also used a more complex expertise mod-els based on Latent Semantic Indexing.
 ulations experiments is a fairly simple one, based on the ACM topic hierarchy. Other domains may require more complex expertise models with different simi-larity functions. One option would be, for example, to extend the expertise model with quantitative measures to indicate how much information for a certain topic of expertise is available on the peer. Another option, on which we are currently working, is to automatically extract a shared term similarity matrix based on a subset of documents retrieved from the network. References Author Biographies
