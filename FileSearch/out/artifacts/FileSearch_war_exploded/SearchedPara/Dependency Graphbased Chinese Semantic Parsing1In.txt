 Semantic analysis is the ultimate goal of natural language processing on sentence level. For sentences as  X   X  X  X  (Tom)  X  (eat)  X  (already)  X  X  X  (apple)  X  and  X   X  X  X  (apple)  X  (been)  X  X  X  (Tom)  X  (eat)  X  (already) ,  X  both of which are semantically identical though with different forms of expression , Their semantic form is  X   X  (eat) (  X  X  X  (Tom)  X  X  X  X  (apple) )  X  . This semantic information is helpful to w ord -sen s e disa m-biguation, information retrieval , machine translation and so on . 
SDP integrates dependency structure and semantic information in the sentence, bas ed on dependency grammar [1] , which is a deep semantic analysis task. SDP co n-pendency grammar, i.e. t o find out all pairs of words with direct semantic relations in a sentence , and then assign semantic labels between each word pair s .

The corpora with semantic -oriented dependenc ies already exist . [2, 3] ha ve ann o-tated a corpus in the scale of one million words manually . They adjusted the semantic relations defined by HowNet, combining similar labels, eliminating those rarely used and revising those with semantic blurs and differences. 
HIT semantic dependency is established by Research C enter for S ocial C omputing and I nformation R etrieval in Harbin I nstitute of T echnol ogy in 2011. It is also based on the semantic framework of HowNet, with the combination of LuChuan and Yuan Yulin semantic representation system s. [4] annotate d 10 thousand of sentenc es in Penn Chinese Treebank . [5] organized the international pu blic asses sment in SemEval -2012 using this corpus . Many research institutions in China partici pated in th is share task . However, flaw s of HIT semantic dependency exist 1) there are too many fine -grained labels, many of which are rarely mentioned or used; 2) HIT corp us is annotated on news corpus, Whether it is able to cover complex linguistic phenomena is in question; and 3) there are much overlapping between labels. Thus it needs further improvement.
SDP is studied based on dependency trees. B ut semantic structure in Chinese often canno t be completely expressed by trees. For instance,  X   X  X  X  ( we )  X  ( select )  X  ( h e )  X  ( as )  X  X  ( monitor ) .  X  The head of  X   X  X  X  he  X   X  is  X   X  ( select )  X  referring to a patient  X   X  (I)  X  (head)  X  (ache)  X  (de)  X  X  ( serious )  X  X  X  (still)  X  (flow)  X  X  X  (snot )  X  According is a lso a semantic relation between  X   X  (flow)  X  X  X  (snot)  X  and  X   X  ( I ) .  X  Thus li mitation of dependency tree s is obvious .

Due to the mentioned flaws, in this paper we introduce a semantic dependency scheme with stronger theory foundations on the basis of HIT  X  s . T o cover Chinese semantics in a more all -round way, we propose semantic dependency graphs on the ex ten sion of the dependency tree structure. T his paper parses dependency graphs on the basis of a parser for dependency tree s and a SVM classifier . 2.1 Structure of Semantic Dependency Graphs According to real corpus on large scale and considering that Chinese is a kind of pa r-ataxis language with little syntactic restrictions , we ex tend the traditional structure of depe ndency tree s to dependency graph s .
 refer to words and sides refer to semantic relations between words with one semantic label . There is one and only one node without any head as the center of whole graph . more than one head on certain node s , as well as cross ing of a rcs. As in Figure 1 and Table 1 , node  X   X  ( she )  X  has semantic relations with both  X   X  X  X  ( face )  X  and  X   X  parsing here is different from topics in pragmatics)  X  meanwhile arc s (  X  ( disease ) ,  X  ( she ) ) and (  X  X  X  (terrible -look ing) ,  X  X  X  ( now ) ) cross. (DG) [1] . D ependency graph s break the rules of traditional DG on  X  N o element d e-pends directly on more than one others  X  and  X  no crossings of arcs are allowed  X  . But it s core idea still inherits from DG , for example the relation s are transitive, irreflexive, and anti -symmetric. T herefore dependency graph is an ex ten sion of the DG. 2.2 Semantic R elation S cheme on the B asis of Chinese P arataxis N etwork There are several problem s in HIT semantic dependency scheme . T here are too many semantic labels, and some of which only appear a few times. Much overlapping also appeared. HIT corpus is annotated on news corpus, but news sentences cover only limited means of Chinese expression . Thus it needs further improvement.
 Chuan [6] , this paper borrows relation labels, the cl assification of semantic units and the idea of se mantic combination , and also integrates the characteristics of DG , to construct a semantic relation scheme of more clarity. 2. 3.1 Semantic units and semantic combination T h e semantic units can be divided, from high to low , into event chain , event , arg u-ment , concept and mark . It  X  s worth pointing out that concept equals a simple concept in human thoughts basically , or a notional word in syntax and mark m eans the info r-matio n which is attached to the entity infor mation being conveyed by speakers , such as the tone and mood of the speaker. These s e matic units correspond to complex sentence, minor sentence, chunk, notional word and function word. T he semantic of one sentence can be expressed by the event chain which comprises of events represented by each minor sentence. The semantic of minor sentences can be expressed by the central and side arguments, while the semantic of central argument is expr essed by p redication concept and side argument by other referential or defining concepts. Concepts are related by mark s. between these units includ ing semantic relation s and semantic attachment s . The s e-mantic attachment refers to the mark s of semantic units. Semantic relation includes symmetric and asymmetric relation. Symmetric relation includes coordinati on , sele c-tion and equivalence relations . Meanwhile, asymmetric relation includes : example, in  X   X  X  X  (worker)  X  X  (repair)  X  X  X  (pipeline)  X  ,  X   X  X  X  (pipeline)  X  is the patient of  X   X  X  (repair)  X  and they form cooperative relation. Semantic role s usually refer to cooperative relation s , and this paper defines 3 1 semantic roles, see appendix . Add i-tional relation refers to the modif icatio n between add itional concept and the central concept within the side argument , includes all kinds of roles, e.g.  X   X  X  X  (underground)  X  (de)  X  X  X  (pipeline)  X  (  X  X  X  (pipeline) ,  X  X  X  (underground) : Loc ) . Connectional relation means the bridging relation between two events that are of neither symmetric nor nest ed relation. For example,  X   X  X  X  ( If )  X  X  X  ( weather )  X  ( good ) ,  X  ( I )  X  ( will )  X  ( go )  X  X  X  X  (t he Summer Palace ) . X  the former event is the hypothesis of the latter event. There are 15 relations with respect to event in the new semantic scheme. provides re -organization of HIT seman tic dependency system on above theoretical basis. A ll semantic relations are shown in appendix. 2. 3. 2 Import ant rules Firstly, i f two words are semantic associated in a sentence , then the dependency structure must reflect th is association, either through direct or transitive arc. But for the sake of simplification, if two associated words have already got indirect dependency arc s and the relation can be inferred , then there  X  s no need for direct arc. Secondly, Chinese w ill not g enerate modifying circle s, so does semantic dependency graph s . 2. 3. 3 Special situation s (1) Re verse relation s When the modif ier in a phrase is a predication concept, it is marked as re verse relation. For example, in phrase  X   X  X  X  ( emerg e)  X  (de)  X  X  X  ( comet )  X  the head of  X  X  X  (emerg e) is  X  X  X  (comet) , and  X   X  X  X  ( comet )  X  (de)  X  X  X  ( emerg e) .  X  the head of  X  X  X  (comet) is  X  X  X  (emerg e) . T h ough the y are different in syntactic structure and synta c tic hierarchy , se mant ic relations on both arcs are the same, apart from the opposite direc tion o f arc s . T o distinguish the m ,  X  r  X  is added to sematic roles . T h is is consistent with HIT semantic depend ency scheme . (2) N est ed events If two events have a nest ed relation, namely that one event is degraded as a co nstituent of another and then they are  X  nested  X  . For example, in the sentence  X   X  X  X  (g randpa )  X   X  (see)  X  (he)  X  (de )  X  ( little )  X  X  X  ( granddaughter )  X  (is)  X  ( play )  X  X  X  X  ( computer ) .  X  , the underlined part is degraded as a cont ent of the action  X   X  X  (see)  X  . The nest ed relation is labeled as  X  d -role  X  . Th is part will provide detailed analysis of dependency graphs.
 into following categories . 1) many omissions exist in recount structure s ; 2 ) the omission of central predicates can easily lead to cross ed arcs; 3) in some sentences, the important part is pre -posed and later referred to by pronouns, namely the occurrence of equ i v a-lence relation is often accompanied by cross ed arcs; and 4) fle xible  X  ba  X  -sentences. Following are corresponding examples . tences caused by the causative s ; 2) the reference of pronouns often cause multiple head s; 3) in a sen tence comprising of several clauses, when the latter clause omit s its subject and its subject is different from the former clause , there is a need for labeling the relation be tween predicate in the latter clause and its corre sponding subject , As interlock takes place as the event degrade d and the central word in the interlocking structure does not have direct semantic association with the modified part. Figure 4 gives examples under each situation.
 Agt) and (  X   X  X  ( discuss )  X  ,  X   X  X  ( topic )  X  : rCont ). Clearly, the omission of these arcs is a loss of the semantic in C h inese. dependency graphs are common language phenomena in Chinese and have a consi d-erable quantity. relations dis c arded by tree s . So b ased on the parsing of dependency tree s , we use SVM to find arcs didn  X  t appear in th e tree s and then assign semantic label s to each arc s . Chinese -English bilingual corpus. The average length is 18 words. The statistics of sentences with cross ed arcs and nodes with multiple heads is shown in table 2 . 4.1 Parsing of D ependency T ree s We adopt transition -based dependency parsing algorithm to process no n -project ive dependen cy tree s . The transition actions we used come from [7] . The main idea of this algorithm is that using a queue to keep the tokens popped out of stack in order to be compare d with following unprocessed tokens in the buffer , thus t his algorithm can successfully process non -projective dependency trees. T h e decoding decision is co n-sulted by gold -standard trees during training and beam -search [8] during decoding. L earning algorithm adopts averaged -perceptron [9, 10] . 4.2 Parsing Dependency Graph s base d on SVM The re are two steps to construct dependency graph s . F irstly , set up human -written rules based on the analysis of section 3 to get the candidate arcs, and then use SVM to select the arcs really need ed to be in corpo rated. Finally , carry out another SVM on selected arcs and determine the semantic relations. 
SVM classification relies on the design of features [11, 12] . We use some fea tures proposed by [13] as the basis , such as the unigram bigram trigram features . Apart from th ose , we also add feature about the frequency of dependency arcs within the training corpus and about the two word s X  nearest common ancestor , including morphology , distance s to ancest or and postag s on the path to common ancestor respectively . 
An aly s i s of real corpus reveals that dependency arc s exist ing beyond the depen d-ency tree s ha ve numerable semantic relations. Therefore, the process of assign ing semantic labels can be treated as a multi -classification problem . The feature s used here are the same as arc s identification used . 4.3 Result s and Analysis of Dependency Tree Parsing Tab l e 3 shows the corpus statistics of our experimental data . The result of parsing of dependency tree is that UAS is 8 5 .3 8 % and LAS is 6 9.37 %.

It is relatively low for LAS . I n annotating stage, to further clarify the annotati on , the hierarchy of the labels is clearly set, we can first pin down the main category of a sentence and find out the specific label later on, but all labels are equally treated by the parser. A ll together 98 labels are processed , t hus the training is insufficient. relatively low r ate of precision and recall . Semantic role s correspond to reverse rel a-tion s and nested relations . In the training set , reverse relations and nested relations rarely exist. Thus the training on these two kind s of relations is not sufficient enough . and no furthe r features could help, and the arc length is longer on average . As a result, the precision of event rela tions is also relatively low . W hereas semantic marks is rel a-tively high er , since more adverbs and conjunctions make up se mantic marks and all the words included in each mark can be enumerated.
 son s . Firstly , the existence of compressed sentences makes label ing of verbs more diffi cult. T wo verbs form many relations, for example, eSucc, ePurp, dMann and so on . Secondly, Pivotal phrases in pivotal sentences usually express different meanings , and lead to multiple semanti c relations between two actions , as eResu and eCau etc . Thirdly , relations between two clauses are represented by two kernel words of the two events. Mostly, the kernel words are verbs . However, according to our previous ana l-ysis, event relations have a relatively low rate of precision . 4.4 Results and Analysis of Appending Additional Arcs The experimental data is the tes t set in part 4.2 . There are 195 Sentences with 210 extra control the scale of candidate arcs, we cannot over generalize these rules. So the recall here is a compromise. The average amount of candidate arcs for each sen tence is 6.8. ture s subs equently, the result rise s 1.68 % . The feature of word pair frequency helps on finding head s of arcs. The common ancestor features help to distinguish whether two words are in the same semantic chunk and to find distance betwee n two words. This is helpful to eEqu, since if two words are close to their common ancestor, even if they are distan t from one another they can still express relatively close semantic information. errors occur with eEqu mainly in the sentences wi th multiple nouns and pronouns , still eEqus between closer nouns or pronouns are recognized better than far distance . E r-ro rs produced by the tree parser is cascaded here, features extracted for SVM is partly wrong. This is another important reason affecting the result of classification. Both of these problems stand in the way of the construction of semantic dependency graphs. we have a precision of 71.96%. At the beginning , we analyzed the flaws of HIT semantic dependen cy scheme, to refine it, W e utilize d strong linguistic theories to propose a new sch eme with clear semantic hierarchy and more standard label s . Moreover, it ex ten d s , on the basis of DG , the structur e to dependency graphs , which are more suitable for Chinese se ma n tics. W e annotated 10 thousand sentences with our dependency scheme . In the later part, we will share the corpus with other researchers. Lastly, we introduce an auto parsing system of semantic dependen cy graphs. T he serial process of the system led to cascading errors, causing parsing result s of low accura cy . How to enhance the parsing of dependency graph s is our main work in the future .
 Acknowledgement We thank the anonymous reviewers for their const ructive comments, an d appreci a-tively acknowledge the support of the National Natural Science Foundation of China (NSFC) via Grant 61170144, 61133012 and 61370164 . Table of whole s emantic dependency relatio ns
