 Biomedical functional relations (relations for short) state interactions among biomedical substances. For instance, the PROTEIN-ORGANISM-LOCATION (POL) relation that we study in this paper provides information about where a PROTEIN is located in an ORGANISM, giving a valuable clue to the bi-ological function of the PROTEIN and helping to identify suitable drug, vaccine and diagnostic tar-gets. Fig. 1 illustrates possible locations of proteins in Gram + and Gram  X  bacteria. Previous work in biomedical relation extraction task (Sekimizu et al., 1998; Blaschke et al., 1999; Feldman et al., 2002) suggested the use of predicate-argument structure by taking verbs as the center of the relation  X  in con-trast, in this paper we directly link protein named en-tities (NEs) to their locations; in other related work, (Claudio et al., 2006) proposed an approach that solely considers the shallow semantic features ex-tracted from sentences.

For relation extraction in the newswire domain, syntactic features have been used in a generative model (Miller et al., 2000) and in a discriminative log-linear model (Kambhatla, 2004). In comparison, we use a much larger set of syntactic features ex-tracted from parse trees, many of which have been shown useful in SRL task. Kernel-based methods have also been used for relation extraction (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005) on various syntactic represen-tations, such as dependency trees or constituency-based parse trees. In contrast, we explore a much wider variety of syntactic features in this work. To benefit from both views, a composite kernel (Zhang et al., 2006) integrates the flat features from enti-ties and structured features from parse trees. In our work, we also combine a linear kernel with a tree kernel for improved performance. Fig. 2 shows one example illustrating the ternary re-lation we are identifying. In this example,  X  X xoen-zyme S X  is a PROTEIN name,  X  X xtracellular X  a LO-CATION name and  X  X seudomonas aeruginosa X  an ORGANISM name. Our task is to identify if there exists a  X  X ROTEIN-ORGANISM-LOCATION X  re-lation among these three NEs.

To simplify the problem, we first reduce the POL ternary relation extraction problem into two binary relation extraction problems. Specifically, we split the POL ternary relation into binary relations as: (1) PO: PROTEIN and ORGANISM, and (2) PL: PRO-TEIN and LOCATION.

The ORGANISM-LOCATION relation is ignored because it does not consider the PROTEIN and is less meaningful than the PO and PL relations. Based on this simplification, and following the idea of SRL, we take the PROTEIN name in the role of the predicate (verb) and the ORGANISM/LOCATION name as its argument candidates in question. Then the problem of identifying the binary relations of PO and PL has been reduced to the problem of argu-ment classification problem given the predicate and the argument candidates. The reason we pick PRO-TEIN names as predicates is that we assume PRO-TEIN names play a more central role in linking the binary relations to the final ternary relations.
Compared to a corpus for the standard SRL task, there are some differences in this task: first is the relative position of PROTEIN names and ORGAN-ISM/LOCATION names. Unlike the case in SRL, where arguments locate either before or after the predicate, in this application it is possible that one NE is embedded in another. A second difference is that a predicate in SRL scenario typically consists of only one word; here a PROTEIN name can contain up to 8 words.
 We do not use PropBank data in our model at all. All of our training data and test data is annotated by domain expert biologists and parsed by Charniak-Johnson X  X  parser (released in 2006). When there is a misalignment between the NE and the constituent in the parse tree, we insert a new NP parent node for the NE.
Fig. 3 shows the system overview. The input to our system consists of titles and abstracts that are extracted from MEDLINE records. These extracted sentences have been annotated with the NE infor-mation (PROTEIN, ORGANISM and LOCATION).
 The Syntactic Annotator parses the sentences and in-serts the head information to the parse trees by using the Magerman/Collins head percolation rules. The main component of the system is our SRL-based relation extraction module, where we first manu-ally extract features along the path from the PRO-TEIN name to the ORGANISM/LOCATION name and then train a binary SVM classifier for the binary relation extraction. Finally, we fuse the extracted binary relations into a ternary relation. In contrast with our discriminative model, a statistical parsing based generative model (Shi et al., 2007) has been proposed for a related task on this data set where the NEs and their relations are extracted together and used to identify which NEs are relevant in a particu-lar sentence. Since our final goal is to facilitate the biologists to generate the annotated corpus, in future Table 1: Features adopted from the SRL task. PRO: PROTEIN; ORG: ORGANISM work we plan to take the relevant labeled NEs from the generative model as our input.

Table 1 and Table 2 list the features that are used in the system. 4.1 Data set Our experimental data set is derived from a small expert-curated corpus, where the POL relations and relevant PROTEIN, ORGANISM and LOCATION NEs are labeled. It contains  X  150k words, 565 rela-tion instances for POL, 371 for PO and 431 for PL. 4.2 Systems and Experimental Results We built several models to compare the relative util-ity of various types of rich syntactic features that we can exploit for this task. For various represen-tations, such as feature vectors, trees and their com-binations, we applied different kernels in a Support Vector Machine (SVM) learner. We use Joachims X  Table 2: New features used in the SRL-based rela-tion extraction system.
 SVM light 1 with default linear kernel to feature vec-tors and Moschetti X  X  SVM-light-TK-1.2 2 with the default tree kernel. The models are: Baseline1 is a purely word-based system, where the features consist of the unigrams and bigrams between the PROTEIN name and the ORGAN-ISM/LOCATION names inclusively, where the stop-words are selectively eliminated.
 Baseline2 is a naive approach that assumes that any example containing PROTEIN, LOCATION names has the PL relation. The same assumption is made for PO and POL relations.
 PAK system uses predicate-argument structure ker-nel (PAK) based method. PAK was defined in (Mos-chitti, 2004) and only considers the path from the predicate to the target argument , which in our set-ting is the path from the PROTEIN to the ORGAN-ISM or LOCATION names.
 SRL is an SRL system which is adapted to use our new feature set. A default linear kernel is applied with SVM learning.
 TRK system is similar to PAK system except that the input is an entire parse tree instead of a PAK path.
 TRK+SRL combines full parse trees and manually extracted features and uses the kernel combination. 4.3 Fusion of Binary relations We predict the POL ternary relation by fusing PL and PO binary relations if they belong to the same sentence and have the same PROTEIN NE. The pre-diction is made by the sum of confidence scores (produced by the SVM) of the PL and PO relations. This is similar to the postprocessing step in SRL task in which the semantic roles assigned to the argu-ments have to realize a legal final semantic frame for the given predicate. 4.4 Discussion Table 3 shows the results using 5-fold cross valida-tion. We report figures on ternary relation extraction and extraction of the two binary relations. Compari-son between the PAK model and SRL model shows that manually specified features are more discrimi-native for binary relation extraction; they boost pre-cision and accuracy for ternary relation extraction. In contrast to the SRL model for binary relation ex-traction, the TRK model obtains lower recall but higher precision. The combination of SRL with the TRK system gives best overall accuracy of 71.8% outperforming shallow word based features. In this paper we explored the use of rich syntac-tic features for the relation extraction task. In con-trast with the previously used set of syntactic fea-tures for this task, we use a large number of fea-tures originally proposed for the Semantic Role La-beling task. We provide comprehensive experiments using many different models that use features from parse trees. Using rich syntactic features by com-bining SRL features with tree kernels over the en-tire tree obtains 71.8% accuracy which significantly outperforms shallow word-based features which ob-tains 56.3% accuracy.

