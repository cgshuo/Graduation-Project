 paper analyses four cases in whic h a tool to support collaborative wok include factors supporting and constraining reflection in tools as well as implicati ons for tool design. K.3.1 [ Computer Uses in Education ]: Collaborative learning; K.4.3 [ Organizational Impacts ]: Computer-supported collaborative work.
 Measurement, Performance, Design, Human Factors Reflection, Collaborative Refl ection, Workplace, Learning Reflection is a common activity performed by people in different work places every day: Workers ask themselves whether they can and think about improving their cooperation, and during work reflection can be understood as returning to experiences, re-reflecting on past experiences need s attention to work being done and the rationales for doing it the way it was done [32] as well as a mindset of being open to learn fro m current or past experiences, which needs to be established and spread to make reflection effective in organizations [30]. there might be no time and space to do this, or there may be other experiences may not be availabl e for individuals, but only from a group of people. These and other constraints of reflection in daily perspectives on these experiences, reflect on them individually or [13,15,26]). It has been found that collaborative reflection may create insights combining different people X  X  perspectives and knowledge [13,20], and that this needs specific support for the collection, coordination process. Unfortunately, resear ch on reflection support mainly covers individual reflection and education settings, in which constraints such as time and space occurring in many workplaces curriculum. Consequently, there are only a few insights on how to [16,26,33]). Given the potential of collaborative reflection at work there is a need to fill the resulting research gap. ideas for change in future work [6,33]. This needs communication support e.g. for the exchange of similar experiences and to collaboratively understand them [4,10,33]. In work on face-to-face collaborative reflection it has been shown that structuring the refer to each other [11]. C C d c c t h p fu [ fr r s p c d s g i n d p 2 A t h i n i n r A n t o f r D i n s f h r p L s w [ F C ollaborative re f C SCW and CSC d ecision suppor t c oncepts from c ollaborative re fl h e discriminati n p ast wor k , und e fu ture  X  are no t 26]. Therefore fr om such con c eflection work s s upport it at thei r B ased on empir i p resented in t h c ollaborative re f d evelopment of s upporting colla b g roup and leavi n n cludes (usua l d ocumentation o p rocess, possibil i 2 .2 Tool Supp o A n analysis on e h is work reve a n tensively, and n dividual refle c ecently also b e e A mong existing n otable approac h o ol, users can d f eelings about t h e-assess these r D espite the val u n dividual refl e s upport, besides f or reflection p u h ow a series of eflection in a s p ortfolios can su p L ooking at this s ufficient amou n w ork available. 19,23] aims to F igure 1. Colla b collab o the de v reflecti when w Literat u certain figures offers conver s means our ca s Codin g analyz i they f u reflecti analyz i b y Fle c from m reflecti work. regard conten t of bei n schem e reflect. extensi reflecti [3,17,2  X  R e  X  P r  X  L i  X  R e  X  S h  X  D r  X  T r In co m related coding Howe v solely approa c examp l comm u p ropos e of peo p a conv e networ k To ga i suppor t workpl reflecti analysi networ k from t h h s t e d d 1 2 3 T w t h r F w u r T i n s w o p B r r p o e i n r i n T i n i s i n r h olistic insight i s upport and al l e chnology sup p d esigning collab d escribed in the p 1 . How do ( d 2 . Which are t 3 . Which aspe T his paper desc r w as undertaken i h e same tool (t h eflection. F or the analysis o w e conducted a u sing a tool we eflection at w o T alkReflection A n teraction such s tudy covered d w ork such as s p o thers we did n o p articipating in t h B ased on earlie eview], the Tal k eflection on i p roviders and c o rganizations: I e xamples, in m e n teraction with p elatives, and in n teractions with T he TalkRefle c n teractions by c s sues in a peer n teractions an d esulting report s
Figure 2. The related and re f steps o f  X  C r  X  S h  X  C o The a p the co n comm e to wor k The T a three o contex t admini worki n suppos e and m e p artici p which w the to o other d with p h their a b p repar e British care home for people suffering from dementia. The aim of conversations with residents, relatives and third parties. different amounts of users  X  the study configuration was based on some after a couple of days) and given the sample size we cannot differently. Using the data of all participants is necessary because participants commented on each the notes created by the dropouts. Table 1. Overview for cases of using the TalkReflection App. In each case, the TalkReflection App was introduced to the participants in on-site workshops including an introduction of the app and a session of initially usi ng of the app, asking some users to provide real experience reports and others to comment on them. It was also discussed how the app could be used in the respective workplace, including how to use it in meetings or during the day. to use the tool in a way that suited the group best. differed in terms of organization and conduction (see Table 1): In differed, as in cases 3 and 4 users worked on the same floor, while different buildings as well. Table 1 summarizes this information. different groups and workplaces by analyzing each group but also role of tools to support colla borative reflection at work. The analysis was done with a mixture of tools to ensure a holistic view on how the participants in the studies use the TalkReflection App. For this we combined usage and content analysis with subjective impact creat ed by using app:  X  Usage analysis was done by the amount of content created  X  Social network analysis was applied to analyze the  X  The results from the analysis mentioned above were app, we have comparably little da ta on reflection outside the app, that is, reflection possibly started in the app and continued in face-insights on how users reflected in the app and the impact resulting who cannot be present in certain face-to-face encounters. Besides content analysis, analyzing and comparing group and empirical base showing that collaborative reflection relies on sensemaking and inference, we f ound that we also need means to descriptive data on user and group activity we use  X  the amount of experiences reports and comments made on  X  the average length of communication threads as proposed  X  the answer ratio to experience reports as proposed by [8] as Domain Interns, Duration (days) 51 80 42 50 Time Sep-Oct Dominant user no yes yes no Process integr. no yes no no social network analysis as proposed by [8,37], including  X  the density of the graph resulting from conversations as  X  the ratio of unique edges in the graph as a measure of analysis of conversations, we used the abovementioned measures to analyze collaborative reflection in the cases and to complement the content analysis described below. the tool was used in the cases. Facing the lack of existing schemes drawing from the work described in section 3.3.1 on (collaborative) includes nine phases as described in Table 2. These phases in the scheme may build on each other. In a reflection experiences without needing any other code in between. described similarly by Fleck and Fitzpatrick [9] and de Groot et al. include (1) the description and sharing of experiences and emotions from them, (2) trying to understand and solve issues in experiences shared, and (3) describing learning and change. Table 2. Coding scheme for content in collaborative reflection Code Phase 1 Description of an experience and mentioning of an 2 Mentioning and describing emotions of oneself or 3 Interpreting or explaining behavior in the 4 Linking an experience explicitly to other experiences 5 Linking an experience to knowledge by referring to 6a Responding to the explanation of an experience by 6b Responding to the explanation of an experience by 7a Contributing to work on a solution by providing 7b Contributing to work on a solution by providing 8a Showing insights or learning from reflection by 8b Showing insights or learning from reflection by 9 Describing or implementing change such as proposing Stage 1 is concerned with the basic elements of reflection such as actual change. Table 3 summarizes these stages and shows which communication thread to a certain st age if at least one code of the using the app. Table 3. Stages of reflection and codes related to the stages. Stage Description Codes 1 Provision and description of experience , 2 Reflection on experiences , including 3 Learning or change resulting from reflection shared perspectives on issues or learning and change happening. timeframes shown in Table 1 as well as log data on usage of the app observations made onsite in the cases. content, that is, content including a report describing an experience receiving at least one comment) in Table 4 show that for every case which there were no traces of reflection, indicated by no code being the resulting number of conversations analyzed for each case. These comments to 74 conversations and 159 comments analyzed. conduct a debriefing meeting with the manager of the group, which was not possible in case 4. In case 3 we were able to conduct short cases. relation to the time and amount of users in each case. Table 4shows cases. In our analysis, we differentiated between average usage per impression of activity a user gets from the app. of experience reports created were also commented on (answer ratio between 0.71 for case 2 and 0.88 for case 3). This indicates that the experience reports per day ( X  X eports/user, day X ), while this was less in cases 1 and 4  X  again we need to take into account that in case 1 lowering the respective average valu es for case 1. Likewise, we can per day than in cases 1 and 4. Therefore we can conclude that users cases. Reports/day 0.47 0.56 0.57 0.48 Reports/user,day 0.03 0.05 0.06 0.05 Answer ratio 0.83 0.71 0.88 0.80 Comments/day 0.92 0.81 0.93 0.50 Comments/user,day 0.05 0.07 0.10 0.06 Avg. thread length 2.35 2.03 1.77 2.08 Concerning the intensity of communication, that is how many was similar, with the exception of the low number of comments per communication threads than in the other cases, with case 3 showing the lowest value for average communication thread length. Thus we other cases (although per user and day this was different due to the for case 2, thread length in case 3 and comments per day in case 4). 1, as  X  including the early dropouts in case 1  X  case 2 had a similar number of users. experience reports per day is similar in all cases, while the number comments. expect the numbers to be slightly higher in practice. However, while be used more often (e.g., [15]), when using collaborative reflection described by the figures in Table 1 and Table 4. applied basic social network analysis as proposed by [37,40] to the log data gathered from the cases (see section 3.3) experience report as directed edges from the user commenting to the vertices is the number of users in the cases as shown in Table 4. As Table 5 shows, graph density is lowest for case 1 and highest for case 4, with cases 2 and 3 in between. This indicates that in case 4 more users were connected to each other than in the other cases; the lower for cases 2 and 3. This suggests that communication in cases communicating) than in cases 2 and 3, while the low values indicate communication relationships established. Graph density 0.10 0.17 0.19 0.25 Microsoft Excel based tool (https://nodexl.codeplex.com/). participants used the tool in a self-directed manner, in cases 2 and reflection in the tool, and in case 3 the senior physician had asked shared by them in return. This resulted in multiple communication dominant user had added one) fewer other edges. Content coding was done independe ntly by two coders on the comments). This means that a code was assigned once or not at all codes assigned by the two coders. Concerning the agreement among coders, we calculated values for agreement concerning the stage of reflection reached in each compared to the coding scheme, the quality of the resulting data is levels reached in the conversations . To further enhance the quality of the coding for stage 3, the code rs discussed differences in using coders. This data was used for the following analysis. Table 6. Stages of collaborative reflection reached in the cases. Stage Case 1 Case 2 Case 3 Case 4 1 100 % 95.8 % 100 % 100 % 2 94.1 % 95.8 % 95.2 % 83.3 % 3 23.5 % 33.3 % 0 % 16.7 % Analyzing the content coding and a pplying it to the three stages of collaborative reflection described in Table 3, we found that stages 1 and 2 were reached in most conversations throughout the cases, while there are differences in the proportion of conversations that surprising, because before the coding the obviously non-reflective conversations that did not reach th is stage (only two thread in case 2, see Table 6) were initiated by the respective user with solution than we initially expected, especially for the cases with lower user numbers. The figures for stage 3 show major differences between gives an overview of stages reached. experiences received at least one comment (that is, the data set we coded) the conversation was very likely reach stage 2 and thus to conversations reached this stage. This can be seen as a success of the tool, especially because we f ound in earlier studies that many conversations in which issues had been brought up were not immediately from work when being told about an experience) and session and outside face-to -face group meetings. case 3 no learning took place. We are aware that concluding from face-to-face situations. In fact feedback from participants and our cases. However, with a focus on the role of tools in collaborative percentages of stage 3 reached for a group also mean that by using especially in cases such as case 3, in which there was good effort the discussion in the tool takes place cannot take full benefit from collaborative reflection. The high proportion of stage 2 conve rsations and the existence of some conversation reaching stage 3 also show the impact of using articulations of outcomes from reflection. Comparing this to makes reflection not only possible, but also sustainable and understandable for those not directly involved but reading through the content of a tool afterwards. interns X  manager. reflect on own practices and cha nges on it in the upcoming merge immediately. Their manager as the leading users of the tool added each other as a result of reflection, and that he had liked to bring up topics and to ask his staff to reflect on them. did not see much value in it as they had known most experiences that the exchange had helped them to know that others had similar had added this advice to nearly all reports. Overall, the perception felt the tool gave him the opportunity to train his staff. the care home, which they only used for documentation purposes. Those who had used the tool despite these constraints told us that their meetings, which was re fused by the manager. The feedback of participants adds a flavor to the analysis that data would have been overshadowed e.g. by orders to use the app (case 3) or constraints hindering the usage (case 4). The results of our studies give good insights into how participants used the TalkReflection App in each case, and also how the groups differed from each. Given the lack of insights in this area, this section analyzed these results. that there are some decisive aspects that accounted for success or low activity and perceived value. and in participation (highest unique edge ratio and average thread length). Other values on activity per user would have been higher amount of stage 3 reflection outcome s, but the number of reports from the interns. This may be attributed to the spatial situation of problems they were facing. The TalkReflection App gave them this opportunity, resulting in good uptake and results. values for reports and comments per user and day), and low numbers for diversity (lowest unique edge ratio) and participation proportion of cases reaching stage 3 of reflection. Therefore, case 2 is an example in which average or low figures for participation much value in using the tool. reports and comments, feedback indicating little impact) seems to be low. We attribute this to the organization of reflection and the to use the tool regularly, which resulted in high usage figures, but dominant user giving a dvice in his comments how to deal with the in other participants waiting for him to answer and thus lowering resulted in traces of learning or change (stage 3). example in which people saw value in the tool but could not hold usage up. The resulting low usage is grounded in lacking process integration and co-location of the users. dominant users in reflection groups can be good or bad for participation figures show engageme nt in reflection, the lead user led to comparably little diversity in the communication (see Table activity in the group caused the group to be more reflective in the contained traces of stage 3 reflection. This may be explained with the different roles these users played (see sections 3.2 and 4.4): In collaborative reflection. In case 3 the physician had asked staff to communication, as their comments may have discouraged others have dominated the respective social network. Another conclusion from the comparison is that scale matters: the users a higher overall number of documents and comments is support tool a higher amount of c ontent available makes using the collaborative reflection in the tool and that issues are reflected on lower answer ratio in case 2 seems to have had no negative effect more people than they are for small groups. The comparison of the groups as described above points to measures and figures that help to explain why collaborative reflection works better or wo rse in different settings: measures such as answer ratio or activity per user and day showed success in any way, as cases 1 (low values per day and user) and 2 worked much better . The other way round, particularly low values that reflection has not worked well. Together with thread length as might reach a threshold of activity per day from which on it might success factor of tools support for collaborative reflection. uptake and usage without additional context . For example, social unique edge ratio cannot be considered predictors of collaborative unique edges, and vice versa. The aspects described above may al so help the design of a socio-point to decisive factors in this dimension:  X  Dominant user vs. self-directed use: The cases show that  X  Role of a dominant user: Looking into cases 2 and 3 we  X  Process integration and co-location: The cases show that come at a surprise, as in co-locat ed groups much happens in direct communication. However, we saw that with good process the dominant user, this might have also happened in case 3. The analysis of the cases described in this paper reveals three ways in which the TalkReflection App was helpful for the participants:  X  Supporting face-to-face reflection: Especially from case 2  X  Connecting reflection participants: Case 1 and partly case 2 Besides analyzing the roles the TalkReflection App played in supporting collaborative reflection in the cases we also need to ask improvements:  X  Provoke activity: Our analysis shows that overall activity  X  Scaffold dominant user role: We have shown that dominant  X  Balance diversity and intensity of communication: We have Our analysis revealed differences between group activity and  X  from feedback  X  insights on which differences indicate reflection success more or less successful reflection. In terms of setting up technology supported collaborative reflection as socio-technical system we can say that dominant users in the role integration is decisive in small, co-located groups while connecting that for groups in which users are c onnected mainly by a tool a self-of being connected and able to reflect together is enough motivation reflection and with good integration into work such as using content from the tool in meetings seems to work, as case 2 shows. This may perceived value and others identified in cases 3 and 4. In a way these results resemble the old-new themes of the disparity between effort invested and benefit gained [12] and added value for may help to keep reflection going in a tool. However, we regard the to find more of such measures to allow the design of better tools to support collaborative reflection. automatically just by giving people tools. While we could see in all cases that if at least one comment was made on a report, reflection on the level of stage 2 was likely to happen. However, reflection on collaborative reflection sufficiently. described in this paper. Therefore the results presented above cannot be understood as a basis to draw from for further work and research researched area that can be used to build on. we could identify measures to be used when assessing collaborative While these results are not final or generalizable, they provide good ground to start from in further research. our work, we also recognized that there is need for better measures work. worthwhile working on, as the tool used in our cases created change such workplaces. This work has been supported by projects MIRROR (funded by the EmployID (FP7, project number 619619). We thank all members of the projects for their support and ideas on this work. 1. Baumer, E.P., Khovanskaya, V ., Matthews, M., Reynolds, L., 2. Bj X rn, P. and Boulus, N. Dissenting in reflective 3. Boud, D. Reflection: Turning experience into learning. Kogan 4. Daudelin, M.W. Learning from experience through reflection. 5. Dennis, A.R., George, J.F., Jessup, L.M., Nunamaker Jr, J.F., 6. Dyke, M. The role of the  X  X ther X  in reflection, knowledge 7. Edgington, T., Choi, B., Henson, K., Raghu, T., and Vinze, A. 8. Fahy, P.J., Crawford, G., and Ally, M. Patterns of interaction 9. Fleck, R. and Fitzpatrick, G. Reflecting on reflection: framing 10. Forneris, S.G. and Peden-McAlpine, C.J. Contextual learning: 11. De Groot, E., Endedijk, M.D., Jaarsma, A.D.C., Simons, P.R.-12. Grudin, J. Why CSCW App lications fail: Problems in the 13. Hoyrup, S. Reflection as a core process in organisational 14. Introne, J.E. and Drescher, M. Analyzing the flow of 15. Isaacs, E., Konrad, A., Walen dowski, A., Lennig, T., Hollis, 16. Lee, S. Design and analysis of reflection-supporting tools in 17. Levina, N. Collaborating on multiparty information systems 18. Lockhorst, D., Admiraal, W., Pilot, A., and Veen, W. Analysis 19. Marcu, G., Dey, A.K., a nd Kiesler, S. Designing for 20. Mercer, N. and Wegerif, R. Is  X  X xploratory talk X  productive 22. Newman, D.R., Webb, B., and Cochrane, C. A content 23. Porges, Z., Yang, X., Desai, A., et al. Achieve: Evaluating the 24. Power, D.J. and Sharda, R. Decision support systems. Springer 25. Prilla, M., Degeling, M., a nd Herrmann, T. Collaborative 26. Prilla, M., Pammer, V., a nd Krogstie, B. Fostering 27. Prilla, M. User and Group Behavior in Computer Support for 28. Prilla, M. Collaborative Reflec tion Support at Work: A Socio-29. Raelin, J.A. I don X  X  have time to think! X  versus the art of 30. Reynolds, M. Critical reflec tion and management education: 31. Roschelle, J. and Teasley, S. The construction of shared 32. Sch X n, D.A. The reflectiv e practitioner. Basic books New 33. Scott, S.G. Enhancing Re flectio n Skills Through Learning 34. Suchman, L.A. Plans and Situated Actions: The Problem of 35. Tigelaar, D., Dolmans, D., Meijer, P., de Grave, W., and van 36. Weick, K.E. Sensemaking in organizations. Sage Publications, 37. Wever, B.D., Schellens, T., Valcke, M., and Keer, H.V. 38. White, B.Y., Shimoda, T.A., and Frederiksen, J.R. Enabling 39. Van Woerkom, M. and Croon, M. Operationalising critically 40. Zhu, E. Meaning Negotiation, Knowledge Construction, and 
