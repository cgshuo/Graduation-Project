 Weblog, one of the fastest growing user generated contents, often contains key learnings gleaned from people X  X  past ex-periences which are really worthy to be well presented to other people. One of the key learnings contained in weblogs is often vented in the form of advice. In this paper, we aim to provide a methodology to extract sentences that reveal advices on weblogs. We observed our data to discover the characteristics of advices contained in weblogs. Based on this observation, we define our task as a classification prob-lem using various linguistic features. We show that our pro-posed method significantly outperforms the baseline. The presence or absence of imperative mood expression appears to be the most important feature in this task. It is also worth noting that the work presented in this paper is the first attempt on mining advices from English data.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing Algorithms, Performance, Experimentation Text Mining, Advice Mining
Previous survey has shown that the largest percentage of bloggers (37%) cited  X  my life and personal experiences  X  as the main topic [4]. As the manifestation of personal expe-riences, weblogs often contain explicit key learnings gleaned from people X  X  past experiences which are really worthy to be well presented to other people. One can surely learn from past experiences that others have discovered so that one can get new information or perspective that one might not have discovered before. Advice is one of the key learnings that can be found in weblogs.

Specifically, in travel weblogs, key learnings from one X  X  travel experiences are often vented in the form of travel ad-vices. This kind of advice can range from guiding people in performing action at a particular tourism place, to specific recommendation concerning what people have to do. More-over, advice can be also recommendation against a particular course of action [1]. Table 1 shows some examples of travel advices extracted from well-known travel weblogs. Storing those advice-revealing sentences is obviously very useful for future use.

Such travel advices are very important information among online travelers (i.e., those travelers who have internet con-nection). This information gives them perspective on where they should travel, what they should do, and what they should be aware of. According to the Travel Industry Asso-ciation of America [8], 67% of online travelers in the United States search for information on destination via the Inter-net. Unfortunately, current search techniques are not de-signed for in-depth advice seeking. Top ranking pages from search engine may not contain the desired advices. Even if they do, people are still needed to read through the re-trieved pages and capture manually which part of the pages contains desired advices. Even these difficulties also exist when people go directly to well-known travel websites (or weblogs) for seeking advices since advices are mostly min-gled with other unrelated information in the text content. It would be very nice if these travel advices were all captured and subsequently indexed by well-organized user-friendly in-dices enabling people to find easily what kind of travel advice they would like to seek. Therefore, the need of system that can capture and collect advices automatically on the Web is very urgent.

To address those aforementioned problems, we introduce a new task so called advice mining. The goal of this task is to capture automatically advices on the Web and subsequently store them in the depository called advice depository . The stored advices are in well-organized user-friendly structured information comprising 6 slots as listed below.
A full solution to the task of mining aforementioned com-plete advice representations is beyond the scope of this pa-per. We leave the full solution of advice mining task for future work. But, this paper addresses an important sub-task so called advice-revealing sentence extraction . The ex-amples of extracted sentences are shown in table 1. The results from this task are used to fill slot number 1 in the 6-slot structure mentioned before, i.e., advice mentions. In our research, we extract sentences which reveal advices from travel weblogs due to its usefulness and importance in travel domain. Although our data belongs to travel domain, our proposed method is completely domain-independent. We define the problem as a classification task using some lin-guistic features and opinionated lexical resource. A full so-lution obviously needs this task as the first step because advice context, advice type, reason, associated experience mention, and link to resource could only be extracted after knowing the advice mention.

Once those advice-revealing sentences have been success-fully extracted, there are two other points as additional benefits of this task besides providing easiness for people in accessing travel advices. (1) Extracted advices can be used as prepared information for context aware application [3]. The rapid development of mobile devices such as smart phones and tablet PCs triggers many researches in devel-oping such information recommendation system considering users X  contexts. After the system detects the users X  con-texts, e.g., place and time, the system could provide advices for the users in accordance with current place and time. For instance, user A is going to have lunch at restaurant B . Subsequently, the recommender system may present auto-matically some advices regarding what kind of menu user A should eat, what kind of menu user A should avoid, or maybe what kind of action user A should avoid. Those re-turned advices are retrieved from extracted advice-revealing sentences depository. Those advices were written by other people who have experiences in having lunch at restaurant B before. (2) Extracted advices provide a big boost to the tourist destination marketers. After people visited a partic-ular tourist destination, they usually write down some ad-vices in accordance with their experience on a travel weblog. These advices are manifestation of their experiences being communicated about the strengths and weakness of the des-tination. Understanding individual travel experiences from extracted advices is clearly a cost-effective method for desti-nation marketers to assess their service quality and improve travelers X  overall experiences [5].

This paper is organized as follows. In section 2, we review the related work. In section 3, we mention our observation to discover the characteristics of advice. Following that, section 4 gives explanation about our proposed method. Section 5 evaluates the proposed method. Finally, section 6 concludes the paper and mentions some future works.
 Table 1: Example of extracted advices in travel we-blogs 1 A request or advice, make sure you carry suffi-2 Be careful with your money and count the change 3 Avoid to pay in full in advance, especially if you
There have been some attempts to harvest people X  X  expe-riences from weblogs [7]. Sentiment analysis is also another task which is related to our task. The goal of sentiment analysis is to find opinionated sentences and then extract objects contained in those sentences as well as their associ-ated features and sentiment [6]. Based on our observation, some advice-revealing sentences contain opinionated words as shown in sentence  X  it is nice idea to bring medicine wher-ever you go  X . In this sentence, the opinionated word nice is a good indicator showing that the sentence reveals an advice. Later, we show that existing approach for sentiment analysis is used for determining the value of one of our features. As far as we know, the only one closest work was done by Kozawa et al. [3]. They also addressed the problem of ex-tracting advice-revealing sentences. However, the final goal of their research is different from ours. Moreover, they as-sumed that the target language is Japanese language which is different from our target language, i.e., English. They defined the problem as classification task using some fea-tures which are not suited to be applied directly on English data. Furthermore, we implemented their proposed method with some adaptations. Finally, we show that our proposed method is significantly better than their method.
In our research, we define advice as a sentence made by person, usually as a suggestion or a guide to action and/or conduct relayed in a particular context . Furthermore, we also observed each sentence in our data, especially advice-revealing sentence, to capture the characteristic of advices in English data. Firstly, we found that advice-revealing sentences tend to contain specific vocabulary aid such as make sure you, be careful with, be sure to, be aware, you have to, i suggest, i strongly recommend, advice, etc. Table 1 shows the examples of vocabulary aid in bolded words. Secondly, advice-revealing sentences often express modal-ity such as obligation, suggestions, necessity, and command. These modalities are expressed using following modal verbs: could, might, must, shall, should, will, and would . Thirdly, we found that advice-revealing sentences often contain im-perative mood expression that urge the readers to act a cer-tain way. In our data, this imperative mood is often ex-pressed by using a simple unconjugated form of the verb without any subject attached. The third sentence in table 1 shows the example. Lastly, advice-revealing sentences often contain opinionated words as shown in sentence  X  it is nice idea to bring medicine wherever you go  X . In this sentence, the opinionated word nice is a good indicator showing that the sentence reveals an advice. One more thing is that most of sentences described in past tense are not advices.
As mentioned previously, we defined the problem as bi-nary classification task. We extract a set of features that can help us label each sentence in the corpus whether or not it reveals advice mention. These features are selected mainly based on characteristics of advice addressed in the previous section.

Feature A ( FA ) is set of clue expressions defined through investigating our data. Suppose, there are m clue expres-sions in the set. FA is essentially a collection of binary sion corresponded with f a i appears in an instance x , then f a i ( x ) = 1; otherwise f a i ( x ) = 0. There are currently 54 clue expressions in the set.

Feature B ( FB ) represents proper-noun and modal verb contained in a sentence. The proper-noun should be directly attached to the modal verb as a nominal subject. To deter-mine this kind of proper-noun, we use dependency parser 1 to find proper-nouns that have  X  X ominal subject X  ( nsubj ) relation with modal verbs found in the sentence. The com-bination between identified proper-noun and modal verb is the value of this feature.

Feature C ( FC ) consists of three elements: set of clue verbs found in the sentence, proper-noun attached to the clue verbs as nominal subject, and POS tags of those clue verbs. Formally, we define { f cv i ( x ) } m i =1 as binary feature functions corresponded with each clue verb in the set, where m is the number of clue verbs in the set. The value of f cv is determined based on the presence of clue verb in an in-stance x . Furthermore, we associate f cv i with additional features (i.e., aforementioned proper-noun and POS tags), if only f cv i ( x ) = 1. To construct the set of clue verbs, firstly, we used some seed clue verbs found directly by in-vestigating our data (e.g., suggest, recommend, advice, etc.). Finally, we expanded the set of clue verbs by adding verbs from Framenet 2 using those seed clue verbs. Verbs that have the same frame with seed clue verbs were considered.
Feature D ( FD ) is binary feature indicating whether or not a sentence contains imperative mood expression. We de-fined 2 heuristic methods to determine the value of this fea-ture. The first heuristic method consists of some rules lever-aging only each word X  X  POS tag information (Penn Treebank tagset). The rationale of this method is that if the sentence contains verb which is not preceded by subject, then the sentence most likely contains imperative mood expression. The detail rules are as follow. 1. If first word X  X  POS is either VB (verb, base form) or 2. If first word X  X  POS is RB (adverb) and second word X  X  3. Starting from any word position whose POS is either
We use Stanford Dependency Parser http://framenet.icsi.berkeley.edu 4. Other conditions: no imperative mood expression found
The second heuristic method can be easily explained us-ing an algorithm. If the sentence contains at least one verb without any subject attached, then it most likely con-tains imperative expression. Given initial set of detected verbs in the sentence, the algorithm eliminates any verb contained in the list which acts as governor in following de-pendency relation:  X  X ominal subject X  ( nsubj ),  X  X lausal sub-ject X  ( csubj ),  X  X lausal passive subject X  ( csubjpass ),  X  X assive nominal subject X  ( nsubjpass ),  X  X uxiliary X  ( aux ),  X  X ontrolling subject X  ( xsubj ). To handle negative imperative expression such as  X  do not bring smartphone here  X , the algorithm pays attention on each auxiliary (aux) relation detected in the sentence. If governor of auxiliary relation is attached to any subject, then verb acting as dependent in the auxiliary rela-tion is also eliminated from the list. In the end, if the list is not empty, then the sentence contains imperative expression; otherwise it does not.

Feature E ( FE ) is binary feature indicating whether or not a sentence contains opinionated copula . A copula is the rela-tion between the complement of a copular verb ( is, am, are ) and the copular verb itself. For example, the sentence  X  it is better to bring umbrella  X  contains copula relation where word better acts as governor and word is acts as dependent. Opinionated copula means that the governor of the relation has subjectivity score above a given threshold. We found some evidences on our data showing that advice-revealing sentences contain opinionated copula. Suppose, w is a par-ticular word. Subjectivity score of the word w is determined by leveraging SentiWordNet [2], i.e., a well-known existing resource for sentiment analysis. It is also worth noting here that 0 6 Subjectivity ( w ) 6 1. If Subjectivity ( w ) is above a given threshold 3 value, then the sentence has opinionated copula; otherwise it does not.
We evaluated our proposed method on data crawled from travelblog.org 4 . Our data consists of weblog entries which tell about people X  X  travel experiences around the world. We selected 650 weblog entries using some clue words which in-dicate the presence of advices, such as suggest, advice, rec-ommend, tips, etc. Thus, we followed some pre-processing steps including sentence splitting. Finally, we judged man-ually whether or not a particular sentence reveals advice based on our definition of advice. Currently, we have al-ready labeled 207 weblog entries consisting 8,109 sentences. Table 2 describes our data in detail.

We also implemented method proposed by Kozawa et al. [3] for our baseline since they also addressed the task of advice-revealing sentence extraction. We had to do some modifications on their features since some of their features cannot be directly applied for English sentences. Their pre-constructed resources such as set of clue expressions and evaluative expressions are in Japanese language. Instead, we implemented their features using our own set of clue expres-sions and opinionated words obtained from SentiWordNet. Their features are summarized in table 3.

We used SVM as a machine learning tool since it is known to be the state-of-the-art algorithm for classification prob-
We use threshold of 0.69 http://www.travelblog.org Table 3: Features proposed by Kozawa et al. [3] for English data Feature Description lem. Table 4 shows the performance of our baseline method. In [3], FKD is shown to be a good feature. However, this is not true in our experiment. This is most probably be-cause we used a completely different set of expression clues and opinionated words. The best performance for baseline is achieved when we use FKA, FKB, and FKC at the same time, i.e., 0.309 in terms of F-score.
 Table 5 shows the performance of our proposed method. FD 1 is implementation of FD using first heuristic, i.e., set of rules using word X  X  POS information. Likewise, FD 2 is implementation of FD using second heuristic. Based on the results, FD 2 does not seem to be a good feature. But, when we use FD 1 and FD 2 as features at the same time, the performance is higher than individual feature X  X  perfor-mance. The best performance is achieved when all features are included. In this case, the F-score value reaches 0.586, which means that our proposed method is significantly bet-ter than the baseline on English data. Although it is not so significant, opinionated copula (FE) also improves the overall performance.

To see the contribution of each feature, we also measured the performance by excluding each feature. As the results FD (combination between FD 1 and FD 2) is the most im-portant feature in this task. Excluding FD 1 and FD 2 in the series of features decreases the performance as much as 21% from the best performance in terms of F-score. On the other hand, FB does not seem to be a good discriminator since excluding FB almost does not change the overall per-formance. The performance difference is just 0.3% from the best performance in terms of F-score.
We have shown first attempt to extract advice-revealing sentences from English weblogs. We also observed our data to discover the characteristics of those advice-revealing sen-tences. Based on this observation, we defined our task as classification problem using various linguistic features. Our experiments showed that our proposed method significantly outperforms the baseline. The presence or absence of im-We do not show the results here due to lack of space Table 5: Performance of our proposed method
FA+FB+FC+FD 1+FD 2+FE 0.523 0.665 0.586 perative mood expression appears to be the most important features in this task.

Despite the significant improvements, the results are still far short of the ideal situation yet. There are two future directions that we would like to do. First direction for fu-ture work would be to define better features so that advice-revealing sentences can be more accurately extracted. Sec-ond direction would be to work on other subtask on advice mining such as finding advice context. This research was supported by a Korean Government Scholarship Grant from the Ministry of Education, Science, and Technology (MEST), Republic of Korea. [1] Dalal, R. S. and Bonaccio, S. What types of advice do [2] Esuli, A. and Sebastiani, F. Sentiwordnet: A publicly [3] Kozawa, S., Okamoto, M., Nagano, S., Cho, K., [4] Lenhart, A. and Fox, S. Bloggers: A portrait of the [5] Pan, B., MacLaurin, R., Crotts, J.C. Travel blogs and [6] Pang, B. and Lee, L. Opinion mining and sentiment [7] Park, K., Jeong, Y., Myaeng, S. Detecting experiences [8] Travel Industry Association. Executive summaries -
