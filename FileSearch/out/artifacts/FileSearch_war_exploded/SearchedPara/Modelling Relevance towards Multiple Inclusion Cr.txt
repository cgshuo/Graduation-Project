 In the medical domain, information retrieval systems can be used for identifying cohorts (i.e. patients) required for clinical studies. However, a challenge faced by such search systems is to retrieve the cohorts whose medical histories cover the inclusion criteria specified in a query, which are often complex and include multiple medical conditions. For example, a query may aim to find patients with both  X  X upus nephritis X  and  X  X hrombotic thrombocytopenic purpura X . In a typical best-match retrieval setting, any patient exhibit-ing all of the inclusion criteria should naturally be ranked higher than a patient that only exhibits a subset, or none, of the criteria. In this work, we extend the two main existing models for ranking patients to take into account the coverage of the inclusion criteria by adapting techniques from recent research into coverage-based diversification. We propose a novel approach for modelling the coverage of the query inclu-sion criteria within the records of a particular patient, and thereby rank highly those patients whose medical records are likely to cover all of the specified criteria. In particular, our proposed approach estimates the relevance of a patient, based on the mixture of the probability that the patient is retrieved by a patient ranking model for a given query, and the likelihood that the patient X  X  records cover the query cri-teria. The latter is measured using the relevance towards each of the criteria stated in the query, represented in the form of sub-queries. We thoroughly evaluate our proposed approach using the test collection provided by the TREC 2011 and 2012 Medical Records track. Our results show significant improvements over existing strong baselines. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage &amp; Retrieval]: Information Search &amp; Retrieval
Electronic medical records (EMRs) have recently been de-ployed to improve healthcare services [12]. One of the im-portant applications is to leverage the EMRs within a search system to identify cohorts for clinical trials. An effective pa-tient ranking system plays a crucial role in identifying such relevant cohorts. Specifically, when conducting comparative effectiveness studies for a particular healthcare procedure (e.g. a diagnostic test), healthcare practitioners can use the system to search for cohorts (i.e. patients) having a medical history (in the form of medical records) relevant to a set of inclusion criteria [8, 30, 31], which are used as a query. It is essential to identify the patients whose medical histories are relevant to (i.e. cover) all of the inclusion criteria [8, 12]. Edinger et al. [8] showed that existing patient ranking sys-tems (e.g. [7, 14, 19]) fail in retrieving the patients whose medical records cover all of the criteria specified in a given query. In this paper, we propose to rank the patients whose medical histories are likely to cover all or most of the in-clusion criteria higher. For example, for a query identifying patients with  X  X eart disease X ,  X  X iabetes X  and  X  X lzheimer X  X  X , an effective patient ranking system should rank the patients who are diagnosed with all of the three diseases higher than those who suffer from only two or one of the conditions.
Existing works on patient ranking mostly focus on esti-mating the relevance of the patients without considering how many of the inclusion criteria the retrieved patients cover. There are two main groups of patient ranking models [18]. First, the so-called patient model ranking approaches (e.g. [7, 14]) represent a patient by combining the associated med-ical records into the form of a single patient document , and use the latter as a unit of retrieval. For example, Demner-Fushman et al. [7] effectively deployed the patient model by using a term weighting model (e.g. BM25 [25] or a language model [13]) to rank the patient documents. On the other hand, the so-called two-stage model ranking approaches (e.g. [19, 34]) initially rank the medical records based on their rel-evance towards the query, and then calculate the relevance of patients by aggregating the relevance scores of their as-sociated medical records that have been retrieved for the query. For example, Limsopatham et al. [19] used the exp-CombSUM voting technique from the Voting Model [20] to effectively aggregate the relevance scores for a patient. Later, Limsopatham et al. [18] showed that while in most cases the two-stage model approach based on the expComb-SUM voting technique outperformed the patient model, the differences in the retrieval performances were not significant.
However, none of the aforementioned approaches explic-itly aims to rank patients based on the probability that they are relevant to all or most of the query criteria. To deal with such a challenge, in this work, we propose to rank patients based on the relevance of their medical history towards a query, while also maximising the relevance towards a greater number of the specified inclusion criteria, within both the patient and the two-stage models. Inspired by recent work on coverage-based search result diversification [1, 26], we estimate the relevance of a patient towards the inclusion criteria based on the likelihood that a patient X  X  medical his -tory covers the set of inclusion criteria, measured using the notion of sub-queries [26]. To do so, we make use of the probability that a patient X  X  medical history is relevant to (i.e. covers) a sub-query representing a criterion extracted from the original query. While existing search result diver-sification techniques aim to generate a ranking that covers the possible interpretations of information needs, the goal of our proposed approach is to retrieve patients who are highly relevant to multiple inclusion criteria. In particular, we pro-pose to extend both the patient and the two-stage models to measure the relevance towards multiple inclusion criteria, while ranking patients. We demonstrate the effectiveness of our proposed approach in the context of the TREC 2011 &amp; 2012 Medical Records track. Our results show that our pro-posed approach significantly outperforms existing effective patient ranking baselines. The main contributions of this paper are four-fold: 1. We propose a novel extension for existing patient rank-2. We extract the inclusion criteria from a query by using 3. We describe different techniques to estimate a parame-4. We thoroughly evaluate our proposed approach us-
The remainder of the paper is organised as follows. Sec-tion 2 further discusses related work. Section 3 illustrates the problem that existing approaches could not effectively rank higher those patients who are relevant to more inclu-sion criteria stated in the query. Sections 4 and 5 intro-duce our approach to model relevance towards multiple in-clusion criteria for a particular patient by measuring the relevance towards each of the inclusion criteria using sub-queries, and our approach for extracting the inclusion cri-teria from a given query using a well-established domain-specific resource, respectively. Sections 6 and 7 discuss our experimental setup and the obtained results when the trade-off parameter is uniformly set. Section 8 discusses and eval-uates our proposed approach when using a regression tech-nique to automatically set the trade-off between the rele-vance probability towards a query and the likelihood of cov-ering the multiple inclusion criteria extracted from the query using training data. Section 9 analyses the retrieval per-formance of our approach. Finally, we provide concluding remarks in Section 10.
Existing patient ranking approaches do not explicitly model the relevance towards the multiple inclusion criteria that are stated in the query. For example, Demner-Fushman et al. [7] and King et al. [14] whose systems achieved the best retrieval performances at the TREC 2011 Medical Records track used the patient model to retrieve patients after enriching the medical records and/or queries using medical resources (e.g. UMLS Metathesaurus). Meanwhile, Limsopatham et al. [19] used the expCombSUM voting technique [20] to effectively retrieve patients based on the relevance of their medical records. The expCombSUM voting technique ranks the pa-tients who have a few medical records that are highly rel-evant to the query higher than those who have many par-tially relevant medical records. However, Edinger et al. [8] showed that these approaches could not effectively retrieve patients whose medical records were relevant to the multi-ple inclusion criteria stated in the queries. Later, Zhu and Carterette [34], whose system achieved the best performance at TREC 2012, showed that combining the relevance scores computed using both the patient model and the two-stage model further improved retrieval performance. Still, their approach did not take into account the relevance towards multiple inclusion criteria. A conceptual representation ap-proach (e.g. [16, 17, 23]) that represents documents and queries using medical concepts may be considered as im-plicitly ranking patients based on the relevance towards the inclusion criteria, assuming that the medical concepts in the query are the inclusion criteria. However, the conceptual representation approach does not explicitly model the prob-ability that the set of the inclusion criteria stated in the query are covered by the medical records of a patient. In contrast, in this work, we introduce a novel approach to ex-plicitly model the relevance towards the multiple inclusion criteria, which is inspired by existing works in the area of search results diversification. To the best of our knowledge, this is the first study on explicitly modelling the relevance towards several inclusion criteria when ranking patients.
Coverage-based search result diversification approaches aim to maximise the coverage of the possible interpretations of information needs within a set of retrieved documents. For example, Agrawal et al. [1] and Santos et al. [26] reranked documents to promote the maximum coverage of the pre-defined interpretations of the query, while minimising the redundancy of the documents. Unlike these approaches, we model the coverage of the multiple inclusion criteria within the subset of the retrieved medical records that are also as-sociated to a particular patient, in order to promote the patients whose medical records are likely to cover a higher number of the inclusion criteria.

Another research area related to this work is the term weighting regularisation approach to promote the coverage of query aspects within a given retrieved document [33]. In-deed, the approach to regularise term weighting based on the semantic relationship among the query terms increases the weight of the query terms that are not associated to the other query terms, while decreasing the weight of the terms that highly relate to the other terms. Different from this approach, we highly rank patients whose retrieved med-ical records cover the multiple inclusion criteria stated in a query, which are measured based on the relevance towards each inclusion criterion extracted from the query.
The aforementioned existing approaches rank patients based on their relevance to the query; however, they do not explic-itly promote the patients whose medical records are relevant to multiple query criteria. Indeed, the patient model (e.g. [7, 14]) estimates the relevance of a patient p for a query q , P ( p | q ), as follows: where the patient document D p is created by concatenating the medical records associated to the patient p . P ( D p which is the probability that D p is relevant to the query q , can be estimated using any probabilistic retrieval model, such as a language model [13].
Alternatively, the t wo-stage model (e.g. [19, 34]) estimates the relevance of a patient p , by suitably aggregating the relevance probabilities of the medical records associated to the patient p , as follows: where d i is a medical record in R p , which is the set of re-trieved medical records that are also associated to the pa-tient p . P ( d i | q ) is the probability that the medical record d is relevant to the query q (e.g. estimated using a language model [13]), while aggregate d i  X  R p [ ] can be calculated using any aggregate function, such as a voting technique [20].
Nevertheless, both the patient and the two-stage models may fail in ranking the patients for a query searching for patients with multiple health conditions, as discussed in the previous sections. We use Figure 1 to illustrate this prob-lem. Consider that a query q is to find patients with  X  X eart disease X  (i.e. criterion q 1 ),  X  X iabetes X  (i.e. criterion q  X  X lzheimer X  X  X  (i.e. criterion q 3 ), and that medical records d and d 2 are associated with the patient p 1 , while the medical records d 3 and d 4 are related to the patient p 2 . In Fig-ure 1(a), the patient model (as in Equation (1)), which esti-mates the relevance of each patient using the concatenation of the medical records of that patient (e.g. D p 1 and D p 2 ranks the patient p 1 higher than the patient p 2 , according to their relevance probabilities, towards the query q (0.9 vs. 0.8). Meanwhile, in Figure 1(b), the two-stage model, which estimates the relevance of patients by suitably aggregating the relevance of their associated medical records (as in Equa-tion (2)), also ranks the patient p 1 higher than the patient p . For instance, CombSUM estimates the relevance prob-relevance probabilities of their associated medical records (e.g. after normalising, the relevance probabilities of patient p 1 and p 2 are 0.57 and 0.43, respectively). However, as previously discussed, an effective patient ranking approach should rank the patient p 2 higher than the patient p 1 , as the patient p 2 is relevant to more criteria in the query q than the patient p 1 ( q 1 , q 2 , q 3 vs. q 1 , q 2 ).
Denoting the probability that a patient p is relevant to a query q as P ( p | q ), and the likelihood that p is relevant to the multiple inclusion criteria stated in the query q as P c ( p | q ), an effective patient ranking model denoted by F ( p | q ) must have the following two properties, which promote patients who are likely to be relevant to multiple query criteria: Property 1: If P ( p 1 | q ) = P ( p 2 | q ), then a patient p be ranked higher than a patient p 2 , F ( p 1 | q ) &gt; F ( p P ( p 1 | q ) &gt; P c ( p 2 | q ).
 Property 2: If P ( p 1 | q ) 6 = P ( p 2 | q ), then F ( p when P ( p 1 | q ) L P c ( p 1 | q ) &gt; P ( p 2 | q ) L P an appropriate mixture of the two probabilities.
In this section, we propose to build a probabilistic model that satisfies the two properties previously discussed in Sec-tion 3. Specifically, our proposed approach models the mix-ture of the relevance towards the query and the likelihood of covering the inclusion criteria extracted from the query, to promote the patients whose medical records are relevant evance probabilities to maintain probability estimates. to a higher number of the inclusion criteria. Our proposed approach can be calculated as follows: where P ( p | q ) is the probability that the patient p is relevant to the query q (i.e. the relevance probability ), which can be measured using any existing patient ranking approach (e.g. Equations (1) or (2)); P c ( p | q ) is the likelihood that the med-ical records of the patient p cover the multiple inclusion cri-teria stated in the query q (we refer to this as the cover-age likelihood ), and  X  is a mixture parameter to weight the proach to promote the patients whose medical records cover several query criteria, which may not be measured when us-ing existing patient ranking approaches.

Given a set Q = { q 1 ; q 2 ; :::; q n } containing the inclusion criteria stated in the query q , we propose to estimate the coverage likelihood P c ( p | q ) as the combination of the beliefs that each criterion (i.e. akin to a sub-query) q i in Q is cov-ered by the medical records of the patient p , as follows: where P ( p | q i ) is the probability that the patient p is relevant to the criterion q i in Q . bel is a belief combination function, such as AND and OR, to combine the probabilities that the medical records of the patient p cover each inclusion crite-rion. Indeed, the belief combination functions have been extensively deployed within search approaches (e.g. [21, 24, 29]) to combine the probabilities that a particular document is relevant to each query term. For instance, bel AND can be calculated as [21]:
In the remainder of this section, we discuss how our pro-posed approach can be applied within the existing patient and two-stage ranking models, respectively. Then, in Sec-tion 5, we describe our technique to extract the inclusion criteria from a query.
Within the patient model, our proposed approach can be adapted by inserting Equations (1) and (4) into Equa-tion (3), as follows: where  X  is a mixture parameter that weights the impor-tance of the relevance probability and the coverage likeli-hood. Specifically, the first part of the equation, (1  X   X  ) P ( D p | q ), focuses on the relevance probability of the patient document D p towards the query q . The second part of the equation calculates the coverage likelihood of D p . We use P ( D p | q i ) to measure the likelihood that D p covers a partic-ular inclusion criterion q i .
As shown in Figure 1(b), the two-stage model firstly ranks the medical records, and then suitably aggregates their rel-evance probabilities to rank the associated patients. Hence, we can model the mixture of the relevance probability and the coverage likelihood either at the stage of ranking patients (Section 4.2.1), or at the stage of ranking medical records (Section 4.2.2).
First, we can model the mixture of the relevance proba-bility and coverage likelihood at the patient ranking stage of a two-stage model by inserting Equations (2) and (4) into Equation (3), as follows:
In contrast, at the medical record ranking stage, the two-stage model considers each medical record individually, be-fore suitably aggregating the relevance probabilities of the medical records to estimate the relevance of their associated patients. The existing aggregation techniques, such as the voting techniques, cannot take into account the coverage of the multiple inclusion criteria among the medical records of a particular patient. Indeed, without alteration, the medical record ranking stage of the two-stage model cannot exam-ine the fact that a particular medical record may cover an inclusion criterion that the other medical records associated to the same patient do not cover. Thus, to highly rank the patients whose medical records cover the multiple inclusion criteria of the query, we need a mechanism to measure how well each of the inclusion criteria stated in the query is cov-ered by different medical records of a particular patient. To achieve this, we introduce the notion of criterion novelty , which is the probability that a criterion is not well covered by the medical records that are also associated to the same patient. For instance, in the example of Figure 1(b), after considering the criterion novelty, the coverage likelihoods of the medical records d 3 and d 4 are boosted, since both of them cover at least one new criterion that is not covered by the other medical records associated to the same patient. Consequently, the patient p 2 , which is associated to the med-ical records d 3 and d 4 , is likely to be ranked higher than the patient p 1 . To integrate the criterion novelty at the medi-cal record ranking stage of the two-stage model, we adapt Equations (3) and (4) to estimate the relevance probability and the coverage likelihood of the medical record d i , before using Equation (2), as follows: where P ( R p n d i | q i ) is the criterion novelty of q mate the criterion novelty, we resort to techniques (e.g. [1, 4]) from web search result diversification that measure the novelty of a document within a set of web search results, based on the probability that the document covers an inter-pretation of information need that is not well covered by the other documents in the result set. In this work, we adapt an existing state-of-the-art technique for search result diversifi-cation (namely, xQuAD [26]) to estimate the criterion nov-elty within our approach, since it has been shown to be effec-tive for diversifying web search results over several successive TREC tracks (e.g. [26, 27]). However, other techniques that explicitly model the novelty of a document within a set of search results (e.g. IA-Select [1]) can also be adapted.
Specifically, for a given query q and a patient p , we adapt xQuAD [26] to iteratively rerank the medical records in R by maximising the mixture of the relevance probability and the coverage likelihood within Equation (8). By assuming the independence of the inclusion criteria within the query, P ( R p n d i | q i ) can be estimated as Q d when calculating the mixture probability:
F ( p | q )  X  aggregate d i  X  R p where Q d the criterion q i is not well covered by any medical records in R d and that are also associated to the patient p .
As discussed in Section 4, to measure the coverage like-lihood, we need to extract the set of the inclusion criteria Q (as used in Equations (6), (7), and (9)) from a query q and use the extracted inclusion criteria as sub-queries. Im-portantly, the quality of the extracted sub-queries can affect the effectiveness of our proposed approach. For example, if the sub-queries are not a good representative of all of the inclusion criteria stated in the query, our approach may not be able to highly rank the patients whose medical records cover all or at least most of the inclusion criteria expected by the searchers. When diversifying web search results, San-tos et al. [26] use as sub-queries the recommended queries suggested by a commercial web search engine for the origi-nal query. It has been shown in the literature that the in-clusion criteria that healthcare practitioners focus on when Figure 2: Medical concepts extracted by the M etaMap tool from query 102:  X  X atients with di-abetes mellitus who also have thrombocytosis X , as the query inclusion criteria.
 Table 1: Statistics of the inclusion criteria extracted from the queries searching the medical records often relate to four types of th e medical conditions of patients (namely, symptom, diagnostic test, diagnosis, and treatment) [16, 17]. Consequently, we follow [16] and deploy MetaMap [3] to extract the medical concepts related to these four types of medical conditions from the query. Importantly, we use the textual definitions of the extracted concepts as sub-queries. As MetaMap can generate a number of candidate concepts when mapping a given phrase, we select only those that are defined as  X  X eta Mapping X , which are the concepts identified with the high-est confidence for a particular phrase in order to improve the accuracy and to avoid the redundancy of the extracted inclusion criteria. For example, in Figure 2, for the query  X  X atients with diabetes mellitus who also have thrombocy-tosis X , we extract two inclusion criteria,  X  X iabetes Mellitus X  and  X  X hrombocytosis X , both of which are diagnosis concepts identified using MetaMap.
In this section, we discuss our experimental setup to evalu-ate the effectiveness of our proposed approach for modelling the coverage of the inclusion criteria. In particular, Sec-tion 6.1 describes the used test collection, while Section 6.2 discusses the ranking approaches used in our experiment.
We evaluate our proposed approach using the test collec-tion provided by the TREC 2011 and 2012 Medical Records track [30, 31], which aims to retrieve patient visits based on the relevance of their associated medical records towards a query. To avoid privacy issues, a visit, which contains a set of medical records associated to a patient during a visit to the hospital, is used as a representative of a patient [30, 31]. The test collection consists of 101,710 medical records, which are associated to 17,265 patient visits, and includes 34 and 47 queries from TREC 2011 and 2012, respectively. A query describes the compulsory medical conditions of the targeted patients. For example, query 149 is  X  X atients with delirium, hypertension, and tachycardia X .

Table 1 shows the statistics of the inclusion criteria ex-tracted from the queries, using our approach discussed in Section 5. For example, we find that on average we extract more inclusion criteria from the queries from TREC 2011 than those from TREC 2012 (i.e. 4.32 vs. 3.36 inclusion cri-teria per a query). The highest numbers of inclusion criteria extracted from a query are 13 (2 queries) and 17 (1 query), for TREC 2011 and 2012, respectively.

We evaluate the retrieval effectiveness using the track X  X  official measures, namely bpref for TREC 2011 and inf-AP &amp; infNDCG for TREC 2012 [30, 31]. In addition, we measure significant differences between the retrieval perfor-mance achieved by our approach and the existing patient ranking baselines using the paired t-test ( p &lt; 0 : 05).
We conduct experiments using the Terrier retrieval plat-stopwords. In addition, as handling negated language is a common, effective practice for this patient ranking task [7, 14, 15], we follow Limsopatham et al. [15] and tokenise term occurrences with a positive (e.g. patient has nausea) or neg-ative context (e.g. patient has no nausea) differently, so that our search system can distinguish between terms with posi-tive and negative contexts in both the medical records and the queries. For example, a term  X  X ausea X  is tokenised as  X  X ausea X  or  X  X $nausea X , if it occurs in a positive or negative context, respectively.
As representatives of the patient model, we follow King et al. [14] and concatenate the medical records associated to the same patient to create a patient document (discussed in Section 3). We estimate the relevance towards a given query of the patient documents using DPH from the Divergence from Randomness (DFR) framework [2], and BM25.
Since the voting techniques have been shown to be effec-tive for this TREC patient ranking task [18, 19], we use the two-stage model approaches based on the CombSUM, exp-CombMNZ, and expCombSUM voting techniques [20], as al-ternative baselines. Table 2 describes how each of the three used voting techniques estimates the relevance of a given pa-tient. We follow Limsopatham et al. [19] and use DFR DPH to rank medical records at the first stage of the model, and limit the number of voting medical records to 5,000.
Another possible baseline is to use a boolean model to re-trieve patients whose medical records contain all of the ex-tracted inclusion criteria (i.e. the textual definitions of the medical concepts extracted from the query, as discussed in Section 5); however, we find that the boolean model is not ef-fective, as it retrieves patients for only 6 out of the 34 queries of TREC 2011 and 16 out of the 47 queries of TREC 2012 (i.e. for some queries, the medical records of relevant patients may not contain all of the textual definitions of the extracted query criteria). Hence, it is excluded from the paper. We evaluate our proposed Inclusion Criteria Coverage (IC-Cover) approach within both the patient and the two-stage models by deploying the same ranking techniques as those of the corresponding baselines. Indeed, we apply our proposed approach within the patient model (denoted IC-Cover-P ) h ttp://terrier.org Table 2: Voting techniques used in our experiments. as in Equation (6) and use either BM25 or DFR DPH to e stimate the relevance of a patient. Next, for the two-stage model, we apply our proposed approach either within the patient ranking stage (denoted IC-Cover-2P ), as in Equa-tion (7), or within the medical record ranking stage (de-noted IC-Cover-2R ), as in Equation (9). Specifically, we deploy DFR DPH to estimate the relevance of the medical records, while using the CombSUM, expCombSUM, or exp-CombMNZ voting technique to estimate the relevance of a particular patient. In addition, similar to the baselines, we also limit the number of voting medical records to 5,000. Mixture Parameter Setting: Initially, we uniformly set the mixture parameter  X  in Equations (6), (7) and (9) to 0.5 for every query. This gives an equal emphasis on both the relevance probability and the coverage likelihood, of a par-ticular patient. Later, in Sections 7.2 and 8, we analyse the effect of  X  and discuss how to automatically learn a suitable  X  value for a given query from training data, respectively. Belief Combination Function: We evaluate our pro-posed approach using three different belief combination func-tions (namely, AND , OR , and SUM ), which have been shown to be effective for different search tasks [21, 24, 29]. Specifi-cally, the belief combination functions AND, OR, and SUM combine the coverage likelihood as follows [21, 29]: where | Q | is the number of inclusion criteria in the set Q = { q 1 ; q 2 ; :::; q n } .
This section presents the experimental results obtained using our proposed approach. Specifically, Section 7.1 exam-ines the effectiveness of our proposed approach compared to the baselines, when our mixture parameter  X  is set to equally weight the relevance probability and the coverage likelihood. Section 7.2 discusses the robustness of our proposed ap-proach, as we vary the parameter  X  . Then, in Section 8, we introduce and evaluate a technique to automatically set  X  using training data. We further discuss and analyse the retrieval performance of our approach in Section 9.
We first compare the retrieval performance of our pro-posed approach, when the mixture parameter  X  is uniformly set to 0.5 to balance the importance of the relevance prob-ability and the coverage likelihood, with existing effective baselines, including the patient and the two-stage models, discussed in Section 6.2. As we will show later in Sections 7.2 and 8.3, this will prove to be a very effective parameter value for  X  . Table 3 compares the retrieval effectiveness of our approach with the baselines, in terms of bpref for TREC 2011 and infNDCG &amp; infAP for TREC 2012. Moreover, the number of queries that our proposed approach improves or harms compared to the corresponding baselines is also re-ported. The remainder of the queries are unaffected. For ease of notation, in Table 3, the used belief combination function along our proposed approach is indicated between parentheses. For instance, for IC-Cover-P(AND), we apply our approach within a patient model and use the belief com-bination function AND to combine the probabilities that the medical records of a patient cover the multiple inclusion cri-teria extracted from the query.

From Table 3, we observe that applying our proposed approach within the medical record ranking stage of the two-stage model (i.e. IC-Cover-2R) is effective. For exam-ple, when using the CombSUM voting technique, IC-Cover-2R(OR) and IC-Cover-2R(SUM), which use the belief com-bination functions OR and SUM, respectively, significantly (paired t-test, p &lt; 0 : 05) outperform the CombSUM-based baseline, for every reported measure across both TREC 2011 and 2012. In addition, when using the expCombSUM voting technique, IC-Cover-2R(OR) and IC-Cover-2R(SUM) im-prove the retrieval performances over the expCombSUM-based baseline by up to 4.77%. The performance improve-ment is statistically significant (paired t-test, p &lt; 0 : 05) for TREC 2011. On the other hand, we find that the belief combination function AND is not effective for our proposed approach. We also observe that the expCombMNZ voting technique is not effective when used in conjunction with our approach. This might be due to the fact that the exp-CombMNZ voting technique also considers the number of retrieved medical records associated to a particular patient when estimating the relevance of that patient, which could outweigh the coverage likelihood within our approach. Next, when applied within the patient model (i.e. IC-Cover-P), our proposed approach markedly improves the re-trieval performance by up to 9.13% compared to the corre-sponding baselines. For example, when using BM25, the re-trieval performances of IC-Cover-P(SUM) are bpref 0.5315, infNDCG 0.4286 and infAP 0.1959, while the retrieval per-formances of the BM25 baseline are bpref 0.4870, infNDCG 0.4080, and infAP 0.1922. Even though the performance improvements are not statistically significant, our approach improves the retrieval performances for about half of the queries. For example, when using BM25, IC-Cover-P(SUM) improves the retrieval performance over the BM25 baseline, in terms of bpref, for 19 out of 34 queries from TREC 2011, while for TREC 2012 it benefits 24 and 23 out of 47 queries, in terms of infNDCG and infAP, respectively.

When applied within the patient ranking stage of the two-stage model, we observe that our approach (i.e. IC-Cover-2P) is not effective. For example, when using the Comb-SUM voting technique, our IC-Cover-2P(OR) performs only comparably to the CombSUM-based baseline (e.g. infNDCG 0.3361 vs. 0.3304). This is likely because when applied within the patient ranking stage of the two-stage model, the used voting techniques tend to give very high relevance probabilities to the patients who are relevant to a single particular criterion. Hence, when using a belief function (i.e. AND, OR, or SUM) to combine the likelihoods that the medical records of the patients cover the multiple inclusion criteria, the highly ranked patients could be relevant to only one or few criteria. (resp. harmed) in relation to the corresponding baseline.
Overall, we conclude that our approach to model the rele-v ance towards multiple inclusion criteria applied either within the patient model or within the medical record ranking stage of the two-stage model is effective for the patient ranking task. In addition, we find that the belief combination func-tions SUM and OR are effective for combining the likeli-hoods that the medical records of a patient cover each of the inclusion criteria stated in the query.
This section investigates the robustness of our proposed approach by varying the mixture parameter  X  that weights the importance of the relevance probability and the coverage likelihood. To analyse the impact of the parameter  X  within our approach, we experiment setting  X  within a range of val-ues between 0 and 1, with an interval of 0.1. When  X  = 0, our proposed approach considers only the relevance probability towards the query, while when  X  = 1 our approach takes into account only the coverage likelihood. Due to space limita-tion, in Figure 3, we report only the experiment on TREC 2011. We found that the experimental results on TREC 2012 follow the same pattern. In addition, for readability pur-poses, while we only show the retrieval performances of our approach using the most effective belief combination func-tion (namely SUM as shown in Table 3), the results with the belief combination function OR are consistently similar, although slightly less effective in magnitude.

From Figure 3(a), we observe that when applied within the patient model (using either BM25 or DPH), our ap-proach (i.e. IC-Cover-P) performs better than the baseline (i.e.  X  = 0), when 0 : 1  X   X   X  0 : 8. Hence, our approach is robust when applied within the patient model, as it is more effective than the baseline for a very wide range of  X  values (in fact for all  X  values when using BM25). In addi-tion, the most effective performance is achieved when  X  is set to 0.2 and 0.6 when using BM25 and DPH, respectively. Next, Figure 3(b) shows the retrieval performances of our approach when applied within the patient ranking stage of the two-stage model (i.e. IC-Cover-2P). We observe that our approach is not effective, which is in line with the observa-tion in Section 7.1. Meanwhile, in Figure 3(c), when applied within the medical record ranking stage (i.e. IC-Cover-2R), our proposed approach markedly outperforms the baseline (  X  = 0) for a wide range of  X  values. For CombSUM, when 0 &lt;  X   X  1, our approach outperforms the baseline, especially for  X  values closer to 1. For expCombSUM, our approach performs better than the baseline when 0 : 1  X   X   X  0 : 9, while the most effective performance is obtained when  X  = 0 : 7. On the other hand, Figure 3(c) shows that applying exp-CombMNZ in conjunction with our approach is not effective, which supports the finding discussed in Section 7.1.
To summarise, we find that our proposed approach is ef-fective and robust when applied within the patient model or when applied within the medical record ranking stage of the two-stage model. This shows the importance of pro-moting patients relevant to multiple query criteria for the patient ranking task. Specifically, as shown in Figure 3, our approach is effective when setting  X  uniformly for a wide range of values (particularly 0 : 2  X   X   X  0 : 7). In the next section, we show how to automatically set the parameter  X  for each query, using training data.
This section discusses an automatic technique to set the mixture parameter  X  . We hypothesise that queries benefit from different levels of emphasis on the relevance probabil-ity and the coverage likelihood. For example, a query that contains several inclusion criteria may benefit from more em-phasis on the coverage likelihood. Within the xQuAD frame-work, Santos et al. [27] also suggested to selectively set the level of diversification based on the ambiguity of the query.
In this work, we deploy Gradient Boosted Regression Trees (GBRT) [28] to learn the parameter  X  from a set of train-ing queries, since GBRT has been shown to be effective for several regression tasks (e.g. [9, 18, 28]). We use the jforest  X  between 0 and 1.
 package implementation [9] 3 w ith the default settings. How-ever, any regression technique can be deployed. To train a regression model, the root-mean-square error (RMSE) is used as a loss function when learning  X  .
To estimate an effective mixture parameter  X  , we identify the  X  that attains the best retrieval performance in terms of a particular retrieval measure (e.g. bpref or infNDCG) for each training query. In particular, for a given query, we sweep the  X  between 0 and 1 (with an interval of 0.1) to find the best setting of  X  . Then, the set of the identified  X  from the training queries are used as the labelled data to train the regression model for choosing  X  for an unseen query.
Next, we define the features used for choosing the effective parameter  X  for an unseen query. An effective feature should indicate the level of emphasis on the relevance probability and the coverage likelihood for each query. In this work, we use 23 features, which measure the predicted difficulty of the query. A query with multiple inclusion criteria tends to be complex and long; hence, it can be assumed to be dif-ficult. If the query is difficult, then it might be beneficial to focus on the coverage likelihood. Table 4 lists the two groups of features used in this experiments. The first group of features are the 12 query performance predictors [5, 6, 32] computed on the original query, which are well-known for measuring the difficulty of a query. The second group of features are the 11 semantic similarities [10], which can esti-mate the similarity between the inclusion criteria extracted from the original query. The more dissimilar the inclusion criteria in the query, the more difficult the query is likely to be, since it may be difficult to find a patient with such unrelated conditions specified by the inclusion criteria. We sures [10] and average the similarity scores among every pair of the medical concepts extracted as inclusion criteria by the approach described in Section 5.
Due to the difference between the used methods for the relevance assessment in TREC 2011 and 2012 [30, 31], we h ttp://code.google.com/p/jforests/ deploy a 5-fold cross-validation on the 34 and 47 queries of TREC 2011 and 2012, respectively, where each fold has completely separated training and test query sets.
We compare the retrieval performance of our approach when using the cross-validation setting to learn the mixture parameter  X  (i.e. 5-fold) with uniform settings of  X  , namely  X  = 0 (i.e. the focus is only on the relevance probability to-wards the query),  X  = 1 (i.e. the focus is only on the coverage likelihood), and  X  = 0.5 (i.e. equally weight the importance of both the relevance probability and the coverage likeli-hood). In addition, the best possible retrieval performance, when the mixture parameter  X  is optimally set for every query (i.e. an oracle), is also reported. For space reasons, we show only the experiments with our proposed approach when applied within the patient model (i.e. BM25) and us-ing the belief combination function SUM, since it is the most effective approach as shown in Figure 3(a); however, we were also able to find effective  X  values when using the learned technique on the other variants of our proposed approach.
Table 5 reports the retrieval performance of our proposed approach when the mixture parameter is set in various man-ners. From Table 5, we observe that our approach with the learned  X  (5-fold) is effective, as it outperforms all of the uniform setting baselines (i.e. when  X  is set to 0, 1, or 0.5). In particular, for TREC 2011, our cross-validation setting improves the retrieval performance over the baseline where  X  = 0 by up to 9.8% (bpref 0.5346 vs. 0.4870). Indeed, it improves the retrieval performance for the majority of the queries (i.e. 18 of 34 queries). For TREC 2012, in terms of infNDCG, our cross-validation setting significantly outper-forms the settings where  X  = 0 and  X  = 1 (paired t-test, p &lt; 0 : 05). The performance improvements are up to 7.5% and 16.5%, respectively. Specifically, our cross-validation setting outperforms the baseline that does not take into ac-count the coverage likelihood (i.e.  X  = 0) for 24 out of 47 queries. Meanwhile, in terms of infAP, our cross-validation setting (infAP 0.2066) significantly outperforms the base-line where  X  = 1 (infAP 0.1585). However, even though the cross-validation setting outperforms the setting where  X  = 0.5 for all of the reported measures, the improvements are not significant. We find that setting  X  = 0.5 is an effective baseline, since it can improve the retrieval performance for most of the queries improved by the oracle. For instance, for TREC 2012, the setting where  X  = 0 : 5 improves the re-trieval performance, in terms of infNDCG, over the baseline where  X  = 0 for 24 out of 47 queries, while the oracle setting improves the retrieval performance for 30 out of 47 queries.
In addition, our approach, when  X  is set either to 0.5 (i.e.  X  = 0 : 5) or to a learned value (i.e. 5-fold), markedly outperforms the median of 127 and 88 participating sys-tems at TREC 2011 and 2012, respectively. In particular, our approach performs comparably to the best system of TREC 2011 (bpref 0.5346 vs 0.5520). This is despite the f act that we only focus on investigating an effective mod-elling of the relevance towards inclusion criteria, while most of the TREC participating systems deployed several sophis-ticated techniques (e.g. information extraction, query expan-sion) to deal with other unique characteristics (e.g. the use of acronyms) of the medical records in the patient ranking task. For TREC 2012, we observe that the best TREC sys-tem performs better than our approach. This system applied a query expansion technique, which is typically used by effec-tive systems at TREC. However, we do not use query expan-sion in our current approach. We leave for future work the extension of our approach to use query expansion to improve the representation of each of the query inclusion criteria.
Next, we discuss the retrieval performances assuming we can effectively set the  X  for all of the queries (i.e. oracle). We observe that with the oracle setting, our approach fur-ther improves the retrieval performances markedly. It sig-nificantly (paired t-test, p &lt; 0 : 05) outperforms all other settings in Table 5. In addition, we find that it improves the retrieval performances over the corresponding baselines where the coverage likelihood is not taken into account (i.e.  X  = 0) for the majority of the queries (i.e. 24 out of 34 queries for TREC 2011, 30 out of 47 queries for infNDCG TREC 2012, and 29 out of 47 queries for infAP TREC 2012). These results show the potential of our proposed approach, and suggest that there is room for further improvements.
In this section, we analyse the retrieval performance of our approach for each query, when using the cross-validation setting discussed in Section 8.3. Table 6 shows, for var-ious numbers of extracted inclusion criteria, the numbers and percentages of the queries impacted (either positively or negatively) by our proposed approach. The impacted performances are measured based on bpref and infNDCG because they are the primary measures for TREC 2011 and TREC 2012, respectively [31]. We divide the 81 queries from TREC 2011 (34 queries) and 2012 (47 queries) into 4 groups, according to the number of the extracted inclu-sion criteria in the queries, and report the percentages of queries for each group. The sizes of the groups vary from 14 to 30 (average of 20.25) queries. From the cross-validation setting, we observe that our approach is most likely to ben-efit (63%) the queries with 3 inclusion criteria, followed by the queries having a number of inclusion criteria between 4 and 17 (57%). This is in line with the oracle setting where the queries for which the number of extracted criteria is at least 3 are most likely (more than 70%) to benefit. On the other hand, for the queries with 1 or 2 inclusion criteria, our approach is less likely to be beneficial (e.g. 43% and 39% for the queries with 1 and 2 inclusion criteria, respec-tively), which is intuitive. Indeed, as our approach aims to Table 6: Analysis of our approach w.r.t. the num-ber of inclusion criteria extracted from the queries. The numbers between the parentheses indicate the percentage compared to the total number of queries. promote the relevance towards multiple inclusion criteria, q ueries that contain only very few criteria may not bene-fit much from our approach (e.g. queries 109, 143, 147 and 154). However, we also observe improvements for queries with one inclusion criterion, since our approach enables the retrieval system to focus on the inclusion criterion instead of the non-important terms in the queries. In contrast, our pro-posed approach tends to be effective for long and complex queries (i.e. the queries with at least 3 inclusion criteria), such as queries 111, 113, 121 and 176. For example, for query 121: X  X atients with CAD who presented to the Emer-gency Department with Acute Coronary Syndrome and were given Plavix X , our approach can improve the retrieval perfor-mance to bpref 0.4088, while the performance of the patient model baseline is bpref 0.1869. This is because the patient model, which uses a patient ranking model to estimate the relevance probability of the patients, tends to focus on the occurrences of informative terms (e.g. Plavix) within the medical records. However, the relevant patients are also re-quired to be relevant to the other conditions, indicated by occurrences of the other query terms, such as acute, coro-nary, and syndrome. Meanwhile, our proposed approach is effective since it promotes the patients who are relevant to multiple inclusion criteria (e.g.  X  X AD X ,  X  X cute Coronary Syndrome X , and  X  X lavix X ).

On the other hand, when looking at the harmed queries, we observe that the queries with 3 and 4-17 inclusion cri-teria are also more likely to be harmed by our proposed approach than the queries with 1 or 2 inclusion criteria. Because of the limited number of queries (i.e. we use a 5-fold cross-validation on two separate sets of only 34 and 47 queries when learning the regression model), we find that the learned model could not always generalise, as it tends to favour the coverage likelihood for the queries with several inclusion criteria, while focusing on the relevance probability for the queries with a very few inclusion criteria.
Moreover, when investigating the effectiveness of each query, we find that some queries do not benefit from our approach, because the used MetaMap tool could not effectively ex-tract the inclusion criteria (e.g. queries 104, 107, 146 and 149). For example, instead of only 2, 13 inclusion crite-r ia are incorrectly extracted from the query 104:  X  X atients diagnosed with localized prostate cancer and treated with robotic surgery X . Consequently, this misleads the estimation of the coverage likelihood. We leave for future work the in-vestigation of a more effective inclusion criteria extraction technique.
We have discussed the importance of ranking highly pa-tients whose medical records cover the multiple inclusion cri-teria stated in the query when retrieving patients for clinical studies. To achieve this, we have proposed a novel approach for modelling the mixture of the relevance probability to-wards the query and the likelihood that the medical records of a patient are relevant to the multiple inclusion criteria occurring in the query (i.e. the coverage likelihood). We measured the coverage likelihood using the relevance prob-ability towards each of the inclusion criteria, represented as medical concepts extracted from the query using an existing medical resource. We showed how our approach can be ap-plied within the state-of-the-art patient ranking models (i.e. the patient and the two-stage models). When applied within the patient model or at the medical record ranking stage of the two-stage model, our approach significantly improved the retrieval performance over both of the state-of-the-art patient ranking models. Moreover, we showed that our pro-posed approach was effective, either by weighting equally the importance of the relevance probability and the cover-age likelihood or by deploying a regression technique to learn an effective setting of the mixture parameter.

Through the experiments, we showed that our proposed approach was robust, as it improved the retrieval perfor-mances for a wide range of the mixture parameter X  X  values, especially when the parameter is set between 0.2 and 0.7. When analysing the retrieval performances for each query, we found that our approach tended to particularly improve the retrieval performances for queries from which at least 3 inclusion criteria could be extracted.
