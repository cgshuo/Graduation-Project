 which is called a Web object [1]. A web object can be further segmented into atomic ute name to each object element are necessary for Web data integration [1], which can meta-search etc. ways ahead of its description in all the pages. Conditional Random Fields (CRFs) are sequence labeling. For instance, on online bookselling sites, the existing CRFs can not guarantee the uniqueness of all semantic labels in a book object. 
To improve the accuracy of semantic annotation, a Constrained Conditional Ran-model extends CRFs models to support a variety of constraints. It introduces a novel inference procedure based on integer linear programming (ILP) to replace traditional Viterbi inference. The modeling allows one to add logical constraints over the seman-Web object. than traditional CRFs for semantic annotation of Web objects. The rest of this paper is organized as follows. First, the related work is discussed in Section 2. Then, the concepts of traditional CRFs are introduced in Section 3. In Sec-perimental setup and results are showed. Finally, the conclusion is presented. There has been much work in the field of semantic annotation for Web objects. Em-with the closest labels on result pages. However, this method has limited applicability because many sites do not encode data units with their labels on result pages. 
CRFs[2] are the state of the art approaches in information extraction taking the se-fields, such as NLP tasks, IE etc. Although some researchers have tried to incorporate the constraints into Viterbi algorithm used for inference in CRFs, it can only support with certain types of constraints, but the types of constraints may only disallow some labels or ensure that some object elements are assigned some labels. It can not process more complex constraints. 
The idea of inference using ILP has been attempted in previous work. Dan Roth et approach does not apply to semantic annotation of web objects so far. Semantic anno-to incorporate logical constraints into semantic annotation for web objects. exponential distribution over label sequences given a particular observation sequence. over a finite label alphabet y . In a discriminative framework, CRFs construct a condi-bels. Formally, the definition of CRFs [2] is given subsequently: graph: {} (|, ) (|, ) except the node v and v N is the set of neighbors of the node v in Graph G . 
Thus, Conditional Random Fields are Markov Random Fields globally conditioned xx x = K has the form, factor, also know as partition function, which has the form, Training of CRFs requires estimating the values of the weight set,  X  , which is usually done by maximizing the log-likelihood of a given training set. Popular training meth-ods include generalized iterative scaling, conjugate-gradient and limited-memory quasi-Newton [10]. 
Inference in CRFs is done by finding the most probable label sequence, * y , for an input sequence x, given the model in equation (1): is defined over each pair of labels , yy Y  X  X  X   X  start and end respectively, the sequence probability is the most likely label sequence. CRFs are the state-of-the-art approaches in information extraction taking the sequence annotation of Web objects, which extends Linear-Chain CRFs and incorporates a variety of logical constraints. 4.1 Model In this section, a Constrained CRFs model is presented, which can deal with a variety of constraints. Definition 2. Let , GXY = be a Linear-Chain CRFs, X denotes the random variable Chain CRFs with logical constraints are called Constrained Conditional Random Fields (Constrained CRFs). yy y = K be a corresponding label sequence. The conditional probability for y given x and c to be  X  is a learnt weight associated with makes the probabilities of all label sequences sum to one, which has the form, 4.2 Parameter Estimation training samples. For Constrained CRFs, the log likelihood is given by where the term likelihood in order to avoid over-fitting, and 2  X  is a variance. cave function. Each element of the gradient vector is given by expectation with respect to distribution p . 4.3 Inference The Viterbi algorithm is often used for infere nce in CRFs. It has been extended, as is And it can not deal with more complex constraints, for example, no duplicate seman-tic labels within the same web object. Ther efore, it is necessary to incorporate a new gramming (ILP) can easily incorporate logical constraints. Logical constraints can be section, we first transform the inference procedure of CRFs into the problem that ILP has modeled. Then the inference procedure is modeled by ILP. At last, the construc-tion and incorporation approaches of logical constraints are presented. 4.3.1 Transformation of Inference Problem As the shortest path problems have been modeled in ILP[11], the inference procedure follows [7]. 
Let n be the number of object elements in the observation sequence, and m be the number of labels each object element can take. In addition to two special nodes start section 3. 
Fig. 1 illustrates the graph. As is shown in the graph, the path from start to end will path. Then, algorithm. 4.3.2 Shortest Path Problems Modelled by ILP A general shortest path problem can be processed by integer linear programming [13]. The ILP model of shortest path problem in Fig. 1 is shown in Fig. 2. should be 1. Equation (11.3) denotes the number of outward edges for node be 0 or 1. linear programming. Without any other constraints, the label sequence in the path of Fig. 2 corresponds to the outputs of Viterbi algorithm. 4.3.3 The Construction and Incorporation of Logical Constraints Boolean expression can be represented as sets of linear (in)equalities [12]. 
After analyzing semantic annotation of web objects in different domain, we sum up any logical constraints of interest. 
Let Boolean variable a,b indicate whether the semantic labels L a , L b appear respec-tively, that is to say, corresponding linear (in) equalities. 3 a 5 () () va vb  X  linear (in)equalities. 
In Fig. 2, the Boolean expression of the first logical constraint can be represented represented by the linear inequality  X  inequalities in Table 1. 
The meaning of the second logical constraint is that if L a appears, then L b can not xxwherecab linear inequality  X  Table 1. 
The third logical constraint represents the meaning in Fig. 2 that the number of in-ward edge for the node marked as L a is equal to one in the whole graph. appear again. The conversion rule is similar to the second constraint. 
In Fig. 2, the Boolean expression of the fifth logical constraints can be represented as [ ( ) ( )] ab va vb  X  X  &gt; can get the corresponding linear inequalities in Table 1. 
As is shown in Table 1, we can see that logical constraints can easily extended ac-cording to the characteristics of different do mains. The approach in [12] can be used 5.1 Datasets The approach is evaluated on the following datasets. (1) Book dataset (denoted as Book) 1000 books are used for training and the remaining 2000 are used for testing. Books book database. (2) Paper reference dataset (denoted as Paper) ~mccallum/data). It contains 800 references , and 300 references are used for training table as an external database. 5.2 Evaluation Criteria To evaluate the performance comprehensively, several criteria that were widely used performance of the model on different aspects. A brief definition is given as follows. 
Defining A as the existing total number of special object elements, B as the number which are wrongly labeled. (1) First, two basic measurements, Recall and Precision , are defined as: 
Then F1 is calculated to be F1 rectly labeled.
 5.3 Experimental Results 5.3.1 Transformation of Inference Problem their corresponding average value on each field, and Fig. 3 shows the Instance Accu-racy on the two datasets. achieve an obvious improvement on almost each field compared with CRFs. Con-tainly improve the performance of semantic annotation of web object. 
In Fig. 3, it shows the Instance Accuracy of four models on the two datasets. From the results, it can be found that compared with CRFs, the Instance Accuracy of Con-strained CRFs achieves an obvious improvement on the two different datasets. 5.3.2 Effect of Incrementally Adding Logical Constraint Book are shown in Table 4 in which semantic labels represent Boolean variables. The adding order of logical constraints conforms to the order of id in Table 4. 
Fig. 4 shows the change of average F1 when incrementally adding different logical straints, the average F1 is a gradually improvement. It shows that every logical con-straint can improve the performance of semantic annotation. In this paper, a Constrained Conditional Random Fields model(Constrained CRFs) is proposed. Constrained CRFs extend traditional CRFs and use integer linear program-straints are defined by Boolean expression to describe logical relations among seman-tic labels. Experimental results using a large number of real-world data collected from mantic annotation accuracy of web objects. improve the semantic annotation accuracy of Web objects will be focused on. Acknowledgments. This work was supported in part by the National Natural Science Foundation of China under Grant No. 90818001 and the Natural Science Foundation of Shandong Province of China under Grant No.Y2007G24, No. Y2007G38. 
