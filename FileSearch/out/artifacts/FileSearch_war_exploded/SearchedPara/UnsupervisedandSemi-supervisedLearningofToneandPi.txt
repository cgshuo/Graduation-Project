 Tone and intonation play a crucial role across man y languages. Ho we ver, the use and structure of tone varies widely , ranging from lexical tone which de-termines word identity to pitch accent signalling in-formation status. Here we consider the recognition of lexical tones in Mandarin Chinese syllables and pitch accent in English.

Although intonation is an inte gral part of lan-guage and is requisite for understanding, recogni-tion of tone and pitch accent remains a challeng-ing problem. The majority of current approaches to tone recognition in Mandarin and other East Asian tone languages inte grate tone identification with the general task of speech recognition within a Hid-den Mark ov Model frame work. In some cases tone recognition is done only implicitly when a word or syllable is constrained jointly by the segmental acoustics and a higher level language model and the word identity determines tone identity . Other strate-gies build explicit and distinct models for the syl-lable final region, the vowel and optionally a final nasal, for each tone.

Recent research has demonstrated the importance of conte xtual and coarticulatory influences on the surf ace realization of tones.(Xu, 1997; Shen, 1990) The overall shape of the tone or accent can be sub-stantially modified by the local effects of adjacent tone and intonational elements. Furthermore, broad scale phenomena such as topic and phrase struc-ture can affect pitch height, and pitch shape may be variably affected by the presence of boundary tones. These findings have led to explicit modeling of tonal conte xt within the HMM frame work. In addition to earlier approaches that emplo yed phrase structure (Fujisaki, 1983), several recent approaches to tone recognition in East Asian languages (W ang and Sen-eff, 2000; Zhou et al., 2004) have incorporated ele-ments of local and broad range conte xtual influence on tone. Man y of these techniques create explicit conte xt-dependent models of the phone, tone, or ac-cent for each conte xt in which the y appear , either using the tone sequence for left or right conte xt or using a simplified high-lo w contrast, as is natural for inte gration in a Hidden Mark ov Model speech recognition frame work. In pitch accent recognition, recent work by (Hase gawa-Johnson et al., 2004) has inte grated pitch accent and boundary tone recogni-tion with speech recognition using prosodically con-ditioned models within an HMM frame work, im-pro ving both speech and prosodic recognition.
Since these approaches are inte grated with HMM speech recognition models, standard HMM training procedures which rely upon lar ge labeled training sets are used for tone recognition as well. Other tone and pitch accent recognition approaches us-ing other classification frame works such as support vector machines (Thubthong and Kijsirikul, 2001) and decision trees with boosting and bagging (Sun, 2002) have relied upon lar ge labeled training sets -thousands of instances -for classifier learning. This labelled training data is costly to construct, both in terms of time and mone y, with estimates for some in-tonation annotation tasks reaching tens of times real-time. This annotation bottleneck as well as a theo-retical interest in the learning of tone moti vates the use of unsupervised or semi-supervised approaches to tone recognition whereby the reliance on this of-ten scarce resource can be reduced.

Little research has been done in the application of unsupervised and semi-supervised techniques for tone and pitch accent recognition. Some prelimi-nary work by (Gauthier et al., 2005) emplo ys self-organizing maps and measures of f0 velocity for tone learning. In this paper we explore the use of spectral and standard k-means clustering for un-supervised acquisition of tone, and the frame work of manifold regularization for semi-supervised tone learning. We find that in clean read speech, un-supervised techniques can identify the underlying Mandarin tone cate gories with high accurac y, while even on noisier broadcast news speech, Mandarin tones can be recognized well abo ve chance levels, with English pitch accent recognition at near the levels achie ved with fully supervised Support Vec-tor Machine (SVM) classifiers. Lik ewise in the semi-supervised frame work, tone classification out-performs both most common class assignment and a comparable SVM trained on only the same small set of labeled instances, without recourse to the un-labeled instances.

The remainder of paper is organized as fol-lows. Section 2 describes the data sets on which English pitch accent and Mandarin tone learning are performed and the feature extraction process. Section 3 describes the unsupervised and semi-supervised techniques emplo yed. Sections 4 and 5 describe the experiments and results in unsuper -vised and semi-supervised frame works respecti vely . Section 6 presents conclusions and future work. We consider two corpora: one in English for pitch accent recognition and two in Mandarin for tone recognition. We introduce each briefly belo w. 2.1 English Cor pus We emplo y a subset of the Boston Radio Ne ws Cor -pus (Ostendorf et al., 1995), read by female speak er F2B, comprising 40 minutes of news material. The corpus includes pitch accent, phrase and boundary tone annotation in the ToBI frame work (Silv erman et al., 1992) aligned with manual transcription and syllabification of the materials. Follo wing earlier re-search (Ostendorf and Ross, 1997; Sun, 2002), we collapse the ToBI pitch accent labels to four classes: unaccented, high, low, and downstepped high for ex-perimentation. 2.2 Mandarin Chinese Tone Data Mandarin Chinese is a language with lexical tone in which each syllable carries a tone and the mean-ing of the syllable is jointly determined by the tone and segmental information. Mandarin Chinese has four canonical lexical tones, typically described as follo ws: 1) high level, 2) mid-rising, 3) low falling-rising, and 4) high falling. 1 The canonical pitch con-
Figure 1: Contours for canonical Mandarin tones tours for these tones appear in Figure 1.

We emplo y data from two distinct sources in the experiments reported here. 2.2.1 Read Speech
The first data set is very clean speech data dra wn from a collection of read speech collected under lab-oratory conditions by (Xu, 1999). In these mate-rials, speak ers read a set of short sentences where syllable tone and position of focus were varied to assess the effects of focus position on tone realiza-tion. Focus here corresponds to narro w focus, where speak ers were ask ed to emphasize a particular word or syllable. Tones on focussed syllables were found to conform closely to the canonical shapes described abo ve, and in pre vious supervised experiments using a linear support vector machine classifier trained on focused syllables, accurac y approached 99%. For these materials, pitch tracks were manually aligned to the syllable and automatically smoothed and time-normalized by the original researcher , resulting in 20 pitch values for each syllable. 2.2.2 Br oadcast News Speech The second data set is dra wn from the Voice of America Mandarin broadcast news, distrib uted by the Linguistic Data Consortium 2 , as part of the Topic Detection and Tracking (TDT -2) evaluation. Us-ing the corresponding anchor scripts, automatically word-se gmented, as gold standard transcription, au-dio from the news stories was force-aligned to the text transcripts. The forced alignment emplo yed the language porting functionality of the Uni versity of Colorado Sonic speech recognizer (Pellom et al., 2001). A mapping from the transcriptions to English phone sequences supported by Sonic was created using a Chinese character -pin yin pronunciation dic-tionary and a manually constructed mapping from pin yin sequences to the closest corresponding En-glish phone sequences. 3 2.3 Acoustic Featur es Using Praat X  s (Boersma, 2001)  X  X o pitch X  and  X  X o intensity X  functions and the alignments generated abo ve, we extract acoustic features for the prosodic region of interest. This region corresponds to the  X  X inal X  region of each syllable in Chinese, including the vowel and any follo wing nasal, and to the sylla-ble nucleus in English. 4 For all pitch and intensity features in both datasets, we compute per -speak er z-score normalized log-scaled values. We extract pitch values from points across valid pitch track ed regions in the syllable. We also compute mean pitch across the syllable. Recent phonetic research (Xu, 1997; Shih and Kochanski, 2000) has identified signifi-cant effects of carryo ver coarticulation from preced-ing adjacent syllable tones. To minimize these ef-fects consistent with the pitch tar get approximation model (Xu et al., 1999), we compute slope features based on the second half of this final region, where this model predicts that the underlying pitch height and slope tar gets of the syllable will be most accu-rately approached. We further log-scale and normal-ize slope values to compensate for greater speeds of pitch fall than pitch rise(Xu and Sun, 2002).
We consider two types of conte xtualized features as well, to model and compensate for coarticula-tory effects from neighboring syllables. The first set of features, referred to as  X  X xtended features X , in-cludes the maximum and mean pitch from adjacent syllables as well as the nearest pitch point or points from the preceding and follo wing syllables. These features extend the modeled tone beyond the strict bounds of the syllable segmentation. A second set of conte xtual features, termed  X  X if ference features X , captures the change in pitch maximum, mean, mid-point, and slope as well as intensity maximum be-tween the current syllable and the pre vious or fol-lowing syllable.

In prior supervised experiments using support vector machines(Le vow, 2005), variants of this rep-resentation achie ved competiti ve recognition levels for both tone and pitch accent recognition. Since man y of the experiments for Mandarin Chinese tone recognition deal with clean, careful lab speech, we anticipate little coarticulatory influence, and use a simple pitch-only conte xt-free representation for our primary Mandarin tone recognition experiments. For primary experiments in pitch accent recognition, we emplo y a high-performing conte xtualized repre-sentation in (Le vow, 2005), using both  X  X xtended X  and  X  X if ference X  features computed only on the pre-ceding syllable. We will also report some contrasti ve experimental results varying the amount of conte x-tual information. The bottleneck of time and monetary cost asso-ciated with manual annotation has generated sig-nificant interest in the development of techniques for machine learning and classification that reduce the amount of annotated data required for train-ing. Lik ewise, learning from unlabeled data aligns with the perspecti ve of language acquisition, as child learners must identify these linguistic cate-gories without explicit instruction by observ ation of natural language interaction. Of particular interest are techniques in unsupervised and semi-supervised learning where the structure of unlabeled examples may be exploited. Here we consider both unsuper -vised techniques with no labeled training data and semi-supervised approaches where unlabeled train-ing data is used in conjunction with small amounts of labeled data.

A wide variety of unsupervised clustering tech-niques have been proposed. In addition to classic clustering techniques such as k-means, recent work has sho wn good results for man y forms of spec-tral clustering including those by (Shi and Ma-lik, 2000; Belkin and Niyogi, 2002; Fischer and Poland, 2004). In the unsupervised experiments re-ported here, we emplo y asymmetric k-lines clus-tering by (Fischer and Poland, 2004) using code available at the authors X  site, as our primary unsu-pervised learning approach. Asymmetric clustering is distinguished from other techniques by the con-struction and use of conte xt-dependent kernel radii. Rather than assuming that all clusters are uniform and spherical, this approach enhances clustering ef-fecti veness when clusters may not be spherical and may vary in size and shape. We will see that this flexibility yields a good match to the structure of Mandarin tone data where both shape and size of clusters vary across tones. In additional contrasti ve experiments reported belo w, we also compare k-means clustering, symmetric k-lines clustering (Fis-cher and Poland, 2004), and Laplacian Eigenmaps (Belkin and Niyogi, 2002) with k-lines clustering. The spectral techniques all perform spectral decom-position on some representation of the affinity or ad-jacenc y graph.

For semi-supervised learning, we emplo y learn-ers in the Manifold Re gularization frame work de-veloped by (Belkin et al., 2004). This work postu-lates an underlying intrinsic distrib ution on a low di-mensional manifold for data with an observ ed, am-bient distrib ution that may be in a higher dimen-sional space. It further aims to preserv e locality in that elements that are neighbors in the ambient space should remain  X  X lose X  in the intrinsic space. A semi-supervised classification algorithm, termed  X  X apla-cian Support Vector Machines X , allo ws training and classification based on both labeled and unlabeled training examples.

We contrast results under both unsupervised and semi-supervised learning with most common class assignment and pre vious results emplo ying fully su-pervised approaches, such as SVMs. We executed four sets of experiments in unsu-pervised clustering using the (Fischer and Poland, 2004) asymmetric clustering algorithm. 4.1 Experiment Configuration In these experiments, we chose increasingly dif fi-cult and natural test materials. In the first experi-ment with the cleanest data, we used only focused syllables from the read Mandarin speech dataset. In the second, we included both in-focus (focused) and pre-focus syllables from the read Mandarin speech dataset. 5 In the third and fourth experiments, we chose subsets of broadcast news report data, from the Voice of America (V OA) in Mandarin and Boston Uni versity Radio Ne ws corpus in English.
In all experiments on Mandarin data, we per -formed clustering on a balanced sampling set of tones, with 100 instances from each class 6 , yield-ing a baseline for assignment of a single class to all instances of 25%. We then emplo yed a two-stage re-peated clustering process, creating 2 or 3 clusters at each stage.

For experiments on English data, we extracted a set of 1000 instances, sampling pitch accent types according to their frequenc y in the collection. We performed a single clustering phase with 2 to 16 clusters, reporting results at dif ferent numbers of clusters.

For evaluation, we report accurac y based on as-signing the most frequent class label in each cluster to all members of the cluster . 4.2 Experimental Results We find that in all cases, accurac y based on the asymmetric clustering is significantly better than most common class assignment and in some cases approaches labelled classification accurac y. Unsur -prisingly , the best results, in absolute terms, are achie ved on the clean focused syllables, reaching 87% accurac y. For combined in-focus and pre-focus syllables, this rate drops to 77%. These rates con-trast with 99-93% accuracies in supervised classi-fication using linear SVM classifiers with several thousand labelled training examples(Surendran et al., 2005).

On broadcast news audio, accurac y for Mandarin reaches 57%, still much better than the 25% level, though belo w a 72% accurac y achie ved using super -vised linear SVMs with 600 labeled training exam-ples. Interestingly , for English pitch accent recogni-tion, accurac y reaches 78.4%, aproaching the 80.1% Figure 2: Dif ferences for alternati ve unsupervised learners across numbers of clusters. accurac y achie ved with SVMs on a comparable data representation. 4.3 Contrasti ve Experiments We further contrast the use of dif ferent unsupervised learners, comparing the three spectral techniques and k-means with Euclidean distance. All contrasts are presented for English pitch accent classification, ranging over dif ferent numbers of clusters, with the best parameter setting of neighborhood size. The re-sults are illustrated in Figure 2. K-means and the asymmetric clustering technique are presented for the clean focal Mandarin speech under the standard two stage clustering, in Table 1.

The asymmetric k-lines clustering approach con-sistently outperforms the corresponding symmetric clustering learner , as well as Laplacian Eigenmaps with binary weights for pitch accent classification. Some what surprisingly , k-means clustering outper -forms all of the other approaches when producing 3-14 clusters. Accurac y for the optimal choice of clus-ters and parameters is comparable for asymmetric k-lines clustering and k-means, and some what bet-ter than all other techniques considered. The care-ful feature selection process for tone and pitch ac-cent modeling may reduce the dif ference between the spectral and k-means approaches. In contrast, for the four tone classification task in Mandarin us-ing two stage clustering with 2 or 3 initial clusters, the best clustering using asymmetric k-lines strongly outperforms k-means.

We also performed a contrasti ve experiment in pitch accent recognition in which we excluded con-textual information from both types of conte xtual features. We find little dif ference for the majority of Figure 3: Scatterplot of pitch height vs pitch slope. Open Diamond: High tone (1), Filled black traingle: Rising tone (2), Filled gre y square: Lo w tone (3), X: Falling tone (4) the unsupervised clustering algorithms, with results from symmetric, asymmetric and k-means cluster -ing dif fering by less than 1% in absolute accurac y. It is, howe ver, worth noting that exclusion of these features from experiments using supervised learning led to a 4% absolute reduction in accurac y. 4.4 Discussion An examination of both the clusters formed and the structure of the data pro vides insight into the effec-tiveness of this process. Figure 3 displays 2 dimen-sions of the Mandarin four -tone data from the fo-cused read speech, where normalized pitch mean is on the x-axis and slope is on the y-axis. The sepa-ration of classes and their structure is clear . One ob-serv es that rising tone (tone 2) lies abo ve the x-axis, while high-le vel (tone 1) lies along the x-axis. Lo w (tone 3) and falling (tone 4) tones lie mostly belo w the x-axis as the y generally have falling slope. Lo w tone (3) appears to the left of falling tone (4) in the figure, corresponding to dif ferences in mean pitch.
In clustering experiments, an initial 2-or 3-w ay split separates falling from rising or level tones based on pitch slope. The second stage of cluster -ing splits either by slope (tones 1,2, some 3) or by pitch height (tones 3,4). These clusters capture the natural structure of the data where tones are charac-terized by pitch height and slope tar gets. By exploiting a semi-supervised approach, we hope to enhance classification accurac y over that achie v-able by unsupervised methods alone by incorporat-ing small amounts of labeled data while exploiting the structure of the unlabeled examples. 5.1 Experiment Configuration We again conduct contrasti ve experiments using both the clean focused read speech and the more challenging broadcast news data. In each Mandarin case, for each class, we use only a small set (40) of labeled training instances in conjunction with an ad-ditional sixty unlabeled instances, testing on 40 in-stances. For English pitch accent, we restricted the task to the binary classification of syllables as ac-cented or unaccented. For the one thousand samples we proportionally labeled 200 unaccented examples and 100 accented examples. 7
We configure the Laplacian SVM classification with binary neighborhood weights, radial basis func-tion kernel, and cosine distance measure typically with 6 nearest neighbors. Follo wing (C-C.Cheng and Lin, 2001), for -class classification we train test instance using all of the classifiers and assign the most frequent prediction, with ties brok en ran-domly . We contrast these results both with con ven-tional SVM classification with a radial basis func-tion kernel excluding the unlabeled training exam-ples and with most common class assignment, which gives a 25% baseline. 5.2 Experimental Results For the Mandarin focused read syllables, we achie ve 94% accurac y on the four -w ay classification task. For the noisier broadcast news data, the accurac y is 70% for the comparable task. These results all sub-stantially outperform the 25% most common class assignment level. The semi-supervised classifier also reliably outperforms an SVM classifier with an RBF kernel trained on the same labeled training in-stances. This baseline SVM classifier with a very small training set achie ves 81% accurac y on clean read speech, but only 35% on the broadcast news speech. Finally , for English pitch accent recogni-tion in broadcast news data, the classifier achie ves 81.5%, relati ve to 84% accurac y in the fully super -vised case. We have demonstrated the effecti veness of both unsupervised and semi-supervised techniques for recognition of Mandarin Chinese syllable tones and English pitch accents using acoustic features alone to capture pitch tar get height and slope. Although outperformed by fully supervised classification tech-niques using much lar ger samples of labelled train-ing data, these unsupervised and semi-supervised techniques perform well abo ve most common class assignment, in the best cases approaching 90% of supervised levels, and, where comparable, well abo ve a good discriminati ve classifier trained on a comparably small set of labelled data. Unsuper -vised techniques achie ve accuracies of 87% on the cleanest read speech, reaching 57% on data from a standard Mandarin broadcast news corpus, and over 78% on pitch accent classification for English broad-cast news. Semi-supervised classification in the Mandarin four -class classification task reaches 94% accurac y on read speech, 70% on broadcast news data, impro ving dramatically over both the simple baseline of 25% and a standard SVM with an RBF kernel trained only on the labeled examples.
Future work will consider a broader range of tone and intonation classification, including the richer tone set of Cantonese as well as Bantu family tone languages, where annotated data truly is very rare. We also hope to inte grate a richer conte xtual rep-resentation of tone and intonation consistent with phonetic theory within this unsupervised and semi-supervised learning frame work. We will further ex-plore impro vements in classification accurac y based on increases in labeled and unlabeled training exam-ples.
 We would lik e to thank Yi Xu for granting access to the read speech data, Vikas Sindhw ani, Mikhail Belkin, and Partha Niyogi for their implementation of Laplacian SVM, and Igor Fischer and J. Poland for their implementation of asymmetric clustering.
