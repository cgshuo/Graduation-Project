 The development of the World Wide Web h as created the ever-increasing num-bers of Web-accessible documents in languages other than English. The auto-mated organization of these heterogeneous document collections has posed a challenge. On the other hand, the literature about cross-lingual document clus-tering is sparse. Typically, machine translation system is introduced to fill the gap between different languages[2,3]. In this paper, we propose a novel model, called domain alignment translation model , to effectively cluster the multi-lingual documents. Our model is inspired by the observation that its translation of a word greatly depends on the domain information of the context. In addition, our method differs widely from existing m ethods in that instead of the process of term translation and then clustering, the domain alignment translation model conducts term translation and clustering simultaneously by learning a bilingual domain alignment model and a domain-specific term translation model. This occurs in a collaborative way with the help of a bilingual translation dictionary after conducting monolingual document clustering on two document sets, re-spectively. Experimental results show that the method based on the proposed model can achieve a comparable performance with the direct machine transla-tion method, and that in some cases, the method can even outperform the latter one greatly.

The rest of this paper is organized as follows. In Section 2, we present re-lated work on cross-lingual document cl ustering. In Section 3, we describe the domain alignment translation model consisting of a cross-lingual domain align-ment model and a domain-specific term translation model. A method based on the proposed model is described in detai l in Section 4. Experimental results with the method on data collected from the Int ernet are shown in Section 5. Finally, we conclude in Section 6. The literature about cross-lingual document clustering is sparse. Evans et al. (2003, 2004) [2][3] used simple document tra nslation for multilingual clustering in their Columbia Newsblaster system. A lthough they developed a simple dic-tionary lookup glossing system for Japan ese and Russian, the system performed less well than full translation. Mathieu et al. (2004)[1] proposed a cross-lingual similarity measure for the documents, using bilingual dictionaries, employing a Shared Nearest Neighbor approach by Ertoz et al. (2001)[6] to cluster cross-lingual documents and achieving promising results. However, their method was not compared with full-fledged translation and it was not practical since it took eight hours for 3,000 documents to clust er in the cluster discovery phrase. Fur-thermore, Evans and Mathieu noticed a common phenomenon that found docu-ments from the same language tending to cluster more easily than from different languages. Compared with the above two methods, Chen and Lin(2000)[4] pro-posed a different cluster mapping approach for cross-lingual document clustering in their multilingual news summarizer but did not conduct experiments for the clustering performance, since their system is for multilingual news summarizer. In their cross-lingual clustering, they sel ect words with high frequency occurrence in the target language as the translations of the words in the source language. 3.1 Model Description Before describing the model, the following notations are introduced.  X  S denotes a set of source words to be translated. It can be further represented  X  T denotes a set of translated words given S . It can be further represented  X  GEN ( S ) is a set of candidate translations given S.  X  C denotes some specific domain and  X  denotes domain sets. That is, C is an
We use the term domain alignment translation model torefertoamech-anism that determine the probability P ( T,C | S ). We need to gather the heteroge-neous documents, e.g. Chinese documents and English documents into different groups. Compared with homogeneous documents, e.g. only Chinese document or only English document, there exists a wide language gap among heterogeneous documents. Meanwhile, it is our observation that a strong relationship between a translation of a word and its domain exists. For example, there are varied trans-lations in different domains in the case of , the translation of which is export in business domain , is exit in transportation domain and is speak in politics domain etc. Accordingly, it is reasonable to search for the translation of words and the specific domain simultaneously . According to Bayes X  X  theorem, given a set of source words S ,thebest T and C is the one that carry out maximization as follows: where P ( C | S ) is called cross-lingual domain alignment model and P ( T,C | S )is called domain-specific term translation model. If we postulate that given a spe-cific domain C and a set of source words S , its translation of each word in S is generated conditionally independently. The second term in Equation (1) rewritten as 3.2 Parameter Estimation P ( C | S ). If we had available parallel corpus from some specific domain C ,esti-mating P ( w T ij | w S i ,C ) could be the same as estimating the translation model in IBM noisy channel model. However, it is usually non-trivial to explicitly define what is the domain we need. On the other hand, it is also hard to acquire large Equation (3): If we assume that the occurrence of its translation w T ij in domain C is indepen-can obtain the following formula: fore,Equation(4)canbewrittenas: w i in a specific domain, P ( w denotes the frequency of word w ij in the domain C and TF ( w, C ) denotes the frequency of all words in the given domain. As for P ( w S i ), it is actually the un-igram model and thus can use the MLE estimation, smoothed by some known techniques. However, it doesn X  X  really involve the resulting decision for optimal C and T , since it is constant in the decision-making process. In section 3, we propose a domain alignment translation model. In this section, we propose a algorithm based on the model. Simply speaking, the algorithm comprises two steps: mono-lingual docume nt clustering; two-level search, that is, to search for term translation and the corresponding cluster that maximize P ( T,C | S ). In the monolingual document clustering phrase, we cluster the docu-ments in a language at an appropriate cluster number. In the search phrase, we simultaneously search the aligned clusters and term translation.

The clustering algorithm based on na  X   X ve Bayes model has been shown to be effective for high dimensional text clustering. Also, the clustering model has the similar assumption as our proposed model, which each word is generated independently in the given domain. Hence, we choose the algorithm to conduct monolingual document clustering. One can be referred to [8] for details.
On the other hand, to obtain the optimal translations and domain of a set of source words, we have to try all possible combination of their translations and the domains. However, it is computationally prohibitive. Therefore, our best option is to use a greedy algorithm toward this end. In our proposed two-level search algorithm, we just choose the set of translations with most high probability given some domain to avoid try too many candidate translations, totally ignoring the other possible translation combinations. We refer to the two-level search algorithm based on clusters as C-TLS. The algorithm is summarized in Fig. 1. In this paper, we also investigate the extreme case of the algorithm, called TLS. That is, it occurs when K 2 equals to | D 2 | in C-TLS. 5.1 Experimental Setup The test data is collected via RSS reader 1 . The test data comprises Chinese Web pages and English Web pages from various Web sites. They consist of news during December 2005, consisting of 6,462 English Web pages and 6,011 Chinese Web pages. We should have collected data with seven topics. Unfortunately, when we translate all Chinese Web pages into English Web pages via translation tools provided by Google language tool, there are various errors for some Web pages via Google translation tool 2 , so that we have to select five topics for experimentation. They include business, education, entertainment, science and sports. The category information is obtained by RSS reader. In addition, in the experiments, we use a general-purpose Ch inese-English bilingual dictionary with about 292,000 entries.

In the paper, we use average purity and average entropy for our evaluation metrics. Average entropy is used to measure mean status of how the various classes of documents are distr ibuted within each cluster. where q is the number of classes in the document collection, k is the number of partitioned clusters, n i is the number of documents from cluster i ,and n j i is the number of documents from cluster i assigned to category j .

The second measure is average purity that measures the average extent to which each cluster contained documents from one primary class. The purity measure is defined as follows: where P j is the fraction of the overall cluster size that the largest class of docu-ments assigned to that cluster represents. 5.2 Experimental Results and Discussion In our experiments, Our main experimental results are shown in Fig. 2. All re-sults are shown as average  X  1 standard deviation over 5 runs. The term Google , Google(I2C) and Google(C2C) represent our three baselines. Specifically speak-ing, Google refers to the method employing nbEM algorithm to all preprocessed English web pages and translated Chinese web pages, while Google(I2C) de-notes the method making a mapping from a translated Web page to clusters of native English Web pages through nbEM and Google(C2C) denotes the method relating clusters of the translated web page to clusters of the native English web pages. In addition, En2Ch indicates that English is source language and Chinese is target language, whereas Ch2En indicates the reverse case.

From Fig. 2, Fig. 3 and Table 1, we can summarize the results as follows:  X  C-TLS have better performance than TLS and can achieve comparable per- X  C-TLS achieves substantial and significant(p-value &lt; 0.05) improvements over  X  Compared with Google , Google(I2C) and Google(C2C) , TLS and C-TLS In this paper, we propose a novel domain alignment translation model to simul-taneously conduct cross-lingual clustering and term translation. By learning a cross-lingual domain alignment model and a domain-specific term translation model in a collaborative way, we can cluster documents with a similar topic in different languages. Experimental results show our method without any re-sources other than a bilingual dictionary can achieve comparable performance to the direct machine translation method via Google translation tool. In our experiments, we only consider word, ignoring base phrase. We will incorporate translation of base phrase into our system in the future. On the other hand, the clustering in the source language and the clustering in the target language are related highly and thus we will explore how to reinforce their clustering quality interactively for future research.

