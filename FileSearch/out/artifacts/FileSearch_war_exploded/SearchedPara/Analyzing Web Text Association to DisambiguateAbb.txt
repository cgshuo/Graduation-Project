 We introduce a statistical model for abbreviation disam-biguation in Web search, based on analysis of Web data resources, including anchor text, click log and query log. By combining evidence from multiple sources, we are able to accurately disambiguate the abbreviation in queries. Exper-iments on real Web search queries show promising results. H.3.3 [ Information Systems ]: Information Storage and Retrieval X  Query formulation Algorithms, Experimentation Web search, Query expansion, Text association, Abbrevia-tion
Mining text associations, especially, word associations, is important to Information Retrieval (IR) to achieve semantic match instead of literal word match [3, 2, 4]. Most auto-matic text association-finding methods are based on word co-occurrence information [1, 5]. Though these techniques are effective in document modeling, they often fail in query modeling because of (i) lack of information in queries, (ii) noise in data resources, especially for Web data, and (iii) difficulties to achieve precise text associations, e.g., it may be easy to associate  X  X pple X  with  X  X ruit X  but is hard to as-sociate only  X  X he most popular Japanese apple X  with  X  X uji X  though they have the same search intent.

One important application of text association in Web search is abbreviation disambiguation. For example, word  X  X im X  in the query  X  X im download X  probably means  X  X ol instant mes-senger X ; while in query  X  X im stock X , it probably means  X  X l-ternative investment market X , and in query  X  X im at Spain X  X  gains X , it probably stands for the word  X  X im X  itself. Correctly expanding  X  X im X  to its full representation can dramatically improve search quality. However, a bad expansion will also significantly hurt search quality. Thus, the accuracy of ab-breviation disambiguation is critical.

To alleviate the problems with text associating methods for query reformulation, we do not use documents as the resource to mine associations from. In addition to query logs, we explore other resources that can give extra evidence for abbreviation disambiguation: anchor text and click log. These three resources give different evidence for text associ-ation. The motivation for using query log is that users often reformulate a query to get better results if the original query did not satisify him/her. For example, if  X  X im download X  did not return accurate result s, he/she may reformulate the query into  X  X ol instant messenger download X . From here we can learn the association between  X  X im X  and  X  X ol instant messenger X . Achnor text is another useful resource; people may use different text to link to the same page. Based on this co-link information, we can infer probability of text as-sociation. A third useful resource is click log where users click the same page from different queries. All these three resources are easily availabl e, and are accura te in the sense that they all have human involved in the process. In the rest of the paper, we present a statistical model to leverage these three resources for abbreviation disambiguation and validate the effectiveness on real search data.
To expand abbreviations, we would like to model P ( E | AC ) where E is an expansion, A is the abbreviation and C is the context  X  other terms than A in the query.
 P ( E | AC )= P ( C | AE ) P ( E | A ) /P ( C | A )  X  P ( E where P ( E | A ) is the prior probabilty of meaning E when seeing A , P ( C | AE ) is the conditional probability of C oc-curring in the context of seeing both A and E . To compute P ( C | AE ), we can apply n-gram language models but in this work we assume that the words c i in C are independent when A , E are given for simplicity. Thus where P ( E | A )and P ( c i | AE ) can be computed from the three different resources.
 Case One: E = E A
We define a special  X  X xpansion X  E = E A inEq2torep-resent the case of not to expand ( E A represents the word A when A is not an abbreviation and thus should not be ex-panded, such as the word  X  X im X  in  X  X im at Spain X  X  gains X ). In this case, where P ( E A | A ) shows how likely A should not be ex-panded, which is estimated from some other text resources and we will not discuss the details in this paper. It is ex-pensive to estimate P ( c i | AE A ) because enough examples of query term with labels will be needed to show whether a term is a to-be-expand abbreviation or not. For simplicity, we use the distribution of term c i in a 3-month query log as an approximation.
 Case Two: E = E A Considering E is not E A , but an expansion. For the three Web resources of anchor text, click log and query log, we define three types of estimation as following: where colinked ( A ) is the set of all anchor texts that have colinked pages with A when A is anchor text, Weight ( e )is the link-weight of anchor text e (reciprocal of the number of links that the page contains), e is the anchor text of E , g is the anchor text of G ,and G can be any text. c i is the context word and w can be any word. where freq ( c i | ae ) is the frequency of c i given that e is the expansion of abbreviation a . We use a query similarity matrix derived from click logs. For each query there is a vector of clicked URLs (if a URL is clicked, then the corresponding value is set to be 1), and the query similarity score of two queries is computed between the two click-log vectors based on the assumption that two similar queries usually result in similar clicked URLs.
To compute context informat ion from query similarity scores: where Sim ( c i | ae ) is the similarity score between a query containing c i and the given abbreviation-expansion pair.
We define the final probability of P ( c i | AE )inEq2tobea mixture of Eq 5, 6, and 7. The mixture weight will be deter-mined by experience due to the lack of test examples caused by the small percentage of queries containing abbreviations, which will be described in Section 3. The mixture probabil-ity of P ( c i | AE ) will then be smoothed on the background of a 3-month query log with linear smoothing. We have tested with both of linear smoothing and Dirichlet smoothing and found that linear smoothing achieves better results.
To show the effectiveness of the model described in Sec-tion 2, we ran it on 1359 multi-word queries (queries that contain more than one word for disambiguation), which are random samples from query logs and have been manually labeled with corresponding expansions. In our experiments, we define an abbreviation term as a term that should be ex-panded through the abbreviation dictionary; there are 56 abbreviation terms in the 1359 queries; a non-abbreviation term is defined as a term that should not be expanded; there are 4370 non-abbreviation terms in total. The precision and recall of the abbreviation terms and non-abbreviation terms from our model are presented in Table 1. Note that only when an abbreviation term is associated to the correct ex-pansion will it be counted as a positive example. There are two settings of parameters in the table, which define the thresholds of expansion by comparing the probability of two cases in Section 2.
 Parameters Precision Recall Precision Recall Setting 1 100% 30.4% 99.1% 100% Setting 2 77.8% 50% 99.2% 99.8% Table 1: Results of the abbreviation disambiguation experiments Abbreviation disambiguation is overall a hard problem. From our comparison the model is at least as effective as the abbreviation disambiguation in current major search en-gines. As we discussed in Section 1, precision is a crucial factor to query expansion and thus we prefer high precision over recall in parameter setti ngs. In future, the results may be further improved by applying an n-gram language model in (Eq 1). [1] D. M. Blei, A. Y. Ng, and M. J. Jordan. Latent [2] G. Cao, J. Nie, and J. Bai. Integrating Word [3] V. Lavrenko and W. B. Croft. Relevance-based [4] X. Wei and W. Croft. LDA-based Document Models for [5] X. Wei and W. Croft. Modeling Term Associations for
