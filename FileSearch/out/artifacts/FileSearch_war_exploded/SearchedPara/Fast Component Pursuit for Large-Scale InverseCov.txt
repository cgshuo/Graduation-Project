 The maximum likelihood estimation (MLE) for the Gaussian graph-ical model, which is also known as the inverse covariance estima-tion problem, has gained increasing interest recently. Most exist-ing works assume that inverse covariance estimators contain sparse structure and then construct models with the ` 1 regularization. In this paper, different from existing works, we study the inverse co-variance estimation problem from another perspective by efficiently modeling the low-rank structure in the inverse covariance, which rank structure is common in many applications including the cli-mate and financial analysis, and another one is that such assump-tion can reduce the computational complexity when computing its inverse. Specifically, we propose an efficient COmponent Pursuit (COP) method to obtain the low-rank part, where each component can be sparse. For optimization, the COP method greedily learns a rank-one component in each iteration by maximizing the log-likelihood. Moreover, the COP algorithm enjoys several appealing properties including the existence of an efficient solution in each iteration and the theoretical guarantee on the convergence of this greedy approach. Experiments on large-scale synthetic and real-world datasets including thousands of millions variables show that the COP method is faster than the state-of-the-art techniques for the inverse covariance estimation problem when achieving comparable log-likelihood on test data.
 Inverse Covariance Estimation; Component Pursuit; Large-Scale Data; Greedy Algorithm Suppose there are n instances { x 1 ,..., x n } sampled from a Gaussian distribution N (  X  ,  X  ) , where each instance x (1  X  i  X  n ) lies in a p -dimensional space,  X   X  R p is the mean, and  X   X  R p  X  p is the covariance matrix. An important and chal-lenging problem is to recover  X  or its inverse  X   X  1 dimensional setting where n p . Estimating the inverse covari-ance matrix has attracted a lot of interests in several fields including machine learning, signal processing, computational biology and so on, since it can reveal the dependence among the p attributes [28, 11, 3]. The inverse covariance matrix is estimated by maxi-mizing the log-likelihood as or equivalently minimizing the negative log-likelihood (NLL): where  X  is the inverse covariance estimator,  X  0 indicates that  X  is positive definite, | X | denotes the determinant of a square ma-trix,  X  X  ,  X  X  denotes the dot product between two matrices or vectors,  X   X  = 1 n P n i =1 x i is the mean of the samples, and S = ing problem (1), we can obtain an analytical solution for  X  as  X  = S  X  1 . Under the high-dimensional setting where n p , S is rank-deficient and hence this analytical solution is ill-posed. In order to make the problem well-defined, some regularizers are used to constrain  X  and a widely used one is the ` 1 regulariza-tion [28, 11, 3] which assumes that  X  is sparse with the objective function formulated as where  X  is a regularization parameter that controls the trade-off be-tween the sparseness of  X  and the fitness to the data.

A large body of works have been devoted to solving problem (2) recently [4, 6, 11, 23, 24, 25, 16, 17, 26], among which the state-of-the-art methods including the QUIC [16], Big-QUIC [17] and BCDIC [26] methods can handle  X  with billions of entries under the assumption that  X  is sparse. Those methods commonly use Newton proximal approaches, where a quadratic approximation is made and one key step is to calculate the inverse of  X  , to minimize the NLL. Obviously, the computational bottleneck in those meth-ods is that they need to compute the matrix inverse  X   X  1 iteration, which is computationally heavy when p is very large. Al-though the Big-QUIC and BCDIC methods alleviate this problem by splitting the huge matrix  X  into blocks and use some cheaper operations, e.g., solving some linear systems, to update the corre-sponding blocks in  X   X  1 , the matrix inverse operation, whose com-isting methods to solve problem (2) have this problem. Moreover, in the QUIC, Big-QUIC and BCDIC methods, an operation used to largely improve the efficiency is to restrict the number of updated positions in  X  and this operation works well when the optimal  X  is very sparse, corresponding to a situation that the regularization parameter  X  in problem (2) has a large value. To see this, empirical studies in those works [16, 17, 26] choose  X  such that the optimal  X  has only 10 p non-zero entries out of a total number of p tries and so only a very small fraction (i.e., 10 /p ) in the optimal  X  can have non-zero values. Therefore, although those works claim that their methods can handle a covariance matrix with billions of entries, only a small number of non-zero values are actually com-puted. Empirically we find that the QUIC, Big-QUIC, and BCDIC methods are not very efficient when  X  has a smaller value. More-over, an extremely sparse  X  learned in those works may fail to recover the true relations between attributes.

In this paper, we investigate the inverse covariance estimation problem from another perspective by modeling the low-rank struc-ture contained in  X  . One motivation for learning the low-rank structure in  X  is that the low-rank structure is common in many applications. For example, in climate research, spatially close lo-cations usually exhibit strong dependencies in the climate attributes and such geographical consistency usually leads to low-rank struc-correlations have been detected on large-scale traffic networks and hence low-rank structure exists [13]. Moreover, in computational finance, a large body of works have focused on estimating nearly low-rank covariance or precision matrices for economy and stock analysis [9, 10, 7, 8]. Moreover, in addition to the generality of the low-rank structure in various applications, this assumption can bring the computational benefit since the matrix inverse  X  quired in each iteration can be computed in lower complexity.
Specifically, we propose a COmponent Pursuit (COP) method which assumes that the inverse covariance is a combination of a diagonal matrix and a low-rank matrix which can be sparse. In order to obtain the low-rank part in  X  , the COP method greedily learns a rank-one component in each iteration by maximizing the log-likelihood, where each rank-one component can be sparse. The subproblem associated with each rank-one component is shown to be non-convex under the high-dimensional setting but due to the special structure of the subproblem, we can prove that all its local optimums have the globally optimal objective value, making the optimization easier. We further show that the greedy COP algo-rithm inherently enjoys several appealing properties including the existence of an efficient solution for each subproblem and the theo-retical guarantee on the convergence of this greedy approach. Com-pared with most existing methods whose complexity is O ( p proposed COP method only takes O ( p 2 ) operations. Experiments on large-scale synthetic and real-world datasets show that the pro-posed COP method is faster than the state-of-the-art methods for large-scale inverse covariance estimation when achieving compa-rable log-likelihood on test data.
 Notations: We use lower-case letters for scalars, bold-face and lower-case letters for vectors, and bold-face and upper case letters notes the rank of a matrix. diag (  X  ) converts a vector to a diagonal matrix or extracts the diagonal entries in a square matrix to form a vector. k X k 2 denotes the ` 2 norm of a vector. k X k ? denotes the ` norm of a matrix, which equals the maximum eigenvalue of a square matrix.
Most of the previous studies [4, 6, 11, 23, 24, 25, 16, 17, 26] assume that the inverse covariance matrix is sparse and propose different optimization algorithms to solve problem (2). Different from those approaches, we aim to learn low-rank structure in the inverse covariance matrix.

Similar to our work, some recent methods investigate other struc-tures of the inverse covariance instead of learning with pure spar-sity. For example, in [23, 14, 17], the inverse covariance matrix is assumed to have diagonal block structure, where each diagonal block matrix is sparse, when the attributes can be divided into sev-eral groups with each one containing similar attributes. Moreover, the latent Gaussian graphical model (LGGM) proposed in [5] as-sumes that the inverse covariance is equal to the difference between a sparse matrix and a low-rank matrix, and two algorithms [22, 15] including the alternating direction method and Newton proximal method have been proposed for the LGGM method. However, these methods [23, 14, 17] still learn the sparse inverse covariance and the LGGM method treats the sparse part as a dominate part. Moreover, computing the matrix inverse with O ( p 3 ) complexity is unavoidable in the LGGM method and even worse, it has to re-cover the low-rank part via the eigen-decomposition in each itera-tion, which also costs O ( p 3 ) . Different from these algorithms, the proposed COP method focuses on learning the low-rank part and greedily pursuits a rank-one component in each iteration, whose complexity is O ( p 2 ) .

The proposed COP method seems related to the principal com-ponent analysis (PCA) [18] but they are different, since the PCA assumes the covariance matrix is a sum of a low-rank part and a diagonal one but in the proposed COP method, the inverse covari-ance matrix is a combination of a low-rank part and a diagonal one, implying that the covariance matrix equals the difference between a diagonal part and a low-rank one.
In this section, we formally present the motivation and define the problem. In order to make the inverse covariance  X  positive definite to satisfy the constraint of problem (1), we assume that  X  is combination of two matrices, i.e.,  X  = L + P , where L is a low-rank positive semidefinite matrix and P is a positive definite diagonal matrix. Such assumption on the structure of L and P is motivated by the solution of problem (1) as revealed in the follow-ing corollary.

C OROLLARY 1. The optimal solution  X   X  of problem (1) sat-isfies the following condition: where I is an identity matrix with appropriate size and A B implies that A  X  B is positive semidefinite for two square matrices A and B .
 Corollary 1 can be directly proved by theorems in [3, 21] and thus its proof is omitted here. From Corollary 1,  X   X  can be rewrit-ture. Inspired by this decomposition, we just assume that L is a low-rank positive definite matrix and P = diag (  X  ) is a diagonal matrix where  X   X  R p with each entry, i.e.,  X  i , positive. As we will see later, such assumption on the structure of  X  can bring compu-tational benefit since the complexity to compute  X   X  1 reduces from O ( p 3 ) to O ( p 2 ) .

Then we are ready to present the problem formulation. Given the sample covariance matrix S  X  R p  X  p , we consider the inverse co-variance estimation problem by assuming a low-rank plus diagonal structure as min s . t .  X  = L + P , P = diag (  X  ) ,  X  i &gt; 0 , L 0 , rank ( L )  X  r, where r p is a pre-defined rank. In the next section, we propose the efficient COP method to solve problem (3). In this section, we show how to solve problem (3) efficiently. Since there are two parts, L and P , in problem (3), we use an al-optimize problem (3) with respect to (w.r.t.) P by fixing L and then estimate L with P fixed, where L is learned by pursuing its rank-one components greedily.
When the low-rank component L is fixed, the problem w.r.t. the diagonal part P is It is easy to prove that problem (4) is convex w.r.t. P or  X  and we can use some gradient descent method to solve it directly, where the gradient of the objective function in problem (4) is where ( L + P )  X  1 = P  X  1  X  P  X  1 U ( I + U T P  X  1 U ) utilizing the low-rank structure of L that L equals UU T for some low-rank U and hence it can be computed efficiently. Then, with a carefully chosen step size as [16, 17, 15], the positiveness of  X  can be guaranteed in each iteration.

Moreover, at the beginning of the COP algorithm, L is set to be a zero matrix and the problem for P is formulated as min which has an analytical solution  X  i = 1 s denotes the ( i,j ) th element in S and s ii is positive since S is a co-variance matrix. We use this analytical solution as the initialization for P . With a fixed P , we aim to learn the low-rank part L efficiently. We propose to pursue its rank-one components of L iteratively. When P is fixed, the problem w.r.t. L can be formulated as In order to make the whole algorithm efficient, we aim to learn the rank-one components in L greedily and hence in the ( k +1) th itera-tion we formulate the estimation L k +1 as L k +1 = L k + u where L k is the low-rank estimation obtained until the k th iteration and u k +1 is the rank-one component to be learned in the ( k + 1) th iteration. By defining M k = L k + P k , the subproblem w.r.t. u in the ( k + 1) th iteration can be formulated as which can be simplified by omitting some constant terms as
Based on problem (7), we are also interested in learning struc-tured components. For example, in many situations, the rank-one component in the low-rank structure can be sparse [29]. To ob-tain sparse components via the ` 1 regularization, a simple variant of problem (7) can be formulated as where  X  &gt; 0 is a regularization parameter controlling sparsity in the rank-one component vector u .

Here we investigate both problems (7) and (8). For the two prob-lems, the following theorem with its proof in the appendix shows that they are non-convex under the high-dimensional setting.
T HEOREM 1. When n p , problems (7) and (8) are non-convex w.r.t. u .
 According to Theorem 1, we could only find a local optimum of u k +1 , making the greedy algorithm hard to learn a globally optimal rank-one component of L in each iteration. Fortunately, we find that all the local optimums of problem (7) have the same globally optimal objective value of problem (6) according to the following theorem.

T HEOREM 2. For problem (7), if u is a rank deficient local minimum of f ( u ) , then U = uu T is a global minimum of F ( U ) , i.e., all the local optimums have the same globally optimal objective value in problem (6).

Theorem 2 allows us to use any optimization method, which can find a local optimum, to solve problem (7). Generally, we can use gradient descent algorithms since the objective function f (  X  ) is dif-ferentiable and its gradient can be computed as For problem (8), there is no result similar to Theorem 2. However, we can use general proximal gradient (GPG) methods [12, 20] to solve it efficiently by using the optimal solution of problem (7) as the initialization to speedup the convergence. The entire greedy COP algorithm is depicted in Algorithm 1.
 Algorithm 1 The COP algorithm.
 Input: S , r ; Output:  X   X  ; 1: Initialize P 0 and set M 0 = P 0 , k = 0 ; 2: repeat 3: Solve problem (7) or (8) with fixed P k ; 5: M k = L k + P k ; 7: Update P k with fixed L k ; 8: k := k + 1 ; 9: until k &gt; r or some convergence criterion is satisfied 10:  X   X  = M k ;
In this section, we theoretically analyze the COP method, where we derive an efficiently analytical solution for problem (7) and prove the convergence of the COP algorithm in Algorithm 1.
We first present some interesting properties, which set the stage for the introduce of our main results, of the COP method.
P ROPOSITION 1. Assume M k is the matrix obtained in the k th iteration of Algorithm 1. If there exists a vector a  X  then by defining we have L ( M k + uu T ) &lt; L ( M k ) . Otherwise, adding any rank-one component to M k will not decrease the NLL, implying that Algorithm 1 will stop at the k th iteration.

Proposition 1 provides the necessary condition, i.e., Eq. (9), for the convergence of the COP method. Note that Proposition 1 does not require that u should be a local optimum of problem (7) or (8).
P ROPOSITION 2. Suppose a vector a satisfies Eq. (9) and de-fine c = a T M decrease of the NLL in the two successive iterations, i.e. L ( M L ( M k + uu T ) , is a monotone increasing function w.r.t. c : where c &gt; 1 .
 Proposition 2 implies that in order to achieve fast decrease in the NLL by adding a rank-one component to M k , we need to choose the maximum value of c . Until now, both the Propositions 1 and 2 hold for Algorithm 1 when solving either problem (7) or (8), since those results are obtained by analyzing the difference of the NLL values in two successive iterations. When we solve problem (7) based on the COP algorithm, we can obtain an analytical solution for it with the detailed result shown in the following proposition.
P ROPOSITION 3. If there exists a vector a satisfying Eq. (9), then problem (7) is equivalent to the following Rayleigh quotient problem: which admits an analytical solution by solving the generalized eigen-decomposition problem M  X  1 k a  X  =  X   X  Sa  X  with  X   X  and a largest eigenvalue and the corresponding eigenvector. Moreover, c max , i.e., the maximum value that c can reach in the ( k + 1) th iteration of Algorithm 1, can be computed as In Proposition 3, the largest eigenvalue  X   X  and eigenvector a the generalized eigen-decomposition problem can be computed ef-ficiently by the power method [19]. Moreover, Proposition 3 im-plies that solving the Rayleigh quotient problem also provides a way to check whether Eq. (9) can be satisfied in the ( k + 1) th it-eration by testing whether c ( k +1) max =  X   X  &gt; 1 holds or not. When solving problem (8) instead, we directly check Eq. (9) based on the component obtained by the GPG method to determine whether the COP algorithm needs to be terminated.

In the following theorems, we present the analytical solution for problem (7) and prove the convergence of the COP algorithm in Algorithm 1.

T HEOREM 3 (A NALYTICAL S OLUTION ). Let M k be the ma-trix defined in step 5 of Algorithm 1 in the k th iteration and denote by  X   X  and a  X  the largest eigenvalue and the corresponding eigen-vector of the generalized eigen-decomposition problem M  X  1  X 
Sa  X  . Then u  X  , which is defined as is a local optimum of problem (7) in the ( k + 1) th iteration.
T HEOREM 4 (C ONVERGENCE ). In the COP algorithm shown in Algorithm 1, which solves either problem (7) or (8), the NLL de-creases iteratively until convergence.
 Theorems 3 and 4 provide important guarantees for the proposed COP method. According to Proposition 3 and Theorem 3, a key step in the COP method is solving the Rayleigh quotient problem (12) if we want to adopt the analytical solution for problem (7) or use it to initialize the estimator in problem (8). Both Eq. (9) and problem (12) require that ( a  X  ) T Sa  X  &gt; 0 for the optimal a a  X  lies in the range space of S . We can rewrite S as S = X if we assume that the data samples are normalized to have zero sample mean and based on this reformulation, we can see that the range space of S is spanned by X , implying that a  X  lies in the row space of X . Hence we can represent a as a = X T b where b  X  contains the spanning coefficients. Accordingly problem (12) can be reformulated as Problem (15) is still a Rayleigh quotient problem which can be solved by the power method. One advantage to solve problem (15) instead of problem (12) is that the size of matrices in the gener-alized eigen-decomposition problem (15) is n  X  n which is much smaller than that of problem (12) under the high-dimensional set-ting where n p , leading to a much more efficient implementa-tion and a significant speedup. Moreover, when solving problem (15), we only need to store the data matrix X instead of the sample covariance matrix S as in problem (12), which can largely reduce the storage requirement. For the case where n &gt; p , we still solve problem (12) since in this situation the null space of S is empty with a large probability.
In this section, we discuss the complexity of the proposed COP method in Algorithm 1 and compare with existing approaches.
In each iteration of Algorithm 1, the matrix inverse M a vector, we can efficiently compute M  X  1 k +1 as which only needs O ( p 2 ) operations because M  X  1 k has already been stored during the previous iteration. Step 3 in Algorithm 1 when we consider problem (7) needs to solve problem (12) or (15), whose complexity is O (min( p 2 ,n 2 )) . When solving problem (8), the complexity of the GPG method is no more than O ( p 2 ) , and when we adopt the optimal solution of problem (7) as the initialization, the GPG method will converge fast in considerably few iterations. Moreover, updating the diagonal matrix P k in each iteration costs O ( p 2 ) . In a word, the overall time complexity of the COP algo-rithm is O ( rp 2 ) where r is the pre-defined rank satisfying r p . Moreover, the storage requirement for the the two matrices (i.e., L and P ) in the COP algorithm is a linear function w.r.t. p , since we only need to keep the diagonal elements in P k and the component vectors { u  X  1 ,  X  X  X  , u  X  k } .

All the sparse inverse covariance estimation methods including mal methods to solve problem (2) where computing the inverse of a p  X  p matrix  X   X  1 k is needed and costs O ( p 3 ) . So the com-putational complexity of the COP method is lower than those of the aforementioned approaches. For the LGGM methods [5, 22, 15], which assume the inverse covariance has a sparse minus low-rank structure, they need to compute the inverse of p  X  p matrices with O ( p 3 ) cost and also need additional O ( p 3 ) operations for the eigen-decomposition to update the low-rank part, making it have higher complexity than the proposed COP method. Moreover, as discussed before, the storage complexity of the COP algorithm is O ( p ) but those of the above approaches depend on the number of non-zero entries in  X  , which could be O ( p 2 ) in the worst case.
In this section, we conduct experiments on both synthetic and real-world datasets to evaluate the proposed COP method and the ` -regularized COP method (COP-` 1 ).
We compare with a number of state-of-the-art methods for the inverse covariance estimation problem, including the QUIC [16], Big-QUIC [17], BCDIC [26] and QUIC&amp;Dirty [15] methods. ong those methods, the QUIC, Big-QUIC and BCDIC methods are the state-of-the-art sparse inverse covariance estimation methods, while the QUIC&amp;Dirty method is currently the most efficient algo-rithm for the LGGM problem. The implementations for the QUIC, Big-QUIC, BCDIC and QUIC&amp;Dirty methods adopt the recom-mended settings as provided in their works and the Big-QUIC and BCDIC methods are parallelized with multiple cores. All the ex-periments are performed on a machine with dual 6-core Intel Xeon X5650 2.66GHz processor and 32GB RAM.

In the experiments, we split the data into a training set contain-ing 90% of the samples and a test set with the rest samples. We use S train to denote the sample covariance matrix on the train-ing set and S test as the sample covariance matrix on the test set. All the data are normalized such that the diagonal elements in both S train and S test are all ones. By following [16, 17, 26], we choose the regularization parameter  X  in problem (2) for the QUIC, Big-QUIC and BCDIC methods such that the estimated  X   X  contains ap-proximately 10 p non-zero elements. For the QUIC&amp;Dirty method, we set its regularization parameter  X  1 for the sparse part to be  X  in problem (2) and choose another regularization parameter  X  can be downloaded from http://www.stat.ucdavis.edu/~chohsieh/ and that for the BCDIC method can be obtained at http://www. javierturek.com/software/. the low-rank part from { 0 . 1 , 1 , 10 } . For the COP-` choose the best  X  from the candidate set { 10  X  5 , 10  X  4
In this section, we conduct experiments on synthetic data to test the performance of the proposed COP and COP-` 1 methods.
We first generate a dataset of small scale to test the correctness of the theoretical results presented in Section 5. In order to do this, we generate a matrix A  X  R r  X   X  p , where r  X  = 20 and p = 100 . Each entry in A is sampled from the standard normal distribution N (0 , 1) . Then we generate the sample covariance matrix S ( S  X  )  X  1 = A T A + I . We estimate  X   X  by solving problem (1) and compare the estimated  X   X  and ( S  X  )  X  1 to see whether they are exactly the same. In order to see the learned L , we suppose that the diagonal part P is known and set to be the ground truth, i.e., the identity matrix I .

Fig. 1 shows detailed results of the COP method. Fig. 1(a) de-picts the change of the NLL values when increasing the the number of components or equivalently the iterations. Since we are aware of the ground truth of the inverse covariance, we can calculate the ground truth of the NLL value which is illustrated by the red dashed line. We see that the NLL of the COP algorithm decreases in al-most a linear rate, and when the rank or equivalently the number of components reaches 20, which is the ground truth for the rank, the COP method exactly recovers the ground truth of the inverse covariance and the corresponding NLL value is equal to the ground truth. Hence, the COP algorithm stops at the 21st iteration by per-fectly recovering the ground truth of the inverse covariance. Fig. 1(b) plots change of the  X   X  against the rank. As expected, the value of  X   X  decreases when increasing the rank and when the number of iterations reaches 21,  X   X  becomes 1, which implies that Eq. (9) is no longer satisfied, leading to the termination of the COP algo-rithm. These observed results well match the theoretical results in Section 5. Similar to the previous section, we generate a matrix A  X  where r  X  = 100 and each entry in A is sampled from the stan-dard normal distribution N (0 , 1) . The true covariance S erated in the same way as ( S  X  )  X  1 = A T A + I . In this case, we generate n = 1000 samples, which are stored in the data matrix X  X  R n  X  p , from N ( 0 , S  X  ) . We vary p from 5 , 000 to 25 , 000 at an interval of 5 , 000 to evaluate the performance of all the meth-ods. Since the sparse inverse covariance estimation methods in-cluding the QUIC, Big-QUIC and BCDIC methods solve problem (2) and the QUIC&amp;Dirty method solve the LGGM problem, the comparison among them is not straightforward. In order to make fair evaluations, we compare the running time of different methods when they achieve the same or comparable NLL on the test dataset and the method with the lowest running time is the most efficient one. Moreover, we compare the COP and COP-` 1 methods with the sparse inverse covariance estimation methods and the QUIC&amp;Dirty method separately.
 Table 1 shows the results by comparing the proposed COP and COP-` 1 methods with the sparse inverse covariance estimation met-group of columns denotes different settings for p . The second group shows the value of the regularization parameter  X  in prob-lem (2), the number of non-zero (NNZ) entries in the estimated which is around 10 p by following experimental settings in the orig-inal works, and the NLL on the test data denoted by NLL te
Training NLL 6 50 100 150 200 250 QUIC, BCDIC, and the proposed methods, i.e., COP and COP-` , on synthetic data. The detailed settings for various methods are denoted by NLL te .
 p = 5 , 000 0.218 51,296 4967.5 79.8 64.9 50.7 11 4965.3 15.0 14 10 p = 10 , 000 0.231 103,422 9959.3 271.8 234.8 191.4 16 9959.2 87.9 21 10 parameter  X  , and the NLL on the test data denoted by NLL after running over 5 hours for all choices of  X  2  X  X  0 . 1 , 1 , 10 } . QUIC, Big-QUIC and BCDIC methods. Since all the three meth-ods solve the same problem (i.e., problem (2)), their NNZ X  X  and NLL te  X  X  are nearly the same and thus we only report the results obtained from the BCDIC method. The third group reports the run-ning time for the QUIC, Big-QUIC and BCDIC methods. The forth group of columns shows the learned rank r and the NLL te of the COP method, and the fifth group reports its running time. Similarly, the last two columns show the results for the COP-` 1 method. From the results, the COP and COP-` 1 methods usually needs 10 to 20 components to achieve comparable NLL te with those of the QUIC, Big-QUIC and BCDIC methods on all the synthetic datasets and the COP and COP-` 1 methods are always faster than other meth-ods under all the settings.

The comparison results among the QUIC&amp;Dirty, COP and COP-` methods are recorded in Table 2. Table 2 has a similar format to Table 1 and it shows all the detailed settings and the running time of the three methods. When p is lower than 20 , 000 , the COP and COP-` 1 methods are much more efficient than the QUIC&amp;Dirty method when they achieve similar NLL te . When p becomes larger, the QUIC&amp;Dirty method cannot provide the estimation in reason-able time (i.e., 5 hours) and hence it can only handle medium-scale datasets. For the COP and COP-` 1 methods, we try larger ranks, i.e., 50, and they still obtain lower NLL te in reasonable time.
By comparing Table 1 and Table 2, we find that the QUIC&amp;Dirty method has slightly better testing NLL values than the sparse in-verse covariance estimation methods when their regularization pa-
Training NLL 6 32 34 36 38 40 42 44 46 48 rameters, which control the sparsity, are set to the same value. This observation reveals that considering both the low-rank and sparse structure can fit the data better than purely sparse inverse covari-ance in these synthetic datasets. However, training the QUIC&amp;Dirty method is much more computational expensive and hence it can hardly process large-scale data as shown in Table 2.

In Tables 1 and 2, the COP-` 1 method does not perform better than the non-regularized one, and it generally needs more ranks and running time to obtain comparable NLL te with the COP method. This is probably because under the synthetic setting, the ground truth does not contain sparse components.

In addition, we provide more details for the COP method in Fig. 2 which plots iterative results of the COP method on synthetic data with p = 5 , 000 . We set the total number of ranks to be 101 in this case. Fig. 2(a) plots the change of the NLL on the training data w.r.t. the number of iterations. Again, we find that the NLL on the training set decreases in a linear rate against the number of iterations. Fig. 2(b) shows the value of  X   X  in each iteration and we see that  X   X  becomes smaller iteratively while it is always larger than 1 even at the 101st iteration, implying that the algorithm can further proceed. Note that in this situation, the ground truth of the rank is 100 but the COP algorithm does not terminate at the 101st iteration. This is reasonable since under this setting where n p , the sampling bias exists in the training data and hence the estimated components are not exactly the true components.
In this section, we conduct experiments on large-scale real-world datasets. We use four datasets from the Gridded Climate Data one stock dataset collected from the Yahoo finance 3 , which are also Hemisphere EASE-Grid Weekly Snow Cover and Sea Ice Extent (Snow), which records the weekly snow cover in northern hemi-sphere on 1.0 latitude  X  1.0 longitude grids from January, 1971 to December, 1995. Each grid is treated as an attribute. By re-moving invalid observations, the number of attributes p is 9 , 148 , and the number of samples n is 297 ; (2) the NCEP/NCAR Re-analysis air data (Air), which contains daily air temperature on the earth with 2.5 latitude  X  2.5 longitude global grids. The number of attributes p is 10 , 512 and by following [14] we use n = 1460 records in year 2001; (3) the CPC Unified Gauge-Based Analysis of Daily Precipitation over CONUS (Precip), which focuses on the daily precipitation in USA. The valid data contains p = 13 , 610 attributes and we use n = 3652 observations from year 1997 to year 2006; (4) the NOAA X  X  Outgoing Longwave Radiation (OLR) Daily Climate Data Record, which provides the OLR records on the earth. In this dataset, p equals 21 , 720 and n is equal to 2903 . For the Stock dataset, we collect p = 21 , 602 stocks with daily closing price recorded in latest 300 days before Dec. 31, 2015. Table 3 reports experimental results for the QUIC, Big-QUIC, BCDIC and QUIC&amp;Dirty methods on all the datasets, while Table 4 gives the results of the COP and COP-` 1 methods. In Table 3, the QUIC, Big-QUIC and BCDIC methods, whose  X   X  X  have about 10 p non-zero entries, have much larger NLL X  X  on the test data especially for the Snow, Air, and OLR datasets when comparing with the COP and COP-` 1 methods in Table 4. The QUIC&amp;Dirty method has better NLL te than the sparse inverse covariance estimation meth-ods on the Snow and Air datasets, but it fails to learn the model on the larger Precip, OLR and Stock datasets in reasonable time. Under all the settings, we set the rank of the COP method to be 5, which is good enough to obtain lower NLL X  X  on all the test data, and we choose the model parameters for the COP-` 1 method to obtain similar testing NLL X  X  to the COP method. According to Table 4, in most settings, the COP method not only has better NLL te the COP-` 1 method but also performs faster. The exceptions are that on the OLR dataset, the COP-` 1 method has better predictive performance and that it is slightly faster on the Stock dataset. Moreover, we provide some additional results for the QUIC, Big-QUIC and BCDIC methods on the Snow, Air, OLR and Stock datasets in Table 5, where their regularization parameters  X   X  X  are selected such that the resulting estimators can achieve comparable Stock datasets when decreasing  X  to obtain more non-zero elements. te QUIC Big-QUIC BCDIC NLL X  X  on the test data with those of the COP and COP-` 1 Table 5 does not include the Precip data, because the result reported in Table 3 is already comparable to those of the COP and COP-` methods. Under this setting, the QUIC&amp;Dirty method still can not return any result in 5 hours and so it is not included. From the re-sults, we can see that in order to achieve lower NLL X  X  on the test set of the four datasets, the numbers of the non-zero entries in their estimators become larger and as a consequence, the running time of the three methods significantly increases, which again demon-strates the efficiency of the proposed COP and COP-` 1 methods.
In this paper, we proposed an efficient component pursuit (COP) method and its ` 1 -regularized variant for the large-scale inverse co-variance estimation problem by assuming that the inverse covari-ance is a combination of a low-rank matrix and a diagonal matrix. Both theoretical analysis and empirical evaluations demonstrate the effectiveness and efficiency of the proposed methods when com-pared with the state-of-the-art methods.

As a future direction, we are interested in applying the COP methods to more large-scale applications, e.g., the gene expression data, where there exists inherent low-rank structure among the fea-tures. Another future direction is to extend the COP method to deal with more complex structure in the inverse covariance estimation problem, e.g., the low-rank plus block diagonal structure, since in many applications such as financial analysis, the group information among features is available as a priori information. datasets will lead to memory exceeded problem for the three meth-ods and hence we just set  X  to be 0 . 95 .
 This research was partially supported by NSF IIS-1250985, NSF IIS-1407939, NIH R01AI116744 and NSFC 61305071.
 [1] F. Bach, J. Mairal, and J. Ponce. Convex sparse matrix factor-[2] M. T. Bahadori, Q. R. Yu, and Y. Liu. Fast multivariate spatio-[3] O. Banerjee, L. El Ghaoui, and A. d X  X spremont. Model selec-[4] O. Banerjee, L. E. Ghaoui, A. d X  X spremont, and G. Natsoulis. [5] V. Chandrasekaran, P. A. Parrilo, and A. S. Willsky. Latent [6] A. d X  X spremont, O. Banerjee, and L. El Ghaoui. First-order [7] J. Fan, F. Han, and H. Liu. Page: Robust pattern guided esti-[8] J. Fan, Y. Liao, and H. Liu. An overview on the estimation [9] J. Fan, Y. Liao, and M. Mincheva. High dimensional covari-[10] J. Fan, Y. Liao, and M. Mincheva. Large covariance es-[11] J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse co-[12] P. Gong, C. Zhang, Z. Lu, J. Z. Huang, and J. Ye. A general [13] L. Han, G. Song, G. Cong, and K. Xie. Overlapping decom-[14] C.-J. Hsieh, I. S. Dhillon, P. Ravikumar, and A. Banerjee. A [15] C.-J. Hsieh, I. S. Dhillon, P. K. Ravikumar, S. Becker, and [16] C.-J. Hsieh, I. S. Dhillon, P. K. Ravikumar, and M. A. Sustik. [17] C.-J. Hsieh, M. A. Sustik, I. S. Dhillon, P. K. Ravikumar, and [18] I. Jolliffe. Principal Component Analysis . Wiley Online Li-[19] C. Lanczos. An iteration method for the solution of the eigen-[20] H. Li and Z. Lin. Accelerated proximal gradient methods for [21] Z. Lu. Smooth optimization approach for sparse covariance [22] S. Ma, L. Xue, and H. Zou. Alternating direction methods [23] R. Mazumder and T. Hastie. Exact covariance thresh-[24] F. Oztoprak, J. Nocedal, S. Rennie, and P. A. Olsen. Newton-[25] B. Rolfs, B. Rajaratnam, D. Guillot, I. Wong, and A. Maleki. [26] E. Treister and J. S. Turek. A block-coordinate descent ap-[27] R. Yu, D. Cheng, and Y. Liu. Accelerated online low rank ten-[28] M. Yuan and Y. Lin. Model selection and estimation in the [29] H. Zou, T. Hastie, and R. Tibshirani. Sparse principal com-Proof . For problem (7), the derivative and the Hessian of f ( u ) can be calculated as  X  u f =  X  2 M  X  2 u f =  X  2(1 + u It is easy to see that 2 definite and u T M  X  1 k u &gt; 0 for any vector u . If S M is easy to see that the hessian  X  2 u f 0 and f ( u ) is convex w.r.t. u . However, under the high-dimensional case where S is posi-tive semidefinite but not positive definite due to n p , 2 S  X  least p  X  n negative eigenvalues. Moreover, the first term in the right-hand side of Eq. (17) is only a rank-one matrix. So  X  not positive semidefinite and hence f ( u ) is a non-convex function w.r.t. u . 2 Proof . The proof of Theorem 2 follows directly from the Proposi-tion 4 in [1]. 2 Proof . By considering the difference between L ( M k ) and L ( M uu T ) , we have
L ( M k )  X  X  ( M k + uu T ) =  X  log | M k | +  X  S , M k  X  + log | M k +  X  2 aa T | X  X  S , M  X  = log 1 +  X  2 a T M  X  1 k a  X   X  2 a T Sa .

Define l (  X , a ) = log 1 +  X  2 a T M  X  1 k a  X   X  2 a T Sa . We inves-tigate whether there exists some pair (  X , a ) such that When a is fixed, we define c 1 = a T M  X  1 k a and c 2 = a obviously c 1 &gt; 0 and c 2  X  0 since M  X  1 k is positive definite and function w.r.t.  X  as The convexity and the extreme value of l (  X  ) depends on the two scalars c 1 and c 2 . Fig. 3(a) plots some examples of the function l (  X  ) when adopting different values for c 1 and c 2 . By setting 0 we obtain the maximizer of l (  X  ) as
From Eq. (19), if c 1 &gt; c 2 , plugging Eq. (19) into l (  X , a ) gives max where q ( c ) = log c + 1 c  X  1 . Then we get  X  X   X  X  = 1 c see that the function q ( c ) is monotonically increasing when c &gt; 1 , we can get that L ( M k + uu T ) &lt; L ( M k ) .

When c 1  X  c 2 , based on Eq. (19), we have u =  X  a = 0 and hence L ( M k )  X  X  ( M k + uu T ) = 0 , which implies that adding an additional rank-one component is not helpful to decrease the NLL. If this happens, the greedy algorithm stops. 2 Proof . When condition (9) is satisfied, combing Eqs. (10), (19) and (20), we have Based on the proof of Proposition 1, q ( c ) is a monotonically in-creasing function w.r.t. c for c &gt; 1 . 2 Proof . According to Eq. (20), the decrease in the NLL becomes faster if c is larger, since q ( c ) is monotonically increasing when c &gt; 1 . Therefore, based on the analysis on the Rayleigh quotient problem (12), we reach the conclusion. 2 l( , ) -35 -30 -25 -20 -15 -10 q(c) Proof . Based on propositions 1-3, we only need to check whether u  X  =  X   X  a  X  is a local optimum of problem (7). Since  X  f ( u 0 and  X  2 u f ( u  X  ) 0 , u  X  is a local optimum and we reach the conclusion. 2 Proof . Proposition 1 implies that adding a rank-one component will lead to a lower NLL in the current iteration, if the component vector a satisfies Eq. (9). Moreover, after adding a rank-one com-ponent, updating the diagonal part P solves a convex function w.r.t. P , and therefore the NLL will not increase after the updating. So the NLL is guaranteed to decrease during iterations in Algorithm 1 until there is no vector satisfying Eq. (9) and then the algorithm converges. 2
