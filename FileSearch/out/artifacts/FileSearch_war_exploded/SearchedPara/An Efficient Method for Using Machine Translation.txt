 Topics in prior-art patent sear ch are typically full patent applications and relevant item s are patents often taken from sources in different languages. Cross language patent retrieval (CLPR) technologies support search ing for relevant patents across multiple languages. As such, CLPR requires a translation process between topic and document langua ges. The most popular method for crossing the language barrier in cross language information retrieval (CLIR) in general is machine translation (MT). High quality MT systems are becoming widely available for many language pairs and generally have higher effectiveness for CLIR than dictionary based methods. Ho wever for patent search, using MT for translation of the very long search queries requires significant time and computatio nal resources. We present a novel MT approach specifically designed for CLIR in general and CLPR in particular. In this method information retrieval (IR) text pre-processing in the form of stop word removal and stemming are applied to the MT training corpus prior to the training phase of the MT system. Applying this step leads to a significant decrease in the MT computational and resource requirements in both the training and translation phases. Experiments on the CLEF-IP 2010 CLPR task show the new technique to be 5 to 23 times faster than standard MT for query translation, while maintaining statistically indistinguishable IR effectivenes s. Furthermore the new method is significantly better than stan dard MT when only limited translation training resources are available. H.3 [ Information Storage and Retrieval ]: H.3.3 Information Search and Retrieval Algorithms, Performance, Experimentation. Patent Retrieval; Cross-Language Information Retrieval; Machine Translation. Interest in patent retrieval re search has shown considerable growth in recent years. The focus of most of this research has mainly been on exploring methods for monolingual patent search tasks, where the emphasis has b een on indexing techniques for patents and query formulation for topics. However, an important and largely overlooked topic in patent retrieval is international and hence multilingual patent sear ch. Patents on the same topic may be published in different countries in different languages, and it is important for patent examiners to be able to locate relevant existing patents whatever language they are published in. Hence an important topic in patent retrieval is cross-language information retrieval (CLIR), where the topic is a patent application in one language and th e objective is to find relevant prior-art patents in other languages [2, 6]. In recent years machine translation (MT) has become established as the dominant technique for translation in CLIR. This has largely come about due to the increased availability of high quality MT systems, which usually achieve better CLIR effectiveness than dictionary-based translation methods. St andard MT systems focus on generating proper translations that are morphologically and syntactically correct. Development of effective MT systems requires large training resources and high computational power for training and translation. This is an important issue for patent CLIR where queries are typically very long, sometimes taking the form of a full patent application; meaning that query translation using MT systems can be very slow and computationally demanding. However, in contrast to MT, the focus for information retrieval (IR) is on the conceptual meaning of the search words regardless of their surface form. Thus much of the complexity of the standard MT process is not required for effective CLIR. The significant time and re sources required for translation of patent topics in cross language patent retrieval (CLPR) has not received much attention to date. In addi tion, some language pairs have limited suitable training data available, meaning that it is not possible to train an effective MT system for these language pairs leading to low CLPR effectiveness. In this paper, a novel adaptation of MT for CLIR is presented which addresses the high com putational cost and resource requirements of MT for CLPR. The is demonstrated to be up to 23 times faster than standard MT in both the training and decoding phases for the CLEF-IP 2010 patent search task. Retrieval effectiveness using the new approach is shown to be statistically indistinguishable from that obtained using standard MT. Furthermore, it is found to be sta tistically significantly better than standard MT when only a small amount of data is used to train the system. In recent years, several IR ev aluation campaign have included tracks exploring recall-orientated tasks. Two of these are the NTCIR [2] and CLEF [6] patent search tracks, which have examined ad-hoc search, invalidity search, and prior-art search. In this paper, we focus on the prio r-art patent search task, which is concerned with finding all relevant patents that can invalidate the novelty of a patent application or at least that have common parts to that patent [6]. The full patent application submitted to the patent office is considered as the topic, and patent citations that are identified by the patent office are taken as the relevant documents, therefore the objective in prior-art patent search is to find these citations of patents automatically. CLPR has featured as a task at both NTCIR and CLEF. The typical procedure adopted for CLPR has been to translate the query into the target collection la nguage using one of the available free MT systems, and then to perform search in the document language. Thus this research has tr eated the translation stage as a black box without any control over the translation process. In addition, little attention has been directed toward the time taken for the translation process. The basic idea of the new approach is to train an MT system for translation of topics or documen ts in CLIR using training data pre-processed for IR. The pre-processing uses the standard stages performed by most IR systems. specifically case folding, stop word removal, and stemming. Th ese operations aim to improve retrieval efficiency and impr ove effectiveness by matching different surface forms of word s. While these are standard processes in IR, for standard MT applying these operations would be destructive to the quality of the translated output. For example, the translated sentence  X  he are an great idea to applied stem by information retrieving  X  instead of  X  It is a great idea to apply stemming in information retrieval  X  would be considered a very bad translation from an MT pers pective. However, from an IR perspective this output is fine si nce it contains all the information needed for the retrieval process, since both are the same after IR pre-processing:  X  great idea appli stem informat retriev  X . Our hypothesis is that training an MT system using corpora pre-processed for IR can lead to sim ilar or improved translated text from the IR perspective, which consequently can lead to better retrieval effectiveness. In addition, the training of the MT system is expected to be much faster and more efficient, since a large proportion of the training text represented by the stop words will be removed, and the rest will be normalized creating a smaller vocabulary. Further this reduced vocabulary should mean that a smaller training corpus will be found to be as effective as a larger unprocessed one for translation in CLIR. Figure 1 presents the workflow of the proposed CLIR system. The upper part represents the MT training which produces the translation model used for the translation step in the CLIR. The new  X  X ext Processing X  step intr oduced for both languages in the parallel corpus works by applying the standard IR pre-processing steps. The resulting translation model is in the  X  X rocessed X  form, where words are in their stemmed form and no stop words are present. For consistency, th e terms  X  X rocessed X  and  X  X ext Processing X  in the remainder of the paper refer to  X  X ase folding X ,  X  X top word removal X  and  X  X temming X . For query translation in CLIR when using MT, a query in source  X  X  X  language is translated into ta rget  X  X  X  language; the translated query is then processed in language  X  X  X  for search. Actually, when using MT for CLIR, longer que ries are preferable since they tend to be more grammatical, therefore better translation can be achieved using an MT system taking context into account, leading to better retrieval effectiveness. The novel translation approach introduced here is shown in the lo wer part of Figure 1. It can be seen that the  X  X ext Processing X  step has been moved to be a step prior to translation instead of a posterior step in the standard CLIR workflow. Therefore, the processing is applied to the source language query which produces a much shorter input with a reduced vocabulary to be translated using the processed MT model. The output from the translation process is in the processed form, and therefore no additiona l processing of the query is required. This query is used directly to search the index of documents and produce a list of retrieved results. The experimental inve stigation examines th ree main dimensions of the proposed approach. The first is to explores the effect of processing the words before the MT step. The second investigates the efficiency of the proposed translation process according to the computational requirements for the MT training and decoding phases when compared to translation using standard MT. However, more emphasis is given to the decoding time for query translation since it is the online processing time for translating the query which is generally more significant to the user. The third dimension considers the effect of using a limited amount of training data on the retrieval effectiveness. Retrieval effectiveness in this investigation is measured using MAP and the recently introduced patent retrieval evaluation score (PRES) [3]. PRES is an evaluation score designed for recall-oriented tasks where the objective is to find all possible relevant documents at the highest possible ranks. PRES emphasises the quality of the system in retrieving a large portion of the relevant documents at relatively high rank based on a user specific cut-off ( N max ). In our analysis, we focus on PRES since it is specifically designed for measuring retrieval ef fectiveness in patent search, where it combines recall and qua lity of ranking in one score. Moreover, it is used in CLEF-IP track since 2010 to evaluate the performance of the submitted runs. Significance is tested using a Wilcoxon test with p -value 0.05. In addition, the times for training the MT systems and for decoding (translating) the topics are calculated for both methods. The cross language search task in CLEF-IP 2010 is used for our experiments. The main objective is to find relevant patents in a multilingual collection that are relate d to patent applications filed in French and German languages. The patent collection consists of 1.35M patents from the European Patent Office (EPO) with 69% of them in English and 31% in German and French. The German and French patents are provided w ith many sections manually pre-translated into English, including the patent title, abstract and claims. The English text of all patents in the collection was indexed to create an index of documents in English only. The CLEF-IP track provided two sets of topics; 300 training topics of which 89 are German, 15 are French, and the remainder are English; and 2000 test topics of which 520 are German, 134 are French, and the rest are English. Both sets of topics are patent applications filed after those in the patent collection and do not contain translations. For the CLPR experiments, the 89 German training topics and the 134 French test topics were selected to have a similar number of topics for each query language. Since the patent collection comes from the EPO, most of the patents in the collection have the title and claims sections translated into three languages (English, French, and German). For the MT experiments, more than 8M (~8.1M) parallel sentences in English, German, and French were extracted from the collection for use as the MT training set. The average length of the English sentences in the corpus is 28 words. Query formulation from the patent topic is one of the main challenges in patent search [2, 6]. To construct a baseline retrieval run, we tested a number of query formulation approaches based on the best runs submitted to the CLEF-IP 2010 [6]. Based on these existing runs, our query form ulation used the title, abstract, description, claims, and classification sections. We followed the our query formulation originally presented in [4], where the query is constructed using terms in the topic after translation that appeared more than two times across the sections when combined and all bigram terms that appeared more than three times, with the term frequency acting as weight for these terms. The Indri search toolkit 1 was used for indexing and search, Porter stemmer was applied for the queries and docume nts, and a list of 684 stop words from patent domain used in [4] was filtered out from text. Two baseline runs were prepared for each query language: the first baseline used Google translat e to translate the German and French topics into English, as was done by most of the participants in CLEF-IP 2010 [6]. For the second and main baseline, we used the MaTrEx MT system 2 [7]. The 8M extracted sentences were used to train the MaTrEx MT system to create two translation models: (French  X  English) and (German  X  English). The default configuration and trai ning parameters of the MaTrEx system were used to generate the translation model, which was then used to translate the German and French test topics into English. Table 1 shows the MAP and PRES values for each of the baselines for the French and German topics. From these results it can be seen that, for the French topics the Google and MaTrEx MT systems achieved similar retrieval effectiveness. However for German topics Google translate achieved lower performance with respect to both MAP and PRES, this can be attributed to the many unusual compounds found in the text that require a training corpus in a similar domain in order to be translated effectively. For the translation time using MaTrEx, it was found that the average translation time was 31 mins for the French patent topic (which contain 7,058 words on average) and 12 mins for the German patent topic (which contain 3,571 words on average) on a server machine (Intel Xeon quad-core processor, 2.83GHz, 12MB cache, and 32GB RAM). However, the average search time using all the translated text as a query was 42 secs for French topics and 14 secs German topics on a deskt op machine (Intel Core2Due, 3GHz, 6MB cache, 3GB RAM). This highlights the importance of developing faster translation techniques for patent topics. Table 1: Baseline runs for the German and French topics The same training dataset of parall el sentences was used to train the MaTrEx MT system again, but after pre-processing the data ( X  X rocessed MT X ). This was then compared to the standard MT system without pre-processing the data ( X  X rdinary MT X ). In addition, several portions of the training data were selected and used to train alternative MT systems to explore the performance of both MT systems when less training examples are available. For these experiments subsets 800k, 80k, 8k and 2k sentences were extracted at random from the full 8M training set and used to train the additional MT systems. Table 2 shows the retrieval effectiveness measured by MAP and PRES, the out-of-vocabulary ( OOV) rates when decoding the topics, and decoding time for French and German topics compared when using ordinary MT vs. processed MT for the cross language patent search task. For the retrieval effectiveness measured by MAP and PRES, it can be seen that the difference in the retrieval effectiveness using both translation methods is not signi ficant compared to each other for almost all training sizes. Howe ver, with smaller training sets (2k), it is found that the processed MT achieved significantly better retrieval effectiveness than the ordinary MT for both query languages when compared using PRES. For the French topics when using processed MT, results remain statistically indistinguishable from Google translate for training sizes 8M, 800k, and 80k. However, for ordi nary MT, the 80k training set translation led to retrieval that is statistically worse than Google translate when compared using PRES. These results show that the new approach has higher effec tiveness when limited amounts of training data are available. To analyse the reason behind th ese results, the OOV percentage while translating the patent topics is also reported in Table 2. It can be seen that the stemming performed in the  X  X ext Processing X  step in the processed MT syst em reduces the number of OOV terms, leading to the presence of a translation. In particular, it can be seen that for small size training sets, the standard translation approach suffers from a large percentage of OOVs, while the processed MT system overcomes part of this problem. The German topics suffer from higher OOV than the French ones due to the presence of produc tive compounds in German. The second main benefit of the ne w approach to translation is shown clearly in the last row of Table 2, which compares the average decoding time required to translate a patent topic into English using both approaches. It can be seen that the processed MT system is at least 5 times faster than the ordinary MT system MAP PRES OOV (%) 
Decoding time ( mm:ss ) when using the same training parallel corpus. In addition, with smaller sized training data sets, the speed of decoding using the new MT system reaches up to 23 times faster than the ordinary MT system. Furthermore, the decoding time needed for the processed MT system when it is tr ained with 8M parallel sentence is comparable to the decoding time required for the ordinary system when it is trained with only 2k examples. Similar results to those shown in Table 2 were obtained for the training time, where the training time for the processed MT system was 5 to 13 times faster than the ordinary MT system. Comparing the retrieval effectiveness of the processed vs. the ordinary MT systems when a very small training corpus was used (only 2k) performance was statistic ally indistinguishable when compared by MAP, but statisticall y better for processed MT when compared by PRES. This result means that while the systems cannot be distinguished when compared with respect to finding relevant documents at very high ranks, the processed MT is noticeably better when compared to standard MT for finding a greater number of relevant documents at higher ranks. For a recall-oriented search task such as patent retrieval, PRES is a more a meaningful score, since the average number of documents to be examined for this task is often large, sometimes reaching hundreds of documents [1]. The large difference in the average translation time for a French patent compared to that of a German patent stems from the length of the patents, where the French patents are nearly double the length of the German patents on average due to word compounding in the German patents. In addition, the high percentage of the OOV terms in the German patents speeds up the translation since no translation is examined for OOV words. Removing the stop words from the text reduces the amount of text to be translated by nearly half. However, the gain in speed is much more than the double (5 to 23 times). The reason for this comes from the nature of stop words, where the MT takes a longer time to translate them in order to select the proper translation in the proper position. Additionally, stemming reduces the vocabulary in the MT model leadi ng to less choices of translation for terms, which leads to higher translation speed. This paper has presented a novel technique for adapting MT systems for the purpose of CLIR. Although the technique mainly comprises a re-ordering of the workflow of the steps in CLIR, the impact was shown to be significantly more efficient in the resource and computational requirem ents of the MT process. The new technique was tested on the pa tent search task that usually requires a large amount of traini ng data and for which the query translation time that can reach more than 50 times the search time. Experimental results show that processing the text by stop word removal and stemming be fore MT training and decoding leads to speeding up the translation process by up to 23 times. In addition, this technique proved to be much more effective when a limited amount of data is available. For future work, the approach shoul d be tested for different types of CLIR tasks including ad hoc and web search, especially for languages where limited MT trai ning resources are available. This research is supported by the Science Foundation Ireland (Grant 07/CE/I1142) as part of the Centre for Next Generation Localisation (CNGL) project. 1 Azzopardi L., H. Joho and W. Vanderbauwhede. A Survey on 2 Fujii A., M. Iwayama, and N. Kando. Overview of patent 3 Magdy W. and G. J. F. Jones. PRES: a Score Metric for 4 Magdy W. and G. J. F. Jones. Applying the KISS Principle for 5 Oard, D. W. and Diekema, A. R. Cross-Language Information 6 Piroi F. CLEF-IP 2010: Retrieval Experiments in the Intellectual 7 Stroppa, N. and A. Way. 2006. MaTrEx: DCU Machine 8 Wang J., D. W. Oard. Combining Bidirectional Translation 
