 Update is a fundamental data management activity. Data updates allow users to remove expired data, to correct data, and to insert new data. Maintenance of a dynamic dataset and its corresponding discovered knowledge is more com-plicated compared to the knowledge disc overy of a stable dataset. Updates may induce new knowledge and invalidate discovered information. Re-execution of discovery algorithms from scratch every time when a database is updated causes significant computation and I/O overheads. Therefore, effective algorithms to maintain discovered knowledge on the updated database without re-execution of mining algorithms are very desirable.

Databases can be updated in several manners. We focus here on the case when a batch of transactions are removed from the existing database. A novel method is proposed to update and maintain discovered frequent patterns [1].
Let I = { i 1 , i 2 , ..., i m } be a set of distinct literals called  X  X tems X . An  X  X temset X , or a  X  X attern X , is a set of items. A  X  X ransaction X  is a non-empty set of items. A  X  X ataset X  is a non-empty set of transactions. A pattern P is said to be contained or included in a transaction T if P  X  T . A pattern P is said to be contained in a dataset D , denoted as P  X  X  ,ifthereis T  X  X  such that P  X  T .The  X  X upport X  of a pattern P in a dataset D , denoted sup ( P, D ), is the number of transactions in D that contain P . A pattern P is said to be frequent in a dataset D if sup ( P, D ) is greater than or equal to a pre-specified threshold ms .Givena dataset D and a support threshold ms , the collection of all frequent itemsets in D is called the  X  X pace of frequent patterns X , and is denoted by F ( ms, D ).
The  X  X pace of frequent patterns X  can be large. As a result, maximum pat-terns [3, 7], closed patterns [8], key patterns [11] (also known as generators), and borders of equivalence classes [10] hav e been proposed to concisely represent the space of frequent patterns. Borders o f equivalence classes are arguably the most flexible succinct lossless representation of the frequent pattern space [10]. Conceptually, it partitions the frequent pattern space into equivalence classes that are convex. Then the entire space is represented by the most general and most specific patterns of these equivalence classes. As it turns out, these most general patterns are precisely the key patterns, and these most specific patterns are precisely the closed patterns.

The task of frequent pattern maintenance is to update the  X  X pace of frequent patterns X  according to the updates of the dataset.

Incremental maintenance , where new transactions are inserted, has at-tracted intensive research attention. Current incremental maintenance algo-rithms can be categorized into two main approaches: Apriori -based[5,6,2] and sliding window filtering ( SWF ) [4, 9]. The performance of both Apriori -based and SWF algorithms is limited by the candidate-generation-elimination framework, which involves multiple d ata scans and unneces sary computations on infrequent candidates.

To achieve more efficient updates, algorithms are proposed to incrementally maintain only frequent maximum patterns. ZIGZAG 1 [12] is one effective repre-sentative. ZIGZAG is inspired by its related work GenMax [7]. It incrementally maintains maximum patterns by a backtracking search, which is guided by the outcomes of previous maintenance iteration.

Decremental maintenance , where old transactions are removed, on the other hand, has not received as much res earch attention. Zhang et al. [13] pro-posed an algorithm, named DUA , to address the decremen tal maintenance prob-lem. DUA maintains frequent patterns by a pairwise comparison of original fre-quent patterns and patterns included in the removed transactions. Since the number of frequent patterns is usually enormous, the pairwise comparisons cause heavy computations. In addition, algorithms FUP2H [6], Borders [2], ZIGZAG can also be applied to decremental mainten ance with some parameter changes.
It is observed that most previous methods are proposed as an extension of some effective data mining algorithms or data structures. E.g. FUP [5] and Bor-ders [2] are developed based on Apriori ,and ZIGZAG is inspired by GenMax . Unlike these previous works, our algorithm is proposed based on an in-depth study on the evolution of the frequent pattern space. In [10], we found that the space of frequent patterns can be decomposed into sub-spaces  X  equivalence classes, as shown in Figure 1 (a). Definition 1. Let the  X  X ilter X , f ( P, D ) ,ofapattern P in a dataset D be defined as f ( P, D )= { T  X  X | P  X  T } . Then the  X  X quivalence class X  [ P ] D of P in a dataset D is the collection of patterns defined as [ P ] D = { Q | f ( P, D )= f ( Q, D ) , Q is a pattern in D} . Note that under this definition, [ Q ] D =  X  if Q does not appear in D . For convenience in some of our proofs, we also use the traditional notion of an equivalence class, and write it as [ P ]  X  D = { Q | f ( P, D )= f ( Q, D ) } . In other words, two patterns are  X  X quivalent X  in the context of a dataset D iff they are included in exactly the same transactions in D . Thus the patterns in a given equivalence class have the same support. So we extend the notations and write sup ( C, D ) to denote the support of an equivalence class and C  X  X  ( ms, D ) to mean the equivalence class is frequen t. Figure 1 (a) presents the frequent pattern space for the original dataset with ms = 2. In addition, it graphically demonstrates how the space of frequent patterns can be structurally decomposed into frequent equivalence classes.

Structural decomposition of frequent pattern space inspired us to solve the maintenance problem in a divide-and-conquer manner. Instead of maintaining the pattern space as a whole, which is computationally costly, we attack the problem by maintaining each frequent equivalence class. Compared with the frequent pattern space, an equivalence class is much smaller and easier to update. Moreover, not all the equivalence cla sses are affected by the updates. If we can efficiently locate only those equivalenc e classes that are affected by the updates, we can solve the problem effectively by u pdating only the affected equivalence classes. In addition, a nice property of equivalence classes of patterns is that they are convex and they can be concisely repr esented by their borders. The border of an equivalence class consists of a closed pattern and a group of key patterns [10]. Thus, the corresponding closed and key patterns form the border of and define an equivalence class. Definition 2. A pattern P is a  X  X ey pattern X  in a dataset D iff for every P  X  pattern X  in a dataset D iff for every P  X  P , it is the case that sup ( P , D ) &lt; sup ( P, D ) . We investigate in this section how freque nt patterns, key patterns, closed pat-terns, equivalence classes and their support values evolve when multiple trans-actions are removed from an existing dataset. We use the following notations: D org is the original dataset, and D upd  X  = D org  X  X  dec is the updated dataset. We assume without loss of generality that D dec  X  X  org .
 An existing equivalence class can evolve in exactly three ways, as shown in Figure 1 (b). The first way is to remain unchanged without any change in sup-port. The second way is to remain unchanged but with a decreased support. If the support of an existing frequent equivalence class drops below the minimum support threshold, the equivalence class will be removed. The third way is to grow X  X y merging with other classes, where at most one of the merging classes has the same closed pattern and the same support as the resulting equivalence class and all other merging classes have l ower support. In short, after the decre-mental update, the support of an equivalence class can only decrease and the size of an equivalence class can only grow by merging.

In order to have an in-depth understanding of the three ways that an existing equivalence class may evolve, we now provide the exact conditions for each of these ways to occur.
 Proof. Refer to the Appendix in the full online version of this paper at http://www.ntu.edu.sg/home5/feng0010/FullPaper.pdf .
 This theorem describes in detail how t he space of frequent patterns evolves when a group of transactio ns are removed. Moreover, it describes how to derive equivalence classes in D upd  X  from existing equivalence classes in D org ,whichis an extremely constructiv e result for the maintenance of frequent patterns. An algorithm for maintaining the frequent pattern space after some trans-actions are removed from the original database is proposed in Figure 2. In the proposed algorithm TRUM , we use notations X.closed to mean the closed pattern of an equivalence class, X.keys to mean the set of keys of an equivalence class, and X.sup to denote the support value of an equiv-alence class. The algorithm addresse s the maintenance problem effectively by working on the borders of equival ence classes, instead of the entire pattern space. The proposed algorit hm is proved to be correct and com-plete. (Refer to the Appendix in the full online version of this paper at http://www.ntu.edu.sg/home5/feng0010/FullPaper.pdf .) With proper implementation techniques, the computational complexity of TRUM can be approximated as O ( |D dec | ), where |D dec | denotes the size of the decremental dataset. This shows that TRUM is much more computationally ef-fective, compared to previous works, like [7, 12], whose computational complexity is O ( N FP ), where N FP refers to the number of frequent patterns. This is be-cause O ( |D dec | ) N FP . (Some implementation techniques are suggested in our full paper http://www.ntu.edu.sg/home5/feng0010/FullPaper.pdf ). 4.1 Experimental Studies Extensive experiments were performed to evaluate the proposed algorithm. TRUM was tested using several benchmark datasets from the FIMI Reposi-tory, http://fimi.cs.helsinki.fi . Due to space constraints, only the results of T 10 I 4 D 100 K , mushroom and gazelle are presented in this paper. These datasets form a good representative of both synthetic and real datasets.
We varied two parameters in our experiments: minimum support ms and update interval. For each employed ms , we preformed multiple execution of the algorithm, where each executi on employed a different update interval. Moreover, the performance of the algorithm varies slightly when different sets of transac-tions are removed. To have a stable performance measure, for each update inter-val, 5 random sets of transactions were employed, and the average performance of the algorithm was recorded. The expe riments were run on a PC with 2.8GHz processor and 2GB main memory.

To justified the effectiveness of the pr oposed algorithm, we compared its per-formance against some state-of-art frequent pattern discovery and maintenance algorithms. These algorithms includes ZIGZAG [12], FpClose [8] and GC-growth [10]. Results of the performance co mparison is presented in Figure 3.
We observe that TRUM outperforms ZIGZAG by at least an order of magni-tude over all update intervals. The advantage of the proposed algorithm is most obvious in mushroom dataset. For mushroom dataset, TRUM , on average, out-performs ZIGZAG 200 times. It is measured that, for both T 10 I 4 D 100 K and gazelle , TRUM achieves around 80 and 20 times average speed-up.
 TRUM is also more effective compared to r e-discovering all patterns using FpClose and GC-growth .E.g. TRUM is, on average, 30 times faster than FpClose and 100 times faster than GC-growth for T 4 I 10 D 100 K dataset. However, we also observe that as the size of the removed transactions increases, the advantage of TRUM diminishes. This is because, corresponding to the complexity analysis, the execution time of TRUM increases as more transactions are removed. In contrast, due to the shrinkage of data size, the execution time of re-discovery approaches drops when more transactions are removed. Combining these two effects, it is logical that the speed-up gained by our maintenance approach diminishes as the size of removed transactions goes up.

The performance of the proposed algorithm was also evaluated under different support thresholds ms . The results are presented in Figure 4. It demonstrates that TRUM remains effective compared to FpClose over a wide range of minimum support thresholds. Nevertheless, the achieved speed-up drops slightly for higher ms thresholds. When ms is high, the frequent pattern space becomes smaller, which makes the discovery process much easier. As a result, the advantage of TRUM becomes less obvious. This paper has investigated how the space of frequent patterns, equivalence classes, closed and key patterns will evol ve when transactions are removed from a given dataset. It was shown that the equivalence classes can evolve in three ways: (1) remain unchanged with the same support value, (2) remain unchanged with decreased support value, and (3) grow by merging with others. Based the evolution analysis, an effective maintenance algorithm TRUM is proposed. TRUM maintains the frequent pattern space usi ng the concept of equivalence classes. TRUM addresses the problem efficiently by updating only the affected equiva-lence classes. The effectiveness of the proposed algorithm is validated by exper-imental evaluations.

This paper, to our best knowledge, is the first to study the evolution of fre-quent pattern space under data updates. The proposed algorithm outperforms the state-of-the-art algorithms at least an order of magnitude over a wide range of support thresholds and update sizes. In the future, it is interesting to exploit the evolution of frequent pattern space under other types of updates, e.g. addi-tion of transaction and items, or removal of items. Solving these maintenance problems with an equivalence class approach could be promising.

