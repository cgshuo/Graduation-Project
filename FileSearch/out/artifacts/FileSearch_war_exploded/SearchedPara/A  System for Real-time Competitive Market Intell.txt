 much information is now available on-line and is immedi-ately accessible, we can readily use computers to scan the digital writings with some higher level purpose in mind, in our case looking for word patterns and trends over a sam-pling period. 
In a sense, we can poll the new wires to look for patterns in the stories, for example whether the stories written about a certain company over the last month are favorable or not. 
Clearly, we do not have the rigor of a scientific poll, where a sample is randomly collected and attempts are made to get quantifiable answers to carefully crafted questions, such as multiple choice questions. Our sample is a collection of written articles, and these articles are hardly in the form of answers to polling questions. Yet, we will view the articles as virtual individuals and extract patterns over the sample. 
While the collection of stories is not a well-organized as a formal poll, it is more immediate, less difficult to obtain, and can still provide valuable information on competitive perceptions and changes in brand image. 
We can make this pseudo-poU more organized and scien-tific. Instead of aimlessly, collecting articles that appear on a newswire, we can specify a subset to be collected relative to key characteristics. Our goal is competitive analysis, so it is straightforward to specify a set of competitors and sam-ple all articles for those companies. Moreover, we can limit those articles to a specific time period, for example the most recent week or month. While the written word is inherently qualitative, unlike a poll where the questions seek quanti-tative information, we may enhance objectivity by relating the articles to a highly exact, numerical measure, such as the companies' stock prices. It might be entertaining to try and predict stack price movements, relative to the written word, and in some sense traders try to do this by check-ing written documents, such as analyst's recommendations or other news sources. Such information is rapidly factored into a stock price. However, for a competitive analysis, less predictive power is required. Stock movements and news stories can be tracked relative to the competitors, so that we can observe patterns that indicate relative strength or weakness, even though the overall market trend may be in another direction. For example, one company may be get-ting much better press, and may be doing better than its competitors, even though its stock is declining because of a recession and overall poor economic conditions. 
How do most people access documents on the web? They  X  Crawl the net in real time for articles about the com-petitors.  X  Specify conditions for separating the documents into groups for comparison.  X  Transform the text into a numerical form in prepara-tion for applying machine learning methods. market intelligence system is an advisory system that does not reach perfect; decisions, the analysts will always have an opportunity to select the interesting results. That reduces the need for exacting preparation of sample data. 
Unlike the typical text categorization problem, or the clas-sical numerical classification problem, labels are not perma-nently assigned. Here they are computed. We know that we will compare two or more groups of documents, but the composition of those groups can vary greatly depending on the satisfaction of various conditions for computing the la-bels. The crawler has assembled documents for a set of competitors. Not all these documents may be used in the a given comparison. We may compare a company to itself over different time periods. We may compare two or more (groups of) companies over different time periods. We may compare the same company for instances when the stock price rose versus when it declined. The general approach is illustrated in Figure 2. A set of conditions are specified for the stories of one of the competitors. Currently, these condition include the company name, a time period, stock price change and relative capitalization change. The stories that meet the conditions are extracted from the database of documents collected by the crawler. They form a sin-gle group of documents for comparison and are assigned the same label. The process is repeated for each group. When the conditions change, the labels may change. 
At this point, we have a text categorization problem, the data has been separated into different groups of labeled doc-uments, all in XML format. To solve this problem, a number of methods can be applied. As we indicated earlier, our pref-erence is for rule induction. The result will be analogous to reversing the usual search with a search engine, and instead, finding the most likely patterns for the documents. Figure 4 illustrates the steps taken to find patterns in the data. 
First a dictionary of words is extracted from the data. One 1. Specify the two groups to be compared. 2. Extract documents from the database corresponding 3. Store the documents belonging to the two groups in 
Figure 4: Finding Patterns and Displaying Results 1. For each class create a local dictionary. 2. Merge the two dictionaries and remove stop-words. 3. Vectorize the stories and add class labels. 4. Apply rule induction methodsto find patterns that 5. Display word patterns. Highlight stories and the words 
Once the rules are induced, and they are found be less than promising, some of their words may be added to the stop-words, causing the method to search for alternative patterns not containing the previous unsatisfactory words. Thus, the process can be directed by knowledge of the analyst, shifting direction based on unsatisfactory results. 
The method learns compact disjunctive normal form (DNF) rules [5] and has proven to give excellent results on a wide variety of classification problems and has a time complex-ity that is almost linear in time relative to the number of rules and cases. This Lightweight Rule Induction (LRI) pro-cedure is particularly interesting because it can rival the performance of very strong classification methods, such as boosted trees. 
Figure 5 shows an example of a typical DNF rule gener-ated by LRI. The complexity of a DNF rule is described with two measurements: (a) the length of a conjunctive term and (b) the number of terms (disjuncts). In this example, the rule has a length of three with two disjuncts. Complexity of rule sets generated is controlled within LRI by providing upper bounds on these two measurements. 
The LRI algorithm for generating a rule for a binary clas-sification problem is summarized in Figure 6. FN is the number of false negatives, FP is the number of false pos-
Rives, and TP, the number of true positives, e(i) is the cumulative number of errors for case i taken over all rules. 
The components of our methods for text mining and pat-for problem statement. The current system incontrovertibly collects documents, organizes them to subsets and groups, and performs a form of text mining that has proven to be be very successful in yielding low error rates for document indexing. 
Can leveraging that approach be successful for market in-telligence? That is our hypothesis, but it cannot be readily evaluated by collecting large samples of examples and pro-ducing a single performance result. Instead, it is up to the market analysts to determine whether insightful or interest-ing patterns are found and their relevant text highlighted. 
Figure 7 is a snapshot of a straightforward comparison of news stories :for IBM and Microsoft during the first two months of 2002. We see that patterns emerge relative to the retirement of the CEO of IBM and the states antitrust actions for Microsoft. 
Consider the following excerpts from a session of market intelligence analytics: 1. Starting with stories dated after September 1, 2001, crawl the newswires and Collect stories for IBM, Mi-crosoft, Dell, Compaq, and Sun. These are the desig-nated competitors. Sample very 15 minutes and add any new materials. Clean and convert to XML. Col-lect price quotes at the time of stories. Add stories to current data base. 2. Indicate conditions for forming analytical groups and labels: IBM stories from December 1, 2001 until De-cember 10 versus IBM stories from December 11 until 
December 31. 3. Compare using rules of form A or B, where A and B are no more than 2 words each. Resulting patterns for recent period: (a) services or network (b) york or work, 
Display articles with these patterns and highlight sec-tion containing word patterns. The first pattern ap-pears in articles highlighting the signing of many new contracts for IBM Global Services. The second pat-tern is useless because york is just the location of New 
York. 4. Delete york and invoke a new comparison. Resulting patterns: sign or systems is added as the second pat-tern. Display documents and highlight words. 5. New comlitions. IBM vs Sun for the month of Decem-ber. [3] F. Sebastiani. Machine learning in automated text [4] S. Weiss, C. Apte, F. Damerau, and et al. Maximizing [5] S. Weiss and N. Indurkhya. Lightweight rule induction. 
