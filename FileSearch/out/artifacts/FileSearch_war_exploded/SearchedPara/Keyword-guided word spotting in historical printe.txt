 ORIGINAL PAPER T. Konidaris  X  B. Gatos  X  K. Ntzios  X  I. Pratikakis  X  S. Theodoridis  X  S. J. Perantonis Abstract In this paper, we propose a novel technique for word spotting in historical printed documents com-bining synthetic data and user feedback. Our aim is to search for keywords typed by the user in a large col-lection of digitized printed historical documents. The proposed method consists of the following stages: (1) creation of synthetic image words; (2) word segmen-tation using dynamic parameters; (3) efficient feature extraction for each word image and (4) a retrieval pro-cedure that is optimized by user feedback. Experimental results prove the efficiency of the proposed approach. Keywords Historical document indexing  X  Word spotting  X  User feedback 1 Introduction Historical printed documents contain a vast amount of valuable information. A robust indexing of these docu-ments is essential for quick and efficient content exploi-tation of the valuable historical collections. In this paper, we deal with historical printed Greek documents that date since the period of Renaissance and Enlighten-ment (1471 X 1821) and are considered among the first Greek printed historical documents. Nevertheless, the proposed methodology is generic having the potential to be applied to other than Greek historical printed documents. The general framework of our work is the development of a system that will integrate, manage and provide access to historical printed documents.
Traditional approaches in document indexing usu-ally involve an Optical Character Recognition (OCR) step [5]. OCR is widely used in a variety of applica-tions [14] and it performs well in modern printed doc-uments and documents of high quality printing. In the case of printed historical documents OCR, several fac-tors affect the final performance like low paper qual-ity, paper positioning variations (skew, translations, etc), low print contrast, typesetting imperfections. Usually, printed OCR systems involve a character segmentation step followed by a recognition step using pattern classifi-cation algorithms. Due to document degradations, OCR systems often fail to support a correct segmentation of the printed historical documents into individual charac-ters [2]. This is the case of the documents we used for our experiments. The low quality of the documents as well as typesetting imperfections did not allow any OCR tasks. Figure 1 shows the results of conventional OCR of an extract taken from the processed printed historical documents used in our experiments.

In the literature, two general approaches can be iden-tified: the segmentation approach and the global or seg-mentation-free approach. The segmentation approach requires that each word has to be segmented into char-acters while the global approach entails the recognition of the whole word. In the segmentation approach, the crucial step is to split a scanned bitmap image of a doc-ument into individual characters [9].

A segmentation-free approach is followed in [4,6,15, 16,18,23,35] where line and word segmentation is used for creating an index based on word matching. In [23], a discussion on different approaches to word matching is given. In [4], Ulam X  X  distance is used for image match-ing by identifying the smallest number of mutations between two strings. In [6], a two-dimensional image is converted into a one-dimensional string. The method describes how to extract information from the strings and compute the distance between them resulting in sim-ilar matches. In the segmentation-free approach of [35], word matching is based on the vertical bar patterns. Each word is represented as a series of vertical bars that is used for the matching process. Word image matching is also applied in [18] using the weighted Hausdorff distance. Before applying the matching process using the Haus-dorff distance a normalization scheme is used for each word. Word matching is also performed in [16] where global and local features based on profile signatures and morphological cavities are used for each word character-ization. Matching of whole words in printed documents is performed in [3]. In this approach, a Dynamic Time Warping (DTW) based partial matching scheme is used to overcome the morphological differences between the words. Another segmentation-free approach which uses HMMs and statistical language models for handwritten text is described in [31]. In [8] a holistic approach is used in order to digitize natural history cards containing both printed and handwritten information.
 In the case of historical documents, Rath and Manmatha [26] presented a word matching scheme where noisy handwritten document images are prepro-cessed into one-dimensional feature sets and compared using the DTW algorithm. Rath et al. [25] present a method for retrieving large collections of handwritten historical documents using statistical models. Lavrenko et al. [17] present a holistic word recognition approach for handwritten historical documents. They performed a series of experiments showing the performance of this segmentation-free approach applied to degraded histor-ical documents where the segmentation of words into characters is not feasible.

In [20,22] a method for word spotting is presented wherein matching was based on the comparison of entire words rather than individual characters. In this method, an off-line grouping of words in a historical document and the manual characterization of each group by the ASCII equivalence of the corresponding words are required. The volume of the processed material was limited to a few pages. This process can become very tedious for large collections of documents.

Typing all unique words as well as constructing an index is an almost impossible task for large document collections. To eliminate this tedious process, we pro-pose a novel method for keyword-guided word spotting which is based on: (1) creation of synthetic image words; (2) word segmentation using dynamic parameters; (3) efficient feature extraction for each image word and (4) a retrieval procedure that is improved by user feedback. The synthetic keyword image is used as the query image for the retrieval of all relevant words, initializing in this way, the word spotting procedure. The retrieval accuracy is further improved by the user feedback. Combination of synthetic data creation and user feedback leads to satisfactory results in terms of precision and recall. Fig-ure 2 illustrates the distinct steps of the proposed system architecture.

The paper is organized as follows: In Sect. 2, we describe the preprocessing stage including image binarization and enhancement, calculation of the aver-age letter height as well as frame removal. Section 3 is concerned with the word segmentation process that is based upon an efficient smoothing procedure. Section 4 describes the process of creating synthetic key-word images using character image templates. Section 5 details the feature extraction process while Sect. 6 is dedicated to the analysis of the word image retrieval process that is enhanced by the incorporation of user feedback. Experimental results are given in Sect. 7, dem-onstrating the performance of the proposed method in terms of precision and recall. Finally, in Sect. 8 conclu-sions are drawn. 2 Preprocessing 2.1 Image binarization and enhancement Binarization is the starting step of most document image analysis systems and refers to the conversion of the gray-scale image to a binary image. Since historical document collections are usually of very low quality, an image enhancement stage is also essential. The proposed scheme for image binarization and enhancement is described in [12,13] and consists of five distinct steps: a pre-processing procedure using a low-pass Wiener filter, a rough estimation of foreground regions using Niblack X  X  approach [24], a background surface calcu-lation by interpolating neighboring background intensi-ties, a thresholding by combining the calculated background surface with the original image and finally a post-processing step that improves the quality of text regions and preserves stroke connectivity. Figure 3 illus-trates the steps for improving image quality and finally a post-processing step that preserves stroke connectivity as well as eliminates noise and improves the quality of text regions by isolated pixel removal and filling of pos-sible breaks, gaps or holes. Figure 3 illustrates the steps for image binarization and enhancement. 2.2 Average character height estimation The average character height estimation is required for the frame removal step described in Sect. 2.3 as well as for the segmentation phase described in Sect. 3. For the calculation of the average character height we take a random pixel ( x A , y A ) that has at least one background pixel in its four-connected neighborhood and we follow the contour of the connected component where pixel ( x
A , y A ) belongs to. This procedure is repeated for a predefined number of random pixels that have at least one background pixel in their four-connected neighbor-hood. We then calculate the histogram with the heights of every connected component we have processed. The maximum value of the histogram corresponds to the average character height. Figure 4a illustrates the pro-cess of following the contour of the connected compo-nent that pixel ( x A , y A ) belongs to. Figure 4b illustrates how the bounding box of the connected component is formed. y corresponds to the height of the connected component. 2.3 Frame removal To ease the segmentation process we remove poten-tial frames around the text areas. The process of frame removal is based on the work of [10]. The line detection algorithm is based on processing horizontal and vertical black runs as well as on a set of morphological opera-tions with suitable structuring elements in order to con-nect possible line breaks and to enhance line segments. All parameters used in this step depend on the average character height that has been calculated in Sect. 2.2. An example of the frame removal procedure is shown at Fig. 5. 3 Segmentation The process involves the segmentation of the document images into words. Manmatha and Rothfeder [21] use a technique for automatically segmenting documents into words. In [29] different techniques for separating lines of unconstrained handwritten text into words is described. In the proposed methodology this is accom-plished with the use of the Run Length Smoothing Algo-rithm (RLSA) [30,35] by using dynamic parameters which depend on the average character height as it is described in Sect. 2.2. RLSA examines the white runs existing in the horizontal and vertical directions. For each direction, white runs with length less than a thresh-old are eliminated. In the proposed method, the hor-izontal length threshold is experimentally defined as 50% of the average character height while the verti-cal length threshold is experimentally defined as 10% of the average character height. The application of RLSA results in a binary image where characters of the same word become connected to a single connected compo-nent (Fig. 6a). Although there should exist cases where the character spacing may exceed the RLSA threshold leading to incorrect segmentation (see, word  X  X lcohol X  at Fig. 6), this does not cause significant problems since words with wide character spacing are found rarely in the processed collections. In the sequel, a connected component analysis is applied using constraints which express the minimum expected word length (Fig. 6b). This will enable us to reject stop-words and therefore eliminating undesired word segmentation. More specifi-cally, the minimum expected word length for words that are not stop-words has been experimentally defined to be twice the average character height. 4 Synthetic data creation Synthetic data creation concerns the synthesis of the keyword images from their ASCII equivalent. Prior to the synthesis of the keyword image, the user selects one example image template for each character. This selec-tion is performed  X  X nce-for-all X  and can be used for entire books or collections. During manual character marking, adjustment of the baseline for each character image template is applied in order to minimize align-ment problems. The baseline is manually adjusted by the user. Figure 7 demonstrates an example of the resulting synthetic data with and without adjustment of the base-line as well as the individual characters used for the creation of the synthetic keyword image. The spacing between the characters has been experimentally defined as 10% of the average character height that has been estimated over the complete document collection. The average character height may vary depending on the document collection under study. 5 Feature extraction The feature extraction phase consists of two distinct steps; (1) normalization and (2) hybrid feature extrac-tion. 5.1 Normalization The normalization process is dedicated to preserve scale invariance for word images. In particular, for the nor-malization of the segmented words we use a bounding box with user-defined dimensions. The segmented words are resized to fit in the bounding box while preserving their aspect ratio. The size of the bounding box con-cerning both width and height is the same for all words. Thereafter, exact positioning of the word in the bound-ing box is achieved by placing the geometric center of the word in the center of the bounding box. 5.2 Hybrid feature scheme For the word matching, feature extraction from the word images is required. Several features and methods have been proposed based on strokes, contour analysis, zones, projections, etc. [4 X 7,27]. In our approach, we employ two types of features in a hybrid fashion. The first one, which is based on [5], divides the word image into a set of zones and calculates the density of the character pix-els in each zone. The second type of features is based on the work in [27], where we calculate the area that is formed from the projections of the upper and lower profile of the word.

In the case of features based on zones, the image is divided into horizontal and vertical zones. In each zone, we calculate the density of the character pixels (see Fig. 8). Let im ( x , y ) be the word image array hav-ing 1s for foreground and 0s for background pixels, x max and y max be the width and the height of the word image, respectively and Z H and Z V be the total number of zones formed in both horizontal and vertical direction. Then, features based on zones f z ( i ) , i = 0, ... , Z H Z V  X  calculated as follows: f z ( i ) = where, x ( i ) = i  X  i x ( i ) = i  X  i y ( i ) = i y ( i ) = i In the case of features based on word (upper/lower) profile projections, the word image is divided into two sections separated by the horizontal line y = y t which passes through the center of mass of the word image ( x , y t ) (see 2). y Upper/lower word profiles (3, 4) are computed by con-sidering, for each image column, the distance between the horizontal line y = y t and the closest character pixel to the upper/lower boundary of the word image (see Fig. 9): y y We define P V as the total number of blocks that each produced zone (upper, lower) is divided. For each block, we calculate the area of the upper/lower word profiles denoted as in the following: f f where, x ( i ) = i  X  i x ( i ) = i  X  i where i = 0, ... , P V  X  1. Figure 9 illustrates the features extracted from a word image using projections of word profiles.

The overall calculation of the proposed hybrid fea-ture vector is given in (7). The corresponding feature vector length equals to Z H Z V + 2 P V . f ( i ) = 6 Word image retrieval 6.1 Word matching The process of word matching involves the comparison/ matching between the query word (a synthetic keyword image) and all the indexed segmented words. Ranking of the comparison results is based on L 1 distance metric as in the following: Dist ( f q ( i ) , f db ( i )) = where, f q ( i ) concerns the features of the query word (synthetic image) and f db ( i ) concerns the features of the segmented images.

The aim is to produce an initial list of ranked results that will be improved with the user feedback. 6.2 User feedback User feedback is an efficient mechanism for drastically improving the results of the matching process. Since the initial results are based on the comparison of the syn-thetic keyword with all the detected words, these results might not present high accuracy because a synthetic key-word cannot a priori perform a perfect match with a real word image. Motivated by this, we propose a user intervention where the user selects as query the cor-rect results from the list produced after the initial word matching process as described in Sect. 6.1. Then, a new matching process is initiated. The critical impact of the user feedback in the word spotting process lies upon the transition from synthetic to real data. Furthermore, in our approach user interaction is supported by a sim-plified and user friendly graphical interface that makes the word selection procedure an easy task. Figure 10 illustrates the matching results before and after the user feedback process. 7 Experimental results For the evaluation of the performance of the proposed method for keyword-guided word spotting in historical printed documents, we used the following methodology. We created a ground truth set by manually marking cer-tain keywords on a subset of the available document collection. The performance evaluation method used is based on counting the number of matches between the words detected by the algorithm and the marked words in the ground truth. For the experiments we used a sample of 100 document pages. We have used in total 25 keywords that were randomly selected through a list of the most frequently appearing words in the sample document images. The total number of words detected in the sample images is 27,702. The task is to search for the 25 randomly selected keywords. When applying user feedback we use the first 5% of the correct words in the results list.

Due to segmentation errors (see Fig. 11), there are a number of word misses that affect the precision/recall rates. There is an average of 1.6% concerning segmen-tation errors.

Evaluation is performed using precision versus recall curves. Precision is the ratio of the number of relevant words to the number of retrieved words. Recall is the ratio of the number of retrieved relevant words to the number of total relevant words marked on the images. They are defined as follows [28]: Precision ( A ) = where A denotes the number of word images retrieved, S denotes the total number of relevant marked words, and R a denotes the retrieved relevant words from A .We have used a variety of answer sets by a step of 10% of the total word instances in the dataset of the corresponding class.

The size of the normalized word images used is x max = 300 and y max = 30.

In the case of features based on zones, the word image is divided into three ( Z H = 3) horizontal and thirty ( Z blocks with size 10  X  10 (see Fig. 8). Therefore, the total number of features is ninety (90).

In the case of features based on word (upper/lower) profile projections we keep the same size of the normal-ized image, while the image is divided into thirty (30) vertical zones ( P V = 30) (see Fig. 9). Consequently, the total number of features equals to sixty (60).
Combination of features based on zones and features based on word profile projections led to the proposed hybrid model (7) that uses a total of ninety (90) features.
The overall system performance given in Fig. 12 shows the average recall vs. average precision curves in the case of single features as well as in the case of the proposed hybrid scheme. Furthermore, it is demonstrated the per-formance achieved in the absence or presence of user feedback. It is clearly illustrated that the hybrid scheme outperforms the single feature approaches. Addition-ally, in all cases when the user feedback is applied, the precision/recall rates are improved by at least of 20%. Combination of synthetic data creation and user feed-back leads to improved performance in terms of preci-sion and recall. 8 Conclusions This paper proposes a novel technique for keyword-guided word spotting in historical printed documents. It is based upon: (1) creation of synthetic image words; (2) word segmentation using dynamic parameters; (3) efficient hybrid feature extraction and (4) a retrieval procedure that is optimized by user feedback.
In this work, we propose a methodology which intro-duces a novel way to initialize the word retrieval mech-anism through the creation of synthetic word data along with a robust hybrid feature extraction that supports meaningful representations of word images.

From our experimental results, it can be clearly stated that the combination of synthetic data and user feedback in a hybrid fashion leads to an improved performance for keyword-guided word spotting in comparison with the other feature extraction schemes used.

Our future research will focus on exploiting new features as well as fusion methods to further improve the performance for keyword-guided word spotting in large historical collections. This will be applied for both printed typed and handwritten manuscripts.
 References
