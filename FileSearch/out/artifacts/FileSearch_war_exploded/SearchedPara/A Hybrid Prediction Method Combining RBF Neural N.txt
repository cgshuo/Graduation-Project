 fields of biology, weather, economy, traffic, industry and other fields. 
The actual observation time series from all kinds of applications such as stock price forecasting theory fails to deal with them with preferable performance [2]. 
Radial Basis Function Neural Network (RBFNN) is a local approximation neural network, which can model the inherent connections of training data and has favorable self-adaptive capability. Owning to the prominent advantages of simple structure, fast convergence and high prediction precision, RB FNN was efficiently applied to predict approximating non-smooth functions limits its popularization in dynamic systems. 
Functio nal-coefficient Autoregressive model (FAR), which is a nonparametric model in statistics, has succeeded in modeling and analyzing the stationary nonlinear time series [5]. Compared to ARMA model, it X  X  able to avoid effectively the deviation in modeling, and then reduce the prediction error caused by the model X  X  unsuitability. However, it has limitation in dealing with a nonstationary time series. The Hybrid Prediction combining RBF Neural Network and FAR model (HP-RBFNN&amp;FAR), makes entire use of the prominence of RBFNN in predicting a nonlinear time series, letting them work complementally and cooperatively. The basic which can be separately predicted with their most suitable prediction methods, makes a good prediction. Here, the decomposition is based on the partition of spectrum. 2.1 Structure of RBFPNN the following hypothesis: the observation the m available observations } { expressed by the equation Where, k (1  X  k ) is the prediction step ahead, F is a R R a m continuous function. layer is input layer, which has the m -dimension vector input and connects with the hidden layer via unitary weights. The activation functions off centers. ) ( Gauss function Where, parameter of ) (  X  and neuron. The last layer is called output layer , whose output is given by 2.2 Training of RBFPNN the parameters The improved RBFNN training algorithms [6] can also efficiently train RBFPNN. 
How to determine the optimal dimension m of values of } { 3.1 FAR Model autoregressive model ) FAR( d p, ( p , d are the model parameters ) admits the form [5] Where, } { with zero mean and unity variance, and are unknown continuous functions, can be estimated by using the local linear regression technique [8]. 3.2 Factors Influencing on the Performance of FAR Prediction Model Based on model (5), the one-step-ahead FAR Prediction Model (FARPM) is given by Where, ) (  X  As for the multiple-step-ahead predictor, the method of iteration is employed. 
Since the coefficient functions X  estimators ) (  X  parameters p , d are the influence factors on the performance of FARPM. 
Overall Average Prediction Error (APE) introduced in the reference [11] is adopted to evaluate the performance of FARPM, which is the function of b , p and d , individually, when predicting an observation time series characterized simultaneously success with RBFPNN and FARPM complementally and cooperatively combined, overcoming their respective deficiencies in approximating non-smooth functions which describe dynamic systems and modeling a nonstationary time series. 
As shown in Fig.2, the process of HP-R BFNN&amp;FAR can be briefly summarized as filters. Secondly, through scale filters, the observation time series is decomposed into + sequences, classed into two clusters. One characterized by lower frequency zed by smoothness and reflecting the trend can be precisely predicted with RBFPNN, while the stationary sequences fluctuating randomly at zero can be well modeled and prediction results of RBFPNN and FARPM. 
In the scheme of HP-RBFNN&amp;FAR, the partition of spectrum directly affects the and determination of t and s are all important things for HP-RBFNN&amp;FAR. HP-RBFNN&amp;FAR, which simultaneously contains trend elements, cycle elements and random elements just as most observatio n time series ( e.g. the daily observations areas such as hydrology, weather, biology, economics, traffic and industry. decomposed into two parts of a smooth trend sequence )} ( { t x sequence )} ( { t x For each sequence, the first 500 data defined as training samples are used to train Mean Squared Error (MSE) is adopted as a metric on prediction precision. For )} ( { t x is obtained ( 4 = m ) with the proposed method in Section 2.2. The testing samples of For )} ( { t x The estimated coefficient functions ) (  X  f ~ Where, t is the current time, ) 2 (  X  = t x u * polynomial-fitting curves can be written as 
With FARPM, the one-step-ahead predictor is got with OSPMSE 0.0959, as shown in Fig. 4(b). Finally the integrated prediction result is obtained with OSPMSE 0.0960. steps and 12 steps ( standing respectively for short term, medium term and long term) and 60% respectively, compared to the methods with ARMA, RBFPNN and FARPM. In the paper, a hybrid prediction method combining organically RBFPNN and FAR-prediction method succeeds in pr edicting a nonlinear and nonstationary time series by combining the respective algorithms of RBFPNN and FARPM in a complemental and cooperative way. Compared to the prediction with ARMA, RBFPNN or FARPM, HP-RBFNN&amp;FAR is deemed to result in a better accuracy in actual applied areas. 
Another important finding of the research is that the total prediction performance is directly affected by the partition of spectrum. Thus how to select the suitable wavelet to construct optimal filters and make RBFPNN and FARPM more efficiently combined is the future work. 
