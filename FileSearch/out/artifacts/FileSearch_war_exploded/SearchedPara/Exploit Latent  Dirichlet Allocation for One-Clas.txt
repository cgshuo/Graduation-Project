 Previous work studied one-class collaborative filtering (OCCF) problems including pointwise me thods, pairwise methods, and content-based methods. The funda mental assumptions made on these approaches are roughly the same. They regard all missing values as negative. However, this is unreasonable since the missing values actually are the mixture of negative and positive examples. A user does not give a positive feedback on an item probably only because she/he is unaware of the item, but in fact, she/he is fond of it. Furthermore, content-based methods, e.g. collaborative topic regression (C TR), usually require textual content information of items. This cannot be satisfied in some cases. In this paper, we exploit latent Dirichlet allocation (LDA) model on OCCF problem. It assumes missing values unknown and only models the observed data, and it also does not need content information of items. In our model items are regarded as words and users are considered as documents and the user-item feedback matrix denotes the cor pus. Experimental results show that our proposed method outperforms the previous methods on various ranking X  X riented evaluation metrics. H.3.3 [ Information Search and Retrieval ]: Information filtering-Recommendation System .
 Algorithms. One-class Collaborative Filtering; Latent Dirichlet Allocation; Topic Model The goal of recommendation system is to automatically suggest items to each user that she/he may find appealing. Traditional collaborative filtering approaches predict users X  interests by mining user rating history data, and these rating data are multi-valued scores, which can be categorized as  X  X ulti-class X  recommendation problem [1]. Many machine learning based algorithms are designed to predic t user X  X  interesting on these multi-valued data, among of which matrix factorization based algorithm achieved great success [2]. However, in many applications, the collected data of user behaviors are in  X  X ne-class X  form rather than multi-class form, e.g.,  X  X ike X  in Facebook,  X  X ought  X  in Amazon,  X  X ollect X  in Taobao and  X  X ollow X  in Sina weibo. Such data are usually called implicit [3] or one-class [1, 4, 5] feedback. The one-class collaborative filtering (OCCF) problem is different from that of multi-valued rating prediction problem, since the former only contains positive feedback rather than both positive feedback and negative feedback, and the goal is item ranking instead of rating prediction. Traditional machine learning based algorithms cannot directly be used to tackle OCCF because of imbalanced data [6]. The important difficulty to tackle OCCF problem is over fitting, because only positive feedbacks are observed. In order to avoid over fitting previous methods, including pointwise methods [4], pairwise methods [1, 3] and c ontent-based methods [7, 8], all assume missing data negative. However they introduced newer over fitting problem caused by too many negative data. A good learning method is that it fits the observed data well and introduce topic model, i.e., latent Dirichlet allocation [9, 10] (LDA) to deal with this problem. Our model is different from the methods proposed in [7, 8] in tw o aspects: (1) we only model the observed data, and the latter a ssume missing data negative and strive to fit all the data. (2) our model does not need contents information of items. Compared with the pointwise [4] and pairwise methods [1, 3], the para meters learned by our model are probability distributions, which have the inherent characteristics that the probability is a positive number and the summation of probabilities is equals to 1. Thes e characteristics made our model have excellent ability to avoid ove r fitting. Experimental results show that our proposed method outperforms the previous methods on various ranking X  X riented evaluation metrics. The rest of the paper is organized as follows. In the next section, we review previous works rela ted to the OCCF problems. In Section 3, we propose our approach for OCCF problems. In Section 4, we empirically compar e our method to state-of-the-art methods on three real world data sets. Finally, we conclude the paper and give some future works. In this section, we review the lite rature of a few state-of-the-art approaches proposed for OCCF problems. There are mainly three types of approaches, (1) pointwise methods, (2) pairwise methods, and (3) content-based methods. Pointwise methods take implicit f eedback as absolute preference scores. For example, an observed us er-item pair is interpreted as a positive feedback and is assigned with a high absolute rating score, e.g., 1, and the unobserved user-item pair is seen as a negative feedback and is assigned with rating score 0. Then, machine learning based methods , e.g. weighted low-rank approximations (WLRA) [4], are designed to fit the rating score matrix. Because most of the data are negative, in order to correct the bias there are two kinds of techniques are adopted, (1) the weight of the negative data is assigned with a small value relative to it of the positive data, and (2) the negative data are sampled with a small probability. The limita tion of these methods is that taking unobserved user-item pair s as negative feedback may introduce errors. Pairwise methods achieved great success in OCCF problems, which mainly include Bayesian personalized ranking based matrix factorization (BPR) [3] and group Bayesian personalized ranking (GBPR) [1]. BPR supposes that a user u prefer an item i to an observed, and then take pairs of items as basic units and maximize the likelihood of pairwise preferences over observed items and unobserved items. Different from BPR, GBPR proposes a stronger constraint which can be expressed by Eq.(1) and Eq. (2): Where item i , and , uj r denotes the preference value of user u on item j , and , i and it is the average preferen ce value of all users in group item i which is expressed by Eq.(2). GBPR use sigmoid function approximate the probability by a product of two vectors which is expressed by Eq(3). Where of item j . These latent vectors are learned by maximize the likelihood of pairwise preferences. Pairwise methods [1, 3] outperfo rms pointwise methods [4], but both of them have roughly the same fundamental assumptions that all missing data should be negative. Because according to their optimization goal, if a user-item pair (u, j) is unobserved, the smaller the preference of user u on item j is the easier the optimization goal can be realized. Matrix factorization technique is adopted in these methods to access to the optimization goal, and meanwhile it utilizes the interaction between latent vectors to bound the value of the preference. In this OCCF scenario, items ha ve textual contents. Topic model is used in this scenario to m odel the corpus and the user-item rating scores at the same time. Where an item is seen as a document and all the items X  contents constitute a corpus. Meanwhile, all missing data are assumed negative and are assigned with a small value, e.g. 0, and positive feedback are assigned with value 1 [7, 8]. The models proposed in [7] and [8] are called collaborative topic regression (CTR) and collaborative topic regression with social ma trix factorization (CTR-SMF) respectively. Figure 1 shows th e CTR model. CTR represents users with topic interests and assu mes that items are generated by a topic model. CTR additionally includes a latent variable which offsets the topic proportions ratings. This offset variable can capture the item preference of a particular user based on their ratings. Assume there are K topics, and let 1. For each user i , draw user latent vector  X   X  1 ~0, 2. For each item j , 3. For each user-item pair ( i , j ), draw the rating Where determined in advance by cross validation, and it represents the confidence for rating is set with a big value relative to negative examples (i.e. CTR-SMF model extended CTR model, and it can be used to address the recommendation problem when item X  X  content, rating records and social network info rmation are all known. However, in recommendation scenario, items usually have no textual contents, and these two methods assume missing data negative, which may not hold water, so, these two methods have limitations. In this paper, similar to the articles [7,8], we also use topic model to tackle OCCF problem, but in our model, a user is seen as a document, and an item is regarded as a word, and a positive document u . We use latent Dirichlet allocation (LDA) [9] to model OCCF problem, which is represented by Figure 2. Our method has two stages. Step 1 , LDA model for OCCF was used to learn the matrices  X  and  X  , i.e., topic distributions of users and item distributions of t opics respectively. The generative process is as follows. 1. For each user u , Draw topic proportions  X   X  ~ 3. For each observed user-item pair (u, i) , We use Gibbs sampling method to estimate the parameters  X  and , for more information please refer to [11]. Here, the topic number K and the super parameters  X  and  X  need to be tuned. Step 2 , compute the preference of user u on item i by Eq. (4). Where distribution of topic k on item i , and they are all positive numbers. From Eq.(4), we can see that only numbers, ui r becomes bigger. This conforms to actuality. For example, if user u very likes action movie, and movie i has many probability like this movie. Conversely, if user u hates to see action movie or movie i has no action scenes, he will not like this movie. Here, the genre of acti on denotes a topic. Thus, using Eq.(4) to measure the preference of user u on item i is reasonable other than the Euclidean distance between the two vectors. When a target user X  X  preferences on all items are figured out, recommendation item list can be ranked. We call this proposed method LDA-OCCF, which has three better characteristics than previous works: (1) Compared with the previous methods, in LDA-OCCF, missing ratings are assumed unknown other than negative; (2) Compared with CTR or CTR-SMF model, LDA-OCCF does not n eed contents information of items; (3) Compared with pointwise or pairwise methods, the parameters learned in LDA-OCCF are probability distributions, which are positive numbers and the summation of them is equal to 1. These strong constraints help LDA-OCCF avoid over fitting. We use three real-world datasets in our empirical studies, including MovieLens100K 1 , MovieLens1M 1 , and a subset of Netflix 2 . MovieLens100K contains 100, 000 ratings assigned by 943 users on 1, 682 movies, Movi eLens1M contains 1, 000, 209 ratings assigned by 6, 040 users on 3, 952 movies. Similar to [1], we sample 155,872 ratings larger than 3 as the observed positive feedbacks (to simulate the one-class feedback) from the Netflix dataset, and the ratings cont ain 5039 users and 5018 movies. We call this subset of Netflix datase t Netflix5K5K. We use  X  X tem X  to denote movie. For MovieLens100K, MovieLens1M, we also take a pre-processing step, which only keeps the ratings larger than 3. Then, we randomly divide each data set into 5 equal parts for five-fold cross validation, i.e., for each dataset, 4 parts of the data (i.e., 80%) is used to train the model and th e rest data is used to test the model, and the reported result is the average value over 5 independent runs. The final datase ts used in the experiments are shown in Table 1. MovieLens100K 942 1447 55,375 MovieLens1M 6038 3533 575,281 Netflix5K5K 5039 5018 155,872 Because users usually only check a few top-ranked items, we use top-k evaluation metrics to study the recommendation performance, including top-k resu lts of precision, recall, and MAP. For each evaluation metric, we first calculate the performance for each user from the test data, and then obtain the averaged performance over all users. Precision is the proportion of top recommendation results that are relevant. Recall is the proportion of all relevant results included in the top results. They can be computed by Eq. (5) and (6) respectively. Where r is the number of relevant items in top N recommendation list of a user u which means these r items are preferred by user u in test set, and T is the number of items that user u preferred in test set. MAP (Mean Average Precision) is widely used in information retrieval for evaluating the ranked documents over a set of queries. We use it in this paper to assess the overall performance based on precisions at different r ecall levels on a test set. It computes the mean of average precision (AP) over all users in the preferred items in the ranked list: where i is the position in the rank list, N is the number of recommended items which are the items that user u did not express positive feedback in training set, prec(i) is the precision (fractions of recommended items that are preferred by user u in otherwise. The MAP is the mean of AP u over all users. We use three popular baseline algorithms in our experiments, PopRank, BPR [3], and GBPR [1]. PopRank is a basic algorithm in one-class collaborative filtering, which ranks the items according to their popularity in the training data. BPR [3] is a seminal work for OCCF problem and is also a very strong baseline, which is shown to be much better than two well-known pointwise methods, i.e., iMF [12] and OCCF [4]. Note that the implementation of this baseline is done with the publicly available software MyMediaLite [13]. GBPR [1] is recently proposed method, which outperforms BPR. The parameters in BPR and GBPR are tuned according to the papers [3] and [1] respectively. In our method LDA-OCCF, for all experiments, the topic number K is tried with {10, 20, 50}, the parameter  X  is set to 0.5 and  X  is set to 0.02, and Gibbs sampling times are chosen from {1000, 10000, 100000}. The recommendation performance of LDA-OCCF and other baselines are shown in Table 2, from which we can have the following observations. 1. Both BPR, GBPR and LDA-OCCF are much better than the 2. LDA-OCCF further outperforms BPR and GBPR on all On the other hand, LDA-OCCF onl y samples observed data, so its computation complexity is lower than BPR and GBPR if all of them take the same sampling times. Dataset Algorithm Prec@5 Rec@5 MAP MovieLens MovieLens
Netflix 5K5K In this paper, we study the one-class collaborative filtering problem and design a topic model based algorithm LDA-OCCF. Different from previous proposed methods, it avoided the unreasonable assumption that missing data are negative. Due to the strong constraint that the learned probabilities are positive and their summation is equal to 1, LDA-OCCF alleviates the over fitting problem. Meanwhile, different from previous topic model based recommendation methods, it does not need content information of items. Experimental results show that, this proposed method outperforms the compared algorithms. In the future, we will further study how to integrate more information such as social structure into the algorithm to improve the performance further. We greatly appreciate Weike Pan, i.e., the author of paper [1], for his codes of algorithm GBPR, whic h makes us able to evaluate the algorithm more efficiently and more fairly. This work is supported by NSFC (Nos.61170189, 61370126, 61202239), the Research Fund for the Doctoral Program of Higher Education (No. 20111102130003), the Fund of the Stage Key Laboratory of Software Development Envir onment (No. SKLSDE-2013ZX-19), Microsoft Research Asia F und (No. FY14-RES-OPP-105), the Fund of Beijing Social Science [No.14JGC103], and the Statistics Research Project of National Bureau [No. 2013LY055]. The third author thanks the Innovation Foundation of Beihang University for Ph.D. Graduates (YWF-13-T-YJSY-024). [1] Pan W, Chen L. GBPR: group preference based Bayesian [2] Koren Y, Bell R, Volinsky C. Matrix factorization [3] Rendle S, Freudenthaler C, Gant ner Z, et al. BPR: Bayesian [4] Pan R, Zhou Y, Cao B, et al. One-class collaborative [5] Li Y, Hu J, Zhai C X, et al. Improving one-class [6] He H, Garcia E A. Learning from imbalanced data[J]. TKDE [7] Wang C, Blei D M. Collaborative topic modeling for [8] Purushotham S, Liu Y, Kuo C C J. Collaborative topic [9] Blei D M, Ng A Y, Jordan M I. Latent dirichlet allocation[J]. [10] Chen Y, Yin X, Li Z, et al. A LDA-based approach to [11] Heinrich G. Parameter estimation for text analysis[R]. [12] Hu Y, Koren Y, Volinsky C. Collaborative filtering for [13] Gantner Z, Rendle S, Freudent haler C, et al. MyMediaLite: 
