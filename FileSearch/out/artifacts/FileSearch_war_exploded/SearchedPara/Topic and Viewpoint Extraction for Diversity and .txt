 Constant advances in information technologies and the spread of these technologies have changed our everyday lives. A major change is the ready availability of cross-media news content. News is now available from TV, Web sites, and newspapers, and people can access these information sources as they choose. Video news clips (TV news program and video news on the Web) offer immediacy and realism, but they suffer from time restrictions and often need to maintain audience ratings, which limits the details and scope of the information they provide. I n addition, because the news agencies have different viewpoints and they have collected different news materials, the perspective the news content has may be biased. For example, news material, especially which used in a news item, is a kind of evidence that supports the viewpoint of news agencies in a certain organization. That is, news material stands for a viewpoint on a news event and the news professionals select news material s based on what their intentions are and what they want to convey to the audience. As a res ult, the perspective of news content may be diverse and biased. Hence, detecting bias and intent are very important and necessary to help users understand the news event and acquire balanced information. If the news contents are diverse, we need to read more ar ticles to acquire balanced information. On the other hand, when the diversity of news contents is small, we do not need to check other articles because there may be little additional information on that news event. However, in this case, the credibility of news contents may be questionable.
We call an event or an activity a  X  X opic X . To represent such  X  X opics X  described in a news item (e.g., a video news clip or a news article) and analyze the bias (diver-sity) in news, we propose a novel notion of content structure to represent the topic and viewpoint described in a news item. The content structure is made up of three-tuple of subject, aspect, and state terms. Intuitively, a subject term denotes the most dominant term. An aspect term means a term that has strong co-occurrence relationships with the subject terms and denotes the aspect described in that news item. State terms are key-words that denote the current state or status of a subject  X  X  aspect . The topic of a news item is represented by using the content structure extracted from the whole text. How-ever, because the last paragraph of a news article usually describes the conclusion or scoop material that clarifies the authors X  focus, we can represent the viewpoint of that news item by using the content structure extracted from the last paragraph. We currently use a video news clip X  X  closed caption to analyze its topic and viewpoint.
 Based on the extraction of topics and viewpoints, we propose a system called TVBanc ( T opic and V iewpoint based B ias A nalysis of N ews C ontent) to analyze and present the bias (diversity) in news content to help users understand news and acquire balanced information. Given a news item, TVBanc facilitates analysis of bias and diver-sity in three steps: First, TVBanc extracts the topic and viewpoint from the text data of a news item by using the content structure. Second, TVBanc searches for related news items from multi-sources such as TV news programs, video news clips, and articles on the Web. Finally, TVBanc groups the related news items into different clusters, and an-alyzes their distribution to estimate the diversity and bias of news content. The details on clustering results are also presented to help users understand the different viewpoints in the news contents.

The remainder of this paper is organized as follows. Section 2 introduces related work. Section 3 describes the method used to extract content structure from news con-tent. Section 4 introduces a mechanism for an alyzing bias and an application system TVBanc. The experimental results are described in Section 5 and we conclude this pa-per in Section 6. Topic detection and tracking (TDT) research has led to algorithms for discovering and weaving together topically related material in data streams such as newswires and broadcast news [6, 9, 11]. In contrast, as one of the next steps in TDT, we have fo-cused on how to extract the topic and viewpoint to analyze the bias and diversity in news content.

The CORPORUM [3] is a tool designed to extract content-representation models from natural language texts and use them for information retrieval. It consists of two basic concepts: an extraction concept that focuses on the semantics of a text, and a resonance algorithm that enables the content of two texts to be compared as a way of analyzing their conceptual structure. WebMaster [5] is a software tool for knowledge-based verification of Web pages designed to h elp maintain the content of Web sites. It is able to reveal hidden cluster relationships between different conceptual information by analyzing the content of weakly or semi-structured information sources. These tools are based on an ontological and knowledge-b ased approach to representing content. In contrast, by identifying the roles of various keywords, our keyword-based content structure enables us to analyze the difference in news items from different aspects.
Newsjunkie [4] generates personalized news for users by identifying the novelty of topics within the context of topics they have already reviewed. This approach focuses on the novelty of news topics using a tf  X  idf -based method and personalized presen-tation, while our research uses the content structure to analyze the bias and diversity of viewpoints in news content.
 Numerous studies have also been done on news browsers. For example, Columbia X  X  Newsblaster is a tracking and summarization system that clusters news into events, categorizes the events into broad topics, and summarizes multiple articles on each event [2, 7]. The Comparative Web Browser (CWB), which is a system that allows users to concurrently browser different news articles for comparison, has also been proposed [8]. Unlike our system, the CWB did not aim at analyzing bias. 3.1 Content Structure As previously mentioned, we have considered a content structure to be a three-tuple of subject, aspect, and state terms. To reiterate, the subject terms denote the most dom-inant terms of a news item, while the aspect terms are those that have a strong co-occurrence relationships with the subject terms. The state terms, which have strong co-occurrence relationships with subject and content terms, denote the state or status of a certain topic X  X  certain aspect. In other words, the subject terms are the centric key-words that play the title role in a news item. The aspect terms indicate which part (i.e., subtopic or viewpoint) of that topic has been focused on, while state terms describe the state and status of that aspect. Content structure CS is defined as where  X  +  X  means that the element(s) should appear one or more times. In addition, a keyword should not occur more than once in a content structure, i.e., the subject, aspect, and state terms should be different. For example, content structure, denotes that the news item is reporting that the opening ceremony ( aspect ) of the Beijing Olympics ( topic ) was spectacular ( state ).
 To present a content structure to a user, we used an edge-labeled directed graph. In this graph, the source vertex denotes the subject terms and the destination vertex denotes the aspect terms. The label of the directed edge stands for the state terms. 3.2 Content-Structure Extraction We respectively define the notions of subject degree , aspect degree ,and state degree to determine whether a keyword has a high probability of being a subject, aspect, or state term.
 First, we extract the news item X  X  keywords (nouns and unknown-words) as a set of K . For each keyword w  X  K , we compute its subject degree by using the formula below. If w appears frequently, and is close to the leading part and has a strong co-occurrence relationship with other terms, then w has a high probability of being a subject term. Moreover, a proper noun is a ssigned higher probability. where tf ( w ) stands for the term frequency of w .The weight ( w ) is a weight function depending on the word class of w ; the proper noun has been assigned a higher weight than the others. The dis ( w ) denotes the distance between w and the first term of that news item. The cooc ( w, w i ) denotes the co-occurrence relationship between w and w i .
The dis ( w ) is currently computed as the numbe r of words appearing between the first term and w . Because w may appear more than once, we only use the first location of w to compute dis ( w ) .

The co-occurrence relationship between two words w and w i is defined as the ratio of sentences containing both w and w i in all sentences in that news item. where sf ( w, w i ) means the number of sentences containing both w and w i . N is the total number of sentences.
 The keywords with the top n subject degrees will be selected as the subject terms. After this, we compute the aspect degrees of the remaining keywords as where S denotes subject terms. w  X  K  X  S
Keywords with the top m aspect degrees will be selected as the aspect terms. After that, we compute the state degrees of remaining keywords as state ( w, S, A )= where S and A are subject and aspect terms, respectively. w  X  K  X  S  X  A . In contrast to the formula for subject and aspect degrees, a larger dis ( w ) leads to a smaller state degree. This is because we have assumed that t he state and viewpoint will be described in the latter parts of a news article. weight ( w ) is a weight function depending on the word class of w ; we assign the adjective noun the highest weight, and assign proper noun higher weight than the other. Keywords having the top l state degrees will be selected as state terms. 3.3 Topic and Viewpoint Analysis We used the content structure to represent the topic and viewpoint of a news item. Generally, a news article consists of three parts: the lead is used to give a summary, the nut graf is used to show the details, and the conclusion is used to describe additional information and original material to indicate the viewpoint of the authors. Based on such structure of a news article, as shown in Fig. 1, we extract the content structure from the whole text as the topic of that news item. The viewpoint is the content structure extracted from the conclusion of the news article.

To analyze the topic and viewpoint of a group of similar news items, we merge para-graphs corresponding to these news items together to construct one virtual news item. For example, as shown in Fig. 2, to construct the virtual article from articles A and B, we first merge the titles of A and B to that of the virtual article. Similarly, the lead, nut graf, and conclusion of articles A and B are merged into those of the virtual article. We then extract the topic and viewpoint from that virtual news item as those of that group. By using the method of extracting the topic and viewpoint, we propose a mechanism that can be used to analyze the diversity and bias of news content and an application system TVBanc.

As we can see from Fig. 3, we first extract the topic and viewpoint for a given news item (e.g., video news clip or news article) based on the content structure by using its text data or closed caption data. We then use the keywords in the topic and viewpoint to search for related news items from the Inte rnet and a local news database. After the search results are obtained, we group these news items into clusters. We also extract the topic and viewpoint of each cluster. Finally, we analyze the distributio n of clusters to estimate the diversity and bias of news content and present users with the results to help them understand the news.
 4.1 Topic and Viewpoint Analysis We extract the topic and viewpoint for a given news item. Hereafter, the topic will be considered to be based on the content structure consisting of two-subject, two-aspect, and two-state terms, while the viewpoint consists of one-subject, one-aspect, and one-state terms. 4.2 Related News-Item Retrieval We search for related news items of that given one from the Internet and a local news database.

To search for related news items from the In ternet, we generate keyword queries by using the subject and aspect terms of the topic extracted from the given news item. Such keyword queries will be issued to a search engine via a Web search API. The strategy to generate keyword queries is that at least one subject term should appear in the title and at least one aspect term should appear in the body of a searched news page. For example, suppose the subject terms are s 1 ,s 2 , and the aspect terms are a 1 ,a 2 , the query should be where  X  X ntitle X  means the following term s hould appear in the title and  X  X ntext X  means it should appear in the body of the searched news item.  X   X   X  stands for logical AND and  X   X   X  means logical OR.

The local news database implemented by using MySQL currently consists of three kinds of news contents (in Japanese). The topic and viewpoint based on the content structure are also extracted and stored in the database.  X  TV news program with closed caption data. Eight news TV programs from digital  X  News article on the Web. Four well-known news sites in Japan were the targets for  X  Video news clip and its surrounding text. In Japan, major TV stations also publish
To find related news items from the news database, we issued an SQL query to the database. The subject and aspect terms (of the topic and viewpoint based on the content structure) of a searched news item should contain at least two of those extracted from the given news item. In the above example, the SQL query is generated as 4.3 Diversity Analysis and Presentation After the related news items were searched, we grouped them including the given one into clusters by using the complete linkage method. The similarity between news items, i.e., the measure used in the complete-linkage method, is computed using the vector space model as correspond to the tf  X  idf keyword vectors of s 1 and s 2 . Here, keywords denote the nouns and unknown-words appearing in that news item and idf value is computed within the related news items.
 We compute the entropy of the related news items as where c i denotes the cluster size, i.e., the number of news items in cluster i . Here, m is the number of clusters and N is the number of news items. Obviously, N =  X  i = m i =1 c i . Intuitively, E is a score that indicates the diversity of news on a certain topic or event. We hence called E the diversity degree .Alarge E means the news report on that topic is diverse. A small E , on the other hand, denotes the news reports may be biased. That is, the smaller the E , the greater the bias.

We presented the results to users to help them understand the news and bias. Addi-tionaly, we also extract the topic and viewpoi nt of each cluster (a group of similar news items) and use the viewpoint as the label for each cluster. If the news content is biased, we do not need to check other news because there is little new information. However, the credibility may be questionable. However, if the news content is diverse, we need to check other items to acquire news that has balanced viewpoints. 4.4 Prototype System We developed a prototype system of TVBanc based on the methods above. Fig. 4a is a screenshot of TVBanc. The top left window is a viewer for the news item that can be used to browse news pages and to watch video news clips. The bottom left window displays the topic and viewpoint of the current news item. The right window is used to present clustering and diversity-analysis results. In our prototype system, we grouped related news items per media (news sites, and videos (TV)). The top right pie chart shows the results of clustering news items on a news site. The bottom right pie chart shows the results of clustering news on the TV and Web sites of a TV station.
The window presenting details of each cluster will pop up if a user clicks the clus-tering results pie chart. As shown in Fig. 4b, each tab window stands for a respective cluster. The top left window is the viewer for the topic and the viewpoint of the cluster. The top right window is the list of related news items. When a news item in the list has been selected, the bottom left window will display its topic and viewpoint, and its text data will be presented in the bottom right window.
 The prototype system was developed on a Windows Server 2003 machine by using Visual Studio 2008 Professional Edition Service Pack 1. The target news items are currently in Japanese. We used ChaSen[1] to analyze the Japanese morphology and only nouns and unknown-words as the keywords for further processing. To exclude stop words, we built a stop-word dictionary that contained 593 terms in English and 347 terms in Japanese. Google Web API and Yahoo! Web API were used to search for related news items from the Web. Top 50 results returned by Google and Yahoo! were selected as the related news items on the Web. This section describes the experimental results. We carried out two kinds of exper-iments: 1) an experiment to evaluate methods of extracting the topic and viewpoint based on the content structure, and 2) an experiment to evaluate the method of analyz-ing diversity and bias.

We selected 10 experimental news items as th e target data for evaluation from video-news Web sites, such as NHK News, FNN, News-i and News24. The local news database contained 26111 news items at the time of the experiment. Google Web API and Yahoo! Web API were used to search for related news items from the Web. 5.1 Experiment 1: Topic and Viewpoint Extraction We asked 10 students to evaluate the methods of extracting the topic and viewpoints. First, each student was asked to read each given news article and then extract six key-words to represent the topic and three to represent the viewpoint of that news item. We asked them to compare the topic and viewpoint given by TVBanc with those of their own. Then we asked them give a score ranging from 0 to 10 to show how well the topic and viewpoint given by TVBanc.

Similarly, we asked these students to check the news items in a cluster (of related news items) and extract six keywords to represent the topic and three to represent the viewpoint of that cluster. These students were then asked to compare the topic and viewpoint given by TVBanc with their own topic and viewpoint. Then these students were asked to score the topic and viewpoint given by TVBanc, respectively. In experi-ment 1, we only asked these students to evaluate the largest top-three clusters. We also computed the common keywords ratios of topic ( r t ) and viewpoint ( r v )givenbythe10 students and TVBanc as follows. where T u i and V u i are the topic and viewpoint keywords given by student i . T s and V s are the respective keywords of the topic and viewpoint given by TVBanc.

The experimental results listed in Table 1 revealed that our method can extract key-words that are similar to those given by human (the 10 students). They also revealed that our method can extract better topics than viewpoints based on the content structure. The topic extracted from a news item is better than that from a cluster, while the viewpoint extracted from the cluster is better. One si gnificant reason is that the conclusion of a news item is too short to extract its viewpoint, while the cluster X  X  conclusion is merged from more than one news item and has long text data for extracting the viewpoint. An-other reason is that although the conclusion may describe original material to reveal the authors X  focal points, the reader may focus on other areas from his/her own viewpoint. The content structure of larger clusters is better than that of smaller ones. This is to say, when we extract the content structure from a virtual news item, a small cluster is easily influenced by the noise of news items, which is a false result in the clustering method. We intend to discuss these issues in the near future. 5.2 Experiment 2: Diversity Analysis We carried out a user study to evaluate our mech anism for analyzing diversity and bias. Experiment 2 was actually carried out before Experiment 1. We asked the same 10 students to access the given news items carefully and then do a survey on the Internet to estimate the news diversity and bias. If there were many news items describing the same topic (event) from different aspects and viewpoints, then the news on that topic (event) was diverse and the bias was small. From this viewpoint, we asked these students to score the diversity (bias) on a five-point Likert scale ranging from one to five. If there were six students who scored a news topic greater than three, we considered the news topic to be diverse and regarded it as a relevant result.

However, we also computed the degree of diversity in the given 10 news items based on our mechanism for analyzing diversity an d bias. When the degree of diversity was greater than threshold  X  , we regarded it as a positive result (i.e., the news content on that topic is diverse.) returned by our method. We computed the precision and recall ratios (Table 2). The average degree of diversity of the given 10 news items was 2.92. Although Experiment 2 was a preliminary evaluation and further experiments are necessary, at least the results denoted that the proposed method based on the extraction of topics and viewpoints is potentially an efficient way of analyzing diversity and bias in news. We proposed a system of analyzing diversity and bias in Web news called TVBanc based on the extraction of topics and viewpoints. We also proposed a novel notion called the content structure to extract topics and viewpoints. First, for a given news item, we extracted its topic and viewpoint based on the content structure. We then searched for its related news items from the Internet and a local news database. We computed the degree of diversity in the news content to estimate the bias in news by analyzing related news items. We intend to present the analysis results to users to help them understand news items. The experimental results revealed that the methods of extracting topics and viewpoints could extract keywords that were similar to those given by human. A preliminary study of users validated our m echanism for analyzing diversity and bias based on the extraction of topics and viewpoints.

Further studies on the mechanism for analyz ing diversity and bias, and evaluations are necessary. For instance, other core technical areas, i.e., retrieval of related news items and clustering, need to be studied in the near future. The notion of content struc-ture and methods of extracting topics and viewpoints should be improved.
 This work is supported in part by the National Institute of Information and Communi-cations Technology. This research is partly supported by the research for the grant of Scientific Research (No.20700084 and 20300042) made available by MEXT, Japan.
