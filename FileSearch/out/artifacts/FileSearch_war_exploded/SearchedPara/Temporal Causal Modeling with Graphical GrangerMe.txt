 Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications X  Data Mining General Terms: Algorithms, Performance, Design Keywords: Graphical models, Causal modeling, time series data
Statistical modeling and data mining methods are play-ing an increasingly critical role in real world application s that involve forecasting and prediction. In domains that involve decision making, such as business intelligence app li-cations, however, it is hardly satisfactory to merely disco ver the statistical correlations that exist in the data. Causal re-lationships between the levers , or variables that are subject to decision making, and the outcomes , those that are objects of optimization, need to be established so that the provided insights can be made actionable.

Causal modeling is an area of active research, with rich existing literature. Most notably the framework of Bayesia n networks [12, 18, 22, 8], and the related causal networks [14 , 25, 1, 20], have been recognized as suitable frameworks to study this issue. There is some very interesting past work that has revealed cases in which causal structure can be de-termined purely from statistical tests [26], and sometimes computationally efficiently. Still in general, the problem of determining causal structure is considered a major chal-lenge, both computationally and philosophically. There ar e many cases in which statistical observations alone are not enough to determine the causal structure among a set of variables, and even in cases where it is possible to do so in principle, efficient algorithms are hard to come by.
In many applications of business intelligence and opti-mization, the data available for analysis often involve tim e series information. The question of how to leverage the tem-poral structure present in such data for better understandi ng of causal structure among the relevant variables thus natu-rally arises. Indeed, considerable research has been done o n causal modeling with time series data [1, 7, 30, 21]. Most past work, however, has focused on the modeling of causal relationship between temporal variables, thus admitting th e formulation of the causal modeling problem as that of stan-dard time series statistical modeling.

In the present paper, we address and explore the ques-tion of to what extent temporal information present in time series data can assist in the modeling and understanding of the causal structures between time-persistent features , rather than temporal variables. Take, as an illustrative ex -ample, the problem of understanding the causal relation-ship between various key performance indicators (KPI) one may have about a company. For example, one might ask a question such as  X  X s the stock price of a company causally affected by the inventory turnover ratio of that company? X  Emphatically, the question we are asking here is not how much the turnover ratio this quarter will affect the stock price after a fixed period of time, say two quarters from now, but rather whether and to what extent the turnover ratio affects the stock price.

As it turns out, a seminal work in the area of econometrics by the Novel prize winner, Clive Granger, has addressed this very question [11]. A notion of causality he introduced, ap-propriately called  X  X ranger causality X , presents one poss ible solution to this question, and is the one that is of particula r interest to us in the present context. Granger causality is based on the intuition that a cause helps predict its effects in the future, beyond what is possible with auto-regression . More specifically, a feature x is said to Granger-cause y , if auto-regressive model for y in terms of past values of both x and y is statistically significantly more accurate than that based just on the past values of y .

As it was originally introduced, Granger causality was de-fined for a pair of features, and the question of how one could apply this notion to the analysis of time series data involving many features was not directly addressed. Pio-neered by the work by Eichler et al, there has recently been some interest in combining the notion of Granger causal-ity with graphical models [7]. However, the area is young and many issues of practical significance remain, such as the question of relative accuracy and efficiency of competing methods. Specifically, with increasing interests in applyi ng model selection methodologies for solving structural lear n-ing problems for graphical models, it is natural to ask how best to combine the time series specific notion of causality that Granger provides with these new learning techniques to devise a practical approach to temporal causal modeling.
In the present paper, we conduct a systematic empir-ical investigation as an attempt to start answering such questions. In particular, we consider a number of variants which, loosely speaking, fall under the category of graph-ical Granger methods, including the canonical exhaustive Granger method and the Lasso-Granger method. We also compare their performance against some benchmark meth-ods for time series analysis, including the vector autoregr es-sion (VAR) method [9] and the SIN method [5] tailored to handle time-series analysis.

We attempt to characterize the relative performance of these competing methods, by conducting a host of system-atic simulation experiments, in which a number of parame-ters of interest are varied and their effects on their perfor-mance are observed. Specifically, a large number of simula-tions are randomly generated in which a target time series model is generated, essentially as a VAR model, and the per-formance of the various methods is examined as a function of various parameters of the simulation. Finally, we apply the proposed method on an actual data set in the domain of corporate KPIs, obtained from the publicly available S &amp; P Compustat database [27], and exhibit some concrete results .
The rest of the paper is organized as follows. In Section 2, we describe the problem formulation as well as the key no-tion of Granger causality. In Section 3, we describe the various methods considered in our empirical evaluation and discuss their relationship. In Section 4, we describe the te ch-niques used to evaluate the performance of these methods. In particular, the generation process of the target model an d the associated parameters which we vary are described. We then present the results of our experimental evaluation in Section 5. We conclude the paper with some remarks and discussions of open issues in Section 6.
In this section we formally present the problem, introduc-ing notation and definitions. We also describe the key notion of  X  X ranger causality X .
In this section, we precisely formulate the causal modeling problem we consider in this paper. We are interested in modeling and characterizing the causal relationship betwe en features , x 1 ,..., x p . A feature causal network is defined as a directed graph over the features, in which each edge is labeled with a natural number called the lag of the edge. The semantics of a feature causal network is akin to that of the popular Bayesian networks, but with the underlying premise that an edge necessarily entails causation, analogously to the interpretation of an edge in causal networks [26]. As in Bayesian networks, the lack of an edge between a pair of features does imply that the two features are conditionally independent, given some subset of the other features.
Given a feature causal network, we associate a certain stochastic process that generates time series data with re-spect to it. In order to define this stochastic process, it is convenient to introduce the notion of temporal (or lagged) variables corresponding to each feature x i . That is, for some predefined window size T , we define temporal variables x ,..., x T i , corresponding to feature x i . The stochastic data generation process of a feature causal network is concretel y defined by a corresponding graphical model (Bayesian net-work) over these temporal variables in the following way: If the lag associated with an edge x i , x j is k , then we place a directed edge from x T  X  k i  X  x T j . Given the graphical model over the temporal variables, the stochastic process starts by generating an initial sequence of T feature vectors, and sub-sequently generating, at any given time step, the next fea-ture vector according to the conditional probability densi ty defined by the graphical model over the lagged set of vari-for t = 0 , ..., T  X  1 are instantiated with the values in the vec-tors in the last T time steps. Note that this is essentially the way time series data can be obtained using a  X  X nit causal graph X  [1], which plays the role of the graphical model men-tioned above. Here the conditional density model for an edge set could in principle be an arbitrary statistical model [13, 1], but in all of our experiments, we assume that they are linear Gaussian models [23]. Similarly, we assume that the initial distribution is a linear combination of Gaussia ns. With these assumptions, the stochastic models associated with causal feature networks are also equivalent to the so-called Vector Auto-Regressive (VAR) models, but it is im-portant to recognize that the notion could make sense for a wider range of model classes.

Given the above definition of a feature causal network, the goal of a causal modeling algorithm is to infer the struc-ture of the feature causal network, given as input time serie s data generated by its associated stochastic process. Here t he structure of the causal network refers to the directed graph over the feature space, usually excluding the lag labels at-tached to the edges, or the particular statistical models in the associated temporal data generation model. Thus, the performance of a causal modeling algorithm can be mea-sured purely in terms of a measure of similarity between the output or hypothesis graph and the target graph that gave rise to the input data.

Note that what we present here is closely related to the standard formulation of statistical modeling for time serie s data, but with a slightly different emphasis in its goal. That is, in the usual formulation, the goal is to recover the as-sociated model of temporal data generation, whereas here the goal is in understanding the underlying causal structur e among the features, which is nothing but the graph struc-ture among the features.
As it turns out, a notion of causality that is highly rel-evant to the present context of temporal causal modeling called  X  X ranger Causality X  has been introduced in the area of econometrics [11]. This notion is based on the idea that a cause should be helpful in predicting the future effects, be-yond what can be predicted solely based on their own past values. More specifically, a time series (or a  X  X eature X  in the terminology of the present paper) x is said to  X  X ranger cause X  another time series y , if and only if regressing for y in terms of both past values of y and x is statistically sig-nificantly more accurate than doing so with past values of y only. Let { x t } T t =1 be lagged variables of x and { y and let ~x t denote, in general, the vector h x t i t t =1 Granger test is performed by first conducting the following regressions: and then applying an F-test (or some other similar test) to obtain a p -value for whether or not (1) results in a better regression model than with (2) with statistically significa ntly advantage.

It should be noted that the original notion of Granger causality was formulated in terms of linear regression, but this need not necessarily be the case  X  there are some non-linear extensions in the literature [2]. It is also importan t to note that Granger causality attempts to capture an in-teresting aspect of causality, but certainly is not meant to capture all. In particular, it has little to say about situa-tions in which there is a hidden common cause for the two features in question. More generally, in the present paper, we do not address the important but challenging issue of dealing with hidden variables.
In this section we describe the various methods for tem-poral causal modeling we consider in our experiments, and discuss some of their properties.
A natural way of applying the notion of Granger Causality to modeling of time series data involving many features is to simply apply the Granger causality test to each pair of features to determine the presence/absence and orientatio n of the corresponding edge in the output feature causal graph . Schematically, this method can be represented as follows.
Procedure Exhaustive -Granger ( X, T ) 1. X lag  X  Lag( X, T ) 2. G = h V, E i X  F ullyConnectedF eatureGraph ( X )
Note here that we use Lag( X, T ) to denote the lagged ver-sion of data X , that is, the data set constructed by appro-priately displacing and repeating the temporal variables x = x i, 0 ...x i,T of our original features x i . F ullyConnected F eatureGraph ( X ) denotes the fully connected graph de-fined over the features. Also note that we use Granger( x, y, X lag ) to denote the outcome ( X  X es X  or  X  X o X ) of the Granger causality test between features x and y applied on the lagged data X lag , possibly parameterized by a significance level, as described above.

In our experiments, we make use of the  X  X rangertest X  function in the lmtest library in R for performing the Granger Test.
The Exhaustive Granger method of the last subsection does not address the issue of combinatorial explosion, both in the computational and statistical senses. Computation-ally, having to conduct Granger Test, which itself involves applying regression on the lagged variables, O ( p 2 ) times, where p is the number of features, can be prohibitive for large values of p . Also, the statistical significance tests, for all pairs of features, are conducted sequentially without r e-gard to the possible interactions between them.

The Lasso Granger method we consider next is one way to address such issues. One can apply regression to the neighborhood selection problem for any particular feature , namely that of identifying the subset of features on which the feature in question is conditionally dependent, given t he fact that the best regressor for that variable with the least squared error will, in theory, have non-zero coefficients onl y for the variables in the neighborhood.

The Lasso algorithm for linear regression is an incremental algorithm that embodies a method of variable selection using the L1-penalty term [29]. That is, its output, ~w , minimizes the sum of the average squared error of regressing for y , plus a constant times the L1-norm of the coefficients, namely, where S is the input sample, n is the number of examples in S , and  X  is a constant to be determined. It is well-known that the L1-penalized least square regression, as targeted by the Lasso, is a convex problem, making it possible to attain the global maximum, via the so-called  X  X east angle regres-sion X  procedure, which incrementally updates the weight fo r one variable at a time [6].

The following summarizes the Lasso-Granger method just described. Note here that we denote by Lasso ( y, X lag ) the set of temporal variables receiving a non-zero coefficient by the Lasso algorithm, when regressing y t in terms of the lagged variables x t  X  , t  X  = t  X  T, ..., t  X  1 for all x  X  X .
Procedure Lasso -Granger ( X, T ) 1. X lag  X  Lag( X, T ) 2. G = h V, E i X  F ullyConnectedF eatureGraph ( X ) One question that arises is how to set the parameter  X  . In this paper we tried two methods. The first ( lasso time series ) uses the generalized cross validation score [10] (a pop-ular tool for calculating the parameters of regularized lin ear regression) to select a set of candidate features, and does another round of linear regression to select the most signif -icant subset of these candidates. The second method ( lasso lambda or modified lasso time series ) sets  X  as in [19]. For completeness, we also tested a non-Grangerized version of lasso (without lagging) called lasso standard .
As one of the  X  X aseline X  methods, we consider the  X  X IN X  method. SIN is a method for structure learning which works very well for linear Gaussian graphical models with rela-tively small numbers of features, thus it should serve as a good upper bound of ideal performance for that portion of the problem space.

The SIN method rests on the observation that there is no causal relationship between two variables, x i and x j there exists a subset of variables X s  X  X \{ x i , x j } condi-tioned upon which x i and x j are independent (the so-called assumption of faithfulness [22, 26]). Indeed, this is the ma in idea behind many causal discovery algorithms such as the PC-algorithm [26, 1, 25].

More specifically, SIN is based on the fact that the d-separation, or conditional independence in graphical mode ls, coincides with the notion of partial correlations. The par-tial correlation,  X  xy.V , between two features x, y is the cor-relation between them in the conditional distribution give n the rest V of the variables. A key fact is that the partial correlation can be computed in terms of the inverse of the covariance matrix  X   X  1 , known as the concentration matrix, i.e. where  X  x,y denotes the x, y -th element of  X   X  1 .
SIN is also distinguished by the way it applies  X  X imulta-neous X  statistical tests on the hypotheses  X   X  xy.V = 0? X , for all pairs x, y , in such a way that the overall error rate can be controlled.

Given the neighborhood determination made by the SIN method, what remains is the orientation of the edges in its output graph. Once again, we resort to the disjunctive collapsing procedure of a variable space graph to the cor-responding feature graph, by judging that a directed edge x  X  y is to be placed if there is an edge from at least one of x  X  X  lagged variables x 1 , ..., x t  X  1 to y t and vice-versa, and an undirected one if both are true. A schematic representation of the resulting method, SIN-Granger, is given below.
Procedure SIN -Granger ( X, T ) 1. X lag  X  Lag( X, T ) 2. G  X  F ullyConnectedV ariableGraph ( X lag )
Note that F ullyConnectedV ariableGraph ( X lag ) denotes the fully connected graph defined over the lagged variables, as the name implies. The graph in the temporal variable space in Line 3 is projected to the feature space by the P rojectF eatures procedure in Line 4, by merging all the variables x lag i of a feature x i into a single node, using the disjunctive semantics described above, and implicitly em-ployed by the previous two methods.
 When the covariance matrix can be inverted feasibly, the SIN method does provide a nearly perfect solution to the structure learning for linear Gaussian graphical models, be -cause of the correspondence between the zeros in the con-centration matrix and the d-separation in a linear Gaussian graphical model. There are issues, however, for example when the number of features is large and the inversion of the covariance matrix can fail due to under-specification. Also , the computation time can be an issue, due to the nearly cubic time complexity of the matrix inversion process.
In our experiments, we make use of the SIN library in R, to perform the SIN part.
As another  X  X aseline X  method, we also consider the Vec-tor Auto-Regressive (VAR) model estimation method, which generalizes the univariate auto-regressive (AR) model to mu l-tiple time-series. In the simple AR model, an observation of time t is given by where a i is the parameters of the model and  X  t is the Gaus-sian noise. The stochastic model associated with our causal feature graph is nothing but a VAR model on the lagged temporal variables, and given the assumption that each of the models is a linear Gaussian model, they can be formu-lated as follows. Letting ~ X t denote the vector of all features at time t , a VAR model is defined as: where each of the A matrices are p  X  p coefficient matrices. This formulation is essentially a notational shorthand for multiple linear regression formulations, one for each of th e features x .
The VAR model estimation method is to invert the A ma-trices in the above formulation, and is basically solving le ast squared regression problems. In our experiments, we use the  X  X stVARXar X  function in the DSE library of R, which in turn makes calls to the  X  X r X  function, an auto-regressive modeling procedure with ARMA, and has a number of dis-tinguishing features: It can handle endogenous variables, optionally invoking a model selection method based on AIC, and it is using the Yule-Walker approach, and thus the mod-eling is done effectively with the means subtracted out.
Since the data generation process we use is indeed a VAR model, this procedure is also expected to work well and pro-vide another baseline.
As we pointed out earlier, the estimation using VAR per-forms well only in cases where the sample size n is much larger than the number of features p , i.e. n &gt;&gt; p . Rem-edy for sparse data can be found in various methods which could be viewed as regularized versions of VAR. Here are a few examples.
Several comparison studies on the relative performance of different regularization methods show that: in general a hard threshold performs slightly worse than other ap-proaches; in terms of connectivity, ridge regression works the best for graphs with large connectivity while Lasso out-performs others for graphs with small connectivity; in term s of small sample size, Lasso tends to perform poorly and James-Stein type shrinkage works well. 1 Overall, however, the difference in performance between the various penaliza-tion schemes is relatively small [21, 30]. Therefore in the present paper we elect to employ the VAR algorithm com-bined with AIC as a representative of this class of methods.
Note that Lasso applied as regularization on VAR here is to be disntinguished from Lasso Granger of the last subsec-tion  X  in Lasso Granger, Lasso is applied for regressing each variable, whereas here the L1-penalization is to be applied for the VAR estimation process for the entire vector.
One of the major advantages of using Lasso for graphi-cal model structure learning is its consistency. It has been shown that the probability of Lasso falsely including any of the non-neighboring variables of a given node into its neigh -borhood estimate vanishes exponentially fast, even if the number of non-neighboring variables may grow very rapidly with the number of observations. More rigorously, letting p denote the number of features, a be an arbitrary node in the true graph G, and ne a be the set of neighbors of a in mal linear regressor for a using ne a , we have the following theorem due to [19].

Theorem 1. Suppose the following assumptions are ful-filled: (1)high dimensionality: there exists  X  &gt; 0 , so that p = O ( n r ) for n  X   X  . (2) non-singularity: for all a  X  V and n  X  N , Var ( a ) = 1 and there exists v 2 &gt; 0 , so that Var ( a | V \{ a } )  X  v 2 . (3) sparsity: there exists 0  X   X   X  1 , max a | ne a | = O ( n  X  ) , for n  X  X  X  ; (4) sparsity: there exists of partial correlations: There exists a constant  X  &gt; 0 and where  X  ab is the partial correlation between a and b [17]: (6) neighborhood stability: there exists some  X  &lt; 1 , | S a for all ( a, b )  X  E , where S a ( b ) = Then, if the penalty for sample size n satisfies  X  n  X  dn with some  X   X   X   X   X  and d &gt; 0 , there exists some c &gt; 0 such that for all a  X  V it holds that the estimated neighborhood c ne a satisfies P ( c ne a  X  ne a ) = 1  X  O (exp(  X  cn  X  )) for n  X  X  X  . In addition, we also have P ( ne a  X  c ne a ) = 1  X  O (exp(  X  cn for n  X  X  X  .
 Notice that Theorem 1 holds even for cases in which the number of variables is larger than the number of observa-tions, i.e. p &gt;&gt; n .

In our present context, this theorem can be directly ap-plied to derive a corollary on the consistency of Granger Lasso.
 Corollary 1. Suppose that a true feature causal graph G and its associated stochastic model (graphical model) M gives rise to time series data. If the assumptions in Theo-rem 1 are fulfilled by the M  X  X , then Granger Lasso, taking the time series data as input, will output graph which is con-sistent with the true graph G with probability converging to 1, as n and p tend to  X  .

Proof. In step 3(a) of Procedure Lasso-Granger , follow-ing Theorem 1 we have P ( c ne  X  x  X  ne x ) = 1  X  O (exp(  X  cn for n  X   X  and P ( ne x  X  c ne  X  x ) = 1  X  O (exp(  X  cn  X  )) for n  X   X  . Given the correctness of the estimated graphical model on the lagged variables, the disjunctive projection i n steps A-D in Procedure Lasso-Granger will also be correct with respect to the edge presence and orientation in the original feature causal graph.
While most research on structure learning focuses on re-covering the true graph that gave rise to the data, in many real world applications we need to deal with large-scale dat a with hundreds or thousands of features. This may pro-hibit the use of accurate but computationally demanding methods. The computational complexity is therefore an im-portant factor that directly influences the applicability o f a learning algorithm. Here we analyze the computational complexity of the main methods considered in this paper: SIN algorithm is matrix multiplication and inversion. As is well-known, the general complexity of inverting a matrix is essentially cubic in the dimension 2 . Therefore the computa-tional complexity of SIN is O (( pT ) 3 + n ( pT ) 2 ) L 1 regularizer in Lasso requires quadratic programming, an NP-hard problem in general. However, by rewriting the ob-jective function, we can solve the problem using the Least Angle Regression (LARS), which computes all possible Lasso estimates for a given problem and enjoys a much smaller computational complexity [6]. With this implementation, the computational complexity of Lasso Granger is signifi-cantly reduced to O ( n ( pT ) 2 ).
 Granger causality via regression between each pair of fea-tures. Therefore the complexity is O ( n 2 p 2 T 2 ). gression, which theoretically involves cubic complexity. How-ever, there are many types of speeding algorithms, such as Yule-Walker approach, and the time complexity is between O ( p 2 T 2 ) and O ( pT ).
In this section we introduce the techniques used to eval-uate the temporal causal modeling algorithms laid out in the previous section. Specifically, we describe the data gen -eration process used in our simulation experiments, as well as some measures of graph similarity used to quantify the quality of the models output by the respective algorithms.
The data generation process we use essentially parallels the problem formulation presented in Section 2.1, in terms of the feature causal network and its associated stochastic data generation process. We begin by randomly generating a feature causal network. This random generation is governed by a parameter which we call affinity , or the probability of forming a link between any given pair of feature nodes. Having formed the feature causal graph, we then generate a unit causal graph in the temporal variable space that is consistent with it. This is done by randomly choosing the lag k for any edge x  X  y in the feature causal graph, according to a uniform distribution within a prescribed range and then forming an edge x T  X  k  X  y T in the unit causal graph.
Once this graph structure is created, we then randomly assign those links some weight, sampled from a specified range(min, max effect), which determines the parameter of the corresponding linear gaussian model. Each variable als o gets some gaussian noise of mean 0 and some specified range of standard deviations. We then apply the unit causal graph
The complexity of matrix inversion can be reduced, for example to O ( p 2 . 376 ) by using the Coppersmith Winograd algorithm [3]. recursively to obtain the time series data, each of some fixed time steps (Max T ). Once we reach Max T , we have one com-plete sample. We then repeat this process to get n samples.
We now describe how we quantify the similarity between the target causal graph used to generate the input data and the output causal graph. For this, we simply apply the met-rics of Precision, Recall and F 1 -measure, commonly used in the machine learning and information retrieval literature, to the problem of predicting the 0,1-label in the adjacency matrix representation of the graph. (See, for example, [25] for use of these metrics in evaluation of structural learn-ing methods.) Note that for any pair of features, x i and x , there are two entries in the adjacency matrix A , A [ i, j ] and A [ j, i ], each representing an edge going in one direc-tion. A bi-directed edge corresponds to having 1 in both entries, whereas a directed edge would have 1 in one of the entires and a 0 in the other. Given this formulation, preci-sion and recall are well-defined. For example, predicting a bi-directional edge between x i and x j , when there is actu-ally a directed edge from x i  X  x j , would entail one correct prediction and one prediction error.

So, letting A  X  denote the target adjacency matrix, b A the output adjacency matrix, and V  X  V the set of feature pairs, precision P and recall R are defined as follows: Furthermore, given precision P and recall R , the F 1 -measure, F , is defined in the usual manner.
 There is clearly a trade-off between precision and recall as the goal of prediction, and the F 1 -measure tries to balance the overall quality of prediction.
In this section, we present the results of our experimental evaluation. First, we examine how the relative performance of the competing methods depends on various parameters of the problem. We then present some concrete examples of applying these same methods on a real world data set and discuss their relative merits.
A series of simulation experiments were conducted, each of which consisted of a large number of randomized simu-lation runs, in which various aspects of the simulation or the problem space were varied, which are mostly parame-ters of the target causal and stochastic model to be learned from generated data. In each such run, all or a subset of the competing methods were run to obtain their learned models, which were then compared and evaluated against the target model that generated that run X  X  data.

Several series of such experimentation were run: First, all the methods were run on a representative range of the prob-lem space varying all the parameters of the problem space (f) samples per feature per lag .
 Figure 2: F 1 varies as a function of maximum lag (Max T , (a) and (b)) and features ( p , (c) and (d)) conditioned on samples per feature per lag ( n/p/Max T ). to examine the overall trend of their relative performance. We then  X  X rilled down X  into some selected sub-spaces of the problem space to examine some specific questions. Part of this is done by examining the distributions of relative per-formance measures, conditioned upon some restrictions of one or more of the parameters considered, in terms of in-equalities (e.g. the sample size per feature be greater than 10 or less than 10.)
The parameters of the problem space that we varied are: the number of features, the maximum lag, the number of samples per feature, the number of samples per feature per maximum lag, the maximum standard deviation of noise, the maximum/minimum coefficient of an effect, the affinity or anti-sparsity, which is defined as the probability of an edge presence.

In each of these series of experiments, the simulations were repeatedly run on a large number of different data sets, with all the reported performance numbers averaged over them, algorithms on multiple synthetic data sets (right). and confidence intervals calculated using the standard er-ror. The results of these experiments are shown in Figure 1. Although complete results for exhaustive Granger are not shown (due of the excessive time required to complete each trial, as will be shown in the plots of running time: c.f. Figure 5), preliminary experiments indicate exhausti ve Granger X  X  performance is somewhere between SIN and VAR. Plot (a) indicates that increasing lag (Max T ), in and of it-self, does not affect performance that much, while (b) shows the expected drop in performance as the number of features increases. This decrease in performance is also seen in (c) a s a function of affinity. Interestingly, as the density increas es, most of the algorithms suffer, while the time series lasso (T) maintains its performance and thus relatively improves . Plot (d) suggests that all methods are relatively robust to noise. Finally, plots (e) and (f) show a shrinking of the gap between SIN and lasso as the number of samples available to the algorithm (weighted by feature size and lag, respec-tively) approaches zero. This makes sense in light of the fact that the regularized lasso has many fewer parameters to estimate than the full VAR or SIN model, and thus can achieve comparable results with fewer examples.

Because of the marginalization over unmeasured param-eters in the plots above, it is somewhat difficult to tease out exactly how variations in groups of parameters affect each algorithm X  X  relative and absolute performance. Figure 2 attempts to address this issue by showing a detail of Fig-ure 1, this time splitting the plots out by conditioning on sample size. F 1 vs maximum lag in (a) and (b), and F 1 vs p in (c) and (d). Plots (a) and (c) are for experiments with small samples per feature per lag ( n/p/Max T &lt; 10), while (b) and (d) show trials with a relatively large num-ber of samples per feature per lag. We can see that SIN dominates when it has access to lots of examples (b). As the number of examples decreases, however, the lasso-based methods become more competitive (a). A similar pattern is seen between plots (c) and (d). We see that SIN excels when given data containing few features and lots of data (d), and struggles otherwise. Again, due to the high computation time, Exhaustive Granger trials are not shown.

Figure 3 shows the actual graph structure output on a few such trials. The leftmost graph shows the true struc-ture from which the synthetic data was generated. To the right are the graphs learned by each of the six algorithms. Examining these output graphs is illuminating, since they contain extra information that is lacking in simpler perfor -mance metrics summarized as a single number. For example, you can see, for this subspace of the problem space, SIN is very accurate, VAR tends to output dense graphs, Exhaus-tive Granger seems less robust alternately outputting dens e and spare graphs, and the model selection mechanism of the time series Lasso with the  X  X ambda X  modification appears to be working well.
 Log(Runtime in seconds) Log(Runtime in seconds) Log(Runtime in seconds) Log(Runtime in seconds) Log(Runtime in seconds) Log(Runtime in seconds) Figure 5: Log runtime (in seconds) as a function of effective feature size ( p  X  MAX T )).

Figure 5 shows the rate at which the running time of each algorithm grows as a function of the number of features , 15 &lt; p &lt; 125, times the maximum lag , 1 &lt; Max T &lt; 5. Since all of these algorithms (except standard lasso) lag th e data before attempting to model it, the effective number of features of the data is p *Max T . Time is plotted on a log scale to better show the exponential growth in running time. Ex-haustive Granger (denoted  X  X ranger X  in the graph) clearly is the most expensive algorithm taking over ten minutes for a dataset of less than 100 features. SIN grows at a slightly slower rate, followed by the two lagged lasso methods (T and M in the figure). Standard lasso grows the most slowly since it does not lag its input data. VAR is interesting because it starts out fast but begins to run much more slowly as Max is increased. This is because, unlike the other algorithms, VAR actually searches the space of possible lagged models in order to choose the best fit.
In this subsection, we present some results of applying our causal modeling methods on a real world data set involving key performance indicators (KPI X  X ) of electronics companie s. The problem of monitoring and analyzing performance in-dicators of corporations is important in business investme nt decision making, and has recently received considerable at -tention [15, 16]. This particular data set was obtained from Standard and Poor X  X  Compustat database [27].

The data set consists of values of various performance in-dicators for electronics companies that are in the industry group of  X  X emiconductors and semiconductor equipments. X  Specifically, quarterly data over the duration of three year s were pulled, for companies having at least 25 million dollars in annual revenue. The performance indicators in the data set include financial performance metrics such as Revenue growth, EBIT margin, productivity (Revenue/Employee), ROA, Market Cap Growth, Earnings per Share (EPS), PE Ratio, and Beta. The data also include lower level (op-erational) metrics such as Revenue per R&amp;D Spend, Busi-ness Week X  X  Investing 4 Future Index, Capital Expenditure / Revenue, Current Ratio, Working Capital/Revenue, COGS/ Revenue, SG&amp;A Revenue, Operating Cash Flow/Revenue, Inventory Cost/Revenue, Inventory Turnover, Cash conver-sion cycle in days, SG&amp;A Revenue, and Net Working Capital Ratio.

For many of these metrics, we consider both  X  X bsolute X  values and the  X  X AGR X  values or the  X  X ompound Annual Growth Rate X , which measures the annual rate of growth of the KPI in question. We note that some normalization and outlier filtering were performed in generating these data.
The results of running each of the structure learning al-gorithms on this KPI data are shown in Figure 4. Some interesting observations can be made, particularly with the output graph of  X  X odified Lasso time series X . For exam-ple, we see that SGA2Rev (SGA to Revenue) is causally related to PE Ratio. We also see that Inventory Turnover is causally related to Beta. Since SGA to Revenue and In-ventory Turnover are lower level operational metrics than PE Ratio and Beta, which are financial, this admits the in-terpretation that the former two metrics could be  X  X evers X  to pull for attaining desired financial performance in terms of the latter two. Although interpreting these relationshi ps properly is difficult without deeper domain knowledge, it is clear that the graph learned by the lasso with lambda tun-ing is the most succinct and potentially useful for corporat e performance management purposes.

Even with domain expertise, making sense of the very dense models generated by Exhaustive Granger (denoted  X  X RANGER X ), SIN and Var would be tedious, if not im-possible, and would likely yield few insights.
We have presented a systematic evaluation of the rela-tive performance of a host of related methods of temporal causal modeling based on Granger causality and graphical modeling. Our empirical evaluation has demonstrated that some of the new model selection methods in regression and graphical modeling are effective for providing a practical a l-ternative to canonical methods, which are more exhaustive in nature. In certain scenarios, it has been found, they can add extra predictive accuracy and may also help improve the interpretability of obtained models by arriving at more suc -cinct models. In the future, efforts are required to further pinpoint the conditions in which the different approaches discussed in the paper are most effective, and the range of real world problems for which they add value. Various possi-bilities should also be explored to improve the performance of these methods, possibly by combining them with other techniques known in the causal modeling literature. The authors would like to thank Saharon Rossett, Rick Lawrence, Markus Ettl and Rama Akkiraju of IBM Re-search, and Richard Scheines, Clark Glymour, and Peter Spirtes of CMU for discussions and support. [1] T. Chu and C. Glymour. Semi-parametric Causal [2] T. Chu, D. Danks, and C. Glymour. Data Driven [3] D. Coppersmith and S. Winograd. Matrix [4] A. Dobra, B. Jones, C. Hans, J. Nevins, M. West. [5] M. Drton and M.D. Perlman. A SINful Approach to [6] B. Efron, T. Hastie, I. Johnstone and R. Tibshirani. [7] M. Eichler. Graphical modeling of multivariate time [8] N. Friedman, I. Nachman, and D. Peer. Learning [9] P.D. Gilbert. Combining VAR Estimation and State [10] G. Golub, M. Heath, and G. Wahba. Generalized cross [11] C. W. J. Granger. Investigating causal relations by [12] D. Heckerman. A Tutorial on Learning with Bayesian [13] P. O. Hoyer, S. Shimizu, and A. J. Kerminen. [14] M. Kalisch and P. Buehlmann. Estimating [15] R. Kaplan and D. Norton. The Balanced Scorecard -[16] R. Kaplan and D. Norton. The Balanced Scorecard: [17] S. Lauritzen. Graphical Models . Oxford University [18] C. Meek. Graphical Models: Selecting Causal and [19] N. Meinshausen and P. Buhlmann. High dimensional [20] A. Moneta and P. Spirtes. Graphical models for the [21] R. Opgen-Rhein and K. Strimmer. Learning causal [22] J. Pearl. Causality . Cambridge University Press, [23] S. Roweis and Z. Ghahramani. A Unifying Review of [24] S. Shimizu, A. Hyv  X  a rinen, P.O. Hoyer, and Y. Kano. [25] R. Silva, R. Scheines, C. Glymour, P. Spirtes. [26] P. Spirtes, C. Glymour, and R. Scheines. Causation, [27] Standard &amp; Poor X  X  Compustat Data. Available from [28] R. Scheines, P. Spirtes, C. Glymour,and C. Meek X . [29] R. Tibshirani. Regression shrinkage and selection via [30] P.A. Valdes-Sosa et. al. . Estimating brain functional
