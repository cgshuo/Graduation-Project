 The use of brain-wave patterns for person verification has been investigated at IDIAP in Switzerland [1]. It has been shown that the brain-wave pattern of every individual is unique and that the electroencephalography (EEG) brain signal can be used for person identification [2]. Traditional biometrics such as fingerprint, voice, and retina can be damaged or missing for some people, however EEG biometric exists in every person. EEG has advantageous such as unobtrusive, requiring living person recording, spontaneous signal, individual uniqueness due to different brain configurations [3].

Person verification is different from perso n identification. Person identification is to match the user biometric data against all the records in a database, while person verification is to accept or to reject a user claimed identity providing his biometric data. EEG-based biometry is an emerging research topic that can open new research directions and applicatio ns. Most EEG-based biometry work was focusing mainly on person identification, for example [4] and very little work has been done on person verification [1]. In [5], Manhattan distances on autoregressive (AR) coefficients with PCA were used to com pute thresholds for determining test patterns were clients or impostors, the person verification task from 5 subjects were done in 2 stages. In [6], Independent Component Analysis (ICA) was used to determine dominating brain regions to extract AR features, then a Naive Bayes probabilistic model is employed for person authentication of 7 subjects with Half Total Error Rate (HTER) of 2.2%. In [1], Gaussian mixture models has been ap-plied for person verification task on EEG signal from 9 subjects. Half total error rate of 6.6 % was achieved for imagination left task. Those results were satisfactory but the numbers of subjects were very small.

Most features in BCI research have high dimensionality due to the number of channels. In addition, the training sets are usually small since the training process is time consuming and demanding [7]. As a result, models based on density estimation do not have enough data for training. Usually, maximum a posteriori adaptation is used to overcome this problem as seen in [1]. On the other hand, models based on kernel aim at determining the boundaries of the data instead of probability density, hence they do not require a lot of data for training. In support vector data description (SVDD), a spherically shaped boundary around a normal data set is used to separate this set from abnormal data. The volume of this data description is minimized to reduce the chance of accepting abnormal data. I n [8], SVDD was used to model 70 individuals using energy features and attained 0.9913 area under curve (AUC). However SVDD does not guarantee that the single spherically shaped boundary can best describe the EEG data due to complex data distributions and much noise and outliers. A better description is the use of multiple spheres, however there is currently no investigation available for EEG-based person verification.

In speaker verification, the task can be stated as a hypothesis testing be-tween the two hypotheses: the input utterance is from the hypothesis speaker, are usually in modelling the hypothesis H 1 since it should represent all possi-ble alternatives speakers. There are two approaches to model the alternatives speakers [9]. The first approach uses a set of other speaker models to cover the space of the alter native hypothesis, this is called likelihood ratio sets, cohorts or background speakers. The selection, size and combination of the background speakers have been the subject of much research [9]. The second approach pools speech from several speakers and train a single model, this is called the world model or universal background model (UBM). This approach has become the predominate and has been focused on sel ection and composition of the speakers [9]. The advantage of this approach is that a single background model can be trained once and shared for all hypothesis testing of individual speakers.
GMM UBM has been the state-of-the-art high performance probabilistic model for representing speaker model and alternative speaker models because of its capability to approximate arbitrary densities [10]. Recently, Support Vector Ma-chine (SVM) has been used for speaker verification. Because SVM draws an op-timal hyper-plane to separate two classes, its application to speaker verification is to separate the client from impostors. The score of a vector is its the distance to the hyperplane and the threshold can be changed by adding some amount to the decision value causing the hyperplane moves nearer or further the class H 0. In [11] SVM was combined with GMM for sp eaker verification by stacking the means of the adapted mixture components into a GMM super-vectors. Then a linear kernel is derived based on an appr oximation to KL divergence between two GMM models. In [12] and [8] the authors use SVDD for speaker verification task the distance to the sphere centers are used as scores, the former author con-vert score to probability and the later author use percentage of rejection data as threshold.

In this paper, we propose a multi-sphere SVDD (MSSVDD) person verification in which an optimisation problem and an iterative algorithm are proposed to determine model parameters for MSSVDD to provide a better data description to EEG data for a person. An SVM UBM model is proposed to represent the person and background models as a set of sphere distributions, each sphere can represent some characteristics of a person with well-trained decision boundaries. Hence the collection of spheres can hopefully represent the varieties of feature space.
 Experimental results on 4 large data sets show that the proposed multi-sphere SVDD can perform as the GMM UBM and the SVM UBM out perform GMM UBM. 2.1 Problem Formulation Consider a set of m hyperspheres S j ( c j ,R j )with center c j and radius R j , j = 1 ,...,m . This hypershere set is a good data description of the normal data set data set and the sum of all radii m j =1 R 2 j should be minimised.
Let matrix U =[ u ij ] n  X  m , i =1 ,...,n , j =1 ,...,m where u ij is the hard membership representing the belonging of data point x i to hypersphere S j , u ij = sphere SVDD can be formulated as follows subject to is vector of centres.

Minimising the function in (1) over variables R , c and  X  subject to (2) will determine radii and centres of hyperspheres and slack variables if the matrix U is given. On the other hand, the matrix U will be determined if radii and centres of hyperspheres are given. Therefore an iterative algorithm will be applied to find the complete solution. The algorithm consists of two alternative steps: 1) Calculate radii and centres of hyperspheres and slack variables, and 2) Calculate membership U .

Forclassifyingadatapoint x , the following decision function is used The unknown data point x is normal if f ( x ) = +1 or abnormal if f ( x )=  X  1. 2.2 Calculating Radii, Centres and Slack Variables The Lagrange function for the optimisation problem in (1) subject to (2) is as follows L ( R,c, X , X , X  )= u
Setting derivatives of L ( R,c, X , X , X  )with respect to primal variables to 0, we obtain m individual optimisation problems as follows subject to After solving all of these individual optimization problems, we can calculate the updating radii R =[ R j ] and centres c =[ c j ], j =1 ,...,m using the equations in SVDD. 2.3 Calculating Membership U We use radii and centres of hyperspheres to update the membership matrix U . The following algorithm is proposed: 2.4 Iterative Learning Process The proposed iterative learning process for multi-sphere SVDD will run two al-ternative steps until a convergence is reached as follows The MSSVDD UBM models the background space by using multi-hypersphere distribution approach. The set of K background people is trained using multi-sphere SVDDs, each person is represented by n spheres resulting nK spheres in total. Then this single background model will be shared for all hypothesis testing of individuals. When testing hypothesis for a person, his/her model will be removed from the background model.
 Below are widely used normalisation methods in person verification [13]: The simplest method of scoring is to use the absolute likelihood score or in its log domain (7). The score (8) and its log domain (9) uses normalisation, the term log P ( X |  X  ) is called the normalisation term and requires calculation of all impostors likelihood functions. An approximation of this method is to use only the closest impostor model for calculating the normalisation term (10)
Let x be a feature vector, S = S ( c,R ) be a hyper-sphere, we can consider the probability of x belongs to the sphere S as Then the above scores for SVM will become L 1 ( x ) = log P ( x |  X  S )  X  log P ( x |  X  )=  X  x  X  c S  X  log The above scores for SVM have simple interpretations. The score (11) with a radius threshold R S checks whether x is inside or outside sphere S .Thescore (12), (13) and (14) check whether x is nearer to the sphere S than other sphere T .
 In this paper, we define the probability of x belonging to the sphere S as P ( x |  X  S )= e  X  x  X  c  X  R to incorporate the sphere size. Since the distribution of feature vectors in X is unknown, it is approximately modelled by a mixture of Gaussian densities, which is a weighted sum of K component densities, given by the equation where  X  denotes a prototype consisting of a set of model parameters  X  = { w i , X  i , X  i } , w i , i =1 ,...,K , are the mixture weights and N ( x t , X  i , X  i ) , i =1 ,...,K ,arethe d -variate Gaussian component d ensities with mean vectors  X  i and covariance matrices  X  i . The background model for GMM-UBM is trained in a similar way to MSSVDD-UBM. The set of K background people is trained using GMMs, each person is represented by a mixture of n Gaussian resulting nK Gaussian in total. Then this single background model will be shared for all hypothesis testing of individuals. When testing hypothesis for a person, his/her model will be removed from the background model. The score (14) will be used for testing.
 The verification task can be stated as a hypothesis testing between the two hypotheses: the input is from the hypothesis person, ( H 0) or not from the hy-pothesis person ( H 1) [13].

Let  X  0 be the claimed person model and  X  be a model representing all other possible people, i.e. impostors. For a given input X and a claimed identity, the choice is between the hypothesis H 0: X is from the claimed person  X  0 ,andthe alternative hypothesis H 1: X is from the impostors  X  . A claimed person X  X  score L ( X ) is computed to reject or accept the person claim satisfying the following rules where  X  L are the decision thresholds. 7.1 Datasets The Australian EEG Database used in this research consists of EEG recordings of 40 patients. This database consists of EEG records recorded at the John Hunter Hospital [14], near University of Newcastle, over an 11-year period. The recordings were made by 23 electrode s placed on the scalp sampled at 167 Hz for about 20 minutes.

The EEG motor movement/imagery ( EEGMMIDB) dataset contain record-ings of 109 subjects performed different motor/imagery tasks 1 [15]. Each subject performed 14 experimental runs in one or t hree minutes. The tasks include open-ing and closing fists or imagine opening and closing fists. The recordings used 64 electrodes 10-10 system.

The Alcoholism datasets come from a study to examine EEG correlates of genetic predisposition to alcoholism. The datasets contain EEG recordings of control and alcoholic subjects. Each subj ect was exposed to either a single stim-ulus (S1) or two stimuli (S1 and S2) which were pictures of objects chosen from the 1980 Snodgrass and Vanderwart picture set. When two stimuli were shown, they were presented in either a matche d condition where S1 was identical to S2 or in a non-matched condition where S 1 differed from S2. The 64 electrodes placed on the scalp sampled at 256 Hz for 1 second. The Alcoholism large dataset contains training and test data for 10 alcoholic and 10 control subjects. The Al-coholism full dataset contains 120 trials for 122 subjects. The summary of those datasets is listed in Table 1 7.2 Preprocessing and Feature Extraction EEG signals were first divided into 15-millisecond segments. The Alcoholism large and full datasets are downsampled to 128 Hz. Then the raw EEG signals were spatially filtered using Surface Laplacian (SL) with spline interpolation below the electrodes [1]. Then the power spectral density (PSD) in the band 8-30 Hz was estimated. The Welch X  X  averaged modified periodogram method was used for spectral estimation. Hamming window was set to 1 second and 50% overlap. 12 power components in the frequency band 8-30 Hz were extracted. Besides PSD features, autoregressive (A R) model parameters were extracted. In AR model, each sample is considered linearly related with a number of its previous samples. The AR model has the advantage of low complexity and has been used for person identification and v erification [16] [17] [5]. Burg X  X  lattice-based method was used with the AR model order 21, as a previous study [17] suggested when there were many subjects and epochs.

The electrodes C3, C4, Cz, P3, P4 and Pz were selected to extract PSD and AR features that result in 6*(12+21)=198 features. Those electrodes are available in both datasets and were used in previous study [1] based on expert knowledge. 7.3 Experimental Results All experiments were conducted using 3-fold cross validation training and the best parameters found were used to train models on the whole training set and test on a separate test set. Table 2 shows the identification rate of GMM training. The best parameter number of Gaussian is 128 for Australian EEG dataset and 4 for EEGMMIDB dataset.

For MSSVDD training the RBF kernel function K ( x, x )= e  X   X  || x  X  x || 2 was used. The parameter for MSSVDD training is  X  and  X  . The parameter  X  was proportional to the rejection percentage of the positive data when training the smallest hypersphere enclosing the positive data. The best parameters found for the first two datasets are  X  =0 . 031 and  X  =0 . 031 with EER=0.221 and the latter two datasets are  X  =0 . 125,  X  =0 . 125 with EER=0.25 and 0.35 respectively.

Figures 1 and 2 show DET curves of GMM-UBM, MSSVDD, MSSVDD-UBM on Australian EEG dataset and EEGMMIDB datasets, respectively. Over all, the MSSVDD outperforms SVDD, and the MSSVDD-UBM outperforms MSSVDD and GMM-UBM. We have presented a Multi-Sphere Support Vector Data Description approach to solving person verification problem. Experiments on the Australian EEG, EEG motor movement/imagery and Alcoholism datasets show a lower verification error rates comparing with SVDD and Gaussian mixture model-based universal background model (GMM-UBM).

