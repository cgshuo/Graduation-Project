 Online learning has been extensively studied in the machine learning community (Rosenblatt, 1958; algorithms work by assigning a fixed weight to a new example when it is misclassified. As a result, the weights assigned to the misclassified examples, or support vectors, remain unchanged during the entire process of learning. This is clearly insufficient because when a new example is added to the pool of support vectors, we expect it to affect the weights assigned to the existing support vectors received in previous trials.
 Although several online algorithms are capable of updating the example weights as the learning process goes, most of them are designed for the purposes other than improving the classification accuracy and reducing the mistake bound. For instance, in (Orabona et al., 2008; Crammer et al., 2003; Dekel et al., 2005), online learning algorithms are proposed to adjust the example weights in order to fit in the constraint of fixed number of support vectors; in (Cesa-Bianchi &amp; Gentile, 2006), example weights are adjusted to track the drifting concepts. In this paper, we propose a new formulation for online learning that aims to dynamically update the example weights in order to improve the classification accuracy as well as the mistake bound. Instead of only assigning a weight to the misclassified example that is received in current trial, the proposed online learning algorithm also updates the weight for one of the existing support vectors. As a result, the example weights are dynamically updated as learning goes. We refer to the proposed approach as Double Updating Online Learning , or DUOL for short.
 The key question in the proposed online learning approach is which one of the existing support vec-tors should be selected for weight updating. To this end, we employ an analysis for double updating online learning that is based on the recent work of online convex programming by incremental dual ascent (Shalev-Shwartz &amp; Singer, 2006). Our analysis shows that under certain conditions, the pro-posed online learning algorithm can significantly reduce the mistake bound of the existing online algorithms. This result is further verified empirically by extensive experiments and comparison to the state-of-the-art algorithms for online learning. The rest of this paper is organized as follows. Section 2 reviews the related work for online learning. Section 3 presents the proposed  X  X ouble updating X  approach to online learning. Section 4 gives our experimental results. Section 5 sets out the conclusion and addresses some future work. Online learning has been extensively studied in machine learning (Rosenblatt, 1958; Crammer &amp; Singer, 2003; Cesa-Bianchi et al., 2004; Crammer et al., 2006; Fink et al., 2006; Yang et al., 2009). One of the most well-known online approaches is the Perceptron algorithm (Rosenblatt, 1958; Fre-und &amp; Schapire, 1999), which updates the learning function by adding a new example with a constant weight into the current set of support vectors when it is misclassified. Recently a number of online learning algorithms have been developed based on the criterion of maximum margin (Crammer &amp; Singer, 2003; Gentile, 2001; Kivinen et al., 2001b; Crammer et al., 2006; Li &amp; Long, 1999). One example is the Relaxed Online Maximum Margin algorithm (ROMMA) (Li &amp; Long, 1999), which repeatedly chooses the hyper-planes that correctly classify the existing training examples with the maximum margin. Another representative example is the Passive-Aggressive (PA) method (Cram-mer et al., 2006). It updates the classification function when a new example is misclassified or its classification score does not exceed some predefined margin. Empirical studies showed that the maximum margin based online learning algorithms are generally more effective than the Perceptron algorithm. However, despite the difference, most online learning algorithms only update the weight of the newly added support vector, and keep the weights of the existing support vectors unchanged. This constraint could significantly limit the effect of online learning.
 Besides the studies for regular online learning, several algorithms are proposed for online learning with fixed budget. In these studies, the total number of support vectors is required to be bounded either by a theoretical bound or by a manually fixed budget. Example algorithms for fixed budget online learning include (Weston &amp; Bordes, 2005; Crammer et al., 2003; Cavallanti et al., 2007; Dekel et al., 2008). The key idea of these algorithms is to dynamically update the weights of the existing support vectors as a new support vector is added, and the support vector with the least weight will be discarded when the number of support vectors exceeds the budget. The idea of discarding support vectors is also used in studies (Kivinen et al., 2001b) and (Cheng et al., 2006). In a very recently proposed method (Orabona et al., 2008), a new  X  X rojection X  approach is proposed for online learning that ensures the number of support vectors is bounded. Besides, in (Cesa-Bianchi &amp; Gentile, 2006), an online learning algorithm is proposed to handle the drifting concept, in which the weights of the existing support vectors are reduced whenever a new support vector is added. Although these online learning algorithms are capable of dynamically adjusting the weights of support vectors, they are designed to either fit in the budget of the number of support vectors or to handle drifting concepts, not to improve the classification accuracy and the mistake bound.
 The proposed online learning algorithm is closely related to the recent work of online convex pro-gramming by incremental dual ascent (Shalev-Shwartz &amp; Singer, 2006). Although the idea of si-multaneously updating the weights of multiple support vectors was mentioned in (Shalev-Shwartz &amp; Singer, 2006), no efficient updating algorithm was explicitly proposed. As will be shown later, the online algorithm proposed in this work shares the same computational cost as that of conventional online learning algorithms, despite the need of updating weights of two support vectors. 3.1 Motivation We consider an online learning trial t with an incoming example that is misclassified. Let  X  (  X  ,  X  ) : be the collection of n misclassified examples received before the trial t , where x i  X  R d and y i  X  { X  1 , +1 } . We also refer to these misclassified training examples as  X  X upport vectors X . We denote by  X  = (  X  1 , . . . ,  X  n )  X  [0 , C ] n the weights assigned to the support vectors in D , where C is a predefined constant. The resulting classifier, denoted by f ( x ) , is expressed as and the resulting classifier becomes The shortcoming with the conventional online learning approach is that the introduction of the new support vector ( x a , y a ) may harm the classification of existing support vectors in D , which is re-vealed by the following proposition.
 Proposition 1. Let ( x a , y a ) be an example misclassified by the current classifier f ( x ) = P As indicated by the above proposition, when a new misclassified example is added to the classi-fier, the classification confidence of at least one support vector will be reduced. In the case when y  X y a y b k ( x a , x b )  X   X   X /n ; at the meantime, it can be shown that when the classification confidence to update the weight for the existing support vector whose classification confidence is significantly affected by the new misclassified example. In particular, we consider a support vector ( x b , y b )  X  X  for weight updating if it satisfies the following two conditions We refer to the support vector satisfying the above conditions as auxiliary example . It is clear that ( x b , y b ) simultaneously. In the next section, we show the details of the double updating algorithm for online learning, and the analysis for mistake bound.
 interpreted as an efficient updating rule for maximizing the objective function in the dual form of SVM. We denote by  X  t the improvement of the objective function in dual SVM when adding a new is designed to ensure that all  X  t is bounded from the below by a positive constant  X  , then the number M , is upper bounded by: that  X  , which is referred to as the bounding constant for the improvement in the objective function, could be significantly improved when updating the weight for both the newly misclassified example and the auxiliary example.
 ( x b , y b ) . We define According to the assumption of auxiliary example, we have w ab = s ab y a y b  X   X   X  . Finally, we de-we assume  X  ( x, x )  X  1 for any example x . 3.2 Double Updating Online Learning y lemma shows how to compute  X  t , i.e., the improvement in the objective function of dual SVM by adjusting weights for ( x a , y a ) and ( x b , y b ) .
 Lemma 1. The maximal improvement in the objective function of dual SVM by adjusting weights where Proof. It is straightforward to verify that the dual function of min denoted by D t (  X  1 , . . . ,  X  t ) , is computed as follows, where 0  X   X  i  X  C, i = 1 , . . . , t and f t (  X  ) = Using the relation f t ( x ) = f t  X  1 ( x ) +  X   X  b y b  X  ( x, x b ) +  X  a y a  X  ( x, x a ) , we have h (  X  a ,  X   X  b ) =  X  a (1  X  y a f t  X  1 ( x a )) +  X   X  b (1  X  y b f t  X  1 ( x b ))  X  Finally, we need to show  X   X  b  X  0 . Note that this constraint does not come directly from the box end, we consider the part of h (  X  a ,  X   X  b ) that is related to  X   X  b , i.e., results in the constraint  X   X  b  X  0 .
 The following theorem shows the bound for  X  when C is sufficiently large.
 following bound for  X  have Thus,  X  is bounded as above problem is  X  a =  X   X  b = 1 / (1  X   X  ) , which leads to the result in the theorem. We now consider the general case, where we only assume C  X  1 . The following theorem shows the bound for  X  in the general case.
 Theorem 2. Assume C  X  1 . We have the following bound for  X  , when updating the weights for the new example ( x a , y a ) and the auxiliary example ( x b , y b ) Proof. By setting  X  a = 1 , we have h (  X  a ,  X   X  b ) computed as Hence,  X  is lower bounded by Since we only have  X   X  1 / 2 if we only update the weight for the new misclassified example ( x ( x by Theorem 1, the improvement in  X  can be very significant.
 The final remaining question is how to identify the auxiliary example ( x b , y b ) efficiently, which cation score. When a new support vector ( x a , y a ) with weight  X  a is added to the classifier, we double updating online learning is O ( n ) , where n is the number of support vectors, similar to that of the kernel online learning algorithm. Figure 1 shows the details of the DUOL algorithm. Finally, we show a bound on the number of mistakes by assuming C is sufficiently large. number of prediction mistakes M made by DUOL on this sequence of examples is bounded by: where M d (  X  ) is the number of mistakes when there is an auxiliary example, which depends on the threshold  X  and the dataset ( M d (  X  ) is actually a decreasing function with  X  ).
 Proof. We denote by M s the number of mistakes when we made a single update without finding appropriate auxiliary example. Using Theorem 1, we have the following inequality, Plugging M = M s + M d into the equation above, we can get It is worthwhile pointing out that although according to Theorem 3, it seems that the larger the value of  X  the smaller the mistake bound will be. This however is not true since M d (  X  ) is in general a increase when  X  is increased. 4.1 Experimental Testbed and Setup We now evaluate the empirical performance of the proposed double updating online learning (DUOL) algorithm. We compare DUOL with a number of state-of-the-art techniques, including Perceptron (Rosenblatt, 1958; Freund &amp; Schapire, 1999), the  X  X OMMA X  algorithm and its aggres-sive version  X  X gg-ROMMA X  (Li &amp; Long, 1999), the ALMA p (  X  ) algorithm (Gentile, 2001), and the Passive-Aggressive algorithms ( X  X A X ) (Crammer et al., 2006). The original Perceptron algorithm was proposed for learning linear models. In our experiments, we follow (Kivinen et al., 2001b) by adapting it to the kernel case. Two versions of PA algorithms (PA-I and PA-II) were implemented as described in (Crammer et al., 2006). Finally, as an ideal yardstick, we also implement a full online SVM algorithm ( X  X nline-SVM X ) (Shalev-Shwartz &amp; Singer, 2006), which updates all the support vectors in each trial, and is thus computationally extremely intensive as will be revealed in our study. To extensively examine the performance, we test all the algorithms on a number of benchmark datasets from web machine learning repositories. All of the datasets can be downloaded from LIB-limitation, we randomly choose six of them in our discussions, including  X  X erman X ,  X  X plice X ,  X  X pam-base X ,  X  X ITFace X ,  X  X 7a X , and  X  X 7a X .
 To make a fair comparison, all algorithms adopt the same experimental setup. In particular, for all the compared algorithms, we set the penalty parameter C = 5 , and employ the same Gaussian kernel with  X  = 8 . For the ALMA p (  X  ) algorithm, parameter p and  X  are set to be 2 and 0 . 9 , respectively, based on our experience. For the proposed DUOL algorithm, we fix  X  to be 0 . 2 for all cases. All the experiments were conducted over 20 random permutations for each dataset. All the results were reported by averaging over these 20 runs. We evaluate the online learning performance by mea-suring mistake rate , i.e., the ratio of the number of mistakes made by the online learning algorithm over the total number of examples received for predictions. In addition, to examine the sparsity of the resulting classifiers, we also evaluate the number of support vectors produced by each online learning algorithm. Finally, we also evaluate computational efficiency of all the algorithms by their running time (in seconds). All experiments were run in Matlab over a machine of 2.3GHz CPU. 4.2 Performance Evaluation respectively. Figure 2 to 6 show the mistake rates of all online learning algorithms in comparison over trials. We observe that Online-SVM yields considerably better performance than the other online learning algorithms for dataset  X  X erman X ,  X  X plice X ,  X  X pambase X , and  X  X ITFace X , however, at the price of extremely high computational cost. For most cases, the running time of Online-SVM is two order, sometimes three order, higher than the other online learning algorithms, making it unsuitable for online learning. For the remaining part of this section, we restrict our discussion to the other six baseline online learning algorithms.
 First, among the six baseline algorithms in comparison, we observe that the agg-ROMMA and two PA algorithms (PA-I and PA-II) perform considerably better than the other three algorithms (i.e., Perceptron, ROMMA, and ALMA) in most cases. We also notice that the agg-ROMMA and the two PA algorithms consume considerably larger numbers of support vectors than the other three algorithms. We believe this is because the agg-ROMMA and the two PA algorithms adopt more aggressive strategies than the other three algorithms, resulting more updates and better classification performance. For the convenience of discussion, we refer to agg-ROMMA and two PA algorithms as aggressive algorithms, and the three algorithms as non-aggressive ones.
 Second, comparing with all six competing algorithms, we observe that DUOL achieves significantly smaller mistake rates than the other single-updating algorithms in all cases. This shows that the proposed double updating approach is effective in improving the online prediction performance. By examining the sparsity of resulting classifiers, we observed that DUOL results in sparser clas-non-aggressive algorithms.
 Third, according to the results of running time, we observe that DUOL is overall efficient compared tron, for its simplicity, is clearly the most efficient algorithm, and the agg-ROMMA algorithm is significantly slower than the others (except for  X  X nline-SVM X ). Although DUOL requires double updating, its efficiency is comparable to the PA and ROMMA algorithms.
 Table 1: Evaluation on german (n=1000, d=24).
 Table 3: Evaluation on spambase (n=4601, d=57).
 This paper presented a novel  X  X ouble updating X  approach to online learning named as  X  X UOL X , which not only updates the weight of the newly added support vector, but also adjusts the weight of one existing support vector that seriously conflicts with the new support vector. We show that the mistake bound for an online classification task can be significantly reduced by the proposed DUOL algorithms. We have conducted an extensive set of experiments by comparing with a number of competing algorithms. Promising empirical results validate the effectiveness of our technique. Future work will address issues of multi-class double updating online learning.

Figure 2: Evaluation on the german dataset. The data size is 1000 and the dimensionality is 24.
Figure 3: Evaluation on the splice dataset. The data size is 1000 and the dimensionality is 60.
Figure 4: Evaluation on the spambase dataset. The data size is 4601 and the dimensionality is 57.
Figure 5: Evaluation on the a7a dataset. The data size is 16100 and the dimensionality is 123.
Figure 6: Evaluation on the w7a dataset. The data size is 24292 and the dimensionality is 300. Cavallanti, G., Cesa-Bianchi, N., &amp; Gentile, C. (2007). Tracking the best hyperplane with a simple budget perceptron. Machine Learning , 69 , 143 X 167.
 Cesa-Bianchi, N., Conconi, A., &amp; Gentile, C. (2004). On the generalization ability of on-line learn-ing algorithms. IEEE Trans. on Inf. Theory , 50 , 2050 X 2057.
 Cesa-Bianchi, N., &amp; Gentile, C. (2006). Tracking the best hyperplane with a simple budget percep-tron. COLT (pp. 483 X 498).
 Cheng, L., Vishwanathan, S. V. N., Schuurmans, D., Wang, S., &amp; Caelli, T. (2006). Implicit online learning with kernels. NIPS (pp. 249 X 256).
 aggressive algorithms. JMLR , 7 , 551 X 585.
 Crammer, K., Kandola, J. S., &amp; Singer, Y. (2003). Online classification on a budget. NIPS . Crammer, K., &amp; Singer, Y. (2003). Ultraconservative online algorithms for multiclass problems. JMLR , 3 , 951 X 991.
 Dekel, O., Shalev-Shwartz, S., &amp; Singer, Y. (2005). The forgetron: A kernel-based perceptron on a fixed budget. NIPS .
 Dekel, O., Shalev-Shwartz, S., &amp; Singer, Y. (2008). The forgetron: A kernel-based perceptron on a budget. SIAM J. Comput. , 37 , 1342 X 1372.
 Fink, M., Shalev-Shwartz, S., Singer, Y., &amp; Ullman, S. (2006). Online multiclass learning by inter-class hypothesis sharing. ICML (pp. 313 X 320).
 Freund, Y., &amp; Schapire, R. E. (1999). Large margin classification using the perceptron algorithm. Mach. Learn. , 37 , 277 X 296.
 Gentile, C. (2001). A new approximate maximal margin classification algorithm. JMLR , 2 , 213 X 242. Kivinen, J., Smola, A. J., &amp; Williamson, R. C. (2001a). Online learning with kernels. NIPS (pp. 785 X 792).
 Kivinen, J., Smola, A. J., &amp; Williamson, R. C. (2001b). Online learning with kernels. NIPS (pp. 785 X 792).
 Li, Y., &amp; Long, P. M. (1999). The relaxed online maximum margin algorithm. NIPS (pp. 498 X 504). Orabona, F., Keshet, J., &amp; Caputo, B. (2008). The projectron: a bounded kernel-based perceptron. ICML (pp. 720 X 727).
 Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organiza-tion in the brain. Psychological Review , 65 , 386 X 407.
 Shalev-Shwartz, S., &amp; Singer, Y. (2006). Online learning meets optimization in the dual. COLT (pp. 423 X 437).
 Weston, J., &amp; Bordes, A. (2005). Online (and offline) on an even tighter budget. AISTATS (pp. 413 X 420).
 Yang, L., Jin, R., &amp; Ye, J. (2009). Online learning by ellipsoid method. ICML (p. 145).
