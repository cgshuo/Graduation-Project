 People use various social media for different purposes. The information on an individual site is often incomplete. When sources of complementary information are integrated, a bet-ter profile of a user can be built to improve online services such as verifying online information. To integrate these sources of information, it is necessary to identify individ-uals across social media sites. This paper aims to address the cross-media user identification problem. We introduce a methodology (MOBIUS) for finding a mapping among identities of individuals across social media sites. It con-sists of three key components: the first component identifies users X  unique behavioral patterns that lead to information redundancies across sites; the second component constructs features that exploit information redundancies due to these behavioral patterns; and the third component employs ma-chine learning for effective user identification. We formally define the cross-media user identification problem and show that MOBIUS is effective in identifying users across social media sites. This study paves the way for analysis and min-ing across social media sites, and facilitates the creation of novel online services across sites.
 H.2.8 [ Database Management ]: Database Applications X  Data mining User Identification; Cross-Media Analysis; MOBIUS
Verifying ages online is important as it attempts to deter-mine whether someone is  X  X n 11-year-old girl or a 45-year-old man X . Its significance is convincingly pointed out by The New York Times [16], which reported  X  X kout, a mobile social networking app, discovered that, within two weeks, three adults had masqueraded as 13-to 17-year olds. In three separate incidents, they contacted children and, the police say, sexually assaulted them. X  Age verification is also an elusive problem to solve. In 2008, a serious effort was made to evaluate age verification technologies when the In-ternet Safety Technical Task Force was convened with ex-perts from academia and Web companies. The same report mentions that  X  X our years later, members of that task force sound, at best, deflated X  and that  X  X n informal survey of major figures in the Artificial Intelligence industry revealed that little, if any, research is being done on age verification X . The New York Times report suggests that age verification is even more difficult for social media, where people can expect a degree of anonymity.

This paper proposes an alternative solution addressing the age verification problem by exploiting the nature of social media and its networks. Social media can provide rich, di-verse, sometimes spurious, information otherwise not avail-able. It is an easy and conducive platform for people of all walks of life participating, sharing, and interacting with a large number of users anytime and anywhere. Many users likely have multiple accounts at different social media sites to serve their disparate needs. When false information (e.g., incorrect age) is provided, information inconsistencies likely arise across sites, as well depicted in the saying,  X  X  thousand lies are needed to hide one lie X . Detecting these inconsisten-cies can help provide a first line of security toward solving the age verification problem. One way to detect these in-consistencies is to start connecting the different identities of a user across social media sites. For example, if a user has multiple user accounts that are associated with incon-sistent profile information, a further investigation should be warranted to verify the individual X  X  claimed age.

Connecting user identities across social media sites is not a straightforward task. The primary obstacle is that con-nectivity among user identities across different sites is often unavailable. This disconnection happens since most sites maintain the anonymity of users by allowing them to freely select usernames instead of their real identities, and also be-cause different websites employ different user-naming and authentication systems. Moreover, websites rarely link their user accounts with other sites or adopt Single-Sign-On tech-nologies such as openID, where users can logon to differ-ent sites using a single username (e.g., users can login to Google+ and YouTube with their GMail accounts). Re-gardless, there exists a mapping between usernames across different sites that connects the real identities behind them. Can we find this mapping?
In this paper, we introduce a methodology (MOBIUS) for finding the mapping among identities across social me-dia sites. Our methodology is based on behavioral patterns that users exhibit in social media, and has roots in behav-ioral theories in sociology and psychology. Unique behav-iors due to environment, personality, or even human limita-tions can create redundant information across social media sites. Our methodology exploits such redundancies to iden-tify users across social media sites. We use the minimum amount of information available across sites.

Section 2 formally presents the user identification prob-lem across social media sites. Section 3 describes behavioral patterns that users exhibit in social media that can be har-nessed to develop a user identification technique. Section 4 details experiments for identifying corresponding identities, followed by related work in Section 5. Section 6 concludes this research with directions for future work.
Information shared by users on social media sites provides a social fingerprint of them and can help identify users across different sites. We start with the minimum amount of infor-mation that is available on all sites. In terms of information availability, usernames seem to be the minimum common factor available on all social media sites. Usernames are of-ten alphanumeric strings or email addresses, without which users are incapable of joining sites. Usernames are unique on each site and can help identify individuals, whereas most personal information, even  X  X irst name + last name X  com-binations, are non-unique. We formalize our problem by using usernames as the atomic entities available across all sites. Other profile attributes, such as gender, location, in-terests, profile pictures, language, etc., when added to user-names, should help better identify individuals; however, the lack of consistency in the available information across all so-cial media, directs us toward formulating with usernames. When considering usernames, two general problems need to be solved for user identification:
II. Given a single username u from individual I , can we
Question I can be answered in two steps: 1) we find the set of all usernames C that are likely to belong to individual I . We denote set C as candidate usernames and, 2) for all candidate usernames c  X  C , we check if c and u belong to the same individual. Hence, if candidate usernames C are known, question II reduces to question I . Since finding can-didate usernames has been discussed in detail in [19], from now on, we focus on question I . One can answer question I by learning an identification function f ( u,c ),
Without loss of generality, we can assume that username u is known to be owned by some individual I and c is the candidate username whose ownership by I we would like to verify. In other words, u is the prior information (history) provided for I . Our function can be generalized by assuming that our prior is a set 1 of usernames U = { u 1 ,u 2 ,...,u
Mathematically, a set can only contain distinct values; how-ever, here a user may use the same username on more than Figure 1: MOBIUS: Modeling Behavior for Identifying Users across Sites (hereafter referred to as  X  X rior usernames X ). Informally, the usernames of an individual on some sites are given and we have a candidate username on another site whose ownership we need to verify; e.g., usernames u t and u f of someone are given on Twitter and Facebook, respectively; can we verify if c is her username on Flickr? Definition . User Identification across Social Media Sites. Given a set of n usernames (prior usernames) U = { u 1 ,u 2 ,...,u n } , owned by individual I and a candidate username c , a user identification procedure attempts to learn an identification function f ( .,. ) such that Our methodology for MO deling B ehavior for I dentifying U sers across S ites ( MOBIUS ) 2 is outlined in Figure 1. When individuals select usernames, they exhibit certain be-havioral patterns. This often leads to information redun-dancy , helping learn the identification function. In MO-BIUS, these redundancies can be captured in terms of data features. Following the tradition in machine learning and data mining research, we can learn an identification function by employing a supervised learning framework that utilizes these features and prior information ( labeled data ). In our case, the labeled data is sets of usernames with known own-ers. Supervised learning in MOBIUS can be performed via either classification or regression. Depending on the learn-ing framework, one can even learn the probability that an individual owns the candidate username, generalizing our binary f function to a probabilistic model ( f ( U,c ) = p ). This probability can help select the most likely individual who owns the candidate username. The learning compo-nent of MOBIUS is the most straightforward. Therefore, we next elaborate how to analyze behavioral patterns related to user identification and how features can be constructed to capture information redundancies due to these patterns. To summarize, MOBIUS contains 1) behavioral patterns , 2) fea-tures constructed to capture information redundancies due to these patterns, and 3) a learning framework. Due to the interdependent nature of behaviors and feature construction, we discuss them together next. one site. In our definition of username set, it is implied that usernames are distinct when used on different sites, even though they can consist of the same character sequence.
The resemblance to the M  X  obius strip comes from its single-boundary (representing a single individual) and its connect-edness (representing connected identities of the individual across social media).
Individuals often exhibit consistent behavioral patterns while selecting their usernames. These patterns result in in-formation redundancies that help identify individuals across social media sites.

Individuals can avoid such redundancies by selecting user-names on different sites in a way such that they are com-pletely different from their other usernames. In other words, their usernames are so different that given one username, no information can be extracted regarding the others. Theoret-ically, to achieve these independent usernames, one needs to select a username with Maximum Entropy [6]. That is, a long username string, as long as the site allows, with char-acters from those that the system permits, with no redun-dancy -an entirely random string.

Unfortunately, all of these requirements are contrary to human abilities. Humans have difficulty storing long se-quences with short-term memory capacity of 7  X  2 items [18]. Human memory also has limited capability in storing ran-dom content and often, selectively stores content that con-tains familiar items, known as  X  X hunks X  [18]. Finally, human memory thrives on redundancy, and humans can remember material that can be encoded in multiple ways [18]. These limitations result in individuals selecting usernames that are generally not long , not random , and have abundant redun-dancy . These properties can be captured using specific fea-tures which in turn can help learn an identification function. In this study, we find a set of consistent behavioral patterns among individuals while selecting usernames. These behav-ioral patterns can be categorized as follows: 1. Patterns due to Human Limitations 2. Exogenous Factors 3. Endogenous Factors
The features designed to capture information generated by these patterns can be divided into three categories: 1. (Candidate) Username Features : these features 2. Prior-Usernames Features : these features describe 3. Username  X  Prior-Usernames Features : these fea-
We will discuss behaviors in each of the above mentioned categories, and features that can be designed to harness the information hidden in usernames as a result of the pattern X  X  existence. Note that these features may or may not help in learning an identification function. As long as these features could be obtained for learning the identification function, they are added to our feature set. Later on in Section 4, we will analyze the effectiveness of all features, and if it is necessary to find as many features as possible.
In general, as humans, we have 1) limited time and mem-ory and 2) limited knowledge . Both create biases that can affect our username selection behavior. Selecting the Same Username . As studied recently [19], 59% of individuals prefer to use the same username(s) re-peatedly, mostly for ease of remembering. Therefore, when a candidate username c is among prior usernames U , that is a strong indication that it may be owned by the same individual who also owns the prior usernames. As a result, we consider the number of times candidate username c is repeated in prior usernames as a feature.
 Username Length Likelihood . Similarly, users commonly have a limited set of potential usernames from which they select one, once asked to create a new username. These usernames have different lengths and, as a result, a length distribution L . Let l c be the candidate username length and l be the length for username u  X  U (prior usernames). We believe that for any new username, it is more likely to have, for example, if an individual is inclined to select usernames of length 8 or 9, it is unlikely for the individual to consider creating usernames with lengths longer or shorter than that. Therefore, we consider the candidate username X  X  length l and the length distribution L for prior usernames as fea-tures. The length distribution can be compactly represented by a fixed number of features. We describe distribution L , observed via discrete values { l u } u  X  U as a 5-tuple feature, where E is the mean,  X  is the standard deviation, and med is the median of the values { l u } u  X  U , respectively. Note that this procedure for compressing distributions as a fixed num-ber of features can be employed for discrete distributions D , observed via discrete values { d i } n i =1 .
 Unique Username Creation Likelihood . Users often prefer not to create new usernames. One might be inter-ested in the effort users are willing to put into creating new usernames. This can be approximated by the number of unique usernames ( uniq ( U )) among prior usernames U ,
Uniqueness is a feature in our feature set. One can think of 1 /uniqueness as an individual X  X  username capacity , i.e., the average number of times an individual employs a username on different sites before deciding to create a new one. Limited Vocabulary. Our vocabulary is limited in any language. It is highly likely for native speakers of a lan-guage to know more words in that language than individuals speaking it as a second language. We assume the individ-ual X  X  vocabulary size in a language is a feature for identifying them, and, as a result, we consider the number of dictionary words that are substrings of the username as a feature. Sim-ilar to username length feature, the number of dictionary words in the candidate username is a scalar; however, when counting dictionary words in prior usernames, the outcome is a distribution of numbers. We employ the technique out-lined in Eq. (4) for compressing distributions to represent this distribution as features. Limited Alphabet. Unfortunately, it is a tedious task to consider dictionary words in all languages, and this feature can be used for a handful of languages. However, we ob-serve that the alphabet letters used in the usernames are highly dependent on language. For instance, while the let-ter x is common when a Chinese speaker selects a username, it is rarely used by an Arabic speaker, since no Arabic word transcribed in English contains the letter x . Thus, we con-sider the number of alphabet letters used as a feature, both for the candidate username as well as prior usernames.
Exogenous factors are behaviors observed due to cultural influences or the environment that the user is living in. Typing Patterns. One can think of keyboards as a gen-eral constraint imposed by the environment. It has been shown [9] that the layout of the keyboard significantly im-pacts how random usernames are selected; e.g., qwer1234 and aoeusnth are two well-known passwords commonly se-lected by QWERTY and DVORAK users, respectively. Most people use one of two well-known keyboards DVORAK and QWERTY (or slight variants such as QWERTZ or AZERTY) [17]. To capture keyboard-related regularities, we construct the following 15 features for each keyboard layout (a total of 30 for both): 1. (1 feature) The percentage of keys typed using the 2. (1 feature) Percentage of keys typed using the same 3. (8 features) The percentage of keys typed using each 4. (4 features) The percentage of keys pressed on rows: 5. (1 feature) The approximate distance (in meters) trav-
We construct these features for candidate username and each prior username. Thus, for all prior usernames, each feature has a set of values. Adopting the technique outlined in Eq. (4) for compressing distributions as features, we con-struct 15  X  5 = 75 additional features for prior usernames. Language Patterns. In addition to environmental fac-tors, cultural priors such as language also affect the user-name selection procedure. Users often use the same or the same set of languages when selecting usernames. There-fore, when detecting languages of different usernames be-longing to the same individual, one expects fairly consis-tent results. We consider the language of the username as a feature in our dataset. To detect the language, we trained an n -gram statistical language detector [10] over the European Parliament Proceedings Parallel Corpus 3 which consists of text in 21 European languages ( Bulgarian, Czech, Danish, German, Greek, English, Spanish, Estonian, Finnish, French, Hungarian, Italian, Lithuanian, Latvian, Dutch, Polish, Portuguese, Romanian, Slovak, Slovene, and Swedish ) from 1996-2006 with more than 40 million words per language. The trained model detects the candidate user-name language, which is a feature in our feature set. The http://www.statmt.org/europarl/ language detector is also used on prior usernames, providing us with a language distribution for prior usernames, which again is compressed as features using Eq. (4). The detected language feature is limited to European languages. Our lan-guage detector will not detect other languages. The lan-guage detector is also challenged when dealing with words that may not follow the statistical patterns of a language, such as location names, etc. However, these issues can be tackled from a different angle, as we discuss next.
Endogenous factors play a major role when individuals se-lect usernames. Some of these factors are due to 1) personal attributes (name, age, gender, roles and positions, etc.) and 2) characteristics, e.g., a female selecting username fun-girl09 , a father selecting geekdad , or a PlayStation 3 fan selecting PS3lover2009 . Others are due to 3) habits, such as abbreviating usernames or adding prefixes/suffixes. Personal Information. As mentioned, our language de-tection model is incapable of detecting several languages, as well as specific names, such as locations, or others that are of specific interest to the individual selecting the username. For instance, the language detection model is incapable of detecting the language of usernames Kalambo , a waterfall in Zambia, or K2 and Rakaposhi , both mountains in Pakistan. However, the patterns in these words can be captured by analyzing the alphabet distribution. For instance, a user selecting username Kalambo most of the time will create an alphabet distribution where letter  X  a  X  is repeated twice more than other letters. Hence, we save the alphabet distribution of both candidate username and prior usernames as features. This will easily capture patterns like an excessive use of  X  i  X  in languages such as Arabic or Tajik [7, 11], where language detection fails. Another benefit of using alphabet distribu-tion is that not only is it language-independent, but it can also capture words that are meaningful only to the user. Username Randomness. As mentioned before, individ-uals who select totally random usernames generate no in-formation redundancy. One can quantify the randomness of usernames of an individual and consider that as a fea-ture that can describe individuals X  level of privacy and help identify them. For measuring randomness, we consider the entropy [6] of the candidate username X  X  alphabet distribu-tion as a feature. We also measure entropy for each prior username. This results in an entropy distribution that is en-coded as features using aforementioned technique in Eq. (4).  X  X ld habits, die hard X , and these habits have a significant effect on how usernames are created. Common habits are, Username Modification . Individuals often select new usernames by changing their previous usernames. Some, 1. add prefixes or suffixes, 2. abbreviate their usernames, 3. change characters or add characters in between.
Any combination of these operations is also possible. The following approaches are taken to capture the modifications: Generating Similar Usernames. Users tend to gener-ate similar usernames. The similarity between usernames is sometimes hard to capture using approaches discussed for detecting username modification. For instance, gateman and nametag are highly similar due to one being the other spelled backward, but their similarity is not recognized by discussed methods. Since we store the alphabet distribution for both the candidate username and prior usernames, we can compare these using different similarity measures. The Kullback-Liebler divergence (KL) [6] is commonly the mea-sure of choice; however, since KL isn X  X  a metric, comparison among values becomes difficult. To compare distributions, we use the Jensen-Shannon divergence (JS) [13], which is a metric computed from KL, where M = 1 2 ( P + Q ), and KL divergence is Here, P and Q are the alphabet distributions for the candi-date username and prior usernames. As an alternative, we also consider cosine similarity between the two distributions as a feature. Note that Jensen-Shannon divergence does not measure the overlap between the alphabets. To compute alphabet overlaps, we add Jaccard Distance as a feature. Username Observation Likelihood. Finally, we believe the order in which users juxtapose letters to create user-names depends on their prior knowledge. Given this prior knowledge, we can estimate the probability of observing can-didate username. Prior knowledge can be gleaned based on how letters come after one another in prior usernames. In statistical language modeling, the probability of observing username u , denoted in characters as u = c 1 c 2 ...c n , is Figure 2: Individual Behavioral Patterns when Selecting Usernames We approximate this probability using an n -gram model, Commonly, to denote the beginning and the end of a word, special symbols are added: ? and  X  . So, for username jon , the probability approximated using a 2-gram model is
To estimate the observation probability of the candidate username using an n -gram model, we first need to compute the probability of observing its comprising n -grams. The probability of observing these n -grams can be computed using prior usernames. These probabilities are often hard to estimate, since some letters never occur after others in prior usernames while appearing in the candidate username. For instance, for candidate username test12 and prior user-names { test, testing } , the probability of p ( 1 | ? test ) = 0 and therefore p ( test12 ) = 0, which seems unreasonable. To estimate probabilities of unobserved n -grams, a smoothing technique can be used. We use the state-of-the-art Modi-fied Kneser-Ney (MKN) smoothing technique [4], which has discount parameters for n -grams observed once, twice, and three times or more. The discounted values are then dis-tributed among unobserved n -grams. The model has demon-strated excellent performance in various domains [4]. We include the candidate username observation probability, es-timated by an MKN-smoothed 6-gram model, as a feature.
We have demonstrated how behavioral patterns can be translated into meaningful features for the task of user iden-tification. These features are constructed to mine informa-tion hidden in usernames due to individual behaviors when creating usernames. Overall, we construct 414 features for the candidate username and prior usernames. Figure 2 de-picts a summary of these behavioral patterns observed in individuals when selecting usernames.

Clearly, our features do not cover all aspects of username creation, and with more theories and behaviors in place, more features can be constructed. We will empirically study if it is necessary to use all features and the effect of adding more features on learning performance of user identification.
Following MOBIUS methodology, we compute the feature values over labeled data, and verify the effectiveness of MO-BIUS by learning an identification function. Next, experi-ments for evaluating MOBIUS are detailed.
The MOBIUS methodology is systematically evaluated in this section. First, we verify if MOBIUS can learn an accu-rate identification function, comparing with some baselines. Second, we examine if different learning algorithms make a significant difference in learning performance using acquired features. Then, we perform feature importance analysis, and investigate how the number of usernames and the number of features impact learning performance. Before we present our experiments, we detail how experimental data is collected.
A simple method for gathering identities across social net-works is to conduct surveys and ask users to provide their usernames across social networks. This method can be ex-pensive in terms of resource consumption, and the amount of gathered data is often limited. Companies such as Yahoo! or Facebook ask users to provide this kind of information; however, this information is not publicly available.
Another method for identifying usernames across sites is by finding users manually. Users, more often than not, pro-vide personal information such as their real names, E-mail addresses, location, gender, profile photos, and age on these websites. This information can be employed to map users on different sites to the same individual. However, manually finding users on sites can be quite challenging.

Fortunately, there exist websites where users have the op-portunity of listing their identities (user accounts) on dif-ferent sites. This can be thought of as labeled data for our learning task, providing a mapping between identities. In particular, we find social networking sites, blogging and blog advertisement portals, and forums to be valuable sources for collecting multiple identities of the same user.
 Social Networking Sites. On most social networking sites such as Google+ or Facebook, users can list their IDs on other sites. This provides usernames of the same individual on different sites.
 Blogging and Blog Advertisement Portals : To adver-tise their blogs, individuals often join blog cataloging sites to list not only blogs, but also their profiles on other sites. For instance, users in BlogCatalog are provided with a feature called  X  X y Communities X . This feature allows users to list their usernames in other social media sites.
 Forums: Many forums use generic Content Management Systems (CMS), designed specifically for creating forums. These applications usually allow users to add their user-names on social media sites to their profiles. Examples of these applications that contain this feature include, but are not limited to: vBulletin, phpBB, and Phorum.

We utilize these sources for collecting usernames, guar-anteed to belong to the same individual. Overall, 100,179 ( c -U ) pairs are collected, where c is a username and U is the set of prior usernames. Both c and U belong to the same individual. The dataset contains usernames from 32 sites, such as Flickr, Reddit, StumbleUpon, and YouTube.

The collected pairs are considered as positive instances in our dataset. For negative instances, we construct instances by randomly creating pairs ( c i -U j ), such that c i is from one positive instance and U j is from a different positive instance ( i 6 = j ) to guarantee that they are not from the same individ-ual. We generated different numbers of negative instances (up to 1 million instances), but its effect on the accuracy of learning the identification function was negligible, so we continue with a dataset where the class balance is 50% for each label (100,179 positive + 100,179 negative  X  200,000 in-stances). Then, we compute our 414 feature values for this data and employ this dataset for our learning framework.
To evaluate MOBIUS, the first step is to verify if it can learn an accurate identification function. Given our labeled dataset where all feature values are calculated, learning the identification function can be realized by performing super-vised learning on our dataset. We mentioned earlier that a probabilistic classifier can generalize our binary identifi-cation function to a probabilistic one, where the probabil-ity of a candidate username belonging to an individual is measured. Probabilistic classification can be achieved by a variety of Bayesian approaches. We select Naive Bayes. Naive Bayes, using 10-fold cross validation, correctly classi-fies 91.38% of our data instances.

There is a need to compare MOBIUS performance to other methods as well. To the best of our knowledge, methods from Zafarani et al. [19] and Perito et al. [15] are the only methods that tackle the same problem. The ad hoc method of Zafarani et al. employs two features: 1) exact match between usernames and 2) substring match between user-names. Perito et al. X  X  method uses a single feature. This fea-ture, similar to our username-observation likelihood, utilizes a 1-gram model to compute the username observation prob-ability. Table 1 reports the performance of these techniques over our datasets. Our method outperforms the method of Zafarani et al. by 38% and the method of Perito et al. by 18%. The key difference between MOBIUS and the methods in comparison is that MOBIUS takes a behavioral modeling approach that systematically generates features for effective user identification.

To evaluate the effectiveness of MOBIUS, we also devise three baseline methods for comparison. When people are asked to match usernames of individuals, commonly used methods are  X  X xact username matching X ,  X  X ubstring match-ing X , or finding  X  X atterns in letters X . Hence, they form our three baselines, b 1 , b 2 , and b 3 : b : Exact Username Match. It considers an instance positive if the candidate username is an exact match to  X  % of the prior usernames. To set  X  accurately, we computed the percentage of prior usernames that are exact matches to the candidate username in each of our positive instances and averaged it over all positive instances to get  X  ,  X   X  54%. To further analyze the impact, we set 50%  X   X   X  100%. Among all  X  values, b 1 does not perform better than 77%. b : Substring Matching. It considers an instance positive if the mean of the candidate username X  X  normalized longest common substring distance to prior usernames is below some threshold  X  . We conduct the experiment for the range 0  X   X   X  1. In the best case, b 2 achieves 63 . 12% accuracy. b : Patterns in Letters. For finding letter patterns, b 3 uses the alphabet distribution for the candidate username and the prior usernames as features. Using our data labels, we perform logistic regression. b 3 achieves 49 . 25% accuracy.
Our proposed technique outperforms baseline b 1 , b 2 , and b by 19%, 45%, and 86%, respectively. The performance for Naive Bayes, other methods, and baselines are summarized Table 2: MOBIUS Performance for Different Classification Techniques Technique AUC Accuracy J48 Decision Tree Learning 0.894 90.87% Naive Bayes 0.937 91.38%
Random Forest 0.957 93.59% ` 2 -Regularized ` 2 -Loss SVM 0.950 93.70% ` 1 -Regularized ` 2 -Loss SVM 0.951 93.71% ` 2 -Regularized Logistic Regression 0.950 93.77% ` 1 -Regularized Logistic Regression 0.951 93.80 % in Table 1. Now, we would like to see if different learning algorithms can further improve the learning performance.
To evaluate the choice of learning algorithm, we perform the classification task using a range of learning techniques and 10-fold cross validation. The AUCs and accuracy rates are available in Table 2. These techniques have different learning biases, and one expects to observe different perfor-mances for the same task. As seen in the table, results are not significantly different among these methods. This shows that when sufficient information is available in features, the user identification task becomes reasonably accurate and is not sensitive to the choice of learning algorithm. In our ex-periments, ` 1 -Regularized Logistic Regression is shown to be the most accurate method; hence, we use it in the follow-ing experiments as the method of choice. The classification employs all 414 features. Designing 414 features and com-puting their values is computationally expensive. Therefore, we try to empirically determine 1) whether all features are necessary, and 2) whether it makes economic sense to add more features, in Sections 4.4 and 4.5.
Feature Importance Analysis analyzes how important dif-ferent features are in learning the identification function. In other words, it finds features that contribute the most to the classification task. This can be performed by stan-dard feature selection measures such as Information Gain,  X  , among others. We utilize odds-ratios (logistic regression coefficients) for feature importance analysis and ranking fea-tures. The top 10 important features are as follows: 1. Standard deviation of normalized edit distance between 2. Standard deviation of normalized longest common sub-3. Username observation likelihood, 4. Uniqueness of prior usernames, 5. Exact match: number of times candidate username is Figure 3: User Identification Performance for Users with Different Number of Usernames 6. Jaccard similarity between the alphabet distribution 7. Standard deviation of the distance traveled when typ-8. Distance traveled when typing the candidate username 9. Standard deviation of the longest common substring 10. Median of the longest common subsequence between
In fact, a classification using only these 10 features and logistic regression provides an accuracy of 92.72%, which is very close to that of using the entire feature set. We also notice that in our ranked features,
Although these 10 features perform reasonably well, it is of practical importance to analyze how we can further improve the performance of our methodology in different scenarios, such as by adding usernames or features.
It is often assumed that when more prior usernames of an individual are known, the task of identifying the individual becomes easier. If true, to improve identification perfor-mance, we need to provide MOBIUS with extra prior infor-mation (known usernames). In our dataset, users have from 1 to a maximum of 30 prior usernames. To verify helpfulness of adding prior usernames, we partition the dataset into 30 datasets { d i } 30 i =1 , where dataset d i contains individuals that have i prior usernames. The user identification accuracy on these 30 datasets are shown in Figure 3. We observe a mono-tonically increasing trend in identification performance, and even for a single prior username, the identification is 90.72% accurate and approaches 100% when 25 or more usernames are available. Note that the identification task is hardest when only a single prior username is available.

Rarely are 25 prior usernames of an individual available across sites. It is more practical to know the minimum number of usernames required for user identification such that further improvements are nominal. The relative per-formance improvement with respect to number of usernames Figure 4: Relative User Identification Performance Improvement with respect to Number of Usernames Figure 5: Relative Change in Number of Features Required with respect to Number of Usernames can help us measure this minimum. Figure 4 shows this im-provement for adding usernames. We observe a diminishing return property, where the improvement becomes marginal as we add usernames and is negligible for more than 7 user-names. A power function ( g ( x ) = 2 . 44 x  X  1 . 79 ), found with 95% confidence, fits to this curve with adjusted R 2 = 0 . 976. The exponent -1.79 denotes that the relative improvement by adding n usernames is  X  1 /n 1 . 79 times smaller than that by adding a single username, e.g., for 7 usernames, relative identification performance improvement is  X  1 / 33 times smaller than that of a single username.

Similar to adding more prior usernames, one can change number of features. More practically, we would like to ana-lyze how adding features correlates with adding prior user-names. For instance, if we double the number of prior user-names, how many features should we construct (or can be removed) to guarantee reaching a required performance?
To measure this, for each number of prior usernames n , we compute the average number of features such that MOBIUS can achieve fixed accuracy  X  . We set  X  to the minimum accuracy achievable, independent of number of usernames (90% here). We then compute the relative change in the number of required features when usernames are added.
Figure 5 plots this relationship. We observe the same di-minishing return property, and as one adds more usernames, fewer features are required to achieve a fixed accuracy. A power function ( g ( x ) = 0 . 1359 x  X  0 . 875 ), found with 95% con-fidence, fits to this curve with adjusted R 2 = 0 . 987. The ex-ponent -0.875 denotes that the number of features required for n usernames is  X  1 /n 0 . 875 times smaller than that of a single username.

Finally, if one is left with a set of usernames and a set of features, should we aim at adding more usernames or con-struct better features? Let f ( n,k ) denote the performance Figure 6: The  X  ( n,k ) function, for n usernames and k features. Values larger than 1 show that adding usernames will improve performance more and val-ues smaller than 1 show adding features is better. of our method for n usernames and k features. Let
The  X  function is a finite difference approximation for the derivative ratio with respect to n and k . When  X  ( n,k ) &gt; 1, adding usernames improves performance more and when  X  ( n,k ) &lt; 1, adding features is better. To compute f ( n,k ), for different values of n , we select random subsets of size k . We denote the average performance over these random subsets as f ( n,k ). Figure 6 plots the  X  ( n,k ) function. We plot plane z = 1 to better show where adding features is more helpful and where usernames are more beneficial. We observe that for small values of n and k , i.e., when fewer usernames and features are available, features help best, but for all other cases adding usernames is more beneficial.
In this section, we focus on summarizing research related to identifying individuals in social media. We provided a review of directly relevant techniques to our study in Section 4. In addition to those methods, there exists related research about 1) identifying content produced by an individual on the web or 2) identifying individuals in a single social network . Identifying Content Authorship. In [1], the authors look at the content generation behavior of the same indi-viduals in several collections of documents. Based on the overlap between contributions, they propose a method for detecting pages created by the same individual across dif-ferent collections of documents. They use a method called detection by compression, where Normalized Compression Distance (NCD) [5] is used to compare the similarity be-tween the documents already known to be authored by the individual and other documents. Author detection has been well discussed in restricted domains. In particular, machine learning techniques have been employed to detect authors in online messages [20] and in E-mails [8]. Although, one can think of usernames as the content generated by individ-uals across sites; however, in content authorship detection, it is common to assume large collections of documents, with thousands of words, available for each user, whereas for user-names, the information available is limited to one word. User Identification on One Site. Deanonymization is an avenue of research related to identifying individuals on a single site. Social networks are commonly represented using graphs where nodes are the users and edges are the con-nections. To preserve privacy, an anonymization process replaces these users with meaningless, randomly generated, unique IDs. To identify these masked users, a deanonymiza-tion technique is performed. Deanonymization of social net-works is tightly coupled with the research in privacy preserv-ing data mining or Identity Theft attacks [3]. In [2], Back-strom et al. present such process where one can identify in-dividuals in these anonymized networks by either manipulat-ing networks before they are anonymized or by having prior knowledge about certain anonymized nodes. Narayanan and Shmatikov in [14] present statistical deanonymization tech-nique against high-dimensional data. They argue that given little information about an individual one can easily identify the individual X  X  record in the dataset. They demonstrate the performance of their method by uncovering some users on the Netflix prize dataset using IMDB information as their source for background knowledge. Our work differs from these techniques, as it deals with multiple sites. Moreover, it avoids using link information, which is not always avail-able on different social media sites.
In this paper, we have demonstrated a methodology for connecting individuals across social media sites (MOBIUS). MOBIUS takes a behavioral modeling approach for system-atic feature construction and assessment, which allows in-tegration of additional features when required. MOBIUS employs minimal information available on all social media sites (usernames) to derive a large number of features that can be used by supervised learning to effectively connect users across sites. Users often exhibit certain behavioral patterns when selecting usernames. The proposed behav-ioral modeling approach exploits information redundancy due to these behavioral patterns. We categorize these be-havioral patterns into (1) human limitations, (2) exogenous factors, and (3) endogenous factors. In each category of behaviors, various features are constructed to capture in-formation redundancy. MOBIUS employs supervised learn-ing to connect users. Our empirical results show the ad-vantages of this principled, behavioral modeling approach over earlier methods. The experiments demonstrate that (1) constructed features contain sufficient information for user identification; (2) importance or relevance of features can be assessed, thus features can be selected based on particular application needs; and (3) adding more features can further improve learning performance but with diminishing returns; hence, facing a limited budget, one can make informed de-cisions on what additional features should be added.
MOBIUS can help solve the problem of age verification in a collective effort of protecting youth on the web against predators. For example, profiles of individuals across sites can be connected and inconsistencies on reported age can be checked. Detecting these inconsistencies can help provide a first line of security toward solving the age verification prob-lem. Identifying users across social media sites opens the door to many interesting applications. Studying user be-haviors across social media such as user migration [12] is an example of the many areas that can benefit from the results of this study. Future work includes analyzing these possi-bilities and discovering features indigenous to specific sites, beyond those constricted to usernames, and incorporating them into MOBIUS for future needs.
 This work was supported, in part, by the Office of Naval Research grant: N000141110527. [1] E. Amitay, S. Yogev, and E. Yom-Tov. Serial Sharers: [2] L. Backstrom, C. Dwork, and J. Kleinberg. Wherefore [3] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda. All [4] S.F. Chen and J. Goodman. An Empirical Study of [5] R. Cilibrasi and P.M.B. Vit  X anyi. Clustering by [6] T.M. Cover and J.A. Thomas. Elements of [7] D. Cowan. An Introduction to Modern Literary Arabic , [8] O. De Vel, A. Anderson, M. Corney, and G. Mohay. [9] C. Doctorow. Preliminary Analysis of LinkedIn User [10] T. Dunning. Statistical Identification of Language . CR [11] C.A. Ferguson. Word Stress in Persian. Language , [12] S. Kumar, R. Zafarani, and H. Liu. Understanding [13] J. Lin. Divergence Measures based on the Shannon [14] A. Narayanan and V. Shmatikov. Robust [15] Daniele Perito, Claude Castelluccia, Mohamed Kaafar, [16] N. Perlroth. Verifying Ages Online is a Daunting Task, [17] Wikipedia. Keyboard Layouts. http://bit.ly/kXso . [18] J. Yan, A. Blackwell, R. Anderson, and A. Grant. The [19] R. Zafarani and H. Liu. Connecting Corresponding [20] R. Zheng, J. Li, H. Chen, and Z. Huang. A Framework
