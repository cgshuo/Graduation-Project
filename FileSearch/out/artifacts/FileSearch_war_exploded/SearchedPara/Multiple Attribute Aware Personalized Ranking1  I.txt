 Due to the dramatically increasing content in the Web, users are now suffering from the information overload. To cope with such heavy burden, recommender systems, which embed personalized rank ing techniques, have attracted a signif-icant attention from both academic and industrial communities. For example, Taobao and Amazon use personalized ra nking techniques to improve their rec-ommender systems in order to attract customers for more purchasing.

Among a variety of recommendation methods, the collaborative factorization is one of the most successful approaches, which learns low dimensional latent rep-resentations for both users and items. Most of work [1,2,3] in this field is based on explicit ratings. However, explicit ratings are generated by users actively in-teracting with the systems, and are hard to be obtained in practice. For instance, users are encouraged to provide ratings for the movies on the site of MovieLens, and then the recommender system provides recommendation services based on these explicit ratings. In many scenarios, the systems can only obtain implicit interactions between users and items, e.g., whether a user viewed a web page or whether a customer purchased an item. These binary signals are called as implicit feedbacks. Recently, some factor ization methods [4,5,6] are proposed to exploit the implicit feedbacks for personalized ranking. Typical examples, such as Bayesian Personalized Ranking (BPR) [7] and its extensions [8,5,1], are pop-ular for personalized ranking by assuming that users are interested in items they had selected than the remaining items.
 The above factorization methods ind eed promote persona lized ranking a lot. However, they are easily suffering from the cold start problem because of lack-ing enough collaborative in formation for entities. Recently, with the increasing of social media, apart from collaborative information, there is much attribute in-formation associated with entities, such a s the profiles, posts of users, and the de-scription of items. By utilizing such information, researchers have proposed some methods [8,9] to deal with the lack of enough collaborative information. These methods usually treat the attribute information as complete supplementary to collaborative information. However, in real-word applications, the attribute in-formation is usually noisy, incomplete and having multiple types. How to cope with these issues is still a challenge in personalized ranking. Besides, since the implicit feedbacks are widespread and easy to be collected, how to systemati-cally combine vast multiple types of attributes and sparse implicit feedbacks to achieve better recommendation performance is still a thorny problem.
In this paper, for enhancing the performance of personalized ranking, we pro-pose a novel model, which can fuse multiple attribute, and jointly learn latent vectors for entities as well as effective ma ppings for multiple attribute. Different from the traditional attribute-aware factorization models [10,8], which usually assume that the attribute information of entities is complete and only has single type, our proposed model is robust to the incomplete attributes and multiple at-tribute. Moreover, we present an advanced parameter learning algorithm, which is different from the traditional methods that segment the processes of learn-ing latent vectors and learning attribute mappings into two independent parts. Through a unified parameter learning framework of systematically combining multiple attribute and implicit feedbacks, our parameter learning algorithm can learn more reliable latent vectors for entities as well as obtain the mappings from the multiple attribute spaces to the latent feature space.

In a nutshell, our contributions in this paper are listed as follows: 1. To systematically combine collaborative information and attribute infor-mation for personalized ranking, we propose a multiple-attribute-aware method, Maa-BPR, which can learn more reliable latent vectors for entities and obtain the attribute-aware mappings. 2. For fusing multiple attribute, we bring structured regularizers into our model, and provide a reasonable solution for jointly learning parameters. 3. For investigating the performance of our method, we conduct a series of ex-periments, and the results show that our method can combine multiple attribute and implicit feedbacks for improving personalized ranking. In this section, we discuss related work in two branches, i.e., collaborative meth-ods and attribute-aware methods.

Collaborative methods [4,7,11] are usually based on a mass of users interac-tions with items, which are called as collaborative information. These methods attempt to factorize collaborative information, and map users and items into a shared latent space. Matrix factorization (MF) [12] is a classical factorization method to be used for dealing with explicit ratings. There are various extensions of MF for personalized ranking. For instance, for dealing with implicit feedbacks, implicit MF (iMF) [4] extends the basic MF by introducing adaptive confidence weights for each user-item pair. Although MF methods, e.g., iMF, can be ex-tended to deal with implicit feedbacks, the phenomenon of data skew commonly exists in the datasets of implicit feedbacks (the number of positive samples is usually less than one percent of the total number), which causes the MF based methods to easily suffer from the over-fi tting problem. Recently, Rendle et. pro-pose a framework for personalized ranking, i.e., Bayesian Personalized Ranking (BPR) [7], which can cope with data skew in implicit feedback datasets. BPR and its extensions [5,1,6] make a pair-wise assumption that users are interested in items they had selected than the remai ning items, which results in a pair-wise ranking object that tries to discriminat e between a small set of selected items and an extremely large set of irrelevant items. Since massive training instances will be derived by the assumption, the learning of parameters is typically based on a stochastic gradient descent (SGD) with uniformly drawn pairs [6].
On the other hand, since the attribute information can indicate many char-acteristics of entities, attribute-aware methods [8,2,13] are also a kind of main-stream approaches in the field of personalized ranking. For example, in Factor-ization Machines (FM) [2], all kinds of attribute information are concatenated into a feature matrix, and then factors a ssociated with attributes are learned by a process of rating regression. However , in real-world applications, the at-tribute information usually is multiple types, noisy and redundant. For fusing multiple attribute, [13] and [14] have been proposed, which utilize techniques of structured sparsity to handle multi-type attributes. Besides, to alleviate the cold start problem, Map-BPR [8] improve BPR framework to learn attribute-aware mappings from both collaborative information and attribute information. Note that, unlike Map-BPR that only treats the attributes as complete informa-tion with a single type, our work takes multiple, noisy and redundant attributes into account. Moreover, due to the limitation of parameter learning, the latent vectors of observed entities learned by Map-BPR only encode the collaborative information of entities, while our learning algorithm can learn the latent vectors of combining collaborative information and attribute information for entities. In real applications, recommender systems mainly obtain two kinds of informa-tion, i.e., collaborative information and attribute information. The information linked to a user-item pair is called as collaborative information, e.g., explicit ratings and implicit feedbacks. The information pertaining to one entity is the attribute information, e.g., profile and posts of a user, or genre, cast and de-scription of movies, etc.

In this section, we explore these two kinds of information, and propose a new model to incorporate the collaborative information and the attribute information into a unified personalized ranking framework. Before diving into the details, we first present our model from a sketched view. Then, we will introduce how to model the implicit feedbacks and the multiple attribute respectively. Finally, we formally propose our model and give the algorithm of parameter learning. 3.1 The Sketch of Model In traditional factorization models [4,7,11], every entity is represented by a latent vector, which can be learned if the entit y occurs in the (collaborative) training set. However, when the models are suffering from an entity associated with few collaborative data, the latent vector of the entity could not be well learned. Furthermore, new entities without any collaborative information could be added into the real systems at any time. To employ factorization models for the entities of lacking collaborative information, a common method is to learn the attribute mappings from the attribute space to the latent feature space, and then estimate the latent vectors for these entities of lacking collaborative information by their existing attribute information.

Figure 1 illustrates the sketch of our factorization model. Our model is driven by three kinds of data: the collaborative training data (left), the latent factors of entities (middle) and the attributes of entities (right). The rectangles in the mid-dle part represent the factor matrices, where the entities of lacking collaborative data have no latent factors. These unknown latent factors will be estimated using the corresponding attribute mappings. Thus, taking the attribute information into account, the training of our model consists of the following alternant learning steps: learning the latent vectors of entities from the collaborative information and the attribute information; then, learning the attribute-aware mappings from the latent vectors of observed e ntities and their attributes. 3.2 Learning Latent Factors From Implicit Feedbacks BPR [7] is a popular personalized ranking framework for dealing with the implicit feedbacks. In the BPR framework, if the user u m has selected the item v i but not selected the item v j , then the work of BPR assumes that, u m prefers v i over v , and defines the pairwise preference of of u m as any kind of scoring functions which indicate the relevance between two entities.
Because this work mainly focuses on studying the implicit feedbacks, we sim-ply follow the pair-wise assumption of BPR [7] to create training data D S := { ( m, i, j ) | v i  X  I + u denotes the set of the observed items which are linked to the user u m ,andthe triple t =( m, i, j )in D S represents the user u m is relevant to the item v i but v j is a negative item of u m . It should be noted that the training triples can be easily created from any datasets with explicit ratings. For example, if the user u m has given a higher score to the item v i than the item v j ,thenwecantreat v as the positive item of u m and v j as the negative one.

After obtaining the training triples, the goal of BPR is to maximize the like-lihood of all pair-wise preference: which is equivalent to minimize the negative log likelihood: where  X  is the latent feature vectors of entities and  X  is a hyper-parameter. 3.3 Learning Attribute-Aware Mappings In the above sections, we have illustrated how to learn the latent factors of entities only considering implicit fee dbacks. However, in the real recommender systems, entities are not always having enough collaborative information, e.g., new entities will be added into the systems at any time. Therefore, apart from the collaborative information, we also need to take the attribute information of entities into account for learning latent vectors of entities. For the sake of simply bridging the attribute space and the latent space, as shown in Figure 2, we concatenate the multiple attribute of an entity into an attribute vector, and then leverage a linear mapping to map the attribute vector to be a latent vector. Thus, our task is in turn to learn the linear mappings for attribute information.
Here, we formally present an unsupervised solution for learning the linear mappings. In this work, we consider the classical scenario of recommendation, which has two types of entities, i.e., users (e.g., customers) and items (e.g., movies, books and songs). We use u and v to denote a user and an item, re-spectively. For simplicity, we use e to denote an abstract entity, which can be a user or an item. y ( e ) i denotes the latent vector of the entity e i and the matrix Y y m denotes the latent vector of user u m and Y ( u ) denotes the latent matrix of attribute of entities. a ( e ) i  X  R d is an attribute vector concatenating k types of attributes, where d is the total number of attributes of an entity, each type j has d j attributes, and d = learn the attribute-aware mappings from the attributes of k types: trix, and c is the dimension of latent vectors. w q p indicates the weights of all attributes in the q -th type with respect to the p -th latent factor.
However, the optimization problem expressed by Eq. (4) has infinite solu-tions because of lacking supervised information. Fortunately, using the BPR substitute it into Eq. (4). With the pseudo labels, we can solve the optimization problem, and jointly learn the mapping matrix W ( e ) from both the collaborative information and the attribute information.
However, the attributes of entities usually are multiple types, noisy and re-dundant. Taking these issues into considerations, we still need to design a proper scheme to deal with the interrelations among multiple attribute, and select the informative attributes from a mass of attributes.

In multiple attribute fusion, different types of attributes can be more or less discriminative for different factors. F or instance, the description of a movie is usually more associated with the genre of the movie, while the cast of this movie indicates the potential popularity of the movie. To capture the interrelations between multiple attribute and latent factors, we attempt to conduct structured sparsity on mapping matrices. Thus, the group l 1 -norm ( G 1 -norm) [15] is used for Figure 2, the G 1 -norm uses l 2 -norm within each type of attributes and l 1 -norm between types. In this way, the sparsity between different types is enforced [15], i.e., if attributes of one type are not discriminative for the latent factors of a certain group, the elements corresponding to those latent factors in W ( e ) will be assigned with zeros (in practical case, they are usually very small values), otherwise, their weights should be large.

Besides, in certain cases, even if most a ttributes of one type are not discrim-inative for the latent factors of any groups, there are still a small number of attributes in this type to be highly discriminative. Such important attributes should be shared by all latent factors. Thus, the l 2 , 1 -norm [16] is also used for the i -th row of matrix W . Thus, the linear mappings can be learned by where  X  ( e ) is a hyper-parameter for tuning the weight of users or items. 3.4 The Unified Model and Parameter Learning To systematically incorporate collaborative information and attribute informa-tion into a solution, our model for learning latent vectors and attribute-aware mappings can be expressed as
To learn the parameters Y ( u ) , Y ( v ) , W ( u ) and W ( v ) in Eq. (6), we design an alternative optimization algorithm, which uses SGD with uniformly drawn training triples to learn the latent vector s and implements matrix decomposition to learn the mapping matrices.

In each iteration, when we are updating the latent factor matrix Y ( e ) ,weset the mapping matrix W ( e ) to be a constant and L attribute , the entire optimization objective of attribute information, to be a regularizer. Thus, the gradient of an arbitrary latent parameter  X  is Theupdatingruleforparameter  X  is  X  =  X  +  X   X  X   X  X  ,where  X  is the learning rate.
On the other hand, given a latent factor matrix Y ( e ) , we view Y ( e ) as pseudo labels and treat L feedback as a constant. Thus, the optimization objective of Eq. (6) is equal to L attribute = 0 and the updating rule for W ( e ) can be derived as the j -th diagonal block as 1 Note that both D i (1  X  i  X  c )and D are dependent on W ( e ) . Thus, they are also unknown variables but can be approximatively calculated by the value of W ( e ) in last iteration.

In a nutshell, the iterative algorithm for learning parameters of Maa-BPR is summarized in Algorithm 1. The algorithm mainly repeats two learning steps until the parameters reach convergence, i.e., it first learns the latent factors of entities from implicit feedbacks, by SGD with uniformly drawn training triples, then it learns the attribute mapping matrices by given latent factors. In this section, we perform experiments to validate our proposed model by com-paring with other approaches on real world datasets. In the following experi-ments, we first investigate the comprehensive prediction quality by evaluating Area Under the ROC Curve (AUC) and Mean Average Precision (MAP). Then, we study the performance of our method on Top-N recommendation. Finally, we study the cold start problem by simulating the recommendation of new items. 4.1 Datasets For evaluating our method, we use two real world datasets, i.e., DBLP 1 and MovieLens 2 , and carry out training and testing on randomly split training (80%) and testing (20%) data.

DBLP contains 2,084,055 papers with 2,244,018 citations. Each paper may be associated with abstract, authors, published year, and title. We preprocess the DBLP data to be an experimental data set in a similar way as [6]. More Algorithm 1. Learn parameters for Maa-BPR specifically, we sample 1,000 authors who have published no more than 5 papers and cited 5-100 papers from the DBLP data. Thus, we obtain 1,000 authors, 16,313 papers and 23,506 author-paper pairs. Each author-paper pair denotes a relation of the author cited the paper. In the experiments, we treat texts in published papers of an author as the content information of this author, and paper text as content information of the paper. We use the term-frequency over texts as features of content informatio n. Our task is to predict the personalized ranking of citing papers for each author.

MovieLens includes 100,000 ratings by 943 users on 1682 movies. Each user has rated at least 20 movies. In our experiments, the age, gender and occupation of a user are used as the multiple attribute of the user, and the genre of movie and key words in title are viewed as the multiple attribute of an item. Using the same processing method in [17], we do not use the rating values but just binary rating events by assuming that users tend to rate movies they have watched. For a specific user, our task is to predict the potential ranking list of movies.
In addition, comparing these two experimental datasets, we can observe that: 1) the implicit rating matrix of DBLP data set is sparser than that of Movie-Lens; 2) each entity in MovieLens has its corresponding attributes, but entities in DBLP always lack corresponding texts. Thus, in DBLP, many authors and papers have incomplete attribute information. 4.2 Compared Methods Table 1 shows the characteristics of compared methods. Our method, i.e., Maa-BPR is first compared with two basic methods, i.e., BPR-MF [7] and iMF [6], which only consider implicit feedbacks. Then, we investigate two advanced attribute-aware methods, i.e., Map-BPR [8] which extends BPR with attribute mappings and FM [2] which is an attribute-aware framework. In our experi-ments, since the datasets we used existing data skew, i.e., the number of positive feedbacks is far less than the number of negative feedbacks, we train FM and MF with the training data sets which contain randomly drawn negative feedbacks, i.e., the proportions of negative feedbacks and positive feedbacks are 50 : 1 on DBLP and 100 : 1 on MovieLens.
 4.3 Results and Discussion Figure 3 presents the ranking performance of methods evaluated by MAP and AUC. Since the attribute information is noisy and consists of multiple types, the traditional attribute-aware methods, e.g., FM, usually could not get reliable results. On the other hand, due to the lack of enough collaborative informa-tion, the methods only considering implicit feedbacks, e.g., iMF and BPR-MF, also could not get ideal results. Owing much to combining multiple attribute and implicit feedbacks, Maa-BPR consistently outperforms other methods. Fur-thermore, we observe that, although both Map-BPR and Maa-BPR combine attribute information and collaborative information to learn the attribute map-pings, the performance of Maa-BPR on different datasets is more stable than these of Map-BPR. This result demonstrates that, our method is more robust than Map-BPR in terms of incomplete attribute information. This is because that our method fuses multiple attribute, and jointly learns latent vectors from implicit feedbacks and multiple attribute.

Figure 4 shows the precision of different methods with varying numbers of recommendations. Our method achieves the best performance in most cases, es-pecially in recommending a small set of items. Since in real-world scenarios, users only care about several items which are listed on the top places, this experiment of Top-N recommendation in turn show s that our method can well fit recom-mender systems. In addition, with the number of recommendations increasing, the performance of attribute-aware met hods decline more quickly than the meth-ods only taken collaborative information into account. This phenomenon may indicate that the attribute information usually has more noise than collabora-tive information. Thus, it is valued for designing proper schemes to alleviate the noise of attributes, when modeling the attributes of entities.
For investigating the cold start probl em, we assess the performance of new items recommendation in Figure 5. In th e experiments, We only evaluate the user-item pairs which their items are not occurring in the training set. Due to the lack of collaborative information, the traditional methods without consid-ering attribute information can only provide random recommendation results, while most attribute-aware methods have better performance regardless of com-prehensive prediction and Top-N recommendation. Moreover, Maa-BPR obtains the best results among attribute-aware m ethods. Besides, we can observe that FM has poor performance on the exper iment of Top-N recommendation, espe-cially in recommending a small set of items. This result may be because that FM only takes attributes into account, and Top-N recommendation is easily influenced by the noise in attributes. For promoting personalized ranking by fusing multiple attribute, this paper has proposed a novel personalized ranking model, Maa-BPR, which combines multi-ple attribute and interactions between enti ties to learn latent vectors for entities and attribute-aware mappings for multiple attribute. Comprehensive experiments have shown that our model achieves better predictive performance and is robust to both the cold start problem and incomplete attributes. However, the strategy of randomly drawn training triples would cause a slow convergence. In the future, to speed up the parameter learning proces s and further promote the performance of our model, we plan to improve the sampling strategy by taking attribute infor-mation of items and social information of users into account.
 Acknowledgments. This work is jointly supported by National Basic Research Program of China (2012CB316300), and Nati onal Natural Science Foundation of China (61175003, 61202328, 61420106015, U1435221, 61403390).

