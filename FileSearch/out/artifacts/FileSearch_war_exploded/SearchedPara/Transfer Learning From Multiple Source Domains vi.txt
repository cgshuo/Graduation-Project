 Recent years have witnessed an increased interest in trans-fer learning. Despite the vast amount of research performed in this field, there are remaining challenges in applying the knowledge learnt from multiple source domains to a target domain. First, data from multiple source domains can be se-mantically related, but have different distributions. It is not clear how to exploit the distribution differences among mul-tiple source domains to boost the learning performance in a target domain. Second, many real-world applications de-mand this transfer learning to be performed in a distributed manner. To meet these challenges, we propose a consensus regularization framework for transfer learning from multi-ple source domains to a target domain. In this framework, a local classifier is trained by considering both local data available in a source domain and the prediction consensus with the classifiers from other source domains. In addition, the training algorithm can be implemented in a distributed manner, in which all the source-domains are treated as slave nodes and the target domain is used as the master node. To combine the training results from multiple source domains, it only needs share some statistical data rather than the full contents of their labeled data. This can modestly relieve the privacy concerns and avoid the need to upload all data to a central location. Finally, our experimental results show the effectiveness of our consensus regularization learning. I.2.6 [ Learning ]: Induction Algorithms, Experimentation, Performance.
 Classification, Transfer Learning, Consensus Regularization. Copyright 2008 ACM 978-1-59593-991-3/08/10 ... $ 5.00.
Classification plays an important role in many real-world applications, such as Web-page classification and video con-cept detection. Traditional classification techniques have the assumption that training and test data are drawn from the same distribution, and thus fail to deal with the situation when the new unlabeled data are obtained from fast evolv-ing, related but different information sources. This leads to the new learning problem about how to build the classifier when the distributions of training and test data are different.
Previous works in this area deal with the knowledge trans-fer from only one source-domain D s to a target-domain D t 2, 3]. The Source-domain D s owns labeled data, while the target-domain D t contains plenty of unlabeled data. In this paper, we investigate the problem of transfer learning from multiple source-domains to a target domain. More precisely, we have m source-domains as D 1 s ,  X  X  X  , D m a target-domain D t (Note that D 1 s ,  X  X  X  , D m s and D represent their corresponding data sets throughout this pa-per). The labeled source-domains and the unlabeled target-domain may be geographically distributed. We assume that the class labels in D 1 s ,  X  X  X  , D m s and the labels to be pre-dicted in D t are drawn from the same class-label set C .Fur-thermore, while these source-domains and the target-domain have different distributions, we assume that they are seman-tically related to each other in the sense that similar features would describe similar categories. Under this assumption, we aim to adapt the knowledge learnt from these m source-domains for classifying the data in the target domain.
Motivating Examples. We provide the following two application scenarios to motivate the above problem formu-lation. In the first example, assuming we have downloaded all the Web pages of a university, and we want to use text classification to find the course main pages. To do this, we create training data by manually labeling a collection of training course pages from different universities. However, different universities usually use different course page tem-plates, in which the terms used can also be different. For example, the terms indicating the reading materials may in-clude  X  X equired Reading List X ,  X  X extbooks X ,  X  X eference X  and so on. Thus, the data distribution of the main course Web pages from different universities are likely to be differ-ent. If we consider a university as a domain, the manually labeled Web pages come from multiple domains. Now, the goal is to find new course Web pages in a target university. This is a transfer learning problem discussed in this paper.
In the second example, let us consider the problem of video concept detection , which aims to generalize models built for detecting semantic concepts from multiple-source video data to other domains. Here, a domain is a TV chan-nel, such as CCTV, CBS, CNN, and NBC. For instance, the TRECVID collection [4] is such a multi-domain video corpus which has news video from different TV channels. Due to the large data variance and the  X  X emantic gap X  be-tween visual features and the semantic content, the problem of mismatch among the distributions of the multiple train-ing domains and the test domain is particularly severe in multimedia area [5]. As shown in Figure 1, video shots of easily recognizable anchors from four different famous TV channels exhibit dissimilar visual features. As a result, con-cept classifiers trained from only one source-domain might perform poorly on t he target domain.
 Figure 1: Anchor Shots from Major Media including CCTV, CBS, CNN and NBC
The common ground of the above two applications is that the training data are from multiple related but different source domains. One can argue that, if we merge the mul-tiple source-domains into one source-domain, this problem can be solved by existing transfer learning algorithms. How-ever, the important information, such as the distribution dif-ferences among the source-domains, is lost during the merg-ing process. This information is the key to understand the common nature of these source-domains. In addition, the training data from different source-domains might be dis-tributed geographically, and it is difficult to put them into a central location due to the network bandwidth, central disk space, and data copyright considerations. Under this circumstance, the learning algorithm must be performed in a distributed and modest pri vacy-preserving manner. In our formulation, given m source-domains: D 1 s ,  X  X  X  , each of which is drawn from a distribution that might be different from the distribution of the target domain D t ,a classifier h l ( l =1 ,  X  X  X  ,m ) can be trained locally on each of these data sets D l s ,since D 1 s ,  X  X  X  , D m s are fully labeled. However, to classify D t , simply applying one h l may not achieve good performance due to the mismatched distribu-tion. Moreover, any classifier h l trained on the limited data s may suffer from the high variance problem, and give dif-ferent predictions on the data set D t . Since each instance in the target-domain represents a unique piece of ground truth, this disagreement of predictions on the target domain in-spires a direction for optimization. That is, to achieve better prediction performance, one should leverage both the knowl-edge in the labeled data from the multiple source-domains and the unlabeled data in the target-domain.

In this paper we develop a consensus regularization frame-work that aims to transfer the knowledge from multiple source-domains to a target domain. This regularization frame-work is applied into the model of Logistic Regression .Note that it also can be implemented into other classification models. To the end, the following two challenges have been addressed. 1. How to make good use of the distribution differences 2. How to extend this consensus regularization based al-
For the first challenge, we propose the maximum con-sensus regularization method, which incorporates the un-labeled data from the target-domain into the learning pro-cess. For each source-domain, this consensus optimization framework will output one classifier, which is trained by considering both the local data and the prediction consen-sus with the other classifiers on the unlabeled target-domain data. In this mutually-affected manner, the resultant classi-fiers not only maintain the individuality of the corresponding source-domains, but also reveal the common nature of all the source-domains and the target-domain. For the second chal-lenge, when multiple source-domains and the target-domain are distributed geographically, the learning algorithm is run-ning in a distributed manner. This distributed system has a master-slave architecture, with the node for the target-domain being the master and the node for the source do-mains being the slaves. To achieve the same learning per-formance as a corresponding non-distributed algorithm, the training process takes multiple rounds to complete. In each round, only some statistical data (not full contents of labeled data) are shared between the slave nodes and the master node, and they cooperate in a synchronized fashion. There-fore, it is a distributed algorithm, which also addresses a modest degree of privacy concerns.

Finally, in the context of text classification, we validate the proposed method using real-world text data sets. The experimental results show that the consensus regularization learning method can effectively improve the learning perfor-mance in the target domain even if the source-domain data are geographically distributed.
In this section, we first introduce the notations used through-out this paper, and then present some preliminary concepts about logistic regression and consensus measuring.
In this paper, we use bold letters, such as p and a ,to represent vectors. Also, p ( i ) indicates the i -th element of p . Random variables are written in upper case, such as X and Y . Therefore, Bold upper case letters, such as X and Y , represent vectors of random variables. Calligraphic letters, such as A and D , represent sets. Finally, we use to denote the set of real numbers and R + to denote the set of nonnegative real numbers.
Logistic regression [6] is an approach to learning functions of P ( Y | X )inthecasewhere Y is discrete-valued, and X is any vector containing discrete or continuous random vari-ables. Logistic regression assumes a parametric form for the distribution P ( Y | X ), then directly estimates its parameters from the training data. The parametric model assumed by logistic regression in the case where Y is Boolean is where w is the parameter of the model. Under the principle of Maximum A-Posteriori (MAP), w is estimated under the Laplacian prior. Given a data set D = { ( x i ,y i ) } N i to find the parameter w which maximizes: This criterion is a concave function of w , so that the global solution can be obtained by methods of the non-linear nu-merical optimization. After w is estimated, Equation (1) can be used to compute the probabilities of an instance be-longing to the positive and negative class.
In the subsection, we first give the definition of Shannon entropy in a probability distribution vector ,andthenshow how to measure the degree of consensus on the predictions that are made by a group of classifiers for an instance.
Definition 1 (Probability Distribution Vector). p  X  R d + is a probability distribution vector if and only if P probability that this instance belongs to class i .
Definition 2 (Shannon Entropy). Assuming p  X  R d + is a probability distribution vector, then the Shannon entropy in p is defined as Given a group of m classifiers H = { h l } m l =1 ,eachofwhich outputs a probability distribution vector p l for an instance x , the average probability distribution vector can be com-puted as: Then, using the Shannon entropy, we can measure the degree of consensus in these prediction results as shown in the ex-amples of Table 1. For 3-class classification problem, Table 1 records the probability distribution vectors of x 1 , x 2 and x 3 predicted by the classifiers h 1 , h 2 and h 3 respectively, and their corresponding average probability distribution vectors. consensus that it belongs to class 1 with 100% probability. Therefore, the degree of consensus on these results reaches its maximum, while the entropy E (1 , 0 , 0) of the average distribution vector reaches its minimum for any 3-entry dis-tribution vectors. On the other hand, for the third instance x and 3 respectively with 100% probability. Thus, these pre-diction results totally disagree with each other, and their degree of consensus reaches its minimum. However, the en-tropy E ( 1 3 , 1 3 , 1 3 ) of the average distribution vector reaches its maximum. Therefore, the negative of the entropy in the average probability distribution vector can be the consensus measure for the different prediction results. Formally, the definition of the entropy based consensus measure is: Definition 3 (Entropy based Consensus Measure).
 Given m probability distribution vectors p 1 ,  X  X  X  , p m ,thecon-sensus measure for these vectors is defined as where E is the Shannon entropy in Definition 2 and p is the average of these vectors defined by (4).

Since we only consider the relative magnitude of two con-sensus measures, it is acceptable that the value of this con-sensus measure is negative. Thus, by this definition, the consensus degree for the prediction results of the second in-stance x 2 is  X  E (0 . 7 , 0 . 2 , 0 . 1).

Due to the computing complexity in the entropy, for 2-entry probability distribution vectors, this consensus mea-sure can be simplified as: It is clear that, when comparing the relative magnitude of two degrees of consensus, C e and C s are equivalent for 2-entry probability distribution vectors in the sense that they always give the same answer.
In this section, we first formulate the problem of transfer learning from multiple domains and then describe the prin-ciple of consensus regularization. Next, we analyze why and when this consensus regularization works for this problem formulation. Finally, we show how to adapt this principle into the model of logistic regression.
Let D 1 s ,  X  X  X  , D m s be m (m &gt; 1) source-domains of labeled data , and the labeled data set from the l -th source-domain is represented by D l s = { ( x l i ,y l i ) }| n l i =1 ,where y x and n l is the number of data in this domain 1 . The unla-beled target-domain is denoted by D t = { ( x i ) }| n i =1 is the number of data objects in the target-domain. Under the assumption that the distributions of D 1 s ,  X  X  X  , D m different but closely related, we aim to train the classifica-tion models on these labeled source-domains to accurately classify the unlabeled data in the target-domain.
If we train m classifiers h 1 ,  X  X  X  ,h m locally, each of which is based only on the data from one source-domain data, the ideal situation is that these m classifiers make a perfect con-sensus that they predict an instance from the target-domain to be its ground truth with 100% confidence. However, since the distributions of D 1 s ,  X  X  X  , D m s , D t are different, these ini-tial m classifiers usually disagree with each other to some
In the following, the upper index of a letter denotes the index of source-domain, while the lower index of a letter, if existing, denotes the index of the data in the data set. degree on the prediction results of a certain instance. Thus, there is room to further maximize the consensus of these models on the prediction results of the data in the target-domain. Therefore, we can incorporate this consensus mea-sure into the standard framework of supervised learning as follows. This adapted supervised learning framework with consensus regularization will output m models h 1 ,  X  X  X  ,h m , which maximize the following equation: where P ( h l |D l s ) is the probability of the hypotheses h the observed data set D l s ,and Consensus ( h 1 ,  X  X  X  ,h m the consensus measure of these m models h 1 ,  X  X  X  ,h m on the prediction results of the data in the target-domain D t .
In the first term of (7), each model h l is applied to its local source-domain, while the second term in (7) is used as a bridge to link all these models, and realizes a mutual coupling optimization. In this way, each of these resultant models not only keeps the individuality of the corresponding local source-domain, but also reveals the common nature of the target-domain. Thus, this regularization framework maximizes not only the posteriori in each source-domain, but also the consensus degree of these models.

Given a source-domain data set D l s = { ( x l i ,y l i independent and identically-distributed (IID) observations, the maximization of P ( h l |D l s ) in the first term of (7) can be expanded further as follows: As to Consensus ( h 1 ,  X  X  X  ,h m |D t ), it is defined as the sum of the consensus measures of these m models on all the data in D t and is shown as follows: where C e is the consensus measure in Definition 3, and p is the probability distribution vector predicted by the l -th model h l for the i -th instance in the target-domain D t tually, this consensus measure has two sides of effect. One is to promote the degree of agreement on all the models. The other is to minimize the entropy of the prediction results on unlabeled data.
In this subsection we will theoretically show that maximiz-ing agreement between any two individual classifiers could lead to the performance improvement of the individual clas-sifiers.

In this study we focus on binary classification problems with the labels 1 and  X  1. We can train m models h 1 ,  X  X  X  for m source-domains. Let Y be the target label, and the disagreement of any two individual models be P ( h i = h j ( i, j  X  X  1 ,  X  X  X  ,m } ,i = j ). In the following the number of the individual models is set to 3 for convenience. Note that the results in this subsection can be extended to any number of individual models similarly. We also have the following two definitions.

Definition 4 (non-trivial classifier). If a classifier h satisfies the condition where u  X  X  X  1 , 1 } and u is the complement of u .Thenwe call classifier h is a non-trivial classifier.
 In other words, we can restate the non-trivial condition as Definition 5 (conditional independent classifiers). The conditional independence of models h 1 ,h 2 ,h 3 is shown as follows, where u, v, w, y  X  X  X  1 , 1 } .
 According to the assumption of non-trivial and conditional independent classifiers, We obtain the following theorem.
Theorem 1. If the conditions that conditional indepen-dent assumptions are satisfied, it holds that the disagreement upper bounds the misclassification error for nontrivial clas-sifier.
 Proof. The classification error of h 1 is and the disagreement between h 1 and h 2 is To validate that P ( h 1 = Y )  X  P ( h 1 = h 2 ), we only have to proof the following inequation, According to equation (10) and the Bayes Principle, Inequa-tion (12) can also be written as follows, From Definition 4, the following inequations (14), (15) hold, Therefore, Inequation (13) holds.

Finally we obtain that the disagreement upper bounds the misclassification error as Similarly, we can prove that the following inequations also hold,
Theorem 1 shows that the disagreement upper bounds the misclassification error for nontrivial classifier. Thus, mini-mizing the disagreement means to decrease the classification error.
Here, we introduce how to adapt and integrate the prin-ciple of consensus regularization into the model of logistic regression.

According to the problem formulation in Section 3.1, this consensus regularization framework outputs m logistic mod-els w 1 ,  X  X  X  , w m , which maximize: where the conditional probability P is the logistic function defined in (1), and E is the Shannon entropy. Note that this regularization framework works for multi-class problems.
For the 2-class classification problem, the entropy based consensus measure can be substituted with the equivalent form C s , defined in Equation (6). Thus, the new objective function is where the conditional probability P is the logistic function defined in Equation (1).

To simplify the discussion, in this paper we only describe this regularization framework in Equation (18) for 2-class classification problems, but it can be extended to multi-class problems using the framework in Equation (17). Thus, The partial differential of the objective g s is where the function  X  is defined in (1), and
Though the objective function in Equation (18) is neither concave nor convex, for given initial values, the local op-timization solution can also be obtained by any non-linear optimization technique. In this study, we adopt the conju-gate gradient method [7] as the optimization technique (the reason why we adopt conjugate gradient is described in the experimental section), and the initial models are set to the ones trained on each local source-domain separately. The pseudo-code of our method is shown in Algorithm 1. To solve the sub-problem in Step 4 of Algorithm 1, any opti-mization technique can be used. In our implementation the function fminunc provided by Matlab is adopted for Step 4.
In this section, we investigate how to extend this cen-tralized consensus regularization method into a distributed learning algorithm, which can work in the situation that the source-domains D 1 s ,  X  X  X  , D m s and the target domain D all geographically separate distributed. In this distributed setting, the data nodes containing the source-domain data are used as slave nodes , denoted by sn 1 ,  X  X  X  ,sn m ,andthe data node containing the target-domain data is used as the master node , denoted by mn .

Let us first revisit the partial differential of the objec-tive g s in (19), which consists of two parts. It is clear that the computation of the first term  X  l sn ( w l , D l only the local model w l and the data set D l s .Thus,itcan be computed locally. The computation of the second term and the target-domain data set D t . Therefore, if the slave nodes sn l ( l =1 ,  X  X  X  ,m ) sends w l and  X  l sn to the mas-ter node mn , the master node can compute  X  w l ( g  X 
As a result, if each round of the optimization process per-forms this synchronous communication of the statistic data between the slave nodes and the master node, the gradient Algorithm 1 Centralized Version of Consensus Regulariza-tion by Conjugate Gradient Ascent Input : The labeled data sets D 1 s ,  X  X  X  , D m s , the unlabeled data set D t , the element matrix Q  X  R k  X  k where k = | the dimension of the data in the source-domain, the error threshold  X &gt; 0, and the maximum iterating number max . Output : m classifiers w 1 ,  X  X  X  , w m . 1. Each source-domain calculates the initial w l 0 by logis-2. k := 0. 3. For l =1 ,  X  X  X  ,m , compute the gradients  X  w l 4. Compute the best searching step  X   X  0, which maxi-5. k := k +1. If k  X  max ,thenturntoStep3. 6. Output w 1 k ,  X  X  X  , w m k .  X  w l ( g s ) can be computed accurately. However, the maxi-mization in the Step 4 of Algorithm 1 involves all the data from the source-domains and the target domain, which is hard to be solved distributively. In order to extend Algo-rithm 1 to a distributed version, the searching step  X  in it can be set to a constant. Then, the method of distributed consensus regularization is described in Algorithm 2, which is an approximation of Algorithm 1.

In each round of Algorithm 2, each slave node sn l sends avector  X  l sn to the master node (in the first round the slave node should also send the initial model to the master node), and the master node sends back the updated model. Therefore, if this process terminates after k iterations, the total communication overhead will be
Note that this distributed process communicates only some statistic values, such as  X  l sn ( l =1 ,  X  X  X  ,m ) and the classifi-cation models, without sending the raw source-domain data. Therefore, this also can modestly alleviate the privacy-concerns.
The experiments performed in this section evaluate the performance of the proposed methods. In the experiments, we focus on the problem of binary classification, however, it is straightforward to extend the proposed methods for multi-Algorithm 2 The Distributed Version of Consensus Regu-larization by Conjugate Gradient Input : The labeled data sets D 1 s ,  X  X  X  , D m s on the separated slave nodes sn 1 ,  X  X  X  ,sn m respectively, the unlabeled data set D t on the master node mn , the error threshold  X &gt; 0, the maximum iterating number max , and the step constant  X  .
 Output : m classifiers w 1 ,  X  X  X  , w m . 1. Each slave node sn l ( l =1 ,  X  X  X  ,m ) calculates the ini-2. k := 0. 3. The master node computes the gradients  X  w l 4. The master node sends w l k +1 ( l =1 ,  X  X  X  ,m )to 5. k := k +1. If k  X  max ,thenturntoStep3. 6. Output w 1 k ,  X  X  X  , w m k . class classification. Additionally, in this study the number of the source-domains for transfer learning is set to 3.
We follow the data preparation method in [2] to construct the problems of transfer learnin g from multiple source-domains, which will be detailed following. Since the public data col-lections are not originally designed for transfer learning from multiple source-domains, we need to make some modifica-tions on them to fit the problem settings. It requires that each of these data sets has at least a two-level hierarchical structure. In this paper, we assume A and B are two root categories in a data set, and A 1 ,  X  X  X  , A 4 and B 1 ,  X  X  X  the four sub-level categories of A and B respectively. These sub-level categories are used for the three source-domains and one target-domain. Now we construct the training and test data as follows. For i =1 ,  X  X  X  , 4, let A a i and be the positive and negative instances in the i -th domain D once and only once in these domains. In this way, the posi-tive (negative) data from different domains are similar since they belong to the same top category A ( B ), and the posi-tive (negative) data from different domains are still different since they belong to different sub-categories. Thus, these four domains own different but similar data distributions. We can then select any one of these four domains as the target domain, and the other three domains as the source-domains. Therefore, given A 1 ,  X  X  X  , A 4 and B 1 ,  X  X  X  , can construct 96 (4  X  P 4 4 ) instances of 3-source-domain trans-fer learning problems. 20 Newsgroup 2 is one of the public available data collec-http://people.csail.mit.edu/jrennie/20Newsgroups/ tion, which satisfies the problem requirement that the top category contains at least four sub-categories. In this sec-tion, we list the evaluation results on the data sets of sci and talk , which are regarded as the top categories, denoted by A and B respectively. The four sub-categories in sci are sci.crypt , sci.electronics , sci.med and sci.space , denoted by A talk.politics.guns , talk.politics.mideast , talk.politics.misc and talk.religion.misc , denoted by B 1 ,  X  X  X  , B 4 respectively. The threshold of Document Frequency with the value of 5 is used to select the features. Then, these corresponding 96 prob-lem instances are evaluated by the benchmark classification methods in Section 5.2.

We also evaluate our algorithm on other text data sets, including comp vs. talk and comp vs. sci etc. Furthermore, we construct and evaluate the transfer learning problems of image classification. These results are quite similar to those in this section. Due to the space limitations, we omit these detail results.
Under the assumption that the source-domains and the target domain are geographically separate distributed, we introduce the following benchmark classification methods for comparison. They can be grouped into two types: dis-tributed and centralized classification algorithms.
Distributed Approach: in this approach, the algorithm is implemented in a distributed manner. The simplest dis-tributed approach is Distributed Ensemble (DE), where a classifier is trained based on the local data on each source-domain. The other distributed approach is Distributed Con-sensus Regularization (DCR) described in Algorithm 2. In both DE and DCR, the prediction is made by majority vot-ing on the probability distribution vectors of the resultant classifiers.

Centralized Approach: in this approach, all the data from the source-domains and the target-domain are accu-mulated and processed on a central node. In this case, the simplest method is Centralized Training (CT) which trains a global classifier on all the data. Meanwhile, if all the data from the source-domains are put together as one labeled data set, Centralized Consensus Regularization (CCR) in Algorithm 1 with m = 1, denoted by CCR 1 ,can be used. The transfer learning method CoCC [2] and the semi-supervised techniques TSVM [8] as well as SGT [9] can also be applied to this situation. On the other hand, in or-der to explicitly consider that the centralized data are from three different source-domains, CCR with m = 3, denoted are compared with DE, CT, CoCC, TSVM and SGT. Note that when the parameter  X  in the objective function (Equa-tion 18) is set to 0, DE is equivalent to DCR, and CT is achieves the same accuracy performance as CCR 3 at the cost of some communication overhead. Therefore, these two
Details of Implementation: Some initial experiments show that several popular non-linear optimization techniques output similar models for the proposed optimization prob-lem and conjugate gradient is the fastest one. Therefore, we use conjugate gradient in this paper. After some preliminary test, we find that  X  l is not very sensitive in the value range [10,300], so the  X  l in the objective function (Equation 18) is set to 145 (for l =1 ,  X  X  X  ,m ). And the value range of  X  is [0, 0.25]. In the algorithms of consensus regularization, the maximal iterating number max is set to 200, and the error threshold  X  is set to 0.1. Before conducting the opti-mization for consensus regularization, logistic regression performed on each source-domain to obtain the initial val-ues of the model for further optimization. The parameters of CoCC, TSVM and SGT are the same as those in [2].
The performance of the comparison methods is evaluated by accuracy. Let c be the function which maps each instance to its true class label, and f be the function which maps each instance to its prediction label given by the classifier. Accuracy is defined as We also measure the consensus degree of multiple classi-fiers on the target-domain as follows. Let h be the function which maps each instance to the probability distribution vector predicted by the classifier. This consensus degree of m classifiers h 1 ,  X  X  X  ,h m is defined as where C s is defined in (6). It is clear that these m classifiers reach perfect consensus when c reaches its maximal value 1.
For each of the 96 problem instances described in Sec-tion 5.1, we record the values of accuracy and consensus for the resultant classifiers of Algorithm CCR 3 and CCR 1 on different values of  X  . Table 2 gives an example of these mea-sures for one of these problem instances. Due to the space limitation, we cannot list all the 96 tables. However, the properties in these tables are similar, as can be seen later in this section.

For each  X  , Algorithm CCR 3 outputs three classifiers on the corresponding three source-domains. These classifiers are tested on their own source-domains and the target-domain, and the results are recorded from the 2nd to 7th column of Table 2. Then, the 8th column records the consensus mea-sure of three classifiers. Fina lly, the accuracy performances of this table respectively. As mentioned above, when  X  =0 (71.9937 at the 1st row and 10th column of Table 2) is that of CT.

The results in Table 2 show that: 1) When  X  = 0, CCR 3 distribution differences among source-domains can improve the performance. 2) When  X  = 0, the performances of the local classifiers tested on their own source-domains are sta-ble (always near 100%). Additi onally, under this situation the performances of the local classifiers tested on the target-domain increase significantly. For example, the performance http://research.microsoft.com/  X  minka/papers/logreg/ of the classifier on D 2 s increases from 55.7489% to more than 90% when it is applied to the target-domain. 3) When  X  increases, the consensus measure of the resultant three clas-sifiers increases. When this consensus measure reaches some extent, the classifiers always output the same results for an instance. So the performances of these classifiers tested on the target-domain are almost equal to that of CCR 3 when  X  =0.

To further validate this on the other 95 tables, for each of these tables, we measure six values: 1) the performance of DE; 2) the performance of CT; 3) the average perfor-mance of CCR 3 when  X  is sampled in [0.05,0.25], denoted by CCR 3 ; 4) the best performance of CCR 3 when  X  is sampled in [0.05,0.25], denoted by CCR max 3 ; 5) the average perfor-mance of CCR 1 when  X  is sampled in [0.05,0.25], denoted by CCR 1 ; 6) the best performance of CCR 1 when  X  is sam-pled in [0.05,0.25], denoted by CCR max 1 . For each of the six numbers we can average its values on all the 96 problem instances. These results are shown in Figure 2 and Table 3. In Figure 2(a) and Figure 2(b), the 96 problem instances are sorted by the increase order of the performances by CT.
Figure 2(a) shows that CCR max 3 outperforms DE and CT on every problem instance. Figure 2(b) shows that except Problem 45 CCR max 3 outperforms CCR max 1 on each problem instance, which further proves that explicitly exploiting the distribution differences among the source-domains increases the performance. In Figure 2(c) the x -axis represents the accuracy of DE while the y -axisrepresentstheperformance difference between CCR max 3 and DE. Figure 2(c) shows that this performance improvement decreases when the perfor-mance of DE increases. The reason is that if the accuracy of DE is high, these original classifiers usually output the same right results, and the consensus measure of the classi-fiers is big. In this case, the room for futher increasing this consensus measure is very limited, and thus the improve-ment by consensus regularization is small.
 Table 3: Avg. Values( % )on96ProblemInstances
Table 3 lists the average values of the six accuracy mea-sures over the 96 problem instances in a decreasing order. Note that the same performance of CCR max 3 can be achieved by DCR in a distributed manner. Compared with DE, the accuracy of DCR increases from 79.2111 to 92.6571. lect the data sets in [2] which can be modified to fit our problem setting. We divide the single source-domain of the original problem into multiple source-domains. Four data sets, which are described in Table 4, are selected for this these problems by the two values CCR 3 and CCR max 3 .The experimental results in Table 5 show that both CCR 3 and CCR max 3 outperform TSVM and SGT on these four data fourth data set, both CCR 3 and CCR max 3 are better than CoCC on the other three data sets.
 Table 5: The Performance Comparison Results ( % ) domly selected problem instances. These results are shown in Figure 3, where the x -axis represents the number of iter-ations and the y -axis represents the accuracy performance. It shows that for each problem instance the accuracy perfor-mance increases along the number of iterations and almost converges after 20 iterations. This indicates that our algo-rithm owns a good property of convergence.
In this section, we introduce some existing works in the fields of transfer learning, self-taught learning, semi-supervised classification, and multi-view learning, which are closely re-lated to the problem studied in this paper.

Transfer Learning aims to solve the fundamental prob-lem of mismatched distributions between the training and testing data. It is also referred to as Cross-Domain Learn-ing , which adapts the knowledge from a source-domain ( in-domain , auxiliary-domain ) to a target domain ( out-of-domain , primary-domain ). In general, previous works in this area can be grouped into two categories. The first category is under the assumption that there are some labeled data from the target domain with different distribution. For instance, Liao et al. [10] estimated the degree of mismatch of each instance in the source domain with the whole target do-main, and incorporated this information into logistic regres-sion. Also, Dai et al. [1] extended boosting-based learning algorithms to transfer learning, in which the source-domain data with very different distribution are less weighted for data sampling. They also analyzed the theoretical effective-ness of this algorithm using the Probability Approximately Correct (PAC) theory. In addition, Yang et al. [5] stud-ied the problem of transform the existing classifier from the source-domain to a target-domain in an incremental way. The principle behind this transforming is that the difference between the classifiers before and after adaption should be as small as possible. This work involves the data from multi-ple source-domains, but it does not consider the distribution difference among these source-domains. Meanwhile, Smith and Elkan [11] built generative classifiers, which address the selection bias problem in transfer learning. Finally, Raina et al. [12] focused on constructing information priors from the source-domain by a semi-definite program, and then en-coded them into the model built.

In the second category, for the problem that the data from the target-domain are totally unlabeled, Dai et al. [2] pro-posed a Co-clustering based Classification method (CoCC), in which the class labels are transferred through the bridge of co-clustering. Xing et al. [3] proposed a transductive learn-ing algorithm for this problem. Their method performs a two-phase label propagation, which is based on the adjacent matrix of the data. However, the method cannot output the classifier for future unlabeled data. The proposed method in this paper falls into this category of transfer learning.
Self-Taught Learning [13] studies how to use a large number of unlabeled data to improve performance on a given classification task. The distributions of the unlabeled data and the labeled data in the given task can be totally different (not related). Raina et al. [13] proposed an approach to self-taught learning that used sparse coding to construct higher-level features using the unlabeled data. The labeled data are represented by these succinct features. The significant performance improvement is shown in their experiments.
However, none of the above existing works consider the problem of transfer learning from multiple source-domains to a target domain in a distributed manner. These methods were not developed for the situation that the training data for transfer learning are geographically separate distributed. Moreover, we explicitly leverage the distribution differences among the source-domains and the target domain in our model to further improve the learning performance in the target domain.

Semi-Supervised Classification uses a large amount of unlabeled data, together with the labeled data, to build bet-ter classifiers. Different from t ransfer learning, the labeled and unlabeled data in semi-supervised learning are from the same distribution. The most related work in this area is semi-supervised learning by e ntropy minimization [14]. To compare with this method in the same problem setting, we assume that the labeled data and unlabeled data consist of a source-domain and target-domain, respectively. The reg-ularization framework in [14] is recognized as an instance of the objective (17) with m =1( m is the number of source-domains). In other words, our regularization approach is more general and includes this method as a special case. Furthermore, our consensus regularization method is de-signed in a distributed manner.
Multi-View Learning is a new and natural, but non-standard learning problem, where the data are represented by multiple independent sets of features. As an example, Yarowsky [15] as well as Blum and Mitchell [16] noticed that having multiple representations can improve the perfor-mance of semi-supervised classification. The techniques of multi-view classification, such as co-Training [16] and Mixt-Boost [17], often boost the agreement among two views on unlabeled data. Sindhwani et al. [18] proposed a co-regularization approach, which penalizes not only the mis-classifications by any individual classifier but also the high level of disagreement between different views. The experi-ments in [18] are performed on two views only, and the reg-ularization term do not have the effect of entropy minimiza-tion. In addition, Dasgupta et al. [19] and Abney [20, 21] provided PAC bounds on the error of co-Training in terms of the disagreement rate of hypotheses on unlabeled data in two independent views. This inspires the principle of con-sensus maximization, which says that by minimizing the dis-agreement rate on unlabeled data, the error rate can be min-imized. Our work utilizes this principle to another problem setting: transfer learning from multiple domains. From the point view of data partition, the difference between multi-view learning and multi-domain learning is that the data are vertically partitioned for multi-view learning while they are horizontally partitioned for multi-domain learning.
In this paper, we studied the problem of transfer learning from multiple source domains to a target domain. Specifi-cally, for the case that data from multiple source domains and the target domain are semantically related, but have dif-ferent distributions, we proposed a consensus regularization framework to exploit the distribution differences and learn the knowledge among training data from multiple source domains to boost the learning performance in a target do-main. In this framework, we designed a distributed learning algorithm. In other words, a local classifier is trained at each source domain by considering both local data and the prediction consensus with the classifiers from other source domains. To modestly alleviate the privacy concerns, only some statistical data are shared between the source domains and the target domain, rather than the full contents of la-beled data. Our experiments on real-world text data sets have shown that our consensus regularization learning method can effectively improve the learning performance in the tar-get domain by leveraging the knowledge learnt from multiple source domains.
The authors Fuzhen Zhuang and Qing He are supported by the National Science Fo undati on of China (No. 60435010, 60675010), 863 National High-Tech Program (No.2006AA01 Z128), National Basic Research Priorities Programme (No.2 007CB311004). [1] W. Dai, Q. Yang, G. Xue, and Y. Yu. Boosting for [2] W.Dai,G.Xue,Q.Yang,andY.Yu.Co-clustering [3] D. Xing, W. Dai, G. Xue, and Y. Yu. Bridged [4] A. Smeaton and P. Over. Trecvid: Benchmarking the [5] J. Yang, R. Yan, and A. G. Hauptmann. Cross-domain [6] David Hosmer and Stanley Lemeshow. Applied [7] Andrzej Ruszczynski. Nonlinear Optimization . [8] T. Joachims. Transductive inference for text [9] T. Joachims. Transductive learning via spectral graph [10] X. Liao, Y. Xue, and L. Carin. Logistic regression [11] A. Smith and C. Elkan. Making generative classifiers [12] R. Raina, A. Y. Ng, and D. Koller. Constructing [13] R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng. [14] Y. Grandvalet and Y. Bengio. Semi-supervised [15] D. Yarowsky. Unsupervised word sense [16] A. Blum and T. Mitchell. Combining labeled and [17] Y. Grandvalet, F. d X  X lch  X  e-Buc, and C. Ambroise. [18] V. Sindhwani, P. Niyogi, and M. Belkin. A [19] S. Dasgupta, M. L. Littman, and D. A. McAllester. [20] S. Abney. Bootstrapping. In Proc. of the ACL , 2002. [21] S. Abney. Understanding the yarowsky algorithm.
