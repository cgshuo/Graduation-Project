 Department of Automatics, Mechanics and Informatics, University of Valenciennes, Valenciennes, France
Department of Applied Mathematics, University of Valenciennes, Valenciennes, France Department of Reliability, Bombardier Transport, Crespin, France 1. Introduction
Improving the knowledge about systems (e.g., industrial, economic, biomedical) often amounts to collecting data [14,17], which is becoming easier due to increasingly automatic computing and storage performance in microprocessor-based devices [18]. However, whatever the data collection strategy  X  observational, experimental or correlational [34]  X  the phase coming just after collecting the data may still remain dif fi cult. On the one hand, the data compression phase may yield many large Multifactor Multivariate (MFMV) data sets, likely to be heterogeneous. For instance,in an experimental design where signals are recorded, the time factor and the experimental factors do not feature the same status. Another example of heterogeneity occurs when qualitative and quantitative data sets are involved simultaneously. On the other hand, the statistical methods require speci fi c entries. For instance, in the case of Principal Component Analysis, a matrix may only contain quantitative data, or in the case of Parametric Variance Analysis, dummy indicators may exist for some of the factor columns and Laplace Gaussian quantitative data for the variable columns [22]. These speci fi c entries are very different from the above mentioned MFMV heterogeneous data sets.
This paper focuses on a complex but frequent case. In research based on an experimental design, for the statistical analysis of experimental design results recommends using mainly methods that consider the data within a statistical inference context [19, 29,30]. Similarly, the lite rature about time series analysis often suggests using this inference context, whether the chronological aspect is absent (e.g., probability estimation; globa l indicator tests, using mono-or multivariate moments; and functional tests, using spectral or density functions) or present (e.g., autocorrelation analysis, dynamic system modeling, forecasting) [1,33].

Instead of investigating the time data sets using this statistical inference context, we suggest using the descriptive context for at least the preliminary analysis, keeping both the Multifactor and Multivariate (MFMV) aspects, where time may be one of the factors. To conduct this preliminary analysis, we recommend a fi ve-step procedure [26]: 1) Data characterization  X  Each multidim ensional signal is r eplaced with a new data set, which 2) Data coding  X  If necessary, the indicators from the previous step are changed so that they ei-3) Table building  X  In most cases, the data sets are plotted onto a two-entry table, with the rows 4) Table analysis  X  The data is mainly analyzed to show the factor effects and/or the relationships 5) Result presentation  X  Since the output of the previous step is rather complex, texts and simpler
It is worth noting that such a fi ve-step procedure stands in the inferential context also and, in many cases, Step 4 mainly affects the remaining procedure. Let us consider the situation where an engineering system is studied using a n experimental design and where each tr ial yields a multidimensional signal. In the view to assess the effects of the factors and/or the connections between variables, the Principal Component Analysis (PCA) is chosen fi rst in a descriptive statistical context and the usual (parametric) analysis of variance is chosen fi rst in the inference statistical context.

To illustrate the usefulness of this fi ve-step descriptive procedure, we suggest considering a rather well known method in the engineering fi eld, i.e. PCA, and a method much less known in this fi eld but more known in the fi eld of psychology or sociology, i.e. Multiple correspondenceAnalysis (MCA), since MCA has been designed for qualitative variables (e.g. multiple choice questionnaire or discrete behavioral state variables). Both methods will be compared using a brief description (Section 2) and considered with two examples from a simulated system (Section 3) and a mechatronic system (Section 4). Section 5 discusses the analysis methods considered in this paper, providing further information about the advantages and disadvantagesand several ways to continue the analysis from a more inferential perspective. In Section 6, we offer our conclusions and prospects for future research.

To facilitate comprehension, we have used the following notati onal system throughout the paper:  X  an outlined letter designates a set (e.g., set E );  X  if an initial set must be transformed, tag  X 0 X  designates this set (e.g., set E 0 ), and tag  X 1 X  designates  X  an uppercase letter designates the set size (e.g., E 0= card ( E 0)) ,where card is the cardinality  X  a boldface letter designates either a vector or a matrix (e.g., x =( x 1 ,x 2 ,x 3 ) or X = x  X  x ).
Given these basic notations, U 0= { X 0 u , u = 1 ,..., U0 } and V 0= { Y 0 v , v = 1 ,..., V0 } ,are, respectively, the initial factor set (i.e., independent variables; even though time is a factor when time data is present, time will be not considered as belonging to U 0 ) and the initial variable set (i.e., dependent variables). In our case, the dependent variables yield multidimensional raw signals with V 0 components. when an MFMV data set is organized using a speci fi c data table, the table will be denoted with the same symbol a (e.g., if a data set E 1 is considered (during the analysis step a = 1), the data tables linked to the factors and to the variables will be noted X 1and Y 1 respectively, even though Tables X 0and Y 0 do not exist. 2. The fi ve-step descriptive procedures based on PCA and MCA
First, let us recall the common point of both methods, i.e. the singular value breakdown, and the main different point, i.e. usually PCA deals with V quantitative variables and MCA with V qualitative variables, where the latter may originate from a (fuzzy) space windowing (as with automatic control or expert system based on fuzzy sets, the considered data pieces are membership values) [9,16,36]. Keeping both points in mind, there are several ways of presenting PCA and MCA [4,10,28,37]. As it is a descriptive statistical context, only a brief summary of the geometrical point of view will be given in Table 1.

If didactic examples with PCA and MCA (in a book or any tutorial about the method) often start with a table matching the input Y required for the corresponding method, most data collecting strategies (e.g. based on experimental or observational design) often yield several tables. So, as mentioned in the introduction, more than one step may be required in the prospect of a MFMV analysis. In such a case, let us compare these methods using a didactic example, fi rst. 3. The fi ve-step descriptive procedures with a didactic example
Let us suppose a dynamic system studied through an experimental design with U 0= 1 factor with I = 4 levels. For each of the I = 4levels, V 0= 2 time variables are present, yielding a multidimensional signal (MS) with V 0= 2 components (the time being a factor, there are U 0+1= 2 factors). As data, let us reconsider Anscombes X  X  example [2] as following: the 2 MS components are obtained at a given sampling rate which gives two data sets (one per component) for each I = 4 level, as follows for i = 1, Y 0 1 = { 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 } and Y 0 2 = { 4.26, 5.68, 7.24, 4.82, 6.95, 8.81, 8.04, 8.33, 10.84, 7.58, 9.96 } ; for i = 2, Y 0 1 and Y 0 3 = { 3.10, 4.74, 6.13, 7.26, 8.14, 8.77, 9.14, 9.26, 9.13, 8.74, 8.10 } ; for i = 3, Y 0 1 and Y 0 4 = { 5.39, 5.73, 6.08, 6.42, 6.77, 7.11, 7.46, 7.81, 8.15, 12.74, 8.84 } ; 5.56, 7.91, 6.89,12.50 } .

For instance one can imagine these two main cases:  X  the dynamic system is a stamping press studied using an experimental design with one 4 level- X  an observational design of 4 factories of a given major company. The two measurement variables
It is worth reminding that Anscombe had chosen his example to show the importance of creating graphics prior to any statistic computations. With these data pieces, the generic value will be referred to didactic example, the subscripts i and n indicate, respectively, the level of the factor ( i =1 ,...,I =4 ) and of the time factor ( n =1 ,...,N 0= 11). The I = 4 empirical situations yield I time data sets E 0 i of 22 values y 0 in,v ( n =1 ,...,N 0= 11, v =1 ,...,V 0= 2).

Let us now begin a preliminary analysis of the I = 4 data sets, keeping in mind the descriptive context previously mentioned in the introduction. 3.1. Stage 1: Data characterization
As usual, each bivariate data set E 0 i may be summarized using W = 2 indicators, i.e. the arithmetic mean and standard deviation, yielding a data set E 1 i of W  X  V 0=2  X  2=4 values. The I = 4newsets are identical (see the 16 values on a gray background on the PCA column of Table 2). To continue the analysis, the V 1= W  X  V 0 new variables will be called the analysis variables .

Now, let us suppose that the values are characterized using space windowing, making differences appear between the I = 4 new sets. To reduce the information loss inherent to space windowing, instead of considering rectangular windows with identical width, let us use the fuzzy membership function concept introduced by Zadeh [41] as follows:  X  With usual (crisp) space windowing (or space segmentation), generic value y 0 in,v is either within or  X  With fuzzy space windowing, it is then possible to deal with the situation where y 0 in,v just falls on
For this didactic example, a very simple segmentation with S = 3 space windows (SW) is used. (A more complex segmentation is to be used in our mechatronic example, presented in Section 4 and discussed thereafter in Section 5). The main principle is as follows: 1) S = 3 rectangular windows with identical width are de fi ned (let a v be the width, with a v = 2) For the two borderline cases (between windows 1 and 2 and between windows 2 and 3), the 3) For the left side window ( s = 1), the membership value is 1 if y 0 in,v is  X  X ow X , let say if y 0 in,v is 4) Finally, linear membership value changes are chosen to jump from one space window to the next
With this windowing, each value is changed into W = S = 3 values as follows: where notation  X  bc ( a ) means the  X  membership value of data item a for the space window c of the variable b  X  and the sum condition is used to remain within a statistic context. Let E 1 i be the set of membership values ( E 1 i = card( E 1 i )= N0*V*W X  = 11*2*3 = 66). As an example, let us consider the fi rst multidimensional signal ( i = 1andthesets Y 0 1 and Y 0 2 ); Table 2 gives the initial data and membership value sets.

Once each triplet is obtained using Eq. (1), the N 0= 11 membership values linked to each time data set i and each space window s for variable v are characterized using the usual arithmetic mean as follows:
Thus, each in itial data set E 0 i of 22 values is summarized using a data set E 1 i of 6 membership value averages (see the values on a gray background of the MCA column of Table 3). 3.2. Stage 2: Data coding
To perform a multivariate analysis with the I = 4 data sets E 1 i several choices would have been available if the sets were different, for example, traditional standardization using the arithmetic mean and standard deviation or ranking [23]. Concerning the I = 4 data sets E 1 i , the coding stage is not required since these sets contain membership values only. 3.3. Stage 3: Data table plotting
As usual, several two-entry tables can be plotted, a row corresponding to an empirical situation (a time sample n or a trial i , see Tables 2 and 3) or to any combination of these empirical situations (a given time window or a level cluster. Cf. next section). The columns correspond to the indicators. 3.4. Stage 4: Data table analysis
With Table Y3 I , PCA could have been chosen, but since the 4 lines are identical, this analysis is not appropriate. However, MCA and PCA will be compared in the mechatronic example.
 With Table Y3 I , MCA yields three main axes with relative inertia values of about 78%, 14% and 8%. Given the third main axis very low value, only the plane crossing axes 1 and 2 will be considered. The row points and column points are shown Fig. 2. Given the pattern of the V 0= 2 variable trajectories and the size of the corresponding V 0  X  S = 6 lozenges, axis 1, which displays the information, mainly opposes two space windows: window 1 L (on the negative side) and window 1 M (on the positive side). Thus, axis 1 opposes any MS in which the variable 1 Low space window is often present (here, the MS corresponding to the factor level i = 4, on the left side) to any MS in which variable 1medium modality is to be found (here, the MS corresponding to the factor levels i = 1, 2 and 3, on the right handside). Of course, like in PCA, the more salient phenomena have to be compared to the average point, located at the point where the main axes cross. Table 2 (MCA column) con fi rms the opposition underscored by axis 1. A similar analysis could be done using the second axis, which only shows 1/4 of the information. There is consequently a hierarchy between the MS differences, i.e. 1) axis 1 opposes MS n  X  4 to the three other MS and 2) axis 2 makes a distinction between these three MS. Let us now study how the 4 different time evolutions look like.

To achieve this aim, the rows of table Y3 I  X  N 0 can be considered supplementary points. The respective positions of the 4*11 = 44 points are consistent with the 88 initial values. For instance, for i = 1, 2 the left handside (thus 1 L is mainly present, which is consistent with the data), then there is a transition towards the right handside (thus 1 M is mainly present, which is consistent with the data), fi nally this a slight turn back towards the left handside (thus 1 M is less present, which is consistent with the data). A second example could be taken for i = 3 where the time in fl uence according to axis 2 is mainly as follows: There is a sudden down-to-up change from the 9 th to 10 th point (thus 2 H becomes more present, which is consistent with the data). 3.5. Stage 5: Result presentation
Here, since Table Y3 I is very small, no other result will be considered. Before considering a more complex example that will require this fi fth stage, let us mention that: 1) A space windowing based characterization generates I = 4 different data sets, which is not the 2) MCA shows where the 4 MS primarily differ, or in other words what are the pairs ( v,s ) among the
Let us now consider a more complex MS setting, which contains U 0= 5 factors and V 0= 5 components. In addition, instead of considering each MS through a single time window, the time scale is to be segmented. Since our objective in considering the next example is to show how the descriptive MFMV approach can yield interesting preliminary results from a MFMV data set produced through an experimental design, the details about the process used to obtain this database are not given. For reasons of con fi dentiality, some results and some of the level values for the experimental factors are not given either. 4. The 5-step descriptive procedures with a mechatronic example
For trains, tubes or trams, the train door system (TDS) is one of the systems bound to malfunction most frequently (about 30%). This malfunction delays t he train/tube/tram and possibly even immobilize it. To decrease this ratio, an experimental test bench was designed at the 1:1 scale. Our objective by using this example is to present a preliminary investigation with a set of U 0= 5 main factors:  X  X 1 , passenger load, with I = 3 levels (no load and two other load levels),  X  X 2 , cant, with J = 3levels(  X  7  X  ,0  X  and 7  X  ),  X  X 3 , passenger pushing, with K = 3 levels (no pushing and two other levels of pushing),  X  X 4 , obstacle, with L = 2 levels (absence or presence of an obstacle preventing the door from  X  X 5 , door impact, with M = 3 levels (no impact and two other levels of impact).

In the following description, a factor-level combination is a quintuplet labeled ( i, j, k, l, m ). If a full experimental design had been performed,the total number of quintuplets would have been I  X  J  X  K  X  L  X  M = 162. Since this number is obviously huge, it must be reduced, bearing in mind 3 parameters: 1) This experimental design is the fi rst phase in a four-phase development process. The second phase 2) There must be a minimal number C of open/close cycles for each quintuplet ( i,j,k,l,m )inorderto 3) Going from one quintuplet to the next one (temporally speaking) may involve several changes in
Keeping these three things in mind, we have chosen an optimal design [11,25]. First, a D-Optimal design was created using the JMP software (connectedwith SAS statistical package). For an experimental plan with U 0= 5 factors and all the interactions between two factors, JMP recommended 24 different trials. However, over the two weeks of the project, the test bench was able to perform 29 trials. Thus we added 5 trials (situated around the center of the hyperparallelepiped) in order to improve the experimental design error accuracy [13]. The order of the trials was de fi ned in order to optimize the times for maintenance operations between trials.

In the light of these 29 quintuplets ( i, j, k, l, m ), let us now consider the experimental protocol (i.e., the time description with which the 29 runs were performed). Since obstacles and impacts yield high constraints and may occur together, for a given quintuplet, all the cycles C = 160 were not disturbed, but only one cycle out of every 10 for the obstacles and one cycle out of every 20 for the impacts, resulting in one sequence of cycles without impact nor obstacle and one cycle with impact and/or obstacle. With C = 160 cycles, the 10-cycle sequence was repeated 16 times. The presence of an impact and/or an obstacle can increase the test duration by 400%, due to the need to wait 10 seconds to fully complete obstacle detection cycles.
 Our experiment resulted in an hyperparallelepipedic data structure H 0 with U 0= 5 entries and H 0= 29 cells among the H 0 max = 162 possible ones. Our experimental test bench recorded a multidimensional signal (MS), in which the main components are related to the door position and the current intensity in the door motors (thus V 0= 2 components). Because of the recording technology used and the signal dynamics, the sampling frequency is not identical for the V 0 time variables; it was 100 Hz for the door pos ition and 10 Hz for the current intensity. In addition, as explained above, due to constraints (impacts and/or obstacle), the duration of a MS is not strictly identical for all the H 0= 29 cells.

To use the notation proposed in our didactic example, each MS generic value is y 0 ijklmn,v (instead of y 0 in,v ), where a comma (,) is used to dissociate the factor and the variable. Since the number of time samples depends on the experimental combination (i.e., quintuplet i, j, k, l, m ), n runs from 1 to N 0 ijklm,v . Given that there are C = 160 open/close cycles for each hyperparallelepipedic cell h ( h = 1, H 0 ) corresponding to an existing quintuplet ( i, j, k, l, m ), the minimum and maximum MS recording durations computed over the H 0= 29 cells were, respectively, about 120 minutes and 180 minutes. The total duration of the experiment (sum of the H 0= 29 durations and the 28 test bench changes) was 10 days.

In summary, the output of the data recording stage is an hyperparallelepipedic structure H 0 featuring 5 different entries, with a non-empty cell ( i, j, k, l, m ) containing a MS with V 0= 2 components. The corresponding time data set is E 0 ijklm . We applied our 5-step procedure for a preliminary MFMV descriptive analysis with the two options considered in the previous section, namely the Arithmetic Mean/Standard Deviation/Principal Component Analysis triplet (labeled AM&amp;SD/PCA) and the Mem-bership Value Average/Multiple Correspondence Analy sis pair (MVA/MCA). There are two alternatives available to compare these two options: either present two complete fi ve-step procedures separately or present both options for each stage. To fac ilitate the compari son, we have opted for the second alternative. Cf. Table 3 for a summary. 4.1. Step 1: Data characterization
First, the time data set corresponding to each open-close cycle c ( c = 1, ... , C = 160) can be char-acterized using indicators that provide a satisfactory assessment of the TDS performance. Bombardier Transport mainly uses indicators for duration, maximal speed and current consumption. Each indicator is computed for both the opening (O) and closing (C) phases of the cycle, thus yielding:  X  the opening and closing terms (OT and CT in seconds),  X  the maximal opening and closing speed (OS and CS in m.s  X  1 ) ,  X  the motor X  X  current consumption for the opening and closing terms (the signal is integrated over time Next, it is necessary to verify that there is no time in fl uence during the execution of the C = 160 cycles for each quintuplet ( i, j, k, l, m ). To achieve this aim, each time series total duration is cut into T time windows (TW). A time segmentation with 3 windows of identical width is assumed to be suf fi cient to verify the absence of such a time effect. This segmentation choice may seem arbitrary; however, keep in mind that the main aim of the time segmentation is to not miss a temporal phenomenon, which makes T = 3suf fi cient. Let t ( t =1 ,...,T = 3) be the time index.

In the following explanation, to simplify the notation and the graphic views used in the MFMV analysis, each of the 29 MS will be labeled with subscript o instead of using quintuplet ( i, j, k, l, m ); thus, o = 1, ... , O = 29. For reasons related to the door obstacle and impact perturbations, the total number of values for which statistics will be computed is not O * C = 29*160 = 4640, but rather 4389 statistical units. (Up to this point, Matlab was used for the computations; the rest of the computations were performed with the statistical package R .)
Each pair ( o , t ) can be summarized using synthetic values. As in our didactic example, we have used two basic methods: 1) arithmetic mean ( AM ) and standard deviation ( SD ) values . In the following, uppercase and lower-2) membership value averages (MVA).
Space windowing was performed as follows. (The multiple options of this critical operation will be considered in the discussion later on.) We designed the space windowing after a careful analysis of the V 1 a = 6 histograms. If a histogram features a Laplace-Gauss pattern, 3 space windows are suf fi cient to display non-linear relationships. Otherwise, space windowing may be adapted to the salient modes and/or to the dissymmetry. Due to the possible presence of doubtful values, the windows were not designed based on the values of the minimum, maximum and arithmetic mean but as follows. Since the histograms for CT, OT, OC and CC variables were not too far from a Laplace-Gauss distribution, we built the medium window around the trimmed mean with p = 1% fraction. The left side of the left window starts decreasing at the 1 st percentile and the right side of the right window stops increasing at the 99 th percentile. The same principle was applied for the two modal areas (i.e., variables OS and CS), with the center of the modal area being selected manually. For OC and CC variables, which present one frequent modal area and two much less frequent modals areas, three space windows were considered. Figure 5, shows the V 1 a = 6 histograms and the S = 20 space membership functions. In summary, the hyperparallelepipedic structure H 0 with 5 entries, yields a similar structure, H 1 , the generic data piece corresponding to a time window t instead of a cycle c . 4.2. Step 2: Data coding The data sets were coded using the usual standardization technique so that the traditional normalized PCA could be performed. In summary H 1 yields H 2 , the hyperparallelepipedic data structure is kept. 4.3. Step 3: Data table building
In order to demonstrate the in fl uences of the 6 basic factors  X  i, j, k, l, m and t  X  many two entry-tables can be plotted, depending upon the way the factors are combined (Only one single factor, 2 by 2, ... ). We fi rst consider tables Y3 OxT and Y3 X  OxT (Cf. Table 4) and then, given the large number of factors, we factor), with T = 3levels. 4.4. Step 4: Ddata table analysis
We focus fi rst on tables where the rows and columns are implied in the building up of the main axes (i.e. tables Y3 OxT (87,12) for PCA and Y3 X  OxT (87,20) for MCA) PCA of Y3 OxT yields 4 main axes with 41%, 21%, 15% and 8% variance percentages (the following values are much lower). Since the fi rst 2 axes have much higher variation than the next two axes (62% vs. 23%), only the plane spanned by axes 1 and 2 will be considered. As shown in Fig. 6a, the fi rst major component is mainly controlled by the 8 variables linked to the speed and current indicators (i.e., both the maximum opening and closing speeds and both the arithmetic mean and standard deviation indicators). Keeping in mind the relative positions of these 8 column points, a fi rst result is that trials 13 to 17 present the highest values for the variables corresponding to 4 arithmetic means and 4 standard deviations (Fig. 6b). The opposite holds true for trial 27 and 29. The second axis is mainly positioned by variables linked to the time indicators, yielding trial 22 with 4 high values, for instance.

MCA of Y3 X  OxT yields 4 main axes with 38%, 19%, 14% and 9%.information percentages. Again, only the plane spanned by axes 1 and 2 will be considered. As shown in Fig. 7a, the fi rst axis is mainly controlledbySW 3 and 4 for variables OS and CS (i.e., maximal speed linked to opening and closing phases), SW 1 for CT (closing time) and SW 3 for CC (i.e., current for closing phase). Just as in mechanics, given the MCA barycentric principle [4], the lower the membership function for a space window, the higher its distance from the gravity center, which explains why OS4 and CS4 are very far way from the gravity center (such window mainly occurs with trials 13 to 17, Fig. 7b). To summarize, axis 1 mainly opposes trials with low values for OC and CC (on the left side) to trials with high values for OS, CS and CT (on the right side). The multivariate combination in which OS, CS and CT are high is mainly to be found for trials 13 to 17. There is no obvious time in fl uence, Fig. 6b, as can be seen in Fig. 6b.

We now focus on tables where the rows and columns are not involved in the building up of the main axes but allow to show the in fl uences of factor j and t (i.e. tables Y 3 JxT (9,12) for PCA and Y 3 X  JxT (9,20) for MCA). In light of the respective positions of the J  X  T =3  X  3=9 supplementary row points, Figs 6b and 7b, the time factor has no in fl uence and cant factor appears to have an intermediate effect (for factor j , a null effect would be shown with J = 3 points very close to the gravity center, and a great effect would be shown with points very far away from the gravity center. 4.5. Step 5: Results presentation
PCA and MCA yield two main kinds of outputs  X  graphic (bi-dimensional plots) and numerical tables (eigen-values, relative contributions and square cosines)  X  where each kind of output involves three rather lengthy analyses:  X  The column points projection onto a series of bi-dimensional plots (crossing of the main axes  X  The row points projection onto a series of bi-dimensional plots; and  X  The matching of both two result sets.

In addition to being time-consuming, these analyses yield rather complex graphic and textual results, including texts interpreting the plots and tables. This complexity is due to the MFMV aspect, as well as space windowing in MCA.

In order to complete the data exploration phase with more concrete results for the user (i.e., the train engineers), two main kinds of results can be plotted: 1) the relationships between the variables and 2) the factor effects. Choosing a speci fi c graphic view for each kind of result is not an easy task because PCA and MCA highlight relatively different results. On the one hand, the relative position of the V 2= 12 variable-points in the PCA results (Fig. 6a) shows that speed indicators are not linked (linearly) to time indicators; on the other hand, the position of the space window points in the MCA results (Fig. 7a) shows that there are some local correspondences (e.g., between CT1 and CS3). Figures 8a and 8b con fi rm the PCA result generally speaking, but Fig. 8b con fi rms the MCA result locally.
Let us now consider another example related to the second kind of results, the factor effects. According to the fi rst principal component, the relative positions of the O = 29 trial points highlight two subgroups: trials 13 to 17 and the rest (Figs 6b and 7b). Let us examine the 5 trials in the fi rst subgroup as compared to trial 29 in the second subgroup, which, according to axis one, h as an opposing pos ition in both the PCA and MCA. Again, Fig. 9a con fi rms the PCA result globally (all the fi ve trials are quite different from trial 29), but Fig. 9a also con fi rms the MCA result locally (among the 5 trials, trials 16 and 17 feature higher maximum speeds than trials 13, 14 and 15). In addition, Fig. 9b con fi rms the PCA and MCA results related to the fairly low impact of the cant factor.
 5. Discussion
Despite the fact that the two examples considered above are completely different, the two respective studies have focused on a identical generic quintuplet of data analysis elements: 1) Characterizing the multidimensional signals (MS) through analysis variable s,2) Coding the analysis variables,3) Organizing the two-entry tables, 4) Highlighting the effects of the factors on the variables and/or the relationships between the variables through data analysis, and 5) Representing the results using easy-to-read graphs and/or tables. Obviously, this data analysis quintuplet (DAQ) can be used for both descriptive and inferential statistics. From an Intelligent Data Analysis point of view, let us fi rst focus on the reasons to consider descriptive statistics before embarking on inference statistics. 5.1. Descriptive analysis prior to inference analysis
Conceiving and executing an experimental design is a long and complex task. Thus, as soon as all the time data sets have been recorded, the researchermay be in a hurry to test the statistical hypothesesthat the experiment was primarily designed to test. Nevertheless, faced with a large experimental database H 0  X  yields a large MS  X  an interface procedure must be designed between the initial hyperparallelepipedic structure H 0 and the two-entry table structure Z inf required by most inferential methods. In most cases, the C columns in the tables correspond to the factors and the variables and the R rows to the experimental combinations. For instance, with our second example, how would it be possible to convert H 0 with 5 entries, H 0= 29 tested combinations and V 0= 2 components per MS into a Z inf table with R rows and C columns in order to conduct a variance analysis?
Among the many possibilities, one solution would consist in the following procedure: In the usual case of the mono-variate variance analysis (ANOVA) in which the time factor is completely removed from the analysis, the R rows could correspond to the H 0 non-empty cells (the trials) and the C columns to the U 0= 5 experimental factors, plus one variable (the one being studied); thus, R = H 0 and C = U 0+1 [22]. If the variables originate from a signal spectrum analysis with F frequency windows, many other H 0 / Z inf adaptation solutions are conceivable, especially if it is kept in mind that, during the characterization step, either only one overall time window ( T =1 ) or several time windows ( T&gt; 1 ) can be considered for each MS.

Thus, generally speaking, the main dif fi culty is that, regardless of whether each MS is stationary or not, there are many ways to characterize it. In our example, each MS signal includes 160 cycles, which may evolve over time between the fi rst and the 160 th cycle, despite the fact that 160 is very small given the millions of open-close cycles in the 30-year lifetime of a door system. With the presence of U 0=5 factors and V 0= 2 MS components, we agree that, as suggested by such statisticians as Tukey or Benzecri, the primary analysis must be MFMV descriptive, even if it means testing more than one DAQ, which may contain several loops, especially if outliers have been highlighted (see below).
Given the multiple ways to characterize each MS component, the number o f choices can be reduced if the indicators are kept closely linked to the conditions schedule. In our mechatronics example, these conditions include the door opening and closing times, the maximal opening and closing speeds and the current consumption for the two parts of the cycle. These variables being chosen, we suggest two approaches to continue this characterization step:  X  Computing the traditional arithmetic mean and standard deviation indicators and investigating the  X  Performing space windowing, computing membership value averages and investigating the resulting
Being aware that there are many different ways to de fi ne Data Analysis [4,18,27,40], a fi rst main advantage of considering descriptive analysis before inference analysis with time data is the possibility to see each statistical unit of the empirical study as one point (at least) within a large space. With time data, a statistical unit may run from one time sample (as with the fi rst example or any observation of a time series) to the MS itself (as with the second example), including all possibilities between these two extreme such as a set of MS time windows (as with the second example). The large space comes from the combination of indicators used to depict each statistical unit.

A second main bene fi t of considering descriptive analysis prior to inference analysis featuring time data is the possibility to test, fairly quickly, very different 5-step procedures (as the two mentioned just above or hierarchical clusteri ng procedures). Of cour se, this possibility is also to be found with the inference analysis but, due to the will to obtain the hypothesis test outputs ASAP once the empirical study data sets have been obtained, only one 5-step procedure is often performed. The most often encountered example is the use of ANOVA to assess the factors X  effects on variables, whatever the data origin: from an experimental or observational design. Given the widespread use of this method in Step 4 of our 5-step procedure, no to mention the data analysis probl em in steps 1 and 2 and the probabilistic hypotheses related to ANOVA, variance analysis might have to be adequately renamed variance processing !
To go further in our discussion, given the two advantages to start data analysis using a descriptive approach, let us compare the two procedures tested in this paper. 5.2. Comparison AM&amp;SD/PCA vs. MVA/MCA
The fi rst didactic example (Cf. Section 3), which corresponds to a simplistic situation,  X  X learly highlights the advantages of using a space windowing: Anscombe X  X  4 bivariate sets yield 4 identical sets using the standard summary indicators (see [2] for other summary indicators), which is not the case with the MVA sets (Table 3). On the other hand, the fi rst main disadvantage of space windowing-based characterization must be acknowledged: it can potentially take a lot of CPU time to obtain the membership values. This disadvantage becomes increasingly crucial if numerous variables are present (e.g., several tens) and each variable has many values (e.g., several thousands). For instance, using a PowerMAC with 2  X  2.8 Ghz Quad-Core Intel Xeon with statistical package R , for a variable with 10 4 values (simulated using a Laplace-Gauss model) and 3 fuzzy space windows, computing 3 MVA requires about TC MVA = 6 s and the pair arithmetic mean/standard deviation takes about TC AM &amp; SD = 0.1 s .The latter time was obtained from R functions using C ++ programs, and the former time was obtained from R commands. This means that a C ++ program would probably require much less value for TC MVA .Of course, for both examples, TC AM &amp; SD and TC MVA are almost null.

A second main disadvantage comes from the dif fi culty of performing space segmentation. For this aspect, if many windowing practical techniques exist [3,21,27,31], remember that Anscombe X  X  sets were primarily designed to emphasize the following idea: Before computing any statistical summary, it is worth displaying the data with speci fi c graphs. Thus, the histogram, which belongs to the speci fi cgraph set, should be seen as a suitable tool for space windo wing (and of course for s howing outlie rs). A lthough, as suggested in Fig. 1, a simple segmentation with 3 fuzzy space windows can give signi fi cant results (see Fig. 2), more sophisticated windows may be drawn using the histogram pattern.

For this more sophisticated segmentation, let us fi rst consider analysis time TA MVA , which is a sum of times needed to complete the following two phases:
Phase 1  X  To analyze the histograms, especially a) The ranges in relation to the physical functioning
Phase 2  X  To choose the window patterns according to the histogram and/or any knowledge of the
The space segmentation choices must be made in light of the following considerations:  X  a data item may belong to either one space window (i.e., crisp windowing, which yields frequency  X  a small number of space windows probably means 1) A large information loss but may yield robust  X  Space windowing can be performed using either purely mathematical criteria (e.g., identical widths
Sinceitisratherdif fi cult to generalize space windows design, let us use our second example to carry out the two space windowing phases described above. First, some histograms featured doubtful data, for example, the duration histograms for CT and OT, which displayed very low values (less than 1 s )on the left side, were not really consistent with the speci fi cation value (3.5 s ). One of the reasons for such outliers was software development errors; The software was developed by the door supplier, with the time computations coming from a  X  X lack box X . To remove irrelevant values, we have chosen to back-up OT, CT, OS and CS using our own sensor and not the supplier X  X . Now, OT, CT OS and CS are computed based on the derivation of the door position signal, instru mented by a pos ition sen sor on each door leaf.
Once this outlier problem was s olved, even though each variable v ( v = 1, ... , V 1= 6) contains rather numerous values (about 160*29), the fi nal number of empirical situations that were studied was very small (29 trials). Thus using only 3 fuzzy windows is suf fi cient for a distribution like the Laplace-Gauss one. If there is more than one modal area, the space windows can be adjusted around these areas.
In our second mechatronic example, analysis time TA MV A was about 2h, and TA AM &amp; SD is null. For the second case we have assumed that, like many cases containing empirical quantitative data, we merely had to compute the arithmetic mean and standard deviation without mentioning the data characterization issue. In a nutshell, with our mechatronic example, the DAQ times can be roughly evaluated as follows: In term of time constraint, the comparison AM&amp;SD vs. MVA yields the fi rst one as the best characteri-zation method. Similarly, the PCA vs. MCA comparison outputs the fi rst one as an easier MFMV data analysis method. This is due to the presence of V variable points only instead of V space window point trajectories . Although inte rpreting the respective positions of th e MCA points is muc h more complex an phenomena.

At the end of Section 5.1, we have mentioned different aspects as regards data analysis .Ifwenow focus more on intelligent data analysis , the authors X  point of view is that performing simply the usual standardization consisting in translating the scale around the arithmetic mean and dividing the scale by the standard deviation (Some statistical packages only propose this procedure), is considered less intelligent than performing a scale windowing consisting in watching carefully the histograms fi rst. That is why, in a descriptive intelligent data analysis context, our 5-step procedure is better with the MVA/MCA option than the AM&amp;SD/PCA one. Furthermore, it is worth noting that space windowing features many convenient options such as a bivariate space windowing with signals recorded either in relation to images (e.g. eye movement when looking at an ad [27]) or dynamic system analysis (e.g. a signal and its fi rst derivative). In addition, it is worth noting that if both quantitative and qualitative variables are present, both can be investigated into simultaneously.

Finally, the fuzzy windowing concept can be used with both space and time scales, Fig. 10. For instance with S = 3 space windows and T = 5 time windows, instead of computing S MVA within a rectangular window t (As in our mechatronic system), S weighted MVA can be computed, the weight corresponding to the time membership value to a time window. With this generalization, if one keeps in mind that, in most cases, there is not only one time variable recorded during one empirical situation (as in Fig. 10), but several time variables recorded during many situations (e.g. many multidimensional signals or multivariate time series), space windowing can be adapted either to the variable v  X  Locally, i.e. adapted to v and the empirical situation(s) (e.g. human being(s) in a human component 6. Conclusion
Given a large MFMV database containing complex time data, we have demonstrated that several DAQ are available, each one providing a different kind of  X  information  X . The number of DAQs increases (several tens) if one combines approaches proposed by fi elds such as statistics, data mining, signal analysis, pattern recognition or arti fi cial intelligence (with quite the same objectives but different names for DAQ) [17,18,20,22,32] stages. For instance what we call data characterizing is often named data pre-processing in data mining [17] and feature selection in pattern recognition [32]).

Indeed, starting a DAQ using the AM/SD pair will not contain the same information as with starting a DAQ using the MVA n-uplet (And comparing these two indicator sets may be irrelevant!), the two examples considered in this article have shown that, for the preliminary analysis, it is better to use a space windowing based procedure based: The fi rst example, which comes from an often mentioned didactic example [2], exhibits that two very different data sets may yield the same AM/SD pair but different MVA n-uplets (Of course this example may be seen as a caricature), and the second example, which comes from a complex mechatronic system, shows that MVA can characterize the histogram better than an AM/SD pair.

Furthermore, if it is noticed that is many cases, only the AM indicator being considered, MVA n-uplet based DAQ is now much better, still in a preliminar y analysis, even though the segmentation process is rather time consuming and dif fi cult. Nevertheless, as shown in our examples, it may be worthwhile testing several descriptive DAQ via the singular value breakdown principle  X  such as Principal Component Analysis, Correspondence Analysis or all the derivative methods  X  in which supplementary points can be used to show the factor in fl uences, whether the research is an experimental or observational design.
Since this preliminary analysis also helps highlight doubtful data, it makes the data itself and the results of the data analysis quite trustworthy, and the data can be used without hesitation in subsequent analyses involving more local studies, such as inference tests of factors in fl uences performed variable per variable.

For an industrial company like Bombardier Transportation , this study permits a better knowledge of the door system (including measurement device performance). These results can help door system engineers and reliability engineers better understa nd the numerous problems c ropping up during design and exploitation. In order to solve operational failures more ef fi ciently and to negotiate a better contract with the supplier of future doors, such experimental design/MFMV descriptive analysis is therefore essential.
 Acknowledgements
This research was funded by Bombardier Transport, the International Campus on Safety and Inter-modality in Transportation, the Nord/Pas-de-Calais Region, the European Community, the Regional Del-egation for Research and Technology, the Ministry of Higher Education and Research, and the National Center for Scienti fi c Research. The authors gratefully ackno wledge the support of these institutions. References
