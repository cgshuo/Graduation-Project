 In this paper, we propose feature subset non-negative matrix factorization (NMF), which is an unsupervised approach to simultaneously cluster data points and select important fea-tures. We apply our proposed approach to various document understanding tasks including document clustering, summa-rization, and visualization. Experimental results demon-strate the effectiveness of our approach for these tasks. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval.
 General Terms: Algorithms, Experimentation.
 Keywords: Feature subset selection, NMF. Keyword (Feature) selection enhances and improves many IR tasks such as document categorization, automatic topic discovery, etc. Many supervised keyword selection tech-niques have been developed for selecting keywords for clas-sification problems. In this paper, we propose an unsuper-vised approach that combines keyword selection and docu-ment clustering (topic discovery) together.

The proposed approach extends non-negative matrix fac-torization (NMF) by incorporating a weight matrix to indi-cate the importance of the keywords. This work considers both theoretically and empirically feature subset selection for NMF and draws the connection between unsupervised feature selection and data clustering.

The selected keywords are discriminant for different topics in a global perspective, unlike those obtained in co-clustering, which typically associate with one cluster strongly and are absent from other clusters. Also, the selected keywords are not linear combinations of words like those obtained in La-tent Semantic Indexing (LSI): our selected words provide clear semantic meanings of the key features while LSI fea-tures combine different words together and are not easy to interpret. Experiments on various document understanding applications demonstrate the effectiveness of our proposed approach.

Optimizing Eq.(1) with respect to F is equivalent to op-timizing obtain the following updating formula First of all, we examine the clustering performance of FS-NMF using four text datasets as described in Table 1, and compare the results of FS-NMF with seven widely used document clustering methods: (1) K-means; (2) PCA-Km: PCA is firstly applied to reduce the data dimension fol-lowed by the K-means clustering; (3) LDA-Km [2]: an adap-tive subspace clustering algorithm by integrating linear dis-criminant analysis (LDA) and K-means; (4)Euclidean co-clustering (ECC) [1]; (5) minimum squared residueco-clustering (MSRC) [1]; (6) Non-negative matrix factorization (NMF) [5]; (7) Spectral Clustering with Normalized Cuts (Ncut) [9]. More description of the datasets can be found in [6]. The accuracy evaluation results are presented in Figure 2.
From the results, we clearly observe that FS-NMF out-performs other document clustering algorithms in most of the cases, and the effectiveness of FS-NMF for document clustering is demonstrated.
In this set of experiments, we apply our FS-NMF algo-rithm on document summarization. Let X be the document-sentence matrix, which can be generated from the document-term and sentence-term matrices, and now each feature (col-umn) in X represents a sentence. Then the sentences can be ranked based on the weights in W . Top-ranked sen-tences are included into the final summary. We use the DUC benchmark dataset (DUC2004) for generic document summarization to compare our method with other state-of-art document summarization methods using ROUGE eval-uation toolkit [7]. The results are demonstrated in Table 3.
