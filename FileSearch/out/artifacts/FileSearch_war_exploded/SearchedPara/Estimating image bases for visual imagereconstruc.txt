 The image basis is a key concept for understanding neural representation of visual images. Using image bases, we can consider natural scenes as a combination of simple elements corresponding to neural units. Previous works have shown that image bases similar to receptive fields of simple cells are learned from natural scenes by the sparse coding algorithm [4, 9]. A recent fMRI study has shown that visual images can be reconstructed using a linear combination of multi-scale image bases (1x1, 1x2, 2x1, and 2x2 pixels covering an entire image), whose contrasts were predicted from the fMRI activity pattern [6]. The multi-scale bases produced more accurate reconstruction than the pixel-by-pixel prediction, and each scale contributed to reconstruction in a way consistent with known visual cortical representation. However, the predefined shapes of image bases may not be optimal for image reconstruction.
 Here, we developed a method to automatically extract image bases from measured fMRI responses to visual stimuli, and used them for image reconstruction. We employed the framework of canonical correlation analysis (CCA), in which two multi-dimensional observations are related via a common coordinate system. CCA finds multiple correspondences between a weighted sum of voxels and a weighted sum of pixels. These correspondences provide an efficient mapping between the two observations. The pixel weights for each correspondence can be thought to define an image basis. As the early visual cortex is known to be organized in a retinotopic manner, one can assume that a small set of pixels corresponds to a small set of voxels. To facilitate the mapping between small Figure 1: Model for estimating image bases. (a) Illustration of the model framework. The visual image I (pixels) and an fMRI activity pattern r (voxels) is linked by latent variables z . The links from each latent variable to image pixels define an image basis W I , and the links from each latent variable to fMRI voxels is called a weight vector W r . (b) Graphical representation of the model. Circles indicate model parameters to be estimated and squares indicate observations. The matrices W
I and W r , the common latent variable z , and the inverse variances I and r are simultaneously estimated using the variational Bayesian method. Using the estimated parameters, the predictive distribution for a visual image given a new brain activity pattern is constructed (dashed line). sets of pixels and voxels, we extended CCA to Bayesian CCA [10] with sparseness priors. Bayesian CCA treats the multiple correspondences as latent variables with two transformation matrices to two sets of observations. The transformation matrix to the visual image can be regarded as a set of image bases. The matrices are assumed to be random variables with hyper-parameters. We introduced a sparseness prior into each element of the matrices, such that only small subsets of voxels and pixels are related with non-zero matrix elements.
 The Bayesian CCA model was applied to the data set of Miyawaki et al. [6]. We show that spa-tially localized image bases were extracted, especially around the foveal region, whose shapes were similar to those used in the previous work. We also demonstrate that the model using the estimated image bases produced accurate visual image reconstruction. We constructed a model in which a visual image is related with an fMRI activity pattern via latent variables (Figure 1). Each latent variable has links to a set of pixels, which can be regarded as an image basis because links from a single latent variable construct an element of a visual image. The latent variable also has multiple links to a set of fMRI voxels, which we call a weight vector. This model is equivalent to CCA: each latent variable corresponds to a canonical coefficient [3] that bundles a subset of fMRI voxels responding to a specific visual stimulus. We then extended the CCA model to the Bayesian CCA model that can conduct a sparse selection of these links automatically. 2.1 Canonical Correlation Analysis We first consider the standard CCA for estimating image bases given visual images I and fMRI activity patterns r . Let I be an N 1 vector and r be a K 1 vector where N is the number of image pixels, K is the number of fMRI voxels and t is a sample index. Both data sets are and v 1 are called the first canonical variables and the vectors a 1 and b 1 are called the canonical by maximizing the correlation of u 2 and v 2 while the second canonical variables are orthogonalized to the first canonical variables. This procedure is continued up to a pre-defined number of times M . The number M is conventionally set to the smaller dimension of the two sets of observations: in our case, M = N because the number of visual-image pixels is much smaller than that of the fMRI voxels ( N&lt;K ). The M sets of canonical variables are summarized as where u ( t ) and v ( t ) are M 1 vectors, A is an M N matrix, and B is a M K matrix. The matrices A and B are obtained by solving the eigen problem of the covariance matrix between I and r [1]. The visual image can be reconstructed by where each column vector of the inverse matrix A 1 is an image basis. 2.2 Bayesian CCA Bayesian CCA introduces common latent variables that relate a visual image I and the fMRI ac-tivity pattern r with image basis set W I and weight vector set W r (Figure 1 (b)). These variables are treated as random variables and prior distributions are assumed for each variable. Hyper-prior distributions are also assumed for an inverse variance of each element of the image bases and the weight vectors. The image bases and the weight vectors are estimated as a posterior distribution by the variational Bayesian method [2]. After the parameters are determined, a predictive distribution for the visual image can be calculated.
 We assume two likelihood functions. One is for visual images that are generated from latent vari-ables. The other is for fMRI activity patterns that are generated from the same latent variables. When observation noises for visual images and fMRI voxels are assumed to follow a Gaussian dis-tribution with zero mean and spherical covariance, the likelihood functions of the visual image I and the fMRI activity pattern r are where W I is an N M matrix representing M image bases, each of which consists of N pixels, W r is a K M matrix representing M weight vectors, each of which consist of K voxels, z ( t ) is an M 1 vector representing latent variables, 1 I and 1 r are scalar variables representing unknown noise variances of the visual image and fMRI activity pattern, and T is the number of observations. The latent variables are treated as the following Gaussian prior distribution, The image bases and weight vectors are regarded as random variables, and the prior distributions of them are assumed as, which are assumed to be mutually independent.
 We also assume hyper-prior distributions for the inverse variances I ( n;m ) and r ( k;m ) , where G ( j ; ) represents the Gamma distribution with mean and confidence parameter . For our analysis, all the means I ( n;m ) and r ( k;m ) were set to 1 and all the confidence parameters This configuration of the prior and hyper-prior settings is known as the automatic relevance deter-mination (ARD), where non-effective parameters are automatically driven to zero [7]. In the current case, these priors and hyper-priors lead to a sparse selection of links from each latent variable to pixels and voxels.
 Prior distributions of observation noise are assumed as non-informative priors, which are described by the observation noise, 2.3 Parameter estimation by the variational Bayesian method ables and variance parameters, Since the joint posterior distribution cannot be calculated analytically, we approximate it using a trial distribution based on the variational Bayesian (VB) method [2]. In the VB method, a trial distribution Q ( W I ; W r ; z ; I ; r ; I ; r ) with the following factorization is assumed, of the image bases Q w ( W I ) is derived as where and N ( x j x; 1 ) represents a Gaussian distribution with mean x and variance 1 . The trial distri-and N with K in Eqs. (15-17). The trial distribution of the latent variables Q z ( z ) is obtained by where In Eq. (20), E is an identity matrix, and w I and w r are defined as Finally, the distribution of the inverse variances Q ( I ; r ; I ; r ) is further factorized into Q ( The expectation of I ( n;m ) is given by and that of I is given by
I = NT The expectations of Q ( r ) and Q ( r ) are obtained in a similar way, by replacing I with r , n with k , and N with K in Eq. (23) and Eq. (24), respectively. The expectations of these distributions 3) Q ( expectation of Q ( W I ) . 2.4 Predictive distribution for visual image reconstruction Using the estimated parameters, we can derive the predictive distribution for a visual image I new given a new brain activity r new (Figure 1 (b), dashed line). Note that I new and r new were taken from the data set reserved for testing the model, independent of the data set to estimate the model distribution of latent variables P ( z new j r new ) as follows, Because the multiple integral over the random variable W I and z new is intractable, we replace the random variable W I with the estimated image bases W I to vanish the integral over W I . Then the predictive distribution becomes where ting the terms related to the visual image in Eqs. (18) -(20), where Finally, the predictive distribution is obtained by where 2.5 fMRI data We used the data set from Miyawaki et al. [6], in which fMRI signals were measured while subjects viewed visual images consisting of contrast-defined 10 10 patches. The data set contained two independent sessions. One is a  X  X andom image session X , in which spatially random patterns were were presented for each subject. The other is a  X  X igure image session X , in which alphabetical letters and simple geometric shapes were sequentially presented for 12 s followed by a 12 s rest period. Five alphabetical letters and five geometric shapes were presented six or eight times per subject. We used fMRI data from V1 for the analyses. See Miyawaki et al. [6] for details. We estimated image bases and weight vectors using the data from the  X  X andom image session X . Then, reconstruction performance was evaluated with the data from the  X  X igure image session X . 3.1 Estimated image bases Figure 2 (a) shows representative image bases estimated by Bayesian CCA (weight values are in-dicated by a gray scale). The estimation algorithm extracted spatially localized image bases whose shapes were consistent with those used in the previous study [6] ( 1 1 , 1 2 , and 2 1 shown in 1st and 2nd row of Figure 2 (a)). We also found image bases with other shapes (e.g., L-shape, 3 1 and 1 3 , 3rd row of Figure 2 (a)) that were not assumed in the previous study. We repeated the estimation using data resampled from the random image session, and calculated the distribution of the image bases (defined by a pixel cluster with magnitudes over 3 SD of all pixel values) over eccentricity for different sizes (Figure 2 (a), right). The image bases of the smallest size ( 1 1 ) were distributed over the visual field, and most of them were within three degrees of eccentricity. The size of the image basis tended to increase with eccentricity. For comparison, we also performed the image basis estimation using CCA, but it did not produce spatially localized image bases (Fig-ure 2 (b)). Estimated weight vectors for fMRI voxels had high values around the retinotopic region corresponding the location of the estimated basis (data not shown). 3.2 Visual image reconstruction using estimated image bases The reconstruction model with the estimated image bases was tested on five alphabet letters and five geometric shapes (Figure 3 (a), 1st row). The images reconstructed by Bayesian CCA captured the essential features of the presented images (Figure 3 (a), 2nd row). In particular, they showed fine the peripheral reconstruction was poor and often lacked shapes of the presented images. This may be due to the lack of estimated image bases in the peripheral regions (Figure 2 (a), right). The standard CCA produced poorer reconstruction with noise scattered over the entire image (Figure 3 (a), 3rd row), as expected from the non-local image bases estimated by CCA (Figure 2 (b)). Reconstruction using fixed image bases [6] showed moderate accuracy for all image types (Figure 3 (a), 4th row). To evaluate the reconstruction performance quantitatively, we calculated the spatial correlation between the presented and reconstructed images (Figure 3 (b)). The correlation values (a) Estimated image bases by Bayesian CCA (b) Estimated image bases by CCA Figure 2: Image basis estimation : (a) Representative bases estimated by Bayesian CCA (left, sorted by the number of pixels), and their frequency as a function of eccentricity (right). 3-pixel bases (L-shape, 3x1 and 1x3) were not assumed in Miyawaki et al. [6]. Negative (dark) bases were often associated with negative voxel weights, thus equivalent to positive bases with positive voxel weights. (b) Examples of image bases estimated by the standard CCA. were not significantly different between Bayesian CCA and the fixed basis method when the alphabet letters and the geometric shapes were analyzed together. However, Bayesian CCA outperformed the fixed basis method for the alphabet letters, while the fixed basis method outperformed Bayesian CCA for the geometric shapes ( p&lt;: 05 ). This is presumably because the alphabet letters consist of more foveal pixels, which overlap the region covered by the image bases estimated by Bayesian CCA. The reconstruction performance of CCA was lowest in all cases. We have proposed a new method to estimate image bases from fMRI data and presented visual stimuli. Our model consists of the latent variables and two matrices relating the two sets of obser-vations. The previous work used fixed image bases and estimated the weights between the image bases and fMRI voxels. This estimation was conducted by the sparse logistic regression that as-sumed sparsenes in the weight values, which effectively removed irrelevant voxels [8]. The proposed method introduced sparseness priors not only for fMRI voxels but also for image pixels. These pri-ors lead to automatic extraction of images bases, and the mappings between a small number of fMRI voxels and a small number of image pixels. Using this model, we successfully extracted spatially localized image bases including those not used in the previous work [6]. Using the set of image bases, we were able to accurately reconstruct arbitrary contrast-defined visual images from fMRI activity patterns. The sparseness priors played an important role to estimate spatially localized im-age bases, and to improve reconstruction performance, as demonstrated by the comparison with the results from standard CCA (Figure 2 and 3).
 Our method has several limitations. First, as the latent variables were assumed to have an orthogo-nal Gaussian distribution, it may be difficult to obtain non-orthogonal image bases, which have been Figure 3: Visual image reconstruction : (a) Presented images (1st row, alphabet letters and geo-metric shapes) and the reconstructed images obtained from Bayesian CCA, the standard CCA, and the fixed basis model (2nd -4th rows). (b) Spatial correlation between presented and reconstructed images. shown to provide an effective image representation in the framework of sparse coding [4,9]. Differ-ent types of image bases could be generated by introducing non-orthogonality and/or non-lineality in the model. The shape of estimated image bases may also depend on the visual stimuli used for the training of the reconstruction model. Although we used random images as visual stimuli, other types of images including natural scenes may lead to more effective image bases that allow for ac-only poor reconstruction was achieved for peripheral pixels. The cortical magnification factor of the visual cortex [5] suggests that a small number of voxels represent a large number of image pixels in the periphery. Elaborate assumptions about the degree of sparseness depending on eccentricity may help to improve basis estimation and image reconstruction in the periphery.
 Acknowledgments This study was supported by the Nissan Science Foundation, SCOPE (SOUMU) and SRPBS (MEXT). [1] Anderson, T.W. (2003). An Introduction to Multivariate Statistical Analysis. 3rd ed. Wiley [2] Attias, H. (1999). Inferring parameters and structure of latent variable models by variational [3] Bach, F.R. and Jordan, M.I. (2005). A probabilistic interpretation of canonical correlation anal-[4] Bell, A.J. and Sejnowski, T.J. (1997) The independent components of natural scenes are edge [5] Engel, S.A., Glover, G.H. and Wandell, B.A. (1997) Retinotopic organization in human visual [6] Miyawaki, Y., Uchida, H., Yamashita, O., Sato, MA., Morito, Y., Tanabe, HC., Sadato, N. and [7] Neal, R.M. (1996). Bayesian learning for Neural Networks. Springer-Verlag. [8] Yamashita, O., Sato, MA., Yoshioka, T., Tong, F., Kamitani, Y. (2008) Sparse estimation au-[9] Olshausen ,B.A. and Field, D.J. (1996). Emergence of simple-cell receptive field properties by [10] Wang, C. (2007). Variatonal Bayesian Approach to Canonical Correlation Analysis. IEEE
