 The rapid growth of data generated and stored has led us to the new era of Big Data [3, 4, 14, 18, 19]. Nowadays, we are surrounded by different types of big data, such as enterprise data, sensor data, machine-generated data and social data. Extracting valu-able information and insightful knowledge from big data has become an urgent need in many disciplines. In view of this, big data analytics [3, 4, 14, 18, 19] has emerged as a novel topic in recent years. This technology is particularly important to enterpris-customers and make more intelligent decisions. Due to its high impact in many areas, more and more systems and analytical tools have been developed for big data analyt-However, to the best of our knowledge, no existing studies have incorporated the concept of utility mining [2, 6, 7, 8, 11, 12, 13] into big data analytics. 
Utility mining is an important research topic in data mining. The main objective of one of the most important tasks in utility mining, which can be used to discover sets of items carrying high utilities (e.g., high profits). This technology has been applied to bioinformatics . Due to its wide range of applications, many studies [2, 6, 7, 8, 11, 12, 13] have been proposed for mining HUIs in databases. However, most of them as-the mining tasks. However, in big data environments, data may be originated from different sources and highly distributed. A large volume of data also makes it difficult the applications of big data.  X  
Although mining HUIs from big data is very desirable for many applications, it is a challenging task due to the following problems posed: First, due to a large amount of transactions and varied items in big data, it would face the large search space and the combination explosion problem. This leads the mining task to suffer from very expen-sive computational costs in practical. Seco nd, pruning the search space in HUI mining pruning techniques developed for frequent pattern mining cannot be directly trans-ciently processed by a single machine. A well-designed algorithm incorporated with parallel programming architecture is needed. However, implementing a parallel algo-rithm involves several problematic issues, such as search space decomposition, avoid-ance of duplicating works, minimization of synchronization and communication overheads, fault tolerance and scalability problems. 
In this paper, we address all of the above challenges by proposing a new frame-work for mining high utility itemsets in big data . To our knowledge, this topic has not yet been explored. The contributions of this work are summarized as follows:  X  First, we propose a novel algorithm named PHUI-Growth ( Parallel mining High plemented on a Hadoop platform [14] and thus it inherits several nice properties from Hadoop, such as easy deployment in high level language, fault tolerance, low communication overheads and high scalability on commodity hardware.  X 
Second, PHUI-Growth adopts the MapRedu ce architecture to partition the whole mining task into smaller independent subtasks and uses HDFS ( Hadoop Distri-buted File System ) to process distributed data. Thus, it can parallel mine HUIs from distributed databases across multiple commodity computers in a reliable manner.  X 
Third, PHUI-Growth adopts a novel strategy called DLU-MR ( Discarding local unpromising items in MapReduce framework ) to effectively prune the search space and unnecessary intermediate itemsets produced during the mining process, which further enhances the performance of PHUI-Growth.  X 
Experimental results on both synthetic and real datasets show that PHUI-Growth outperforms the state-of-the-art algorithms developed for mining HUIs on a single machine and that it has good scalability on large-scale datasets. 
The remaining of this paper is organized as follows. Section 2 and Section 3 re-spectively introduce the basic concepts of HUI mining and related works. Section 4 presents the proposed methods. Experimental results and conclusion are presented in Section 5 and Section 6, respectively. I , ..., I N } be a finite set of distinct items . A transactional database D = { T T } is a set of transactions, where each transaction T c  X  has a unique transaction identifier c , called its TID . Each item I The external utilities of items are stored in a utility table . Every item I T An itemset X is a set of items { I 1 , I 2 ,..., I k itemset of length k is called k -itemset. X in a transaction T c  X  D is denoted as u ( X , T database D is the summation of the utilities of X in all the transactions containing X , which is denoted as u ( X ) and defined as . ) , (  X  Definition 3 (Transaction utility of a transaction). The transaction utility ( abbre-viated as TU ) of a transaction T c  X  D is the summation of the utility of each item in T which is denoted as tu ( T c ) and defined as . ) , (  X  noted as  X  and defined as ). (  X  Definition 5 (Relative utility of an itemset in a database). The relative utility of an itemset X in a database D is denoted as ru ( X ) and defined as the ratio of u ( X ) to Definition 6 (High utility itemset). Let  X  ( 0 &lt;  X   X   X  utility threshold. An itemset X is called a high utility itemset (abbreviated as HUI ) iff u ( X )  X   X  . An equivalent definition is that X is a HUI iff ru ( X ) called relative minimum utility threshold. Otherwise, X is called low utility itemset . 
Notice that the well-known downward closure property [1] does not held for the utility of itemsets. For example, {A} is low utility, but its superset {AC} is high utili-ty. As a consequence, the search space of HUI mining cannot be effectively pruned as it is done in traditional frequent itemset mining. To effectively prune the search space, the concept of transaction-weighted utilization model (abbreviated as TWU model ) [6] was proposed, which is based on the following definitions. Definition 7 (TWU of an itemset). The transaction-weighted utilization ( abbreviated containing X , which is denoted as TWU ( X ) and defined as Definition 8 (High TWU itemset). An itemset X is called high TWU itemset iff TWU ( X )  X   X  . Otherwise, X is called low TWU itemset . Definition 9 (TWU down ward closure property). The TWU downward closure property states that any superset of a low TWU itemset is low utility. By this proper-ty, the downward closure property can be applied to the TWU of itemsets for effec-tively prune the search space. The detailed proof of this property can be found in [6]. In this section, we review some studies that are related to parallel programming, HUI mining, and parallel HUI mining. 3.1 Parallel Programming Parallel programming has become a necessity for handling big data. The parallel algorithms can be generally categorized into two types: shared-memory algorithm and shared-nothing algorithm (also called distributed algorithm ) [14]. The main feature of shared-memory algorithms is that it allows all processing units to concurrently access architecture. However, the resulting algor ithms are usually not scalable enough and have their own memories to communicate with each other by passing messages. Al-designed distributed algorithm usually has better scalability. 
The message passing interface ( MPI ) is one of the most well-known framework based on shared-nothing architecture, but it works efficiently only on low-level pro-gramming languages (e.g., C and Fortran ). Nowadays, high-level programming lan-guages (e.g., Java ) have become more and more important and popular in many do-mains. Apache Foundation has developed a Jave-based open-source library named Hadoop [14] for parallel processing big data. It consists of two key services: HDFS ( Hadoop Distributed File System ) and MapReduce software . HDFS is a reliable dis-other hand, MapReduce software is designed to process vast amounts of data in paral-lel. The combination of HDFS and MapReduce software allows to parallel process large-scale datasets across multiple clusters of commodity hardware in a reliable, fault-tolerant manner. A MapReduce program consists of two stages: map stage and reduce stage . In map stage, each Mapper processes a distinct chunk of data and pro-and transformed. The transformed key-value pairs are fed to Reducers. Reducers fur-ther process these transformed pairs and then output the final or intermediate results. 3.2 High Utility Itemset Mining Extensive studies have been proposed for efficiently mining HUIs in centralized data-bases. These algorithms can be generally categorized into two types: two-phase and one-phase algorithms. The main characteristic of two-phase algorithms is that they TWU itemsets) for HUIs. In the second phase, they calculate the utility of each candi-date found in the first phase to identify HUIs. For example, Two-Phase [6], IHUP [2], phase. For example, HUI-Miner [7] is one of the state-of-the-art one-phase algo-rithms. Although these algorithms are very efficient for mining HUIs from a centra-lized database, they have not been parallelized for handling big data. 3.3 Parallel High Utility Itemset Mining In utility mining, only few preliminary studies [11, 13] have been proposed for paral-lel mining HUIs in distributed databases. Vo et al. proposed the DTWU-Mining algo-Subramanian et al. proposed the FUM-D algorithm [11] to extract HUIs from distri-buted horizontal databases. FUM-D enumerates local HUIs in each local database and two approaches are parallel HUI mining algorithms, they are not implemented in Ha-doop platform and do not integrated with the MapReduce framework. Therefore, they crashes is very small when handling big data. Therefore, DTWU-Mining and FUM-D are not reliable and practical enough for handling big data. In this section, we propose a novel algorithm named PHUI-Growth ( Parallel mining High Utility Itemsets by pattern-Growth ) for efficiently parallel mining HUIs based on Hadoop MapReduce architecture. It has three input parameters: (1) a distributed HUIs in DD . PHUI-Growth consists of three main phases: (1) counting phase , (2) PHUI-Growth. 4.1 Counting Phase The input database DD can be viewed as a set of transactions that are stored in several computers. In counting phase, the algorithm takes one MapReduce pass to parallel counts TWU of items in DD . The whole process in this phase can be divided into map stage and reduce stage. Map Stage. In map stage phase, each Mapper is fed with a transaction T I TU ( T )&gt;, called Item-TU pair . Reduce Stage. In reduce stage, Item-TU pairs outputted by Mappers are fed to Re-ducers. The Item-TU pairs having the same key are collected into the same Reducer. Let R = {&lt; I , v 1 &gt;, &lt; I , v 2 &gt;,..., &lt; I , v Reducer. The Reducer calculates TWU of I by summing up each value of a pair and outputs a key-value pair &lt; I , TWU ( I )&gt;, called Item-TWU pair . 
Fig. 1 shows the process of map and reduce stages in counting phase. In Fig.2(a), the input of the Mapper 1 is T 1 = {A, B, C, D} of Table 1. After the process, the Map-the Item-TU pairs having the same key {A} are collected into the Reducer 1. After the process, Reducer 1 outputs an Item-TWU pair &lt;{A}, 50&gt;. 4.2 Database Transformation Phase In database transformation phase, the algorithm removes all low TWU 1-itemsets from DD (Definition 7, 8 and 9) and sorts remaining items in a TWU ascending order. algorithm transforms each reorganized transaction T  X  = { I special structure called u-transaction. A u-transaction is of the form &lt; I I ( u L )&gt;, where u j is called the utility of I of utilities of all the items in T  X . 4.3 Mining Phase In mining phase, the algorithm parallel discovers HUIs through several iterations. performing a MapReduce pass. The process of this phase can be divided into two cases: (1) k = 1 and (2) k  X  2. We first explain the former case and then describe the latter case. 4.3.1 Map Stage in the First Iteration When k = 1, each Mapper is fed with a u -transaction T  X  = &lt; I ditional u-transaction. A conditional u -transaction has three fields: Prefix , PrefixUtili-fields. For UTrans field, it stores the set of items appearing after I TWU ascending order, that is, &lt; I j+1 ( u j+1 ), I j+2 is denoted as TU ( T X  ) and defined as the value in PrefixUtility field. PU of the first conditional u -transaction is 8. 4.3.2 Reduce Stage in Mining Phase In reduce stage, each Reducer is fed with a conditional u -transaction. The conditional u -transactions having the same prefix are collected into the same Reducer. Let R  X  be no less than the min_util threshold, the Reducer outputs X and its utility because X is a HUI (Definition 6). Then, the algorithm applies a proposed strategy called DLU-MR ( Discarding local unpromising items in MapReduce framework ) to further reduce the search space. The main idea of this strategy is based on the following definitions. Definition 10 (Local TWU of an item in k -th iteration). Let R  X  be the set of condi-tional u -transactions collected by a Reducer in k -th iteration, the local TWU of an item denoted as LTWU ( X , k ) and defined as )]. ( + ) ( [ Definition 11 (Local unpromising items in k -th iteration). Let R  X  be the set of con-ditional u -transactions collected by a Reducer in k -th iteration, an item is called local unpromising items in k -th iteration iff LTWU ( X , k ) &lt; Definition 12 (Local TWU downward closure property). The local TWU down-ward closure property (or simply called LTWU-DC Property ) states that LTWU ( X , k ) &lt;  X  , all the L -itemsets containing X are low utility ( L
The DLU-MR strategy is performed by scanning R  X  twice. In the first scan of R  X , the Reducer calculates local TWU of items in u -transactions of R  X . In the second scan of R  X , the Reducer removes local unpromising items in each u -transaction T  X  of R  X  and trimmed conditional u -transaction is outputted as the input of ( k+ 1)-th iteration. 4.3.3 Map-Reduce Stages in the k -th Iteration ( k  X  In the k -th iteration ( k  X  2), the algorithm takes a MapReduce pass to find all the HUIs of length k. In map stage, each Mapper is fed with a conditional u -transaction CT = &lt; X , u x , T  X &gt; produced from ( k -1)-th iteration, where X is the prefix of CT , u of CT and T  X  = &lt; I 1 ( u 1 ), I 2 ( u 2 ),..., I I in T  X  (1  X  j  X  L ), the Mapper outputs a conditional u -transaction &lt;{ X &lt; I those conditional u -transactions having the same prefix are fed to the same Reducer. Fig. 3 and Fig. 4 respectively show the running examples when k =1 and k = 2. In this section, we compare the performance of PHUI-Growth with HUI-Miner [7], a state-of-the-art non-parallel type of HUI mining algorithms. To evaluate the effec-tiveness of the DLU-MR strategy, we prepared two versions of PHUI-Growth, respec-tively called PHUI-Growth ( Baseline ) and PHUI-Growth ( DLU-MR ). We also evaluate the number of intermediate itemsets produced by the algorithms. For HUI-Miner, intermediate itemsets refers to the itemsets having an estimated utility no less than the min_util threshold. Thus, the number of intermediate itemsets produced by HUI-Miner can be regarded as that of utility-lists constructed by HUI-Miner during the mining process. For the proposed algorithms, the number of intermediate itemsets is the number of conditional u -transactions produced by Reducers during the mining All experiments were conducted on a five-node Hadoop Cluster. Each node is equipped with Intel X  Celeron X  CPU G1610 @ 2.60GHz CPU and 4 GB main memo-ry. All the algorithms are implemented in Java. Both synthetic and real datasets were which already contain unit profits and purchase quantities. Retail dataset was obtained from FIMI Repository [15]. A synthetic dataset T10I4N10K|D|2,000K was generated ternal and external utilities of items are generated as the settings of [6, 12]. In Retail and T10I4N10K|D|2,000K datasets, external utilities of items are generated between 1 generated randomly between 1 and 5, as the settings of [6, 12]. To evaluate the per-formance of the algorithms on a larger da taset, we duplicate each transaction in Chainstore five times to form a dataset named Chainstore  X  ristics of the datasets. 5.1 Performance Evaluation on Small Dataset 5(a), PHUI-Growth(Baseline) and Growth(DLU-MR) generally run slightly slower than HUI-Miner when relative min_util thresholds are higher than 0.02%. This is because that PHUI-Growth(Baseline) and Growth(DLU-MR) use five-node Hadoop Cluster to parallel process the mining tasks and they need to pass necessary data and messages across different machines via networks, which requires additional commu-nication overheads. Therefore, they take more time than HUI-Miner for high thre-sholds. However, when the threshold decreases, HUI-Miner starts to suffer from long execution time. For example, for relative min_util = 0.01%, HUI-Miner takes 4,429 seconds, while PHUI-Growth(DLU-MR) only takes 566 seconds. When the threshold decreases, the number of HUIs dramatically increases and HUI-Miner need to pro-duce a large amount of utility-lists for intermediate itemsets. However, the number of candidates produced by PHUI-Growth(DLU-MR) is up to two orders of magnitude smaller than that produced by HUI-Miner. 5.2 Performance Evaluation on Large-Scale Datasets including Chainstore, T10I4N10K|D|2000K and Chainstore  X  5. Execution time of the algorithms and the number of candidates are respectively shown in Fig.5 and Fig. 6. Results show that PHUI-Growth(Baseline) and Growth(DLU-MR) outperform HUI-Miner significantly. The reason why PHUI-Growth(Baseline) and Growth(DLU-MR) HUIs across multiple machines, while HUI-Miner is executed on non-parallel single machine. In Fig.5, PHUI-Growth(DLU-MR) generally runs much faster than PHUI-Growth(Baseline) on all the datasets. This is because that PHUI-Growth(DLU-MR) integrates the DLU-MR strategy for effectively prune the candidates and hence en-hances its mining performance. Then, we compare the scalability of the algorithms on large datasets Chainstore  X  5 and T10I4N10K|D|2000K. As shown in Fig 5(c) and Fig. 5(d), PHUI-Growth(DLU-MR) has very good scalability on large datasets. On the contrary, the execution time of HUI-Miner increases dramatically on large datasets. In Fig 6(d), as the relative min_util is set to 0.01%, PHUI-Growth(DLU-MR) only takes about 592 seconds, while HUI-Miner takes more than 7,500 seconds. data . A novel algorithm PHUI-Growth is proposed for efficiently parallel mining high utility itemsets from distributed data across multiple commodity computers. It is implemented on a shared-nothing Hadoop platform and thus inherits several merits of Hadoop, including easy deployment in high level language, supporting fault recovery and fault tolerance, low communication overheads and high scalability on commodity hardware. A novel strategy called DLU-MR is proposed to effectively prune the search space and greatly improve the performance of PHUI-Growth . Empirical evalu-ations of different types of real and synthetic datasets show that PHUI-Growth has good scalability on large datasets and outperforms the state-of-the-art algorithms. 
