 search [1]. The document is usually represented as a vector by weighted index terms. A typical method, the Bag of Words (BOW), identifies all the words occurring in the corpus as index terms. For its simplicity and usability, BOW has been widely adopted in text categorization. However, BOW results in the high dimensions of feature space many text representation methods have been proposed in two main directions: 
In one direction, diverse language units, such as phrase [2], word senses and syn-Extensive experiments have shown that these complex unites do not yield signifi-cantly better effectiveness . Likely reasons for the discouraging result, as stated in to tackle. 
In the other direction, topic-models, such as, Distributional Words Clustering (DWC) [5], Latent Semantic Indexing (LSI) [6] and LDA [7] [8] etc. are proposed to extract some kinds of latent information structures of documents beyond words. Among these models, LDA has attracted much attention for its dimension reducing power, comprehensibility and computability. Whereas LDA has been extensively applied in machine learning, information retrieval [9] and some NLP tasks, the poten-tial of LDA in text categorization isn X  X  systematically explored. In addition, the size of corpora and/or categories in former related studies [8] [10] are relative small. 
In this paper, we will study how to effectively smooth LDA model for improving text categorization under the generative framework. Our works concentrate on follow-tions from inside of multi-level graphical models. Accordingly, we propose the data-driven smoothing strategy for LDA model and its two instances. Experiment evaluations show this data-driven strategy can significantly improve the performance on both balanced and unbalanced text categorization corpora.

This paper is arranged as follows. Section 2 shows a brief of LDA model. Our pro-posed data-driven smoothing strategy and two concrete methods, L_LDA model and JM_LDA model, are presented in section 3. Experiment evaluations and analyses are given in section 4. Section 5 is the related work, and section 6 gives a conclusion. LDA [8] is a document-level generative probabilistic language model (in Figure 1), in which each document is modeled as a random mixture over latent topics. Each topic is, in turn, modeled as a random mixture over words. The generative process for each document w can be described as following steps: 1: Select a latent topics mixture vector  X  from the Dirichlet distribution Dir (  X  ). 2: For each word w n LDA is a directed graphical model and the joint distribution is given by formula ( 1 ): 
For probabilistic language models, the critical task is to calculate the probability of the marginal distribution of a document. This can be obtained for LDA by: 
As the formula ( 2 ) shows: Given a LDA model instance defined by parameters (  X  ,  X  latent topics mixture vector  X  and the other is summing over latent topic z n . In such a way, LDA model can synthesizes the topic structures implicated in the document and key advantage compared with other language models like N-gram model which only consider the distribution of words. 2.1 Applying LDA Model in Text Categorization Under the generative probability framework of classification can be formulated as ( 3 ), obtain a new generative classifying model in formula (4): language models (like n-gram, hmm, etc.), A smoothing procedure must be added to the parameter  X  to overcome the zero probability caused by OOV(out of vocabulary). gory c i , is formulated as (5): result, the deviation of the training of the LDA smoothing method will also increase. 
In order to obtain a tractable posterior in the LDA model setting, the Dirichlet prior estimation equation of parameter  X  in formula (6): 
It is obvious that  X  ij can avoid zero probability for any word index j because of the multi-level graphical model. In the iterative procedure of training the LDA model,  X   X  const is added in the estimation for the reason of simplicity of calculation. 3.1 Data-Driven Strategy LDA model. We construct virtual instances which cover all words in global vocabu-lary and add them to the training set. The LDA model would be smoothed and avoid driven smoothing. The most virtue of this data-driven smoothing is that it can take use of the inference mechanism rooted in LDA model to integrate with the inference of  X  and z . In such a natural way, appropriate probability mass are allocated toward OOV. So, this strategy can avoid that the OOV X  X  probabilities are calculated isolated in the traditional LDA model. 
In this paper, two concrete smoothing methods following the data-driven strategy are introduced. We name them as Laplace LDA model (L_LDA) and Jelinek-Mercer LDA model (JM_LDA) which are discussed in detail in following. 3.2 Laplacian Smoothing LDA (L_LDA) Model of documents in the corpus: 
The smoothing procedure is not embeded in the LDA model. In implement, a vir-tual instance is constructed and added to the class c i . All words in the global vocabu-ability is set to OOV of each class. Iit is guaranteed that the probability mass of OOV will not decrease to a too low level in the iteration of the training of the model. 3.3 Jelinek-Mercer Smoothing LDA (JM_LDA) Model From another way, we can use the L_LDA as a background model under the Jelinek-Mercer Smoothing framework which has been used widely in information retrieval. We formulize this in (8): 
For the Jelinek-Mercer Smoothing on 1-gram language model, there is an assump-tion that the occurrence of the words in a document is position-free and then we ob-cally conditional independent on the occurrence of any other w t2 given the document X  X  type c i . We can formulate this idea in formula (9) which will be used in the phrase of predicating: 
We can use the MLE to estimate p JM_LDA ( w t | c i ) by formula (10): 
This item must be attached some other smoothing method. Here, L_LDA is intro-duced to do this job in formula (11): 
As we know that MLE parameter estimating method only uses the explicit word frequency information. In contrast, the LDA parameter estimating method uses both p ( w t | c i ), as shown in formula (11). topics) of the document. Hence this method can more accurately estimate the weight of the specific word by using the internal structural information. This is the advantage compared with the MLE estimate method which only uses the frequency information of words. 
The integration (11) is normally calculated by variational method [11] [12]. One the number of iterations required for a single document is on the order of the number the order of about O ( k ) because that the  X  X ocument X  in (11) have only 1 word, so the N =1. It is obviously that this is a quickly calculating procedure. 
Consequently, applying LDA to parameter estimating process but not to predicat-ing phase will increase the predicating speed as in formula (9). The order at predica-tion phrase of JM_LDA Model is O ( N ) , which is equal to the order of classical Na- X veBayes multinomial model whereas the order at predication phrase of L_LDA model is O ( N 2 k ). This is very important for the real application environment. 4.1 Experiment Setting In our experiments, the following test collections are used: 20newsgroup: It is collected by Ken Lang for text categorization research. All docu-47802. We randomly select 50% of documents per class for training and the remain-ing 50% for testing. Fudan: It is published on http://www.nlp.org.cn. This is a Chinese text categorization are unbalanced . We remove common stop words and the last vocabulary size is 79093. We also randomly select 50% of documents per class for training and the remaining 50% for testing. These are summarized in the table 1: 
In this section, we evaluate the traditional LDA model and two LDA smoothing methods: L_LDA and JM_LDA. We firstly concentrate on the synthesis classification performance measured by micro_F 1 and Macro_F 1 across all classes on each corpus. balanced classification to enucleate the significant improvement obtained on fudan corpus. 
In all our experiments, the LDA-C (implemented by D. Blei) with default settings is chosen as the basic software. On the other side as you have seen, the JM_LDA model has two super parameters: topic number and mix coefficient  X  . As in other models, we fix the topic number, you can only search the optimum mix coefficient  X  . 4.2 Experiment &amp; Analysis Synthesis Classification Performance evaluate the synthesis classification performance on 20newsgroup and fudan corpus. We perform the comparison among three methods: traditional LDA model and our ( micro_F 1 or Macro_F 1 ). 
For the LDA model, the number of latent topics is an important factor which de-fines the granularity of the model. So, we evaluate models on different topic number. From the figure 2.1 and 2.2, we can get the following things: (1) On the whole, the L_LDA model and JM_LDA model have a very near per-formance where the L_LDA has a small superiority of about 1% than JM_LDA. At the same time, both L_LDA and JM_LDA have an evident higher performance of about 5%~6% than LDA model. This occurs across all value of topic number. (2) When different latent topic number is selected, the behaviors of the three mod-interval and the JM_LDA remains much stably. Among the three models, only the L_LDA model increases monotonously along with this model expanding. (3) Comparing the figure 2.1 and 2.2, we can find that the performances measured performance value of every model, the relative performance difference among three models and the performance tendencies exhibited on the sequence of topic numbers. model and JM_LDA model can alleviate this difficulty obviously. 
Subsequently, we will compare the performances of the three models on the fudan corpus as shown in the figure 3. From the figure 3.1 and 3.2, we can obtain the following things: On the whole, both L_LDA and JM_LDA have evident highly performance ( mi-cro_F 1 and Macro_F 1 ) than LDA model across all value of topic number. Neverthe-less, except this point of similarity, figure 3.1 and 3.2 show several differences: (1) The most significant one is the different improvement extent between the meas-Macro_F 1 obtains an approximate 30% improvement for both L_LDA and JM_LDA. This result shows that the data-driven smoothing strategy can advance the Macro performance on the unbalanced corpus. (2) For the L_LDA model, the tendencies across the sequence of topic numbers are different between the measures of micro_F 1 and Macro_F 1 . The micro_F 1 increases change of topic number. (3) Comparing between the L_LDA model and JM_LDA model, the Macro_F 1 measures of them are very near but the improvement extent of L_LDA X  X  micro_F 1 is twice of JM_LDA X  X . This shows that L_LDA has some superiority than JM_LDA. 
Summarizing on the experiments with respect to the two corpora, 20newsgroup and fudan, we can draw the following main conclusions: (1) Both L_LDA and JM_LDA can significantly improve the synthesis perform-ance measured by micro_F 1 and Macro_F 1 . This result corroborates the effectiveness of our data-driven smoothing strategy on LDA model. (2) On the balanced corpus, our smoothing methods show highly identical between micro_F 1 and Macro_F 1 . On the unbalanced corpus, however, the Macro_F 1 improve balanced classification task. detailed granularity where the performance of every class is examined. Detailed Analysis Classification Performance on Unbalanced Corpus driven smoothing strategy on unbalanced corpus ( fudan corpus). F 1 measure is used for every class and Macro_F 1 measure is used for groups of classes. We also compare the three methods: traditional LDA model and our L_LDA model &amp; JM_LDA model. In the following experiments, the topic number of three models is fixed on a specific value: strate the superiority of data-driven smoothing for unbalanced classification task. 
First of all, we show the unbalanced distribution of documents quantities across all categories on fudan corpus in figure 4.1 and corresponding performance comparison between models (LDA, L_LDA and JM_LDA) as 4.2: 
Figure 4.1 shows that the classes of corpus are evidently divided into 2 parts: there are 11 small classes (1-11), where every one has about tens of documents in training &amp; testing set; the other 9 classes are big classes. 
From table 2, we can firstly get that on the whole corpus, the Macro_F 1 obtains an improvement over LDA about 26% for JM_LDA and about 28% for L_LDA. Other details are discussed as following: (1) The performances of L_LDA model and JM_LDA model measured by Macro_F 1 are very near on both small classes and big classes. So, these two models can get the closer performance on the whole corpus. only have little difference: the Macro_F 1 of L_LDA is higher than JM_LDA by 2.2%. In turn, the Macro_F 1 of JM_LDA is higher than LDA by 1.4%. These improvements key reason is small classes. (3) On small classes, the LDA model has a very poor performance which can only attain 12.7% measured by Macro_F 1 . After smoothed by L_LDA and JM_LDA, this performance advances to about 60% which result in an improvement of 47%. It is just this great contribution urges the whole corpus X  Macro_F 1 goes up about 26%~28%. 
Next step, we will look into the detail views across all classes by different aspects the measure F 1 . 
We can see that the F 1 of L_LDA model is always higher than LDA model across all classes where the F 1 of most small classes increase greatly and L_LDA model can L_LDA model shows that the main principle of the whole improvement is digging classes. The similar principle is also the same with JM_LDA. 
We know that the measure F 1 is composed by Recall and Precision . We will look into these two measures to find the factors that prompt the synthesis performance. The Recall result is shown in figure 5.1 and the Precision result is shown in figure 5.2. The most noticeable thing is that the figure 5.1 is almost the same as the figure 4.2. So, we can determine that the promotion of Recall on the unbalanced corpus greatly improve performance of F 1 . So, L_LDA and JM_LDA can find documents of small size classes significantly. This is the key function for unbalanced classification. 
On the contrary, the figure 5.2 is much different with figure 4.2 and figure 5.1. The precisions of L_LDA and JM_LDA of small classes vibrate severely and deviate from the LDA X  X  to much extent. As whole, the Precision of L_LDA and JM_LDA are JM_LDA are more effective than LDA model X  X  because that the Precision of LDA is based on the very low Recall which makes the high Precision meaningless. 
For the unbalanced corpus, the OOV amounts of the small classes are much more learning algorithms for small classes will decrease severely. For the smoothing proce-dure of the corpus, probability distribution has been performed for all word across all classes. This procedure has different influences between huge classes and small classes. Huge classes have bigger vocabularies, and words appear more frequently. So the smoothing procedure has little influence on big classes. By contrast small classes have relative much smaller vocabulary, and words appear less frequently because fewer documents involved. Thereby the smoothing procedure has bigger influence on small classes. According to the experiment s, the default smoothing approach of LDA has severe over-fitting on small classes. Our data-driven strategy smoothing methods can alleviate this defect to much extent. [8] conduct binary classification experiments on the Reuters-21578 dataset. They compared two type text presentations, classical BOW and low-dimensional represen-tation derived from LDA model. Their performances are very near (with a difference of about 1%~2%). This shows the potential of the LDA in using as dimension reduc-ing method for text categorization. 
Wei Li et al. [10] conduct a 5-way classification experiment on the comp subset of the 20newsgroup dataset to compare LDA with PAM (Pachinko Allocation Model) gets an improvement of about 3% over LDA by Accuracy measure. Our experiments show data-driven smoothing LDA exceeds traditional LDA about 4% measured by micro_F 1 (in single-labeled setting, micro_F 1 is equivalent to the Accuracy [14]). 
In above experiments, the quality of both classes and/or documents is too small to exhibit the advantages or disadvantages of LDA. So, we study LDA on corpora with more classes and documents. Moreover, their works have not dig into unbalanced classification as our works. For unbalanced classification problem, there are two basic them and similar with the idea of the feature processing as [16]. 
Our JM_LDA model is inspired by the work of Wei, X and Croft, W.B. [9]. How-p In this paper, we propose the data-driven smoothing strategy for LDA model to over-in multi-level graphical model. Laplacian smoothing and Jelinek-Mercer smoothing are introduced to LDA model following this data-driven smoothing strategy. Lapla-cian smoothing alleviates the over-fitting of LDA model evidently; and moreover, Jelinek-Mercer smoothing decreases the time complexity of Laplacian at predicting phase without damaging the performance on the whole. The evaluation shows that the data-driven smoothing strategy can significantly improve the performance on both balanced and unbalanced text categorization corpora. work shows that the smoothing is very important for the application of the LDA model to text categorization, further researches of different smoothing methods should be done. Secondly, topic model is a rich area where many instances have been proposed [17] [18] [10]. Testing data-driven smoothing strategy on these models will be concerned. Acknowledgments. This work is partially supported by National Natural Science Foundation of China with the contract No. 60773027 and No. 60736044 and by the 863 project of China with the contract No. 2006AA010108. 
