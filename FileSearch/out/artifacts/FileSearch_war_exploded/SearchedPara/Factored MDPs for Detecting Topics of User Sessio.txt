 Recommender systems aim to capture interests of users to provide tailored recommendations. User interests are however often unique and depend on many unobservable factors including a user X  X  mood and the local weather. We take a contextual session-based approach and propose a sequential framework using factored Markov deci-sion processes (fMDPs) to detect the user X  X  goal (the topic) of a ses-sion. We show that an independence assumption on the attributes of items leads to a set of independent models that can be optimised efficiently. Our approach results in interpretable topics that can be effectively turned into recommendations. Empirical results on a real world click log from a large e-commerce company exhibit highly accurate topic prediction rates of about 90%. Translating our approach into a topic-driven recommender system outperforms several baseline competitors.
 H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval MDP; recommender systems; session-based; user intent
Recommender systems are designed to satisfy user X  X  information and tangible needs. Guessing the intention of users is not only fun-damental for the overall user experience but directly linked to rev-enue. User intent however is driven by unobservable internal (e.g., mood, spontaneous inspiration) as well as external (e.g., weather, location) processes [15]. Capturing user intent is therefore one of the most challenging problems in many retrieval and recommenda-tion tasks.

The context of a user is often seen as a proxy for the unobserved processes [34]. Context may be provided by previously visited pages [8], viewed items [28], or user profiles [11], and is often studied together with personalisation [20]. There is a broad range of applications using contextual variables of users including query refinement [27], re-ranking for web search [12], market segmen-tation [14], and latent variable models for spoken language under-standing [9]. An alternative approach to capturing the intent of users are topic models. Topic models [5] can be seen as a gener-ative probabilistic semantics that have been proposed for retrieval [31] as well as recommender systems [23, 10]. Topic models for temporal data however often require stationary data distributions [4, 1], an assumption too restrictive for highly dynamic scenarios such as e-commerce.

In this paper, we focus on recommender systems where user feedback is recorded implicitly, for instance through clicks on re-sult pages of search engines or on lists of recommended items. The implicit feedback can be used to train autonomous recommender systems as the noisy and incomplete batch of user responses pro-vides a partial labelling of the data. Note that these partial labels do not suffice for purely supervised approaches as the outcome of rec-ommending alternative items is undefined. On the other hand, the task neither fits a purely unsupervised setting as the valuable (par-tial) ground-truth would be discarded. The abstract problem setting matches that of reinforcement learning-style approaches where un-certainty about the value of actions (e.g., recommending an item) is minimised by trading off exploration and exploitation [28, 18]. Reinforcement learning-based approaches are naturally sequential models with intrinsic Markov assumptions that allow for capturing the context of a user by explicitly representing sequences of previ-ously clicked items [28, 35].

We study factored Markov decision processes (fMDPs) [6] to detect topics of user sessions. We take a sequential approach and leverage ideas from [35] and [28] to characterise sessions in terms of the history of viewed items. However, straight forwardly solving the resulting fMDPs is infeasible due to exponentially increasing state spaces. Moreover, the structure of the value function does not necessarily retain the structure of the process after factorisation [17]. Hence, many approaches to approximate value functions have been proposed (e.g., [13, 7]).

Commencing with a standard fMDP on the history of viewed items, our main contributions are as follows. We show that an in-dependence assumption on the attributes of items allows to equiva-lently represent the fMDP by an ensemble of independent fMDPs. Compared to the initial fMDP, the resulting state space is orders of magnitude smaller and the ensemble can be optimised efficiently. In addition, we propose a robust approximation following ideas from Shani et al. [28] to improve the predictive accuracy in the presence of data sparsity and large-scale applications. We show that the learned Q -values can be easily turned into interpretable topics and recommendations.

In extensive experiments on real world data at enterprise-level scales provided by Zalando, we observe highly accurate topic de-Figure 2: Left: Transition model of a joint factored MDP. Ev-e ry attribute value depends on the complete history of all previ-ously viewed items and their attributes which leads to an infea-sible model. Right: Sequences of attributes form independent components. There are no dependencies between attributes. Positive rewards indicate a click on a recommended item in which case the recommendation was successful and has been accepted by the user. The transition function P ( s  X  | s, a ) estimates the probabil-ity of entering state s  X  after recommending a in state s . Note that s serves as a prefix of s  X  which is given by s  X  = s  X  i is the clicked item by the user and  X  the operator that appends two sequences, e.g., q  X  p = pq .

The length of the actual state s is continuously increased by ap-pending clicked items, exactly one at a time. Thus, instead of ad-dressing the complex P ( s  X  | s, a ) , transition probabilities P ( i are often used as an equivalent proxy due to their simpler structure. The quantity P ( i  X  | s, a ) is the transition probability of clicking on item i  X  when in state s and recommending item a . The transition probabilities can be represented as a two-layer acyclic graph that connects the attributes of the previously viewed items in s with the attributes of the item to be clicked denoted by i  X  . Theoretically, the joint transition probability can be efficiently computed by factoris-ing conditional probabilities, e.g., where parents ( X  X  j ) denotes the parents of the node X derlying graphical model. However, the state space of the fMDP grows exponentially and renders practical application infeasible as the exact estimation of the optimal policy is not feasible due to the curse of dimensionality [13]. Thus, we haven X  X  won anything yet in terms of feasibility but successfully rephrased the model over attribute sequences of the viewed items (Figure 2 left).
Directly addressing the joint Pr( X 1 , . . . , X n | s, a ) requires a state space that is intractable even for small and medium-sized ware-houses. We therefore treat the attributes of the items as independent and approximate the intractable joint by a product of independent decisions, The idea is to split the fMDP into an ensemble of n disjoint and independent fMDPs, one for each attribute. The j -th fMDP focuses on only the j -th attribute and recommends a realisation a based on the sequence of attributes s j of the previously viewed items. In Figure 1 for instance, guessing that the next item will be another shirt can trivially be done in the absence of all other attributes. A similar argument holds for expecting a dark colour or a garment for women .

The following theorem shows that an fMDP with independent chains of random variables admits an equivalent representation as an ensemble of n independent fMDPs. In order to propagate single receiving reward through all fMDPs, we consequentially assume additive factorised rewards R ( x, a ) = P n j =1 R j ( x
T HEOREM 1. A factored MDP with a set of n independent com-ponents X = {X 1 , . . . , X n } allows an equivalent representation as an ensemble of n independent fMDPs, one for each component X j where 1  X  j  X  n . Let V  X  ( x ) be the optimal value for state X = x in the joint fMDP and V  X  ( x j ) be the optimal value for attribute X j = x j in the j -th fMDP, for all 1  X  j  X  n . It holds P ROOF . The standard update rule of value iteration is given by
V N +1 ( x ) = max Replacing the maximum operator by a softmax gives V where  X  controls the degree of the approximation and the exact maximum is recovered for  X   X   X  . We show the claim by induc-tion for value iteration. For N = 1 , we have for the j -th fMDP of the ensemble and the joint is obtained by
V 1 ( x ) = The innermost summation can be rewritten as
X by drawing unrelated terms out of the sum. Continuing for the other summations gives which shows the claim for N = 1 . Now assume that V N ( x ) = P summand in the exponent is simplified by where the latter gives rise to the telescope sum The innermost summation over the new state x  X  n yields and since P x  X  Drawing out the remaining terms from unrelated summations and putting things together gives Reordering terms shows the claim.

Theorem 1 shows that any high dimensional fMDP with inde-p endent attributes can be equivalently expressed by several inde-pendent fMDPs. Exploiting the independence between the attribut-es, the resulting ensemble consists of an fMDP for every compo-nent. The resulting state spaces are independent sequences over a single attribute given by the Kleene closure S j = ( dom ( X all components j . Note that a result by [17] shows that the value function of fMDPs does in general not retain the structure of the process. Our theorem proves that a structured value function is generally obtainable for fMDPs with independent components.
Still, a major drawback of the model is the dependence on the whole session, that is, every viewed item impacts all subsequent actions. We therefore take a k -th order Markov assumption to rep-resent only the k most recently viewed items explicitly. The set of states of the j -th fMDP is effectively reduced to S j = ( dom ( X The Markov assumption discards long-range dependencies and lead, together with the previous independence assumption, to an efficient and compact representation of the ensemble as shown in Figure 2 (right).
The resulting independent fMDPs can be optimised indepen-dently and in parallel using standard reinforcement learning tech-niques such as value iteration. Value iteration learns the state-value function, V ( s ) , using the model of the environment; the reward and transition functions R ( s, a ) and P ( s  X  | s, a ) , and converges to the optimal solution in a discounted finite MDP [29].

The set of states in the j -th fMDP is described by a k -sequence of realisations of the j -th attribute X j given by s j = ( x The task of the agent is to predict the value of action a in the actual state s j . The transition function P encodes the proba-bility of observing the subsequent state s  X  j = ( x t  X  k +1 and the reward function R j provides feedback for recommending a in s j . Value iteration uses the following update rule for value determination, V When the value function converges to the optimal V  X  , state-action values Q ( s j , a j ) can be derived where Q ( s j , a j ) measures the quality of recommending a s . Realisations with high Q -values are likely to be observed in the next page view while small Q -values indicate very unlikely obser-vations. We use the terms Q ( s j , a j ) and Q ( s j , x in the remainder.

Reinforcement learning techniques often perform poorly in large scale problems due to slow convergence rates. Adapting the model to data is therefore performed in two steps; offline and online. First, an initial model is learned by value iteration where transition and reward functions are adapted to historic data by maximum likeli-hood. The trained model is then deployed in an online scenario where it is gradually updated according to the user feedback to improve estimations. In practice, value iteration can be repeated periodically (e.g., once in a week) to keep the system up to date.
In practical applications, the available data is often too sparse to allow for an accurate estimation of the transition probabilities. In addition, applications on large-scales render keeping the whole set of transition probabilities infeasible due to memory requirements. We thus propose an efficient approximation of our model based on the ideas of Shani et al. [28].

The main idea is to focus on estimating the probability Pr( i of item i  X  to be clicked next, irrespectively of the action. The transition Pr( i  X  | s, a ) can be approximatively reconstructed from Pr( i  X  | s ) as follows. Recall that action a is identical to an item i  X  I . There are three possible outcomes of taking action i = x when in state s : (i) The user accepts the recommendation i with probability P ( i | s, i ) , (ii) she rejects i and clicks instead on item i with probability P ( i  X  | s, i ) , or (iii) the session terminates with probability P (  X  X  s, i ) . Consider the former two events. The task is sition function. Note that in the latter, a click on i  X  is independent of the recommended item i .

The assumption is that the probability of clicking on a recom-mended item is larger than the probability of choosing the item in the absence of a recommendation, that is P ( i | s, i )  X  P ( i | s ) [28]. Analogously, the probability of clicking on item i in the absence of any recommendation is higher than for clicking on i when the recommended item is actually i  X  6 = i , that is P ( i | s, i By choosing appropriate constants  X  &gt; 1 and 0 &lt;  X  &lt; 1 , the desired quantities are approximated by [ P ( i | s, i )  X   X P ( i | s ) and P ( i | s, i  X  )  X   X P ( i | s ) , subject to P ( i | s, i ) + P P (  X  X  s, i ) = 1 , which is obtained by normalisation.
Once approximate or exact Q -values Q ( s j , x j ) are computed, they can be used to extract the topic of the session as follows. The value Q ( s j , x j ) is proportional to the probability that the user clicks on an item with attribute x j given the sequence of realisa-tions s j . In other words, realisations with high Q -values are likely observed next and thus constitute a part of the topic of s formly distributed Q -values, e.g., Q ( s j , x j )  X  Q ( s x , x  X  j , the topic contains the whole domain dom ( X j ) , indicating that the j -th attribute does not contribute to the topic. As a conse-quence, any realisation of that attribute may be observed next. In-termediate Q -values are ranked according to their difference to the maximum Q -value, such that the expected realisations of attribute j a re computed by the min-max normalisation q ( X j = x j | s j ) = for all 1  X  j  X  n . The independent results are then multiplica-tively combined to approximate the desired probabilities
Our approach can also be turned into a recommender system. In contrast to the topic extraction, we use a softmax instead of the min-max normalisation to translate Q -values into probabilities, The softmax gives us a probability distribution over the state space of every attribute. The use of the exponential function penalises even small differences and thus acts like a probabilistic winner-takes-all. Note that in practice, recommendations have to be com-puted very efficiently under rigid time constraints. Having a clear set of winners helps to speed-up the computation by continuously filtering out items at early stages that cannot make it into the top-m to save time for more promising candidates.

Given the estimates in Equation (3), the score for item i with attribute combination x 1 , . . . , x n is simply given by the product of the corresponding probabilities, or alternatively, by the sum of the corresponding log-probabilities, that is, score ( i ; s ) = The scores impose a ranking on the items and the top-scoring prod-ucts can be recommended.
In this section, we evaluate our approach on an anonymised click log from Zalando 1 , a large European online fashion retailer. The data distribution is modified so that no conclusions on customer data or business figures of the company can be drawn. There are 1 , 721 , 483 user sessions consisting of 24 , 353 , 852 clicks in total. Sessions are split after 25 minutes idle time and the average session consists of 14 clicks. Every click is associated with a timestamp, the attributes of the viewed item, user ID, and the recommended items. We focus on attributes colour, gender, category, and price. There are 62 different colours, 16 genders (including types of ac-cessories), 61 categories, and 16 discrete levels of price in the log.
Measuring the performance of topic detection methods using real world data is difficult as topics are not observed variables but con-tained only implicitly in the data. We therefore test the topic pre-diction against the attribute values of the next clicked item. We translate the distribution in Equation (2) into a discrete set of at-tribute values. A simple thresholding approach discards unlikely realisations and returns a set T j for every attribute 1  X  j  X  n given a session s = ( s 1 , . . . , s n ) , w ww.zalando.com where c is a user defined constant. Large values of c thin out the topic and focus on highly probable attribute values. On the other hand, small values of c weaken the interpretability and usability of the resulting topics unnecessarily that may contain many unlikely realisations. In the first set of experiments, we use c = 1 variations of the parameter afterwards. The joint topic T ( s ) is then given as the union over all attributes by T ( s ) = S n j =1
We evaluate the accuracy of the extracted topics for every at-tribute as well as for the joint topic using indicator functions [[ z ]] yielding one if the argument z is true and 0 otherwise. Let T be the topic of an ongoing session and x  X  j the corresponding real-isation of the next clicked item. The topic prediction is correct if [[ x j  X  T j ( s j )]] . The joint topic is then evaluated by concatenating the individual results with an and-operator, Note that high accuracies in individual attributes do not necessarily indicate a good joint performance as the all attribute values need to be contained in the topic.

We compare the ensemble approach of Section 3.4 (M1) with its approximation in Section 3.5 (M2). As a baseline, we deploy a simple Markov process (MP) that uses estimates P ( i  X  | instead of Q ( s, i  X  ) for the computation of the topic. Thus, its proba-bilities are proportional to the number of times that item i clicked in state s estimated by maximum likelihood. Additionally, we include LDA [5] as another baseline. To this end, every session is treated a document where the attributes of the viewed items are considered the words of the document. The set of words is thus defined by S n j =1 dom ( X j ) and contains 155 distinct words. We apply the method by [5] for both estimation and inference of topic proportions as well as word distribution per topic. At testing time, LDA determines the topic mixture of the ongoing session based and computes the probability distribution of attributes according to the mixture. Thresholding is identical for all methods.

For the first set of experiments, we only use a subset of the data for evaluation as the exact variant cannot be evaluated on all avail-able data due to memory issues. In the corresponding subset, there are 34 , 343 user sessions consisting of 722 , 179 clicks in total with the average of 21 clicks per session. We split 70% of the resulting sessions for training, 20% as holdout, and 10% as test sessions ac-cording to the temporal nature of the data. Optimal parameters for M2 and LDA are found by model selection and are given by  X  = 2 ,  X  = 0 . 001 for M2 and  X  LDA = 0 . 1 and 100 topics for LDA, re-spectively. Rewards are positive for clicks on recommended items as well as adding to cart, and sale actions. Removing items from the cart is penalised with negative rewards, all other actions realise a reward of zero.

Table 1 shows average accuracies of the best models for Markov assumptions of order k  X  { 1 , 2 , 3 , 4 } and LDA. The exact ensem-ble M1 performs poorly for short histories but improves signifi-cantly for larger k . We credit this finding to the necessity of taking chains of consecutive clicks into account. Although the individual predictions on attribute levels are promising, the joint topic is not well captured. Further, the high sparsity of small data sample leads to the predictive accuracy of below 70%. By contrast, the approx-imate M2 performs much better for short histories and detects the correct topic in 94% of the cases for k = 1 . The performance de-creases for longer chains. The observed effect originates from the approximation itself. The data sample is not sufficiently large for reliably approximating longer histories. We will address this issue in the next experiment again.
L DA characterises the next click by dominant attributes of the ongoing session. The results show that users tend to click on items with so far unseen attribute values, particularly for price and colour. However, apart from M2, the joint topics are mostly inaccurate and do not reflect the performance for individual attributes. The out-comes of MP show that simply counting frequencies of subsequent events is not sufficient for achieving state-of-the-art performances.
In this section, we focus on the approximate ensemble (M2) and repeat the previous experiment on the whole click log. We split all available data into consecutive training (70%), holdout (20%), and test (10%) sets to preserve the temporal nature of the data. Table 2 shows the results for MP and the approximate M2 for histories of size k  X  { 1 , 2 , 3 , 4 } as well as LDA. All three methods exploit the abundance of data and improve their performance. However, the overall joint performance of LDA is still far from a real-world deployment and even for MP still stays constantly below 40% . The approximate M2 clearly outperforms the baselines and yields im-pressive joint accuracies of about 90% for all k . The additional data trades-off the approximation issues observed in the previous experiment for larger k at the expense of smaller k .
In this experiment, we study the variation of the detected topics in the course of the sessions using the experimental setup of Sec-tion 4.2. We measure the difference of subsequent topics T ( s ) and T ( s  X  ) by their Jaccard distance. A large distance indicates rapid changes in neighbouring topics and either refers to a badly adapted model or to undetermined users who are just browsing instead of following a specific goal. By contrast, small distances indicate that users are very predictable and only search for very particular items without digressing.

Figure 3 (left) depicts the session on the x -axis and the variation of neighbouring topics in terms of their Jaccard distance on the y -axis averaged over all sessions. Unsurprisingly, for all histories 1  X  k  X  4 , the variation decreases rapidly after a few clicks. The more clicks a user performs, the more feedback is provided to the system and can be exploited by the model. Except for histories of length k = 4 , all models converge quickly to only a few variations. That is, only very few attribute values are replaced between time steps. For longer histories k = 4 , we observe more variations which is also reflected by lower overall accuracies in Table 2.
Figure 3 (center) shows the impact of the topic threshold c on the average size of the topics for the attribute category . Increasing the threshold effectively thins-out the topics on average. However,
Table 2: Accuracies for the topic detection using all data. c hanging the topic threshold c also impacts the accuracy. Figure 3 (right) shows that tighter topics may fail to capture the user X  X  intent and we observe decreasing accuracies for larger values of c . The actual value of c trades-off the specificity of topics and the accuracy of the topic prediction.
We now demonstrate the effectiveness of the topic detection by translating the detected topics into recommendations according to Section 3.7. We use again the experimental setup from Section 4.2 and compare the approximate ensemble M2 with a collaborative filtering using matrix factorisation (CF) and a combination of topic models and collaborative filtering presented in [31] (TM). Both CF and TM are the same methods as described in [31], however we set  X  LDA = 0 . 1 , number of topics = 100 , and the number of factors in matrix factorisation = 200 by model selection. To evalu-ate these two baselines, items are ranked according to the previous clicks of the actual user as given by the user-item matrix. Note the conceptual difference of our fMDP and the collaborative filter-ing approaches. While the former takes a session-based approach and thus aims at short-term interests, the latter two are user-specific and could be considered global models for long-term user interests. Additionally, we incorporate three simple baselines: ranking items randomly (Rnd), ranking items according to their similarity to the previously viewed item so that items with the same attributes are ranked on top (Prev), and ranking items according to their popular-ity (Pop).

We also wanted to include a sequential MDP-based approach [28] as another competitor. However, a standard MDP approach as described in Section 3.1 is defined in terms of the items and turns out infeasible even for the small sample that we used in Section 4.1. There are more than 80,000 items in the small sample, leading to a minimum memory requirement of about 52GB for maintaining two tables of size 80 , 000  X  80 , 000 , one for transitions and the other for the Q-values (for k = 1 ) using only four byte representations. The data set we are experimenting with in this section contains more than 240,000 items. We therefore leave this comparison for future work.

Figure 4 shows average ranks of the recommendations in the course of the sessions. Note that the average rank is a variant of Average Relative Position (ARP) [22]. As the baselines are static recommender systems that do not exploit the sequential nature of the data, their performance is more or less constant in the length of the session; small fluctuations disappear in the figure due to the log-scaled y-axis. The sequential M2 exploits the temporal nature of the data and adapts quickly to the topic of the session. The best method realises a second-order Markov assumption. The figure could be extended to the right to include longer sessions but the information gain is rather small as the performance of all methods does not change significantly.
Table 3 shows aggregated results by averaging the performances over the length of the session. The baselines perform worse than M2, and among them, Prev and Pop outperform Collaborative based methods. The best method for histories of length two realises aver-age ranks of about 15,000. Although the absolute number appears quite high, recall that there are more than 240,000 items in the data set. On average, clicked items are among the top 7% of the ranking for k = 2 .

T ables 1 and 2 exhibit differences in the predictability of the attributes. Unsurprisingly, gender is always predicted with high accuracy as it is unlikely that users switch often between genders within a session. The same is held for the attribute category . In contrast to gender and category , attributes colour and price prove more difficult. Apparently, users are somewhat flexible about prices and colours. Nevertheless, we observe highly accurate predictions for these attributes for the approximate ensemble M2.

Note that the choice of k depends on the application at hand. Our results show that the performance of the exact M1 increases with larger k (Tables 1). However, the larger the history, the longer it may take to adapt to a change in the topic; for instance because the user has not found what she was searching for or is distracted by a completely different item that is also displayed on the page. In practice, the fMDPs could be reset after cart or purchase operations by the user. The approximate fMDPs however perform better for short histories although the effect becomes smaller for larger train-ing sets. We credit this finding to difficulties in the approximation caused by sparsity in the data distribution.

Since the internal representation of the factored MDPs is a graph-ical model, it is straight forward to augment additional variables to capture the context of the user. A promising candidate seems to be the time the user spends on the page before clicking. Very short stays could be an indicator for dissatisfaction, possibly followed by a change in topic while longer stays may give rise to a careful examination of the item at hand and a possible cart operation.
Finally, recall the conceptual differences of the fMDP-based rec-ommender and the collaborative filtering baselines. While the for-mer takes a session-based approach (short-term interests), the latter is user-centric and implements the notion of personalisation (long-term interests). Thus, the two strategies can be considered orthogo-nal. An interesting open questions is therefore whether it is possible to combine session-based with personalised strategies to obtain the best of the two worlds.
Topic detection is a broad field in machine learning, particularly for processing text. Topics of static data collections such as text corpora are traditionally identified using Latent Dirichlet Alloca-tion (LDA) [5] and variations thereof. The evolution of topics in data streams is for instance detected by modelling time [33] or by introducing additional dependencies [2]. Other approaches, such as dynamic topic models [4] and online LDA [1], study segmented data streams. The idea is to turn topics of previous segments into priors for the actual time slice. A drawback of these approaches is that the topics remain constant across segments; effectively the same topics are re-identified and there is no mechanism to discard outdated topics or to introduce new ones.

Barbieri et al. [2] extend LDA to a first-order Markov model that determines topics of interest for collaborative recommendations. They propose a personalised recommender system based on user click histories where topics are identified for every user in the sys-tem. Wang and Blei [31] study LDA with collaborative filtering and matrix factorisation. They deploy topic models to assess con-tent similarities in the reduced space of topics. Similarly, Chatzis [10] proposes to combine collaborative filtering with indian buf-fet processes for movie recommendations. The three approaches therefore aim at capturing long-term interests of users and an ap-plication to short-term goals of a session is not straight forward. By contrast, Wang and Zhang [32] propose a session aware recom-mender system that aims to capture the general intention of users in terms of three predefined and abstract categories: repurchase, variety-seeking, and buying new products. Note that the topics in [2, 31, 10, 32] are computed prior to the recommendation and can thus be considered static.

Markov decision processes (MDPs) [29, 24] are frequently used for sequential decision-making under uncertainty. Shani et al. [28] introduce sequential MDPs for recommender systems. Prior to their work, Zimdars et al. [35] propose a sequential recommender system where item recommendations are computed by random fo-rests. Rendle et al. [26] study first-order Markov chains with ma-trix factorisation for basket recommendations. A reinforcement learning approach to recommender systems based on Q-learning has been presented in [30]. Moreover, Karatzoglou [16] combines temporal and collaborative aspects by minimising regularised loss functions. We design our approach based on fMDPs to take ad-vantages of both, MDPs and factorisations. Factored MDPs are introduced by Boutilier [6].
We presented a sequential session-based approach for detecting the intention of user sessions on the Web. We phrased the problem as a topic detection task in terms of item attributes and proposed to solve the task via factored MDPs. We argued that a straight for-ward application is infeasible and devised an efficient formulation b y assuming independence of attributes. We showed that factored MDPs with independent components admit an equivalent represen-tation as an ensemble of independent fMDPs with structured value functions. Additionally, we presented an approximation of the en-semble and evaluated both methods on a large click log. Our em-pirical results showed that our methods were able to accurately de-tect topics of sessions. Translating our approach into a topic-driven recommender system outperformed collaborative baseline methods simple straw men.
 We would like to thank Chong Wang and David M. Blei for sharing their code with us on short notice. We are grateful to Zalando for sharing data and actively supporting our work. Maryam Tavakol is supported by a Zalando scholarship. [1] L. AlSumait, D. Barbar X , and C. Domeniconi. Online LDA: [2] N. Barbieri, G. Manco, E. Ritacco, M. Carnuccio, and [3] R. Bell and Y. Koren. Scalable collaborative filtering with [4] D. M. Blei and J. D. Lafferty. Dynamic topic models. In [5] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [6] C. Boutilier, T. Dean, and S. Hanks. Decision-theoretic [7] C. Boutilier, R. Dearden, and M. Goldszmidt. Stochastic [8] H. Cao, D. H. Hu, D. Shen, D. Jiang, J.-T. Sun, E. Chen, and [9] A. Celikyilmaz, D. Hakkani-T X r, and G. T X r. Leveraging [10] S. P. Chatzis. A coupled indian buffet process model for [11] M. Daoud, L. Tamine-Lechani, M. Boughanem, and [12] G. Giannopoulos, U. Brefeld, T. Dalamagas, and T. Sellis. [13] C. Guestrin, D. Koller, R. Parr, and S. Venkataraman. [14] P. Haider, L. Chiarandini, and U. Brefeld. Discriminative [15] A. Hassan, R. Jones, and K. Klinkner. Beyond DCG: user [16] A. Karatzoglou. Collaborative temporal order modeling. In [17] D. Koller and R. Parr. Computing factored value functions [18] L. Li, W. Chu, J. Langford, and R. E. Schapire. A [19] G. Linden, B. Smith, and J. York. Amazon.com [20] Z. Ma, G. Pant, and O. R. L. Sheng. Interest-based [21] I. K. Paparrizos, B. B. Cambazoglu, and A. Gionis. Machine [22] I. Pil X szy, D. Zibriczky, and D. Tikk. Fast ALS-based matrix [23] S. Purushotham, Y. Liu, and C.-C. J. Kuo. Collaborative [24] M. Puterman. Markov Decision Processes . Wiley, New York, [25] N. Ramakrishnan, D. Conry, and Y. Koren. Recommender [26] S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. [27] E. Sadikov, J. Madhavan, L. Wang, and A. Halevy.
 [28] G. Shani, D. Heckerman, and R. I. Brafman. An MDP-based [29] R. Sutton and A. Barto. Reinforcement learning: An [30] N. Taghipour, A. Kardan, and S. S. Ghidary. Usage-based [31] C. Wang and D. M. Blei. Collaborative topic modeling for [32] J. Wang and Y. Zhang. Opportunity model for e-commerce [33] X. Wang and A. McCallum. Topics over time: a non-Markov [34] R. W. White, P. N. Bennett, and S. T. Dumais. Predicting [35] A. Zimdars, D. Chickering, and C. Meek. Using temporal
