 Multilingual speakers tend to exhibit code-mixing and code-switching in their use of language on so-cial media platforms. Code-Mixing is the embed-ding of linguistic units such as phrases, words or morphemes of one language into an utterance of an-other language whereas code-switching refers to the co-occurrence of speech extracts belonging to two different grammatical systems (Gumperz., 1982). Here we use code-mixing to refer to both the sce-narios.

Hindi-English bilingual speakers produce huge amounts of CSMT. Vyas et al. (2014) noted that the complexity in analyzing CSMT stems from non-adherence to a formal grammar, spelling variations, lack of annotated data, inherent conversational na-ture of the text and of course, code-mixing. There-fore, there is a need to create datasets and Natural Language Processing (NLP) tools for CSMT as tra-ditional tools are ill-equipped for it. Taking a step in this direction, we describe the shallow parsing pipeline built during this study. Bali et al. (2014) gathered data from Facebook generated by English-Hindi bilingual users which on analysis, showed a significant amount of code-mixing. Barman et al. (2014) investigated lan-guage identification at word level on Bengali-Hindi-English CSMT. They annotated a corpus with more than 180,000 tokens and achieved an accuracy of 95.76% using statistical models with monolingual dictionaries.

Solorio and Liu (2008) experimented with POS tagging for English-Spanish Code-Switched dis-course by using pre-existing taggers for both lan-guages and achieved an accuracy of 93.48%. How-ever, the data used was manually transcribed and thus lacked the problems added by CSMT. Vyas et al. (2014) formalized the problem, reported chal-lenges in processing Hindi-English CSMT and per-formed initial experiments on POS tagging. Their POS tagger accuracy fell by 14% to 65% without using gold language labels and normalization. Thus, language identification and normalization are criti-cal for POS tagging (Vyas et al., 2014), which in turn is critical further down the pipeline for shallow parsing as evident in Table 5.

Jamatia et al. (2015) also built a POS tag-ger for Hindi-English CSMT using Random Forests on 2,583 utterances with gold language labels and achieved an accuracy of 79.8%. In the monolin-Lang. All Sentences Only CM Sentences Hindi 6318 (57.05%) 5352 (63.34%) English 3015 (27.22%) 1886 (22.32%) Total 11075 8450 gual social media text context, Gimpel et al. (2011) built a POS tagger for English tweets and achieved an accuracy of 89.95% on 1,827 annotated tweets. Owoputi et al. (2013) further improved this POS tagger, increasing the accuracy to 93%. CSMT was obtained from social media posts from the data shared for Subtask 1 of FIRE-2014 Shared Task on Transliterated Search. The existing annota-tion on the FIRE dataset was removed, posts were broken down into sentences and 858 of those sen-tences were randomly selected for manual annota-tion.

Table 1 and Table 2 show the distribution of the dataset at sentence and token level respectively. The language of 63.33% of the tokens in code-mixed sentences is Hindi. Based on the distribution, it is reasonable to assume that Hindi is the matrix lan-guage (Azuma, 1993; Myers-Scotton, 1997) in most of the code-mixed sentences. 3.1 Dataset examples 1. hy... try fr sm gov job jiske forms niklte h... 2. To tum divya bharti mandir marriage kendra 3.2 Annotation Annotation was done on the following four layers: 1. Language Identification : Every word was 2. Normalization : Words with language tag  X  X i X  3. Parts-of-Speech (POS) : Universal POS tagset 4. Chunking : A chunk tag comprises of chunk la-This whole dataset was annotated by eight Hindi-English bilingual speakers. Two other annota-tors reviewed and cleaned it. To measure inter-annotator agreement, another annotator read the guidelines and annotated 25 sentences (334 tokens) from scratch. The inter-annotator agreement calcu-lated using Cohen X  X   X  (Cohen, 1960) came out to be 0.97, 0.83 and 0.89 for language identification, POS tagging and shallow parsing respectively. Shallow parsing is the task of identifying and segmenting text into syntactically correlated word groups (Abney, 1992; Harris, 1957). Shallow pars-ing is a viable alternative to full parsing as shown by (Li and Roth, 2001). Our shallow parsing pipeline is composed of four main modules, as shown in Figure 1. These modules, in the order of their usage, are Language Identification , Normalization , POS Tag-ger and Shallow Parser .

Our pipeline takes a raw utterance in Roman script as input on which each module runs sequen-performs well on Hindi-English CSMT (Jamatia et al., 2015) was used to tokenize the utterance into words. The Language Identification module assigns each token a language label. Based on the language label assigned, the Normalizer runs the Hindi nor-malizer or the English/Rest normalizer. The POS tagger uses the output of the normalizer to assign each word a POS tag. Finally, the Shallow Parser assigns a chunk label with boundary.

The functionality and performance of each mod-ule is described in greater detail in the following subsections. 4.1 Language Identification While language identification at the document level is a well-established task (McNamee, 2005), iden-tifying language in social media posts has certain challenges associated to it. Spelling errors, phonetic typing, use of transliterated alphabets and abbrevi-ations combined with code-mixing make this prob-lem interesting. Similar to (Barman et al., 2014), we performed two experiments treating language iden-tification as a three class ( X  X i X ,  X  X n X ,  X  X est X ) classi-fication problem. The feature set comprised of -BNC : normalized frequency of the word in British National Corpus (BNC) 3 . LEXNORM : binary fea-ture indicating presence of the word in the lexical normalization dataset released by Han et al. (2011). HINDI DICT : binary feature indicating presence of the word in a dictionary of 30,823 transliterated Hindi words as released by Gupta (2012). NGRAM : word n-grams. AFFIXES : prefixes and suffixes of the word.

Using these features and introducing a context-window of n-words, we trained a linear SVM. In another experiment we modeled language identifica-tion as a sequence labeling task, where we employed CRF into usage. The idea behind this was that code-mixed text has some inherent structure which is largely dictated by the matrix language of the text. The latter approach using CRF had a greater accu-racy, which validated our hypothesis. The results of this module are shown in Table 3. 4.2 Normalization Once the language identification task was complete, there was a need to convert the noisy non-standard tokens (such as Hindi words inconsistently written in many ways using the Roman script) in the text into standard words. To fix this, a normalization module that performs language-specific transforma-tions, yielding the correct spelling for a given word was built. Two language specific normalizers, one for Hindi and other for English/Rest, had two sub-normalizers each, as described below. Both sub-normalizers generated normalized candidates which were then ranked, as explained later in this subsec-tion. 1. Noisy Channel Framework : A generative 2. SILPA Spell Checker : This subnormalizer
The candidates obtained from these two systems are ranked on the basis of the observed precision of the systems. The top-k candidates from each system are selected if they have a confidence score greater than an empirically observed  X  . A similar approach was used for English text normalization, using the English normalization pairs from (Han et al., 2012) and (Liu et al., 2012) for the noisy channel frame-language tag  X  X est X  were left unprocessed. The ac-curacy for the Hindi Normalizer was 78.25%, and for the English Normalizer was 69.98%. The over-all accuracy of this module is 74.48%; P@n (Preci-sion@n) for n=3 is 77.51% and for n=5 is 81.76%. 4.3 Part-Of-Speech Tagging Part-of-Speech (POS) tagging provides basic level of syntactic analysis for a given word or sentence. It was modeled as a sequence labeling task using CRF. The feature set comprised of -Baseline : Word based features -affixes, context and the word itself. LANG : Language label of the token. NORM : Nor-malized lexical features. TPOS : Output of Twitter POS tagger (Owoputi et al., 2013). HPOS : Output of IIIT X  X  Hindi POS tagger 6 . COMBINED : HPOS for Hindi words and TPOS for English and Rest. The results of POS Tagger are shown in Table 4. 4.4 Shallow Parsing A chunk comprises of two aspects -the chunk boundary and the chunk label. Shallow Parsing was modeled as three separate sequence labeling prob-lems: Label , Boundary and Combined , for each of which a CRF model was trained. The feature set comprised of -POS : POS tag of the word. POS Context : POS tags in the context window of length 5, i.e., the two previous tags, current tag and next two tags. POS LEX : A special feature made up of concatenation of POS and LEX. NORMLEX : The word in its normalized form. The results of this module are shown in Table 5. The best performing model was selected from each module and was used in the pipeline. Table 6 tabu-lates the step by step accuracy of the pipeline calcu-lated using 10 fold cross-validation. In this study, we have developed a system for Hindi-English CSMT data that can identify the language of the words, normalize them to their standard forms, assign them their POS tag and segment them into chunks. We have released the system.

In the future, we intend to continue creating more annotated code-mixed social media data. We would also like to improve upon the challenging problem of normalization of monolingual social Hindi sen-tences. Also, we would further extend our pipeline and build a full parser which has aplenty applica-tions in NLP.

