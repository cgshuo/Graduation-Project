 ORIGINAL PAPER Ehtesham Hassan  X  Santanu Chaudhury  X  M. Gopal Abstract The paper presents a novel framework for large class, binary pattern classification problem by learning-based combination of multiple features. In particular, class of binary patterns including characters/primitives and symbols has been considered in the scope of this work. We demon-strate novel binary multiple kernel learning-based classifica-tion architecture for applications including such problems for fast and efficient performance. The character/primitive clas-sification problem primarily concentrates on Gujarati and Bangla character recognition from the analytical and exper-imental context. A novel feature representation scheme for symbols images is introduced containing the necessary elas-tic and non-elastic deformation invariance properties. The experimental efficacy of proposed framework for symbol classification has been demonstrated on two public data sets. Keywords Feature combination  X  Character recognition  X  Symbol recognition  X  Multiple kernel learning 1 Introduction Binary pattern classification is an important problem in var-ious real-world recognition applications. These applications require two separate modules; an effective scheme for rep-resentation of the pattern in terms of useful features and a robust classification system. The effectiveness of a feature is defined by its invariance to size, orientation, distortions and noise for samples belonging to the same class, and by high variance across different classes. The classifier is expected to learn the discriminating boundary between example cate-gories for robust classification. Conventionally, colour, shape and texture has been the preferred cues for object representa-tion in computer vision. However, shape and structure are the primary attributes for feature-based representation of binary patterns. Ability of a feature to capture distinctive character-istics of classes varies with the inherent variabilities embed-ded in the individual classes. Use of different feature sets can provide complementary information about characteris-tics of different classes. The recognition performance can significantly increase by combining different features by a principled approach. In this paper, we explore the applica-tion of multiple features for binary pattern recognition. Sum-mary of proposed concepts and experimental evaluations on small data collection is presented in [ 23 ]. In this work, two important binary pattern recognition problems namely char-acter primitive recognition and symbol recognition have been addressed. These problems offer similar challenges for clas-sification in terms of large categories and variation in exam-ples. These variations include deformations because of non-linear transformations and distortions including elastic and non-elastic deformations.

Recognition of the primitives is an important step in opti-cal character recognition (OCR). The basic OCR system seg-ments word image in set of character/symbol primitives and recognizes them using a classifier trained over standard tem-plates. Indian scripts belong to alpha-syllabic writing sys-tem with the basic unit consisting of consonants and vowels. The vowels are practised in independent/dependent manner. Use of dependent vowels and modifiers ( maatraas , diacritic marks, etc.) with base consonants exhibits large variations. Additionally, large set of compound characters are generated by consonant combinations (half and full forms), vowels and modifiers feature in the script. In such scenario, segmenta-tion of primitives from word image poses another challeng-ing problem. In the context of Indian scripts, the problem is further compounded because of the modifiers above and below the characters in the word formation (Fig. 1 shows use of modifiers for word formation). These problems make the primitive/character segmentation process highly error prone. We assume the availability of segmented primitives in the scope of present work. The segmentation in such scenario generates large primitive set of character glyphs and base characters. The recognition consequently results in large cat-egory classification problem. Simultaneously, these prim-itives exhibit complex combinations of cursive, horizontal and vertical structures. The recognition performance there-fore depends on feature space definition as well as gener-alization ability of classifier. In such scenario, application of multiple types of features exploiting inner detailed struc-tural characteristics as well as envelope shape of the primitive can provide desired classification accuracy. In this work, we explore this possibility. Additionally, a classifier learned by logical combination of different types of features would be more robust to segmentation errors than the classifier learned by single feature. We establish this by performing our exper-iments in cross-validation setting. Nevertheless, we empha-size that the above discussion on isolated character/primitive classification is primarily intended for the current develop-ment stage of Indian script recognition. For other scripts such as Latin, even beyond printed manuscript, i.e. in case hand-written documents, research has advanced to more advanced methods involving complicated modelling techniques. For example, the works discussed in [ 9 , 10 , 24 , 50 ] present appli-cation of graph modelling based approaches for handwritten document recognition.

Symbol recognition covers range of identification tasks performed in applications as document image analysis, graphics recognition and trademark/logo retrieval. The present work also considers class of binary graphic patterns, e.g. logos, trademarks or silhouette images as symbols. Sym-bols are used for graphical mode of information sharing and usually appear in isolation. The independence because of appearance in isolation commonly contributes to elastic deformations because of view point variations with rotation, scaling and shape distortions. In addition, symbols exhibit morphological distortion as protrusions, incision or hollow-ing in silhouettes. The visual properties of symbols also vary widely with change in application scenarios. To meet this unique challenge in variation of shapes of symbols, we have proposed a new shape-based feature descriptor.

Here, we present a scheme for the use of multiple fea-tures for character and symbol classification. Combinations of features for recognition is a well-researched problem [ 4 , 26 , 41 , 44 , 45 , 48 , 51 ]. We propose a learning-based frame-work to optimally combine features in large category prob-lems. The framework exploits the existing theory of multi-ple kernel learning (MKL), which has shown excellent per-formance in many recognition applications [ 22 , 28 , 47 ]. Fast classification is an essential requirement for practical recog-nition applications. A novel multi-class framework employ-ing MKL in directed acyclic graph (DAG) architecture is presented for fast classification. The character classifica-tion experiments target two prominent Indian scripts namely Gujarati and Bangla. The symbol recognition experiments concentrate on MPEG-7 shape data set available at [ 33 ] and GREC-SEG data set available at [ 25 ]. Experimental results have shown significant improvement over the existing results for both problems.

The paper is organized as follows: Sect. 2 presents review of existing work in Gujarati and Bangla OCR and sym-bol recognition in general. Section 3 presents the details of features used in this work. Additionally, novel shape-based descriptor for symbol images is presented. The pro-posed classification framework is discussed in Sect. 4 .The discussion briefly reviews the existing MKL formulations and presents the proposed DAG-based architecture for multi-class MKL. The experimental results and related discussions are presented in the Sect. 5 . The final section presents the concluding remarks. 2 Related works This section provides a review of the existing work in the field of Indian script OCR and symbol recognition. The char-acter and glyph primitives across the Indian scripts exhibit significant variations. However, the present work focusses on Gujarati and Bangla script characters for evaluation and analysis. In addition, the recent works in the direction of symbol/logo recognition are also discussed.

Gujarati is a prominent Indian script practised by approx-imately 60 million people. The script has 12 vowels and 34 + 2 1 consonants. In addition to basic symbols,  X  X owel modifiers X  (total 12 symbols) are used to denote the attach-ment of vowels with core consonants. Consonant X  X owel combinations are defined by attaching an unique symbol for each vowel to the consonant, called a dependent vowel mod-ifier. The dependent vowel can appear before, after, above or below the core consonant. In addition to basic consonants, Gujarati also uses consonant clusters (conjuncts). The devel-opment in Gujarati OCR is in infancy comparing with other Indian scripts like Devanagari, Bangla, Telugu and Tamil. The earliest work on Gujarati character recognition reported by Antani and Agnihotri applied first-and second-order Hu moments for character image representation [ 3 ]. The appli-cation of these features for recognition is demonstrated by nearest neighbour (NN) and Minimum Hamming Distance-based classification. Dholakia et al. [ 15 ] presented zone-wise identification algorithm for Gujarati script which separates the text in three logical zones, i.e. lower and upper modifier, and middle character. The identification helps to segment the character/symbols at zone level (Fig. 2 ). The strategy gener-ates finite number of symbol categories therefore resulting less misclassification. Followingthesimilar approachin[ 16 ], the authors applied Daubechies D4 wavelet transform-based feature representation. For the subset of middle zone sym-bols having 119 categories and 4173 examples (excluding the dependent vowel modifiers), the authors reported recog-nition accuracy of 97.59% with neural network-based classi-fier. Table 1 presents the concise description of data sets used in above cited papers. The absence of Shirorekha (horizontal line at the upper part of word formation) in Gujarati script displays unique appearance than Devanagari and Bangla. The recognition of independent symbols from each zone requires the identification of symbols as middle zone sym-bols (consonants + conjuncts + vowel modifier correspond-ingto/AA + half forms of consonants + half form of con-juncts), upper zone symbols (upper parts of vowel modifiers) and lower zone symbols . The possibility of distinct symbols defined by this combination is significantly higher than 119. Majority of these symbols are from middle zone having com-plex shapes, e.g. combination of consonants, half form of consonants and conjuncts. Additionally, some symbol cat-egories are very similar in appearance; therefore, making the recognition more difficult. Considering the large symbol set and shape complexity, the problem of Gujarati character recognitionisstillachallengingproblem.Thepaperproposes the application of multiple features for recognition because single feature representation is not sufficiently discrimina-tive. The novel concept of multiple kernel learning (MKL) provides efficient solution here. The MKL algorithms learn an optimal combination of set of kernels as part of training, therefore providing an intelligent method to combine mul-tiple features. It also provides the flexibility of learning the best kernel for the task than the traditional method of cross-validation.

Bangla is a widely researched script after Devanagari among Indian scripts for OCR development. The script con-sists of 11 vowel and 39 consonant characters in basic set. The shapes of vowels are modified when used with con-sonants except when used in the start of word or in pairs. Additionally, two or three consonants may be combined into complex shapes. These compound characters may appear alone or attached with a vowel modifier. The characters in a word are usually connected through headline (Shirorekha or Matra). Therefore, the OCR processing is required to segment/identify individual characters. The earliest work on Bangla OCR reported in [ 39 ] used NN-based classi-fier and connected component-based features for recogni-tion. In [ 35 ], Pal and Chaudhuri presented an OCR for uni-font Bangla documents. The recognition follows zone-wise approach, which first identifies three prominent horizontal zones in text followed by linear scanning based character segmentation. A multi-stage recognition framework is pre-sented by applying the structural and shape features over tree-based classification. The details of character segmenta-tion in Bangla OCR are discussed in [ 20 ]. Following the zone separation approach, Sural and Das [ 46 ] presented hierarchical framework employing multi-layer perceptron for recognition. The authors proposed Hough transform-based fuzzy features for addressing the noise presence in scanned documents. In [ 32 ], the author applied curvelet transform in combination with NN classifier for recognition. However, the performance of this approach on noisy and degraded documents is not documented. The recent work by Pal et al. [ 36 ] presented OCR for complex documents printed in different styles. However, these methods exploit the infor-mation represented through a single feature set. Details of some data sets used in Bangla script recognition are given in Table 2 . We observe that performance of above-discussed frameworksisnotguaranteedinfontvariationsaswellasseg-mentation errors because of inherent limitations of single fea-ture set. Most of these works are knowledge based and have not exploited machine-learning algorithms to their potential for designing/improving their system. In this case, the paper presents a robust classification framework by employing multiple feature-based representations for character/symbols images. The work also makes a novel attempt to explore the learning-based approach for feature combination in Bangla OCR.

Symbol recognition in the recent past has received sig-nificant research attention because of its importance in var-ious applications. In this context, large amount of con-tributions are available in both feature representation and classifier architecture. The comprehensive survey of early related works is presented in [ 12 , 30 ]. Feature extraction algorithms have primarily exploited shape information for symbol description. Introduction to various shape descrip-tors following MPEG-7 standards is presented in [ 8 ]. In this context, Mokhtarian et al. [ 1 ] defined curvature scale space for object image using the outer boundary information of closed contours. In [ 7 ], symbol description is generated using representative set of selected points from the training exam-ples. Alajlan et al. [ 2 ] presented triangle area representation by estimating the areas of triangles within the closed object boundary. The representation is scale, translation and rota-tion invariant. However, the invariance to deformations is not established. Shape context [ 6 ]-based symbol description rep-resents global object shape characteristics by a set of descrip-tors computed over points sampled along the boundary. The representation is robust to occlusions and deformations. However, classification requires correspondence matching for similarity-based labelling. Further, [ 43 ] presented multi-resolution shape context for symbol recognition by corre-spondence matching based similarity establishment. Recent works presented in [ 49 ] and [ 31 ] explored use of structural attributes for symbol representation. In [ 49 ], symbol recog-nition is addressed as graph matching problem which permits matching to be performed using simple point-pattern match-ing methods in a unified framework by embedding graph nodes into a metric space, whereas [ 31 ] exploited topological and geometrical information embedded in symbol structure and encoded it in a relational graph further used as symbol signature. Escalara et al. [ 17 ] presented blurred shape model for symbol representation to address soft, rigid and elastic deformations. The blurred shape model uses the spatial prob-ability of the appearance of shape pixels and their contexts for descriptor computation. The extension for rotational invari-ance in the model is presented as circularly blurred shape model [ 18 ]. However, the robustness of these feature rep-resentations in case of symbol rotations, partial occlusions and deformations, and high intra-class variations is not guar-anteed. In this direction, Barrat and Tabbone [ 5 ] presented Bayesian formulation for combining multiple descriptors for symbol recognition. The evaluation showed improvement in recognition accuracy with higher time complexity in com-parison with SVM classifier. In this paper, we present a new feature definition for symbols for addressing the problem of deformations. This feature is less sensitive to occlusion and possess rotation invariance. Subsequently, we present novel symbol recognition engine by learning-based feature com-bination using MKL. 3 Feature extraction The features used in this work are presented in this section. We have used 1. Feature map: a distance transform-based feature repre-2. Shape descriptor: a shape context based global shape 3. Histogram of oriented gradients 4. Modified shape descriptor: a modified version of shape The details of feature sets are as follows. 3.1 Feature map (FM) The feature map essentially represents the distance trans-form of the binary symbol/character image. The transform extracts the distance relationship between image pixels and presents the knowledge in template of the size of origi-nal image [ 40 ]. Conventionally, the template is referred as distance map. Therefore, the distance map is the greyscale equivalent of binary image having set of foreground (object) and background pixels. In the generation of distance map, the positions of non-feature pixels are replaced by their dis-tances to nearest feature pixel. The positions of feature pix-els are replaced by 0 X  X . For given binary image I ( x , y F remaining pixels F nonfeature are background pixels. Mathe-matically distance transform is defined as: D ( I ( x
Here,  X  p is the L p norm metric applied for computa-tion. In the present work, Manhattan distance is considered such that the generated distance maps consist of integer val-ues. The conventional distance transform consider all eight directions for map computation; however, the present work has considered only four prominent directions to reduce the transform computation time. In this sense, the distance map computation presents an approximate form of distance trans-form by considering only the four nearest neighbours. The computation process reads the original binary image as iden-tifies0 X  X .Thescanningprocessleaves0 X  X unchangedwhereas 1 X  X  which are four neighbours of 0 X  X  also remain unchanged. These 1 X  X  are marked, and the subsequent computation con-verts all the 1 X  X  which are four neighbours of marked 1 X  X  to 2 X  X  and identifies them as marked. The procedure follows until all the non-feature pixels are marked and the image is stored as corresponding distance map. Figure 3 shows the feature map for sample character images of Gujarati and Bangla script. The preprocessing step for transform computation includes bound detection of the symbol image. The feature map com-putation is parameter-independent process, therefore simpli-fying the parameter tuning problem. Additionally, the feature representation can be made constant dimension equal to nor-malized image size and can be easily used with different classifiers. 3.2 Shape descriptor (SD) The shape descriptor defines a generic representation scheme applicable for binary patterns including character and symbol images. The computation process for the descriptor ensures that the inner contours in complex shapes are also utilized for feature representation. The information of inner con-tours is used to give distinct representation to objects hav-ing similar outer boundary. The conventional approach of boundary-based descriptor computation detects object con-tour and randomly samples points from the contour coordi-nate set as descriptor points. The object X  X  shape is represented by point set P ={ P i } for i ={ 1 ,..., l } . Subsequently, set P is used for descriptor computation. The contour extraction methods have inherent limitation due to the involvement of edge detection. Additionally, the random sampling does not guarantee uniform distribution of points on the boundary. In our approach, a logical grid S of constant size is overlaid on object. The transition points over the grid lines are set of descriptor points P . Additionally, the boundary points coin-ciding with the grid lines are treated as descriptor points. A transition point is marked based on intensity change, i.e 0  X  1or1  X  0. The grid-based approach gives better point distribution with respect to distance and orientation in com-plex shapes. In addition, the shape information embedded in inner contours is also used efficiently. Figure 4 ashowsthe red circles as transition points on the horizontal and vertical grid lines.

Thedensityofdescriptorpointsvarieswiththecomplexity of object shape. The distribution of these points based on the relative arrangement is represented by log-polar histograms defining the shape context histograms. The histogram corre-sponding to point P i is computed by centring the log-polar origin to point location with bins having frequency of points based on log distances and angles [ 6 ]. The bins are uniform in log-polar space, therefore more sensitive to closely located points. Let [ d 0 , d 1 ] X  X  d 1 , d 2 ] X  X  X  X  X  d m  X  1 , d m and [  X  0 , X  1 ] X  X   X  1 , X  2 ] X  X  X  X  X   X  n  X  1 , X  n ] be the angular bins for the histogram. Parameter m and n are the number of dis-tance and angle bins. If D is the distance, and A is the angle matrix for P , the shape context h i for P i is computed as h ( p , q ) =
Function  X ( D ij , A i , j , d p  X  1 , d p , X  q  X  1 , X  q ) [ d
The summation of shape contexts for point set P is the rep-resentative of global distribution of point-pairs. The cumula-tivehistogram h sum isthedistributionoflogdistancesandrel-ative angles of points in P with bins containing the frequency of points arranged within defined distance and angle ranges. Thenormalized h sum isnamedaspointdistributionhistogram pdh .The pdh represents the structural arrangement of the shape and provides access to inherent semantic information embedded in the object shape. Similar shapes generate simi-lar point distribution histograms. The local shape properties defined by closely positioned point-pairs are expressed by the rising gradient of the pdh as seen in Fig. 5 a.
The global shape properties defined by distantly posi-tioned point-pairs are expressed in the peaks and descending surface. The pdh is treated as image and the amplitude infor-mation of its Fourier transform define the shape descriptor for object feature representation. The Fourier transform rep-resents the characteristic function of pdh and captures the periodicity in h sum . The computational steps are summarized as:  X  Extractionofpointset P andcomputationofshapecontext  X  Computation of h sum as l i = 1 h i  X  Shape descriptor F ( P ) is defined by the magnitude of
Fourier Transform of normalized ( h sum ) 3.3 Histogram of oriented gradients (HOG) The gradient feature is a directional feature which is suitable for both binary and greyscale image representations [ 13 ]. It has been popularly employed in many computer vision and character recognition problems. The HOG feature represents the distribution of orientation gradient in the local neighbour-hood. In this case, local gradient is computed by dividing the image in smaller regions defined as cells . In the present work, the contribution by each pixel in the local histogram compu-tation is weighted by gradient magnitude at the pixel location. The illumination and contrast invariance are obtained by the gradient normalization in local region. The normalization is performed by defining larger regions blocks by combin-ing neighbouring cells . Blocks may be overlapping or non-overlapping; however, we have considered non-overlapping blocks for normalization. The rectangular blocks are defined by grouping adjacent cells , and L 2 norm of the concatenated histograms corresponding to cells is computed for obtaining the normalization factor. 3.4 Modified shape descriptor (MSD) The shape descriptor presented in Sect. 3.2 conveys the object shape information by exploiting the distribution of relative distances and orientations of boundary points. The bound-ary points are the set of descriptor points which are sam-pled from the inner and outer contour of the object. The distribution referred as point distribution histogram is equiv-alently the distribution of point-pairs based on their structural arrangements. The robustness of the descriptor is established by dense distribution of point-pairs which is invariant in case of small shape variations and deformations.

Nevertheless, in practice, many symbols appear in dis-torted form having protrusions, incision or elastic deforma-tions. Such distortions are primarily due to irregular style of use. These distortions generate noisy point-pair distribu-tions. The following discussion presents the novel extension toensuretherobustnessofshapedescriptorinsuchsituations. We derive a subset of points from the original set of descrip-tor points. The derivation applies smoothing over the descrip-tor points in local neighbourhood. The operation results in blurred version of descriptor point set. The new point set is less sensitive to the artificial distortions and encodes the global object shape information. The spatial neighbourhood for smoothing the descriptor point set P is defined by placing a logical grid S centre . The grid S centre is smaller or equal to the original grid S used for extraction of P . The new point set P centre is defined as the centroid of the descriptor points from P located in rectangular regions of grid S centre . The centroid computation is done by averaging the local points in a region. Figure 6 shows an example symbol image. Grid S is shown by continuous black lines, and S centre is shown by dashed blue lines. The red circles are the descriptor points forming set P as the transition points over S . The green plus signs are P centre obtained as centroid of points in the rectangular region defined by logical grid S centre .

Subsequently, the modified shape descriptor is computed using the point set P centre . The computation steps follow the procedure as discussed in Sect. 3.2 with P centre replacing point set P . The use of P centre gives robust feature descrip-tion to symbols in case of artificial shape deformations. In addition, the computationally complexity of modified shape descriptor is significantly less because of | P centre | &lt; | 4 Multiple kernel learning for character/symbol classification In general, the classification problem addressing charac-ter recognition and symbol recognition is referred as large category problem. Fundamentally, OCR processing is done following two strategies. The first strategy follows direct recognition of the complete consonant X  X owel, consonant X  vowel modifiers or conjunct X  X owel combination. The com-binations generate large number of primitive classes, the recognition of which is practically very challenging task. In the second strategy, we can segment the consonants from the dependent vowel modifiers and recognize them sepa-rately. In this strategy, the primitive categories are signifi-cantlyreduced.Forexample,extendingthesecondstrategyto zone-wise recognition of Gujarati script reduces the primitive categories to 10%. In this case, classification complexity is also reduced by utilization of zone information as the process requires three separate classifiers for the task. Additionally, character segmentation following the zone-based separation generates highly dense distribution of primitives in middle zone, whereas it has sparse primitive distribution in upper and lower zones. This simplifies the recognition problem as a simple classifier, e.g. minimum distance classifiers, linear discriminant or template-based matching can perform effi-ciently for lower and upper zone primitives. Nevertheless, total number of primitive categories following zone-wise or direct recognition of all primitives is still large primarily because of minor inter-class variations between many primi-tives. For example the authors considered 119 symbol classes for Gujarati OCR in [ 16 ], and the Bangla OCR discussed in [ 11 ] considered 300 symbol categories. Also the frequency distribution in this case is highly unbalanced due to rare prac-tice of many characters.

Symbols mostly appear in isolated fashion. The selection of symbol set is generally context and application specific. Nevertheless irrespective of application domain, large types of conventionally significant symbols is prevalent in regular use. The appearances are generally influenced by rigid and non-rigid transformations for beautification resulting in high within class variation. Large symbol categories contributing high between class variation and complex within class vari-ations present a challenging task in designing an efficient symbol recognition system. In this section, we present novel MKL framework for large category recognition problems. We concisely review existing MKL formulations and intro-duce the binary MKL adopted in this work. The subsequent discussion presents the detail of proposed DAG-based archi-tecture multi-class MKL. 4.1 Existing MKL formulations Kernel methods in machine learning provide a set of algo-rithms which operate by projecting the input data to high dimensional feature space thanks to the famous kernel trick . The embeddings of data points to the high dimensional space is done implicitly by defining an inner product in the feature space, i.e. for two data points x 1 and x 2 the embedding is defined as  X ( x 1 ),  X ( x 2 ) . The inner product is defined by the kernel function K ( x 1 , x 2 ) .For N data points, the mapping givesapositivedefinitematrixofsize N  X  N definedaskernel matrix. The support vector machine (SVM) is demonstrated to be state-of-the-art classifier based on kernel learning and has been extensively applied for many classification prob-lems. The SVM is inherently a binary classifier which relies on a quadratic optimization problem to learn the maximum margin hyperplanes in the kernel space. The margin hyper-planeisdefinedbyasetoftrainingdatapointsnamelysupport vectors. The decision function is defined as y = w,  X ( x ) + b where parameter w represents the weights coefficients and b is the bias parameter. The hyperparameter search for SVM and kernel matrix parameter is done by cross-validation method. The recent research in SVMs and other kernel meth-ods has shown that using multiple kernels instead of single kernel can improve the interpretation of the decision function as well as classifier performance. This problem is solved in the multiple kernel learning (MKL) framework, where the optimal combination of the set of base kernel matrices is learned in the process of classifier learning. Additionally, the fact that typical learning problems often involve multiple het-erogeneous data source MKL provides a logical platform to combine information from different data sources. The infor-mation in this case is supplied in the form kernel matrices computed from different sources.

The most natural approach for MKL is considering lin-ear combinations of kernels. The combination of kernels is defined as K c = M k = 1  X  k K k , where  X  is defined as kernel weight parameters. In recent research, many MKL formula-tions have been proposed [ 27 , 38 , 42 ]. In this regard, consid-ering unweighed base kernel set, i.e. direct addition of ker-nels presents the simplest approach. In [ 29 ], Lazebnik et al. presented extensive discussion on different combinations of different features for texture analysis. However, unweighed addition gives equal preference to all kernels, which may not be optimal. Using a weighted combination of kernels is a more advanced approach. The weights in this case define the importance of the kernels for discrimination. The MKL algo-rithm learns these weight parameters from the training data. Lanckriet et al. [ 27 ] have proposed conic combination of kernel matrices by formulating a quadratically constrained quadratic program. In [ 42 ], Sonnenburg et al. formulated the MKL problem as semi-infinite linear program where the SVM parameters and kernel weights are learned simulta-neously in a two-step process. First, the SVM parameters are learned by a standard solver following the optimization of kernel weights by solving a cutting plane algorithm. In [ 34 ], the authors have considered weighted combination of the colour, shape and texture features for flower recognition. The weights are learned by optimizing the performance mea-sure. In a recent work [ 21 ], the authors have evaluated the MKL with direct combination of features with different set of features including SIFT and HOG features. Campos et al. [ 14 ] have used combined six different features using MKL for character recognition in Kannada and English scripts in natural images. 4.2 Binary MKL problem formulation We have adopted MKL SVM formulation proposed by Rako-tomamonjy et al. [ 38 ]. The formulation presents an effi-cient approach to learn sparse combination of kernels thus making it applicable for large scale problems. The spar-sity of the linear combination of kernels is controlled by a L 1 norm constraints on the kernel weights. The decision function of kernel-based SVM for an input x is defined as y ( x ) = f ( x ) + b , where f  X  H .The H is the Reproducing Kernel Hilbert Space (RKHS) associated with the best ker-nel K . If we prefer to use combination of kernels instead of using best kernel, the above decision function is modified as y ( x ) = k f k ( x ) + b , where f k  X  H k .The H k is the RKHS associated with kernel K k . Let us consider  X  is the vector representing the kernel combination weights. The formula-tion of primal optimization problem of MKL SVM is done by incorporating weighted L 2 norm regularization: such that t i k f k ( x i ) + t i b  X  1  X   X  i  X  i The above optimization problem can be decomposed in two steps.Inthefirststep,the f k , b and  X  i arelearnedwithfixed In the second step,  X  is optimized through a gradient descent step towards the minimum of the J (  X  ) . The two steps can be represented as min J (  X  ) such that
J (  X  ) = The constraints of the optimization problem defined in ( 2 ) are over the simplex. The problem is minimized by reduced gradient method, assuming that J (  X  ) is differentiable. Once the gradient of J (  X  ) is computed,  X  is updated in the descent direction such that the constraint on the simplex as well the positivity constraint of  X  are satisfied. The smoothness of f k is controlled by problem 3 is defined as such that i t i  X  i = 0 Thus, following the strong duality the objective function is redefined as J (  X  ) = X  1 The coefficient  X   X  i define the maximal hyperplane in a high-dimensional feature space, where the input data are mapped through k  X  k K k ( x i , x j ) . The gradient of the J (  X  ) case is defined as  X 
J  X  X  4.3 DAG-based classifier design Conventionally, the extension of SVM for multi-class prob-lem is done by decomposition-based methods, i.e. the prob-lem is decomposed in set of binary classification problems. Multi-class labelling is performed by combinatorial use of the binary classifiers. The two most preferred methodologies in this context are winner-takes-all using 1-Vs-rest binary classifiers and majority vote using 1-Vs-1 binary classifiers. However, classifier training with large data in case of 1-Vs-rest binary classifiers is computationally costly. In case of multi-class MKL by binary 1-Vs-rest MKL classifiers, the computational cost multiplies due to the joint optimization procedure. The 1-Vs-1 methodology requires N ( N  X  1 )/ 2 binary SVMs trained for each pair of classes in N class prob-lem. The labelling is done by applying the test point to all the binary classifiers and assigning the label from class set which gets maximum vote. Character/symbol recognition is described as large multi-class problem where application of N ( N  X  1 )/ 2 binary classifiers for final labelling is unaccept-ableinpractice.Thedecision-directedacyclicgraph(DDAG) framework proposed by Platt et al. [ 37 ] presents an efficient solution for combining the results of 1-Vs-1 binary SVMs for suchlargecategoryproblems.Theframeworkarrangesallthe binary SVMs in DAG architecture with N ( N  X  1 )/ 2 nodes in the graph (the graph for 4-class problem with symbolic binary classifiers is shown in Fig. 7 ). In the proposed frame-work, we arrange the set of binary MKLs in DAG framework. Figure 7 demonstrates the labelling process for test point x in 4-class problem in DAG framework. For N class problem, the process evaluates N  X  1 nodes, therefore significantly reducing the required number of kernel computations. The path followed by DDAG for a test point labelling is called its evaluation path. The average kernel computation for com-plete test data is obtained by averaging over the count of unique support vectors over the evaluation path for all test points.

The MKL formulation presented in Eq. ( 3 ) is applica-ble for binary classification. Considering the conventional approach of decomposing the multi-class problem in set of binary problems, the possible extension of Eq. ( 3 )isto define a global optimization problem J (  X  ) for joint opti-mization corresponding to all the binary classifiers. The objective function J (  X  ) is defined as N k J k (  X  ) . Since the global objective function is direct summation of individual {
J extendible by the principle of linearity. However, the global optimization problem is not applicable in case of DDAG architecture for multi-class MKL, as the test point labelling process does not include all binary classifiers. Therefore, the linearity assumption is not valid. Alternately, learning binary MKLs for all possible pairs of classes is another solu-tion. This approach seems more intuitive as the kernel matrix is most informative when it is aligned with the target vari-able. In addition, selection of unique  X  for all the binary classifiers is not justifiable as the decision plane correspond-ing to a classifier is optimal with respect to its kernel space representation. 5 Experimental results and discussion The section presents the evaluation of proposed concepts for two applications: primitive/character recognition and sym-bol recognition. The experiments first evaluate the individual effectiveness of the proposed features. The subsequent exper-iments apply the proposed classification framework over dif-ferent combination of features. 5.1 Character/primitive recognition The first part of experiments is performed on Gujarati and Bangla character/primitive recognition. The experimental data sets for both these scripts were compiled by charac-ter/symbol level segmentation of collection of printed docu-ment images using different strategies. The document images were scanned pages of different printed books published since 1950, manually type setted in more than five different fonts. The resolution setting was fixed at 300dpi. Figure 8 shows sample primitives from the experimental image col-lection. Common set of parameters have been applied for computing the feature representations corresponding to both data sets. The shape descriptor, feature map and HOG feature are used for primitive representation. The parameter descrip-tion of the features is as follows:  X 
Feature map for the example character/primitive images are computed after object bound detection and resizing to 32  X  32.  X 
Shape descriptor is computed after object bound detection andresizingto32  X  32 withlogicalgrid S isselectedofsize 16  X  16. The histogram parameters m and n are selected as 35 and 36.  X 
HOG feature is computed after object bound detection and normalization to 32  X  32 with each cell covering rectangu-larareaof8  X  8 pixels. The local histogram computation is done for 9 bins and the block level normalization is per-formed by 4 adjacent cells arranged as 2  X  2. Therefore, the HOG computation results in a vector of 144 elements. The Gujarati example set used for experiment contains 5, 7 and 240 primitive categories from lower, upper and middle zone, respectively. The example image distribution corre-sponding to three zones is as 457, 1,307 and 13,083 images, respectively. Each image was resized to 32  X  32 after post-processing of segmentation stage. The primitives are glyphs representing half or full forms of consonants, vowels or their combinations as discussed in Sect. 2 . The distribution shows that majority of primitive classes originate from middle zone. Additionally, distribution of training examples per category is minimum for middle zone primitives which require major attention for feature extraction and classifier design. There-fore, the major objective of experiments is to improve the classification of middle zone primitives. For all the experi-ments, feature sets have been used in original form without any scaling or dimension reduction. The results presented in this section are the average of fivefold cross-validation. The SVM parameter tuning is performed by grid-based search, and Euclidean distance is used for similarity measure in near-est neighbour-based classification. Initially, the discrimina-tive power of feature sets is established by applying them for lower and upper zone primitives for classification. The resultswithKNNandSVMclassifierarepresentedinTable 3 . The application of different features achieved classification accuracy between 95.89 and 99.32%. We accept the present results for these primitive categories and evaluate the middle zone primitive classification using individual features. The results in Table 4 shows similar order of accuracy using all the features.

In the next step, the features are applied for recognition using the proposed MKL-based classification. In this case, the base kernels for shape descriptor included linear, second-order polynomial and eight Gaussian kernels with variance ranging from { 2  X  3 ,..., 2 4 } . Similarly the base kernels for featuremapincluded19Gaussiankernelswithvariancerang-ing from { 2 0 ,..., 2 9 } and the base kernels for HOG included set of linear and 16 Gaussian kernels with variance ranging from { 10 0 ,..., 10 1 . 5 } . Inall theexperiments discussedinthis paper, the exponent of variances are scaled on linear scale with uniform step defined by the minimum and maximum and number of kernels. The results in Table 4 shows improve-ment of 0.43 X 1.08% in accuracy over NN-and SVM-based performance. Also the HOG feature-based classification is faster than other features.

For learning the combination of features, the base ker-nel set is formed by the union of individual base kernels. In case of combination of features using nearest neighbour classifier, the feature representation is defined by concatenat-ing different features. Initially pair-wise features are selected for MKL-based classification. The results are presented in Table 4 . Thecombinationof shapedescriptor andfeaturemap increased the classification accuracy by 1.03% with individ-ual best (Refer Table 4 ). The complementary nature of infor-mation represented by feature set is efficiently combined by MKL. The L 1 norm constraint over  X  forces some  X  k to zero, therefore selecting only few kernels for combination from the base kernel set. In the analysis of kernel weight parameter for the classifiers applied in the evaluation path of a test point, the average of sum of  X  k corresponding to each feature rep-resents its contribution in learning the optimal kernel space. The measure gives insight into the final classifier design as the estimate of information supplied by different features. In the present case, feature map contributed by 67.8% weight following the discussed procedure. The MKL-based combi-nation of shape descriptor and HOG increases the accuracy by small margin of 0.17% over individual best. The reason for small improvement is the exploitation of similar symbol characteristics for feature computation as both the features fundamentally represent shape property. HOG feature brings the major contribution with 96.5% weights in final combina-tion. The combination of HOG with feature map improved the classification accuracy by reasonable margin of 1.23% over the individual best. The result establishes the claim of efficient utilization of complementary information inbuilt in different features for performance improvement. HOG fea-ture again brings the major contribution with 87.3% weights though the dominance is lower than the observation in com-bination of HOG and shape descriptor. However, the combi-nation required marginally increased number of kernel com-putations.
 Finally, combination of shape descriptor, feature map and HOG feature is learned for recognition. The result in Table 4 shows that combination improved classification accuracy by 0.19% with marginal increase in average kernel computa-tions (2.41%) than pair-wise best results. The observation of  X  showed that HOG and feature map contributed 87.5 and 9.8% kernel weights. Additionally, we observe that the dis-tribution of kernel weights in different feature combinations has followed the trend of  X  SD &lt; X  FM &lt; X  HOG , which is in accordance with their performance with base classi-fiers (Table 4 ). The experimental results show that multiple feature-based primitive representation combined with MKL-based classification provides a robust classification frame-work for OCR applications. It must be observed that the features discussed above contain reasonable amount of over-lapping information; however, the MKL utilizes the com-plementary information from different features to learn the resulting feature space. The mean accuracies presented in Table 4 based on MKL classification have well-defined sig-nificance. Nevertheless, the observed difference between average means may have been generated by chance. In order to conclude the absolute mean difference, we also need to consider the within-group variability. In particular, if within-group variation is significantly smaller than inter-group vari-ation, we conclude that observation has a real effect. For such statistical analysis, a hypothesis test would further establish presentedclassificationresults.Here,thenullhypothesissays that mean accuracies for different groups are same. Cross-validation-based procedure generates set of accuracies (or selected performance measure) by considering each fold of the data set as testing set. Here, we perform one-way ANOVA (analysis of variance [ 19 ]) to test the difference between groups of accuracies obtained for different feature combi-nations. The procedure produces one-way analysis of vari-ance for classification accuracy with respect to used feature sets. Table 5 presents the one-way analysis of variance of cross-validation accuracies obtained by different feature and their combinations. The p values obtained for both classifi-cation configurations, i.e. DAG and 1-Vs-1 are significantly below significance level of 0.05 which establish real differ-ence between the presented mean accuracies.

The Bangla character recognition experiment is per-formed on image collection consisting of 17,000 example images of 49 categories. Each example was of size 28  X  28, subsequently resized following the specific procedure for different feature representations. The examples represent isolated Bangla alphabets (vowels and consonants) which appear in the middle zone of the word object. Therefore, images corresponding to Chandra Bindoo are not consid-ered for data set compilation. The available data set has been pre-processed by normalizing it to 32  X  32. The experiments estimate the improvement in classification accuracy by the application of multiple features by MKL. Similar experimen-tal methodology is adopted as discussed for Gujarati script. First, we evaluate the character classification accuracy using KNN and SVM as base classifiers. The SVM parameter tun-ing is performed by grid-based search following fivefold cross-validation. The results are presented in the Table 6 .
Infollowingstep,theproposedMKLframeworkisapplied for classification. The base kernel selection for each feature is as following: second-order polynomial and 17 Gaussian kernels with variance ranging from { 2  X  1 ,..., 2 7 } for shape descriptor, linear and 13 Gaussian kernels with variance ranging from { 2 2 ,..., 2 8 } for feature map, and set of lin-ear and 16 Gaussian kernels with variance ranging from { 10 0 ,..., 10 1 . 5 } for HOG. The results with individual fea-tures are shown in the Table 6 . The results using HOG feature is distinctly better using base classifier as well as MKL-based classifier. However, we observe that accuracy improvement is less than other features (0.44%, than 1.20% and 0.96% in case of shape descriptor and feature map in DAG architec-ture). In this case, feature map-based classifier requires least kernel computations while HOG-based classifier performs 0.06% more computations in comparison.

The MKL-based character classification using HOG fea-ture has shown reasonably acceptable performance (  X  99 . 07 %). However, to investigate further improvement in accuracy, we first learn combination of shape descriptor and feature map using MKL. In this case, the base kernel set is formed by union of individual base kernels. In case of nearest neighbour, the feature representation is defined by concate-nating different features. The results in Table 6 shows that optimal combination of both features has increased the clas-sification accuracy 1.25% in comparison with individually best. Nevertheless the process requires 14.25% more kernel computations. The observation of kernel weight parameter  X  showed that, on average 73.53% weight belonged to fea-ture map. The combination of HOG with other two features improved average classification accuracy by 0.41% at a com-putational cost of the similar order of when HOG is applied independently. The examination of  X  showed that for the final kernel used for classification, 89.11% kernels belonged to HOG and 6.17% belonged to feature map. The result is obvi-ous as the classification accuracy with HOG feature has been significantly high using SVM and MKL in comparison with other features. However, by combination of features using presented MKL framework, we are able to improve the char-acter classification accuracy by 0.85%. Results presented in Table 6 clearly show the improvement in classification accu-racy using combination of features. The MKL classification-based cross-validation accuracies obtained for different fea-tures and their combinations shown in Table 6 have been fur-ther validated using one-way analysis of variance-based sig-nificant test. Table 7 shows the comparative measures where the null hypothesis is rejected with significant confidence as shown by the obtained p values.

The above experiments demonstrate significant improve-ment in baseline (NN and SVM-based results). The clas-sification accuracy achieved for Gujarati character recogni-tion is significantly better in comparison with the results pre-sented in [ 16 ]. In addition, the framework has shown robust performance while considering more number of primitive categories. Bangla character recognition is much researched topic. Our framework has shown significant improvement over the baseline results. Additionally, the comparison of our results with [ 20 , 32 , 36 ] shows comparable or improved accuracy. Our framework presents an efficient classification approach for character recognition by efficient combination of structural and shape-based feature sets. Additionally, the classification framework is much faster than conventional framework which is an essential requirement for OCR based applications. 5.2 Symbol recognition The evaluation of proposed classification for symbol recogni-tion is performed on two standard data sets. First, set of exper-iments is performed on the MPEG-7 CE Shape-1 Part-B data set available at [ 33 ]. The collection consists of 70 symbol categories having 20 examples each. The examples exhibit significant variations covering translation, rotation, scaling and non-rigid deformations. First, different features discussed in the Sect. 3 are applied for symbol representation in NN and SVM-based classification. All the related experi-ments have been performed in cross-validation setting for 10-folds. NN-based classification is performed with euclidean distance as the similarity measure, and three nearest neigh-bours are considered for majority voting. The feature extrac-tion details for different representations are listed below.  X 
Feature maps for the example images are computed after symbol bound detection and normalization to 64  X  64.  X 
Shape descriptor is computed after symbol bound detec-tion and normalization to 128  X  128 with logical grid S of size 32  X  32. The histogram parameters m and n are selected as 40 and 36.  X 
HOG feature is computed after symbol bound detection and normalization to 128  X  128 with each cell covering rectangular area of 32  X  32 pixels. The local histogram computation is done for 24 bins and the block level nor-malization is performed by 4 adjacent cells arranged as 2  X  2.

Initial classification results presented in Table 8 estab-lish the effectiveness of HOG feature in addressing different shape distortions existing in symbol images. The localized approach for HOG computation incorporates strong invari-ance to minor degradations and distortions affecting parts of symbol shape.

Subsequently, the modified shape descriptor is applied for symbol image representation. The descriptor is computed after normalizing the bounded symbol image to 128  X  128. The logical grids S and S centr e are of size 32  X  32. The his-togram parameters m and n are selected as 40 and 36. The classification results are shown in Table 8 . The descriptor computation after smoothing the sampled boundary points improves its robustness. In general, inner contours are not very common in symbols images than the character images. In this case, the descriptor primarily represents global shape information. Nevertheless, the original shape descriptor is more sensitive to distortions, although the margin is reduced after smoothing the descriptor point set. The results estab-lish the effectiveness of the modified shape descriptor where the NN-based results are comparable with the recent result achieved in [ 18 ]. Additionally, the SVM-based classification achieved substantial improvement in the accuracy.
In the following experiment, multiple features are applied for symbol classification. The proposed framework learns optimal combination of different representations for the recognition. First, the pair-wise combination of modified shapedescriptor,fringemapandHOGisexperimented.Next, all the features are combined for recognition. The base ker-nel selection for each feature set is as follows: linear and 15 Gaussian kernels with variance ranging from { 2  X  1 ,..., for modified shape descriptor, linear and 13 Gaussian ker-nels with variance ranging from { 2 1 ,..., 2 7 } for feature map, and set of linear and 17 Gaussian kernels with variance uni-formly distributed over { 2  X  1 ,..., 2 3 } for HOG. The results are presented in the Table 9 . The pair-wise combinations of modified shape descriptor with feature map and HOG with feature map show significant improvement over individual best results. The combined application of HOG and modified shape descriptor does not improve the performance typically because of the overlapping nature of information. The com-bination of HOG with feature map achieved best result with 88.63% kernels contributed by HOG. Next, the combination of three features for recognition achieved comparable result to the combination of HOG with feature map. The analy-sis of kernel weight parameter  X  shows that HOG descriptor is the dominant contributor supplying 75.94% kernels with modified shape descriptor contributing 17.63% kernels. The results in Table 9 show 5.28% improvement in the classifica-tion accuracy over the results obtained in [ 18 ]. Additionally, the features proposed in this work are much easier to com-pute, and classifier training and prediction process are much simpler and straightforward. Again the DAG-based formu-lation is much faster for recognition. We have demonstrated that recognition performance is significantly improved by principled combination of simple features. HOG descriptor characterizes object shape information by orientation his-tograms computed in local neighbourhood. The modified shape descriptor considers global as well as local shape infor-mation for description. The fringe map is continuous descrip-tor and represents the structure of the object by extracting the distance information between pixels. These complementary informations are efficiently combined by our MKL-based classification framework which is established by the exper-imental analysis. Table 10 presents the one-way analysis of variance of cross-validation accuracies obtained by different feature combinations. For both classification configuration, i.e. DAG and 1-Vs-1, we observe that p values is signifi-cantly below significance level of 0.05. With such high value of F-statistics, the results strongly indicate the real difference between mean classification accuracies for different feature combinations. 5.2.1 GREC-SEG symbol recognition Additionally, we have also evaluated the proposed symbol recognition framework on GREC-SEG symbol recognition data set [ 25 ]. The data set consists of 60 instances of 80 different graphical symbols representing architectural and electrical equipments. The collection is a subset of original GREC database having straight lines without arcs. Exam-ple instances of different symbol categories are generated by applying three levels of synthetic distortion contributing 20 examples each. The distortion is applied by randomly shifting the nodes, i.e. joining points between two line seg-ments within predefined radius r selected as 5, 10 and 15, respectively. Feature sets discussed in Sect. 5.2 are applied for symbol representation with following parameters.  X  Feature maps for symbol images are computed after sym- X  Shape descriptor is computed after symbol bound detec- X  HOG feature is computed after symbol bound detection
Modified shape descriptor for symbol images is computed after normalizing the bounded symbol image to 128  X  128. The logical grids S and S centre areofsize32  X  32, and his-togram parameters m and n are set as 40 and 36.

For the present experiment, the complete collection is applied in fivefold cross-validation procedure. First, the recognition experiment with individual features is performed to evaluate the effectiveness of different descriptors. Results are presented in the Table 11 . The accuracy comparison establishes the superiority of HOG and MSD over other descriptors.

Subsequently, multiple features are applied for symbol recognition using proposed MKL-based classification frame-work. We have applied different combinations of above-described feature sets for evaluation. As the MKL platform learns the kernel space for classification by optimal combina-tion of base kernels, we have used similar set of base kernel matrices for all features. Base kernel set is formed by com-bining a linear kernel with 15 Gaussian kernels with variance uniformly distributed { 2  X  1 ,..., 2 6 } . In case of multiple fea-tures, the base kernel set remains unchanged. Table 11 shows the results.

Again, feature map does not provide sufficient discrim-inative attributes for effective symbol representation. Nev-ertheless, the combination of feature map with shape-based description shows significant improvement in the classifica-tion accuracy as shown in Table 11 . The analysis of kernel weight parameter  X  shows that HOG is the dominating con-tributor with 81.54% kernels in case of HOG combined with FM, whereas MSD contributed 78.76% kernels incase of MSD combined with FM. Here, the combination of HOG with FM has achieved maximum of 3.20% improvement in DAG-based classification in comparison with best accuracy obtained using individual features. The inclusion of MSD with HOG and FM does not show any improvement over paired combination of HOG and FM primarily due to over-lapping information. In the following step, we perform one-way analysis of variance (ANOVA) for validation of the pre-sented results. Table 12 shows the p value and other compara-tive measures for analysing the group of accuracies obtained for different feature combinations. The analytical parame-ters clearly reject the null hypothesis that all the means are equal. 6 Conclusion The paper proposed a novel classification framework for binary pattern recognition. We presented a novel frame-work for character/primitive labelling for Gujarati and Bangla script character recognition. The generalization of framework is demonstrated by application on symbol recog-nition. These applications are two important examples of large category binary pattern classification problem. The framework is based on MKL which efficiently combines different features for robust labelling. The experimental resultsdemonstratetheefficacyoftheframework.Theframe-work presents novel DAG-based architecture for MKL-based multi-class classification for addressing the need of fast recognition. In addition, a novel feature representation is proposed for symbol images exhibiting elastic deformations with other distortions. The symbol recognition on standard data set has achieved significant improvement in existing result. The evaluation of presented concepts for other Indian scripts and symbol data sets constitutes the scope of future work.
 References
