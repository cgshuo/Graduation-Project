 Given an ambiguous or underspecified query, search result diversification aims at ac-commodating different user intents within a single Search Engine Result Page (SERP). For example, a query  X  X ed cliff X  may represent several different search intents, such as  X  X  want to go to the Red Cliff movie website X  and  X  X  want to read various re-views of the movie Red Cliff. X  Given a query, typical diversification algorithms first try to identify these different intents, and then rank documents so that  X  X ovel X  docu-ments (i.e. those that are dissimilar to the ones ranked above them) are included in the SERP [1,4,5,16,17].

While automatic identification of different intents for a given query is a crucial step for result diversification, we argue that also important is the estimation of intent types (informational vs. navigational [3]). If it is possible to distinguish between informa-tional and navigational intents, search e ngines can aim to return one best URL for each navigational intent, while allocating more space to the informational intents within the SERP [13]. For example, consider the aforementioned navigational intent  X  X  want to go to the Red Cliff movie website X : the user probably wants one particular URL for this intent, so the search engine probably should try to allocate more space to the other more informational intents, for which more relevant documents basically means more informativeness.

In light of the above observations, we propose a new framework for search result diversification that is intent type-aware . The framework comprises the following steps: Subtopic mining and clustering. We first obtain subtopics from query suggestions, Intent importance estimation. Next, we estimate the importance of each intent by uti-Intent type estimation. We also classify each intent to either navigational or informa-Document reranking. Finally, we generate a diversified search result by leveraging Except for the character type feature used in intent type estimation, our framework is basically language-independent.
 Our experiments using the NTCIR-9 INTENT Japanese Subtopic Mining and Document Ranking test collections [18] show that: (a) our intent type estimation method for Japanese achieves 64.4% accuracy; and (b) our proposed diversification method achieves 0.6373 in D -nDCG [14] and 0.5898 in DIN -nDCG [12] over 56 topics, which are statistically significant gains over the top performers of the NTCIR-9 INTENT Japanese Document Ranking runs 2 . Moreover, our relevance oriented model significantly outperforms our diversity oriented model and the original model by Dou et al. [5]. 2.1 Intent Type Estimation Lee, Liu and Cho [9] proposed a method for identifying the user goals (informational or navigational) based on user-click behavior and anchor-link distribution. Dou, Song and Wen [6] utilized the click entropy to estimate intent types of queries. These studies con-cern only head queries, for which reliable statistics can be obtained from clickthrough data. In contrast, we aim to estimate the intent type of any given subtopic, and therefore their methods are not directly applicable. Li, Wang and Acero [10] constructed click graphs based on clickthrough data and developed query intent classifiers. In order to compensate for the sparsity of a click graph, they also used the contents of documents. Our approach also utilises both clickthrough data and search engine results, as we shall describe in Section 5. 2.2 Search Result Diversification Several search result diversification al gorithms have been proposed in the literature [1,4,5,16,17]. The common approach is to first identify multiple possible subtopics (or intents) for the given query, and to try to cover as many subtopics as possible with the SERP, by minimizing retrieved redundant docum ents for each subtopic. State-of-the-art diversification algorithms include IA-select by Agrawal et al. [1], xQuAD by Santos, Macdonald and Ounis [16] and the algorithm by Dou et al. [5]. Santos, Macdonald and Ounis [17] also proposed a diversification approach which takes intent types (naviga-tional and informational) into account. However, their approach does not aim to return one best URL for a navigational intent.

Our proposed algorithm uses the algorithm by Dou et al. as the starting point. 3.1 Subtopic Mining Resources Our subtopic mining component mines subtopics of a given query from three different resources, as described below.
 Query Suggestions. Query suggestions, which are  X  X uggested queries X  (a.k.a. query autocompletions) and  X  X elated queries, X  obt ained from WSEs are an easy and effective choice for obtaining subtopics. As Santos, Macdonald and Ounis [16] suggest that sug-gested queries are more effective for search re sult diversification, we also decided to use suggested queries rather than related queries. In our experiments, we use the  X  X fficial X  Japanese suggested queries as we shall describe in Section 7.1.
 Clickthrough Data. Another popular resource for obtaining subtopics is clickthrough data. In our experiments, we first obtained d ata that consists of approximately 14.8 mil-lion Japanese queries from Bing over a one month period (April 2012). Then, for each original query q , we used the following simple filters for obtaining candidate subtopics: extract all queries that (1) were issued by at least five unique users; and (2) are of the form  X  q plus an additional keyword. X  The first condition is designed to avoid subtopics that are too obscure; the second condition was devised based on the observation that most of the subtopics submitted by the NTCIR-9 INTENT Japanese Subtopic Mining participants conformed to this style 3 .
 Search Result Clusters. While either query suggestions or clickthrough data may work for simple phrase queries, these resources may not help when the original query is more complex. We therefore follow Zeng et al. [20] and use search result clusters for mining subtopic candidates. In their method, top N search results for the original query are grouped into K clusters based on key phrases (n-grams) extracted from snippets. As for the parameters, we used N = 200 and K =10 , following Zeng et al. [20].
The above method obtains words such as  X  X eviews X  and  X  X vd X : we thus add the original query to the mined words to form subt opics such as  X  X ed cliff reviews. X  Also, the above method requires a search engine for obtaining a ranked list of URLs with snippets for a given query. For this purpose, we used Microsoft X  X  internal web search platform WebStudio 4 . Unless otherwise noted, this is the search platform we use for creating document rankings throughout this paper. 3.2 Subtopic Clustering Having obtained candidate subtopics for a given query, the next step is to cluster subtopics in order to identify the intents .

As Dou et al. [5] reported that combining subtopics from multiple sources is useful for discovering user intents, we first pool all subtopics extracted from query sugges-tions, clickthrough data and search result cl usters. Recall that not all of our subtopics are head queries: thus click-based clustering methods [2,7] would not work for this purpose. Instead, we use a simple clustering a pproach based on search result contents.
First, we extract all terms from the titles and snippets in the top l web pages returned for each subtopic, using Bing API 5 . Then, we create a featur e vector for each subtopic, where each element represents the tf-idf va lue for an extracted term. Here,  X  X f X  is the total frequency of the term within the top l result (titles and snippets only) for the subtopic;  X  X f X  is the number of subtopics whose search results contain the term. By assuming that subtopics that share the same intent have similar search results, we can apply a clustering algorithm to the subtopics represented as vectors.

We apply the well-known Ward X  X  method [19] for clustering subtopics. As Ward X  X  method is a hierarchical agglomerative clustering (HAC) method, we stop clustering the subtopics when the minimum distan ce between two clusters is less than d avg ( q )  X  h , where d avg ( q ) represents the average distance between every pair of subtopics.
In this paper, we empirically set l and h to 200 and 0 . 3 , respectively. Having obtained clusters o f subtopics, we first estimate the importance of each representative subtopic , which we regard as a representation of a particular intent. Only the representative subtopics are used for diversifying the search result.

Our method for intent importance estimation is based on the overlap between a SERP for the original query and a SERP for each s ubtopic, and the rank information for each subtopic. The assumption is that the overlap between the sets of URLs near top ranks is more important than that between those at low ranks. Let D k ( q ) and D k ( c i ) denote the set of top k retrieved URLs for a query q and a subtopic c i , respectively. This method calculates the importance of c i given q as: where rank ( q,d ) is the rank of the document d in the ranked list for q . In this paper, we empirically set k to 200 . Since Broder [3] proposed his taxnomy of search intents (informational, navigational and transactional), some researchers have addressed the problem of classifying queries into intent types, especially for the first two intent types [6,8,9]. In contrast to their faithful interpretation of  X  X avigational X  ( X  The immediate intent is to reach a particular site  X  [3]), we adopt a broader interpretation for the purpose of search result diversifi-cation, following Sakai and Song [15]. To be more specific, in addition to homepage finding intents, we also consider single answer finding intents as navigational. For ex-ample, if the user submits a query  X  X reside nt obama full name, X  probably exactly one good web page that answers this question suf fices for this intent, and any additional web pages that contain the same information would be redundant. From the viewpoint of optimizing the SERP, these two types of intents can both be regarded as navigational.
We use SVM with RBF (Radial Basis Function) kernel to classify representative subtopics into navigational and informational intent types. Effective classification fea-tures were used in previous studies [6,8,9], but these are not suitable for our purpose for the following two reasons. First, as not all of the representative subtopics are head queries, statistics such as click entropy are not so reliable. Second, while these meth-ods may be suitable for separating homepage finding intents from informational intents, they are probably not for separating single answer finding intents from informational intents. For example, different users may click different URLs to find the answer to the aforementioned question:  X  X resident oba ma full name, X  just like with informational intents.

In order to solve the above two problems, we propose two categories of features for SVM below: click features and character type features. Only the latter category of features was designed for Japanese queries and is language-dependent. 5.1 Click Features Our first category of features for intent type estimation is based on clickthrough data. Recall that not all of our subtopics are head queries, and that therefore looking for oc-currences of the subtopics in the clickthrough data would not work. Instead, we assume that the rightmost term (or tail term ) of a query is often useful for estimating query intent types. For example, suppose that the user wants to read reviews of the movie Red Cliff: we assume that the user is likely to enter  X  X ed cliff review X  rather than  X  X eview red cliff. X  Here, the tail term  X  X eview X  suggests that the intent is informational: the user wants many relevant documents. Similarly, if the user wants to visit the Red Cliff offi-cial homepage, we assume that the user will en ter  X  X ed cliff homepage X : again, the tail term suggests that the intent is navigational. (Note that the actual queries and subtopics we currently handle are in Japanese.) Note that while the occurrrences of  X  X ed cliff re-view X  may not be frequent in the clickthrough data, those of  X  X eview X  probably are. Thus we try to avoid the sparsity problem.

More specifically, given a subtopic c , we first extract its tail term t . (If c consists of one term, then t is equal to c .) Then, we extract all queries that contain t as a tail term from the clickthrough data. As each reco rd in our clickthrough data contain a user id, a query, a clicked URL and its position, we can compute the following features for t : (1) Average number of clicked pages per query per user; (2) Average number of unique clicked URLs per query; (3) Average rank of the first clicked web page for each query for each user; (4) Average rank of the last clicked web page for each query for each user; and (5) Average rank of any clicked web pages for each query for each user. The first feature represents how many pages are clicked after a user issues a query; if this is small, the query whose tail term is t may be navigational. The second feature approximates the number of relevant URLs for a query containing t ; this should be small at least for homepage finding intents, if not for single answer finding intents. The other three features are to do with clicked ranks: for example, we can hypothesize that many homepage finding intents are easy to satisfy, as search engines often manage to return the home pages near the top ranks. In addition to these five features for t ,wealso compute the corresponding statistics for the most frequent query that has t as its tail term. Hence we use ten click features in total. 5.2 Character Type Features Our second category of features for intent type estimation is designed specifically for Japanese, and is based on character types. Unlike English, Chinese and many other languages, the Japanese language uses three distinct character types that are outside the ascii codes: kanji, katakana and hiragana. Kanji, also known as Chinese characters, is an ideogram; Katakana and hiragana are phonograms. Just like our click features, we examine the tail term of a given subtopic as described below.

We observed that when the intent is informational, the tail term tends to be made up from a single character set, e.g.  X  joho (an all-kanji word meaning  X  X nformation X ) X  and  X  osusume (an all-hiragana word meaning  X  X  ecommendation X ). X  On the other hand, ruru-kaisetsu (a kanji-katakana-combined word meaning  X  X xplanation of a new rule X ). X  Moreover, we observed that the similar tendency is also seen about a query.

In light of this observation, we count how many times the character types change in the tail term and the original query, and use them as features. Orii, Song and Sakai [11] also used these features for a Japanese question classification task and found it effective. As we mentioned earlier, our proposed diversification framework builds on the one proposed by Dou et al. [5], which has been shown to outperform IA-Select [1] and MMR [4]. The framework was also used at the NTCIR-9 INTENT Japanese Document Ranking subtask, where it outperformed other participating teams. We first describe the algorithm by Dou et al. , and then propose a few modifications below. 6.1 Dou et al.
 Let C denote the set of representative subtopics obtained as described in Section 4 and let c beamemberof C . We first generate a nondiversified ranked list for the original query q and for each representative subtopic c : following Dou et al. [5], we obtain 1,000 URLs for q and 10 URLs for each c .Let rank ( q,d ) denote the rank of document d in the nondiversified ranked list of q . According to Dou et al. , the relevance score of document d with respect to the original query q is given by rel ( q,d )=1 / rank ( q,d ) . Similarly, rel ( c, d ) , the relevance score of d with respect to a representative subtopic c is also computed.

Let R be the pool of candidate documents retrieved by the original query q and its subtopics, and let S n denote the top n documents selected so far. Dou et al. [5] employs a greedy algorithm which iteratively selects documents and generates a diversified rank-ing list. The n +1 -th document is given by: where  X  is the parameter that controls the trade off between relevance and diversity and we use  X  =0 . 3 , following Dou et al. [5];  X  ( d, S n ,C ) represents a topic richness score of d given the set S n : where w c is the importance of subtopic c . In this paper, w c is calculated by the method described in Section 4.  X  ( c, S n ) is the discounted importance of subtopic c given S n :
More details of this framework can be found in Dou et al. [5]. 6.2 Proposed Framework As the algorithm by Dou et al. does not consider intent types, we modify it in order to make it intent type-aware. We propose two modified methods, but first describe their common features.

In our intent type-aware models, the relevance score with respect to c is given by: timated by our SVM-based intent type estimation component. The key here is that the relevance score with respect to c is defined separately depending on intent types. In particular, we define the relevance score for the case where c is navigational as to reflect the fact that we want exactly one relevant document for such an intent. Whereas, rel inf ( c, d ) , the corresponding score for the informational case, differs ac-cording to our two models.
 Relevance Oriented Model. In our first model, we let rel inf ( c, d )=1 / rank ( c, d ) just as in the original model. However, we modify  X  ( c, S n ) : we still use Equation 4 if c is navigational, but let  X  ( c, S n )=1 regardless of n if c is informationa l. This is because Equation 4 penalizes  X  X edundant X  documents for each c regardless of the intent type. In intent type-aware diversification, multiple relevant documents for an informational intent are not necessarily  X  X edundant. X  Diversity Oriented Model. In our second model, we first rerank each ranked list for each informational intent c to obtain a new rank for document d (denoted by rerank ( c, d ) ), and let rel inf ( c, d )=1 / rerank ( c, d ) . The reranking is intended to prioritize documents that cover many intents compared to those that are highly relevant to one particular intent. Thus, for each document d in the original ranked list for c ,we first count the number of intents that also retrieved d . Using the number of covered in-tents as the first key (larger the better) and the original rank as the second key (smaller the better), we sort the original ranked list. This section reports on a component-by-component evaluation of our proposed frame-work using the NTCIR-9 Document Ranking test collections. 7.1 Data Our experiments utilize the NTCIR-9 INTENT Japanese Subtopic Mining and Docu-ment Ranking test collections [18]. These test collections were constructed as follows: 1. In the Subtpic Mining subtask, 100 topics were released to participating teams, who 2. The INTENT task organisers pooled th e submitted subtopics and let assessors man-3. The organisers then estimated intent probabilities based on assessor voting; 4. In the Document Ranking subtask, the same 100 topics were released to participat-5. The organisers pooled the submitted documents and let assessors conduct per-
As for the Document Ranking subtask, the document collection used in the Doc-ument Ranking task is the ClueWeb09-JA collection, which is the Japanese portion of ClueWeb09 6 . Per-topic graded relevance asse ssments are provided on a five-point scale: from L 0 (judged nonrelevant) to L 4 (highly relevant), based on assessments by two assessors for every topic.
 The organisers released query suggestion data , which were scraped from Google, Bing and Yahoo, for the NTCIR-9 INTENT topics to its participants, in order to enhance the repeatability of the participants X  experiments and to enable fair comparison. In our subtopic mining method, we al so utilise this data set.

In addition to the above official data from the INTENT tasks, we obtained the intent type labels for the INTENT-1 Japanese topics from Sakai and Song [15], so that we can conduct intent type-aware evaluation. According to the intent type labels, only 56 topics of the 100 Japanese INTENT-1 topics contains at least one navigational and informational intents. For this reason, her eafter we use these 56 topics only. On average, each topic has 2.32 navigationa l intents (21%) and 8.89 info rmational intents (79%).
Evaluating search result diversification using an existing diversity test collection, however, is problematic. This is because exis ting diversity test collections are highly unlikely to be reusable, as their relevance assessments are obtained through shallow pooling [13]. For example, TREC 2010 and NTCIR-9 diversity test collections all used the pool depth of 20. Therefore, if a new system is evaluated using the official relevance assessments, the system is underestimated, as it returns many unjudged documents, some of which might be relevant. In light of this, we conducted some additional rele-vance assessments of our own to obtain more reliable results, following the relevance assessment procedure used at the INTENT task. We shall discuss this in Section 7.3. 7.2 Results of Intent Types Estimation In this section, we discuss the accuracy of our intent type estimation component. As was described in Section 5, we use an SVM classifier to determine whether each given intent is likely to be navigational or informational. As SVM requires training data, we conducted the evaluation as follows. The 56 Japanese topics from the INTENT task had 1,902 (539 navigational and 1,363 informational) intents in total, but our subtopic min-ing and intent importance estimation components managed to identify only 481 of them (137 navigational and 344 informational). S ince the remaining 1,421 (402 navigational and 1,019 informational) intents are never used in any part of our evaluation, these un-used intents were utilized for training the SVM classifier. Furthermore, in order to avoid including extremely rare intents in the tra ining data, only those that have at least 50 hits in our clickthrough data were used. This gave us 819 intents (231 navigational and 588 informational). Finally, to balance the amount of training data, we randomly sampled 231 informational intents.

Table 1 shows the classification results for the aforementioned 481 intents. The over-all classification accuracy was (83 + 227) / 481 = 0 . 644 . It can be observed that nav-igational intents are more difficult to classify than the informational ones. From our classification results, we found that our approach that relies on tail terms has some clear limitations. In particular, it is often difficult to determine whether an intent is navi-gational or informational from its tail term alone. For example,  X  X eijing image X  (user wants pictures of Beijing) may be labelled as informational, as the information need is vague and it is not clear if any one particular image will completely satisfy the user. On the other hand,  X  X utch flag image X  (user wants an image of the Dutch national flag) may be labelled as navigational, as returning one item may suffice. The gold standard data set itself contains some gray area: Sakai and Song [15] report that the kappa agree-ment of intent type labels between two assessors was .713 for TREC diversity topics. In short, our intent type classification task itself is a difficult one. 7.3 Results of Search Result Diversification Evaluation Metrics. To finally evaluate the diversified search results, we use five evaluation metrics, namely, I-rec, D-nDCG , D -nDCG [14], DIN-nDCG and DIN -nDCG [13] 7 . The first three measures are the official metrics used at the NTCIR-9 INTENT task: D -nDCG is a linear combination of I-rec (a pure diversity measure) and D-nDCG (an overall relevance measure) . We evaluate the top 10 documents as our objective is to diversify the first search engine result page.

In contrast, the recently proposed DIN-nDCG and DIN -nDCG are more suitable for the purpose of intent type-aware diversity evaluation. DIN( )-nDCG is a simple modifi-cation of D( )-nDCG: the only difference is that, whenever multiple relevant documents are retrieved for a navigational intent, DIN( )-nDCG treats only the highest ranked rel-evant document as relevant to that intent. Th ese intent type-aware metrics were used at the NTCIR-10 INTENT-2 Document Ranking subtasks.
 More details on the evaluation metrics can be found elsewhere [13].
 Evaluation with the Intent Data. We evaluate the overall performance of our diver-sified search system using the intent sets from the INTENT task. In this experiment, we compared three methods: the framework by Dou et al. [5] ( Dou ), the relevance ori-ented model proposed in Section 6.2 ( REL ), and the diversity oriented model proposed in Section 6.2 ( DIV ). In addition, we obtained top performing runs from the NTCIR-9 INTENT Japanese Document Ranking tasks: MSINT-D-J-3 and MSINT-D-J-2, which were the top two performers in terms of both I-rec@10 and D -nDCG@10; and uogTr-D-J-1 and uogTr-D-J-2, which were the top two performers in term of D-nDCG@10. (These official results suggest that the MSINT runs are diversity oriented while the uog runs are relevance oriented [18].)
As we briefly mentioned in Section 7.1, we conducted some additional relevance assessments for this experiment as some of the documents returned by our systems are not covered by the official relevance assessments. The first two authors of this paper used the official relevance assessment tool from the INTENT task [18] to independently conduct relevance assessments for 97 unjudged documents, and the relevance assess-ments were merged with the official ones. Th e inter-assessor kappa agreement for this additional document set was 0.581, which is statistically significant at  X  =0 . 01 .
Table 2 shows the performances of our seven runs (three proposed systems plus four official runs from NTCIR-9). The runs have been sorted by DIN -nDCG. It can be observed that REL significantly outperforms all top performing runs from the NTCIR-9 INTENT Japanese Document Ranking task in terms of D -nDCG and DIN -nDCG.
 Table 3 summarize the significant test results when different diversification methods are compared. Table 3 shows that REL is the best diversification method. We proposed a new intent type-aware search result diversification framework, and con-ducted evaluation using the NTCIR-9 INTENT Japanese Subtopic Mining and Docu-ment Ranking test collections. Except for the character set-based feature used for intent type estimation, our proposed framework is basically language-independent.

Our main findings are as follows: (a) Our int ent type estimation method for Japanese achieved 64.4% accuracy. Moreover, navigati onal intents were more difficult to classify than informational ones; and (b) For search result diversification, methods using the relevance oriented model significantly outperformed our diversity oriented model and the original model by Dou et al. [5]. Our best method achieved 0.6373 in D -nDCG and 0.5898 in DIN -nDCG over 56 topics, which are statistically significant gains over the top performers of the NTCIR-9 INTENT Japanese Document Ranking runs.
 Our future work includes evaluation with English diversity test collections (i.e. TREC diversity data), and exploration of more sophisticated diversification methods. For example, our current models do not consider the contents of the documents already selected: some document features may be use ful for estimating whether a document is likely to be relevant to a navigational intent or to an informational intent, or even both. Acknowledgements. This work was supported in part by the following projects: Grants-in-Aid for Scientific Research (Nos. 24240013) from MEXT of Japan and JSPS KAKENHI Grant Number 243993.

