 1. Introduction
Computer games have become one of the most popular entertainment medium around the world. So what makes a successful video game? The answer is immersion. An immersive experience is produced when the game world is so well crafted that the player lose themselves in the game experience ( Li et al., 2010 ). As noted by Nicole Lazzaro, emotions are the key to great experiences ( Lazzaro, 2008 ).

Hence, more elaborate model of emotions is required for creating more realistic characters in video games. Actually, the accurate modeling of the emotional state of any agent, and changes to that emotional state, has long been the subject of extensive research ( Blewitt and Ayesh, 2008 , 2009 ). A large number of researchers have studied automatic emotion recognition ( Fasel and Luettin, 2003 ; Fragopanagos and Taylor, 2005 ; Hanjalic and Xu, 2005 ; Picard, 2003 ) and computational modeling of casual factors of emotion for human X  X omputer ( Bickmore and Picard, 2005 ; Hudlicka, 2003 ; Kasap, 2011 ; Paiva, 2000 ). However, only a small part of affective computing community is explicitly concerned with modeling the effects of emotions, such as formal modeling of cognitive appraisal theory ( Broekens et al., 2008 ; Marsella and Gratch, 2009 ; Meyer, 2006 ), affective influences on cognition ( Canamero, 2002 ; Gadanho, 2003 ; Hudlicka, 2005 ; Marsella and Gratch, 2009 ; Vela  X  squez, 1998 ), interacting emotional states in agent reasoning ( Coddington and Luck, 2003 ; Meyer, 2006 ; Steunebrink et al., 2008 ), and models of emergent emotions, that is emerging from the interaction between a simple adaptive agent and its environment ( Canamero, 2002 ; Lahnstein, 2005 ; Vela  X  squez, 1998 ).

In this paper, we firstly introduce a computational affective model called OpenPsi. It is inspired by PSI theory, which is proposed and described informally by German psychologist Dietrich D  X  orner D  X  orner et al., 2006 ). The emotional model is then applied to control a virtual robot living in a game world inspired by Minecraft ( http:// www.minecraft.net/ ). Simulations are performed for three distinc-tive scenarios. Finally, the experimental results are carefully ana-lyzed using one of the contemporary dynamic theories of emotions proposed by Lewis ( Lewis, 2000 , 2005 ).

D  X  orner X  X  PSI theory covers a wide range fields of intelligence, including knowledge representation, perception and bounded
Starker, 2004 ; D  X  orner et al., 2006 ). However, we mainly focus on its affective model, which is quite different from other emotional models like OCC ( Ortony et al., 1990 ). Emotion in PSI theory is not considered as an isolated component. Rather, it emerges from the interaction between the agent and the environment where the agent lives. The agent controlled by the PSI model is considered as an autonomous machine driven by internal motives that are related to urges, which stand for physiological, cognitive or social demands. Then emotions, in PSI model, are derived from the dynamics of the whole system, where the processes of perception, cognition and action selection interact with each other.
Lewis, similar with D  X  orner, possesses a non-linear, dynamic view of emotional activations ( Lewis, 2000 , 2005 ). He suggests that emotions should be considered as phenomenon, which emerge from the dynamics of the whole system. He argues that emotion X  appraisals may be conceived as phas e transitions including trigger phase, self-amplification phase and self-stabilization phase. Once triggered, recurrent interactions between microscopic processes of emotion appraisal induc e a rapid self-amplification effect on the activity of the interaction of the a ppraisal X  X motion constituents of the system. Positive feedback lo op between perceptual, emotional and attentional processes are firstly lured by the self-amplifying phase, but then inhibited or constra ined by negative feedback effects as the amplification grows. When ne gative feedback overtakes the system dynamics, the appraisal pro cess enters self-stabilization phase, where change decreases and continuity increases.
The experimental results show that OpenPsi proposed in this paper is a quite promising approach of emotion modeling. The emergent emotions fit quite well with different circumstances; and the phase transitions suggested by Lewis could be observed in the simulations.

In Section 2 , the emotional model within PSI theory is explained in detail. In Section 3 , dynamic theories of emotional models are discussed. In Section 4 , our computational affective model inspired by the PSI theory is described in detail. Section 5 covers three simulation results of OpenPsi. Section 6 concludes the paper with a discussion and future work. 2. The emotional model of PSI theory
The most distinctive feature of the PSI theory is its perspective on the autonomous choice and regulation of behaviors. It suggests that each goal-directed action has its source in a motive that is connected to an urge, which stands for a physiological, cognitive or social demand ( Bach, 2009 ). In order to verify the ability of the PSI model, D  X  orner also implemented virtual agents controlled by PSI living within a complex simulated game world ( Fig. 1 ). These
PSI agents are little virtual steam vehicles, which depend on fuel and water for their survival.

A PSI agent does not need any executive structure that controls its behavior, instead it is driven by demands. Some of the demands are related to external resources, like water and energy, or its integrity. There are also abstract cognitive demands, such as certainty and competence, while the affiliation demand is an example of social urge, which can only be fulfilled by other agents. Moreover, there is a threshold for each demand.
A deviation from the threshold set for a need will signal as an urge, which then give rise to an intention or a motive. There may be multiple motives at any given time but only one  X  X  X uling motive X  X  dominates the system. This active motive is selected based on the strength of the urge and the estimated chance of realization. After selecting a motive intention, actions of the agent are produced accordingly.

PSI agents are based on something like a  X  X  X ense X  X hink X  X ct X  X  cycle, but perception, planning and action do not occur in strict succession. Rather, they are working as parallel processes and are strongly interrelated. All actions of agents happen due to motiva-tional impulses, which are derived from a set of predefined dynamic demands. Perception, memory retrieval and action con-trol strategies are influenced by modulator parameters, which make up a setting that can be interpreted as an emotional configuration ( Fig. 2 ).
 D  X  orner has suggested four modulators:
Activation is the preparedness of perception and reaction. It helps the agent balance between rapid, intensive activity and reflective, cognitive activity. Fast behavior comes along with high level activation and becomes slower with decreasing level of activation.

Resolution level determines the accuracy of cognitive processes including perception, planning, action regulation, etc. It decrease with increasing activation. For example, when an agent gets angry (with high activation), it would probably not pay enough attention to the consequence of its action (with low resolution level).

Securing threshold controls the frequency of securing behavior, which can be implemented as a series of behavior programs that check unexpected changes in a dynamic environment. The securing threshold is proportional to the strength of the current motive, that is there would be less securing behavior (with high securing threshold) in the face of urgency. It also depends on the agent X  X  certainty of current circumstances. For instance, an undetermined environment would require more securing behavior (with low securing threshold).

Selection threshold indicates how easily the agent switches between conflicting motivations. It prevents oscillation of behavior by giving the current leading motive priority. It increases with heightening activation. For example, when escaping threats (with high activation), the agent is highly concentrated on current integrity demand (with high selection threshold).

Then emotions of PSI agents are recognized as areas in the multidimensional space spanned by a small set of proto-emotional dimensions in terms of basic demands and modulators. In the simplest approach, we can use a six-dimensional contin-uous space: Pleasure Activation Resolution level Securing threshold Selection threshold Level of goal-directed behavior It is worth noting that these dimensions are not orthogonal. Fig. 3 shows how they are derived from underlying urges and modulators. For instance, resolution is mainly inversely related to activation.

Then all sorts of emotions are recognized as regions in the space spanned by these dimensions. Sadness, for instance, is characterized by low activation, high resolution, weak motive dominance and low goal-orientedness; anger by high activation, low resolution, weak motive dominance and low goal-orientedness.

The approach to emotion modeling in the PSI theory is quite different from other emotional models, such as the OCC ( Ortony et al., 1990 ) model, which has established itself as the standard model for emotion synthesis. The OCC model describes a concise hierarchy of 22 emotions and specifies the conditions of each emotions in terms of actions, objects and emotions. Since the OCC model could be easily described in formal language, a number of computational models have been proposed by formalizing the OCC model, such as Egges et al. (2003) , Gebhard (2005) , Katsionis and Virvou (2005) , Kshirsagar (2002) , Liu and Pan (2005) .
However, emotion in PSI model is not considered as isolated component. Rather, it emerges from the dynamics of the whole system, where the processes of perception, cognition and action selection controlled by modulators interact together. Since the PSI theory is formulated within psychology, it has relatively little impact on the subject of emotion modeling within computer science. Joscha Bach has extended the original PSI theory and implemented a concrete model named MicroPsi ( Bach, 2003 , 2008 ; Bach et al., 2006 ). The OpenPsi proposed in this paper is another computational model inspired by the PSI theory as well. However, unlike MicroPsi which is very close to the original PSI theory, we intend to only implement the essential motive driven system of the PSI theory and reserve flexibility of building other cognitive components, including knowledge representation, per-ception, planning and learning. 3. Dynamics of an emotional model
Affective computing has been studied for decades. However, many researchers mainly focus on automatic emotion recognition and computational modeling of casual factors of emotions; and only a few of them pay special attention to the dynamics of the cognitive appraisal processes. Lewis is one of those researchers interested in the dynamics of emotional models.

Lewis (2005) , like D  X  orner also holds a non-linear, dynamic view of emotional activations. He argues that emotions are actually both cause and effect of appraisals. His  X  X  X ppraisal X  emotion amalgams X  X  model places emphasis on the emergence of stable states, which is induced by the effects of negative feedback on the amplifying effect on states receiving positive feedback. This increasingly popular position as to a possible mechanism for the generation of emotions is similarly described by many neuroscientists. As Lowe et al. (2007) noted,  X  X  X he basic emotional systems may act as  X  X trange attractors X  within widespread neural networks that exert a certain type of  X  X eurogravitational X  force on many ongoing activities of the brain, from physiological to cognitive. X  X 
According to Lewis,  X  X  X ppraisal X  X motional amalgams are con-strued as globally coherent states arising and stabilizing through non-linear casual transactions among appraisal and emotion constituents. X  X  Once triggered, recurrent interactions between the microscopic process constituents of the emotion X  X ppraisal amalgams induce a rapid self-amplifying effect on the activity of the interaction of the appraisal X  X motion constituents of the system. The self-amplifying effect thus results in positive feed-back loop between perceptual, emotional and attentional pro-cesses that initially perpetuate the positive feedback effect, but are then inhibited or constrained by negative feedback effects as stabilization phase, i.e. phase transition, is referred to by Lewis as Emotion Interpretation or EIs.

We also argue that emotions should be considered as phe-nomenon that emerges from the dynamic of the whole system. As suggested by Smith and Thelen (2003) , there are two basic assumptions of the development of a dynamic system,
Multicausality . Dynamic systems are complex systems made up of many individual elements, none of which has causal priority. Such systems can exhibit coherent behavior inher-ently, that is the parts are coordinated without an executive agent or a central programme that produces the organized pattern. Rather, the coherent is formed in the relationship between the organic components and the constraints, and opportunities of the environment. These self-organized sys-tems are characterized by the instability or relative stability of their states.

Nested timescales . Behavioral changes occur over different time-scales. As illustrated in Table 1 , emotional episode happens in secondsorminutes,whilethemoodlastsforhoursordays,and the personality may even take yea rs to develop. For the organism, the dynamics of one time-scale (e .g. emotional episode) must be continuous with and nested within the dynamics of all other time scales (e.g. the changes of the mood or the development of the personality). That means time is unified and coherent, as are the collaborating elements of the system.

Lewis X  X  dynamical systems approach to emotion X  X ppraisals provides a bridge between psychological and neurobiological mechanisms for emotion X  X ppraisal processing. The crux of his model could be summarized as follows:
Trigger phase is usually the beginning of an appraisal X  X motion episode, when the orderly behavior of the system is inter-rupted by a perturbation, resulting in rapid loss of orderliness and an increase in sensitivity to the environment. It is characterized by sudden changes and temporary disorders as the system switches to a new organization. Thus a trigger indicates a phase transition.
 Self-amplification phase follows perturbation and nucleation.
When the system enters positive feedback loops, it is domi-nated by positive feedback. It is highly sensitive, i.e. small deviations may be rapidly amplified.

Self-stabilization phase happens when negative feedback takes over the dynamics of the system, change decreases and continuity increases. Principles of dynamical systems suggest that the consolidation of coherent emotion X  X ognitive appraisal states is necessary for complexification, allowing appraisals to become more elaborate and articulated.

Learning cognition X  X motion associations that tend to recur in future is the connection between biases, believes, traits, emotional habits and real-time appraisal processes. The self-stabilization phase is the necessary precondition for this learning. When appraisals have stabilized, interp retations, action plans and expec-tancies endure for some period of time. Learning is then fulfilled by strength the connectivity among these elements, which are reciprocally activated in real time appraisals.

According to Lewis X  X  dynamic theory, emotions can be under-stood based on the instability of appraisal and emotion response.
We suggest that different phase transitions of emotions among trigger, self-amplification and self-stabilization are the results of multicausality of processes in dynamic systems, and the coher-ence of emotional process in nested timescales can be achieved by learning. 4. OpenPsi in detail 4.1. Architecture overview The OpenPsi is implemented within the framework of Open-Cog ( http://www.opencog.org ), which is an open source Artificial General Intelligence (AGI) software under active development.
OpenCog has been used in the area of natural language processing ( Lian et al., 2010 ), data mining, and controlling virtual dogs in virtual worlds ( Goertzel et al., 2010 ).

The general architecture of OpenPsi is presented in Fig. 4 .It consists of six  X  X  X ind agents X  X  running on top of the knowledge base. A  X  X  X ind agent X  X  is a software object that could access the knowledge base and runs concurrently like system thread. Since each  X  X  X ind agent X  X  is relatively simple and does very specific jobs, none can induce complex behaviors on itself. However, all the  X  X  X ind agents X  X  are closely related via the global knowledge base and talk with each other through messages, which may result in more interesting dynamics. The inherent emergence of this architecture fits the principle of PSI theory quite well, that is emotions emerge from the dynamics of the whole system.
Regarding to  X  X  X orld Interface X  X , it is similar to  X  X  X orld adapter X  X  in MicroPsi ( Bach, 2003 ; Bach et al., 2006 ). It provides a generic interface between OpenPsi and outside world, which can be a game world or even the real world in future. It converts data coming from the world into the format desired by Perception UpdaterMindAgent, and encapsulates actions generated by ActionSelectionMindAgent into requests sent back to the outside world.

There are two optional subsystems  X  X  X isualizer X  X  and  X  X  X og system X  X , which are responsible for tracking the dynamics of OpenPsi. Fig. 5 shows the changes of demands, modulators and feelings in real time from the visualizer. It is quite useful of observing the internal changes of the model as the system evolves, and also helpful when tuning parameters of the system. Furthermore, the log system can record even more details in log files, which can be analyzed later. Our experiments in Section 5 take advantages of both. 4.2. Knowledge representation
The knowledge of OpenPsi is stored within large hypergraphs with nodes and links linked together to represent knowledge. A hypergraph is an abstract mathematical structure ( Gunopulos et al., 1997 ; Karypis et al., 1998 ; Zass and Shashua, 2008 ). Different from traditional graph in computer science, a hyper-graph can have Edges that point to Edges rather than Vertices; or Vertices, that when you zoom in on them, contain embedded hypergraphs ( Fig. 6 ). Since Edges and Vertices in a hypergraph are not as distinct as they are within an ordinary mathematical graph, we use Atom as a generic term to encompass both Edge and Vertex.

The AtomSpace is an interface for the manipulation and storage of Atoms. It consists of a single server and a bunch of clients possessed by mind agents ( Fig. 7 ). All the Atoms are actually stored in the back-end database, which can be a rela-tional database or NoSQL database. The AtomSpace Server is responsible for processing requests coming from the mind agents, by retrieving and storing Atoms in the back-end database. Atom-
Space Server and Clients communicate through messages, that is clients send requests to the server and the server sends back the results after manipulating the back-end database.

From the perspective of a mind agent, it retrieves Atoms, does some computations, and sends results back to the hypergraphs through its own AtomSpace client. It is not aware of the existence of the back-end database, and even does not realize the presence of other mind agents, if no explicit communication is required.
The great advantages of this knowledge representation are as follows:
Highly distributed . In principle, any component of the system can run anywhere, in different threads, processes or even distinctive machines, as long as its AtomSpace Client can communicate with the AtomSpace Server. Furthermore, the back-end database itself may be also distributed. For example, if Redis, a high performance in-memory NoSQL database ( http://redis.io ), is adopted as the back-end database, the back-end database can be distributed among different machines, then it is the responsibility of AtomSpace Server to manage and load balancing among them.

Parallelism and concurrency . Since all the mind agents are relatively simple, have little direct relevance with each other, and only have to communicate with the AtomSpace Server directly through messages, they can run concurrently or in parallel easily. It should be noted that little direct commu-nication among the mind agents does not mean they are independent. On the contrary, they are closely related with each other, because the information interchange is implied within the global knowledge base.
 Cross platform and programming languages . Once the Atom-
Space Client is ported to a specific platform written in a given programming language, we can then implement a mind agent with the given programming language and run it on the specific operating system. For example, in our current imple-mentation of OpenPsi, ActionSelectionMindAgent is written in Scheme, PerceptionUpdaterMindAgent in C  X  X  , and Monitor
ChangesMindAgent in Python. Moreover, it is far from difficult to port AtomSpace Client to different platforms or program-ming languages. The major job involved is implementing an interpreter of messages, followed by both AtomSpace Server and Client during their communication, using given program-ming language on the specific platform.

Facilitate designing algorithms . It would be convenient to apply data mining or machine learning algorithms to the knowledge base when unified knowledge representation is adopted. It is also possible to design more generic algorithms. 4.3. Mind agents in depth
The OpenPsi is implemented as six  X  X  X ind agents X  X  in the architecture described in Section 4.1 . Each of them is relatively simple and has a specific task, which can hardly induce complex related with each other, which would produce much more complicated and interesting behavior. Then the emotions emerge from the dynamics of both internal changes, and the interaction between the system and the environment. Remaining part of this section provides the details of these  X  X  X ind agents X  X .
PerceptionUpdaterMindAgent updates the perception of the environment. The perception process is modulated by resolution level. As this mind agent is closely related to the environment, the concrete implementation highly depends on the outside world. For example, in our current implementation, the resolution level has influence on the range of virtual field. Lower resolution level comes along with a smaller visual field, which would make the avatar living in the virtual world take less effort to explore the environment.

MonitorChangesMindAgent monitors remarkable changes by comparing Atoms within the latest and previous AtomSpaces. This process is controlled by securing threshold, that is lower securing threshold would result in more frequent detection of changes. Then results of mining evident changes are then pushed back into the AtomSpace, and can be served as heuristic hints for other mind agents. For example, they can bias the behavior of PerceptionUpdaterMindAgent, by giving priority to irregular variations.

ActionSelectionMindAgent starts from a dominant demand and tries to figure out a chain of actions that would probably lead to the satisfaction of the demand. Selection threshold affects the process of selecting active intention. The pseudo-code below presents a simple mechanism that currently used.
 IF random  X  0 , 1  X  o selection _ threshold ELSE
DemandUpdaterMindAgent is responsible for updating a fixed set of demands of the avatar living in the virtual world, and the primary goal of the avatar is to maintain these demands within certain ranges.

For each demand (d), it comes along with a minimum and maximum level (min_l and max_l), then the satisfaction (S) of the demand can be derived from current level (L) using simple fuzzy formulas, S  X  L , min_ l , max_ l , a  X  X  where fuzzy _ equal is defined as fuzzy _ equal  X  x , t , a  X  X  1 =  X  1  X  a n  X  x t  X  2  X  :  X  2  X  random  X  0 , 1  X  generates random numbers in  X  0 , 1 . When L 4 max_ l ,0 : 9 r S _ d r 1 : 0; when min_ l r L r max_ l ,0 : 8 r S _ d r 1 : 0. a denotes how fast the fuzzy _ equal output decreases when x deviates from t . Smaller a causes slower decrease. In our experi-ments we use a  X  150.

It should be noted that, unlike PSI or MicroPsi, in our model, the target ranges of demands are not fixed. Rather, they start with initial values and are updated according to the interaction between the avatar and the environment (formulas (3) and (4) ). The very basic assumption is that the avatar would probably expect even more if a specific demand is satisfied, and may tend to restrain themselves when the related resource to the demand is not easily reachable. As the system evolves, the personality of an avatar could be leaned from appraisal processes in real time: min_ l  X  t  X  1  X  X  max_ l  X  t  X  1  X  X 
In respect to the demand levels, many physiological demand levels can be retrieved directly from the world interface, while levels of abstract demands, such as certainty, competence and affiliation are calculated based on the avatar X  s experience or the environment: L _ certainty  X  fuzzy _ new  X  t i , t s  X  X  2 =  X  1  X  exp  X  0 : 002 n  X  t s L _ competence  X  n s =  X  n s  X  n 3 = 2 f  X  ,  X  7  X  L _ affiliation  X  fuzzy _ near  X  d i , d max  X  X  1 =  X  1  X  0 : 00015 n  X  d i
Formulas (5), (7) and (8) are tentative equations of updating certainty, competence and affiliation demands. In formula (5) , t the latest time stamp of observing object i and t s is the current time stamp of the virtual world. n s and n f in formula (7) stand for the number of successful and failed actions separately. For formula (8) , d i denotes the distance between friend i and the avatar itself, while d max is a distance threshold to decrease the impact of friends far away.
 ModulatorUpdaterMindAgent renews modulators continuously. Modulators are considered as parameters controlling both cogni-tive and emotional processes. In addition, they are closely related, thus result in the inherent dynamics of the system.

We propose a group of formulas below to update the mod-ulators. resolution _ level  X  1 securing _ threshold  X  S certainty S selection _ threshold  X  fuzzy _ equal  X  S competence , 1 , 15  X  :  X  13  X 
Activation is related to energy and competence demands (formula (10) ), which means the avatar would be more ready to react (higher activation), when it has enough energy (higher S energy ) and feels more confidence of its ability (higher S
Resolution level is mainly reverse to activation (formula (11) ), that is if the avatar is more ready to execute an action (higher activation), it will put less effort into cognitive processes (lower resolution level), such as perception, irregular changes detection, action planning, etc.

Securing threshold is influenced by satisfactions of certainty and integrity demands (formula (12) ). When the avatar knows more about the environment (higher S certainty ) or is safe in the environment (higher S integrity ), it would tend to more securing behavior (lower securing threshold).

Selection threshold is inversely correlated with the satisfaction of competence demand (formula (13) ). When the avatar feels confidence of its ability (higher S competence ), the chance to abandon the current action (or plan) is low (higher selection threshold).
FeelingUpdaterMindAgent updates the emotional states of the avatar based on the pleasure and the modulators. Since the system dynamic is formed by these modulators, emotional varia-tions derived from modulators naturally embody the dynamic of the system.

More specifically, the intensity (I) of each emotion (E) is calculated from modulator (m) levels as below: I  X  E  X  X   X  i m  X  H , L , M , EL , EH , U  X  X  14  X 
W m denotes the weight of contribution for modulator m. P is a simple fuzzy logic function, which produces a number within  X  0 , 1 in terms of the modulator level m and its corresponding indicator i
An indicator, which controls the calculation of P , can be H (high), L (low), M (medium), EL (extremely low), EH (extremely high), and U (undefined).
 We suggest P as
P  X  m , i m  X  X  where fuzzy _ low  X  x , t , a  X  X  fuzzy _ high  X  x , t , a  X  X 
The parameter a in formulas (16) and (17) has the same meaning in formula (2) .

After calculating the intensities of all the possible emotions, the dominant emotion ^ E with greatest intensity is selected and can be processed further, such as emotional expression, etc. We also introduce a threshold g to filter out many small emotional fluctuations.

For example, given the relationship of emotions and modula-tors ( Table 2 ), we firstly calculate the intensity of each emotion according to the current modulator levels ( Table 3 ). For instance, assuming all the W m are equivalent (all equals to 1/5), then the intensity of Happy is computed as
I  X  Happy  X  X  0 : 2 n P  X  0 : 4247 , H  X  X  0 : 2 n P  X  0 : 3466 , L  X  X  0 : 2  X  0 : 2 n P  X  0 : 7752 , H  X  , 0 : 2 n P  X  0 : 7245 , H  X  X  0 : 7088
If we choose the intensity threshold g  X  0 : 6, Happy is selected as the dominant emotion, as it has the highest intensity 0.7088, and is also higher than the threshold g ( Table 4 ). 5. Computational experiments 5.1. Experimental setup
In order to verity our proposed OpenPsi model, a number of experiments have been performed in a virtual world full of building blocks inspired by Minecraft ( http://www.minecraft.net ). A virtual robot controlled by OpenPsi lives in this virtual world. It can move freely across the world and its m ain mission is to collect enough energy cubes containing batteries to survive ( Fig. 9 ). It has energy level, which decreases by performing actions and can be fulfilled by consuming battery cubes; integrity level, which decreases when the robot gets hurt by the harmful lightning cloud and increases while it stays at home. It also has abstract demands including certainty and competence. Furthermore, the robot can take advantages of building blocks to reach goals. For example, it may build a stair to get battery cubes high above the ground.

The emotional model was then carefully explored in three different scenarios,
Scenario A . Firstly, set the robot in a world with no battery cubes. When the robot run out of energy, the human player spawned some energy cubes for the robot.

Scenario B . The robot was loaded in a world with some battery cubes. However, the human player prevented the robot from consuming them by either throwing away the energy cube or simply destroying it when the robot approached any of the energy cubes.

Scenario C . Placed energy cubes near the lightning cloud. When the robot tried to fetch these batteries, it got hurt by the harmful lightning cloud.

It should be noted that all the experiments share the same parameters of the emotional model ( Table 5 ), such as initial modulator values and the target range of each demand, which implies that all the experimental results presented here are caused by the interaction among the robot and the environment, and the dynamics of the emotional model itself, rather than a set of carefully tuned parameters of the affective model for each scenario. 5.2. Emotion variations in different scenarios
As presented in Fig. 10 , the robot experienced happiness, sadness and happiness again in scenario A. It felt happy at first while loaded to the virtual world without any batteries, but the intensity of happiness decreased as the robot exhausted its energy gradually during the time interval from 0 to 120. At the same time, the sad feeling grew and reached a peak at time equals to 270. The human player spawned some energy cubes at around 350 s. After the robot consumed some batteries, its energy level recovered to the target range and it became happy again during 450 X 500 s.

In scenario B ( Fig. 11 ), the robot was settled in a world with some battery cubes, but the human player prevented it from consuming any of them. The happiness decreased and anger grew before 200 s. Anger dominated the whole emotional system during 200 X 300 s. However, after 300 s, sadness became the major feeling as the robot ran out of energy. Anger dropped slightly and kept in around 0.5. In the meanwhile, the fear feeling developed gradually and reached 0.6 at time 450 s.

Fig. 12 shows the experimental results for scenario C. The fear intensity increased during 40 X 110 s as the robot was hurt by the lightning cloud when it tried to fetch energy cubes near the harmful cloud. Sad feeling also increased as the fear developed and took over the whole system after 120 s. 5.3. Different phases of emotional dynamics
The hints of different traditional phases as suggested by Lewis X  X  dynamic theory of emotions could be found when we study the experiment results more careful ly. For instance, in scenario A ( Fig. 10 ), the sad feeling increases dramatically between 250 and 270 s, during which the system may experience a self-amplification phase, since small deviations accumulated in previous stages are rapidly amplified. Before this, between 80 and 250 s, there are small and frequent variations but none of the emotions dominates the system, which stands for a trigger phase. Within the trigger stage, the system becomes sensitive to the environment and the orderli-ness is lost by perturbation from the environment. After 270 s, the system undergoes a self-stabilization phase, during which sad intensity decreases as negative feed back gradually takes control of the system dynamics. From 370 to 450 s, the system enters another trigger stage, the previous dominant sadness is replaced with many small and frequent emotion fluctuations. When this trigger phase ends around 450 s, happiness soars dramatically and becomes the new major emotion, which implies another self-amplification stage.
Phase transitions can also be observed in scenarios B and C but they are slightly different from those in scenario A. In scenarios B and C, trigger stages happen during 200 X 300 and 40 X 70 s, respec-tively. However, unlike typical trigger phases in scenario A, where orderlinessiscompletelylost,duringtriggerstagesinscenariosB and C, there is an emotion slightly stronger than any other feelings.
Within the trigger stage in scenario B, anger is more stronger than others; while in the trigger phase of scenario C, the robot feels more fear than other emotions. 6. Discussion 6.1. Conclusion In this paper, OpenPsi, a novel emotional model inspired by
D  X  orner X  X  PSI theory is introduced. The affective model is then constructed and verified in a game world.

The emotional model has been carefully explored in three different circumstances. The experimental results show that emotion variations fit quite well with these scenarios. For example, the robot gets angry when the human player keeps it from fetching batteries in scenario B; in scenario C, the robot becomes fear when hurt by the lightning cloud. Furthermore, we also observed the evidences of phase transitions as suggeste dbyLewis,suchastriggerphase, self-amplification and self-stabilization phases.

It is worth noting that a fixed set of parameters for the emotional model is adopted during all the experiments, which means that all the emotion dynamics are produced by different environmental settings and distinctive interactions between the human player and the virtual robot.

These simulation results suggest that OpenPsi is a quite promising approach of emotion modeling, since three essential features are presented,
Emotions emerge from the dynamics of the whole system, rather than produced by a set of predefined appraisal rules.
Emotion variations experience critical phase transitions, includ-ing trigger, self-amplification and self-stabilization stages.
Emotions are grounded to the environment, that is emotion changes fit well with different environmental settings and interactions between the robot and the human player.

Compared with Joscha Bach X  X  MicroPsi, an extensive imple-mentation of the original PSI theory, our computational model OpenPsi, mainly focuses on the most distinctive features of the emotional model within the PSI theory. It should be noted that both MiroPsi and OpenPsi would never work without other cognitive components, including knowledge representation, per-ception, planning and learning. Because the emotion in PSI theory is not considered as an isolated component, instead it is recog-nized as emergent behavior of the whole system. The difference between MicroPsi and OpenPsi is the implementation of those supporting cognitive components. MicroPsi is very close to the original PSI theory; while OpenPsi has completely different knowledge representation scheme resulting in different planning and learning processes. We intend to only implement the essen-tial motive driven system of the PSI theory and reserve the flexibility of incorporating state-of-the-art algorithms within Artificial Intelligence field. 6.2. Future work
The analysis of emotional dynamics at present heavily relies on a qualitative description of emotion evolution over time. It would be more convincing if the analysis of the data could be supported by numerical comparisons between the curves. A more formal and accurate definition of different stages in emotional transitions is required for more numerical analysis.

One of the practical and nontrivial next steps would be to work on the expression of emotional states of the virtual robot, which now seems overly simplified with only a few textures represent-ing distinctive facial expressions separately. The major challenge of this work is how to convey multiple emotions on just one face since the virtual robot could feel various types of emotions at the same time.

Moreover, many improvements can be made to the model itself. A possible extension would be incorporating the emotional model with learning processes. For example, emotion variations could provide feedback signals for reinforcement learning. Another improvement could be using emotions to bias memories. As a simplest example, the system may preserve information related to strong feelings and tend to forget those have little relevance with significant emotion variations.

For the moment, we focus more on the virtual world, where perception is greatly simplified. A much more exciting application may be applying the emotional model to a robot in the real world, that can communicate affectively with humans in a more natural way. When applying the affective model to a physical robot, many extensions are required, such as using emotions to modulate all sorts of perceptions and introducing more natural emotion expressions. However, the perspective to extend to actual robot is really far from what has been done.
 Acknowledgments
The authors would like to thank all the anonymous reviewers for their insightful comments, and kindly people from Opencog community, including Jared Wigmore, Joel Pitt and Linas Vepstas, for their generous technical support in various aspects. Especially, we thank Nil Geisweiller for his suggestion of splitting OpenPsi into several minor mind agents running in parallel, Cassio Pennachin for his bright ideas of knowledge storing and retrieving based on back-end database, Cord Krohn for his reminder of removing many small emotional fluctuations when choosing the dominant emotion.

This work was partly supported by the Hong Kong ITF Grant for  X  X  X  Software Toolkit for Creating Intelligent Non-Player Characters in Video Games X  X , the N ational Natural Science Founda-tion of China (Grant No. 61003014/F020101), the Ph.D. Programs Foundation of Ministry of Education of China (Grant No. 20100121120021), and the Natural Science Foundation of Fujian Province (Grant No. 2010J05142).
 References
