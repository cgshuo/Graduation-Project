 Similarity search is one of the fundamental problems for large scale multimedia applications. Hashing techniques, as one popular strategy, have been intensively investigated ow-ing to the speed and memory efficiency. Recent research has shown that leveraging supervised information can lead to high quality hashing. However, most existing supervised methods learn hashing function by treating each training ex-ample equally while ignoring the different semantic degree related to the label, i.e. semantic confidence, of different examples.

In this paper, we propose a novel semi-supervised hashing framework by leveraging semantic confidence. Specifically, a confidence factor is first assigned to each example by neigh-bor voting and click count in the scenarios with label and click-through data, respectively. Then, the factor is incor-porated into the pairwise and triplet relationship learning for hashing. Furthermore, the two learnt relationships are seamlessly encoded into semi-supervised hashing method-s with pairwise and listwise supervision respectively, which are formulated as minimizing empirical error on the labeled data while maximizing the variance of hash bits or minimiz-ing quantization loss over both the labeled and unlabeled data. In addition, the kernelized variant of semi-supervised hashing is also presented. We have conducted experiments on both CIFAR-10 (with label) and Clickture (with click da-ta) image benchmarks (up to one million image examples), demonstrating that our approaches outperform the state-of-the-art hashing techniques.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Retrieval models  X  c Figure 1: T hree exemplary image pairs. (a) Both im-Algorithms, Performance, Experimentation.
 Hashing; similarity learning; neighbor voting; semi-supervised hashing; click-through data
The rapid development of Web 2.0 technologies has led to the surge of research activities in large scale visual search. One fundamental research problem is similarity search, i.e., nearest neighbor search, which attempts to identify similar instances according to a query example. The need to search for millions of visual examples in a high-dimensional feature space, however, makes the task computationally expensive and thus challenging.

Hashing techniques [23][26][29], one direction of the most well-known Approximate Nearest Neighbor (ANN) search methods, have received intensive research attention for its great efficiency in gigantic data. The basic idea of hashing is to design a compact binary code in a low-dimensional s-pace for each example, making the Hamming distances on similar examples minimized and simultaneously maximized on dissimilar examples. In the similarity search process, the query example is usually first transformed to its hash-ing code. Then, the Hamming distances between the hash codes of instances in the retrieved database and the query example are computed. The instances within small Ham-ming distances are returned. Through hashing, the storage is substantially reduced as the representations of examples are highly compressed with a low-dimensional binary space a nd the Hamming distance between two hash codes can be implemented by bitwise XOR operation, leading to a very efficient searching process.

While existing hashing approaches are promising to re-trieve neighbors, each example is treated equally during the learning of hash function. Importantly, we argue that hash-ing would obtain higher search accuracy if the semantic de-gree to the label of each example, i.e., semantic confidence, is taken into account. Figure 1 shows three exemplary im-age pairs. Conventional supervised hashing methods use to learn hash function to make the corresponding binary codes similar for images annotated by the common label while dis-similar for those with different labels. However, take the two pairs in Figure 1 (a) and (b) as examples, although each pair is relevant to an individual label, the two images in (a) are all highly relevant and thus their hashing code should be clos-er in proximity than the image pair in (b). Meanwhile, for images that share different labels in Figure 1 (c), their hash codes should be made as dissimilar as possible, especially when they are highly relevant to their respective labels.
By encoding the semantic confidence into hash function learning, this paper presents a novel and principled semi-supervised hashing framework for large scale image search, as illustrated in Figure 2. The semantic confidence is for-mulated by devising a confidence factor that evaluates the semantic relatedness of an example to a label. We consider two kinds of confidence factors computed based upon image neighbor voting and click count respectively. By assuming the availability of labeled examples, the former first builds a similarity graph over all images of a given label followed by assigning each image a confidence score based on the number of its out-link neighbors. The latter considers click-through data and relates the confidence score directly to the num-ber of click counts an image receives. Based on the seman-tic confidence, the pairwise and triplet relationships among image examples are further developed and incorporated in-to the hash function learning in standard (with pairwise supervision) and ranking (with listwise supervision) semi-supervised hashing framework, respectively. In addition, to accommodate linearly inseparable data, a kernel formulation is employed on ranking semi-supervised hashing. After the hash function learning, each image is mapped to compact binary codes. For any query image, the image search list will be returned by sorting their Hamming distances with the query.

In summary, this paper makes the following contributions:
The remaining sections are organized as follows. Section 2 briefly surveys several popular hashing methods. Section 3 presents the semantic confidence, the pairwise and triplet relationships with semantic confidence, while Section 4 fur-ther details the utilization of the two relationships in semi-supervised hashing framework. Section 5 provides empirical evaluations, followed by the discussion and conclusions in Section 6.
We briefly group the related works into three categories: unsupervised, supervised, and semi-supervised hashing.
Unsupervised hashing refers to the setting when the la-bel information is not available. Locality Sensitive Hashing (LSH) [3] is one of the most popular unsupervised hash-ing methods, which simply uses random linear projections to construct hash functions. This method was continuously expanded to Kernelized and Multi-Kernel Locality Sensitive Hashing [11][31]. Another effective method called Iterative Quantization (ITQ) [4] was suggested for better quantiza-tion rather than random projections. The Spectral Hashing (SH) in [30] was proposed to design compact binary codes by preserving the similarity between samples, which can be viewed as an extension of spectral clustering [33]. Recently, the graph based hashing technique namely Anchor Graph Hashing (AGH) was proposed by Liu et al. in [14], which can leverage low-dimensional manifold structure of data to design efficient hash codes. Later in [12], Discrete Graph Hashing (DGH) was proposed to generate high-quality codes by preserving the neighborhood structure of massive data in a discrete code space.
In contrast, when the label information is available, we re-fer to the problem as supervised hashing. For example, Lin-ear Discriminant Analysis Hashing (LDAH) [24] can tackle supervision via easy optimization. The deep neural network stacked with Restricted Boltzman Machine (RBM) [6] was applied to learn binary hash codes in [23]. To utilize the pair-wise supervision information in the hash function learning, Kernel-Based Supervised Hashing (KSH) proposed in [13] used pairwise relationship between samples to achieve high quality hashing. Binary Reconstructive Embedding (BRE) [10] was proposed to learn hash functions by minimizing the reconstructed error between the metric space and Hamming space. Minimal Loss Hashing (MLH) was proposed in [16] which aims to learn similarity-preserving binary codes by us-ing the pairwise relationship. Moreover, there are also sever-al works using the ranking order information to design hash functions. Ranking-based Supervised Hashing (RSH) [27] was proposed to leverage listwise supervision into the hash function learning framework. Besides RSH, the tree-based method [20] and a hamming metric learning framework pre-sented in [17] also aim to preserve the ranking orders.
In addition, several cross-view hashing methods have been proposed as well. The Canonical Correlation Analysis with Iterative Quantization (CCA-ITQ) was proposed in [4] to learn the hash codes from the content features and tags. In [21], Rastegari et al. proposed Predictable Dual-View Hashing (PDH) to create a cross-view hamming space by embedding proximity of data samples in the original spaces. Semi-supervised hashing methods have also been proposed. One representative work is Semi-Supervised Hashing (SSH) [26] which utilizes pairwise information on labeled samples to preserve semantic similarity while remaining robust to overfitting. Semi-Supervised Discriminant Hashing (SSDH) can learn hash codes based on Fisher X  X  discriminant anal-ysis to maximize the separability between labeled data in different classes while the unlabeled data are used for reg-ularization [8]. In another work [15], the label-regularized maximum margin partition (LAMP) method was proposed to enhance hashing quality by using kernel-based similari-ty and additional pairwise constraints as side information. Semi-Supervised Tag Hashing (SSTH) proposed in [28] can fully incorporate tag information into hash function learning by exploring the correlation between tags and hashing bits.
In short, our approach belongs to semi-supervised hash-ing. While these aforementioned semi-supervised hashing methods focus on the regularization of both labeled and unlabeled examples from different means, they treat each image equally and hence the role that each image should play and contribute in learning is overlooked. Our work in this paper contributes by exploring this issue through not only devising the rigorous ways of measuring semantic con-fidences, but also how the hash function can be more reliably learnt by exploring the semantic confidence.
In this section, we first define the semantic confidence measurement for each image example, i.e. confidence fac-tor, in the context of scenarios with label and click-through data, respectively. Then, pairwise and triplet relationships with semantic confidence is further devised to be encoded into hash function learning in semi-supervised hashing.
Given a label t , let X = { x 1 , x 2 , , x L } be the set of all images annotated by the label t , where x i represents the i image in X and its image feature vector is denoted as v i Let N k ( i ) be the k -nearest neighbor set of the i th image. A directed graph is then built where nodes are all images in X and there is an edge between the i th and j th image if and only if the i th image appears in N k ( j ). Deriving from the idea of neighbor voting [34], the semantic confidence of the i th image is reflected by the number of the image appearing in the neighbors of other images in the graph, i.e., the num-ber of out-link neighbors. Specifically, the confidence factor is generally formulated as where ( o + i ) is the number of out-link neighbors of the i image and it is normalized by the maximum number of out-link neighbors of all images in the graph.  X  is used to control the impact of the number of out-link neighbors. The ratio-nale underlying this formula is that, if the i th image always appears in the k -nearest neighbors of other images, the i image is similar to the other images of the category and thus s hould be more semantically related to this category.
In the scenario with click-through data, we view the click count of an image in response to a query (category) as an indicator of their relevance [19]. As most image search en-gines display results as thumbnails, the users can view the entire image before clicking on it. As such, the users pre-dominantly tend to click on images that are relevant to the query. Therefore, click count can be served as a reliable con-nection between queries and images. Then, the confidence factor can be re-expressed as where c i is the click count of the i th image in response to the query and max j ( c j ) is the maximum click count of the returned images for the query. Particularly, the higher the click count, the more the relevance between the image and the query.
Most of the existing learning to hash methods are to gen-erate hashing code to satisfy pairwise supervision, i.e., mak-ing the Hamming distance minimized on similar pairs while maximized on dissimilar pairs. As a result, pairwise rela-tionship is first developed with semantic confidence of each example. Let M and C be the set of neighbor pairs and non-neighbor pairs, respectively. Specifically, a pair ( v i , v M is denoted as a neighbor pair in which v i and v j are from the same category or in answering the common query. Similarly, a pair ( v i , v j )  X  C is called as a non-neighbor pair if v i and v j are from the different category or in response to the different query. By incorporating the semantic confi-dence, the pairwise relationship is defined as S
P ( v i , v j ) = where s i and s j are the confidence factor for the i th and j image, respectively.

The spirit of pairwise relationship with semantic confi-dence is to make the neighbor pair in close proximity if the two examples of the pair both have high confidence factors, while weakening the relationship of the neighbor pair if any one in the pair has a low confidence. On the other hand, if the two examples in a non-neighbor pair are both with high confidence to each category, the pair will receive a very dissimilar relationship strengthened by their semantic con-fidences.
To further leverage the listwise supervision [27] which has been employed to design more effective hash functions in search tasks, semantic confidence is then encoded into triplet relationship learning. Denote T as the set of triplets, and each triplet as ( v i , v + j , v  X  k ). In the case when labels are available, v i refers to a query image, v + j ( v  X  k ) as the image with the same (different) category as v i . For click data, v refers to the clicked image of the same query on image v i and v  X  k is a clicked image of another query different from that of v i . For any triplet, we can derive the relationship with semantic confidence as ship defined in Section 3.2. It is straightforward to see that tionship when the image v + j is close to the query image v and simultaneously the image v  X  k holds a quite dissimilar relationship with the image v i .
In this section, we will present our semi-supervised hash-ing framework under the umbrella of encoding the learnt relationships with semantic confidence to three primary as-pects: semi-supervised hashing by exploiting pairwise rela-tionship with semantic confidence, ranking semi-supervised hashing by leveraging triplet relationship with semantic con-fidence and its kernelized variant.

Suppose there are n images in the whole set, represented as: V = { v i | i = 1 , , n } , where v i  X  R D represents the image feature vector and V = { v 1 , v 2 , . . . , v n }  X  R the feature matrix of the image set. Similarly, assume there are L ( L &lt; n ) labeled images and the feature matrix of the labeled images are denoted as V l  X  R D  X  L . Note that the feature matrices are normalized to zero-centered. Our goal is to map V  X  R D  X  n to a compact binary code representa-tion B  X  { X  1 , 1 } K  X  n in a low-dimensional Hamming space, where K is the code length.
Here we use the linear formulation to design the hashing functions. For each bit k = 1 , . . . , K , its hash function is defined as where w k  X  R D is the coefficient vector and sgn (  X  ) is the signum function. Let W = { w 1 , w 2 , . . . , w K }  X   X  R be the projection matrix, we can get the K -bit binary code representation B of an image set V as
Inspired by the idea of semi-supervised hashing [26], we propose the semi-supervised hashing with semantic confi-dence. The problem is formulated as simultaneously max-imizing empirical accuracy on the labeled images and the variance of hash bits over both the labeled and unlabeled images, in which pairwise relationship with semantic confi-dence is encoded into the computation of empirical accura-cy. Specifically, the empirical accuracy on the label images is defined as where S P ( v i , v j ) is the pairwise relationship with semantic confidence for pair ( v i , v j ). By defining the pairwise rela-tionship matrix S  X  R L  X  L on the labeled images V l with its element S i ,j = S p ( v i , v j ), the empirical accuracy J can be represented as
Through maximizing empirical accuracy on the labeled images, the hash codes will be in close proximity for neigh-boring pairs with high pairwise relationship, while very dif-ferent for non-neighboring pairs especially when both sam-ples are with high confidence to different category.
On the other hand, to generate hash codes in which each bit maximizes the information by generating a balanced par-tition of the data, the variance of hash bits should be also maximized. Here, the variance of hash bits over the labeled and unlabeled images is measured as
The overall objective function integrates the empirical ac-curacy on the labeled images and the variance of hash bits over the labeled and unlabeled images. Hence we get the following optimization problem where  X  is the tradeoff parameter and the constraint WW  X  I limits the hashing projection matrix to be orthogonal.
We use non-orthogonal projection learning [26] for the op-timization, which relaxes the orthogonality constraint and solves the non-convex problem with matrix decomposition.
To design more effective hash functions, we further in-corporate the triplet relationship with semantic confidence into ranking semi-supervised hashing which represents the ranking information by a set of ranking triplets. The train-ing of Ranking SHSC (RSHSC) is performed by minimizing both the triplet loss based on the labeled images and the quantization loss on the whole image set.

Formulation. For Ranking SHSC, we still use the linear form of hash functions as defined in Eq.(5). Formally, giv-en an image pair ( v i , v j ), we revise a distance function to measure the degree of hash code difference as d ( v i , v j ) = ( sgn ( Wv i )  X  sgn ( Wv j ))  X  ( sgn ( Wv i )  X  sgn ( Wv The triplet loss on the labeled images V l is defined as
J 1 ( W ) = X
L ( v i , v + j , v  X  k ) = max 0 , d ( v i , v + j )  X  d ( v where S T ( v i , v j + , v k  X  ) is the triplet relationship with se-mantic confidence consisting of the query image v i , an im-age v j + from the same category and an image v k  X  from a different category. Note that all the triplets in Eq.(12) are from the triplet sets T generated on labeled images V l . The triplet loss exploits the margin ranking loss [5][32] that is widely used in information retrieval weighted by the triplet relationship. By minimizing the triplet loss on the labeled images, the relative distance relationship for hash codes in hamming space is preserved under the listwise supervision. tionship, we aim to make the hash codes in close proximity for v i and v j + , and simultaneously get the very different bits for v i and v k  X  .

To better generate hash codes and avoid overfitting, we additionally incorporate another term by using all the la-beled and unlabeled images, leading to a semi-supervised framework. Motivated by iterative quantization [4], the quantization loss is defined on the whole image set V as where B = sgn ( WV ) and k X k F denotes the Frobenius nor-m. Minimization of the quantization loss will preserve the original locality structure better in the generated hash codes.
The overall objective function for Ranking SHSC is com-prised of the triplet loss in Eq.(12) and the quantization loss in Eq.(13). Hence we get the following optimization problem for our RSHSC: where  X  is the tradeoff parameter and the constraint WW  X  I forces the hashing projection matrix W to be orthogonal, making the bits of the generated hash codes uncorrelated to each other.

Optimization. The orthogonal constraints and the non-differentiable terms (i.e., sgn (  X  )) in Eq.(14) make the op-timization difficult to be solved. To address this problem, we first relax the overall objective function by replacing the signum function in Eq.(11) with its signed magnitude as sug-gested in [26][28]. With this relaxation, the distance function in Eq.(11) can be rewritten as Thus, the triplet loss in Eq.(12) becomes differentiable.
Next, the orthogonal constraint WW  X  = I can be re-laxed by appending the converted soft penalty term to the objective function. The penalty term is defined as
After the two relaxations, the overall objective function becomes where  X  and  X  are the tradeoff parameters.

To address the relaxed optimization problem in Eq.(17), the stochastic gradient descent is used for its efficiency and capability in dealing with highly scalable problems. Note that the quantization loss term in Eq.(13) cannot be relaxed by its signed magnitude directly, otherwise this quantization loss will go to 0, which is meaningless in practice. Similar to the common solution used in [4][28], in each iteration of the gradient descent procedure, we split the optimization process into two steps: 1) fix W and update B = sgn ( WV ); 2) fix B and update W according to the gradient descent for the objective function. We alternate the process of updating B and W to find a locally optimal solution. The whole RSHSC algorithm is given in Algorithm 1. Algorithm 1 R anking Semi-supervised Hashing with Se-mantic Confidence (RSHSC) 1: I nput: Training images V and labeled images V l . 2: Generate a set of triplets T consisting of ( v i , v j 3: for iter = 1 to T max do 4: Select a random triplet ( v i , v j + , v k  X  ) from T . 5: B = sgn ( WV ) 6: W = W  X   X  (  X  2  X  ( B  X  WV ) V  X  + 2  X  ( WW  X   X  I ) W ) 7: L ( v i , v + j , v  X  k ) = max(0 , d ( v i , v j + )  X  d ( v 8: if L ( v i , v + j , v  X  k )  X  0 then 9:  X  L = 2 W ( v i  X  v + j )( v i  X  v + j )  X  10: Compute S T ( v i , v j + , v k  X  ) via Eq.(4). 11: W = W  X   X S T ( v i , v + j , v  X  k )  X  L 12: end if 13: end for 14: Output:
O ur Ranking SHSC method can be easily kernelized (Kernel-based Ranking SHSC) through the kernel trick which has been proven to be able to tackle linearly inseparable data. To kernelize Ranking SHSC, we use a kernel function  X  : R
D  X  R D 7 X  R to construct the hash functions. Following the kernel-based hashing algorithms [11][13], we define the kernelized hash function with the kernel  X  plugged in as where v (1) , . . . , v ( m ) are m samples randomly selected from V , w j  X  R is the coefficient and b  X  R is the bias. It is worth noting that in order to make this kernel-based hashing fast, m is set to be much smaller than the image dataset size n . Following the balancing criterion [4][13] in hash function that the generated hash bit should take as much information as possible, the bias b is set as Therefore, the kernelized hash function is rewritten as  X  h ( v i ) = sgn where w = [ w 1 , . . . , w m ] is the coefficient vector and  X  : R
D 7 X  R m i s the vectorial map, which is defined as
With the vectorial map  X  , we can obtain the kernelized feature matrix V  X   X  R m  X  n . The K -bit kernel-based binary Figure 3: T en example images randomly selected from code representation B  X  of the image set V is then given as where W is learnt by using the proposed Ranking SHSC method.
We conducted large-scale image retrieval experiments on two image datasets, i.e., CIFAR-10 1 , a tiny image collection in 10 classes and Clickture [7], a click-based image dataset.
The CIFAR-10 dataset contains 60,000 real world tiny images (32  X  32 pixels), which is a labeled subset of the 80 million tiny images dataset [25]. It consists of 10 object classes and each class contains 6K samples. Every image in this dataset is assigned to a mutually exclusive class label and represented by a 512-dimensional GIST feature vector [18]. Figure 3 shows 10 randomly selected images from each class in CIFAR-10.

The dataset is partitioned into two parts: a training set with 59K images and a test set with 1K images evenly sam-pled from ten classes. We additionally sample 100 images from each class in the training set and constitute 1K labeled subset for training. For each test image, the ground-truth similar images are derived from class label, i.e., images from the same class are deemed to be similar.

Clickture is a large-scale click based image dataset [7]. It was collected from one year click-through data of one com-mercial image search engine. The dataset comprises two parts, i.e., the training and development (dev) sets. The training set consists of 23.1 million { query, image, click } tri-ads of 11.7 millions distinct queries and 1.0 million unique images. Figure 4 shows a few exemplary queries with their clicked images and click counts in the Clickture. For exam-ple, users clicked the first image 25 times in the search results h ttp://www.cs.toronto.edu/  X kriz/cifar.html Figure 4: E xamples in Clickture dataset (upper row: when submitting query  X  X ardinal logo X  in total. In the de-v dataset, there are 79,926 h query, image i pairs generated from 1,000 queries, where each image to the corresponding query was manually annotated on a three point ordinal s-cale: Excellent, Good, and Bad. Inspired by the success of deep convolutional neural networks (DCNN) [1][9], we take the output of 1000-way fc8 classification layer by using De-CAF [2] as the image representation for Clickture dataset, which constitutes a 1000-dimensional feature vector.
In the experiment, we adopt 1.0 million unique images in the training set as our training data and randomly sampled 10K images as labeled subset. Moreover, 1K unique images that are annotated as  X  X xcellent X  to the query in the dev set are randomly selected as the test images. To ensure ob-jective as well as effective evaluation, the ground truth data are carefully generated on the click-through. Specifically, for each test image, the set of images clicked by the same query in the training set are taken as the semantically simi-lar images. In addition, for training queries that share more than one common noun phrase with the query of the test image, their clicked images are also regarded as the similar ones. The other images in the training set are all used as dissimilar ones to the test image.
We follow three evaluation protocols, i.e., hash lookup, recall and mean average precision (MAP), which are wide-ly used in [4][13][26]. Hash lookup takes constant search time over a lookup table. We carry out hash lookup with-in a Hamming radius 2 of the query and report the search precision. Following [26], query failing in finding any hash bucket receives zero score in precision. Given the number of the retrieved images, the fraction of relevant ones, i.e., recall, is given as well. MAP is further exploited to evaluate the ranking quality in Hamming space for each query image.
We compare the following approaches for performance e-valuation:
To ensure that all the methods are comparable under the same setting, as in [13], we use the same Gaussian RBF ker-samples in all kernel-based methods. The parameter  X  is tuned on each dataset. The parameters  X  and  X  are select-ed from { 0.2, 0.4, 0.6, 0.8, 1.0 } and the optimal values are determined by using a validation set. Finally,  X  and  X  are both set to 0.8.
Performance Comparison. Figure 5(a) shows the MAP performances of nine runs on CIFAR-10 dataset. Overall, the results on MAP across different lengths of hash code consistently indicate that hashing with semantic confidence leads to a performance boost. There is a significant perfor-mance gap between the kernel-based and linear runs. It is not very surprising to see that LSH provides the worst MAP performance since the random hash functions lack discrim-ination power for small bit lengths. On the other hand, PCAH and SH work relatively well for small bit sizes, but getting worse as the number of bits increases, indicating that PCA is effective in preserving semantic consistency for small hash code lengths. Furthermore, by additionally incorporat-ing semantic confidence, SHSC exhibits better performance than SSH . Similar is spirit, KRSHSC  X  improves KSH , but the performance is still lower than that of KRSHSC , demon-strating the advantage of exploiting the unlabeled data in semi-supervised hashing approaches. The improvement can also be observed of RSHSC compared to SHSC .

In the evaluation of hash lookup within Hamming radius 2 as shown in Figure 5(b), the precisions for most of the Figure 6: M AP performances and Precisions within compared methods drop when a longer size of hash code is used (32 bits in our case). This is because the number of samples falling into a bucket decreases exponentially for longer sizes of hash code. Therefore, for some query images, there are even no any neighbor in a Hamming ball of radius 2. Even in this case, our proposed KRSHSC provides the best performance and the drop in precision for long size of hash code is less than others.

We further details the recall at different numbers of re-turned examples in Figure 5(c). The results confirm the trends seen in Figure 5(a) and demonstrate performance im-provement using the proposed semi-supervised hashing with semantic confidence approaches, especially KRSHSC , over other runs. In addition, to verify that the performance of different approaches is not by chance, we conducted signif-icance test using the randomization test [22]. The number of iterations used in the randomization is 100,000 and at 0.05 significance level. KRSHSC is found to be significantly better than others.

Varying the number of iterations. In our RSHSC and KRSHSC algorithms, the learning of hash function is an iterative process. Next, we conducted experiments to evaluate the performances of our proposed approaches by varying the number of iterations from 1 to 1.0 million on CIFAR-10 dataset. Note that the training time grows lin-early with the number of iterations.

MAP performances and precisions within Hamming ra-dius 2 hash lookup with 32 hashing bits are reported in Figure 6. Not surprisingly, we can observe that the perfor-mances of RSHSC and KRSHSC are both improved with the increase of iterations. Furthermore, after a number of iterations (600K in our case), the performances of RSHSC and KRSHSC change very smoothly, as the algorithms have already received sufficient knowledge to learn a good hash function. Figure 7 shows the experimental results on Clickture dataset. As for some queries in Clickture dataset, there are only tens of or even less than ten clicked (relevant) images, making the search task very challenging. MAP performance and precision with Hamming radius 2 using hash lookup are giv-en in Figure 7(a) and (b), respectively. Our KRSHSC ap-proach consistently outperforms other runs. In particular, the MAP performance and precision with Hamming radius 2 using hash lookup of KRSHSC can achieve 0.0818 and 0.1735 with 48 hash bits, which make the improvement over the best competitor KSH by 3.5% and 12.8%. Method-s that learn hash functions with semantic confidence, e.g. KRSHSC  X  and SHSC , are generally better than KSH and SSH , respectively. Similar to the observations on CIFAR-10 dataset, LSH performs poorly especially for small bit sizes and SH leads to better performance gain than PCAH for longer hash code. Figure 8 showcases some exemplar query images and their retrieved neighbors with 48 bits. KRSH-SC still exhibits the best search quality in terms of visual relevance.
The time complexities for training RSHSC and KRSHSC are T max  X  O ( nKD + DK 2 + D ) and T max  X  O ( nKm + mK 2 + m ), respectively, which scales linearly with n given n  X  D  X  m  X  K . In practice, take the training on 1 million triplets for example, KRSHSC takes about 30 minutes on a server with 2.40GHz CPU and 128GB RAM. For each query, the hashing time of RSHSC and KRSHSC are O ( KD ) and O ( Dm + Km ), respectively.
In this paper, we have presented an important concep-t, i.e. semantic confidence, for the learning of hash func-tion. Particularly, we propose two ways of measuring the semantic confidence, by neighbor voting and click counts, where the former is for general purpose and the latter ex-ploits the click-through data which is largely available by search engine. With the semantic confidence, pairwise and triplet relationships are deployed and further incorporated into semi-supervised hashing learning framework with pair-wise and listwise supervision, respectively. Finally, a kernel-based version is proposed to handle the linearly inseparable data.

We performed extensive experiments on two image dataset-s and compared with the state-of-the-art hashing techniques. Experimental results demonstrated that the proposed semi-supervised hashing with semantic confidence yields superior performance. The current work can be extended with the design of multiple listwise supervised hash tables, which is expected to show even better performance.
 This work was supported in part by the 973 Programme un-der Grant 2015CB351803, the 863 Programme under Grant 2014AA015102, and National Natural Science Foundation of China (No. 61272290, No. 61325009). [1] C. F. Cadieu, H. Hong, D. Yamins, N. Pinto, N. J. [2] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, [3] A. Gionis, P. Indyk, and R. Motwani. Similarity search [4] Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. [5] R. Herbrich, T. Graepel, and K. Obermayer. Large [6] G. E. Hinton and R. R. Salakhutdinov. Reducing the [7] X.-S. Hua, L. Yang, J. Wang, J. Wang, M. Ye, [8] S. Kim and S. Choi. Semi-supervised discriminant [9] A. Krizhevsky, I. Sutskever, and G. E. Hinton. [10] B. Kulis and T. Darrell. Learning to hash with binary [11] B. Kulis and K. Grauman. Kernelized locality-sensitive [12] W. Liu, C. Mu, S. Kumar, and S.-F. Chang. Discrete [13] W. Liu, J. Wang, R. Ji, Y.-G. Jiang, and S.-F. Chang. [14] W. Liu, J. Wang, S. Kumar, and S.-F. Chang.
 [15] Y. Mu, J. Shen, and S. Yan. Weakly-supervised [16] M. Norouzi and D. M. Blei. Minimal loss hashing for [17] M. Norouzi, D. M. Blei, and R. Salakhutdinov. [18] A. Oliva and A. Torralba. Modeling the shape of the [19] Y. Pan, T. Yao, T. Mei, H. Li, C. W. Ngo, and [20] P. Ram, D. Lee, H. Ouyang, and A. G. Gray.
 [21] M. Rastegari, J. Choi, S. Fakhraei, D. Hal, and KRSHSC -KRSHSC KRSHSC -KRSHSC [22] J. P. Romano. On the behavior of randomization tests [23] R. Salakhutdinov and G. Hinton. Semantic hashing. [24] C. Strecha, A. M. Bronstein, M. M. Bronstein, and [25] A. Torralba, R. Fergus, and W. Freeman. 80 million [26] J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised [27] J. Wang, W. Liu, A. X. Sun, and Y.-G. Jiang. [28] Q. Wang, L. Si, and D. Zhang. Learning to hash with [29] Q. Wang, D. Zhang, and L. Si. Semantic hashing using [30] Y. Weiss, A. Torralba, and R. Fergus. Spectral [31] H. Xia, P. Wu, S. C. Hoi, and R. Jin. Boosting [32] T. Yao, T. Mei, C.-W. Ngo, and S. Li. Annotation for [33] L. Zelnik-Manor and P. Perona. Self-tuning spectral [34] X. Zhu, W. Nejdl, and M. Georgescu. An adaptive
