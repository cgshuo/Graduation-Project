 As the richness of information on the web grows, more and more researchers are motivated to discover knowledge such as topics and events from web data. The existing approaches of such event detection can be divided into three categories: content-based method, structure-based method and log-based method. In plain terms, the content-based method detects events through analyzing textual information of web resources using techniques such as natural language processing [1]; the structure-based method utilizes website structures and hyperlink structures to discover events exploits web search logs (namely, the click-through data ) to detect events [3] [4]. centric . Based on this classification, the former two approaches utilize the author-Therefore, the log-based method can extract information such as users X  activities and interestingness to various real world events, and such information may play equally or even more important role in event detectio n compared with the author-centric data. Besides, the click-through data are collected automatically by web search engine and are easier to obtain. Detecting events from such data has more practical significance. through data. 
Table 1 shows an example of click-through data, which record the interactions between users and a web search engine. It can also be represented as a bipartite graph elements: query keywords issued by users, URL of the page clicked by users and the time the query was submitted to the search engine. From the click-through data, three kinds of information can be used for event detection: link information (that is above information to discover groups of click records (or query-page pairs in the bipartite graph) that correspond to real life events. 
In order to enhance event detection from click-through data, we deem that three issues need to be addressed. First, the click-through data are produced by users X  query discover real life events with high precision and recall is a problem. Second, the web organized well so that from the results users can find the real world interesting events conveniently. 
This paper aims to address the above three issues. In terms of the effectiveness, we event detection and incorporate link inform ation, temporal information and query content simultaneously to ensure the quality of detected events. As for the efficiency, we propose an efficient algorithm, which divides the whole data into several small semantic-relevant subsets, each of which is called a topic . Then the event detection is performed in each topic, making the whole process efficient. In order to organize the results orderly, we introduce an interestingness measure, which is similar to the work extracted from one topic can be clustered naturally. 
The proposed log-based event detection method is performed on a real life click-through dataset collected from MSN search engine. We also manually labeled a list of events to evaluate the quality of the detected events. The results show that by and from the performance on datasets of different size our algorithm shows high efficiency. Experimental results on real life data are shown in Section 4. Finally, we draw conclusions and future work in Section 5. discuss difference between previous works and our work. 
Event detection is part of a broader area called Topic Detection and Tracking (TDT). TDT is a famous research project which can be divided into two categories [5] as Retrospective Event Detection (RED) [5 ] [6] and New Event Detection (NED) [7] [8]. At the moment, our work is more related to RED. RED is first proposed in [5] by Yang et al., and an agglomerative clus tering algorithm called Group Average Clustering was proposed in that paper. In [6], the author proposed a multi-model RED algorithm, which incorporated both the co ntent and the time information, and an approach was proposed to determine the approximate number of events. Besides TDT, many research works focus on detecting events by identifying burst patterns of content-based features from a text stream [9] [10] [11]. [9] introduced how to extract burst features from text streams, where the text stream is modeled as an infinite state automation and the bursts are modeled as transition states. In [10], the author for event detection. The difference between our work and above TDT research or the visitor-centric data, we may find hotter and more interesting events. 
Recently, with the development of search engine and Web2.0 technology, many researches have focused on exploiting web search logs for various purposes such as query expansion [12], named entity mining [13] and web search improvement [14], etc. However, to the best of our knowledge, there are only two of such works focusing on event detection [3] [4]. The work done by Zhao et al. [3] is the first effort, in which two phases of clustering based on semantic and temporal similarity respectively are performed to group similar query-page pairs corresponding to real life events. While in [4], the authors use query session as indicator of event. They first map each query session to a polar space based on content and time similarity, then group query general method of our work is different from the above two works. Besides, both the above two works run some time consuming algorithms in the whole click-through data and fail to mention the efficiency in their papers; while the algorithm we propose is quite efficient and applicable. The framework of our method, TED , for exploiting web search logs to detect events is presented in Fig. 2. 
Given the click-through data, which can be represented as a bipartite graph, we first divide this graph into several sub-graphs each of which corresponds to a topic by information. Then, we propose a novel notion called click-through burst region as event indicator to further detect events from topics. For each topic, the events can be detected by clustering the similar burst regions. Here the link information, temporal information organize the detected events th rough their interestingness and the topics they belong to. 3.1 Dividing Click-Through Data into Topics that events can be detected efficiently in each small sub-graph. To do this, we use the Jaccard coefficient to measure similarities of nodes in a graph so that the nodes with similar neighbors tend to be grouped into one dense sub-graph. While its method is based on recursive stages of fingerprinting the graph, which after multiple applications efficient and is capable of handling graphs with tens of billions edges [15]. 
After running the algorithm Shingle, we get dense sub-graphs of click-through graphs. To solve this problem, we further consider query content of each dense sub-graph and merge the content-similar sub-graphs into one larger sub-graph to reflect each dense sub-graph, here the classical tfidf and cosine similarity techniques are used to measure the similarity of queries, and the inverted indexing is used to speed up this step. in Section 3.3 is used so that uninteresti ng topics need not be considered anymore. 3.2 Event Detection In this section, we will introduce our method to detect events from each topic. From each topic, we first propose a novel event indicator called click-through burst region ( burst region for short). Then link information, temporal information and query content are combined linearly to measure the similarity between burst regions. Finally burst regions can be clustered as events. 3.2.1 Click-Through Burst Region Based on the intuitive premise used in [9], the appearance of an event can be signaled by a  X  X urst of activity X . Therefore, a sharp increase in time series of query-page pair X  X  click-through (the number of click-throughs) tends to indicate a real life event. Based on this, we choose burst region defined below as event indicator. Definition 1 ( click-through burst region ) click-through burst region is a period in the time series of a query-page pair X  X  click-through, in which the click through increased sharply than average click-through of the time series. the click-through time series for detecting burst regions. Each of detected burst end time of burst region B respectively. 3.2.2 Burst Region Similarity In this section, we introduce the method to measure the similarity of two click-through burst regions by combining link, content and time similarity. 
The link-based similarity between two burst regions B i and B j is denoted as First, bipartite graph of each topic is converted to a dual graph. Each edge between a graph. Two nodes in the dual graph are linked by an edge if they have the same query or URL. Then, we run algorithm SimFusion [17] to calculate the link similarity between different nodes to represent link-based similarity of burst regions as shown in P contains burst region B j . The content-based similarity is donated as contentSim ( B i , B j ) and is calculated by the query content similarity as introduced in Section 3.1. how near two burst regions happened by Equation (3): which can be measured by the difference between the starting time of B j and the T four days and so |B 1 | equals 4. Therefore, by Equation (3), if two burst regions have overlap, the larger overlap they have, the more similar they are. Otherwise, the larger distance they have, the less similar they are. 
Based on the three type similarity introduced above, the similarity between burst regions B i and B j , Sim ( B i , B j ), can be calculated by Equation (4):  X  ,  X  and  X  are three parameters used to tradeoff the effectiveness of link, content and experimental section. After getting the similarity between click-through burst regions, clustering procedure. Each cluster obtained after this step corresponds to an event. 3.3 Organizing Detected Events After detecting the events, effective organization of the detection results is important for improving the utility of our method. To do this, we develop an interestingness measure to indicate how hot and interesting a detected event is. An event is assumed pattern of  X  X urst of activity X . So we introduce the following definition to measure the interestingness. Definition 2 ( attention degree ). Given a query-page pair p and event E it belongs to, ad ( E ), are defined as: attention degree means this query-page pair or event attracts more people X  X  attention. Definition 3 ( burst rate ) Given a query-page pair p and the event E it belongs to, burst rate of p and E are defined as follows: give the notion of interestingness measure . Definition 4 ( interestingness measure ) The interestingness measure of an event E considers both the attention degree factor and burst rate factor of this event, which is defined as follows: We calculate each event X  X  interestingness measure to rank the detected events so that the more interesting an event is, the topper position it will be in the ranked event list. Furthermore, since we detect event in each topic, events detected from one topic can be organized together and listed by order of the timestamp of each event. 4.1 Dataset Our experiments are conducted on a real life click-through dataset collected from MSN search engine from May 1 to May 31, 2006. Our click-through dataset contains million distinct query-URL(query-page) pairs. 
To evaluate effectiveness of our method, we manually labeled 10 real life topics and 13 corresponding events from the dataset. Each labeled topic and event contains a set of query-page pairs. Given a topic, we label query-page pairs to represent the topic and the corresponding events by the following steps: 1. Select a set of queries, denoted as Q , which were frequently submitted and 2. The click-through data are represented as a bipartite graph, which contain a 3. For each connected sub-graph in G , filter out the queries and URLs whose 4. For each query-page pair in the filtered G , we manually check whether it belongs 
Based on the above method, we extract 13 real life events from the click-through Then from the labeled click-through records, we randomly choose other unrelated records from the whole datasets to generate larger and noisier data. We extracted four datasets: dataset1, dataset2, dataset3 and dataset4, whose numbers of click-through records are 250k, 350k, 600k and 1,000k respectively. 4.2 Parameter Setting performed on dataset1. Methods based on different linear combinations of link information, temporal information and query content are listed in Table 3. 
The parameter  X  ,  X  and  X  in equation (4) are set in the following way: z For Detection based on Link_Content schema,  X  is set to zero and  X  is set to 0.1, z For Link_Time_Content schema,  X  ,  X  and  X  are set according to the values that the quality of detected events. The F-score of Link schema is quite low and it cannot be shown in the figure. By analyzing the detected events, we find that this is because most events detected by this schema have high precision but very low recall, which is consistent with the observation in [16]. Though the performance of the method only based on link information is poor, combining link information with temporal or content information often leads to better performance, and the performance based on the combination of all the three kinds of information is best. 4.3 Efficiency Evaluation Setting the parameters according to the above experiment, we run our algorithm TED on the other three datasets. The experiment is conducted on a HP dc7700 desktop with an Intel Core2 Duo E4400 2.0 GHz CPU and 3.49 GB RAM. Figure 5 and 6 shows the runtime of separation step and F-score of our algorithm on different datasets. minutes. Besides, with the augment of the datasets, the runtime of the algorithm no reduce of the F-score of detected events. These two figures testify that our algorithm has quite high efficiency with good effectiveness. 4.4 Illustrative Examples By running our algorithm TED on the dataset4, we get a list of ranked detected found in the top 100 events. 
From Table 4 we can find that events of rank 1, 2, 4 and 5 are events in the labeled dataset, and two events about David Blaine are organized together in chronological events of rank 6 and 7 correspond to two criminal case news and event of rank 10 is about a legend ball held by Oprah Winfrey in honor of 25 African-American women movie star and a government organizatio n are not available now or have been updated, so we have no idea what exactly happened at that time. By analyzing the result, we find that our algorithm still has some shortcomings. For correspond to any real life event. This problem may be relieved through a more critical pruning strategy. Besides, although we consider the query content to solve the top 100 hot events. 4.5 Comparative Experiment similar to our method for event detection. In this section, we compare our method with it (we call it two-phase-clustering) on efficiency and effectiveness. Since the two-phase-clustering method runs a time-consuming algorithm experiment environment. To do the comparison, we generate another four smaller datasets: no_noise, noise_2, noise_4 and noise_8, which stand for labeled datasets Dataset of no_noise contains 35k click records. 
For efficiency, we compare the runtime of first phase of [3] with the runtime of the separation step of TED . Both methods X  second steps are performed on subset data and are relatively efficient. Fig. 7 shows the experimental result, where we can see that the runtime of our method increases much slower than that of Two-phase-clustering. In noise_8, our method consume about one minute while First Phase consume four days. So our method is much more efficient than the first phase of [3] in dealing with click-through data. As for effectiveness, Fig. 8 shows the result of F-score for four datasets. We can see that our method has a much higher F-score for each dataset, which means our event detection method performs better than that of [3]. In this paper, we propose an efficient log-based method, TED , which incorporates link information, temporal information and query content for topic and event detection. Two major steps are contained in our method. The first is a separation step, in which step is performed, in which we use the burst region as indicator of events and clustering similar burst regions by linearly combing link information, temporal information and query content. The experiments conducted on real life dataset show that our method can detect events effectively and efficiently from click-through data. 
Practice asks for online detection of emerging events. For future work, we will extend our Retrospective Event Detection algorithm to New Event Detection. Moreover, we will explore how to utilize the page content to further improve the performance of our method. Acknowledgments. This work was supported in part by the National Natural Science Foundation of China under Grant No. 70871068, 70621061 and 70890083. We also thank Microsoft Research Asia for providing the real data and funding this research. 
