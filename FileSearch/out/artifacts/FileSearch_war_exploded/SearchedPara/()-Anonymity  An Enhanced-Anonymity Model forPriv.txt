
Privacy preservation is an important issue in the release of data for mining purposes. The -anonymity model has been introduced for protecting individual identification. Recent studies show that a more sophisticated model is necessary to protect the association of individual s to sensitive information. In this paper, we propose an -anonymity model to protect both identifications and rela-tionships to sensitive information in data. We discuss the proper-ties of -anonymity model. We prove that the optimal -anonymity problem is NP-hard. We first present an optimal global-recoding method for the -anonymity problem. Next we pro-pose a local-recoding algorithm which is more scalable and result in less data distortion. The effectiveness and efficiency are shown by experiments. We also describe how the model can be extended to more general cases.
 Categories and Subject Descriptors: H.2.8 [Database Applica-tions]: Data Mining; K.4.1 [Public Policy Issues]: Privacy General Terms: Algorithms, Theory, Performance, Experimenta-tion Keywords: anonymity, privacy preservation, data publishing, data mining
Privacy preservation has become a major issue in many data min-ing applications.When a data set is released to other parties for data mining, some privacy-preserving technique is often required to re-duce the possib ility of identifying sensitive information about indi-viduals. This is called the disclosure-control problem [4] in statis-tics and has been studied for many years. Most statistical solutions concern more about maintaining statistical invariant of data. The data mining community has been studying this problem aiming at building strong privacy-preserving models and designing efficient optimal and scalable heuristic solutions. The perturbing method [2] and the -anonymity model [11, 10] are two major techniques for Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00.
 Table 1: Raw Medical Data Set
Table 3: An Alternative 2-anonymous Data Set of Ta-ble 1 this goal. The -anonymity model has been extensively studied recently because of its relative conceptual simplicity and effective-ness (e.g. [5, 1]).

In this paper, we focus on a study on the -anonymity prop-erty [11, 10]. The -anonymity model assumes a quasi-identifier , which is a set of attributes that may serve as an identifier in the data set. It is assumed that the dataset is a table and that each tu-ple corresponds to an individual. Let be the quasi-identifier. An equivalence class of a table with respect to is a collection of all tuples in the table containing identical values for . For example, tuples 1 and 2 in Table 2 form an equivalence class with respect to attribute set Job, Birth, Postcode . The size of an equivalence class indicates the strength of identification protection of individu-als in the equivalent class. If the number of tuples in an equivalence class is greater, it will be more difficult to re-identify individual. A data set is -anonymous with respect to if the size of every equivalence class with respect to is or more. As a result, it is less likely that any tuple in the released table can be linked to an individual and thus personal privacy is preserved.

For example, we have a raw medical data set as in Table 1. At-tributes job, birth and postcode 1 form the quasi-identifier. Two
We use a simplified postcode scheme in this paper. There are four single digits, representing states, regions, cities and suburbs. Postcode 4350 indicates state-region-city-suburb.
 unique patient records 1 and 2 may be re-identified easily since their combinations of job, birth and postcode are unique. The ta-ble is generalized as a 2-anonymous table as in Table 2. This table makes the two patients less likely to be re-identified. In the literature of -anonymization, there are two main models. One model is global recoding [11, 7, 5, 10] while the other is local recoding [11, 1].

We assume that each attribute has a corresponding conceptual hierarchy or taxonomy. A lower level domain in the hierarchy pro-vides more details than a higher level domain. For example, birth date in D/M/Y (e.g. 15/Mar/1970) is a lower level domain and birth date in Y (e.g. 1970) is a higher level domain. We assume such hierarchies for numerical attributes too. In particular, we have a hi-erarchical structure defined with value, interval, ? ,wherevalue is the raw numerical data, interval is the range of the raw data and ? is a symbol representing any values. Generalization replaces lower level domain values with higher level domain values. For example, birth D/M/Y is replaced by M/Y.

In global recoding , all values of an attribute come from the same domain level in the hierarchy. For example, all values in Birth date are in years, or all are in both months and years. One advantage is that an anonymous view has uniform domains but it may lose more information. For example, a global recoding of Table 1 may be Table 4 and it suffers from over-generalization . With local recod-ing , values may be generalized to different levels in the domain. For example, Table 2 is a 2-anonymous table by local recoding. In fact one can say that local recoding is a more general model and global recoding is a special case of local recoding. Note that, in the example, known values are replaced by unknown values (*). This is called suppression , which is one special case of generalization, which is in turn one of the ways of recoding.

Let us return to the earlier example. If we inspect Table 2 again, we can see that though it satisfies 2-anonymity property, it does not protect two patients X  sensitive information, HIV infection. We may not be able to distinguish the two individuals for the first two tuples, but we can derive the fact that both of them are HIV infectious. Suppose one of them is the mayor, we can then confirm that the mayor has contracted HIV. Surely, this is an undesirable outcome. Note that this is a problem because the other individual whose gen-eralized identifying attributes are the same as the mayor also has HIV. Table 3 is an appropriate solution. Since (*,1975,4350) is linked to multiple diseases (i.e. HIV and fever) and (*,*,4350) is also linked to multiple diseases (i.e. HIV and flu), it protects indi-vidual identifications and hides the implication.

We see from the above that protection of to sen-sitive attribute values is as important as identification protection. Thus there are two goals for privacy preservation: (1) to protect individual identifications and (2) to protect sensitive relationships. Our focus in this paper is to build a model to protect both in a dis-closed data set. We propose an -anonymity model, where is a fraction and is an integer. In addition to -anonymity, we require that, after anonymization, in any equivalence class, the fre-quency (in fraction) of a sensitive value is no more than .We first extend the well-known -anonymity algorithm Incognito [7] to our -anonymity problem. As the algorithm is not scalable to the size of quasi-identifier and may give a lot of distortions to the data since it is global-recoding based, we also propose an efficient local-recoding based method.

This proposal is different from the work of association rules hid-ing [12] in a transactional data set, where the rules to be hidden have to be known beforehand and each time only one rule can be hidden. Also, the implementation assumes that frequent itemsets of rules are disjoint, which is unrealistic. Our scheme blocks all rules from quasi-identifications to a sensitive class.

This work is also different from the work of template-based pri-vacy preservation in classification problems [13], which considers hiding strong associations between some attributes and sensitive classes and combines -anonymity with association hiding. There, the solution considers global recoding by suppression only and the aim is to minimize a distortion effect that is designed and dedi-cated for a classification problem. The model defined in this paper is more general in that we allow local recoding and that we aim at minimizing the distortions of data modifications without any at-tachment to a particular data mining method such as classification.
The -diversity model [8] is proposed to solve the above problem, which is called the homogeneity attack. However, the tack, which is assuming that the attacker has background knowl-edge to rule out some possible values in a sensitive attribute for the targeted victim. Parameter describes the level of diversity of sen-sitive values. If is larger, there will be more different sensitive val-ues in a group. The idea of using parameters and is to ensure that the most frequent sensitive value in a group should not be too fre-quent after the next most frequent sensitive values are removed, where is related to parameter . It is quite difficult for users to set parameters and . Though we anticipate attacks with background knowledge, it is not clear what background knowledge an attacker may have. For example, it is possible that the attacker can rule out 90% of the possib ilities if he/sh e judges from the symptoms (e.g. coughing). An attacker knows that his/her neighbor should have either one of a few diseases (e.g. lung cancer), among tens or even hundreds of other diseases that have no relationship to the symptoms. To keep such background knowledge at bay, we must prepare for the elimination of a large amount of possible values. Setting and to fortify against the exclusion of say over 90% of all possibilities would require massive generalization, if not simply impossible. Besides we do not know what other kinds of back-ground knowledge an attacker may have. Hence we believe that background knowledge attack should be handled by more special treatment and not by a general anonymization mechanism. Also, the proposed algorithm in [8] is based on a global-recoding exhaus-tive algorithm Incognito, which is not scalable and may generate more distortion compared to local recoding.

We propose to handle the issues of -anonymity with protection of sensitive values for sensitive attributes.

Our Contributions: (1) We propose a simple and effective model to protect both iden-tifications and sensitive associations in a disclosed data set. The model extends the -anonymity model to the -anonymity model to limit the confidence of the implications from the quasi-identifier to a sensitive value (attribute) to within in order to protect the sensitive information from being inferred by strong implications. We prove that the optimal -anonymity by local recoding is NP-hard. (2) We extend Incognito[7], a global-recoding algorithm for the -anonmity problem, to solve this problem for -anonymity. We also propose a local-recoding algorithm, which is scalable and gen-erate less distortion. In our experiment, we show that, on average, the local-recoding based algorithm performs about 4 times faster and gives about 3 times less distortions of the data set compared with the extended Incognito algorithm. We also describe how the model can be extended to more general cases.
The -anonymity model requires that every value set for the quasi-identifier attribute set has a frequency of zero or at least . For example, Table 1 does not satisfy -anonymity property since tuples Cat1, 1975, 4350 and Cat1, 1955, 4350 occur once. Ta-ble 2 satisfies 2-anonymity property. Consider a large collection of patient records with different medical conditions. Some diseases are sensitive, such as HIV, but many diseases are common, such as cold and fever. Only associations with sensitive diseases need pro-tection. To start with, we assume only one sensitive value, such as HIV. We introduce the -deassociation requirement for the protec-tion.
 a data set , an attribute set and a sensitive value in the do-main of attribute .Let be the set of tuples in equiva-lence class containing for and be a user-specified thresh-old, where .Dataset is -deassociated with respect to attribute set and the sensitive value if the relative frequency of in every equivalence class is less than or equal to . That is,
For example, Table 3 is 0.5-deassociated with respect to attribute set Job, Birth, Postcode and sensitive value HIV. There are three equivalence classes: , and . For each of the first two equivalent classes of size two, only one tuple contains HIV and therefore . For the third equivalence class, no tuple contains HIV and therefore . Thus, for any equivalence classes, .

Our objective is therefore to anonymize a data set so that it sat-isfies both the -anonymity and the -deassociation criteria.
D EFINITION 2( -A NONYMIZATION ). A view of a table is said to be an -anonymization of the table if the view mod-ifies the table such that the view satisfies both -anonymity and -deassociation properties with respect to the quasi-identifier.
For example, Table 3 is a (0.5, 2)-anonymous view of Table 1 since the size of all equivalence classes with respect to the quasi-identifier is 2 and each equivalence class contains at most half of the tuples associating with HIV.

Both parameters and are intuitive and operable in real-world applications. Parameter caps the confidence of implications from values in the quasi-identifier to the sensitive value while parameter specifies the minimum number of identical quasi-identifications.
D EFINITION 3(L OCAL R ECODING ). Givenadataset of tuples, a function that convert each tuple in to is a local recoding for .

Local recoding typically distorts the values in the tuples in a data set. We can define a measurement for the amount of distortion generated by a recoding, which we shall call the recoding cost . If a suppression is used for recoding of a value which modifies the value to an unknown *, then the cost can be measured by the total number of suppressions, or the number of * X  X  in the resulting data set. Our objective is to find local recoding with a minimum cost. We call it the problem of optimal -anonymization. The corresponding decision problem is defined as follows. identifier and a sensitive value , is there a local recoding for by a function such that, after recoding, -anonymity is satisfied and the cost of the recoding is at most ?
Optimal -anonymization by local recoding is NP-hard as dis-cussed in [9, 1]. Now, we show that optimal -anonymization by local recoding is also NP-hard.

T HEOREM 1. ( )-anonymity is NP-hard for a binary alpha-bet ( = 0, 1 ).
 Proof Sketch : The proof is by transforming the problem of EDGE PARTITION INTO 4-CLIQUES to the ( )-anonymity problem.

EDGE PARTITION INTO 4-CLIQUES: Given a simple graph , with for some integer , can the edges of be partitioned into edge-disjoint 4-cliques? [6] Given an instance of EDGE PARTITION INTO 4-CLIQUES.
 Set and . For each vertex , construct a non-sensitive attribute. For each edge ,where , create a pair of records and , where the two records have the attribute values of both and equal to 1 and all other non-sensitive attribute values equal to 0, but one record has the sensitive attribute equal to 1 and the other record has the sensitive attribute equal to 0.

We define the cost of the ( )-anonymity to be the number of suppressions applied in the data set. We show that the cost of the ( )-anonymity is at most if and only if can be partitioned into a collection of edge-disjoint 4-cliques.
Suppose can be partitioned into a collection of disjoint 4-cliques. Consider a 4-clique with vertices , and .If we suppress the attributes and in the 12 records corre-sponding to the edges in , then a cluster of these 12 records are formed where each modified record has four * X  X . Note that the -deassociation requirement can be satisfied as the frequency of the sensitive attribute value 1 is equal to 0.5. The cost of the ( )-anonymity is equal to .

Suppose the cost of the ( )-anonymity is at most .As is a simple graph, any twelve records should have at least four attributes different. So, each record should have at least four * X  X  in the solution of the ( )-anonymity. Then, the cost of the ( )-anonymity is at least . Combining with the proposition that the cost is at most , we obtain the cost is exactly equal to and thus each record should have exactly four * X  X  in the solution. Each cluster should have exactly 12 records (where six have sensitive value 1 and the other six have sensitive value 0). Suppose the twelve modified records contain four * X  X  in attributes , , and , the records contain 0 X  X  in all other non-sensitive attributes. This corresponds to a 4-clique with vertices , , and . Thus, we conclude that the solution corresponds to a partition into a collection of edge-disjoint 4-cliques.
Let be the fraction of the set of tuples that contain sensitive values. Suppose is set smaller than . Then no matter how we partition the data set, by the pigeo n hole principle, there should be at least one partition which contains or more sensitive value, and therefore cannot satisfy -deassociation property.

L EMMA 1(C HOICE OF ). should be set to a value greater than or equal to the frequency (given in fraction) of the sensitive value in the data set .

Distortion Ratio or Recoding Cost : Since we assume the more general case of a taxonomy tree for each attribute, we define the cost of local-recoding based on this model. The cost is given by the distortion ratio of the resulting data set and is defined as fol-lows. Suppose the value of the attribute of a tuple has not been generalized, there will be no distortion. However, if the value of the attribute of a tuple is generalized to a more general value in the taxonomy tree, there is a distortion of the attribute of the tuple. If the value is generalized more (i.e. the original value is updated to a value at the node of the taxonomy near to the root), the distortion will be greater. Thus, the distortion of this value is defined in terms of the height of the value generalized. For example, if the value has not been generalized, the height of the value generalized is equal to Table 6: Projected Table with Quasi-identifier = Postcode: (a) Original Table and (b) Generalized Table 0. If the value has been generalized one level up in the taxonomy, the height of the value generalized is equal to 1. Let be the height of the value generalized of attribute of the tuple .The distortion of the whole data set is equal to the sum of the distor-tions of all values in the generalized data set. That is, distortion = ized data set divided by the distortion of the fully generalized data set, where the fully generalized data set is one with all values of the attributes are generalized to the root of the taxonomy.
In this section, we extend an existing global-recoding based algo-rithm called Incognito [7] for the -anonymous model. Incog-nito algorithm [7] is an optimal algorithm for the -anonymity problem. It has also been used in [8] for the -diversity problem. [7] and [8] make use of monotonicity property in searching the solution space. The searches can be made ef ficient if a stopping condition is satisfied. The stopping condition is that, if table satisfies the privacy requirements, then every generalization of also satisfies the privacy requirement.

Algorithm: The algorithm is similar to [7, 8]. The difference is in the testing criteria of each candidate in the solution space. [7] tests for the -anonymity property and [8] tests the -anonymity and -diversity properties. Here, we check the -anonymity property.
The extended Incognito algorithm is an exhaustive global recod-ing algorithm which is not scalable and may generate excessive dis-tortions to the data set. Here we propose a scalable local-recoding algorithm called top-down approach.

In this section, we present a top-down approach to tackle the problem. For ease of illustration, we first present the approach for a quasi-identifier of size 1. Then, the method is extended to handle quasi-identifiers of size greater than 1. The idea of the algorithm is to first generalize all tuples completely so that, initially, all tuples are generalized into one equivalence class. Then, tuples are spe-cialized in iterations. During the specialization, we must maintain ize the tuples anymore.

Let us illustrate with an example in Table 5. Suppose the quasi-identifer contains Postcode only. Assume that and .
 Initially, we generalize all four tuples completely to an equivalence class with Postcode = **** (Figure 1 (a)). Then, we specialize each tuple one level down in the generalization hierarchy. We obtain the branch with Postcode = 4*** in Figure 1 (b). In the next iterations, we obtain the branch with Postcode = 43** and the branch with Postcode = 435* in Figure 1 (c) and Figure 1 (d), respectively. As the Postcode of all four tuples starts with the prefix  X 435 X , there is only one branch for each specialization of the postcode with pre-fix  X 435 X . Next, we can further specialize the tuples into the two branches as shown Figure 1 (e). Hence the specialization process-ing can be seen as the growth of a tree.

If each leaf node satisfies -anonymity, then the specializa-tion will be successful. However, we may encounter some prob-lematic leaf nodes that do not satisfy -anonymity. Then, all tuples in such leaf nodes will be pushed upwards in the generaliza-tion hierarchy. In other words, those tuples cannot be specialized in this process. They should be kept unspecialized in the parent node. For example, in Figure 1 (e), the leaf node with Postcode = 4352 contains only one tuple, which violates -anonymity, where . Thus, we have to move this tuple back to the parent node with Postcode = 435*. See Figure 1 (f).

After the previous step, we move all tuples in problematic leaf nodes to the parent node. However, if the collected tuples in the par-ent node do not satisfy -anonymity, we should further move some tuples from other leaf nodes to the parent node so that the parent node can satisfy -anonymity while also maintain the -anonymity. For instance, in Figure 1 (f), the parent node with Postcode = 435* violates -anonymity, where .
 Thus, we should move one tuples upwards in the node with Post-code = 4351 (which satisfies -anonymity). In this example, we move tuple 3 upwards to the parent node so that both the parent node and the node satisfy the -anonymity.

Finally, in Figure 1 (g), we obtain a data set where the Postcode of tuples 3 and 4 are generalized to 435* and the Postcode of tuples 1 and 2 remains 4351. We call the final allocation of tuples in Figure 1 (g) the final distribution of tuples after the specialization. The results can be found in Table 6 (b).

In this approach, we have to un-specialize some tuples which have already satisfied the -anonymity. Which tuples should we select in order to produce a generalized data set with less dis-tortion? We tackle this issue by the following additional steps. We further specializing all tuples in all candidate nodes. We repeat the specialization process until we cannot further specialize the tuples. Then, for each tuple , we record the number of times of specializa-tions. If the tuple has fewer times of specializations, it should be considered as a good choice for un-specialization since it is evident that it cannot be specialized deeply in later steps.

Quasi-identifier of Size More Than 1: Next we extend the top-down algorithm to handle the case where the quasi-identifier has a size greater than one. Again, all attributes of the tuples are generalized fully in the first step. Then, for each iteration, we find the  X  X est X  attribute for specialization and perform the specialization for the  X  X est X  attribute. The iteration continues until no further specialization is available.

Consider a group . We will specialize the group by spe-cializing with one attribute. We have to find the  X  X est X  attribute for specialization. For each attribute in the quasi-identifer, our ap-proach  X  X ries X  to specialize . Then, among those specializations, we find the  X  X est X  attribute for final specialization. Our criteria of choosing the  X  X est X  attributes are described as follows.
Criteria 1 (Greatest No of Tuples Specialized): During the specialization of , we obtain a final distribution of the tuples. Some are specialized and some may still remain in . The  X  X est X  specialization yields the greatest number of tuples specialized be-cause that corresponds to the least overall distortion.
Criterion 2 (Smallest No of Branching Specialized): In case there is a tie when we consider the first criterion, we will fur-ther consider the number of branches specialized (i.e. non-empty branches). The  X  X est X  specialization yields the smallest number of branches specialized. The rationale is that smallest number of branches can be an indicator of more generalized domain and it is a good choice compared to a less generalized domain.
Pentium IV 2.2GHz PC with 1GM RAM was used to conduct our experiment. The algorithm was implemented in C/C++. In our experiment, we adopted the publicly available data set, Adult Database, at the UCIrvine Machine Learning Repository [3]. This data set (5.5MB) was also adopted by [7, 8, 14, 5]. We used a configuration similar to [7, 8]. We eliminated the records with un-known values. The resulting data set contains 45,222 tuples. Nine of the attributes were chosen as the quasi-identifier, as shown in Ta-ble 7. On default, we set and , and we chose the first eight attributes and the last attribute in Table 7 as the quasi-identifer and the sensitive attribute, respectively.

We evaluated the proposed algorithm in terms of two measure-ments: execution time and distortion ratio (see Section 2). We con-ducted the experiments five times and took the average execution time.

We denote the proposed algorithms by Top Down and eIncog-nito . eIncognito denotes the extended Incognito algorithm while Top Down denotes the local-recoding based top-down approach, respectively.

Figure 2 shows the graphs of the execution time and the dis-tortion ratio against quasi-identifier size and when .In Figure 2 (a), when varies, different algorithms change differ-ently. The execution time of eIncognito Algorithm increases with . This is because, when increases, the number of candidates (representing the generalization domain) increases, and thus the execution time increases. The execution time of Top Down Al-gorithm decreases when increases. In the top-down algorithm, Figure 2: Execution Time and Distortion Ratio Versus Quasi-identifier Size and ( ) we may have to unspecialize some tuples in the branches satisfying When is small, it is more likely that the parent cannot satisfy un-specialization step is more complex, the execution time is larger when is smaller.

In Figure 2 (b), when the quasi-identifer size increases, the ex-ecution time of the algorithm increases because the complexity of the algorithms is increased with the quasi-identifier size.
On average, among these three algorithms, eIncognito Algorithm requires the greatest execution time and Top Down Algorithm has the smallest execution time. This shows that eIncognito performs much slower compared with local-recoding based algorithm. In Figure 2 (c), when increases, the distortion ratio decreases. Intuitively, if is greater, there is less requirement of -deassociation, yielding fewer operations of generalization of the values in the data set. Thus, the distortion ratio is smaller.

In Figure 2 (d), it is easy to see why the distortion ratio increases with the quasi-identifier size. When the quasi-identifier contains more attributes, there is more chance that the quasi-identifier of two tuples are different. In other words, there is more chance that the tuples will be generalized. Thus, the distortion ratio is greater. When is larger, it is also obvious that the distortion ratio is greater because it is less likely that the quasi-identifer of two tuples are equal. On average, Top Down algorithm results in about 3 times smaller distortion ratio compared with eIncognito Algorithm. Figure 3: Execution Time and Distortion Ratio Versus Quasi-identifier Size and ( )
We have also conducted the experiments for ,whichis shown in Figure 3. The results are also similar to the graphs for
In this section, we will extend the simple -model to multi-ple sensitive values. When there are two or more sensitive values and they are rare cases in a data set (e.g. HIV and prostate cancer). We may combine them into one combined sensitive class and the simple -anonymity model is applicable. The inference confi-dence to each individual sensitive value is smaller than or equal to the confidence to the combined value, which is controlled by .
Next we consider the case when all values in an attribute are sensitive and require protection. It is possible to have an -anonymity model to protect a sensitive attribute when the attribute contains many values and no single value dominates the attribute (which will be explained later). The salary attribute in employer table is an example. When each equivalent class contains three salary scales with even distribution, we have about 33% confidence to infer the salary scale of an individual in the equivalent class.
D EFINITION 4( -RARE ). Given an equivalence class ,an attribute ! and an attribute value " ! .Let " be the set of tuples containing " in and be a user-specified threshold, where set ! if the proportion of every attribute value of ! in the data set is not greater than ,i.e. " for " ! .

For example, in Table 3, if ! # , equivalent class is 0.5-rare because  X  X lu X  and  X  X ever X  occur evenly in the equivalent class. If every equivalent class is -rare in the class, the data set is called -deassociated.
 Given a data set , an attribute set and a sensitive class attribute .Let be a user-specified threshold, where .Data set is generally -deassociated with respect to an attribute set and a sensitive attribute if, for any equivalent classes , is -rare with respect to .

For example, Table 3 is 0.5-deassociated since all three equiva-lent classes, , and , are 0.5-rare with respect to attribute set Illness. When a data set is -deassociated with re-spect to a sensitive attribute, it is -deassociated with respect to every value in the attribute. Therefore, the upper bound of infer-ence confidence from the quasi-identifier to the sensitive attribute is .

The proposed algorithms in Sections 3 and 4 can be extended to the general -anonymity model. The global-recoding based algorithm depends on the monotonicity property. The propoerty holds for the general -anonymity. Thus, the global-recoding based algorithm can be extended by modifying the step of testing of candidates with the general model.

The top-down local-recoding algorithm can also be easily ex-tended to the general model by modifying the condition when test-ing the candidates.
The -anonymity model protects identification information, but does not protect sensitive relationships in a data set. In this paper, we propose the -anonymity model to protect both identifica-tions and relationships in data. We discuss the properties of the model. We prove that achieving optimal -anonymity by lo-cal recoding is NP-hard. We present an optimal global-recoding method and an efficient local-encoding based algorithm to trans-form a data set to satisfy -anonymity property. The experi-ment shows that, on average, the local-encoding based algorithm performs about 4 times faster and gives about 3 times less distor-tions of the data set compared with the global-recoding algorithm. We also describe how the model can be extended to more general cases.

