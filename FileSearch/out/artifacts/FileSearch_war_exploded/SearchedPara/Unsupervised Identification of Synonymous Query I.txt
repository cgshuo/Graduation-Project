 Among all web search queries there is an important subset of queries containing entity mentions. In these queries, it is observed that other than querying the entity name, users are most interested in requesting some attribute of an entity, such as  X  X bama age" for the intent of age, which we refer to as the attribute intent. In this work we address the problem of identifying synonymous query in-tent templates for the attribute intent. For example,  X  X ow old is [Person]" and  X  X Person] X  X  age" are both synonymous templates for the age intent. Successful identification of the synonymous query intent templates not only can improve the performance of all ex-isting query annotation approaches, but also could benefit applica-tions such as instant answers and intent-based query suggestion. In this work we propose a clustering framework with multiple kernel functions to identify synonymous query intent templates for a set of canonical templates jointly. Furthermore, signals from multi-ple sources of information are integrated into a kernel function be-tween templates, where the weights of these signals are tuned in an unsupervised manner. We have conducted extensive experiments across multiple domains in FreeBase, and results demonstrate the effectiveness of our clustering framework for finding synonymous query intent templates for attribute intents.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Query Intent Algorithms, Performance, Experimentation Attribute Intent, Synonymous Query Intent Templates, Clustering with Multiple Kernels Copyright c  X  2013 ACM 978-1-4503-0757-4/11/07 ...$15.00.
Accurate understanding of the intent underlying a user query is a crucial problem in modern information retrieval. The understand-ing of user X  X  intent not only can improve the accuracy of the search results, but also enables new types of applications that help the user make decision and finish tasks directly. For example, for a query  X  X om Cruise age", an intelligent search engine would trigger the di-rect answer of  X 50 years" on top of the result page, which quickly fulfils the user X  X  information need for finding this fact about Tom Cruise. Likewise, for a query  X  X ap of Chicago", it is more desir-able to show a city map of Chicago directly. Another emerging application is the entity search, which returns the most relevant en-tities and attributes instead of relevant web pages. The examples mentioned above all require precise understanding of the intent of a user query.

In this work we focus on the subset of queries containing en-tity mentions since they are one of the most important subset of queries. One previous research reported that 71% of search queries contained named entities [1], another research found that 57% of queries have entities or entity categories [2]. We have observed from the query log of a major search engine that among the entity queries, other than querying the entity name users are most inter-ested in requesting an attribute of an entity 1 . We refer to such intent as attribute intent , which is the focus of this work. For example,  X  X bama age" for the intent of age ,  X  X he Museum of Modern Arts phone number" for the intent of phone number are attribute intents.
An ultimate goal of the attribute intent understanding is that as-sume we have a gigantic database of all entities and attributes in the world, map all possible search queries to the corresponding attributes. This goal shares similarities with other researches on query annotation [17, 22], in which they aim at annotating a query to a structured schema. Note that the query intents in these works are not necessarily attribute intents. However, these approaches ei-ther require a lot of labeled data, or rely on a highly developed and structured domain database. Most recently, unsupervised method does exist [11], yet it is limited in its ability to merge query pat-terns conveying same intent.

Not surprisingly, achieving the ultimate goal of attribute intent understanding automatically across many domains is very chal-lenging. In some tail domain doing this mapping is not even pos-sible because of the data sparsity. Thus in this work we aim at mapping the attribute intent at the template level, where individual queries are aggregated into query intent templates, partly reduc-ing the data sparsity issue. For example, for the attribute  X  X ge" in
W e have manually labeled 500 randomly selected queries that have entity mentions. In which 244 (48.8%) queries mention the entity name only, 192 (38.0%) queries mention entity name and an attribute, and 64 (12.8%) queries have other intents. Person domain,  X  X Person] age" is a query intent template for the  X  X ge" intent, while  X  X bama age",  X  X om Cruise age" are individual queries conforming to this template. We refer to the query intent templates conveying same underlying intent as synonymous query intent templates . Table 1 shows two attribute intent templates as well as their synonymous templates. Specifically, in this work we seek to address the problem of identifying synonymous query intent templates for attribute intents. Successful identification of query in-tent templates to their corresponding attribute intents can provide benefits to several applications. First, it can potentially improve all exiting query intent annotation approaches by merging the synony-mous templates. Second, in the application of instant answers, it enlarges the questions that a system can answer. Third, by know-ing synonymous query intent templates, a search engine can rec-ommend more queries based on rules between query templates for long-tailed queries [29].

T o the best of our knowledge, there are no existing methods that directly address the synonymous query templates identifica-tion problem. There might be several indirect solutions though. For example, the above mentioned query annotation methods could be used to solve the problem. However, due to the structure and semantic difference between queries and query templates, these methods might not be feasible. We could also apply approaches for question paraphrasing in the Question and Answer research com-munity [30, 31]. However, [30] focuses on finding synonymous phrases on the question level, not on the template level. And [31] aims at identifying alternative expression of the answers, while in this paper we focus on alternative ways people query (ask) attribute intents. Thus these previous approaches can not be directly applied to the problem we are addressing.

In addition, we can treat it as a string synonym problem, which previous researches have addressed with several similarity features such as distributional similarity [18, 19], coclick similarity [10, 9] etc . However, from Table 1 we can see that sometimes the synony-mous templates may be different from the canonical template (the attribute intent template itself) on small lexical variation and word orders. Yet sometimes they are very different on lexicon. There-fore, we can imagine that only relying on single similarity such as string similarity, it is very hard to discover templates that are syn-onymous to the canonical template in semantic level.

In fact, the synonymous query intent templates share similari-ties among several independent, sometime complementary signals. For example, other than the lexicon similarity, they would mani-fest high similarity on the distribution of entities that occur in the templates. In addition, people tend to click on same set of docu-ments when they issue queries conforming to semantic equivalent templates. For instance, it X  X  common that users who issue  X  X bama age" and  X  X ow old is Obama" will both land on the wikipedia page of Barack Obama. In this work we attempt to identify synony-mous query intent templates by integrating multiple information sources. Among multiple information sources, some are more im-portant in determining synonym relations than others. Moreover, the relative importance of these sources also depends on the do-main: a feature that is crucial in the Person domain might be only marginal in the Location domain. Therefore automatic determina-tion of the weights of different information sources is critical. Here we propose to automatically learn these weights via a novel cluster-ing procedure with multiple kernel functions that cluster candidate query intent templates to the canonical templates and effectively determine the appropriate weights of the signals.

Other than the choice of information sources, there are differ-ent options for the mode of learning. We could identify the syn-onymous templates for a single canonical query intent template at a time, or learn the synonymous templates for all canonical tem-plates jointly. Handling single template at a time might lead to the difficulty of differentiating synonymous templates of close re-lated ones. For example, for template  X  X Person] height",  X  X Person] weight" could be identified as synonym mistakenly because they share a lot of coclicks. However if we learn synonymous templates from those two values jointly, this error could be corrected eas-ily because of the awareness of each other. Joint learning of syn-onymous templates also provides the must-link and can-not-link constraints among canonical templates, which could effectively im-prove the results.

In this work we address the problem of finding synonymous query intent templates for a set of canonical query intent (attribute intent) templates jointly. We have proposed a clustering model with multiple kernel functions to take advantage of multiple heteroge-neous information sources. Qualitative and quantitative results on attribute intent templates from a large knowledge demonstrate that our method can identify synonymous query intent templates accu-rately.
Query understanding has long been an important topic of infor-mation retrieval. In terms of query structural analysis, there are early and recent research attempts to do query segmentation [7, 14], part-of-speech tagging [5], shallow linguistic structure parsing [6] etc . In this work we are interested in entity related queries, where named entity recognition inside a query is an important task that has been addressed by previous works [13, 12]. These works are focused on entities, while the focus of this work is on the attributes, especially the attribute intent. There are recent attempts for entity attribute identification based on query logs [32, 33]; and the results from these works could potentially enlarge the attributes on which we are looking for synonymous query intent templates.

Finding synonymous query intent templates for attribute intent is an important task toward the ultimate goal of mapping all entity queries to the associated attribute intents. This goal shares similar-ity with the query annotation tasks, which try to annotate a query to some structured schema based on the query intent. There has been research attempts to find groups of queries sharing same in-tents [28, 21], however in these works queries are not explicitly mapped to structured schema. To do explicit schema discovery from queries, people have been using a grammar-based approach, in which domain specific rules are defined and queries are matched to these predefined rules. However these rules are domain depen-dent, which preclude them from applying to a large number of do-mains. Also, defining such rules manually takes a lot of effort. To reduce the cost of defining rules, supervised and semi-supervised statistical models are developed [17]. But a fair amount of labeled data is still required in these approaches. There are recent attempts to discover a query X  X  schema information in an unsupervised way. For example, Sarkas et al. [22] propose an unsupervised method to annotate queries with a highly developed and structured domain database. Unfortunately, these resources may not be available to domains where data is sparse. To overcome this limitation, Che-ung et al. propose using sequence clustering with a large open source knowledge graph for query schema annotation [11]. How-ever, a major limitation of this work is that it is unable to merge query templates conveying same underlying intent. The main dif-ference of this paper and these query annotation works is that we focus on mapping synonymous templates to canonical intent tem-plate, while these works focus on mapping queries to templates. Thus the previous works in this line is orthogonal to our work. The successful identification of synonymous templates can potentially improve the query annotation quality by merging the synonymous query templates. Besides, synonymous templates can be also used to improve query recommendation for long-tail queries [29].
The problem setup in this paper is similar to finding question paraphrases in Question and Answer [31, 30]. [31] aims at find-ing alternative expression of the answers, thus their features are majorly from the documents. However in this paper we focus on alternative templates people query (ask) attribute intents, not the answers. In addition, [30] focuses on finding synonymous phrases on the question level, not on the template level. So it is not obvious whether the method in [30] can be applied to our problem setup. What X  X  more, [30] uses supervised approach to identify question paraphrase pairs, while we are more interested in unsupervised methods that can scale to large set of entities and attributes.
Researchers have also employed several similarity metrics to other tasks such as finding string synonyms from web data. Such simi-larities include distributional similarity [18, 19], coclick similar-ity [10, 9], point wise mutual information [25], and co-occurrence statistics [4]. Differing from these works, our work introduces novel similarity metrics like entity distribution similarity and query trend similarity that are tailored for finding synonymous query in-tent templates.

In our approach we combine the metrics with weights learn the weights automatically in an unsupervised manner. In this sense our work is also related to the previous works on semi-supervised metric learning [27, 23, 3]. We differ from these works in that our metric learning approach is embedded in a clustering framework.
In this work, we seek to identify synonymous query intent tem-plates from a set of entity attribute intents of a domain. The precise representation of the entity attribute intent could be difficult, here we start from using the attribute names as the representation of an entity attribute intent. And the definition of a domain can be flex-ible, we only assume that a domain contain a set of homogeneous entities with attribute values. Without loss of generality, we fo-cus on entity attributes from a large open source knowledge graph: FreeBase where a large amount of the real world entities and at-tributes are covered. In fact, our technique does not depend on a specific data source. For example, it is not hard to adapt to other knowledge graphs such as Wikipedia.

Formally, given a set of M semantically distinct entity attribute intent templates V = { v 1 , v 2 , ..., v M } for a domain, where each template v  X  V is represented by its canonical form (here we as-sume the attribute name), such as  X  X Person] age" for intent  X  X inding age of a person", and  X  X Movie] cast" for the intent  X  X inding cast of a movie". From a set of N candidate synonymous templates X { x 1 , . . . , x N } , we define an oracle mapping F : X  X  V  X  X  which assigns each candidate template x to its unique canonical synonym query intent template v , or if x is not a synonym of any value in V , to the special background template v 0 . Note that we as-sume each candidate query template maps to at most one canonical template. Now, we can define the synonymous query intent tem-plates identification problem as follows: Definition 1 : For each canonical attribute intent templates v find the subset X v = { x  X  X |F ( x ) = v } , representing the set of synonymous query intent templates for value v .

For example, for the attribute intent template  X  X Person] age", its synonymous templates include  X  X ow old is [Person] X  and  X  X ge of [Person]", but not include templates like  X  X Person] birthday" or  X  X ow high is [Person]" though they are related templates.
Here we propose to identify synonymous query intent templates by a clustering model that has multiple similarity functions. In this model, query templates X = { x 1 , x 2 , ..., x N } are modeled as data points. Points are connected to each other by similarity functions f (also called kernels). Data points form clusters such that points in the same cluster are considered synonyms. The canonical query (attribute) intent templates v 1 , v 2 , ..., v M also belong to have hard assignments to their respective clusters.

We tackle the problem with a clustering framework in order to take advantage of modeling a set of canonical templates jointly. We further consider transitivity and compactness in our model, which means we choose a cluster assignment by considering a committee of points in a cluster rather than a single medoid. In addition, pre-vious researches measure similarity with single or only a few sim-ilarity features, while we want to support arbitrary features. Thus, manual tuning of parameters is not sufficient. Though there are ex-isting works in metric learning with supervision, we are also inter-ested in unsupervised techniques. Hence, we employ the regular-ized metric learning approach to guide our parameter optimization. In this section we first describe the center initialization and how to obtain candidate templates. After that, we define the similarity ker-nel functions according to different information sources. Then we introduce a basic clustering model for finding synonymous tem-plates. Further, by addressing its limitations, we propose several extensions that lead to the refined model. To facilitate the readabil-ity of the paper, we summarize the major notations in Table 2.
Cluster center initialization includes two major steps: (1) allo-cate initial values to the centers; (2) choose the number of clusters. For step 1, we first assign each attribute names as the initial value of the cluster centers. This approach is generally effective; however, there is a limitation when the attribute names are long or written in a way that is uncommon in the query log where we look for can-didates. For example, in the Person domain, the attribute names  X  X ate of the birth" and  X  X ountry of nationality" are written in such forms. We employ an automatic reformulation method to handle the initial center allocations as follows: first, we check whether a canonical attribute name is above a threshold of query counts in the query log. If not, we use a state-of-the-art query log-based string synonym finder [9] to obtain a synonym that is most popular in the query log, and then replace it with this string synonym as the ini-tial cluster center. For instance, in the above example, after proper reformulation, the initial value of these two centers are  X  X Person] date of birth" and  X  X Person] nationality". Finally, if we couldn X  X  find any valid synonyms for an attribute name, we drop this cluster from the cluster list.

In step 2, we can set the number of clusters as the number of valid canonical attribute intent templates after reformulation in step 1. But we can do better by adding more clusters due to the reasons as follows: we observe that usually the current knowledge graph does not cover all attribute intents in a domain, and some of these uncovered intents will affect the clustering results. For example, for intent templates  X  X Person] age" and  X  X Person] height", we find that intents  X  X Person] wiki" and  X  X Person] biography" are ranked high in both clusters, which is not desirable. However, they are not covered by attribute names in Person domain in FreeBase, pre-cluding us from assigning them as canonical templates. Hence, the final results can be improved by adding a few auxiliary clusters ini-tialized by these popular intent templates. We identify these intent templates by two criteria: (1) they are most popular intents among all intents about the entities in a given domain; (2) they are not string synonyms of the valid canonical templates after processing in step 1. Furthermore, in addition to the auxiliary clusters, we add a background cluster to attract random templates. And the back-ground cluster is initialized by a set of random candidate templates whose generation process is described in the following section.
After these steps, finally we obtain K + 1 clusters (the back-ground cluster being the 0 th cluster) in total, among which M ( M  X   X  M ) clusters correspond to the valid canonical attribute in-tent templates. There are also K  X  M  X  auxiliary clusters, and 1 background cluster.
Our clustering framework assumes we have a set of candidate query intent templates { x 1 , x 2 , ..., x N } as input. Here we describe how we obtain them efficiently. The search space of potential can-didate templates is huge: any template in the query log that con-tains the target entities could potentially be a synonymous template. Therefore reducing the template search space is critical. Specifi-cally, for a set of valid attribute intent templates V = { we identify candidate templates as follows: 1. For each v  X  V , we first get the set of entities under intent templates v from FreeBase. And for each of these entities, we instantiate the template to a query by the entity mention. For example,  X  X Person] age" can be instantiated into  X  X bama age" or  X  X om Cruise age". Then, for each of instantiated query, we obtain a set of most related queries by a query similarity function. For instance,  X  X ow old is Obama",  X  X ow old is Tom Cruise" are within the most related queries. By iteration all entities, we can get a set of related queries for v . 2. From the set of most related queries, we only keep queries that contain at least one entity in the entity set of v . Then, we generate candidate templates from such queries. In the above ex-ample, a candidate template  X  X ow old is [Person]" is generated accordingly. 3. In order to cover most of the candidates, other than a similar-ity function, we also employ other similarities to select template candidates. Particularly, for each similarity, we keep only top 50 candidates, and merge them and remove duplicates to form the set of candidate templates.
Before diving into the similarity kernel definitions we briefly de-scribe the knowledge graph we use to facilitate the query intent template initialization and kernel function computation. Freebase is a large knowledge graph that consists of over 20 million enti-ties across over 10,000 concepts. There are multiple entities under a concept such as  X  X eople" or  X  X ocation", and each entity is con-sist of multiple attributes. We use the attribute name of the enti-ties under a concept to nominate the query intent template, such as  X  X People] age" or  X  X hone number of [Institution]". In addition, we utilize the entities under a concept to compute the similarity kernel functions between two query intent templates.
Defining proper similarity measures between data points is an essential part of a clustering framework. In our problem setup, we can measure the similarity between two query intent templates in different aspects. For example, two similar templates may share similar lexicon, with only minor difference in word order. Like-wise, two templates are similar if people click on same set of docu-ments after issuing queries conforming to these templates. Multiple heterogeneous information sources, in the forms of query log, an-chor text, query document pairs, temporal and spatial query trends, can be used to calculate the similarity between query intent tem-plates. In this section we describe 4 similarity functions, which are also called similarity kernels, in detail. Our clustering framework is not limited to these kernels; in fact our framework can accom-modate arbitrary number of similarity kernels, whose weights are automatically tuned. 1. Entity distribution similarity . This similarity measures the entity frequencies under different query intent templates. Our hy-pothesis is that the distribution of entities for which user query about a particular intent should be similar among synonymous templates of that intent, while should be very different from tem-plates conveying different intents. Fig. 1 illustrates an example of entity distribution similarity. We can see from Fig. 1 that query templates that follow the same underlying intent manifest similar query counts correlation across entities (color comparison in the same row). On the other hand, templates from different intents show very different entity distribution (row comparison). For-mally, for a query intent template x i , let its entity distribution be: where  X  t , 1  X  t  X  n e is the normalized query counts of a query intent template instantiated with an entity. And n e is the num-ber of entities in consideration. In the example shown in Fig. 1,  X  t could be the query counts of  X  X bama age", normalized by the total query counts of queries containing  X  X bama". And the simi-larity between templates x i , x j is the cosine similarity of  X  2. Coclick similarity. This similarity measures how similar the set of documents users click on when they issue queries conform-ing to the query intent templates in consideration. We refer to such queries as proxy queries. A proxy query is generated by injecting an entity into the intent template. For example,  X  X he
Museum of Modern Art phone number" is a proxy query for tem-plate  X  X Institution] phone number". Given an intent template x let the set of proxy queries of x i be Q i = { q i 1 , q i each query q i l , assume that the users have clicks (  X  0 ) on a set of documents represented by vector:  X  l = {  X  l 1 ,  X  l 2 , ...,  X  n d is the total number of documents. And let the accumulation of these clicks be:
Under this assumption, for templates x i and x j , we define their coclick similarity as the cosine similarity of  X  i and  X  j 3. Pseudo-document similarity. This similarity is related to the coclick similarity, and it is a more robust measure on sparse data such as clicked documents. This similarity has been successfully applied to finding entity synonyms [9]. For a document D , the document title and body are not always easy to get; and they are usually long, thus might not be the best representation of D . In-stead, the queries which have user clicks on D (referring queries) provide a succinct representation of D . We define the document augmented by all referring queries as the pseudo-document of D : P
D . We then define the one-way similarity of two proxy queries given the pseudo-document. For proxy queries q a , q b , let the set of documents users click after issuing q b . The one-way pseudo-document similarity from q a to q b is:
That is, the percentage of pseudo-documents that contain query q a . Likewise, the symmetric, two-way pseudo-document similar-ity between q a and q b is:
Finally , for two query intent templates x i , x j , and given a set of entities E under the templates, we generate proxy queries q q e for x i and x j according to e document similarity between x i and x j as the average pseudo-document similarity of their corresponding proxy queries: 4. Query trend similarity. Query templates with same intent should share similar query volume patterns over time. To illus-trate this, we show 4 queries on GoogleTrend to display their query volumes from the year of 2005 to 2011 in Fig. 2. These 4 queries are of 2 distinct intents, one is  X  X Location] map", the other is  X  X Location] time zone". The temporal trends of these queries demonstrate that query patterns from same underlying in-tents are more correlated than from different intents. To measure it quantitatively, we collect a large query log with temporal query volumes. This query trend log contains about 80 millions unique queries. For each query, we record the monthly query volume from June 2008 to June 2011. Given a query q , let its monthly query volumes be  X  = {  X  1 ,  X  2 , ...,  X  n t } , where n number of months in the records. Then for two proxy queries, we define their query trend similarity as the cosine similarity of  X  and  X  j :
And for two query intent templates x i , x j , and given a set of en-tities E under the templates, we generate proxy queries q q e for x i and x j according to e . Finally the query trend similar-ity between x i and x j is the average query trend similarity of the proxy queries:
The similarity kernels defined above have these properties: (1) symmetric; (2) f t ( x i , x j )  X  [0 , 1] , for 1  X  t  X  T . We seek to integrate multiple kernels into a new function that the weights of individual kernel can be automatically learned. Since our model re-sembles the K-medoids clustering [15], here we follow the nomen-clature in the clustering literature and define the distance between query intent templates x i and x j as a convex combination of the similarity kernels: where f t ( x i , x j )  X  [0 , 1] is the similarity kernel of x culated based on evidence from information source t  X  X  1 , ..., T tween x i and x j . And w t are the weights needed to be learned, following non-negative constraints: In the following, we describe our clustering model that identifies synonymous query intent templates and learns the appropriate ker-nel weights iteratively.
We first define an objective function for our model and refine it by overcoming its limitations. Overall, we aim at minimizing the following objective function: subject to:
The above objective function minimizes the sum of with-cluster dispersions. In this formulation, the first term is the overall within-cluster distances of the normal clusters, and the second term is the within-cluster distances in the background cluster. Such formula-tion is to make the resulting clusters compact. Note that in our model there is no need to represent data points with explicit feature vectors or coordinates, instead, we only require that d ( x . The notations of variables are listed below: The objective function of the initial model is similar to the for-mulation of K-medoids[15]. The advantage of employing the K-medoids framework rather than K-means is that we only need to define distance functions (kernels) between data points, while ex-plicit feature vectors are not needed. This is desirable because fea-ture vectors are sometime hard to represent explicitly. In addition, there are important differences between our initial model and the K-medoids model: firstly, the first K medoids in our model are fixed to the canonical templates, assuming they are best represen-tatives of these clusters. This also implies that there is no need to update the medoids. Secondly, in our model the distance between points is a weighted kernel function, which is very different from the standard K-medoids model. Such weights measure the relative contribution of the kernels, and they are estimated in an unsuper-vised manner. Thirdly, in our model we add a background cluster in order to attract the random points. Here we assume that the dis-tance of any point to the background cluster is a constant.
Although this initial model can partition the data points into clus-ters efficiently, it suffers from the following limitations: (1) Using a single fixed representative for a cluster may be problematic. First, the canonical template is not always the most representative one. It may have idiosyncrasies that are not shared by other members of the cluster. Second, because the similarity features are noisy, if we only compare a candidate against the canonical template, a noisy feature may bias it towards an incorrect cluster. (2) Manu-ally setting the constant  X  is very difficult. Nominating a good  X  at the beginning is hard, and further, since the distance between data points depends on the weights, it makes it even harder to choose the appropriate  X  inside the algorithm. Therefore an automatic es-timation of this constant is necessary. (3) Not enough guidance for learning the kernel weights. The initial model doesn X  X  make use of the constraints in the forms of must-link and can-not link, to learn the optimal weights.
We propose to address Limitation 1 by introducing pseudo-medoids instead of fixed centers; and we address Limitation 2 by estimat-ing  X  with random points. In addition, we tackle Limitation 3 by adding constraints that regularize the value of kernel weights. Now we look for cluster assignments and kernel weights that minimize the new objective function: g 1 ( R, Z  X  , W ) (14) =  X  +  X  1 subject to: Eq . (13), where z  X  k is the pseudo-medoid, A is the subset of random points in the background cluster.  X  1  X  0 ,  X  are the weights for regularization terms. And This new formulation addresses all limitations of the initial model. First, limitation 1 can be addressed by having a flexible represen-tati ve or a small set of representatives for each cluster. However it X  X  not desirable to have flexible medoids since in our problem setup the canonical values are good representatives and it is more robust to include them into the medoids. Thus we propose to use a small subset of points, including the canonical value, to form a new pseudo-medoid z  X  k . This subset is viewed as a committee that determines the distance from a point to the cluster. By carefully choosing pseudo-medoid members, it will reduce the risk of having unpopular canonical values and noisy features, making the clusters more compact. In fact a similar idea of clustering with committees of points has been successfully applied to the document cluster-ing problem [20]. As the optimal solution for K-medoids cluster is NP-hard, we can only find the local optimum of medoids by algo-rithms such as PAM [16]. However, this algorithm takes O ( m time to update a medoid where m is the number of points in a cluster, which is inefficient. Also it doesn X  X  take the advantage of the canonical templates. In our new formulation, we form the new pseudo-medoid by including the top L  X  1 most similar templates to the canonical template as well as the canonical template itself. The advantage of this nearest neighbors approach is that it forms a compact pseudo-medoid around the canonical value efficiently, which takes only O ( m ) time.

Second, by assuming random points follow similar properties as the background, we address the limitation 2 by to randomly select-ing  X  proportion of points to form the set A from the background cluster. Thus  X  can be estimated by taking the average of the dis-tance to this random subset. Results show that the final synonyms are stable with respect to different setting of  X  .

Third, we propose to guide the search of optimal kernel weights in a regularization framework. The first regularization term is to prevent the weights from becoming too large. The second reg-ularization term acts as a must-link constraint in which each set S contains templates that should be close to each other. In this work we include templates of each pseudo-medoid z  X  k to S k , which tries to make the pseudo-medoid more compact. On the contrary, the third regularization term acts as a can-not-link constraint in which U k contains templates that should be far away from each other. Ac-tually for each cluster, the canonical intent template should be away from the other clusters. In that way, we include K pairs of points in each U k , resulting in K  X  ( K  X  1) 2 such pairs in total. In the refined model there are three set of unknown variables: R , Z  X  and W , which are dependent on each other. There is no exact solution to solve all of them at the same time. Instead we solve this optimization problem by iteratively solving the following minimization problem: 1. Fix Z  X  =  X  Z  X  and W =  X  W ; find the best R that minimizes 2. Fix W =  X  W and R =  X  R ; find the best medoids Z  X  that 3. Fix Z  X  =  X  Z  X  and R =  X  R ; solve the best parameters W that Sub-problem 1 can be solved by: For sub-problem 2 , we update the pseudo-medoids of first K clus-ters by including up to the top L  X  1 most similar values to the canonical value as well as the canonical template itself: z For the background cluster, there is no need to calculate the updated medoid. For sub-problem 3 , we follow the basic ideas for solving the regularized metric learning problem [23]. Note that after fixing R and Z , solving Eq . (14) becomes a Semi-Definite Programming (SDP) problem. To see this, we rewrite Eq . (14) as: g 1 ( R, Z  X  , W ) (20) =  X  +  X  1 subject to: No w the objective function is linear in both y and W . It has two convex constraints: the first is a second order cone constraint, while the second is a positive semi-definite constraint. There exist effi-cient solutions that guarantee to solve this problem in a polynomial time. In this work we use the method implemented in SeDuMi [24] to solve W efficiently.
The optimal allocation of points to clusters and the best kernel weights can be found by iteratively solving the above sub-problems. These iterative updates are summarized in Algorithm 1 . Algorithm
Algorithm 1: Clustering with Multiple Kernels input : A set of canonical attribute values { v 1 , v 2 , ...v output : Optimal membership matrix R , pseudo-medoids Z  X  1 Init: init Z  X  0 = { v 1 , v 2 , ..., v k } and choose uniform 2 f or q  X  0 to q max do 3 Let  X  Z  X  = Z  X  q and  X  W = W q , find the best R q +1 in 4 Let  X  R = R q +1 and  X  W = W q , update Z  X  q +1 in 5 Let  X  R = R q +1 and  X  Z  X  = Z  X  q +1 , find the best W 1 is guaranteed to converge to a local minimum after several itera-tions. The time complexity of Algorithm 1 is O ( P  X  ( N  X  1)  X  T + T 3 )) , where P is the number of iterations, N is the num-ber of candidate templates, L is the number of nearest neighbors, K + 1 is the number of clusters, and T is the number of similarity kernels. The SDP solver for W takes T 3 time complexity.
To test the effectiveness of our proposed model, in this section we have carried out a set of experiments on datasets across mul-tiple domains from a large knowledge graph. We first present the qualitative results obtained by all methods in comparison. Then we make direct comparison of our model to the baselines quanti-tatively. After that we investigate the model performance at top results. Finally we analyze the model sensitivity subject to different parameter settings.
For evaluation purpose, we have collected a large set of canoni-cal templates from Freebase. These templates are formed by com-bining the entity type and attribute names, such as  X  X Person] place of birth",  X  X Educational Institution] phone number". They are col-lected from three major domains: People, Location, and Organiza-tion, which have many sub-relations. We have selected 113 canoni-cal templates from People domain, 102 from Location domain, and 93 from Organization domain respectively. Because it X  X  very diffi-cult to come up with all true synonymous templates of the selected canonical templates, we employ the TREC style pooling strategy to obtain the initial pool of candidate ground-truths. That is, for each canonical template, we use all competing methods to produce up to 50 best synonyms. And then these results are pooled, producing another list of top 50 templates by a simple ensemble method. Fi-nally domain experts are asked to label these candidate templates into true synonyms or not (1/0 labeling), resulting in 15450 labels in total. All of the labeled data as well as our experiment results will be freely available to the public.

We also describe the data sources from which the similarity func-tions are computed. Firstly, all of the similarity kernels are com-puted on a large query log and a query-click log from a major com-mercial search engine. There are more than 100 millions unique queries in the query log and about 600 millions query-clicked doc-ument pairs in the query-click log. Part of the queries has monthly query volume records from June 2008 to June 2011, which are used to compute the query trend similarity. All these query and click logs are preprocessed and indexed in a compression trie data structure so that the similarities can be computed efficiently.
To the best of our knowledge, there is no existing work directly addressing the problem of finding synonymous query intent tem-plates for attribute intents. Thus we choose a set of baselines that are based on individual features. We also add another baseline by string synonym induction. 1. Individual feature . Individual feature can identify synony-mous query intent templates effectively. Here we include base-lines using individual feature we defined in section 4.4. Synony-mous templates are identified by single input canonical template at a time. 2. Clustering with Fixed Weights . In order to reveal the effec-tiveness of the kernel weights learning in our model, we add a baseline that uses the same clustering model, with fixed and equal kernel weights (0.25). 3. String Synonym Induction . Synonymous query templates can be also identified by inducing the string synonyms of proxy queries. Specifically, for a canonical query intent template, we first obtain a set of proxy queries by instantiating the associated entities. Next, string synonyms of these proxy queries are found by our in-house string synonym finder. After that, the resulting string synonyms are induced back to query templates. Finally synonymous templates are found by keeping the most popular in-duced templates.
We evaluate our system using metrics of Mean Average Precision (MAP) and Precision @  X  K , which are based on the precision and recall measures. Specifically, for an canonical query intent tem-plate, v  X  V , O ( v ) = { o 1 , o 2 , ..., o K v } is the set of synonym outputs in ranked order (decreasing). Let S ( v ) denote the set of true synonymous templates annotated by the human experts for v . Precision for a particular input template v is computed as: where I p ( o, v ) = 1 if o  X  S ( v ) , and 0 otherwise. When eval-uating methods with ranked synonyms, MAP is a good measure to distinguish the approaches across different recall levels. MAP is the mean of the average precision for multiple templates. Sup-pose for canonical template v j , the set of true synonyms of v mous templates obtained by taking the top results until we reach true synonym s k , then Note that when a true synonymous template is not found in the ranked list, the corresponding precision in the above equation is set to 0. Besides MAP, we also use the Precision @  X  K measure to assess the quality of top ranked results down to position has practical significance.
The performance of our models will vary with respect to differ-ent parameter setting. Table 3 lists the optimal parameter setting we use to report results.

In order to demonstrate what the results really look like and re-veal the strength and weakness of the methods in comparison, we conduct a qualitative analysis in a concrete example. Table 5 shows the results of an input template  X  X Person] place of birth". Due to space limitation, for individual features we only present the results of Pseudo-document Similarity and Query Trend Similarity, which represent a strong feature and a weak feature. Based on the exam-ple, we have the following observations: First, among all individ-ual features, the results computed by Pseudo-document Similarity is good. However there are noisy templates such as  X  X utobiography [Person]" and  X  X iki [Person]" which affect the results. On the other hand, the results obtained by Query Trend Similarity is poor; there are several related, but not true synonymous, templates at the top results. Second, although String Synonym Induction demonstrates effectiveness in producing good results, it is unable to identify other true synonyms like  X  X here was [Person] born", which might due to the limitation of its focus on finding string synonyms. Thirdly, results produced by Clustering with Fixed Weights are very good though it is still inferior to our clustering model that produces most clean results.
In this experiment we investigate the overall effectiveness of our clustering model. We present the results measured in Mean Av-erage Precision (MAP) from all three domains in Table 4. The results indicate that (1) among all individual features, the Pseudo-document Similarity is the most effective feature, achieving MAP of 0.588; while the weakest one is Query Trend Similarity, only getting MAP of 0.332. (2) finding synonymous templates by String Synonym Induction is effective, achieving intermediate performance. (3) learning synonymous query templates jointly clearly demon-strates advantages: it achieves a competitive MAP of 0.608 even by simply fixing the weights to be all equal. And by learning the weight with regularization, our clustering model achieves 0.670 in MAP, which is significantly better than all other methods. We have conducted the statistical significance test (T-Test) and it is shown that there is statistically significant difference between our model and two baselines (Clustering with Fixed Weights and String Syn-onym Induction) at confidence level p = 0 . 01 . The quantitative results in Table 4 are also consistent with our findings in the quali-tative analysis.

Previous experiment measures the average precision across all levels of recall. In this experiment we zoom in the results at top ranked positions since high precision at top positions is highly de-manded in several applications. We summarize the Precision @ results at Fig. 3. Results in Fig. 3 clearly show the superior per-formance of our model at top positions. For example, our model achieves precision of 0.899 at position 1 and 0.778 at position 2, which is much better than the baselines. These results are consis-tent with the MAP results reported in previous experiment, sug-gesting that methods that perform well in top ranked positions are generally superior to the methods that do poorly in top positions.
Further, we break down the results by domains to investigate how well our model does in different domains. The breakdown results are shown in Fig. 4. We have two observations on the breakdown results: First, baselines powered by individual features achieve con-sistent results across domains, suggesting that the features we used are stable across different categories. Second, our model achieves best performance in all three domains, indicating that our clustering framework with multiple kernels may be applied a large number of domains without relying on domain specific labels that are expen-sive to collect in large scale.

Our proposed model is able to learn the weights of similarity kernels. In this experiment we look into the learnt weights to see whether they reflect the relative importance of the similarity ker-nels. For this purpose, we have conducted the ablation test, in which we remove one similarity kernel at a time and run the model. We also report the weights learnt without removing any kernels. Results on a subset of data in each domain are shown in Table 6. These results indicate that Pseudo-document Similarity seems to play relatively higher importance than other kernels. For example, in all three domains, it carries the highest weights; and the F1 mea-sures drop to the lowest when removing this kernel (the lowest F1 is marked in bold). On the contrary, the Query Trend Similarity seems to play a marginal role in the model, reflected by the low weights in all domains. And removing Query Trend Similarity has a negligible effect on the MAP.

Furthermore, we discuss the sensitivity of our model X  X  perfor-mance according to the change of parameters. We focus on two parameters: one is L  X  1 , the number of nearest neighbors; the other is  X  , the proportion of random points drawn from the back-ground. According to Fig. 5, the Mean Average Precision of our model does change with respect to different L  X  1 . The MAP in-creases when L  X  1 increases with a small step, while it decreases when the L  X  1 becomes relatively big. This suggests that while the pseudo-medoid is effective, if it becomes too large, the inclu-sion of noisy data will hurt the result. Thus, a small size of L like 1 or 2, is a good choice. On the other hand, Fig. 6 indicates that results are most stable with different values of  X  . It suggests that using a small  X  is reliable, which makes our clustering model running faster.

In this work we address the problem of finding synonymous query intent templates for a set of canonical query intent templates simultaneously. To solve this problem, we propose a clustering model that enables the integration of multiple heterogeneous in-formation sources. The weights of these signals are tuned by a regularized metric learning strategy. We have conducted extensive experiments on a large set of attribute intent templates from Free-Base. Qualitative and quantitative results both demonstrate that the performance of our model is superior to the baselines. There are some interesting problems remained as future works. For example, given a small amount of labeled data, how to integrate the labeled data into our model to further improve the accuracy is an interest-ing problem to investigate. Another interesting problem is how to take advantage of the synonymous query templates to improve the query annotation quality.
