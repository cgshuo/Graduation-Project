 Srinivasan Sengamedu  X  Matching product titles from different data feeds that re-fer to the same underlying product entity is a key problem in online shopping. This matching problem is challenging because titles across the feeds have diverse representations with some missing important keywords like brand and oth-ers containing extraneous keywords related to product spec-ifications. In this paper, we propose a novel unsupervised matching algorithm that leverages web search engines to (1) enrich product titles by adding important missing tokens that occur frequently in search results, and (2) compute im-portance scores for tokens based on their ability to retrieve other (enriched title) tokens in search results. Our matching scheme calculates the Cosine similarity between enriched ti-tle pairs with tokens weighted by their importance scores. We propose an optimization that exploits the templatized structure of product titles to reduce the number of search queries. In experiments with real-life shopping datasets, we found that our matching algorithm has superior F1 scores compared to IDF-based cosine similarity.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms Web-based enrichment, Entity resolution  X  Work done while at Yahoo Labs, Bangalore
Consumers are increasingly turning to online shopping sites (e.g., shopping.yahoo.com, shopping.bing.com) to re-search products prior to making buying decisions. These sites leverage data from multiple sources that include aggre-gator sites (e.g., PriceGrabber, CNET), merchant sites (e.g., buy.com, amazon.com) containing sales offers, reviews sites (e.g., epinions.com, newegg.com) containing reviews and rat-ings information, and auction sites (e.g., eBay, Amazon mar-ketplace). The sites consolidate the specifications, prices, ratings, and reviews information for each product present in the various source data feeds, and present a unified view of each product to the user. Thus, the sites allow users to compare prices offered by different vendors for a product or browse through reviews for a product from different web sites.

A key challenge to providing a unified product view is matching records for the same product from different data feeds. This record matching problem has been extensively studied in the literature under different names like record linkage [13], duplicate detection [12, 20], entity resolution [2, 1], and merge/purge [14]. Much of this previous work has focused on matching records with multiple overlapping attributes. The general approach is to first compute sim-ilarity scores for each attribute using traditional similarity metrics like Jaccard similarity, Cosine similarity, edit dis-tance, etc. [17, 12], and then combine these attribute-level similarity scores to derive record-level matching scores us-ing unsupervised and supervised techniques. However, as discussed below, prior approaches may not work well in our product record matching scenario.

In our product setting, records in the different data feeds may have heterogeneous schemas and thus contain diverse sets of attribute values. For example, sales offer feeds from merchants may contain information about prices but not re-views, while a feed from a blogging or a product forum site may contain ratings and reviews information but not prices. Furthermore, even if these attributes are present, their val-ues for the same product may vary widely across feeds mak-ing them unreliable to use for matching. This is because dif-ferent vendors may price the same product very differently; similarly, product reviews across feeds may be written by di-verse users with disparate viewpoints and writing styles. In the absence of universally agreed upon unique product iden-tifiers between the various information providers, the only attribute that uniquely identifies a product and that is con-sistently present in all the feeds is product title . So in this paper, we rely on product titles for matching records in the different data feeds.

A product title is a short unstructured textual descrip-tion that uniquely identifies a product. Previous work has used similarity metrics like Jaccard similarity, Cosine sim-ilarity, edit distance, etc. for determining the similarity between string-valued attributes like person names or ad-dresses. However, different feeds may use diverse product title representations for the same product. Consequently, traditional string similarity metrics may not work well for matching product titles.

Consider the 3 product title pairs from product aggrega-tors PriceGrabber and CNET in rows (a)-(c) of Table 1. The pair of titles in row (a) are different representations of the same camera product with model number  X  X 200 X . The brand name  X  X ikon X  is missing in Title 1 while Title 2 does not con-tain relevant descriptive keywords like  X  X igital slr camera X  and other product specifications. Even though the two ti-tles correspond to the same product, the Jaccard similarity between their token sets (using white space as delimiter) is only 1 22 = 0 . 045. In contrast, the pair of titles in row (b) cor-respond to different camera models but have a much higher Jaccard similarity of 0.125. Now, based on the title pairs in rows (a) and (b), it may be tempting to declare two titles as matching if they have identical model numbers. However, besides the obvious difficulty of identifying a wide range of model number formats within titles, this strategy will not work in many cases. For instance, the two titles in row (c) have the same model number but they represent different products. Specifically, Title 2 corresponds to a camera while Title 1 refers to its accessory  X  a camera battery charger.
Clearly, traditional similarity metrics like Jaccard simi-larity fare very poorly at the task of detecting matching product titles  X  the first matching title pair in Table 1 has a much lower similarity score compared to the other two non-matching pairs. The problem with simple Jaccard sim-ilarity is that it treats all tokens equally. However, as we saw earlier, tokens like model number are more important and thus should be assigned a higher weight. A popular weight assignment method in the IR literature [17] is In-verse Document Frequency (IDF)  X  it assigns each token w a weight of I w = log N N of records in the feeds and N w is the number of records that contain token w . The Cosine similarity metric (with IDF token weights) between a pair t,t 0 of titles is then larity scores for the title pairs in the final column of Table 1 (the IDF scores are computed over a corpus of 30M product titles obtained from PriceGrabber). As can be seen, taking IDF weights into account, the Cosine similarity score of the matching title pair in row (a) increases but is still much be-low the similarity scores for non-matching titles in rows (b) and (c).
 One of the main reasons for the poor performance of the Cosine similarity metric is that product titles for the same entity across feeds have fairly diverse representations. Some titles could be missing important tokens like brand (e.g.,  X  X ikon X  in Title 1 of row (a)), while others may contain ex-traneous tokens corresponding to product specifications that are not critical for identifying the product (e.g., Title 1 in row (a)). This hurts the similarity score of the matching title pair in row (a). Furthermore, in some instances, IDF weights do not accurately capture the importance of tokens. In Table 2, we show the IDF weights (in parenthesis) as-signed to tokens belonging to the titles in Table 1.
As can be seen, in Title 1 of row (a), several extraneous to-kens like  X 3872 X  and  X 2592 X  are assigned higher weights than the model number  X  X 200 X . Similarly, in Title 1 of row (c), important tokens like  X  X harger X ,  X 2800mah X  and  X  X echarge-able X  that describe the battery charger accessory are as-signed low weights compared to the model number  X  X e140 X . A shortcoming of IDF is that it assigns a single weight to each token proportional to the inverse of its global frequency in the feeds independent of the context. Essentially, IDF does not take into account the relevance of a token to its product title context when computing its weight.

To overcome the above-mentioned challenges associated with using traditional similarity metrics to match product titles, we leverage the web. Our approach to matching prod-uct titles involves three key steps: (1) Enrich each product title by filling in missing tokens that frequently occur in the broader context of the product title, (2) Compute an im-portance score for each token in the enriched product title based on its power to identify the underlying product, and (3) Match enriched titles with tokens weighted by their im-portance scores. We use web search engines in the first two steps to determine an expanded context for each product ti-tle in order to enrich it, and to compute importance scores. Web search engines allow us to efficiently sift through bil-lions of pages to identify the most relevant web pages for a product.

Our main contributions can be summarized as follows: 1) We present an end-to-end system architecture for match-ing product titles with varying formats. The system is com-pletely unsupervised, and performs a sequence of tasks start-ing with enrichment of product titles and computation of to-ken weights, followed by matching the potentially co-referent enriched title pairs. 2) We propose a method for enriching product titles with (missing) keywords that appear frequently in the context defined by search engine results. 3) We assign an importance score to each token in the en-riched title based on its ability to retrieve other tokens (of enriched title) in search results. Our matching algorithm calculates the Cosine similarity between enriched title pairs with tokens weighted by their importance scores. 4) We propose an optimization for reducing the number of calls to the search engine. Our optimization predicts ap-proximate enrichments and importance scores for a product title based on past enrichments for similar-structured prod-uct titles. 5) In experiments with real-life shopping datasets, our match-ing algorithm achieves higher F1 scores compared to IDF-based Cosine similarity. Furthermore, our enrichment and importance score prediction optimizations reduce the num-ber of search queries significantly without adversely impact-ing matching accuracy. # Title 1 Title 2
The input to our matching system consists of a pair of data feeds D 1 ,D 2 , each containing product title records. Each record contains a variable length string that represents the title of a unique product. For a product title record t , we abuse notation a bit and use t to also denote the set of tokens (using space as delimiter) in t . Our system outputs matching product title pairs from the two data feeds that refer to the same underlying product entity.

As we saw earlier, product titles contained in data feeds are unstructured and have diverse formatting conventions  X  some may be missing important keywords while others may contain redundant keywords that are not required for iden-tifying the product. This makes the task of matching prod-uct title pairs extremely challenging. Our matching system consists of four main components: (1) Enrichment, (2) Im-portance score computation, (3) Blocking, and (4) Pairwise matching. Below, we describe the high-level functionality of each component, deferring the presentation of algorithmic details to the next section. (1) Enrichment. The enrichment module enriches product titles by adding relevant tokens like brand or product line that may be previously absent. It leverages web search en-gines to determine the broader context for a product title t , and then augments the title with high-frequency tokens in the context to get the enriched title E ( t ). (2) Importance score computation. Each token w belonging to an enriched title E ( t ) is assigned an importance score I ( w ) based on its power to identify the underlying prod-uct entity. This is computed based on the search results obtained by pairing each enriched title token w with the remaining tokens. I t ( w ) is proportional to the number of enriched title tokens retrieved in these results. (3) Blocking. The enriched feeds E ( D 1 ) ,E ( D 2 ) containing the enriched product titles with token importance scores are input to the blocking module. Comparing every pair of en-riched titles to see if they match is extremely inefficient es-pecially for large feeds containing hundreds of thousands of records. The blocking module uses prefix filtering [6] to prune away enriched title pairs that cannot possibly match. (4) Pairwise matching. A subset of the enriched title pairs E ( t ), E ( t 0 ) (returned by blocking) are compared, and output if they are found to match. More specifically, if the Cosine similarity between the titles with tokens weighted by their importance scores exceeds a pre-specified threshold, then ti-tles t and t 0 are declared to be a matching pair.

The enrichment and importance score computation mod-ules are the most expensive from a computational perspec-tive  X  as they repeatedly invoke the search engine to enrich the product titles and calculate token weights. In Section 4, we propose an optimization to reduce the overall number of web search queries for enrichment and importance score calculation. Our optimization predicts enrichments and im-portance scores for product titles based on previously com-puted enrichments and importance scores for product titles with similar structure/templates.
In the following subsections, we describe the algorithms at the core of the four components of our matching system.
The enrichment module is responsible for filling in missing relevant tokens in the product title. Our enrichment solution described in Algorithm 1 achieves this by first determining the expanded context for the product title, and then adding to the title frequently occurring tokens in the context.
Algorithm 1 uses the web to determine the broader con-text for an entity given its product title. The web is a vast repository of documents containing information on virtually every possible entity or topic, from the very esoteric to the Algorithm 1 Enrich Input: Product title t , support threshold  X  ; Output: Enriched title E ( t );
Get top-K web search result titles t 1 ,...,t K by issuing t as query;
For each token w , let freq ( w ) be the number of distinct titles t i that contain w ; /* Compute high-frequency tokens */
Let w 1 ,w 2 ,...,w q be tokens with freq ( w j ) &gt;  X  arranged in decreasing order of freq ( w j );
Let j be the index for which freq ( w j )  X  freq ( w j +1 maximum; High-frequency tokens h = { w 1 ,...,w j } ;
E ( t ) = t  X  h ; return E ( t ); extremely common. For product entities, the web contains dedicated pages containing product information like title, price, description, reviews, ratings etc. in a wide range of web sites like Wikipedia, and aggregator sites like Price-Grabber, CNET, Amazon, Yahoo!, MSN, etc. These sites contain mentions of product entities in a variety of different formats. Thus, we can use the different representations of a given entity on the web, and also the keywords that oc-cur in the vicinity of entity references within web pages to establish the extended context for the entity.

The key question, of course, is how to sift through the bil-lions of pages on the web to locate the most relevant pages with mentions of a product entity. This is exactly the task that web search engines are good at. Given a query with a subset of keywords describing a unique product, search en-gines return the top web pages related to the product. To surface the most relevant pages for a given query, search en-gines exploit a range of signals like font, size, and position of query keywords within a page, presence of query keywords in anchor text for the page, PageRank, query and page cat-egories (e.g., electronics, music, apparel), etc.

Search engines assign a ranking to the returned web pages with the ranking algorithm designed to place the most rel-evant pages at the top. Consequently, in our work, we only consider the top-K results returned by the search engine since these are very likely to contain most of the highly rel-evant product pages. For each result of a query, the search engine interface returns the page URL, title, and a short summary comprising a few sentences from the page contain-ing query terms.

Our enrichment procedure starts by invoking the search engine interface with the product title t as the search query. It then considers the titles t i of the top-K results returned by the search engine as the expanded context for the un-derlying product entity. Finally, it uses the high-frequency tokens in the context to enrich the input title t . To iden-tify the high-frequency tokens, Algorithm 1 considers the tokens w with frequency freq ( w ) greater than the support threshold  X  and clusters them into two sets such that the minimum gap in frequencies between the two sets is maxi-mized. The tokens in the cluster with the higher frequencies are then considered to be the high-frequency tokens h . Note that clustering helps to separate the more relevant tokens with higher frequencies from the less relevant ones which Algorithm 2 Compute Importance Scores Input: Enriched title E ( t ), support threshold  X  ;
Output: Token importance scores I t ( w ); for each token w  X  E ( t ) do end for return { I t ( w ) : w  X  E ( t ) } ; are pruned. The final enriched title E ( t ) is then obtained by adding the high-frequency tokens in h to the title t .
In our experiments, we found that selecting K = 20 and  X  = 0 . 2 gave enrichments with the best matching perfor-mance. Also, in our implementation, we shrunk the gap freq ( w j )  X  freq ( w j +1 ) in the frequencies of tokens w w j +1 by a factor (0 . 9) j  X  this further biased token selection towards higher frequencies and increased relevance. Table 3 shows the enrichments for the product titles in Table 1  X  the new keywords that are added to the enriched titles are shown in bold. As can be seen, the enriched rep-resentations now contain important tokens like brand (e.g.,  X  X ikon X ,  X  X ony X ) that were previously missing.
Not all tokens in an enriched title are equally important  X  clearly, certain tokens like model number are more impor-tant than others. Intuitively, a token in an enriched title is important if it is critical for identifying the underlying prod-uct entity. For example, in Title 1 in row (a) of Table 1, the model number  X  X 200 X  is more important than  X  X oom X  or  X 2592 X  since it plays a bigger role in identifying the product. Consequently, we assign importance scores to tokens based on their identification power.

The main question then is: how do we measure the identi-fication power of a token? For this, we rely on web search. A key observation here is that the enriched product title con-tains several relevant keywords for describing (and uniquely identifying) the corresponding product. As a result, if the search results for a token contain many repetitions of key-words in the enriched title, then the results are very likely for the underlying product and we can conclude that the token has high identification power. Thus, the number of repeat-edly appearing enriched title keywords in the web search re-sults for a token is a good proxy for its identification power.
In practice, however, individual tokens can be ambiguous, causing search results to span the diverse meanings for the token. So to disambiguate queries, we pair each token w with other tokens w 0 in the enriched title, and consider the number of frequently occurring title tokens in the web search results of all the pairs as a measure of importance of the to-ken w . Algorithm 2 describes our procedure for computing importance scores for the tokens of an enriched title E ( t ). Notice that when computing the importance score I t ( w ) for # Enriched Title 1 Enriched Title 2 Cosine token w  X  E ( t ), we only consider tokens w 00 in E ( t )  X  X  w,w that frequently occur in the search result titles for keyword pair w w 0 . This is because the search result titles for query w w 0 will most likely contain the keywords w and w 0 irre-spective of how important tokens w or w 0 are; however, if the result titles also repeatedly contain other keywords from E ( t )  X  X  w,w 0 } , then it is a strong indication that either token w or w 0 or both are important.

Traditional IR approaches use IDF scores to capture the importance of tokens. The basic premise is that rare words in a corpus have high identification power, and so are more important. Thus, IDF assigns each token a single score that is inversely proportional to its global frequency in the cor-pus. In our experiments, we found that IDF usually assigns high scores to important tokens like model number. How-ever, there are also instances when it assigns high scores to redundant keywords like  X 2592 X  (in row (a) of Table 2) be-cause they are rare and low scores to important keywords like  X  X harger X  (in row (c) of Table 2). A general drawback of IDF is that it assigns each token a single score based only on global context independent of the co-occurring keywords in the token X  X  local product title context. Furthermore, IDF score computation requires a base corpus, and token scores can vary depending on the choice of corpus.

Our importance score computation approach is very dif-ferent from the IDF approach. For each token, we directly estimate its identification power by measuring the overlap between its local product title context and web search re-sults, and use the degree of overlap as a measure of the to-ken X  X  importance. Thus, our approach computes importance scores taking into account only local contextual information for each product title and web search results  X  this has multi-ple consequences: (1) Our approach does not require a base corpus and is not sensitive to the choice of corpus, and (2) A token can have multiple importance scores depending on the local product title context that it appears in.
The importance scores computed by our approach for to-kens in enriched product titles are shown in parenthesis in Table 3. As can be seen, in Title 1 of row (a), the model number  X  X 200 X  with high identification power is also as-signed a high importance score while the less relevant to-kens like  X  X oom X  and  X 2592 X  are assigned much lower im-portance scores. Similarly, important tokens like  X  X harger X  and  X 2800mah X  in Title 1 of row (c) are also assigned high scores relative to the model number  X  X e140 X . In contrast, IDF assigns high scores to tokens  X 3872 X  and  X 2592 X  relative to the model number  X  X 200 X  (see row (a) of Table 2). Also,  X  X harger X  and  X 2800mah X  are assigned low IDF scores of 6.7 and 11 compared to the model number  X  X e140 X  which is as-Algorithm 3 Matching Pairs
Input: Titles t,t 0 , support threshold  X  , similarity thresh-old  X  ; Output: Match/No match;
E ( t ) = Enrich ( t, X  ); { I t ( w ) } = Compute Importance Scores ( E ( t ) , X  );
E ( t 0 ) = Enrich ( t 0 , X  ); { I t 0 ( w ) } = Compute Importance Scores ( E ( t 0 ) , X  ); else end if signed an IDF score of 15.6 (see row (c) of Table 2). Thus, our importance scores capture the significance of a token in a product title better than IDF scores.

Observe that Algorithm 2 issues a search query for every keyword pair w w 0 , where w 0  X  E ( t )  X  X  w } , when computing the importance score I t ( w ) for token w . This can result in a large number of calls to the search engine which can get computationally expensive. One way to reduce the number of queries is to randomly select a subset of tokens E 0 from E ( t )  X  X  w } , and then issue queries for only keyword pairs w w 0 where w 0  X  E 0 . The importance score I t ( w ) for w is then computed by summing up the number of times tokens from E ( t )  X  X  w,w 0 } frequently occur in the search results for the random queries.
Comparing every pair of enriched titles to see if they match can be prohibitively expensive for large data feeds containing hundreds of thousands of records. Clearly, ti-tles whose enrichments have no tokens in common cannot possibly match, and we can skip comparing such title pairs. The blocking module uses prefix filtering techniques [6] that look for overlap among small filtered prefixes of the titles to generate potentially matching title pairs.
Algorithm 3 describes our matching algorithm to deter-mine whether two product titles t and t 0 represent the same entity or not. Our matching procedure calculates the Cosine similarity between the two enriched titles with importance scores as token weights. The titles are a declared to be a match if their similarity exceeds the similarity threshold  X  .
Table 3 shows the similarity scores between enriched title pairs using our matching approach. Compared to traditional IDF-based similarity between the original product titles (see Table 1), our matching algorithm returns higher similarity scores for matching titles (in row (a)) and lower scores for non-matching titles (in rows (b)-(c)). Moreover, observe that the similarity scores for matching titles are greater than those for non-matching titles, thus allowing the matching ti-tle pairs to be distinguished from the non-matching ones.
Issuing queries to the search engine and subsequently pro-cessing the search results to compute product title enrich-ments and importance scores is the most expensive step in our matching solution. In this section, we propose an opti-mization to reduce the number of search engine invocations.
Frequently, within a data feed, there are groups of prod-uct titles with very similar structure. For example, product titles for the same product line in Table 4 share a common template with the only difference being the model number. Now, within a group of similar-structured titles, if a suffi-cient number of titles have already been enriched, then we can use these enrichments to predict approximate enrich-ments for the remaining titles in the group. Similarly, we can leverage previously calculated importance scores for en-riched titles to predict approximate importance scores for new enrichments. This is the key idea underlying our op-timization that predicts enrichments and importance scores for product titles.

Algorithm 4 describes our procedure for predicting the en-richment and importance scores for a given input title t . The procedure starts by using Jaccard similarity (with threshold  X  ) to identify a subset S of previously enriched titles that are similar to t . Note that the subset S can be efficiently retrieved by indexing the entire set T of enriched titles and using prefix filtering techniques described in [6]. Now, if S contains very few titles (less than  X  ), then we simply compute the enrichment and importance scores using Algo-rithms 1 and 2 instead of trying to predict them. Else, we find the tokens F that consistently and frequently occur in the enrichments of the similar titles in S  X  clearly, these are very likely to also belong to the enrichment for t and so we add these to t to obtain its enrichment E ( t ). These frequent tokens in the enrichments cover brand names and generic keywords like camera, etc. Observe that some of the tokens in F may not occur in the titles themselves. For each token w in F , we set its importance score I t ( w ) to the average of its importance scores I t 0 ( w ) for titles t 0  X  S . Furthermore, to overcome the variations in token importance scores across titles, we normalize scores by dividing each token score by the maximum score in the title.

Now, certain discriminating tokens like model numbers will not be frequent in the enrichments, and thus will not be in F . In order to predict importance scores for these (infrequent) tokens in E ( t )  X  F , we introduce the notion of landmark tokens  X  these are basically tokens in t that occur frequently in the titles in S . We store landmark tokens in the set L . For each token w occurring in a title t 0  X  S , we construct a signature sig t 0 ( w ) based on w  X  X  distance from the landmark token set. More specifically, the signature sig t consists of pairs ( w 0 ,dist t 0 ( w,w 0 )) for each landmark token w . Here, dist t 0 ( w,w 0 ) is the distance (in terms of tokens) of w from w 0 in the sequence-of-tokens representation for t Algorithm 4 Predict Input: Title t , set T of enriched titles, their enrichments E ( t 0 ), and normalized token importance scores I t 0 ( w ); Input: Threshold parameters  X  ,  X  ,  X  ,  X  ; Output: Predicted enrichment E ( t ), importance scores I t ( w );
S = { t 0 : t 0  X  T  X  JaccardSim ( t,t 0 ) &gt;  X  } ; if ( | S | &lt;  X  ) then return  X  ,  X  ; /* Compute enrichment */ Let E ( S ) = { E ( t 0 ) : t 0  X  S } ; Let freq ( w,E ( S )) = frequency of token w in E ( S ); F = { w : freq ( w,E ( S ))  X   X  } ;
E ( t ) = F  X  t ; /* Predict importance scores for tokens in F */ for all tokens w  X  F do end for /* Predict importance scores for tokens in E ( t )  X  F */ Let freq ( w,S ) = frequency of token w in S ;
L = { w : w  X  t  X  freq ( w,S )  X   X  } ; for all titles t 0  X  S do end for for all tokens w  X  ( E ( t )  X  F ) do end for return E ( t ) , { I t ( w ) : w  X  E ( t ) } ; Table 4: Product titles along with importance scores. # Product Title Importance Scores (a) sony cybershot dsct20 black 0.4 0.6 1 0.8 (b) sony cybershot dsch10 black 0.4 0.6 1 0.8 (c) sony cybershot dsct2 blue 0.4 0.6 1 0.8 Note that dist t 0 ( w,w 0 ) is negative if w occurs to the left of landmark token w 0 in the title t 0 , and positive if it occurs to the right. In case w 0 does not belong to t 0 , then dist is  X  .

Now, since titles in S and t follow the same template, tokens of the same type (e.g., model number, color) occur in similar positions across the titles and will thus have near-identical signatures. As a result, even though an individual token w in E ( t )  X  F is not frequent in the enrichments, w  X  X  signature will be frequent due to tokens of the same type as w in other titles. Furthermore, these tokens belonging to other titles in S , of the same type and with near-identical signatures as w , will also have similar importance scores as w . Thus, we can predict the importance score of token w  X  ( E ( t )  X  F ) by averaging the importance scores of tokens belonging to t 0  X  S with very similar signatures (that agree on the distances to most of the landmark tokens).
Example 1. Consider a new product title t =  X  X ony cy-bershot dscw80 black X  and let the product titles in Table 4 be the set S of titles similar to t . Let the enriched product titles be the same as the raw product titles. Furthermore, let the importance scores for the four tokens in each title be 0.4, 0.6, 1 and 0.8 as shown in Table 4. For support threshold  X  = 2 , the frequent tokens F in the enrichments are {  X  X ony X ,  X  X ybershot X ,  X  X lack X  } . Thus, the enriched title E ( t ) = F  X  t = {  X  X ony X ,  X  X ybershot X ,  X  X scw80 X ,  X  X lack X  } . The importance scores for tokens in F are computed by averag-ing their importance scores across the enrichments. Thus, the importance scores (shown in parenthesis) for tokens in F are:  X  X ony X  (0.4),  X  X ybershot X  (0.6), and  X  X lack X  (0.8). Next, we show how the importance score for token  X  X scw80 X  in E ( t )  X  F is calculated. For  X  = 2 , the landmark tokens L are {  X  X ony X ,  X  X ybershot X ,  X  X lack X  }  X  these are the frequent to-kens in the titles in S . Now, the signature for token X  X scw80 X  in t is { ( X  X ony X , 2), ( X  X ybershot X , 1), ( X  X lack X , -1) } . The to-kens  X  X sct20 X  and  X  X sch10 X  in their respective titles (in rows (a) and (b)) have the same signature. Thus, the importance score for token  X  X scw80 X  is 1 which is the average of the scores for tokens  X  X sct20 X  and  X  X sch10 X . 2
In this section, we present a detailed evaluation of our proposed enrichment, importance score computation, and optimization algorithms.
 Datasets: We use two datasets in our experiments. Evaluation Metrics: We use the popular F1 score mea-sure to evaluate the matching quality. To characterize the effectiveness of enrichment prediction, we define two met-rics: Enrichment Prediction Coverage (EPC) and Enrich-ment Prediction Quality (EPQ) . EPC is the fraction of titles for which enrichments as well as importance scores are pre-dicted, and EPQ is the average Cosine similarity between the actual and the predicted importance score vectors over predicted titles. Observe that the cost savings in search queries (defined as the fractional decrease in search queries issued to get the enrichments and the importance scores) is equal to EPC . Also, EPQ measures the similarity between the actual and the predicted importance scores.
 Schemes Compared: We evaluate the matching quality for the following two schemes:
Available at http://dbs.uni-leipzig.de/en/research/ projects/object_matching/fever/benchmark_datasets_ for_entity_resolution
We use the Bing Search API for the search results. Fur-thermore, we perform blocking as discussed in Section 3.3 for all the above three schemes. Our experimental results demonstrate that (1) our web-based enrichments and impor-tance scores improve the matching quality compared to IDF-based Cosine similarity, and (2) the search query volume re-duces substantially with our proposed enrichment prediction scheme. Figure 1: Matching quality of IDF vs EN+IMP.
 The graphs in Figure 1 show the F1 scores for the IDF and EN+IMP schemes as the similarity threshold (parameter  X  in Algorithm 3) is varied. As can be seen from the figure, our EN+IMP matching scheme with web-based enrichments and importance scores outperforms IDF-based matching. For instance, for the Abt-Buy dataset, IDF performs the best at  X  = 0 . 4 with an F1 score of 0 . 57, as compared to our EN+IMP scheme which achieves a higher F1 score of 0 . 62 at  X  = 0 . 6. The difference in F1 scores is much higher in the PG-CNET dataset, with IDF having its highest F1 score of 0 . 57 at  X  = 0 . 3, as compared to 0 . 78 with our EN+IMP scheme.

Also, an important point to note here is that our method is completely unsupervised. The F1 scores obtained with our scheme, specifically for the Abt-Buy dataset, are comparable to the scores presented in [16], obtained using supervised techniques. The PG-CNET dataset performs better than the Abt-Buy dataset, mainly because the product titles in PG-CNET are more ambiguous than the Abt-Buy titles  X  missing key tokens and presence of extraneous words.
Table 5 compares the normalized scores assigned by IDF and EN+IMP to important keywords for a few example product titles. For a given product title, the brand name and model number are the representative tokens and are ex-pected to get high scores. As can be seen, the IDF scores for brand names are significantly lower than the importance scores computed by EN+IMP. This is because brand names like Cannon and Samsung despite being important appear in many product titles, and so get assigned low IDF scores. Also, model number terms get higher importance scores compared to IDF scores most of the times. (IDF) (EN+IMP) (IDF) (EN+IMP) Table 6: F1 scores with varying number of web re-sults ( K ) for Abt-Buy. similarity threshold K = 5 K = 10 K = 20 K = 25
We perform a series of experiments to identify the optimal parameter settings for our algorithms. In this section, we present the parameter sensitivity results for the Abt-Buy dataset. The number of web results for each query ( K ) and support threshold (  X  ) are two important parameters in our matching scheme (Algorithms 1 and 2). Enrichments and importance scores are computed based on the search results fetched. The support threshold should not be high so as to miss some important keywords; and at the same time it should not be very low to allow erroneous keywords.
Table 6 shows the F1 matching scores with varying num-ber of web results ( K ) for similarity match thresholds (  X  ) between 0 . 3 and 0 . 7. As can be seen, we obtain the highest F1 score at K = 20. Figure 2 shows the F1 scores for differ-ent values of support threshold (  X  ). Setting  X  to 0.2 gives the best F1 score. So we set K = 20 and  X  = 0 . 2 in all our experiments. In general, we found that the matching quality of EN+IMP to be more sensitive to the support threshold (  X  ), as opposed to the number of search results ( K ). How-ever, K plays an important role in limiting the number of results processed. Figure 2: Varying support threshold  X  for Abt-Buy.
Reducing the number of web searches is an important component of our matching scheme. In this section, we present a detailed evaluation of our enrichment prediction algorithm EN+IMP(Opt). We perform enrichment predic-tion in a batch setting. Here we use an initial seed set of (randomly selected) titles and their enrichments ( B ), and use this seed set for predicting enrichments and importance scores for the rest of the corpus. Recall that EPC captures the cost savings in the number of search queries and EPQ measures the quality of prediction -we compute these met-rics for the non-seed titles. We also evaluate the effect of seed set size | B | on EPC and EPQ . In our experiments, we set the default value of | B | for the Abt-Buy and PG-CNET datasets to 1000 and 133 respectively.
The graphs in Figure 3 compare the matching quality of EN+IMP with enrichment prediction to IDF, for both the datasets. From the graph 3(a), we observe that the EN+IMP(Opt) does marginally better than the IDF scheme, for the Abt-Buy dataset. The difference in performance is higher for the PG-CNET dataset, as seen from the graph 3(b). The highest F1 score with IDF is 0 . 57 as compared to 0 . 61 with EN-IMP(Opt). Furthermore, the EPC value is 0 . 8 im-plying that enrichments were predicted for 80% of remaining titles. This shows that with our prediction schemes based on the templatized structure of product titles, we can re-duce the number of web searches significantly while preserv-ing matching quality. One important observation to make here is the prediction algorithm does well if the initial seed set of titles is diverse and covers various title templates. We have not focussed on this batch selection problem. However, random selection of the seed set does ensure good coverage for frequently occurring title templates.
Table 7 shows the EPC, EPQ values and the correspond-ing highest F1 score in the setting where we vary | B | for the Abt-Buy dataset. Observe that, with a batch size of 1000, EPC and EPQ values are 0 . 87 and 0 . 89 respectively, Table 7: EPC-EPQ values with highest F1 score for different | B | for Abt-Buy. Figure 4: EPC*EPQ for varying  X  and  X  = 4 , 6 , 8 for Abt-Buy. which implies that the coverage and quality of enrichment prediction are high. A batch size of 1000 and an EPC of 0 . 87 implies that with an initial seed set size of 1000, we could predict 87% of the remaining enrichments/importance scores. The F1 score achieved in this setting is 0 . 59, which is more than that of IDF which has a highest score of 0 . 57.
For a batch size of 1000, we analyze the sensitivity of two important parameters, support size  X  and Jaccard similarity threshold  X  (Algorithm 4). Figure 4 shows the EPC * EPQ values for different values of  X  and  X  . We want both EPC and EPQ values to be high; a high EPC value implies that we have predicted a high number of enrichments and a high EPQ value implies that the quality of prediction is high. As we can see, a support size  X  of 8 performs the best at all thresholds. This can be attributed to better quality enrich-ment predictions at higher  X  values. We further analyze the EPC and EPQ values for  X  = 8 to find an optimum value for  X  . For  X  = 8, Figure 5 shows EPC and EPQ as a function of the Jaccard similarity threshold (  X  ). EPC values decrease with an increase in  X  value, whereas enrichment quality EPQ increases. Observe that, a threshold value  X  of 0 . 3 strikes a good balance between enrichment prediction coverage and quality, for the Abt-Buy dataset.

Table 8 gives an example of the importance scores with enrichment prediction. The predicted scores are very close to the actual scores; thus the Cosine similarity between the actual and the predicted scores ( EPQ ) is close to 1.
The problem of matching records has been extensively studied in the literature  X  [12] and [11] present comprehen-sive surveys of research work in the area. Prior research on matching has primarily focused on three aspects: (1) similarity functions for matching individual attribute val-ues, (2) unsupervised and supervised techniques for match-Figure 5: EPC vs EPQ with  X  = 8 for Abt-Buy.
 ing records containing multiple attributes, and (3) blocking methods for determining record pairs to match.

Developing robust similarity metrics for attribute compar-ison is essential since the input data to the matching process is often noisy (e.g., due to spelling errors) and/or in different formats (e.g., phone numbers with and without  X - X ). There is a large body of work on approximate string similarity measures like edit distance or Cosine similarity applied to IDF-weighted string tokens, q -grams, etc. [12, 17, 5].
Existing matching approaches use attribute-level similar-ity measures as the basic building block, and can be either unsupervised or supervised. Unsupervised methods com-bine attribute-level similarity scores to define record-level similarity which is then compared with a fixed threshold to identify matching records. In the supervised approach, la-beled record pairs with attribute similarity values as features are used to train a classifier. The trained classifier is then used to predict whether a new record pair matches or not. In essence, one can view the classifier as learning record-level similarity measures from attribute-level ones. A detailed evaluation of the matching performance of existing unsuper-vised and supervised techniques on two real-world product datasets is presented in [16]. In general, the authors find that conventional approaches result in low matching quality for product entities with supervised techniques (with multi-ple attributes) performing the best.

To handle continuously arriving product offers from mer-chants, [3] uses a voted perceptron classifier for online learn-ing of similarity functions. In other work, [20] uses active learning to reduce classifier training data requirements. Fi-nally, since running classifiers on all record pairs is expen-sive, blocking techniques are used to reduce the number of record pairs that enter into the matching phase. [9] con-tains a recent survey on the use of indexing techniques for blocking.

The focus of our work is not on record-level matching or blocking, but rather on devising a good attribute-level similarity function for product titles. Our matching algo-rithm improves upon traditional Cosine similarity with IDF weights by leveraging the web to enrich product titles and assign token weights.

The enrichment step of our matching solution is closely re-lated to previous work on query expansion [18], although the primary goal of query expansion is to improve recall as op-posed to matching quality. Given the widespread prevalence, efficiency, and relevance of web search engines, there has been a growing trend to exploit search engines for tasks such as word similarity computation [10], query classification [4], extracting model numbers from titles [21], etc. Matching is no exception and recently there has been interest in leverag-ing web search engines (or more generally, the web corpus) for the matching problem. For instance, [21] uses web search for author name disambiguation. It augments the author name with associated information (like co-author, institu-tion, etc.) and uses the search results of the augmented query for disambiguation. [19] also employs web search en-gines to compute context vectors for short text snippets that are then used to determine similarity. Weights for tokens in the context vectors, however, are still computed using IDF. [7, 8] explore the use of web data for identifying discrim-inating token subsets (called  X  X DTokenSets X ) of comprehen-sive title strings in a reference entity table. These IDTo-kenSets are then matched with candidate strings in docu-ments in order to disambiguate entity mentions. The pa-pers propose efficient techniques for deriving IDTokenSets: [7] uses web search while [8] employs a web corpus. Both [7, 8] assume the existence of a reference entity table with comprehensive title strings containing the most relevant to-kens to identify an entity, and possibly extraneous tokens. However, this is a strong assumption and may not hold in practice  X  as shown in Table 1, important tokens like brand may be missing from product title strings. Observe that we also leverage web search results in our work, but to com-pute enrichments and token importance scores as opposed to IDTokenSets. [15] considers the problem of matching unstructured offers to structured product descriptions. Tokens in the offer that match attribute values in the product are tagged with at-tribute names, and a feature vector is constructed based on the similarity between attribute values. The similarity func-tion is then learned by training a logistic regression classi-fier using the features. Note that our matching algorithm is completely unsupervised and does not require training data. Moreover, our focus in this paper is on matching unstruc-tured product title pairs, and our approach does not require product specification tables.
In this paper, we have proposed two novel ideas to tackle the matching problem for product titles: enrichment of titles with essential missing tokens and importance score compu-tation that takes context into account. Both ideas lever-age the web corpus effectively through web search engines. To reduce repeated invocation of search engines, we also presented a technique for predicting enrichments and im-portance scores. This exploits the templatized structure of product titles. The experimental results demonstrate that the proposed techniques are effective and outperform the widely used IDF technique with higher F1 scores. Enrich-ment prediction reduces search queries significantly while re-taining matching effectiveness over IDF. Our experimental results validate our approach for product titles having dis-tinctive tokens like brand name and model number (product titles of cameras and appliances). We plan to extend this approach to other domains like apparel, toys, software prod-uct titles (e.g., from the Amazon-Google dataset [16]) which may not contain representative tokens.
