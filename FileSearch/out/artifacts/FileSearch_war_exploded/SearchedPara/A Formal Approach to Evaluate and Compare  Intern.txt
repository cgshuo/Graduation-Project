 Pokorny provided an overview on existing web search engine architectures and concluded that current web search techniques are inefficient with respect to robustness, flexibility, and precision, and there is much room for improvements in new search different algorithms are used in the various stages of the web mining process. It is not an easy task to isolate and examine these algorithms X  efficiency and effectiveness, not Usually, one judges how good a search engine is by determining the relevance of the returned results. However, there are other im portant factors that one must consider in order to evaluate a search engine properly and thoroughly. Our philosophy is that the evaluation of search engines should be consistent, reproducible, and unbiased. Over seventy feature (e.g., user interface, search criteria, etc.) and performance (e.g., response time, quality of results, etc.) factors are considered and formulated in a mathematical evaluation model. 
A survey has shown that China ranks second in the world in Internet usage. With only 8% of the Chinese population currently online, this projects a huge potential popular Chinese search engines to illustrate our proposed methodology. Though this case study shows the results of comparing Chinese search engines, our model is general enough to be used in evaluating search engines in other languages. 
Web search engines in general, and Chinese search engines in particular, are introduced in Section 2. The selections of search sites and keywords are discussed in Section 3. A formal search engine evaluation model and its parameters are described in Section 4. Observations, analysis, and discussion of the results are made in Section 5. Finally, work in progress and future research directions are presented in Section 6. One of the first search engine comparisons was published in 1997 where Kingoff observed that the search engines studied did not have many overlaps in the first page of results [8]. He concluded that the reviewed engines are different in their search focus, and each has its own niche. Since then, there are many search engine comparisons with the majority published on the web [19]. Most of these articles give tabulated qualitative comparisons of the engines under study, with no numerical scoring or ranking given. Many focus on specific aspects of the search and consider only a few evaluation factors. These informal approaches quite often introduce biased subjectivity and rigorous and suitable for automation. 2.1 Issues in Chinese Web Search language, segmentation and indexing are more difficult tasks than that in the English language. Similar conclusions can be made for other Asian languages such as Japanese. 
There are many different Chinese character sets in use. BIG5 or Dawu (Big Five), the traditional Chinese character set, is used in Taiwan and Hong Kong, while GB or Guojia Biaozhun (National Standard) is used to re present simplified Chinese characters in China. Increasingly, new web sites either use GBK, Guojia Biaozhun Kuozhan (Extended National Standard), or the multilingual Unicode Standard, both of which have a larger character set that include GB and BIG5. Interested readers should refer to [3] for a comprehensive introduction to Chinese character sets and encodings. 
Since there is no white space between words in a sentence, depending on how one reads it or combines the characters, it is po ssible to interpret the same Chinese sentence in many ways. The effectiveness of word segmentation [7], and therefore the index its document base in an optimal fashion [10]. Furthermore, the white space results, especially for algorithms using similarity measure between the query and document vectors. 2.2 Chinese Search Engine Comparison There exists only a few informal comparisons on Chinese search engines. The Shanghai Society for Scientific and Technical Inform ation introduced twenty-one Chinese search recentness, page summarization, and coding support [16]. However, no ranking or scoring was given to the compared engines. Though this article was published in 1998, it remains as one of the most complete surveys on Chinese search engines yet. Another article published in the same year in eSAS World introduced twenty-six Chinese search engines, and described each engine X  X  features. The author recommended Openfind, Tianwang, and Yahoo China [11]. 
The Popular Computer Week magazine published a report on five commonly used search engines in June 2000: Yahoo China, Sohu, Goyoyo, Zhaodaole, and Tonghua [14]. Parameters for comparison included home page features, search options, and keyword entry options. Yahoo China and Sohu were the top-ranked engines. In August 2003, PC Computing published a comparison of ten search engines (Sina, Sohu, Netease, Chinaren, Wander, Excite China, Yahoo China, Cseek, Tianwang, and Zhaodaole) using various parameters including home page feature, advance search feature, coding support, dead links, total hits, search speed, and search result X  X  relevance, precision, and ranking [13]. Sina was ranked the best search engine. In December 2003, an email survey to Chinese Netizen through iUserSurvey found the top three search engines to be Baidu, Google, and 3721 [4]. In a July 2004 report by the Tsinghua IT Usability Lab, Google, Yahoo China, Baidu, and Zhongsou were compared based on search result X  X  relevancy, recall, and number of dead links [18]. Baidu and Google excelled in this short and simple comparison. 
One striking fact from these search engine comparisons and surveys is that they produced a wide range of results recommending different top-ranked search engines. This inconsistency is part of the motivation for our research work. We aim to devise a thorough and complete formal model for search engine evaluation. Currently, there are more than 300 active Chinese search engines. However, most of these engines X  databases are relatively small and many are simply powered by the bigger search engines. One of our goals of this work is to provide an overview of the current features and capabilities of the prominent Chinese search engines. We are interested in the most commonly used search sites, as well as sites that are enhanced with attractive features. Therefore, we followed a rigorous process to select the most appropriate and representative engines for our study. After extensive browsing and searching, as well as reviewing the many topic directories, we identified forty-two most commonly referred to web search engines with the affix CN (China, 18 sites), HK (Hong Kong, 11 sites), and TW (Taiwan, 13 sites), including Cseek, Netease, Chinaren, Wander, Excite, Zhogshou, Sina, Sohu, Goyoyo, Zhaodaole, Baidu, Yahoo, Tianwang, and Google. 
The list of forty-two search sites was still too large for a thorough and meaningful study. We then further eliminated search engines that are specialized in designated fields such as in consumer electronics; are powered by the same search engine host, for example, popular sites such as Shalala and Yam that use Google X  X  search engine; and are practically inaccessible because they are frequently too busy or too slow. We also discovered that many search sites in Taiwan and Hong Kong are poorly designed and almost unusable due to their long response time and limited capability. Furthermore, instance, a search on Google.HK and Google.CN yield almost the same results. We then decided to focus on search engines in China only. 3.1 Selected Search Engines We finally settled on five search engines (statistics cited as of January 1, 2005): z Google China (http://www.google.com/intl/zh-CN/): established on September 12, z Yahoo Yisou (http://www.yisou.com/): with the current version updated on June z Zong guo sou suo (http://www.zhongsou.com): founded in September 2002, it z Baidu (http://www.baidu.com): founded in 1999, it provides services such as z Tianwang (http://e.pku.edu.cn): founded in October 29, 1997, and is very popular 3.2 Selection of Keywords In order to make the analysis manageable, rare words are often used for the search in an search engines. For examples,  X  X rumpet X  and  X  X olyphenol X  were used in [12], and ten rare words were used in Ljosland X  X  study [9]. In other cases, common words were used to evaluate the coverage of the respective search engines. 3.2.1 Keywords Selected shown in Fig. 1, a phrase of relatively rare occurrence,  X  X hinese Search Engine Comparison X , is used, an appropriate choice within the context of this work. The second phrase is  X  X ird Flu X , a hot news item since the beginning of 2004. engines into finding mismatched items, as a preliminary test on their segmentation and retrieval capability. These issues will be discussed in more details in Section 5.1. As mentioned previously, most existing Chinese search engine comparisons either simply review a few superficial factors, or focus on some parts of the search results, or rate several aspects of the site subjectively. In order to perform a thorough evaluation of the search engines and make meaningful comparisons, we need to explore and review possible evaluation parameters, we concluded that the evaluation of a search engine must deal with two logical parts. The first part consists of parameters to evaluate the part includes the various metrics to examine the performance of the search engine including the quality of the results and response time. One can thus evaluate a search engine for its Feature part and the Performance part, either jointly or separately. 
Within each part, collections of related parameters are further classified into subgroups and sub-subgroups, resulting in a hierarchy of evaluation parameters. This particular focus. Seventy-nine parameters are used in our evaluation model that includes commonly used web metrics such as the ones found in [6]. 4.1 Weighed Parameters and Score Equations parameters can be expressed as Where w i  X  X  are the weights assigned to the X parameters of that group. For example, the total score of a search engine is formulated as scoring equations at lower levels of the evaluation hierarchy. A negative weight can be used to indicate the undesirable impact of a parameter on the total score. For example, the higher the number of dead links (with a negative weight) in the results, the worse indicate whether a feature or capability exists. A range between 0 and 1 is assigned to parameters that have various degrees of quality. The sum of the positive weights assigned to the parameters within a group must be equal to 1. This normalization ensures the consistency of weight distribution among the different groups. 
The flexibility of tailoring the scoring system to individual needs makes the proposed evaluation model very attractive to search engine users, subscribers, and Using our model and adjusting the weights of the seventy-two parameters, a user will be able to find, empirically, the particular sear ch engine that best suits his/her needs. It should be emphasized that the methodology and the parameters examined in our evaluation model are language independent and can be applied to a wide range of search engines of various languages. 4.2 Feature Parameters We have classified Feature parameters into six major categories as shown in Fig. 2: 1. Home Page Features: This category indicates how user friendly the home page is regarding various help and user selection menus. This group includes a user X  X  evaluation of the home page, the availability and visibility of help links, result language selection, topic directory selec tion, and advanced search selection. 2. User Preferences: This category includes a choice of the home page language, the availability of safe search filtering, the control of the number of results per page, the choice of displaying the results in a new window, intelligent input correction, setting the search default, having search options within the result page, and news search. 3. Search Options: This category is further divided into the subgroups of search publication date, etc.), and search meta words for focused search (specified sites only, similar pages, geographic regions, etc.). 4. Keyword Entry Options: This category consid ers the capability of the search engine in stop word interpretation, case sensitivity, exact phrase specification, wildcard allowance, search by pronunciation, and Boolean operators. 5. Database: This category indicates the number of groupings arranged in directories and the total number of pages. 6. Result Features: This category reviews statistics and display type features such as whether there is indication for the total number of hits, the number of pages, and search time, the capability to search within the results, whether the results are ordered and numbered, whether the different file formats are allowed in the returned items, whether pay listing is allowed (a negative weight), web page snap, further search for related pages, and the presence of the hits X  date, size, and summarization. Feature , according to the above order, 0.1, 0.1, 0.3, 0.2, 0.1, 0.2, respectively. We felt that the flexibility of having different search options is the most important factor among weights are assigned to the parameters in other groups and subgroups. Table 1 in section 5.1 tabulates the results of the Feature group. 4.3 Performance Parameters Three metrics are considered in Performance : the Response Time and the Total Number of Results as indicated on the result page, and the Quality of Results, as shown in Fig.3. The Problems subgroup indicates the severity and frequency of problems encountered number of times that the search site is down during our experimentation, the number of parameters within the Problems subgroup carry equal but negative weights. humans to examine the relevance of the returned items with respect to the keywords. human interpretation. To collect search statistics, we followed a rigorously designed process based on the averaging principle. For the purpose of illustrating our evaluation methodology in this preliminary study, data were collected four times over a period of two weeks, on two Wednesdays and two Sundays to reflect workday and weekend patterns. On each day, searches were performed at 10am, 9pm, and 1am to examine usage at peak and other times. At each time, three rounds of searches separated by one-half hour were Through this process, we expect to discover average patterns and the degree of variations on response time, as well as update frequency as indicated in any changes in the number of hits in these thirty-six sets of data. The results show that Google and Yahoo updated most frequently, while Tianwang did not update its database throughout our experimentation period. 5.1 Chinese Language Specific Issues The results from all five search engines exhi bit the peculiarity of the Chinese language. As expected, results of (b) from Fig. 1 are limited while (a) returned items including the ones in (b) and (c). In addition, (a) also returned items with the independent phrases of  X  X hinese X ,  X  X earch X , and  X  X ngine comparison X , in which engine was interpreted in a machinery sense. All five search engines exhibit this behaviour. Similarly in (d), together) appeared together and separately when retrieved. This rendered the results in two categories either of which may suit the need of the particular user. 
To further examine how each engine handles Chinese phrases, we have performed further experiments using additional keywords as shown in Fig. 4. AIDS is a very produced similar results. The left-hand-side word in (ii) is used for  X  X ngel X  in traditional literature, while the word on the right hand side is its modern English phonetic representation. Both forms are widely used these days. The results obtained, as expected, index the two variations into two distinct categories of documents. Similarly, the two variations of ice cream (iii), both English phonetic representations, resulted in two groups of non-overlapped documents. Finally, in (iv), two sets of documents each some overlaps. These results point to the need of a Chinese synonym database to make the search more effective. keywords used, as indicated in Fig. 1 and 4 in our experiments. For each keyword, the results of all five search engines are normalized to the longest response time and the largest number of returned items, Ideally, a good search engine should locate the largest number of documents in the shortest time. This corresponds to the upper-left quadrant in the figure. For this quantitative measure, Zhongsou and Baidu performed the best. Qualitative performance of these Chinese engines is discussed in Section 5.3. 5.2 Feature Comparison Assigning the appropriate values for the various parameters in the Feature group, it is Table 1. Features group 0.8 0.6 0.6 0.5 0.4 5.3 Performance and Overall Comparison Fig. 6 shows the scores of the components in the Performance group. It can be seen that both Google and Yahoo have the best average performance in this category. 
Fig. 7 shows a comparison of the overall scores of the five engines. Google ranks compared to other search engines. 
For convenience, we have assigned equal weights to the Problems and the Relevance groups. One can argue that the Relevance of the returned hits is more important than the Problems encountered. In such cases, the weight assigned to Relevance would be higher. This scenario of having a weight of 0.7 for Relevance and 0.3 for Problems is illustrated in Table 2. There are a couple of outstanding issues in the proposed methodology. First, humans, being subjective, are involved in the evaluation of the Relevance parameter. Second, as the evaluation process involves humans X  input, it cannot be automated. It is an expensive endeavour to rate search engines manually on a regular basis. 
In order to eliminate subjectivity and enable automation, the use of a common appropriate. Since the results from each sear ch engine are already available, a common list can be generated using a data fusion algorithm, such as the ones found in [17]. We are currently focusing on algorithms to merge multiple (possibly multi-lingual) ordered process of regularly evaluating search en gines according to a user X  X  preference by weight adjustment can proceed. 
