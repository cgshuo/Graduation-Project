 Methods for improving sponsored search revenue are often tested or deployed within a small submarket of the larger marketplace. For many applications, the ideal submarket contains a small number of nodes, a large amount of spend-ing within the submarket, and a small amount of spending leaving the submarket. We introduce an efficient algorithm for finding submarkets that are optimal for a user-specified tradeoff between these three quantities. We apply our algo-rithm to find submarkets that are both dense and isolated in a large spending graph from Yahoo! sponsored search. G.2.2 [ Discrete Mathematics ]: Graph Theory X  Network Problems ; H.3.3 [ Information Systems ]: Information Search and Retrieval X  clustering Algorithms, Theory, Experimentation e-commerce, sponsored search, dense subgraphs, sparse cuts, vector-valued optimization, pareto-optimality, parametric flow
One type of graph that arises from Yahoo! X  X  sponsored search business is a bipartite spending graph, with adver-tisers on the left, query phrases on the right, and weighted edges ( a, q ) representing the amount of money the adver-tiser a spends on the query phrase q during a given period of time. This graph provides a detailed picture of the spon-sored search marketplace.

There are many approaches for improving sponsored search revenue, including new auction schemes, new methods for query suggestion, and new methods for bidding on batches of queries. One example is described in [1]. If such an ap-proach is to be employed not in the entire search market-place, but only for a submarket containing certain bidders and queries, then the properties of that submarket as a sub-graph of the spending graph should be carefully considered. For a given subgraph H , we should consider 1. The total amount of spending M ( H ) on edges within 2. The total amount of spending B ( H ) on edges crossing 3. The total number of nodes | H | inside the subgraph. The task that motivated this research is to find a moderately sized subgraph of the spending graph that is both dense, containing a large amount of money M ( H ) for its size, and isolated, having a small amount of money on its boundary B ( H ) relative to M ( H ) or | H | .

There are various algorithms for optimizing certain objec-tive functions of M ( H ), B ( H ), and | H | . A subgraph that maximizes the density M ( H ) / | H | can be found in polyno-mial time using algorithms based on network flow [16]. It is possible to identify an isolated subgraph with small ratio cut score B ( H ) / | H | , or small conductance B ( H ) /M ( H ), using graph partitioning algorithms. For the datasets we consider, the tasks of identifying dense subgraphs and isolated sub-graphs are different; the subgraphs that are most isolated, having the smallest ratio cut score or conductance, tend not to be dense, and the densest subgraphs tend to have large amounts of money crossing their boundaries. More gener-ally, there is some unknown tradeoff between how dense a set can be and how isolated.

In this paper, we describe an algorithm for finding sub-graphs that are simultaneously dense and isolated, and ex-amine experimentally the tradeoff between density and isola-tion in a large spending graph. Our main tool is an efficient algorithm for finding a subgraph that is optimal for a gen-eral objective function of M ( H ), B ( H ), and | H | . We show that for a fixed value of  X   X  0 and  X   X  0, we can find a subgraph that optimizes the following objective function, by performing a single minimum cut computation in an aug-mented graph. Using efficient existing network flow algo-rithms, we find a large collection of subgraphs within a Ya-hoo! spending graph that are optimal for a large collection of objective functions. Each optimal subgraph yields both upper and lower bounds; we obtain an actual subgraph, and also a proofs of the non-existence of other hypothetical sub-graphs. We use these bounds to describe the space of possi-ble subgraphs, and determine to what extent any subgraph in the sponsored search graph can be simultaneously dense and isolated.
In this section we discuss previous work in identifying dense subgraphs and partitioning graphs. We also discuss known methods for optimizing families of objective functions that include the objective functions f  X  X  as a special case.
There are a wide variety of tools available that can be used to optimize the objective functions f  X  X  . To our knowl-edge these tools have not been used previously to study the tradeoff between density and isolation.

The augmented graphs that we construct to optimize the objective function f  X  X  are generalizations of the graphs con-structed by Goldberg for solving the densest subgraph prob-lem [16]. A similar augmented graph is constructed in solv-ing the graph partitioning task of finding the best quotient cut contained within one side of a given bisection [23, 12].
The problem of maximizing the objective function f  X  X  can also be viewed as a special case of the selection problem , in-troduced by Baliski [4] and Rhys [29], which can be solved by computing a minimum cut in a certain bipartite graph whose left side nodes correspond to edges and right side nodes correspond to nodes in the original graph. The prob-lem may also be solved using the fractional programming framework of Picard and Queyranne [27].

If we fix a value of  X  , then the problem of maximizing the objective function f  X  X  is a parametric flow problem, which may be solved for every value of  X  simultaneously using the parametric flow algorithm of Gallo et al. [15], or using the bipartite parametric flow algorithm of Zhang et al. [32, 31]. We will discuss these parametric flow approaches in more detail in a later section. It is also possible to compute solutions for every value of  X  by computing the principal partition of a submodular function [26, 25].

The problem of finding isolated submarkets in an adver-tiser/keyword bidding graphs was considered in [6]. There is a large body of research on the problem of co-clustering the two sides of a bipartite graph (for example, [9, 22]).
Many graph clustering and partitioning problems are NP-hard, but can be approximated reasonably well in practice using heuristics and approximation algorithms, including spectral partitioning and clustering algorithms [28, 17], ap-proximation algorithms for the sparsest cut problem based on linear and semidefinite programming [24, 2], and the ef-fective multilevel heuristic implemented in METIS [20].
The problem of finding the densest subgraph (the sub-graph of highest average degree) can be solved in polynomial time [16], or approximated within a factor of two in roughly linear time [21]. The problem of finding the subgraph on exactly k vertices with the largest number of edges is con-siderably more difficult [14]. A different objective function for density that is suitable for large directed graphs and bi-partite graphs was studied in [7, 19].
We will use the following graph terminology. We consider an undirected graph G with a vertex set V and with an edge weight function w ( u, v ). The degree d ( u ) is the sum of the weights of edges incident to u . The volume of a subgraph H  X  G is the sum of the degrees of its vertices, For two subgraphs X and Y , we define e ( X, Y ) to be the sum of the weights of edges between vertex pairs with one point in X and the other in Y , In particular, e ( X, X ) is twice the sum of weights of edges with both endpoints in X . The cutsize  X  ( H ) is defined to be e ( H,  X  H ), which is the sum of weights of edges with one endpoint in H and one endpoint not in H . In Section 2 we discuss the objective function f  X  X  in detail. We motivate our decision to solve this scalarized version of the more general tri-criterion optimization problem, and describe an efficient flow-based method for optimizing f  X  X  We then explain how f  X  X  relates to the well-known concepts of subgraph density and cut sparsity.

In Section 3 we discuss optimized algorithms that can cheaply generate solutions for numerous values of  X  and  X  by exploiting the fact that the flow problems of Section 2.2 are parametric flow problems with respect to  X  . We dis-cuss an implementation of the sophisticated parametric flow algorithm of [15] which very recently became available, but which unfortunately does not currently scale up to the spend-ing graph we consider. We also describe our own code that utilizes the nesting property of parametric flow solutions in a simple way, and can handle graphs with tens of millions of nodes and large and widely varying edge weights.
In Section 4 we finally describe the results of the com-putation on a large sponsored search spending graph which motivated this project.
In this section we explain why we choose to optimize the scalarized objective function f  X  X  (certain other formulations of our vector-valued optimization problem are intractable), and describe a very efficient flow-based algorithm for op-timizing f  X  X  . We discuss a family of problems related to density and cut sparsity that can be solved by optimizing this scalarized objective function, and also describe several problems that cannot be solved by this method.
Recall that we want to choose a subgraph H  X  G that op-timizes three different graph properties. We want to max-imize e ( H, H ), minimize  X  ( H ), and minimize | H | . These three goals can be packaged together in the following vector-valued optimization problem: values in an entire halfspace, not just in an octant.
We do not propose that there is a single best solution to the problem, but instead we wish to understand the set of objective function values that are achieved by some sub-graph, O = { ~ Z ( H ) | H  X  G } . Geometrically, O is a cloud of points in 3 space. Point in the interior of this cloud are dominated by points on its 2-dimensional surface. We are interested in finding these undominated surface points. This general situation is shown schematically in Figure 1.
Our goal of finding undominated subgraphs can be for-malized in more than one way. We will now discuss two of them. The first way initially sounds reasonable but leads to intractability. The second way obtains a solvable problem using the techniques of pareto optimality and scalarization.
One way to formalize our goal of finding subgraphs that map to points on the optimal surface of O is to ask the fol-lowing question: if we fix the values of any two components of ~
Z ( H ), can we find the optimal value of the third compo-nent? That is, is there a polynomial time algorithm for the following task: Task 1: given a graph G , and indices ( i, j, k ) a permutation of (1 , 2 , 3), and two fixed values c 1 and c 2 , solve the single-valued maximization problem. This general approach is shown schematically in Figure 1A. Unfortunately, it is easy to see that this general problem is intractable, since a polynomial time algorithm for Task 1 would trivially yield polynomial time algorithms for solv-ing the densest-k-subgraph problem and the sparsest cut problem for unweighted graphs, both of which are NP-hard. Each of these two algorithms would consist of iterating over the limited number of possible values for the fixed variables, optimizing over the third variable to generate a sequence of candidate subgraphs, of which we take the best.

Now we obtain a tractable problem via the route of pareto-optimality and scalarization.

Let  X  H be a subgraph of G with the following property: there does not exist any subgraph H 0 for which there is some permutation ( i, j, k ) of (1 , 2 , 3) such that the following holds: z ( H 0 ) &gt; z i (  X  H )  X  z j ( H 0 )  X  z j (  X  H )  X  z k Then  X  H is a pareto-optimal solution, and ~ Z (  X  H ) is a pareto-optimal point in the 3-d objective function space.
Geometrically, a pareto-optimal solution  X  H rules out the existence of solutions that map to any value besides ~ Z ( that lies in an octant of objective function space whose min-imum corner is ~ Z (  X  H ). This is drawn schematically in Fig-ure 1B.

The optimal tradeoff surface for our tri-criterion graph problem is non-convex. There can be pareto-optimal points lying on nonconvex as well as convex regions of the surface. Ideally we would like to have the ability to find solutions mapping to any pareto-optimal point whatsoever, but this will also lead to intractibility. The problem of maximizing f  X  X  , which we can solve efficiently, may be viewed as the result of adopting a scalarization technique.
The first step in using the scalarization method is to choose a  X  X eighting X  vector u = (  X ,  X ,  X  ) T with  X   X  0 ,  X   X  0 ,  X   X  0, which selects a preferred direction in the 3-dimensional ob-jective function space. Next one defines a new scalar ob-jective function F u ( H ) = u T ~ Z ( H ) that hopefully can be solved efficiently. In Section 2.2 we show that (with one fur-ther restriction on u ) there is indeed an efficient algorithm for solving our scalarized problems. Different pareto-optimal solutions (all mapping to points on the convex hull of O ) can be obtained by scalarizing with different weighting vectors u . This technique will only allow us to find pareto-optimal points lying on the convex hull of the optimal tradeoff sur-face. In Figure 1C, this method can find point P1, but not point P2.

The inability of the scalarization method to find pareto-optimal points lying in  X  X imples X  of a nonconvex optimal tradeoff surface (like ours) is somewhat counterbalanced by the strong optimality property of the convex-hull solutions that it can find. Each solution not only rules out an oc-tant of objective function space, it also rules out an en-tire halfspace (which contains that octant) as follows. Let  X  H u = arg max H F u ( H ), and let k u = F u (  X  H u ) = u T ~ Then @ H 0 such that F u ( H 0 ) = u T ~ Z ( H 0 ) &gt; k trated in Figure 1C.

Now we have one more restriction to make. For technical reasons, our efficient algorithm for maximizing the scalarized objective function requires that  X  6 = 0.

One effect of this restriction is that we will be able to ex-plore subgraph density while completely ignoring subgraph isolation by optimizing with weighting vectors u = (1 , 0 ,  X  ), but we will not be able to explore subgraph isolation while completely ignoring subgraph density, because that would require optimizing with forbidden weighting vectors u = (0 , 1 ,  X  ).

At this point, we might as well set  X  = 1 and then rescale the other two parameters to get weighting vectors u = (1 ,  X ,  X  ). Then our scalarized objective function takes on the form in which it appears elsewhere in this paper.

F u ( H ) = u T ~ Z ( H ) = e ( H, H )  X   X  X  ( H )  X   X  | H | = f
Each subgraph of the spending graph has a certain amount of money on the edges contained within it, money crossing its boundary, and number of nodes. In this section, we show how to find a subgraph that optimizes a specified tradeoff between these three quantities. Given a weighted graph G , and any two fixed values  X   X  0 and  X   X  0, we will find a subgraph H that optimizes the following objective function, We call such a subgraph (  X ,  X  )-optimal, or tradeoff-optimal. A tradeoff-optimal subgraph can be found by solving a single s-t minimum cut problem in an augmented graph derived from G .

Lemma 2.1. For any graph G and any fixed values  X   X  0 and  X   X  0 , a subgraph H of G that maximizes f  X  X  can be found by solving an s-t minimum cut problem in an aug-mented graph with m + 2 n edges and n + 2 vertices.
Proof. We will construct an augmented graph G (  X ,  X  ) with two distinguished nodes s and t , and show that the Figure 2: This figure depicts the construction of the augmented graph G (  X ,  X  ) . The nodes s and t are the source and sink nodes. In the middle of the graph is a copy of G with edge weights multiplied by 1 +  X  . minimum s-t cut in this graph corresponds to a subgraph of G that optimizes the desired objective function. The con-struction of G (  X ,  X  ) is depicted in Figure 2. The vertex set of the graph consisists of the original vertex set of G , along with two new nodes s and t . The edge set of G (  X ,  X  ) con-tains the edges of the original graph G with edge weights multiplied by 1 +  X  , and in addition, the source node s is connected to every node v  X  G by an edge of weight  X  , and the sink node t is connected to every node v  X  G by an edge of weight d ( v ).

There is a natural correspondence between induced sub-graphs of G and s-t cuts in G (  X ,  X  ). For any subgraph H of G , we define  X  ( H ) to be the s-t cut where the set of nodes on the sink side of the cut is t  X  H . We define cost( H ) to be the capacity of the cut separating  X  ( H ) from its complement in G (  X ,  X  ).

The graph has been constructed so that cost( S ) is related to the objective function value f  X  X  ( S ). By the construction of the graph G (  X ,  X  ), we have cost( H ) = Vol( V \ H ) + (1 +  X  )  X  ( H ) +  X  | H | We note that in the calculation above, e ( H, H ),  X  ( H ), and Vol( H ) are all measured in the original graph G .
By computing the minimum s-t cut in G (  X ,  X  ), we obtain a subgraph H for which cost( H ) is as small as the cost of any other subgraph H , and therefore H maximizes the objective function f  X  X  .
 We remark that the cost of the empty subgraph is cost(  X  ) = Vol(G), while the cost of the full graph is cost( G ) =  X  | G | . For some values of  X  and  X  , one of the trivial solutions  X  or G maximizes the objective function f  X  X  .
In this section we define a new ratio-style metric that com-bines an objective function for density with an objective function for isolation, and show that it can be optimized exactly by finding an (  X ,  X  )-optimal submarket with appro-priate parameters.
 We define subgraph density to be D ( H ) = e ( H, H ) / | H | . This is twice the weight of edges internal to H , divided by the number of nodes in H. Elsewhere in the paper we use the phrase  X  X ubgraph isolation X  informally to refer to sev-eral related quantities. Here we will focus on the quantity Q ( H ) =  X  ( H,  X  H ) / | H | . If H contains more than half of the graph X  X  nodes, or its size is unknown or unspecified, then we call Q ( H ) the  X  X seudo-sparsity X  metric. If | H |  X  | G | / 2, then Q ( H ) is exactly the objective function of the sparsest cut problem, and we call it the  X  X rue sparsity X  metric.
We define the following ratio-style metric C  X  ( H ) that com-bines the density metric with the pseudo-sparsity metric, with relative importance controlled by  X  ,
The following standard argument shows that for a given  X  , there is a value  X   X  for which any ( X   X ,  X  )-optimal subgraph H  X   X  X  maximizes C  X  ( H ). Assuming that H is a nonempty subgraph, the usual tri-criterion objective function f  X  X  be rewritten in terms of C  X  ( H ) as follows. Since | H | &gt; 0, we see that f  X  X  ( H ) &gt; 0 if and only if C ( H ) &gt;  X  . On the other hand, for the empty subgraph H =  X  , we have f  X  X  ( H ) = 0. Therefore f  X  X  ( H ) &gt; 0 if and only if H 6 =  X  and C  X  ( H ) &gt;  X  .
 Now by choosing a value of  X  and computing a subgraph H  X  X  which maximizes f  X  X  , we either have f  X  X  ( H  X  X  ) &gt; 0 or we know that no such subgraph exists. Therefore we either have H  X  X  6 =  X  and C  X  ( H  X  X  ) &gt;  X  , or we know that no such subgraph exists.

With this constructive decision procedure in hand we can perform binary search on  X  for logarithmically many steps, and thereby determine the value of C  X   X  , the largest value of C ( H ) attained by any subgraph. If we set  X   X  = C  X   X   X  for some sufficiently small value of  X  , the subgraph H  X   X  X  will satisfy C  X  ( H  X   X  X  ) = C  X   X  .

As a special case, when  X  = 0 this binary search method exactly reduces to Goldberg X  X  1984 flow-based method for computing the densest subgraph [16].
Now we illustrate the topic of this section using two ex-ample graphs. The first graph is the 498925-node, 1460791-edge largest connected component of the bipartite actors vs movies graph which is downloadable from the website of A. Barabasi. The second graph is a 522979-node, 2522294-edge subgraph of the TREC  X  X eb graph X  WT10G. Our prepro-cessing of that graph is described in Section 3.3. In the plots of Figure 3 we show how the subgraphs H  X   X  = H  X   X  X  achieving C  X   X  trace out part of the optimal tradeoff curve between subgraph density and cut sparsity. In these plots, each of the black diamonds connected by the black line en-codes the subgraph density and cut sparsity of a particular  X  -optimal subgraph H  X   X  .

The red circle marks the graph X  X  densest subgraph. The red square marks the graphs X  sparsest known cut (obtain-able for example by spectral partitioning [30] or by the flow-based partitioning method described in [23]). For the TREC graph, by computing  X  -optimal subgraphs for  X  values rang-ing from 0 to 780, one can generate solutions which trace out the entire optimal tradeoff curve between the densest sub-graph and the sparsest cut.

For the actors/movies graph, one can trace out part of the curve starting at the densest subgraph, but not extending all the way to the sparsest cut. There is more than one reason why the method of optimizing f  X  X  may fail to generate the complete tradeoff curve including the sparsest cut, but we should not expect to always get the sparsest cut given that computing it is NP-hard. For the actors/movies graph, there is a particularly simple reason why the generatable portion of the curve stops short: any subgraph that is less dense than the entire graph can never be obtained by optimizing f  X  X  for any legal (nonnegative) values of  X  and  X  .
The proof of this can be sketched as follows: let H be a D ( G ). Then for  X   X  D ( H ) and any nonnegative  X  , we have f  X  X  ( H ) &lt; 0 = f  X  X  (  X  ), so H is not the optimum. For  X  in the more meaningful range 0 &lt;  X  &lt; D ( H ), and for any nonnegative  X  , we have f  X  X  ( H ) = e ( H, H )  X   X  X  ( H )  X   X  | H |  X  e ( H, H )  X   X  | H | &lt; e ( G, G )  X   X  | G | = f the middle step is by a standard argument using the fact that e ( H, H ) / | H | &lt; e ( G, G ) / | G | . We conclude this section with three additional remarks.
First, each of the subgraphs that maximize C  X  , which are plotted along the black line in Figure 3-left or Figure 3-right, is obtained by optimizing f  X   X  X  for a particular  X   X  that is a function of  X  . We call such a subgraph  X  -optimal. For the TREC graph we also show some bigger subgraphs ob-tained by optimizing f  X  X  for some smaller values of  X  . These subgraphs are not optimal for the objective function C  X  ( H ), which does not care about subgraph size per se , but they do achieve the best C  X  ( H ) scores for their size.
Second, the straight black lines that we have drawn con-necting the points for the various  X  -optimal subgraphs do not necessarily reveal the true shape of the optimal tradeoff curve between the points.

The final point is subtler but more important: in general a subgraph H  X   X  actually achieves a  X  -optimal tradeoff between density and pseudo -sparsity, not true sparsity. However, a simple argument shows that whenever | H  X   X  | &lt; | G | / 2, then H  X  also achieves a  X  -optimal tradeoff between density and true sparsity. In the plots of Figure 3 we only show those parts of the tradeoff curve in which all subgraphs H  X   X  are smaller than half of the graph, where the optimal density vs pseudo-sparsity and density vs true sparsity curves coincide.
We would like to generate a collection of (  X ,  X  )-optimal subgraphs for many different values of  X  and  X  . The sim-plest way to do this is to perform a single flow computation for each setting of  X  and  X  . In this section we describe and compare several methods for generating a collection of solutions for multiple parameter values more quickly.
In Subsection 3.1 we point out that the auxiliary flow problem from Section 2.2 is a parametric flow problem in  X  . This makes it possible to use one of several known para-metric flow algorithms to cheaply generate a sequence of nested (  X ,  X  )-optimal subgraphs for a fixed value of  X  and an increasing sequence of  X  values.

In Subsection 3.2 we discuss our own code that imple-ments a simple  X  X haining X  approach to compute a sequence of tradeoff-optimal subgraphs. This approach utilizes the nesting property of parametric flow solutions in a simple way. Our implementation can handle graphs with tens of millions of nodes and edges (and with large and widely vary-ing edge weights).

In Subsection 3.3 we present preliminary experiments with a recently released implementation of a more sophisticated parametric flow algorithm. This algorithm should in princi-ple allow us to efficiently generate (  X ,  X  )-optimal subgraphs for every value of  X  for a given  X  , but the code does not currently scale up to the spending graph we consider.
If we fix a value of  X  and let  X  vary, then optimizing the objective functions f  X  X  is a parametric flow problem, as defined in [15]. Using the parametric flow algorithm of Gallo, Grigoriadis, and Tarjan, it is possible to compute a collection of nested subgraphs H 0  X  X  X  X  X  X  H J , such that for any value of the parameter  X  , the objective function f  X  X  maximized by one of the sets H i . Such a collection can be computed in roughly the time it takes to solve a single s-t max flow problem in the augmented graph G (  X ,  X  ) using the push-relabel algorithm.

If we view f  X  X  as a function of  X  , the values of  X  for which the slope of f  X  X  changes are called breakpoints . These are the values of  X  for which no single subgraph optimizes the objective function f  X  X  at both  X  and any value  X  0 &lt;  X  . For more details on parametric flow, we refer the reader to [15].
In this section, we describe the simple chaining method we have implemented to compute a large collection of (  X ,  X  )-optimal subgraphs by solving sequences of standard maxi-mum flow problems. To solve each flow problem, we use Cherkassky and Goldberg X  X  program hi_pr , which is a fast implementation of the push-relabel algorithm [8].
Like other parametric flow algorithms, the chaining method will produce, for a fixed value of  X  , a sequence of (  X ,  X  )-optimal subgraphs for which the values of  X  are increasing and the size of the subgraphs are decreasing. Unlike more sophisticated algorithms like that of [15], it will not pro-duce a subgraph for every breakpoint of the parametric flow problem. The reduction in running time over the naive com-putation comes from contracting the augmented graph after each flow computation. As a result, we solve a sequence of flow problems in progressively smaller augmented graphs.
Initially, we construct the augmented graph G (  X ,  X  ). At each step, we set  X   X  C  X  ( H ), where C  X  ( H ) is defined as in Subsection 2.3, and find a minimum cut H in the augmented graph. We then contract all the nodes outside of H into the source node of the augmented graph, and proceed to the next step, halting when the resulting cut H is equal to  X  or to the entire remaining contracted graph. The nesting property of parametric-flow solutions proved in [15] implies that the subgraph H found within the contracted graph is in fact (  X ,  X  )-optimal within the original graph for the current value of  X  .
 Chaining method input: A graph G and parameter  X  . output: A sequence of subgraphs H . initialization: loop:
On the 8-million node weighted spending graph that we will discuss in Section 4, this chaining approach (running on a 2.4 GHz Opteron with 64 Gbytes of memory) was able to find  X  -optimal submarkets for 70 values of  X  in about 350 minutes, for an average of about 5 minutes per  X  value. Around 700 auxiliary flow problems were solved, for an aver-age of 10 auxiliary problems (with different values of  X  ) per  X  value, and an average of 30 seconds per auxiliary prob-lem. Since the chaining approach generates a sequence of progressively smaller problems, the first problem for each  X  value typically required about 1-3 minutes to solve, while the last few required a couple of seconds each. We estimate that roughly one seventh of the total time consisted of hi_pr cut time. The outerloop program that processed the graph and repeatedly wrote out flow problems on which hi_pr was invoked used about 5 Gbytes of memory. hi_pr itself used 1.6 Gbytes on the biggest flow problems.

In the above pseudocode,  X  may increase dramatically during a given step when we set  X   X  X   X  ( H ). This is advan-tageous for quickly computing the maximum value of C  X  at-tained by any subgraph, but if one would like to obtain more solutions with intermediate values of  X  , the line  X   X  C  X  can be replaced by  X   X  (1 + )  X  . Many of the scatterplots in this paper were produced using this approach.
The recent paper [3] contains one of the first empirical comparisons ever of high-performance implementations of several of the more complicated parametric flow algorithms from the theoretical literature. Very recently, the source code for one of the main programs from that study was released. This program, written by Maxim Babenko and Andrew Goldberg, contains implementations of: 1) The full algorithm from [15], which computes all  X  -breakpoints in time that is within a constant factor of the time needed to solve one st max flow problem using the push-relabel algo-rithm. 2) A simplified and usually faster algorithm called  X  X imple X  that also computes the complete set of  X  break-point values. 3) A  X  X haining X  algorithm similar to the one that we have been using that typically computes only a few breakpoints but is guaranteed to find the largest one.
One of the authors of the above study wanted to know how well that code would perform on our problems, which are larger than any in the study. Unfortunately, some bugs in the code were exercised by our large graphs, especially for  X  &gt; 0. However, we are still very curious about the number of  X  -breakpoints in our tri-criterion optimization problem, so we have done some preliminary experiments on a somewhat smaller publicly available graph.

The basis for this experiment is the publicly available X  X eb graph X  X alled WT10G that was created by TREC and can be downloaded as the file test collections/wt10g inlinks.gz from http://ir.dcs.gla.ac.uk/. We symmetrized it and extracted the largest connected component to get an undirected graph with 1458316 nodes and 6225033 edges.
 Unfortunately this graph is still too big for the Babenko-Goldberg code to avoid hitting bugs, so we used Metis to partition it into three subgraph, of which we took the dens-est, then we again extracted the largest connected compo-nent, resulting in a graph with 522979 nodes, 2522294 edges, maximum degree = 25609, and overall graph density = av-erage degree = 9.645871.  X  = 125 6.2 64.5 error 365.4 370  X  = 625 3.3 49.5 error 177.0 17  X  = 3125 3.6 23.1 25.0 48.1 1
In the above table, for our implementation of the chain-ing method (described in Section 3.2), we report the to-tal cut time (in seconds on a 2.4 GHz Opteron) reported by the multiple invocations of Goldberg and Cherkassky X  X  hi pr program that we use to solve a sequence of successively smaller max-flow problems in order to find the maximum  X  -breakpoint.

For the runs of all three Babenko-Goldberg programs, we list the reported  X  X olve time X  (in seconds on a 2.4 GHz Opteron), which includes more than just the min cut time, but does not include read time and other initialization and finalization work.

Since the Babenko-Goldberg implementation of the chain-ing method does the same basic computation as our pro-gram, using push-relabel max flow code similar to hi pr, their reported solve time is surprisingly large. One possi-ble reason (besides the fact that  X  X olve time X  includes more than just the min cut computations) is that their program tries to achieve high precision by using very large denomi-nators for fractional values, whereas we just use a fixed and comparatively small denominator of 1000.

We observe that the parametric flow problem for  X  = 0 (this is the pure densest subgraph calculation) appears to be slightly easier than for the problems for larger  X  values where we are computing a tradeoff between density and isolation. In fact, one can see that the  X  = 25 problem took longer to solve than the  X  = 0 problem even though there were fewer breakpoints. For very large  X  values the problem starts to become trivial and the number of breakpoints declines, and eventually (as with  X  = 3125 here) there is only a single  X  -breakpoint lying between the two degenerate solutions G and  X  , so there are no interesting solutions at all. We have also tried a recently released implementation of Hochbaum X  X  parametric pseudoflow algorithm [18], which looks very promising. The total run time, including input and output, of this program on the above partial WT10G graph for  X  = 0 and  X  = 25 was less than the solve time alone as reported by the Babenko-Goldberg chaining code (while finding solutions for a similar but not identical set of alpha values). Also, this program works fine on the complete WT10G graph, where its total run time is roughly similar to the hi pr cut time alone as reported by our chaining code.
Now we finally get to the real task. The input is a large sponsored search spending graph G (defined below) and a 3-dimensional vector-valued objective function that maps each subgraph H  X  G to a triple ( e ( H, H ) ,  X  ( H ) , | H | ) measuring internal money, boundary-crossing money, and size. To sat-isfy the multiple consumers of our work who have slightly discussion. different (and sometimes changing) criteria for selecting a particular subgraph, the output of our computation is a siz-able collection of lower-bounding points and upper bound-ing planes which together encode a large amount of infor-mation about the optimal frontier of the set of achievable objective function values. The lower-bounding points, each with a corresponding subgraph H , prove the existence of certain achievable values. The upper-bounding planes prove the non-existence of other hypothetical objective function values.
Sponsored search is a highly profitable business conducted by Yahoo, Google, MSN, and other search engine companies. Roughly speaking, in this business advertisers make mone-tary bids on (query phrase, advertisement) pairs. When a user of the search engine enters a search pattern that matches a bid X  X  query phrase, then the search engine many choose to display that bid X  X  advertisement on the results page. If the user then clicks on that ad, then the bidder must pay the search engine company some money.

The structure of the bidding database can be encoded as a bipartite graph with nodes representing query phrases on one side, nodes representing advertisers on the other side, and each edge indicating that a given advertiser has bid on a given phrase. If one were to apply a clustering algorithm to a bidding graph, one would see block structure showing that the overall advertising market breaks down into numerous submarkets associated with topics such as flowers, travel, financial services, etc.

A spending graph for a given time period has the same basic structure as a bidding graph, with query phrases on one side, and advertisers on the other, but now each edge indicates that a bid resulted in one or more clicks during the time period, and the edge is weighted by the amount of money that was paid by the advertiser for those clicks.
The spending graph for this paper X  X  experiment was con-structed from the click logs of a subset of Yahoo X  X  servers over a time period in 2006. It contains approximately 8 million nodes.
We used our implementation of the chaining method (de-scribed in Section 3.2), to generate optimal subgraphs  X  H for several thousand parameter value pairs (  X  i ,  X  i ). These solutions took an average of about 30 seconds each to com-pute. Associated with each of these optimal subgraphs  X  H is an objective function triple Z i lying on Hull( O ), and also an upper-bounding plane P i . The collection of bounding planes can be combined into a simplex W containing the achievable set O , which means that outside of W there are no achievable points.

In Figure 4 we show a two-dimensional representation of the collection of achievable triples Z i and of several slices through the upper-bounding simplex W . To construct the latter, we chose seven fixed amounts of money M 7 &gt; M 6  X  X  X  &gt; M 1 , and then for each M k we computed the inter-section of the axis-parallel plane e ( H, H ) = M k with the upper-bounding simplex W . This yielded a piecewise linear bounding curve lying in each of the seven constant-money slices.

The plot in Figure 4 was made by mapping the achievable points Z i and the 7 slice upper bounds through the following nonlinear mapping: ( e ( H, H ) ,  X  ( H ) , | H | )  X  ( e ( H,H ) This nonlinear mapping (and the plot X  X  log scales) cause the upper-bounding lines to look curvy even though they are piecewise linear in the original objective function space. The points representing achievable triples are colored in Figure 4 according to the amount of money in the corre-sponding subgraph. A point Z i with M j &lt; e (  X  H i , M j +1 is drawn with the same color as the bounding line derived from the e ( H, H ) = M j slice through the simplex W . The resulting colored bands can be interpreted as fol-lows. Let us consider the band comprising the blue points and blue upper-bounding lines. Each blue point represents a solution containing less than M 6 but more than M 5 units of money. The blue line is an upper bound above which every point must represent a solution containing less than M 5 units of money. If we were to generate additional points by optimizing over more (  X ,  X  ) pairs, some (but not all) the gaps in the blue band would be filled in, and the blue line would also move down slightly because every new point comes with a new bounding plane that tightens up the sim-plex W , but still there would never be a blue point above the blue line.

Having defined the colored bands, let us now see what they tell us about the tradeoffs in our problem. Each colored band seems to trend more or less from the upper left to the lower right. This shows that for a given amount of money there is a tradeoff between subgraph density (the x axis) and subgraph isolation (the y axis). The bands lying down and the left contain the most money, but have the worst tradeoff between density and isolation. The bands lying up and to the right have the best tradeoff between density and isolation, but contain the least money.

Even though we have been discussing a three-way trade-off throughout this paper, it is always possible for a given graph to contain a subgraph that scores very well on all three metrics. We have just seen that this is not the case for the spending graph. Figure 4 shows that in this graph the three quantities are in true opposition to each other, and we will always have to settle for a compromise. However, the pareto-optimal solutions that we have generated at least allow us to make the compromise in the best possible way.
One of the Yahoo projects that has used the output of our algorithm is described in [1].
Some of the gaps correspond to dimples in the nonconvex achievable region, and will never be filled in.
One interesting question is how solutions for different val-ues of  X  relate to the cluster structure of the dataset. On our sponsored search datasets we typically observe that small values of  X  yield the union of the dense cores of numerous clusters, while larger values of  X  produce a union of more complete versions of a smaller number of clusters.
We will illustrate this point using a sponsored search bid-ding graph that could be viewed as a small, unweighted ver-sion of our actual task. After quite a bit of pre-processing, including random sampling and elimination of low-degree nodes, this toy graph contains about 0.65 million nodes and 4.5 million edges. The graph is bipartite with query phrases on one side, advertisers on the other side, and edges repre-senting bids. We computed subgraphs maximizing f  X  X  for a large number of  X  and  X  values, then hand-selected two different subgraphs that enclosed roughly the same amount of edge weight. For  X  = 0 we selected a 3507-node subgraph S 0 for which Vol( S 0 ) = 126180. For  X  = 25 we selected a 9292-node subgraph S 25 for which Vol( S 25 ) = 128526.
Next we used graclus [10] to break the graph into 250 clusters. The following tables show what fractions of those clusters are covered by the two sets S 0 and S 25 .
We see that S 0 contains the dense cores of numerous clus-ters. S 25 touches fewer clusters overall, but a larger fraction of several of them, and in particular it primarily consists of nearly all of two clusters and about 2 / 3 of another one. This is qualitatively similar to what we observe on the large weighted spending graph discussed in section 4. 1. We have posed and studied a novel question in prac-2. By judiciously selecting and combining ideas from the 3. Using this algorithm we were able to generate hun-4. In the process of generating these pareto-optimal so-5. We have found that for the spending graph that moti-[1] Z. Abrams, O. Mendelevitch, J. Tomlin. Optimal [2] S. Arora, S. Rao, and U. Vazirani. Expander flows, [3] M. Babenko, J. Derryberry, A. V. Goldberg, [4] M. L. Balinksi. On a selection problem. Management [5] S. Boyd and L. Vandenberghe. Convex Optimization. [6] J. Joseph , M. Carrasco, D. Fain, K. Lang, and [7] M. Charikar. Greedy approximation algorithms for [8] B. V. Cherkassky and A. V. Goldberg. On [9] I. S. Dhillon. Co-clustering documents and words [10] I. Dhillon, Y. Guan, and B, Kulis, A Fast [11] W.E. Donath and A. J. Hoffman. Lower bounds for [12] U. Feige and R. Krauthgamer, A Polylogarithmic [13] U. Feige, D. Peleg, and G. Kortsarz. The dense [14] U. Feige and M. Seltser. On the densest k-subgraph [15] G. Gallo, M.D. Grigoriadis, and R.E. Tarjan. A fast [16] A. V. Goldberg. Finding a maximum density [17] R. Kannan, S. Vempala, and A. Vetta. On clusterings: [18] Dorit S. Hochbaum. The Pseudoflow Algorithm and [19] R. Kannan and V. Vinay. Analyzing the Structure of [20] G. Karypis and V. Kumar. A fast and high quality [21] G. Kortsarz and D. Peleg. Generating sparse [22] Y. Kluger, R. Basri, J. T. Chang, and M. Gerstein. [23] K. Lang and S. Rao. A flow-based method for [24] T. Leighton and S. Rao. Multicommodity max-flow [25] H. Narayanan, S. Roy, and S. Patkar, Approximation [26] S. B. Patkar and H. Narayanan. Improving graph [27] J.C. Picard, M. Queyeranne, Selected applications of [28] A. Pothen, H. Simon, and K. Liou. Partitioning sparse [29] J. M. W. Rhys. A selection problem of shared fixed [30] J. Shi and J. Malik. Normalized cuts and image [31] B. Zhang, J. Ward, and Q. Feng. A Simultaneous [32] B. Zhang, J. Ward, and Q. Feng, A Simultaneous
