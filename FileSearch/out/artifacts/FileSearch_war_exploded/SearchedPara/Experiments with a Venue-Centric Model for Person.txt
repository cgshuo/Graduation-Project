 Location-based social networks (LBSNs), such as Foursquare, fostered the emergence of new tasks such as recommending venues a user might wish to visit. In the literature, rec-ommending venues has typically been addressed using user-centric recommendation approaches relying on collaborative filtering techniques. Such approaches not only require many users with detailed profiles to be effective, but they also can-not recommend venues to users who are not actually mem-bers of the LBSN. In contrast, in this paper, we introduce a venue-centric yet personalised probabilistic approach that suggests personalised and popular venues for users to visit in the near future. In our approach, we probabilistically in-corporate two components, a popularity component for pre-dicting the popularity of a venue at a given point in time, as estimated from the attendance of the venue in the LBSN (i.e. number of check-ins), and a personalisation component for identifying its interestingness with respect to the estimated preferences of the user. The popularity of each venue is pre-dicted using time series forecasting models that are trained on the recent attendance trends of the venue, while the users X  interests are modelled from the entity pages that they like on Facebook. Using three major cities, we conduct a user study to evaluate the effectiveness of the two components of our approach in suggesting venues for different types of users at different times of the day. Our experimental results show that an approach that combines the popularity and person-alisation components is able to consistently outperform the recommendation service of the leading Foursquare LBSN. We also find that combining popularity and personalisation is effective for both new visitors and residents, while former visitors prefer popular venues.
With the prevalence of smartphones and ever improving mobile access to the Internet, new behaviours have emerged. People stay connected and rapidly share their opinions, in-terests, locations and many other aspects of their lives on social networks. The users of these social networks therefore act as Internet-connected sensors of the real world and pro-c  X  vide a wealth of information about what is currently happen-ing around them. At the heart of these user-generated in-formation lie Location-based Social Networks (LBSNs) [40], such as Foursquare, Flickr or to some extent Twitter. All such services allow their users to share their location, whether by tweeting a message, posting a photo on Flickr, or entering a review about a venue on Foursquare.

New applications have emerged [40] with these rising tech-nologies, such as the suggestion of venues that might be of interest to a user. This task of venue suggestion has been mainly tackled in the literature using user-centric recom-mendation approaches that rely on collaborative filtering [3, 12, 38, 39], where suggestions are based on venues that were highly rated by users that have the same preferences as the current user (i.e. similar users). The main drawback of such approaches is that they require many users with detailed profiles to learn individual preferences. Moreover, they are not able to recommend venues to those users that are not members of the same social network. To overcome these lim-itations, instead of relying on similar users, some recent ap-proaches directly model the likelihood of suggesting venues with venue-centric methods [16, 21], which focus on the fea-tures that make a venue relevant rather than on venues that similar users like. However, all the applications derived from these user-and venue-centric methods have been restricted to specific sub-problems of venue suggestion. These include the recommendation of only new venues [3] (venues in a city that the user has not visited before), the prediction of the next location of the user [16, 21], or the suggestion of only a certain type of venues [21] (e.g. restaurants). In addition, none of the aforementioned studies explored how the qual-ity of their suggestions vary for different types of users (e.g. residents or visitors), or at different times of the day. More importantly, no study so far has reported results derived from the judgments of users.

In this paper, we address all of these issues by proposing a general venue-centric model, which suggests personalised venues at different times of the day. Along with the mod-elling of the user X  X  preferences, the proposed model addi-tionally predicts the popularity of a venue at a given time to provide the user with timely and high quality suggestions.
Our model is composed of two components. The first one estimates the popularity of a venue (an indicator of high quality) by measuring its level of attendance: the most pop-ular venues are the most attended ones. Following recent work on estimating venues X  attendance at different times of the day [25, 32], we use the data generated by the Foursquare users when they  X  X heck-in X  1 at venues to regularly measure
A term used by Foursquare to denote users sharing their current location with the LBSN. the venues X  level of attendance throughout the day. We then predict the future level of attendance of a given venue by ap-plying state-of-the-art time series forecasting models, such as those in [18]. By doing so, we predict the future popular-ity of venues at a given point in time, thereby adapting the suggestions as a function of the date and the time of the day. Indeed, while harnessing the Foursquare venues X  popularity has already been studied [22], no past work attempted to estimate this popularity at future points in time.

The second component of our model takes advantage of the Facebook profile of the users to suggest personalised venues by inferring their interests. People indeed openly share pieces of their interests on Facebook by  X  X iking X  vari-ous pages, which can be viewed as records of their personal-ity [20]. Our model uses the pages users like to estimate the likelihood of a venue being of interest to them. With nearly 1.5 billion users in 2014 2 , Facebook is a central and widely used repository of user interests. Leveraging this centrality allows us to avoid the usual cold-start and sparsity problems that plague recommender systems [13].

While we use specific information sources in this study (i.e. Foursquare and Facebook), our model is general enough to be adapted to other sensors of attendance (e.g. CCTV cameras) or sources of user interests (e.g. Google+). Unlike in previous work, we evaluate the effectiveness of our venue suggestions by asking judgments from users . In particular, we conduct a user study, where we examine the quality of venue suggestions over various dimensions such as the time of the day or the profile of the user (i.e. visitor or resident). Hence, this paper presents a three-fold contribution:  X  We propose a principled probabilistic model that suggests personalised venues based on their estimated interesting-ness and popularity over time;  X  We separately evaluate the two components of our model by conducting experiments on: (1) the inference of the user X  X  interests; and (2) the prediction of the venues X  level of attendance by applying time series forecasting models;  X  We integrate our observations and analysis from the above experiments to build an effective instantiation of our venue suggestion model, which we validate through a user study that involves 100 participants over three major cities . The experimental results from the user study show that: (1)
Taken separately or in combination , both components of our model significantly outperform the Foursquare recom-mendation service, thus validating our approaches for esti-mating the popularity of a venue and the user X  X  interests; (2) New visitors and residents tend to prefer personalised venues, while former visitors prefer popular venues.
The remainder of this paper is organised as follows. Sec-tion 2 reviews approaches related to the task of venue sug-gestion. In Section 3, we describe our proposed model. We experiment in Section 4 with the two components of our model taken separately, before combining them and carry-ing a user study in Section 5. We conclude and discuss future work in Section 6.
Suggesting venues or activities to users is an emerging application that is currently receiving attention due to the growing interest in smart cities [6] and location-based so-cial networks (LBSNs) [40]. These applications are often classified in the literature as Point-of-Interest (POI) [28] (or also sometimes Location [38]) Recommendation. Ap-proaches studied for POI recommendation range from tra-ditional user-centric collaborative filtering [3, 12, 38, 39] to venue-centric topic modelling [16, 21]. User-centric ap-proaches focus on the user and perform recommendation based on the venues that similar users have liked or visited in the past. One weakness of collaborative filtering is that it requires detailed profiles from many users to be able to accurately infer their interests. For example, Bao et al. [3] tackled the sparsity of the user profiles and the cold start problem in collaborative filtering by identifying experts in high-level categories of venues, which are estimated to be of interest to the user from previous interactions on the LBSN (previous visits). Unlike these approaches, we do not rely on previous interactions on LBSNs to model the users X  interests.
In contrast, venue-centric approaches to venue suggestion can abstract from the need of detailed profiles, and also offer the advantage of being able to accommodate a wide range of users by not being restricted to users of a single LBSN. Thus far, the venue-centric approaches have relied on prob-abilistic topic models [16, 21]. Kurashima et al. [21] showed that a topic model can effectively mine logs of GPS tra-jectories to infer the next visit of a user. Hu et al. [16] proposed a very similar model that uses text and locations extracted from social media (e.g. Twitter). However, the venue-centric approaches [16, 21] only predict the next lo-cation of the user, which may not be a venue, thus leading to a low suggestion precision. Moreover, while all of the aforementioned user-and venue-centric approaches relate to our work in that they can all recommend venues, they only consider two parameters: the users and (sometimes) their current location, but they do not consider time. Our ap-proach is different in the sense that it models the quality of venues with respect to both their popularity and the user X  X  interests, and also tracks their popularity over time.
A few studies are closely related to ours. Yuan et al. [39] and Gao et al. [12] proposed time-aware recommendation models that incorporate the temporal check-in behaviour of each user in the LBSN. Both use collaborative filtering, and incorporate the similarity between users that exhibit similar temporal patterns (i.e. users that visit the same locations at the same time of the day). Although these two approaches take time into account for POI recommendation, they are both user-centric and thus suffer from the drawbacks men-tioned earlier. Our approach distinguishes itself from those studies by being venue-centric, and by modelling the tem-poral behaviours of the venues instead of those of the users. Brilhante et al. [8] proposed an approach for mining Flickr and Wikipedia to build sequences of visits for users before they start their trip. However, this last approach only gen-erates a static path of venues given a target city. In contrast, our proposed model adapts to the city, the time, the user, and her/his current location.

The TREC Contextual Suggestion track [10] is investi-gating research questions related to the personalised sugges-tion of places. The most effective approaches [11, 31, 37] heavily rely on the high quality search results of the recom-mendation APIs in various LBSNs such as Google Places, Yelp, or Foursquare. Achieving a personalised ranking is then mostly a matter of re-ranking those results to better fit the user X  X  interests. In the context of the Contextual Sug-gestion track, these interests are expressed through a list of previously visited places associated with ratings, as for user-centric approaches. One issue when considering such profiles is that suggestions will always be biased towards categories of venues that the user rated highly, thereby harming the exploration or discovery of new kinds of venues. Again, our approach does not require the user to have a detailed profile of previously visited venues.

The approach we present in this paper differs from all of the above in the sense that it tracks the popularity of venues over time, and proposes a novel method for inferring the in-terests of the user by using an independent source of prefer-ences (i.e. Facebook) . Our proposed model is principled and flexible enough that it could be instantiated using different approaches to represent the popularity and the interesting-ness of a venue. It is specifically designed to tackle the zero-query retrieval task, where suggestions are presented to the user without requiring her/him to issue a query [23].
We present this model and detail the specific instantia-tions we explore in this paper in the following section.
For a given user u at a location l and at a certain time t , we aim to model the likelihood of a venue v to be of interest to the user. This model can be formally written as: and is composed of two components: an interestingness com-ponent, which estimates the likelihood P ( v | u ) that a venue v would correspond to the interests of user u ; and a pop-ularity component, which estimates the likelihood P ( v | l,t that v would be accessible to the user currently at location l , and that it would be popular at some point in the near future t 0 , where t 0 = t + . In other words, our model can suggest venues that may be of interest in the near future by anticipating the needs of the user. The parameter controls the length of this  X  X ear future X ; we will discuss its setup in Section 5. Note that the model in Equation (1) assumes independence between the user u and the location and time ( l,t ). This assumption simplifies the model allowing us to study the interestingness and the popularity components, independently or in combination, by making use of judg-ments from users. It is also consistent with a venue-centric approach that does not require data detailing the locations of the users at different times. Our model is a venue-centric approach in the sense that it models the likelihood of a venue to be of interest given three parameters, namely the user, its location, and the current time. Venues are modelled both in a conceptual space (finding venues that match the interests of a user) and in a physical space (finding nearby venues that are usually popular at certain points in time). The core of our approach lies in the estimation of the two probabilities of Equation (1), which we describe in the following sections: first, we detail in Section 3.1 our approach for predicting the popularity of a venue at a certain point in the future; then, in Section 3.2 we describe how we can leverage elements of the Facebook profile of a user to infer her/his interests.
We now address the issue of estimating the popularity of a venue as expressed by P ( v | l,t 0 ). In our model, this popularity acts as a surrogate for the quality of the venue suggestion for the user, and depends both on the time and on the user X  X  current location. The quality of a venue would for example decrease if it is far from the current location of the user. We safely assume that a venue will not become popular Figu re 1: Probability that users check-in at a venue given its distance to their own location. The x-axis represents the distance (in km) between the venue v and the user X  X  location l . just because the user is nearby. We thus consider the current location l of the user to be independent of the time t 0 . The right-hand term of Equation (1) can then be written as: We detail in the two following sections how we model both the venue proximity P ( v | l ) and the likelihood P ( v | t the venue will be highly attended in the near future.
It has been shown in previous studies [30, 38] that users tend to visit venues that are near their current location. Ideally, the probability P ( v | l ) would thus be high when the distance d ( v,l ) between the venue v and the user X  X  location l is short. To do so, we look at pairs of Foursquare venues at which the user has checked in over short periods of time (i.e. less than three hours), and fit a Gamma distribution on this distance distribution. The resulting probabilities, expressed as a function of the distance d ( v,l ) between the venue v and the user X  X  location l , are displayed on Figure 1. Finally, the probability that a venue v would be of interest given the current location l of the user is expressed as: P ( v | l ) = P ( d ( v,l )). Note that evidence other than distance can be used for estimating P ( v | l ), for example search logs [4], but we leave the use of this additional evidence for future work.
In our model, the popularity of a venue is mainly related to its predicted level of attendance . We follow the ongoing initiatives in the development of smart cities and use social sensors [1, 33] to construct a time series of attendance for each individual venue. Time series are numerical informa-tion that are observed sequentially over time. In this work, we use the Foursquare API 3 as a social sensor. When asking for information about a venue, the API permits to obtain the number of people currently visiting the venue. We query the API every hour for each venue to build a comprehensive time series of venue attendance. It is important to note that we do not depend on using Foursquare as a particular type of sensors. Indeed, any other kind of sensors (or combination of sensors) that can measure crowd density could be used here, such as CCTV cameras for example [34]. Since we focus on predicting popularity, we build a time series of attendance for each venue and rely on three state-of-the-art time series forecasting algorithms [24]. Time series forecasting encom-passes a family of methods that can predict not only the value of the next point of the time series, but the values of the next N points. State-of-the-art forecasting algorithms such as ARIMA ( Auto-Regressive Integrated Moving Av-erage), Neural Networks, and Exponential Smoothing use past observations to learn trends, seasonal variations, and recurring patterns in the data [18, 24].

We use these forecasting models to estimate the probabil-ity P ( v | t 0 ) in Equation (2). We apply Bayesian smoothing with a Dirichlet prior to avoid zero probabilities: where  X  y ( v,t 0 ) is a forecast of the number of people attending the venue v at time t 0 , using either ARIMA, Neural Net-works, or Exponential Smoothing as forecasting models. V is the complete set of venues for a given city. P ( v |T ) models the popularity of the venue v over an entire timespan T of past observations, where T also represents the training pe-riod of the forecasting models. This background probability is expressed as P ( v |T ) = y ( v, T ) P total number of people that attended the venue v during T .
The Dirichlet prior  X  is the mean of the counts for all venues in the same city, over the entire timespan T . The rationale behind applying such a smoothing is analogous to traditional information retrieval: we avoid eliminating the candidate venues with 0 attendances. Without any smooth-ing, the probability P ( v | t 0 ) is null when  X  y ( v,t to be 0. However, even if a venue has a low level of atten-dance, it may still be interesting to some users . For example, we observed in our data that a board game shop is a very unlikely venue to check-in; however, a person who likes such games would be highly interested by this kind of sugges-tion s. Hence, smoothing this probability helps us to tackle the inevitable sparsity of our observations.
The second component of our approach models the in-terests of the user in order to personalise the suggestions. Users supply a wealth of information about their personality on social networking websites. With its ever growing num-ber of users, Facebook is one of the most popular publicly available personality repository [20]. On Facebook, people can explicitly share their interests by  X  X iking X  pages that re-fer to entities such as public figures, bands, venues, events, or even fictional characters. The personality of users can then be represented as sets of entities covering their vari-ous interests [20]. We leverage this entity representation in a probabilistic model, which extracts the interests of a user with the aim of suggesting personalised venues. More specif-ically, we compute the probability P ( v | u ) that a venue fits the interests of user u by marginalising over the space of all known entities of the entire Facebook Graph 4 (with the fair assumption of independence between the user and an entity): We reasonably hypothesise that a  X  X ike X  is an indicator of relevance, hence a page e will always be relevant for a user u if that user has liked it in the past. Therefore, we define the user u likes the entity e , and 0 otherwise.
 Estimating P ( v | e ) is thus the core part of this component. Since venues and entities do not share the same space, we map them into a common space of categories and apply ma-chine learning. We detail in the remainder of this section the categorisation and classification approach es we employ.
Our approach for estimating the probability that a venue is relevant given an entity relies on the categories of the DMOZ 5 Open Directory Project, a curated directory of web pages that have been manually categorised. This allows us to represent both venues and Facebook entities as sets of categories, thus enabling their comparison to measure how well a venue corresponds to the interests expressed by an en-tity. Bi et al. [5] recently proposed a method that relies on DMOZ to map Facebook profiles with search profiles in the Bing search engine, using proprietary search logs. However this previous work is limited in that only the number of sim-ilar categories are counted, which we overcome by directly computing probabilities. Moreover, Bi et al. only predicted specific personality traits such as the age, the gender, or the political views of the users. Here, we propose a method that can match two types of entities of very different natures, e.g. a Facebook page and a venue, by categorising each in a space of DMOZ categories. Formally, given C , the set of DMOZ categories, we rewrite the expression of P ( v | e ) used in Equation (4) as (with the fair assumption of independence between the entity and a category): Using Bayes X  rule, P ( v | c ) can be expressed as: As we do not consider any prior information about venues in this component of the model, P ( v ) is constant and does not affect ranking and can be removed from Equation (6). We can then rewrite Equation (5) as: Estimating P ( v | e ) comes down to estimating the category distribution P ( c | X  ), where  X  X  X { v,e } . We cover this estima-tion in the following section.
Our approach to entity and venue classification builds upon recent work in query classification. In particular, pre-dicting the categories of queries has been studied in the past, and successful approaches agreed on the fact that context is needed [5, 36] to tackle the sparsity problem. This context is usually obtained by retrieving documents that are topically relevant to the query, and classifying the top results into a predefined set of categories. We take the same approach to predict the category distribution of venues and Facebook entities. We train three state-of-the-art classifiers using web pages previously labelled with the top-level DMOZ 6 gory information. Venues and Facebook Likes can be en-tities of very different types, we thus intentionally consider the highest level of the DMOZ hierarchy to represent these entities in a general and diverse category space. We show http://dmoz.org 6 The DMOZ hierarchy has 16 top-level categories. Our training data has a total of 13 categories as it does not contain  X  X ids and Teens X ,  X  X orld X  and  X  X egional X . in Section 4.2 that using the highest-level categories of the DMOZ hierarchy is valid for this task. Future work could however address more refined taxonomies.

Like Bi et al. [5], we transform each Facebook entity e into a query by using its title. Similarly, for each venue v , we concatenate its name and its city to provide some disambiguation, and use this as a query. Let R (  X  ) be the set of top search results using  X  as a query. The retrieval model can be of any kind, as long as the retrieved documents are topically relevant to  X  . Each retrieved document of this set is then classified, yielding a probability distribution over the DMOZ categories. More formally, the probability P ( c | X  ) that  X  would be of category c is expressed as: where |R (  X  ) | is the number of retrieved documents. These documents are retrieved from a general repository of web pages that we detail in Section 4.2. The probabilities P ( c | D ) are directly derived from the predictions of the classifier, which models the category distribution of unseen documents. Different retrieval models and classifiers can be deployed to estimate P ( c | X  ), as we detail in Section 4.2.
 We rewrite Equation (7) using Equation (8) as:
It is important to note that our approach could be in-stantiated using other sources of user preferences in lieu of Facebook (e.g. Google+) to infer the user X  X  interests. We could also imagine a combination of social networks to im-prove the coverage of the user personality. We leave these improvements for future work.
As detailed in the previous section, our model is built upon two principal components that model the popularity and the interestingness of a venue. In this section, we evaluate the two components separately before carrying a user study of the entire model in Section 5. More specifically, we seek to answer the following research questions:
RQ1 : What is the best time series forecasting algorithm for predicting venue attendance levels? (Section 4.1)
RQ2 : Which choice of retrieval model and classifier en-ables to effectively model the categories of users X  interests? (Section 4.2)
We describe in this section the dataset, the measures, the baselines, and the results of our experiments in order to answer our first research question.
We chose three major cities to evaluate our model and an-swer our first research question: London, Amsterdam, and San Francisco. London is a major capital with a large pop-ulation (more than 8 million). Amsterdam has a higher density and counts more than 800,000 inhabitants. We com-pleted our test bed with San Francisco in order to see if the Figure 2: Distribution of venues over their Foursquare categories for the three cities we con-sider in this study. observations made on two European capitals generalise to a major American city.

We used 3 different Foursquare API accounts belonging to the researchers involved in this study to measure the lev-els of attendance of venues. The Foursquare API limits the number of calls per account to 5,000 per hour, thus adding up to 15,000 possible API calls per hour. We reasonably lim-ited the frequency of obtaining the levels of attendance to one measurement per hour for each venue. This rate allowed us to both accurately keep track of each venue X  X  attendance while considering a large amount of venues. We equally di-vided the API calls across the three cities, and monitored 4,950 venues for each city 7 from 5 th November 2013 to 17 January 2014. However, tens of thousands of Foursquare venues are available for these cities . Initial experiments showed that the 3,000 venues with the highest total num-ber of check-ins contained the majority of the most popular venues for the three cities. We then performed a selection of venues by choosing the 3,000 ones with the highest num-ber of check-ins, and randomly selected the remaining 1,950 venues from those that had at least 25 check-ins at the time we began our experiments. This threshold of 25 check-ins was used to ensure that we did not include fictitious venues. While performing this selection, we omitted venues falling under the Foursquare categories  X  X ollege &amp; University X  and  X  X ravels &amp; Transport X . While airports and train stations for example are very popular among Foursquare users (who like to check-in at these locations to show that they are travel-ling), they may not be useful suggestions. Some Foursquare venues can belong to multiple Foursquare categories, hence we kept venues that belong to the two blacklisted categories above if they also belong to other (whitelisted) categories. Overall, this selection policy allowed us to build a diverse dataset that includes the most popular venues, which might be of interest to visitors, while also containing less well at-tended venues. Statistics on this dataset are available in Figure 2, which shows the number of venues for each cate-gory in each city.
We detail here the baselines and evaluation measures we use to answer RQ1. Forecast accuracy is determined by computing the errors of the forecasts with respect to the real observations. We report the results in terms of root mean squared error (RMSE), which is a commonly used er-
The last 50 API calls were used as a safety buffer in case of an intermittent unavailability of the Foursquare service. ror measure 8 . As already mentioned in Sections 2 and 3.1.2, we explore the effectiveness of three forecasting models. We compare them to 3 widely used baselines that proved to be competitive [24]. The first baseline, denoted by Mean, fore-casts all future values for a given venue to be the mean of the past observations. The second one is called Na  X   X ve, for which all forecasts are simply set to be the value of the last observa-tion. It was shown to be very effective in the context of eco-nomic and financial time series forecasting [24]. The last one is the Seasonal Na  X   X ve method, with the forecast being equal to the previous day. All the time series forecasting models were built using the well-known forecast package of R [17] .
Research question RQ1 aims to explore the accuracy of time series forecasting algorithms for predicting the venue attendance levels. To this end, we evaluate daily forecasts by predicting the attendance of each of the venues for the following 24 hours. In this case, all the days prior to the prediction can be considered as training data. We forecast the attendance of each venue for 10 randomly chosen days (while allowing at least 21 days for training), then average their accuracy. The results are reported in Table 1, where we evaluate the three widely used forecasting models: Neu-ral Networks (Neural), ARIMA, and Exponential Smoothing (Smooth.) with respect to three baselines commonly used in forecasting studies [17]: Mean, Na  X   X ve, and Seasonal Na  X   X ve (S. Na  X   X ve). We vary the number of training days between 7 and 21 , and we report the averaged RMSE for all venues in each city. Since RMSE measures a forecast error, the best results are the lowest numbers.

On analysis of Table 1, we see that the Mean method is the most effective method when trained using a small num-ber of observations (7 days) . However, with more histor-ical data, ARIMA achieves the best accuracy. The good results of the very basic Mean baseline can be explained by the sparsity of the observations. When building time se-ries of attendance, we consider that a venue is empty if no Foursquare user has checked-in for the current hour. This can result in time series that are mostly composed of zeros for venues that have low levels of attendance, or that attract few Foursquare users. This explains the high results of the Mean baseline, which predicts very low levels of attendance for unattended venues. However, state-of-the-art forecasting models improve their accuracy when we use more historical data, as they are able to model daily and weekly trends even for venues with very few check-ins. ARIMA achieves almost the best results for all cities when using more train-ing days , and Exponential Smoothing models are on par with the three baselines. In contrast, we see that Neural Networks tend to over-fit and hence cannot cope with large daily variations. Nevertheless, we conclude that state-of-the-art time series forecasting models are in general able to outperform these competitive baselines, unless they have a limited amount of training data.

To summarise, in order to address RQ1, we conducted the first systematic series of experiments on the evaluation of forecasting models for predicting the levels of attendance of the venues. Moreover, the forecasting accuracies are very similar across three different cities, which is promising for other potential applications in other cities. It should be
We noticed in our preliminary experiments that RMSE was highly correlated with other common error measures (such as MAE or MASE).
 Table 1: Accuracy of the three used forecasting models compared to the three standard baselines. We report the average RMSE for all the venues of each city, varying the number of training days. Numbers in bold are the best results per city and per number of training days. noted that despite the computational requirements of the state-of-the-art forecasting models, they are still suitable for practical deployments, since the forecasting process is done offline on a regular basis and not in real-time..
 In the user study we conduct in Section 5, we use the ARIMA models built from the past 21 days as the instanti-ation of the popularity component of our model.
We now answer RQ2 by evaluating the component that models the user X  X  interests. As described in Section 3.2, this component is a two-step approach, where it first retrieves documents related to a Facebook entity, before classifying them into DMOZ categories. We detail in this section the retrieval models and the classifiers that we use, our evalua-tion methodology, and the results of this experiment.
As already presented in Section 3.2, our method for es-timating the interests of a user has two sequential steps: the retrieval of documents related to a Facebook entity, and their classification into 13 DMOZ categories. We detail here the different retrieval models and classifiers we experimented with in order to answer our second research question RQ2. The retrieved documents come from the category B of ClueWeb09, a corpus of 50M web pages. We use the Ter-rier IR platform [26] for indexing and retrieval. We ex-perimented with three different well-known retrieval mod-els using their default settings in Terrier: Language Mod-elling (LM) [15], BM25 [29] and the DPH model [2] (an effective parameter-free model from the Divergence From Randomness framework). It is well-known that ClueWeb09 contains many spam documents, which we overcome by us-ing the Waterloo spam list [9] that provides spam percentiles for all documents. We follow [9] and only retain documents with a percentile score higher than 70.

We use the Weka machine learning software [14] for train-ing and classifying web pages, and test three different classi-fiers. We take a traditional text classification approach and consider word frequencies as features. Our baseline classifier is the well-known Na  X   X ve Bayes [19]. We also experiment with two other state-of-the-art classifiers: Random forests [7] and Decision trees (J48) [27]. Each classifier is trained using 5,000 9 randomly selected examples from 197,125 documents that were previously labelled in the DMOZ categories.
Increasing the number of training examples only resulted in reducing efficiency and had no significant effect on classi-fication accuracy. distributions, and that has a JS divergence of 16 . 038 ( and O ), and (2) the Na  X   X ve Bayes baseline ( N and H ).
The nine combinations of classifiers and retrieval models that we described above all output a probability distribu-tion over the DMOZ categories that estimate the interests of the user. In order to quantify the ability of this approach to approximate interests as per RQ2, we first need users to explicitly state their  X  X rue X  interests in terms of the DMOZ categories. We obtained this gold standard by using the Amazon Mechanical Turk 10 crowdsourcing service. We pre-sented workers with the list of the 13 DMOZ categories and asked them the following question:  X  What are your general interests?  X . They had to rate each of these categories in order to answer this question. Ratings ranged from 0 (not interested at all) to 10 (extremely interested). We paid users $0.05 for this task, which was completed in 32 seconds on average. We asked users to connect with their Facebook ac-count, using Facebook X  X  software development kit 11 , in order to obtain the titles of the pages they like while they were performing the task. The users were explicitly asked to au-thorise access to the titles of pages they like on Facebook and nothing else. This login step also allowed us to entirely prevent our task from being completed by robots or mali-cious workers. We obtained a total of 25 manually entered user profiles, which constitute our gold standard.

We then converted the ratings of this gold standard into a reference probability distribution over categories, in order to be able to compare this reference to our automatically gen-erated distributions using statistical distances. Categories from which users attributed a high rating received a high probability, and vice versa . In order to measure the statisti-cal distance between our estimated category distribution and the reference distribution, we used the Jensen-Shannon (JS) divergence, which is the symmetric version of the well-known Kullback-Leibler divergence. We use this measure as it is a natural and principled choice for dealing with and comparing probability distributions, and quantifying their differences. We also experimented with the Kendall X  X   X  rank correlation coefficient, from which we made similar observations.
We experiment with the three classifiers and the three re-trieval models presented earlier, and vary the number of re-trieved documents for each Facebook entity used as a query. For each of these settings, we compute the average JS di-vergence across the estimated profiles and the crowdsourced references profiles. We report the results of these experi-ments in Table 2. As the numbers represent divergences, lower are better. As a simple baseline, we randomly generate the category distributions, which achieves a JS divergence of 16.038 (not shown in Table 2).

On analysis of Table 2, we see that increasing the amount of retrieved documents always improves the quality of the estimation, which stabilises around 40-50 documents for a majority of settings. The DPH and BM25 retrieval mod-els have similar behaviours with all classifiers: using BM25 allows to achieve marginally better results than DPH, with one exception for random forest. Language models are in-effective when used in conjunction with Na  X   X ve Bayes and Random Forest, but achieve the best results when the re-trieved documents are classified with decision trees. Using decision trees for this task significantly outperforms both the random and Na  X   X ve Bayes baselines for all settings (ac-cording to a pairwise t-test at p &lt; 0 . 05), except for DPH when using 20 retrieved documents.

To summarise, in this section we conducted a compre-hensive experiment, which revealed that our approach can automatically quantify the interests of a Facebook user from the pages she/he likes. In answer to our research question RQ2, we conclude that our approach performs best using language models (LM) to retrieve 40 retrieved documents that are classified by decision trees (J48) ; we adopt this set-ting to instantiate our model for the following user study. While the evaluation in this section focused on estimating the interests of the users without considering the venues, in the next section, we evaluate the effectiveness of the person-alised venue suggestions through our user study.
We now conduct our user study, where we obtain judg-ments from users (recruited volunteers), to measure the ef-fectiveness of our model for time-aware and personalised venue suggestion . Specifically, we seek to answer three fur-ther research questions:
RQ3 : Is our model effective with respect to a state-of-the-art venue suggestion baseline? RQ4 : Is our model effective for different times of the day?
RQ5 : Is our model able to accommodate different types of users (such as visitors or residents)?
To answer these questions, we developed a web interface for assessing venue suggestions and asked 100 volunteers (using word-of-mouth and social networks) from across the world to judge these suggestions. Participants had to judge the relevance of a set of venues with respect to three con-ditions: their own interests, their location in the city and the time of the day. They first had to connect with their Facebook account, so that our model could infer their pref-erences. As in the experiment in Section 4.2, the partici-pants were explicitly asked to authorise access to the titles of pages they like on Facebook. Then, they had to choose a city: (London, Amsterdam, or San Francisco). The pre-sumed location of the participant during these assessments was randomly chosen within the city they selected. We used the local time of the participants as the time of the day, and set the parameter (see Section 3) to 1 hour. We specif-ically chose this value for two reasons. First, the terms of use of the Foursquare API prevented us from choosing a smaller without reducing the total number of venues in our dataset. Second, we assume that 1 hour is a reasonable duration for a user to walk in a busy area of a major city, while still having the time to visit a few venues. We further clustered the assessments from different times of the day by  X  X ime periods X  that represent the main parts of the day. The  X  X orning/lunch X  part includes assessments performed between 7am and 1pm, the  X  X fternoon X  one focuses on the time period between 2pm and 6pm, and the  X  X vening/night X  closes the day by covering assessments between 7pm and 2am. Before displaying the suggestions to be judged, we asked participants for their previous knowledge of the city. We divided this knowledge into three levels, allowing us to explore the effectiveness of our model for different types of users: people who have never been, people who have already visited, or people who live/ have lived in the city. We display in Table 3 a summary of the 100 total participants broken down by city, time period, and knowledge. As said earlier, we left the choice of the city to the participants, who showed a high preference towards London. We thus take London as our main test city, and consider Amsterdam and San Fran-cisco as additional cities in order to show generalisation. We also observe that a majority of the participants had already visited the city they chose, while a lower number of resi-dents participated in our study. However, as we will see in the results below, the improvements over the baselines were consistent enough so that we could still identify statistical differences.

After the user had selected a city, the ranking lists of venue suggestions were computed using five different algo-rithms: Nearby (N) , Foursquare (F), Popularity (P), Inter-estingness (I), and our Full model (Full). Nearby is a sim-ple baseline that selects venues that are located near the user within a 500 meters radius (this value has been set ac-cording to the probability density function depicted in Fig-ure 1) , and ranks them randomly. Foursquare is a com-petitive, but a blackbox baseline that uses the API of the Foursquare LBSN, i.e. it uses the same data. It uses its own data to recommend venues near a given location 13 . Since it is currently an industrial application, we do not know the implementation details of the Foursquare recommenda-tion algorithm. However, considering the current leader-ship role of Foursquare among LBSNs, we reasonably use its recommendation service as a state-of-the-art venue sug-gestion system. Since less than 5 of the participants had a 12 Due to the limited space, we have not provided screenshots of the interface used by the recruited vol-unteers. To preserve anonymity, we will provide a URL to the interface when the paper is published. Table 3: Number of participants for the three cities, as a function of their level of knowledge of the city and of the time of the day.
 Foursquare account (which would be required to obtain per-sonalised suggestions from Foursquare), these suggestions were not personalised. The (Full) system is the instantia-tion of the model we propose in this paper as expressed in Equation (1). The (P) and (I) variants aim at exploring the influence of the two components of our model on suggestion effectiveness. For (P), venues are ranked based on their level of forecasted attendance only and according to the follow-ing equation: P ( v | u,l,t )  X  P ( v | l,t ). The (I) model is the opposite of (P) and only considers venues that match the user X  X  interests. In other words, venues are ranked accord-ing to P ( v | u,l,t )  X  P ( v | u ) for this model. Details on these probabilities are available in Section 3.

We retained the 10 venues with the highest scores for each of these algorithms. The union of these rankings constitutes the pool of venues to be judged. The average size of the pool for all users is 38.31 venues. We randomised the order of the venues in the pool so that participants could perceive changes of quality in the suggestions. The web interface se-quentially presented participants with a single venue, asking them to judge it with respect to the time, the location, and their own interests. Each venue was located on a map, which also shows the participant X  X  location. Before assessing, the participants were presented with a paragraph that detailed the situation (city, exact location, time of the day), and were provided with instructions for judging the relevance of the venue. We also displayed a description of the venue, which included a photo, a list of categories, and a link to the Foursquare homepage of the venue. Participants were then asked to judge on a 3-point scale how likely they would visit the venue (not likely, likely, highly likely). Once an assessment is submitted, the next venue in the randomised pool is displayed. At the end of the study, participants had the opportunity to enter free comments in a dedicated text box 14 . We believe that obtaining user judgments on venues by asking the users to imagine that they are in a certain location of the city is realistic and indeed it has been used for evaluating venue suggestions in the TREC Contextual Suggestion track [10]. We follow the evaluation methodol-ogy of previous work in venue suggestion [38, 39] and report performances in terms of precision and nDCG after ranking 10 suggestions.

The first results, reported in Table 4, are averages over the 100 participants. We see that each of the three instanti-ations of our model outperforms the two baselines (N) and (F) in terms of P@10 and nDCG@10 by a statistically sig-nificant margin ( p &lt; 0 . 05, according to a pairwise t-test). While (I) gave the best suggestions according to the par-ticipants, (P) and (Full) achieve comparable results. The 14 We received a lot of positive feedback from the partic-ipants of our study, who noted the promising applications and thanked us for making them want to travel. Table 4: Average effectiveness results over all the participants of our study.  X  and  X  represent statis-tically significant improvements (using a two-sided paired wise t-test) over the Nearby and Foursquare baselines (with p &lt; 0 . 05 ), respectively.
 Table 5: Effectiveness results for the 3 different cities. Notations are identical to those in Table 4. Foursquare recommendation service (F) achieves a low per-formance, even when compared to (N). The full model (Full) achieves a 17% improvement in terms of P@10 over the base-line (F), while (I) achieves a 22% improvement (respectively +13% and +18% in terms of nDCG@10).

We report in Table 5 the suggestion effectiveness results when looking at each city separately. We note that the re-sults are similar to those in Table 4. However, Foursquare achieved similar results to (P) for Amsterdam, and slightly outperformed (I) and (Full). For this particular city, (F) was able to provide participants with diversified suggestions of either  X  X ood X ,  X  X ightlife Spot X ,  X  X rts &amp; Entertainment X , or  X  X utdoors &amp; Recreation X  venues. (F) failed to do the same for London and San Francisco, where 64.8% of its suggestions were  X  X ood X  venues. From the observations we make in Tables 4 and 5, and in answer to RQ3 , we find that (P), (I), and (Full) are effective and consistently outperform Foursquare in terms of P@10 and nDCG@10.

We explore in Table 6 the quality of the suggestions for different time periods. When looking at the  X  X orning X  row, we see that all methods achieve similar results. Often, peo-ple X  X  activities are very personal during this period of the day and highly depend on their activities and the time at which they start their day. While one user may want to have a breakfast, another user may already have visited a museum or might be at her/his office. By suggesting person-alised venues, (I) hence achieves slightly better results than the other methods. Moreover, it is interesting to see that (P) achieves the best results on the evening. When looking at the judgments, we see that 32% of the  X  X vening/night X  relevant suggestions belong to the  X  X ightlife Spot X  category, 44% belong to  X  X ood X , and 10% belong to  X  X rts &amp; Enter-tainment X . The fact that 86% of the relevant suggestions are evening-related activities (even if the food venues are pop-ular for the entire day), along with the high performance of (P) for this time period, demonstrates the validity of our forecasting approach for timely promoting high qual-ity venues. As a summary and in answer to RQ4, we find that venue suggestion is a time-dependent problem and that our model is able to cope with time variations by providing a good balance between mornings and evenings.
 Table 6: Effectiveness results for 3 different time periods. Notations are identical to those in Table 4.
Finally, Table 7 explores the effectiveness of the venue sug-gestions for users with various prior knowledge of the city. The results show that while Foursquare is rather effective for people that never visited the city, it is clearly ineffective for residents or former visitors. On the other hand, our model is effective for all types of users. The results achieved by (I) when suggesting venues to residents (i.e.  X  X ive/lived in X ) are interesting . We observe that this class of users are not interested in popular venues and rather want to go to venues that suit their interests. The venues that residents labelled as relevant have a total number of check-ins of 2707 on av-erage, while visitors are attracted by more popular venues (3419 and 3587 check-ins on average for new and former visitors, respectively). In answer to RQ5, we find that our model is able to accommodate different types of users with suggestions of both personalised and popular venues.
In this paper, we proposed a venue-centric and time-aware model that suggests venues based on their estimated popu-larity and interestingness to the user. We presented an appli-cation of time series forecasting algorithms, and an approach for categorising the interests of a user by using the Face-book pages she/he likes. We evaluated these two different components separately using a dataset of 15000 Foursquare venues spread across three cities. The experimental results showed that state-of-the-art time series forecasting models, especially ARIMA, proved to be effective at predict ing the levels of venue attendance, although highly dependent on the amount of training data. By crowdsourcing the categorised Facebook user profiles, we demonstrated that users X  interests can be inferred using the title of the Facebook pages they like as queries and classifying the top retrieved web docu-ments using decision trees. Despite evaluating on Facebook, we argue that our model can generalise to other sources of user interests. For example,  X  X iked entities X  can be replaced with URLs or entities from searching/browsing logs.
Through a user study involving 100 users, we evaluated our complete probabilistic model . We also saw through our user study that our model was effective in different cities, at different times of the day, and for different types of users. Moreover, we showed that the level of attendance of a venue is a good indicator of its popularity. Residents were found to prefer personalised suggestions, while participants pre-ferred highly popular venues during the evening. Hence, as future work, we plan to address the problem of balancing the influence of the two components in function of different parameters, such as the knowledge of the user or the cate-gory of the venue (e.g. Food, Shop). We also aim to reuse the judgments of our user study to learn this trade-off, for example by applying Learning to Rank techniques.

Overall, the user study showed that our proposed model is versatile by generalising over different types of users, and times of the day. It also demonstrated that we can model venues using social sensors (user check-ins), paving the way Table 7: Effectiveness results for different levels of knowledge of the participants in our study. Nota-tions are identical to those mentioned in Table 4. to a wider use of such data. Note that in our evaluation, we chose large cities with a relatively large number of Four-square venues and Foursquare adoptions. We aim to con-sider in future work how our model performs in small cities, rural environments or in developing countries with lesser adoption of LBSNs. Finally, our approach could be ex-tended to combine data coming from other sources, such as the physical sensors of mobile phones [35].
 This work has been carried out in the scope of the EC co-funded project SMART (FP7-287583).
