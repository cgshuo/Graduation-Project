 Innovative Information Industry Research Center, Harbin Institute of Technology Shenzhen Graduate School, HIT Campus, Shenzhen University Town, Shenzhen, Guangdong, China Shenzhen Key Laboratory of Internet Information Collaboration, School of Computer Science and Technology, Harbin Institute of Technology She nzhen Graduate School, HIT Campus, Shenzhen University Town, Shenzhen, Guangdong, China Department of Computer Science and Information Engineering, National University of Kaohsiung, Kaohsiung, Taiwan Department of Computer Science and Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan Computational Intelligence Technology Center, I ndustrial Technology Resea rch Institute, Hsinchu, Taiwan 1. Introduction
Data mining can be divided into many specific areas due to its applications [1 X 3,5,8,13,15,16]. It is a useful technique to analyze the raw data for retrieving the useful information, consisting of association-rule mining [1 X 3], classification [14,21], clustering [11,18], and sequential pattern mining [4,20], among others. Among them, finding sequential patterns in temporal transaction databases has become an im-portant issue since it allows the modeling of customer behaviors.

Agrawal et al. firstly designed an iterative algorithm for mining sequential patterns [4]. Their algorithm finds customer purchase sequences to predict whether there is a high probability that when customers buy some products, they will buy some other products in later transactions. For example, for an electronics store, a sequential pattern may be that when a customer buys a television in one transaction, he will buy a Blu-ray player in a later transaction. Note that the transaction sequences need not be consecutive.
Although customer behaviors can be efficiently extracted to assist managers in making decisions, the discovered sequential patterns may become invalid when new transactions are added to the database. An intuitive approach is to re-mine the entire updated database to discover valid sequential patterns. When the database is very large, however, considerable computation time is required for re-mining the desired sequential patterns. Developing an efficient approach to update sequential patterns is thus a critical issue in real-world applications. Studies on maintaining sequential patterns are relatively rare compared to those on maintaining association rules. Lin et al. proposed the FASTUP algorithm [19] to maintain sequential patterns by extending the fast update (FUP) algorithm [7] of association-rule mining. Their approach has great performance except when new candidate sequences are not frequent (large) in the original database. Han et al. proposed the frequent-pattern (FP)-tree algorithm [8] for efficiently mining association rules without the generation of candidate itemsets. It keeps only large items from databases to form FP-tree structures. The FP-growth mining algorithm [8] recursively derives frequent patterns from the FP-tree. Hong et al. modified the FP-tree structure and designed the fast updated frequent-pattern tree (FUFP-tree) algorithm [9] to efficiently handle new transactions in incremental mining based on the FUP concept [7]. The FUFP-tree structure is similar to the FP-tree structure except that the links between parent nodes and their child nodes are bi-directional. The counts of the sorted frequent items are kept in Header_Table of the FP-tree algorithm.

The present study extends the concepts of the FUFP-tree algorithm for efficiently mining sequential patterns in incremental mining. An incremental FUSP-tree algorithm is proposed to efficiently handle new transactions from both old and new customers. A fast updated sequential-pattern tree (FUSP-tree) the initial FUSP-tree. Like the FP-tree and FUFP-tree, only frequent items are used to build the tree to reduce its size. The complete customer sequences with only large items in the given databases are kept in the FUSP-tree. The advantage is that when frequent items are not changed, the approach does not need to rescan the original database; it can produce results from the FUSP-tree. The proposed incremen-tal FUSP-tree algorithm reduces the execution time of re-constructing the tree when new transactions are added. After the tree is maintained, the final frequent sequences (sequential patterns) are found by the designed FUSP-growth algorithm, which is similar to FP-growth-like approach [8]. Experimental results show that the proposed approach balances the trade-off between execution time and tree com-plexity. The proposed algorithm can be used in the web traversal patterns since the discovered patterns should be constantly updated when the new web data are inserted into the old ones. The designed algo-rithm can also provide the efficient marketing decisions in dynamic databases, such as advertisements recommendation, weather prediction, patient treatment sequences, behavior prediction, among others. In summary, the contributions of this paper are described below. 1. Traditional AprioriAll algorithm [4] processes the inserted transactions in a batch way. It is thus 2. The proposed algorithm can efficiently handle new transactions from both old and new customers. 3. In the proposed algorithm, only a small number of itemsets must be rescanned to maintain the 4. The number of generated tree nodes of the proposed algorithm is nearly the same as the batch
The remainder of this paper is organized as follows. Related work is reviewed in Section 2. The proposed FUSP-tree construction algorithm and the FUSP-growth mining algorithm are described in Section 3. An illustrative example is given in Section 4. Experimental results are given in Section 5. Conclusions are given in Section 6. 2. Review of related work
In this section works related to mining sequential patterns and the FUFP-tree algorithm are briefly reviewed. 2.1. Mining sequential patterns
Agrawal et al. first proposed a non-trivial algorithm called the AprioriAll algorithm for mining se-quential patterns level-by-level [4]. The algorithm first finds customer purchase sequences to predict whether there is a high probability that when customers buy some products, they will buy some other products in later transactions. Although customer behavior models can be efficiently extracted by the mining algorithm to assist managers in making correct decisions, the discovered sequential patterns may become invalid when new customer sequences are added. Some new sequential patterns may be gener-ated and some old ones may become invalid. Conventional approaches may re-mine the entire database to update the sequential patterns. When databases are large, however, considerable computation time is required to rescan them and re-mine the desired rules. An efficient approach for maintaining sequential patterns is thus desirable in real-world applications.
 Lin et al. thus proposed the FASTUP algorithm [19] to maintain sequential patterns by extending the FUP algorithm [7]. For an original database and some new customer sequences, the following four cases (illustrated in Fig. 1) may arise:  X  Case 1: A sequence is frequent both in the original database and new customer sequences.  X  Case 2: A sequence is frequent in the original database but not frequent in new customer sequences.  X  Case 3: A sequence is not frequent in the original database but frequent in new customer sequences.  X  Case 4: A sequence is not frequent both in the original database and in new customer sequences.
Since sequences in Case 1 are large in both the original database and new customer data, they will still be large after the weighted average of the counts. Similarly, sequences in Case 4 will still be small after the new customer sequences are added. Thus, Cases 1 and 4 will not affect the final large sequences. Case 2 may remove some existing large sequences, and Case 3 may add some new large sequences. A summary of the four cases and their FUP results is given in Table 1.

FASTUP is thus able to handle Cases 1, 2, and 4 more efficiently than conventional batch mining algorithms. If the sequences in Case 3 occur frequently, the performance of the FASTUP algorithm will decrease. Cheng et al. proposed the IncSpan (incremental mining of sequential patterns) algorithm for efficiently maintaining sequential patterns in a tree structure [6]. They used the frequent and semi-frequent sequences, which are similar to large and pre-large sequences in Hong et al. X  X  approach [10], to speed up the maintenance for items appended to old sequences, and used the IncSpan tree to store the frequent and semi-frequent sequences. Their approach does not generate the frequent sequences from the tree, as in the FP-tree approach, but instead uses the tree to maintain the frequent sequences. When new transactions are added, there are two possible cases:  X  Case 1: The new transactions involve old customers from the original database;  X  Case 2: The new transactions involve new customers not in the original database.

The IncSpan algorithm, however, only considers the first case, in which new transactions are appended to existing customer sequences. 2.2. FUFP-tree algorithm
In the past, many algorithms were proposed to efficiently mine the desired information from tree struc-capable answering the essential queries efficiently [17]. Han et al. proposed a FP-growth algorithm and designed the FP-tree structure to mine the frequent itemsets without the generation of candidates [8]. Hong et al. then extended the FP-tree structure to present a FUFP tree for transaction insertion in incre-mental mining [9].

The FUFP tree must be built in advance from the original database before new transactions are added [9]. When new transactions are added, the FUFP-tree incremental algorithm updates the FUFP-tree. It first partitions items into four parts according to whether they are large or small in the original database and the new transactions. Each part is then processed separately. Header_Table and the FUFP-tree are updated whenever necessary. In the process of updating the FUFP-tree, item deletion is done before item insertion. When an originally large item becomes small, it is directly removed from the FUFP-tree and its parent and child nodes are then linked together. In contrast, when an originally small item becomes large, it is added to the end of Header_Table and then inserted into the leaf nodes of the FUFP-tree. It is reasonable to insert the item at the end of Header_Table since when an originally small item becomes large due to the new transactions, its updated support is usually only a little larger than the minimum support. The FUFP-tree can thus be least updated in this way, greatly improving the per-formance of the FUFP-tree incremental algorithm. The entire FUFP-tree can then be re-constructed in a batch way when a sufficiently large number of transactions have been inserted. 3. Proposed incremental FUSP-tree approach
In this paper, the FUSP-tree structure is designed to store large 1-sequences. The frequent sequences (sequential patterns) are then derived from it. The concepts of the FUSP-tree are extended from both the FUFP-tree [9] and the IncSpan tree [6]. Based on the FUFP-tree, only the frequent items are stored in the FUSP-tree structure, thus making the tree structure condensed. The complete sequential patterns can be derived from the complete FUSP-tree without rescanning the original database. To process the incremental FUSP-tree algorithm, the FUSP-tree must be built in advance from the initial database before new transactions are added. A built FUSP-tree is shown in Fig. 2.

In Fig. 2, only the frequent items (1-itemsets) are stored in the tree structure. Like the IncSpan algo-rithm [6], the link between two connected nodes is marked by the symbol s (representing the sequence relation) if the sequence is within the sequence relation in a sequence; otherwise, the link is marked by the symbol i , which indicates the sequence is within the itemset relation in a sequence. Header_Table is used to find appropriate items or sequences in the tree. It sorts the frequent items initially in descending order. Infrequent items are not used to build the tree. The construction process is executed tuple by tu-ple, from the first customer sequence to the last one. After all the customer sequences are processed, the FUSP-tree is completely constructed. The FUSP-tree contains the complete customer sequences from the database. The flowchart of the proposed algorithm is shown in Fig. 3.

The notations used in the proposed incremental FUSP-tree algorithm and the FUSP-growth mining approach are listed below. 3.1. Notations D Original customer sequences ; T Newly inserted transactions ;
U All updated customer sequences ; d Number of customer sequences in D ; t Number of customer sequences in T ; q Number of new customers not in the original customer sequences ; I Item or itemset ; S Generated sequence ; S D ( I ) Number of occurrences of I in D ; S T ( I ) Number of occurrence increments of I in T ;
S U ( I ) Number of occurrences of I in U ; pool ( I ) Results for the combinations of processed I ; Branch_Items Set of 1-itemsets to be rescanned to build new branches in the FUSP-tree ;
Insert_Items Set of 1-itemsets for which the new transactions have to be reprocessed for updating Rescan_Items Set of 1-itemsets to be rescanned to get their supports in the original database . The details of the proposed incremental FUSP-tree algorithm are described below.
 Incremental FUSP-tree algorithm:
INPUT : An old database contains ( D ) customer sequences, its corresponding Header_Table OUTPUT : An updated FUSP tree for the updated database ( U ).
 BEGIN Procedure Scan the inserted transactions t to get all the 1-itemsets ( t_items ) and their counts. Increment the count of 1-itemset of the new customer, and set as 0 otherwise; END Procedure
After that, the final updated FUSP-tree is constructed. The newly inserted transactions can be inte-grated into the original database. Based on the FUSP-tree, the desired large sequences for the updated database can be determined using the proposed FUSP-growth approach. The procedure is as follows: FUSP-growth mining algorithm:
INPUT : An updated FUSP-tree ( FUSP_tree ) with its Header_Table ( Htable ), a support threshold OUTPUT : A set of large sequences LS ; BEGIN Procedure
END Procedure 4. An illustrative example 4.1. Incremental approach for maintaining the FUSP-tree
In this section, an example is given to illustrate the proposed incremental mining approach for fre-quent sequences based on the FUSP-tree. Table 2 shows the database used in the example. It contains 6 customer sequences and 9 items, denoted (A) to (I).

Assume that the minimum support threshold is set at 50%. For the given database, the large 1-itemsets are (A), (B), (D), and (E), from which Header_Table can be constructed. The FUSP-tree is then built from the database shown in Fig. 2. Assume that there are three newly inserted transactions, shown in Table 3. The proposed incremental mining algorithm for sequential patterns proceeds as follows.
In Table 3, only one transaction exists in the original database (Cust_id = 1); the other two transactions are from new customers (Cust_id = 7 and Cust_id = 8). The three new transactions are merged with the original database. The results are shown in Table 4.

The three newly inserted transactions are first scanned to get the 1-itemsets and their counts. The counts of the three newly inserted transactions are shown in Table 5.

The counts of the 1-itemsets in the newly inserted transactions are checked against with the minimum count. In this case, the minimum support threshold is set at 0.5. The minimum count for a 1-itemset to be large in the newly inserted transactions is thus 0.5  X  2( = 1). The 1-itemsets in Table 5 are divided into two parts, and the results are shown in Table 6.

The 1-itemsets which are large both in the newly inserted transactions and the original database are processed. In this example, 1-itemsets (A), (B), and (D) satisfy the condition and are processed. After that, Insert_Items = {A, B, D}.

The 1-itemsets which are small in newly inserted transactions but large in the original database are processed. In this example, only 1-itemset (E) satisfies the condition and is processed. In this example, 1-itemset (E) thus becomes small after the database is updated. 1-itemset (E) is thus removed from Header_Table. After that, Insert_Items = {A, B, D}. The updated FUSP-tree is shown in Fig. 4.
The 1-itemsets which are large in the newly inserted transactions but small in the original database (not appearing in Header_Table) are processed. In this example, 1-itemsets (G) and (H) satisfy the condition and are processed. After that, Insert_Items = {A,B,D,H}and Rescan_Items = {H}.
 The 1-itemsets in the set of Rescan_Items = {H} are sorted in descending order of their updated count. In this example, 1-itemset (H) is then inserted at the end of Header_Table. The corresponding branch is thus found with 1-itemset (H) from the original database. The results are shown in Table 7. After processing the corresponding branches in Table 7, the updated FUSP-tree and its corresponding Header_Table are shown in Fig. 5.

The FUSP-tree is updated according to the new transactions with 1-itemsets in Insert_Items .Inthis example, Insert_Items = {A, B, D, H}. The corresponding branches for the merged customer sequences with any of these 1-itemsets are shown in Table 8.

After processing the corresponding branch in Table 8, the final updated FUSP-tree and its correspond-ing Header_Table are shown in Fig. 6.

The three newly transactions are thus inserted and integrated with the original database. The construc-tion process of the FUSP-tree in incremental mining is done. The proposed FUSP-growth is then used to derive the large sequences from the FUSP-tree. An example is given below to illustrate the proposed FUSP-growth mining approach. 4.2. FUSP-growth mining approach
The 1-itemsets in Header_Table in Fig. 6 are processed one by one bottom-up. In this example, 1-itemset (H) is first processed. The corresponding node of 1-itemset (H) and its prefix paths are traced from the FUSP-tree. The corresponding branches of 1-itemset (H) are shown in Fig. 7.

The recursive approach for the prefix paths of the current processed node I are executed. In Fig. 7, (H) nodes can be found out together by the links between the nodes. In this example, the prefix path of the left branch in Fig. 7 is {(B:5)(A:4)} for node {(H:3)}; the recursive way is then processed to find the associated sequences, which are {(B)(H):3}, {(A)(H):3}, and {(B)(A)(H):3}. The derived three sequences are then put into pool ( H ). From the second branch of the right side in Fig. 7, the first node {(H:2)} with its prefix paths form the 2-sequences {(D)(H):2}. The second node in this branch {(H:1)} is then recursively processed. The results are generated as {(H)(H):1}, {(D)(H)(H):1}, {(D)(D)(H):1}, {(H)(D)(H):1}, and {(D)(H)(D)(H):1}. Note that the sequence {(D)(H)} is not calculated from the sec-ond node {(H:1)} since it has been already generated from this branch. The generated sequences of 1-itemset (H) are shown in Table 9.

In this example, the minimum count is set at (6 + 2)  X  0.5 ( = 4). Only large sequence {(H:5)} satisfies the condition. That is, the large sequence of 1-itemset (H) is {(H:5)}. The other 1-itemsets in Header_Table are processed in the same way as 1-itemset {(H)}. The results of the derived large sequences for all 1-itemsets in Header_Table are shown in Table 10. 5. Experimental results
Experiments were made to compare the performance of the AprioriAll algorithm [4], batch FUSP-tree algorithm, and the proposed incremental FUSP-tree algorithm. When new transactions are added, the AprioriAll algorithm and the batch FUSP-tree algorithm integrate them into the original database for mining large sequences from the updated database. The incremental FUSP-tree algorithm processes new transactions incrementally, as described in Sections 2.1 and 3. The experiments were coded in Java and performed on a computer with an Intel 2.6-GHz dual-core processor and 2 GB of RAM running the 32-bit Microsoft Windows XP operating system. The IBM data generator [12] was used to generate the sequence data S4I2N1KD25K in the experiments. The number of initial transactions for building the original FUSP-tree was set at 15,792. The value of the minimum threshold was set at 2.1% to 2.7% for the three algorithms in 0.1% increments. The execution times and the numbers of nodes obtained from the three algorithms were compared. Figures 8 to 14 show the execution times of the three algorithms for various minimum support thresholds. Note that the processed algorithms executed for six incremental times in their own way. 1,000 transactions were then sequentially inserted into the original database each time.
 Figures 8 to 14 show that the proposed incremental FUSP-tree algorithm is fastest. The incremental FUSP-tree algorithm has a higher probability of generating a less concise tree than that of the batch FUSP-tree algorithm since the later completely follows the sorted frequent items to build the tree. As mentioned above, when an originally small 1-itemset becomes large due to new transactions, its updated support is usually only a little larger than the minimum support. It is thus reasonable to put a new large item at the end of Header_Table. The difference between the batched FUSP-tree structure and the proposed incremental FUSP-tree structure will thus not be significant. The incremental FUSP-tree algorithm has a higher probability of generating a less concise tree since an original large 1-itemset becomes small due to new transactions. To show this effect, comparisons of the numbers of nodes for the three algorithms are given in Figs 15 to 21. The batch approach and the proposed algorithm generated trees with nearly the same sizes.

In the experimental results, it is obvious to see that the proposed incremental FUSP-tree algorithm can greatly reduce the rescanning time of the original database, comparing to the batch AprioriAll algorithm and the batch FUSP-tree approach. We have also found that the proposed incremental FUSP-tree algo-rithm can generate nearly the same number of tree nodes comparing to the batch FUSP algorithm. Thus, the proposed incremental FUSP-tree algorithm balances the trade-off between execution time and tree complexity. 6. Conclusion
This paper proposed an incremental FUSP-tree algorithm, including the construction and mining pro-cesses, to efficiently and effectively handle newly inserted transactions in incremental mining. The pro-posed incremental FUSP-tree algorithm can handle both newly inserted customer sequences and ap-pended sequences to old customers. When the added customer sequences contain old customers or new customers, the proposed incremental maintenance algorithm processes them to maintain the FUSP-tree. It first partitions 1-itemsets into four parts according to whether they are large or small in the original database and in the newly inserted transactions. Each part is processed separately. Header_Table and the FUSP-tree are correspondingly updated whenever necessary.

The FUSP-growth mining approach was proposed to derive the large sequences from the FUSP-tree structure. It inherits the properties of the FP-growth algorithm for recursively mining large sequences. Based on the proposed incremental FUSP-tree algorithm, the large sequences can be derived efficiently and effectively.

In real-world applications, transaction may be deleted or modified from the database. More efficient algorithms for handling the above issues will be developed in the future. Acknowledgments This research was partially supported by the Shenzhen Peacock Project, China, under grant KQC201109020055A, by the Natural Scientific Research Innovation Foundation in Harbin Institute of Technology under grant HIT.NSRIF.2014100, and by the Shenzhen Strategic Emerging Industries Program under grant ZDSY20120613125016389.
 References
