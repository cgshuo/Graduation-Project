 Statistical mac hine translation (SMT) has evolved from the initial word-based translation mo dels to more adv anced mo dels that tak e the con text sur-rounding the words into accoun t. The so-called phrase-based and N -gram-based mo dels are two ex-amples of these approac hes (Zens and Ney , 2004; Mari  X  no et al., 2006).

In curren t state-of-the-art SMT systems, the phrase-based or the N -gram-based mo dels are usu-ally the main features in a log-linear framew ork, rem-iniscen t of the maxim um entrop y mo deling approac h.
Tw o basic issues differen tiate the N -gram-based system from the phrase-based one: the training data is sequen tially segmen ted into bilingual units; and the probabilit y of these units is estimated as a bilin-gual N -gram language mo del. In the phrase-based mo del, no monotonicit y restriction is imp osed on the segmen tation and the probabilities are normally es-timated simply by relativ e frequencies.

This pap er extends the analysis of both systems performed in (Crego et al., 2005a) by additionally performing a man ual error analysis of both systems, whic h were the ones used by UPC and RWTH in the last Tc-St ar evaluation.

Furthermore, we will prop ose a way to com bine both systems in order to impro ve the qualit y of trans-lations.

Exp erimen ts com bining sev eral kinds of MT sys-tems have been presen ted in (Matuso v et al., 2006), based only on the single best output of eac h system. Recen tly, a more straigh tforw ard approac h of both systems has been performed in (Costa-juss` a et al., 2006) whic h simply selects, for eac h sen tence, one of the pro vided hypotheses.

This pap er is organized as follo ws. In section 2, we briefly describ e the phrase and the N -gram-based baseline systems. In the next section we presen t the evaluation framew ork. In Section 4 we rep ort a struc-tural comparison performed for both systems and, af-terw ards, in Section 5, we analyze the errors of both systems. Finally , in the last two sections we rescore and com bine both systems, and the obtained results are discussed. 2.1 Phrase-based System The basic idea of phrase-based translation is to seg-men t the given source sen tence into units (here called phrases), then translate eac h phrase and finally com-pose the target sen tence from these phrase transla-tions.

In order to train these phrase-based mo dels, an alignmen t between the source and target training sen tences is found by using the standard IBM mo d-els in both directions (source-to-target and target-to-source) and com bining the two obtained align-men ts. Giv en this alignmen t an extraction of con-tiguous phrases is carried out, specifically we extract all phrases that fulfill the follo wing restrictions: all source (target) words within the phrase are aligned only to target (source) words within the phrase.
The probabilit y of these phrases is normally esti-mated by relativ e frequencies, normally in both di-rections, whic h are then com bined in a log-linear way. 2.2 N -gram-based System In con trast with standard phrase-based approac hes, the N -gram translation mo del uses tuples as bilin-gual units whose probabilities are estimated as an N -gram language mo del (Mari  X  no et al., 2006). This mo del appro ximates the join t probabilit y between the source and target languages by using N -grams.
Giv en a word alignmen t, tuples define a unique and monotonic segmen tation of eac h bilingual sen-tence, building up a much smaller set of units than with phrases and allo wing N -gram estimation to accoun t for the history of the translation pro-cess (Mari  X  no et al., 2006). 2.3 Feature functions Both baseline systems are com bined in a log-linear way with sev eral additional feature functions: a tar-get language mo del, a forw ard and a bac kward lex-icon mo del and a word bonus are common features for both systems. The phrase-based system also in-troduces a phrase bonus mo del. The translation mo dels presen ted so far were the ones used by UPC and RWTH in the second evaluation campaign of the Tc-St ar pro ject. The goal of this pro ject is to build a speech-to-sp eech translation sys-tem that can deal with real life data.

The corpus consists of the official version of the speeches held in the Europ ean Parliamen t Plenary Sessions (EPPS), as available on the web page of the Europ ean Parliamen t. Table 1 sho ws some statistics.
The follo wing tools have been used for building both systems: Word alignmen ts were computed us-ing GIZA++ (Oc h, 2003), language mo dels were es-timated using the SRILM toolkit (Stolc ke, 2002), de-coding was carried out by the free available MARIE deco der (Crego et al., 2005b) and the optimization was performed through an in-house implemen tation of the simplex metho d (Nelder and Mead, 1965). Both approac hes aim at impro ving accuracy by in-cluding word con text in the mo del. However, the implemen tation of the mo dels are quite differen t and may pro duce variations in sev eral asp ects.
Table 2 sho ws the effect on deco ding time intro-duced through differen t settings of the beam size. Additionally , the num ber of available translation units is sho wn, corresp onding to num ber of avail-able phrases for the phrase-based system and 1gram, 2gram and 3gram entries for the N -gram-based sys-tem. Results are computed on the dev elopmen t set. Table 2: Impact on efficiency of the beam size in PB (top) and NB system (bottom).

As it can be seen, the num ber of translation units is similar in both tasks for both systems (537 k 537 k for Spanish to English and 594 k 651 k for English to Spanish) while the time consumed in de-coding is clearly higher for the phrase-based system. This can be explained by the fact that in the phrase-based approac h, the same translation can be hypoth-esized follo wing sev eral segmen tations of the input sen tence, as phrases app ear (and are collected) from multiple segmen tations of the training sen tence pairs. In other words, the searc h graph seems to be over-populated under the phrase-based approac h.
Table 3 sho ws the effect on translation accuracy regarding the size of the beam in the searc h. Results are computed on the test set for the phrase-based and N -gram-based systems.

Results of the N -gram-based system sho w that de-creasing the beam size pro duces a clear reduction of the accuracy results. The phrase-based system sho ws that accuracy results remain very similar un-der the differen t settings. The reason is found on how translation mo dels are used in the searc h. In the phrase-based approac h, every partial hypothesis Table 3: Impact on accuracy of the beam size in PB (top) and NB system (bottom). is scored uncon textualized, hence, a single score is used for a given partial hypothesis (phrase). In the N -gram-based approac h, the mo del is intrinsically con textualized, whic h means that eac h partial hy-pothesis (tuple) dep ends on the preceding sequence of tuples. Thus, if a bad sequence of tuples (bad scored) is comp osed of a good initial sequence (well scored), it is placed on top of the first stac ks (beam) and may cause the pruning of the rest of hypotheses. In order to better asses the qualit y and the differ-ences between the two systems, a human error anal-ysis was carried out. The guidelines for this error analysis can be found in (Vilar et al., 2006). We randomly selected 100 sen tences, whic h were evalu-ated by bilingual judges.

This analysis rev eals that both systems pro duce the same kind of errors in general. However some dif-ferences were iden tified. For the English to Spanish direction the greatest problem is the correct genera-tion of the righ t tense for verbs, with around 20% of all translation errors being of this kind. Reordering also poses an imp ortan t problem for both phrase and N-gram-based systems, with 18% or 15% (resp ec-tively) of the errors falling into this category . Miss-ing words is also an imp ortan t problem. However, most of them (appro ximately two thirds for both sys-tems) are filler words (i.e. words whic h do not con-vey meaning), that is, the meaning of the sen tence is preserv ed. The most remark able difference when comparing both systems is that the N -gram based system pro duces a relativ ely large amoun t of extra words (appro ximately 10%), while for the phrase-based system, this is only a minor problem (2% of the errors). In con trast the phrase-based system has more problems with incorrect translations, that is words for whic h a human can find a corresp ondence in the source text, but the translation is incorrect.
Similar conclusions can be dra wn for the inverse di-rection. The verb generating problem is not so acute in this translation direction due to the much simpli-fied morphology of English. An imp ortan t problem is the generation of the righ t prep osition.
The N -gram based system seems to be able to pro-duce more accurate translations (reflected by a lower percen tage of translation errors). However, it gener-ates too man y additional (and incorrect words) in the pro cess. The phrase-based system, in con trast, coun teracts this effect by pro ducing a more direct corresp ondence with the words presen t in the source sen tence at the cost of sometimes not being able to find the exact translation. Integration of both output translations in the searc h pro cedure is a complex task. Translation units of both mo dels are quite differen t and generation his-tories pose sev ere implemen tation difficulties. We prop ose a metho d for com bining the two systems at the level of N -best lists.

Some features that are useful for SMT are too com-plex for including them directly in the searc h pro-cess. A clear example are the features that require the entire target sen tence to be evaluated, as this is not compatible with the pruning and recom bination pro cedures that are necessary for keeping the target sen tence generation pro cess manageable. A possible solution for this problem is to apply sen tence level re-ranking by using N -best lists. 6.1 Rescoring Criteria The aim of the rescoring pro cedure is to choose the best translation candidate out of a given set of N possible translations. In our approac h this transla-tion candidates are pro duced indep enden tly by both of the systems and then com bined by a simple con-catenation 1 . In order for the hypothesis to have a comparable set of scores, we perform an additional  X  X ross-rescoring X  of the lists.

Giv en an N -best list of the phrase-based ( N -gram-based) system, we compute the cost of eac h target sen tence of this N -best list for the N -gram-based (phrase-based) system. However this computation is not possible in all cases. Table 4 sho ws the per-cen tage of target sen tences that the N -gram-based (phrase-based) system is able to pro duce given an N -best list of target sen tences computed by the phrase-based ( N -gram-based) system. This percen tage is calculated on the dev elopmen t set.

The vocabulary of phrases is bigger than the vo-cabulary of tuples, due to the fact that phrases are extracted from multiple segmen tations of the train-ing sen tence pairs. Hence, the num ber of sen tences repro duced by the N -gram-based system is smaller than the num ber of sen tences repro duced by the phrase-based system. Whenev er a sen tence can not be repro duced by a given system, the cost of the worst sen tence in the N -best list is assigned to it.
Table 4: Sen tences (%) pro duced by eac h system. 6.2 Results Table 5 sho ws results of the rescoring and system com bination exp erimen ts on the test set. The first two rows include results of systems non-rescored and PB (NB) rescored by NB (PB). The third row corre-sponds to the system com bination. Here, PB (NB) rescored by NB (PB) are simply merged and rank ed by rescored score.
 Table 5: Rescoring and system com bination results. The structural comparison has sho wn on the one hand that the N -gram-based system outp erforms the phrase-based in terms of searc h time efficiency by avoiding the overp opulation problem presen ted in the phrase-based approac h. On the other hand the phrase-based system sho ws a better performance when deco ding under a highly constrained searc h.
A detailed error analysis has also been carried out in order to better determine the differences in per-formance of both systems. The N -gram based sys-tem pro duced more accurate translations, but also a larger amoun t of extra (incorrect) words when com-pare to the phrase-based translation system.
In section 6 we have presen ted a system com bina-tion metho d using a rescoring feature for eac h SMT system, i.e. the N -gram-based feature for the phrase-based system and vice-v ersa. For both systems, con-sidering the feature of the opp osite system leads to an impro vemen t of BLEU score.
 M.R. Costa-juss` a, J.M. Crego, A. de Gisp ert, P. Lam bert, M. Khalilo v J.A.R. Fonollosa, J.B.
Mari  X  no, and R. Banc hs. 2006. Talp phrase-based statistical mac hine translation and talp system com bination the iwslt 2006. IWSL T06 .
 J. M. Crego, M. R. Costa-juss` a, J. Mari  X  no, and J. A.
Fonollosa. 2005a. N-gram-based versus phrase-based statistical mac hine translation. IWSL T05 , Octob er.
 J.M. Crego, J. Mari  X  no, and A. de Gisp ert. 2005b.
An Ngram-based statistical mac hine translation deco der. ICSLP05 , April.
 J.B. Mari  X  no, R.E. Banc hs, J.M. Crego, A. de Gis-pert, P. Lam bert, J.A.R. Fonollosa, and M.R.
Costa-juss` a. 2006. N-gram based mac hine trans-lation. Computational Linguistics , 32(4):527 X 549. E. Matuso v, N. Ueffing, and H. Ney . 2006. Com-puting consensus translation from multiple ma-chine translation systems using enhanced hypothe-ses alignmen t. EACL06 , pages 33 X 40.
 J.A. Nelder and R. Mead. 1965. A simplex metho d for function minimization. The Computer Journal , 7:308 X 313.
 F.J. Och. 2003. Giza++ soft ware. http://www-i6.informatik.rwth-aac hen.de/  X o ch/ soft-ware/giza++.h tml.
 A. Stolc ke. 2002. Srilm -an extensible language mo deling toolkit. Proc. of the 7th Int. Conf. on
Spoken Language Processing, ICSLP X 02 , Septem-ber.
 David Vilar, Jia Xu, Luis Fernando D X  X aro, and Hermann Ney . 2006. Error Analysis of Mac hine Translation Output. In LREC06 , pages 697 X 702, Genoa, Italy , Ma y.
 Ric hard Zens and Hermann Ney . 2004. Impro ve-men ts in phrase-based statistical mac hine transla-tion. In HLT04 , pages 257 X 264, Boston, MA, Ma y.
