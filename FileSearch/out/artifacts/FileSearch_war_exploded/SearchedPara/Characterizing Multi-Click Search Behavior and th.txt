 Although searchers often click on more than one result following a query, little is known about how th ey interact with search results after their first click. Using large scale query log analysis, we characterize what people do when they return to a result page after having visited an initial result. We find that the initial click pro-vides insight into the searcher X  X  subsequent behavior, with short initial dwell times s uggesting more future interaction and later clicks occurring close in rank to th e first. Although users think of a search result list as static, when people return to a result list following a click there is the opportunity for the list to change, potentially providing additional re levant content. Such change, however, can be confusing, lead ing to increased abandonment and slower subsequent clicks. We ex plore the risks and opportunities of changing search results during use, observing, for example, that when results change above a user X  X  initial click that user is less likely to find new content, whereas changes below correlate with increased subsequent interaction. Our results can be used to im-prove people X  X  search experience during the course of a single query by seamlessly providing new, more relevant content as the user interacts with a search result page, helping them find what they are looking for without having to issue a new query. H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval  X  Search process .
 Log analysis; web search; result list change; search dynamics. Many queries involve multiple search result clicks. Previous re-search found that for queries wher e at least one search result was clicked, 46% contained addition al clicks [12]. Since 2003 this number appears to have grown, with multi-click queries now rep-resenting 59% of the clicked queri es in our dataset. There are many reasons why searchers might click multiple results. They may, for example, have trouble finding what they are looking for and thus visit multiple results w ith limited success, or they may have a need that cannot be satis fied by a single result [8]. Despite the prevalence of multiple clicks after a query, much of the research to understand search result interaction has focused on user behavior surrounding the first click. An accurate picture of behavior when many results are clicked could positively impact everything from the retrieval models people build to how search engines are evaluated. This paper presents the first study that we are aware of that characterizes what people do within a single query when they return to a sear ch result page af ter having visited an initial result. We find that people X  X  initial interaction with the result page, including what they click and how long they dwell, significantly impacts their future interactions with those results. While searchers think of search result lists as static, the results for a single query actually often change over time [14, 19], even after very short intervals such as the time between when a user visits a clicked search result and when that user returns to identify a sec-ond result to click. Previous research has shown that change inter-feres with a person X  X  ability to interact with the results during repeat queries [25]. This paper l ooks at the impact of short term search result change on user behavior during multi-click queries. We find that when changes occur during the course of a single query, they interfere with the searcher X  X  ability to find new infor-mation, leading to increased ab andonment and slower clicks. However, search result change presents not just a risk, but also an opportunity for the search engine to provide new, more relevant information without additional input from the user. While changes to a search result list sometimes happens as a result of unexpected instability (e.g., concurrent indexing [14]), change can also hap-pen as the result of intentionally designed features. For example, it is not always possible for a search engine to identify the most relevant content immediately after a query is issued. The implicit feedback users provide as they search can be incorporated in real time to produce a bett er ranking [15, 27, 28]. New content may also become available as the web changes [1], or search engines may want to take more than a few hundred milliseconds to pro-cess complex queries [26]. The ability to provide some results initially, and then change the results as new information becomes available could enable search engines to significantly and seam-lessly improve the search experience. In our analysis we observe that there are cases where change leads to greater satisfaction, and explore one way to take advantag e of this opportunity to positive-ly impact millio ns of users. The goal of this paper is to provide in-depth picture of the rela-tionship between the first and s ubsequent clicks following a que-ry, with a focus on instances where the result page changes in between. After a discussion of rela ted work, we describe the ap-proach we use to understand multi-click behavior. We then char-acterize how people interact with results after their first click, and look at the impact of change on this behavior. We conclude with a discussion of how our findings can be used to provide new con-tent as a person searches, and implement and explore an example. Understanding people X  X  search beha vior is critical to improving the search experience, and substantial effort has been invested to this end. Large scale search logs provide an invaluable picture that can be used to estimate things like search success and result rele-vance. Previous research has formalized the task of relevance learning as a click modeling pr oblem using assumptions about general user behavior. Position bi as (where top ranked documents attract more attention, even wh en less relevant) is a well-known example [12]. The ex amination hypothesis [6] suggests that a document is relevant only if it is examined and clicked. Based on this hypothesis, many extensions have developed sophisticated ways to model user behavior [5, 29] . It is often assumed that users examine results from top to bottom without skipping, as is the case with the cascade model [6]. Wh ile this assumption is general-ly effective, people X  X  search behavior can be more complicated. This motivates subsequent work [4, 10, 11] that emphasizes mod-eling multiple clicks after a si ngle query. Recent studies go be-yond the examination hypothesis to consider the impact of lower ranked documents on clicks [22]. While existing research shows how characterizations of user be-havior can be used to improve search, very little is understood about multi-click behavior beyond the fact that it exists. Previous research suggests 46% of clicked queries have more than one search result click [12]. Despite the fact that multi-click behavior is not well understood, it has been explored as a way to improve ranking and relevance estimates. As a form of implicit feedback, Agichtein et al. [2] used post-click behavior (among other fea-tures) to optimize the ranker effe ctiveness, and Zhong et al. [30] proposed a Bayesian approach to incorporate post-click features for estimating documen t relevance. These models have been shown to improve document ranking, but relatively little can be learned from them about how and wh y users interact with search results and how search result pr esentation impacts user behavior. A particularly unique aspect of our analysis is that we look at what happens when search results change as the user interacts with them. Although users are typi cally not aware of it, results regularly change [14, 19]. Change can occur unintentionally, as an artifact of server side variation, such as the contents of the cache or which back end index is hit [14]. It can also reflect changes to the underlying web [1], with new content identified and changes to existing content impacting ranki ng. Or it can be a result of per-sonalization and contextualization, with new, more relevant con-tent identified via implicit releva nce feedback and provided to the users as they interact with search results. For example, SurfCan-yon dynamically updates the search result list as users interact with it [15], and White et al. explored providing users with a dy-namic list of relevant sentences as they searched [27]. Researchers of human-computer in teraction have long known that interface instability can cause problems, even when change seems beneficial. For exampl e, dynamic menus were developed to help people access menu items more quick ly than traditional menus by bubbling commonly accessed items to the top. Rather than de-creasing access time, however, dy namic menus slow users down as commonly sought items no longer appear where expected [21]. Similar problems result from instability for search results [17]. For example, White et al. [27] tried to help people search by dy-namically re-ranking lists of rele vant sentences using implicit feedback, and found that people did not perform as well with a dynamic list as they did when it was static. This is probably be-cause, as Selberg and Etzioni [19] state,  X  X nstable search engine results are counter-intuitive for the average user, leading to poten-tial confusion and frustration when trying to reproduce the results of previous searches. X  Teevan et al. [25] present the only log study that we are aware of on the impact of search result change on user behavior. They find that searchers take significantly long-er to click on a repeat search result following change. We extend this work by providing a detailed look at interaction with results that change within a single query, rather than across sessions. Becaus e searchers may value having new information presented in the course of a single query, several solutions have tried to ad-dress the fact that dynamic search results can cause problems. For example, SurfCanyon attempts to avoid confusion while providing real time implicit relevance feedback by highlighting new results in a separate location [15]. Howe ver, this approach calls out changes at a time when most users are merely focused on finding what they are looking for. The Re :Search Engine tries to avoid this by merging new content into an existing search result list [24]. While the solution shows pr omise, it has only been studied in a laboratory setting on a small scale. In addition to using log analysis to characterize how people interact with change, we pro-pose providing users with new content when they return to a result page while maintaining stability in the results they have seen, and run a preliminary test of this ap proach with millions of users. In summary, the work presented in this paper extends existing models of search result interact ion by focusing specifically on how people behave when they return to a search result page after their first search result click. Because search results can change, even as they are being used, we look carefully at the impact of such changes, and suggest and test one potential solution. We now describe how the analysis presented in this paper was performed. We describe the dataset, formalize the problem, and define the measures we study, including behavior-based measures of search success and measures of search result change. To understand how people interact with search results for multi-click queries, we analyzed logs collected by Microsoft X  X  Bing search engine. We sampled two months of log data from 2012 for users in the United States Engl ish language locale. The sample was filtered to remove bots, spam, and outliers (e.g., queries fol-lowed by more than 20 clicks or result lists with more than 14 search results). We also removed adult and navigational queries because these query types have very unique behavior following the first click. Navigational queries, for example, are typically followed by only one click. For each query, the logs contain in-formation about when the query wa s issued and the URL and rank of any clicked results. Using this we extracted the subset of in-stances where a query was issued, a result was clicked, and the user returned to the result page following the click. The resulting dataset contains 8,863,684 queries and 17,154,920 clicks from 1,658,931 distinct users. The dataset also includes 17,72 7,368 impressions of the results displayed to the user, half representing the result list seen before clicking, and half representing the list seen when returning from an initial click. The results provided by all major search engines change over time [14, 19], and change can occur even during the course of a single query. In such cases the results shown after the user returns to a result page foll owing a click are different from those displayed prior. Changes may arise from instability (includ-ing the dynamic nature of the web and the complex architectures of search engines [14]) or be intentional. For example, in the logs we analyze in this paper Bing disp layed, by design, eight results to the user following their initial query, and twelve when the user returned. In each case, the results were ranked according the best information available to the search engine at that instant. Changes like those observed in our logs ar e prevalent for top search en-gines [14, 19], although most users are not aware of them. Using this dataset, we character ize the behavior of users who clicked a search result following a query, visited the clicked result for some period of time, and then returned to the search result page. When the search result page is presented to the user for a second time, we study a wide range of characteristics of the inter-actions that the users might have with it. To formulate the problem, we specify a general scenario tuple  X  : The first part of the tuple,  X  , X  X   X   X ,  X  user issued a query  X  , viewed a search result page  X   X  to  X  , and then clicked the result  X   X  that the user then used the back button or some other means (e.g., the refresh button) to return to the search result page. When this happens, a search result page for  X  is once again presented to the can also be differences between them. These differences are de-noted as the second part of the tuple,  X   X  interactions with the results for  X  other than the first click occur with  X   X  since after the first click Bing instructs the browser to keep the search result page in its cache. Given the scenario tuple  X  , we characterize user behavior with the second search result page (  X   X  ) by asking: 1. Which factors from  X  impact user behavior with  X   X  and 2. How do changes to the result page (  X   X  In Section 4 we address the first question, using the first part of the scenario tuple to study the impact of the user X  X  issued query and initial click on their subsequent behavior. In Section 5 we address the second question, using the second part of the tuple to characterize how the system appears to influence a user X  X  interac-tion with  X   X  by changing or holding stable the search result list. In our analysis we use several behavior-based measures of search success and search result change. Standard statistical analysis including confidence interval and z-test were conducted on these measures where appropriate and when the two means derived from two populations were compared. We look at four common measures of search success: the number of clicks, click satisfaction, cl ick position, and time to click. Number of clicks One way to understand a us er X  X  search experi-ence is to look at the number of clicks that a user makes following a query. In particular, researchers have explored this using aban-donment , which is a measure of how likely a searcher is to not click on any result at all following a query. While abandonment can indicate a positive search inte raction when the searcher finds what they are looking for directly within a search result page [16], the absence of a click is generally taken as an indication that the user has failed to find relevant content [4]. All of the queries in our sample are filtered to have at least one click, meaning abandonment fro m the first result page,  X  Because we are interested in users X  interactions with  X   X  return following a click, we study abandonment of  X   X  . This behav-ior is unlikely to indicate a positive experience because any rele-vant inline content was probably seen prior to the initial click. Satisfaction Another way to measure a user X  X  success during a search is to look at time spent on th e visited result pages. Previous research has found that implicit signals such as clicks, time, and end user action are good predictors of satisfaction [8], with a dwell time of 30 seconds on a re sult commonly used to indicate satisfaction. We refer to clicks with dwell times of 30 seconds or longer as SAT clicks , and those with shorter dwell times as NSAT clicks . Due to the limitation of event-based logging, it is impossi-ble to calculate the dwell time of the last click in a search session because there is no subsequent event. For precision, we only con-sider clicks where the dwell time can be calculated accurately. A little over half (59%) of the initial clicks on  X   X  in our subsample are SAT clicks. Occasionally, for si mplicity, we will refer to users who had a SAT initial click (  X   X  into our analysis of  X   X  already satisfied, and users who had a bad start (or an NSAT initial click) as NSAT users . Regardless of their initial experience, users who return to a result list after an initial click are probably trying to find additional relevant information. To measure how often this happens successfully, we look at whether any subsequent clicks for that query are SAT clicks. If at least one click is a SAT click, we call it a SAT return . The ratio of the number of SAT returns to the number of NSAT returns pro-vides a picture of how many more times the return experience is satisfactory versus unsatisfactory. The larger the value, the more satisfied users are. We refer to this satisfaction ratio as  X  Click Position The position of a clicked result can also provide insight into the search experience. Typically, the higher a result click is in a search result list, the better the list is considered to be [13]. People also trust that releva nt results are highly ranked, and thus have a positional bias towards clicking higher [9]. Consistent with this previous work, the firs t clicks for a majority (51%) of the queries in our sample are on the first result. Commonly under-stood assumptions about click position, however, do not neces-sarily hold true for the second a nd subsequent clicks, since the user is likely to be oriented to th e search results in a different way. All users in our sample clicked one initial result on  X   X  more results on  X   X  . We define three possible changes in click position between two consecutive clic ks: the user can click higher in a result list than they originally did ( Up ), click the same posi-tion in both lists ( Stay ), or click lower the second time ( Down ). Thus the set of possible click patterns is  X  X  X  X  X , X  X  X  X , X  X  X  X  X  X  . The position of the initial click affects the possible subsequent behavior. For example, Up clicks can only occur when the first click is not on the first result in  X   X  , and Down can only occur when the initial click is not the lowest ranked result in  X  measure the probability of each pattern occurring in the logs: Time to Click The time between when a user is first presented with a search result list and when th at user clicks a result for the first time provides an indication of how hard it is to locate a result to click. We refer to the time it takes a user to make their first click as  X   X  their second click as  X   X  In addition to changes in search result interaction before and after the first click, we also measure changes to the results presented. We study the impact of two differe nt types of change, illustrated in Figure 1. In the first (top of Figure 1) we look at instances where the position of the search result initially clicked changes between when the result page is first presented (  X   X  ) and when it is next presented (  X   X  ). In the second (bottom of Figure 1), we look at instances where the other results on the result page change given the initial click remained in the same position. We parameterize  X   X  X   X  in terms of the two result pages displayed to the user for the query  X  (  X   X  and  X   X  ) and the initial click  X   X  Change in Ranking of the Clicked Result A positional change of the first result clicked can be important, as previous research suggests that people are particular ly likely to remember where the results they clicked appear in a search result list [23]. When a user clicks on a search result and then returns to the result list to look for additional results, the result that was clicked initially (  X  appear in the same place (which we refer to as Stay ), or be ranked closer to the top (which we refer to as Up ) or lower ( Down ). It can also disappear entirely ( Gone ). These changes are represented as the top set of changes in Figure 1. All of these types of change occurred in our dataset; for 62% of the queries we sampled, the initially clicked result stayed in the same position, for 14% it moved up, for 23% it moved down, and for 1% it disappeared. Change in Ranking of the Other Results We also look at the impact of changes that occur between  X   X  and  X   X  that do not impact the position of the clicked result. These are represented in the bottom part of Figure 1. To avoid confounding such changes with changes to the initially click result X  X  position, we only look at the 62% instances where the clicked result stays in exactly the same place (referred to as Stay earlier). The other results can either change above that click ( Above ) or below it ( Below ) . We consider a change to have occurred if any results occur in a different posi-tion from where they occurred in  X   X  or do not appear at all. Eight-een percent of the queries had a change above and 94% below. Because changes to the result immediately preceding or following the initial click may be particular ly noticeable, we also look spe-cifically at changes to these (referred to as Above1 or Below1 ). The position of the initial click affects the types of changes that can be observed. For example, the initial click is very likely to be on the first search result, and in these cases it is impossible for the search results above where the click occurred to change. Like-wise, if the initial click is on the last search result, results below can only change if new results are added to the result list. We use the entire dataset when analyzing the effect of changes in position to the initial click, but only use the instances that can be defined for analysis for changes to the rest of the search result page. We begin our analysis by looking at how characteristics of a us-er X  X  initial interaction with a result list relates to their subsequent interactions. Regardless of any ch anges that may have occurred to the result ranking, we explore how many results people click when they return, whether the results they click satisfy their need, the position of their clicks, and the time it takes to make a click. The median number of results user s clicked following their initial click was one, meaning the median number of clicks for queries in our sample was two. This is higher than typically observed in the literature because we only analyzed queries that had at least one click and for which the user had returned to the search result page following that click. Abandonment of  X   X  (or clicking no results upon returning) indicates that the us er has failed to find new rele-vant content. The probability of abandoning the search result fol-lowing the first click but after returning to the result list was 0.41. Users who were satisfied with their initial click seemed to put less effort into finding additional relevant results upon returning. Fig-ure 2 plots the probability that users would click a certain number of results on  X   X  , broken down by whether the initial click (  X  was satisfactory (SAT) or not (N SAT). SAT users abandoned with a probability of 0.43, or 11% more than NSAT users (0.39), with 99% confidence interval (CI) from 0.0391 to 0.0409 for the dif-ference between the two means. Users who were unsatisfied ini-tially also tended to click more re sults than SAT users. The medi-an number of clicks for NSAT users was one, and zero for SAT users. This may imply that satisf ied users have si gnificantly less ( p &lt; .0001) motivation to find additional relevant content because they already found something useful. Subsequent click behavior also appears to be impacted by the position of the initial click, as can be seen in Figure 3. The proba-Figure 2. The probab ility a user will click a certain number of results on  X   X  after an initial click. Users who were satisfied 
Figure 3. The probability of ab andoning upon returning as a function of different initial click positions. The lower the ini-
Figure 1. The types of search change studied, including in-stances where the clicked result changes rank (top) and where it remains static but the results around it change (bottom). bility of abandoning  X   X  generally grows as the first click moves lower, from 0.39 when the second resu lt is the first clicked to 0.54 when the tenth result is. The difference in abandonment between position 2 and 10 for SAT and NSAT users is significantly differ-ent with a p -value &lt; .0001 and 99% CI (0.1396, 0.1604) for the two mean differences. A lower initia l click is usually considered indicative of lower result quality, and this may be why users are less likely to find new relevant content upon returning. However, the probability of abandonment is also relatively higher (0.43) when the first click is on the first result. These queries may be ones where the user is particularly satisfied and thus is less likely to put significant effort in to continuing their search. We also look at how satisfied users were with the results they found upon returning. Approximately 64% of the first clicks on  X  (i.e., second clicks ove rall) were SAT clicks. However, any click on  X   X  may result in satisfaction, not just the first. We observe that for 76% of queries that have subs equent clicks, at least one was a SAT click. As was the case for general click behavior, two factors emerge as being particularly likely to correlate with one or more SAT clicks on  X   X  : the user X  X  satisfaction with their initial click, and that click X  X  position in the result list. Regarding the first point, although users who were satisfied w ith their first click tended to be more likely to abandon the results after their first click, they also seemed to be satisfied with newly clicked results more often than NSAT users, assuming they clicked on something. Specifi-cally, we find that SAT users had a satisfaction ratio (  X  4.75, compared to 2.10 for NSAT users. In these cases the result quality may be high, or perhaps the user or task easily satisfied. Secondly, although users were mo re likely to abandon their query when their initial click was ranked lower, they were also more likely to be satisfied by subseque nt clicks. Figure 4 shows that lower initial click positions had hi gher satisfaction ratios. As we will show in Section 4.3, a lower initial click also tended to be followed by higher subsequent c licks, and it may be these higher ranked results were indeed more relevant even though they were initially skipped. Likewise, user s who start out clicking high are more likely to follow up with lower ranked clicks, which are pre-sumably less relevant and thus less likely to be satisfactory. We now look at the position of the clicked results as a function of when the click occurred. Figure 5 shows the positional probability distribution for the first 10 clicks following a query, with C i rep-resenting how likely the i th click was to occur at each position. Note that only the first click (C1=  X   X  clicks (C2 to C10) took place on  X   X  . As expected, the first click is most likely to be on the first result. For the subsequent clicks, however, the peak of the i th click is at position  X  . This is consistent with a general trend of progressing down the result se t linearly, as observed previously via analysis of search [3] and gaze logs [7, 9, 13]. However, the top positions (pos itions 1 to 3) become relative-ly popular again compared to other positions among later clicks (see C6-10). It appears that users sometimes return to the begin-ning of the list after having actively clicked on many results. Table 1 summarizes how a user X  X  in itial interactions with the re-sult list impacted whether they clicked higher or lower in  X  in  X   X  . As suggested by the progression of clicks in Figure 5, users were most likely to move down the result list after returning to it, with 65.4% of all second clicks being lower than the first. How-ever, 16.0% of all users clicked at the same position (sometimes on a new result, if the initial result changes rank), and 18.6% clicked higher. For subsequent pa irs of consecutive clicks, when they occurred, there was a tendency for  X  X  X  X  X   X  X  X  to increase and  X  X  X  X  X  X  X  X  X  X  to decrease, especially for later clicks. When this analysis is broken down by whether the user was satis-fied by their initial click or not, we see that satisfied users were 1.37 times more likely to stay on the same result (  X   X   X  X  X  X  X  X   X  ) than NSAT users (18.1% v. 12.2%, p &lt; .0001). It appears short-time re-finding behavior [25] is pa rticularly common for satisfied users, perhaps because the clicked result is indeed the current best for the user. We also see in Table 1 that the initial position of the first click affects the landing pos ition of the second click. Users starting with a lower initial clic k (e.g., at position 5) choose to click higher results more often than lower results. While clicking results from top to bottom is usually believed to be more natural, a reverse click order (i.e.,  X  X  X  X  ) may indicate a difficult search. We also analyzed how far users moved in the result list between clicks. Follow-up clicks tended to occur close in rank to the previ-ous click, with a median distance of one between two consecutive 
Figure 4. Satisfaction ratio gi ven initial click position. Users who click lower are more likely to be satisfied when returning.
Table 1. The likelihood that the position of the second click was above, the same as, or below the first click. Users tend to move down the result list, except wh en the initial click was low. click is most likely to be on the i th result. clicks. However, clicks that occurred low in the result list were more likely to be followed by a large move in position. Figure 6 shows the average absolute value of the positional difference be-tween consecutive clicks, with different lines representing differ-ent initial click positions. It may be that hard queries, where users click low ranked results, cause us ers to expend more effort scan-ning for relevant results. We also observe that, as reflected by the distance between two clicks, users appear to search conservatively in the beginning, jumping around in the middle, and finally focus for later clicks. This is consistent across different initial positions. The time it takes for a user to click a result tells us how quickly that user is able find what they are looking for. We observe that it took longer to make the first click (  X   X  9.66) than the second (  X   X  that users learned something a bout the search result list during their initial interaction. Consistent with this, we observe that users who spent more time inspecting the search result list prior to their first click were more likely to make their second click relatively faster than their first. Figure 7 shows  X   X  general (All),  X   X  We further break the data down by the user X  X  satisfaction with their initial click. Users took 28.6% longer to make their first click when they found a satisfactory result than an unsatisfactory one (median 10.75 seconds v. 8.36). It may be that spending more time reading prior to clicking helps users find better results. It may also be that these are slower users in general, and it takes more time for them to both click and return. As shown in Figure 7, initially SAT users also spent more time reading results before clicking a second time. This may be part of the reason why these users are also usually more satisfie d with their subsequent clicks. Next we look at the impact of the initial click positions on the time to the second click, shown in Figure 8 for initial click posi-tions of one through five. Not surprisi ngly, the time to first click is usually longer for lower initial pos itions, as users at least need to locate the result before clicking it. For example, the median of  X  for Pos=1 is 6.75 seconds and for Pos=5 is 19.23 seconds. How-ever, a higher initial click also seems to lead to a longer time to click the second result, perhaps because users have spent less time inspecting the other results in the list. The trend reverses when  X  is longer than approximately 14 seconds. These may represent hard queries where the user inspects all results before clicking. We showed that a user X  X  interaction with a result page following a click is strongly influenced by features of their initial interaction. Users who appeared satisfied with the first result they found were less likely to identify new content to visit, but more likely to be satisfied with the new content if they did. We confirm that users in general click results from top to bottom of a ranked list, but observe that top ranked positions regain their relative popularity for later clicks. The user X  X  initial click position can affect the dis-tance between consecutive clicks, w ith lower initial clicks result-ing in a larger gap between two consecutive clicks. People X  X  sec-ond click tended to occur faster than the first, and satisfied users usually spent more time read ing results before clicking. In addition to changes in search result interaction before and after the first click, there can also be changes to the underlying search results that are presented. We now look at different types of change correlate with post-click behavior. We begin by looking at the relationship of change to the number of clicks a user made following their initial click, focusing on abandonment, and observe that ch ange often preceded high aban-donment. Table 2 shows the probability of abandonment as a function of whether the initial click,  X   X  list, stayed in the same place, moved down, or disappeared entire-
Figure 6. The distance between two consecutive clicks for dif-ferent initial positions. C i :C j represent the i th and j th click. 
Figure 7. Time to click  X   X  as a function of time to click  X  second click tends to occur faster, particularly for NSAT users.
Figure 8. Time to click  X   X  as a function of time to click  X  ers who click on a top ranked result quickly need more time to 
Table 2. The probability of aba ndonment by whether the result initially clicked moved up, down, stayed in the same place, or disappeared. Users abandoned most when it disappeared. 
Table 3. The probability of ab andonment for changes in the search result list above or belo w initial click, given the clicked result X  X  position remains the same. Users abandon more when results above change, and less when results below change. ly. The probability of abandonment is particularly high when  X  disappeared from the list. For example, 0.492 for Gone is signifi-cantly higher than 0.425 for Stay with a p -value &lt; .0001 and 99% CI (0.0628, 0.0712). It may be that when users return to a result page they expect to see the link they followed as a colored link, and its absence could be confus ing. On the other hand, if  X  ranked lower in  X   X  than it was in  X   X  , we observe a lower aban-donment probability than if it stayed in the same place. These trends are consistent when beha vior was partitioned by whether the user was satisfied with the initial result they found or not. We also looked at the abandonment rate when the result list changed but the initially clicked result remained static (Table 3). Changing results above the init ial click (Above) led to higher abandonment, while changing re sults below the initial click (Below) led to lower abandonment. This was also true when the result immediately before (Above1) or after (Below1) the clicked result changed. All pairwise comparisons between different groups of users suggest that change in result ranking significantly impact user response ( p &lt; .0001). As we have seen that people often progress through the result page, it may be that changing results that have already been viewed causes confusion. Changing the results below the initial click, on the other hand, appears bene-ficial. We observe similar behavi or when breaking the data down by users X  initial satisfaction. The increase in abandonment following change suggests most change can interfere with a search, particularly when the clicked result disappears or change occurs high in the result list. However, when we look at user satisfaction, we see that change can some-times help the user find new relevant content, particularly if they were unable to find what they were looking for initially. Table 4 shows the satisfaction ratio when changes occur to the ranking of the initial click. For users who were not satisfied with their initial click, moving an NSAT result up the list correlated with the least subsequent satisfaction, while removing it correlated with the highest. Promoting an unsatisfyi ng result harms the user experi-ence, while moving it down or removing it improves the user experience as long as the user does not abandon the search. In contrast, users who found a result that satisfied them on their first click were most likely to be satis fied on subsequent clicks if the result stayed in the same place. Consistent with what we observed for abandonment, removing the link a satisfied user liked provided the worst experience. Table 5 shows the satisfaction ratio when the search result list changed but the initially clicked result remained in the same place. As we saw with abandonmen t, result changes that happened below the initial click appear to be beneficial, resulting in a higher satisfaction ratio for both SAT a nd NSAT users. However, unlike abandonment (where users were more likely to abandon if the results above the click changed), the satisfaction ratio for users not satisfied with their initial click went up even with changes above their click. Change high in the result list may help unsatis-fied searchers, as long as they do not abandon their search. In addition to relating to whethe r users abandon or find relevant content upon returning to a result page, change also correlates with where users focus their attention, as evidenced by how changes impact the position of thei r second click. When the result initially clicked moves up or the re sults above the click change we see that the next click occurs high er in the list. Table 6 shows how the position of a user X  X  second click changes compared to the position of the first given a change in rank of the initially clicked result. Consistent with what we observed in Section 4.3, users are most likely to progress down the result page with their clicks when the initially clicked result remains in the same position or moves down in rank. However, if the initially clicked result moves up in rank or disappears from the list, the user is signifi-cantly ( p &lt; .0001) more likely to click higher in the result list for the second click (37.64%) than if the result stayed in the same place (15.02%) or moved down (16.71%). It may be that users orient themselves around their previous click while progressing through a result page. We also analyzed how changes above and below the clicked result relate to changes in the position of the user X  X  subsequent clicks (Table 7). Changes above the initia l click appeared to attract us-ers X  attention, significantly ( p &lt; .0001) increasing the likelihood they clicked results above (46.26%) compared to when those re-sults remained static (38.65%). Ch anges below the initial click, on the other hand, had a smaller impact on click positi on. Results for Above1 and Below1 are very similar and thus omitted. Our analysis also suggests that changing results may slow users down as they try to find new results to click upon returning. To illustrate this, we plot the time to the second click (  X  tion of the time to the first click (  X   X  whether the user X  X  initial click changed rank or stayed in the same position. In all cases, people were able to click a second result fastest when their search result was shown in the same place. Consistent with what we observe d in our earlier analyses, when 
Table 4. The satisfaction ratio by whether the clicked result moved up, stayed, moved down, or disappeared. While SAT users like it to remain static, NSAT users prefer it removed. 
Table 5. The satisfaction ratio for changes in the result list above or below the firs t click. Users tend to be more satisfied when results change, although users who were satisfied with the first result they found want the res ults above it to remain static.
Table 6. The change in click position as a function of how the rank of the first clicked result changes. Users tend to progress down the page, but are more likely to move up the page when 
Table 7. The change in click position as a function of how the search results changed around the initial click. Users tend to progress down the page, but are more likely to move up when the result disappears entirely it correlated with a particularly large delay. However, while a clicke d result moving up suggests in-creased abandonment and decreased satisfaction, it also delays the second click the least. It may be that since people tend to remem-ber clicked results as having been ranked higher than they were [23], result lists with this type of change appear very similar. Figure 10 shows the same graph for instances where the initial click remained in the same position and the results above and below changed. In both cases change delayed  X   X  the static case, although changing the results below did so to a lesser extent. This is consistent with our previous findings that suggest lower changes are less disruptive. We have seen conflicting evidence as to whether search result change during a single query benef its or harms the user experi-ence, suggesting there are both risks and opportunities to provid-ing dynamic results. For users who were satisfied with their initial click, changing the result page appears primarily to cause harm; these users mostly preferred the page to be static, except for changes to results below their initial click. In contrast, users who were not satisfied by their initial click appear more likely to bene-fit from change. Even seemingly si gnificant search result changes, such as the removal of the first clicked result, sometimes im-proved these users X  satisfaction. Although change is potentially beneficial under certain conditions, it should be introduced care-fully because along with the incr eased satisfaction often comes the risk of increased aba ndonment and time to click. The analysis presented in this pa per paints a rich picture of multi-click search behavior, particularly in the context of search result change. These findings can be used to model user behavior better and improve the search experience. In general, we observe that relevance alone is not the only cr iteria that should be considered by search engines for multi-click queries. Instead, search engines must account for the user X  X  previous experience with the search results. In this section, we expl ore ways search engines might do this to build an accurate picture of multi-click behavior, support fast comprehension of the search result list, keep users engaged after their first click, and introduce new, relevant content in a seamless manner over the course of a single query. We then pre-sent a simple example that highlights the potential for these find-ings to positively impact millions of users. A number of the measures we stud y could be valuable for model-ing user behavior and improving ranking and relevance evaluation for multi-click queries. For example, models that assume a linear progression through the result list [6] appear to be roughly accu-rate for the first few clicks, but could be improved to assume an increased likelihood of returning to earlier results for later clicks. Rankers could also use more complex features of a searcher's initial interactions with a result pa ge than previously explored [2, 30], such as click rank and dwell time, to optimize their estimates of document relevance. Accounting for people X  X  initial interactions with a search result page is important because people use what they learn during their first encounter when they return. We observed, for example, that second clicks were typica lly faster than first clicks. To help users quickly understand search content, a search engine could offer a summary or visual representation of the results. It could also help orient users in the result page when they return, marking visited content and highlighting important changes, doing for a single query what Qvarfordt et al. explored for a session [18]. Different approaches could be used to keep users engaged as a function of their initial experience. For example, users who spend only a short time on the search result page initially may not have constructed a rich picture of the results and thus need more orientation support than consistency upon returning. Likewise, users who spend only a short time visiting a search result may not want that search result stressed or promoted when they return but rather want new con-tent drawn to their attention. On the other hand, users who are satisfied with the first results they find are less likely to continue clicking when they return. A search engine could instead provide these users with query suggestions or information related to the clicked result to support further exploration on the same topic. Our results also reveal an opportunity to provide new, relevant content to searchers when they re turn to a result list. Thus far efforts to contextualize results have focused on using information from the initial queries in a se ssion to improve the ranking of subsequent queries [20]. Our findi ngs suggest it may also be pos-sible to identify new content for users without their ever having to issue a new query. This could be done using implicit feedback from the user X  X  initial interactions (e.g., dwell time and click posi-tion), or by taking more than a few hundred milliseconds to pro-cess the initial query [26]. However, there appears to be a risk to capitalizing on this opportunity, in that changing the result rank-ing during a search may cause c onfusion. When ranking results mid-query, a search engine must account for the user X  X  initial experiences. Clicked results appear to be used for orientation, and thus should probably be included in subsequent result lists instead of displaced by new, more relevant results. The most relevant new content should not naively be ranked at the top of the list, but instead placed where the user will attend to it (e.g., immediately below the previously clicked result). Satisfied users appear less tolerant of change, so the largest changes should be reserved for when a user X  X  initial experience is unsatisfactory. 
Figure 9. Time to click  X   X  as a function of time to click  X  broken down by how the first clicked result moved. The sec-
Figure 10. Time to click  X   X  as a function of time to click  X  broken down by whether the resu lts above or below the initial click changed. The second click is fastest when the list is static. As an example of how a search engine might use the analysis presented in this paper to inten tionally provide new content during a multi-click query in a seamless manner, we conducted an initial exploration into a simple approach . We describe the approach we implemented, and discuss what we learned about the complexities of controlling change in the process. In our analysis up to this point, we have studied search results that change during the course of a query without taking into account the user X  X  initial interactions with the results. While some of this change was the result of uncontrolled instability, the search engine also chose, by design, to display a longer result list when a user returned. Due to changing conditions, new results often appeared early in the list and the initial result ordering changed. Given the importance of stability, we implem ented an approach that contin-ued to display the same new content but in a stabilized manner. The results from  X   X  were held constant when a user returned to  X  and four to six new results were appended at the end of the list. We hypothesized these new results would be seen if needed but not disrupt the user X  X  search expe rience. We refer to this method as the stabilized approach, and discuss it in the context of the original , completely dynamic approach.
 Using the same approach to data collection described in Section 3.1, we collected log data for 9,883,375 queries with stabilized results from a two month period in the year 2013. As before, the dataset was restricted to instances where users had clicked a result following their query and returned to the result list. However, because of the enforced stability, the result clicked initially rarely moved; only 6% of the time in total did it move up, down, or dis-appear, as compared to 76% of the time in our earlier analysis. Although we aimed for 100% stab ility among the results from  X  this was not always possible due to factors outside of our control related to operating in a large scale production environment. Giv-en the initial click remained in the same position, results changed above that click 4% of the time (again, due to factors outside of our control) and below 99% of the time (by design).
 Six months separate the collection of the stabilized and original datasets. Changes in user base, underlying ranker, task, and even season can impact user behavior, so the two datasets are not di-rectly comparable. Here we provide some initial observations of the differences in how user behavi or correlates with change within each individual dataset, but we are unable to directly compare the two datasets. The goal of this disc ussion is to provide preliminary insight into the expected and un expected ways that stabilization changed the user experience to the extent possible. Our analysis of the new dataset suggests that showing new content in a controlled manner may benefit users for multi-click queries. However, our observations of ho w people interact with the stabi-lized results also highlight an unexpected edge case where change appears particularly confusing: users whose first click is on the last result appear to have a part icularly unsuccessful return expe-rience if new results were appended below the clicked result. In general, we observe that users abandon the re-ranked search result list less (with a 2.5% drop in the probability of abandon-ment) and find new content more (with a 3.6% increase in the satisfaction ratio) in the stabilized dataset than in the original da-taset. Table 8 shows the probability of abandonment of the stabi-lized dataset broken down by whether the results changed above the initial click or below. As a poi nt of reference, it also includes the probability of abandonment of the original dataset. For both the original and stabilized rankings, users were more likely to abandon their search after the firs t click when the results above that click changed compared with when they remained static. This seemed particularly true for the stabilized experience. Users were 13% more likely to abandon the query when the results above the click changed compared to when they were static in the stabilized condition, and only 3% more likely to abandon when the results changed in the original condition. It may be that users resisted change more when most results were the same. Because changes above the click were rare in th e stabilized case, the increase in abandonment had minimal impact on overall abandonment. Table 8 also shows that for both datasets the probability of aban-donment is lower when the results below the initial click changed (Below). There is a 15% decrease in abandonment when results below change in the stabilized condition, and only a 3% decrease in the original condition. We furt her observe that users were more likely to click on the appended results in the stabilized case than they were to click on the low ranked results when the initial re-sults were not held static, as shown in Figure 11.
 However, the most noticeable change with the stabilized dataset is that there was a negative impact when the result immediately below the clicked result changed (Below1). There is a 5% in-crease in abandonment when the immediate result changed in the stabilized condition, whereas in the original condition changing in fact helped reduce abandonment by 8%. In the stabil ized dataset, change immediately below the user X  X  initial click primarily oc-curred when users clicked the result at position eight (i.e., the last result of  X   X  ), as shown in Figure 12. In the original, more dynamic dataset, instances of change immediately below the initial click were more widely dist ributed. This negative impact thus may be because users who click the last result in the list are surprised to see additional content appended below that result. This is but a simple initial explor ation into how the controlled intro-duction of new content might positively impact the user experience 
Figure 11. The position distribution of the subsequent clicks on  X   X  (focused on positions 9 to 14) in original and stabilized 
Figure 12. The position distri bution of the initial click on  X  in original and stabilized data sets given results changed one search results above or below initial click in the original dy-during a single query. Our findings suggest that stabilizing results can have a positive impact, but may also make some types of change more detrimental. Given this and our earlier analysis, we believe there are many further oppor tunities to contextually enforce stability or provide new content while people search. This paper explored how a person interacts with the search result page after their initial click. By analyzing the Bing query logs, we showed that a user X  X  initial search result click can provide important insight into that user X  X  subsequent interactions with the result page. For example, a short initial dwell time correlates with increased future interaction, perhaps because someone who does not find what they are looking for is more motivated to look for results in the following steps. On the other hand, if a user appears satisfied with their initial click but returns to the result page regardless, they are usually happier with their subsequent clicks than others. We con-firmed that users tend to move down a result list as they search, but observed that top positions can re gain popularity as a search pro-gresses. We also saw that searchers are generally faster when select-ing the second result to click than the first, but can take longer if they only spent a short time inspecting the result list prior to their first click. Although search engine users think of query results as static, when a searcher returns to a search result following a click there is an op-portunity for the results to change. Such changes may hinder a us-er X  X  ability to find what they are looking for, as reflected by an in-creased abandonment probability. However, some changes may enhance overall satisfaction if the user does not abandon the search task. Behavioral response s to change vary based on the user X  X  initial experience with the result list. Init ially satisfied users react positive-ly to minimal change, while users who failed to locate a good result initially benefit more from changes. Although altering search results may sometimes be helpful, it appears that users have to spend extra time adjusting to the new content. We discussed several ways these results could be used, and ex-plored one way these results can be used to provide new content during a single query by maintaining a static search result list and appending additional results at the end. We found that this invites clicks on the appended results but highlights challenges when change does occur. We discuss ways these findings can be used, including proactively adjusting resu lts for users who are frustrated by their initially clicked result while maintaining stability for others. Our results can be used to impr ove people X  X  search experience dur-ing a single query by providing new, more relevant content as the user interacts with a search result page, allowing users to find what they are looking without having to issue a new query. [1] Adar, E., Teevan, J., Dumais, S. T. &amp; Elsas, J. L. The web [2] Agichtein, E., Brill, E. &amp; Dumais, S. T. Improving web search [3] Baeza-Yates, R., Hurtado, C., Mendoza, M. &amp; Dupret, G. [4] Chapelle, O. &amp; Zhang, Y. A dy namic Bayesian network click [5] Chen, W., Wang, D., Zhang, Y., Chen, Z., Singla, A &amp; Yang, [6] Craswell, N., Zoeter, O., Taylor, M. &amp; Ramsey, B. An experi-[7] Dumais, S. T., Buscher, G. &amp; Cu trell, E. Individual differences [8] Fox, S., Karnawat, K., Mydland, M., Dumais, S.T. &amp; White, T. [9] Granka, L. A., Joachims, T. &amp; Gay, G. Eye-tracking analysis [10] Guo, F., Liu, C., Kannan, A., Minka, T., Taylor, M., Wang, [11] Guo, F., Liu, C. &amp; Wang, Y.-M. Efficient multiple-click mod-[12] Jansen, B. J. &amp; Spink, A. An an alysis of web information seek-[13] Joachims, T., Granka, L. A., Pan, B., Hembrooke, H. &amp; Gay, [14] Kim, J. &amp; Carvalho, V. R. An analysis of time-instability in [15] Kim, J. Y., Cramer, M., Teevan, J. &amp; Lagun, D. Understanding [16 ] Li, J., Huffman, S. &amp; Tokuda, A. Good Abandonment in mo-[17] Obendorf, H., Weinreich, H., Herder, E. &amp; Mayer, M. Web [18] Qvarfordt, P., Golovchinsky, G., Dunnigan, T. et al. E. Look-[19] Selberg, E. &amp; Etzioni, O. On the instability of web search en-[20] Shokouhi, M., White, R. Bennett, P. et al. Fighting search [21] Somberg, B. L. A comparison of rule-based and positionally [22] Srikant, R., Basu, S., Wang, N. &amp; Pregibon, D. User browsing [23] Teevan, J. How people recall, recognize, and reuse search [24] Teevan, J. The Re:Search Engine: Helping people return to [25] Teevan, J., Adar, E., Jones, R. &amp; Potts, M. Information re-[26] Teevan, J., Collins-Thompson, K., White, R. W., Dumais, S. [27] White, R. W., Ruthven, I. &amp; Jose , J. M. Finding relevant doc-[28] White, R. W., Ruthven, I., Jose, J. M. &amp; van Rijsbergen, C. J. [29] Zhang, Y., Chen, W., Wang, D. &amp; Yang, Q. User-click model-[30] Zhong, F., Wang, D., Wang, G., Chen, W., Zhang, Y., Chen, 
