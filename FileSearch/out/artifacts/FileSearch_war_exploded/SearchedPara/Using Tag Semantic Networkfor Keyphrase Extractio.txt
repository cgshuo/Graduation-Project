 Folksonomies provide a comfortable way to search and browse the blogosphere. As the tags in the blogosphere are sparse, ambiguous and too general, this paper proposes both a su-pervised and an unsupervised approach that extract tags from posts using a tag semantic network. We evaluate the two methods on a blog dataset and observe an improvement in F1-measure from 0.23 to 0.50 when compared to the base-line system.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Information filtering. General Terms: Algorithms, Experimentation, Performance. Keywords: Blog,Tag Recommendation, SemRank.
Folksonomies are  X  X etadata for the masses X  to facilitate search and browsing information in the blogosphere. They reflect directly the vocabulary of users and describe more facets of an object from different points of view than tra-ditional ontological classification schemata. Together with information visualization techniques, they give users a bet-ter overview and categorization of the data.

However, we find that tags are very sparse in the blogo-sphere and most of them indicate only general topical infor-mation like  X  X usic X  and  X  X log X . Uncontrolled vocabularies lead to the ambiguity of tags. A tag suggestion system can facilitate the vocabulary convergence in a manner that users are encouraged to select the suggested ones. In addition, im-portant keyphrases extracted from blog posts can compen-sate for general tags by providing more focused information. Based on these ideas, this paper proposes both supervised and unsupervised ways to overcome the weaknesses of hu-man tagging by using a tag semantic network derived from the existing tag space. This is a different approach as op-posed to the existing tag recommendation systems in the blogosphere [4, 7], since tag candidates are extracted di-rectly from the blog content, thus the existing tag space is expanded with novel and more focused tags. Also, the state-of-the-art keyphrase extraction systems like [3, 8, 9] are tuned for keyphrases assigned by professional indexers, we show in our evaluation that two of them can only achieve low performance on the blog data.

The logistic regression classifier from Autonlab 2 is applied to the feature vectors of candidate terms to identify the top 5 ranked candidate terms as the final set of keyphrase.
Like TextRank[9], our SemRank algorithm considers each document as a directed text graph G ( V, E ), where V denotes the set of vertices representing lemmas of occurring noun and adjective unigrams, E denotes the set of weighted edges. As in [9], In ( V i ) denotes the collection of vertices pointing to V i and Out ( V i ) is the set of vertices pointed by V i .
We define different edge weights in our experiments. i. w within a window of size N . ii. If two lemmas i and j are matched in the tag network, the weight of edges w conf ij is set to their conf idence . iii. w cont ij defines the cosine distance between the two corresponding mean tf.idf vectors. iv. if two lemmas i and j are found as Hypernym or Meronym within a distance of K in WordNet, w ij is set to 1 1+ K .
Let w ij be the weight from vertex j to i , we use PageRank [6] to calculate the ranking score S ( V i ) of V i :
S t +1 ( V i ) = (1  X  d ) + d  X  X where the dumping factor d is set to 0.85 in our expriments. When stacking all S ( V i ) into a vector s , we get the follow-ing formula to represent the ranking scores of lemmas at iteration t + 1.
Here p = [1 , ..., 1] T is the preference vector and M = { m ij } is the transition matrix with m ij = w ij P
According to PageRank, a random surfer starts a new navigation by jumping to a page picked uniformly and ran-domly from the collection. Since each lemma is of different significance, we use a normalized tf.idf vector to replace the original uniform distribution p to model the  X  X reference X .
By using the matrix interpretation, the different types of edge weight definition can also be used together, which can be seen as the sum of the corresponding transition matrices. To ensure the convergence of the algorithm, the sum of the matrices is normalized so that the Manhattan norm of each column is equal to 1.

After ranking, all unigrams with the top 5 scores are se-lected as candidates. These candidates, if located adjacent to each other, are collapsed into new multi-word keyphrases.
In our experiments, we use 621 English posts with at least 3 gold standard tags selected from the ICWSM 2006 3 blog corpus for evaluation and 2500 for building the tag seman-tic network. The tags are chosen as the gold standard, if they occur at least once in the posts. To evaluate our su-pervised method, 434 of them are used for training and 187 for testing. On the same test dataset, the KEA system [8], TextRank and SemRank are evaluated for comparison.

The evaluation measure we use is based on the exact stem matching of tags. The results are given in terms of precision, recall and F1-measure. http://www.autonlab.org http://www.icwsm.org/data.html
