 1. Introduction
On-linelearningapplicationswherethetargetconceptmay change over time pose serious problems. Underlying changes may make the model designed on old data, inconsistent with new data.
This problem is known as concept drift . One of the most important challenges in machine learning is dealing with concept changes.
Other challenge in on-line learning algorithms is to adapt and deal with changes without being informed about them, and make use of the past experiences in sit uations where old contexts may reappear ( Widmer and Kubat, 1996; Bosni  X  et al., 2014 ). In industry, a large demand of algorithms for on-line prediction is observed, such algorithms are usually called Soft Sensors ( Ibarg X engoytia et al., 2013;
Kadlec et al., 2011 ). They employ predictive models to provide on-line estimations of dif fi cult-to-measure variables based on some easy-to-measure variables ( Wu et al., 2009 ). Examples of applications are the groundwater level prediction in a coastal aquifer ( Taormina et al., 2012 ), the river fl owdischargepredictioninareservoir( Cheng et al., 2005 ), and others ( Kadlec and Gabrys, 2011; Chau, 2007 ). Unfortu-nately, industrial processes exhibit time-varying behavior. Causes for such a behavior are changes in the measuring devices, environment changes, and changes of process behavior or of some external process condition ( Vergara et al., 2012 ). It is important to develop on-line adaptive methodologies that should be able to handle time varying behavior in prediction settings.

The main adaptive mechanisms to deal with concept drift can be classi fi ed as: instance selection ( A 1), instance weighting ( A 2), and ensemble learning ( A 3). Instance selection approaches obtain a set of relevant samples of the current concept. A common strategy is the moving window (MW), in which a window slides along the data and the newest samples are included to be taken into consideration into the model and the oldest samples are excluded from the model. One dif fi culty is the selection of the window's size. In instance weighting (IW), samples are weighted according to their age and/or relevance to the current concept. Recursive methods, where the models' parameters are updated over time, belong to this category. The method most commonly used is the Recursive Partial Least Squares (RPLS) proposed in Qin (1998) . In this work, a currently existing
Partial Least Squares (PLS) model is merged with the new data using a forgetting factor that is employed to update the model. Recent
RPLS models update the mean and variance of data using a MW approach to track the process changes ( Ahmed et al., 2009 ). In general, the RPLS works well in cases where the process dynamics are well represented in the initial training data set. On the contrary, the model may not track the process dynamics occurring in the new data. Boosting is also an IW approach, where samples are re-weighted in order to emphasize those samples predicted incorrectly by the previous model ( Drucker, 1997 ).

Ensemble learning has been proven itself as a valuable tool to handle concept drift scenarios. It combines a set of models in order to get a fi nal prediction ( Chao et al., 2014; Huang and Chau, 2008 ).
Results indicate that ensemble learning improves the general-ization capability and the overall system performance ( Soares et al., 2012; D'Este et al., 2014 ). Adaptive ensembles can combine a subset of the following strategies ( Polikar, 2012 ): adaptation of the models' weights ( E 1); adaptation of the models' parameters ( E 3); and/or add new models in the ensemble ( E 3) according to each incoming sample or batch of samples. Adaptive ensembles can also be classi fi ed as batch-based or sample-based if they are adapted when a batch of data or a sample is available, respectively.
Most adaptive ensembles are batch-based and focus on classi -cation tasks, for example the Learn  X  X  .NSE ( Elwell and Polikar, 2011 ), which is inspired by the Boosting ( Drucker, 1997 ). When a batch arrives, Learn  X  X  .NSE identi fi es the samples misclassi the ensemble and obtains a penalty distribution. The distribution is used to assign errors to each model based on its contribution to the ensemble. The weight of each model is assigned using a weighted average of their errors on the current and old batches by a sigmoid function with two slope parameters. The parameters' setting is not an easy task, since Learn  X  X  .NSE is sensitive to their values. More-over, Learn  X  X  .NSE requires a long time for waiting a batch, and when it is available, it may not re fl ect the current concept.
On the contrary, sample-based ensembles offer faster adaptation capability. Examples are the Additive Expert (AddExp) ( Kolter and Maloof, 2005 ) and the Incremental Local Learning Soft Sensing
Algorithm (ILLSA) ( Kadlec and Gabrys, 2011 ) algorithms. AddExp uses a loss bound to obtain the models' errors, and models' weights are adapted according to their actual losses and a decreasing factor, employed to reduce a model's weight when it performs poorly. The
ILLSA algorithm has two phases. On the training phase, a set of models is designed, where each model is trained with samples of a different concept contained on the training data; while on the on-line phase, for each incoming sample, the models' weights are adapted using the posterior probability by a Bayesian framework.
ILLSA works well when the process dynamics are well represented in the training data set. One drawback is that few models are designed if the training data contains few concepts.

This paper proposes an on-line weighted ensemble of regressor models (OWE) which is able to learn incrementally sample by sample in the presence of several types of changes and simulta-neously retain old information in recurring scenarios. OWE employs several adaptive mechanisms to deal with several types of drifts.
OWE is inspired by Learn  X  X  .NSE ( Elwell and Polikar, 2011 ). But unlike Learn  X  X  .NSE, in the OWE, the ensemble is adapted on a sample basis, leading the system to faster recovery from changes and increasing the system accuracy. Additional and new strategies are proposed to increase the OWE's accuracy. The experiments indicate that OWE outperforms Learn  X  X  .NSE in all tests.
The key idea is to keep a fi xed MW slides along data when a new sample is available. Then, the error of each model on the current window is determined using a boosting strategy ( Feely, 2000; Shrestha and Solomatine, 2006 ) that assigns small errors to the models that predict accurately the samples predicted poorly by the ensemble. To handle recurring and non-recurring changes,
OWE uses a new method for assigning the models' weights that takes into account the models' errors on the past and recent windows using a discounting factor that decreases or increases the contribution of old windows. In addition, OWE launches new models if the system's accuracy is decreasing, and it can remove inaccurate models for reducing memory and computational time.
The method removes the model with the largest total error rate on the current and old windows. Experiments on arti fi cial data sets and industrial data sets are detailed to evaluate, and demonstrate the performance and the effectiveness of the OWE over the state-of-the-art concept drift approaches.
 weighted ensemble of regressor models with faster adaptation cap-ability; (2) regression scope (while most on-line ensemble applications for handling changes is devoted to classi fi cation tasks); (3) systematic analysis of the related ensemble algorithms; (4) thorough analysis of the experimental results using both arti fi cial data sets and industrial data sets, demonstrating faster adap tation capability and accuracy of the OWE over the main state-of-the-art approaches; (5) implementa-tion of a new Learn  X  X  .NSE algorithm for regression tasks. of concept drift. Section 3 outlines the related works. In Section 4 the
OWE algorithm is described. In Section 5 the results are presented and discussed. Finally, Section 6 presents the concluding remarks. 2. The concept drift problem 2011; Klinkenberg, 2005 ), consider an on-line learning framework where samples arrive incrementally one by one, and each sample s  X  X  x ; y  X  is composed of r inputs grouped into an input vector, x A R r 1 , and one output y A R . Consider that the samples are grouped into several windows of equal size m : |fflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflffl} where s  X  w ; i  X  is the i -th sample of window w . For each window w , the data is independently and identically distributed according to a distribution D w  X  x ; y  X  . If all the windows are distributed over the same distribution, the concept is considered stable and thus there is no concept drift. On the other hand, if two windows a and b have different data distributions, i.e. D a  X  x ; y  X  a D concept drift. Learning algorithms to handle the concept drift problem should be able to predict the next data window (e.g. t  X  1) using the old data windows (from 1 to t ) or a subset of them. drifts are classi fi ed with respect to their speed, cyclical nature, scope, etc ( Minku et al., 2010; Elwell and Polikar, 2011; Zliobaite, 2009 ). The drift speed describes the rate by which old concepts are substituted by new concepts. An abrupt drift happenswhenanoldconceptis abruptly replaced by a new concept; while a gradual drift happens when an old concept is slowly substituted by a new concept. Gradual drifts are harder to identify since they result in small data shift and lower error prediction when compared to abrupt drifts. recurring drift happens if a previously occurring concept recurs after some time; while a non-recurring drift happens if a previously occurring concept cannot recur over time. Recurring drifts may occur due to the cyclic nature of a system (e.g. due to the seasons of the year). Other drift classi fi cation is with respect to scope. A local drift affects only some regions of the instance space; while a global drift affects the whole instance space. In local drifts, changes depend on the location in the instance space; And therefore, a learning algorithm should detect such changes and adapt only those locations of the model that cover the in fl uenced regions of the instance space ( Ikonomovska, 2012 ). 3. Related works
A learning algorithm that deals with changing environments can be characterized in several ways, such as classi fi cation or regression scope ;an explicit or implicit algorithm ( Minku and Yao, 2012; Elwell and Polikar, 2011 ); the types of drifts that the algorithm can deal with; the incorporated adaptive mechanisms ( A 1, A 2, A 3); the adaptive ensemble learning mechanisms ( E 1, E 2, E 3) (for the ensemble-based approaches); time step (if the algorithm learns one sample or a batch of samples at a time), etc. Table 1 lists the main ensemble-based approaches and related works.

An explicit drift algorithm constantly monitors the system to detect the starting time and the severity of drifts, allowing the algorithm to adapt to changes and continue the learning accord-ingly ( Bosni  X  et al., 2014; Baena-Garc X a et al., 2006 ). In implicit drift algorithms, the system does not monitor the time instant when the drift occurs, and it constantly learns from the environment by constructing and organizing the knowledge. Approaches with implicit drift mechanisms usually associate to each model of the ensemble a weight based on its accuracy in the current concept.
Additionally, some approaches dynamically add new models to the ensemble for learning new concepts and, remove old models that perform poorly (possibly trained with old concepts).

Table 1 reveals that most approaches employ adaptation of the models' weights ( E 1) and addition of models ( E 3). Only AddExp and ILLSA adapt the models' parameters ( E 2). This strategy may be useful for assuring faster convergence of the ensemble to new concepts. However, in systems where the parameters of all the models are adjusted to the new concept, this adaptation may produce redundant models and affect the system's performance in recurring drifts. Ensembles can employ an ensemble pruning strategy, which is based on pruning the ensemble by selecting a subset of models from the original set of models, and excluding those models that are either detrimental to the ensemble's performance or contain redundant information, normally with the goal of limiting the number of models and/or improving the ensemble accuracy ( Soares et al., 2013; Zhang and Chau, 2009 ).
Adaptive Classi fi ers-Ensemble system (ACE) creates a new model when the buffer of samples is full or a drift is detected, where a drift mechanism monitors the con fi dence interval of the models' accuracies ( Nishida et al., 2005 ). For each new sample, the models' weights are updated according to the models' accuracies in that sample. ACE can remove the model with the lowest pruning weight when the number of models exceeds a threshold ( Nishida and Yamauchi, 2007 ). Initially, when a model j is created, its pruning weight w j is set to 0. At each time step, if model j achieves larger accuracy on the new buffer when compared to its accuracies on the old buffers, then w j is increased by 1. Otherwise, w is reduced by 1. The drawback is that the newest model may be easily excluded, since its pruning weight is set to 0. ILLSA and AddExp are sample-based ensembles for regression. ILLSA does not use ensemble pruning strategies. AddExp is an ensemble for predicting a discrete set of classes, AddExp.D, or continuous values in the interval  X  0 ; 1 , AddExp.C. The models' weights are dynamically updated according to their current losses and a decreasing factor  X  . A new model is added when the ensemble's loss is greater than a factor  X  . The new model's weight is set according to the sum of the remaining models' loss and a factor  X  , employed to control the importance of the new model. A model can be removed when the number of models is greater than K . Two pruning strategies are proposed: oldest fi rst , where the oldest model is removed from the ensemble; and weakest fi where the model with the lowest weight is removed from the ensemble. AddExp does not reveal which samples should be taken for the initial training of a new component model.

Fast and Light Boosting (FLB) ( Chu and Zaniolo, 2004 ), Incre-mental Boosting (IBoost) ( Grbovic and Vucetic, 2011 ), and Learn NSE ( Elwell and Polikar, 2011 ) are algorithms based on boosting. In the FLB, when a batch is available, the ensemble predicts it and a new model is included into the ensemble. Each sample from the batch receives a weight based on its prediction error, and a weighted training batch is obtained using the samples' weights and is used to train the new model. Changes are detected using a statistical decision theory, and a new ensemble is created from scratch when a change is detected. This approach leads the system to bad performance in scenarios where drifts recur, since models trained on old drifts are excluded. IBoost is an ensemble that employs a stochastic gradient descent procedure to dynamically assign the models' weights. It uses a MW to keep the most recent samples. At a pre-de fi ned frequency p , a model is added to the ensemble, if the ensemble misclassi fi es the newest sample. At this frequency, if the number of models exceeds a threshold, then the model with the lowest weight is excluded. At each time step, the models with weights less than zero are removed from the ensemble. Results in Grbovic and Vucetic (2011) show that IBoost has faster adaptation than batch-based ensembles. The Learn  X  X  .NSE algorithm suggests two pruning strategies when the number of models is greater than a threshold ( Elwell and Polikar, 2009 ): the oldest model is excluded, or the model with the largest current error is excluded.
Boosting algorithms were fi rstly developed for solving binary classi fi cations problems. Freund and Schapire (1997) proposed the fi rst regression boosting algorithm called AdaBoost.R .Themainidea is to map each regression sample into an in fi nite set of binary classi fi cation samples. Although it has theoretical proof of its convergence, the number of classi fi cation samples grows linearly in each iteration, hindering its practical application. Drucker (1997) proposed the AdaBoost.R2 algorithm, a modi fi cation of the AdaBoost. R , that has promising results. AdaBoost.R2 uses loss functions to convert regression loss into the domain of classi fi cation loss. Big Error Margin (BEM) boosting ( Feely, 2000 ) is quite similar to AdaBoost.R2 . However, BEM is less sensitive to noise and the system can handle weak learners with larger errors. In BEM, the absolute predictive error of a sample is compared to a pre-de fi ned threshold, and the corresponding sample is demarcated as incorrect or correct. BEM algorithm has a problem when the variability of the real values is very high. To overcome this drawback, in the OWE proposed in this paper, a threshold is used to demarcate an incorrectly or correctly predicted sample based on its absolute relative predictive error, as in the AdaBoost.RT algorithm ( Shrestha and Solomatine, 2006 ). 4. On-line weighted ensemble of regressor models (OWE) This section details the new On-line Weighted Ensemble of
Regressor Models (OWE) algorithm. OWE incorporates all the main adaptive mechanisms ( A 1, A 2, A 3) to deal with the problem of concept drift. OWE employs the common assumption that the most recent data provides the best and most relevant representa-tion of the current concept and near-future concept; and only this input data should be kept ( Brzezinski and Stefanowski, 2014;
Klinkenberg, 2005 ) (but the ensemble model keeps information about other past concepts). For this purpose, a fi xed MW is used to keep the most recent set of samples ( A 1). These samples are employed to obtain the ensemble's accuracy based on the error predictions, and to train a new model. Additionally, OWE also incorporates instance weighting ( A 2) mechanisms based on boost-ing ( Feely, 2000; Shrestha and Solomatine, 2006 ). That is, a weighted distribution of the ensemble's error on the current window is obtained, and then the error of each model is calculated based on its contribution to the ensemble. This contribution is seen as the ability of a model to predict accurately the samples poorly predicted by the ensemble. Moreover, OWE is an ensemble learning ( A 3) algorithm that takes into account that the data exhibits time-varying behavior. The main adaptive ensemble mechanisms for dealing with concept drift are: ( E 1) adaptation of the models' weights (with respect to their contributions on the recent and old windows); ( E 3) dynamic inclusion of models when the ensemble's performance is degrading; and removal of models over time (more details in Table 1 ). Adaptation of the models' parameters ( E 2) is not employed, since it usually results in redundant models and inaccuracy in recurring drifts.
 of the algorithm are (Step 1): a data set D  X f X  x i ; y i y i A R ; i  X  1 ; ... ; M g ,where x i is a vector of r inputs, y and  X  x i ; y i  X  is a sample; the window's size, m ;afactorfordemarcating correct and incorrect predictions,  X  ; a factor to control the inclusion of anewmodel,  X  ; a discount factor,  X  ;where0 o  X  ;  X  o 1and0 a generic supervised learning algorithm for regression, Weak Learner; a pruning activation factor,  X  ; and the maximum number of models, B (enforced if and only if (iff)  X  isactivated).InStep2,theinitializationof somevariablesisdone.Variable k denotes the number of models in the ensemble, f k denotes the most recently designed model, and t is thetimestep. D t is a data window (of size m )producedattime t . d m T , holds the weights of each sample on the current data window, where each weight is based on the ensemble prediction accuracy on a sample. D is fi rstly initialized to be a uniform distribution model training as instance weighting, e.g. for resampling the training dataset. It is considered that all the training samples have the same weight/contribution during the training process.

Algorithm 1. On-line Weighted Ensemble of Regressor Models (OWE). 1. Inputs: a data set D  X f X  x i ; y i  X g M i  X  1 ; window's size, m ; 2. Initialization: Set s  X  1; k  X  0; D 0  X   X  ; the distribution ; ... ; d m T , where d i  X  1 = m , for i  X  1, ... , m ; 3. for t  X  1 ; ... ; M : ; y = E
 X  ;  X j X  F  X  x i  X  y i  X  = y i j , for i  X  s ; ... ; t ; 4  X  U ;  X  j  X   X  j  X  1; ; ... ; k , p  X  0 ; ... ;  X  q 1; 4. end for
Step 3 is repeated when a new sample from data set D becomes available. The data window D t is fi rstly fi lled with the of D ,if t is not greater than m (Step 3(a)ii). Otherwise, the window slides along D (Step 3(a)i). In Step 3b, the algorithm is directed to create the fi rst model if t is equal to m .InStep3c,theensemble F  X  X  is used to predict the new sample. The ensemble's output is obtained by a weighted sum of the models' outputs using a logarithm function.
Step 3d obtains the absolute relative error of the samples predicted bytheensembleusing D t , ARE F t  X  X  ARE F s ; ... ; ARE F sample ARE F i (where i  X  s ; ... ; t ) is obtained using the real output value y i , and the predicted output of the ensemble F  X  x  X  x ; y  X  A D t .

In Step 3e, samples of D t are demarcated as incorrectly or correctly predicted by the ensemble using a threshold  X  . The objective is to count the total number of samples incorrectly predicted by the ensemble for obtaining the new penalty distribu-tion. OWE employs concepts similar to the (BEM boosting Feely, 2000 and to the AdaBoost.RT Shrestha and Solomatine, 2006 boosting regression algorithms. The strategy works as follows: if an error ARE  X  i (of a sample i A D t predicted by a component model,  X   X  1 ; ... ; k , or the ensemble,  X   X  F ; Steps 3e, 3(g)ii, 3(i)) is greater than  X  , then sample i is demarcated as incorrect, otherwise as correct. As in the AdaBoost.RT and BEM algorithms, OWE is sensitive to the setting of  X  . The methods perform well when between 0 and 0.4.
 Step 3f determines the values of variables upFactor and down-
Factor using totalSamples . The variable upFactor increases the weights of the samples predicted incorrectly by the ensemble and downFactor decreases the weights of the samples predicted correctly by the ensemble. In Step 3g, the values of D are updated. First, in Step 3(g)i, distribution D is reinitialized to be uniform. In
Step 3(g)ii, each weight d i of a sample i is obtained. The main idea is to assign larger weights to the samples predicted incorrectly by the ensemble and small weights to the samples predicted correctly by the ensemble.

In Step 3h, a new model is launched to the ensemble if the absolute relative error of the ensemble on the newest sample is greater than  X  . The new model is trained using all samples of D
Then, all the models are evaluated based on their predictions of D and their contributions to the ensemble (using D ) in the Step 3i. In summary, for each model j , it is obtained the absolute relative error ARE j i for each sample  X  x i ; y i  X  A D t . The current error rate calculated using the sum of the weights (from D ) of the samples demarcated as incorrectly predicted by model j . Therefore, since the sum of the elements of D is 1,  X  j t can assume values between 0 and 1. As mentioned before, large errors are given to the models that predict poorly the samples predicted incorrectly by the ensemble; and small errors are given to the models that predict correctly the samples predicted incorrectly by the ensemble. In this Step, the variable  X  j for each model j is incremented. It holds the total number of windows where model j has been evaluated.
The total error rate E j of each model j is calculated using a discounting factor that weights the model's errors on the past and recent windows (Step 3j). The discounting factor weights recent errors more heavily than old errors for obtaining E j as
E  X   X  ! where j is a model of the ensemble;  X  is the discounting factor with 0 r  X  o 1; and  X  p j denotes the error of model j on a window p . Eq. (1) can be rewritten as
E  X  1 The sequence of weights  X   X  j p is decreasing with the oldness of the window,  X  j p , so that  X   X  j 1 r ... r  X  1 o  X  0 , as can be observed in the Figs. 1 and 2 . Also, smaller values of  X  imply that lower weights are given to the errors on the old windows. This case works well in non-recurring drifts, since more importance is given to the current scenario/concept. Larger values of  X  imply that larger weights are given to the errors on the old windows. This case performs well in scenarios with recurring drifts, since more importance is given to the errors on the old windows. The proposed approach employs concepts of the discounted Mean Square Forecast Error (MSFE) method ( Shen et al., 2008 ). It uses discounting factors to obtain weights of each forecast in an ensemble system. This strategy is simple and easy to apply, and it is simple to tune the discount factor value. Other strategy is Weighted Majority Algorithm (WMA) which combines a set of models using a weighted majority vote of the models' predictions ( Littlestone and Warmuth, 1994 ). When a model incorrectly classi fi es a sample, then WMA decreases its weight by a constant. Therefore, the weight is discounted only when it performs poorly on the newest sample. AddExp also employs the same concept. Learn  X  X  .NSE employs a sigmoid function with two parameters to decrease or increase the contribution of the old batches. However, the parameters' setting is not an easy task, and Learn  X  X  .NSE is sensitive to their values.
In Step 3k, if the pruning factor  X  is activated by the user, then a model is removed if the number of models is greater than the threshold B . The pruning strategy removes the model with the largest total error rate E j . Note that a new model f k created at sample-iteration t is never removed by the pruning strategy at that same iteration t . 5. Experimental results Experimental results are detailed in this section to compare OWE to the state-of-the-art approaches. The approaches are evaluated on different scenarios using two arti fi cial data sets and two industrial data sets. The use of arti fi cial data sets allows the control of relevant parameters and to empirically evaluate the algorithms in several types of changes. There is a lack of arti data sets to simulate changing environments for regression tasks. In this paper, it is used the hyperplane data set proposed by Kolter and Maloof (2005) , a benchmark for evaluating algorithms that deal with concept drifts for both classi fi cation and regression tasks; and the drifting Friedman's function proposed by
Ikonomovska (2012) , a recent data set created for evaluating regression algorithms in changing environments. The real-world data sets enable us to evaluate the merit of the proposed approach in real-world problems, and compare it to the most recent works in real-life problems. However, it may not be possible to precisely state when drifts occur or if there is any drift at some speci instant. This paper uses two well-known industrial data sets widely employed to evaluate algorithms for dynamic system modeling: the catalyst activation data set, which has slowly changing process dynamics due to the catalyst decay over the period of one year ( Kadlec and Gabrys, 2011; Ni et al., 2012 ); and the Fluidized Catalytic Cracking Unit (FCCU) data set, a benchmark for evaluating dynamic systems ( Liu et al., 2009; Yan et al., 2004 ).
Other public data sets for soft sensor modeling are the debutanizer column and the sulfur recovery unit proposed by Fortuna et al. (2006) . However, they are rarely employed to evaluate systems with time-varying behavior. The tests have been performed on the
Matlab environment, running on a PC equipped with an Intel Core i7-2600 3.4 GHz process of 4 cores and 8 GB of RAM. 5.1. Experimental setup: data set description
Drifting Friedman ' s function. The Friedman's function is a well-known function for producing benchmark data ( Friedman,1991 ). It has linear and non-linear relations between inputs variables and output variable. The function contains 5 input variables, x 1 and 1 output variable, y i , and is given by y  X  10 sin  X   X  x 1 i x 2 i  X  X  20  X  x 3 i 0 : 5  X  2  X  10 x 4 where  X  N  X  0 ; 1  X  is a zero-mean, unit-variance Gaussian random variable. The input space is enlarged by including other 5 input variables are uniformly distributed over the interval of  X  0 create drifting scenarios, 3 drifting data sets using the original
Friedman's function were produced according to Ikonomovska (2012) , each one with 2000 samples. The fi rst data set, local and abrupt drift data set (Friedman-LA), introduces changes in 2 differ-ent regions of the input space (local drift) using 3 points of abrupt changes. The second data set, global recurring abrupt drift data set (Friedman-GRA), has global, abrup t, and recurring dr ifts introduced in 2 drift points of the data. The third data set, global non-recurring gradual drift data set (Friedman-GnRG), contains 2 points at which gradual concept changes are be ginning to be introduced. It is generated by slowly introducing sam ples which belong to a different function in contrast to the initial samples. The complete description of these drifting data can be found in Ikonomovska (2012) .
Drifting hyperplane data set. It is a well-known drifting data set used to evaluate algorithms that deal with concept drift ( Minku et al., 2010; Shaker and H X llermeier, 2012 ). It contains noise, and gradual and non-recurring drifts, and is similar to the one proposed in Kolter and Maloof (2005) (AddExp). The whole data set consists of 10 inputs with uniform distribution over the interval of  X  0 ; 1 and 1 output, y i A  X  0 ; 1 ; and 2000 samples ( M  X  2000). The data set contains 4 concepts, where each concept holds 500 samples. The outputs of the data set are given by: concept 1: y i  X  X  x 1 i  X  x 2 i  X  x 3 i  X  = 3, for i  X  1 ; ... ; M concept 2: y i  X  X  x 2 i  X  x 3 i  X  x 4 i  X  = 3, for i  X  X  M concept 3: y i  X  X  x 4 i  X  x 5 i  X  x 6 i  X  = 3, for i  X  X  M concept 4: y i  X  X  x 7 i  X  x 8 i  X  x 9 i  X  = 3, for i  X  X  3 M
A random variate noise uniformly distributed in the interval of  X  0 : 1 ; 0 : 1 is injected to each output sample y i (for i  X  1
The value of y i is clipped to 0 or 1 if its value is less than 0 or greater than 1, respectively.
 evaluating adaptive soft sensing algorithms ( Kadlec and Gabrys, 2011 ). It describes a polymerization reactor which consists of 1000 tubes fi lled with catalyst, used to oxidize a gaseous feed.
The reaction speed has a nonlinear relation to the temperature of the coolant which is used to cool the reactor. The plant is equipped with measurements to log all the variations of the feed and the operating conditions of the process. Moreover, measure-ments are done to show the concentrations, fl ows, and tempera-tures along the reactor. The aim is to predict the catalyst activity in the reactor. The catalyst activity values are synthetically produced using chemical reactions equations for simulating a real case. The data covers one year of operation of the process plant and it contains 15 input variables ( x 1 ; ... ; x 15 ), 1 output (the catalyst activity) and 8687 samples. The sampling rate of the output for the last 3000 samples is lower so that the data set was pre-processed as follows: downsample by a factor 10 of the 5687 samples; remove x 3 , x 4 and x 15 , since they are affected by outliers and missing samples; remove x 2 , since it is not correlated to the output; remove x 13 , since it is redundant to x 12 exclude all the samples with missing output values. At the end of this process, the data set contains 648 samples, 10 inputs and 1 output.
 lighter hydrocarbon products (e.g. gasoline) and has an important role in a re fi nery ( Liu et al., 2009 ). There are 6 input variables, and the output variables are the gasoline, light diesel oil (LDO) and lique fi ed petroleum gas (LGP) concentrations. In traditional opera-tions, these variables can only be estimated off-line with a sampling time of about of 8 [hours] or 1 [day]. The FCCU data set has 104 samples and 6 inputs, mainly fl ow of the oil and temperature of the FCCU components. 5.2. Experimental setup: approach setup and description
AddExp.C, Learn  X  X  .NSE, and ILLSA. RPLS is a widely used algo-rithm in on-line process modeling to adapt to the process changes. Its popularity is motivated by its reduced computational time and computer memory requirements ( Qin, 1998 ); and robustness under collinearity, measurement error and high dimensionality of input space, which are common characteristics in most industrial data sets ( Souza and Ara X jo, 2014 ). AddExp.C and Learn  X  X  .NSE are two well-known adaptive ensembles for dealing with concept drifts; they are suitable to compare OWE to adaptive sample-based ensembles (AddExp.C) and adaptive batch-based ensembles (Learn  X  X  .NSE), respectively. On the other hand, ILLSA is a popular adaptive ensemble for soft sensing.
 bles are designed with and without pruning strategy. Ensembles with pruning strategy are termed as pruned . For each pruned ensemble, the pruning strategy was selected according to the best result indicated by its authors. In the pruned AddExp.C, the model with the lowest weight is excluded. In the pruned Learn  X  X  ( Elwell and Polikar, 2009 ), the model j with the largest current error is excluded. In all pruned the algorithms, the maximum number of models in the ensemble is set to 20. This choice was considered the best suitable for all the ensembles, since the maximum number of models usually varies between 15 and 30 ( Elwell and Polikar, 2009; Kolter and Maloof, 2005; Nishida and
Yamauchi, 2007 ), and the use of more models linearly increases the processing time of the experiments.

Either PLS ( Qin, 1998 ) or RPLS ( Ahmed et al., 2009 ) are used as base models in the methods studied in the experiments. The PLS is able to deal with large dimensional co-linear data by projecting the input and outputs into a new space. The PLS projects the scaled and mean-centered input and output data into separate latent variables. This paper uses the Statistically Inspired Modi cation of the Partial Least Squares (SIMPLS) algorithm ( de Jong, 1993 ) available in the PLS Toolbox ( Wise et al., 2003 ). The SIMPLS calculates the PLS components faster and more accurately when compared to the other PLS algorithms. The optimal number of latents is determined by 10-fold cross-validation using the sum of squared prediction errors (PRESS) between the real output and the predicted output.

The following structure is performed in all the algorithms (except ILLSA). Consider a data set D  X f X  x i ; y i  X g M i  X  1
The fi rst model is designed using the fi rst m samples from D .
While the other  X  M m  X  samples of D are grouped to form the on-line data to simulate an on-line scenario. Each method is evaluated using the Mean Square Error (MSE), which is calculated using the predicted outputs and the real outputs from the on-line data. MSE is a widely used metric to evaluate models. It provides a quadratic loss function that penalizes larger errors. MSE has the disadvan-tage of heavily weighting outliers. But as the data sets are free of outliers, this paper considers MSE as metric to evaluate models.
The RPLS is implemented by updating recursively the mean and variance data, where the oldest sample is excluded and the newest sample is included into the model simultaneously ( Ahmed et al., 2009 ). This method can be seen as a MW approach, since the model is always trained using a fi xed number of the most recent samples. The RPLS allows the adaptation to the new events and the partial retention of the process history. Here, the RPLS starts by calculating the mean and variance of the initial training data. Then, the data are mean-centered and variance-scaled to design a model using the SIMPLS. When a new sample is available, the model is employed to predict it. Then, the mean and variance data are updated using the new sample. Next, the new sample is included to, and the oldest sample is removed from, the previous training data set. The data are scaled and the SIMPLS is repeated to design a new model.

The models of the AddExp.C are implemented using RPLS models, each one trained using the most recent m samples. The parameters are set based on the pilot studies from Kolter and
Maloof (2005) :  X   X  0.5,  X   X  0.1, and  X   X  0.05. In our experiment, the ensemble is adapted on a sample basis. If a new model should be included at time step t , its training data is obtained as
D  X f X  x i ; y i  X g t i  X  t m  X  1 D . As the AddExp.C requires the output data to be normalized to the interval of [0,1], the outputs of all the data sets for all the methods are normalized to this interval.
As the Learn  X  X  .NSE is an algorithm for classi fi cation tasks, a new scheme is proposed to adapt it for regression tasks. Learn NSE was implemented using a boosting regression algorithm, the
AdaBoost.RT ( Shrestha and Solomatine, 2006 ). Each time step of the Learn  X  X  .NSE consists of a batch of samples (it can be viewed as the window's size). Therefore, the batches are considered to have size m . The Weak Learner is the SIMPLS. Parameters of the
Learn  X  X  .NSE are set according to the authors' suggestions ( Shrestha and Solomatine, 2006 ): a  X  0.5 and b  X  10, The ILLSA is implemented according to the works ( Kadlec and
Gabrys, 2011; Miranda, 2012 ). The ILLSA is simulated by dividing the data set D into two data sets: 30% of D is used as a training data set (the initial samples of D ), for building the pool of RPLS models; and 70% of D is used as an on-line data set (the ending samples of D ). Therefore, the on-line data set of ILLSA is different from the other methods. Here, even if only one concept is detected on the training data set to train one model, two models are designed to assure that an ensemble is designed. ILLSA does not have an ensemble pruning strategy. The size of the initial window, n init , is set as m . In each experiment, the optimal values of the kernel size (  X  ) and the kernel size for the adaptation masks ( are chosen by 10-fold cross-validation (using the training data) using values in the range of f 10 4 ; 10 3 ; 10 2 ; 10 1 ; The OWE and pruned OWE are implemented according to Algorithm 1 , where the SIMPLS is used as a Weak Learner. Based on pilot studies,  X  is set to 0.05 for the OWE, pruned OWE and Learn  X  X  .NSE; since in our tests, large values of  X  produce unstable systems. For the pruned OWE,  X  is set to 1 and B is set to 20; and for the OWE,  X  is set to 0. For each experiment, the result is obtained by averaging 20 independent runs. 5.3. Analysis of OWE parameters
The parameters' setting is discussed in this section. In on-line ensembles, the frequency of adding new models may impact the ensemble's performance, and the discounting factor  X  can be tuned according to the data characteristics. Based on pilot studies, tests of the OWE algorithm are conducted by varying  X  from 0.01 to 0.1 in steps of 0.01 (  X  lower than 0.01 produces a very large number of models and increases the computational time, while greater than 0.1 may produce inaccurate ensembles); varying from 0 to 0.95 (in steps of 0.05) and also using  X   X  0.99 (its values range over all the interval of 0 r  X  o 1 for analyzing its behavior); and varying m in the following ranges: m A f 20 ; 30 ; 40 ; 50 ; 60 g , for the arti fi cial data sets; m A f 10 ; 15 ; 20 ; 25 ; 30 g , for the industrial data sets. These ranges of m are suf fi cient to analyze the behaviors with the other parameters.
 It has been observed that for the hyperplane data set and the Friedman-GnRG data set, the OWE's performance improves when  X  increases. While for the other arti fi cial data sets, OWE has almost constant accuracy when  X  varies. For the industrial data sets, the accuracy of OWE slightly improves when  X  decreases. From the performed analysis it is seen that the most adequate  X  depends on the characteristics of each data set, i.e. in data sets that require faster adaptation capability,  X  should be set to a low value for including new models at a higher frequency. For data sets with small amounts of concept changes and that require low adapta-tion,  X  should be set to a large value for adding new models in a low frequency. In the tests below,  X  is set to 0.10 for the arti data sets, and to 0.04 for the industrial data sets.

The MSE results of the OWE when  X  varies using all the data sets are shown in Fig. 3 . The tests show that for the hyperplane data set and Friedman-GnRG data set, OWE performs well when assumes small values; And in this case, the MSE increases substantially when  X  is 0.99. This happens because both data sets have non-recurring drifts and more importance should be given to the current concept. Therefore, the ensemble has better perfor-mance when the total error rate of each model is assigned by decreasing the contribution of the old window errors, and conse-quently, increasing heavily the contribution of the recent window errors. In contrast, on the Friedman-GRA data set, which is a recurring drift data set, OWE improves signi fi cantly its perfor-mance when  X  is large, since the total error of the models takes more into account the errors on the old windows. For the Friedman-LA data set, OWE has almost constant accuracy when varies. In the catalyst activation data set, it is observed that OWE performs well when  X  is low; while in the FCCU data set, OWE oscillates its performance when  X  varies. In the tests below, to 0.2 for all the data sets, except for the Friedman-GRA where set to 0.99. 5.4. Experimental results using arti fi cial data sets
Results. In this section, results of the algorithms using the arti fi cial data sets are detailed and analyzed. Results of the ILLSA can be hidden in some fi gures due to its large errors when compared to the other methods, making dif fi cult the analysis of the experiments. The fi rst test aims to determine the impact of the window's size on the algorithms' accuracies. Fig. 4 shows the algorithms' errors when the window's sizes m varies from 10 to 150 (in steps of 5). This range was chosen in pilot tests that indicated that, for all the approaches, the accuracies do not signi fi cantly improve when m is greater than 150 (see Fig. 4 ). As can be observed, m is a factor that may in fl uence the algorithms' accuracies. The results indicate different behaviors when m varies.
But in most cases, the approaches' accuracies increase when m is large. Fig. 4 (b) and (c) shows that all the algorithms' errors do not signi fi cantly reduce after m  X  100. Table 2 shows the average and standard deviation of the MSE results of all the approaches on all values of m ; bold font is used to indicate the best result in each data set. The MSE results reveal that OWE and pruned OWE have the best accuracies in most cases. The exception is in the hyper-plane data set, where AddExp.C outperforms (6.34 10 3 )OWE (13.35 10 3 ) and pruned OWE (6.95 10 3 ) on average. In the
Friedman-LA data set, OWE and pruned OWE have achieved the lowest errors (6.46 10 3 and 7.11 10 3 , respectively); while other approaches have MSE greater than 8 10 3 on average. In the Friedman-LA data set, OWE and pruned OWE also outperform (11.78 10 3 and 11.81 10 3 , respectively) AddExp.C, pruned
AddExp.C, RPLS, Learn  X  X  .NSE and pruned Learn  X  X  (13.08 10 13.13 10 3 , 13.67 10 3 , 13.87 10 3 and 13.91 10 3 , respec-tively) on average. In the Friedman-GnRG data set, pruned OWE has the lowest error (10.86 10 3 ), while other methods have errors greater than 12 10 3 . It is observed that OWE and pruned
OWE have the lowest standard deviation of the MSE when compared to the state-of-the-art approaches.

A test is applied to show the impact of the ensemble size (maximum number of models) on the algorithms' accuracies. Fig. 5 shows the MSE errors of the pruned ensembles when the max-imum number of models is increased ( m is set to 40). For the drifting Friedman data sets, the Learn  X  X  .NSE and the AddExp.C have constant accuracies when the maximum number of models increases; while the OWE tends to reduce the error when the maximum number of models increases. However, for the hyper-plane data set, the OWE performs better when the maximum number of models is small. Table 3 shows some details of all the approaches using the arti fi cial data sets. The values are calculated by obtaining the average and standard deviation of the running (computation) time and the number of models using different values of m for each algorithm. Learn  X  X  .NSE and pruned Learn  X  X  .NSE have the lowest running time among all the meth-ods (including the single model RPLS). OWE and AddExp.C produce larger number of models when compared to ILLSA and Learn  X  X  .NSE. It can be observed that the ILLSA produces less models than the other methods.

Discussion. ILLSA has achieved the largest error when compared to the other approaches. This is because, in ILLSA, each model is trained with a different concept of the training data set; And, if the training data contains few concepts (for example, the Friedman-GRA data set, which contains one concept in the training data set), few models are built and they may be insuf fi cient to deal with the dynamics of the data during the on-line phase. Regarding Learn NSE and RPLS, they rarely outperform OWE and AddExp.C algo-rithms. In the Learn  X  X  .NSE, the ensemble is adapted only when a new batch is available, requiring a long period of time for system adaptation. In contrast, sample-based ensembles (such as the OWE and the AddExp.C) have faster adaptation capability, since the ensembles are adapted on a sample basis. The RPLS is also adapted on a sample basis, but it employs few strategies to deal with concept drifts: the only strategy is to recursively include each new sample into the model at each time.

AddExp.C has good prediction performance when compared to the Learn  X  X  .NSE and RPLS algorithms; and to the OWE for some values of m (mainly in the hyperplane data set). AddExp.C out-performs RPLS since AddExp.C is a dynamic ensemble of models, while RPLS is composed of only one model. This shows that an ensemble is generally more accurate than any single model. AddExp.C outperforms Learn  X  X  .NSE, because in the AddExp.C, the ensemble is adapted when a sample is available (rather than on a batch basis). AddExp.C has worse performance when com-pared to the OWE for the drifting Friedman data sets. In the AddExp.C, when a new sample is available, all the models are re-trained using such new sample. After some time, the models become very similar. This occurs because the models start to contain only information about the recent samples, since the recursive learning excludes the oldest samples. In this way, the old models start to lose information about the old scenarios. In recurring drifts, if the system becomes to lose information about the past concepts, the system takes more time to react to them when they recur.

In summary, the results in the data sets indicate that the OWE has better or comparable performance to the other state-of-the-art methods. The good accuracy of OWE is attributed to the develop-ment of a set of mechanisms. For example, OWE keeps a set of diverse models trained with different parts of the data so that when an old concept recurs, old models can be re-activated and the system performs well. Additionally, in the pruned OWE, the pruning strategy removes the model with the worst performance on the old and current windows. This strategy is important to assure the ensemble's performance in recurring scenarios, since it reduces the probability of excluding good models that belong to old concepts. OWE dynamically launches new models if the ensemble's performance is poor on the newest sample. Further-more, the models' weights are obtained by taking into account their accuracies on the recent and past windows.

Common behaviors are observed in the experiments. For example, pruned ensembles outperform ensembles without prun-ing strategy in the non-recurring drifts; and ensembles without pruning strategy outperform pruned ensembles in the recurring drifts. In recurring drifts, since an old concept recurs, the pruning strategy may exclude models trained on an old concept. On the other hand, in non-recurring drifts, the pruning strategy can be seen as a way to remove redundant models and keep the most accurate set of models that maximize the performance on the current concept. 5.5. Experimental results using industrial data sets data sets are presented in this section. The algorithms' accuracies when the window's sizes vary from 10 to 20 (in steps of 1) are shown in Fig. 6 . This range was chosen in pilot tests that indicated that, for all the approaches, the accuracies do not signi improve when m is greater than 20  X  . The test indicates that the
OWE has the lowest error when compared to the other methods in most values of m . For the FCCU data set, most approaches achieve smaller errors for large m . Table 4 shows the average and standard deviation of the MSE results of all the algorithms for all values of m , where bold font indicates the best result in each data set. The MSE results indicate that OWE and pruned OWE have the best results in most data sets. In the catalyst activation data set, OWE (0.97 10 3 ) slightly outperforms the RPLS (1 10 3 ) on average; while other approaches have MSE greater than 1 10 3 . In the gasoline concentration prediction (FCCU data set), OWE, pruned
OWE and AddExp.C have achieved the lowest errors on average, i.e. 24.48 10 3 , 26.05 10 3 and 28.92 10 3 , respectively; while most of the other approaches have errors larger than 30 10 3 . In the LDO concentration estimation (FCCU data set), pruned OWE and OWE have the lowest errors, i.e. 33.23 10 3 and 33.41 10 3 , respectively; and other methods have errors larger than 35 10 3 . For the LPG concentration estimation (FCCU data set), AddExp.C has the best accuracy (i.e. 37.08 10 3 followed by OWE (i.e. 37.39 10 3 ). Figs. 7  X  10 show the estimated outputs of each algorithm on its best window's size m as evaluated by the MSE.

Fig. 11 shows the performance of the pruned ensembles when B increases ( m is set to 20). In general, it is observed that the error tends to decrease when B increases. Table 5 shows interesting details of all the approaches. The test shows that OWE produces more models than the other methods. However, in most cases, OWE has smaller running time when compared to AddExp.C. For the catalyst activation data set, ILLSA has produced a larger number of models when compared to the arti fi cial data sets, because this data set contains more concept changes in the training data set.
Discussion. It can be observed that ILLSA and the Learn  X  X  more sensitive to the value of m . The RPLS and ILLSA have achieved better accuracy in the catalyst activation data set when compared to their performances in the arti fi cial data sets. Possibly, in the catalyst activation data set, the dynamics of the process are well represented for designing the set of models in the ILLSA; and for training the model in the RPLS. The AddExp.C and the OWE algorithms outperform the Learn  X  X  .NSE approach. As mentioned before, Learn  X  X  .NSE uses batch learning and it takes longer time to adapt to the changes. In most cases, the tests indicate th at the ensembles without pruning usually have equal or superior performance when compared to their pruned versions. Therefore, this result reveals that a larger number of models may lead to a better ensemble's accuracy. This performance mayberelatedtothediversityamongthemodelsorbecausethedata sets have recurring behavior and, consequently old models are necessary to be re-activated during predictions. 6. Conclusions
This paper proposes a new ensemble to deal with the concept drift: the on-line weighted ensemble of regressor models (OWE).
The proposed ensemble is able to handle several types of drifts, including abrupt and gradual drifts, global and local drifts, and recurring and non-recurring drifts. The ensemble employs several adaptive strategies for avoiding system's degradation in changing environments.

ILLSA, AddExp.C, and Learn  X  X  .NSE) using arti fi cial data sets and industrial data sets have shown that, in general, OWE achieves better accuracy than other state-of-the-art methods, and in some cases, OWE has comparable accuracy to the other state-of-the-art approaches. RPLS assumes that samples that fall outside the moving window are irrelevant for the learning, and such method does not have capability to use the old acquired data, since the oldest samples are discarded. Other methods able to conciliate previous data and current data (e.g. Learn  X  X  .NSE) may perform poorly since a long time is required for system adaptation.
In this paper, the tests show notable behaviors. Results show that, in most cases, ensemble learning outperforms learning using only one single model. The tests also show that OWE has capability to deal with the concept drifts. Our analysis reveals that the frequency of including a new model to the ensemble (  X  ), the contribution of old windows over new windows (  X  ), and the maximum number of models are important issues in on-line ensembles that deal with changing environments.

Other important issues are shown in this paper. In ensemble learning, the re-training of all models on the same data can produce very similar models. In this speci fi c case, the ensemble loses information about the old scenario s, leading the ensemble to a poor accuracy in scenarios where an old concept can recur. In recurring drifts, ensembles without pruning strategies are usually more accurate than pruned ensembles. Since in recurri ng drifts, old concepts can recur, the pruning s trategy may remove important models trained on these old concepts. OWE monitors the models' performances on the current and old windows so that when an old concept recurs, old and accurate models can be re-activated. Despite the attractive characteristics of the OWE, its accuracy is related to the windows' size and the  X  value. To cover these limitations, as a future work, we would to propose a variable window size that adapts according to the process dynamics ( Khediri et al., 2011 ); and an adaptive setting of  X  that is automatically adjusted according to the change of characteristics, e.g. when a change occurs,  X  would be set to a low value to include new models in a high frequency. Moreover, as a future work, the authors would like to introduce other pruning strategies and methods to dynamically adjust other OWE's para-meters over time.
 Acknowledgments Ci X ncia e a Tecnologia (FCT) under the Grant SFRH/BD/68515/2010. Industrial Control Systems Through Process Data  X  (reference:
SCIAD/2011/21531) co-fi nanced by QREN, in the framework of the  X  Mais Centro -Regional Operational Program of the Centro and by the European Union through the European Regional Development Fund (ERDF).

Amparo  X  Pesquisa de Goi X s  X  , in Portuguese). The authors are grateful to Dr. Petr Kadlec and Dr. Yi Liu for providing their data sets.
 References
