 In this paper we focus on the problem of ranking news stories within their historical context by exploiting their content similarity. We observe that news stories evolve and thus have to be ranked in a time and query dependent manner. We do this in two steps. First, the mining step discovers metastories, which constitute meaningful groups of similar stories that occur at arbitrary points in time. Sec-ond, the ranking step uses well known measures of content similar-ity to construct implicit links among all metastories, and uses them to rank those metastories that overlap the time interval provided in a user query. We use real data from conventional and social media sources (weblogs) to study the impact of different meta-aggregation techniques and similarity measures in the final ranking. We evalu-ate the framework using both objective and subjective criteria, and discuss the selection of clustering method and similarity measure that lead to the best ranking results.
 H.2.8 [ Database Applications ]: Data Mining; I.5.4 [ Pattern Recog-nition ]: Text Processing Algorithms, Experimentation Text Mining, Temporal Ranking
Existing technologies for online news browsing allow users to have continuous access to up-to-date news, as well as to a wide range of related opinions and comments coming from the social media. However, the larger-scale problem of aggregating, search-ing, and ranking the historical archives of such content has not been thoroughly addressed. Since news aggregation engines tend to con-struct small, highly consistent, short-lived clusters of similar news articles, the evolution of stories through multiple events that are widely spaced in time is not captured in the archives. Under these conditions, it is difficult to rank stories in the context of a user spec-ified time interval. For example, consider a BBC article 1 the authors attempt to list and rank the most important stories of the past decade. The article points out that the readers who were polled to create the list missed important events such as the sequencing of the human genome. Given the large time-span, and the lack of spe-cific query keywords, a keyword-based search would not succeed in this case either. In addition to this, the proposed ranking was subjective, and thus is likely to disagree with the actual relevance of each story. Therefore, there is a need to answer such and other similar queries in a principled and automatic way.

In this paper we show that the time interval specified in the query should affect ranks of stories whose evolution overlaps the interval. We propose a two-step framework that allows to compute such tem-porally sensitive ranking. First, the metastory mining step employs a clustering method to create metastories by aggregating a set of story clusters, similar to the way news aggregators place stories to-gether. The generation of metastories is a challenging problem be-cause even though the central theme of each metastory is the same, the actual content of the news articles within can vary widely. Sec-ond, the ranking step, selects the metastories overlapping the user-specified time interval and produces their ranking. Ranking is done through link analysis. However, unlike traditional PageRank [6] which is based on hypertext-links, we construct implicit links using content-based similarity between all pairs of active metastories. We exploit the symmetry of similarity measures to avoid the expensive power iteration traditionally used to compute the PageRank vector.
Consider the example of news story aggregation and ranking pro-cess in Figure 1. We use story clusters containing news articles as well as related blogs provided by a state-of-the-art platform for news and social media aggregation called Thoora. Five out of 700 individual story clusters valid during October 2009 are shown in Figure 1(a). As indicated by the arrows, they can be aggregated into metastories corresponding to important events. This metastory aggregation is performed once, over the set of all existing story clusters. The ranking step determines the relative ordering of the metastories with regard to a time interval specified by the user. Fig-ure 1(b) shows two rankings for different query intervals: October 1-31, and October 26-31, 2009. Observe that though metastories http://news.bbc.co.uk/2/hi/8409040.stm are the same, the rankings differ due to time-dependent nature of the ranking process.
Topic Detection and Tracking (TDT) is related to our problem of metastory detection. The goal of TDT is to automatically iden-tify topics within a set of documents, and to keep track of these topics as the document set evolves. Most of the existing TDT algo-rithms focus on the online discovery of new topics from recent data and on the tracking of developments within known topics [2, 1, 12, 18]. The critical difference between TDT and our approach is in the granularity of the clustering. We find, in line with Leskovec et al. [17], that clusters in TDT are too general to represent individ-ual stories evolving through time, and that a much finer clustering is needed. In addition, we merge related stories into metastories with-out any restriction on their temporal distance, and unlike Allan et al. [2] we do not use time decay in our similarity measure. Finally, while standard TDT methods work on reasonably clean news doc-ument data, our initial story components contain news documents and blogs that do not adhere to any standards either of content, language, or structure. This complicates the metastory generation process beyond what standard TDT was designed to handle.
Regarding the document ranking, our framework is closely re-lated to PageRank [6, 5] and HITS [13], two widely used approaches for web-page ranking based on hyperlink analysis. There have been a few attempts to rank documents replacing traditional hyperlinks with links based on similarity scores. In contrast to [23, 14], we as-sume no prior hyperlinks between stories and use solely the content similarity. Furthermore, we argue that using a symmetric similar-ity measure to construct the links is more intuitive and appropriate than asymmetric Kullback-Leibler divergence proposed by Kurland et al. [16, 15]. We show in this work that this property of the simi-larity measure allows very efficient evaluation of PageRank.
Here we formally describe the ranking framework. Let W be a keyword dictionary. A story s is defined as a pair s = h f where f s is the term frequency vector whose entries correspond to particular terms w i  X  W, i = 1 , . . . , | W | and represent the number of times the term w i occurs within s . T s = [ b s , e s of s represented as an interval bounded by two time points, b e . Two lifespans, T  X  and T  X  X  , overlap (or intersect) if T  X   X  T  X  X  6 =  X  . In our particular application scenario, a story refers to a cluster of news and blog articles and its lifespan overlaps all the documents in the story.

From an input set of stories, S , a clustering algorithm constructs disjoint and non-empty subsets S 1 , . . . , S k  X  S , i.e. S and S i  X  S j =  X  for all i 6 = j . Then a metastory m is a triplet m = h S m , f m , T m i , where S m  X  S . Its term frequency vec-tor f m is an aggregation over a set of term frequency vectors, i.e. f m = P s  X  S m f s . Its lifespan T m = [ b m , e m ] refers to the max-imum time-interval covering the entire set of lifespans associated with all stories in S m , b m = min s  X  S m { b s | b s  X  T
We can rank a set of metastories, M , using a content similarity function sim : M  X  M  X  [  X , 1] . Assuming that  X  &gt; 0 is the min-imum similarity between metastories ensures that the graph con-structed through the similarity values is fully connected. Without loss of generality, we also assume that frequency vectors represent proper probability distributions, i.e. they are normalized to have unit mass. Then, the rank of metastory m  X  M is
According to this equation, a metastory should be ranked high if it is similar to other highly ranked metastories. Computing the ranks is equivalent to finding the stationary distribution of a random walk over the graph whose nodes correspond to metastories, and whose edges are the normalized similarities [6]. While in general it is a computationally expensive task, the following lemma that follows from [7] shows that for symmetric similarity measures the computation is straightforward and efficient.

L EMMA 1. For a set of metastories, M , similarity measure sim s.t.  X  m, m  X   X  M sim ( m, m  X  ) = sim ( m  X  , m ) , and some constant  X  we have rank ( M, m ) =  X  P m  X   X  M sim ( m, m  X  ) .

Now we incorporate the temporal dimension into the ranking of metastories. Intuitively, the rank of a metastory that intersect with the lifespan specified in the user query should depend only on those member stories that also intersect the query. This way the temporal aspect associated with a specific query allows us to capture the evolution of stories as illustrated previously in Fig-ure 1. Let Q = [ b Q , e Q ] be the user specified lifespan. For each metastory m  X  M we construct its reduction m  X  that only con-tains stories overlapping the query, i.e. S m  X   X  S m  X   X  s  X  S Accordingly, its term frequency vector is f m  X  = P s  X  S the lifespan starts at b m  X  = min s  X  S the reduced and non-empty metastories, i.e. M Q = { m  X  i of a metastory m  X  M is equal to the rank of its reduced version Figure 2: (a) Clustering entropy as a function of aggregation ratio; (b)Kendall X  X  tau distance between the rankings produced by  X  2 and other similarity measures as a function of query length in the set of all the reduced and non-empty metastories:
To design an optimal temporal ranking framework we must, first, select a clustering algorithm that produces good metastories, then we must choose the similarity measure that ranks the metastories best. Our experimental study provides sufficient information re-garding these two choices and illustrates the usefulness of our ap-proach. The data we collected from Thoora spans 56 days starting from 15 September 2009, and is classified into seven categories: Business, Entertainment, Controversy, Lifestyle, Politics, Science &amp; Technology, and Sports. For each category we create a separate dataset that records the 50 biggest stories for each day yielding on average 700 unique story clusters per dataset. All the experiments are replicated on each dataset and average values as well as stan-dard errors are reported.

Using the expected entropy [3] measure we compare the quality of clustering results obtained from three different clustering meth-ods: efficient graph-based segmentation (ES) [10], Markov Clus-tering (MCL) [22] and the agglomerative Information Bottleneck (aIB) [20]. These methods represent a wide range of clustering paradigms and have been successfully applied in different fields[10, 8, 11, 3, 20]. For the ES and MCL algorithms we use the  X  tance as it has been shown to provide close to optimal performance at a low computational cost [19]. Figure 2(a) shows the expected entropy each algorithm yields as a function of the aggregation ratio. The lower this ratio, the more clusters there are in our system and vice versa. Lower entropy values suggest better clustering quality, small error bars indicate that the entropy results are stable across all categories. The results of this experiment provide us with a princi-pled way to choose the best clustering method among those studied. In the context of our particular problem we have observed that ag-gregation ratios over 30% tend to produce metastories that are too general and do not correspond to a well defined world event. We will, therefore, set the aggregation ratio to a fixed value of 20% . At this ratio MCL and aIB produce equivalent result, yet aIB provides a much finer control of the level of aggregation. Therefore, we will use aIB as the clustering method in all the subsequent experiments.
Having selected the clustering algorithm to produce the metas-tories, we turn to the analysis of the ranking results. In order to see whether the choice of the similarity measure influences the fi-nal outcome we measure the normalized Kendall X  X  tau distance [9], K , between the rankings produced using the following symmet-ric measures that have shown good performance in clustering and retrieval tasks: Jensen-Shannon ( JS ) [20],  X  2 , minimum ( M IN ) and maximum ( M AX ) overlap, Jaccard Coefficient ( JC ), and Co-sine ( COS ) similarity [4]. Distances given by  X  2 and JS are con-verted to similarities by dividing them by maximal distance value and subtracting resulting normalized values from 1. When query lifespans are fixed to cover 100% of the time domain  X  2 and JS rankings are the closest ( K = 0 . 013 ). All the other rankings are significantly distant with JC and M AX being the furthest apart ( K = 0 . 326 ). Fig. 2(b) depicts the average distance between  X  and rankings by other measures as a function of query lifespan. It is apparent that the distance values do not depend on the query, there-fore, it is the similarity function that influences the final ranking independently of the time interval specified in the query and, there-fore, must be chosen in a principled way to yield the best ranking result.

Next, we construct a ground truth ranking based on the social impact of a story measured by the count of blogs related to it. We assume that the more important a story, the more people will blog about it. Fig. 3(a) shows the distance between the framework rank-ings and the ground truth as a function of the size of the query window. Fig. 3(b) shows the average result separately for each category. Overall, we observe that JS and  X  2 perform best and the other measures lag behind. This is reasonable and agrees with the conclusions from [19]. The average Kendall X  X  tau distance for JS is 0 . 2914 which is remarkable given that the ranking relies ex-clusively on the similarity scores with no access to social impact information. This verifies the validity of our ranking approach for situations in which the social impact factor is not available. It is worth noting that the differences in performance over different cat-egories may be indicative of particular properties of stories in each category that may be exploited for ranking purposes. This remains a topic of future work.

We further validate our framework using the Amazon Mechan-ical Turk 2 (AMT). This service facilitates human interaction for answering arbitrary questions. We use the AMT to generate sub-jective ground-truth rankings to use in the evaluation of the ranking framework. For each category we randomly and uniformly sample a subset of 15 metastories and choose one representative title for each of them. Pairs of titles are shown to 11 different AMT users who are asked to choose the one that should be ranked higher. Intu-itively, if a title gets more votes than any other title in its category, it should be ranked first. We construct ranked lists from the pairwise http://www.mturk.com Table 1: Kendall X  X  tau distance between rankings produced by different measures votes using the Schulze method [21] and further refer to them the AMT lists . Table 1 shows the distances between framework, social impact ( SI ) and AMT list rankings. Note that we only compare ranks of the metastories that are part of the AMT lists.  X  and M IN give the best overall ranking with regards to the AMT and the standard error across different categories varies the least for  X  2 and JS indicating that these two measures are the most con-sistent. This is in agreement with the results reported previously in Figure 3(a). An interesting observation is that the distance be-tween BC and the AMT lists is larger than the distance between any distance measure and either BC or the AMT lists. This could very well be caused by cultural and environmental differences be-tween AMT users and the blogger community. However, it is en-couraging to verify that in both cases the similarity measures do a good job of ranking metastories. As a final test, we compared rankings obtained using PageRank and HITS implemented as sug-gested in [16]. While we do not show the full results due to the lack of space, we note that PageRank provides slightly but consistently better ranking at better computational cost.
We have presented a framework for the ranking of evolving sto-ries through meta-aggregation. Metastory ranks are obtained in two steps. First, related stories are clustered into metastories. We ex-plored the issue of selecting an optimal clustering method for this task, and showed that the MCL algorithm yields the best results. Second, the metastories are ranked using implicit links constructed based on their content similarity and the time interval specified by the user. The choice of similarity function for ranking was a sig-nificant factor determining the overall quality of the ranking result. Interestingly, the ranking quality does not depend on the lifespan of the query, but varies across data categories instead. We dis-cussed the efficient computation of metastory ranks and showed that overall the Jensen-Shannon distance measure provides the best and the most stable prediction of the social impact a metastory would have within a specific historical context. Our results con-firm the validity of the framework and its usefulness to determine a time-dependent rank of the metastories in a completely unsuper-vised manner. Future work will focus on scalability issues, includ-ing the efficient computation of metastory representatives, and the incremental computation of ranking results. [1] Gediminas Adomavicius and Jesse Bockstedt. C-TREND: [2] James Allan, Jaime Carbonell, George Doddington, Jonathan [3] Periklis Andritsos, Panayiotis Tsaparas, Ren X e J. Miller, and [4] Ricardo Baeza-Yates and Berthier Ribeiro-Neto. Modern [5] Pavel Berkhin. Survey: A survey on pagerank computing. [6] Sergey Brin and Lawrence Page. The anatomy of a [7] C. S. Chennubhotla. Spectral Methods for Multi-Scale [8] Ouzounis C.A. Enright A.J., Van Dongen S. An efficient [9] Ronald Fagin, Ravi Kumar, and D. Sivakumar. Comparing [10] Pedro F. Felzenszwalb and Daniel P. Huttenlocher. Efficient [11] Oktie Hassanzadeh, Fei Chiang, Hyun Chul Lee, and [12] Jon Kleinberg. Temporal dynamics of on-line information [13] Jon M. Kleinberg. Authoritative sources in a hyperlinked [14] Apostolos Kritikopoulos, Martha Sideri, and Iraklis [15] Oren Kurland and Lillian Lee. PageRank without hyperlinks: [16] Oren Kurland and Lillian Lee. Respect my authority!: HITS [17] Jure Leskovec, Lars Backstrom, and Jon M. Kleinberg. [18] Jakub Piskorski, Hristo Tanev, Martin Atkinson, and [19] Yossi Rubner, Jan Puzicha, Carlo Tomasi, and Joachim M. [20] Noam Slonim and Naftali Tishby. Agglomerative [21] N. Tideman. Collective Decisions and Voting: The Potential [22] Stijn van Dongen. Graph Clustering by Flow Simulation . [23] Gu Xu and Wei-Ying Ma. Building implicit links from
