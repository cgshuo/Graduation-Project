 Sentiment classification [1][2][3][18-20] has gradually become a research hotspot with broad application prospects. A key problem of sentiment analysis is to determine the polarity of a review is positive (thumbs up) or negative (thumbs down). Unlike topic-based text classification [4][21-22], where a high accuracy can be achieved because the topic clusters are typically well-separated from each other, resulting from documents [5]. However, many reviews are sentimentally ambiguous for a variety reasons. Objective statements interleaved with the subjective statements can be confusing for learning methods, and subjective statements with conflicting sentiment further complicate the classification task [6]. 
One of the main challenges for document-level sentiment classification is that not whole document. Thus, we think that making a distinction between key sentence and In this paper, we first propose an approach for key sentence extraction, and then incorporate key sentences in supervised and semi-supervised sentiment classification respectively. 
For key sentence extraction, our approach takes three attrib utes into account: discriminates whether a sentence is accompanied by subjective feelings. Position attribute guarantees that sentences at the beginning and end have higher probability than the middle part. Special words attribute increases the weight for those sentences that contain special words such as  X  X verall X . Finally, a weighted sum model is used to extract the key sentence from each document. 
In supervised learning, a classifier combination approach is adopted. This kind of method requires individual classifier as independent as possible for ensemble methods to work well. In our work, key sentences are usually summative and brief while trivial different and complementary. As a result, key sentence classifier and trivial sentence classifier have different feature space and they provide different knowledge and benefit, that is why classifier combination approach could work well in our approach. 
In semi-supervised learning, a co-training algorithm is proposed to incorporate unlabeled data for sentiment classification. The main idea behind this method is: Key sentences and trivial sentences follow different distributions. When an example can be labeled confidently by the key sentence classifier, it may be not easy to be useful information to improve itself and vice versa. It is the diversity of each classifier that makes co-training algorithm applicable. 
The rest of this paper is organized as follows: Section 2 introduces the related work Section 4 and Section 5 show the supervised and semi-supervised methods on sentiment classification respectively. Experimental results are presented and analyzed in Section 6. Lastly we conclude this paper in Section 7. According to granularity, sentiment classification can be conducted on: words, sentences and documents. According to traini ng mode, sentiment classification can be categorized into: supervised, unsupervised and semi-supervised. In this paper we focus on supervised and semi-supervised document sentiment classification. 
Supervised methods usually regard the polarity predicting task as a classification task and use the labeled corpus to train a sentiment classifier. Pang et al. [1] conducted early polarity classification of reviews using supervised approaches. They employed Support Vector Machines, Na X ve Bayes and Maximum Entropy classifiers using a diverse set of features and concluded that sentiment classification is more difficult than standard topic-based classification. Mullen and Collier [7] used SVM and expanded the feature set for representing documents with favorability measures from a variety of diverse sources. Gamon [8] demonstrated that using large feature vectors in combination with feature reduction, high accuracy can be achieved in the very noisy domain of customer feedback data. Koppel and Schler [9] used neutral McDonald et al. [10] investigated a stru ctured model for jointly classifying the model for sentiment classification based on personal/impersonal views. 
Semi-supervised methods make use of both labeled and unlabeled data for training, typically a small amount of labeled data with a large amount of unlabeled data [12]. Goldberg and Zhu [13] presented a graph-based algorithm that addresses the rating inference problem in the semi-supervised learning setting, where a closed-form solution to the underlying optimization problem is found through computation on a matrix induced by a graph representing inter-document similarity relationships, and the loss function encodes the desire for similar items to receive similar labels. Li et al. [14] employed lexical prior knowledge fo r semi-supervised sentiment classification based on non-negative matrix tri-factorization, where the domain-independent prior knowledge was incorporated in conjunction with domain-dependent unlabelled data and a few labeled documents. Dasgupta and Ng [5] firstly mined the unambiguous reviews using spectral techniques, and then exploit them to classify the ambiguous reviews via a novel combination of active learning, transductive learning, and ensemble learning. The polarity of a review mainly depends on the author X  X  overall evaluation rather than statement that expresses the author X  X  overall attitude or opinion, which is more discriminative than the trivial sentences. Here, we aim to extract the key sentence from the document automatically. There X  X e thr ee attributes to be considered and three functions to be constructed respectively. The final score of each sentence is the weighted sum of three attributes score and sentence with the highest score is considered as key sentence. where m is the number of sentences and each sentence s i is represented as a sequence of words: s i ={w i1 , w i2 , ..., w in } where n is the number of the words. 3.1 Sentiment Attribute The opinion and preference of the product reviews are usually reflected by the opinion words, thus we take opinion words into account and introduce sentiment attribute. Here, sentiment attribute measures the sentiment importance of a sentence and its function is defined as: where positive(w ij ) and negative(w ij ) are defined as : Here, a sentiment lexicon (http://www.keenage.com/ html/e_index.html) is used to identify whether a word is positive or negative. Denominator n of f_sentimen (s i ) is set absolute value is to solve the sentiment ambiguity when a sentence has opposite polarity words. For example,  X  X he computer looks clumsy but works well X , the word  X  X lumsy X  and  X  X ell X  are in the same sentence but have opposite polarity which may confuse the polarity predicting. Therefore, only the unipolar sentiment sentence is regarded as key sentence. Overall, fu nction of sentiment attribute reveals characteristics of the key sentence from two aspects. On one hand, a key sentence is accompanied with emotion and preference and the more the better. On the other hand, the emotion and preference of a key sentence is unipolar and confident. 3.2 Position Attribute Two psycholinguistic and psychophysical experiments showed that in order to one should concentrate computational efforts on messages in the final position of the text [15]. However, the first sentence of the text usually comes straight to the point, so we think that both beginning and ending sentences have higher probability to be a key sentence than the middle part. Function of position attribute is defined as: subject to  X  &gt;0 ;  X  &gt;0 ; where m is the number of sentences in document d ; pos(s i ) is an integer indicating the sentence whose score is the lowest. According to function of position attribute, sentences near the beginning and end will have higher score than the middle part. 3.3 Special Words Attribute Some conclusive words such as  X  X verall X  often appeared in a key sentence, which offers good heuristic information to key sentence extraction. In this paper, we collected ten common special words that us ually occur in key sentences. The special words are collected as follows: Firstly, we suppose that the last sentence of a review is key sentence. Secondly, we compute the frequency of the front unit (segmented by comma) of all pseudo key sentences. Finally, we regard the units with high frequency as special words. 
Function of keyword attribute is defined as: After key sentence extraction, the training data is divided into two parts: key sentences and trivial sentences. Key sentences and trivial sentences follow different word distributions. The feature space of key sentences is usually smaller than that of trivial sentences because key sentence is just one sentence while trivial sentences consist of many sentences. Besides, key sentence is usually summative and trivial discriminative than trivial sentences. In supervised sentiment classification, we adopt classifier combination method. classifier outputs not only the class label but also some kinds of confidence measurements, e.g. posterior probabilities of the testing sample belonging to each class. Secondly, the class label of a testing sample is assigned by the combination of f1, f2 and f3. There X  X e many combining methods, and we choose the simple sum rule as combining rule without loss of generality. 
The chosen sum rule combines base classifiers by adding the posterior possibilities final class label cj is assigned by Equation 7. Classifier learned on key sentences and classifier learned on trivial sentences provide different knowledge and benefits when predicting the polarity of a document. If the document has a key sentence, the key sentence classifier will be more confident about its decision. Furthermore, key sentence classifier is appropriate for ambiguity existing case because it can ignore the complex content and focus on limited features. However, not every document has a key sentence, so trivial sentence classifier is still necessary. 
As mentioned before, key sentence classifier and trivial sentence classifier are from different views and sometimes complementary. If one classifier can confidently that this example will be easy to be classified by the second classifier, so the second classifier will get useful information to improve itself and vice versa. In semi-supervised sentiment classification, a co-training algorithm is adopted. There X  X e three views in our co-training algorithm: key sentence view, trivial sentence view and full-text view. The algorithm of co-training is described as follows: 6.1 Experimental Setup To validate the effectiveness and robustness of proposed method, we conduct experiments on product reviews of eight different domains. The product reviews on the first four domains (book, DVD, electronic, and kitchen appliances) are collected from http://www.amazon.com/ by Blitzer et al. [16]. The product reviews on the other http://www.amazon.com/ by Li et al. [11]. Each of the eight domains contains 1000 positive and 1000 negative reviews. In the experiments, we choose Na X ve Bayesian as base classifier and use all words as features without reduction and selection. In supervised sentiment classification, the baseline classifier is trained on full-text. Besides, if a document has only one sentence, it is regarded as key sentence. 
In supervised sentiment classification, we choose 50% labeled data as training data and the rest 50% labeled for testing for each domain. The classifier combination approach is compared with the baseline cl assifier which is trained on full-text. 
In semi-supervised sentiment classification, we choose 10% labeled data as domain. The co-training approach is compared with the following baseline methods: (1)Self-learning: uses the unlabeled data in a bootstrapping way and only the baseline classifier is used to select most confident unlabeled samples in each iteration. (2)Transductive SVM: seeks the largest separation between labeled and unlabeled data through regularization [17]. (3)Co-training with full-text classifier: samples are selected by three base classifiers and labeled by full-text classifier in each iteration. (4)Co-training with combined classifier based on random key sentence: samples are selected by three base classifiers and labeled by combined classifier based on random key sentence. 6.2 Experimental Results Table 1 presents ten random examples of key sentences extracted from book domain by our method, and the original texts with bold key sentences are shown in appendix. The first five are extracted from positive reviews and the last five are extracted from negative reviews. The evaluation of key sentence is too subjective, thus we don X  X  test the accuracy of extracted key sentences. Seen from the examples in appendix, all key key sentences extraction method. 
To make use of the discrepancy and complementarity of key sentences and trivial sentences, we incorporate the key sentences both in supervised sentiment classification and semi-supervised classification. In the experiments, we first compare the proposed classifier combination approach with the baseline method. Table 2 shows the comparison results in supervised sentiment classification. 
From Table 2, we can see that combined classifier based on the extracted key sentences consistently outperforms the baseline across eight domains with an average performance improvement of 2.84%, which justifies that using key sentences can improve performance of supervised sentiment classification. Moreover, before classifier combination, single classifier trained on key sentences outperforms the key sentences is much smaller than that of full-text. In some case, key sentence classifier is more confident about its decision because of its compact features distribution, such as in  X  X etwork X  domain and in  X  X ealth X  domain, the classifier trained on key sentences even outperforms combined classifier. 
In the experiments of semi-supervised sentiment classification, we set the classifier trained on initial 10% labeled data as baseline and conduct four bootstrapping like methods to compare with our co-training approach. Table 3 shows the comparison results in semi-supervised sentiment classification after 100 iterations. In each iteration, two top-confident samples are chosen in each category, i.e. n1=n2=n3=2. 
Seen from Table 3, co-training with combined classifier based on key sentences significantly outperforms the baseline with 9.41% accuracy improvement across all eight domains on average. On  X  X et X  domain and  X  X ealth X  domain, the accuracy even improves 14%. 
Co-training with random views performs worse than co-training with full-text classifier, which proves that the impressive improvements are mainly due to the key sentences extraction rather than the combination strategy again. Of all the five semi-supervised learning methods, co-training with combined classifier based on extracted key sentences performs best. 
The main reason for the effectiveness of our approach in co-training algorithm is that we don X  X  threat sentences of a document equally. Key sentences and trivial sentences have different feature space and different ways of expressing feelings and opinions. Key sentence classifier can confidently predict the class of an example, which may be not easy to be classified by th e trivial sentence classifier, so the trivial sentence classifier will get useful information to improve itself and vice versa. In this paper, we propose an approach for key sentence extraction, which takes three attributes into account: sentiment attribute, position attribute and special words attribute. After key sentences extraction, we incorporate key sentences and trivial sentences in supervised and semi-supervised sentiment classification. In supervised learning, a classifier combination approach is adopted to take advantage of the discrepancy of key sentences and trivial sentences. In semi-supervised learning, a co-training algorithm is proposed to make each classifier learn from each other. The experiments carried out on eight domains show our classifier combination approach and co-training algorithm significantly improve the performance. Acknowledgments. This work was mainly supported by two funds, i.e., 60933005 &amp; 60803085, and one another project, i.e., 2012CB316303. 
