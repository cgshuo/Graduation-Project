 REGULAR PAPER Francesco Bonchi  X  Claudio Lucchese Abstract Constrained frequent patterns and closed frequent patterns are two paradigms aimed at reducing the set of extracted patterns to a smaller, more inter-esting, subset. Although a lot of work has been done with both these paradigms, there is still confusion around the mining problem obtained by joining closed and constrained frequent patterns in a unique framework. In this paper, we shed light on this problem by providing a formal definition and a thorough characterisation. We also study computational issues and show how to combine the most recent results in both paradigms, providing a very efficient algorithm that exploits the two requirements (satisfying constraints and being closed) together at mining time in order to reduce the computation as much as possible.
 Keywords Closed frequent itemsets  X  Condensed representations  X  Constraints  X  Frequent itemsets mining 1 Introduction find interesting patterns from databases, such as association rules, correlations, sequences, episodes, classifiers, clusters. Although the collection of all frequent itemsets is typically very large, the subset that is really interesting for the user usually contains only a small number of itemsets. Therefore, the paradigm of constraint-based mining was introduced. Constraints provide focus on the inter-esting knowledge, thus reducing the number of patterns extracted to those of po-tential interest. Additionally, they can be pushed deep inside the mining algorithm in order to achieve better performance. For these reasons, the problem of how to push different types of constraints into the frequent itemsets computation has been extensively studied (Ng et al. 1998; Srikant et al 1997; Pei et al 2001). both in terms of time and space, is an even harder problem when mining dense datasets containing strongly related transactions. Such datasets are much harder to mine because only a few itemsets can be pruned by the antimonotonicity of frequency, and the number of frequent itemsets grows very quickly while the min-imum support threshold decreases. As a consequence, the mining task becomes rapidly intractable by traditional mining algorithms, which try to extract all the frequent itemsets. Closed itemsets mining is a solution to this problem. Closed same knowledge in a more succinct way. From the set of closed itemsets, it is straightforward to derive both the identities and supports of all frequent itemsets. Therefore, closed itemsets are said to be a condensed representation of all fre-quent itemsets: mining the closed itemsets is semantically equivalent to mining all frequent itemsets, but with the great advantage that closed itemsets are orders of magnitude fewer than frequent ones.
 closed frequent itemsets is clearly an interesting issue. In a knowledge-discovery system, we would like to express mining queries that include both these two paradigms; thus, we need a clear semantics for such queries. Moreover, we want the computational engine to exploit both requirements at mining time in order to reduce the computation as much as possible instead of using one paradigm to prune the search space and exploit the other one in a postprocessing phase. closed as just another constraint, C close . Consider the following inductive query: which requires mining itemsets that are frequent, are closed and have a sum of prices less than 22. Such a query has ambiguous semantics. In fact, there are two possible different interpretations for query Q :  X  I 1 : Mine all frequent closed itemsets that have the additional property of having  X  I 2 : Mine all frequent itemsets having sum of prices less than 22 and that have In this paper, we shed light on this problem by showing that these two possible in-terpretations produce different solution sets: this is due to the fact that being closed is not a property that an itemset satisfies or not for its own characteristics, but it is a property of an itemset in the context of a collection of itemsets. Then we show that, by the point of view of producing a condensed representation, the interpreta-tion I 2 is the meaningful one and, according to it, we define the closed constrained frequent itemset mining problem . Finally, we study computational issues and we provide a very efficient algorithm, which exploits the two requirements (satisfying constraints and being closed) at mining time in order to reduce the computation as much as possible. The proposed algorithm is a depth-first strategy combin-ing Closet (Pei et al. 2000), which is the FP-growth-based algorithm for mining closed frequent itemset, with FP-Bonsai (Bonchi and Goethals 2004), which is the FP-growth-based algorithm for mining frequent itemsets under a conjunction of monotone and antimonotone constraints. 1.1 Problem definition and notation Let I ={ x 1 ,..., x n } be a set of distinct literals, called items , where an item is an object with some attributes (e.g. price, type, etc.). An itemset X is a nonempty subset of I .If | X |= k ,then X is called a k-itemset . A constraint on itemsets is a function C : 2 I  X  X  true , false } . We say that an itemset I satisfies a constraint if and only if C ( I ) = true. We define the theory of a constraint as the set of itemsets that satisfy the constraint Th ( C ) ={ X  X  2 I | C ( X ) } .
 Definition 1 (Antimonotone constraints) Let X be an itemset, a constraint C AM is antimonotone if Definition 2 (Monotone constraints) Let X be an itemset, a constraint C M is monotone if The support of an itemset X in database D , denoted sup D ( X ) , is the cardinality of the set of transactions in D that are a superset of X . Given a user-defined minimum support  X  , an itemset X is called frequent in D if sup D ( X )  X   X  . This defines the minimum frequency constraint: C freq [ D , X  ] ( X )  X  sup D ( X )  X   X  . When the dataset and the minimum support threshold are clear from the context, we address the frequency constraint simply C freq . Thus, with this notation, the set of frequent itemsets can be denoted Th ( C freq ) .
 the support of each solution itemset, we define a special frequency-theory ,which is a set of couples itemset-support .
 Definition 3 ( F -Theory) Given a nonempty conjunction of constraints C and a transaction database D , we define FTh D ( C ) , switching from one to the other whenever more appropriate. ories, which will be useful to characterise the solution spaces of our mining problems.
 Definition 4 (Closure of an F -Theory) The closure of an F-Theory is a function Cl : FTh D  X  FTh D that restricts the F-Theory to those itemsets that do not have a superset in the F-theory with the same support: Definition 5 (Borders of theories) Given a C AM constraint, we define the border of its theory as eral constraint C we define Analogously, we can define the borders of an F-Theory.
 old,  X  , and a general conjunction of constraints, C , we have the following classical mining problems:  X 
MP  X 
MP  X 
MP  X 
MP and MP 4 . According to the interpretation I 2 , discussed in the Introduction, we provide the following definition:  X 
MP This definition will be proven to be the only reasonable one in Sect. 3 . 1.2 Related work Even if a lot of work has been done with closed itemsets and with constrained itemsets, there are only a few approaches analysing the conjunction of these two frameworks.
 closed itemsets, it is proposed to mine free itemsets, i.e. the minimal elements of each equivalence class of frequency (closed itemsets are the maximal elements of such classes). The output of the algorithm is made with all the free itemsets satis-fying a given set of monotone and antimonotone constraints. The authors propose a variation of the A-CLOSE (Pasquier et al. 1999) algorithm, with constraints pushed into the computation. Free itemset representation is concise, though the number of free sets is greater than the number of closed ones, but it is not lossless. through the dataset are performed. Moreover, we will see how this representation retains the same ambiguity in mining constrained free sets. Because this kind of representation is itself problematic (i.e. it is not lossless) and because it does not bring any advantage in mining the constrained solution space, we will focus on closed itemsets in this paper instead of free itemsets.
 sets mining process. The output of the algorithm is the same as a postprocessing given set of constraints. Convertible constraints are faced as in Pei et al. (2003); thus, single items are reordered to make hard constraints treatable as monotone or antimonotone constraints.
 of the information loss it produces. This choice is explicitly made in order to sim-plify the mining process. In this paper, we quantify such information loss given by the postprocessing approach and give a new accurate definition of the prob-lem of constrained closed itemset mining, which provides a concise and lossless condensed representation of the solution space. 2 Preliminaries In this section, we review and deeply characterise the constrained frequent item-sets mining problem, MP 3, and the closed frequent itemset mining problem, MP 4. The provided characterisation will then be useful to characterise the new problem, MP 5. 2.1 Constrained frequent itemsets Ana  X   X ve solution to the constrained frequent itemset mining problem ( MP 3 )isto first find all frequent itemsets and then test them for constraints satisfaction. How-ever, more efficient solutions can be found by analysing the property of constraints comprehensively and exploiting such properties in order to push constraints in the frequent-pattern computation. Following this methodology, some classes of con-straints that exhibit nice properties (and the relative computational strategies) have been defined in the literature (e.g. antimonotonicity, monotonicity, succinctness, convertibility) (Ng et al. 1998; Pei et al. 2001). In this paper, we focus on the two basic classes of constraints, antimonotone (see Definition 1 )and monotone (see Definition 2 ) constraints.
 tonicity of C freq is used by the Apriori (Agrawal and Srikant 1994) algorithm with the following heuristic: if an itemset X does not satisfy C freq , then no superset of X can satisfy C freq and, hence, they can be pruned. This pruning can affect a large part of the search space because itemsets form a lattice. Therefore, the Apriori al-gorithm operates in a level-wise fashion moving bottom up on the itemset lattice, and each time it finds an infrequent itemset, it prunes away all its supersets. metrically, sum ( X . price )  X  m is a C M constraint. In the rest of this paper, we will consider these two constraints as prototypical C AM and C M constraints without loss of generality.
 and Th ( C freq  X  C M ) .
 1998) because they behave exactly as C freq . Any conjunction of C AM constraints is still a C AM constraint, and, because C freq is a C AM constraint, the solutions space Th ( C subsets of X will be solutions as well. In other words, solution itemsets are those that lie under both borders (the border of frequency and the border of C AM ). Proposition 1 (Characterisation of Th ( C freq  X  C AM ) ) Proof Trivially, by definition of antimonotone constraint and border, posite of frequency. Indeed, C AM constraints can be used to effectively prune the search space to a small downward closed collection, while the upward closed col-lection of the search space satisfying the C M constraints cannot be exploited at the same time. This trade-off holding on the search space of the computational prob-where we analyse alternative algorithmic proposals for this problem. Here, we want just to characterise the space of solutions.
 ple. In Fig. 1 , we have a transaction database, D ,anda item-price table, and monotone constraint, C M  X  sum ( X . prices )  X  33. The solutions to the problem Th ( C border of frequency and over the monotone border. The next proposition states algebraically what we have just seen graphically. Proposition 2 (Characterisation of Th ( C freq  X  C M ) ) Proof Trivially, by definition of border,
X  X  Th ( C M )  X  C M ( X )  X  X  X  Z  X  B + ( Th ( C M )) : X  X  Z . 2.2 Closed frequent itemsets The set of frequent closed itemsets is a condensed representation of frequent item-sets. Condensed representation is a term first introduced in Mannila and Toivonen (1996), which we use to indicate a representation of a theory, which is both concise : the size of the representation is significantly smaller than the original lossless : from the representation, it should be possible to reconstruct all the infor-is a condensed representation (concise and lossless) of Th ( C freq ) , while, for the frequency-theory, FTh D ( C freq ) is just concise but not lossless: in fact, from maxi-mal frequent itemsets, we can reconstruct the full set of frequent itemsets but not their supports.
 representation of FTh D ( C freq ) because closed itemsets are orders of magnitude fewer than the frequent ones and, from them, it is possible to reconstruct all fre-quent itemsets and their supports without accessing the transaction database any more.
 in Pasquier et al. (1999) and, since then, it has received a great deal of attention, especially from an algorithmic point of view (Lucchese et al. 2004; Pei et al. 2000, 2003; Zachi and Hsiao 2002).
 us to strongly reduce problem complexity. Moreover, association rules extracted from closed sets have been proven to be more concise and meaningful because all redundancies are discarded.
 to generate frequent sets, for each closed itemset, we must generate all of its possi-ble subsets, and their support is equal to the support of the smallest closed itemset containing them.
 all the items included in the set of transactions T ,and g ( X ) ={ t  X  D | X  i  X  X , i  X  t } , which returns the set of transactions supporting a given itemset X ,the composite function f  X  g is called the Galois operator or closure operator .We have the following definition: Definition 6 An itemset I is said to be closed if and only if c ( I ) = f ( g ( I )) = f  X  g ( I ) = I .
 itemsets, where two itemsets, X , Y , belong to the same class if and only if c (
X ) = c ( Y ) , i.e. they have the same closure. Closed itemsets are exactly the max-imal elements of these equivalence classes. Figure 2 shows the lattice of frequent itemsets derived from the same simple dataset of Fig. 1 . Each equivalence class contains elements sharing the same supporting transactions, and closed itemsets { abc , 3 , bc , 6 , bcd , 4 , bcde , 3 , bce , 4 } . Note that the number of closed frequent itemsets (5) is much less than the number of frequent itemsets (19). advantage that these representatives are orders of magnitude fewer than frequent itemsets. But representatives must be chosen in such a way that every frequent itemset and its support can be derived from the set of representatives without any other scan of the dataset.
 retain exactly the same information of frequent itemsets. Because they include the upper border of the frequency theory and because such theory is downward closed, they identify every frequent itemset in the dataset. Moreover, because their equivalence classes group itemsets having the same support, also the support information of each frequent itemset can be reconstructed without additional best choice of a representative in deriving association rules because they avoid redundancies retaining interesting knowledge.
 representation of frequent itemsets and we investigate how this paradigm can be merged with the constrained frequent pattern mining paradigm.
 the border of frequency (as shown in Fig. 2 ); but what happens to these equiva-lence classes when they are cut by some C AM or C M constraints? characterisation of MP 5 . 3 Closing antimonotone constraint theory Recall the mining query discussed in Sect. 1, The two different interpretations of Q are as follows (where C AM  X  sum ( X . prices )  X  22): sets.
 Example 1 In Fig. 3 . we show the usual itemsets lattice with the frequency equiv-alence classes and the border of the theory of C AM  X  sum ( X . prices )  X  22. { ac , 3 , bc , 6 , bd , 4 , cd , 4 , ce , 4 cde , 3 } .
 constraint. With interpretation I 1 , we mine closed frequent itemsets and then we remove those that do not satisfy the C AM constraint: this way, we lose the whole in-formation contained in those equivalence classes cut by the C AM constraint. On the other hand, according to interpretation I 2 , we mine the set of itemsets that satisfy the C AM constraint and then we compute the closure of such itemsets collection: thus, by definition, the itemsets bd and cd are solutions because they satisfy C AM and they have not a superset in the result set with the same support and satisfying the constraint.
 for all those applications in which closed itemsets are seen as condensed repre-sentation (concise and lossless) of frequent itemsets, it is straightforward to see that interpretation I 1 is not appropriate because it loses a lot of information. In ex-treme cases, it could output an empty solutions set even if there are many frequent itemsets that satisfy the given set of user-defined constraints. On the other hand, is reasonable to choose interpretation I 2 as the definition for the mining problem MP the C AM border (as I 1 ) plus those itemsets that arise in equivalence classes that are cut by the C AM border (such as, for instance, ce and cde in Fig. 3 ). Proposition 3 (Characterisation of Cl ( FTh D ( C freq [ D , X  ]  X  C AM )) ) Proof Given an itemset X  X  I 1 = Cl ( FTh D ( C freq ))  X  FTh D ( C AM ) ,wehavethat C by definition of closure of an F -Theory (Definition 4 ), it holds that  X  X  Y  X  X | and therefore, X  X  Cl ( FTh D ( C freq  X  C AM )) holds.
 tified in Fig. 4 . 3.1 On the size of the closure terns and closed frequent patterns are paradigms aimed at reducing the set of ex-tracted patterns to a smaller, more interesting, subset. When conjoining the two paradigms, one would expect to have a stronger reduction on the number of ex-tracted patterns.
 |
Cl ( FTh D ( C freq )) |= 5. Thus, adding an antimonotone constraint to closed frequent itemset we have increased the number of extracted patterns. This is due to the equivalence classes of bcd that, when intersected by the C AM constraint, generates two representatives on the cut ( bd and cd ) instead of having a single representative per class, as happens with closed frequent itemsets.
 a condensed representation for FTh D ( C freq  X  C AM ) . Because such a theory puts together two concepts, it is more complex than the simple theory of frequency, i.e. it has a more jagged border, and thus it is not surprising that it has a more complex condensed representation as well.
 pends on the selectivity of the C AM constraint; and usually, on real datasets, with reasonably selective C freq and C AM , it is not the case.
 given C AM constraint. We have that equivalence classes intersected by C AM and its complement.
 for each element of I 3 a , it contains one or more element, while it does not contain I 3 b at all.
 +  X  . Therefore, we can conclude that size of I 1 decreases. This is confirmed by our empirical analysis. datasets, with the constraints C AM  X  sum ( X . prices )  X  m . The datasets used in our tests are those of the FIMI repository, 1 , and the constraints were applied on at-tribute values (e.g. pr i ce ) randomly generated with a Gaussian distribution within the range [0 , 150,000].
 ference in size between I 2 and Cl ( FTh D ( C freq )) .InFig. 4 a, we can see that, as than the number of closed frequent itemsets: this is a very small difference, and it represents the  X  given in the equation above. However, as the selectivity of the constraints grows, I 2 becomes much smaller than Cl ( FTh D ( C freq )) .InFig. 4 b, I 2 is always smaller than Cl ( FTh D ( C freq )) , even for not so selective constraints. terpretation I 1 w.r.t. interpretation I 2 . On both datasets, PUMSB and CHESS, this difference rises up to 10 5 itemsets. It is interesting to observe that the dif-ference is larger for medium selective constraints. This seems quite natural be-cause such constraints probably cut a larger number of equivalence classes of frequency. 4 Closing monotone constraint theory Let us move to the dual problem. In Fig. 5 , we show the usual equivalence classes and how they are cut by C M  X  sum ( X . prices )  X  33. Because C M constraints are upward closed, we have no problems with classes that are cut: the maximal element of the equivalence class will be in the alive part of the class. In other words, when we have a C M constraint, the two interpretations I 1 and I 2 correspond. Proposition 4 (Characterisation of Cl ( FTh D ( C freq [ D , X  ]  X  C M )) ) Proof It is possible to prove that I 2 = Cl ( FTh D ( C freq  X  C M ))  X  I 1 = Cl ( FTh D ( C straints (see proof of Proposition 3 ).
  X  X  Y  X  X | sup D ( X ) = sup D ( Y )  X  C monotonicity property, we can conclude that  X  X  Y  X  X | sup D ( X ) = sup D ( Y ) . Therefore, X is closed w.r.t. the frequency and it satisfies the constraint C M ,i.e. X  X  Cl ( FTh D ( C that are subsets of elements in Cl ( FTh D ( C freq  X  C M )) against C M in order not to however, we do not need to access the dataset D anymore.
 actually two choices: on one hand, we can test for monotone constraints where needed; on the other hand, we could store the monotone border B + ( Th ( C M )) dur-ing the mining and use it to avoid additional constraints checks later during the frequent itemset regeneration. The two solutions are alternative: the first one is more appropriate when dealing with monotone constraints that are cheap to be checked; the second one is much more suitable whenever testing monotone con-straints is too expensive.
 good trade-off among performance, conciseness and meaningfulness with the use of Cl ( FTh D ( C freq  X  C M )) as condensed representation, without storing the border. 5 Algorithms In this section, we study algorithms for the computation of MP 5 .Wefirstdis-cuss separately how monotone and antimonotone constraints can be pushed in the computation, then we show how they can be exploited together by introducing the CCIMiner algorithm. 5.1 Pushing monotone constraints As shown in Ng et al. (1998), pushing C AM constraints deep into the frequent itemset mining algorithm is easy and effective. Any conjunction of antimono-in the same way as the frequency constraint, dramatically reducing the search space.
 between a downward-closed collection of itemsets given by C freq and an upward-closed collection of itemsets satisfying C M . These two prunings cannot be ex-ploited at the same time while visiting the lattice, and therefore a trade-off between the two arises.
 cila et al 2001; De Raedt and Kramer 2001), but all these studies have failed to find the real synergy of these two opposite types of constraints, until the recent proposal of ExAnte (Bonchi et al. 2003b). In that work, it has been shown that a real synergy of the two opposites exists and can be exploited by reasoning on both the itemset search space and the transactions input database together . whether it can support any solution itemset, and if it is not the case, it can be pruned. In this way, we prune the dataset, and we get the fruitful side effect of lowering the support of many useless itemsets, that, in this way, will be pruned be-cause of the frequency constraint, strongly reducing the search space. Such an ap-proach is performed with two successive reductions:  X  -reduction (based on mono-tonicity) and  X  -reduction (based on antimonotonicity). According to  X  -reduction, we can delete transactions that do not satisfy C M ; in fact, no subset of such trans-actions satisfies C M and, therefore, such transactions cannot support any solution itemsets. After such a reduction, a singleton item may happen to become infre-quent in the pruned dataset, and thus it can be deleted by the  X  -reductions. Of course, these two steps can be repeated until a fixed point is reached, i.e. no more pruning is possible.
 like breadth-first computation in ExAMiner (Bonchi et al. 2003c) and in an FP-growth (Han et al. 2000) based depth-first computation in FP-Bonsai (Bonchi and Goethals 2004).
 ing closed itemsets and because FP-Bonsai has proven to be more efficient than ExAMiner, we decide here to use an FP-growth-based depth-first strategy for the mining problem MP 5 . Thus, we combine Closet (Pei et al 2000), which is the FP-growth-based algorithm for mining closed frequent itemsets, with FP-Bonsai, which is the FP-growth-based algorithm for mining frequent itemsets with C M constraints.
 a conditional dataset, D | X , has to be analysed, where X is a frequent itemset. New itemsets I are created adding to X ={ I  X  i } one by one the single frequent items i  X  D | X (lines 2 and 3). Then, for every such itemset I , a new conditional dataset, D | I , is created, adding only transactions containing I and satisfying the monotone constraint C M (lines 5 X 7). This last  X  -reduction strongly reduces the projected dataset and, as a side-effect, will boost the  X  -reduction (lines 8 X 10) by reducing the number of frequent singleton items as well as the number of dataset projections to be exploited in the subsequent recursion over D | I (line 11). In this pseudo-code, the  X  and  X  reductions are exploited just once.
 extend FP-Bonsai just gathering singleton items that have the identical support in the same conditional dataset, i.e. that are supported by the same transactions (Algorithm 3, line 19). We will see later in detail this Closet-like computation when mining with monotone and with antimonotone constraints together. 5.2 Pushing antimonotone constraints Antimonotone constraints, C AM , can be easily pushed in a Closet-like computation by using them in the exact same way as the frequency constraint, exploiting the downward closure property of antimonotone constraints. During the computation, as soon as a closed itemset, X s.t.  X  C AM ( X ) , is discovered, we can prune X and all its supersets by halting the depth-first visit. But whenever such closed itemset, X s.t.  X  C AM ( X ) , is met (e.g. bcd in Fig. 3 ), some itemsets, Y  X  X , belonging to the same equivalence class and satisfying the constraint may exist (e.g. bd and cd in Fig. 3 ). For this reason, we store every such X in a separate list, named E dge and, after the mining, we can reconstruct such itemsets, Y , by means of a simple top-down process, named Backward-Mining , described in Algorithm 2.
 set starting from the border defined by E dge without getting into equivalence classes that have been already mined (line 10). If such subset satisfies the con-straint, then it can be added to the output (line 12); otherwise, it will be reused later to generate new subsets (line 14). If we have a monotone constraint in conjunction, the backward process is stopped whenever the monotone border, B + ( Th ( C M )) ,is reached (lines 3 and 8). 5.3 Discussion: closed versus free itemsets Note that we could avoid the need of a backward mining by using minimal elements of equivalence classes (or free sets ) as representative instead of maximal ones (Boulicaut and Jeudy 2001). But in this way, we only shift the problem leading to a symmetric situation. Using free sets interpretations, I 1 and I 2 coincide when dealing with antimonotone constraints because minimal elements are not cut off by the constraint (e.g. de in Fig. 3 ), but I 1 is lossy when dealing with monotone constraints (e.g. no free solution itemsets in Fig. 5 ).
 free itemsets. Minimal elements are not a concise representation of unconstrained frequent itemsets because the upper border cannot be determined without supple-mentary support count steps over the dataset. The frequency border is needed to identify the collection of frequent itemsets. Not only are they not lossless, but they are also less concise because, while we can have only one maximal element for each equivalence class, minimals are likely to be more than one; therefore, they are redundant in this sense.
 mal ones. First, maximal elements are obliviously longer, and thus we can assert that they give a more complete knowledge about the dataset. Second, for every equivalence class, minimal elements will generate many more association rules with the same support and confidence we would have using maximal elements, i.e. we would have redundant association rules that would be better represented with maximal elements.
 a condensed representation of the solution space. 5.4 Closed constrained itemsets miner The two techniques that have been discussed above are independent. We push monotone constraints working on the dataset and antimonotone constraints working on the search space. It X  X  clear that these two can coexist consistently. In Algorithm 3, we merge them in a Closet-like Computation, obtaining CCIMiner . datasets are built at each recursion, exploiting both  X  and  X  reductions (lines 11 X 16). Note that only itemsets that satisfy monotone constraints are actually added to the solution (line 6). To deal with closed itemsets, we added a gather-ing step (lines 17 X 20) where, given one itemset, I , all the items with the same support of I in its conditional dataset, and therefore belonging to its closure, are added to I and deleted from the dataset. Moreover, because multiple paths of the visit can lead to the same closed itemset, we devised the usual duplicate detection technique (line 9). As described in the previous section, itemsets that do not satisfy the antimonotone constraint are stored in a separate list (line 3) for use later. and solution MP 5 given by CCIMiner have to be processed by Backward-Mining 5.5 Experimental results All the tests were conducted on a Windows XP PC equipped with a 2.8-GHz Pentium IV and 512 MB of RAM memory, within the cygwin environment. The were applied on attribute values (e.g. pr i ce ) randomly generated with a Gaussian distribution within the range [0 , 150,000].
 reported. On every dataset tested, the number of FP-trees decreases about four orders of magnitude with the increasing of the selectivity of the constraint. This means that the technique is quite effective independently of the dataset. w.r.t. Closet at different selectivity of the constraint. Because the postprocessing approach must first compute all closed frequent itemsets, we can consider Closet execution time as a lower bound on the postprocessing approach performance. Recall that CCIMiner exploits both requirements (satisfying constraints and being closed) together at mining time. This exploitation can give a speed of up to two or-ders of magnitude, i.e. from a factor 6 with the dataset CONNECT, to a factor of 500 with the dataset CHESS. Obviously, the performance improvements become stronger as the constraint becomes more selective. 6 Conclusions In this paper, we have addressed the problem of mining frequent constrained closed patterns from a qualitative point of view. We have shown how previous works in literature overlooked this problem by using a postprocessing approach that is not lossless, in the sense that the whole set of constrained frequent patterns cannot be derived. Thus, we have provided an accurate definition of constrained closed itemsets w.r.t the conciseness and losslessness of this constrained represen-tation, and we have deeply characterised the computational problem. Finally, we have shown how it is possible to quantitatively push deep both requirements (satis-fying constraints and being closed) into the mining process, gaining performance benefits with the increasing of the constraint selectivity.
 References
