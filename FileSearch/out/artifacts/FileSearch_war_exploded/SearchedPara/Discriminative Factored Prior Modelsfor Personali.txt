 Most existing content-based filtering approaches including Rocchio, Language Models, SVM, Logistic Regression, Neu-ral Networks, etc. learn user profiles independently without capturing the similarity among users. The Bayesian hierar-chical models learn user profiles jointly and have the advan-tage of being able to borrow information from other users through a Bayesian prior. The standard Bayesian hierar-chical model used in filtering assumes all user profiles are generated from the same Gaussian prior. However, consid-ering the diversity of user interests, this assumption might not be optimal. Besides, most existing content-based fil-tering approaches implicitly assume that each user profile corresponds to exactly one user interest and fail to capture a user X  X  multiple interests (information needs).

In this paper, we present a flexible Bayesian hierarchi-cal modeling approach, which we call Discriminative Fac-tored Prior Models (DFPM), to model both commonality and diversity among users as well as individual users X  mul-tiple interests. In our models, each user profile is modeled as a discriminative classifier with a factored model as its prior, and different factors contribute in different levels to each user profile. Compared with existing content-based fil-tering models, DFPM are interesting because they can 1) borrow discriminative criteria of other users while learning a particular user profile through the factored prior; 2) trade off well between diversity and commonality among users; and 3) handle the challenging classification situation where each class contains multiple concepts. We propose and im-plemented two specific discriminative factorization models based on different assumptions. The experimental results on a dataset collected from real digg.com users show that our models significantly outperform the baseline models of L-2 regularized logistic regression and the standard Bayesian hierarchical logistic regression models.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation Recommender System, Personalized Recommendation, In-formation Filtering, Content-based Filtering, Bayesian Hi-erarchical Model, Factorization
Existing content-based filtering research is largely influ-enced by the Filtering Track organized by TREC, where the task is to identify documents relevant to a specific topic from a document stream. There are two major approaches to handle this task. One is to use traditional IR retrieval mod-els (Boolean model, traditional probabilistic models, vector space model, language models, etc.) initially designed for ranking and a threshold setting algorithms for online fil-tering. Another approach is to treat filtering as a classifi-cation task, and thus many existing machine learning ap-proaches (Naive Bayes, Decision Tree, Logistic Regression, SVM, Neural Networks, etc.) could be used. However, both approaches learn each user profile independently and do not make use of the commonality among users.

Yu et al[4] and Zhang et al[6] introduced the Bayesian hi-erarchical modeling approach to jointly learn user profiles for content-based filtering. Based on the fact that different users may have similar interests, the Bayesian hierarchical models assume that all user profiles are sampled from a com-mon Gaussian prior. The Bayesian hierarchical modeling approach helps alleviate the cold-start problem since it is able to borrow discriminative information from other users through the common prior when learning a particular user profile, especially for those users with little training data.
However, some users may have totally different interests, and requiring these users X  profiles to follow the same Gaus-sian prior distribution may negatively influence the learned profiles, thus we need to trade off better between the di-versity and commonality of user profiles. Besides, almost all existing content-based filtering approaches cannot cap-ture the multiple interests of a user. They implicitly assume each user profile only corresponds to a single interest, which does not fit the real scenarios in personalized recommenda-tion, where a real user X  X  interests may contain multiple con-Figure 1: Left: The Bayeisn Hierarchical Model (BHM). Right: The Discriminative Factored Prior Model. cepts/topics. For example, a graduate student working on information retrieval may be interested in both IR research advancements and NBA news.

To better model the diversity and commonality of users and each user X  X  multiple interests, this paper proposes a flex-ible Bayesian hierarchical modeling approach for personal-ized content-based recommendation.

The discriminative factorization models in this paper are motivated by the theoretical attractiveness of factorized topic models as well as the empirical success of discriminative models. Factorization-based generative topic models, such as Probabilistic Latent Semantic Analysis (PLSA) and La-tent Dirichlet Allocation (LDA) are very attractive theoret-ically. However, we are not aware of any empirical evidence of their effectiveness in competitive retrieval and filtering tasks. This is not surprising since most of the successful models in these tasks are discriminative models, such as Logistic Regression or SVM, instead of generative models, such as Naive Bays. Though our models also introduce la-tent factors, there are clear differences between our models and PLSA/LDA. Unlike PLSA and LDA, we learn user pro-files as discriminative functions. The entries of each factor in our models are not necessarily words, and could be any item features such as the time or authority of a document. We noticed that our model is very similar to the multi-task learning model proposed by an independent group of re-searchers [5]. However, the existing paper was focusing on multi-task learning and used Reuters document classifica-tion task for evaluation, while our work emphasizes on the application of personalized recommendation, which has very different characteristics and challenges.
Our Discriminative Factored Prior Models (Figure 1 (right)) are motivated by the well known Bayesian hierarchical model in Figure 1 (left)[4, 6]. There are M users in total and each user has J m training examples. w m is the profile of user In BHM, all user profiles follow a Gaussian prior distribution with mean vector  X  and covariance matrix  X  . In DFPM,  X  is a K  X  H matrix, and  X  m is a user-dependent vector with length H . The product of  X  and  X  m determines the prior mean of each user profile w m ,and  X  is the prior covariance matrix. The assumption of DFPM is: there are a number of hidden factors that represent different decision boundaries in the item feature space; users may be using one or sev-eral of these hidden factors in different levels. Each column of matrix  X  ,whichisa K -dimendional vector, represents a specific hidden factor.  X  m tells how much each column of  X  contributes to the profile of user m .  X  m may follow two alternative distributions: Multinomial and Normal, and we will use DFPM-Mult and DFPM-Norm to denote these two models respectively. In DFPM-Mult, only one entry of  X  m is allowed to be 1 and all other entries be zero. This model clusters users into H groups, and users of the same group share a common hidden factor as the prior. We want to point out that the common Bayesian hi-erarchical model (BHM) is actually a special case of DFPM-Mult. When H = 1, DFPM-Mult is equivalent to BHM. In the case of DFPM-Norm,  X  m follows a Normal distribution with mean 0 and variance b I . DFPM-Norm assumes that each user may be interested in multiple hidden factors, and each entry of  X  m reflects how much the corresponding hid-den factor is related to the user X  X  interests. DFPM-Norm is used to capture each user X  X  multiple interests.

We assume each user profile w m is a random sample from a normal distribution with mean  X   X  m and variance  X  .The label y m j of a training item x m j is y = f ( x m j ; w f could be many existing regression or classification mod-els. We will take the logistic regression as an example to demonstrate how our models could be used for recommen-dation task. Let I be an identity matrix, a, b, c be constant parameters, we summarize the discriminative factored prior models with logistic regression as follows:
Parameter Estimation: The empirical Bayes method[2] is often used when learning a complicated Bayesian hierar-chical model like DFPM. However, the learning algorithm based on Empirical Bayes will be very complicated since there are many hidden variables (  X  ,  X  ,  X  , w m ) entangled in our models. Besides, the number of features and the number of users involved in the recommendation task are usually huge. Thus the empirical Bayes method is too com-putationally expensive to be used here. As an alternative, we use a simplified learning algorithm based on point esti-mation and the conjugate gradient decent algorithm. For those who are interested in the algorithm, please refer to http://users.soe.ucsc.edu/  X  lanbo/cikm10long.pdf.
To evaluate the proposed modeling approach, we collected a data set from Digg.com[1]. Digg.com is a website for peo-ple to share web content including news, images, and videos. Users can digg items they are interested in to promote the items X  ranking. Each item dugg by a user is considered a positive data point (a relevant document) for the user. We collected the complete digg history of news articles of more than 15,000 users. The detailed statistics of our dataset is shown in Table 1.

Since Digg.com only has user digg history available on its website, we couldn X  X  get those articles users read but didn X  X  digg. In other words, we don X  X  have real negative examples. To address this problem, we randomly choose equal number of articles which are not dugg by a user as the negative examples for this user. Considering the large percentage of user undugg articles, we expect most of the articles sampled in this way are irrelevant to this user X  X  interests.
We randomly divide each user X  X  data (including both posi-tive and negative examples) into three parts: training (80%), validation (10%), and test (10%). The validation data is used to tune the parameters of both our models ( H,c 1 ,c and the baseline models. We use the words as features. Both the stop words and rare words (occurring in less than 50 ar-ticles) are removed from the feature set. As a result, there are 35,865 features. When calculating the feature values, we use the TF*IDF scoring method. Precision , Recall ,and Macro-F1 are used as the evaluation measures.

Our experiments are designed to answer the following ques-tions: 1) How is the performance of our models compared with the state-of-the-art algorithms? 2) Can our models learn meaningful hidden factors, and how does the num-ber of hidden factors ( H ) influence the performance? To answer the first question, we compare our models with the L-2 regularized logistic regression ( L2LR )andtheBayesian hierarchical model (Figure 1 (left)) with logistic regression ( BHLR ) implemented in [3], since other researchers have demonstrated that BHLR works much better than popular generative filtering models [4, 6]. To answer the second ques-tion, the results with different numbers of hidden factors will be compared and analyzed.
The top-left graph in Figure 2 shows the overall perfor-mances of four algorithms. Both of our models (DFPM-Norm and DFPM-Mult) are statistically significantly bet-ter than the baselines in terms of Precision and Macro-F1 (based on t-test). The improvement on precision is very sig-nificant. This is very encouraging since Precision is a more important factor in most personalized recommender/filtering systems. To see whether our algorithms are helpful for both hard users (users with little training data) and easy users (users with much training data), we divide the users into five groups according to their numbers of diggs (less than 50, 50-100, 100-200, 200-500, greater than 500 respectively) to see whether the performances for all kinds of users have been improved. The rest graphs in Figure 2 show the results Figure 3: Performances (Macro-F1) of our models at different H (number of hidden factors) on these user groups. We find our models outperform the baselines for all five user groups.
Figure 2 shows that our models significantly outperform the L-2 regularized logistic regression, which learns each user profile independently. This demonstrates that our models successfully borrow discriminative information from other users by learning user profiles jointly. Figure 2 also shows that our models significantly outperform the Bayesian hi-erarchical logistic regression model (BHLR). We find that BHLR already significantly outperforms L2LR, which in-dicates BHLR successfully borrows information from other users. Encouragingly, our models can further improve the performances over BHLR. This demonstrates that our mod-els can learn more accurate user profiles by introducing a factored prior.

Why our models can outperform BHLR? Not all users have similar interests, and it X  X  not always a good idea to assume that all user profiles are generated from the same Gaussian distribution. Our models have less strong assump-tions and use the variable  X  m to model the diversity of users, and thus have the advantage of only borrowing information from similar users. In particular, users with similar in-terests share a common hidden factor as the prior in the DFPM-Mult model.
Figure 3 shows how the number of hidden factors influ-ences the performance. Remember BHLR is a special case (
H = 1) of our model DFPM-Mult. As H increases from 1 to 10, the performance keeps on improving and reaches the optimal value at H = 10. If we consider users with similar interests as a cluster, our model DFPM-Mult can effectively identify the underlying user clusters. To better understand the DFPM-Mult model, we list the top 10 features (words) in some learned factors in Table 2. We observe that most of the words represent the concept of each hidden factor well. Figure 2 shows that DFPM-Mult performs better than DFPM-Norm. This is somewhat surprising. Initially, we ex-pected that DFPM-Norm should perform better than DFPM-Mult since the Normal assumption of  X  m can capture the multiple interests of individual users. There are several pos-sible reasons for this finding. First, we probably should learn apriorfor  X  m instead of using a normal distribution cen-tered on 0. Second, it X  X  possible that the flexibility of Table 2: Top words in some factors (by model DFPM-Mult). makes the learning process more complicated. It may cur-tail the information borrowed from other users so that the commonality of similar users is not captured well. We are planning to investigate the reasons in more details in the future work.
In this paper, we present the discriminative factored prior models for personalized content-based recommendation. Par-ticularly, we propose two models and the corresponding pa-rameter learning algorithms. We evaluate our models on a dataset collected from real web users on Digg.com[1], and compare them with two much related baseline algorithms. The experimental results demonstrate that: 1) Our models significantly improve the recommendation performance, es-pecially for users with little training data. Thus they can help alleviate the cold-start problem. 2) It X  X  helpful to in-troduce a factorized prior. Particularly, the DFPM-Mult model learns more accurate user profiles since it can effec-tively cluster users with similar interests and has the advan-tage of only borrowing discriminative criteria from similar users while learning a particular user profile.
 In the future work, more research is needed to analyze DFPM-Norm, since it captures each user X  X  multiple inter-ests and thus offers some advantages over the DFPM-Mult model. One possible approach is to try a learned prior or using a Dirichlet prior instead of a normal prior for  X  m sides, we will also evaluate our models on more datasets. Our models can also be modified to fit the personalized rec-ommendation task better, for example, to capture user in-terest drift by adding temporal variables.
This work was funded by National Science Foundation IIS-0713111, AFRL/AFOSR and UCSC/LANL ISSDM. Any opinions, findings, conclusions or recommendations expressed in this paper are the authors X , and do not necessarily reflect those of the sponsors. [1] The digg website. https://www.digg.com. [2] Empirical bayes method. [3] Hierarchical modeling in bbr. [4] K. Yu, V. Tresp, and S. Yu. A nonparametric [5] J. Zhang, Z. Ghahramani, and Y. Yang. Flexible latent [6] Y. Zhang and J. Koren. Efficient bayesian hierarchical
