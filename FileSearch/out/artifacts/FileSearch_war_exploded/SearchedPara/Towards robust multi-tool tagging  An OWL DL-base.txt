 NLP systems for higher-level operations or com-plex annotations often integrate redundant modu-les that provide alternative analyses for the same linguistic phenomenon in order to benefit from their respective strengths and to compensate for their respective weaknesses, e.g., in parsing (Crys-mann et al., 2002), or in machine translation (Carl et al., 2000). The current trend to parallel and dis-tributed NLP architectures (Aschenbrenner et al., 2006; Gietz et al., 2006; Egner et al., 2007; Lu  X   X s and de Matos, 2009) opens the possibility of ex-ploring the potential of redundant parallel annota-tions also for lower levels of linguistic analysis.
This paper evaluates the potential benefits of such an approach with respect to morphosyntax (parts of speech, pos) and morphology in German: In comparison to English, German shows a rich and polysemous morphology, and a considerable number of NLP tools are available, making it a promising candidate for such an experiment.

Previous research indicates that the integration of multiple part of speech taggers leads to more accurate analyses. So far, however, this line of re-search focused on tools that were trained on the same corpus (Brill and Wu, 1998; Halteren et al., 2001), or that specialize to different subsets of the same tagset (Zavrel and Daelemans, 2000; Tufis  X , 2000; Borin, 2000). An even more substantial in-crease in accuracy and detail can be expected if tools are combined that make use of different an-notation schemes.

For this task, ontologies of linguistic annota-tions are employed to assess the linguistic infor-mation conveyed in a particular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morpho-logical annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). Various repositories of linguistic annotation termi-nology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Cate-gory Registry (Ide and Romary, 2004; Kemps-Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al., 2002), or the Typological Database System ontology (Saulwick et al., 2005, TDS). Despite their common level of representa-tion, however, these efforts have not yet converged into a unified and generally accepted ontology of linguistic annotation terminology, but rather, dif-ferent resources are maintained by different com-munities, so that a considerable amount of dis-agreement between them and their respective defi-nitions can be observed. 1
Such conceptual mismatches and incompatibi-lities between existing terminological repositories have been the motivation to develop the OLiA ar-chitecture (Chiarcos, 2008) that employs a shal-low Reference Model to mediate between (onto-logical models of) annotation schemes and several existing terminology repositories, incl. GOLD, the DCR, and OntoTag. When an annotation receives a representation in the OLiA Reference Model, it is thus also interpretable with respect to other linguistic ontologies. Therefore, the findings for the OLiA Reference Model in the experiments de-scribed below entail similar results for an applica-tion of GOLD or the DCR to the same task. 2.1 The OLiA ontologies The Ontologies of Linguistic Annotations  X  briefly, OLiA ontologies (Chiarcos, 2008)  X  re-present an architecture of modular OWL/DL on-tologies that formalize several intermediate steps of the mapping between concrete annotations, a Reference Model and existing terminology reposi-tories ( X  X xternal Reference Models X  in OLiA ter-minology) such as the DCR. 2
The OLiA ontologies were originally develo-ped as part of an infrastructure for the sustain-able maintenance of linguistic resources (Schmidt et al., 2006) where they were originally applied to the formal representation and documentation of annotation schemes, and for concept-based anno-tation queries over to multiple, heterogeneous cor-pora annotated with different annotation schemes (Rehm et al., 2007; Chiarcos et al., 2008). NLP applications of the OLiA ontologies include a pro-posal to integrate them with the OntoTag ontolo-gies and to use them for interface specifications between modules in NLP pipeline architectures (Buyko et al., 2008). Further, Hellmann (2010) described the application of the OLiA ontologies within NLP2RDF, an OWL-based blackboard ap-proach to assess the meaning of text from gram-matical analyses and subsequent enrichment with ontological knowledge sources.

OLiA distinguishes three different classes of ontologies:  X  The OL I A R EFERENCE M ODEL specifies  X  Multiple OL I A A NNOTATION M ODEL s for- X  For every Annotation Model, a L INKING The OLiA Reference Model (namespace olia ) specifies concepts that describe linguistic cate-gories (e.g., olia:Determiner ) and grammati-cal features (e.g., olia:Accusative ), as well
Figure 1: Attributive demonstrative pronouns ( PDAT ) in the STTS Annotation Model
Figure 3: Individuals for accusative and sin-gular in the TIGER Annotation Model as properties that define possible relations be-tween those (e.g., olia:hasCase ). More gen-eral concepts that represent organizational in-formation rather than possible annotations (e.g., are stored in a separate ontology (namespace
The Reference Model is a shallow ontology: It does not specify disjointness conditions of con-cepts and cardinality or domain restrictions of properties. Instead, it assumes that such con-straints are inherited by means of v relationships from an External Reference Model. Different Ex-ternal Reference Models may take different posi-tions on the issue  X  as languages do 3  X , so that this aspect is left underspecified in the Reference Model.
Figs. 2 and 4 show excerpts of category and fea-ture hierarchies in the Reference Model.

With respect to morphosyntactic annotations (parts of speech, pos ) and morphological an-notations ( morph ), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos ), TIGER (Brants and Hansen, 2002, morph ), Morphisto (Zielinski and Simon, 2008, pos, morph ), RFTagger (Schmid and Laws, 2008, pos, morph ), Connexor (Tapanainen and J  X  arvinen, 1997, pos, morph ). Further Annotation Models for pos and morph cover five different an-notation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and cur-rently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an an-notation scheme for Tibetan (Wagner and Zeisler, 2004). Figure 5: The STTS tags PDAT and ART , their rep-resentation in the Annotation Model and linking with the Reference Model.
 Annotation Models differ from the Reference Model mostly in that they include not only con-cepts and properties, but also individuals: An-notation Model concepts reflect an abstract con-ceptual categorization, whereas individuals re-present concrete values used to annotate the corresponding phenomenon. An individual is applicable to all annotations that match the string value specified by this individual X  X  hasTag , hasTagEndingWith properties. Fig. 1 illus-trates the structure of the STTS Annotation Model (namespace stts ) for the individual stts:PDAT that represents the tag used for at-tributive demonstrative pronouns (demonstrative determiners). Fig. 3 illustrates the individuals the hierarchy of morphological features in the TIGER Annotation Model (namespace tiger ).
 Fig. 5 illustrates the linking between the STTS Annotation Model and the OLiA Reference Model for the individuals stts:PDAT and stts:ART . 2.2 Integrating different morphosyntactic With the OLiA ontologies as described above, an-notations from different annotation schemes can now be interpreted in terms of the OLiA Reference Model (or External Reference Models like GOLD or the DCR).

As an example, consider the attributive demon-strative pronoun diese in (1). The phrase diese nicht neue Erkenntnis poses two challenges. First, it has to be recognized that the demonstrative pronoun is attributive, although it is separated from adjective and noun by nicht  X  X ot X . Second, the phrase is in accusative case, although the morphology is ambiguous between accusative and nominative, and nominative case would be ex-pected for a sentence-initial NP.
 The Connexor analysis (Tapanainen and J  X  arvinen, 1997) actually fails in both aspects (2). The ontological analysis of this annotation begins by identifying the set of individuals from the Con-nexor Annotation Model that match it according to their hasTag (etc.) properties. The RDF triplet  X  X OM X  4 indicates that the tag is an application of the individual connexor:NOM , an instance of connexor:Case . Further, the annota-tion matches connexor:PRON (an instance of connexor:Pronoun ), etc. The result is a set of individuals that express different aspects of the meaning of the annotation.

For these individuals, the Annotation Model specifies superclasses ( rdf:type ) and other prop-connexor:NOM , etc. The linguistic unit repre-sented by the actual token can now be character-ized by these properties: Every property applica-ble to a member in the individual set is assumed to be applicable to the linguistic unit as well. In order to save space, we use a notation closer to predicate logic (with the token as implicit subject). In terms of the Annotation Model, the token diese is thus described by the following descriptions: provides us with the information that (i) connexor:Pronoun is a subclass of the Re-ference Model concept olia:Pronoun , (ii) connexor:NOM is an instance of the Reference Model concept olia:Nominative , and (iii)
Accordingly, the predicates that describe the to-ken diese can be reformulated in terms of the Re-we know that for some i : olia:Nominative it is true that olia:hasCase( i ) , abbreviated here as
In this way, the grammatical information con-veyed in the original Connexor annotation can be represented in an annotation-independent and tagset-neutral way as shown for the Connexor a-nalysis in (4). Analogously, the corresponding RFTagger analy-sis (Schmid and Laws, 2008) given in (5) can be transformed into a description in terms of the OLiA Reference Model such as in (6). For every description obtained from these (and further) analyses, an integrated and consistent gen-eralization can be established as described in the following section. 3.1 Evaluation setup Fig. 6 sketches the architecture of the evalua-tion environment set up for this study. 5 The in-put to the system is a set of documents with TIGER/NEGRA-style morphosyntactic or mor-phological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard.

From the annotated document, the plain tok-enized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without (ii) two part of speech taggers: the TreeTag-(iii) the RFTagger that performs part of speech and (iv) two PCFG parsers: the StanfordParser (Klein (v) the Connexor dependency parser (Tapanainen These tools annotate parts of speech, and those in (i), (iii) and (v) also provide morphological fea-tures. All components ran in parallel threads on the same machine, with the exception of Mor-phisto that was addressed as a web service. The set of matching Annotation Model individuals for ev-ery annotation and the respective set of Reference Model descriptions are determined by means of the Pellet reasoner (Sirin et al., 2007) as described above.

A disambiguation routine (see below) then de-termines the maximal consistent set of ontological descriptions. Finally, the outcome of this process is compared to the set of descriptions correspond-ing to the original annotation in the corpus. 3.2 Disambiguation Returning to examples (4) and (6) above, we see that the resulting set of descriptions con-veys properties that are obviously contradic-
Our approach to disambiguation combines on-tological consistency criteria with a confidence ranking. As we simulate an uninformed approach, the confidence ranking follows a majority vote.
For diese in (1), the consultation of all seven tools results a confidence ranking as shown in Tab. 1: If a tool supports a description with its analy-sis, the confidence score is increased by 1 (or by 1 /n if the tool proposes n alternative annotations). A maximal consistent set of descriptions is then established as follows: (i) Given a confidence-ranked list of available (ii) Let s 1 be the first element of S = (iii) If s 1 is consistent with every description t  X  (iv) Remove s 1 from S and iterate in (ii) until S The consistency of ontological descriptions is de-fined here as follows: 6  X  Two concepts A and B are consistent iff  X  Two descriptions pred 1 ( A ) and pred 2 ( B ) This heuristic formalizes an implicit disjoint-ness assumption for all concepts in the on-tology (all concepts are disjoint unless one is a subconcept of the other). Further, it imposes an implicit cardinality constraint on concepts and thus disjoint).

For the example diese , the descriptions noun) are inconsistent with type(Determiner) , 4); these descriptions are thus ruled out. The hasCase descriptions have identical confidence scores, so that the first hasCase description that the algorithm encounters is chosen for the set of resulting descriptions, the other one is ruled out because of their inconsistency. Table 2: Recall for rdf:type descriptions for word classes
The resulting, maximal consistent set of de-scriptions is then compared with the ontological descriptions that correspond to the original anno-tation in the corpus. Six experiments were conducted with the goal to evaluate the prediction of word classes and mor-phological features on parts of three corpora of German newspaper articles: NEGRA (Skut et al., 1998), TIGER (Brants et al., 2002), and the Pots-dam Commentary Corpus (Stede, 2004, PCC). From every corpus 10,000 tokens were considered for the analysis.

TIGER and NEGRA are well-known resources that also influenced the design of several of the tools considered. For this reason, the PCC was consulted, a small collection of newspaper com-mentaries, 30,000 tokens in total, annotated with TIGER-style parts of speech and syntax (by mem-bers of the TIGER project). None of the tools con-sidered here were trained on this data, so that it provides independent test data.

The ontological descriptions were evaluated for recall: 7 In (7), T is a text (a list of tokens) with T = ( t 1 , ..., t n ) , D predicted ( t ) are descriptions retrieved from the NLP analyses of the token t , and D target ( t ) is the set of descriptions that corres-pond to the original annotation of t in the corpus. 4.1 Word classes Table 2 shows that the recall of rdf:type de-scriptions (for word classes) increases continu-ously with the number of NLP tools applied. The combination of all seven tools actually shows a better recall than the best-performing single NLP tool. (The NEGRA corpus is an apparent excep-tion only; the exceptionally high recall of the Stan-ford Tagger reflects the fact that it was trained on NEGRA.)
A particularly high increase in recall occurs when tools are combined that compensate for their respective deficits. Morphisto, for example, ge-nerates alternative morphological analyses, so that the disambiguation algorithm performs a random choice between these. Morphisto has thus the worst recall among all tools considered (PCC .69, TIGER .65, NEGRA .70 for word classes). As compared to this, Connexor performs a contextual disambiguation; its recall is, however, limited by its coarse-grained word classes (PCC .73, TIGER .72, NEGRA .73). The combination of both tools yields a more detailed and context-sensitive ana-lysis and thus results in a boost in recall by more than 13% (PCC .87, TIGER .86, NEGRA .86). 4.2 Morphological features For morphological features, Tab. 3 shows the same tendencies that were also observed for word classes: The more tools are combined, the greater the recall of the generated descriptions, and the re-call of combined tools often outperforms the recall of individual tools.

The three tools that provide morphological an-notations (Morphisto, Connexor, RFTagger) were evaluated against 10,000 tokens from TIGER and NEGRA respectively. The best-performing tool was the RFTagger, which possibly reflects the fact that it was trained on TIGER-style annotations, whereas Morphisto and Connexor were developed on the basis of independent resources and thus dif-fer from the reference annotation in their respec-tive degree of granularity. With the ontology-based approach described in this paper, the performance of annotation tools can be evaluated on a conceptual basis rather than by means of a string comparison with target annota-tions. A formal model of linguistic concepts is ex-tensible, finer-grained and, thus, potentially more adequate for the integration of linguistic annota-tions than string-based representations, especially for heterogeneous annotations, if the tagsets in-volved are structured according to different design principles (e.g., due to different terminological tra-ditions, different communities involved, etc.).
It has been shown that by abstracting from tool-specific representations of linguistic anno-tations, annotations from different tagsets can be represented with reference to the OLiA ontologies (and/or with other OWL/RDF-based terminology repositories linked as External Reference Models). In particular, it is possible to compare an existing reference annotation with annotations produced by NLP tools that use independently developed and differently structured annotation schemes (such as Connexor vs. RFTagger vs. Morphisto).

Further, an algorithm for the integration of dif-ferent annotations has been proposed that makes use of a majority-based confidence ranking and ontological consistency conditions. As consis-tency conditions are not formally defined in the OLiA Reference Model (which is expected to in-herit such constraints from External Reference Models), a heuristic, structure-based definition of consistency was applied.

This heuristic consistency definition is overly rigid and rules out a number of consistent alter-native analyses, as it is the case for overlapping categories. 8 Despite this rigidity, we witness an increase of recall when multiple alternative analy-ses are integrated. This increase of recall may re-sult from a compensation of tool-specific deficits, e.g., with respect to annotation granularity. Also, the improved recall can be explained by a compen-sation of overfitting, or deficits that are inherent to a particular approach (e.g., differences in the co-verage of the linguistic context).

It can thus be stated that the integration of mul-tiple alternative analyses has the potential to pro-duce linguistic analyses that are both more robust and more detailed than those of the original tools.
The primary field of application of this ap-proach is most likely to be seen in a context where applications are designed that make direct use of OWL/RDF representations as described, for ex-ample, by Hellmann (2010). It is, however, also possible to use ontological representations to boot-strap novel and more detailed annotation schemes, cf. Zavrel and Daelemans (2000). Further, the conversion from string-based representations to ontological descriptions is reversible, so that re-sults of ontology-based disambiguation and vali-dation can also be reintegrated with the original annotation scheme. The idea of such a reversion algorithm was sketched by Buyko et al. (2008) where the OLiA ontologies were suggested as a means to translate between different annotation schemes. 9 Natural extensions of the approach described in this paper include: (i) Experiments with formally defined consis-(ii) Context-sensitive disambiguation of mor-(iii) Replacement of majority vote by more elab-(iv) Application of the algorithm for the ontolog-(v) Integration with other ontological knowledge Extensions (iii) and (iv) are currently pursued in an ongoing research effort described by Chiarcos et al. (2010). Like morphosyntactic and morpho-logical features, node and edge labels of syntac-tic trees are ontologically represented in several Annotation Models, the OLiA Reference Model, and External Reference Models, the merging al-gorithm as described above can thus be applied for syntax, as well. Syntactic annotations, how-ever, involve the additional challenge to align dif-ferent structures before node and edge labels can be addressed, an issue not further discussed here for reasons of space limitations.

Alternative strategies to merge grammatical a-nalyses may include alternative voting strategies as discussed in literature on classifier combina-tion, e.g., weighted majority vote, pairwise voting (Halteren et al., 1998), credibility profiles (Tufis  X , 2000), or hand-crafted rules (Borin, 2000). A novel feature of our approach as compared to exis-ting applications of these methods is that confi-dence scores are not attached to plain strings, but to ontological descriptions: Tufis  X , for example, assigned confidence scores not to tools (as in a weighted majority vote), but rather, assessed the  X  X redibility X  of a tool with respect to the predicted tag . If this approach is applied to ontological de-scriptions in place of tags, it allows us to consider the credibility of pieces of information regardless of the actual string representation of tags. For ex-ample, the credibility of hasCase descriptions can be assessed independently from the credibility of hasGender descriptions even if the original anno-tation merged both aspects in one single tag (as the RFTagger does, for example, cf. ex. 5).

Extension (v) has been addressed in previous re-search, although mostly with the opposite perspec-tive: Already Cimiano and Reyle (2003) noted that the integration of grammatical and semantic ana-lyses may be used to resolve ambiguity and un-derspecifications, and this insight has also moti-vated the ontological representation of linguistic resources such as WordNet (Gangemi et al., 2003), FrameNet (Scheffczyk et al., 2006), the linking of corpora with such ontologies (Hovy et al., 2006), the modelling of entire corpora in OWL/DL (Bur-chardt et al., 2008), and the extension of existing ontologies with ontological representations of se-lected linguistic features (Buitelaar et al., 2006; Davis et al., 2008).

Aguado de Cea et al. (2004) sketched an ar-chitecture for the closer ontology-based integra-tion of grammatical and semantic information u-sing OntoTag and several NLP tools for Spanish. Aguado de Cea et al. (2008) evaluate the benefits of this approach for the Spanish particle se , and conclude for this example that the combination of multiple tools yields more detailed and more ac-curate linguistic analyses of particularly proble-matic, polysemous function words. A similar in-crease in accuracy has also been repeatedly re-ported for ensemble combination approaches, that are, however, limited to tools that produce annota-tions according to the same tagset (Brill and Wu, 1998; Halteren et al., 2001).

These observations provide further support for our conclusion that the ontology-based integration of morphosyntactic analyses enhances both the ro-bustness and the level of detail of morphosyntac-tic and morphological analyses. Our approach ex-tends the philosophy of ensemble combination ap-proaches to NLP tools that do not only employ dif-ferent strategies and philosophies, but also differ-ent annotation schemes.
 From 2005 to 2008, the research on linguistic ontologies described in this paper was funded by the German Research Foundation (DFG) in the context of the Collaborative Research Center (SFB) 441  X  X inguistic Data Structures X , Project C2  X  X ustainability of Linguistic Resources X  (Uni-versity of T  X  ubingen), and since 2007 in the context of the SFB 632  X  X nformation Structure X , Project D1  X  X inguistic Database X  (University of Pots-dam). The author would also like to thank Ju-lia Ritz, Angela Lahee, Olga Chiarcos and three anonymous reviewers for helpful hints and com-ments.
