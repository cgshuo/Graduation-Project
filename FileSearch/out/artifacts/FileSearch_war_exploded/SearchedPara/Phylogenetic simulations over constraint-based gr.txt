 Popular computational methods for phylogenetic re-search (estimating the evolutionary histories of lan-guages) primarily involve comparisons over cognate sets (Nichols and Warnow, 2008). Recent works (Dunn et al., 2005; Longobardi and Guardiano, 2009) indicate that comparing sets of grammatical parameters can be effective as well. However, gen-erating a large number of meaningful parameters re-mains a formal obstacle. In this paper we argue that constraint-based grammar formalisms may be exploited for parameter generation, and explore to what extent such research is feasible.

Because the use of constraint-based grammars in phylogenetics is relatively novel, we do not know a posteriori how many constraints and how many languages must be considered for a computational approach to be successful. If a minimum threshold is established that is methodologically prohibitive (e.g. if such systems were only accurate given a set of 1,000 languages), we can abandon this approach as infeasible. By initially experimenting with simu-lated data, we establish a footing for future empirical studies.

In this paper, we report on simulations which con-sistently outperform two baseline models. Signifi-cantly, these results obtained with a modest number of constraints c  X  4 and languages l  X  4 . 1.1 Grammatical parameters in phylogenetics Longobardi and Guardiano (2009) argue that gram-matical features, such as whether a language ex-presses a pre-or postpositional genitive, if chosen carefully, present certain advantages over lexically-based comparisons in phylogenetic work. Grammat-ical parameters comprise a universal set of discrete options applicable to any set of languages, espe-cially within frameworks such as Principle and Pa-rameters (Chomsky, 1981). Using grammatical fea-tures for phylogenetic work can be a way to avoid any difficulties associated with the collection and identification of cognate sets.

However, unlike cognate sets, there is no a pri-ori assumption that correspondences between pa-rameter settings are meaningful genetically. Instead, meaningful correspondence derives from the low probability that two languages match in a number of parameter settings by chance. Successful work therefore depends on the construction of a large set of grammatical parameters; larger sets are predicted to produce more accurate results. 1.2 Constraint-based grammar formalisms In constraint-based theories of grammar like Opti-mality Theory (OT) (Prince and Smolensky, 2004), input-output relations are determined by the interac-tion of conflicting violable constraints.

To take a common example from phonology, a language may require that all syllables are open, deleting consonants that would otherwise surface in coda position. In an OT analysis of such a lan-guage, the constraint N O C ODA , which prohibits co-das, dominates the constraint M AX , which prohibits deletion (written N O C ODA M AX ). This encodes that satisfying N O C ODA is more important than sat-isfying M AX , though there may be additional inter-acting constraints complicating the analysis.
In an OT framework, the set of constraints, C ON , is assumed to be universal X  X ts members typically being grounded in typological and psycholinguistic data. Differences between grammars are encoded as different language-specific rankings of the con-straint set.

OT is most often used in phonology, but has been applied widely in various linguistic sub-disciplines, including syntax, sociolinguistics, and semantics (McCarthy, 2008). Constraint-based frameworks can therefore encode diverse grammatical phenom-ena with minimal representation, a constraint rank-ing being simply a directed acyclic graph over C ON .
With the exception of Eden (2013), constraint-based phylogenetic research has not yet, to our knowledge, been attempted. It remains an open question whether such a representation is useful in phylogenetics and if so, under what conditions. 1.3 Parameterizing C ON Following Longobardi and Guardiano X  X  (2009) para-metric approach, we adapt constraint rankings into binary pseudo-parameters, decomposing language-specific rankings into vectors of pairwise dominance relations (Antilla and Cho, 1998): That is, for every pair of constraints C 1 , C 2 , R re-turns a binary value corresponding to whether C 1 dominates C 2 directly or transitively. 1 An example of a constraint ranking and its corresponding R val-ues is shown is shown in Figure 1. C 1 0 1 1 C 2 0 0 1 C 3 0 0 0 Figure 1: A constraint ranking, its representation as a matrix, and as a set of binary pseudo-parameters.
We consider these to be pseudo -parameters be-cause certain constraint pairs may only interact under very specific circumstances or not at all. The ranking of N O C ODA and M AX , for exam-ple, is meaningful under a large number of cir-cumstances: R ( N O C ODA , M AX ) corresponds to whether a grammar deletes consonants that would otherwise surface in coda position. The ranking of N
O C ODA and M AX -V OICE (which prohibits delet-ing a voice feature), on the other hand, is less meaningful because these constraints are not ex-pected to conflict directly (deleting a voice feature does not create an open syllable, and therefore can-not avoid a violation of N O C ODA ). Nevertheless, R ( N O C ODA , M AX -V OICE ) may be determined via transitivity. R values therefore range from represen-tations of a language X  X  grammatical characteristics to higher-level artifacts of the theory as applied to its grammar. Weighting R values accordingly may be a fruitful topic for future research.

Pseudo-parameters pose certain advantages. For a set of n constraints, the size of the corresponding set of pseudo-parameters is on the order of n 2 . This dramatically increases the number of comparisons one is able to make between languages with a mod-est number of empirically motivated constraints, as compared to a parameter set tout court . Because constructing a set of constraints or parameters is tax-ing, an approach that maximizes the impact of each additional constraint is advantageous. With pseudo-parameters, constraint n + 1 contributes n points of comparison, whereas parameter n + 1 contributes only 1 point of comparison.

A theory-internal advantage of this approach is that it faithfully represents even complex constraint rankings. Some models of OT allow for constraints to be unranked. The pseudo-parameter representa-tion handles unranked constraints without issue, thus allowing wide theoretical coverage. Computational phylogenetic systems have taken a diverse set of inputs. Subgroup classification us-ing cognate comparisons has been used by Ringe et al. (2002) for Indo-European (IE) and Bowern and Atkinson (2012) for Pama-Nyungan, among others. Both syntactic and phonological grammatical-level information have also been used effectively for com-putational phylogenetics.

Longobardi and Guardiano (2009) used sixty-three binary syntactic parameters for a phylogeny of twenty-two IE languages and six non-IE languages. Their generated trees largely agreed with the histor-ical relations determined by traditional comparative linguistic methods. In a second experiment using fif-teen languages for which lexical data were available, they found large overlap between trees generated us-ing syntactic parameters and lexical data.

Eden (2013) replicated this study using thirteen typologically grounded parameters related to phono-logical stress over nineteen of the languages used by Longobardi and Guardiano (2009) as well as an additional five, demonstrating that the grammat-ical parameters need not be limited to the domain of syntax. A second experiment using phonotactic constraints over six languages yielded more vari-able results than the first experiment. The con-straints used were generated by a phonotactic con-straint learner (Hayes and Wilson, 2008), which dif-fers from classic OT in several key regards: in this model, constraints are language-specific; constraints are weighted probabilistically, not ranked; and con-straints only reference surface forms, not input-output relations. To utilize a single constraint set, the one hundred thirteen highest-weighted constraints that were persistently generated by the phonotactic learner across the six languages were chosen and reweighted in each language. Each language there-fore had a grammar consisting of the same set of constraints. The rankings of these constraints were compared using Spearman X  X  correlation coefficient.
Eden X  X  (2013) study broke ground in using constraint-based grammars; however, there were certain limitations. The phonotactic learner re-quires a representative input corpus of at least 3,000-6,000 words, impeding the incorporation of under-resourced languages. Further, the generated constraint set is problematically language-specific. Only one constraint generated for English, for ex-ample, was active in the other five languages.
Our approach diverges from Eden X  X  (2013) theory-internally and in scope. We assume an a priori universal constraint set, and our pseudo-parameter approach allows for constraints to be un-ranked relative to one another. We could in princi-ple measure inter-language distance with rank cor-relations over topologically sorted constraint rank-ings, but unranked constraints are predicted to lead to highly variable results. Because our experiments in this study are over simulated languages, we are not limited by available linguistic descriptions. To investigate whether constraint-based formalisms are useful in phylogenetic work and under what as-sumptions, we conducted a large number of simula-tions following the procedure described by Nichols and Warnow (2008): 1. Produce a model tree T ; 2. T evolves from the root, producing a set of 3. S is used as input to the phylogeny estimation 4. T 0 is compared to T to calculate error.

Simulations varied with respect to the number of constraints, the size of S , and the rate of evolution. 2 3.1 Model Tree In these simulations, C ON is defined as a set of c constraints C 1 , C 2 , . . . , C c . The model tree T (gold standard) is initialized with a root-node language consisting of a randomly generated full ranking of C
ON such that every constraint is ranked relative to every other constraint: C (1) C (2) . . . C ( c ) . For c constraints, there are c ! possible full rankings. From this root-node, T evolves into a larger tree. 3.2 Tree Evolution In our simulations, language change is modeled by constraint reranking (Cho, 1998), although this over-simplifies the complex processes observed in actual data. 3 T evolves accordingly. At each evolution-ary step, a leaf language either randomly changes or splits into two daughter languages inheriting the same constraint ranking according to the branching probability b . 4 The lower b is, the more changes on average a language will undergo before branch-ing. A change entails either the addition or removal of a domination relation between two random con-straints. Evolution continues until T contains a pre-determined minimum number of leaves. 3.3 Phylogeny Estimation The constraint rankings of the languages in the set of leaves S are decomposed into pseudo-parameter vectors. Inter-language distance is calculated by tak-ing the Euclidean distance between vectors. We use Euclidean distance because it has been reported to perform well among fifteen vector similarity mea-sures of typological distance (Rama and Prasanth, 2012), and our initial experiments found no major differences between measures. The inter-language distances serve as input to the phylogeny estimation procedure.

Because tree evolution in our model proceeds ac-cording to a lexical clock (i.e., changes accumu-late over time) X  X r more precisely a grammatical clock X  X e use the Unweighted Pair Group Method with Arithmetic mean (UPGMA), a hierarchical clustering method that utilizes the average distance between clusters, as a phylogeny estimation pro-cedure (Nichols and Warnow, 2008). For speed, we use the implementation in fastcluster (M  X  ullner, 2013) with average linkage. The result of phylogeny estimation is a binary tree T 0 , which is compared to T to measure accuracy. 3.4 Evaluation Because we have access to T , the gold standard tree, we diverge from the partially qualitative eval-uations of Longobardi and Guardiano (2009) and Eden (2013) and adopt a purely quantative evalua-tion metric based on precision and recall (van Rijs-bergen, 1979). As in standard precision and recall, we measure the proportion of correct items relative to T 0 and T respectively. We define correct items to be matching subtrees rooted by internal nodes as shown in Figure 2. Two subtrees are counted as matching if they dominate the same set of leaves. Figure 2: Subtree a in A matches subtree b in B . baseline trees, BF and BR .

BF is a flat tree composed of a single internal node dominating the entire set of languages S as in Figure 3. BF encodes the empirical null hypothesis that S contains no subgroups.
 Figure 3: A random baseline tree BF with n leaves
BR is a randomly constructed binary tree encod-ing the null hypothesis that the phylogeny estimation procedure does not outperform chance groupings.
Precision and recall are calculated between T and the three test trees. We consider an experiment suc-cessful when T 0 is more accurate than BF and BR . Simulations were run across a wide range of set-tings. The number of constraints ranged exponen-tially from 2 to 64. The number of languages like-wise ranged exponentially from 2 to 128. For each setting pair, we report precision and recall for BF , BR , and T 0 averaged over 1,000 independent itera-tions. Simulations were run with branching prob-ability b set to 0 . 1 , 0 . 01 , and 0 . 001 , as shown in Figure 4. Low branching probabilities yield more differences even between closely related languages (in the authors X  opinion, this more accurately reflects actual language data).

Overall, the simulations were successful, albeit modestly. T 0 had a higher recall than BF and a higher precision and recall than BR in all cases ex-cept simulations with 2 constraints and 4 languages. The margin between T 0 and BR is promising -it indicates that this method can yield positive results. With 2 languages, as modeled in Figure 5, all hy-and BR , because the order of the leaves does not matter, there is only one way to group 2 languages. Similarly, because there is not additional internal structure, BF has perfect recall. Trivially, BF al-ways has perfect precision because the entire tree is the only subtree it identifies.

As is expected, neither BF nor BR are affected by the number of constraints or b . However, as the number of languages increases, the probability that BR correctly identifies substructure decreases.
The accuracy of T 0 does interact with the numbers of constraints and languages as well as with b .
There is an overall trend that T 0 is more accurate with larger numbers of constraints, in accordance with the trend that phylogenetic algorithms X  perfor-mances correlate with the amount of available data. This is especially clear when b = 0 . 001 . Extend-ing this method to real language data is expected to produce more accurate results with a larger number of constraints; however, this effect plateaus. Even with as few as eight constraints, our method scores around .100 higher precision and recall than BR . Ranking a set of eight constraints is within the scope of typical OT analyses.

The accuracy of T 0 negatively correlates with b , indicating that more grammatical distance is useful. This makes sense, as innovative traits passed down through subtrees aid in grouping.

Both precision and recall of T 0 decrease as the number of languages increases. We expect recall to decrease as the number of subtrees in T increases, which is the case with BF . Likewise, with more possible subtrees, the clustering algorithm makes more mistakes, leading to lower precision. These mistakes may additionally follow from the cluster-ing method. With a large number of languages, the diversity within clusters may be especially large, leading to similar average distances between clus-ters, which can result in unpredictable performance of the linkage function. However, the effect of number of languages is not more pronounced with smaller values of b . With smaller b , there are more changes to the languages and we might expect more diversity. If this is an effect of the algorithm, we ex-pect more error high in the tree than at the leaf level. It would be worthwhile to experiment with different linkage functions at different levels in the tree.
Our method assumes that all constraint rerank-ings are equally likely, which is not the case in real languages; e.g., phonological evolution is fre-quently shaped by phonetic biases. Given that our method was successful, we anticipate that incorpo-rating known diachronic biases will radically im-prove performance on natural language data. Our method yielded positive results for the simula-tions reported on in this paper. This suggests that constraint-based formalisms may be used success-fully in computational phylogenetics, though this remains to be verified with natural language data. These experiments serve to establish a baseline for the use of constraint-based grammars in phyloge-netic research. We believe that the results show promise for the addition of constraint-based research to the phylogenetic toolkit, though additional work is required to fully understand its usefulness.
In the future, we plan to examine the effect of different clustering algorithms, and extend this ap-proach to actual language data. One propitious do-main is the phonology of stress, because a large number of languages have already been analysed us-ing a set of 14 core constraints (Kager, 1999). Fur-thermore, it presents an opportunity to compare di-rectly a constraint-based approach with a paramet-ric approach, such as Eden X  X  (2013) phylogenetic re-sults based on stress parameters.
 For their helpful discussion and feedback, we thank Noor Abo Mokh, Daniel Dakota, Sandra K  X  ubler, Lwin Moe, Larry Moss, Dragomir Radev, and au-diences at the Workshop on Computational Phonol-ogy and Morphology 2015 and the CLingDing dis-cussion group at Indiana University, as well as three anonymous reviewers.
