 Discovering communities from social media and collabora-tion systems has been of great interest in recent years. Ex-isting work show prospects of modeling contents and social links, aiming at discovering social communities, whose def-inition varies by application. We believe that a community depends not only on the group of people who actively partic-ipate, but also the topics they communicate about or collab-orate on. This is especially true for workplace email commu-nications. Within an organization, it is not uncommon that employees multifunction, and groups of employees collabo-rate on multiple projects at the same time. In this paper, we aim to automatically discovering and profiling users X  com-munities by taking into account both the contacts and the topics. More specifically, we propose a community profiling model called COCOMP, where the communities labels are latent, and each social document corresponds to an informa-tion sharing activity among the most probable community members regarding the most relevant community issues. Ex-periment results on several social communication datasets, including emails and Twitter messages, demonstrate that the model can discover users X  communities effectively, and provide concrete semantics.
 H.2.8 [ Database Management ]: Database Applications X  Data Mining Community Discovery, Email, Social Media, Collaboration, Generative Models
Given a large collection of social messages, we are inter-ested in profiling a user X  X  communities, which correspond to  X  The work was done when the author was an intern at IBM Almaden Research Center.
 the user X  X  current focus areas. A focus area is an ad-hoc community, in which several users interact on certain top-ics. Building such a profile automatically will be helpful for a number of subsequent analytical tasks, such as helping users visualize and organize social communications, classi-fying new messages into corresponding focus areas, and pri-oritizing new messages by the user X  X  activeness or relevance in that area.

Current developments in data mining and machine learn-ing provide useful techniques to discover communities from text and social links. For example, topic models can extract topics discussed in documents [9, 5] and represent each topic with a number of ranked key words. On the other hand, so-cial network analysis can identify social relationships accord-ing to the communication patterns [10]. Yet many challenges remain to be addressed. First of all, the definition of com-munity has to be well-aligned to application. A community might be a group of people who are closely linked in a so-cial network, or those who share common interests (but not necessarily interact directly with each other). We believe that a semantically meaningful community has to consider both aspects, especially in a collaboration network. Further, most existing work takes a flattened view on social linkage. More specifically, the link between a pair of users is repre-sented by a collapsed evaluation of their relationship, such as closeness or similarity [12], or shared topics [14]. However, communities are usually more than pair-wise connections. The linkage between a pair of users may be sliced into more than one communities being shared. After all, nowadays it is not uncommon that employees of an organization multi-function, and some employees may collaborate on multiple projects at the same time.

In this paper, we propose a community discovery and profiling method based on an extension of the generative model [5]. A key element in this method is a latent commu-nity assignment, given which the distributions of topics and social links can be determined. The intuition is that each social message document, when created and shared, corre-sponds to a sharing activity within the community (both topic-wise and person-wise). More specifically, we extend the topic models and assume the generative process of a la-tently assigned community for each document. Then, based on the assigned community, words and participants are ran-domly sampled from the vocabulary and pool of people. Such a Bayesian topic model is trained by Gibbs sampling, so that based on the observed words and people who take active roles in the social media, it can discover most promi-nent topics and participants, as well as obtain best bets on the communities to be assigned.

Our solution has a number of advantages. First of all, it fills the gap of discovering multi-layered social communities, and provide a semantic description (i.e. mixture of topics) of each layer. This can potentially help us find more meaning-ful communities, which could be missed by existing methods. In addition, because the latent community can serve as an anchor point for mounting information shared across mul-tiple sources and platforms, our model may be applied to other kinds of knowledge sharing systems, such as instant messaging, online discussion forums and group wiki. With this tool, it is possible for users to summarize his or her focus areas in an automatic fashion, so that it is easy to manage the documents, build profiles, find experts [4] and target relevant users in a social network.

The rest of the paper is organized as follows. In Section 2, we discuss the motivation of the study, characteristics of the data, and the state of the art in related studies. Then we describe our model in Section 3, where we provide the tech-nical details. We evaluate our model on real-world datasets, and compare the performances with existing models in Sec-tion 4. Finally, we conclude in Section 5.
In this paper, we use the term  X  X ocial messages, X  referring to text documents that are associated with a group of people. In the following, we overview the basic characteristics for various types of social messages, with an emphasis on their commonalities.
 Social Media A tweet (or Facebook update) is created by Emails We also consider the email as one type of social Collaborative Content This category include publications
Among the above typical types of social messages, one feature in common is that each document is created and shared among a group of people. If we consider the people as nodes in a graph, then the social links that are being considered are clique-type hyper-edges in that graph. Such social linkage is different from document linkage, such as hyperlinks on blogs that link to other blogs, and references at the end of a paper that link to other papers.
In the rest of the paper, when referring to social mes-sages, we have taken into account many different types of documents that might be modeled the same way. By unify-ing different types of social messages, there is the advantage of integrating different sources of information and providing more comprehensive profiles of the users.
Consider a single-user X  X  perspective. Figure 1 illustrates the collaboration network of user u , who resides at the cen-ter. All other nodes are his or her visible contacts. There is a link between two nodes if there has been any direct message exchange between them.

Figure 1 (a) shows the traditional single-layer view on pair-wise linkage, where each link is evaluated individually based on this pair only. For example, frequency of messages, number of shared contacts, or important topics.

Figure 1 (b) shows a multi-layered view on u  X  X  communi-ties and provides a few examples why it makes more sense than the single-layered view. Imagine that the user u is associated with three communities, A 1 , A 2 and A 3 ,simul-taneously. u and e collaborate on communities A 2 and A 3 simultaneously, so their connection should have two different layers that apply to different activity areas, depending on ei-ther f is involved or d is involved. Sometimes, a message in community A 3 does not involve all people in that commu-nity. For example, u and e , since they work so closely, may exchange emails relevant to community A 3 . Without c or d being involved, such messages should still be routed to com-munity A 3 due to the relevance by content. Furthermore, u could see the linkage between f and g since f put g as an additional recipients in some of the emails he or she writes to u . In this case, even if u and g do not exchange emails directly, A 2 should include person g . These results will be missed by purely analyzing linkages.
Discovering communities has been of interest by many previous studies. Being interested in studying collaboration network, we find that social network analysis and topic mod-eling are both relevant. Specifically, social network analysis typically focuses on closeness of social linkage [7], or evo-lution of social connections [18]. Due to the complexity of the network, social links are typically simplified into a single-layer of measurement, without consideration of the general context. On the other hand, models for topic dis-covery from textual documents are also extensively studied, including probabilistic Latent Semantic Analysis (pLSA) [9], Latent Dirichlet Allocation (LDA) [5], variations [8] and ap-plications [11, 3]. Based on the words in a large corpus of documents, these models can extract human comprehensible topics represented by a list of keywords.

Since documents are commonly related to people, recent developments have taken into account people who are re-lated to the topics. For example, the Author-Topic (AT) model [17] considers the interests of each author across mul-tiple documents, and aim to derive the representative topics for individual authors. The Author-Recipient-Topic (ART) model [13, 14] considers topics that are specific to each author-recipient pair. These models focus on profiling in-dividuals or pairwise relation. However, they do not model communities directly. Other works try to augment social network analysis with topic modeling [6, 16, 19, 12], and such models can discover users X  mixed membership in vari-ous topical communities. However these models are single-layered, without considering the general context of  X  X ho are collaborating on what concurrently X .
To discover the latent communities, we develop a genera-tive model, called COCOMP, which stands for COllaborator COMmunity Profiling. It attempts to discover communities in social media documents by considering context in both topics and collaboration groups. The basic rational is to assume that each social media document corresponds to a conversation session within one community, which is defined both by topics and participants. In other words, the topics of a social media document is derived from the community X  X  topic mixture, and the people involved in the thread tend to be those who actively participate in the work area.
Figure 2 shows the generative process of the latent com-munity model. Like traditional topic models, it is assumed that there are K word distributions  X  1: K which correspond to K latent topics, and are assumed to be Dirichlet distri-butions with prior  X  : Also, we assume that there are M communities, each of
Figure 2: Graphical representation of COCOMP. which has two components: topic mixture  X  and partici-pant mixture  X  . More specifically, in community m ( m = 1 , 2 ,...,M ): Finally, there is a community activeness vector  X  ,whichis assumed a Dirichlet distribution with hyperparameter  X  :
Further, we assume the following generative process of this collection of D email documents. For d =1 , 2 ,...,D : 1. A latent community c d is assigned by tha maximum 2. For each person p , run a Bernoulli trial according to 3. Suppose that this document has N d tokens. For each
We used Gibbs sampling for training the model. In this subsection, we derive the conditional posterior distributions for sampling these parameters sequentially.

For do cument d , the posterior probability for its commu-nity assignment will be where D (  X  d ) j is number of documents (except the d-th doc-ument) that are assigned to community j . After updating the community densities, the document is assigned to the community in which it has the highest likelihood.
For the i -th token in the d -th document, which is as-signed to community c d , the conditional posterior for its latent topic will be where n j,v is the number of times a unique word type v is assigned to topic k , n c,j is the number of times a token in community c is assigned to topic j , and the superscript  X  ( d, i ) means to exclude the i -th token in the d -th document.
After the training process, each parameter is estimated from the ending state: where D c,p is the number of times a person p is involved in community c .
In this section, we present experiments with the COCOMP model. First, we describe the overall setup of the experi-ments, and then show discovery results from each dataset.
First, we introduce the setup of the experiments, including data summaries, data preprocessing, implementation and platform, as well as the evaluation metric.

Datasets Our model has been tested with various types of social messages. Given that we are mainly interested in a single user X  X  perspective, we collected individual user X  X  email exchanges and celebrity X  X  Twitter interactions. Table 1 lists some basic statistics of each user X  X  social media dataset.
For each user, we include bi-direction communications. In other words, for email datasets, we include both inbox and outbox; and for twitter datasets, we include tweets written by this user as well as those that mention this user (such as re-tweets).

Preprocessing Basic data preprocessing has been con-ducted on the raw social media documents, such as pars-ing and unwrapping HTML tags, removing stopwords, and transforming the text into bag of words. We also excluded a small number of incomplete documents. A document is considered incomplete at the preprocessing stage, if it does not involve at least two different users, or if its remaining bag of words after stopword removal is empty.
 Implementation Our model has been implemented in Java, based on modifications of the MALLET [15] package. All experiments are run within Eclipse on a Dell Latitude, running 64-bit Windows 7 Professional with 8.00GB RAM.
Evaluation Metric Perplexity has been a common met-ric for evaluating language models. For community c ,with word sequence w c , whose length (number of tokens) is N c the perplexity can be computed as Assuming independence among words, we have where P ( v | k )and P ( v | k ) are computed as the posterior probability computed at the end of the training.
Since the Enron dataset is publicly available, effectiveness of our model can be verified using it as a benchmark. In Table 2 we list the top topics and top people for prominent communities discovered for the user Greg Whalley, assum-ing that there are 30 topics and 10 communities. For each community, we assign a label corresponding to the topics and the people, which are listed in the last column.
As we can see, most communities include greg.whalley on the top of the contributor list. This means that the user is active in such communities, so his rank is higher. When building his profile, we want to know how relevant a activity area (i.e. community) is to him, so it is desired that this user appears on the top of the contributor list for many communities, which means the communities are his major activity areas. Also, we can see that some topics may rank high in several communities, but the composition of topics and people are different.

From another data source [2], we know that Greg Whalley was the president of Enron, John Lavorato was a CEO, and Louise Kitchen was the president for Enron Online. We don X  X  have information for mark.frevert or liz.taylor, who might be the assistants for Greg Whalley and his contacts. Their roles are consistent to the topics and communities we have discovered.
Although the Enron dataset is public, the actual social network and communities is not well-known and there is no golden standard to check the exact correctness of the important communities found by COCOMP. As a result, we run COCOMP on collections of our own email datasets, which will be presented below.

First, we look at results on the zhouw dataset. This dataset contains one of the authors X  emails sent and received during her internship at IBM. Aassuming 10 topics and 3 communities, we find communities as shown in Figure 3.
As we can see in Figure 3(a), the three communities dis-covered are quite clear. It looks like that the first community is the CS department in general, the second community is the smaller research unit, and the third community has to do with the intern group. Both people and keywords make sense. For example, in the intern community, the top con-tacts are other interns who share similar weights in this com-munity. The top ranked topic, Topic 4, clearly shows that  X  X ummer X  and  X  X ntern X  are the top keywords, and  X  X enese X  is the summer intern coordinator.

Figure 3(a) is a mosaic plot of the topic distribution in each community. Each other represents a topic, and each column represents a community. We can see clearly that the composition of topics, as indicated by the heights of the rectangles, is very different from one community to another. The widths of the rectangles represent the size of each com-munity. In other words, they are proportional to the number of documents in each community. Clearly, a lot of the emails are related to research.

Despite the fact of being a bit more complex than the plain LDA model, since we consider people in addition, our model converges reasonably fast. Figure 4 shows the con-vergence process for model training. Although we run 1 , 000 iterations, the log likelihood begins to stabilize around the 200-th iteration. Other datasets show similar results.
In return of handling more complexity by considering the people information, the communities discovered by COCOMP make better sense than those derived directly from by LDA. In order to find three communities, we run the LDA model with the parameter k = 3. The basic idea is to identify the topic mixture of each document, and assign the documents to the most important topic. Then based on such document communities, we find the most frequently involved people. The results are listed in Table 3.

The communities, as indicated by the key words, make some sense. For example, Community 1 seems to be the announcement of talks and activities. The top participants include major email lists, to which general announcements are typically sent to. However, a major problem is that the interns group is not found. Despite of the saliently differ-ent topics, because there are a small number of emails in the interns community, the LDA fails to capture that com-munity. By considering people (social contacts) in addition, there is clearly the benefit of finding communities that are interesting to the user.

As for the quality of the topics, Figure 6 shows a sim-ple comparison of perplexity for different parameter sets. The three bars on the left correspond to perplexities de-rived from LDA [5], using k =3, k =5,and k = 10, re-spectively. The two bars on the right represent perplexities derived from COCOMP on the same training data, using 10-topic-3-community ( K =10, C = 3), and 10-topic-5-community( K =10, C = 5), respectively. The COCOMP model performs consistently better than LDA for having lower perplexity.

In this subsection, we apply the COCOMP model on so-cial collaboration data from another author of the paper dur-ing a 3-month period. The hongxia dataset contains mostly emails, but also small amounts of data crawled from other social software in IBM, such as wiki and communities. The top 6 communities are shown in Figure 5, assuming 20 latent topics and 10 communities.

As shown in Figure 5, the top 2 communities are both about her big data analytics research activities. Data ana-lytics is her main research direction. Community 2 is focused on the user and community profiling work while community 1 is focused on using user profile to perform context aware prioritization on incoming messages/updates for the user. As one can understand, these research endeavors overlap in the research nature. While she heavily works with 3 other colleagues in both these two areas, some others involved in these two areas are different. Our model clearly detects two overlapping communities that focus on two somewhat over-lapping research activities. Moreover, these two activity ar-eas are indeed her most focused activities.

The second major activity for Hongxia is related to patent-ing. Our model detected two different communities that Hongxia is involved with regarding patenting, namely com-munity 8 and community 5, ranked #3 and #4 respectively in top 6. Again both the topics and the people involved in these two communities overlap. Indeed both Topic 9 is shown in these two communities. Our model managed to clearly detect these two overlapping communities. This in-dicates the multi-layers of Hongxia X  X  social links with those overlapping members in these two communities, an example of what we illustrated in Figure 1 in Section 2.

Ranked #5 in the detected top 6 communities by our model is Community 3. It is mainly about GTO (Global Technological Outlook) planning activities that she involved. It involves proposal writing, submitting and reviewing. This community consists of a different group of colleagues that she lightly collaborates with.

Lastly, Community 7 is about another light activity area in this 3-month period. It is about Digital Rights Manage-ment which was an old research area that Hongxia heavily involved in the past.  X  X raitor tracing X  was the main research topic in this activity area as indicated by Topic #12.
For comparison purpose, we also experiment with LDA using the same dataset. We have LDA detect the top 10 topics and cluster the documents into its dominant topics. We then derive the 10 communities for Hongxia by extract-ing the top people involved in the corresponding documents clustered into each of those 10 topics. For the sake of com-parison, we also illustrate the top 6 communities/topics in Table 4. Again, the weight is calculated based on the num-ber of documents clustered into each community/topic.
As we can see from the table, LDA also detected the two topics/commnities about data analytics, namely Topic 5 and Topic 2. However, the top people involved in both commu-nities are not as precise as the results from our proposed model. More significantly the data analytics activities are not detected very completely. Indeed, many are mixed up with other topics as clearly demonstrated by Topic 3, 4 and 7 in the table. The fact that topics are mixed in the detected communities also means that the documents clustered into each topic are mixed, resulting in the inaccurate weighting of the community. As one can see, LDA result ranks the Topic/Community 2 as the last of the top 6 communities. This rank is incorrect. Similarly, both Topics 3 and 7 are partly about data analytics work but each mixed up with several different actual activities for Hongxia. For example, Topic 7 mixed data analytics with patenting. But these two activities have no overlapping in terms of topics. As a re-sult, the top people shown for these two communities are still those same people involved in the data analytics activ-ity area. Topic/Community 1 is also a mix of topics (mixing with data analytics activities), but to a less extent. It is mainly about patenting. However it mixes the two different groups of people that user Hongxia involved in working with on patenting. In fact some of those people are not shown on top. Instead some of the people involved in data analytics still appear in top 6 participants in this community due to topic mixture. Topic 4 is partly about  X  X raitor tracing X  but heavily mixed with other topics (mainly with the data an-alytics activities). As a result, the correct group of people involved are not even shown on top.
In order to study the effectiveness of our model on Twitter datasets, we choose two celebrity Twitter users and study their tweet exchange with others Twitter users. One ac-count is the United States President Barack Obama (Fig-ure 7), and the other is a famous singer Justin Beiber (Fig-ure 8). We have crawled all the tweets posted by these two users as well as the replied-to tweets by other users, started from November 1, 2009. As a result, we have col-lected 6 , 134 tweets for Barack Obama and 5 , 077 tweets for Justin Beiber. Twitter users use some structure conventions such as a user-to-message relation (i.e. initial tweet author, via, cc, by), type of message (i.e. Broadcast, conversation, or retweet messages), type of resources (i.e. URLs, hash-tags, keywords) to overcome 140 character limit. Since the data are quite noisy with many URLs and acronyms, we pre-processed the data by removing HTML tags and extremely infrequent words.

As shown in Figure 7, if we model Obama X  X  tweets with 30 topics and 5 communities, we can see that his communi-ties from November 2009 to February 2010 can be roughly represented as: President, which is about comments on his advocacy of Presidency; Public Policy, which related to do-mestic and international politics and policy; Holidays, which is mainly about wishing the best for American families and friends; Senate Votes that has to do with health bills; and Blessing Haiti after the tremendous earthquake. It is in-teresting to observe that user 45593 is the Twitter account whitehouse, which is expected to relate to the President regarding domestic and international policies. user 7008 is Nicki Minaj, a singer who originated from Haiti. Not sur-prisingly she is most concerned about the tragedy that has happened in her home country. user 251666 is Martha Coak-ley, Massachusetts Attorney General, who is on top list of participants in Community 4, which is about law making.
We also show Justin Beiber X  X  Twitter communities in Fig-ure 8. For a pop star like Justin, it is expected that the majority of his  X  X ollaborators X  are his fans. However, we are able to group those fans into several groups, such as those who like to express emotions (Community #3) and those who does very casual conversations (Commmunity 4). Community 5 is mainly about Justin X  X  broadcasts of media, such as showing his fans some videos. In Communities 1 and 2, different groups of fans were talking about his new album  X  X y World X , and his Golden Ticket Concert, respectively. Finally, we found that Justin Beiber appeared in Barack Obama X  X  Community 1. In that community he was ranked second in the participant list, right after Obama himself. What does Justin have to do with Obama? On Justin X  X  Wikipedia page [1], we found that  X  X ieber performed Stevie Wonder X  X  Someday at Christmas for U.S. President Barack Obama and first lady Michelle Obama at the White House for Christmas in Washington, which was broadcast on De-cember 20, 2009, on U.S. television broadcaster TNT. X  So probably they are connected because of this event, and also Michelle, who is also in Community 1. For that big event, as a most popular pop star who has countless fans all over the country, Justin is promoted to an activity area of the Presi-dent. For two very influential twitter users, it is interesting to see how they are connected with each other on Twitter. In this paper, we design a latent community model, called COCOMP, to uncover the communities of each user as well as their associated topics and communities. In particular, it models each community as a mixture of topics with a corre-sponding group of users who collaborate together on these topics. With a latent assignment of community membership, we assume that each social media document corresponds to a sharing activity within a community (both topic-wise and person-wise). Experiment results on email and social media datasets demonstrate the effectiveness of our model.
For future work, our model can be extended in various ways. For example, instead of treating all people involved as the same, there is the need of separating active members from passive members (i.e. those who only receive the mes-sages). Also, since the social media contents change over the time, it is meaningful to develop dynamic models to capture the evolving process and online algorithms to monitor the changes over time. This research is continuing through participation in the Social Media in Strategic Communication (SMISC) program sponsored by the U.S. Defense Advanced Research Projects Agency (DARPA) under Agreement Number W911NF-12-1-0034. The views and conclusions contained herein are those of the authors and should not be interpreted as represent-ing the official policies or endorsements, either expressed or implied, of any of the above organizations or any person connected with them. [1] http://en.wikipedia.org/wiki/Justin Bieber, retrieved [2] Enron employee status. Retrieved from http://www.isi [3] A. Ahmed, E. P. Xing, W. W. Cohen, and R. F.
 [4] K. Balog and M. de Rijke. Finding experts and their [5] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [6] J. Chang, J. L. Boyd-Graber, and D. M. Blei.
 [7] W. de Nooy, A. Mrvar, and V. Batagelj. Exploratory [8] E. Erosheva, S. Fienberg, and J. Lafferty.
 [9] T. Hofmann. Probabilistic latent semantic analysis. In [10] T. Lappas, K. Liu, and E. Terzi. Finding a team of [11] Q. Liu, Y. Ge, Z. Li, E. Chen, and H. Xiong. [12] Y. Liu, A. Niculescu-Mizil, and W. Gryc. Topic-link [13] A. McCallum, A. Corrada-Emmanuel, and X. Wang. [14] A. McCallum, X. Wang, and A. Corrada-Emmanuel. [15] A. K. McCallum. Mallet: A machine learning for [16] A. Qamra, B. L. Tseng, and E. Y. Chang. Mining blog [17] M. Rosen-Zvi, T. L. Griffiths, M. Steyvers, and [18] E. Zheleva, C. Park, and L. Getoor. Co-evolution of [19] D. Zhou, E. Manavoglu, J. Li, C. L. Giles, and
