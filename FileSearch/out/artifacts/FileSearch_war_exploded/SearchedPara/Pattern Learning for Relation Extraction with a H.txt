 The detection of relations between entities for the automatic population of knowledge bases is very useful for solving tasks such as Entity Disambigua-tion, Information Retrieval and Question Answer-ing. The availability of high-coverage, general-purpose knowledge bases enable the automatic iden-tification and disambiguation of entities in text and its applications (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Kwok et al., 2001; Pasca et al., 2006; Weld et al., 2008; Pereira et al., 2009; Kasneci et al., 2009).
Most early works in this area were designed for supervised Information Extraction competitions such as MUC (Sundheim and Chinchor, 1993) and ACE (ACE, 2004; Doddington et al., 2004; Li et al., 2011), which rely on the availability of anno-tated data. Open Information Extraction (Sekine, 2006; Banko et al., 2007; Bollegala et al., 2010) started as an effort to approach relation extraction in a completely unsupervised way, by learning regular-ities and patterns from the web. Two example sys-tems implementing this paradigm are T EXT R UN -NER (Yates et al., 2007) and R E V ERB (Fader et al., 2011). These systems do not need any manual data or rules, but the relational facts they extract are not immediately disambiguated to entities and relations from a knowledge base.

A different family of unsupervised methods for relation extraction is unsupervised semantic pars-ing , which aims at clustering entity mentions and relation surface forms, thus generating a semantic representation of the texts on which inference may be used. Some techniques that have been used are Markov Random Fields (Poon and Domingos, 2009) and Bayesian generative models (Titov and Klemen-tiev, 2011). These are quite powerful approaches but have very high computational requirements (cf. (Yao et al., 2011)).

A good trade-off between fully supervised and fully unsupervised approaches is distant supervi-sion , a semi-supervised procedure consisting of find-ing sentences that contain two entities whose rela-tion we know, and using those sentences as train-ing examples for a supervised classifier (Hoffmann et al., 2010; Wu and Weld, 2010; Hoffmann et al., 2011; Wang et al., 2011; Yao et al., 2011). A usual problem is that two related entities may co-occur in one sentence for many unrelated reasons. For ex-ample, Barack Obama is the president of the United States , but not every sentence including the two en-tities supports and states this relation. Much of the previous work uses heuristics, e.g. extracting sen-tences only from encyclopedic entries (Mintz et al., 2009; Hoffmann et al., 2011; Wang et al., 2011), or syntactic restrictions on the sentences and the entity mentions (Wu and Weld, 2010). These are usually defined manually and may need to be adapted to dif-ferent languages and domains. Manually selected seeds can also be used (Ravichandran and Hovy, 2002; Kozareva and Hovy, 2010).

The main contribution of this work is presenting a variant of distance supervision for relation extrac-tion where we do not use heuristics in the selection of the training data. Instead, we use topic models to discriminate between the patterns that are expressing the relation and those that are ambiguous and can be applied across relations. In this way, high-precision extraction patterns can be learned without the need of any manual intervention. Similar to other distant supervision methods, our ap-proach takes as input an existing knowledge base containing entities and relations, and a textual cor-pus. In this work it is not necessary for the corpus to be related to the knowledge base. In what follows we assume that all the relations studied are binary and hold between exactly two entities in the knowl-edge base. We also assume a dependency parser is available, and that the entities have been automat-ically disambiguated using the knowledge base as sense inventory.

One of the most important problems to solve in distant supervision approaches is to be able to dis-tinguish which of the textual examples that include two related entities, e i and e j , are supporting the re-lation. This section describes a fully unsupervised solution to this problem, computing the probability that a pattern supports a given relation, which will allow us to determine the most likely relation ex-pressed in any sentence. Specifically, if a sentence contains two entities, e i and e j , connected through a pattern w , our model computes the probability that the pattern is expressing any relation  X  P ( r | w )  X  for any relation r defined in the knowledge base. Note that we refer to patterns with the symbol w , as they are the words in our topic models.
 Preprocessing As a first step, the textual corpus is processed and the data is transformed in the fol-lowing way: (a) the input corpus is parsed and en-tities are disambiguated; (b) for each relation r in the knowledge base, a new (initially empty) docu-ment collection C r is created; (c) for each entity pair ( e i ,e j ) which are related in the knowledge base, a new (initially empty) document D ij is created; (d) for each sentence in the input corpus containing one mention of e i and one mention of e j , a new term is added to D ij consisting of the context in which the two entities were seen in the document. This context may be a complex structure, such as the dependency path joining the two entities, but it is considered for our purposes as a single term; (e) for each relation r relating e i with e j , document D ij is added to collec-tion C r . Note that if the two entities are related in different ways at the same time, an identical copy of the document D ij will be added to the collection for all those relations.

Figure 1 shows a set of document collections gen-erated for three relations using this procedure. Each relation r has associated a different document col-lection, which contains one document associated to each entity pair from the knowledge base which is in relation r . The words in each document can be, for example, all the dependency paths that have been observed in the input textual corpus between the two related entities. Each document will contain some very generic paths (e.g. the two entities consecutive in the text) and some more specific paths.
 Generative model Once these collections are built, we use the generative model from Figure 2 to learn the probability that a dependency path is conveying some relation between the entities it con-nects. This model is very similar to the one used by Haghighi and Vanderwende (2009) in the con-text of text summarization. w (the observed vari-able) represents a pattern between two entities. The topic model  X  G captures general patterns that appear for all relations.  X  D captures patterns that are spe-cific about a certain entity pair, but which are not generalizable across all pairs with the same relation. Finally  X  A contains the patterns that are observed across most pairs related with the same relation.  X  A is the topic model of interest for us.

We use Gibbs sampling to estimate the different models from the source data. The topic assignments (for each pattern) that are the output of this process are used to estimate P ( r | w ) : when we observe pat-tern w , the probability that it conveys relation r . Settings We use Freebase as our knowledge base. It can be freely downloaded 1 . text corpus used con-tains 33 million English news articles that we down-loaded between January 2004 and December 2011. A random sample of 3M of them is used for building the document collections on which to train the topic models, and the remaining 30M is used for testing. The corpus is preprocessed by identifying Freebase entity mentions, using an approach similar to (Milne and Witten, 2008), and parsing it with an inductive dependency parser (Nivre, 2006).

From the three million training documents, a set of document collections (one per relation) has been generated, by considering the sentences that contain two entities which are related in FreeBase through any binary relation and restricting to high-frequency 200 relations. Two ways of extracting patterns have been used: (a) Syntactic , taking the dependency path between the two entities, and (b) Intertext , taking the text between the two. In both cases, a topic model has been trained to learn the probabil-ity of a relation given a pattern w : p ( r | w ) . For  X  we use symmetric Dirichlet priors  X  G = 0 . 1 and  X 
D =  X  A = 0 . 001 , following the intuition that for the background the probability mass across patterns should be more evenly distributed.  X  is set as (15, 15, 1), indicating in the prior that we expect more patterns to belong to the background and entity-pair-specific distributions due to the very noisy nature of the input data. These values have not been tuned.
As a baseline, using the same training corpus, we have calculated p ( r | w ) using the maximum likeli-hood estimate: the number of times that a pattern w has been seen connecting two entities for which r holds divided by the total frequency of the pattern. Extractions evaluation The patterns have been applied to the 30 million documents left for testing. For each pair of entities disambiguated as FreeBase entities, if they are connected through a known pat-tern, they are assigned arg max r p ( r | w ) . We have randomly sampled 4,000 such extractions and sent them to raters. An extraction is to be judged cor-rect if both it is correct in real life and the sentence from which it was extracted really supports it. We have collected three ratings per example and taken the majority decision. There was disagreement for 9.4% of the items on whether the sentence supports the relation, and for 20% of the items on whether the relation holds in the real world.

The results for different thresholds of p ( r | w ) are shown in Figure 3. As can be seen, the MLE base-lines (in red with syntactic patterns and green with intertext) perform consistently worse than the mod-els learned using the topic models (in pink and blue). The difference in precision, aggregated across all re-lations, is statistically significant at 95% confidence for most of the thresholds.
 Extractions aggregation We can take advantage of redundancy on the web to calculate a support met-ric for the extractions. In this experiment, for every extracted relation ( r,e 1 ,e 2 ) , for every occurrence of a pattern w i connecting e 1 and e 2 , we add up p ( r | w i ) . Extractions that are obtained many times and from high-precision patterns will rank higher. Table 1 describes the results of this aggregation. We have considered the top four highest-frequency relations for people. After aggregating all the ex-tracted relations and ranking them by support, we have divided the evaluation set into two parts: (a) for relations that were not already in FreeBase, we evaluate the precision; (b) for extractions that were already in FreeBase, we take the top-confidence sen-tence identified and evaluate whether the sentence is providing support to the relation. For each of these, both syntactic patterns and intermediate-text patterns have been evaluated.
 The results are very interesting: using syntax, Death place appears easy to extract new relations and to find support. The patterns obtained are quite unambiguous, e.g.

On the other hand, birth place and nationality have very different results for new relation acquisition vs. finding sentence support for new relations. The reason is that these relations are very correlated to other relations that we did not have in our training set. In the case of birth place , many relations re-fer to having an official position in the city, such as mayor ; and for nationality , many of the patterns ex-tract presidents or ministers . Not having mayor or president in our initial collection (see Figure 1), the support for these patterns is incorrectly learned. In the case of nationality, however, even though the ex-tracted sentences do not support the relation (P@50 = 0.34 for intertext), the new relations extracted are mostly correct (P@50 = 0.86) as most presidents and ministers in the real world have the nationality of the country where they govern. We have described a new distant supervision model with which to learn patterns for relation extraction with no manual intervention. Results are promising, we could obtain new relations that are not in Free-Base with a high precision for some relation types. It is also useful to extract support sentences for known relations. More work is needed in understanding which relations are compatible or overlapping and which ones can partially imply each other (such as president -country or born in -mayor ).
