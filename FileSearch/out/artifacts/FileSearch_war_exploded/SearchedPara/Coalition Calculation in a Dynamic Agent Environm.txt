 Ted Scully Edward.Scully@nuigalway.ie MichaelG.Madden Michael.Madden@nuigalway.ie Gerard Lyons Gerard.Lyons@nuigalway.ie A coalition is a set of self-interested agents that agree to cooperate to execute a task or achieve a goal (Tsve-tovat et al., 2000). Coalition formation is currently an active area of research in multiagent systems. This paper considers coalition formation in the context of a market-place where organizations (represented by agents) can cooperate to bid for and perform a task. While the techniques proposed in this paper are gen-erally applicable, we provide context for the work by considering a simplified model of a real world transport market-place. Each agent represents a transportation firm, and its abilities relate to the routes its firm can service. A task involves the transportation of an item from a collection point to a delivery point. The task is broken into subtasks, which are the routes that consti-tute a complete journey. Because different firms have different abilities, their representative agents may form coalitions to service a transportation task. In this domain, a transportation task consisting of sev-eral subtasks is proposed in the market-place. Each agent attempts to form a coalition with other agents to bid for the task. Thus, multiple coalitions are pro-posed and these compete to be awarded the task. We examine the problem from the perspective of an indi-vidual agent; we are not concerned with overall sys-tem performance and we do not make any assump-tions about other agents X  strategies for coalition for-mation. We assume an agent can provide assessments of the abilities of all other agents in the market, but that these assessments are based on personal beliefs rather than objective information. Based on these as-sessments and the task proposed, it must determine the optimal coalition to propose. We define coalition calculation as the determination of the optimal set of agents with which to enter into coalition. Dutta and Sen (2002) observe that in real-life scenarios, multi-ple objectives like time, quality, dependability, etc., will be involved when an agent evaluates the benefit of interacting with another agent. This statement also holds true for coalition calculation: an agent will want to consider all available information in order to ob-tain an accurate valuation of interacting with a num-ber of other agents in a coalition. This information is contained in the profile of other agents X  abilities, as assessed by an agent. An agent X  X  ability to perform a particular subtask is measured by multiple metrics. In the context of our transportation domain, for ex-ample, an agent X  X  ability to deliver an item could be measured by the metrics of time, cost and reliability. A number of complications arise in obtaining an accu-rate value of a coalition using multiple metrics. Firstly, metrics are rarely of equal importance. For example, cost may be significantly more important than relia-bility or time in one situation, but this may change depending on the type of market and specific market conditions. Secondly, metrics often conflict; for exam-ple, an agent may aim to minimize both cost and time, but deliveries at lower cost may take longer time. An-other complication occurs in dynamic markets, where metric importance may vary over time. For example, the significance of cost might decrease over time while the importance of reliability increases. Hence, tech-niques must be sensitive to market changes that can affect metric importance.
 To address these problems, we propose a new algorithm called E-Pareto , which is based on a multi-objective optimization evolutionary algorithm (MOEA). An MOEA combines multiple-objective de-cision making and evolutionary computation. The key concept in obtaining a true valuation of a coalition is Pareto dominance. The combination of an evolution-ary algorithm and Pareto dominance allows for the approximation of the Pareto optimal set of coalitions (Zitzler et al., 2004). We incorporate into this a dis-tance weighting algorithm to maintain diversity when searching for the Pareto optimal solution set, and to encourage search in areas of solution space that have been previously successful.
 In order to select the optimal coalition from the approximated Pareto set, we use an instance-based learning (IBL) algorithm that rewards/punishes coali-tions based on their proximity to previously success-ful/unsuccessful coalitions. We also incorporate explo-ration into this IBL algorithm so that it does not al-ways pursue the greedy strategy of selecting the coali-tion that obtains the highest score.
 This paper is organized as follows. We describe the problem in more detail in Section 2, followed by a de-tailed description of our E-Pareto solution in Section 3. Section 4 presents empirical results and analyzes the performance of the solution. Section 5 describes a collection of related work and details why the prob-lem described above cannot be addressed by existing techniques. Finally, conclusions are drawn in Section 6. We consider an environment consisting of a set of n self-interested agents A = { a 1 ,a 2 ,a 3 , ..., a n } . Tasks to be completed are proposed to all agents in A , where a task T consists of m subtasks { t 1 ,t 2 ,t 3 , ..., t m } Bearing in mind the individual-agent perspective taken in this work, as outlined in the Introduction, each agent maintains a private account of the abilities of other agents within the environment. For a subtask t , an agent a i has an associated ability, B ik . Since the ability represents p metrics such as speed, reliability, etc., B ik is a vector: { b 1 ik ,b 2 ik ,b 3 ik , ..., b sent metric values in the range 0 to 1. No assumption is made about how this private data is derived; the objective of each agent is the determination of the op-timal coalition given the data available to it. (In the absence of other information, it is rational for an agent to act on the basis that its beliefs are accurate.) A coalition C consists of a set of agents such that C  X  A . A function alloc determines the agent within C that will perform each individual subtask: the agent within C that will perform subtask t k is alloc ( k ). An agent may perform more than one subtask in a coali-tion. An agent X  X  objective is to determine the optimal coali-tion given its beliefs about the abilities of other agents, while remaining sensitive to market conditions. This section describes our E-Pareto algorithm, which is de-signed for this task. Since the ability of each agent in the coalition is represented by multiple metrics, the determination of the optimal coalition becomes a multi-objective optimization problem. We tackle this problem using an adapted MOEA. The MOEA we use is based on the Nondominated Sorting Genetic Algo-rithm (NSGA) (Srinivas &amp; Deb, 1994). We use Pareto dominance and a distance weighted algorithm to deter-mine the Pareto optimal set sensitive to market con-ditions (see Section 3.1). The algorithm terminates after a number of generations, returning the Pareto optimal set of coalitions. We detail how the optimal coalition is chosen from this Pareto optimal set using an instance-based learning algorithm in Section 3.2. We also describe how exploration of the solution space can be beneficial compared to a consistently greedy selection in Section 3.3. 3.1. Coalition Valuation An agent has a different ability for each subtask it can perform. These abilities are represented by multiple metrics. A coalition X  X  ability to perform a task can be determined by the abilities of its member agents to perform their respective subtasks. Hence, the ability of a coalition is also represented by multiple metrics. For example to calculate the quality metric of a coali-tion for a given task, we sum the quality metric of each member agent for the specific subtask they are performing. This value is then normalized by dividing it by the number of member agents in the coalition. Thus, for a coalition C a , its ability  X  a to perform the task is the vector {  X  1 a , X  2 a , X  3 a , ...,  X  p a } such that (As before, m is the number of subtasks in T ,which is also equal to the number of agents in a coalition to service T .) Thus, coalitions can be plotted in m -dimensional space based on their respective abilities. In the MOEA, an individual represents a coalition con-sisting of several agents, configured so that each of these agents is assigned to 1 or more subtasks. We calculate fitness of an individual, F ( i ), according to (2). The terms of this equation are explained in the following paragraphs. In our scheme, lower values are assigned to better individuals.
 The first term, L ( i ), relates to Pareto dominance. A vector x is said to dominate a vector y ( x y )if no component of x is smaller then the corresponding component of y and at least one component is greater (Zitzler et al., 2004). Each coalition i from the set that dominates all other coalitions in the population is given a fitness level of L ( i ) = 1 and is then removed from the population. Then, the next non-dominated set of coalitions are assigned a fitness level of L ( i )= 2. This continues until the population is empty. At this stage, all coalitions have received an integer rating value based on Pareto dominance.
 The term D ( i ) in equation (2) seeks to promote di-versity in the population, to counteract the tendency of evolutionary algorithms toward a single solution. We adopt an approach similar to that taken by the Strength Pareto Evolutionary Algorithm 2 (Zitzler et al., 2001). For an individual i , the average Euclid-ian distance, AD ( i ), from i to all other individuals in the population is calculated. The density of individ-ual i is then computed as D ( i )= 1 AD ( i )+2 . This term therefore penalizes individuals in areas of high density. The purpose of the term ND ( i )istoascribebetter fitness scores to individuals that are more similar to previously successful coalitions. This encourages the MOEA to focus on areas of the solution space that have exhibited a high success rate, as such areas should correspond to accurate evaluations of metric impor-tance. To achieve this, each time a coalition succeeds in obtaining a task, the evolutionary algorithm records its details in a set P . Then, for each individual i within the population, the average distance from i to all coali-tion points in P is calculated. ND ( i ) is then com-puted as the average distance normalized by dividing it by the maximum possible distance D max between two coalitions. Therefore, individuals that are further from previously successful coalitions are given larger penalties by this term.
 Clearly, L ( i ) is the most important term in (2), as it is an integer value whereas D ( i )and ND ( i ) have val-ues less than 1. The parameter,  X  , has a range of 0-1 and is used to control the relative importance of D ( i ) and ND ( i ). Since  X D ( i )+(1  X   X  ) ND ( i )cannotex-ceed 1, these terms just affect the relative fitness X  X  of individuals with the same level of Pareto optimality. When initialized, the algorithm has no available his-torical data. In this case the value of ND ( i )issetto 0, hence fitness calculation is purely dependent on the value of L ( i )and D ( i ). 3.2. Coalition Selection using IBL After evolving the population for a specified number of generations, the MOEA returns an approximate Pareto optimal set of coalitions. The preferred coali-tion must now be selected from this set. To distinguish between these coalitions, we propose a scoring mech-anism that uses instance-based learning (IBL) to take into consideration previous successful and unsuccessful coalitions.
 We assume that an agent is informed of the winning coalition after proposing a coalition. Each time the MOEA proposes a coalition, it records both this coali-tion and the coalition that is successful in obtaining the task in a set Q , such that Q = { q 1 ,q 2 ,q 3 , ..., q Each coalition q a in Q is assigned a value V ( q a ), where V ( q a ) = 2 if the coalition X  X  bid for the task was suc-cessful or V ( q a )=  X  1 if it was unsuccessful. Q has a maximum capacity so that older results are forgotten over time.
 Based on this, the IBL algorithm assigns a score S ( i )to each coalition i that is a member of the Pareto optimal set based on weighted distance from members of Q . The score is based on the inverse distance squared from i to each member q j of Q , weighted by V ( q j ): Thus, the closer a coalition is to a negative result the more its score will be downgraded; the closer it is to a positive result the more its score will be upgraded. The weighting of V ( q j ) ensures that in a competitive area of the solution space, where there will be a high concentration of both positive and negative results in close proximity, positive results are given greater im-portance than negative results. The coalition with the highest S ( i ) is chosen, with ties being broken at random. When the algorithm is initialized there is no available historical data, so all coalitions receive a score of 0. Initially therefore, the algorithm will select a coalition at random from the Pareto optimal set. 3.3. Adding Exploration to IBL The IBL approach described above is purely greedy, as it focuses attention only on regions of the solution space that have exhibited a high success rate in the past. By doing this, it potentially misses regions that could possibly lead to higher success rates. To avoid this, we extend the technique to incorporate explo-ration into the selection process. This also allows the agent to adapt more quickly to changing metric values. Essentially, during an exploration phase an area of the Pareto curve is picked at random to explore. Future coalition selection will place emphasis on this area if, in the exploration phase, it is found to have a high associated success rate.
 As in Section 3.2, the set Q records all coalitions pro-posed by the evolutionary algorithm as well as all win-ning coalitions. Exploration phases are initiated with a probability  X  . To prevent coalition selection becom-ing too random a process, a small value of  X  should be adopted. At the start of an exploration phase, a random coalition is chosen from the Pareto optimal set of coalitions. If this coalition is successful then the IBL algorithm begins to explore this area of the curve. This is done by creating a new set Q that temporarily replaces Q . Q initially contains just the randomly se-lected coalition and, like Q , records all coalitions pro-posed by the agent and all winning coalitions for the duration of the exploration phase. Since the IBL X  X  scores, given by (3), are computed relative to Q , sub-sequent coalitions proposed will be in the same area of the Pareto curve. The exploration period ends af-ter a pre-determined number of coalitions have been proposed. The success rates of Q and Q are then compared. The success rate is calculated by dividing the number of successful coalitions in a set by the to-tal number of coalitions in the set. If the success rate of Q is greater then the success rate of Q , then the exploration phase has proved unsuccessful and Q is discarded. In that case, the IBL algorithm returns its focus to the area prior to exploration. However, if the success rate of Q is greater then that of Q , exploration has proved successful. In that case, Q is set equal to Q so that the IBL will assign higher scores to coalitions in this new area of the Pareto optimal curve. The objective of the empirical evaluation is to demon-strate that our E-Pareto algorithm is capable of ac-curately evaluating coalitions by eliciting metric im-portance and adapting to metric variations over time for conflicting metrics. We also wish to establish that E-Pareto is an advancement when compared with pre-vious approaches to coalition evaluation. We have de-veloped a simulation testbed that contrasts the per-formance of E-Pareto against three other evolutionary based algorithms utilizing previous techniques of coali-tion evaluation. The following subsection presents the methodology and the results. 4.1. Experimental Methodology As stated earlier, the coalition calculation operates from the perspective of one agent. This agent is a member of a market-place with a population of 250 agents, and maintains a personal profile of each agent X  X  ability. Agents are capable of performing 15 possi-ble subtasks; so 15 abilities are generated for each agent. These values were assigned to the number of agents and subtasks because they represent a signif-icantly difficult problem to address. We found that algorithm performance was relatively independent of these values. For ease of visualization, in these exper-iments each agent X  X  ability is measured by two met-rics, m 1 and m 2 , both in the range 0-1 inclusive. The agent wishes to maximize both metrics, but the met-rics conflict with one another. The profile of agent abilities is generated randomly at the start of an ex-periment. To simulate conflicting metrics, they obey the rule m 1 2 + m 2 2  X  1.
 To evaluate the performance of the E-Pareto strategy, we set up a competition between an agent using E-Pareto and three other agents that are also based on evolutionary algorithms. Therefore, four agents com-pete for all tasks, each using a different technique to compute fitness for their evolutionary algorithm: 1. E-M1: Calculates coalition fitness based solely on 2. E-M2: Calculates coalition fitness based solely on 3. E-M12: Calculates coalition fitness based equally 4. E-Pareto: As described in Section 3 Thus, E-M1 ascribes importance to m 1 only, E-M2 ascribes importance to m 2 only, and E-M12 ascribes equal importance to both metrics. E-Pareto adapts to changes in the importance of metric values. To our knowledge this problem has not previously been ad-dressed; therefore E-Pareto cannot be tested against other algorithms that generate good solutions over the entire range of importance values. Instead, it is tested against three algorithms that represent previous ap-proaches to this problem. These algorithms E-M1 , E-M2 , E-M12 represent the optimal strategies for spe-cific metric values. By placing E-Pareto in competi-tion with the other evolutionary algorithms, we can examine how E-Pareto performs both in the range of metric values for which the competing evolutionary al-gorithms represent the optimal strategy and outside of these metric values. Each algorithm is purposely based on an evolutionary search algorithm because the re-sults obtained can be attributed entirely to the means of coalition evaluation used, independently of the un-derlying search algorithm.
 In equation (2),  X  is used to control the relative im-portance of D ( i )and ND ( i ) when assigning fitness to coalitions. It was found that a value of 0.25 for  X  pro-duced the best results. Lower  X  values focused too heavily on previously successful areas while higher  X  values focused too heavily on maintaining diversity. Each algorithm generates an initial random popula-tion of 250 coalitions. We used a crossover probability of 70% and a mutation probability of 5%, as these settings were found to be reasonable for all four algo-rithms. Moderate changes to these values does not sig-nificantly degrade performance. Although we assume throughout this work that an agent operates with per-sonal beliefs about the abilities of all other agents that might not be accurate, for these experiments we pro-vide the four competing agents with identical beliefs about the abilities of all agents so that we can compare the performance of the algorithms independent of this information.
 The competition between these four algorithms allows us to determine which performs best when faced with the task of calculating the optimal coalition. The met-rics that the agents use, m 1 and m 2 , are conflicting, of differing importance and the importance rating of each metric varies over time. We refer to the importance of m 1 and m 2 as MI 1 and MI 2 respectively. Initially, MI 1 issetto0%and MI 2 is set to 100%. With the metric importance values held constant, 60 identical tasks are proposed in succession to each of the agents, with the tasks consisting of 15 subtasks. The agents then compete to obtain the task.
 For each task received, the evolutionary algorithms run for 35 generations. We limited the number of genera-tions to 35 as we found that the algorithms plateaued after this value. They each then propose the optimal coalition they calculated. The current metric impor-tance weighting is used to determine which of the four coalitions proposed has the highest value. The m 1 and m 2 values for each coalition are calculated based on the profiles of agent abilities. The overall value of a coali-tion is determined as m 1 MI 1 + m 2 MI 2 . Whichever coalition obtains the highest values is awarded the task. After all 60 tasks have been proposed, the num-ber of tasks won by each algorithm for the current combination of metric importance is recorded. Next, the importance of each metric is altered, incre-menting MI 1 by 1% and decrementing MI 2 by 1%, and the cycle of proposing 60 tasks begin again. The experiment terminates once MI 1 reaches a value of 100%. The steady increase/decrease in metric impor-tance is not a realistic assumption. However, the re-sults we obtain would equally hold for metric impor-tance that changes gradually up or down from step to step in a random walk. The reason we use a steady unidirectional change in metrics in these experiments is to allow us to evaluate the performance over all pos-sible metric values. 4.2. Results When evaluating E-Pareto we are interested in how it performs against the other evolutionary algorithms described in Section 4.1. Also of interest is the differ-ence in performance of E-Pareto when using a purely greedy coalition selection strategy (Section 4.2.1) and when using the exploration-enabled coalition selection strategy (Section 4.2.2). 4.2.1. Greedy Coalition Selection Figure 1 depicts the number of tasks obtained by each evolutionary algorithm throughout the duration of this experiment. The x axis represents the current value of MI 1 in terms of percentages. The corresponding value of
MI 2 can be calculated as (100% -MI 1 ). The y axis represents the number of tasks won. Initially MI 2 has a value of 100%, therefore E-M2 is immediately com-petitive. The reason for this is that it bases its fitness function on obtaining the coalition with highest value of m 2 . However, the E-Pareto algorithm also proves to be as successful as E-M2 . When MI 1 reaches 30% the performance of E-M2 drops sharply until it is no longer competitive, as would be expected. Simulta-neously the performance of E-M12 rises sharply from being uncompetitive to competitive. Throughout this transition, E-Pareto remains constantly competitive. E-M12 remains competitive between the MI 1 values of 30% until 70%. This behavior is expected, because E-M12 considers both m 1 and m 2 to be of equal im-portance. Finally, as the performance of E-M12 drops sharply when MI 1 reaches 60%, E-M1 becomes com-petitive. E-Pareto remains consistently competitive independent of the changing metric values. Figure 2 represents a different perspective of the same experiment. We have mapped coalitions based on their percentage m 1 and m 2 values. Figure 2 maps every op-timal coalition proposed by E-Pareto throughout the duration of the experiment. There are three areas of high concentration. The results of the experiment can clearly be divided into three sections, when E-M2 is competitive with E-Pareto , when E-M12 is competi-tive with E-Pareto and when E-M1 is competitive with E-Pareto . These three areas of high coalition concen-tration reflect the three sections displayed in the re-sults. Figure 1 shows that E-M2 is initially competi-tive because MI 2 has a high value. Figure 2 shows that E-Pareto reacts to this, focusing on this area of com-petitive space for coalition selection. Hence, a high concentration of coalitions is evident in the top left corner of the graph. The two other areas of high con-centration in Figure 2 can be explained in the same way. 4.2.2. Coalition Selection With Exploration The same experiment run in Section 4.2.1 is run again with the difference that the E-Pareto algorithm uses the exploration-enabled strategy described in Section 3.3. From Figure 2 it can be seen that the E-Pareto algorithm focuses only on the currently competitive ar-eas. Our hypothesis is that if the algorithm more fully explored the space available then it would identify ar-eas with a high success rate. The results are presented in Figure 3. There are two main differences between these results and those obtained in Section 4.2.1. The first is that the E-Pareto algorithm identifies two areas of space where it dominates its competition. As in the previous sub-section, E-M2 is initially compet-itive with E-Pareto , however as MI 2 decreases the coalitions proposed by E-M2 become weaker. The E-Pareto with a greedy strategy of coalition selection was unable to take advantage of this because it fo-cused purely on the competitive area of space, where it was competing with E-M2 . The exploration-enabled selection strategy allows the E-Pareto to identify areas of the solution space where it may be more competi-tive. This leads it to dominate all other evolutionary algorithms for certain values of metric importance in this experiment.
 The second difference between this result and that ob-tained in Section 4.2.1 is that there is a competitive cost incurred for exploration. While E-Pareto still re-mains competitive with the other three algorithms, its level of performance has degraded slightly when com-pared with the performance it exhibited in Figure 1. Figure 4 represents all optimal coalitions proposed by E-Pareto throughout the duration of the experiment. When contrasted with Figure 2, the exploration strat-egy demonstrates a thorough coverage of the solution space. Hence through exploration of the Pareto set, it is able to quickly identify and take advantage of shifts in metric importance. This paper addresses the topic of coalition formation. He et al. (2003) observes that it is a necessary tech-nique for agents in e-commerce. However Shehory (2003a) comments that further improvements are re-quired before coalition formation can become applica-ble for practical use.
 Previous work in coalition formation has assumed that agents share an identical valuation for any given coali-tion (Shehory &amp; Kraus, 1999), (Sandholm, 1999). Re-cently, coalition formation has been applied to the area of e-commerce. The assumption that agents share a common value for a given coalition is unrealistic in such an environment. Hence, each agent must calcu-late their own private value. Shehory (2003b) presents two alternative heuristics for evaluating a coalition, both of which are based on a single metric. In contrast with that, our work takes account of multiple conflict-ing metrics, differing metric importance and varying metric importance over time. Saha et al. (2003) as-sess the cost of asking another agent for help based on two metrics, time and quality. However, they treat all metrics as equally important, which is similar the E-M12 strategy used in Section 4.
 Evolutionary algorithms have not often been applied in this problem domain. Sen and Dutta (2000) use a genetic algorithm to calculate the optimal coalition structure, but that is quite a different problem to the one we address, as it deals with the division of all agents in the system into one or more disjoint coali-tions. Again it is assumed that agents share a common value for any coalition. Caillou et al. (2002) present a method of coalition formation which finds a Pareto optimal solution among all agents, but again that ad-dresses a different problem. In their work, each agent X  X  utility is measured with a single metric, and Pareto op-timality is used to jointly maximize all agents X  utility values, rather than to calculate an optimal coalition relative to multiple conflicting ability metrics. Our work does not present a mechanism to enable agents to negotiate to form coalitions, as theirs does; rather, we present a mechanism which will enable an agent to determine the optimal coalition in which to participate relative to the private information it has available to it. This paper has considered the problem of coalition cal-culation , that is, calculating from a single agent X  X  per-spective the optimal coalition to propose for a task based on the information available to it. We have iden-tified the problems associated with coalition calcula-tion: conflicting metrics, differing metric importance and the variation of metric importance over time. To address these problems, an adapted multi-objective optimization evolutionary algorithm has been pro-posed, which enables an agent to identify the optimal coalition relative to the information it has about the world. We have shown through empirical evaluation that this approach is an improvement over previous techniques, and that when given conflicting metrics, it is capable of identifying the importance of these met-rics, remaining competitive as the relative importance of metrics varies.
 In the future, we aim to apply this mechanism of coali-tion calculation to a simulated market environment, where all agents maintain their own private informa-tion about other agents. We also hope to investigate the sensitivity of our approach to inaccuracy in the information held about other agents in such an envi-ronment.
 The support of the Informatics Research Initiative of Enterprise Ireland is gratefully acknowledged. The au-thors are grateful to the anonymous reviewers for their detailed and helpful comments.
 Caillou, P., Aknine, S., &amp; Pinson, S. (2002). A multi-agent method for forming and dynamic re-structuring of pareto optimal coalitions. Proceed-ings of the First International Joint Conference on
Autonomous Agents and Multi-Agent Systems (pp. 1074 X 1081). Bologna, Italy: ACM Press.
 Dutta, P., &amp; Sen, S. (2002). Emergence of stable coali-tions via task exchanges. Proceedings of the First In-ternational Joint Conference of Autonomous Agents and Multi-Agent Systems (pp. 312 X 313). Bologna, Italy: ACM Press.
 He, M., Jennings, N., &amp; Leung, H. (2003). On agent-mediated electronic commerce. Knowledge and Data Engineering, IEEE Transactions on , 15 , 985 X 1003. Saha, S., Sen, S., &amp; Dutta, P. (2003). Helping based on future expectatioins. Proceedings of the Sec-ond International Joint Conference on Autonomous
Agents and Multiagent Systems (pp. 289 X 296). Mel-bourne, Australia: ACM Press.
 Sandholm, T. W. (1999). Distributed rational deci-sion making. In G. Weiss (Ed.), Multiagent systems:
A modern approach to distributed artificial intelli-gence , 201 X 258. Cambridge, MA, USA: The MIT Press.
 Sen, S., &amp; Dutta, P. (2000). Searching for the optimal coalition structure. Proceedings of the Fourth In-ternational Conference on Multiagent Systems (pp. 286 X 292). Boston, Massachusetts: IEEE.
 Shehory, O. (2003a). Coalition formation: Towards feasible solutions. Proceedings of the 3rd Interna-tional Central and Eastern European Conference on Multi-Agent Systems (pp. 218 X 251). Prague, Czech Republic: Springer-Verlag.
 Shehory, O. (2003b). Coalition formation with un-certain heterogeneous information. Proceedings of the Second International Joint Conference on Au-tonomous Agents and Multiagent Systems (pp. 1 X 8). Melbourne, Australia: ACM Press.
 Shehory, O., &amp; Kraus, S. (1999). Feasible formation of coalitions among autonomous agents in nonsuper-additve environments. Computational Intelligence , 15 , 218 X 251.
 Srinivas, N., &amp; Deb, K. (1994). Multiobjective opti-mization using nondominated sorting in genetic al-gorithms. Evolutionary Computation , 2 , 221 X 248. Tsvetovat, M., Sycara, K., Chen, Y., &amp; Ying, J. (2000). Customer coalitions in the electronic mar-ketplace. Proceedings of the Fourth International Conference on Autonomous Agents (pp. 263 X 264). Barcelona, Catalonia, Spain: ACM Press.
 Zitzler, E., Laumanns, M., &amp; Bleuler, S. (2004). A tu-torial on evolutionary multiobjective optimization. Proceedings of the Workshop on Multiple Objective Metaheuristics . Paris, France: Springer-Verlag. Zitzler, E., Laumanns, M., &amp; Thiele, L. (2001). Spea2:
Improving the strength pareto evolutionary algo-rithm (Technical Report 103). Swiss Federal In-stitute of Technology, Gloriastrasse 35, CH-8092 Zurich, Switzerland.
 Zitzler, E., &amp; Thiele, L. (1998). An evolutionary algo-rithm for multiobjective optimization: The strength pareto approach (Technical Report 43). Swiss Fed-eral Institute of Technology, Gloriastrasse 35, CH-
