 Languages with rich morphological systems present significant hurdles for statistical ma-chine translation (SMT), most notably data sparsity, source-target asymmetry, and prob-lems with automatic evaluation.

In this work, we propose to address the prob-lem of morphological complexity in an English-to-Finnish MT task within a phrase-based trans-lation framework. We focus on unsupervised segmentation methods to derive the morpholog-ical information supplied to the MT model in order to provide coverage on very large data-sets and for languages with few hand-annotated resources. In fact, in our experiments, unsuper-vised morphology always outperforms the use of a hand-built morphological analyzer. Rather than focusing on a few linguistically motivated aspects of Finnish morphological behaviour, we develop techniques for handling morphological complexity in general. We chose Finnish as our target language for this work, because it ex-emplifies many of the problems morphologically complex languages present for SMT. Among all the languages in the Europarl data-set, Finnish is the most difficult language to translate from and into, as was demonstrated in the MT Sum-mit shared task (Koehn, 2005). Another reason is the current lack of knowledge about how to ap-ply SMT successfully to agglutinative languages like Turkish or Finnish.

Our main contributions are: 1) the intro-duction of the notion of segmented translation where we explicitly allow phrase pairs that can end with a dangling morpheme, which can con-nect with other morphemes as part of the trans-lation process, and 2) the use of a fully seg-mented translation model in combination with a post-processing morpheme prediction system, using unsupervised morphology induction. Both of these approaches beat the state of the art on the English-Finnish translation task. Mor-phology can express both content and function categories, and our experiments show that it is important to use morphology both within the translation model (for morphology with content) and outside it (for morphology contributing to fluency).
 Automatic evaluation measures for MT, BLEU (Papineni et al., 2002), WER (Word Error Rate) and PER (Position Independent Word Error Rate) use the word as the basic unit rather than morphemes. In a word com-prised of multiple morphemes, getting even a single morpheme wrong means the entire word is wrong. In addition to standard MT evaluation measures, we perform a detailed linguistic anal-ysis of the output. Our proposed approaches are significantly better than the state of the art, achieving the highest reported BLEU scores on the English-Finnish Europarl version 3 data-set. Our linguistic analysis shows that our models have fewer morpho-syntactic errors compared to the word-based baseline. 2.1 Baseline Models We set up three baseline models for compari-son in this work. The first is a basic word-based model (called Baseline in the results); we trained this on the original unsegmented version of the text. Our second baseline is a factored translation model (Koehn and Hoang, 2007) (called Factored), which used as factors the word,  X  X tem X  1 and suffix. These are de-rived from the same unsupervised segmenta-tion model used in other experiments. The re-sults (Table 3) show that a factored model was unable to match the scores of a simple word-based baseline. We hypothesize that this may be an inherently difficult representational form for a language with the degree of morphologi-cal complexity found in Finnish. Because the morphology generation must be precomputed, for languages with a high degree of morpho-logical complexity, the combinatorial explosion makes it unmanageable to capture the full range of morphological productivity. In addition, be-cause the morphological variants are generated on a per-word basis within a given phrase, it excludes productive morphological combination across phrase boundaries and makes it impossi-ble for the model to take into account any long-distance dependencies between morphemes. We conclude from this result that it may be more useful for an agglutinative language to use mor-phology beyond the confines of the phrasal unit, and condition its generation on more than just the local target stem. In order to compare the performance of unsupervised segmentation for translation, our third baseline is a segmented translation model based on a supervised segmen-tation model (called Sup), using the hand-built Omorfi morphological analyzer (Pirinen and Lis-tenmaa, 2007), which provided slightly higher BLEU scores than the word-based baseline. 2.2 Segmented Translation For segmented translation models, it cannot be taken for granted that greater linguistic accu-racy in segmentation yields improved transla-tion (Chang et al., 2008). Rather, the goal in segmentation for translation is instead to maxi-mize the amount of lexical content-carrying mor-phology, while generalizing over the information not helpful for improving the translation model. We therefore trained several different segmenta-tion models, considering factors of granularity, coverage, and source-target symmetry.

We performed unsupervised segmentation of the target data, using Morfessor (Creutz and Lagus, 2005) and Paramor (Monson, 2008), two top systems from the Morpho Challenge 2008 (their combined output was the Morpho Chal-lenge winner). However, translation models based upon either Paramor alone or the com-bined systems output could not match the word-based baseline, so we concentrated on Morfes-sor. Morfessor uses minimum description length criteria to train a HMM-based segmentation model. When tested against a human-annotated gold standard of linguistic morpheme segmen-tations for Finnish, this algorithm outperforms competing unsupervised methods, achieving an F-score of 67.0% on a 3 million sentence cor-pus (Creutz and Lagus, 2006). Varying the per-plexity threshold in Morfessor does not segment more word types, but rather over-segments the same word types. In order to get robust, com-mon segmentations, we trained the segmenter on the 5000 most frequent words 2 ; we then used this to segment the entire data set. In order to improve coverage, we then further segmented any word type that contained a match from the most frequent suffix set, looking for the longest matching suffix character string. We call this method Unsup L-match.

After the segmentation, word-internal mor-pheme boundary markers were inserted into the segmented text to be used to reconstruct the surface forms in the MT output. We then trained the Moses phrase-based system (Koehn et al., 2007) on the segmented and marked text. After decoding, it was a sim-ple matter to join together all adjacent mor-phemes with word-internal boundary markers to reconstruct the surface forms. Figure 1(a) gives the full model overview for all the vari-ants of the segmented translation model (super-vised/unsupervised; with and without the Un-sup L-match procedure).

Table 1 shows how morphemes are being used in the MT system. Of the phrases that included segmentations ( X  X orph X  in Table 1), roughly a third were  X  X roductive X , i.e. had a hanging mor-pheme (with a form such as stem +) that could be joined to a suffix ( X  X anging Morph X  in Ta-ble 1). However, in phrases used while decoding the development and test data, roughly a quar-ter of the phrases that generated the translated output included segmentations, but of these, only a small fraction (6%) had a hanging mor-pheme; and while there are many possible rea-sons to account for this we were unable to find a single convincing cause. 2.3 Morphology Generation Morphology generation as a post-processing step allows major vocabulary reduction in the trans-lation model, and allows the use of morpholog-ically targeted features for modeling inflection. A possible disadvantage of this approach is that in this model there is no opportunity to con-sider the morphology in translation since it is removed prior to training the translation model. Morphology generation models can use a vari-ety of bilingual and contextual information to capture dependencies between morphemes, of-ten more long-distance than what is possible us-ing n -gram language models over morphemes in the segmented model.
 Similar to previous work (Minkov et al., 2007; Toutanova et al., 2008), we model morphology generation as a sequence learning problem. Un-like previous work, we use unsupervised mor-phology induction and use automatically gener-ated suffix classes as tags. The first phase of our morphology prediction model is to train a MT system that produces morphologically simplified word forms in the target language. The output word forms are complex stems (a stem and some suffixes) but still missing some important suffix morphemes. In the second phase, the output of the MT decoder is then tagged with a sequence of abstract suffix tags. In particular, the out-put of the MT decoder is a sequence of complex stems denoted by x and the output is a sequence of suffix class tags denoted by y . We use a list of parts from ( x , y ) and map to a d -dimensional feature vector  X ( x , y ), with each dimension be-ing a real number. We infer the best sequence of tags using: where F ( x ) returns the highest scoring output y  X  . A conditional random field (CRF) (Lafferty et al., 2001) defines the conditional probability as a linear score for each candidate y and a global normalization term: where Z = P y 0  X  GEN ( x ) exp( X ( x , y 0 )  X  w ). We use stochastic gradient descent (using crfsgd 3 ) to train the weight vector w . So far, this is all off-the-shelf sequence learning. However, the output y  X  from the CRF decoder is still only a sequence of abstract suffix tags. The third and final phase in our morphology prediction model is to take the abstract suffix tag sequence y  X  and then map it into fully inflected word forms, and rank those outputs using a morphemic language model. The abstract suffix tags are extracted from the unsupervised morpheme learning pro-cess, and are carefully designed to enable CRF training and decoding. We call this model CRF-LM for short. Figure 1(b) shows the full pipeline and Figure 2 shows a worked example of all the steps involved.

We use the morphologically segmented train-ing data (obtained using the segmented corpus described in Section 2.2 4 ) and remove selected suffixes to create a morphologically simplified version of the training data. The MT model is trained on the morphologically simplified train-ing data. The output from the MT system is then used as input to the CRF model. The CRF model was trained on a  X  210,000 Finnish sentences, consisting of  X  1.5 million tokens; the 2,000 sentence Europarl test set consisted of 41,434 stem tokens. The labels in the output sequence y were obtained by selecting the most productive 150 stems, and then collapsing cer-tain vowels into equivalence classes correspond-ing to Finnish vowel harmony patterns. Thus variants -k  X o and -ko become vowel-generic en-clitic particle -kO, and variants -ss  X a and -ssa become the vowel-generic inessive case marker -ssA, etc. This is the only language-specific com-ponent of our translation model. However, we expect this approach to work for other agglu-tinative languages as well. For fusional lan-guages like Spanish, another mapping from suf-fix to abstract tags might be needed. These suf-fix transformations to their equivalence classes prevent morphophonemic variants of the same morpheme from competing against each other in the prediction model. This resulted in 44 possi-ble label outputs per stem which was a reason-able sized tag-set for CRF training. The CRF was trained on monolingual features of the seg-mented text for suffix prediction, where t is the current token: Word Stem s t  X  n , .., s t , .., s t + n ( n = 4) With this simple feature set, we were able to use features over longer distances, resulting in a total of 1,110,075 model features. After CRF based recovery of the suffix tag sequence, we use a bigram language model trained on a full seg-mented version on the training data to recover the original vowels. We used bigrams only, be-cause the suffix vowel harmony alternation de-pends only upon the preceding phonemes in the word from which it was segmented. For all of the models built in this paper, we used the Europarl version 3 corpus (Koehn, 2005) English-Finnish training data set, as well as the standard development and test data sets. Our parallel training data consists of  X  1 million sen-tences of 40 words or less, while the develop-ment and test sets were each 2,000 sentences long. In all the experiments conducted in this paper, we used the Moses 5 phrase-based trans-lation system (Koehn et al., 2007), 2008 version. We trained all of the Moses systems herein using the standard features: language model, reorder-ing model, translation model, and word penalty; in addition to these, the factored experiments called for additional translation and generation features for the added factors as noted above. We used in all experiments the following set-tings: a hypothesis stack size 100, distortion limit 6, phrase translations limit 20, and maxi-mum phrase length 20. For the language models, we used SRILM 5-gram language models (Stol-cke, 2002) for all factors. For our word-based Baseline system, we trained a word-based model using the same Moses system with identical set-tings. For evaluation against segmented trans-lation systems in segmented forms before word reconstruction, we also segmented the baseline system X  X  word-based output. All the BLEU scores reported are for lowercase evaluation.
We did an initial evaluation of the segmented output translation for each system using the no-tion of m -BLEU score (Luong et al., 2010) where the BLEU score is computed by comparing the segmented output with a segmented reference translation. Table 2 shows the m -BLEU scores for various systems. We also show the m -BLEU score without unigrams, since over-segmentation could lead to artificially high m -BLEU scores. In fact, if we compare the relative improvement of our m -BLEU scores for the Unsup L-match system we see a relative improvement of 39.75% over the baseline. Luong et. al. (2010) report an m -BLEU score of 55.64% but obtain a rel-ative improvement of 0.6% over their baseline m -BLEU score. We find that when using a good segmentation model, segmentation of the morphologically complex target language im-proves model performance over an unsegmented baseline (the confidence scores come from boot-strap resampling). Table 3 shows the evalua-tion scores for all the baselines and the methods introduced in this paper using standard word-based lowercase BLEU, WER and PER. We do Model BLEU WER TER Baseline 14.68 74.96 72.42
Factored 14.22 76.68 74.15 (Luong et.al, 2010) 14.82 --Sup 14.90 74.56 71.84 Unsup L-match 15.09  X  74.46 71.78 CRF-LM 14.87 73.71 71.15 better than (Luong et al., 2010), the previous best score for this task. We also show a bet-ter relative improvement over our baseline when compared to (Luong et al., 2010): a relative im-provement of 4.86% for Unsup L-match com-pared to our baseline word-based model, com-pared to their 1.65% improvement over their baseline word-based model. Our best perform-ing method used unsupervised morphology with L -match (see Section 2.2) and the improvement is significant: bootstrap resampling provides a confidence margin of  X  0.77 and a t -test (Collins et al., 2005) showed significance with p = 0 . 001. 3.1 Morphological Fluency Analysis To see how well the models were doing at get-ting morphology right, we examined several pat-terns of morphological behavior. While we wish to explore minimally supervised morphological MT models, and use as little language spe-cific information as possible, we do want to use linguistic analysis on the output of our sys-tem to see how well the models capture essen-tial morphological information in the target lan-guage. So, we ran the word-based baseline sys-tem, the segmented model (Unsup L-match), and the prediction model (CRF-LM) outputs, along with the reference translation through the supervised morphological analyzer Omorfi (Piri-nen and Listenmaa, 2007). Using this analy-sis, we looked at a variety of linguistic construc-tions that might reveal patterns in morphologi-cal behavior. These were: (a) explicitly marked noun forms, (b) noun-adjective case agreement, (c) subject-verb person/number agreement, (d) transitive object case marking, (e) postposi-tions, and (f) possession. In each of these cat-egories, we looked for construction matches on a per-sentence level between the models X  output and the reference translation.

Table 4 shows the models X  performance on the constructions we examined. In all of the cat-egories, the CRF-LM model achieves the best precision score, as we explain below, while the Unsup L-match model most frequently gets the highest recall score.

A general pattern in the most prevalent of these constructions is that the baseline tends to prefer the least marked form for noun cases (corresponding to the nominative) more than the reference or the CRF-LM model. The base-line leaves nouns in the (unmarked) nominative far more than the reference, while the CRF-LM model comes much closer, so it seems to fare better at explicitly marking forms, rather than defaulting to the more frequent unmarked form.
Finnish adjectives must be marked with the same case as their head noun, while verbs must agree in person and number with their subject. We saw that in both these categories, the CRF-LM model outperforms for precision, while the segmented model gets the best recall.

In addition, Finnish generally marks di-rect objects of verbs with the accusative or the partitive case; we observed more accusative/partitive-marked nouns following verbs in the CRF-LM output than in the base-line, as illustrated by example (1) in Fig. 3. While neither translation picks the same verb as in the reference for the input  X  X larify, X  the CRF-LM-output paraphrases it by using a grammat-ical construction of the transitive verb followed by a noun phrase inflected with the accusative case, correctly capturing the transitive construc-tion. The baseline translation instead follows  X  X ive X  with a direct object in the nominative case.

To help clarify the constructions in question, we have used Google Translate 6 to provide back-Construction Freq. Baseline Unsup L-match CRF-LM translations of our MT output into English; to contextualize these back-translations, we have provided Google X  X  back-translation of the refer-ence.

The use of postpositions shows another dif-ference between the models. Finnish postposi-tions require the preceding noun to be in the genitive or sometimes partitive case, which oc-curs correctly more frequently in the CRF-LM than the baseline. In example (2) in Fig. 3, all three translations correspond to the English text,  X  X ith the basque nationalists. X  However, the CRF-LM output is more grammatical than the baseline, because not only do the adjective and noun agree for case, but the noun  X  X ask-ien X  to which the postposition  X  X anssa X  belongs is marked with the correct genitive case. However, this well-formedness is not rewarded by BLEU, because  X  X askien X  does not match the reference.
In addition, while Finnish may express pos-session using case marking alone, it has another construction for possession; this can disam-biguate an otherwise ambiguous clause. This al-ternate construction uses a pronoun in the geni-tive case followed by a possessive-marked noun; we see that the CRF-LM model correctly marks this construction more frequently than the base-line. As example (3) in Fig. 3 shows, while nei-ther model correctly translates  X  X atkan X  ( X  X rip X ), the baseline X  X  output attributes the inessive  X  X hteydess X  ( X  X onnection X ) as belonging to  X  X u-lokset X  ( X  X esults X ), and misses marking the pos-session linking it to  X  X ommissioner Fischler X . Our manual evaluation shows that the CRF-LM model is producing output translations that are more morphologically fluent than the word-based baseline and the segmented translation Unsup L-match system, even though the word choices lead to a lower BLEU score overall when compared to Unsup L-match. The work on morphology in MT can be grouped into three categories, factored models, seg-mented translation, and morphology generation.
Factored models (Koehn and Hoang, 2007) factor the phrase translation probabilities over additional information annotated to each word, allowing for text to be represented on multi-ple levels of analysis. We discussed the draw-backs of factored models for our task in Sec-tion 2.1. While (Koehn and Hoang, 2007; Yang and Kirchhoff, 2006; Avramidis and Koehn, 2008) obtain improvements using factored mod-els for translation into English, German, Span-ish, and Czech, these models may be less useful for capturing long-distance dependencies in lan-guages with much more complex morphological systems such as Finnish. In our experiments factored models did worse than the baseline.
Segmented translation performs morphologi-cal analysis on the morphologically complex text for use in the translation model (Brown et al., 1993; Goldwater and McClosky, 2005; de Gis-pert and Mari  X no, 2008). This method unpacks complex forms into simpler, more frequently oc-curring components, and may also increase the symmetry of the lexically realized content be-tween source and target. In a somewhat or-thogonal approach to ours, (Ma et al., 2007) use alignment of a parallel text to pack together ad-jacent segments in the alignment output, which are then fed back to the word aligner to boot-strap an improved alignment, which is then used in the translation model. We compared our re-sults against (Luong et al., 2010) in Table 3 since their results are directly comparable to ours. They use a segmented phrase table and language model along with the word-based ver-sions in the decoder and in tuning a Finnish tar-get. Their approach requires segmented phrases to match word boundaries, eliminating morpho-logically productive phrases. In their work a seg-mented language model can score a translation, but cannot insert morphology that does not show source-side reflexes. In order to perform a similar experiment that still allowed for mor-phologically productive phrases, we tried train-ing a segmented translation model, the output of which we stitched up in tuning so as to tune to a word-based reference. The goal of this ex-periment was to control the segmented model X  X  tendency to overfit by rewarding it for using correct whole-word forms. However, we found that this approach was less successful than us-ing the segmented reference in tuning, and could not meet the baseline (13.97% BLEU best tun-ing score, versus 14.93% BLEU for the base-line best tuning score). Previous work in seg-mented translation has often used linguistically motivated morphological analysis selectively ap-plied based on a language-specific heuristic. A typical approach is to select a highly inflecting class of words and segment them for particular morphology (de Gispert and Mari  X no, 2008; Ra-manathan et al., 2009). Popovi  X c and Ney (2004) perform segmentation to reduce morphological complexity of the source to translate into an iso-lating target, reducing the translation error rate for the English target. For Czech-to-English, Goldwater and McClosky (2005) lemmatized the source text and inserted a set of  X  X seudowords X  expected to have lexical reflexes in English.
Minkov et. al. (2007) and Toutanova et. al. (2008) use a Maximum Entropy Markov Model for morphology generation. The main draw-back to this approach is that it removes morpho-logical information from the translation model (which only uses stems); this can be a prob-lem for languages in which morphology ex-presses lexical content. de Gispert (2008) uses a language-specific targeted morphological clas-sifier for Spanish verbs to avoid this issue. Tal-bot and Osborne (2006) use clustering to group morphological variants of words for word align-ments and for smoothing phrase translation ta-bles. Habash (2007) provides various methods to incorporate morphological variants of words in the phrase table in order to help recognize out of vocabulary words in the source language. We found that using a segmented translation model based on unsupervised morphology in-duction and a model that combined morpheme segments in the translation model with a post-processing morphology prediction model gave us better BLEU scores than a word-based baseline. Using our proposed approach we obtain better scores than the state of the art on the English-Finnish translation task (Luong et al., 2010): from 14.82% BLEU to 15.09%, while using a simpler model. We show that using morpho-logical segmentation in the translation model can improve output translation scores. We also demonstrate that for Finnish (and possi-bly other agglutinative languages), phrase-based MT benefits from allowing the translation model access to morphological segmentation yielding productive morphological phrases. Taking ad-vantage of linguistic analysis of the output we show that using a post-processing morphology generation model can improve translation flu-ency on a sub-word level, in a manner that is not captured by the BLEU word-based evalua-tion measure.

In order to help with replication of the results in this paper, we have run the various morpho-logical analysis steps and created the necessary training, tuning and test data files needed in or-der to train, tune and test any phrase-based ma-chine translation system with our data. The files can be downloaded from natlang.cs.sfu.ca .

In future work we hope to explore the utility of phrases with productive morpheme boundaries and explore why they are not used more per-vasively in the decoder. Evaluation measures for morphologically complex languages and tun-ing to those measures are also important future work directions. Also, we would like to explore a non-pipelined approach to morphological pre-and post-processing so that a globally trained model could be used to remove the target side morphemes that would improve the translation model and then predict those morphemes in the target language.
 This research was partially supported by NSERC, Canada (RGPIN: 264905) and a Google Faculty Award. We would like to thank Christian Monson, Franz Och, Fred Popowich, Howard Johnson, Majid Razmara, Baskaran Sankaran and the anonymous reviewers for their valuable comments on this work. We would particularly like to thank the developers of the open-source Moses machine translation toolkit and the Omorfi morphological analyzer for Finnish which we used for our experiments.
