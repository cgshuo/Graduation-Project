 This paper characterizes general properties of useful, or Effective , explanations of recommendations . It describes a methodology based on focus groups, in which we elicit what helps moviegoers decide whether or not they would like a movie. Our results highlight the importance of pers onalizing explanations to the individual user, as well as considering the source of recommendations, user mood, the effects of group viewing, and the effect of explanations on user expectations. H.5.2 [ User Interfaces ]: User-centered design, Evaluation/Methodology Design, Experimenta tion, Human Factors Recommender systems, explanations The recommender systems community is reaching a consensus that accuracy metrics such as mean average error (MAE), precision and recall, can only partially evaluate a recommender system [9]. User satisfaction and derivatives thereof such as serendipity [8], diversity [12] a nd trust [3] are increasingly seen as important. Explanations of recommendations can play an important role in improving the user experience. However, the definition of a good explanation is still largely open and depends on the general aim of the recommender system. Previous recommender systems with explanation facilities have been evaluated in a number of ways, reviewed and discussed in-depth in [11]. Among other things, good explanations could help inspire user trust and loyalty, increase sa tisfaction, make it quicker and easier for users to find what they want, and persuade them to try or purchase a recommended item. Table 1 defines seven possible aims of explanation facilities in recommender systems. In this paper, we investigate the general properties of an explanation that helps a movie recommender system fulfill the criterion of Effectiveness, i.e. helps users to make good decisions. Aim Definition Transparency Explain how the system works Scrutability Allow users to tell the system it is wrong Trust Increase users X  confidence in the system Effectiveness Help users make good decisions Persuasiveness Convince users to try or buy Efficiency Help users make decisions faster Satisfaction Increase the ease of us ability or enjoyment The paper is organized as follows. In Section 2 we discuss the motivation for this work. In Section 3, we discuss the methodology and results from our focus groups. Therein we survey how moviegoers discuss their favourite and other movies in dialogue, and what they consider when making a choice. We conclude in Section 4 with plans for future work. Herlocker et al. [6] found that out of twenty-one explanation interfaces participants were most likely to see a movie if they saw a histogram of how similar user s had rated the item, with the  X  X ood X  ratings clustered together and the  X  X ad X  ratings clustered together. However, a limitation of this experiment in terms of Effectivness is a bias toward positive ratings in the MovieLens dataset. Using another dataset, Bilgic and Mooney [2] have shown that using this type of histogram causes items to be overestimated, and suggest this is due to the sk ew towards high ratings. That is, participants think they like an item more than they really would. This means that the histogram based explanation may be more Persuasive than it is Effective. A second limitation of the experiment of Herlocker et al. is that the explanations based on movi e properties such as favorite actor/actress were not personalized for the participants, but rather for the main author of the paper [6]. This may have resulted in the relatively poor, yet significant, acceptance for explanations using this type of information. It w ould seem plausible that a movie feature such as favorite actor/actress is more important to some users than others, and that it would depend on each user X  X  disposition toward the particular actor/actress. The high variance in acceptance for this type of explanations in the Herlocker et al experiment suggests that this is likely. We consider the role of mentioning item features to users in explanations. The rationale behi nd studying user X  X  utilization of features is that simply stating that two items are similar does not always help users see the commonality between items, while an explanation using feature-based information may better help a user understand how two items ar e related. For example, Hingston [7] who studied the perceived Effectiveness of explanations found that participan ts requested information about why items were judged to be si milar to one another in an explanation interface which compared the recommended item to similar items the user had liked in the past. Similarly, Bilgic and Mooney [2] failed to show a significant effect on Effectiveness for an explanation interface which used information about previously rated items, but wher e the explicit relations between these previously rated items and the current recommendation are not clear. Therefore, in our study we set out to find out what helps moviegoers decide whether or not they would like a movie. If personalization has any merit, we wanted know what and how to personalize. In addition, we hope d that natural dialogue would help us discover how to best present this information to moviegoers. We conducted two focus groups to gain an intuition if particular movie features such as e.g. actors, awards etc determine whether or not participants will see and lik e a movie. For this purpose, an initial list of features was obtained in an exploratory analysis of online reviews from Amazon.co. uk (see Table 2, the numbers indicate how many times each feature was mentioned across 48 reviews). In particular we aimed to find out how participants would like to be recommended, or dissuaded, from watching a movie. As we intend to create a system using explanations, we hoped that in the informal setting of a focus group we would find particular formulations and keyw ords moviegoers use and prefer in justifications of recommendations. Cast (28) Good in its genre Script (19) Visuals (18) Suites mood (18) Realistic (15) Director (12) Subject matter (12) Easy viewing (8) Good for kids (7) Repulsive/ violent (7) Dialogs (6) Pace (5) Soundtrack (5) Original (5) Movie Studio (2) Sex (1) A limitation of the focus groups is that what users like to say may differ from what they like to hear. We will not know for sure how helpful a participant X  X  justifica tion would be to a potential user, although we can watch the reactions of other participants. A total of eleven participants were spread over two focus groups, with the same facilitator. Audio recordings were made for later analysis. Participants were we lcomed, and explained the purpose of the focus group. The focus group began with each participant telling what their favorite movie was and why they liked it. Next, the facilitator asked participants to suggest movies, selecting one that the majority had seen. Participants we re informally asked about their initial expectations for this movie, and if something in particular made them consider watching it. Th ey were also asked about their impression after watching the movi e, and which features helped form this impression. This was augmented with a final question about how they would like to be recommended or dissuaded from watching the discussed movie. Ca re was taken to phrase this question so that the recommendation would be directed to them by someone who knew their tastes, e.g.  X  If a friend would recommend, or tell you not to s ee, this movie, how would they motivate it? X  The facilitator aimed primarily to let the participants themselves suggest movies. However, they could not always think of suggestions, in which case a movie from a prepared list (Appendix A 1 ) was used, based on the most rated movies in MovieLens balanced with a handful of the most popular movies in each genre on IMDB 2 . The list was printed out and shown openly to participants. After the introductions, each focus group discussed an average of five movies in detail. Participants also sometimes referred to a movie to illustrate a point, although this movie had not been seen by a ma jority of participants. Including these discussions, but not the introductions, the average number of movies mentioned in each focus group is ten. We concluded the focus groups with a summary of what had been said so far. The participants were asked for feedback on this summary. For completeness, they we re also asked if any type of movie or deciding feature had been neglected in the discussion. At the end, we orally went through the list of features mentioned in Table 2, and asked participants to note their importance. In total each session took between 1 and 1 1/2 hours. Eleven participants interested in movies were recruited from the staff and student population of Aber deen University (eight males and three females, aged 24-33). Participants varied in nationality (Irish, Israeli, French (3), Sco ttish (2), Spanish, South African, Swiss/Bolivian and Vietnamese). Using academic and multi-cultural participants may lead to a bias in taste, such as an increased preference for independent cinema. We did however find a great divergence in taste, both in terms of the types of movies participants liked and the weight different features had in determining if a movie was wort h viewing or not. For example, the genres discussed varied greatly and included: action, children, animated, comedy, crime/gangster, documentary, horror, fantasy, musical, romance, science fiction, thriller and western. Participants X  introductions of th eir favorite movies show which features they intuitively cons idered important to mention http://www.csd.abdn.ac.uk/~ntin tare/appendix/recSys07.rtf http://www.imdb.com: retrieved November 2006 (Citations of introductions are available in Appendix B 1 shows the features mentioned and how often they were mentioned across all participants. The features mentioned varied largely between subjects, the most co mmonly mentioned feature was  X  X ood in its genre X  (e.g. this movi e is funny, when talking about a comedy) followed by  X  X cript complexity X  and  X  X ood X . Good in its genre (6) Script complexity (4) Mood (4) Subject matter (2) Initial expectations (2) Cast (2) Director (1) Visuals (1) Realistic (1) Original (1) Note that  X  X ood X  may relate to se veral sub-features in turn such as affect (Appendix B, quote 4), genre preferences (quote 8), and atmosphere (quote 11). We confirmed that participants differ in the features they use when describing their favorite movies. For instance, consider these examples: P1:  X ..normally I don X  X  have a favorite actor or actress, but Jet Li is probably one of my favorite actors. Anything from him is good... X  Facilitator:  X  X hat made you watch it? X  P2:  X  X he director I think, Scorsese X  Participant P1 differentiated the movie according to one particular actor; while P2 mentioned the director as an important factor in choosing a movie and was in fact consist in this preference throughout the focus group. We note that in both cases, it was not only enough to mention director or actor in general ; each participant found it important to refer specifically to their favorite . In a similar manner, some par ticipants cared more about the overall movie aesthetics and musical score, while others did not notice or consider these feat ures particularly important. Participants believed that their mood is likely to influence the genre they choose to see, and as a secondary effect, what features they consider important; such as script complexity, affect (e.g. feel good movie). These factors were often situational ;  X  X  mean for a musical I don X  X  really need a great script, a great plot at least, uh or for uh what I call a pre-exam uh film the night before I mean. Bruce Willis saving the world is just what I need. Uh you know you don X  X  want something, y ou just want to use two neurons and that X  X  it, just relax. X  . In both groups, for most of the participants there was a clear distinction between movies viewed in larger, more casual groups of friends, and movies seen alone or in more intimate circumstances such as with a part ner. Movies seen with groups of friends were often light or easy viewing. Other movies, such as Schindler X  X  list are better viewed in more intimate company or even alone;  X  X  think I watched it on my own or something, I X  X  kind of thinking it X  X  not the kind of thing you watch [...] in a group X . The reason behind this seem s two-fold. In larger gatherings the aim is often light-hearted entertainment, the viewers aim to enjoy themselves rather than conduct a mental activity. More serious or drama tic movies on the other hand may invoke strong emotions and tension. Secondly, in large gatherings there is often a lot of simultaneous activity, someone is always speaking, going to get a tea or coffee etc. which obstructs the viewers from following a complex plot. Participants listened to thei r friends X  recommendations, in particular when they had time to spare. Whether or not participants listen to a recommendation depends on how it was given:  X  X t probably depends on the way they describe the movie rather than who they are. X  Participants in both groups also agreed that the same advice coming from different people wouldn X  X  have the same impact on them. It depended on whether or not this person had similar taste, i.e. agreed on movies in the past:  X  X ut it depends on the style of the movie; because if it X  X  like a romantic comedy and my sister tells me its brilliant then I X  X l go and see it. If it X  X  an action then I X  X l listen to what my brother thought of it. [...] if I know they have similar tastes in that kind of film to me then I X  X l listen to them. X  Explanations may help users enjoy movies more, rather than serve merely as decision aids. Participants believed that correcting faulty expectations for sequels or adaptations of a movie would not influence whether or not they saw it. Rather both groups unanimously felt that it could increase their acceptance upon viewing, and save potential di sappointment. One participant stated that he liked musicals, but had to know what to expect in advance:  X  X f I go to see a musical I have to know it X  X  a musical before watching it X  . In retrospect, none of the particip ants felt that they would have wanted to be dissuaded from watching movies they had disliked. Participants even watched popular movies which they expected to be disappointed by. They wanted to form their own opinion, and they did not want to reject social invitations, or refute the general consensus without strong warrant:  X  X  wouldn X  X  rush to watch certain genres, but if I was with somebody that was into that then yeah. I always think you try and take everything for what it is and try and look for the good parts X . We suggest that this is mainly due to the social nature of movi e viewing, and may be weaker for less social types of recommendations such as books. The initial features suggested by our exploratory analysis of online reviews were moderately m odified in scope by the results of these focus groups. Firstly, we considered  X  X ealistic X  to be a feature of a movie. Participants in both groups strongly differentiate between the terms realistic and believable. One participant explicitly stated:  X ...you used these two words and I think they are really important; realistic and believable. I don X  X  care about it being realistic; I care about it being believable X . Particularly in genres such as Action and Science Fiction, realism seemed to be watered down to  X  X  elievable X  which is important in the negative sense, e.g. flaws in coherence make a movie less attractive. During the course of the focus groups, we also realized that script complexity was strongly tied to mood. In addition, we realized that a simple script was pretty much synonymous to easy viewing. Some participants were happy to see movies as entertainment and did not place too much weight on the complexity of a story; others liked movies that pr esented a challenge, or were unpredictable:  X  X t depends a lot on how you come to the movies... [Participant X] would like a movie that challenges him, do a bit of thinking. Personally, I pretty mu ch think of a movie as a form of entertainment  X  two hours of fun! X  This definition of mood differs from mood defined as a pref erence for certain genres, i.e.  X  X  feel like seeing an action movie tonight X , as well as in terms of affect, i.e.  X  X  X  X  like to see a feel good movie X .
 Subject matter and how realistic a movie is were found to be very relevant for a documentary or histor ical movie, but not otherwise. From the focus groups, we draw the following conclusions for recommender system explanations:  X  Feature selection in explanations needs to be tailored to the  X  Feature selection in explanations needs to be tailored to the  X  Features can be selected from a relatively short list. Though  X  Explanation source matters . Explanations can be presented Currently, we are developing a prototype which generates explanations for movie recommenda tions. The user model used in this system weighs the movies f eatures elicited by our exploratory corpus analysis and focus groups according to specified user utility. Relevant meta-data is extracted from the Amazon e-Commerce Service (ECS) for this purpose. Textual recommendations are generated by a flexible natural language generation system. This flexibility allows us to modify parameters such as which features to men tion, and how to describe them. Further, the results of the focus group suggest that the optimal explanation is dependant on fact ors such as mood, and source, which allow us further contro l for different scenarios. [1] Van Barneveld, J. and Van Setten, M. Personalized digital [2] Bilgic, M. and Mooney, R.J. Explaining recommendations: [3] Chen, L. and Pu, P. Trust building in recommender agents. [4] Carenini, G. &amp; Moore, D.J. An Empirical Study of the [5] Czarkowski, M. A Scrutable Adaptive Hypertext . PhD thesis, [6] Herlocker, J. L., Konstan, J. A. and Riedl, J. Explaining [7] Hingston, M. User frie ndly recommender systems. Honours [8] McNee, S.M., Lam, S.K., Konstan, J.A. and Riedl, J. [9] McNee, S.M., J. Riedl, and J. A. Konstan. Being accurate is [10] Swearingen, K. and Sinha, R. Interaction design for [11] Tintarev, N. and Masthoff, J. Survey of explanations in [12] Ziegler, C., McNee, S.M., Konstan, J.A. and Lausen, G. 
