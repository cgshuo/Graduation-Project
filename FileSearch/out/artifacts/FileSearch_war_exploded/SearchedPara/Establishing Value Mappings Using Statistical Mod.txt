 In this paper, we present a  X  X alue mapping X  algorithm that does not rely on syntactic similarity or semantic interpreta-tion of the values. The algorithm first constructs a statisti-cal model (e.g., co-occurrence frequency or entropy vector) that captures the unique characteristics of values and their co-occurrence. It then finds the matching values by com-puting the distances between the models while refining the models using user feedback through iterations. Our experi-mental results suggest that our approach successfully estab-lishes value mappings even in the presence of opaque data values and thus can be a useful addition to the existing data integration techniques.
 H.2.5 [ Database Management ]: Heterogeneous Databases  X  Data translation Algorithms, Management Value Mapping, Semantic Correspondences, User Feedback, Statistical Model
Integrating data from multiple heterogeneous sources of-ten involves two related subtasks: (1) reconciling structural heterogeneity of data by mapping schema elements across the data sources  X  schema matching problem; and (2) re-solving semantic heterogeneity of data by mapping data in-stances across the tables  X  object mapping problem. De-pending on the granularity of the object, the object map-ping problem is also known as various names. For instance, if the object is a record, then it becomes the record linkage problem. Similarly, for tuple, it becomes the database join Copyright 2005 ACM 1-59593-140-6/05/0010 ... $ 5.00. problem. In this paper, in particular, we focus on the ob-ject mapping problem with the object being  X  X alues, X  thus named as the value mapping problem.

Virtually all previous value mapping works assume the data values in each corresponding columns are drawn from the same domain or at least they bear some textual similar-ity. However, this assumption is often challenged in prac-tice where sources use various different representations for describing their data. For example,  X  X wo-door front wheel drive X  can be represented as  X 2DR-FWD X  or  X  X 2FD X , or even as  X  X AR TYPE 3 X  in different data sources. Some smart string distance algorithms may be able to suggest cor-respondences among the first three representations, but they will fail to establish any mapping for  X  X AR TYPE 3 X  as it bears no syntactic or semantic clue except the fact that it is about car type.

This problem poses a substantial challenge to the existing object mapping techniques. To address this, we present a novel, semi-automated technique that can be of assistance in the particularly difficult cases in which the data values to be matched are  X  X paque, X  or difficult to understand, and have little syntactic or lexical similarity. To gain insight into our approach, consider the employee tables in Table 1. The task of matching values in the T itle and Degree columns is not quite straightforward. For this case, most traditional techniques that rely on the textual similarity of data, will likely fail to identify the value mapping.

We propose techniques that use the co-occurrence of val-ues and statistical methods like entropy that captures the distributions of co-occurring values to address the value map-ping problem. For example, suppose we are trying to find the value in Table Y that maps to  X  X rofessor X  in Table X as shown in Table 1. To make the exposition simpler, let us assume that we know the correspondences between the val-ues in the Degree columns ( e.g., P h.D.  X  D 7, M.S.  X  D 3, B.S.  X  D 2). Intuitively, we will see a higher correlation be-tween  X  X h.D. X  and  X  X rofessor X  than between  X  X h.D. X  and  X  X .A. X , as is the case in Table X . If we can measure the correlation between  X  X 7 X  (which we know is  X  X h.D. X ) and the two values,  X  X MP10 X  and  X  X MP3 X , in Table Y , and can compare the measurements across the tables, we may be able to find further correspondences. Now, let us assume that the mappings between the two Degree columns were not known a priori (i.e., the mappings for both T itle and Degree are unknown.). How can we proceed?
To address this problem, we propose an algorithm that works as follows: (1) We first construct for each table a statistical model (e.g., co-occurrence frequency or entropy vector) that captures the unique characteristics of values and their co-occurrence within the table; and then (2) finds the matching values by computing the distances between the models (not the values themselves) while refining the models using user feedback through iterations. In this paper we make the following contributions: Problem Definition. We have two tables: the source table, S , with columns, s 1 , . . . , s n , and its corresponding target table, T , with columns, t 1 , . . . , t n . Furthermore, via column-level schema matching, the matching columns be-tween S and T have already been identified. Using the schema match the two tables are pre-processed such that the schema match is converted from an m:n match to a bijec-tive match. For example, if the schema match indicates that S.N ame is equivalent to the concatenation of T.F irstname and T.Lastname , we preprocess the two tables. During the pre-processing, the columns T.F irstname and T.Lastname are composed to create a column with the concatenation of the first name and the last name. In the processed tables, there is a bijective mapping, say f , from columns in S to columns in T (after pre-processing). Formally, we consider the following as the Value Mapping Problem : In general, g can be many-to-many and our algorithm is capable of finding many-to-many value mappings.
 Table 2: A co-occurrence matrix for Table 1(a).
 Solution Overview. Our value mapping algorithm finds a mapping among values using their signature vectors (e.g., co-occurrence frequency or entropy vectors; refer to Sec-tion 3 for more details) without interpreting individual val-ues. An overview of our solution is illustrated in Algo-rithm 1, where g i is a value mapping between two values, g : v i  X  v j , and  X ( v i ) depicts the incorporation of user feedback on the value v i . The algorithm works mainly in two phases: (1) in the first step, Build() takes two ta-ble instances as input and produces corresponding depen-dency models (i.e., the signature vectors) for each unique value, and (2) in the second step, Match() , using the de-pendency models, compares the distances among all pairs of unmapped values, and proposes a ranked list of candi-date mappings to users. Incorporating the user X  X  feedback, the dependency models are improved in the Refine() step. The matching and refining process repeats until complete mappings are found (or the user stops it). Now, we describe the Build() phase of Algorithm 1. Co-occurrence Frequency Vector Model. Let n be the number of rows in which terms a and b co-occur, and r be the total number of rows in the table. Then, the co-occurrence frequency of ( a, b ) is defined as n/r . For example, in Figure 1(a), the co-occurrence frequency of ( M, M arried ) is 2 / 4 = 0 . 5, while that of ( T.A., P h.D. ) is 0 / 4 = 0. The co-occurrence matrix , C i , captures pair-wise co-occurrence frequency between all pairs of values in the corresponding table. Table 2 shows a co-occurrence matrix, C , correspond-ing to Table 1(a). In the table, A1 X  X 9 refer to values { M, F, Professor, TA, Ph.D, M.S, B.S, Married, Single } .
One way to improve the accuracy of co-occurrence model is to weight terms according to their information content . That is, rare terms carry more weights when they co-occur than terms that occur frequently (e.g.,  X  X ale X  or  X  X emale X ). In this work, we use a standard inverse document frequency weighting [6]. Each entry, C ( i, j ), in the co-occurrence ma-trix C can be weighted by multiplying the following weight: W ( i, j ) = (1  X  k N )  X  (1  X  l N ) where k is the number of times the term i occurs in the table, l is the number of times the term j occurs in the table, and N is the total number of rows in the table. We incorporated the weighting scheme in all the models for our experimentation, but have not weighted the examples in this paper to retain their simplicity. Entropy Vector Model. For a given random variable, Shannon X  X  entropy [27] is defined as follows. Let X be a discrete random variable on a finite set X = { x 1 , . . . , x with probability distribution function p ( x ) = Pr( X = x ). Then, the entropy H ( X ) of X is defined as: The conditional entropy of a column Y conditioned on a column X is: H ( Y | X ) =  X  In our work, we are interested in matching individual values and not entire columns. We can obtain the entropy of a column conditioned on an individual value as: H ( Y | X = x ) =  X  and y co-occur, the entropies of a column conditioned on two values can be similarly computed as: H ( Z | X = x, Y = y ) =  X 
Similar to a co-occurrence frequency matrix, we can con-struct a co-occurrence entropy matrix where the entries, in-stead of being co-occurrence frequencies, are entropy vec-tors. If the table has N columns, the entropy vector has N  X  2 elements, each element in the vector corresponding to a column in table. The entropy vector has 2 less elements, because the two columns whose values have been fixed have an entropy of 0 and we take them out. Note that the diago-nals of the matrix have a vector of size N  X  1 elements since in this case only one value has been fixed.
Signature vector are constructed during the Build() and the Refine() phases of Algorithm 1. Note that our value mapping approach is iterative and interactive. In each itera-tion, using a combination of statistical dependencies defined in Section 3.1 (i.e., co-occurrence frequency and entropy), the algorithm captures the unique statistical properties of values in a Signature Vector . Then algorithm uses a sim-ilarity measure between the two vectors to find mappings between the values they represent. We now present a few methods of constructing signature vectors in the following. We denote a signature vector of a value v by 1. Frequency-based Signature Vector : In this method, the 2. Entropy-based Signature Vector : Before any value map-3. Hybrid Signature Vector : In this scheme, the algo-4. Primary Entropy Signature Vector : The entropy-based
This is the Match() phase of Algorithm 1. Suppose two columns, s and t , are known to be mapped, where s has a domain of values { v 1 , ..., v n } and t has a range of values { w 1 , ..., w m } . In this step, our goal is to find all mappings from v i to w j : that is, g : v i  X  w j . Suppose, in the i eration, all signature vectors are properly created using one of the methods in Section 3.2, and thus there are n + m number of signature vectors created: { and { wise distances between two vectors, dist ( (1  X  i  X  n , 1  X  j  X  m ) to find the most similar two vec-tors. In particular, we use the following two simple distance metrics. Given two signature vectors  X  X  X  x and  X  X  X  y , where [ a , ..., a n ] and  X  X  X  y = [ b 1 , ..., b n ], respectively: (1) Euclidean Distance is: dist (  X  X  X  x ,  X  X  X  y ) = and (2) Using the Pearson correlation, Correlation Distance
Our algorithms construct the initial signature vectors, and augment them by processing matches in order. That is, it takes the value match between x and y , and augments both signature vectors and then proceeds to augment the vectors for the next match. This simple procedure ensures the vec-tors to be aligned at all times and the similarity computation is meaningful.
 Top-k Ranking. After computing all pair-wise distances, the algorithm sorts the candidate mappings based on their distances and proposes the top-k ranked candidate map-pings to the user. The algorithm returns the two values mapped, their similarity score (Euclidean or correlation dis-tance), and their p-value . The p-value is a common metric used in hypothesis testing [23], and can be computed by transforming the correlation of the two vectors (of size N ) to create a t -statistic having N  X  2 degrees of freedom. In our context, the p-value states the probability of observ-ing a candidate-mapping X  X  correlation by chance at the level greater than or equal to the observed correlation. The ex-pert uses a combination of the similarity score and the p-value to get an indication of how good the match is. The size of the top-k window can be set by the user. We have experimented with values of 10 and 20 for k . The user then reviews candidates, and either confirms or denounces some of the proposed mappings.
 User Feedback. Instead of finding value mappings in one iteration, our iterative and interactive approaches grad-ually improve mappings by exploiting positive or negative feedbacks from the users. In particular, we consider four plausible scenarios: (1) when users give always correct feed-back to all cases, (2) when users give no feedback, (3) when users give false negatives (denouncing a correct mapping as to be incorrect), and (4) when users give false positives (con-firming an incorrect mapping as to be correct). (1) Correct Feedback. When users confirm a candidate mapping, m p , positively, the mapping will be added to a set of  X  X nown X  mappings, and thus in the next iteration, the signature vector of unmapped value v will have an en-try corresponding to m p in the vector (thus carrying more statistical information). When users reject a candidate map-ping, m n , the mapping is no longer considered as candidate mappings in the subsequent iterations. The user can also go back and reject any mapping confirmed in any previous iteration. (2) No Feedback. In practice, users can be uncertain for some candidate mappings and may leave out those mappings without giving them feedback. The algorithms will just run normally putting the mappings back into the candidate pool and move on to the next iteration. (3) False Negative. Suppose users may mistakenly confirm a bad mapping or denounce a good mapping. We address these problems in two ways. First, we modified the denounce logic of our algorithms not to throw away a mapping that is denounced but to penalize the mapping by applying a negative weight with an exponential decay as follows: where d is the distance measure between the two signatures, c is the decay ( c &lt; 1), i is the current iteration, and t is the last iteration where the mapping was denounced ( t is zero if the current mapping has never been denounced). After a mapping is denounced, the mapping X  X  similarity measure in the next iteration will be discounted by the factor defined with c . In the subsequent iterations, the decay will expo-nentially decrease as the iterations elapse. If the denounced mapping was a true mapping, its correlation value will likely improve over the iterations as more user feedbacks are in-corporated, and will eventually have a second chance as the penalty diminishes. Once a denounced mapping returns to the top-k , in practice, the algorithms can notify users of a potential mistake and ask if users want to review the map-ping again. (4) False Positive. In order to handle false positive cases where users confirm a bad mapping, we introduced a  X  X ick-out X  threshold; we used  X  X -value  X  0.05 X  as the threshold in our experiment. The algorithms now not only update the signatures of unmapped values in each iteration, but also up-date the signatures of the values in the confirmed mappings and continuously monitor the changes in statistics of them as well. If the statistics of a previously confirmed mapping fell below the threshold after some iterations, the user can be given a warning about the mapping or the mapping can be kicked out and included back in the candidate pool. Stopping Criteria. Our iterative matching process con-tinues until all true mappings are found or users want to stop the process. In practice, however, the number of true mappings can be much smaller than the sizes of the two tables being matched, and thus large numbers of candidate mappings can still be generated even after all true mappings were found. To avoid unnecessary iterations, we need stop-ping criteria.

Ideally the iterations should stop right after the last true mapping is found. However, in general, it is not always easy to tell if there will be more mappings in the next iterations or not. Users have to make a subjective decision. Users may decide to stop if the current candidate list does not have any good mappings, and the statistics of all the candidates in the list indicate that they are statistically insignificant. The next iteration X  X  top-k candidates will likely be worse than the current ones, so stopping there perhaps would make sense for users. On the other hand, even if users failed to find a good mapping in an iteration, they might still want to proceed if the statistics of the current top-k candidates were strong. In practice, users may also force iterations stop by explicitly specifying a cut-off point,  X  (e.g., 0.05, 0.01). When  X  is set, the algorithms test in each iteration if the minimum p-value of the current candidates is greater than or equal to  X  , and if so, they stop. Set-up: Our algorithms were implemented using Matlab 7.0. Experiments were conducted on a machine running Windows XP Professional with 3Ghz Pentium 4 and 2 GB of memory. We used census data sets obtained from U.S. Census Bureau 1 . For experiments, we selected 8 different groups of records (17 attributes) including 1) all records for  X  X Y X  state, 2) all records for  X  X A X , 3) all records for teen ager group, 4) 20s, 5) 30s, 6) 40s, 7) 50s, and finally 8) all army veterans. The number of rows in each data set ranges from 7K to 10K. We sampled 5K tuples from each table for experiments. Table 3 shows the basic statistics of NY and CA tables. For example, there are 23 and 22 unique values in the PRMJIND1 columns of CA and NY tables respectively, and among them 22 values are common. The entropy of the PRMJIND1 column of the CA table (=3.0251) is slightly higher than that of the NY table (=3.0193).
 Evaluation Metrics: We assume users only examine the top-k candidates in each iteration, and confirm or denounce all correct and incorrect mappings among the top-k candi-dates. We iterate through each step until the complete map-ping is found. The precision of the system can be calculated http://dataferrett.census.gov/TheDataWeb/index.html Figure 1: Three models (CFM, EVM, PEM) with Euc and Corr are compared. (top-10 window).

Another important metric for measuring the success of the algorithm is response time . The computational complexity of each iteration of the algorithm is bounded by O ( mn 2 where m and n are the numbers of entries to be mapped in each table ( n &lt; m ). In each iteration, we compare two sig-nature vectors of size &lt; O(n) (=maximum possible size of a signature vector) mn times. We considered these two met-rics, precision and response time , to evaluate our approach. Experiments: We present the results in the following or-der: 1) comparing the base-line models, distance metrics, top-k window sizes, 2) hybrid models, 3) response time, 4) error correction, 5) sensitivity to different data distributions, and finally 6) effects of pre-established mappings.
We also evaluated the effects of term weighting (discussed in Section 3). However, since the weighted models outper-formed non-weighted models on average by 15%, in this pa-per, we presented only the results of the weighted models. Figure 1 presents the result of mapping over NY and CA with the three dependency models: Co-occurrence Fre-quency ( CF M ), Entropy Vector ( EV M ), and Primary En-tropy Model ( P EM ). Each of the three models was tested twice, using the Euclidean distance ( Euc ) and the correla-tion ( Corr ) as a similarity metric. Figure 1 shows the result using top-10 windows. The result using top-20 windows was similar, so we omitted the graph.

The straight line ( Optimal ) on the left in Figure 1 is an imaginary line that depicts a best case mapping scenario where an algorithm X  X  top-10 candidates were correct all the time. In both experiments using top-10 and top-20 win-dows, EV M outperformed the other models slightly, and the Corr metric outperformed Euc . CF M performed much better with Corr than with Euc while the other two models, P EM and EV M , performed equally well with both Euc and Corr . Both CF M s (with Euc and Corr ) started slow until the number of found mappings reached to some level ( Corr , 10-20 mappings and Euc , about 30-40 mappings). Then, the two models picked up rapidly in the rate that matches or exceeds those of the other models. Unlike CF M s, both EV M and P EM performed well from the beginning. In Figure 2: Performance comparison of hybrid ap-proaches using correlation as a similarity metric. (top-10 Window). fact, EV M with Corr ( EV M -Corr hereafter) and P EM -Corr produced almost perfect candidate lists for initial iter-ations (first four iterations in Figure 1). Their performance, however, degraded gradually after the initial runs and in the latter stage their growth rate became worse than that of CF M -Corr . EV M -Corr was the best performer achieving 65% precision.
We tested two hybrid models, switching and mixed sig-natures, over the same data sets, and showed the result in Figure 2 (only the top-10 test shown). The P EM / CF M switching model with threshold = 40 (i.e., P EM / CF M 40) uses P EM until it finds 40 initial mappings and then switches to CF M . Also, five mixed signature models with different weights were tested. Recall that unlike the other models, the mixed signature model contains two different types of values: entropies and co-occurrence frequencies. Because the two different types of values carry different information, we can further tune the hybrid model by applying different weights to the two types of values. We tested five differ-ent weights ( w =2, 1, 0.5, 0.1, 0.01) applied to the entropy Figure 3: Evaluation of error-correction strategy for handling incorrect or incomplete user feedbacks. values; that is, if w =1, we weigh the two types of informa-tion equally and if w =0.1, we discount the entropy values by 1 / 10 th .

Among the different weights tried, w = 0 . 1 outperformed the others in both top-10 and top-20 tests. In the top-10 tests, it achieved 82% precision producing more than 8 cor-rect mappings out of 10 candidate mappings on average. In the top-20 tests, it achieved about 74% precision. The PEM/CFM switching model also performed well; it achieved 79% and 74% precision in top-10 and 20 tests, respectively. In summary, the hybrid models were quite successful; Mixed ( w =0.1) outperformed the previous top performer, EVM, by 26% and 21% in top-10 and 20 tests, respectively.
We compared the response times of the two top perform-ing algorithms, M ixed and P EM/CF M , for both top-10 and top-20 windows. In top-10 window tests, M ixed com-pleted in 28 iterations  X  one iteration less than P EM / CF M , while in the top-20 tests, both algorithms finished in 16 iter-ations. All four algorithms ran on average 2.2  X  2.7 seconds per iteration. Figure 4: Sensitivity of algorithm against different data distributions.
We tested how our proposed solutions can handle false positives/negatives (i.e., incorrect feedback from users). Fig-ure 3 shows the result of the experiment where we tested the error correction strategies in three scenarios: 10% leave-outs, false negatives, and the combination of false positives and negatives. We used Mixed ( w = 0 . 1) for this experi-ment and compared the results of the scenarios to that of the perfect user scenario reported earlier. In each iteration, we randomly chose 10% of the candidate mappings from the top-k window and applied the errors. For the 10% leave-out test, we simply send the chosen subset back to the algo-rithm with no feedback. For the 10% false negative test, we assured on average about 10% of the true mappings in each iteration were falsely identified as negative. Lastly, we tried the combination errors where we denounced true map-pings (false negatives) and confirmed false mappings (false positives) for the 10% of the candidates.

As shown in Figure 3, 10% leave-out test finished in 17 iterations finding all true mappings while 10% false negative test finished in 20 iterations also finding all true mappings. On the other hand, 10% combination error test failed to find all true mappings and stopped short at the 18th iteration. We forced the algorithm to stop if all mappings that were confirmed in the previous iteration were immediately kicked out in the next iteration. After its 18th iteration, it pro-duced the mapping result with 216 true mappings (out of 222) and seven false mappings. The seven false mappings survived without being kicked out because their p-values were below the threshold. Small numbers of true mappings were also kicked out as their statistics were too weak; those mappings include the ones with very low frequency values (e.g., values only occur once or twice in the entire table).
We tested the sensitivity of our algorithm against the data sets with different data distribution. Figure 4 shows the result obtained using Mixed ( w = 0 . 1) over six different pairs of data sets: 1) 10s (this data set contains only teens) vs. army veterans (contains people who have ever served in the army), 2) 20s vs. army veterans, 3) 20s vs. 30s, 4) 20s vs.
Figure 5: Effects of pre-established mappings. 40s, 5) 20s vs. 50s, and lastly 6) 30s vs. 40s. The tests over 20s vs. 30s and 30s vs. 40s, representing groups with similar distributions, achieved 75% and 84% accuracy, while the tests over 10s vs. veterans and 20s vs. veterans, representing groups with less similar distributions, achieved only 30% and 59% accuracy, respectively. The 10s vs. veterans test turned out far worse than the rest of the tests. In fact, 10s table represents a completely different distribution from the rest of the tables; teens are very unlikely to own a house, have a job, or be married. Confirming this, the 20s vs. veterans test resulted in a much better result (finished in 38 iterations while 10s-veterans, in 74 iterations). This result suggests that we can expect a good performance from our algorithm when applied to datasets with reasonably similar domains.
All the above tests were done assuming no pre-established mappings exist between the values (all to all match). In practice, however, there can be some mappings that are ob-vious because of their textual similarity. We examined the effect of such pre-established mappings to our algorithms. Figure 5 shows the result.
 We compared the performance of Mixed ( w = 0 . 1) over NY and CA while increasing the number of pre-established mappings. The line at the bottom shows the mapping result of two columns (PRDTOCC1 and PRMJOCC1) across the tables without considering any other columns. It achieved only 32% accuracy.

We then added an extra column (PRDTIND1) with pre-established mapping, to the algorithm. The accuracy of the mapping improved significantly to 89%. As more known columns were added, the accuracy of the result gradually improved up to 95% (when all 17 columns used). The result suggested that even a small number of pre-established map-pings can improve the performance of the algorithm signifi-cantly. Also suggested is that the algorithm can work even with a small number of common columns across the tables, and hence can be applicable to other related problems such as approximate joins [5,13].
There are vast amount of related work to ours  X  notably (1) schema matching (e.g., [2,7,9,14,16 X 18,20,21]) and (2) object mapping (e.g., [1,3 X 5,10,12,13,15,19,28]) problems. (1) In this work, we assumed that we knew the correspon-dences between the columns across the tables. However, in general settings, such correspondences are not known but have to be found first. To generate such correspondences, various schema matching techniques have been proposed. Some employs Machine Learning (e.g., LSD [9]), rules (e.g., TranScm [21]), Neural Network (e.g., SemInt [17]), struc-tural similarity (e.g. Cupid [18]), or interactive user feed-back (e.g., Clio [14]). Recent development (e.g., iMAP [7]) even enables to find not only 1-1, but also more complex n -m schema matches (e.g., name = concat( first , last ) or euro = 1.32  X  dollar ). For a good survey and compari-son, see [8,25]. In particular, our proposals in this paper is an extension of authors X  previous attempt [16] to the object mapping problem  X  in [16], the schema matching problem in the presence of opaque column names and data values are addressed. (2) Our  X  X alue mapping X  problem is more closely related to the object mapping problem (i.e., value is the object to map), which is also known as various names in diverse con-texts: e.g., record linkage [11,28], citation matching [19,24], identity uncertainty [24], merge-purge [15], duplicate detec-tion [1,22,26], and approximate string join [5,13]. Common to all these is the problem to find similar objects (e.g., val-ues, records, tuples, citations). Although different proposals have adopted different approaches to solve the problem in different domains, by and large, they focus on syntactic simi-larities of objects under comparison. On the other hand, our value mapping solutions can identify mappings where two objects have little syntactic similarity. To cope with such difficulties, we proposed to explore statistical characteristics of objects such as co-occurrence frequency or entropy.
In this paper, we investigated the value mapping problem to locate matching pairs of values from two input database tables. We proposed a two-step, iterative algorithm to dis-cover the mapping. Our algorithm uses the statistical de-pendency model among values (e.g., value co-occurrence fre-quency or entropy) as the basis for establishing value map-pings. In each iteration, it suggests a top-k list of candi-date mappings to users. The feedback provided by users is used to improve the mappings suggested in subsequent itera-tions. As validated through extensive experimentations, our solutions successfully establish the mapping between values across tables even in the presence of opaque data values and thus can be a useful addition to existing data integration techniques.
