 ORIGINAL PAPER Aman Goel  X  Matthew Michelson  X  Craig A. Knoblock Abstract Maps are one of the most valuable documents for gathering geospatial information about a region. Yet, find-ing a collection of diverse, high-quality maps is a significant challenge because there is a dearth of content-specific meta-data available to identify them from among other images on the Web. For this reason, it is desirous to analyze the con-tent of each image. The problem is further complicated by the variations between different types of maps, such as street maps and contour maps, and also by the fact that many high-quality maps are embedded within other documents such as PDF reports. In this paper, we present an automatic method to find high-quality maps for a given geographic region. Not only does our method find documents that are maps, but also those that are embedded within other documents. We have developed a Content-Based Image Retrieval (CBIR) approach that uses a new set of features for classification in order to capture the defining characteristics of a map. This approach is able to identify all types of maps irrespective of their subject, scale, and color in a highly scalable and accurate way. Our classifier achieves an F1-measure of 74%, which is an 18% improvement over the previous work in the area. Keywords Map identification  X  K-nearest neighbor classifier  X  Water-filling features  X  Content-Based Image Retrieval (CBIR)  X  PDF documents 1 Introduction Maps are one of the most important documents containing geospatial data about any region in the world. They provide information about a wide variety of subjects including road networks, transportation routes, natural terrain, buildings and other infrastructure, weather, water and gas pipelines. The Web is a great source of information of all kinds, includ-ing maps devoted to the aforementioned subjects. The capa-bility to find and process these maps automatically aids in the construction of useful geospatial knowledge bases. This in turn permits queries similar in nature to those applied to satellite image data, for example queries related to region, latitude/longitude, and street name. Researchers have dealt with various problems in automatically processing map doc-uments, such as extraction of road layers [ 4 ] and conflation of maps with satellite imagery [ 2 , 3 ] (see Fig. 1 ), but most of them assume that they have a corpus of map images to process. In this work, we tackle the problem of building that corpus by harvesting maps from the Web. In addition to the maps that exist independently as images, we also parse and extract suitable examples from documents devoted to geo-spatial subject matter, such as PDF reports.
 There are a couple of challenges involved in this task. First, we cannot rely on only one repository of maps since those maps would describe only a particular subset of prop-erties of an area, such as its infrastructure or topological characteristics. Despite the wealth of map data available via the Web, the said data are highly distributed, in various for-mats and frequently embedded in other objects such as PDF documents. Identifying these maps among the multitude of images is hard, since for most of them there is no metadata to indicate that they indeed are maps. This would suggest that we need to look at the actual content of each image to determine whether it is a map or not.
 Web-based image search engines, such as Yahoo Image Search 1 , are inadequate when tasked with finding specific maps. Figure 2 shows a snapshot of the first result page returned by this service for the query X  X  X ehran maps X . Only two of the 21 displayed images are maps, namely the 4th on the first row and the 5th on the last row. The rest of the images are either satellite images of Tehran or pictures of different places or events. The reason for this is that a search engine indexes an image based on the name of the file and the text surrounding it in the webpage where it appears. It does not look at the actual content of the image. Therefore, if someone wishes to collect a sufficient number of maps for Tehran to cover most of its area using this search engine, he or she will have to browse through all the result pages, hun-dreds of them, to select the few good maps that appear on each page. If one wants to find documents that contain maps using a search engine, this manual process will be even cost-lier since it would involve downloading each such file and looking through the whole document. On the other hand, our system can make this search not only convenient but also fast and more accurate.

Since map is a very generic word, we would like to define precisely what we mean by it in this paper when we talk about identifying or harvesting maps. A map is a high-quality image that depicts a region of earth with sufficient clarity so as to be useful for extracting information from it. Therefore, a very poor-quality scan of a paper map (Fig. 3 a) or a hand-drawn map (Fig. 3 b) or a photograph of a paper map in bad light (Fig. 3 c) or a picture with a tiny part of it displaying a map (Fig. 3 d) is not considered a map. A computer vision system might be interested in identifying any kind of map or even a photograph of a map, but our system is meant for identify-ing those maps that can be usefully processed to extract road intersections and other features of the region for alignment with satellite imagery. Figure 4 shows some of the images that we want to identify as maps. As is evident from the col-lection, we consider software-generated maps (Fig. 4 a, b) and scans of paper maps (Fig. 4 c) as good maps that can be processed successfully.

In this paper, we describe a method to automatically col-lect high-quality maps for any region, from the Web. Figure 5 shows the architecture of our end-to-end system. The rectan-gles in the diagram represent collections of data (e.g. docu-ments, images). The quadrilaterals with slanting sides depict a process. Since search engines have the most exhaustive index of the Internet, we use them as the starting point. We query the search engines for documents and images related to the area. All the images embedded in the gathered docu-ments are then extracted and put together with the indepen-dent images. This combined set contains maps of the area as well as other nonmap images like pictures of people and places.

Each image is classified by applying a K-nearest neigh-bor classifier [ 8 ] based on Content-Based Image Retrieval (CBIR), which we call CBIR classifier in this paper. Our CBIR approach finds the most similar images to each query image from a repository of pre-labeled map and nonmap images based on a set of similarity features. These features are derived from the Water-filling algorithm described by Zhou et al. [ 24 ]. The use of this particular feature set in this work is due to their efficacy in capturing characteristics germane to maps, for example, sharp boundaries and high branching of lines. The image is then classified as belong-ing to the same category to which the majority of the most similar images belong.

We tested our system on real images from the Internet, which represent the actual distribution of various map types for different regions. Our experiments show that our classifier performs better than the classifier used in the previous work byDesaietal.[ 10 ] by almost 20% in F1-measure. We attri-bute this result largely to the use of the previously mentioned feature set versus the use of Laws X  Textures [ 14 ]. Also, our experiments show that K-nearest neighbor classifier is much better at identifying maps than a Support Vector Machine (SVM) [ 22 ] when the training data set is small in size.
We described our map classification algorithm in a previ-ous paper [ 17 ]. Further work documented in this article has been dedicated to modifying the Water-filling algorithm in order to capture the properties of maps more accurately. Also, we have ignored some of the properties suggested by Zhou et al. and adjusted the weights of others to make the algorithm more specific to the task of identifying maps. We describe all these changes in Sects. 4.1 and 4.2 . We have also conducted an elaborate set of experiments on a much larger and diverse data set, with a focus on classifying maps that are totally dif-ferent from the labeled data in terms of scale, locations, etc. (e.g. classifying non-US maps based on a repository of maps of cities in United States).

The major contributions of our paper are the following. 1) We have developed a set of features based on the Water-2) Our paper shows that CBIR-based k-NN is more suited 3) We present an approach to map classification based on 4) Our paper describes an approach to finding documents 5) Finally, our paper describes an end-to-end system, The structure of this paper is as follows. We discuss related work in Sect. 2 . We describe the technique by which we col-lect potential maps of a region in Sect. 3 . We then lay out our technique for classifying these images into maps or nonmaps in Sect. 4 . We explain the methodology of our experiments and present the results in Sect. 5 , which also compares the performance of our system with the current state of the art. We discuss future work in Sect. 6 and conclude with a dis-cussion in Sect. 7 . 2 Related work Previous work on harvesting maps from the Internet was done by Desai et al. [ 10 ]. They used Laws X  Textures [ 14 ]as the representative feature set to differentiate between maps and nonmaps. These features capture the existence of vari-ous regular shapes, such as circles and rectangles in images. We believe that such features are not specific to maps in general and therefore are not very effective in differentiating them from nonmaps. For classification, the authors trained a two-class SVM on the 3,840 element feature vector based on this texture. We, on the other hand, use Water-filling features with CBIR-based k-NN classifier. As demonstrated in the experiments section, both our feature set and clas-sifier perform better than their respective choices for this application, and combining them together, we get a perfor-mance improvement of almost 20% in F1-measure in iden-tifying maps. Also, our approach is more efficient in terms of both time and memory requirement, since we use only a 24-element feature vector and our method takes about 3 s to process an average size image (1,000  X  1,000 pixels), com-pared to 30 s, which is required to extract Laws X  Texture. Further, we also present a method to collect maps embedded in other documents on the Internet. Our experiments demon-strate that general documents like PDF files are indeed useful sources for harvesting high-quality maps.

CBIR methods have been applied to various scientific dis-ciplines ranging from astronomy [ 7 ] to botany [ 23 ]. Much attention has been given to CBIR methods in medicine, where they can have tremendous impact [ 18 , 15 ]. For example, in one medical system [ 15 ], the authors use a CBIR-based k-nearest neighbor approach to classify medical images. This work also uses Water-filling features for the CBIR compo-nent. However, this combination performs the worst among the five different classification systems they have tested because Water-filling algorithm does not work well with images having amorphous boundaries and gradual color gra-dients, which is typical of medical images such as X-ray images (Fig. 6 ). On the other hand, maps generally have sharp boundaries and no color gradient, properties that we have exploited to our benefit in this application. Also, the context in which they apply these algorithms is very dif-ferent from ours. Whereas our system is geared toward automatically harvesting maps from the Web, their system is used to classify images so that they can be queried cate-gorically.

Ta n e t a l . [ 19 ] recently proposed a method for identifying maps embedded in Web documents by analyzing captions of images, references to them that are embedded in text, and their size relative to the font. They do not look at the actual content of the image. It might be possible to combine the two approaches together to take advantage of evidence about the content as well as the text surrounding it to achieve more accurate results. Yet, unlike them, we do not assume that a highly relevant library of documents is already provided to us, but discover the Web documents that are likely to contain useful maps ourselves. This also lets us gather more diverse types of maps. 3 Finding candidate maps The first step in harvesting maps is collecting images from the web. This includes finding PDFs from which we will extract the images. We use the Yahoo Image Search Engine API 2 for the purpose of collecting the independent images. The choice of engine is mostly influenced by convenience and does not affect the performance of the process. Any rea-sonable image search engine is sufficient. To collect maps for a region, we send two queries to the search engine. One query is formed with the word  X  X ap X  appended to the name of the region (e.g.  X  X os Angeles map X ). The other query is formed by appending the word  X  X aps X  in place of  X  X ap X  (e.g.  X  X os Angeles maps X ). We know that the relevance of images to search queries falls sharply after only a few result pages. As we go further in the list of URLs returned, sorted by relevance, the existence of maps becomes more and more sparse. Therefore, we use the top 2,500 URLs returned for both the searches for our purposes. We remove the duplicates from both the lists and then merge them together.

The fact that the search engines fail to identify and provide maps correctly becomes evident when we look at the images that are common between the two lists returned by the search engine. Although there is little semantic difference between the two search queries when it comes to images, there is less than 10% overlap between the two lists. Therefore, a person searching for maps on these search engines using only one of the queries will miss most of the maps that can be obtained by the other. The maps, among the images returned, are of varied types and scales. This is one of the advantages of using a search engine for harvesting the maps. Limiting the search to a particular database restricts access to all kinds of maps available freely on the Internet. Also, new content is con-stantly added to the Internet and indexed by the crawler of these engines. This guarantees a supply of up-to-date maps and greater detail about every region. Figure 7 shows some of the different kinds of maps returned by the search engine. There are physical maps ( 7 a), street maps ( 7 b), political maps ( 7 c), highway/freeway maps ( 7 d), commercial maps ( 7 e), transportation maps ( 7 f), etc.

Yet, all the good-quality maps are not available as separate images on the Internet. Many high-quality maps exist embed-ded in documents such as PDF reports. Therefore, in order to exploit these maps, we query the Google Search Engine 3 for URLs of PDF files related to the region. Again, the choice of the search engine is not fundamental to the performance of the system, as the major difference between the various engines is the relevance they attach to each document. Since we do not restrict ourselves to only the top few URLs, the system effectively has access to the same files that would be returned by any other search engine. We use the same query terms as explained earlier for the images (e.g.  X  X hicago map X  and  X  X hicago maps X ), but we also append the file-type quali-fier to restrict the results to PDF files only, which we focus on for this study, based on the availability of geographic reports. Therefore, an example query for Chicago would be  X  X hicago map filetype:pdf X . A PDF file generally has text included in it along with the images. Hence, a search engine would return the PDFs with greater accuracy based on the word  X  X ap(s) X  included in the query.
We have developed a PDF parser to extract the embedded images out of the downloaded files. According to the offi-cial PDF specification 4 by Adobe, a PDF file stores images, text, and all other information in the form of objects, which reference each other. The primary object for images defines the width, height, and type of the image and the compression algorithm used to store the image data. The actual image stream and optional color maps are stored in other objects that are referenced from the main object. Our parser reads through the entire file to rebuild the objects in memory. Then, it replaces the static references with memory point-ers. Depending on the kind of compression, type of image, color map, etc., the parser decodes the image stream and then stores it to the hard disk. The parser is capable of decoding most of the standard methods of storing images in PDFs including those based on ICC 5 profiles and JPEG formats.

As shown in the experiments section, PDFs indeed contain a huge number of images embedded in them. Although most of these are too small (e.g. company logos, map legends), it turns out that we still get about one image per PDF file downloaded, which can be useful (i.e. big enough for process-ing). The percentage of maps among these useful images is higher (  X  60%) than among the independent images (  X  50%) downloaded using the method described earlier. Also, the quality of the maps is much higher. Figure 8 ashowsasam-ple PDF returned when Google was searched for maps of Tehran. We can clearly see a very high resolution and detailed map embedded in it. Figure 8 b, c show two high-quality images extracted from the PDFs that we downloaded. The image in Fig. 8 c is of size 3,675 pixels by 4,575 pixels, which is quite difficult to find as a stand-alone image on the web.
It should be noted that the process of collection of indepen-dent images has almost no overhead. The entire time taken is that required by the search engine to return the list of URLs and to download the images from the Internet. In order to speed it up further, we use parallel threads to download these images. It also prevents a very slow Web site from holding up the download of images from other Web sites. We employ the same trick to download PDFs from the URLs returned by Google. But in this case, we also process these PDFs to extract the embedded images. Since our parser has been built in-house for experimental purposes, it is not very optimized. Despite this, on an average, we require less than a minute per PDF file for the parsing, extraction, and storage. This is not a very large time, considering the fact that there are fewer PDFs (  X  50) than images (  X  1,000) corresponding to a query for the maps of a city. 4 Classifying images In this section, we describe our approach used to separate the actual maps from all the images collected by the pro-cess described in the previous section. From each image, we extract a set of features to be made explicit shortly, based on the Water-filling features introduced by Zhou et al. [ 24 ]. The Water-filling algorithm works on the edge maps of the images instead of the original images. An edge map is a binary image produced from the original image by marking the sharp color gradients (edges) in black. Figure 9 bshows an edge map for a colored image ( 9 a). Using the edge maps makes the Water-filling features color-invariant. Maps vary widely in their colors schemes, which is mostly controlled by the source of the maps. Previous work [ 5 ] dedicated to identi-fying various features in a map based on color has acknowl-edged the fact that variation in the colors in a map makes any algorithm utilizing them applicable only to a small per-centage of maps, which are mostly from the same source. Therefore, we ignore the color scheme totally in favor of a color-invariant strategy. We explain the Water-filling features along with the modifications we have made to them in detail in Sect. 4.1 .

Having extracted the features, we find nine images from a repository of images that are most similar to the image under consideration. The images in the repository have already been manually labeled as maps or nonmaps, and their features have been extracted and indexed with them. The number of maps and nonmaps among those nine images is calculated, and the query image is classified as belonging to the class that is in majority. The process of finding the most similar images based on the content of the images (represented by some fea-tures) is called Content-Based Image Retrieval (CBIR). The technique of classifying an image (or more generally, any object) based on the majority among the most similar images (objects) is called k-nearest neighbor classification (k-NN). We describe this process in further detail in Sect. 4.2 . 4.1 Extracting features that differentiate between maps The Water-filling algorithm quantifies the general complex-ity of an image by the number of branches and lengths in the edge map. It does this by simulating the flow of water along connected canals that are represented by the connected edges in the edge map. We use the standard Canny edge detector [ 1 ] for generating the edge maps since it is more generally appli-cable to the wide variety of maps and is immune to the vari-ations of hue and saturation in the original images. Figure 9 c shows a part of the edge map (Fig. 9 b), which is circled and enlarged for clarity. The edge map consists of several disjoint segments of lines like the one shown in the center of Fig. 9 c. An average size map of dimensions 1,000  X  1,000 pixels can have any number of segments between 50 and 3,000 depend-ing on its scale and sparseness. For each of the disjoint seg-ments, the water starts flowing from a point along the lines. When it reaches a fork-point, where the line is dividing into two or more lines, the water starts flowing along all of these lines simultaneously, in the same way as water flowing from one canal into multiple canals will flow along each of them. The algorithm notes the number of such fork-points (repre-sented by  X  X ork Count X ) as well as the time required to fill the entire segment ( X  X illing Time X ). It also records the total amount of water stored in the segment ( X  X ater Amount X ), which is the same as the number of pixels in the segment. We explain the Water-filling algorithm in detail in Fig. 10 . Suppose that the top left segment is one of the many segments in an image that is being processed. The three values below each instance of the segment show the calculated parame-ters up to that time in the course of the Water-filling algo-rithm tracing the segment. We show the Filling Time ( X  X T X  in figure), Fork Count ( X  X C X ) and Water Amount ( X  X A X ), which all start with a zero value. The light pixels visible in other instances of the segment represent water, filling up the seg-ment pixel by pixel. The progression of the algorithm is from left to right in each row, starting with the top row. The sec-ond instance of the segment (figure in the middle in the top row) shows the situation when the processing has just begun, with only one pixel (topmost) having been filled up. Accordingly, the Filling Time and Water Amount increase to one each. When water reaches a fork-point (in the figure on the right in the top row), indicated by the crossed pixel, where it begins to flow in two or more directions simultaneously, the Fork Count value increases by one. At the end, all the pixels are filled and the final values are shown below the last instance. The Fork Count is two because the water forked at two places, marked by the crossed pixels. The Water Amount is same as the number of pixels in the segment i.e. 16.
The Filling Time of a segment indicates the approximate length of the longest path in the segment from one end to another. Intuitively, a map will have longer lines that repre-sent streets, freeways, and geographic or land/ocean bound-aries, depending on the scale of the map. On the other hand, a typical nonmap will not have such long lines. For example, a picture of nature or vegetation will have many short seg-ments for edges of leaves on trees and other growth. In an urban landspace, the edge map will have several short seg-ments for windows of building, or faces of people in a crowd. Therefore, a map, in general, will have larger number of long segments when compared to a nonmap image.

The number of Fork Counts, on the other hand, represents the complexity of the segments. Again, a map will generally have more Fork Counts because of the branching of roads at intersection repeatedly or continuous borders branching in different directions to represent neighboring states, coun-tries, etc. Also, by virtue of having longer connected lines in the edge map, the Fork Count per segment will be higher for the maps. In contrast, a nonmap with discrete windows or short leaves will have Fork Counts of mostly zero or one.
The Water Amount in each segment represents the size of the segment. In a map, the large lengths of the lines and high connectivity, as indicated by the Fork Count, makes average size of segments large. In the case of nonmaps, besides the fact that they have lower Filling Time and Fork Count, the color gradient causes the various connected lines to break in the middle. This causes the average segment size to be much smaller. Figure 11 shows how the color gradient causes even clear object boundaries to break up into smaller segments. The edge of the dial of the watch breaks up at several places even though a human eye can clearly see the entire boundary in the original image.

To capture the differences in distribution of Filling Time, we distribute all the segments into 8 bins depending on their individual Filling Times. The range for the 8 bins is as fol-lows : segments with Filling Time of 1 X 2, segments with Filling Time 3 X 5, 6 X 9, 10 X 14, 15 X 19, 20 X 24, 25 X 29, and finally segments with Filling Time equal to or greater than 30. Therefore, we put all the segments with Filling Time of 1 or 2 into the first bin, all the segments with Filling Time between 3 and 5 in the second bin, and so on. This gives us a histogram for Filling Time values. Figure 12 bshowsthe Filling Time histogram of the edge map of a highway map ( 12 a). It is clear that the size of bins with longer Filling Times is much larger. Similarly, Fig. 13 b shows that the distribution of Filling Time in a nonmap (Fig. 13 a) is very different, with the smaller Filling Times having slightly larger portion of all the segments. As with Filling Time, we divide the seg-ments into 8 bins for Fork Count as well. The bins for Fork Count are as follows : segments with Fork Count of 0 X 1, segments with Fork Count of 2, 3, 4, 5, 6, 7, and finally seg-ments with Fork Count equal to or greater than 8. Figure 12 c shows the Fork Count histogram for the map. As we can see, there are large number of segments with high Fork Counts. Figure 13 c, on the other hand, shows the Fork Count his-togram of the nonmap. This image does not have as many complex segments; but there are a large number of segments with low Fork Counts, which is representative of the highly decomposed structure of a nonmap. We also divide the seg-ments based on Water Amount. The bins for Water Amount are as follows : 0 X 2, 3 X 6, 7 X 11, 12 X 18, 19 X 24, 25 X 30, 31 X 37, 38 X . We experimented with various bin sizes for all three features. In order to discriminate between the images in the best possible way, we have adjusted the boundaries of each bin in such as way that, for a property, their sizes are roughly equal when averaged over a large set of images that we used in our experiments. This implies that the varia-tions in histograms among images will be most pronounced. Any other bin size configuration would tend to underestimate the difference between images since the variation would be smaller on average. This is similar in spirit to the concept of maximizing entropy in probabilistic systems. Therefore, we can say that range of bins has been chosen so as to separate segments such that change in the number of segments in any bin reflects a characteristic change in the nature of the image.
In this way, we generate eight values (corresponding to the eight bins) for each property (i.e. Filling Time, Fork Count, and Water Amount), which combined together give us the 24-element feature vector for an image in the Water-filling feature space. If t1, t2, ... ,t8arethebin values for the Filling Time, c1, c2, ... , c8 are the bin values for the Fork Count, and a1, a2, ... , a8 are the bin val-ues for the Water Amount, then the feature vector F [ t1t2t3t4t5t6t7t8c1c2c3c4c5c6c7c8a1a2a3a4a5a6a7a8].
We implemented the feature extraction code in Java. Zhou et al. suggest that in order to find the next pixel to fill with water, we should look for all pixels that are 4-m neighbors of it. The 4-m neighbors of a pixel are the four pixels located to the north, south, east, and west of it. Due to the discrete nature of the pixels on the screen, occasionally, connected pixels occur diagonally (Fig. 14 ). This causes the flowing water to reach a dead end at a point (circled in the figure) even though the line actually goes on further. As a result, features found by using this algorithm do not represent the characteristics of a segment to the fullest possible extent. The average Fill-ing Time and segment size are much lower according to this algorithm. This is why in addition to the 4-m neighbors, we consider the diagonally located pixels as well, in searching for the next connected neighboring pixels to fill. As shown in the experiments section, this small extension to Water-filling gives a much better estimate of the features that we intend to measure and improves the performance of the system considerably.

The size of images on the Internet varies widely. Our hypotheses is that for maps of a particular type, the ratio of number of segments of a particular Fork Count, Filling Time, or Water Amount to the total number of segments will remain roughly constant. The absolute number of segments will increase with the size of the image though. For exam-ple, consider the map shown in Fig. 15 a. We took the top left quarter from this image to create a new image Fig. 15 b. Figure 16 a shows the bin sizes for both the images for var-ious Fork Counts. As expected, the values for Fig. 15 bare smaller than those for the entire image. Yet, the relative dis-tribution is identical in both images as is evident from the scaled-down values of the larger image obtained by dividing them by four. In order to be able to match maps of the same type in our nearest neighbor classifier, we need to normalize the total number of segments in each image, so that the num-ber of segment in each bin also becomes identical for similar maps. We have chosen to normalize the total number of seg-ments in each image to 1,000. We do this on each image in the following way. First, we calculate the actual sizes of bins for Filling Time, Fork Count, and Water Amount. The sum of bin sizes for each property will be equal to the total num-ber of segments in the image. Then, we scale all the values so that this sum becomes equal to 1,000. These resultant bin values are used to construct the feature vector of the image. The nearest neighbor classifier also uses the same values to calculate the distance between images in the feature space. Figure 16 b shows the values of Fork Count bins after the nor-malization. Looking at the values, it becomes clear that both the histograms are identical and hence describe similar types of maps. When the nearest neighbor algorithm searches for similar images for one of the maps, the other map is very likely to be found as a close match, even though their sizes are very different.

We would like to note here that the extraction of these features is very fast when compared to that of Laws X  Tex-tures that was used previously [ 10 ]. The system described herein takes less than 3 s to process a medium-size image (1,000  X  1,000 pixels) versus a method relying on Laws X  Texture, which takes about 30 s for the same image. Also, our feature vector has only 24 elements in it. This is a huge saving in space, considering the fact that Laws X  Texture gen-erates more than 100 times this many elements in its feature vector, i.e. 3,840. Therefore, we gain an order of magnitude improvement in speed, combined with two orders of magni-tude improvement in space. Further, as shown in our experi-ments, our features are more accurate as well. Thus, we have built an efficient and accurate solution. 4.2 CBIR-based k-nearest neighbor classifier There exist a wide variety of useful maps on the Web, and the features of these maps are very different from each other. For example, a physical map does not have clear boundaries, whereas a street map has sharp lines for roads and blocks. Also, the same kind of map shows different densities at var-ious scales. A street map at a low scale (Fig. 17 a) has large white space in between the lines of roads and other struc-tures. On the other hand, a street map displaying the entire city (Fig. 17 b) will have a very grid-like structure with roads forming very small blocks and major freeways depicted by bold lines. Therefore, it is not possible to find a common set of features among all these different maps that can reliably represent any map in general. These characteristics motivate the use of the CBIR-based k-NN classifier. As alluded to previously, this system finds the most similar images given a query image, from a repository of pre-labeled images. This action is in turn based on similarity of content (Fig. 18 ).
A CBIR system finds the most similar images to a given query image from a repository of pre-labeled images based on the similarity in content between those images. Therefore, when we supply a particular map as query, the CBIR system finds those images that are closest to this map in features. If there are sufficient number of maps of this kind in the repository, then most of the similar images returned would be maps of the same type, since they would have the most similar features. CBIR is essentially the image equivalent to traditional text-based Web search. Instead of finding the most similar Web pages for a given set of query terms, in CBIR, the most similar images from a set are returned for a given query image. Figure 18 provides a visual representation of this concept. In this figure, the query image comes into the system, and the most similar images are returned by it. This is the basis of our classifier.

To exploit CBIR for classification, we use a voting, k-nearest neighbor classifier [ 8 ]. We first use CBIR to find the nine most similar images (neighbors) from the combined set of images in the map and nonmap repositories based on the features mentioned above. We then employ a simple major-ity voting mechanism. If the majority of returned images are maps, we classify the query image as a map. If the majority of returned images are nonmaps, we classify the query image as a nonmap. Therefore, although it may be the case that other images on the Web will have clear edge structures (such as diagrams), since our technique relies not only on the edge features themselves, but also on the similarity to the edge features of the images in our map repository, such images will be filtered out. The accuracy of our experimental results indeed show this to be the case. We observed the performance of our system for different numbers of nearest neighbors cho-sen. We tried the following five different values: 5, 7, 9, 11 and 13 and found the variation to not be statistically signifi-cant for alpha = 0.5. Therefore, we decided to use the value of nine to maintain a balance between the complexity of finding the nearest neighbors and accuracy. If the number of near-est neighbors is too small, then, in case that a few nonmap images exist too close to some maps in a map cluster, they would swing the majority in the favor of nonmaps leading to error in classification. However, if the number of nearest neighbors used is big enough, then the other map images in the cluster will also get included and outweigh those nonmap images.

Practically, we represent the repository of images by an index of feature values for each image and its name. We use the open-source CBIR system, Lire 6 to build and access this index quickly, though we have modified it to support our fea-tures. The CBIR system goes through the index calculating the similarity score of each image in the repository with the query image. The similarity score is calculated as follows: for each histogram, we add up the absolute difference between the corresponding bin values. Then, we multiply each of these three values with their corresponding weights and add them together. The Lire system finds nine images with the least similarity score. These are the images that are most similar to the query image. In our implementation, we have assigned equal weights to all the properties after trying a few combi-nations of weights, such as assigning weights of 1.0 to two properties and 0.5 to the third one. We also tried setting the weights of two properties to zero and of one property to 1.0. In all these cases, we found the performance to be lower than the case when the weights are equal.

We choose a CBIR-based k-nearest neighbor classifier over other traditional machine learning methods for the fol-lowing reasons. CBIR similarity methods allow us to exploit image similarities without explicitly modeling them. For instance, hydrography maps are similar to other hydrogra-phy maps, and urban city maps are more similar to urban city maps but these types of maps may be quite different from each other. By using CBIR methods, these similarities can be exploited without modeling them explicitly because the returned images encompass the image similarities implicitly (that is why they are returned as similar).

In contrast, if we use traditional machine learning meth-ods, such as Support Vector Machines, we would train a model for each class of map. Then, if an incoming image matches any of these map classes, we know it is a map (since each class composes the image similarities). That is, we can take the hydography maps and learn a model of what a hydrography map should be. We can then take the urban city map and learn an urban city map model.

There are several problems with trying to learn a model for each type of map. For one, the number of such classes is not known in advance. Therefore, a user will have to make a decision as to which maps constitute a class and hope he or she made the correct choices to lead to accurate classifica-tion. Along these lines, the user must make decisions as to the granularity of the classes (Is an urban-hydrographical map its own class ?), which can further complicate the creation of classes. Also, learning a new model may be a nontrivial process both in the work and time required. So, if a new class is discovered or needed, this can become a prohibitively costly problem since we need to train all the SVM models again with one more class to discriminate from. The other option is to train a two-class SVM as was done by Desai et al [ 10 ]. Such an SVM draws a hyperplane in the feature space to separate instances of maps from nonmaps. Yet, as explained earlier, since maps vary significantly in their properties, it is difficult to find a hyperplane that can clearly separate the two classes with minimal error since many nonmaps will have properties similar to a particular kind of map and lie close to them and maps of one kind might lie very far from maps of other kinds in the feature space.
 The other reason we chose CBIR-based k-NN instead of SVM has to do with robustness and scalability. As we show in Sect. 5 , our classifier is able to learn models of differ-ent kinds of maps from a small set of labeled images. On the same data set, SVM performs relatively poorly since it requires more training data to learn a reliable model of maps from all the different kinds of maps shown to it. As we increase the training data size, SVM performs comparably to our classifier, with the caveat that SVM training becomes prohibitively expensive with increasing data set size. How-ever, CBIR techniques are built on methods from information retrieval, which the major search engines have shown to be fast and robust in very large, practical settings. Further, we can freely tweak the size and composition of our repository to test the effect (something we do in the experiments to test this idea). Using machine learning, we have to retrain a model each time we tweak the training data set. In situations where training is costly, this is not a good solution. There-fore, by using CBIR methods, we can grow the repository over time without retraining which allows for a scalable and incremental solution to classifying maps and building good map repositories. 4.3 Improvements over our previous work We have done some preliminary work on harvesting maps from the Web [ 17 ]. Since then, we have made several changes and additions to our methodology that we elaborate here. The first major difference concerns the Water-filling algorithm. In the previous approach, we did not consider the diagonal neighbors while tracing the pixels to calculate various prop-erties of each segment. In the present work, we have modified the Water-filling algorithm to consider them as well leading to much more accurate measurements of these properties. The second change concerns the normalization of histogram values to fit the size of images. This makes our approach more size-invariant. We believe that both these changes have made the feature vectors become a better representative of the images.

In our earlier methodology, we considered two more prop-erties suggested by Zhou et al., namely Maximum Filling Time and Maximum Fork Count, that we have done away with now. These represented the maximum values for Filling Time and Fork Count, respectively, in the whole image. We found that these properties are more relevant in an image of one solid object with a uniform background. In general maps and nonmaps, these properties have very random values due to the irregularity of these images. For example, the longest line in an edge map can be broken into half just by removing one pixel from the middle, thereby cutting the Filling Time by 50%. Similarly, two highly branching segments located close to each other can be joined by just a small line, which could be a random stroke. Yet, this will result in a segment with a very high Fork Count due to the addition of indi-vidual Fork Counts of the two segments. Therefore, these two features add noise to the CBIR matching process, reduc-ing the effectiveness of other features. We also have made the weights of the histograms equal, in distinction to previ-ous implementation where the Water Amount histogram was given lower weights.

These changes have contributed to significant improve-ment in both precision and recall of the system as illustrated in Sect. 5 . 5 Experiments and results We use the Yahoo Image Search Engine API 7 to discover the images and the Google Search Engine to discover PDF docu-ments from which the images can be extracted out. We imple-ment the Water-filling [ 24 ] algorithm in Java. The images in the repository and their extracted features are indexed and retrieved using the open-source CBIR system Lire, 8 which is in turn based on the popular text-based indexing and retrieval system Lucene 9 [ 16 ]. We extend Lire to support retrieval based on Water-filling features. The PDF parser is based on the official specification by Adobe. 10
The two major components of our classification process are the extraction of Water-filling features from the image and then its classification based on these features using CBIR-based k-NN. To test the contribution of each component in our approach, we use four different experimental config-urations, each of which isolates the different components of our approach. The  X  X BIR/WF X  configuration is our full approach, combining Water-filling (WF) features with our CBIR-based k-NN classifier (CBIR). We also use our CBIR classifier with Laws X  Texture [ 14 ] (LT) features, which we call  X  X BIR/LT X . We also combine the binary SVM classifier with each of the feature sets, which we call  X  X VM/WF X  for the case that uses Water-filling and  X  X VM/LT X  for that which uses Laws X  Textures. By combining each of the classifiers with each of the feature choices, we can isolate the impact of the choice of features and the choice of classifier. The dif-ferent configurations with their individual components are summarized in Table 1 .

Our experimental methodology is as follows. We down-load images located at the URLs obtained from the Yahoo Image Search Engine for 16 different regions of the world. In order to maintain an equal distribution between different regions, we randomly pick 500 images from each of these collections of images for the purpose of our experiments, except for four cities for which we could not find enough unique images. We label each image as a map or a nonmap based on the criteria mentioned before. The distribution of the images among different regions and the number of maps and nonmaps for each is depicted in Table 2 . The  X  X onmap X  images mentioned in the table are taken from the CALTECH 101 data set [ 11 ].

For our experiments, we randomly selected 2,000 maps and 2,000 nonmaps from the entire set of images to build the repository for the CBIR method. Since the repository acts as the set of labeled samples for the CBIR method, we used this same set to train the binary SVM. Then, we tested each method on 2,000 randomly chosen maps and 2,000 randomly chosen nonmaps that were different from the images in the repository/training set. We also wanted to see whether our classifier retains the lead over other systems for smaller repository sizes. To test this, we carried out the same experiment as described above, but with repeatedly smaller repository/training sets. The test set was kept fixed in size and content. The performance of each configura-tion was measured in terms of precision 11 , recall F1-measure 13 . Both the training and testing data set were then returned to the entire set of images. This procedure was repeated 10 times, each time selecting a fresh training and testing data set, sampled randomly from the entire set. The average performance, over 10 runs, of each configuration on the different repository sizes is shown in Table 3 . This table supports three hypotheses. First, it shows that Water-filling is very good at capturing the general character-istics of a map and is therefore a much better feature in dis-criminating between maps and nonmaps than Laws X  Texture used in the previous work by Desai et al. [ 10 ]. With regard to both classifiers, namely CBIR-based k-NN and Support Vector Machine, the precision, recall, and F1-measure for systems using Water-filling features is higher than those using Laws X  Texture. When we look at the first two sys-tems, CBIR/WF and CBIR/LT, in Table 3 , both of which use CBIR-based k-NN, the F1-measure is almost 6% higher with the use of Water-filling features. In case of the next two systems, SVM/WF and SVM/LT, the difference is as high as 17%. This clearly shows that just changing the feature to Water-filling enhances the accuracy of classification. The second hypothesis is that on a small training set, CBIR-based k-NN performs better than the conventional Support Vector Machine. The first and third classifier/ feature configuration in each group use Water-filling features, but differ in the type of classifier. The F1-measure for CBIR-based system is almost 4% more than that for the SVM when the training set has between 250 and 500 images. In fact, the difference remains significant till the repository size grows to 3,000 images after which it becomes less that 1%. Since maps vary a lot in their properties, and yet the SVM learns one label for all kinds of maps, it requires more data to converge to a good hyperplane that separates maps from nonmaps. On the other hand, the CBIR makes use of these differences to identify different kinds of maps and thus has a recall of 59%. The SVM meanwhile has a recall of 52%. When we look at the second and the fourth configurations, both of which use Laws X  Texture, the difference is more marked. Whereas the difference in F1-measure is 12% for the larger training sets, the difference becomes as significant as 20% for the smallest sets. This demonstrates the fact that CBIR-based classifier is superior to SVM in this application, even with the use of a suboptimal feature set.

The third claim we made in the beginning of the paper was that our classification system improves upon the current state of the art by almost 20% in F1-measure (for the largest training set). The big gain in accuracy is the result of combin-ing a better discriminating feature set (Water-filling) with a more flexible classifier (CBIR-based k-NN). In the process, we gain on the speed of classification as well as the main-tainability of the system as discussed in detail in Sect. 4.2 . All the values of F1-measure reported in the table above are statistically significant.

Figure 19 shows the change in F1-measure of the four configurations with the size of the repository/training set. Our system maintains a consistent advantage over the other systems for all sizes of the repository. This shows the strength of our method. Even with a repository size as small as 250 images, it is able to classify 4,000 images correctly with a precision of 77% and F1-measure of 67%. This means that our system is able to capture the most fundamentally unique features of a map that enables it to correctly classify a much more diverse set of images.

Figure 20 shows the precision, recall and F1-measure of only our system with change in the repository size. The pre-cision of our system remains fairly constant even when the repository size is very small. It is the change in recall which increases the F1-measure for the most part. This implies that one can start collecting maps with a very small group of images in the repository. Since the precision is high, the images classified as maps by this system can then be put back into the repository with minimal human intervention to grow the size of the repository for better performance. This process is also called bootstrapping.

To test the robustness of our classifier on images unlike those in the repository, we divide the images into the reposi-tory and test set based on their origin. For example, US cities in general have a more regular grid-based structure to them, which is not found in the other parts of the world like India, Iran, or China. Therefore, we put all the US city images (for example, Fig. 21 ) in the repository and test the performance of the classifier on the set of images belonging to regions outside United States (for example, Fig. 22 ). We also divide the images based on the size of region they represent. In this case, we put all the city images (for example, Figs. 21 and 22 ) in the repository and test the accuracy of classification on maps of continents (for example, Fig. 23 ). We compare the performance on the two distributions of images mentioned above with the standard distribution, in which the repository and test sets are composed by picking uniformly from the entire data set. Both the repository and test sets have 4,000 images, 2,000 being maps and the other 2,000, nonmaps. The precision, recall, and F1-measure of classification are presented in Table 4 .

The results show that the precision remains practically unchanged. From the point of view of a real-world implemen-tation of our algorithm, this implies that the user of this sys-tem can put the same confidence in the classification of a map from any part of the world even if the classifier has seen that area for the first time. Combining this with the fact that the algorithm maintains its superiority to others even when the repository is very small makes MapFinder the most practical alternative to any existing system for identifying maps. 5.1 Improvement from the previous implementation Since we introduced MapFinder in our previous paper [ 17 ], we have experimented extensively with all the major proper-ties of this system. We have made several major changes that are explained in Sect. 4.3 . In order to evaluate how all these changes have translated into improvement in performance of MapFinder, we run the same basic experiment as explained before on its previous implementation as well. Table 5 shows the results.

There is an almost 12% improvement in F1-measure of the system, a direct result of the algorithmic improvements outlined in this paper. The precision and recall have improved by almost 10 and 13%, respectively. This demonstrates two facts. First, MapFinder is more able to differentiate between the maps and nonmaps than previously. This is attributed to a better selection of properties (e.g. rejection of Maximum Fill-ing Time and Maximum Fork Count) and the choice of their weights, which lets the CBIR system select the neighbors more accurately. Second, the significant increase in recall shows that MapFinder can now capture the fundamental char-acteristics of the maps more accurately. This is a direct con-sequence of improved features, arising from the adaptation of the Water-filling algorithm to our task. The values of preci-sion, recall, and F1-measure mentioned here for the previous implementation, based on the new data set, are lower than those reported in our previous paper because the current data set is larger and much more diverse than the previous set and is a more accurate representation of the images in the wild. 5.2 Extracting maps from documents such as PDF files We believe that PDF documents are a good source of images and maps of a region. To test this, we queried the Google Search Engine, with search queries such as  X  X os Angeles maps filetype:pdf X  and  X  X frica maps filetype:pdf X . We down-loaded 210 PDFs in this way. We have developed a PDF parser which extracts images embedded in the PDF files in a wide variety of formats and encodings. We extracted 2,266 images from all the PDF files. After removing images that were too small (e.g. company logo and legend symbols for maps), we were left with 310 images. The reason for pruning is twofold. First, maps that are too small are not of much use since they are either too dense or contain too little infor-mation for any practical use. Second, small images do not contain enough pixels to let the MapFinder algorithm reli-ably extract its features. We consider any image that has both its width and its height less than 300 pixels to be too small for use. After manual labeling, we divide these 310 useful images into 182 maps and 128 nonmaps. This shows that the PDFs returned by the search engine indeed contain useful maps (182 maps in 210 PDFs). The performance of Map-Finder on these 310 images was measured in terms of preci-sion, recall, and F1-measure. As before, the repository was created by picking 2,000 map and 2,000 nonmap images ran-domly from our entire set of images. We measured the perfor-mance three times by creating fresh repositories each time. Table 6 shows the distribution of map and nonmap images in the downloaded PDFs along with the average values of precision, recall, and F1-measure observed.

This table supports our claim that it is possible to har-vest maps from documents like PDF files, over and above the independently available images on the Internet. Although MapFinder is still able to classify these images reliably, the performance for the embedded images is lower than that for the individual images. As we mentioned earlier, the images embedded in PDFs are generally of a much higher quality. In fact, many of the images are stored in a compressed bit-map format, which when extracted produce a high-resolution image. In the process of classification in MapFinder, we first convert the images to the GIF format for implementation reasons. Due to the high quality and richness of colors in the extracted bitmaps, the conversion to GIF format leads to the formation of color edges from the color gradients. These give maps a more nonmap-like property (large number of small edges). It is important to note here that this problem is not inherent in the algorithm, but is a side effect of the choice of implementation.

Overall, these experiments verify and support the efficacy of the different parts of our end-to-end system for harvesting maps from the World Wide Web. 6 Future work The most important issue we will address in the future is that some maps are misclassified by our system when the majority vote is borderline, for example, when the number of maps is four and number of nonmaps is five. We have found that the one image that sways the classification is often among a very small set of nonmaps (  X  10 ) , which repeat-edly get selected by the CBIR system because they have a map-like quality to them. Figure 24 a shows one such non-map. The edge map 24 b has many squares in the background, which is similar to the block structure found in cities. We can deal with this ambiguity by employing relevance feed-back techniques from information retrieval. Such relevance feedback could help us identify and prune away such  X  X ul-prit X  images that consistently sway the vote in misclassifica-tions.

Even though we have changed the weights given to the features from our previous work, so that we ignore two of them and make the remaining three equally important, we have not tried changing the weights for each bin of the his-tograms individually. It does seem possible that some of the bins could have a more significant role in differentiating maps from nonmaps than others. Experiments can be carried out to determine the strength of each of these bins by extensively changing weights for them in steps. We think that it will be possible to achieve even higher precision through these experiments.

Our results point to the necessity of using the correct fea-tures for CBIR. While we chose Water-filling, which is good for images such as maps with strong edge maps, other meth-ods could perhaps work as well. For instance, the  X  X alient point X  features based on wavelets [ 21 ] and another set of features based on shape similarity [ 13 ] could be well suited to our task, since maps seem to share certain shapes within them. Lastly, methods have been proposed to more efficiently store color information [ 9 ], which makes retrieval more effi-cient. Although we use textures based on edge maps to make our method color-invariant, color information might help in discriminating maps. Future work to compare the various fea-tures and their efficiency and accuracy for map classification will be interesting. 7 Conclusion In this paper, we present an autonomous, accurate and scal-able method for harvesting maps from the World Wide Web. Our method first scours the Web to find both stand-alone images and those embedded within documents. Then, our classification algorithm separates these discovered images into a set of maps and nonmaps for the query region. We find that Water-filling features are much better at capturing the features of maps that differentiate them from nonmaps. We also find that a CBIR-based classification method outper-forms an SVM-based method when trained on fewer labeled samples. We show the robustness of our classifier by using a repository of US city maps to identify maps of other regions outside the United States that do not even have a similar grid-like structure. Finally, it is demonstrated that the com-bination of a superior feature set and classifier contributes to an overall system that outperforms the current state of the art.
By extracting images from PDFs, we collect new high-quality maps that are generally not available as independent files. In fact, we find that the percentage of images that are maps is higher in PDFs than among the independent image files obtained from image search engines.

In addition to being very accurate, our system is much more scalable as well, since adding more images to the repos-itory for better performance requires only extracting their features and adding them to the index. On the contrary, an SVM classifier needs to be retrained every time a new image is added to the training set, which for a sufficiently large set requires significant time. Further, our classifier needs a fraction of the time and memory required by previous work [ 10 ].

We have suggested some work that can further improve the performance of the system. Yet, despite the future work pro-posed, our technique provides an automatic, accurate, prac-tical, and scalable solution to the problem of creating useful map repositories from the Web. More importantly, by plug-ging our method in with methods for aligning raster maps with satellite images, we can build effective GIS systems by scouring the freely available images on the Web to build map collections for any given region in the world.
 References
