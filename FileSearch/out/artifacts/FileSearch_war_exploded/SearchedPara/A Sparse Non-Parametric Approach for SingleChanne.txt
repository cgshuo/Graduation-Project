 Keywords: Example-Based Representation, Signal Separation, Sparse Models. This paper deals with the problem of single-channel signal s eparation  X  separating out sig-nals from individual sources in a mixed recording. As of rece ntly, a popular statistical approach has been to obtain compact characterizations of in dividual sources and employ them to identify and extract their counterpart components f rom mixture signals. Statisti-cal characterizations may include codebooks [1], Gaussian mixture densities [2], HMMs [3], independent components [4, 5], sparse dictionaries [6], no n-negative decompositions [7 X 9] and latent variable models [10,11]. All of these methods att empt to derive a generalizable model that captures the salient characteristics of each sou rce. Separation is achieved by abstracting components from the mixed signal that conform t o the statistical characteriza-tions of the individual sources. The key here is the specific s tatistical model employed  X  the more effectively it captures the specific characteristics of the signal sources, the better the separation that may be achieved.
 In this paper we argue that, given any sufficiently large colle ction of data from a source, the best possible characterization of any data is, quite sim ply, the data themselves. This has been the basis of several example-based characterizati ons of a data source, such as nearest-neighbor, K-nearest neighbor, Parzen-window bas ed models of source distributions etc. Here, we use the same idea to develop a monaural source-s eparation algorithm that directly uses samples from the training data to represent th e sources in a mixture. Using this approach we sidestep the need for a model training step, and we can rely on a very flexible reconstruction process, especially as compared wi th previously used statistical mod-els. Identifying the proper samples from the training data t hat best approximate a sample of the mixture is of course a hard combinatorial problem, whi ch can be computationally demanding. We therefore formulate this as a sparse approxim ation problem and proceed to solve it with an efficient algorithm. We additionally show t hat this approach results in source estimates which are guaranteed to lie on the source ma nifold, as opposed to trained-basis approaches which can produce arbitrary outputs that w ill not necessarily be plausible source estimates.
 Experimental evaluations show that this approach results i n separated signals that exhibit significantly higher performance metrics as compared to con ceptually similar techniques which are based on various types of combinations of generali zable bases representing the sources. In this section we cover the underlying statistical model we will use, introduce some of the complications that one might encounter when using it and fina lly we propose an algorithm that resolves these issues. 2.1 The Basic Model Given a magnitude spectrogram of a single source, each spect ral frame is modeled as a histogram of repeated draws from a multinomial distributio n over the frequency bins. At a given time frame t , consider a random process characterized by the probabilit y P t ( f ) of drawing frequency f in a given draw. The distribution P t ( f ) is unknown but what one can observe instead is the result of multiple draws from the p rocess, that is the observed spectral vector. The model assumes that P t ( f ) is comprised of bases indexed by a latent variable z . The latent factors are represented by P ( f | z ). The probability of picking the z -th distribution in the t -th time frame can be represented by P t ( z ). We use this model to learn the source-specific bases given by P t ( f | z ) as done in [10,11]. At this point this model is conceptually very similar to the non-negative factoriza tion models in [8,9]. Now let the matrix V F  X  T of entries v ft represent the magnitude spectrogram of the mixture sound and v t represent time frame t (the t -th column vector of matrix V ). Each mixture spectral frame is again modeled as a histogram of repeated dr aws, from the multinomial distributions corresponding to every source. The model for each mixture frame includes an additional latent variable s representing each source, and is given by where P t ( f ) is the probability of observing frequency f in time frame t in the mixture spectrogram, P s ( f | z ) is the probability of frequency f in the z -th learned basis vector from { z s } represents the set of values the latent variable z can take for source s , and P t ( s ) is the probability of observing source s at time t .
 We can assume that for each source in the mixture we have an alr eady trained model in the form of basis vectors P s ( f | z ). These bases will represent a dictionary of spectra that be st describe each source. Armed with this knowledge we can decom pose a new mixture of these known sources in terms of the contributions of the dictionar ies for each source. To do so we can use the EM algorithm to estimate P t ( z | s ) and P t ( s ): The reconstruction of the contribution of source s in the mixture can then be computed as Figure 1: Illustration of the basic model. The triangles den ote the position of basis functions for two source classes. The square is an instance of a mixture of the two sources. The mixture point is not within the convex hull which covers either sourc e, but it is within the convex hull defined by all the bases combined.
 These reconstructions will approximate the magnitude spec trogram of each source in the mixture. Once we obtain these reconstructions we can use the m to modulate the original phase spectrogram of the mixture and obtain the time-series representation of the sources. Let us now pursue a brief pictorial understanding of this alg orithm, which will help us introduce the concepts in the next section. Each basis vecto r and the mixture input will lie in a F  X  1 dimensional simplex (due to the fact that these quantities are normalized to sum to unity). Each source X  X  basis set will define a convex hull wi thin which any point can be approximated using these bases. Assuming that the training data is accurate, all potential inputs from that source should lie in that area. The union of a ll the source bases will define a larger space in which a mixture input will be inside. Any mix ture point can then be approximated as a weighted sum of multiple bases from both so urces. For visualization of these concepts for F = 3, see figure 1. 2.2 Using Training Data Directly as a Dictionary In this paper, we would like to explain the mixture frame from the training spectral frames instead of using a smaller set of learned bases. There are two rationales behind this decision. The first is that the resulting large dictionary provides a be tter description of the sources, as opposed to the less expressive learned-basis models. As w e show later on, this holds even for learned-basis models with dictionaries as large as the p roposed method X  X . The secondary rationale behind this operation is based on the observation that the points defined by the convex hull of a source X  X  model, do not necessarily all fall o n that source X  X  manifold. To visualize this problem consider the plots in figure 2. In both of these plots the sources exhibit a clear structure. In the left plot both sources appe ar in a circular pattern, and in the right plot in a spiral form. As shown in [12], learning a set of bases that explains these sources results in defining a convex hull that surround s the training data. Under this model potential source estimates can now lie anywhere insid e these hulls. Using trained-basis models, if we decompose the mixture points in these figu res we obtain two source estimates which do not lie in the same manifold as the origina l sources. Although the input was adequately approximated, there is no guarantee that the extracted sources are indeed appropriate outcomes for their sound class.
 In order to address this problem and to also provide a richer d ictionary for the source reconstructions, we will make direct use of the training dat a in order to explain the mixture, and bypass the basis representation as an abstraction. To do so we will use each frame of the spectrograms of the training sequences as the bases P s ( f | z ). More specifically, let W ( s ) be the training spectrogram from source s and let w ( s ) t represent the time frame t from the spectrogram. In this case, the latent variable z for source s takes T ( s ) values, and the z -th basis function will be given by the (normalized) z -th column vector of W ( s ) . Figure 2: Two examples where the separation process using tr ained bases provides poor source estimates. In both plots the training data for each so urce are denoted by  X  and  X  , and the mixture sample by . The learned bases of each source are the vertices of the two dashed convex hulls that enclose each class. The source esti mates and the approximation of the mixture are denoted by  X  , + and . In the left case the two sources lie on two overlapping circular areas, the source estimates however l ie outside these areas. On the right, the two sources form two intertwined spirals. The rec overed sources lie very closely on the competing source X  X  area, thereby providing a highly i nappropriate decomposition. Although the mixture was well approximated in both cases, th e estimated sources were poor representations of their classes.
 With the above model we would ideally want to use one dictiona ry element per source at any point in time. Doing so will ensure that the outputs would lie on the source manifold, and also offset any issues of potential overcompleteness. On e way to ensure this is to perform a reconstruction such that we only use one element of each source at any time, much akin to a nearest-neighbor model, albeit in an additive setting. This kind of search can be computationally very demanding so we instead treat th is as a sparse approximation problem. The intuition is that at any given point in time, the mixture frame is explained by very few active elements from the training data. In other w ords, we need the mixture weight distributions and the speaker priors to be sparse at e very time instant. We use the concept of entropic prior introduced in [13] to enforce sparsity. Given a proba-bility distribution  X  , entropic prior is defined as where H (  X  ) =  X  P i  X  i log  X  i is the entropy of the distribution. A sparse representation , by definition, has few  X  X ctive X  elements which means that the re presentation has low entropy. Hence, imposing this prior during maximum a posteriori estimation is a way to minimize entropy during estimation which will result in a sparse  X  distribution. We would like to minimize the entropies of both the speaker dependent mixtur e weight distributions (given by P t ( z | s )) and the source priors (given by P t ( s )) at every frame. In other words, we want to minimize H ( z | s ) and H ( s ) at every time frame. However, we know from information theory that Thus, reducing the entropy of the joint distribution P t ( z, s ) is equivalent to reducing the conditional entropy of the source dependent mixture weight s and the entropy of the source priors.
 Since the dictionary is already known and is given by the norm alized spectral frames from source training spectrograms, the parameter to be estimate d is given by P t ( z, s ). The model, written in terms of this parameter, is given by Expectation-Maximization algorithm to derive the update e quations. Let all parameters to be estimated be represented by  X . We impose an entropic pri or distribution on P t ( z, s ) Figure 3: Using a sparse reconstruction on the data in figure 2 . Note how in contrast to that figure the source estimates are now identified as training dat a points, and are thus plausible solutions. The approximation of the mixture is the nearest p oint of the line connecting the two source estimates, to the actual mixture input. Note that the proper solution is the one that results in such a line that is as close as possible to the m ixture point, and not one that is defined by two training points close to the mixture. given by where  X  is a parameter indicating the extent of sparsity desired. Th e E-step is given by and the M-step by where we have let  X  represent P f v ft P t ( s, z | f ) and  X  t is the Lagrange multiplier. The above M-step equation is a system of simultaneous transcend ental equations for P t ( z, s ). Brand [13] proposes a method to solve such problems using the Lambert W function [14]. It can be shown that P t ( z, s ) can be estimated as Equations (6),(7) form a set of fixed point iterations that ty pically converge in 2-5 iterations [13].
 Once P t ( z, s ) is estimated, the reconstruction of source s can be computed as Now let us consider how this problem resolves the issues pres ented in figure 2. In figure 3 we show the results obtained using this approach on the same d ata. The sparsity parameter  X  as set to 0 . 1. In both plots we see that the source reconstructions lie on a training point, thereby being a plausible source estimate. The approximati on of the mixture is not as exact as before, since now it has to lie on the line connecting the tw o active source elements. This is not however an issue of concern since in practice the a pproximation is always good enough, and the guarantee of a plausible source estimate is m ore valuable than the exact approximation of the mixture.
 Alternative means to strive towards similar results would b e to make use of priors such as in [15, 16]. In these approaches the priors are imposed on the mixture weights and thus are not as effective for this particular task since they still suffer from the symptoms of learned-basis models. This was verified through cursory sim ulations, which also revealed an additional computational complexity penalty against such models. Figure 4: An oracle case where we fit training data from two spe akers, on the mixture of that data. The top plots show the input waveforms, and the b ottom plots shows the estimated weights multiplied with the source priors. As exp ected the weights exhibit two diagonal traces which imply that the algorithm we used has fit the data appropriately. In this section we present the results of experiments done wi th real speech data. All of these experiments we performed on data from the TIMIT speech datab ase on 0dB male/female mixtures. The sources were sampled as 16 kHz, we used 64 ms win dows for the spectrogram computation, and an overlap of 32 ms. Before the FFT computat ion, the input was tapered using a square-root Hann window. The training data was aroun d 25 sec worth of speech for each speaker, and the testing mixture was about 3 sec long. We evaluated the separation performance using the metrics provided in [17]. These metri cs include the Signal to Inter-ference Ratio (SIR), the Signal to Distortion Ratio (SDR), a nd the Signal to Artifacts Ratio (SAR). The first is a measure of how well we suppress the interf ering speaker, whereas the other two provide us with a sense of how much the extracted sou rce is corrupted due to the separation process. All of these are measured in dB and the hi gher they are the better the performance is deemed to be.
 In the following sections we first present some  X  X racle tests  X  that validate that indeed this algorithm is performing as expected, and we then procee d to more realistic testing. Finally, we show the performance impact of pruning the train ing data in order to speed up computation time. 3.1 Oracle tests In order to verify that this approach works we go through a few oracle experiments. In these tests we include the actual solutions as training data and we make sure that the answers are exactly what we would expect to find. The first experiment we pe rform is on a mixture for which the training data includes its isolated constituent s entences. In this experiment we would expect to see two dictionary components active at each point in time, one from each speaker X  X  dictionary, and both of these progressing throug h the component index linearly through time. As shown in figure 4, we observe exactly that beh avior. This test provides a sanity check which verifies that given an answer this algorit hm can properly identify it. A more comprehensive oracle test is shown in figure 5. In this e xperiment, the training data were again the same as the testing data. We averaged the r esults from 10 runs using different combinations of speakers, varying sparsity param eters and number of bases. The sparsity parameter  X  was checked for various values from 0 to 0.8, and we used train ed-basis models with 5, 10, 20, 40, 80, 160 and 320 bases, as well as the p roposed scenario where all the training data is used as a dictionary. The primary obs ervation from this experiment is that the more bases we use the better the results get. We als o see that increasing the sparsity parameter we see a modest improvement in most cases . Figure 5: Average separation performance metrics for oracl e cases, as dependent on the choice of different number of elements in the speaker X  X  dicti onary, and different choices of the entropic prior parameter  X  . The left plot shows the SDR, the middle plot the SIR, and the right plot the SAR, all in dB. The basis row labeled as  X  X ra in X  is the case where we use all the training data as a basis set. Figure 6: Average separation performance metrics for real-world cases, as dependent on the choice of different number of elements in the speaker X  X  dicti onary, and different choices of the entropic prior parameter  X  . The left plot shows the SDR, the middle plot the SIR, and the right plot the SAR, all in dB. Sparsely using all of the tra ining data clearly outperforms low-rank models by a significant margin on all metrics. 3.2 Results on Realistic Situations Let us now consider the more realistic case where the mixture data is different from the training set. In the following simulation we repeat the prev ious experiment, but in this case there are no common elements between the training and testin g data. The input mixture has to be reconstructed using approximate samples. The resu lts are now very different in nature. We do not obtain such high numbers in performance as i n the oracle case, but we also see a stronger trend in favor of sparsity and the use of all the training data as a dictionary. The results are shown in figure 6. We can clearly s ee that in all metrics using all the training data significantly outperforms trained-basis models. More importantly, we see that this is not because we have a larger dictionary. For trai ned-bases we see a performance peak at around 80 bases, but then we observe a deterioration i n performance as we use a larger dictionary. Using the actual training data results i n a significant boost though. Due to the high dimensionality of the data the effect of sparsity i s a little more subtle, but we still see a helpful boost especially for the SIR which is the most im portant of the performance measures. We see some decrease in the SAR, which is expected s ince the reconstructions are made using elements that look like the remaining data, and ar e not made to approximate the actual input mixture. This does not mean that the extract ed sources are distorted and of poor quality, but rather that they don X  X  match the origina l inputs exactly. The use of sparsity ensures that the output is a plausible speech signa l devoid of artifacts like distortion and musical noise. The effects of sparsity alone in the propos ed case are shown separately in figure 7. Figure 7: A slice of the results in figure 6 in which we only show the case where we use all the training data as adictionary. The horizontal axis re presents various values for the sparsity parameter  X  . Figure 8: Effect of discarding low energy training frames. Th e horizontal axis denotes the percentage of training frames that have been discarded. The se are averaged results using a sparsity parameter  X  = 0 . 1.
 The unfortunate side effect of the proposed method is that we n eed to use a dictionary which can be substantially larger than otherwise. In order t o address this concern we show that the size of the training data can be easily pruned down to a size comparable to trained-basis models and still outperform them. Since sound signals , especially speech, tend to have a considerable amount of short-term pauses and regions of si lence, we can use an energy threshold to in order to select the loudest frames of the trai ning spectrogram as bases. In figure 8 we show how the separation performance metrics are in fluenced as we increasingly remove bases which lie under various energy percentiles. It is clear that even after discarding up to at least 70% of the lowest energy training frames the per formance is still approximately the same. After that we see some degradation since we start di scarding significant parts of the training data. Regardless this scheme outperforms trai ned-basis models of equivalent size. For the 80% percentile case, a trained-basis model of t he same size dictionary results in roughly half the values in all performance metrics, a very significant handicap for the same amount of computational and memory requirements.
 The experiments in this paper were all conducted in MATLAB on an average modern desk-top machine. Overall computations for a single mixture took roughly 4 sec when not using the sparsity prior, 14 sec when using the sparsity prior (pri marily due to slow computation of Lambert X  X  function), and dropped down to 5 sec when using t he 30% highest energy frames from the training data. In this paper we present a new approach to solving the monopho nic source separation problem. The contributions of this paper lies primarily in t he choice of using all the training data as opposed to a trained-basis model. In order to do so we p resent a sparse learning algorithm which can efficiently solve this problem, and also g uarantees that the returned source estimates are plausible given the training data. We p rovide experiments that show how this approach is influenced by the use of varying sparsity constraints and training data selection. Finally we demonstrate how this approach can gen erate significantly superior results as compared to trained-basis methods. [1] S. T. Roweis, One microphone source separation, in Advan ces in Neural Information [2] Reddy, A.M. and B. Raj. Soft Mask Methods for Single-Chan nel Speaker Separation, in [3] T. Kristjansson, J. Hershey, P. Olsen, S. Rennie, and R. G opinath, Super-human multi-[4] Casey, M.A., and A. Westner. Separation of mixed audio so urces by independent sub-[5] Jang, G.-J., T.-W. Lee. A Maximum Likelihood Approach to Single-channel Source [6] Pearlmutter, B., M. Zibulevsky, Blind Source Separatio n by Sparse Decomposition in a [7] L. Benaroya, L. M. Donagh, F. Bimbot, and R. Gribonval, No n negative sparse repre-[8] M. N. Schmidt and R. K. Olsson, Single-channel speech sep aration using sparse non-[9] T. Virtanen, Sound source separation using sparse codin g with temporal continuity [10] Smaragdis, P. Raj, B. and Shashanka, M.V. 2007. Supervi sed and Semi-Supervised Sep-[11] Raj, B.; Smaragdis, P. 2005. Latent Variable Decomposi tion of Spectrograms for single [12] Shashanka, M.V., B. Raj, P. Smaragdis, 2007. Sparse Ove rcomplete Latent Variable [13] Brand, M.E. Pattern Discovery via Entropy Minimizatio n. In Uncertainty 99, AIS-[14] Corless, R.M., G.H. Gonnet, D.E.G. Hare, D.J. Jeffrey, a nd D.E. Knuth. On the Lam-[15] Bouguila N. and D. Ziou. Using unsupervised learning of a finite Dirichlet mixture [16] Hinneburg, A., Gabriel, H.-H. and Gohr, A. Bayesian Fol ding-In with Dirichlet Kernels [17] F  X evotte, C., R. Gribonval and E. Vincent. 2005. BSS EVA L Toolbox User Guide, IRISA
