 1. Introduction
A foreign word can be translated into Chinese in different regional variants, such as  X  X  X axi X  becomes  X  X  forward certain meaning that can be appreciated by native people ( Li, Sim, Kuo, &amp; Dong, 2007 ).The forward connotation and different Chinese variants in different Chinese-speaking communities or regions. For example, the movie Shrek becomes  X  X   X  /Shi-Rui-Ke/ X  in Taiwan and  X  X   X   X   X  /Shi-Lai-Ke/ X  in China. In many natural language processing applications, we have to deal with such regional transliteration variants, which are always out of vocabulary (OOV) and have become a hindrance to be ad-dressed. A big transliteration lexicon would help us address this problem. However, new words emerge every day and it is not to automatically construct a transliteration lexicon of regional variants from the Web, which is a live source of new words.  X 
Transliteration extraction, which is one of the main themes in transliteration research, can be used to automatically con-struct a transliteration lexicon in a short period and help explore the underlying collective intelligence of transliterations, which is seldom reported in the literature and will be addressed in this paper. The other theme of interest, transliteration modeling, on the other hand, has focused on the generative transliteration models ( Knight &amp; Graehl, 1998; Li, Zhang, &amp;
Su, 2004; Meng, Lo, Chen, &amp; Tang, 2001 ) which re-write a foreign word into the native alphabets. The generative modeling technique is found useful in handling OOV words including personal names, place names and technical terms, in tasks such erally hinges on a manually validated bilingual lexicon, which is not easily available.

A large bilingual lexicon labeled and examined by human experts may not be available for all languages. However, label-ing a hundred of samples is feasible. Exploiting these samples, we proposed a cross-learning algorithm for transliteration extraction with self-training capability ( Abney, 2008 ), which aims at learning transliteration information across related re-gional corpora or text sets from the live Web.

The Web is one of the largest text corpora for OOV named entities. It is also multilingual in nature and offers real-world transliterations every day. The challenge here is that these transliterations are not well-organized in a structured manner and at the same time they are artifacts created by many individuals across the globe, which inherently manifest regional variation as a result of cultural difference. The question is how to harvest those transliterations without much human inter-vention. Many efforts have been devoted to acquiring transliterations from the Web for pairs of languages, such as English X  and English X  X hinese ( E X  X  )( Kuo et al., 2007 ). However, there are not many studies on automatically acquiring transliteration three elements includes an English word and its regional variants, such as Shrek , X  X  Shi-Lai-Ke/ X  (China). The next question we face is how to recognize where a transliteration comes from.

The Web domain names, such as  X  X .cn X  (for China) and  X  X .tw X  (for Taiwan), provide us with a natural labeling of geograph-simply use English words as the pivot to construct a lexicon of transliteration variants. In this paper, we consider the trans-literation extraction in this manner as the basic method. Bringing this rudimentary technique a step forward, we further pro-pose exploiting domain knowledge encoded in a transliteration model and predictive query suggestions ( Kamvar &amp; Baluja, 2008 ) offered by search engines to guide the Web search to accumulate related documents in a more efficient way. It is ex-pected that applying such knowledge to transliteration extraction is helpful and in turn helps collect more transliterations to grasp transliteration variation.

To understand transliteration variation and the collective intelligence of transliterations, we also conduct an inquiry into implication. We observed that in spite of cultural difference that results in transliteration variation among communities, some transliterations are also commonly used across the regions. For example,  X  X  wan and China. This implies that the transliterations used in different communities may reveal certain level of inter-regional influence. The extent of inter-regional influence can be estimated by measuring the degree of association from the extracted point of transliterated words.

This paper is organized as follows. In Section 2 , we briefly introduce related work. In Section 3 , we present how to apply knowledge into query formulation to guide the search. In Section 4 , we propose a cross-training strategy, which exploits the pora for cross-training. In Section 6 , we conduct experiments to validate the effectiveness of the proposed algorithms for learning regional transliteration variants and discuss some observations from the databases themselves. Finally, we conclude in Section 7 . 2. Related work
Learning regional transliteration lexicons involves both transliteration modeling and extraction. The former allows us to we focus on the retrieval techniques and adopt the phonetic similarity model (PSM) ( Kuo et al., 2007 ) to validate each ex-tracted transliteration pair. PSM is also called transliteration model in this paper. Next we briefly introduce the prior work related to transliteration extraction.

There have been many attempts to extract translations or transliterations from the Web, for example, by exploring query them are for terms of a pair of languages. Cheng et al. (2004) proposed a transitive translation method by exploiting for-ward X  X ackward collocation information and using English as a pivot language to construct a regional translation lexicon.
However, this method relies completely on collocation information which is more suitable for translation variants than transliteration ones.

Some recent studies use information retrieval (IR) techniques for transliteration extraction. Sproat et al. (2006) exploited both phonetic similarity and temporal distribution to identify named entities in comparable corpora. Kuo et al. (2007) and
Lin, Zhao, Durme, and Pasca (2008) advocated a method to explore English appositive words in the proximity of Chinese proper nouns in language-mixed texts, also known as parenthetical translation . Phonetic similarity, temporal correlation and parenthetical translation are shown to be informative clues for finding transliterations. Searching for transliterations from the Web, transliteration extraction is also known as transliteration retrieval.

In transliteration retrieval or Web-based transliteration extraction, it is always necessary to construct a snippet database, which consists of many query results. Kuo, Li, and Yang (2008) proposed compiling such a corpus from search engines in a random surfing manner over the Web. There are 100 snippets at most in each query result. Note that it is important to incor-porate as many representative transliteration candidates as possible into the corpus. Li, Bai, and Kuo (2006) , on the other hand, without crawling a snippet database, proposed exploiting the Web statistics directly by using an E X  X  word pair as a joint E X  X  query for re-ranking so as to validate whether the E X  X  word pair is a genuine transliteration of each other. It was found that it is helpful to make use of the live statistics about transliterations to improve the transliteration model.
We can extend the idea in another way to improve transliteration extraction by incorporating the information from trans-1996 ), which has been successfully used in information retrieval to overcome the query/document mismatch problem. Here we use transliteration candidates as one of the constraints in crawling required databases. The problem is how to generate quality transliteration candidates so as to find the target transliterations. In this way, we propose a method for guiding the search towards the target transliterations. 3. Guided search
Constraint-based learning algorithms ( Chang, Ratinov, &amp; Roth, 2007 ), which incorporate constraints or domain knowl-edge into the selection of candidates, have been successfully used in information extraction. The idea can also be applied to transliteration extraction especially in creating databases. In Web-based information retrieval, many documents are in-dexed by search engines; however, search queries are usually too short to reflect users X  intentions. It remains a challenge introducing constraints that incorporate knowledge to formulate the queries in transliteration extraction. Now the problem is what kind of knowledge is useful and how to include them. Transliteration modeling represented by the phonetic simi-larity model encoding knowledge and deducing mapping rules of basic pronunciation units from the transliteration samples in the training pool is an excellent candidate. As to how to incorporate the knowledge from transliteration modeling, taking an English word  X  X  X bby X  as input, the generative model outputs Chinese transliteration candidates,  X  X 
A-Bi/ X ,  X  X   X   X   X  /Ai-Bu-Bi/ X ,  X  X   X   X  /Ai-Bi/ X  and  X  X   X   X   X  to validated real-world transliterations ( Kuo et al., 2009 ). Then, the queries can be formed by augmenting the English word to guide the search in collecting required databases from search engines for transliteration extraction. Therefore, we expect to improve the performance of transliteration extraction either in quality or in quantity. We call this way of constructing corpora by biasing generation of snippets towards the target transliterations guided search. This is because submitting a web-based query may obtain hundreds or even thousands snippets, but transliterations may not appear in the first top-n (for example, 100) snippets.

Furthermore, the statistical co-occurrence information compiled from a large corpus attests semantic knowledge for find-ing translation candidates, which has been studied in cross-lingual information retrieval ( Cheng et al., 2004 ). The co-occur-rence statistics can also be used as another kind of constraint in the guided search. To capture such information, we have to
An alternative resource is the predictive query suggestions ( Kamvar &amp; Baluja, 2008 ), which are found in most of the Web-based search engines, such as Google 2 and Yahoo!. 3 It provides look-ahead suggestions as shown in Fig. 1 according to the statistics, which in turn gathered from query logs, when users are formulating their queries.

Apparently we can exploit the knowledge from such a query log directly, guiding the search to collect pages of interest, or pages containing transliterations. We conduct a simple experiment at the time of preparing this paper (September- X 09) by submitting  X  X  X acob X  (submission #1 for easy reference) and  X  X  X acob Black X  (submission #2 for easy reference), where  X  X  X acob X  is the target word and  X  X  X lack X  is the accompanying word, to Google with Taiwanese ( X  X .tw X ) pages only and find that there are 134,000 and 17,900 pages matched, respectively. Though, submission #1 receives more snippets; however, when we man-using expanded keywords might achieve a higher top-n precision, which only takes top-n snippets into consideration in measuring the precision instead of all when receiving limited number of snippets, than that of a single word in a Web-based search engine. This is generally true because there are so many matched documents with a single word on the Web. Note that the accompanying words or phrases to the target word may be in English, Chinese, Japanese or other languages in the predictive suggestion list.

The process of collecting pages from the Web is called crawling ( Cheong, 1996; Cho, Garcia-Molina, &amp; Page, 1998 ). Two crawling algorithms are proposed in this paper: (1) crawling in a random surfing manner by following the collected links as described in Kuo et al. (2008) is called autonomous exploration (AE) as described in Table 1 ; (2) the guided search-based crawling exploiting certain constraints, such as transliteration modeling, which has focused on generating transliteration candidates, or predictive query suggestions, is called constraint-based exploration (CBE) as described in Table 2 and can be illustrated in Fig. 3 .

In the AE procedure, we start with a small set of transliteration pairs as seed pairs to bootstrap the initial phonetic sim-ilarity model (PSM). The PSM is used to measure the phonetic similarity between an E X  X  pair of words. We also use the Eng-ries for the new Web search. In this way, we submit queries and validate the extraction returns with the PSM. This process allows us to discover new transliteration pairs, such as  X  X  X ucas- X  X  X obert. X 
Note that the retrieved snippets may contain both true and false transliteration pairs. The PSM model acts as a filter to screen out the false pairs. As AE procedure searches the space in a random walk manner, the retrieved results may not relate we can launch an AE crawler at each regional Web division independently. The returns that share the common English word form tuples of transliteration variants.

The independent AE-based crawling results from different crawlers do not guarantee anchoring at the same set of English words. To increase the possibility of desired query returns, we suggest generating transliteration candidates and exploiting the predictive information from search engines for a foreign word to expand the query. In this way, we first either generate the quasi transliterations or obtain suggestion terms for different regions, which then serve as the hints for CBE-based crawl-than no hint at all and helps find the target.

As described in Table 2 , we expand the common set of English words with generated regional transliterations or sugges-literation corpora that share common English words, the Chinese transliterations anchored English word  X  X  X eles X  are generated by regional transliteration models, respectively, to guide the crawling. It is ex-pected that such CBE-based techniques exploiting the above-mentioned phonetic and query-log-based knowledge will bring us benefits towards finding the target transliteration for a foreign word.
 will be helpful if we can learn transliteration information from one regional corpus and exploit the information for learning transliterations in another regional corpus. To this end, we propose a cross-training learning framework that learns PSM (Phonetic Similarity Model) parameters from regional corpora through a guided search. 4. Cross-training learning framework It is common that in Chinese/Japanese/Korean predominant webpages, English words are used in parentheses near to the
Chinese/Japanese/Korean transliterations to serve as appositive in a sentence as in Fig. 4 . We adopt the strategy, known as collocation. Then, we validate the candidates by using phonetic similarity clue in a hypothesis test. This algorithm was pro-tion of transliteration variants by formulating it in an unsupervised and cross-learning framework. 4.1. Unsupervised learning
The learning of PSM (phonetic similarity model) transliteration model takes place as we extract transliterations. Let us recap how it works for a single language pair in Table 3 . This algorithm works in an unsupervised manner with minimum human intervention. Now let us extend the algorithm in Table 3 to account for regional variation of transliterations. We carry out unsupervised learning over the regional divisions of the snippet database  X  query returns from Region #1 and query re-turns from Region #2, as shown in Fig. 4 . The transliterations which share the common English words form a transliteration tuple. 4.2. Cross-training correlated classes. It considers each data set as a view to the problem to let classifiers help each other. Cross-training was used successfully in creating an integrated directory from multiple Web directories, such as Yahoo! Directory recommendation ( Yang, Chen, &amp; Wu, 2008 ).

Given an E X  X  regional lexicon, we would like to use cross-training to exploit the information available in different regio-nal data sets to boost the learning of PSM parameters. Specifically, we expect the PSM learning from Region #1 corpus will help boost the PSM learning of Region #2 corpus, and vice versa, as shown in Fig. 5 .

We propose a cross-training algorithm that employs two learners (see the upper and lower panels in Fig. 5 ) with two data sets for simplification. Each learner can learn from a regional data set and run in an unsupervised manner as in Table 3 . The cross-training allows the two learners to exchange their correlated information over the problem in a collaborative learning process. It can be seen as an extension of the unsupervised learning, as summarized in Table 4 .

In order to validate the usefulness of regional transliteration corpora for cross-training algorithm, we investigate the re-gional social association between several Chinese-speaking communities in next section. 5. Regional social association by transliterations
Web-based search engines have tried to meet users X  information needs by exploiting various kinds of resources such as search engines independently by individuals. They stand for the information needs to each user and hence have been used to buzzwords, the information however is not easily accessible to the public. Note that buzzwords usually consist of various kinds of terms, such as personal names (native or transliterated), place names, organization names or even just a sequence of words but being searched frequently. In this way, transliterations of high frequency may appear in the regional buzzword list.
A recent initiative, Linguistic Variations in Chinese Speech Communities (LIVAC usage of words including new terms and personal names and to obtain information such as the talking points across regions. As the LIVAC synchronous corpus is rich in regional Chinese terms, one is able to leverage on this initiative by harvesting trans-literations automatically and gaining insights into the social association among those Chinese-speaking communities.
Due to dialectal and cultural difference, each foreign name may have several distinctive transliterations. On the other hand, different regions often adopt common transliterations as a result of interflow of information. Therefore, translitera-between regions. One can argue that the more transliterations are shared by two regions, the more closely two regions asso-ciate. In this way, we can measure the social association strength (SAS) between two regions by transliteration statistics. The question is how to acquire enough transliterations with a broad coverage. The Web is a live resource consisting of huge transliterations and covers many topics than any available parallel corpus, such as Canadian We believe that exploring the transliterations from the Internet can make the estimation more accurate. We also found that if a same or most likely similar. The PSM model used in this paper exploits statistical information and may erroneously acquire some transliterations due to incomplete model parameters. Therefore, based on this observation, we can measure the social association strength using all the extracted transliterations no matter whether they are genuinely validated correct or not.
To conduct the experiment on observing the regional social association on transliterations, we explored the Web by intu-itively using AE ( autonomous exploration ) procedure, which crawls pages in a random walk manner. In this way, we collected a corpus of query results for each region and hence named each corpus according to the domain name, i.e, CN (Chinese, .cn), TW (Taiwan, .tw), HK (Hong-Kong, .hk), MO (Macau, .mo), MY (Malaysia, .my), SG (Singapore, .sg) and CA (Canada, .ca).
Although Chinese is used in these regions, each region has its own official spoken languages and scripts, both strongly affect the rendering of transliterations. For example, Mandarin is the main spoken language in China and Taiwan and the secondary spoken language in Hong-Kong, Macau, Malaysia and Singapore. Most of the Chinese Web pages from Taiwan and Hong Kong are in traditional Chinese, while those from China, Macau, Malaysia and Singapore are in simplified Chinese. sure as possible as we can, we try to crawl about 450,000 pages in each region corpora indicated by domain names are compiled using AE. The statistics including the number of pages, corpus size in GB (giga-source word and its candidate transliteration for comparison in the paper, to measure the social association strength .
To investigate the regional social association, we further divide the association strength into two categories, i.e., intra-re-convergence of a corpus. Then, we look into the inter-regional strength , which measures the association between two regional transliteration corpora. 5.1. Intra-regional strength
The intra-regional strength denotes the convergence of a corpus. The fewer transliteration variants there are, the higher association strength is. In Kuo et al. (2007) , they observed that about 35.88% of English words consisting of multiple Chinese transliterations in a corpus collected from Taiwan region only. We are interested to see whether the transliteration variation fine the transliteration variation as: where n is a positive integer denoting the minimum number of variants of an English word considered as a variation. Hence the intra-regional strength can be in turn expressed as Eq. (2): In this way, we report the strength and variation (with n = 2, 3 and 5) on collected transliteration variants as shown in
Table 6 . From Table 6 , we can see that there are 62.308%, 69.212%, 62.586%, 62.544%, 63.017%, 62.459% and 61.023% of Eng-lish words consisting of only one transliteration in CN, HK, MO, MY, SG, CA and TW corpora, respectively, if the intra-regional convergence of each corpus is measured in strength. In other word, if it is measured in variation with n = 2, then there are 37.692%, 30.788%, 37.414%, 37.456%, 36.983%, 37.541% and 38.977% of English words with at least two variants in CN, HK,
MO, MY, SG, CA and TW corpora, respectively. The statistics of transliteration variation cross regional corpora are consistent with that of Kuo et al. (2007) and generally span from about 30% to 40% among several Chinese-speaking communities. To our astonishment, on average about 10% of English words consist of five or more Chinese transliteration variants as shown in ent from the report in Kuo et al. (2007) on labeled transliterations, which are genuinely validated correct. 5.2. Inter-regional strength To calculate inter-regional strength , we propose using the forward X  X ackward mutual information (FBMI) ( Saon &amp;
Padmanabhan, 2001 ), which was used for extracting multi-word phrases and is used for measuring the degree of association between two sample sets here, as shown in: where X and Y are sets of distinct transliteration pairs extracted from regional corpora C correlated; or otherwise.

The FBMI between different corpora are shown in Table 7 . We can have several observations from this table: (1) HK does not closely associate with other corpora. This might be because Cantonese is dominantly used in Hong Kong; whereas Man-darin Chinese is commonly used in other regions. As a result, the SAS ( social association strength ) between HK and other cor-pora are similarly low; (2) MO, MY, SG and CA are closely associated with CN. This might be due to the fact that these referred regions have adopted simplified Chinese for years, and that allows the local press to have easy access to information from China; (3) Taiwan is evenly interconnecting with other regions except Hong Kong due to different dialects.
In view of the observations above, we can roughly categorize the collected regional corpora into three groups according to their languages and scripts, i.e., (1) HK; (2) TW; and (3) CN, MO, MY, SG and CA, where Hong-Kong adopts traditional Chinese characters and Cantonese; Taiwan also adopts traditional Chinese characters but Mandarin Chinese; on the other hand, the rest regions adopts simplified Chinese characters and Mandarin Chinese in common;
Geographically, China is close to Taiwan, Hong-Kong and Macau. They share common cultural background and hence should associate closely. However, from Table 7 , it suggests that Taiwan does not associate with China as tightly as Malaysia and Singapore do. This might be due to (1) the adoption of different characters in rendering as observed in Table 9 ; (2)
Taiwanese translators tend to transliterate foreign terms into Chinese in different ways as evidenced in Table 10 ; (3) the imperfect one-to-many conversion from simplified Chinese to traditional Chinese in comparing regional transliterations.
In Table 7 , each region is in association with other regions to some extent. This implies that the information in one region may be useful to the learning of model parameters in another region. Therefore, it is reasonable to expect that using the cross-training algorithm presented in Section 4 to learn transliterations may achieve better performance than that without exploiting other regional information.

To see the effectiveness of cross-training algorithm on learning transliteration variants, we select CN and TW as target corpora because China and Taiwan are found to be two typical communities with rather unique characteristics of translit-eration variants. Note that the effectiveness is evaluated on labeled data, which consist of genuinely validated correct trans-literations as the ground truth that are prepared manually. 6. Extraction of transliterations
To construct a regional lexicon from the Web, we need to obtain a collection of snippets that are rich in transliterations of interest. We exploit two different crawling techniques as described in Section 3 : the autonomous exploration (AE), which is the basic approach for crawling in a random surfing manner described in Kuo et al. (2008) , and the constraint-based explo-ration (CBE), which exploits results either from the generative transliteration model, (CBEg) or predictive suggestions by the we can now move on with learning the PSM model and construction of regional lexicons.
 With the AE procedure, we first construct a snippet database D which consists of 335,010 files in traditional Chinese; and CN nese. Each of these files or pages has at most 100 snippets. Most of them are Chinese words mixed with English ones as seen in Fig. 4 .

With the CBE procedure, we select top-1000 boy X  X  and girl X  X  names of year 2006 from American Social Security Online.
There are 1942 unique names in total. Then, we generate top-20 Chinese candidates using CBEg and top-10
CBEs for each English name. In this way, we obtain 77,680 E X  X  pairs by CBEg and 38,840 E X  X  pairs by CBEs, respectively. In practice, each pair is submitted to regional Web through a search engine. Specifically, with CBEg we obtain 38,840 returning files in traditional Chinese from .tw domain also called TW also called CN CBEg(20) . Each file has at most 100 snippets in this corpus. This database is called D obtain 19,420 returning files in traditional Chinese from .tw domain also called TW D
To establish the ground truth for performance evaluation, we only select first 500 files in the crawling sequence from each data set for manual labeling. 14 This results in a reduced data set, D D CBEs-500(3) with top-3 candidates. For ease of reference, we summarize the statistics of the corpora in Table 8 . Note that D is a condensed corpus consisting of two respective data sets, TW D
CBEg (20) , also in turn consists of two data sets, TW CBEg-500(3) suggests 6176, 76,850 and 35,022 valid pairs, with 3118, 22,330 and 10,999 distinct pairs, for D D
CBEs-500(3) , respectively. Note that no organization can provide the gold standard of Web corpora required in this paper for benchmarking. Therefore, we adopt the process of manually labeling transliterations described in Kuo et al. (2007, 2008) to create the gold standard for performance evaluation.

We report the performance in F -measure, which is used to evaluate the performance of extracting transliterations of each regional corpus and validate the effectiveness of proposed algorithms, described in: where precision is defined as the ratio of extracted number of DQTPs (distinct qualified transliteration pairs), which have been manually labeled as correct, over that of total extracted pairs and recall is defined as the ratio of extracted number of DQTPs over that of total DQTPs. Eq. (4) measures the performance of learning regional variants on a pair basis similar to that in single language pair. Note that some method may outperform the other methods in precision but not in recall or vice versa. However, high precision sometimes may mean that only a small number of genuinely correct samples are har-vested if recall is not examined. Therefore, we propose evaluating the effectiveness in a balanced manner, i.e., in F -measure. 6.1. Unsupervised learning on AE database
As discussed in Section 4.1 , we first derive an initial PSM using randomly selected 100 seed DQTPs for a learner and sim-
DQTP pool; (iii) re-estimate the PSM for each data set separately by using the updated DQTP pool. We evaluate performance on the D AE-500 database from Sections 6.1 X 6.3 for comparison.

To construct a regional lexicon, we run the extraction over each data set independently in unsupervised learning and then use English as the anchor to establish the transliteration tuples. We run multiple iterations of unsupervised learning. At 6th 6.2. Cross-training on AE database
Mandarin Chinese has been used prevalently in Taiwan and China and people in the two regions do not follow the same nese-speaking communities are similar. We expect the phonetic features from multiple regional sets will help each other X  X  learning as in Fig. 6 .

With cross-training, we run the same procedure as in Section 6.1 for each of the regional data sets in parallel. Then, we can re-estimate the PSM of each learner with the transliterations extracted by the learner itself plus those extracted by the unsupervised learning (UL) and cross-training (CT). The results show that the collaborative cross-training attains higher F -measure (0.510) (precision: 0.811, recall: 0.372) than independent unsupervised learning (0.475). This suggests that cross-training benefits from learners exchanging information with the other. 6.3. Cross-training on CBE databases As discussed in Section 3 , the independent AE-based crawling does not guarantee the returns anchoring at the same set of
English words. This will result in an inefficient process when compiling the tuples of regional variants. The CBE-based crawl-abases, namely CBEg and CBEs, are collected and the experiments conducted are described in the following sections. 6.3.1. Exploring the database collected by CBEg
We conduct the unsupervised learning on D CBEg-500(3) as shown in Fig. 7 . We report the F -measure for top-1 and top-3 results. At the 6th iteration, the F -measure on D CBEg-500(3) noted as ULg(3), are 0.540 and 0.551 (precision: 0.812, recall: 0.417), respectively, which outperform that on AE database.
Note that ULg( n ) denotes the experiment conducted using unsupervised learning on the database collected by CBEg with top-n candidates. We follow the same convention hereafter in the paper for learning approaches using unsupervised learning (UL) and cross-training (CT) and for crawling methods using CBEg and CBEs.
 We further conduct an experiment with cross-training and report the performance of cross-training on D represents the best performance so far. 6.3.2. Exploring the database collected by CBEs
We also conduct the unsupervised learning on D CBEs-500(3) from search engines, as shown in Fig. 9 . We report the F -measure for top-3 results. At the 6th iteration, the F -measure on D
CBEs-500(3) with top-3 candidates, denoted as ULs(3), is 0.576 (precision: 0.877, recall: 0.429), outperforming that on CBEg database.
 We then further conduct an experiment with cross-training and report the performance of cross-training on D with top-3 candidates, CTs(3), in Fig. 10 . At 6th iteration, the F -measure by CTs(3) is 0.607 (precision: 0.873, recall: 0.465), which achieves the best performance. It also reveals that the performance on CBEs database is continuously better than that on CBEg.

It is observed that the experiments on databases collected by CBE (CBEg and CBEs) show better results than those on AE database. This is because the independent AE-based crawling results from different crawlers do not guarantee chaining to the same set of English words. Cross-training also consistently outperforms unsupervised learning in all cases because cross-training can learn helpful transliteration information from other corpus. The performance of harvesting regional trans-regional transliteration variants are the intersection of transliterations across two or more single language pairs that share the common English words.
 It is also noted that the experiments on CBEs databases achieves better performance in terms of F -measure than those on
CBEg. The predictive suggestion terms used in CBEs are generally of high frequency according to the statistics from query logs and click-through data ( Joachims, 2002 ), which are recorded by search engines when users browse the original pages of interest. The search engines would like to favor these query terms to meet users X  information needs. It is therefore highly possible that the expanded query terms with clue words may have a higher chance to appear in mixed-lingual snippets, where the source foreign words tend to be transliterated into a target language, such as Chinese. In this way, the source words are always collocated with their candidate transliterations in the snippets.

Also note that we propose algorithms for harvesting regional transliterations by exploring the Web. Data on the Web are generally so noisy and need to be rectified. It may be easy for human being to find out a transliteration pairs; however, it is not easy for computer programs to discover the quality transliterations even though parenthetical clues are used. 6.4. Learning from the web
We have conducted several experiments on a local database. It would be interesting to see how the proposed algorithm works directly on the Web. We conduct an experiment using the same 100 seed pairs as described in Section 6.1 to train an the whole corpus and hence we cannot calculate the F -measure on this corpus; therefore, we only report the estimated pre-cision by randomly sampling 500 tuples. There are 12,033 distinct tuples (43,369 distinct pairs) extracted, with the esti-mated precision of 0.834 on a tuple basis or 0.894 on a pair basis. The expected correct tuples (pairs) are 10,036 (38,768).
Note that we use the full D CBEg(20) database and run one iteration to simulate the Web learning process instead of in incre-mental mode. In an incremental learning algorithm, PSM model can observe transliterations from incoming snippets on-the-fly and PSM parameters can update frequently ( Li, Kuo, Su, &amp; Lin, 2008 ). However, the PSM parameters in the experiments conducted in Sections 6.1 X 6.3 are updated after observing the whole corpus in each iteration. Therefore, to simulate the incremental learning, the PSM here is created only at the initial stage without any update. Some selected entries of the re-gional transliteration lexicon are shown in Table 9 . 6.5. Discussion
To understand transliteration variation and the collective intelligence of transliterations, we also conduct an inquiry into implication. As we state in Section 3 that accents and cultural preference affect the transliteration rendering most across re-gions. The accents closely relate with the pronunciations and hence the generated characters, e.g.,  X  X  X ush X  can be rendered into  X  X   X  X  X  /Bu-Xi/ X  in Taiwan and  X  X   X   X  /Bu-She/ X  in China, respectively, depending how the incomplete syllable/sh/is pro-nounced. The cultural preference affects the translation/transliteration conventions adopted in a region. For example, a Chi-nese surname is always given as part of its Chinese transliteration for a foreign name. One example about this cultural preference is depicted in the transliterations of  X  X  X ino X  in Table 9 , where both of the rendered characters  X  X 
Ji/ X  are Chinese family names with the same pronunciations but different ideographs. From the above observations, it is clear that both accents and cultural preference collectively affect the character rendering and hence transliteration.
The statistics over regional transliteration variants may help understand these two factors and the underlying character-istics of them. We conduct an inquiry into the labeled data, D as the average number of transliterations, character connotation and correlation at whole word level, towards this end.
In Table 10 , we report the average number of Chinese transliterations for an English word (#Trans). It shows that Taiwan databases that adopt traditional Chinese characters have higher numbers of transliteration variants per English word than China databases that adopt simplified Chinese characters. It suggests that transliterations are less regular in Taiwan. From Table 10 , we can expect that on average we will obtain 1.247 regional variants for D It also implies that we can obtain transliterations by constraint-based exploration in a broader coverage.
To investigate the average number of regional transliterations further, we found that the desire to achieve semantic trans-than 4000 frequently used characters representing only about 400 syllables. That means, for each syllable, there could have multiple character choices. For example, an English name  X  X  X ophia X  is a girl X  X  name. To carry its feminine association forward to Chinese,  X  X   X   X   X  /Su-Fei-Ya/ X  is used in Taiwan and  X  X  sen characters with feminine connotation but result in variation.

Another possible reason resulting in a higher number of transliteration variants is character connotation. Most of the Chi-nese characters carry meanings. For those that have positive or neutral connotation, there is a large overlapping between
Taiwan and China databases. Table 11 lists the top-10 characters in the three databases or six data sets. It is interesting to find that the top-3 characters, i.e.,  X  X   X  /Si/, X   X  X   X  some characters are used much more often than others. The top-20 characters account for 20.234%, 24.516%, 24.012%, 29.097%, 31.349% and 38.327% of the usage in the enumerated six data sets. Note that for comparison, all transliterations in Table 11 have been converted into Traditional Chinese. In comparison of the top-20 characters in six data sets, we can see that the characters in CN corpora cover a larger percentage than that in TW corpora in general. This is possible because the simplified Chinese is adopted in China and a character set GB2312 has been defined and deployed as compared to that of Traditional Chinese (13,051 Chinese characters).
 In Table 12 , we further study the correlation at whole word level in the lexicon D ( TW are identical to those in CN AE-500 , and 24.881% of the entries in CN
From Table 12 and the experimental results in Section 6.3 , it becomes evident that the correlation between characters and the underlying sound equivalence across regional databases do allow the cross-training to be effective. We believe that cross-training may also help learn multilingual transliterations among related languages, such as Chinese, Japanese and Kor-adopted in ancient are from Chinese. Note that the main purpose of deploying cross-training is to learn knowledge from re-lated corpora. However, if the corpora are loosely related or even completely different, then the information learned from one corpus become not so useful or even noisy to other corpora. This is the main concern in applying cross-training to the target tasks. Therefore, we will investigate this issue in the future. 7. Conclusions
This paper studies how to learn regional transliteration variants by proposing two techniques for crawling Web corpora, autonomous exploration (AE) and c onstraint-based exploration (CBE), which exploits transliteration knowledge and predictive suggestion terms to guide the query search, and two learning strategies, unsupervised learning and cross-training. Experi-ments show that the cross-training effectively boosts the learning by exchanging correlated information across two regional learners. We find that the CBE-based crawling followed by cross-training technique is a practical method for harvesting re-gional transliteration variants.

In order to validate the effectiveness of using cross-training, we also have studied measuring regional association by sta-tistical approaches using Chinese transliteration variants between Hong Kong, Macau, Singapore, Malaysia and Canada, as knowledge, this is the first journal paper exploring the Web and harvesting transliterations to work towards this end. The same idea can be applied to other language pairs, such as North and South Korean, as well. To extend the idea further, we will take translation terms and other terms used in daily life into account in the future.

To understand transliteration variation further, we also investigate the collective intelligence embedded in translitera-tions from various viewpoints such as the average number of transliterations, character connotation and correlation at whole word level. Through the investigation, transliteration variation is more understandable and the understanding is helpful to the transliteration research.
 References
