 of motion boundaries to be separated from the problem of smoo th flow estimation. Layered models also make reasoning about occlusion relationships easier. In practice, however, none of the current top performing optical flow methods use a layered approach [2 ]. The most accurate approaches are single-layered, and instead use some form of robust smoo thness assumption to cope with flow discontinuities [5]. This paper formulates a new probabili stic, layered motion model that addresses the key problems of previous layered approaches. At the time of writing, it achieves the lowest the accuracy at occlusion boundaries is significantly bette r than previous methods. By segmenting the observed scene, our model also identifies occluded and di soccluded regions.
 Layered models provide a segmentation of the scene and this s egmentation, because it corresponds computing flow between two frames; this is one reason that mul ti-layer models have not surpassed their single-layer competitors on two-frame benchmarks. W ithout loss of generality, here we use three-frame sequences to illustrate our method. In practic e, these three frames can be constructed from an image pair by computing both the forward and backward flow. The key is that this gives two segmentations of the scene, one at each time instant, bot h of which must be consistent with the flow. We formulate this temporal layer consistency probabilistically. Note that the assumption of temporal layer consistency is much more realistic than prev ious assumptions of temporal motion consistency [4]; while the scene motion can change rapidly, scene structure persists. each layer can employ affine, planar, or other strong models o f optical flow. By applying a single smooth motion across the entire layer, these models combine information over long distances and interpolate behind occlusions. Such rigid parametric assu mptions, however, are too restrictive for real scenes. Instead one can model the flow within each layer a s smoothly varying [26]. While accurate as robust single-layer models. Consequently, we f ormulate a hybrid model that combines a base affine motion with a robust Markov random field (MRF) mode l of deformations from affine [6]. This roughness in layers model, which is similar in spirit to work on plane+parallax [ 10, 14, 19], encourages smooth flow within layers but allows significant l ocal deviations.
 more probable (lower energy) solutions. This also allows ex plicit reasoning about occlusions, which our model predicts at locations where the layer segmentatio ns for consecutive frames disagree. Many previous layered approaches are not truly  X  X ayered X : w hile they segment the image into mul-used MRF models [27] encourage neighboring pixels to occupy the same region, but do not capture segmentation [21], our model determines layer support via a n ordered sequence of occluding binary masks. These binary masks are generated by thresholding a se ries of random, continuous functions. This approach uses image-dependent Gaussian random field pr iors and favors partitions which ac-play a key role in accurately modeling temporal layer consis tency. The resulting model produces accurate layer segmentations that improve flow accuracy at o cclusion boundaries, and recover mean-ingful scene structure.
 As summarized in Figure 1, our method is based on a principled , probabilistic generative model for image sequences. By combining recent advances in dense fl ow estimation and natural image segmentation, we develop an algorithm that simultaneously estimates accurate flow fields, detects occlusions and disocclusions, and recovers the layered str ucture of realistic scenes. Layered approaches to motion estimation have long been seen as elegant and promising, since spatial smoothness is separated from the modeling of discontinuiti es and occlusions. Darrell and Pentland [7, 8] provide the first full approach that incorporates a Bay esian model,  X  X upport maps X  for seg-mentation, and robust statistics. Wang and Adelson [25] cle arly motivate layered models of image sequences, while Jepson and Black [11] formalize the proble m using probabilistic mixture models. A full review of more recent methods is beyond our scope [1, 3, 12, 13, 16, 17, 20, 24, 27, 29]. Early methods, which use simple parametric models of image m otion within layers, are not highly more flexible Gaussian process to describe the motion within each layer. Even using modern imple-structure. Our approach, which allows  X  X oughness X  within l ayers rather than  X  X moothness, X  provides a compromise that captures coarse scene structure as well as fine within-layer details. One key advantage of layered models is their ability to reali stically model occlusion boundaries. To do this properly, however, one must know the relative dept h order of the surfaces. Performing inference over the combinatorial range of possible occlusi on relationships is challenging and, con-sequently, only a few layered flow models explicitly encode r elative depth [12, 30]. Recent work or achieve state-of-the-art performance on the Middlebury benchmark. While most current optical flow methods are  X  X wo-frame, X  layered methods naturally ext end to longer sequences [12, 29, 30]. Layered models all have some way of making either a hard or sof t assignment of pixels to layers. Weiss and Adelson [27] introduce spatial coherence to these layer assignments using a spatial MRF model. However, the Ising/Potts MRF they employ assigns low probability to typical segmentations of natural scenes [15]. Adapting recent work on static image segmentation by Sudderth and Jor-dan [21], we instead generate spatially coherent, ordered l ayers by thresholding a series of random continuous functions. As in the single-image case, this app roach realistically models the size and shape properties of real scenes. For motion estimation ther e are additional advantages: it allows accurate reasoning about occlusion relationships and mode ling of temporal layer consistency. Building on this long sequence of prior work, our generative model of layered image motion is summarized in Figure 1. Below we describe how the generative model captures piecewise smooth deviation of the layer motion from parametric models (Sec. 3 .1), depth ordering and temporal con-sistency of layers (Sec. 3.2), and regions of occlusion and d isocclusion (Sec. 3.3). 3.1 Roughness in Layers images I I vector for pixel ( i, j ) is then denoted by ( u ij Each layer X  X  flow field is drawn from a distribution chosen to e ncourage piecewise smooth motion. For example, a pairwise Markov random field (MRF) would model the horizontal flow field as  X  (  X  ) is some robust function [5] that encourages smoothness, but allows occasional significant de-viations from it. The vertical flow field v in Eq. (1), as justified by the statistics of natural flow fields [18].
 While such MRF priors are flexible, they capture very little d ependence between pixels separated by even moderate image distances. In contrast, real scenes exh ibit coherent motion over large scales, planar) motion model, with parameters  X  smooth deformations from the globally rigid assumptions of affine motion: Here,  X  u ij rameters  X  sic smoothness prior of Eq. (1), this semiparametric constr uction allows effective global reasoning about non-contiguous segments of partially occluded objec ts. More sophisticated flow deformation priors may also be used, such as those based on robust non-loc al terms [22, 28]. 3.2 Layer Support and Spatial Contiguity The support for whether or not a pixel belongs to a given layer k is defined using a hidden random field g g We assume a single, unique layer is observable at each locati on and that the observed motion of support of each layer is determined by thresholding g g tk ( i, j )  X  0 P k s tk ( i, j ) = 1 Given the full set of support functions g K  X  1 layers. For this reason, only K  X  1 hidden fields g tk are needed (see Figure 1). Our use of thresholded, random continuous functions to defin e layer support is partially motivated by known shortcomings of discrete Ising/Potts MRF models fo r image partitions [15]. They also provide a convenient framework for modeling the temporal an d spatial coherence observed in real motion sequences. Spatial coherence is captured via a Gauss ian conditional random field in which edge weights are modulated by local differences in Lab color vectors, I c The threshold  X  coherence of surfaces is then encouraged via a correspondin g Gaussian MRF: subsequent frames. By allowing smooth deformation of the su pport functions g support to evolve over time, as opposed to transforming a sin gle rigid template [12]. Our model of layer coherence is inspired by a recent method fo r image segmentation, based on spatially dependent Pitman-Yor processes [21]. That work m akes connections between layered oc-clusion processes and stick breaking representations of nonparametric Bayesian models. By as-signing appropriate stochastic priors to layer thresholds , the Pitman-Yor model captures the power image. Existing optical flow benchmarks employ artificially constructed scenes that may have dif-ferent layer-level statistics. Consequently our experime nts in this paper employ a fixed number of layers K . 3.3 Depth Ordering and Occlusion Reasoning fields u Eq. (3)). To consistently reason about occlusions, we exami ne the layer assignments s s richer occlusion model than standard spatially independen t outlier processes: geometric consistency is enforced via the layered sequence of flow fields.
 Let I s s feature) constancy assumption. Otherwise, that pixel has b ecome occluded, and is instead generated from a uniform distribution. The image likelihood model can then be written as where  X  data error term can be written as up to an additive, constant multiple of  X  change in energy when a pixel transitions from an occluded to an unoccluded configuration. Note that occlusions have higher likelihood only for sufficientl y large discrepancies in matched image features and can only occur via a corresponding change in lay er visibility. Considering the full generative model defined in Sec. 3, maximum a posteriori (MAP) estimation for a T frame image sequence is equivalent to minimization of the fo llowing energy function: E ( u , v , g ,  X  ) = Here  X  is a challenging process; our approach is summarized below. 4.1 Relaxation of the Layer Assignment Process Due to the non-differentiability of the threshold process t hat determines assignments of regions to layers, direct minimization of Eq. (8) is challenging. For a related approach to image segmentation, a mean field variational method has been proposed [21]. Howev er, that segmentation model is based on a much simpler, spatially factorized likelihood model fo r color and texture histogram features. Generalization to the richer flow likelihoods considered he re raises significant complications. exp(  X  g )) . Applied to Eq. (3), this induces the following soft layer as signments: Note that  X  (  X  g ) = 1  X   X  ( g ) , and P K Substituting these soft assignments  X  s backpropagation algorithm for neural network training. 4.2 Gradient-Based Energy Minimization fields u E based technique as described in [22]. For hidden field estima tion, we use an implementation of We apply the proposed model to two-frame sequences and compu te both the forward and backward flow fields. This enables the use of the temporal consistency t erm by treating one frame as both method [22], cluster the flow vectors into K groups (layers), and convert the initial segmentation into the corresponding hidden fields. We then use a two-level Gaussian pyramid (downsampling each level, we perform 20 incremental warping steps and during each step alternately solve for the hidden fields and the flow estimates. In the end, we threshold t he hidden fields to compute a hard Occluded regions are determined by inconsistencies betwee n the hard segmentations at subsequent frames, as matched by the final flow field. We would ideally like to compare layer initializations the preferred order for the  X  X enus X  sequence in Figure 2.
 The parameters for all experiments are set to  X   X  i = 12 Supplemental Material ). Optimization takes about 5 hours for the two-frame  X  X rban X  sequence using our M ATLAB implementation. 5.1 Results on the Middlebury Benchmark Training Set As a baseline, we implement the smoothness in layers model [2 6] using modern not competitive with state-of-the-art methods. The propos ed model with 1 to 4 layers produces that layer. It thus performs worse than the Classic+NL initi alization; the performance improvements allowed by additional layers demonstrate the benefits of a la yered model.
 Accuracy is improved by applying a 15  X  15 weighted median filter (WMF) [22] to the flow fields of Weighted median filtering can be interpreted as a non-local s patial smoothness term in the energy function that integrates flow field information over a larger spatial neighborhood. for example). We use a restricted number of layers, and model the remaining complexity of the flow within each layer via the roughness-in-layers spatial term and the WMF. As the number of layers increases, the complexity of the flow within each layer decre ases, and consequently the need for WMF also decreases; note that the difference in EPE for the 4-layer model with and without WMF is insignificant. For the remaining experiments we use the ve rsion with WMF.
 to minima on the  X  X rove3 X  and  X  X rban3 X  sequences, models with a dditional layers are more robust to the initialization. For more details and full EPE results, s ee the Supplemental Material . Test Set For evaluation, we focus on a model with 3 layers (denoted  X  X ayers++ X  in the Middlebury accurate at motion boundaries, probably due to the use of lay er-specific motion models, and the Material .
 sequences. Notice that the layered model produces a motion s egmentation that captures the major occlusion regions and interpolates their motion reasonabl y well. Several sequences show significant improvement due to the global reasoning provided by the laye red model. On the training  X  X rove3 X  sequence, the proposed method correctly identifies many hol es between the branches and leaves as background. It also associates the branch at the bottom righ t corner with branches in the center. As the branch moves beyond the image boundary, the layered mo del interpolates its motion using layered method can separate foreground objects from the bac kground (e.g., the leaves in the top right corner), and thereby reduce errors made by single-lay er approaches such as Classic+NL. We have described a new probabilistic formulation for layer ed image motion that explicitly models mentation. The approach allows the flow field in each layer to h ave piecewise smooth deformation from a parametric motion model. Layer support is modeled usi ng an image-dependent hidden field prior that supports a model of temporal layer continuity ove r time. The image data error term takes into account layer occlusion relationships, resulting in i ncreased flow accuracy near motion bound-aries. Our method achieves state-of-the-art results on the Middlebury optical flow benchmark while producing meaningful segmentation and occlusion detectio n results.
 der, and the automatic estimation of the number of layers. Co mputational efficiency has not been addressed, but will be important for inference on long seque nces. Currently our method does not number of layers, should adapt to the motions in a given seque nce.
 Acknowledgments DS and MJB were supported in part by the NSF Collaborative Res earch in Computa-
