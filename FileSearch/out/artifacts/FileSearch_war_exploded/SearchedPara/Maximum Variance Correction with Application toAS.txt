 Wenlin Chen wenlinchen@wustl.edu Kilian Q. Weinberger kilian@wustl.edu Yixin Chen chen@cse.wustl.edu Washington University, One Brookings Dr., St. Louis, MO 63130 USA Manifold learning has become a strong sub-field of machine learning with many mature algorithms (Saul et al., 2006; Lee &amp; Verleysen, 2007), often accompa-nied by large scale extensions (Platt, 2004; Silva &amp; Tenenbaum, 2002; Weinberger et al., 2007) and thor-ough theoretical analysis (Donoho &amp; Grimes, 2002; Pa-protny et al., 2012). Until recently, this success story was not matched by comparably strong applications. Rayner et al. (2011) propose to use the Euclidean em-bedding of a search space graph as a heuristic for A  X  search (Russell &amp; Norvig, 2003). The graph-distance between two states is approximated by the Euclidean distance between their respective embedded points. Exact A  X  search with informed heuristics is an ap-plication of great importance in many areas of real life. For example, GPS navigation systems need to find the shortest path between two locations efficiently and repeatedly ( e.g. each time a new traffic update has been received, or when the driver makes a wrong turn). As the processor capabilities of these devices and the patience of the users are both limited, the quality of the search heuristic is of great importance. This im-portance only increases as increasingly low powered embedded devices ( e.g. smart-phones) are equipped with similar capabilities. Other applications include massive online multiplayer games, where agents need to identify the shortest path along a map which can change dynamically through actions by other users. For an embedding to be a A  X  heuristic, it must sat-isfy two properties: 1. admissible (distances are never overestimated ), 2. consistent (a triangular inequality like property is preserved). To be maximally effec-tive, a heuristic should have a minimal gap between its estimate and the true distance X  i.e. all pair-wise distances should be maximized under the admissibil-ity and consistency constraints. In the applications highlighted by Rayner et al. (2011), a heuristic must require small space to be broadcasted to the end-users. The authors show that the constraints of Maxi-mum Variance Unfolding (MVU) (Weinberger &amp; Saul, 2006) 1 guarantee admissibility and consistency, while the objective maximizes distances and reduces space requirement of heuristics from O ( n 2 ) to O ( dn ). In other words, the MVU manifold learning algorithm is a perfect fit to learn Euclidean heuristics for A  X  search. Unfortunately, it is fair to say that due to its semi-definite programming (SDP) formulation (Boyd &amp; Vandenberghe, 2004), MVU is amongst the least scal-able manifold learning algorithms and cannot embed state spaces beyond 4000 states X  X everally limiting the usefulness of the proposed heuristic in practice. Al-though there have been efforts to increase the scala-bility of MVU (Weinberger et al., 2005; 2007), these lead to approximate solutions which no longer guaran-tee admissibility or consistency of heuristics. In this paper we propose a novel algorithm, Max-imum Variance Correction (MVC), which improves the scalability of MVU by several orders of magni-tude. In a nutshell, MVC post-processes embeddings from any manifold learning algorithm, to strictly sat-isfy the MVU constraints by rearranging embedded points within local patches. Hereby MVC combines the strict finite-size guarantees of MVU with the large-scale capabilities of alternative algorithms. Further, it bridges the gap between the rich literature on manifold learning and what we consider its most promising and high-impact application to date X  X he use of Euclidean state-space embeddings as A  X  heuristics.
 Our contributions are summarized as follows: 1) We introduce MVC, a fully parallelizable algorithm that scales up and speeds up MVU by several orders of magnitudes. 2) We provide a formal proof that any so-lution of our relaxed problem formulation still satisfies all MVU constraints. 3) We demonstrate on several A  X  search benchmark problems that the resulting heuris-tics lead to impressive reductions in search-time X  X ven beating the competitive differential heuristic (Ng &amp; Zhang, 2002) by a large factor on all data sets. There have been several recent publications that in-crease the scalability of manifold learning algorithms. Vasiloglou et al. (2008); Weinberger et al. (2007); Weinberger &amp; Saul (2006) directly scale up MVU by relaxing its constraints and restricting the solution to the space spanned by landmark points or the eigenvec-tors of the graph laplacian matrix. Silva &amp; Tenenbaum (2002); Talwalkar et al. (2008) scale up Isomap (Tenen-baum et al., 2000b) with Nystr  X om approximations. Our work is complementary as we refine these embed-dings to meet the MVU constraints while maximizing the variance of the embedding.
 Shaw &amp; Jebara (2009) introduce structure preserv-ing embedding, which learns embeddings that strictly preserve graph properties (such as nearest neighbors). Zhang et al. (2009) also focus on local patches of man-ifolds, however preserves discriminative ability rather than the finite-size guarantees of MVU.
 From a technical stand-point, our paper is probably most similar to Biswas &amp; Ye (2004) which uses a semi-definite program for sensor network embedding. Due to the nature of their application, they deal with dif-ferent constraints and objectives. 2.1. Graph Embeddings We briefly review MVU and Isomap as algorithms for proximity graph embedding. For a more detailed sur-vey we recommend (Saul et al., 2006). Let G = ( V,E ) denote the graph with undirected edges E and nodes V , with | V | = n . Edges ( i,j )  X  E are weighted by some d ij  X  0. Let  X  ij denote the shortest path distance from node i to j . Manifold learning algorithms embed the nodes in V into a d -dimensional Euclidean space, x ,..., x n  X  X  d , such that k x i  X  x j k 2  X   X  ij . Maximum Variance Unfolding formulates this task as an optimization problem that maximizes the variance of the embedding, while enforcing strict con-straints on the local edge distances: The last constraint centers the embedding at the ori-gin, to remove translation as a degree of freedom in the optimization. Because the data is centered, the objective is identical to maximizing the variance, as P convex, Weinberger &amp; Saul (2006) show that with a rank relaxation, x  X  X  n , this problem can be rephrased as a convex semi-definite program by optimizing over the inner-product matrix K , with k ij = x &gt; i x j : maximize subject to k ii  X  2 k ij + k jj  X  d 2 ij  X  ( i,j )  X  E The final constraint K 0 ensures positive semi-definiteness and guarantees that K can be de-composed into vectors x 1 ,..., x n with a straight-forward eigenvector decomposition. To ensure strictly r  X  dimensional output, the final embedding is pro-jected into R d with principal component analysis (PCA). (This is identical to composing the vectors x i out of the r leading eigenvectors of K .) The time-complexity of MVU is O ( n 3 + c 3 ) (where c is the num-ber of constraints in the optimization problem), which makes it prohibitive for larger data sets.
 Graph Laplacian MVU (gl-MVU), Weinberger &amp; Saul (2006); Wu et al. (2009), is an extension of MVU that reduces the size of K by matrix factorization, K = Q &gt; LQ . Here, Q are the bottom eigenvectors of the Graph Laplacian, also referred to as Laplacian Eigenmaps (Belkin &amp; Niyogi, 2002). All local dis-tance constraints are removed and instead added as a penalty term into the objective. The resulting algo-rithm scales to larger data sets but makes no exact guarantees about the distance preservations.
 Isomap , Tenenbaum et al. (2000a), preserves the global structure of the graph by directly preserving the graph distances between all pair-wise nodes: Tenenbaum et al. (2000a) show that (3) can be approx-imated as an eigenvector decomposition by applying multi-dimensional scaling (MDS) (Kruskal, 1964) on the shortest path distances  X  ( i,j ). The landmark ex-tension (Silva &amp; Tenenbaum, 2002) leads to significant speed-ups with Nystr  X om approximations of the graph-distance matrix. For simplicity, we refer to it also as  X  X somap X  throughout this paper. 2.2. Euclidean Heuristic The A  X  search algorithm finds the shortest path be-tween two nodes in a graph. In the worst case, the complexity of the algorithm is exponential in the length of the shortest path, but the search time can be drastically reduced with a good heuristic, which esti-mates the graph distance between two nodes. Rayner et al. (2011) suggest to use the distance h ( i,j ) = k x i  X  x j k 2 of the MVU graph embedding as such a heuristic, which they refer to as Euclidean Heuristic . A  X  with this heuristic provably converges to the exact solution, as the heuristic is admissible and consistent. More precisely, for all nodes i,j,k the following holds: Admissibility: k x i  X  x k k 2  X   X  ik (4) The proof is straight-forward. As the shortest-path between nodes i and j in the embedding consists of edges which are all underestimated, it must be under-estimated itself and so is k x i  X  x j k 2 (which implies admissibility). Consistency follows from the triangu-lar inequality in combination with(4).
 The closer the gap in the admissibility inequality (4), the better is the search heuristic. The perfect heuristic would be the actual shortest path, h ( i,j ) =  X  ij (with which A  X  could find the exact solution in linear time with respect to the length of the shortest path). The MVU objective maximizes all pairwise distances, and therefore minimizes exactly the gap in (4). Conse-quently, MVU is the perfect optimization problem to find a Euclidean Heuristic X  X owever in its original for-mulation it can only scale to n  X  4000. In the following we will scale up MVU to much larger data sets. In this section, we introduce our MVC algorithm. In-tuitively, MVC combines the scalability of gl-MVU and Isomap with the strong guarantees of MVU: It uses the former to obtain an initial embedding of the data and then post-processes it into a local optimum of the MVU optimization. The post-processing only involves re-optimizations of local patches, which is fast and can be decomposed into independent sub-problems.
 Initialization. We obtain an initial embedding  X  x ,...,  X  x n of the graph with any (large-scale) manifold learning algorithm ( e.g. Isomap, gl-MVU or Eigen-maps). The resulting embedding is typically not a feasible solution to the exact MVU problem, because it violates many distance inequality constraints in (1). To make it feasible, we first center it and then rescale the entire embedding such that all inequalities hold with at least one equality, x i =  X  (  X  x i  X  After the translation and rescaling in (6) we obtain a solution in the feasible set of MVU embeddings, and therefore also an admissible and consistent Euclidean Heuristic. In practice, this heuristic is of very limited use because it has a very large admissibility gap (4). In the following sections we explain how to transform the embedding to maximize the MVU objective, while remaining inside the MVU feasible region. 3.1. Local patching The (convex) MVU optimization is an SDP, which in their general formulation scale cubic in the input size n . To scale-up the optimization we therefore utilize a specific property of the MVU constraints: All con-straints are strictly local as they only involve directly connected nodes. This allows us to divide up the graph embedding into local patches and re-optimize the MVU optimization on each patch individually. This approach has two clear advantages: the local patches can be made small enough to be re-optimized very quickly and the individual patch optimizations are inherently parallelizable X  X eading to even further speed-ups on modern multi-core computers. A chal-lenge is to ensure that the local optimizations do not interfere with each other and remain globally feasible. Graph partitioning. There are several ways to di-vide the graph G = ( V,E ) into r mutually exclusive connected components. We use repeated breadth first search (BFS) (Russell &amp; Norvig, 2003) because of its simplicity, fast speed and guarantee that all partitions are connected components. Specifically, we pick a node i uniformly at random and apply BFS to identify the m closest nodes according to graph distance, that are not already assigned to patches. These nodes form a new patch G p = ( V p ,E p ). The partitioning is continued until all nodes in V are assigned to exactly one parti-tion, resulting in approximately r = d n/m e patches. 2 The final partitioning satisfies V = V 1  X  X  X  X  X  V r and V p  X  V q = {} for all p,q .
 We distinguish between two types of nodes within a partition V p (illustrated in figure 1). A node i  X  V p is an inner point (blue circle) of V p if all edges ( i,j )  X  E connect it to other nodes j  X  V p ; i is an anchor point (red circle) of V p if there exists an edge ( i,j )  X  E to some j /  X  V p . Let V x p denote the set of all inner nodes and V a p the set of all anchor points in V p . By definition, these sets are mutually exclusive and together contain all points, i.e. V x p  X  V a p = {} and V p = V x p  X  V a Similarly, all edges in E can be divided into three mu-tual exclusive subsets (see figure 1): edges between inner points ( E xx , blue); between anchor points ( E aa red); between anchor and inner points ( E ax , purple). Optimization. We first re-state the non-convex MVU optimization (1), slightly re-formulated to in-corporate the graph partitioning. As each input is either an anchor point or an inner point of its respec-tive patch, we can denote the set of all inner points as V x = S p V x p and the set of all anchor points as V a = S straints by these sets, we can re-phrase the non-convex MVU optimization (1) as For clarity, we denote all anchor points as a i  X  X  and inner points as x j  X  X  and with a slight abuse of notation write a i  X  V a .
 Optimization by patches. The optimization (7) is identical to the non-convex MVU formulation (1) and just as hard to solve. To reduce the computational complexity we make two changes: we remove the cen-tering constraint and fix the anchor points in place. The removal of the centering constraint is a harm-less relaxation because the fixed anchor points already remove translation as a degree of freedom and fixate the solution very close to zero-mean. (The objective changes slightly, but in practice this has minimal im-pact on the solution.) The fixing of the anchor points allows us to break down the optimization into r inde-pendent sub-problems. This can be seen from the fact that by definition all constraints in E xx never cross patch boundaries, and constraints in E ax only connect points within a patch with fixed points. Constraints over edges in E aa can be dropped entirely, as edges between anchor points are necessarily fixed also. We obtain r independent optimization problems of the fol-lowing type: The solutions of the r sub-problems (8) can be com-bined and centered, to form a feasible solution to (7). Convex patch re-optimization. Similar to the non-convex MVU formulation (1), optimization (8) is also non-convex and non-trivial to solve. However, with a change of variables and a slight relaxation we can transform it into a semi-definite program. Let n p = | V p | . Given a patch G p , we define a matrix X = [ x 1 ,..., x n responds to one embedded input of V x p  X  X he variables we want to optimize. Further, let us define the matrix is 1 and the j th element is  X  1. The vector e i is all-zero except the i th element is  X  1. With this notation, we obtain where ( 0 ; e ij )  X  X  ( d + n p ) denotes the vector e ij with zeros on top and ( a k ; e i )  X  X  ( d + n p ) the concate-nation of a k and e i .
 Through (10), all constraints in (8) can be re-formulated as a linear form of K (after squaring). The objective reduces to trace( H ) = P n p i =1 x 2 i . The result-ing optimization problem becomes: The constraint H = X &gt; X fixes the rank of H and is not convex. To mitigate, we relax it into H X &gt; X . In the following section we prove that this weaker constraint is sufficient to obtain MVU-feasible solu-tions. The Schur Complement Lemma (Boyd &amp; Van-denberghe, 2004) states that H X &gt; X if and only if K 0, which we enforce as an additional constraint: max s.t. ( 0 ; e ij ) &gt; K ( 0 ; e ij )  X  d 2 ij  X  ( i,j )  X  E The optimization (12) is convex and scales O (( n p d ) 3 ). It monotonically increases the objective in (7) and converges to a fixed point. For a maximum patch-size m , i.e. n p  X  m for all p , each iteration of MVC scales linearly with respect to n , with complexity O ( d n m e ( m + d ) 3 ). As the choice of m is independent of n , it can be fixed to a medium-sized value e.g. m  X  500 for maximum efficiency. The r  X  X  n m e sub-problems are completely independent and can be solved in parallel , leading to almost perfect parallel speed-up on comput-ing clusters. Algorithm 1 states MVC in pseudo-code. 3.2. MVU feasibility We prove that the MVC algorithm returns a feasible MVU solution and consequently gives rise to a well defined Euclidean Heuristic. First we need to show Algorithm 1 MVC (V,E) that the relaxation from H = X &gt; X to H X &gt; X does not cause any constraint violations.
 Lemma 1. The solution X of (12) satisfies all con-straints in (8).
 Proof. We first focus on constraints on ( i,j )  X  E The first constraint in (12) guarantees The last constraint of (12) and the Schur Complement Lemma enforce that H  X  X &gt; X 0. Thus, The first result follows from the combination of (13) and (15). Concerning constraints ( i,j )  X  E ax p , the sec-ond constraint in (12) guarantees that With a similar reasoning as for (14) we obtain e bining this inequality with (16) leads to the result: Theorem 1. The embedding obtained with the MVC Algorithm 1 is in the feasible set of (1).
 Proof. We apply an inductive argument. The initial solution after centering and re-scaling according to (6) is MVU feasible by construction. By Lemma 1 , the solution of (12) for each patch satisfies all constraints in E xx p and E ax p in (8). As each distance constraint in (7) is associated with exactly one patch, all its con-straints in E xx and E ax are satisfied. Constraints in E aa are fixed and satisfied by the induction hypoth-esis. Centering X satisfies the last constraint in (7) and leaves all distance constraints unaffected. As (7) is equivalent to (1), we obtain an MVU feasible solu-tion at the end of each iteration in Algorithm 1, which concludes the proof.
 We evaluate our algorithm on a real world short-est path application data set and on two well-known benchmark AI problems.
 Game Maps is a real world map dataset with 3,155 states from the international success multi-player game Biowares Dragon Age: Origins T M . 3 A game map is a maze that consists of empty spaces (states) and ob-stacles. Cardinal moves take unit costs while diagonal moves cost 1.5. The search problem is to find an op-timal path between a given start and goal state, while avoiding all obstacles. Although not large-scale, this data set is a great example for an application where the search heuristic is of extraordinary importance. Speedy solvers are essential to reduce upkeep costs and to ensure a positive user experience. In the game, many player and non-player characters interact and search problems have to be solved frequently as agents move. The shortest path solutions cannot be cached as the map changes dynamically with player actions. M -Puzzle Problem (Jones, 2008) is a NP-hard slid-ing puzzle, often used as a benchmark problem for search algorithms/heuristics. It consists of a frame of M square tiles and one tile missing. All tiles are num-bered and a state constitutes any order from which a path to the unique state with sorted (increasing) tiles exists. An action is to move a cardinal neighbor tile of the empty space into the empty space. The task is to find a shortest action sequence from a pre-defined start to a goal state. We evaluate our algorithm on the 5-(for visualization), 7-and 8-puzzle problem (3  X  2, 4  X  2 and 3  X  3 frames), which contain 360, 20160 and 181440 states respectively.
 Blocks World (Gupta &amp; Nau, 1992) is a NP-hard problem with the goal to build several pre-defined stacks out of a set of numbered blocks. Blocks can be placed on the top of others or on the ground. Any block that is currently under another block cannot be moved. The goal is to find a minimum action sequence from a start state to a goal state. We evaluate our al-gorithm on block world problems with 6 blocks (4,051 states) and 7 blocks (37,633 states), respectively. Problem characteristics. The three types of prob-lems not only feature different sized state spaces but also have different state space characteristics. Game maps has random obstacles that prevents movement for some state pairs, and thus has an irregular state space. The puzzle problems have a more regular search space (which lie on the surface of a sphere, see figure 2) with stable out-degree for each state. The state space of the blocksworld problems is also regular (it lies in-side a sphere); however, the out-degree varies largely across states. For example, in 7-blocks, the state in which every block is placed on the ground has 42 edges, while the state in which all blocks are stacked in a sin-gle column has only 1 edge. We set d ij = 1 for all edges in blocksworld and M -puzzle problems.
 Experimental setting. Besides MVC, we evaluate four graph embedding algorithms: MVU (Weinberger &amp; Saul, 2006), Isomap (Tenenbaum et al., 2000b), (Laplacian) Eigenmap (Belkin &amp; Niyogi, 2002) and gl-MVU (Wu et al., 2009). The last three are used as initializations for MVC. Following Rayner et al. 2011, the embedding dimension is d = 3 for all experiments. For gl-MVU, we set the dimension of graph Laplacian to be 40. For datasets of size greater than 10K, we set 10K landmarks for Isomap. For MV C we use a patch-size of m = 500 throughout (for which problem (12) can be solved in less than 20 s on our lab desktops). Visualization of MVC iterations ( m = 30 ). Fig-ure 2 visualizes successive iterations of the d = 3 di-mensional MVC embedding of the 5  X  puzzle problem. All edges are colored proportionally to their relative admissibility gap, The plot in the top left shows the original Isomap ini-tialization after re-scaling, as defined in (6). The plot in the bottom right shows the actual MVU embed-ding from (2) X  X hich can be computed precisely be-cause of the small problem size. Intermediate plots show the embeddings after several iterations of MVC. Two trends can be observed: 1. the admissibility gap decreases with MVC (all edges are blue in the final embedding) and 2. the variance P i x 2 i of the embed-ding, i.e. the MVU objective, increases monotonically. The final embedding has the same variance as the ac-tual MVU embedding. The figure also shows that the 5  X  puzzle state space lies on a sphere, which is a beau-tiful example that visualization of states spaces in it-self can be valuable. For example, the discovery of specific topological properties might lead to a better understanding of the state space structure and aid the development of problem specific heuristics.
 Setup. As a baseline heuristic, we compare all results with a differential heuristic (Ng &amp; Zhang, 2002). The differential heuristic pre-computes the ex-act distance from all states to a few pivot points in a (randomly chosen) set S  X  V . The graph distance between two states a,b is then approximated with max s  X  S |  X  ( a,s )  X   X  ( b,s ) | X   X  ( a,b ). In our experiments we set the number of pivots to 3 so that differential heuristics and embedding heuristics share the same memory limit. Figure 3 ( right ) shows the total ex-panded nodes as a function of the solution length, aver-aged over 100 start/goal pairs for each solution length. The figure compares MVC with various initializations, the differential heuristic and the MVU algorithm on the 6-blocksworld puzzle. Speedups (reported in Ta-ble 1) measure the reduction in expanded states during search, relative to the differential heuristic, averaged over 100 random (start, goal) pairs across all solution lengths.
 Comprehensive evaluation. Table 1 shows the A  X  search performances of Euclidean heuristics obtained by the MVC initializations, MVC after only 10 iter-ations (MVC-10) and after convergence (bottom sec-tion). Table 1 also shows the MVU objective/variance, P observed: 1. MVC performs best when initialized with gl-MVU X  X his is not surprising as gl-MVU has a similar objective and is likely to lead to better ini-tializations; 2. all MVC embeddings lead to drastic speedups over the differential heuristics; 3. the vari-ance is highly correlated with speedup X  X upporting Rayner et al. (2011) that the MVU objective is well suited to learn Euclidean heuristics; 4. even MVC af-ter only 10 iterations already outperforms the differen-tial heuristic on almost all data sets. The consistency of the speedups and their unusually high factors (up to 2 . 22) show great promise for MVC as an embedding algorithm for Euclidean heuristics.
 Exceeding MVU. On the 6-blocksworld data set in table 1, the variance of MVC actually exceeds that of MVU. In other words, the MVC algorithm finds a better solution for (1). This phenomenon can be explained by the fact that the convex MVU prob-lem (2) is rank-relaxed and the final embedding is ob-tained after projection into a d = 3 dimensional sub-space. As MVC performs its optimization directly in this d -dimensional sub-space, it can find a better rank-constrained solution. This effect is further illus-trated in Figure 3 ( left ), which shows the monotonic increase of the embedding variance as a function of the MVC iterations (on 6-blocksworld). After only a few iterations, all three MVC runs exceeds the MVU solution. A similar effect is utilized by Shaw &amp; Je-bara (2007), who optimize MVU in lower dimensional spaces directly (but cannot scale to large data sets). Figure 3 ( left ) also illustrates the importance of ini-tialization: MVC initialized with Isomap and gl-mvu converge to the same (possibly globally optimal) solu-tion, whereas the run with Laplacian Eigenmaps ini-tialization is stuck in a sub-optimal solution. Our find-ings are highly encouraging and show that we might not only approximate MVU effectively on very large data sets, but actually outperform it if the intrinsic dimensionality of the data is higher than the desired embedding dimensionality d .
 Embedding time. Table 2 shows the training time required for the convex MVU algorithm (2), three MVC initializations (Eigenmap, Isomap, gl-MVU), the time for 10 MVC iterations and the time until MVC converges, across all five data sets. Note that for real deployment, such as GPS systems, MVC only needs to be run once to obtain the embedding. The online calculations of Euclidean heuristics are very fast. All embeddings were computed on an off-the-shelve desk-top with two 8-core Intel(R) Xeon(R) processors of 2.67 GHz and 128 GB of RAM. Our MVC implemen-tation is in MATLAB T M and uses CSDP (Borchers, 1999) as the SDP solver. We parallelize each run of MVC on eight cores. All three initializations require roughly similar time (although Laplacian Eigenmaps is the fastest on all data sets), which is only a small part of the overall optimization. Whereas MVU requires 10 hours for graphs with | V | = 4051 (and cannot be executed on larger problems), we can find a superior solution to the same problem in 5 minutes and are able to run MVC on 45  X  larger problems in only 7 hours. We have presented MVC, an iterative algorithm to transform graph embeddings into MVU feasible so-lution. On several small-sized problems where MVU can finish, we show that MVC gives comparable or even better solutions than MVU. We apply MVU on data sets of unprecedented sizes ( n = 180 , 000) and, because of linear scalability, expect future (parallel) implementations to scale to graphs with millions of nodes. By satisfying all MVU constraints, MVC em-beddings are provably well-defined Euclidean heuris-tics for A  X  search and unleash an exciting new area of applications to all of manifold learning. We hope it will fuel new research directions in both fields. Acknowledgements. WC and YC are supported in part by NSF grants CNS-1017701 and CCF-1215302. KQW is supported by NIH grant U01 1U01NS073457-01 and NSF grants 1149882 and 1137211. The authors thank Lawrence K. Saul for many helpful discussions.
