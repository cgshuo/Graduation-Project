 Interactive web search involves selecting which documents to read further and locating the parts of the documents that are relevant to the user X  X  current ac tivity. In this paper, we introduce UIMaP: U ser I nterest M odeling a nd P ersonalization, a search task based personal user interest model to support users X  information gathering tasks. The novelty of our approach lies in the use of topic modeling to genera te fine-grained models of user interest and visualizations that di rect user X  X  attention to documents or parts of documents that match us er X  X  inferred interests. User annotations are used to help gene rate personalized visualizations for user X  X  search tasks. Based on 1267 user annotations from 17 users, we show the performance comparisons of four different topic models: LDA+H, LDA+KL , LDA+JSD, and LDA+TopN. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Information filtering, Retrieval models User Interest Modeling, Topic Models, Search Personalization Detailed knowledge about a user's interests is beneficial in web search, advertising, and personali zed recommendations as well as in content targeting. The goal of personalized recommendations is to support users by identifying documents or the parts of a document that best match user X  X  interests during an open-ended information gathering task. Such recommendations can result in a more efficient use of the user X  X  time, e.g. that their time is spent on the most relevant documents. Our past research shows that time is frequently a limiting factor in web search tasks: there are too many documents to assess and too much reading to do. The problem in su ch a search task is that even with the best web search engines, and the most effective query formulations, these tasks require people to work through long list of documents to examine potentially relevant documents or part of a document. Most users skim early documents, find portion of a document relevant to the curren t query, and determine additional information needs that result in further queries and more documents to process [1]. This paper describes the usage of user interest models using topic modeling as a basis for visualizati ons that draw a user's attention to similar documents or to a pa rt of documents that match these interests. The paper describes the overall architecture of UIMaP, and the topic modeling based algorithms we developed for user interest modeling. Section 2 surveys related work and section 3 presents our system components and topic modeling algorithms. In section 4 we discuss the results of initial user evaluations, and section 5 presents conclusions and points out some future work. Relevance feedback has a history in information retrieval systems that dates back well over thirty years and has been used for query expansion during short-term modeling of a users' immediate information need [2]. Explicit feed back requires users to assess the relevance of documents or portions of documents or to indicate their interest in cert ain aspects of the content (e.g. identifying nouns or phrases within search results). Explicit feedback has the advantages that it can be easily understood, is fairly precise and requires no further interpretation [3]. Annotations can be interpreted as one form of explicit feedback. Reading documents happens for many reasons: we read for fun, for general knowledge, or for some specific activity. When reading as part of an activity, we have a particular task in mind. Not all reading results in annotations. Annotations are most likely when people read materials crucial to a particular task at hand and are infrequent when reading for fun [4]. Explicit interest indicators such as annotations are based on users directly identifying which documents or portions of it are interesting. As users read through a particular document, they begin to identify the content relevant to the task in hand. If the document text content is large, users will frequently skim or stop reading when they feel what they have is good enough. Consequently, potentially better document contents are left having never been reviewed [5]. A potential solution for this particular problem is to provide visualizations to draw user's attention to similar documents or document parts relevant to their search task [1]. Users' attention to passages of pote ntial interest can be drawn by using colors and icons to highli ght them in a document overview application [6]. XLibris [7], and Sp atial hypertext systems such as VIKI[8] and VKB [9], use a sim ilar visualization techniques to provide system-identified "inter esting document contents" to provide visualization aided navigation. Figure 1 shows the overall architecture of UIMaP. The reading application (web browser) communicates with the UIMaP via the browser plug-in annotation tool. The interest profile stores inferred user interests; records of user activity in reading application. UIMaP then drives the visualizations (system generated underlines of text cont ent) of documents based on the inferred interests the topi c models generated. During information gathering sear ch task, useful documents may be long, and cover multiple subtopics; users may read some segments and ignore others. In order to record which portions of the document pique the user X  X  interests most, an explicit interest expressions capturing tool can be used. The WebAnnoate [1] provides basic annotation capabilit ies, collect data on user's interactions with web documents, and uses inte rest data returned from UIMaP to create visualiza tions(see Figure 2) that enhance document skimming and reading. With annotation tool, users can provide explicit feedback via an notations and convey it to UIMaP with terms associated with the annotation. The interest profile plays the central role in the UIMaP. It collects and stores information about interest related activity from document reading application and this information are processed to create a user interest profile based on UIMaP topic modeling algorithms. The UIMaP then estimates the user interest based on the inferred user interest profile and broadcast it to the document reading application to generate visualizations. Any application that can be modified to include th e interest profile client software API can communicate with the UIMaP enabling multi-application user interest modeling capability. Before introducing our topic model algorithms for inferring user interests, we first give a brief review of the statistical model Latent Dirichlet Allocation (LDA) a nd its parameters used in this research paper. LDA is a hierarchical probabilistic generative model which can be used to mode l a collection of documents by topics [10]. Given LDA paramete rs, a number of topics K, a document corpus of W distinct wo rds, two smoothing parameters  X  and  X  , and prior distribution over document corpus, LDA can create random documents whose cont ents are a mixture of topics. As words are the only observable variables in an LDA model, conditional independence holds true for the outputs of LDA model which are document and topic distributions  X  and  X  . For a corpus containing D documents, the parameters  X  , the  X  X  X  matrix of topic probability distribution per each document and  X  , the  X  X  X  matrix of topics must be learned from the data. The remaining parameters  X  and  X  , and K are specified by UIMaP. For the LDA models used in this paper, parameter fitting is performed using collapsed Gibb s sampling [11] to estimate  X  , and  X  . We use  X 0.01  X  and  X 0.01  X  [12]. Two additional parameters for the Gibbs samp ling are the number of sampling and burn-in iterations, which we set to 1 and 5 respectively. In our experiments with LDA mode ls, we will create similarity matrices to compare the user-gen erated annotations (Source S) to document components (Target T) ; hence we define proposed measures as similarities. The granularity in this scenario is a paragraph/passage of the document. The Hellinger distance is computed over two positive vectors. Since we are dealing with probability distributions in document-topic distribution, we chose helli nger distance [13] to measure their divergence. The main idea of our approach is to use the hellinger distance between document topic distributions to find the similarity of target T to the user generated source S. where  X  is a K-dimensional multinom ial topic distribution and  X  is the probability of the  X   X  X  X  topic. Kullback-Leibler divergence (KL divergence)[14] is a non-symmetric measure of the diff erence between two probability distributions. In our LDA+KL mode l, the association of source and target in the document topi c distribution can be measured using the KL-divergence. The smaller the score is, the stronger the associated similarity is. For tw o probability distributions, from target to the user generated source , KL divergence is calculated as follows: We use Jensen-Shannon divergence (JSD) measure as a smoothed and symmetric alternative to the KL divergence. The measure is 0 only for identical distributions and approaches infinity as the two differ more and more. Formally it is defined as the average of the KL divergence of each distribution to the average of the two distributions [15]. The simplest way to support Top-N topic probabilities is to sort the resultant document topic probab ility distribution in the desired order and then discard all but the first N topic tuples. Then compare the Top-N topics between document topic distributions to find the similarity of target T to the user generated source S. The main motivation behind this method is to find document-based results, such as finding main topics of a document or finding the top topics that are most related to a specific document content or user annotation. Generated In this section we discuss user experiments we have done to evaluate our proposed methods. We first describe our evaluation metrics, and then expe rimental setup. Next we present the results from our user survey that measures the perceived quality of our user interest model. How can we evaluate the effectiveness of our proposed methods? Given that our primary goal is to learn the user X  X  preference from her explicit feedback and use these user generated annotation results to visualize relevant doc ument content, we may consider the standard information retrieval domain evaluation metrics such as precision, recall, accuracy, F1 measure, false positive and true positive. Precision is the ratio of correctly underlined as a class to the total document content as the class. For example, the precision (P) of the underlined class in Table 1 is . Recall (R) is the ratio of correctly underlined document content as a class to the actual user generated annotations in the class. The recall of the underlined class in the table is . Accuracy is the proportion of the total number of under lines that were correct. The accuracy in the table is . F1 is a measure that trades off precision versus recall. F1 measure of the underlined class is . Since our approaches are based on annotated document contents, we need to collect user X  X  annotations for a set of search tasks. In the meantime, users are required to supply a set of annotations using the annotation tool that re flects relevance to the main idea of the given search tasks. The da ta is composed of five search tasks and twenty web documents. Documents are preprocessed and removed graphics and annota tions before experiments. We recruited 17 students to annotate the documents relevant to the given search tasks. Users are to ld to make annotations freely which reflects the main idea of the given task and relevance to the given documents. We collected total of 1267 annotations. It is important to identify the op timum number of topics in each LDA model as they determine the quality of the user interest modeling. We calculate the va lues at first 5, 10, 15, 20, 25 topics respectively. The result s are shown in Figure 3. From performance is not quite large in all four models. K=8 gives the best average F1 measure for all four models. We evaluate the results sensitivity to the similarity threshold in the LDA+H, LDA+KL and LDA+ JSD. Figure 4 shows how the model threshold influences th e performance. As the threshold increases from 0.1 to 0.5, the performance keeps on improving and reaches the average optimal value at 4.5 for all three models. Model LDA+TopN shows a similar trend and reaches optimum F1 measure at N=2. The Figure 5.(b) shows the overall performance of all four algorithms. The improvement on re call and F1 of LDA+JSD and LDA+TopN is very encouraging since recall is a more important factor in generating user interest models to provide relevant content as suggestions/recommendations. The results demonstrate that the LDA+JSD and LDA+TopN consistently outperform the other two methods in terms of h it recall and F1 measure. From this comparison, it can be conclude d that the proposed approach is capable of making accurate and effective search suggestions. 
Figure 4. Impact of varying th e threshold in topic models This paper introduces UIMaP, a novel search task based user interest model based on user X  X  annotations. Annotations are used to help generate personalized visualizations for user X  X  search tasks. Four different topic models are produced: LDA+H, LDA+KL, LDA+JSD, and LDA+TopN. Performance comparisons between these four topic models are made. This paper also describes the usage of user interest models using topic modeling as a basis for visualizatio ns that draw a user's attention to similar documents and to portions of documents that match these interests. We have evaluated the effectiveness of the visualizations in recommending interesting new doc uments and passages within documents based on what the user has explicitly indicated their interests using annotations. In the future, we expect to employ Automatic Query Expansion (AQE) to identify pseudo-implicit-feedback to generate similar visualization to support users search task activity. The classificatio n of documents and parts of a document into different user inte rests in the current UIMaP is based on explicit user annotations in a single application. The current work can be easily exte nded to support multi-application environment with weighting sche mas to detect the relative importance of different ap plications to the users X  search tasks. For example, if the user is writing a paper while she is performing search task relevant to the writing task, the topics that emerge in the paper may be a very effective source of interest profile data. This work was supported in part by National Science Foundation grant DUE-0938074. 
