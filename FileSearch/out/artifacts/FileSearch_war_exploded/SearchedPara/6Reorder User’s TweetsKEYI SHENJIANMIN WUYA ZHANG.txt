 Twitter, as a widely used social networking and microblogging service, enables users to instantly share their latest status and thoughts in the form of short messages of no more than 140 characters known as tweets. A tweet may be an original message, a forwarded message called retweet, or a reply to a message which is only visible to the two users involved and their mutual friends. A user may choose to  X  X ollow X  other users on Twitter and become their friends/fans, that is, subscribe to their messages, so that the subscribed messages are displayed on his/her own Twitter page.

Twitter messages are believed to contain a rich source of instantly updated infor-mation about the world. Several studies have successfully used Twitter messages to predict the stock market [Bollen et al. 2010], election results [Tumasjan et al. 2010], swine flu pandemics [Ritterman et al. 2009], and box-office revenues for movies [Asur and Huberman 2010].
 With the increasing popularity of Twitter, a large volume of messages are produced. As of June 2011, Twitter receives more than 200 million tweets per day. As a matter of fact, many users on Twitter are flooded with a large volume of messages of different all the time. On the other hand, a study by Pear Analytics has put tweets into six categories: pointless babble (41%), conversational (38%), pass-along value (9%), self-promotion (6%), spam (4%), and news (4%) [Kelly 2009]. A significant portion of tweets are in fact meaningless. It is hence desirable to order the tweets in a meaningful way so as to relieve the information overloading problem and facilitate user browsing. a student in computer science may follow a computer expert due to the interest in his comments on IT technology instead of his minutiae of daily life. On the other hand, a friend of the computer expert may want to follow him to stay updated about his personal life. As a matter of fact, tweets of different topics from the same person may according to the the interests of a user.

Twitter currently orders tweets by the reversed chronological order. The problem of ordering users X  tweets becomes nontrivial if we want to consider the differences in length and usually in informal language. These characteristics make it hard to perform ordering involves the understanding of users X  preference and interests, which makes the problem even more difficult. Thirdly, the evaluation of the effectiveness of the personalized reordering is also a challenging problem. Generally speaking, we do not have the ground truth of each individual user X  X  real information need, though we may and expensive to obtain. Moreover, editors are often not able to accurately judge the personalized information need of individuals, making the editorial-based evaluation method not applicable in this scenario.

Here we adopt machine-learning-based approaches to reorder tweets according to their quality and user interests so that tweets with low quality will rank low, and tweets that are attractive to the user are ranked high in the user X  X  homepage.
To identify the topics in the tweet corpus and users X  interests over these topics, we first aggregate the tweets generated or consumed by each user. Then a topic model is built by treating the aggregated tweets associated with each user as a single document. The word co-occurrence in the aggregated tweets is more reliable for topic model than using a single tweet as document. Moreover, the word distribution of each topic is well tailored with regards to the languages used in tweets. We may then infer topics of each tweet with the learned topic model.

We leverage users X  feedbacks such as retweeting and replying activities for training to be interested in the tweets that he publishes than those that he does not interact with. These behavior-based data are used to both train our machine learning models and evaluate the prediction of our machine learning model. We further explore a set of features derived from the content of the tweets, users X  behaviors, and users X  social graph for their prediction power of personalized relevance. We show that with the help of tweets reordering, users are able to find more informative messages, which is especially useful when users have lots of newly received tweets to read.
The major contributions of the article are as follows. First, we use the observable ac-and evaluate our machine learning model, which empowers us to build a personalized ranking model. Second, we explore a wide variety of features for reordering, including many personalized features. Our experimental results demonstrate the effectiveness of personalized features in reordering, that is, the personalized reordering algorithm outperforms the default baseline and the same machine learning method that excludes the personalized features.

The rest of the article is organized as follows. We provide related work in literature labeling and the machine learning ranking model for tweet reordering are presented in Section 4. In Section 5, we present the experimental results on Twitter data, which illustrate the effectiveness of our method. We conclude the article with Section 6. Messages on Twitter are mostly time sensitive.
 Many commercial search engines offer organic search and ranking for tweets. Y. Duan et al. have used a learning to rank method [Joachims 2002] to rank the tweets and empirically compared several strategies to rerank the top-k tweets returned by an existing tweets search engine [Nagmoti et al. 2010].

Analyzing of Twitter users has also drawn much attention from both the industrial and research community. Tweetfind.com and Twitority.com rank the tweets according to et al. rank the users on Twitter by accounting for the number of followers, PageRank [Page et al. 1998] score from Twitter users X  friendship graph, and the number of tweets being retweeted [Kwak et al. 2010].

Recommendation or reorganization of tweets is another interesting topic on Twitter research. J. Chen et al. present a way to recommend URLs in tweets [Chen et al. 2010]. Their recommendation system takes the content, topic interest, and social voting into consideration. The Web sites Paper.li and Twitter Times turn the user X  X  tweets stream help of different categories and topics. But this personalized newspaper only updates once every 24 hours. Twitter Times displays materials based on how many of one X  X  friends and friends X  friends have retweeted this tweet. C. Castillo et al. studied the information quality on Twitter [Castillo et al. 2011]. They classified news on Twitter as credible or not credible by a set of features extracted from tweets.

In Suh et al. [2010], B. Suh et al. studied the information diffusion on Twitter by Z. Yang et al. proposed a factor graph model to predict retweet behaviors [Yang et al. 2010].

All of the afore mentioned studies primarily focus on the tweet search ranking or recommendation, and they involve tweets from all Twitter users. However, our tweets reordering work only considers the tweets from the user X  X  own feeds. Since the tweets that the user u received are generated by u  X  X  followees, we can utilize the personalized features between the information publisher and the receivers. But in the case of ranking or recommendation, the candidate tweets may come from unknown authors, and thus no historical information about the user X  X  preference is available to this author. Table I gives a comparison among the tweets ranking, recommendation, and our reordering method. Due to the controlled source of the candidate tweets, our Twitter reordering method can utilize more personalized and social features to make the reordering more relevant. To achieve personalized reordering of tweets, we explore a set of features to capture a by the user a ,andthetime t when u read the tweet m , the extracted features include the freshness and quality of the tweet m , the authority of the author a ,aswellas personalized social features such as interest match between the user u and the author models based on the extracted features. In the rest of this section, we describe these personalized reordering features in detail. The most notable trait of Twitter is its capability to capture recency-sensitive infor-mation. Hence, we expect freshness to be an important factor in tweet reordering. We define two features based on freshness of a tweet as follows.  X   X  this tweet m and the time this tweet was posted.  X   X  the time t when the user u visits Twitter.
 points of view, in terms of absolute time and relative rank, respectively. Two adjacent user during a long period of time. On the other hand, two tweets that were posted at tweets are posted by the user u  X  X  followees at the same time. A user X  X  interest to a tweet might be consciously or unconsciously influenced by the corresponding author X  X  authority. Here we attempt to use the following set of features Twitter. Some of the features such as active level by their own may not be highly correlated to an author X  X  influence. We still include them in this study because they are likely to contribute to an author X  X  influence.  X   X  may be perceived as an indication of the popularity of the author.

Note that celebrities usually have lots of followers on Twitter. Even though the tweets from a celebrity are not always of high quality, the followers are interested in the tweets in general because they are interested in knowing almost everything about the celebrity. These people with large number of followers are generally influential ones in the Twitter community. According to Kwak et al. [2010], the result of ranking the Twitter users according to their FoC ( a ) is similar to that of the PageRank [Page et al. 1998] ranking based on the following/follower graph of Twitter users.  X   X  followees, a might pay more attention on sharing information; if user a has lots of followees, a might focus on what X  X  happening among a  X  X  followees.  X   X 
Duan et al. [2010] suggests that the number of times a is listed by other users is an effective representation for a  X  X  authority.  X   X  author of the tweet.  X   X  result in Suh et al. [2010], tweets from  X  X enior X  Twitter users (whose accounts were created before 1 year ago) and recent users (whose accounts were created less than a month ago) are more likely retweeted.  X   X  is verified by Twitter officially or not. Most of the verified Twitter accounts belong to celebrities and well-known people. Hence, this feature is another indicator for popularity or authority. The quality of the tweet is expected to be one of the key factors that determine the rank of tweet. We define the following features to measure the quality of tweets.  X   X  characters allowed. Considering many of the tweets are just some buzzes with very short length, longer tweets usually are more formal and informative.  X   X  contains URLs. With the length limitation for tweets, it is quite common for tweets to contain a short URL which points to a Web page with more details. Therefore, tweets with short URLs could provide more information.  X   X 
Hashtag is a special word in tweet with a leading character  X # X , which is designed to indicate topics being covered in this tweet. Tweets with appropriate hashtags usually can be classified with less efforts.  X   X  by the time t when the user reads it. This feature represents the social voting for the tweet m from all other users. The more people share this tweet, the more likely that it is of high quality. The retweet count might be manipulated by the spammers [Duan et al. 2010] for general tweets search. However, in our case, the number is a reliable criterion because all the tweets we consider are posted by the user u  X  X  followees.  X   X  being retweeted by the user u  X  X  followees by the time t when u saw it. A user tends to share similar interest to his social contacts. So retweet count by followees can be perceived as a type of recommendation by one X  X  social contacts. Match between the topic of a tweet and a user X  X  interest is an important factor for ordering the newly received tweets. We infer the interests of a user by the topic model based on the tweets the user generated and consumed in the past. Topics of the received tweets are inferred by the same topic model. To be more concrete, for each user, we represents this user as a  X  X ocument X  with words from the tweets this user generated and consumed. Then we train the PLSA [Hofmann 1999] topic model with the corpus of all Twitter users in our dataset.

Given the number of topics K , the training of a PLSA model is to maximize z P ( the same fold-in scheme as in Hofmann [1999]. Given a tweet m , we can use vector the tweets u generated and consumed and the topic distribution T ( m ) of those tweets.
With the topic models, we propose the following two interests matching features.  X   X  user u , the interests match is measured by the inner product of the vectors T ( u )and
T ( m ), that is, T ( u )  X  T ( m ).  X   X  and T ( a ), that is, T ( u )  X  T ( a ).
 These two topic-model-based features enable us to encode the topic-wise personalized information in the reordering model without additional editorial efforts required. We will analyze the detailed benefits from these features in the experiment part. Social characteristics should be an important factor when talking about reordering tweets. Here we consider several personalized social features which represent the social relationship between the user u and the author a based on historical behaviors. The resulting model based on these features is thus personalized for each individual Twitter user.  X   X  in the past. This is an important indicator for u  X  X  interests on a  X  X  tweets.  X   X  to a  X  X  tweet.  X   X   X   X  The latter two features, which may be perceived as the normalized retweet count and user has large number of updates.
 We adopt a supervised learning framework for building the tweet reordering model. this study, considering the fact that Twitter data are public by default, we attempt to leverage the observable user behavior data on Twitter to build the training set. Next relevance scores in the training data, followed by the procedures for model training. The purpose of the tweet reordering model is to reorder the user X  X  recently received and what tweets the user u is most interested in. Furthermore, we need to get the rank the set of new tweets in each of the user X  X  visits. We here present a heuristic method to approximately define a user session based on users X  observable activities such as tweeting, replying, and retweeting. The relative relevance is then defined for tweets within the same session.

Let us denote the set of tweets received by the user u as S u , where S u ={ m i | i = 1 , S into multiple consecutive subsets so that each subset corresponds to a user session. The tweets in the k -th session are defined by tweet m . We estimate B ( k ) with observable user behavior data.

Let A ={ a m as tweeting, retweeting, and replying. We estimate the starting time of a session as one of the timestamps in A . The underlying guideline is that the starting time for a session should be close to the time when the earliest action was taken after a set of tweets was posted by followees. All tweets published between two consecutive starting times belongs to the same session.

The session partition method is an intuitive way to approximate the sessions. For as t  X  ( m ). Then we have session, that is, B ( k + 1).

Table II provides an example to illustrate the preceding proposed approach for session partition. The events in Table II are ordered by the publishing time of the tweet (the second column). There are two categories of events: passively receiving a tweet and actively publishing through posting a new tweet, retweeting, or replying to a received tweet. The third column is the time when the tweet was retweeted/replied. If this tweet was not retweeted/replied, it would be N/A. The fourth column is the start time of the There are three sessions being detected in this example and the user performs actions on three tweets within the second session.
 a score; (2) the tweets within the same user session/data unit will be compared with of the reordering model.

If new tweets arrive before user u ends his current session, according to the described rule, our partition method will assign the newly received tweets into the user X  X  next session, and tweets in these two sessions will be treated separately.

Our partition method in general can provide a good approximation of the user sessions when the records of the user X  X  active actions are adequate. However, if the This kind of problem can be alleviated by the relative relevance labeler introduced in Section 4.2. relevance of a tweet is based on the following assumption.

Assumption . Within the same user X  X  session, tweets being acted (retweeted/replied)
Although this assumption may not always be true, it is generally accepted that tweets acted upon are more relevant than those not acted upon. This assumption can be justified as follows. First, the relevance of a responded tweet is considered to be higher than that of the nonresponded tweets within the same user session. No tweet is considered to be more relevant than the tweets nearby within a time window in the timeline. We conservatively assume that there is no relative relevance between two tweets that are far from each other in the time being posted, regardless of the user X  X  responses to them. For example, a responded tweet with the rank of 11 is only considered to be more relevant than the nonresponded tweets with rank from 11  X  WS to 11 + WS if available, where WS is the window size of the comparison.

We denote the reorder model as function h ( . ). Given a tweet m , we calculate its j | X  WS , m pairwise preference as training data is similar to that of the click-through method in Joachims [2002].

The reason that we do not directly use the responded tweets as positive samples is that the ratio of the number of user X  X  retweets to the number of tweets the user u received is quite low. According to our analysis (as shown in Table III) only 0.09% of received tweets are responded by a user. That means if we directly use those responded tweets as our positive samples, the positive samples will be quite scarce. The second point is that there are a variety of possible reasons behind a nonresponded tweet: (a) not interested in it; (c) the user somehow does not see this tweet at all; (d) although the tweet is interesting to him/her, the user deliberately chooses not to retweet it. With the personalized features and training data discussed before, the remaining ques-tion is how to learn a model from the data. We use one of the state-of-the-art machine learning methods: Gradient Boosted ranking (GBrank)[Zheng et al. 2007] as the un-derlying algorithm for our learning. Please note that other pairwise-preference-based pare different pairwise preference learning methods. GBrank is a general framework to learn ranking functions with any regression algorithm as the base learner. By minimiz-ing the pairwise loss on the observed data generated, we model the relevance of tweets and has the ability to capture the nonlinearity of features to tweet relevance.
For user X  X  k -th session, the training inputs of the GBrank module are the set of feature vectors {  X  m h means more relevant tweets will achieve higher scores than other tweets in the same user X  X  session.
 More details about how to train the GBrank function h ( . ) are presented in the Appendix. We compare three methods for reordering the tweets for a user. The first method under comparison is Twitter X  X  default way of simply ordering the tweets by their publishing time (thereafter denoted as TIMELINE). The second method is the proposed reorder-ing method (denoted as GBREORDER) where tweets are ordered by their potential relevance to the user as predicted by the machine learned model. All features described in Section 3, that is, features  X  1 to  X  19 , are used in the GBREORDER method. To test the effectiveness of the personalized features, we also consider a third method (NONPERSONALIZED) for comparison which is the same as the second method  X  There are two types of Twitter data: publishing data (e.g., what and when are users posting); and subscription data (e.g., users have followed which of Twitter users).
For the purpose of tweet reordering, we are only interested in the active Twitter users in this experiment. We empirically define Twitter users who retweet or reply at Twitter users in July 2010 according to our data. Due to the limitation of resource, we randomly choose 816 users from them for this study. We crawled all the followee lists of these selected active users with Twitter API. The average number of followees for the selected users are 834.

The publishing data of these selected active Twitter users and their followees include published before 2010-07-11 00:00 are used for training. Tweets published after 2010-07-21 00:00 are left out for evaluation. The remaining tweets are used as validation set for parameter tuning. In this work, we use pairwise reordering accuracy ( ACC ), Mean Reciprocal Rank as our evaluation metrics. Given a user session, let N r and N ir denote the number of relevant tweets and the number of irrelevant tweets in the session, respectively. The pairwise reordering accuracy for a user session is then expressed by equivalent to the number of irrelevant tweets with rank lower than that of the i -th relevant tweet. The ACC is then averaged over all user sessions.

MRR is the mean (calculated over all user session) of the reciprocal rank ( RR )for each user session with the RR is defined as where rank i is the rank for the i -th relevant tweet.
 it X  X  different for each session. We use the pairwise preference data as input for training. A tweet being responded by the user is considered to be more relevant than tweets not being responded nearby within a window size in timeline order. Denote the window size as WS . We tune this reordering model achieves best performance on the validation set when WS is set as 20. In the rest of experiments, we set the window size WS to be 20.

Table IV and V provide a real case to illustrate the effectiveness of GBREORDER when compared with TIMELINE. After the reordering, more relevant tweets bubble up to top positions according to the relevance score (from rank 6, 16, 20 in the TIMELINE to rank 1, 3, 4), which enables users to find the interesting/important tweets more efficiently.
 In Figure 2, we show the performance of GBREORDER, TIMELINE, and NON-PERSONALIZED in terms of the three metrics. We can see that both GBREORDER and NONPERSONALIZED have outperform TIMELINE in terms of the three met-rics. For example, the accuracy is improved by 34 . 5% when comparing the results of TIMELINE and GBREORDER. Moreover, compared with the NONPERSONALIZED results, GBREORDER achieves more performance gain. For example, there is around 3 . 8% improvement in terms of the prediction accuracy. This shows the effectiveness of the personalized features we proposed for tweets reordering. As a property of the boosted trees (boosted trees are used in the GBrank), a greedy feature selection already happens in our model learning. As a byproduct, the GBrank provides a feature importance list, which is computed by keeping track of the reduction of loss function along each feature variable [Friedman 2001].

The feature importance to our GBREORDER algorithm is listed in Table VI. Features not listed in Table VI are eliminated by the GBrank algorithm. Figure 3 shows the curves of accuracy, MRR, and RP scores of our GBREORDER model, when it X  X  trained with different number of top features from the importance list in Table VI. The feature selection adopted here is straightforward but effective for the boosted trees algorithm such as GBrank.

The top two features are time freshness and rank freshness. Given users in general are interested in getting real-time update/information from their contacts, it seems reasonable to have freshness as the key factors for reordering. On the other hand, in the training sessions, the tweets are ordered by publishing time. It is generally Hence the importance of freshness features could also be partially due to an artifact introduced together with the presentation bias in the training data. According to our evaluation, the TIMELINE method, which simply orders the tweets by their freshness, has a much more inferior performance than the GBREORDER method, indicating some other factors also played important roles in tweet reordering.

The next important feature is retweet count, which indicates that a widely spread search engine. The retweet count by followee is a similar feature, but to our surprise it doesn X  X  help in our model. Large retweet count usually corresponds to high quality. Butifmostoftheuser u  X  X  followees have already retweeted it, the tweet might not be retweeted by u . Therefore according to our evaluation this tweet might be considered not as important as other tweets and the feature  X  13 retweet count by followee is not as effective as we expected.

The feature follower count, representing the popularity of the author of the tweet, is also helpful. The importance of this feature is consistent with the observations in an optional function and most users X  list count is zero.

As we expected, the count and ratio of retweet and reply by user are important features for reordering. They provide useful guidelines for predicting whether the tweet will be retweeted/replied by the user or not.

The feature  X  15 , the interest match between the author and the reader, also plays a role in our model (if we drop feature  X  15 , the accuracy, MRR, and RP scores will tweet topics and user interests, is not as effective as the interest match (if we drop 0 . 53%, respectively), because only about 10% of tweets X  topics can be inferred, due to the fact that tweets have very limited length and the words used in Twitter are very informal. Many tweets are just noises with no meaningful topic [Kelly 2009]. The the author and the reader still works, since we use all the user X  X  tweets to learn the user X  X  interests. The interests of users are more reliable than the inferred topics of tweets. This similarity between different users is in fact quite accurate, especially when the reader and the author share lots of common tweets. an assumption that retweeted/replied tweets are relatively more relevant than other tweets. This somehow brings some limitations to our method.
  X  X e assume that retweeting by the user u to a tweet suggests that to some extent, the does not necessarily equal to relevance. There might be other criteria besides the retweet/reply to judge whether a tweet is relevant to its reader.  X  X ome nonresponded but relevant tweets (i.e., some high-quality tweets which are not responded by user u ) will hurt the accuracy for both training and evaluation because we treat them as irrelevant tweets by definition.  X  X e do not have the browsing information of the users. So we are not sure whether a tweet is actually read by the user u or not. This will affect the quality of the user session partition and the relative relevance definition to some extent.
 In all, our method works for those Twitter users with active retweeting or replying activities. Applying the method to nonactive users may obtain unsatisfiable reordering relevance. Therefore, the more the user takes action in Twitter, the better the tweets X  relevance would be by our method. or important tweets. It is hence very important to reorder a user X  X  unread tweets. Ac-cording to our experiments, our GBREORDER method is a very effective personalized method, in comparison with the default TIMELINE method and the NONPERSON-ALIZED method. The direct application of our method could be a Twitter client that client, we can get the users X  real browsing behaviors and refine our model.
For now, we only evaluated our method based on user observable behaviors. We attempted to get real users X  feedback by selecting 54 active users and asking their tically meaningful evaluation. A larger scale of manual evaluation may be performed for future work.
 In this appendix, we describe the details of the GBrank algorithm with GBDT (Gradient Boosting Decision Tree) as the base regression learner for our tweets reordering task in Algorithm 1.

The hyper-parameters in Algorithm 1 such as the number of tree M and the learning rate  X  are determined by cross-validation on the training dataset.

