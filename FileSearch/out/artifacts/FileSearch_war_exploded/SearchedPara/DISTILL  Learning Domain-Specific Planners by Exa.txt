 Elly Winner ELLY @ CS . CMU . EDU Manuela Veloso MMV @ CS . CMU . EDU Intelligent agents must develop and execute autonomously a strategy for achieving their goals in a complex environ-ment, and must adapt that strategy quickly to deal with un-expected changes. Solving complex problems with classi-cal domain-independent planning techniques has required prohibitively high search efforts or tedious hand-coded domain knowledge, while universal planning and action-selection techniques have proven difficult to extend to com-plex environments.
 Researchers have focused on making general-purpose plan-ning more efficient by using either learned or hand-coded control knowledge to reduce search and thereby speed up the planning process. Machine learning approaches have relied on automatically extracting control information from domain and example plan analysis, with relative success in simple domains. Hand-coded control knowledge (or hand-written domain-specific planners) has proved more useful for more complex domains. However, it frequently requires great specific knowledge of the details of the underlying domain-independent planner for humans to formalize use-ful rules.
 In this paper, we introduce the concept of dsPlanners, or au-tomatically generated domain-specific planning programs. We then describe the D ISTILL algorithm, which automat-ically extracts complete non-looping dsPlanners from ex-ample plans, and our method for identifying one-step loops in example plans.
 The learning techniques used in the D ISTILL algorithm allow problem solving that avoids the cost of generative planning and of maintaining exhaustive databases of ob-served behavior by compiling observed plans into compact domain-specific planners, or dsPlanners. These dsPlanners are able to duplicate the behavior shown in the example plans and to solve problems based on that behavior. Other planning methods have exponential time complexity, but dsPlanners return a solution plan or failure with complex-ity that is linear in the size of the planners, and the size of the solution, modulo state matching effort. The current D
ISTILL algorithm learns non-looping dsPlanners from ex-ample plans supplemented with their rationales. We show that these dsPlanners succeed in compactly capturing ob-served behavior and in solving many new problems. In fact, dsPlanners extracted from only a few example plans are able to solve all problems in limited domains. Due to the complexity of finding optimal solutions in plan-ning, dsPlanners learned automatically from a finite num-ber of example plans cannot be guaranteed to find optimal plans. Our goal is to extend the solvability horizon for planning by reducing planning times and allowing much larger problem instances to be solved. We believe that post-processing plans can help improve plan quality.
 Our work on the D ISTILL algorithm for learning dsPlan-ners focuses on converting new example plans into dsPlan-ners in if-statement form and merging them, where possi-ble. Our results show that merging dsPlanners produces a dramatic reduction in space usage compared to case-based or analogical plan libraries. We also show that by con-structing and combining the if statements appropriately, we can achieve automatic situational generalization , which al-lows dsPlanners to solve problems that have not been en-countered before without resorting to generative planning or requiring adaptation.
 We first discuss related work. Then, we formalize the con-cept of dsPlanners. Next, we present the novel D ISTILL algorithm for learning complete non-looping dsPlanners from example plans and present our results. We then dis-cuss our algorithm for automatically identifying one-step loops in example plans. We discuss related work in three main areas: in classi-cal planning and learning, since our approach is another method of learning for planning; in automatic program gen-eration, since our approach is to learn a planning program; and in universal planning, since the planning program our techniques learn is, effectively, a universal plan. 2.1. Domain Knowledge to Reduce Planning Search A large body of work has focussed on acquiring and us-ing domain knowledge to reduce planning search. Some of the most commonly used forms of domain knowledge are control rules, e.g., (Minton, 1988); macro operators, e.g., (Fikes et al., 1972); case-based and analogical reasoning, e.g., (Kambhampati &amp; Hendler, 1992; Veloso, 1994); and hierarchical and skeletal planning, e.g., (Sacerdoti, 1974; fer from the utility problem, in which learning more infor-mation can actually be counterproductive because of diffi-culty with storage and management of the information and with determining which information to use to solve a par-ticular problem. In many cases, domain knowledge written by humans is also much more useful than that learned by computers. However, writing domain knowledge by hand is often very time-consuming and difficult, in part because writing effective domain knowledge often requires a deep understanding of the problem-solving architecture of the underlying planner. Though each of these techniques has been shown to reduce dramatically the planning time re-quired to solve certain problems, they do not reduce the complexity of the planning problem and cannot, in general, solve problems without falling back on generative plan-ning with a general-purpose planner. Our approach avoids generative planning search and the reliance on a general-purpose planner by acquiring a domain-specific planning program from observed example plans.
 One technique used to identify control knowledge is explanation-based learning (EBL). This technique consists of explaining a success or failure in a search conducted by a specific planner. Given a state and a set of goals, EBL gen-erates the explanation by filtering away the facts of the state or other goals that are not relevant to the success or failure of the search. Hence, EBL, applied to planning, produces control knowledge that guides the choices encountered in the search process of an existing planner. DsPlanners also rely on explaining example plans by looking at the weakest preconditions between state and goals. However, dsPlan-ners are not control knowledge for an existing planner; they are themselves planners: complete programs that create an output plan. 2.2. Automatic Program Generation Work on automatic program generation can be divided into two main classes: deductive and inductive program synthe-sis . In deductive program synthesis, programs are gener-ated from specifications, e.g., (Smith, 1991). We do not know of a general and concise way to describe the desired behavior of a domain-specific planner except through ex-amples. Generating a program from examples is called in-ductive program synthesis. Our work falls into this cat-egory. Some work in inductive program synthesis in-duces programs from input/output pairs, e.g., (Muggleton, 1991). In planning, this corresponds to inducing a plan-ning program by looking only at pairs of initial and goal states. Other work induces programs from example exe-cution traces, e.g., (Bauer, 1979; Lau, 2001). In planning, this corresponds to inducing a planner from example prob-lems and solution plans that solve the problems. This is the approach we have taken.
 However, work in inductive program synthesis is not im-mediately applicable to our problem. In much inductive program synthesis work, example execution traces are an-notated to mark the beginnings and ends of loops, to spec-ify loop invariants and stopping conditions, to mark condi-tionals, etc. This kind of labelling cannot be obtained au-tomatically from observed executions, so we do not allow it in our work. Another difference is that, whereas many approaches to IPS must attempt to induce the purpose of the steps from many examples, in our planning-based ap-proach, the purpose of each step is automatically deduced via plan analysis. This information is critical to rapidly and correctly identifying the conditions for executing a se-quence of steps or for terminating a loop. Despite these differences, several researchers have explored the applica-tion of inductive program synthesis to planning.
 Inductive program synthesis has been used to generate iter-ative and recursive macro operators, e.g., (Schmid, 2001). These macros capture repetitive behavior and can drasti-cally reduce planning search by encapsulating an arbitrar-ily long string of operators. However, unlike our approach, this technique does not attempt to replace the generative planner, and so does not eliminate planning search. Some work has also focussed on analyzing example plans to reveal a strategy for planning in a particular domain in the form of a decision list (Khardon, 1999), or a list of condition-action pairs. These condition-action pairs are derived from example state-action pairs. This technique is able to solve fewer than 50% of 20-block Blocksworld problems and requires over a thousand state-action pairs to achieve coverage (Khardon, 1999). In our work, we pre-serve and analyze the structure of the observed plans in or-der to extract as much information as possible from limited evidence. Our hope is that this will result in a more suc-cessful algorithm that requires orders of magnitude fewer examples. 2.3. Universal Planning Some researchers have sought to avoid the planning search problem by acquiring and using  X  X niversal plans, X  or pre-computed functions that map state and goal combinations to actions. Our work can be seen as a new method of ac-quiring and storing universal plans.
 One previous approach to automatically acquiring a uni-versal plan is reinforcement learning. There has, however, been limited success in applying the solution to one prob-lem to another, particularly to a larger or more complex problem. There have also been many approaches to finding more compact ways of representing the learned universal plan, e.g., (Uther &amp; Veloso, 2000), but such plans can still be prohibitively large for interesting problems in complex domains.
 Decision trees have also been used in a purely planning context. Schoppers suggests decision trees splitting on state and goal predicates (Schoppers, 1987), but finds these trees by conducting a breadth-first search for solutions X  X  method which is too time-consuming for most domains. Other researchers have used Ordered Binary Decision Dia-grams (OBDDs) to represent universal plans (Cimatti et al., 1998). OBDDs provide an effective way to compress a uni-versal plan without losing precision, however are currently generated via blind backwards search from goal states, a method that is impractical in complex domains. We now introduce the concept of a dsPlanner, a domain-specific planning program that, given a planning problem (initial and goal states) as input, either returns a plan that solves the problem or returns failure, if it cannot do so. The dsPlanner is a novel method of storing planning knowl-edge. It is expressive and compact and does not rely on an underlying general-purpose planner.
 DsPlanners are composed of the following programming constructs and planning-specific operators:  X  while loops;  X  if , then , else statements;  X  logical structures ( and , or , not );  X  in goal state and in current state operators;  X  v variant indicators;  X  plan predicates; and  X  plan operators.
 In order for dsPlanners to capture repeated sequences in while loops and to determine that the same sequence of op-erators in two different plans has the same conditions, they must update a current state as they execute by simulating the effects of the operators they add to the plan. Without this capability, we would be unable to use such statements as: while (condition holds) do (body). Therefore, in or-der to use a dsPlanner, it must be possible to simulate the execution of the plan. However, since dsPlanner learning requires full STRIPS-style models of the planning opera-tors, this is not an additional problem.
 The dsPlanner language is rich enough to allow compact planners for many difficult problems. We demonstrate this by presenting two short hand-written dsPlanners that solve all problems in well-known domains. Our current algo-rithm for learning dsPlanners from examples, D ISTILL does not find looping dsPlanners. However, we continue to work towards this goal, and in Section 5, we describe the D ISTILL procedure for identifying simple loops in ex-ample plans.
 Table 1 shows a simple but suboptimal hand-written dsPlanner that solves all BlocksWorld-domain (Veloso, 1994) problems that involve building towers of blocks. The dsPlanner is composed of three while loops: first, all blocks should be unstacked; then, the second-to-bottom block of every tower should be stacked onto the bottom block; then, for each block that is stacked on a second block in the goal state, if the second block is already stacked on a third, go ahead and stack the first block on the second.
 Table 2 shows a hand-written dsPlanner that solves all Rocket-domain (Veloso, 1994) problems. The dsPlanner is composed of two while loops: while there is some package that is not at its goal location, execute the following loop: while there is some package in the rocket that should arrive at a goal destination, unload all packages in the rocket that should end up in the rocket X  X  current city, load all packages in the rocket X  X  current city that should go elsewhere, then fly the rocket to the goal destination of the package inside it that should be delivered to a goal destination. Once the rocket contains no more packages that should be delivered to goal destinations, fly the rocket to the location of the original misplaced package, load it into the rocket, and be-gin the rocket-emptying loop again. Once all the packages are correctly placed, fly each rocket to its goal location. We now describe how to generate plans from dsPlanners. As previously mentioned, while executing the dsPlanner, we must keep track of a current state and of the current solution plan. The current state is initialized to the initial state, and the solution plan is initialized to the empty plan. Executing the dsPlanner is the same as executing a pro-gram : it consists of applying each of the statements to the current state. Each statement in the dsPlanner is either a plan step, an if statement, or a while loop. If the current statement is a plan step, make sure it is applicable, then append it to the solution plan and apply it to the current state. If the current statement is an if statement, check to see whether it applies to the current state. If it does, apply each of the statements in its body; if not, go on to the next statement. If the current statement is a while loop, check to see whether it applies to the current state. If it does, ap-ply each of the statements in its body until the conditions of the loop no longer apply. Then go on to the next state-ment. Once execution of the dsPlanner is finished and all suggested plan steps have been determined to be applica-ble, the final state must be checked to ensure that it satisfies the goals. If it does, the generated plan is returned. Oth-erwise, the dsPlanner must return failure. As previously mentioned, dsPlanner execution is of linear time complex-ity in the size of the dsPlanner, the size of the problem, and the size of the solution. The current version of the D ISTILL algorithm, shown in Table 3, learns complete, non-repeating dsPlanners from sequences of example plans, incrementally adapting the dsPlanner with each new plan. In Section 5, we present the D
ISTILL procedure for identifying simple loops in exam-ple plans. We describe the two main portions of the current D
ISTILL algorithm (converting example plans into dsPlan-ners and merging dsPlanners) in detail in the rest of this section. We use online learning in D ISTILL because it al-lows a learner with access to a planner to acquire dsPlan-ners on the fly as it encounters gaps in its knowledge in the course of its regular activity. And because dsPlanners are learned from example plans, they reflect the style of those plans, thus making them suitable not only for planning, but also for agent modeling.
 D
ISTILL can handle domains with conditional effects, but we assume that it has access to a complete STRIPS-style model of the operators and to a minimal annotated consis-tent partial ordering of the observed total order plan. Pre-vious work has shown that STRIPS-style operator models are learnable through examples and experimentation (Car-bonell &amp; Gil, 1990) and has shown how to find minimal an-notated consistent partial orderings of totally-ordered plans given a model of the operators (Winner &amp; Veloso, 2002). The D ISTILL algorithm converts observed plans into dsPlanners, described in Section 4.1, and merges them by finding dsPlanners with overlapping solutions and combin-ing them, described in Section 4.2. In essence, this builds a highly compressed case library. However, another key benefit comes from merging dsPlanners with overlapping solutions: this allows the dsPlanner to find situational gen-eralizations for individual sections of the plan, thus allow-ing it to reuse those sections when the same situation is encountered again, even in a completely different planning problem. 4.1. Converting Plans into dsPlanners The first step of incorporating an example plan into the dsPlanner is converting it into a parameterized if statement. First, the entire plan is parameterized. D ISTILL chooses the first parameterization that allows part of the solution plan to match that of a previously-saved dsPlanner. If no such parameterization exists, it randomly assigns variable names Next, the parameterized plan is converted into a dsPlanner, as formalized in the procedure Make New If Statement in Table 3. The conditions of the new if statement are the initial-and goal-state terms that are relevant to the plan. Relevant initial-state terms are those which are needed for the plan to run correctly and achieve the goals (Veloso, 1994). Relevant goal-state terms are those which the plan accomplishes. We use a minimal annotated consistent par-tial ordering (Winner &amp; Veloso, 2002) of the observed plan to compute which initial-and goal-state terms are relevant. The steps of the example plan compose the body of the new if statement. We store the minimal annotated consistent partial ordering information for use in merging the dsPlan-ner into the previously-acquired knowledge base. Figure 1 shows an example minimal annotated consistent partially ordered plan with conditional effects. Table 4 shows the dsPlanner D ISTILL creates to represent that plan. Note that the conditions on the generated if statement do not include all terms in the initial and goal states of the plan. For example, the dsPlanner does not require that e(z) be in the initial and goal states of the example plan. This is because the plan steps do not generate e(z) , nor do they need it to achieve the goals. Similarly, b(x) and the condi-tional effects that could generate the term c(x) or prevent its generation are also ignored, since it is not relevant to achieving the goals. 4.2. Merging dsPlanners The merging process is formalized in the procedure Add To dsPlanner in Table 3. The dsPlanners learned by the D ISTILL algorithm are sequences of non-nested if state-ments. To merge a new dsPlanner into its knowledge base, D
ISTILL searches through each of the if statements already in the dsPlanner to find one whose body (the solution plan for that problem) matches that of the new problem. We consider two plans to match if:  X  one is a sub-plan of the other, or  X  they overlap: the steps that end one begin the other. If such a match is found, the two if statements are com-bined. If no match is found, the new if statement is simply added to the end of the dsPlanner.
 We will now describe how to combine two if statement dsPlanners, if the body of if conditions C and any step s applicable in the situation C we define C s is executed in the situation C . We also define a new func-tion, Relevant ( C,s ) , which, for any set of conditions and any plan step s , returns the conditions in C that are relevant to the step s .
 Merging if We will label them if is set to a and its conditions are Relevant ( x,a ) . The body of if Relevant ( y,b ) . 3 Finally, the body of if 5 is c and its con-ditions are Relevant ( x ready a member of the dsPlanner is removed and replaced by the three new if statements.
 Combining two if statements with overlapping bodies is similar. Merging the two if statements if and if ments, labelled if to a and its conditions are Relevant ( x,a ) . The body of if Relevant ( y,b ) . Finally, the body of if 5 is c and its con-ditions are Relevant ( y is already a member of the dsPlanner is removed and re-placed by the three new if statements. 4.3. Illustrative Results We present results of applying D ISTILL to limited domains since we have not yet added to D ISTILL the ability to learn looping dsPlanners from observed plans. Our results show that, even without the ability to represent loops, the dsPlan-ners learned by D ISTILL are able to capture complete do-mains from few examples and to store these complete solu-tions very compactly.
 Table 5 shows the dsPlanner learned by the D ISTILL gorithm that solves all problems in a blocks-world domain dsPlanner needs to store only two plan steps, and it is possi-ble for D ISTILL to learn the dsPlanner from only 6 example plans. These six example plans were chosen to cover the domain; more examples could be required for the complete dsPlanner to be learned if the examples were randomly se-lected.
 Table 6 shows the dsPlanner learned by the D ISTILL gorithm that solves all gripper-domain problems with one ball, two rooms, and one robot with one gripper arm. Al-D
ISTILL algorithm to learn the dsPlanner from only six ex-ample plans. Also note that only five plan steps (the length of the longest plan) are stored in the dsPlanner. Our results show that dsPlanners achieve a significant re-duction in space usage compared to case-based or analog-ical plan libraries. In addition, dsPlanners are also able to situationally generalize known problems to solve problems that have not been seen. We now present the D ISTILL procedure to identify one-step loops in which repeated behaviors are not causally linked. A looping plan in the rocket domain involves loading sev-eral packages into the rocket, flying the rocket to the goal destination, and then unloading all the packages. In this ex-ample, the sequence of package loads is a loop, since they are repeated identical behaviors. No package load in this loop is causally linked to the other loads. The unloading sequence is a similar loop. The algorithm we use to iden-tify such loops is shown in Table 7, and Table 8 shows the dsPlanner code our algorithm extracts from the above ex-ample.
 The D ISTILL procedure for identifying loops in observed plans identifies steps that are not linked in the transitive closure of the partial ordering of the plan (and thus run in parallel). If the parallel plan steps are the same operator, differ in only one variable, and have the same needs and ef-fects, they are considered part of a loop. The conditions for the loop X  X  execution are the needs and effects of the steps it encompasses. The repeated steps are removed from the plan and replaced by the newly created loop. Many solu-tions to planning problems involve the repetition of steps, which, when translated into appropriate loops, will greatly increase the complexity of the problems the planner can solve. In this paper, we contribute a formalism for automatically-generated domain-specific planning programs (dsPlanners) and present the D ISTILL algorithm, which automatically learns non-looping dsPlanners from example plans. The D
ISTILL algorithm first converts an observed plan into a dsPlanner and then combines it with previously-generated dsPlanners. Our results show that dsPlanners learned by the D ISTILL algorithm require much less space than do case libraries. dsPlanners learned by D ISTILL also support situational generalization, extracting commonly-solved sit-uations and their solutions from stored dsPlanners. This allows dsPlanners to reuse previous planning experience to solve different problems. We also discuss our work to-wards automatically acquiring looping dsPlanners. Loop-ing dsPlanners will allow observed solutions to small prob-lems to be used to solve arbitrarily large ones.

