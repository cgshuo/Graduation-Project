 Comments left by readers on Web documents contain valu-able information that can be utilized in different informa-tion retrieval tasks including document search, visualization, and summarization. In this paper, we study the problem of comments-oriented docume nt summarization and aim to summarize a Web document (e.g., a blog post) by consider-ing not only its content, but also the comments left by its readers. We identify three relations (namely, topic , quota-tion ,and mention ) by which comments can be linked to one another, and model the relations in three graphs. The im-portance of each comment is then scored by: (i) graph-based method , where the three graphs are merged into a multi-relation graph; (ii) tensor-based method , where the three graphs are used to construct a 3rd-order tensor. To gen-erate a comments-oriented summary, we extract sentences from the given Web document using either feature-biased approach or uniform-document approach . The former scores sentences to bias keywords derived from comments; while the latter scores sentences uniformly with comments. In our experiments using a set of blog posts with manually la-beled sentences, our proposed summarization methods uti-lizing comments showed significant improvement over those not using comments. The methods using feature-biased sen-tence extraction approach were observed to outperform that using uniform-document approach.
 H.3.1 [ Content Analysis and Indexing ]: Abstracting methods; H.3.3 [ Information Search and Retrieval ]: In-formation filtering Experimentation Document Summariza tion, Blog, Comments, Graph-based Scoring, Tensor-based Scoring
Document summarization has always been an important research topic in Information Retrieval (IR). Most existing document summarization tasks take either one document or multiple topically related documents as input, and gener-ate a short document containing the main topics covered by the input document(s) [11, 19, 21]. The resultant summary is therefore determined by the document content provided by the author(s). With the popularity of social websites (e.g., blogs), many Web documents are now presented to-gether with annotations given by their readers in the form of tags, comments, ratings, and others. These user gener-ated annotations are valuable input from the readers and can be utilized in different IR tasks. For instance, tags were showntoimproveWebsearchin[2]. Inthispaper,wefocus on comments-oriented docume nt summarization and aim to summarize a Web document using not only its content, but also the comments contributed by its readers.

The comments-oriented docu ment summarization task to produce a concise document covering the topics presented in the document that are discussed among readers who gave thecommentsisinterestingfora t least three reasons. First, despite their informal tone and style of writing, comments represent readers X  understanding or feedback about a Web document X  X  content. By considering these comments, the generated summary can better capture the input from the readers, as opposed to the author of the document only. That is, a comments-oriented summary provides balanced views from both author and readers. Second, most websites present a Web document (e.g., blog post) together with its comments. In a separate study on blog conversation, it was found that readers treat comments associated with a post as an inherent part of the post [7]. A comments-oriented sum-mary hence better matches one X  X  understanding of the doc-ument as readers often read the document together with its comments. Third, the generated summary could better sup-port many IR applications. One example application is blog search. Many existing blog search engines rank results by recency of posts [20]. A post is ranked at the top because of its recency and/or its containing of a query keyword. With comments-oriented summary, a post can be ranked high if the query keyword is relevant to the main topic of the post identified by its readers through comments.
In this research, we aim to generate comments-oriented summary in the form of extract ed sentences from a given Web document. As shown in Figure 1, we view the given document as a set of sentences and score them with input from both the document and its comments. A subset of sentences is then selected to form the summary satisfying the length requirement. The main focus is sentence scoring , which is expected to deal with two challenges. Firstly, the number of comments varies significantly from one document to another. In the extreme case, a document may not receive any comment. In this case, we may have to fall back to identifying important sentences by the document content only. Secondly, comments are inherently informal and noisy. Many comments may contain information irrelevant to the Web document content.

Depending on the way comments are utilized in sentence scoring, our proposed summarization techniques are classi-fied into either feature-biased approach or uniform-document approach . In feature-biased approach, we treat comments-oriented summarization task as query-biased summarization task, where the query are those keywords derived from the comments. Determining the importance of comments (and hence the words appearing in them) is therefore the key of feature-biased approach. In uniform-document approach, we form a virtual document from the given document and its comments such that it consists of a set of text units. Here, a text unit is either a sentence from the document or a com-ment. The summary is composed by those highly scored text units that are sentences from the original document. Many techniques developed for ranking sentences in single docu-ment summarization could therefore be extended to address comments-oriented summarization using uniform-document approach. In particular, we show in this paper that the techniques for ranking comments (i.e., in the feature-biased approach) can be easily extended to score text units.
To score comments, we mode l the relationships among them using three graphs, namely, topic , quotation and men-tion graphs. Given the three graphs, two techniques are proposed in this paper. One is to merge them into one multi-relation graph and perform graph-based scoring us-ing random walk algorithm [9, 19]. Another is to construct a 3rd-order tensor and score the comments using tensor de-composition. To the best of our knowledge, this is the first effort to bring tensor-based analysis into document summa-rization. With the combinations of two scoring techniques and two summarization approaches, we compare the four methods in our experiments using manually labeled docu-ments.
 Our major contributions in this research are as follows. Firstly, we propose two approaches to address comments-oriented document summarization. In the feature-biased ap-proach, words appearing in comments but not in the given document do not contribute to scoring sentences. The ap-proach is more tolerant to noise in comments. In the uniform-document approach, when there is no or very few comments, the problem naturally degrades to single document sum-marization. Secondly, we introduce tensor-based scoring to score comments (or sentences) in document summarization. Compared to graph-based scoring, tensor-based scoring can directly deal with multiple relations among comments (or sentences) that may also be presented in other document summarization problems besi des comments-oriented sum-marization.
The rest of the paper is organized as follows. In Section 2, we review the related studies. The relationships among com-ments are given in Section 3. The graph-based and tensor-based scoring algorithms are proposed in Section 4, followed by the two approaches for comments-oriented summariza-tion in Section 5. Our experiments are reported in Section 6. We conclude the paper in Section 7.
To generate an extractive summary, sentences in the doc-ument(s) are to be scored according to their salience in rep-resenting the major topic(s) of the document(s). Techniques proposed in literature that aim to measure the salience of sentences can be broadly categorized into three groups: lex-ical chain based methods [3, 25], feature-based methods [11, 21] and graph-based methods [9, 19, 23]. In lexical chain based methods, a lexical-chain is defined by a coherent se-quence of related nouns, verbs, etc., computed based on a thesaurus such as WordNet. Sentences are then scored ac-cording to the lexical chains they belong to. In feature-based methods, each sentence is scored based on some features in-cluding position, length, cue phrases, signature words, etc. In graph-based methods, a sentence sharing similar content with another is considered as a semantic recommendation to the latter. PageRank [4] like algorithms are used to score sentences in a graph constructed through the semantic affin-ity among sentences. It was also shown that graph-based method can improve single-doc ument summarization by in-corporating multiple documents of the same topic [23].
Recently, Web document summarization has gained inter-est from many researchers. Based on the assumption that queries related to a Web page provide some human under-standing about that page, Sun et al proposed to summarize Web pages using clickthrough data in [22]. In their work, a word was weighted by a linear combination of its term frequency in the page and its term frequency derived from the page X  X  clickthrough record. Both LSA (Latent Semantic Analysis)-based and Luhn X  X  methods [17] were applied to se-lect sentences from Web pages and the two methods achieved comparable performance. The proposed approach is similar to our feature-biased approach as both involve extra knowl-edge to the document to be summarized. Nevertheless, com-ments contributed by readers on a Web document are quite different in nature from clickthrough record generated by a search engine.

Summarization of blog post, a new type of textual con-tent on the Web, has not been well studied. Zhou et al viewed a blog post as a summary of online news articles it linked to, with added personal opinions [24]. A summary of a blog post is generated by extracting sentences from the blog post that are relevant to its linked news articles. Us-ing a similar technique presented in [18], one sentence that is most dissimilar to the linked articles is deleted from the post at each iteration, until any more deletion would result in a drop in similarity between the summary and the linked articles. Comments associated with blog posts were however not used.

Utilizing comments to extract sentences from Web docu-ments is quite related to the work of identifying most com-mented sentences reported in [8]. Eight features of com-ments, such as number of terms common to the post in the comment , number of sentences in the comment ,andsoon, were identified to represent each comment using a feature vector. The comments were then clustered based on their feature vectors and human experts were involved to deter-mine the relevance of each cluster. The possible relation-ships among comments were not considered.

Constructing a quotation graph for the purpose of sum-marization is also relate d to the work by Carenini et al who summarized email conversation using  X  X lue words X  obtained from quoted email fragments [5]. Emails were first split into fragments and a fragment quotation graph was then con-structed from fragments for identifying the  X  X lue words X . Their fragment quotation graph is similar to our quotation graph constructed from comments (see Section 3.2) as both rely on quotation relation. However, there are two major differences between the two graphs. First, in their fragment quotation graph, each node is a fragment identified from emails; in our quotation graph, each node is a comment (not fragment). Second, in [5], sentences could be extracted from the fragment quotation graph as a part of the summary. In our approach no sentence from comments is extracted.
In this section, we first formally define the problem of comments-oriented document summarization and then dis-cuss the possible relationships among comments.
Given a document D consisting of a set of sentences D = { s 1 ,s 2 ,...,s n } , and a set of comments C = { c 1 ,c 2 ,...,c associated with D ,thetaskof comments-oriented document summarization is to extract a subset of sentences from D , denoted by S c ( S c  X  D ), that best represents the topic(s) presented in D and discussed among its comments C .
In the above definition, D could be a news article, a blog post, or any other Web document. The set of comments C generally refers to those short textual messages contributed by readers and attached to D . All our following discussions refer to this setting. Nevertheless, the definition does not restrict the form of  X  X omments X . A blog post can also be considered as a comment to its referenced post or news ar-ticle. Note that, the task of comments-oriented document summarization degrades to single-document summarization when the given document is not associated with any com-ment.
Comments provide readers X  feedback about a Web doc-ument and also contribute to the discussion of topics pre-sented in the document. The linkages among them often represent the discussion flow. Understanding the linkages among comments is hence critical for comments-oriented summarization. Based on our observation, three relations commonly exist among comme nts, linking one comment to others.
Based on the above three relations, we derive three graphs, namely, topic graph , quotation graph ,and mention graph .In each graph, the set of nodes are comments and the set of edges represent the particular relation. The weight associ-ated with each edge is the strength of the corresponding rela-tionship. Example of these graphs are given in Figures 2(a), (b), and (c), all involving the same set of four comments. The affinity matrix of each gra phisshownontherightside of the graph. In these three graphs, all edges are binary weighted for clarity.

Compared to quotation and mention, topic relationship is more commonly found amon g comments. In most cases,
If the mentioned contributor publishes several comments, all these comments are related to the mentioning comment through mention relation. Note that, mention could also occur in the passage of a quotation, as quotation is treated as part of a comment. both quotation and mention graphs could be very sparse. However, two comments having very weak or even no topic relationship might be strongly related through mention or quotation. In other words, both quotation and mention re-lations complement topic relation in identifying the linkages among comments.

In some websites, comments are presented in a tree-like structure indicating reply relationships among them. As such reply relationship is website specific, we choose not to include it in our discussion. Nevertheless, our proposed techniques can be easily extended to include this relation (and other relations) if available.
One important task in comments-oriented document sum-marization is to determine the importance of each com-ment in representing the discussed topic(s). Given the three graphs, we propose two methods to integrate the three graphs and score comments.
A straightforward approach to integrate topic graph , quo-tation graph ,and mention graph is to merge them into one multi-relation graph. In the merged graph, the weight of a directed edge between two comments is the total weights re-ceived from all the three graphs, as illustrated by Figure 2(d) together with the affinity matrix 2 .

It is intuitive that important comments are those whose topics are discussed by a large number of other important comments. Based on this intuition, we propose to use PageR-ank [4] algorithm to score the comments (see Equation 1).
Score ( c i )=  X   X  1 |C| +(1  X   X  )  X  where  X  is the damping factor as in PageRank (in our ex-periments  X  =0.15). |C| denotes the number of comments associated with the given document, and w ( c j ,c i )isthe normalized weight from comment c j to c i derived from the multi-relation graph as shown in Equation 2. In Equation 2, e ( c j ,c k ) is the weight on the edge from com-ment c j to c k in the multi-relation graph, which is the sum of the weights on the corresponding edges in the three graphs; e ( c j ,c k ) = 0 if comments c j and c k are not related through any of the three relations.
Tensor provides a good means to represent multiple rela-tions in one data structure. Given the three graphs, a 3rd-order tensor can be constructed, as shown in Figure 2(e). In this tensor, both its first and second dimensions (i.e., mode-1 and mode-2) are comments. The third dimension (i.e., mode-3) represents the relations through which each pair of comments are linked. The constructed tensor therefore captures all three relationships among comments.
Based on the tensor, we measure the importance of com-ments through tensor decomposition. There are two de-composition techniques, namely, High-order SVD (Singular
Multiple edges between a pair of comments are shown solely for illustration purpose.
 Value Decomposition) and PARAFAC (PARAllel FACtor decomposition). The former leads to orthogonal singular vector(s) in each mode assuming that latent factors are in-dependent of each other. The latter does not assume such independence and produces a number of parallel factors. As-suming topics discussed among comments are less indepen-dent from each other, we decompose the 3rd-order tensor in Figure 2(e) through PARAFAC decomposition, shown in Equation 3 and illustrated by Figure 3.
 In Equation 3, tensor A is decomposed into R parallel fac-tors (see Section 6 on determining the value of R ).  X  (1  X  r  X  R ) is a scalar reflecting the salience of the cor-responding factor, which is a topic discussed among com-ments in our setting. Each V ( n ) r ( n =1 , 2 , 3) is a vector where values represent the salience of entries along mode-n with respect to factor r ;and  X  denotes outer product (see [6] for more details). In our setting, V (1) r reflects the salience of comments in supporting topic r , V (2) r reflects the salience of comments in representing topic r ,and V (3) r reflects the salience of relations in identifying topic r .

Based on the result of PARAFAC decomposition, we mea-sure the importance of a comment c i by the most salient topic it could best represent, as shown in Equation 4. In this equation, V (2) r ( i ) denotes the i th entry in vector V
In both graph-based scoring or tensor-based scoring, the scores computed for comments are normalized in the range of [0 , 1] before they are used in other computations.
We propose two approaches to incorporate comments into document summarization. The first approach scores docu-ment sentences based on keywords derived from comments; while the second approach scores document sentences and comments all together. The two comment scoring meth-ods (i.e., graph-based scoring and tensor-based scoring) pre-sentedinSection4canbeusedinbothapproaches.
In the feature-biased approach, the task of comments-oriented summarization is formulated as a query-biased doc-ument summarization problem where the queries are the keywords derived from comments.

With comments scored by their importance in represent-ing the discussed topic(s), words appearing in many impor-tant comments are more topic r epresentative. Thus, each word derives its score by accumulating the scores of the com-ments it appears in, shown in Equation 5: where score ( c i ) is the importance of comment c i given by either graph-based scoring or tensor-based scoring; w k  X  denotes that word w k appears in comment c i .

Sentences in the document are scored according to their contained words. Specifically, every word in the document receives two weights, one for representing the topics dis-cussed in the comments defined by Equation 5, and the other for representing the topics of the document. The latter is measured by the tf  X  idf value, where the document collection consists of all posts in a blog. The final weight of each word is the linear combination of the two weights after normaliza-tion, shown in Equation 6. In this Equation,  X  (  X &gt; 0) is a parameter to control the contribution of the weight received from comments. Note that, words in the document that do not appear in any comment receive 0 score from comments. weight ( w k )= 1
We use density-based scoring to measure the importance of a sentence s in the given document [15].
 Score ( s )= K where K is the total number of keywords (i.e., non-stopwords) in s ; w k and w k +1 are two adjacent keywords in s ,and distance ( w k ,w k +1 ) denotes the distance between w k w k +1 in number of stopwords.

The comments-oriented summary is formed by extract-ing those top scored sentences. Note that, when there are very few comments associated with a document, the sum-mary produced will be mainly based on the tf  X  idf values of the words contained in the document with density-based sentence scoring.
Through the three relations, i.e., topic, quotation, and mention, comments are linked together and modeled in ei-ther a multi-relation graph or a tensor. In uniform-document approach, we further extend topic and quotation relations to link comments to sentences from the given document. If a comment discusses a similar topic with a sentence, they are topically related. Similarly, a comment and a sentence are related through quotation if the comment quotes a text segment from the sentence.

With the extended relations, both the sentences from the document and the comments associated with the document are treated uniformly as text units . Based on our discussion in Section 4, these text units can be modeled in either a multi-relation graph or a tensor and scored with the corre-sponding scoring method. To generate a comments-oriented summary, those highly scored text units that are sentences from the original document are extracted to form the sum-mary.

In uniform document approach, if a document is associ-ated with very few or even no comment, the summary pro-duced will be mainly based on the topic graph formed by the sentences (i.e., text units) in the document.
Recall that both feature-biased and uniform-document ap-proaches work with either graph-based scoring or tensor-based scoring. We have in total four comments-oriented document summarization me thods, shown in Table 1. In this section, we evaluate these four methods with manually labeled documents.
Without existing benchmark dataset, we collected data from two blogs, Cosmic Variance 3 and IEBlog 4 ,bothre-ceiving large number of comments. From all posts collected, we randomly picked up 100 posts, 50 from each blog, to form our evaluation dataset. Table 2 gives the statistics on these 100 posts. To generate re ference summaries, 4 human summarizers were asked to read b oth the posts and their cor-responding comments and then label approximately 7 sen-tences 5 for each post 6 . The labeled set of sentences form the human generated summaries in our evaluation.

Two performance metrics, namely, ROUGE and NDCG , are used to evaluate the effectiveness of the proposed meth-ods. ROUGE has been widely adopted for evaluating docu-ment summarization methods [16]. It evaluates the machine generated summary against human generated summary (la-beled sentences in our setting) by counting overlapping units such as n-gram. We used ROUGE-1.5.5 package and report the F -measure of ROUGE-1 (i.e., unigram). We choose to report F -measure instead of recall as the human generated summaries are limited by number of sentences (not words). In our evaluation, for each document, each method returns the top 7 scored sentences to form the machine generated summary whose length (in number of sentences) matches human generated summary. The selected sentences are or-dered according to their positions in the original document. The values reported are averaged over the 4 human gener-ated summaries for the 100 blog posts.

Given a ranked list of retrieved documents with their rele-vance level in response to a query, NDCG ( Normalized Dis-counted Cumulative Gain ) [13] is computed through Equa-tion 8: http://cosmicvariance.com http://blogs.msdn.com/ie/
We fix the number of labeled sentences as  X  X  constant sum-mary length is more appropriate X  [10].
The user study was conducted in a similar manner to the one reported in [12], with more blog posts and more human summarizers involved. Symbol Method input P blog post only, no comments is given PCt topic relationship among text units PCtq topic and quotation relationships PCtm topic and mention relationships
PCtqm topic, quotation, and mention relationships where Z is a normalization factor derived from the perfect ranked list of K documents; R ( p ) denotes the relevance level of document at rank position p . In our setting, each sentence in the extractive summary is an object to be ranked and the relevance level of each sentence is defined by the number of summarizers labeled it. For example, the relevance level of a sentence is 3 if three summarizers labeled the sentence and 0 if no summarizer labeled the sentence. In our evaluation, for agivendocument, K is also set to 7. The reported NDCG is averaged over 100 posts. We evaluated the four methods listed in Table 1, namely, FeatureGraph , DocGraph , FeatureTensor ,and DocTensor , with different inputs to simulate the cases where different relationships among comments are available. As shown in Table 3, P denotes that only the post is available to the sum-marization methods. The problem is analogous to single-document summarization. PCt denotes that both the post and the topic relationships among comments are available to each method. Similarly, PCtq , PCtm ,and PCtqm refer to the inputs consisting of the blog post and the corresponding relationships respectively. Specifically, with PCtqm ,allthe three relationships discussed in Section 3 are given to the summarization methods.

Different from quotation and mention that are binary (e.g., weighted by 1 or 0), the topic relationship between two com-ments needs to be measured. In our experiments, we used cosine similarity to measure the strength of topic relation-ship and evaluated two settings: weighted and unweighted . With weighted setting, the edges in the topic graph are weighted by the cosine similarity. With unweighted setting, every edge carries the same weight of 1 if the cosine similar-ity is greater than 0 as in [23]. Nevertheless, our experimen-tal results showed that with unweighted topic graph, slightly better performance was achieved for almost all methods. For the sake of page space, we choose to report the results using unweighted topic graph only.

To perform the PARAFAC decomposition, we used Mat-lab Tensor Toolkit [1], where the number of factors (i.e., R ) needs to be specified. As the number of salient factors in sentences and comments of a blog post is usually not known beforehand, R is simply set to be the number of text units (i.e., comments and/or sentences) to be scored.
In the first set of experiments, we compare the perfor-mance of the four methods with the five different inputs. For all methods with feature-biased approach we set  X  =2 (see Equation 6). The impact of using different  X   X  X  is fur-ther studied in the second set of experiments reported in Section 6.3.2.

The summarization accuracy by ROUGE-1 and NDCG are reported in Table 4 and plotted in Figure 4 for easy comparison. Given a particular input, e.g., PCtqm ,the best performance is highlighted in bold in Table 4. From the results, the following observations can be made.
Firstly, for all four methods, much better performance were achieved when comments were used (i.e., PCt , PCtq , PCtm ,or PCtqm ), compared to using post only (i.e., P ) according to both ROUGE-1 and NDCG. Almost all im-provements are statistically significant ( p  X  0 . 05 based on paired t -test); the few non-significant ones are indicated by in Table 4. Such results well support our hypothesis that comments contain valuable information for better document understanding.

Secondly, methods using feature-biased approach achieved better performance than those using uniform-document ap-proach. According to ROUGE-1, FeatureGraph achieved significantly better performance than DocGraph with all inputs except P and PCtq ( p  X  0 . 05, indicated by * in Table 4); FeatureTensor always significantly outperformed DocTensor. According to NDC G, FeatureGraph outper-formed DocGraph significantly with all inputs except P , and FeatureTensor achieved significantly better performance than DocTensor with PCt , PCtm ,and PCtqm .Onepos-sible reason for the worse performance of methods using uniform-document approach is that not all comments are quite relevant to the post due to noise. Using feature-biased approach, words contained in those noisy comments do not contribute to the sentence scoring as long as the words do not appear in the blog post. However, these comments might affect the sentence scoring for methods using uniform-document approach.

Thirdly, FeatureGraph and FeatureTensor performed com-parably, with FeatureGraph being slightly better accord-ing to ROUGE-1, and FeatureTensor being slightly better according to NDCG. In specific, the best ROUGE-1 was achieved by FeatureGraph with PCtqm ,andthebestNDCG was achieved by FeatureTensor with PCtqm .Inshort,all the three relations considered in Section 3.2 could improve the comments-oriented summarization accuracy.
In this section, we study the impact of  X  to the methods using feature-biased approach, i.e., FeatureGraph and Fea-tureTensor. Recall that  X  is the coefficient involved in com-bining the two weights of a word received from the document and the comments respectively. The larger the  X  ,themore emphasis is given to the weight received from comments (see Section 5.1). We varied  X  from0to10toobserveitsimpact to the two methods.

The performance of FeatureGraph and FeatureTensor with different  X  values are reported in Figure 5. Note that, when  X  = 0, a word is weighted solely on blog post content, i.e., tf  X  idf value, and no comment is used in summarization.
As shown in Figure 5, when  X  is greater than 0, better summarization performances were observed for both meth-ods compared to that with  X  = 0. This strongly suggests that incorporating comments benefits blog summarization. Evaluated by ROUGE-1, both FeatureGraph and FeatureTen-sor followed similar trend with different  X  values. Starting from 0, improvement on ROUGE-1 value was observed till  X  = 2 followed by small decrement till  X  = 5. Nevertheless, the decrement is not significant. Evaluated by NDCG, sum-Method ROUGE-1 NDCG
DocGraph 0.6158 0.6293 0.6283 0.6229  X  0.6259  X  0.5390 0.5751 0.5744 0.5674 0.5681
DocTensor 0.6027 0.6065  X  0.6229 0.6216 0.6206 0.5298 0.5466 marization accuracy kept on increasing till  X  =2. When  X  is larger than 2, the performance of the methods were less affected by the value of  X  .

In summary, based on this set of experiments,  X  =2is a reasonable setting in combining the two weights (derived from document and comments respectively) of a word.
In our experiments, graph-based and tensor-based scoring methods achieved comparable s ummarization accuracies. In this section, we further discuss the two methods with respect to their computational cost and representation power.
Let N be the number of sentences and/or comments, M be the number of relations under modeling, R be the number of latent factors, and I be the number of iterations needed for convergence in the computation. Graph-based method has space complexity of O ( N 2 ) to store one transition matrix for its computation, while tensor-based method has space com-plexity of O ( MN 2 ). Nevertheless, M N in most cases, meaning that the two methods are comparable in space com-plexity. On the other hand, graph-based method has time complexity of O ( IN 2 ), while tensor-based method has time complexity of O ( IR 2 (2 N + M )) (analyzed according to [14]), where R = N in our case. In short, graph-based method is more computational efficient than tensor-based method.
However, tensor-based method has its power in repre-senting multiple relations among the given set of objects and their relationships. In our summarization task, topic, quotation, and mention are three example relations that have been considered. Other relations, that link one sen-tence/comment to another, can be naturally incorporated into this method by extending the 3rd-mode of the ten-sor. However, in graph-based method, multiple relations are merged and their semantics are thus lost and unrecon-structible.
Leaving comments on Web documents (or other Web ob-jects) has become an important feature for many websites es-pecially the social websites. Those comments contributed by readers provide valuable information to better understand the Web documents. In this paper, we studied comments-oriented document summarization that aims to generate an extractive summary for a Web document using comments contributed by its readers. We c onstruct three graphs based on the three types of relationships among comments. De-pending on the way the three graphs are merged into one data structure, two scoring methods known as graph-based scoring and tensor-based scoring are proposed to measure the importance of comments. We further propose two ap-proaches to integrate comments into document summariza-tion for generating comments-oriented document summaries. By varying input parameters and using a manually labeled set of blog posts, we evaluated four methods. Our experi-ment results suggest that including comments into the sum-marization improved summariza tion accuracy significantly.
