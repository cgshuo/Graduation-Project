 Reconciling opinions from multiple sources on questions of interest to determine the correct answers is an important problem encountered in collaborative information systems such as Q &amp; A forums and prediction markets. Our current work focuses on a widely applicable variant of the above problem where the opinions and answers are categorical-valued with the set of values possibly varying across ques-tions. Most of the existing techniques are tailored only for binary opinions and cannot be effectively adapted for ques-tions with categorical opinions. To address this, we pro-pose a generic Bayesian framework for opinion reconciliation that can readily incorporate latent and observed attributes of sources and subjects. For the scenario of interest, we derive three specific model instantiations of the general ap-proach (CTM, CTM-OSF, CTM-LSG), which respectively capture the latent source behavior, variations of source be-havior across subject groups, and inter-source correlations. Empirical results on real-world datasets point to the relative superiority of the proposed models over existing baselines. I.2.6 [ Artificial Intelligence ]: [Learning] Design, Experimentation Opinion mining; Graphical models; Gibbs sampling
Rapid advances in internet technologies have made it in-creasingly easy to solicit and exchange information resulting in the creation of massive collaborative information systems powered by user-generated content. Examples include on-line Q &amp; A forums (e.g., Quora), prediction markets (e.g., In-trade), online diagnostic systems(e.g., interactiveMD), wiki-compilations (e.g., Wikipedia, Wikimapia). Harnessing this  X  X isdom of the crowd X  requires an effective solution for in-tegrating sparse opinions from multiple unreliable, and pos-sibly malicious sources.

In a collaborative information system, there are multiple sources offering opinions on various subjects or questions of interest. Unlike a subjective question like  X  X ho is the best US president ever? X , there is a unique correct answer for an objective question like  X  X ho won the 2012 US Presidential election? X . In such scenarios, the goal of opinion integra-tion is to determine this correct answer. Our current work focuses on such Opinion Reconciliation (OR) , where each question is associated with a unique correct answer. Let { U 1 ,  X  X  X  ,U i ,  X  X  X  ,U N u } and { S 1 ,  X  X  X  ,S j ,  X  X  X  ,S note the multiple sources and subjects (questions) in the information system respectively. Each question S j is as-sociated with a single correct answer M j and one or more opinions { O ij } i,j from a subset of the sources { U ten, one might also have access to attributes of sources and subjects, denoted by X i and Y j respectively. The opinion reconciliation (OR) problem can then be stated as follows: Given opinions { O ij } i,j , limited (or even none) observations on the correct answers { M j } j , source attributes { X i subject attributes { Y j } j , predict the unknown correct answer M j ,  X  j, [ j ] N s 1 .

There can be multiple variants of the above problem de-pending on the nature of the opinions and the correct an-swers, which could be real-valued (e.g., US GDP in dollars), ordinal (e.g., US credit rating), binary (e.g., Is US a monar-chy?), categorical from a small known set (e.g., type of gov-ernance in US) , text phrases from a given vocabulary (e.g., US national anthem), set-valued (e.g., list of US presidents from New York), etc. Among all the variants, a particularly important formulation is the one where the space of possible answers and opinions for a question S j comprises of a large number of categorical values or text phrases O j , which could vary across questions. Applications include information sys-tems with heterogeneous questions permitting factoid style answers, which is fairly common in prediction markets, spe-cialized Q &amp; A forums, and diagnostic systems. Table 1 shows a toy example of such a scenario with multiple hu-man sources, heterogeneous questions on various topics and opinions corresponding to text phrases. Existing approaches to opinion reconciliation can be broadly grouped as : Axiomatic approaches. These include simple non-data-driven techniques assuming inter-source and inter-subject independence where the correct answer of a question is ob-tained in terms of various characteristics (mode, mean, me-dian) of the distribution over the corresponding opinions. Discriminative Meta-learning. These approaches in-volve learning a functional mapping (e.g., linear model or decision tree) from the opinions and features of subjects and sources to the correct answer through supervision. But this form of supervised learning is not effective when the opinions are very sparse and supervision is highly limited.
 Trust Propagation. There is a large body of work on trust propagation over graphs that allow one to estimate the  X  X eputation X  (e.g., trustworthiness or correctness) of sources (represented by nodes). Truthfinder algorithm [5] adapts these ideas to OR by considering a bipartite graph over facts (subject-opinion pairs) and sources, with an edge corre-sponding to a positive assertion on a fact by a source (miss-ing edges are negative assertions). The likelihood of a source making true assertions and the probability of a fact being true are iteratively estimated in terms of each other, but the algorithm is not guaranteed to converge.
 Bayesian Models Galland et al. [2] propose a generative model for binary opinions based on source-specific probabil-ity of error and not-opinionating as well as subject-specific probability of error and not-opinionating, with the opinion by a source on a subject being determined by the interaction of these parameters. Unfortunately, the algorithms proposed in the paper are based on heuristics not related to the gen-erative model and are not guaranteed to converge. Rayakar et al. [4] and Zhao et al. [7] both propose similar generative models for binary opinions that take into account source-specific probabilities of Type-1 and Type-2 errors, but use different inference approaches. Both works have also been extended to real-valued opinions [6]. A more advanced ap-proach is the Multi-Source Sensing (MSS) model [3], which considers latent groups of sources and models error proba-bilities as property of each source group.

However, most of the existing techniques are focused on the scenarios where the correct answer M j and the opinions O ij are binary variables [7, 5, 2]. To some extent, these tech-niques can be adapted to handle other scenarios involving categorical, textual and set-valued answers by transforming the original subject space to one that permits binary opin-ions/answers. For example, the question  X  X hat is the type of US government? X  with possible answers {  X  X emocracy X ,  X  X onarchy X ,  X  X ligarchy X  } can be alternately represented as three questions: {  X  X s US a democracy? X ,  X  X s US a monar-chy? X ,  X  X s US an oligarchy? X  } , each of which permits a binary yes/no answer independently. However, these tech-niques cannot effectively exploit the implicit mutual exclu-sivity in the categorical valued variables.

This work is an attempt to directly address the opinion reconciliation problem for heterogeneous questions with a large number of categorical opinions which requires taking into account various practical issues shown in Table 1: Variations in source behavior. In Table 1, we observe that Mr. A is more accurate than other users, indicating that majority vote may not suffice, and source expertise and reliability needs to be accounted for.
 Variations in same source X  X  expertise across topics. In the example, Prof. C is an expert in math and chemistry, but ignorant in history pointing to the need for topic-specific modeling of expertise.
 Highly limited supervision. The correct answer is often known only for a small subset of questions and one needs to use this supervision to calibrate the expertise of sources. Opinion Sparsity. Each source provides opinions on only a small subset of questions, which makes it difficult to employ traditional meta-learning techniques.
 Textual Variations. Certain opinions are minor variations of the correct answer (eg. typos), which need to be treated differently from an outright wrong answer.
 To address some of the above challenges, we propose a Bayesian framework for opinion generation that jointly mod-els the source behavior and subject-specific correct answers as latent variables and make the following contributions: 1) A generic framework for opinion reconciliation via Bayesian modeling that can incorporate latent and observed attributes of sources and subjects. Existing Bayesian approaches such as the LTM [7] can be shown to be special cases. 2) To reconcile categorical-valued opinions, we propose three instantiations (CTM, CTM-OSF, CTM-LSG) of the generic approach to capture the latent source behavior, variations across subject groups, and inter-source correlations. 3) Empirical evaluation of predictive performances of the proposed models and multiple baselines on real-world datasets, which points to the relative efficacy of the proposed models.
In this section, we describe our generic Bayesian frame-work for opinion reconciliation, and present three models for categorical opinions. The graphical model encodes two assumptions: (a) Opinions { O ij } ij are independent of each other given { M j , X i , Y j } , (b) Dependencies among sources and subjects are captured entirely in terms of X i and Y j
The dependencies between the opinions of a source and the correct answer can be succinctly expressed in terms of other variables of interest, such as the source expertise, which are often unobserved or partially observed. An effective solu-tion strategy is to simultaneously infer these latent vari-ables as well as the precise form of the dependencies, in addition to inferring the primary target variable, the cor-rect answer of a subject M j . A natural mechanism is to encode the dependencies between the different variables of interest ( O ij ,M j ,X i ,Y j ) in the form of a joint probability distribution that can be factored into conditional distribu-tions amenable for learning. Figure 1 shows a graphical model corresponding to such a factorization. Here X lat i X i denote the latent and the observed features of source U i such that X i = [ X lat i ,X obs i ]. Similarly, Y lat note the latent and observed features of source S j such that Y j = [ Y lat j ,Y obs j ]. The priors allow one to encode domain knowledge as well as data constraints.

The above framework provides an elegant way to model some of common factors relevant to opinion generation such as source expertise, source bias, difficulty of a question, inter-source correlations. Though Figure 1 depicts a spe-cific directionality for the dependence between latent and ob-served source and subject attributes, e.g., between Y lat Y j , the appropriate directionality depends on which of the conditional probabilities (e.g., p ( Y lat j | Y obs j ) or p ( Y is more learnable given the nature of the variables.
We now consider the specific scenario where M j , O ij are both categorical values with support sets M and O respec-tively. We propose three different models, where the con-ditional probability p ( O ij | M j ,X i ,Y j ) can be viewed as con-fusion profile parametrized by X i and Y j . This confusion profile is essentially a set of |M| distributions on the |O| simplex. In the simple scenario where the variables M j and O ij are binary, it reduces to the distribution of Type I and Type II errors as done in [7], but can capture more in-tricate dependencies among categorical variables in general. The three models are described below.
 CTM. This model attempts to capture hidden source be-havior such as expertise and common mistake patterns in terms of a source-specific confusion profile  X  i , which can be viewed as a latent source-specific feature X lat i . The priors on the correct answer M j and each of components in X lat i =  X  are assumed to be Dirichlet-Multinomial and Dirichlet re-spectively. The generative process is as follows: CTM with Observed Subject Features (CTM-OSF).
 This model attempts to capture the variations in source be-havior across observed categories of subjects. In this sce-nario, each subject is associated with a categorical observed attribute Y ob j  X  { 1 ,  X  X  X  ,N sf ] and and each source is associ-ated with | N sf | confusion profiles corresponding to each of the subject categories. The generative process is given by: CTM with Latent Source Groups (CTM-LSG). Rather than model the confusion profiles at an individual source level, this model assumes that each source U i belongs to a hidden group G i  X  X  1 ,  X  X  X  ,N sg } , and associates each group with a confusion profile. The generative process includes assignment of group indices to the sources.
The generative process for CTM, as described above re-sults in the following joint distribution: p ( O,M, X , X  )  X  Here m ikl is the number of times source i has provided opin-ion l to a subject whose correct answer is k , and n k is the number of subjects which have k as the correct answer. On integrating out  X  and  X  , the Gibbs sampling equation is: p ( M j = k | M  X  j ,O )  X  ( n  X  j k +  X  k ) where n  X  j k and m  X  j ikl are n k and m ikl respectively, without considering subject j . In practice, while sampling M j Figure 1: Graphical model for generic Bayesian opinion restrict ourselves to only those values in M which have been used in at least one of the opinions available on subject j . The inference steps for CTM-OSF and CTM-LSG are simi-larly derived, but are skipped here for brevity.

We choose the hyperparameters  X  and  X  based on the data.  X  kl is set proportional to the number of times l is provided as opinion on a subject where the most frequent opinion is k . We set  X  k to be proportional to the number of times k is provided as opinion. In the presence of super-vision,  X  k is boosted proportional to the number of times it occurs as the correct answer for the supervised subjects.
In this section, we present empirical results comparing the performance of the proposed models (CTM, CTM-OSF and CTM-LSG) relative to the state-of-the-art methods on real-world datasets in supervised and unsupervised settings.
Datasets: We consider two datasets comprising of categorical-valued opinions: (a) Quizmaster Dataset [1], which contains questions on 11 different topics (physics, chemistry, history, literature, etc.) and the Hubdub Dataset [2] which contains questions pertaining to the outcome (winner, victory mar-gin) of upcoming sports matches. For both the datasets, each question has a single correct answer, and the users (sources) attempt a variable number of questions. In the Quizmaster dataset, opinions also have typos and linguistic issues, which was addressed via string-matching and normal-ization as a preprocessing step though in principle, it could be incorporated into the confusion profile. Table 2 provides the details of the datasets. To evaluate the techniques in the presence of supervision, we also created a subset of the QuizMaster dataset (Quizmaster2), where we randomly se-lect 80% of the subjects and their associated opinions. The remaining 20% is kept aside for supervision.

Algorithms: We consider the following baselines: Vot-ing, TruthFinder (TF) [5], 3-Estimates [2], and LTM [7]. For LTM, TF and 3-Estimates, all opinions are transformed into binary-valued facts (question-opinion pairs), and each fact is assigned a score. The opinion corresponding to the fact with the best score is selected as the predicted correct answer for a subject. We consider two versions of LTM: (a) LTM-1 which corresponds to the original LTM and may infer more than one opinion as the correct answer for a question since each question-opinion pair is considered independently and inferred as true/false, and (b) LTM-2, which explicitly chooses a single fact per subject.

In the presence of supervision, we also consider an addi-tional baseline algorithm Discriminative based on discrim-inative modeling. As with TF [5] and 3-estimate, we con-struct question-opinion pairs, which can be associated with a binary label of TRUE ( X  X pinion is correct answer for ques-Table 3: Number of correct answers found by different tion X ) or FALSE. We also construct features based on the opinion distribution and learn a generalized linear model. We compare the newly proposed methods: CTM, CTM-OSF and CTM-LSG, against the above methods. In case of the quizmaster dataset, the topics for each question (11 top-ics such as physics, chemistry, history) can be used as sub-ject features ( Y ob j ) in CTM-OSF. Since the Hubdub dataset does not have such features, we do not evaluate CTM-OSF on this data.

Metrics: All the algorithms except LTM1 output one an-swer for each subject. As performance metrics, we evaluate the number of predicted answers that match the Ground Truth. We note that, in the Quizmaster dataset, none of the opinions are correct in 395 out of the 6076 questions, and so in these 395 questions the correct answer may never be found, and hence, the maximum number of correct pre-dictions achievable on this dataset is 5681. Unsupervised Setting: Table 3 presents the prediction results of various algorithms on the two datasets (Quizmas-ter and Hubdub) in the absence of supervision. The val-ues for CTM-LSG correspond to N sg = 5, but variations of N sg did not significantly affect the prediction. In case of QuizMaster, the proposed methods are clearly superior to all the baselines while in case of Hubdub, these meth-ods are superior to the Bayesian models, but comparable to Voting and TruthFinder. A possible reason for this is that source-specific confusion profiles can effectively capture the latent interactions in QuizMaster dataset. In case of Hub-dub dataset, the representation of the opinions and correct answers (e.g., win by 5 points) may not encode the rele-vant semantics (Soccer Team A wins over Soccer Team B by 5 points or Hockey Team C wins over Hockey Team D by 5 points) which are not the same from a source perspec-tive. This problem would have been alleviated in CTM-OSF in the presence of observed subject-specific features, which were not available in readily usable form.

Since most of the baselines are primarily meant for binary-valued opinions, we also transformed the categorical opin-ions to binary facts (subject-opinion pairs) and measured the prediction quality in each case, in terms of Precision and Recall. In case of TruthFinder, we obtained precision-recall values of (0.87, 0.58) while for 3-estimate, we obtained (0.85,0.94), with thresholds chosen so as to maximize the F-measure. For LTM-2 the values were (0.86,0.86). For CTM, CTM-OSF and CTM-LSG, these values are (0.91, 0.91). So it appears that most of the gain is coming from better uti-lization of the mutual exclusivity between categorical values. Table 4: Effects of Supervision on prediction accuracy Effects of Supervision: Next, we study the effect of pro-viding limited supervision in the form of correct answers to a few subjects being known. We choose these subjects randomly from 20% of Quizmaster dataset kept aside for supervision, and perform the predictions on the test parti-tion (Quizmaster2). We consider 4 levels of supervision-0%, 25%, 50% and 100% of the training subset. Table 4 shows the results pointing to the superior performance of the pro-posed models. However, the performance of the proposed methods is relatively invariant to the amount of supervision provided, unlike TF which clearly benifits from supervision. We proposed a generic opinion reconciliation approach via Bayesian modeling that includes certain existing Bayesian models (e.g. Latent Truth Model [7]) as special cases. We presented three models (CTM, CTM-OSF, CTM-LSG) for categorical-valued opinions that elegantly capture the hid-den source behavior, variations across subject groups, and inter-source correlations via appropriately chosen latent vari-ables. Empirical results are encouraging and indicate that the proposed models are superior to existing state-of-the-art techniques based on trust propagation, discriminative learn-ing, as well as Bayesian approaches designed for binary opin-ions. In future, we plan to explore CTM-variants that incor-porate textual variations in the generative processes, as well as specialized models for subjects that involve a comparison among a pair of entities, e.g., match outcomes in Hubdub. We also plan to explore more efficient utility-based inference mechanisms that can scale to large web-scale datasets. [1] J. Boyd-Graber, B. Satinoff, H. He, and H. Daum  X e III. [2] A. Galland, S. Abiteboul, A. Marian, and P. Senellart. [3] G. Qi, C. Aggarwal, P. Moulin, and T. Huang.
 [4] V. C. Rayakar and S. Yu. Eliminating spammers and [5] X. Yin, J. Han, and P. Yu. Truth discovery with [6] B. Zhao and J. Han. A probabilistic model for [7] B. Zhao, B. I. Rubinstein, J. Gemmell, and J. Han. A
