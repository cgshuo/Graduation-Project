 In this paper, we propose a web search retrieval approach which automatically detects recency sensitive queries and increases the freshness of the ordinary document ranking by a degree proportional to the probability of the need in recent content. We propose to solve the recency ranking problem by using result diversification principles and deal with the query X  X  non-topical ambiguity appearing when the need in recent content can be detected only with uncertainty. Our offline and online experiments with millions of queries from real search engine users demonstrate the significant increase in satisfaction of users presented with a search result generated by our approach.
 Categories and Subject Descriptors: H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval.
 General Terms: Algorithms, Measurement, Performance, Experimentation. Keywords: Recency ranking, diversity, web search.
Modern web search engines face the need to consider dif-ferent non-topical facets of relevance when ranking web doc-uments in response to user queries. While the need in a cer-tain document feature, besides the topical relevance, might be expressed only implicitly in the query, it is still important to recognize its presence in order to adequately satisfy the underlying information need. However, the quality of such recognition cannot be perfect in all cases. Consequently, it brings a certain level of non-topical ambiguity to the queries, which must be taken into account when generating a search result.

One of the most popular non-topical facets of relevance is document freshness. In this paper, we demonstrate how to deal with query ambiguity surrounding the need for re-cent information. Such ambiguity typically appears during short periods of time, when users become increasingly inter-ested in one newsworthy aspect, typically an event, related to a well-known entity: a person (e.g. [Michael Jackson]) or a location (e.g. [Japan]). For example, consider the query [michael jackson]. There has been constant and continuing interest in the biography and discography of Michael Jack-son, which can be satisfied even by non-fresh documents, but users issuing the query [michael jackson] on (June 25, 2009) were often looking for the freshest news related to the Michael Jackson X  X  death. But both intents (news and discography) continued even during this period.

Recently, a number of techniques for search result diver-sification has been proposed in order to compensate for top-ical ambiguity of queries and increase the chance to satisfy the user. We propose to follow the same principles to deal with recency sensitive queries and their non-topical ambi-guity. Our approach aims to maximize the probability that the average user finds some useful information among the search results on recency sensitive queries by blending nec-essary amount of recent results into the result set. To the best of our knowledge, our paper describes the first attempt to tackle the problem of non-topical query ambiguity with a result set diversification technique.

The main contributions of this paper include: 1) the ap-proach to recency ranking by means of search result set di-versification, 2) a thorough offline and online evaluation of the proposed approach in terms of a search result quality metric and the overall user satisfaction.

The remainder of the paper is organized as follows. We first review the related work in Section 2. Section 3 describes our machine learning based approach to obtaining a smooth probability of the need in recent content for a query. Sec-tion 4 explains how we utilize that probability to diversify ordinary document rankings with fresh documents. Section 5 presents the results of evaluation and Section 6 concludes the paper and outlines the research questions left for future work.
There are only a few papers focused exclusively on re-cency ranking. The pioneering work in this area proposed to learn a ranking function which is trained using a subset of features that help to infer the recency of page content [3]. The follow-up work extended that subset to include features extracted from the micro-blogging data stream [4]. Our approach differs in a number of aspects. For one, we try to deal with temporal ambiguity of queries and balance the number of fresh and ordinary relevant documents in the result set, based on the smooth probability of the need in recent content. As a result, while the aforementioned works focus entirely on improving the ranking for one specific case (breaking news queries, 1-2% of search engine X  X  traffic), we aim to affect the ordinary ranking by explicitly increasing its freshness for any query with non-zero probability of the need in recent content. The inference of query X  X  recency sensitivity plays an important role in recency ranking. The aforementioned works detected only highly recency sensitive queries using a linear combination of a few features. In a similar way, Arguello et. al. [5] used a number of features to find verticals relevant for a query, including the News verti-cal. While those methods focused on binary classification of a query, our work is rather based on regression to obtain and utilize the precise estimate of the probability of the need in recent content.

Our work is also largely based on the principles of search result diversification. In [2], a framework for evaluation that systematically rewards diversity was proposed. In [1], a sys-tematic approach to diversifying results that aims to mini-mize the risk of dissatisfaction of the average user was pre-sented. A number of follow-up papers were published re-cently which we do not cover here due to space constraints. Our work complements the research in this area by demon-strating that diversification principles and algorithms are also helpful to increase the chance to satisfy the user in the presence of non-topical query ambiguity.
In order to quantify the ambiguity of a recency sensitive query, we learned a regression model which predicted the level of interest in recent documents for a particular query and a particular time slot. We used around 30 different features (including their minor modifications) previously de-scribed in the papers dealing with similar problems (see Sec-tion 2). We do not provide a thorough analysis of feature importance due to space constraints. The most valuable features were the probabilities of queries to be generated by language models of recent content from different sources, in-cluding the query, social and news data streams, as well as the probability of a click on a news item.

To train the regression model we asked annotators to pro-vide labels of recency sensitivity for a set of queries. In or-der to preselect a list of candidate queries for assessment, we defined a small threshold on each feature used to learn our regression function and filtered out all queries that did not have at least one feature value exceeding the corresponding threshold. As a result, we collected judgments for a set of 4000 unique queries issued to Yandex (www.yandex.ru) web search engine (the major russian search engine) over the pe-riod of three weeks. On each day during this period, judges were presented with the queries submitted by search engine users on that particular day and were asked to determine whether these queries express an interest in upcoming or on-going events for which web search users would prefer recent content. Labeling queries basically represented the manual assignment of the probabilities that a particular query is re-cency sensitive. So, if a query was strictly about a recent event it received the probability of 0.95 (e.g. [flood in thai-land] on the day of the event). If a query X  X  primary interest was related to a recent event, but many users would also like F igure 1: Recency sensitive queries traffic coverage to see just topically relevant results, it was labeled with 0.75 (e.g. the query [oscar] on the day of the ceremony). If the query X  X  primary interest was not likely to be focused on a particular event, but there was some chance that users issu-ing such a query would look for some fresh content, assessors assigned the probability of 0.25 (e.g. it always makes sense to present users with some recent content in response to the query [britney spears]). Otherwise, a query was assigned zero probability to be recency sensitive. Each query was labeled by 3 assessors. Average Cohen X  X  kappa coefficient between all pairs of assessors was 0.76, which is considered a substantial agreement.

We learned the regression model to assign smooth proba-bility of the need in fresh content to any query using Gradi-ent Boosted Regression Trees (GDBT) [8]. Recency sensitive queries traffic coverage by these types based on 4000 human made judgments is illustrated on Figure 1.
To produce a search result for recency sensitive queries we follow the search result set diversification principles. Namely, we aim to maximize the utility of the diversified search result expressed in terms of the Expected Reciprocal Rank mea-sure, which we extended to include an abandonment proba-bility and to handle multiple query intents. Both extensions are proposed by Chapelle et. al. [9] and we combine both of them in this work. We call this metric Intent Aware Expected Reciprocal Rank with Abandonment (ERR-IAA) and regard as the objective we aim to maximize:
ERR-IAA = where P ( t | q ) is taken from the distribution over two classes of information needs t (the need in fresh topically relevant documents and the need in any topically relevant docu-ments) for the given query q . Each document is assigned the probability R t r to satisfy the information need of type t at position r . We take into account the probability that the documents at the previous r  X  1 positions have not satisfied that need. We also assume that any user always may stop (abandon the search result) at rank r with the abandon-ment probability pBreak r due to accumulated frustration ( pBreak is empirically set to 0.85 in our experiments).
We assume that the optimal search result page is the one which maximizes the ERR-IAA measure. In order to maxi-F igure 2: Cumulative share of query instances sub-mitted since the day of the first query mize it, we follow the greedy approach described by Agrawal et. al. [1] and select the document, whose selection leads to the maximum increase of the objective at each step of the selection process.
We also assume that any web document is fresh only for 3 days since the time of its creation or the last update. We use a proprietary algorithm to extract the correct and the most relevant timestamp from document content. Our choice of the number of days is motivated by the following observa-tions. First, according to the studies by Dong et. al. [3], assessors, who judged the freshness of a set of documents, found out that the 1 X 4 days old documents are the ones most likely containing fresh content. Second, the peak of interest in new events lasts for three days in average according to our analysis of 100,000 spiky and long-tail (so, previously unseen) queries submitted by users of Yandex search engine in January, 2011. Figure 2 shows average share of total query volume for each such a query per for each day since the 1st day they become first known to the search engine until the 3rd day when their popularity falls off almost completely.
Guided by our definition of a fresh document, we produce the ranking of fresh topically relevant documents by simply removing the outdated documents from the initial ranking. As a result, we have two document rankings which we use to maximize the ERR-IAA measure, described by Equation 1: the one containing any topically relevant documents and the one containing only fresh topically relevant documents.
However, in order to proceed with maximization of our objective, we still needed to determine the probabilities of relevance R t i . In order to be independent of specific retrieval scores, which may significantly vary over queries and bear a relative, rather than absolute meaning, we turn document ranks into their probabilities of relevance using the inter-nal search engine X  X  statistics about the probability to en-counter a relevant document at the specific position. So, since we fixed the probabilities of document relevance for each of two aggregated rankings, the final ordering of doc-uments depended only on the probabilistic output of our classifier of query X  X  recency sensitivity.
The research questions we aim to answer in this subsection are how our search quality objective (ERR-IAA) changes while we aggregate two result sets: ordinary and fresh, and F igure 3: ERR-IAA for queries with different  X  X rue X  probabilities of need in fresh content how the quality of our classifier of query X  X  recency sensitivity affects the quality of such aggregation.

Figure 3 demonstrates how ERR-IAA changes as the es-timation of the probability of the need in recent documents deviates from its true value for the three different true val-ues assigned by our assessors: 0.25, 0.75 and 0.95. As we see, while minor errors in the probability estimation do not significantly affect the quality of the aggregated ranking, it is evidently important to keep the errors low as the ranking quality drops quite rapidly with their increase.

Further, we analyze the quality of the aggregation for the recency sensitivity classifier that we use in this work (Figure 4). We split our queries judged by their recency sensitiv-ity (see Section 3) into two parts (training and test, 2000 queries each) and conduct the evaluation via two-fold cross-validation. We train our classifier on the training set of queries and evaluate how its accuracy affects the quality of the aggregation on the test set. Note, that in a real setting that we simulate in this experiment, the initial ranking natu-rally contains some number of fresh documents. As a result, ERR-IAA measured on the ordinary ranking starts to grow as the recency need probability approaches 1.0, since the queries with such high probability of the need in recent con-tent are typically the queries that are unambiguous: highly descriptive and possessing enough discriminating power to retrieve very relevant content. For example, for the query [europe alert icelandic ash cloud], both the ordinary result set and the fresh result set are quite similar on the day of the infamous volcano eruption. The major gain from applying the diversification comes for the queries with probabilities of the need in recent content from 0.3 to 0.8. This is to be expected, as our approach to recency ranking focuses on the cases of temporal query ambiguity, in contrast to the previous approaches, which aim to maximize the quality of ranking for the queries with no temporal ambiguity (see [3, 4] for more details).
In order to test our approach in terms of web search en-gine metrics measuring user satisfaction, we conducted an A/B test [7]. Some users of Yandex search engine were al-ways presented with ordinary search results (control bucket), which were never diversified with fresh documents, and some ER R-IAA F igure 4: ERR-IAA for queries with different level of ambiguity, diversified and non-diversified rank-ings users were presented with diversified search results (treat-ment bucket). We ran the experiment for 13 days in March 2011 and that involved about 10 million queries in each bucket (issued by real users as we filtered out bots and spammers). We measured user satisfaction using metrics suggested by Radlinski et. al. [10], as they are known to cor-relate with search result quality. Final results for the control and the treatment are listed in Table 1.
 Table 1: User behavior metrics for the control and the treatment buckets Metric Meaning Contr Treat Abandonment
Rate
Time to first click 1st Position
CTR 2nd Position
CTR First Click Position
All metrics in the treatment are significantly different from metrics in the control (Mann-Whitney U test,  X  = 0 . 01) and all these differences indicate the increase of search result quality after diversification. In other words, the decrease of abandonment rate means less cases when users could not find any relevant result, the decrease of the mean first click position indicates that top results became more relevant, the decrease of the mean time to first click also indicates that relevant results received higher ranks and hence could be spotted faster, and the increase of CTRs of the URLs at the first two positions also indicates their increased relevance.
In this paper, we present an approach to improve recency ranking, while preserving the overall relevance of the ordi-nary search result. We developed a multi-grade recency sen-sitive queries classifier that predicts the degree of the need in recent documents. We further demonstrated how to diver-sify the ordinary search result with fresh documents by max-imizing the search quality measure which takes the query X  X  temporal ambiguity into account. We demonstrated the be-havior of our diversification model in different cases using a set of judged queries. We finally confirmed the intuitions behind our approaches by a large-scale online experiment involving millions of queries from real users.

While we consider a fixed time window to determine if documents are fresh, it definitely makes more sense to de-termine time window which takes the essence of the informa-tion need expressed in the query into account. We also need to more systematically handle the challenge of score nor-malization to obtain the probabilities of document relevance generated according to each possible definition of relevance. In this regard, we look forward to exploit the techniques of results merging developed in the area of Distributed Infor-mation Retrieval [6].

The diversification based approach to recency ranking can be also useful to aggregate documents from a set of relevant verticals (videos, images or shopping items). However, the danger of over-diversification is not well studied yet. It is not clear if users would prefer too many results of different kinds blended into one search result page. Our long term goal is to develop a unified approach to deal with several kinds of query ambiguities: topical and non-topical.
