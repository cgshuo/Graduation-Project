 The popularity of Web 2.0 has resulted in a large number of pub-licly available online consumer reviews created by a demograph-ically diverse user base. Information about the authors of these reviews, such as age, gender and location, provided by many on-line consumer review platforms may allow companies to better un-derstand the preferences of different market segments and improve their product design, manufacturing processes and marketing cam-paigns accordingly. However, previous work in sentiment analysis has largely ignored these additional user meta-data. To address this deficiency, in this paper, we propose parametric and non-parametric User-aware Sentiment Topic Models (USTM) that incorporate de-mographic information of review authors into topic modeling pro-cess in order to discover associations between market segments, topical aspects and sentiments. Qualitative examination of the top-ics discovered using USTM framework in the two datasets col-lected from popular online consumer review platforms as well as quantitative evaluation of the methods utilizing those topics for the tasks of review sentiment classification and user attribute prediction both indicate the utility of accounting for demographic information of review authors in opinion mining.
 H.2.8 [ Database Applications ]: Data mining; I.2.7 [ Natural Lan-guage Processing ]: Text analysis Opinion Mining; Topic Models; Dirichlet Process The emergence of online consumer review platforms, such as Ama-zon 1 , Tripadvisor 2 , and MSN Autos 3 , allowed consumers to pub-licly express their opinions about a wide variety of products and services. The popularity of such platforms has resulted in large h ttp://www.amazon.com/ http://www.tripadvisor.com/ http://www.msn.com/en-us/autos/ amounts of online review content created by a demographically diverse user base. Due to popularity and public availability, on-line consumer reviews have become an increasingly important and valuable source of information not only for consumers, who often base their decisions about purchasing a product or using a service on opinions of other people, but also for companies and manufac-turers, who are trying to understand consumer preferences in dif-ferent market segments and adjust their product design, manufac-turing processes and marketing campaigns accordingly. However, the large volume of on-line reviews has made manual analysis and summarization of reviews, even for a single market segment, a very labor-intensive and time-consuming task. The need to automate such analysis gives rise to a novel problem of summarization of contrasting opinions about aspects of products or services by dif-ferent demographic groups of consumers , which we introduce and address in this work.

Previous studies in opinion mining have largely focused on three major tasks: identification and extraction of opinion aspects, when the reviews are segmented into fine-grained aspects (topics); de-tection of sentiment polarity (positive, negative or neutral) towards these aspects; and summarization of aspects by sentiment polar-ity. Although recently proposed unsupervised topic models, such as Joint Sentiment Topic Model (JST) [17], Aspect and Sentiment Unification Model (ASUM) [8] as well as its hierarchical extension (HASM) [10], allow to summarize both the major aspects as well as the sentiments towards them in collections of on-line reviews, they ignore demographic information about review authors, such as their age, gender and location. However, such information may play an important role in opinion mining and sentiment analysis, since different demographic groups of consumers may have differ-ent opinions about the same product aspect.

Meta-data about review authors (e.g. location, gender and age), often provided by on-line consumer review platforms in user pro-files, can be viewed as a discrete set of textual labels (or tags) asso-ciated with individual reviews, which introduce an element of su-pervision into sentiment summarization using topic models. There-fore, demographic groups of consumers (or market segments) in this setting can be defined as groups of on-line review authors shar-ing one or several user meta-data tags. For example, if such tags are organized along the dimensions of age (e.g.  X 18-25 X ,  X 26-35 X ,  X 35-50 X ), gender ( X  X ale X  or  X  X emale X ) and location (e.g  X  X an fran-cisco X ,  X  X ew york X , ... ), then some of the possible market seg-ments are  X  X emales X ,  X  X eople aged 18-25 X ,  X 26-35 year-old males X ,  X  X emales living in new york X , etc. In the simplest case, market seg-ments correspond to a set of all distinct user meta-data tags in a given collection of reviews, however arbitrary market segments can be dynamically created by combining two or more tags depending on the required resolution of topic summaries. The textual con-Figure 1: T opical structure of automotive reviews with respect to market segments defined by distinct user meta-data tags. tent of reviews can be analyzed to identify specific product aspects, while the user meta-data can be used to jointly determine collec-tive preferences of different market segments. We hypothesize that establishing associations between the content of reviews and de-mographic properties of review authors can facilitate fine-grained understanding of product adoption by different customers, from which the companies can benefit by reshaping their product de-velopment, marketing and consumer relationship strategies. Since each review may have multiple associated user meta-data tags and there can be a large number of such tags (and corresponding market segments), summarization of reviews across all market segments can be challenging.

In this work, we propose User-Aware Sentiment Topic Models (USTM for short), a framework for modeling user meta-data, top-ical aspects and sentiments in a unified way. Each of the topic models in the USTM framework identifies several topical aspects frequently discussed in reviews by each market segment. Each as-pect is in turn a two-level topical hierarchy, the first level of which corresponds to the summary of objective comments related to this aspect and its positive and negative subtopics constitute the sec-ond level. Figure 1 provides an example of the topical structure identified by USTM in automotive reviews with respect to market segments defined by distinct user meta-data tags grouped into the demographic dimensions of location, gender and age.

The proposed USTM framework includes the following 4 topic models:
Overall, the key contributions of this work are two-fold: 1. we propose novel parametric and non-parametric topic mod-2. we experimentally demonstrate the effectiveness of the pro-
The remainder of this paper is organized as follows. Section 2 provides a brief overview of previous relevant work. All topic mod-els within USTM framework are presented in Section 3. Experi-mental results are reported in Section 4 and Section 5 concludes the paper. The topic models proposed in this paper build upon the previous work along the following two research directions.
 Aspect-based sentiment analysis . In the past decade, several ma-chine learning methods [6, 23, 14] have been proposed for opin-ion mining and sentiment analysis at the word/phase, sentence and document levels. In recent years, there is a surging interest in aspect-based sentiment analysis, which aims at extracting aspects of entities commented on in reviews and opinions towards them. A majority of the previously proposed approaches for review as-pect discovery rely on natural language processing techniques such as dependency relations [6], supervised sequence labeling [7] and centering theories [19]. However, some of these approaches are ei-ther supervised and require training data in the form of manually identified aspects or aspect terms, or they cannot group extracted terms from multiple reviews into high-level cross-user latent topics (aspects).

More recently, probabilistic topic models have become the main tool for aspect-based opinion mining due to their ability to iden-tify and concisely represent latent topics in collections of reviews. Several topic models for opinion analysis extending the basic topic models have been proposed. The initial work in this direction is the Topic-Sentiment Model (TSM) [20] which considers each docu-ment as a mixture of topics and sentiments. However, TSM is based upon PLSA [5] and, thus, is prone to overfitting. Titov and Mc-Donald proposed the MG-LDA [28] model and a further extended MAS [27] model both of which aim to determine the local and global topics from reviews with structured aspects and numeric rat-ing associated with each aspects. Both MG-LDA and MAS assume that at least one aspect is rated in one review, which is impractical; Lin et al. proposed the LDA-based Joint-Sentiment/Topic model (JST) [17], which assumes that each sentiment has a multinomial distribution over topics, and that each sentiment-topic pair has a multinomial distribution over words. This model, however, cannot accurately distinguish the different sentiments of each topic. Lin et al. later proposed a Reverse JST model (R-JST) [18] by reversing the association between sentiments and topics in JST, which, how-ever, performed poorly. Jo et al. [8] recently developed the Aspect-Sentiment Unification Model (ASUM), which is based on the as-sumption that all words in one sentence are associated with the same topic and sentiment. Mukherjee et al. [22] proposed a Seeded Aspect and Sentiment Model, which discovers aspect-based senti-m ents given sets of seed words for aspect categories. Sauper et al. [25] developed a topic model to jointly identify properties and at-tributes of review snippets rather than complete reviews. Wang et al. [30] introduced Latent Aspect Rating Analysis, a new aspect-level sentiment analysis task aiming to discover both topical as-pects and each individual reviewer X  X  latent rating for each aspect. Moghaddam [21] et al. addressed the same latent rating prediction problem and proposed three different versions of topic models to solve it. Nevertheless, most of the previously proposed topic mod-eling approaches for aspect-level sentiment analysis largely ignore other valuable supportive information, such as the meta-data of re-view authors.

Several previous works [26, 4, 31, 16, 11] utilized user infor-mation in opinion mining and information retrieval, although in a different way from this work. In particular, [26] and [4] are not topic modeling-based approaches, while [31] and [16] model users as random variables and not the attributes of users in the topic modeling process. However, all these approaches are parametric and require to specify a pre-defined number of topics (aspects) per review. To overcome this limitation, USTM framework includes non-parametric topic models based on Dirichlet Process. The work that is the closest to ours is [10] Hierarchical Aspect Sentiment Unification Model (HASUM), which extends the ASUM model by integrating it with the recursive Chinese Restaurant Process [9], a modified version of the nested Chinese Restaurant Process [1], thus allowing to identify hierarchical aspect-sentiment structure. How-ever, HASUM does not consider user meta-data. Li [15] et al. also explored the structure in on-line reviews.
 Supervised/partially supervised topic models . Many researchers have recently directed their attention to incorporating supervision in the form of additional meta-data associated with textual content into topic models. Supervised LDA [2] extended the traditional Latent Dirichlet Allocation [3] by adding a response variable as-sociated with each document. Partially Labeled Topic Model [24] is based on the assumption that if a document is associated with a set of labels (tags), then those tags play a direct role in generating its content. In particular, PLDA and PLDP introduce an additional layer of latent variables that determine associations of each word with a document tag and topic. Topic models incorporating the locations of Twitter users extracted from their profiles have been shown to improve microblog retrieval in [12] and [13]. Although these models shed some light on how to incorporate useful meta-data into topic modeling process, none of them has been applied to aspect-based sentiment analysis. Therefore, the USTM framework proposed in this paper can be viewed as an extension and unifica-tion of the previous work on supervised/partially supervised topic modeling and aspect-based sentiment analysis. In this section, we introduce the four different topic models that constitute the framework for User-Aware Sentiment Topic Model-ing. Table 1 provides a summary of notations used in our discussion of the topic models in the USTM framework.

Given a collection C = { d 1 ,...,d m } of M reviews, in which each review consists of { w 1 ,...,w N dw } words and is associated with { t 1 ,...,t N dt } user meta-data attributes (tags), the primary goal of topic models in USTM framework is to discover associa-tions between user meta-data attributes, topical aspects and senti-ments associated with those aspects across different demographic groups of users. In the following sections, we discuss how paramet-ric and non-parametric topic models in USTM framework achieve this goal.
 USTM-FT(W) extends the PLDA model [24] by jointly modeling user meta-data attributes and sentiments in a generative process. In particular, USTM-FT(W) associates a multinomial distribution over topics with each tag (or a combination of tags) from a set of tags  X  d for d , a trinomial distribution over sentiments (neutral, positive or negative) with each tag-specific topic and a multinomial distribution over words with sentiment-specific topics for each tag. It generates the reviews according to the following generative pro-cess: 1. for each tag t , topic z and sentiment s , draw a distribution 2. for each review d : The graphical model for USTM-FT(W) in plate notation is pre-sented in Figure 2. Since this model is parametric, each user meta-data tag is associated with a fixed number of topics, which is a parameter that needs to be specified a priori. Sentiment informa-tion is incorporated into USTM-FT(W) using asymmetric Dirichlet priors for positive and negative sentiment-specific topics, in which each word w in the corpus vocabulary is assigned a weight  X  ( s  X  0 , 1 , 2 ), which can be pre-defined or learned off-line by boot-strapping from a set of seed words for the corresponding senti-ment polarity s . In general, positive sentiment words will be as-signed larger weight in the prior for positive topics than in the prior for negative topics and vice versa. Posterior inference of USTM-FT(W) model parameters is done using Gibbs sampling. At each state of the Markov chain for the Gibbs sampler, the latent tag t topic z d,i and sentiment s d,i are sampled for each word i in review d according to the following formula: word w has been assigned to tag j and topic k in the entire corpus; n  X  ,j,k,  X  ,  X  is the total number of words in the entire corpus that have of words in review d that have been assigned to tag j , topic k and been assigned to tag j , topic k , and sentiment s in the entire corpus; n  X  ,j,k,s,  X  is the total number of words in the entire corpus that have been assigned to tag j , topic k , and sentiment s . All these counts exclude the word i for which the associated tag, topic and sentiment are being sampled.

After sampling is complete, the distributions for latent variables  X  ,  X  ,  X  are calculated as follows: Previous studies [8, 10] indicate that assigning sentiment to the entire sentence rather than each individual word might be a bet-ter strategy for opinion mining. Following this idea, we propose USTM-FT(S), which is based on the assumption that all the words in a given sentence have the same sentiment, but can be associated with different tags and topics. We also distinguish the subjectivity of each word, which indicates whether a word is a topic word (e.g.  X  X ar X ,  X  X otel X ,  X  X ngine X ,  X  X reakfast X , etc.) or a sentiment word (e.g.  X  X reat X ,  X  X onderful X ,  X  X wful X , etc.). Therefore, given the sen-timent s d,m  X  { 1 , 2 } (1 = positive and 2 = negative) assigned to the sentence m in document d and the subjectivity p d,m,i assigned to the word i in sentence m , the sentiment of this word s d,m,i  X  { 0 , 1 , 2 } (0 = neutral, 1 = positive and 2 = negative) is determined as s d,m  X  p d,m,i . USTM-FT(S) generates each review according to the following generative process: 1. for each tag t , topic z and sentiment s , draw a distribution 2. for each review d : The graphical model for USTM-FT(S) in plate notation is presented in Figure 3. Each state of the Markov chain for the Gibbs sampler used for posterior inference of parameters of USTM-FT(S) consists of two steps. In the first step, we sample the sentiment for each sentence in a review based upon the tag, topic and subjectivity as-signments to each word in the sentence in the previous iteration of the Gibbs sampler. In particular, the probability of choosing senti-ment s for sentence m in review d can be computed by multiplying the probabilities of assigning every word i in sentence m to the sentiment s : where n (  X  d,m ) d,s,  X  indicates the number of sentences, which have been assigned sentiment s in review d .

In the second step, based on the chosen sentiment for the entire sentence, we further sample the latent tag t d,m,i , topic z sentiment s d,m,i for each word in that sentence, according to the following formula:
After sampling is complete, the distributions for latent variables  X  ,  X  ,  X  are calculated similar to Equations 1, 2 and 3. A major limitation of parametric USTM models is that they re-quire to specify a fixed number of topics per each market segment a priori, while such number cannot be easily estimated. Moreover, a lthough it is possible to empirically determine the optimal setting for the number of topics by optimizing an evaluation metric (e.g., perplexity), such an approach is generally impractical. To over-come this deficiency, we propose two non-parametric topic models, USTM-DP(W) and USTM-DP(S), which build upon the Dirichlet Process (DP for short) and allow to automatically discover the la-tent topical structure in collections of reviews annotated with user meta-data.

In non-parametric Bayesian statistics, a Dirichlet process is a method of assigning a probability distribution over other probabil-ity distributions. Given a Dirichlet Process DP ( H, X  ) which is characterized by a base distribution (or a base measure) H and a concentration parameter  X  , a draw G  X  DP ( H, X  ) will return a random distribution over some values that can be drawn from H . If we further draw a parameter  X  i  X  G and use it as a prior for a mixture model, we get the Dirichlet Process mixture model (DPM), from which we can draw observed data points.

The Chinese Restaurant Process (CRP) metaphor is one typical representation of the Dirichlet Process, which generates partitions of variables that exhibit the same clustering structure as the one cre-ated by the Dirichlet Process. The CRP process can be described as assignment of dining tables to new customers, who enter a restau-rant with an infinite number of tables. In the initial state, all the tables are empty, and the probability of the i th customer, z enters the restaurant, to choose the t th table is: where n t indicates the number of customers who are sitting at the table t . Following the same idea, we can assign each observed word either to a new or to an existing topic (the number of topics can be infinite). USTM-DP(W) and USTM-DP(S) are the non-parametric counter-parts of USTM-FT(W) and USTM-FT(S), in which the LDA-based topic inference is replaced by the Dirichlet Process. In both of these models, a word w is assigned to a user meta-data tag and one of its sentiment-specific topics in proportion to how often other words have been assigned to the given tag, topic and sentiment, or to a new sentiment-specific topic created for some tag in proportion to the concentration parameter  X  .

Similar to USTM-FT(W), USTM-DP(W) assigns sentiment to each individual word. The following Gibbs Sampler updating for-mula shows the probability of choosing the tag j , topic k and sen-timent s for the i th word in review d : USTM-DP(S) assigns sentiment on a sentence-based level. Similar to USTM-FT(S), it first samples a sentiment for the i th sentence in review d based on Equation 4 and then samples the tag t topic z d,m,i and sentiment s d,m,i for each word in that sentence, according to the following formula: Experimental evaluation of the proposed topic models was per-formed according to the following four aspects: perplexity on the test data, qualitative analysis of the discovered topics, review senti-ment classification and prediction of demographic attributes of re-view authors. The results of an experimental evaluation for each of these aspects are provided below. Experimental evaluation of the proposed models was conducted on two real world data sets. This first data set (further referred to as Auto ) consists of reviews crawled from FordForum.com 4 , a public automobile on-line review website, which provides the meta-data of review authors, such as location, gender and occupation (in this work, we are only interested in location and gender). The second data set (further referred to as Hotel ) consists of reviews of hotels crawled from TripAdvisor 5 along with the meta-data of review au-thors, such as location, gender and age 6 . h ttp://www.fordforum.com/forum/ http://www.tripadvisor.com both datasets are available at https://github.com/teanalab/USTM Dataset # reviews # tags voc. size # tokens avg. len Auto 11254 401 4952 362,225 32.19 Hotel 7266 324 6430 441,489 60.75 Table 3: M ost popular demographic attributes in experimental datasets. The number in parenthesis indicates the number of reviews associated with the label. Only these labels were con-sidered in experiments.

For both of these datasets, we performed pre-processing by lower-c asing all words, removing stop-words and retaining only those words, which appear in the English dictionary of the spell-checking program aspell . Since we intend to discover sentiment topics, we kept certain stopwords like not , don X  X  , doesn X  X  and won X  X  . We con-sider only those reviews in each data set, which are associated with at least one user label. From those reviews, we further filtered out the words that are either too rare (i.e. appear less than 5 times in the entire corpus) or too common (i.e. appear in more than 30% of the reviews). Sentences were segmented based on punctuation ( X . X ,  X ? X ,  X ! X  and new line). Various statistics of experimental datasets are summarized in Table 2.

All experimental results reported in this paper were obtained by considering user meta-data tags belonging to three dimensions (lo-cation, gender and age). To avoid the sparsity issue, in addition to the gender tags, we considered the top 5 location tags in both data sets as well as the top 5 age tags in the Hotel dataset in terms of the number of reviews associated with them (there is no age informa-tion for the review authors in the Auto data set). Statistics of the user meta-data tags considered in the experiments reported in this work are presented in Table 3 . Sentiment information is incorporated into our models via asym-metric Dirichlet priors (  X  ) for sentiment-specific topics. For exam-ple, the words with strongly positive sentiment polarity like  X  X ood X ,  X  X etter X  or  X  X reat X  will have the higher weights in the Dirichlet prior for positive topics than for negative topics, so that these words will have a higher probability to be sampled for positive aspects of reviews.

In order to calculate the weights for words in the asymmetric pri-ors for sentiment-specific topics, we utilized the sentiment lexicons from the previous studies as seed words with strong sentiment po-larity. In particular, we used the PARADIGMhasm sentiment lex-icon [10] consisting of 31 positive and 33 negative words, and the MPQA [29] sentiment lexicon consisting of 2718 positive words and 4911 negative words. After filtering out the words from the MPQA lexicon, which are not in the vocabulary of our datasets, we obtained sentiment lexicons consisting of 341 positive and 356 negative words for the Auto dataset, and of 671 positive and 572 negative words for the Hotel dataset.
 Datasets # bi-grams # pos. # neg. # pos. # neg.
 Auto 27791 785 1114 3511 3099 Hotel 7751 924 88 1596 477
We first set the neutral, positive and negative priors for all words in the corpus to 0 . 01 . Then for each word found in the known sentiment lexicon with polarity s , we set its weight in the Dirichlet prior for the topics with the same sentiment polarity  X  w and its weight in the Dirichlet prior for the topics with the opposite sentiment polarity to 0 . 001 . For example, using this approach, the weights of a word that belongs to a positive sentiment lexicon in the Dirichlet priors for neutral, positive and negative topics will be 0 . 01 , 2 . 0 , 0 . 001 , respectively. All results reported in this work were obtained by setting the hyper-parameters  X  ,  X  , and  X  to 0 . 1 ,  X  to 0 . 01 ,  X  to 50 /K and 10  X  8 for parametric and non-parametric models, respectively. Bigrams are generally more informative than unigrams in express-ing sentiments for topics. For example, if the fragment of a review  X  X his hotel has a great location X  is represented as a unigram bag of words { X  X otel X ,  X  X reat X ,  X  X ocation X  X , it is hard to tell whether the hotel is great or the location is great. The bigram  X  X reat loca-tion X , however, clearly indicates positive sentiment about the aspect of  X  X ocation X . In order to compare the different representations of topics, we replaced individual words in reviews with bigrams and ran the topic models in the USTM framework on the resulting col-lection. To create bigrams, we combined all pairs of consecutive words in reviews and retained only those bigrams, which appear in more than five and less than 30% of all reviews in each collec-tion. Table 4 shows the statistics of considered bigrams in both collections. To determine the weight of each bigram in the Dirich-let priors for topics of different sentiment polarity, we assumed that if only one word in the bigram belongs to the known sentiment lex-icon and it is not preceded by a negation like  X  X ot X , then the weight of the entire bigram is determined based on this lexicon. If a bigram is preceded by a negation, then the weight is set based on the senti-ment lexicon of the opposite sentiment polarity. If both terms in the bigram belong to the same subjectivity lexicon, then the weight is set based on the sentiment lexicon of this subjectivity and, if words in the bigram belong to different subjectivity lexicons, we consid-ered such bigram as neutral. In this section, we evaluate the different aspects of performance of the proposed models with respect to the state-of-the-art base-lines Aspect-Sentiment Unification Model (ASUM) [8] and Joint Sentiment-Topic Model (JST) [17], which jointly model aspects and sentiments but do not consider demographic attributes of re-view authors. ASUM associates aspect and sentiment with an en-tire sentence and uses asymmetric priors to incorporate sentiment information for individual words. JST associates sentiment and as-pect with each word rather than an entire sentence and uses sym-metric priors for sentiment-specific topics. Both ASUM and JST are parametric models and require to specify the number of topics a priori.

In all experiments, we use the following settings of parameters for ASUM and JST. For ASUM we set  X  to 50 /K and  X  to 1 . The weights of the seed words from the sentiment lexicons were set to 1 . 0 in the Dirichlet priors for the topics with the same polarity and to 0 in the priors for the topics with the opposite polarity. The weights of all other words in the priors were set to 0 . 0 01 . For JST, we set  X  to 50 /K ,  X  to 0 . 01 ,  X  for positive document-sentiment associations to 0 . 01 and negative document-sentiment associations to 5 . 0 . In the first set of experiments, we evaluate the performance of dif-ferent models in the USTM framework depending on unigram or bigram representation of reviews (Uni for Unigram and Bi for Bi-gram) as well as the sentiment lexicon (P for PARADIGMhasm and M for MPQA) used to create the Dirichlet priors for topics with different sentiment polarity. Performance of the model is evaluated in terms of perplexity, which is a measure derived from the likeli-hood of the data in the testing subset (10% of all reviews) under the model estimated on the training subset (90% of all reviews) of each dataset. The results for this set of experiments are summarized in Table 5.
 Table 5: Perplexity of parametric and non-parametric models using different lexicons for unigram and bigram review repre-sentations. Lower perplexity is better.

As follows from Table 5, the lowest perplexity on both datasets is achieved by the non-parametric topic models using the PARA-DIGMhasm lexicon as a source of sentiment seed words. Second, sentence-based sentiment association consistently results in lower perplexity than word-based sentiment association across all lexi-cons and priors for both parametric and non-parametric topic mod-els. Furthermore, USTM models perform consistently better on unigrams than on bigrams and when using PARADIGMhasm lexi-con instead of MPQA. The proposed topic models also outperform ASUM on most combinations, except when using bigram represen-tation of the Hotel dataset and have lower perplexity than JST on the Auto data set. The primary goal of incorporating user meta-data into topic mod-eling process is to summarize the opinions of different market seg-ments about various aspects of products and services. Therefore, we select several examples of sentiment-specific topics from the list of all topics discovered for different market segments that are designated by one or several user demographic attributes. Sample topics presented in Tables 6 and 7 were discovered by the USTM-FT(S) model in the Auto dataset using unigram-based representa-tion of reviews. 10 terms with the highest weight are reported for each topic.
 Table 6: Sample topics discovered in the Auto dataset for the tag  X  X ale X . Table 7: S ample topics discovered in the Auto dataset for the tag  X  X emale X .
Several observations can be made based on examples in Tables 6 a nd 7. First, the proposed topic models can obtain coherent sentiment-specific topics for different aspects discussed in reviews by the cor-responding market segments. For example, the first, second and third topics in Table 6 are related to battery, transmission and lights, respectively. Second, the proposed topic models can assign subjec-tive terms to the correct sentiment-specific topics corresponding to the same aspect of reviews. Third, aspects are different between males and females. In particular, males tend to focus on mechan-ical aspects of the car, while females, although paying attention to some mechanical topics like Topic 1 (engine light) in Table 7, also talk about more general topics like dealerships (Topic 2) and account information (Topic 4).

Table 8 illustrates the difference between the sentiment-specific topics discovered by different age groups in the Hotel dataset, and Table 10 shows the example sentiment-specific topics for different combinations of gender and location.

As follows from Table 8, one major difference between the users in the age group  X 65 X  and  X 18-24 X  is that older people care more about tips as well as how quiet and comfortable their rooms are, while younger people pay more attention to the location of the ho-tel, breakfast and friendliness of staff. Tables 9 and 10 show sam-Table 8: S ample topics discovered in the Hotel dataset for the age tags  X 65 X  and  X 18-24 X . Table 9: S ample topics discovered in the Auto dataset for the lo-cation tag  X  X ort worth, texas X  and gender  X  X emale X  and  X  X ale X . ple topics discovered for females and males in  X  X ort worth, texas X  a nd  X  X innesota X , respectively. Several interesting observations can be made based on these examples. First, both males and females in Texas are talking about the climate control systems in the car ( X  X eater X  and  X  X onditioner X ), while review authors in Minnesota are more focused on the  X  X attery X  and  X  X tarter X  issues. Therefore, location appears to have a noticeable influence on the aspects peo-ple care about, since the summer temperatures in Fort Worth, TX are typically very high and therefore reviews often mention climate control systems (e.g.  X  X onditioner X ), while extremely cold winters in Minnesota seem to cause battery and starter issues. Second, gen-der influences preferences towards particular makes and models of cars, since  X  X ruck X  and  X  X ustang X  are more frequently mentioned in reviews written by males than by females.

Table 11 presents an example of the topics discovered from the bigram-based representation of the Auto dataset. As follows from Table 11, bigram-based representation of reviews results in much more direct and closer associations between the topical aspects and sentiments than unigram-based representation. In this example, fe-males in  X  X over, ohio X  seem to be more interested in aesthetic as-pects of vehicles, such as interior design (e.g.  X  X eats X ), while males tend to care more about the functional components of a car ( X  X njec-tor X ,  X  X ngine X , etc.). Automatic detection of the overall sentiment of a review is one of the fundamental problems in opinion analysis. In this section, we report the results of using the associations between the words, user meta-data tags and sentiment aspects discovered by the topic mod-els in USTM framework for the task of review sentiment prediction. We adopt a probabilistic approach and estimate P ( s | d ) , a distribu-tion of predicted sentiments for a given review d . In particular, we Table 10: Sample topics discovered in the Auto dataset for the location tag  X  X innesota X  and gender  X  X emale X  and  X  X ale X . Table 11: E xamples of bigram topics discovered in the Auto dataset. compare the probabilities of assigning positive P ( s = p os | d ) and negative P ( s = neg | d ) sentiments to a review and classify the re-view as positive if P ( s = pos | d ) &gt; P ( s = neg | d ) . Since the proposed topic models do not directly provide P ( s | d ) as a result of posterior inference, we derive this distribution from the sentiment-based topics for each market segment,  X  , by marginalizing out the topics, z , and user attributes (meta-data tags), t , as follows:
Since the Auto dataset does not provide any information based on which the sentiment polarity of each review could be automat-ically derived, we only used the Hotel dataset for this experiment. In this dataset, each review is associated with graded ratings for six different aspects: service, value, sleep quality, room, location and cleanliness. Each of these ratings is a numeric score between 0 (lowest) and 5 (highest). The overall sentiment polarity of each re-view in the golden standard created for this dataset was determined automatically based on the average score for these six aspects as follows. If the average score for a given review is equal or greater then 3, then the review was considered as overall positive. If the av-erage score of a review is equal or less than 2, then the review was considered as overall negative. Reviews with the average score be-tween 2 and 3 were considered as neutral. Out of 9411 reviews with known ratings, 8553 were labeled as positive, 351 were labeled as negative and 507 were labeled as neutral, using the above method. For this experiment, we used unigrams as lexical units and both PARADIGMhasm and MPQA lexicons as the sets of seed words for deriving sentiment-specific priors. Since ASUM and JST only consider positive or negative sentiments, we evaluate the perfor-mance of all models based only on those reviews, for which the ground truth labels are either positive or negative and are associ-ated with at least one user attribute label in Table 3. The reported results are macro-averaged based on 5-fold cross validation. Fig-ure 4 illustrates the change in accuracy by varying the number of topics per tag for the USTM topic models as well as the ASUM and JST baselines.
 Several interesting observations can be made based on Figure 4. First, USTM-FT(W) has a comparatively stable prediction perfor-mance as there is a small change in accuracy when the number of topics per tag changes. The accuracy of USTM-FT(S) model, however, significantly improves as the number of topics per tag in-creases, while the performance of both ASUM and JST gradually drops. Table 12 compares the best accuracy, precision, recall, F1 score of the topic models in the USTM framework with ASUM and JST baselines for the review sentiment classification task. Figure 4: A ccuracy of sentiment prediction by varying the num-ber of topics per tag (Hotel dataset) Table 12: Performance the proposed models and the baselines for the task of predicting review sentiment. Best values for each performance metric on each dataset is highlighted in bold. Model Precision Recall F1 Accuracy USTM-FT(W)+P 0.9651 0.8282 0.8914 0.8194 USTM-DP(W)+P 0.9613 0.7789 0.8605 0.7878 USTM-FT(S)+P 0.9555 0.8279 0.8871 0.8396 USTM-DP(S)+P 0.9630 0.8193 0.8854 0.8264 ASUM + P 0.9626 0.5725 0.7180 0.5668 JST + P 0.9563 0.4812 0.6402 0.4778 USTM-FT(W)+M 0.9685 0.8915 0.9284 0.8836 USTM-DP(W)+M 0.9644 0.8294 0.8918 0.8447 USTM-FT(S)+M 0.9534 0.7658 0.8494 0.7880 USTM-DP(S)+M 0.9648 0.7217 0.8257 0.7190 ASUM + M 0.9654 0.5579 0.7071 0.5421 JST + M 0.9506 0.4588 0.6189 0.4643
Several important conclusions can be derived based on the results in Table 12. First, topic models in the proposed USTM framework significantly outperform the ASUM and JST baselines in terms of both accuracy and F1 score. Second, topic models assigning sen-timent to each word individually outperform the models assigning sentiment on a per-sentence basis. Third, tuning the number of topics for parametric topic models allows to significantly improve their classification performance, ultimately outperforming the non-parametric topic models. Fourth, in most cases (except USTM-FT(W)-P and USTM-DP(W)-P), using PARADIGMhasm lexicon to derive sentiment-specific priors results in better accuracy than using MPQA lexicon. Since the experimental datasets are domain specific, larger generic lexicons may not translate into better per-formance. Finally, although the high precision of all models can be attributed to the small number of negative reviews in experimental dataset, USTM models still show better performance in predicting positive reviews than the baseline algorithms. Predicting the attributes of the author of a review based on its lex-ical content is another interesting opinion mining task, for which the topic models in the proposed USTM framework is a natural choice. Similar to the sentiment classification task, the distribution over user attributes (or meta-data tags), P ( t | d ) , for each review, d , can also be estimated using sentiment-based topics for each market segment,  X  , by marginalizing out the topics, z , and sentiments, s , as follows:
Since each review can be associated with several user attributes, we use Mean Average Precision (MAP), which takes into account the positions of the actual user attributes in the list of predicted ones, as a measure of performance of the topic models for this task. For this experiment, we used both the Auto and Hotel datasets and considered only the reviews that are associated with at least one of 100 most frequent tags in each dataset. We also used only unigrams as lexical units and PARADIGMhasm as the seed set for deriving the sentiment priors. The reported MAP is obtained using 5-fold cross validation and macro-averaged over the folds.

First, to optimize the configuration and evaluate the impact of different number of topics on the attribute prediction performance of parametric topic models (USTM-FT(W) and USTM-FT(S)), we varied the number of topics from 5 to 100 and recorded MAP for each setting. Figure 5 presents the results of this experiment along with the performance of non-parametric models (UMTM-DP(W) and UMTM-DP(S)) for comparison.

As follows from Figures 5a and 5b, the user attribute prediction accuracy reaches the maximum value when the number of topics is set to 20 for the Auto data set. For the Hotel data set, it reaches the maximum value at 70 and 100 for USTM-FT(S) and USTM-FT(W) respectively. Table 13 summarizes and compares the best results achieved by the proposed parametric and non-parametric topic models for the task of predicting the attributes of review au-thors on both experimental datasets.
 Table 13: Performance of the topic models in the USTM frame-work for the task of predicting the attributes of review authors.
As follows from Table 13, the proposed models can be used to p redict the attributes of review authors with reasonable accuracy. Furthermore, analysis of the results presented in Table 13 leads to three important conclusions. First, all proposed models consis-tently perform better on the Auto dataset than on the Hotel data set. Second, similar to the sentiment prediction task, topic models as-signing sentiment to each word individually are more accurate than the models assigning sentiment on a per-sentence level. Third, the optimized parametric topic models achieved better accuracy than non-parametric ones for this task. In this paper, we introduced a novel research problem of market segment-based summarization of contrasting opinions about differ-ent aspects of products or services in on-line consumer reviews, which has extensive practical applications. We also proposed two parametric extensions of LDA and two non-parametric extensions of the Dirichlet Process to address this problem. The proposed models incorporate asymmetric sentiment priors and jointly model demographic information of review authors and topical aspects of reviews. Qualitative analysis of sentiment-based topics discovered by the proposed models in two real-world collections of on-line consumer reviews using both unigrams and bigrams as lexical units indicates that incorporating user information into opinion analy-sis of on-line consumer reviews allows to better understand the preferences of different demographic groups of customers. We also demonstrated through quantitative evaluation that the proposed models can be used to accurately predict the overall sentiment of reviews as well as the demographic attributes of their authors.
We envision future work to proceed along the following two di-rections. First, machine learning techniques can be leveraged to learn the sentiment-specific priors for each individual word rather than a group of words. The second direction can focus on lever-aging natural processing techniques, such as chunkers and part-of-speech taggers, to improve aspect-sentiment summaries by parti-tioning the text of reviews into more descriptive lexical units and better accounting for negations.
