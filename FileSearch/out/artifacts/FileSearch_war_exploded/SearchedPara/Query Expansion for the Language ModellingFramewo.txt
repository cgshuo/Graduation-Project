 Many information retrieval systems make use of the assumption that each term is independent of each other in order to achieve fast query times and small storage. Unfortunately, this assumption also reduces the quality of retrieval. By using the assumption that every term is independent of each other term, we cause the retrieval system to disregard the term relationships. This implies that only those documents that contain t he query terms will be retrieved, even if other documents are relevant to the query. Therefore, by making the term independence assumption, we are placing a large importance on the process of user query term selection. If the wrong terms are chosen for the query, the wrong documents will be retrieved.

An effective method of introducing term r elationships to these fast retrieval systems is to modify the query before a search takes place. Query expansion is a method of introducing related terms into the users query, in order to retrieve documents containing the related ter ms that would have otherwise not been found. Query expansion was first introduced to the vector space model [1], and later applied to the probabilistic model of information retrieval [2] due to its simplicity and effectiveness.

Language models for information retrieval [3] are a new method of informa-tion retrieval that have found recent atte ntion due to the intuitiveness of their formulation. To date, there have been several attempts at applying query expan-sion to language models, but they have only caused an increase in the language model complexity.

In this article, we introduce a new form of query expansion that is derived from within the language modelling framework. We show how to use the query expansion and also how we can generate the term relationships to use for the expansion. This article makes the following contributions:  X  a method of query expansion for language models, using the na  X   X ve Bayes  X  the application of PLSA term-term probabilities for query expansion in lan- X  an introduction to query term compensation during query expansion
The article will proceed as follows: Sect ion 2 will provide a brief description of language models and their use for information retrieval, section 3 describes a simple new method of query expansion for language models and provides meth-ods of computing term-term probabilities to use within it. Section 4 shows a problem that is inherit in deriving probabilistic term relationships and provides simple methods to overcome it. Finally, s ection 5 contains the e xperimental per-formance of the language model query expansion and a discussion of the results. Rather than computing the relevance o f a document when given a query, the language modelling approach to information retrieval is to compute the proba-bility of a query being generated from a given document model. By assuming term independence, we are able to decompose the language modelling method into the product of query term probabilities: The value P ( t i | M d ) is the probability of generating the term t i using document model M d , therefore it is a measure of the similarity of term t i to document d . The language modelling approach stats that every document is generated using a document model. The text within document d is sampled from the document model, based on the probability distributions within the model. Therefore, for us to provide P ( t i | M d ), we must estimate the distribution of the terms in the document model M d . To do so, must must use the term frequency values within the document collection; the only evidence that we have of the term distributions within the document model.

By simply using the term frequencies ( f d,t ) to compute P ( t i | M d ), we limit our probability estimations to the sampled terms within the document and we also assign a zero probability to those terms that were not sampled from the document model. This constraint is not v alid, since there is a chance that there are many terms that are found in to document model M d , but not found in this particular sample. To obtain a more global term probability, we could observe the frequency of the term in the docume nt collection; this value provides us with a measure of the rarity of the term, but is not specific to the document. Therefore, to obtain a better approximation of the term distributions within the document model, a mixture of the docum ent term frequency and the collection term frequency is used to compute P ( t i | M d ): where  X   X  [0 , 1] is the smoothing parameter, P ( t i | d ) is the probability of choosing term t i from document d . The language modelling framework provides us with a method of computing the probability of a document generating a query, even if the query terms do not exist within the document. We showed in the previous section that this is possible by observing the global document collection term probability as well as the local document specific term probability.

Unfortunately, this method of term probability computation does not take into account the relationship of the term to any other term in the document set. The probabilities are computed based only on the frequency of the term itself. By ignoring term relationships, the language modelling approach will provide high probability to those queries who X  X  terms appear in the given document and low probability to queries who X  X  terms do not appear in the given document, regardless of the content of the document. Therefore the document retrieval process requires the user to use the right query terms, even though the user is likely to be unfamiliar to the requested information. As a simple example, a search for corn will retrieve documents containing the term corn, but not the equally relevant documents containing the word maize .

In order to retrieve documents contai ning related term, we must be able to: 1. use the term relationships as a query expansion within the retrieval process, 2. identify the term relationships to use as a query expansion There have been attempts to include query expansion in the language modelling retrieval process [4,5], but they greatly i ncrease the complexity of the model and hence negated the simplicity that makes the language modelling method desirable.
In this section we will deduce a simple method of including a query expansion within the language modelling framework by applying the na  X   X ve Bayes assump-tion, and we will explore two methods of computing the term relationships from the document collection. 3.1 Query Expansion Using Na  X   X ve Bayes In order to use term relationships within the language modelling framework, we must be able to derive a model that reflects the simplicity of a language model. A query expansion process computes the set of terms that are related to the query and then uses those terms to perform the retrieval. Put into the language model framework, we compute the probability of generating the query, given the expansion terms and the document model.

To compute the set of term probabilistic relationships, we will use the doc-ument set statistics. If we choose to use the joint probability values, we would over fit our term relationships to the doc ument set. Therefore, to generalise the relationship modelling and hence remove the over fitting, we use na  X   X ve Bayes modelling to remove the dependence of the terms on the set of documents.
To obtain the probability of generating term t i ,giventerm t j and document model M d , we use the following equation: are conditionally independent given t j ,and T is the set of unique terms. Using this equation, we can compute the probability of document model M d generating term t i from the probability of document model M d generating term t j and the probability of term t i given term t j .

Equation 2 provides us with a query expansion method for language models, where P ( t i | t j ) is used to compute the relationship of each term to the query term and hence the query expansion, and P ( t j | M d ) is the language model term probability shown in equation 1, which is used to compute the probability of generating the expansion terms give the document model.

Note that although we use Dirichlet smoothing throughout this article, the above derived query expansion within the language modelling framework can be used with any smoothing method. 3.2 Computing the Query Expansion Now that we have set up a general framework for query expansion within the language modelling method of information retrieval, we will examine methods of computing the term relationships that are needed in order to perform the query expansion. In this section, we present t wo forms of query expansion; the first is based on the probabilities produced using language models, and the second is based on the probabilities produced using probabilistic latent semantic analysis. Probabilistic latent semantic based query expansion. Probabilistic la-tent semantic analysis (PLSA) [6] is a probabilistic method of discovering hid-den topics withing a document collection using maximum likelihood. Given the estimated probability of document d i and term t j as: we want to compute the actual probability of a term and a document, given the model: where P ( d | z )and P ( t | z ) are the probability of document d given topic z and the probability of term t given topic z respectively, and P(z) is the probability of topic z .

It was recently shown that PLSA information can be used effectively as a query expansion by observing only the P ( t | z )and P ( z ) values [7]. We can show: using the na  X   X ve Bayes assumption that term t i and term t j being conditionally independent given topic z . The set of probabilities of terms T are disjoint when given term t j This can be seen by the property that: case where i = j . From this we can see that the probability of a term given itself is less than one. We may also find that the P ( t i | t j )where i = j is greater than P ( t i | t i ), implying that other terms are more related to the term than the term itself.

The effect of a term having a low probability given itself, may cause problems during a query expansion. We may find that other terms introduced from the expansion have a higher probability than the original query terms. Therefore the query terms may become lost in the expansion.

To compensate for this reduction is query term probability, we have explored the method of adding 1 to the computed probability of a term given itself. This compensation is as though we have included the original query in the query expansion, where the add method adds the expansion probability of the query terms in the expansion to the query terms.

Therefore, using the PLSA-based quer y expansion, we provide the following methods of compensation for the conditional probabilities: where  X  is the compensation factor, and the probability for i = j is taken from our derivation earlier in equation 3. Our set of experiments examines PLSA query expansion using add query com-pensation within the language model framework on a collection of 84 , 678 doc-uments from the associated press found in TREC disk 1 1 . Experiments were performed using the values 0, 0 . 1, 0 . 3, 0 . 5, 0 . 7, 0 . 9 and 1 for the compensation factor (  X  ). The results are shown in table 1.

We can see from the results that the MAP peaks at  X  =0 . 5 and that the results are statistically significant at the 0.05 level for larger values of  X  .Wecan also see that the result for  X  = 0 is very poor. Using the add query compensation, where  X  = 0 is equivalent to using no query compensation, so we can see that it is essential to use query compensation on large and small document sets.
The significant increase in MAP shows that using PLSA query expansion with query compensation is a useful addition when used within the language model framework. Within the field of information retrieval, language models have shown to be competitive with other models of retrieval, while offering an intuitive and sim-ple formulation. To simplify the model, language models include the assump-tion that all terms are independent. This assumption places great importance on the user X  X  choice of query terms. To introduce term relationships into the language modelling framework others have applied query expansion, but the complexity of the expansion removed the simplicity from the language model formulation.

In this article, we introduced a method of query expansion for language models which uses the na  X   X ve Bayes assumption to produce generalised probabilistic term relationships. To compute the term relationships, we examined a probabilistic latent semantic analysis (PLSA) method. Experiments on a document collection showed us that the the PLSA query expansion within the language modelling framework provided a significant increase in precision over the language model with no expansion. Therefore the PLSA query expansion was also effective for larger document sets.

