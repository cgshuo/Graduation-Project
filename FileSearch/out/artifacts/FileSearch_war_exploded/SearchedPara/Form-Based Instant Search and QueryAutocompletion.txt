 Finding information in structured data, specifically relational data, is a key task of data management in the age of information explosion. In early days, people could only use Structured Query Language (SQL) to find information in a rela-tional database. SQL provides to users sufficient abilities to express their query intents, but it is hard to use and master even by experienced users. In recent years, because of its ease of use, keyword search on relational data has attracted more and more interests from database researchers. Although keyword search is a easy way for users to find information they need, sometimes its limited expression power cannot meet users X  se arch requirements. For example, if we want to find all papers whose titles contain the word  X  database  X  with Com-pleteSearch 1 [1], which is a search engine on the Computer Science Bibliography (DBLP) 2 dataset, and pose the keyword  X  database  X  as the query to the system, then some of the top-ranked results are irrelevant because in each of them the word is contained in conference name instead of paper X  X  title. Another example is that, if we want to find all of Wei Wang X  X  publications, and simply input  X  wei wang  X  as the query to CompelteSearch, none of the top 20 results are relevant because the system interprets  X  wei  X  X nd X  wang  X  X stwonames.

A trade-off between the ease of use and expression power is Query-By-Example (QBE), in which users input their queries by filling in forms with keywords. By specifying the query condition to different input boxes, the user can express her query intent. However, since a form-style interface is more complicated than a single input box that is used for keyword search, its usage is limited to those  X  X dvanced search X  systems in real applications, such as eBay Advanced Search 3 and PubMed Advanced Search 4 ,etc.

In this paper we investigate the problem of enhancing the ease of use of form-style interface by introducing the instant search feature to it. With this feature users can get results instantly right after each keystroke when they are filling in the form. The feature of instant search has been proved to be useful in im-proving the user experience of traditio nal keyword search, but it has never been considered to be applied in f orm-style interfaces before. In addition, to further improve the user experience, we investigate the problem of query autocompletion for form-style interfaces, with which users can get lists of suggested attribute val-ues or keywords that can help them extend their current queries to get the results they need more quickly when they are typing in the form. The contributions of this paper are summarized as follows.  X  We designed a trie-based index and an efficient incremental algorithm that  X  We addressed the problem of query autocompletion for textual attributes ,in  X  We conducted extensive experiments to evaluate our algorithms on real Besides, we also built a real system that can provide a fully-functional form-style instant search and autocompletion support on the DBLP dataset for computer science researchers. The system is called Seaform 5 , which stands for Sea rch-as-you-type on form s . The system has been online since Oct. 2009, and a brief introduction of it can be found in [16]. All of our experiments in this paper were based on the real query log of this system.

The rest of the paper is organized as follows. In Section 2 we formally define the problems we address. We propose our basic index structures and algorithms in Section 3, and introduce the techniques of query autocompletion for textual attributes in Section 4. Exp erimental results are prese nted in Section 5. We give a review of related work in Section 6 and conclude this paper in Section 7. In this paper, we use a single relational table as our underlying data. We denote the set of tuples of the table we are going to search by T = { t 1 ,t 2 ,...,t M } .The attribute set of the table is denoted by A = { a 1 ,a 2 ,...,a N } . The value of the attribute a n of the tuple t m is denoted by t m,n ,where m  X  [1 ,M ]and n  X  [1 ,N ]. For example, Figure 1(a) illustrates a sample relational table. A form-style keyword search interface consists of several input boxes (see Figure 1(b)). Each of these input boxes corresponds to an attribute of the table. When a user wants to search for something with this interface, she fills in the input boxes with query keywords, and a form-style query is then posed to the system. Without loss of generality, in this paper we only consider the case in which each attribute has exactly one corresponding input box on the form, and as a result we can avoid the distinguishing of attributes and input boxes in the rest of the paper. Formally, a form-style query is defined by q = { f n | n  X  [1 ,N ] } , where f n , called the n -th field of the query, denotes the non-empty query string in the input box that corresponds to the attribute a n . For example, the query {
Title : X  xml  X , Author : X  al  X  } has two fields: one is  X  xml  X  that belongs to the Title input box, the other is  X  al  X  that belongs to the Author input box.

Each field in a form-style query denotes the search condition to the corre-sponding attribute values of the tuples in the relational table. For instant key-word search, keywords in form-style queries are usually prefix keywords , i.e. each keyword is meant to be a prefix of a set of possible complete words appear in the data table. Formally, we use p w to denote that a prefix keyword p is a prefix of a complete word w . If each prefix keyword in a query q has a matched complete word in the corresponding attribute in a tuple t i ,wesaythat q matches t i .Inotherwords, q matches t i (denoted by q t i ) if and only if  X  f formally define the problem of form-based instant search as follows.
 Definition 1 (Form-Based Instant Search). Given a relational table T , form-based instant search answers the form-style query q with a set of tuples R = { t i | t i  X  T and q t i } as the result.
 To further improve the user experience, we can provide all possible distinct attribute string values of the currently-editing input box as query completions to the user when they are filling in the form. Assume that a user is inputting her query q in the n -th input box and the result of form-based instant search is R .Weuse S n to denote the set of distinct string values of the attribute a n ,and use S n,q n to denote the set of those strings in S n that are matched by q n .We rank the strings in S n,q n by their number of occurrences, a.k.a. frequencies ,in R , and provide top-ranked ones to the user as completions. To summary, the formal definition of the problem of form-based query autocompletion is as follows. Definition 2 (Form-Based Query Autocompletion). Given a form-style query q and its result set R , the completion list for the n -th attribute is the top-k ranked distinct string values in S n,q n , in which the score of each string value s  X  S In the following section, we will introduce the detail of our index structures and algorithms that support form-based instant search and query autocomple-tion simultaneously. However, for some kind of attribute such as Title , returning distinct attribute string values to the user is useless for guiding her compose a better query because the number of occu rrences of a specific attribute string value will be small. We call this kind of attribute the textual attribute (corre-spondingly, we call the other attributes the categorical attribute). We discuss the techniques of providing complete words as autocompletion results instead of attribute string values to the user in Section 4. 3.1 Form-Based Prefix Keyword Search According to the definition, the main difference between form-based keyword search and traditional keyword search is that a user X  X  query conditions can be split into fields and specified to different attributes. As a result, each attribute of the data table should have its own index. Specifically, to support prefix-matching-based keyword search, which is the very basic requirement of instant search, we index all of the words appear in each attribute into a trie structure. A trie is a special tree structure in which a path from the root to a leaf corre-sponds to a word and all the words with common prefixes share the same path from the root. For example, Figure 2(a) shows the trie structure of the Title attribute of our sample dataset shown in Figure 1(a).

We can attach an inverted list of tuple ids to each leaf node of the trie to support simple keyword search by prefixes (see Figure 2(b)). For each field in the query, we first locate the trie node for each of the prefix keyword. We get the id list of each prefix keyword by calculating the union of all the inverted lists of the leaf nodes under the sub-trie of the previously located trie node. Finally, we intersect the id lists of all the prefix keywords of all the query fields to get the final id list of the result set, called result list for short.

However, the problem we should solve is not the simple prefix keyword search only. We should also consider the problem of: 1) query autocompletion; and 2) making prefix keyword search achieve interactive speed. To this end, in the following two sub-sections, we will introduce our adapted index and algorithms that support simultaneous query autocompletion and our cache-based techniques that can greatly improve the overall performance of our online processing by making all the online calculations incremental. 3.2 Simultaneous Query Autocompletion The data structures that is used to support this new method are several mapping tables. First, for each attribute, we construct a so-called local-global mapping table .The l -th row of the mapping table stores the ids of all the tuple in the data table containing the l -th distinct string value (for each distinct string value we assign an id to it, called local id , as well). Second, we also construct a global-local mapping table ,inwhichthe g -th row contains the local ids of distinct string values that is contained in the g -th tuple in the data table (accordingly, the id of a tuple in the data table is called a global id ). For example, Figure 2(b) shows the two mapping tables for the Title attribute.
To make the autocompletion more efficiently, we split the process of original prefix keyword search into three steps , and computes the search results and completion results simultaneously. Specifically, the first step of our new method is to find matched attribute string values according to each of the query fields, the second step is to find result set of tuples using these attribute string values, and the final step is to verify the attribute string values of the currently-editing attribute according to the result set to compose the completion list. 3.3 Incremental Online Processing The key requirement of instant search an d query autocompletion is efficiency. As a result, it is reasonable to utilize the previously-computed results and use the difference of the queries to co mpute new results. This is called incremental online processing . Specifically, we cache the previous query and its results. When a new query is submitted, we first check t he cache to see whether the query can be answered from the cached results. If the new query can be obtained by extending thecachedquerywithoneormoreletters,thenwehaveacachehit.Weperform the non-incremental search algorithm described previously if there is no cache hit, or perform an incremental search based on the base query and base results if there is a cache hit. We use global results to denote the result id list of tuples in the data table, and use local results to denote the id list of distinct string values of an attribute. The incremental algorithm can be described as follows. Step 1. Identify the difference between the cached query and the new query. We Step 2. Calculate the local ids of a n basedonthequerystringin a n .Thisis Step 3. Calculate the global results. This is done by first calculating the set of Step 4. Calculate the local results of a n . This step is called  X  X ynchronization X . Dual-List Trie Structures. In step 3 of the incrementa l algorithm, to obtain the global results, we map the local ids calculated in step 2 to lists of global ids, merge these lists, and then intersect the merged list with the global base results. If there are many local ids, the merge ope ration could be very time consuming. To address this problem, we can attach an inverted list of global ids to each of the corresponding trie leaf nodes. In this way, given a prefix keyword, we can identify the matched tuple in the data table without any mapping operation. We call the adapted trie structures dual-list tries . With the help of dual-list tries, the overall search time can be reduced comp ared with that of using original tries, which are called single-list tries .
 On-Demand Synchronization. In step 4 of the incremental algorithm we use a brute-force method to keep the local result list of the currently-editing attribute ( a n ) up to date. However, if the user does not switch the input box to another one, it is unnecessary to perform synchronization for this input box. As a result, we do not perform synchronization for the query that has the same currently-editing input box with the cached query. On the other hand, if the user changes her focus to another input box, we must synchronize for (and only for) the corresponding attribute at once. We call this mechanism the on-demand synchronization . It requires one merge operation and one intersection operation. In contrast, the brute-force synchroni zation requires one merge operation and one intersection operation whenever the user types in a letter. As is discussed in Section 2, if a user is typing in her query in the input box of a textual attribute (for example, in the Title input box), showing a list of distinct attribute string values (i.e. complete title strings) to the user cannot help her much to extend the query. This is because each attribute string value has very few occurrences in the dataset. To address t his issue, for textual attributes, we provide a list of ranked keywords instead of attribute string values as query-extending suggestions (a.k.a. query completions). Specifically, we calculate the scores of each possible keywords accord ing to the current search result set and the current keyword prefix the user is inputting, and return top-k keywords as completions. The score of a keyword to suggest is defined by the number of tuples it appears (i.e. its frequency) in the result set of search. The rational of using this definition is straightforward: if the user uses the top-ranked keyword to extend her query, she will get the largest result set compared with using other keywords. This kind of query autocompletion is called frequency-based keyword suggestion for form-based instant search, and is defined as follows.
 Definition 3 (Frequency-Based Keyword Suggestion). Given the search result set R and the currently-input keyword prefix p in the input box of a textual attribute A n , we return the top-k frequent keywords appear in the attribute A n in the tuples of R . In addition, these keywords should also take p as their prefixes. 4.1 ScanCount: Exact Method as Baseline The most straightforward method can be derived directly from the definition of the problem. Conceptually, after we get the result set R ,wescaneachofthe tuples in R , and count the occurrences of each word in attribute A n . Meanwhile, we should also avoid those words that do not take p as their prefixes. The detail of this baseline algorithm is omitted due to space limitation. 4.2 HistScan: Histogram-Based Estimation Although the ScanCount algorithm is straightforward to implement, its perfor-mance highly depends on the size of the result set: if the result set is large, the algorithm should scan through too many tuples, making the processing time too long for short queries (since short queries usually lead to large result sets). An alternative method is to scan all possible keywords instead of tuples in the result set, calculate their frequencies, and then return top-k most frequent ones as completions. Obviously, the performance of this method does not depend on the size of the result set, making it specially fit for short queries.
The key of this keyword-scan method is the calculation of the frequency values of keywords. With the help of the index we proposed in Section 3, we can get the frequency of a keyword by intersecting its inverted tuple id list with the id list of the result set (called the result list for short). However, this method requires O ( keyword, making it unsatisfactory in terms of performance.

Our solution is to convert the id lists (the inverted list and the result list) into histograms, and estimate the frequency value of the keyword using these histograms in O (1) time. The histogram of an id list is defined as follows. Definition 4 (Histogram of ID List). Given an id list L = l 1 ,l 2 ,...,l | L | , its corresponding histogram H ( L ) is a B -length array h 1 ,h 2 ,...,h B ,where h b  X  [1 ,B ] is the number of ids in L that are in M B  X  ( b  X  1) , M B  X  b .Here B  X  [1 ,M ] isauser-definednumber,and M is the number of tuples in the dataset.
 Using histograms, the frequency of a word w , whose inverted list is I ,inthe result list R can be estimated by i.e. it is the dot product of the two arrays. It can be proved that this estimated frequency can get more accurate when we use a larger B (proof omitted due to space limitation). However, a larger B value also leads to more computation and more storage space for histogram maintain. As a result, adjusting B it is a trade-off between accuracy and efficiency.
 Now we can describe our new query autocompletion algorithm as follows. During the offline process of index building, we calculate the histogram for each of the words appear in attribute a n . During the online process, we first calculate the histogram of the result list, and the n estimate the frequencies of all the matched words using Equation (1). The matched words can be obtained by first identifying the node on the trie of a n in the index corresponding to the currently-inputting keyword prefix in the query, and then traversing the sub-trie rooted at this node to find all of the leaf nodes. Finally, we sort the matched words in descending order of their estimated frequencies and return the top-k of them as query autocompletion results. This algorithm is called HistScan .
 4.3 HistBFS: Scan-Free Histogram-Based Estimation Both of the previous two algorithms have poor performance since they cannot avoid costly scan operations. In this sub-section we propose an algorithm that can avoid the scan on either of the result list or the matched words by applying a best-first traversal on the trie structure of the attribute a n .

For each non-leaf node x on the trie, we estimate the maximum frequency among all of the leaf nodes (complete words) in the sub-trie rooted at x using the pre-calculated histogram for x and the histogram of R . We traverse the trie by enumerating nodes in descending order of the estimated maximum frequency values. Using this traversal strategy, we can avoid visiting unpromising sub-tries, as well as the scan of all the words or result tuples. To estimate the maximum frequency value for a node x without enumerating its corresponding leaf nodes, the histogram of x should be set as the maximum-merging of the histograms of its child nodes, which is defined as follows.
 Definition 5 (Maximum-Merging of Histograms). Given a set of B -length merging is a histogram H  X  = h  X  1 ,h  X  2 ,...,h  X  B ,where h  X  b =max i h ( i ) b . It can be proved that, if we set the histogram of x to be the maximum-merging of all of its child nodes, the estimated frequency value is an upper bound of the actual maximum frequency value among all the leaf nodes of x , no matter what the result set R is. The detail of proof is omitted here.

The maximum-merging histograms for each node on the trie can be calculated in a bottom-up manner after we build the trie structure. During online process-ing, we use a priority-queue to maintain the traversal state. The detail of this algorithm, called HistBFS , is illustrated in Figure 3.

Algorithm 1: HistBFS( p , R ) In this section, we evaluate our proposed algorithms on a real-world dataset, DBLP, which contains 1.3 million computer-science publications. The dataset is delivered in XML format, as a result we converted it into a single relational table, in which each tuple contains the following attributes of a published paper: ID , Title , Journal Name , Authors ,and Year . The whole table is approximately 400MB large. We implemented our algorithms in C++ and compiled our code using gcc with -O3 flag. All the experiments were done on a Ubuntu computer with Intel Xeon CPU 2.50GHz and 16GB of RAM. 5.1 Evaluation of Incremental Algorithms We used a workload of 45,276 real queries collected from the query log of our Seaform system to evaluate our proposed algorithms. Figure 4 shows the com-parison of average processing time per query of four algorithms: (1) SL-BF, which uses Single-List tries and Brute-Force synchronization, (2) SL-OD, which uses Single-List tries and On-Demand synchronization, (3) DL-BF, which uses Dual-List tries and Brute-Force synchronization, and (4) DL-OD, which uses Dual-List tries and On-Demand synchronization.
We can see that both the dual-list tries and on-demand synchronization can improve the performance speed. If we use these two together, the DL-OD algo-rithm can answer a query two times faster than using none of the optimizations, at an average speed of 50 milliseconds per query. Figure 5 shows the scalability of the DL-OD algorithm. The processing time and index size increase linearly as the dataset increases. The index size gets slightly larger if we use dual-list tries compared with using single-list tries (10% larger), while the algorithm becomes about 2 times faster.
 5.2 Evaluation of Query Autocompletion In the DBLP dataset, the Title attribute is a textual attribute. As a result, we evaluated our three algorithms for query autocompletion specifically on this attribute. The query workload we used is a subset of the 45,276 queries: we only consider the queries whose Title fields are not empty. Figure 6 shows the performance of the three algorithms we proposed. As we can see, when the length of the histogram, B , varies, the performance of HistScan and HistBFS gets worse. However, HistBFS still greatly outperforms the other two.
Figure 7 illustrates the comparison of the size of the histograms and the accuracy. The precision values used in th e accuracy computation is obtained by comparing the results of HistBFS and ScanCount (here ScanCount is used for ground-truth). We can see that, when B varies, the total size increases while the accuracy also increases. This result te lls us that we can trade-off between the scalability and accuracy by choosing different B values. Making the querying on relational data easier has attracted many interests of database researchers recently [12]. Query-By-Example [17] is the earliest paradigm that enables a user query a relational database without using SQLs. In recent years, keyword search has been used as a novel search method in re-lational databases [3]. With the support of autocompletion [7,14] and the  X  X ype-ahead X  functionality [1,10,13], keyword search becomes more and more powerful in searching the underlying data with relatively simple schemas. In addition, [6] takes another way of making the querying of relational data easier by suggesting complete SQL statements to users according to their keyword queries. These works are all based on single-input-box interfaces.

Query autocompletion on relational databases has also been researched for years. [2] provides users the ability to navigate a relational database in different facets. [1] and [5] also provide query autocompletion over the DBLP dataset. In addition, [11] and [15] enable users to navigate the underlying dataset by choos-ing one of the frequently occurred terms . There are also recent works on keyword search in form-style interfaces, in which [8] and [9] focus on form creation, and [4] focuses on finding the most possible interfaces for keyword search. Obviously, the goals of these works are different from ours. In this paper we proposed new methods of instant search and query autocomple-tion that can greatly improve the ease of use of traditional QBE search paradigm. Experimental results show that our algorithms achieve scalability and accuracy, and also have high performance.
 Acknowledgement. This work is supported by the National Natural Science Foundation of China (Grant No. 60833003).

