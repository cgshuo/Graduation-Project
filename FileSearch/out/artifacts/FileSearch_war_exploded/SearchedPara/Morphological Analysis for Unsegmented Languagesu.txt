 In contrast to space-delimited languages like En-glish, word segmentation is the first and most cru-cial step for natural language processing (NLP) in unsegmented languages like Japanese, Chinese, and Thai (Kudo et al., 2004; Kaji and Kitsure-gawa, 2014; Shen et al., 2014; Kruengkrai et al., 2006). Word segmentation is usually performed jointly with related analysis: POS tagging for Chi-nese, and POS tagging and lemmatization (anal-ysis of inflected words) for Japanese. Morpho-logical analysis including word segmentation has been widely and actively studied, and for exam-ple, Japanese word segmentation accuracy is in the high 90s. However, we often observe that strange outputs of downstream NLP applications such as machine translation and question answering come from incorrect word segmentations.

For example, the state-of-the-art and popu-lar Japanese morphological analyzers, JUMAN (Kurohashi and Kawahara, 2009) and MeCab (Kudo et al., 2004) both analyze  X   X  X  X  X  X  X  X  X  X  (foreigner X  X  right to vote) X  not into the correct seg-mentation of (1a), but into the incorrect and awk-ward segmentation of (1b). (1) a.  X  X  X  /  X  JUMAN is a rule-based morphological analyzer, defining word-to-word (including inflection) con-nectivities and their scores. MeCab is a supervised morphological analyzer, learning the probabilities of word/POS/inflection sequence from an anno-tated corpus of tens of thousands of sentences. Both systems, however, cannot realize semanti-cally appropriate analysis, and often produce to-tally strange outputs like the above.

This paper proposes a semantically appropriate morphological analysis method for unsegmented languages using a language model. For unseg-mented languages, morphological analysis and language modeling form a chicken-and-egg prob-lem. That is, if high-quality morphological analy-sis is available, we can learn a high-quality lan-guage model from a morphologically analyzed large corpus. On the other hand, if a high-quality language model is available, we can achieve high-quality morphological analysis by looking for a segmented word sequence with a large language model score. However, even if we learn a language model from a corpus analyzed by a certain level of morphological analyzer, the language model is affected by the analysis errors of the morphologi-cal analyzer and it is no practical use for the im-provement of the morphological analyzer. A lan-guage model trained by incorrectly segmented  X   X   X  (foreign)/  X  X  X  (carrot)/  X  X  X  (regime) X  just sup-ports that incorrect segmentation.

The point of the paper is that we have tackled the chicken-and-egg problem, not by using a lan-guage model of raw word sequences, but by using a semantically generalized language model based on word embeddings, RNNLM (Recurrent Neural Network Language Model) (Mikolov et al., 2010; Mikolov et al., 2011). The RNNLM is trained on an automatically analyzed corpus of ten million sentences, which possibly includes incorrect seg-mentations such as  X   X  X  X  (foreign)/  X  X  X  (carrot)/  X  X  X  (regime). X  However, on semantically gener-alized level, it is an unnatural semantic sequence like nation vegetable politics . Since the state-of-the-art morphological analyzer achieves the high accuracy, it does not often produce incorrect anal-yses which support such a semantically strange se-quence. This would prefer analysis toward seman-tically appropriate word sequences. When a mor-phological analyzer utilizes such a generalized and reasonable language model, it can penalize strange segmentations like  X   X  X  X  (foreign)/  X  X  X  (carrot)/  X  X  X  (regime), X  leading to better accuracy.

We furthermore retrain RNNLM using an an-notated corpus of manually segmented 45k sen-tences, which further improves morphological analysis. There have been several studies that have inte-grated language models into morphological anal-ysis. Wang et al. (2011) improved Chinese word segmentation and POS tagging by using N-gram features learned from an automatically segmented corpus. However, since the auto-segmented cor-pus inevitably contains segmentation errors, fre-quent N-grams are not always correct and thus this problem might affect the performance of morphological analysis. They also divided N-gram frequencies into three binned features: high-frequency, middle-frequency and low-frequency. Such coarse features cannot express slight differ-ences in the likelihood of language models.
Kaji and Kitsuregawa (2014) used a bigram lan-guage model feature for Japanese word segmenta-tion and POS tagging. Their objective of using a language model is to normalize informally spelled words in microblogs. Therefore, their objective is different from ours.

Some studies have used character-based lan-guage models for Chinese word segmentation and POS tagging (Zheng et al., 2013; Liu et al., 2014). Although their approaches have no drawbacks of learning incorrect segmentations, they only cap-ture more local information than word-based lan-guage models.

Word embeddings have been also used for mor-phological analysis. Neural network based models have been proposed for Chinese word segmenta-tion and POS tagging (Pei et al., 2014) or word segmentation (Mansur et al., 2013). These meth-ods acquire word embeddings from a corpus, and then use them as the input of the neural networks. Our proposed model learns word embeddings via RNNLM, and these embeddings are used for scor-ing word transitions in morphological analysis. Our usage of word embeddings is different from the previous studies. We propose a new morphological analysis model that considers semantic plausibility of word se-quences by using RNNLM. We integrate RNNLM into morphological analysis (Figure 2). We train the RNNLM using both an automatically analyzed corpus and a manually labeled corpus. 3.1 Recurrent Neural Network Language RNNLM is a recurrent neural network language model (Mikolov et al., 2010), which outputs a probability distribution of the next word, given the embedding of the last word and its context. We Figure 2: Workflow for training RNNLM and base model. by (Mikolov et al., 2011; Mikolov, 2012) as the implementation of RNNLM. The RNNME lan-guage model has direct connections from the input layer of the recurrent neural network to the output layer, which act as a maximum entropy model and avoid to waste a lot of parameters to describe sim-ple patterns. Hereafter, we refer to the RNNME language model simply as RNNLM.

To train RNNLM, we use a raw corpus of 10 million sentences from the web corpus (Kawa-hara and Kurohashi, 2006). These sentences are automatically segmented by JUMAN (Kurohashi and Kawahara, 2009). The training of RNNLM is based on lemmatized word sequences without POS tags.

The trained model contains errors caused by an automatically analyzed corpus. We retrain RNNLM using a manually labeled corpus after training RNNLM using the automatically ana-lyzed corpus as shown in Figure 2. The retraining aims to cope with errors related to function word sequences. 3.2 Base Model For our base model, we adopt a model for su-pervised morphological analysis, which performs segmentation, lemmatization and POS tagging jointly. We train this model using a tagged cor-pus of tens of thousands of sentences that contain gold segmentations, lemmas, inflection forms and POS tags. To predict the most probable sequence of words with lemmas and POS tags given an input sentence, we execute the following procedure: 1. Look up the string of the input sentence using 2. Make a word lattice. 3. Search for the path with the highest score Figure 1 illustrates the constructed lattice during the procedure. At the dictionary lookup step, we use the basic dictionary of JUMAN and an ad-ditional dictionary comprising 0.8 million words, both of which have lemma, POS and inflection in-formation. The additional dictionary mainly con-sists of itemizations in articles and article titles in Japanese Wikipedia.

We define the scoring function as follows: where y is a tagged word sequence,  X ( y ) is a feature vector for y , and  X  X  is a weight vector. Each element in  X  X  gives a weight to its corre-sponding feature in  X ( y ) . We use the unigram and the bigram features composed from word base form, POS and inflection described in Kudo et al. (2004). We also use additional lexical features such as character type, and trigram features used in Zhang and Clark (2008). To learn the weight vector, we adopt exact soft confidence-weighted learning (Wang et al., 2012).

To consider out-of-vocabulary (OOV) words that are not found in the dictionary, we automat-ically generate words at the lookup step by seg-training, we regard words that are not found in the dictionary but found in the training corpus as OOV words to learn their weights. 3.3 RNNLM Integrated Model Based on retrained RNNLM, we calculate an RNNLM score (score R ( y ) ) to be integrated into the base model. The RNNLM score is defined as the log probability of the next word given its con-text (path). Here, the score for an OOV word is given by the following formula: where C p is a constant penalty for OOV words, L p is a factor for the character length penalty, and length( n ) returns the character length of the next word n . This formula is defined to penalize longer words, which are likely to produce segmentation errors.

We then integrate the RNNLM score into the base model using the following equation: score I ( y ) = (1  X  ) score B ( y ) + score R ( y ) ; where is an interpolation parameter that is tuned on development data.

For decoding, we employ beam search as used in Zhang and Clark (2008). Since the possi-ble context (paths in the word lattice) consid-ered in RNNLM falls into combinatorial explosion in morphological analysis, we keep only prob-able context candidates inside the beam. That is, each node keeps candidates inside the beam width. Each candidate has a vector represent-ing context, and two words of history. The re-current model makes decoding harder than non-recurrent neural network language models. How-ever, we use RNNLM because the model outper-forms other NNLMs (Mikolov, 2012) and the re-sult suggests that the model is more likely to cap-ture semantic plausibility. Since a sentence rarely contains ambiguous and semantically appropriate word sequences, we think that beam search with enough beam size is able to keep the ambiguous candidates of word sequences. In the case of non-recurrent NNLMs and the base model, which uses trigram features, we can conduct exact decoding using the second-order Viterbi algorithm (Thede and Harper, 1999). 4.1 Experimental Settings In our experiments, we used the Kyoto University Text Corpus (Kawahara et al., 2002) and Kyoto University Web Document Leads Corpus (Hangyo et al., 2012) as manually tagged corpora. We ran-domly chose 2,000 sentences from each corpus for test data, and 500 sentences for development data. We used the remaining part of the corpora as training data to train our base model and retrain RNNLM. In total, we used 45,000 sentences for training.

For comparative purposes, we used the follow-ing four baselines: the Japanese morphological an-alyzer JUMAN, the supervised morphological an-alyzer MeCab, the base model, and a model using a conventional language model. For this language model, we built a trigram language model with Kneser-Ney smoothing using SRILM (Stolcke, 2002) from the same automatically segmented cor-pus. The language model is modified to have an interpolation parameter and length penalty for OOV, L p .

We set the beam width to 5 by preliminary ex-periments. We also set a constant penalty for OOV words ( C p ) as 5, which is the default value in the implementation of Mikolov et al. (2011). We tuned the parameters of our proposed model and the baseline model ( and L p ) and the parameters of language models using grid search on the de-velopment data. We set = 0.3, L p =1.5 for the proposed model ( X  Base + RNNLM retrain  X ). 3
We measured the performance of the baseline models and the proposed model by F-value of word segmentation and F-value of joint evaluation of word segmentation and POS tagging. We calcu-lated F-value for the two corpora (news and web) and the merged corpus (all).

We used the bootstrapping method (Zhang et al., 2004) to test statistical significance between proposed models and other models. Suppose we have a test set T that includes N sentences. The method repeatedly creates M new test sets by re-sampling N sentences with replacement from T . We calculate the F-value of each model on M + 1 test sets including T , and then we have M + 1 score differences. From the scores, we calculate the 95% confidence interval. If the interval does not overlap with zero, the two models are consid-ered as statistically significantly different. In our evaluation, M is set to 2,000. 4.2 Results and Discussions Table 1 lists the results of our proposed model and the baseline models. Our proposed model ( X  X ase + RNNLM retrain  X ) significantly outperforms all the baseline models and  X  X ase + RNNLM, X  which does not use retraining. In particular, we achieved a large improvement for segmentation. This can be attributed to the use of RNNLM that was learned based on lemmatized word sequence without POS tags.  X  X ase + SRILM X  segmented the example de-scribed in Section 1 ( X   X  X  X  X  X  X  X  X  X   X ) into the incorrect segmentation  X   X  X  X  /  X  X  X  /  X  X  X   X  in the same way as JUMAN. This segmentation error was caused by errors in the automatically seg-mented corpus that was used to train the language model. Our proposed model can correctly seg-ment this example if a proper context is available by semantically capturing word transitions using RNNLM.

The base model, JUMAN and  X  X ase + SRILM X  incorrectly segmented  X   X  X  X  (healthy)/  X  X  (etc.)/ from that of all other models.  X  (of)/  X  (point)/  X  (in)/ ......  X  (in terms of health and so on) into  X   X  X  X   X  (healthy)/  X  X  X  (any)/  X  (point)/  X  (in)/ ...... . X  Although this segmentation can be grammatically accepted, it is difficult to semantically interpret this word sequence. Our proposed model can correctly segment this exam-ple because RNNLM learns semantically plausible word sequences. In this paper, we proposed a new model for morphological analysis that is integrated with RNNLM. We trained RNNLM on an automati-cally segmented corpus and tuned on a manually tagged corpus. The proposed model was able to significantly reduce errors in the base model by capturing semantic plausibility of word sequences using RNNLM. In the future, we will design fea-tures derived from RNNLM models, and integrate them into a unified learning framework. We also intend to apply our method to unsegmented lan-guages other than Japanese, such as Chinese and Thai.

