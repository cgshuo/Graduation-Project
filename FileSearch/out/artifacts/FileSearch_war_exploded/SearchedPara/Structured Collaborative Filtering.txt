 In a general collaborative filtering (CF) setting, a user pro-file contains a set of previously rated items and is used to represent the user X  X  interest. Unfortunately, most CF ap-proaches ignore the underlying structure of user profiles. In this paper, we argue that a certain class of interest is best represented jointly by several items, drawing an analogy to  X  X hrases X  in text retrieval, which are not equivalent to the separate meaning of their words. At an alternative stance, we also consider the situation where, analogously to word synonyms, two items might be substitutable when represent-ing a class of interest. We propose an approach integrating these two notions as opposing poles on a continuum spec-trum. Upon this, we model the underlying structure in user profiles, drawing an analogy with text retrieval. The ap-proach gives rise to a novel structured Vector Space Model for CF. We show that item-based CF approaches are a spe-cial case of the proposed method.
 H.3.3 [ Information Search and Retrieval ]: Information filtering Algorithm, Performance, Experimentation Recommender systems, Collaborative filtering, synonymy
Most Collaborative Filtering (CF) algorithms disregard the fact that the rating data shows some structure. For example, in an item-based approach, the candidate item X  X  preference is commonly predicted by independently evalu-ating its similarity to each individual items in the profiles and then averaging them together to obtain the final score. However, the items in the system may have explicit relations among them, such as sharing the director (for movies), or belonging to the same genre (movies, music, books). Dealing properly with this structure is a challenge for the commu-nity. Most of the works assume some kind of clustering is performed on the users or the items, and then, predictions are performed using only these subsets of the collection [4, 1]. Obviously, this would increase the sparsity of the sys-tem, which turns out to be a serious problem for real-world systems. On the other hand, some works propose to use clustering for avoiding the sparsity, although it is not clear how the structure is kept in this situation [8].

Recently, different papers have explicitly linked CF al-gorithms with Information Retrieval (IR) techniques, and apply them successfully for recommendation. In [7], the authors find an analogy between implicit CF and IR, ap-plying the Probability Ranking Principle from IR to CF. More recently, [2] proposes a framework in which any IR scoring function could be used with CF rating data. In [3], the authors reformulate the recommendation problem and use algorithms from IR, namely a model based on Discrete Fourier Transform and the Vector Space Model (VSM).
In the proposed approach, we adapt, upon the already found analogies between IR and CF, the extended Boolean retrieval model presented in [6]. In that work, the authors introduce a generic model in which intermediate systems between Boolean and VSM models appears naturally. In particular, they acknowledge that the query structure should be altered in order to distinguish between compulsory terms (phrases) and alternative words (synonynms), whereas the Boolean strategy requires a very strict interpretation of such structure, the VSM model completely loses this distinction and the terms are considered independent of each other.
The proposed approach defines a method for providing structure to user profiles in CF. The extended model is applied to two particular tasks: a) user profile expansion which consists of propagating user ratings to other similar (or synonym) items; and b) user profile decomposition into area-specific subprofiles, as an enhanced structure enabling recommendation performance improvements. We report em-pirical results confirming that structured user profiles in CF outperform the standard item-based approach, which is a particular case of our model with plain profiles and no syn-onymy expansion.
The main idea of this work is inspired by the Salton X  X  clas-sic paper [6]. The novelty here lies in the use of the analogy between IR and CF proposed in [2] to address the structure problem in CF. In the next subsections, we propose how structure could be added to CF, by adapting the methods proposed in [2] so that more advanced models such as [6] could be used.
As already proposed in [2], we can obtain a new insight into the current CF approaches by reformulating them using a Vector Space Model [5]. Formally, a user profile can be Table 1:  X  X ND X  and  X  X R X  representations of a user interest regarded as a query. Each of the rated items in the profile is considered as a query term. Therefore, we could use a vector to represent a user profile as follows: where Q u denotes a user profile u . r u i k represents the rating of item k by this user, where k  X  X  1 ,n } . It is equal to 0 when item k is not rated by u . In practice, the ratings are normalized with respect to the users X  mean or items X  mean.
By contrast, the item representation is different to the text retrieval. In CF, we do not have a common feature space. Thus, we should project each item into the same feature space as queries by using its similar items. That is where s i k is the similarity between the candidate item j item k , using, for instance, the Pearson X  X  similarity.
Given the vector representations of Eq. (1) and Eq. (2), a query-item similarity value may be obtained by comparing the corresponding vectors, using for example the conven-tional vector product: The system could provide a ranked recommendation output in decreasing order of the computed similarities between Q and I j . In practice, it is also needed to predict the user X  X  rating of an unspecified item. The similarity score should be normalized to produce a rating in the proper range: indeed an item-based CF approach, but rather in a vector space formulation.
As we discussed previously, the user profile represented by independently rated items is problematic. We shall illustrate it by considering the following Boolean retrieval example. Suppose we have a class of user interest, and it is represented jointly by two items a and b . In a Boolean retrieval model, we would use an  X  X ND X  rule, meaning that a candidate item should be similar to both of them. By contrast, if a class of user interest is represented by either of two items, an  X  X R X  rule may be applied. Table 1(a) illustrates the results from the Boolean Retrieval model for the four different types of items. Note that for simplicity, the binary similarity is assumed.

From the table, we can see that the Boolean retrieval is too rigid in terms of producing the ranking score, either too loose or tight. And in practice, the interest representation is between  X  X ND X  and  X  X R X . An extension of the Boolean model was given in [6]. The idea was to apply a more dis-criminative ranking formula by calculating the distance to-wards the most desired point in the vector space. Let us define how we represent the query and documents in the ex-tended model by using a regular expression, where n is the number of terms in the collection: In this definition, a clause query is a combination of simple queries (as in VSM, where qw i is the weight given for that query to the term t i ) by means of connectives and clause weights ( cw ). Besides, each connective has an associated value, in this case, we denote p 2 as the inner value and the outer one. Documents are simply represented as in the standard VSM, where dw( i, j ) is the weight between doc-ument D i and term t j . Using this notation, the similarity between a query and a document can be computed recur-sively until a simple query is found, by using cw to weight the importance of the similarity between the subqueries and the document (more details in [6]). Depending on the con-nective, similarity between a document and a simple query is calculated as follows: where p  X  [1 , +  X  ) is the corresponding connective p -value. Note that when p =1wehave sim ( Q or , D i )= sim ( Q and
In this way, depending on the value of p we can gener-alize different retrieval systems. For instance, when p = (assuming binary weights) a standard Boolean scoring is per-formed, for p = 1 a VSM is obtained, and the rest of the values produce intermediate extended retrieval models.
Furthermore, as stated in [6], each p -value has a seman-tic interpretation in IR, depending on the connectives used. With p =  X  and the X  X ND X  X onnective, then a strict phrase has to be matched, i.e., the document is not retrievable un-less all phrase components are present. If, on the other hand, the connective is an  X  X R X , then a strict thesaurus feature is used, i.e., all the connected terms are substitutable for one another. When the p -value is lower, these constraints are less strict, in the sense that, for the  X  X ND X  connective, the presence of every term is worth more than the presence of only some of them, but they are not compulsory; simi-larly, for the  X  X R X  connective, the presence of several terms from a given class is more important than the presence of only one term. Finally, when p = 1 both connectives are equivalent and the distinction between phrase and thesaurus disappears, thus only the presence or absence of the terms is considered, i.e., the terms are independent of each other.
We have seen in the previous section that documents need no further modification. Thus, in the context of CF, this means that only the user profile (query) has to be expressed as a set of clause queries by using different connectives, and the items (documents) may be represented as in Section 2.1. Since the equivalence presented in that section corresponds with a VSM in IR, the representation of the constituent elements in the extended model is simply as follows, where n now is the number of items in the system: In this situation, the query is defined as an  X  X ND X  rule with p = 1. As we have already noted, for this value of p ,the similarity formula of an  X  X ND X  rule is equivalent to that of an  X  X R X  rule, so we can define the queries with or(1) instead of and(1). Besides, we have to note that Eq. (4) is not completely equivalent with the formulation presented herein, since standard item-based CF normalizes with respect to the similarity values, which are encoded in the document vector, while in IR the model is normalized using the query weights. Both representations, nonetheless, could be equivalent with a slight modification of the extended model.
Once an extended user profile representation is available for recommendation by adapting the extended retrieval model, we envision two main applications. First, performing ex-pansions over the user profiles, in a similar way as IR re-searchers include synonyms and related words when expand-ing queries. Second, providing structure to the profiles based on implicit similarities found between the items in the sys-tem. In the following, we explain how these two applications may be performed in CF.
In any recommendation system, there are some items which tend to occur very frequently together, such as movie series (e.g., Lord of the Ring, Star Wars, or Star Trek), or movies by some particular director. These movies could be consid-ered close synonyms , in the sense that people tend to like them all or none of them. If this assumption holds, once one item belonging to a particular group is rated in a pro-file, the rating could be propagated to the rest of synonyms in the system, by using an  X  X R X . In this way, the rating sparsity would be reduced, since each user would contain in her profile additional items, implicitly derived through the synonym relation.

A very important parameter in this setting would be the expansion size, that is, how many synonyms are incorpo-rated into the user profile. As a first attempt, we can ex-pand all the user profiles in the same way. However, as in query expansion, it seems clear that some users could benefit more from the expansion than others. Query per-formance techniques, which have been frequently applied to query expansion, can be very useful in order to determine the strength of the expansion on a per-user basis. Another important parameter is the p -value, which, for instance, could be set based on the co-occurrence strength between each pair of items, or any function which manipulates those co-occurrences, such as normalization by the average, mini-mum, or maximum value.
It often makes sense to find subprofiles within user pro-files. This is a very recurrent idea in recommender systems, with different motivations, such as when two users A and B have very similar movie tastes, but very different in mu-sic. Their music dissimilarity should not obscure their movie similarity, so that A and B can get area-specific recommen-dations from each other based on their area-specific common tastes. Preference clusters can be created automatically and used in many ways (see [4, 8] among others).

In this view, user profile vectors could be decomposed into a soft  X  X R X  of cohesive subprofiles or phrases (music tastes, movie tastes, sports, etc.), where subprofiles are also soft  X  X R X  X  of item ratings, and the outer  X  X R X  should have a higher p than the inner  X  X R X . Different options arise when defining this structure with respect to how the clusters are defined and how to set the inner and outer p values.
Clusters within a user profile can be created using prede-fined clusters over the item space, and these clusters can be found using classic clustering algorithms (such as K-means) or any other alternative strategy. Pearson correlation can be used as distance between items, and external features such as genre or actor information apart from ratings may be taken as input data.

Inner p -values can be set in many different ways: they can be fixed or depend on the average (or minimum, maximum) similarity in the cluster or its centroid, using an additional step function discretizing those values, in such a way that the higher the cohesion in the cluster, the higher the inner value. The outer p -value can have a fixed, low value since we want to retrieve documents matching any of the subprofiles, however if we want to boost those documents matching more than one subprofile, a higher p -value should be used instead. Actually, the outer  X  X R X  rule may be replaced by an  X  X ND X  rule in order to check if documents matching every subprofile are more likely to be relevant to the user or not.
The experiments have been carried out using the pub-licly available dataset called Movielens 100K 1 . This dataset contains 943 users, 1682 items and 100000 ratings. We per-formed a 5-fold cross validation using the splits contained in the public package, these splits retain the 80% of the data for training, and the rest for testing.

The evaluation was performed as explained in [2], that is, for each user, a ranking is generated by predicting a score for every item in the test set. We then measure the performance of this ranking, using the trec eval program.

Now, we present the results obtained in the two tasks where the extended retrieval model has been applied: ex-panding the user profiles and inferring profile structure.
In this experiment, we analyze the recommendation per-formance variations that result from introducing different amounts of profile expansion, compared to a plain item-based recommender baseline without expansion ( S =0). Besides, as noted in Section 2.4.1, we consider the expanded items as synonyms, and thus, we include an infinity inner p -value, in order to have the standard Boolean behaviour for the  X  X R X  connective. As shown in Table 2(a), we may observe a significant improvement when user profiles are ex-panded with similar items, and the more synonyms are used in the expansion, the better the performance. It is worth noting that changing the order of the connectives (bottom row) leads to poor results, showing that profiles built this way make little sense.

The baseline in the table is the method presented in Sec-tion 2.1, which corresponds to the standard item-based CF approach. We can see that properly using the extended model leads to outperforming the baseline formulation. In contrast with [2], we have not yet experimented with differ-ent normalization techniques, in order to keep the extended model as close to the original as possible. The results sug-gest, nonetheless, that a combination of both methods might result in higher, more significant performance improvements, since they may be used complementarily: while our method expands the profiles, the method described in [2] explores different techniques inspired by IR scoring functions.
Available at http://www.grouplens.org/node/73
In Table 2(b), we present further experiments with a dy-namic profile expansion strategy. In this experiment, the parameter S is not fixed for all the users in the system, but depends on each user X  X  characteristics. In particular, and as a first attempt, we assume that the size of the user profile might be an indicator of the demand for more or less items in the expanded model  X  X n the same way as the query length may be used in IR for deciding whether or not to ex-pand the query. In this context, we only expand those users which are below some threshold. In the table, we show the results when the threshold is the average or the median of the number of ratings in the system. These two methods obtain very similar results, and compared with the previous methods, they outperform static expansion when the cutoff value is high, e.g., P@10 and NDCG@50.
In order to compare whether structured profiles improve the performance, we compare against the baseline method presented in Section 2.1, which simply uses plain profiles (no structure). Furthermore, to provide structure to the item profiles, two clustering algorithms were used: K-means and X-means (as implemented by Weka library 2 ). These al-gorithms have been trained on different data related with items, more specifically, on genre information and similar-ity values among items. Different values for the number of clusters with K-means were tried, and an optimal K =50 was found and used in our experiments.

Table 2(c) shows the results of this experiment. We have tried a uniform p for all the subprofiles, which corresponds to the clusters found by the clustering algorithm. In the future, a different p depending on the intracluster similarity might be considered. Results with the X-means algorithm are not reported here because it always performed worse than K-means. As we can see in this table, structured pro-files obtain better performance than plain profiles. Besides, we have found no significant differences when changing the inner p -value, since or(2) and or(5) gave the same result. Furthermore, clustering genre information about items pro-vides better results than clusters generated using similarity between items. This may be due to the relatively higher amount of noise when using item similarity, in comparison to explicit external information such as item genres.
Available at http://www.cs.waikato.ac.nz/  X ml/weka/
We have presented a method for incorporating structure into the user profiles of CF algorithms. Upon the work de-scribed in [2], we apply an extended retrieval model which allows for incorporating such structure. We report two ap-plications for this approach: user profile expansion and in-ference of profile structure. Empirical results show that our methods introduce significant performance improvements over an item-based CF baseline, which can be simply represented in our framework as a method where the items are consid-ered independent from each other. Therefore, taking into account the structure of the user profiles seems to lead to better performing CF algorithms, while it opens up new pos-sibilities and applications.

As future work, we plan to investigate a formal way for calculating automatically the p -values, instead of the fixed values used so far. This would provide insights about the real meaning in CF of the IR concepts of synonymy and phrase. More generally, the proposed model may provide a flexible ground for the exploration of further potential applications.
This work was supported by the Spanish Ministry of Sci-ence and Innovation (TIN2008-06566-C04-02), University Aut  X  onoma de Madrid and the Community of Madrid (CCG10--UAM/TIC-5877).
