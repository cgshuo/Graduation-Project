 1. Introduction
The explosive growth of the Web has drastically changed the way in which information is managed and accessed. The large-scale of Web data 1 sources and the wide availability of services over the Internet have increased the need for effective Web data management techniques and mechanisms. Understanding how users navigate over Web sources is essential both for computing practitioners (e.g. Web sites developers) and
Frasconi, &amp; Smyth, 2003; Banerjee &amp; Ghosh, 2001; Cadez, Heckerman, Meek, Smyth, &amp; White, 2003; Chak-
Chen, 2001 ) for increasing Web information accessibility, understanding users X  navigation behavior, improv-ing information retrieval and content delivery on the Web.
The aim of clustering is to organize information circulated over the Web into groups/collections (of similar
Web-based applications such as e-commerce (to adapt Web sites and to recommend new products to customers X  based information retrieval (to improve real-time and dynamic data accessing ( Baldi et al., 2003 )).
Considering that there are several users X  navigation patterns within groups (each group consists of a huge Therefore, it is typical to use mechanisms which explore these groups and extract useful conclusions ( Cadez, Heckerman, Meek, Smyth, &amp; White, 2003; Fraley &amp; Raftery, 1998 ).

The goal of this paper is to show that certain statistical techniques, developed for statistical inference of can be further used to validate and interpret the obtained clusters in order to reveal and explain associations among users X  navigation patterns.

The main idea is to improve the access to searching and personalization cations take advantages of clustering Web users X  navigation patterns, where each navigation pattern reflects the interaction between the users and the Web.

Pallis et al., 2005 ). The proposed methodology is applied on Web users X  navigation patterns by a model-based approach employing:
Cluster validation , i.e. evaluation of the results of a clustering algorithm in a quantitative and objective manner. We propose a quantitative validation procedure, which is based on the statistical chi-square ( v 2 ) test. Each cluster is represented by a probability distribution and the chi-square metric is used to mea-sure the distances between these distributions and to test their homogeneity. Since the goal of a clustering procedure is to discover groups in the data so that each group is significantly different from all the others, we essentially test the heterogeneity between the clusters in order to assess their successful discrimination.
Cluster interpretation , i.e. understanding and appropriately interpreting the meaning of the derived clusters in the wider context of the underlying application, by using statistical data analysis. Specifically, we propose a visualization approach as a result of the statistical method known as correspondence analysis, for inter-preting the clustering results. This analysis is used to facilitate revealing of similar or related features in Web users X  navigation behavior and their interaction with the content of Web information sources.
The cluster validation and interpretation method were tested on two real data sets, one from a rather pop-ular and active Web server (msn.com) and one from a typical and low-traffic Web server (Department of
Informatics in Aristotle University). Experimental results are encouraging and indicate that the proposed sta-tistical analysis can be used to enhance the existing practices for cluster validation and interpretation. the paper X  X  contribution. Section 3 describes the clustering procedure that is used to group the users X  patterns.
Section 4 presents the statistical validation technique for model-based clustering approaches. Section 5 presents a visualization method for cluster analysis interpretation. Section 6 provides the experimental results and the application scenarios that could be benefited from the proposed work. Finally Section 7 has the conclusions. 2. Related work and paper X  X  contribution
Earlier research efforts, have mainly been devoted to proposing clustering algorithms and validating clus-ters, whereas, clustering interpretation has also been considered towards web usage understanding and char-acterization. A brief related work is highlighted in this section. 2.1. Clustering algorithms
Existing clustering algorithms for assigning Web users X  navigation patterns with common characteristics (also summarized in Table 1 ):
Similarity-based approach which uses a distance function (similarity measure) to judge whether two patterns should be clustered together. Hierarchical and partitional algorithms have been mostly used under this approach.

Model-based approach which relies on the assumption that objects follow a finite mixture of probability dis-tributions such that each distribution indicates a cluster (each cluster has a data-generating model with its own parameters). In model-based approaches it is critical to learn the parameters for each cluster so that to assign objects to clusters by using a hard assignment policy
Chi-square is commonly used for testing similarities among two different distributions. Moreover, in recent and to classify rows or columns of a contingency table ( Govaert &amp; Nadif, in press ). Another recent approach decide whether a sub-clustering approach should be followed. 2.2. Validation of web users X  sessions clusters
A main challenge with the above clustering algorithms is the difficulty in interpreting and in assessing the
Liu, 2003; Halkidi, Batistakis, &amp; Vazirgiannis, 2001; Pallis et al., 2004 ). Therefore, a clustering approach becomes more valuable if it is further evaluated and validated. For instance, the challenge of a Web person-explicitly. Clustering evaluation may be employed under three different views:
External view : when results of a clustering method are evaluated on the basis of a pre-specified structure on a data set, which reflects a user X  X  intuition about the clustering structure of this data set. Internal view : clustering results are evaluated in terms of quantities obtained from the data set itself.
Relative view : clustering result is compared with other clustering schemes, by modifying only the parameter values.

Cluster validity approaches based on external and internal criteria rely on statistical hypothesis testing, where the basic idea is to examine whether the points of a data set are randomly structured or not. Such an analysis typically involves a Null Hypothesis (Ho) expressed as a statement of random structure of a data ( Morey &amp; Agresti, 1984 ) and Cophenetic Correlation Coefficient (CPCC). These statistics are summarized in ( Halkidi et al., 2001 ).

The basic characteristic of the approaches based on internal or external criteria is their high computational demands. On the other hand, the relative approach does not involve statistical tests but evaluates several results originating from different parameter settings and challenge is to choose the best clustering scheme from a set of defined schemes. This choice is commonly done according to a pre-specified criterion, the so-called ces have been proposed already where the most indicative are: the Davies X  X ouldin index (DB) ( Gunter &amp;
Bunke, 2003 ), the Frobenius norm ( Huang, Ng, &amp; Cheung, 2001a ), and the other indices overviewed in ( Halk-idi et al., 2001 ).

Most of the earlier approaches (e.g. ( Gunter &amp; Bunke, 2003; Halkidi et al., 2001; Huang et al., 2001a )) for cluster validation are based on the similarity-based clustering approaches, whereas the model-based approaches have gained ground in the Web community since they can efficiently represent the dynamic  X  X  X at-et al., 2003; Pallis et al., 2005 ). Such model-based approaches capture the users X  navigation behavior quite well, by the use of a Markov model, to capture the uncertainties occurring on the Web, which are due to the various large-scale, distributed, decentralized, self-organized, and evolving sources and users navigation patterns. However, further analysis and validation of the model-based clustering schemes is rarely given. 2.3. Interpretation of web users X  sessions clusters
Understanding clustering results is not a straightforward process, since different clustering schemes might result in diverse clusters which need further analysis and interpretation. Moreover, clusters role is perceived differently depending on the nature and orientation of the underlying application. This is explained by the fact that in some applications clustering is an initial exploration task (prior to classification which needs clusters i.e. fixed number of classes), whereas in other applications clustering is used to support a decision process (such as in the form of a rule set or a decision tree). Therefore, having an efficient interpretation method is important and often necessary. Several research works in various industrial and academic research communi-ties are focusing on interpreting clusters of users X  navigation patterns by:
Interpreting and analysing users X  navigation patterns of online stores (e.g. in ( Gomory, Hoch, Lee, Podla-seck, &amp; Schonberg, 1999 )), or predicting users X  commercial behaviors based on their navigation is proposed ( Montgomery et al., 2004 );
Visualizing users grouping ( Baldi et al., 2003 ) by using a mixture model to predict behavior of users, or to interactively visualize Web logs by providing a global view of visitor accesses;
Visualizing clustering of users X  navigation paths in real time by a developed a tool (called INSITE) for knowledge discovery from users Web site ( Shahabi, Faisal, Kashani, &amp; Faruque, 2000 ).

However, according to the authors X  knowledge, most of such approaches use empirical methods to interpret instance, several correlations between Web pages may not be observed by using simple visualization schemes.
Thus, deeper and more detailed observation is required towards understanding these correlations. 2.4. Paper X  X  contribution
Considering that, in model-based approaches, the clusters are represented by a probabilistic distribution,
According to the authors X  knowledge, no earlier work has emphasized on using chi-square measure in the pro-cess of validating Web users sessions.

The purpose of this paper is to present a combination of probabilistic and statistical methods providing a comprehensive analysis of Web user sessions clusters. The whole approach is presented in the form of a pro-cedure starting from the clustering of the sessions, continuing with the validation of the derived clusters and concluding with the interpretation of the clusters and the utilization of the conclusions for understanding and explaining users X  navigation behavior.

First, the users X  sessions extracted from a Web site are clustered by the well-known EM algorithm, which is a model-based approach able to capture the dynamic evolution of the Web. The optimal number of clusters is determined a priori by using a probabilistic model. Next, the resulted clusters are represented by probability distributions and they are validated using the chi-square test. Finally, the correspondence analysis is used to find relations between clusters and user preferences and therefore to interpret the navigational behavior. Certain applications for which this approach is expected to be beneficial are also highlighted in this paper.
The whole methodology can be described by the diagram in the form of a flowchart, given in Fig. 1 . 3. Web users X  sessions clustering
Clustering of Web sessions under a probabilistic-based approach, involves certain tasks which need to be followed in sequential order, namely session identification, number of clusters identification and clustering algorithm employment. 3.1. Web log files pre-processing and session identification Users on the Web visit a site and spend arbitrary amount of time at each page between consecutive visits.
Web log files provide information about activities performed by a user from the moment the user enters a Web site to the moment the same user leaves it and it typically contains the fields (depicted in Fig. 2 ): domain name (or IP address) of the request; name of the user who generated the request; date and time of the request; method of the request; name of the file requested; result of the request (success, failure, error, etc.); size of the data sent back; URL of the referring page; identification of the client agent; cookie, a string of data generated by an application and exchanged between the client and the server.
Given the Web log file, the goal is to use it as a basic information in order to capture the Web users X  nav-requests made by a single user over a certain navigation period and a user may have a single (or multiple) ses-sion(s) during a period of time . A session is a directed list of page accesses performed by an individual user during a visit in a Web site. Several approaches for identifying users X  sessions from the Web log files ( Baner-ature. The most popular session identification methods include:
Using a timeout threshold , in which a user poses a sequence of consecutive requests which are separated by an interval less than a predefined threshold. This session identification suffers from the difficulty to set the time threshold, since different users may have different navigation behaviors, and their time intervals between sessions may significantly vary. In order to define an indicative value for the time threshold, earlier research efforts proposed a time threshold of 25.5 min based on empirical data ( Catledge &amp; Pitkow, 1995 ), whereas in ( Goker &amp; He, 2000 ) used a wide range of values and concluded that a time range of 10 X 15 min was an optimal session interval threshold. In general, the optimal time threshold clearly depends on the spe-cific context and application. Up to now, the most common choice is to use 30 min as a default time threshold.
 imal forward reference. Each session is defined as the set of documents visited originating from the first document in a request sequence to the final document before a backward reference is made. Here, a back-ward reference is defined to be a document that has already occurred in the current session. One advantage of the maximal forward reference method is that it does not have any tuneable parameters (e.g., time threshold). However, it has the significant drawback that backward references may not be recorded by the server if caching is enabled at the client site.

Dynamically identifying sessions X  boundaries ( Huang, Peng, An, &amp; Schuurmans, 2004 ), based on a statistical n-gram language modelling, to predict the probability of requests X  sequences. A session boundary is iden-tified by measuring the change in information (entropy) in the sequence of requests, i.e. when a new object is observed in the sequence, an increase in the entropy of the sequence occurs. Therefore, such an entropy increase serves as an indication for session boundary detection and if the change in entropy is over a specific threshold, then a session boundary is placed before the new object.

In this paper, we use the timeout threshold in order to define the users X  sessions and Web log file is auto-records per day are logged in a common Web server). Typically, each Web user can be uniquely identified, by his IP-address, which acts as a unique identifier and at the same time, each of the requested pages has a dif-ferent unique page id. Then, the data are undergone a certain pre-processing in order to identify Web user sessions. The following steps take place to extract the Web users X  sessions from a Web log file:
Data cleaning : We remove all the records which do not include useful information for the users X  navigation behavior (such as graphics, javascripts, small pictures of buttons, advertisements etc.) as well as the non-static information (cgi scripts,  X  X ? X  X  etc.).

Data transformation : The remaining page ids are categorized into different categories with respect to their content (e.g. a category may be all the pages which refer to the weather in a news site). It should be noticed that the process of grouping the Web pages into categories is a usual practice ( Cadez et al., 2003 ), since it improves the data management and in addition eliminates the complexity of the underlying problem (since the number of page categories is smaller than the number of Web pages in a Web site). In this paper, the individual pages are grouped into semantically similar groups (as determined by the Web site ad-ministrator).

Time window identification : We retain the ordering in the page requests and we assume that a time difference of 30 min between two requests of the same user indicates different sessions, we end up with several sessions of the following form: s ij =5312643886441, where s ij is the session j for user i , where its elements are the Web page categories.

Considering the above pre-processing of Web data, the session identification process can be formulated as follows (the variables notations are summarized in Table 2 ): Let R user access records in the log (sorted by the ascending order of the access frequency), and t the time when r ij was logged in the Web log file. Let A ={ A total number of categories. We assume that each r ij is represented by one of these categories and the user i generates L i sessions (possibly unequal length ordered sequences of pages). Assuming that W is the total number of users in the Web log file, let D  X f R 1 ; ... ; R the log.

Definition 1 ( Web user session ). The sessions for an individual user i are defined as a list of subsets where t r
S ={ S 1 , ... , S W } represents the sessions for all the users in our data set. 3.2. Determining the number of clusters
The proposed clustering approach assumes that the number of clusters is known at priori and as commonly employed in model-based schemes, the number of clusters might be determined by using several probabilistic values and methods, such as Bayesian Information Criterion (BIC), Bayesian approximations, or bootstrap methods ( Fraley &amp; Raftery, 1998 ). The present evaluation of the optimal number of clusters for our model is inspired from ( Cadez et al., 2003 ) where a Bayesian approximation is used.

Formally, we assume that there are K clusters, denoted by C its own probability distribution. Once the model is specified, we use the EM algorithm and the probabilistic out-of-sample log likelihood evaluation to determine the best number of clusters. A model is fitted on a sub-sample of sessions (the so-called training data set) and then scored on the remaining data (the so-called testing data set). Thus, we get an objective measure of how well each model fits with the data. In order to determine the number of clusters, we choose the model with the minimum out-of-sample predictive log score for many values of K , i.e. we select that value for K , which minimizes the following equation: length of session s ij . 3.3. The clustering approach
Since the Web users X  sessions have been identified, we cluster them by using a model-based clustering approach, the EM algorithm. Each resulted cluster contains a set of Web users X  sessions generated by a prob-abilistic distribution. Each distribution is determined by a set of parameters which are different for each clus- X  X  X rgodic X  X , we mean a Markov chain that has the following two properties: (1) Each node can reach any other node (all states intercommunicate), (2) the chain is not periodic (all states have period one). Such properties hold in the context of defining Web users X  navigation behavior, since a Web user may navigate to every page, independently on which page had been previously visited and as proved in ( Baldi et al., 2003 ) is periodic. In our framework, the parameters of each first-order Markov chain correspond to an individual transition matrix (which contains the transition probabilities among the states) and a vector (which represents the initial state probabilities). Thus, using a Markov chain model, we model the probability that the user will go to a certain page category given that he/she is viewing the current page category. Therefore, we have a transition matrix of user will begin a navigation session in a given page category. The following matrix P shows the structure of such a transition matrix where the probability for a user to navigate from page category A is denoted by P ij .

Definition 2 [Sessions Cluster]. The sessions are assigned to one of the underlying clusters by using the hard assignment policy . More specifically, a session s ij belongs to cluster C p  X  x  X  s ij j h k  X  X  max f p  X  x  X  s ij j h 1  X  ; ... ; p  X  x  X  s
C .

From the above definition, it occurs that if the values of h into clusters. However, these values are hidden. In order to learn the set of parameters h Expectation-Maximization (EM) algorithm is used. The EM algorithm originates from ( Dempster, Laird, &amp;
Rubin, 1977 ) while in ( Cadez et al., 2003 ) a method for employing EM on users X  sessions is proposed. The EM algorithm searches for a maximum likelihood hypothesis by repeatedly re-estimating the expected values of the hidden variables h k given a current hypothesis. Specifically, the following steps are repeated:
The expectation E-step : Given a set of parameter estimates, the E-step calculates the conditional expectation of the complete-data log likelihood given the observed data and the parameter estimates.

The maximization M-step : Given a complete-data log likelihood, the M-step finds the parameter estimates to maximize the complete-data log likelihood from the E-step.

The two steps are iterated until convergence, based on the core idea of the EM approach that the current hypothesis is used to estimate the unobserved variables, and the expected values of these variables are then used to calculate an improved hypothesis.

In terms of the complexity of the EM algorithm, it depends on the complexity of the E and M steps at each iteration ( Dempster et al., 1977 ). For example, in our case (Markov mixtures) the complexity is linear in the sum of the lengths of all sessions, whereas in more complex mixture models the complexity can be higher. 4. Validating web users X  sessions clusters In this section we present a novel validation method, which evaluates the model-based clustering schemes.
The approach belongs to the internal type since the clustering result is evaluated in terms of quantities obtained from the data set itself.

The first stage of the procedure takes as input the resulted clusters, where each one consists of users X  ses-sions. As we have already mentioned, the objects of each cluster are assumed to follow a first-order Markov ergodic model 4 . The main idea is to consider the equilibrium distribution of the transition matrices for each the most popular Web pages.

Theorem 1. If P is the V  X  V transition matrix of a homogeneous ergodic Markov chain, then there is a unique vector f =(f 1 , ... ,f V ), such that
Proof. A thorough study and classification of finite Markov chains and the proof of this theorem is given in ( Cox &amp; Miller, 1997 ).

This theorem offers us a way of approximately evaluating the access frequencies of the nodes (visited categories in our case), by simply calculating powers of the transition matrix. It gives us a way to evaluate the relative frequency of accessing (retrieving) nodes 1, ... , V respectively in a long run, based on the transition called the equilibrium or stationary distribution of the Markov chain since any element represents the limiting probability of accessing the respective nodes 1, ... , V after infinite number of steps.

The next step involves the representation of each cluster by its corresponding equilibrium distribution and the clustering validation, performed by testing the homogeneity of the cluster equilibrium distributions using the v 2 test.

In general the v 2 test is used for testing the independence of two categorical variables or alternatively the distribution homogeneity in the categories of one variable with respect to the other ( Snedecor &amp; Cochran, 1989 ). The v 2 is a statistic, i.e. a quantity computed from observations, which is used to measure the dissimilarity among probability distributions. Considering therefore that each cluster can be represented by a probabilistic distribution (the equilibrium distribution), we can directly apply this homogeneity test. So in our case, we essentially consider two variables: one having as values the K derived clusters and the other having as values the V page categories. These variables are cross-tabulated in a contingency table , i.e. a table summarizing the relation between clusters and page categories. The general form of such a cross-tabulation is given in Table 3 . The contingency table is next used for the computation of the v test of homogeneity.

In order to describe in detail the procedure, we assume that the clustering algorithm results in K clusters denoted by C 1 , ... , C K . The V different page categories, denoted by A according to its equilibrium probability distribution denoted by f in the cells of the contingency table ( Table 3 ) is computed by multiplying the equilibrium probability f
A page category with the number of sessions that belong to cluster C
Having formed the contingency table, our aim now is to test the homogeneity of the clusters with respect to the distribution of the page categories in each of them. If the test shows significant heterogeneity, this can be attributed to the ability of the clustering algorithm to produce distinguishable groups. Moreover, this heterogeneity can be further analyzed in order to reveal and interpret the characteristics of the users X  behavior in each cluster. On the other hand, if the test shows that the clusters are homogeneous (i.e. the categories are distributed more or less similarly) we can infer that the clustering was not successful, and the clusters cannot be interpreted.

The v 2 statistic is computed from the contingency table by the following formula: where and it is used to test the null hypothesis that the distributions of the page categories in each cluster are not whether v 2 is really large, we need to know a critical value for the boundary of the area of hypothesis X  X  rejec-rejecting the null hypothesis) and the degrees of freedom (df). From statistical theory we know that under the null hypothesis of homogeneity, the v 2 statistic has asymptotically a v the v 2 distribution corresponding to probability a , denoted by v 2 level of significance a . In such a case we can conclude that the clustering algorithm produced separable groups. 5. Interpreting users X  sessions clusters
From the validation procedure of the previous section we obtain a strong indication about the overall dis-similarity of the clusters, using the v 2 statistic. However, some clusters may be closer than others while some categories may be highly associated with certain clusters. These relations cannot be investigated by the v and therefore a further analysis of clusters is essential in order to reveal and interpret certain associations.
Interpreting the navigation behaviors exhibited by the Web users X  sessions in each cluster is important for a number of tasks, such as providing of valuable insight about users X  preferences, designing of a Web site, iden-tifying malicious visitors and managing targeted advertising. It also helps in understanding the sessions of dif-ferent users X  groups and, therefore, in organizing the Web site to better suit the users X  needs. Furthermore, interpreting the results of clusters contributes in identifying and providing customized services and recommen-dations to Web users by exploring relations between the categories. However, the interpretation of clusters is a difficult and time-consuming process due to large-scale data sets and its complexity. To address this interpre-tation problem the research community has focused on visualization approaches ( Baldi et al., 2003 ). Cluster-ing visualization can help the Web administrators to visually perceive the clustered results, and sometimes oncover hidden patterns in data.

In this section, we introduce a novel clustering interpretation approach by analyzing the contingency table, which has been constructed for the validation process described in the previous section. The analysis uses the statistical methodology known as correspondence analysis method (CO-AN).

The main goal of CO-AN is to describe the relationships between two categorical variables in a contingency table. These relationships are described by projecting the values of the variables as points on a two-dimen-sional space, in such a way that the resulting plot describes simultaneously the relationships between the cat-egories of each variable. For each variable, the distances between points in the plot reflect the relationships between the categories. Similar categories are plotted close to each other while distant points show dissimilar-ity. The computation of the coordinates in the two-dimensional axis system are based on the v measure of distance. Mathematical details of CO-AN can be found in ( Johnson &amp; Wichern, 1998 ).
In our case we can apply the CO-AN method to the rows and columns of Table 3 in order to explore further the relationships between clusters and page categories. The obtained graphical representation provides a meaningful interpretation of clusters and therefore useful information regarding users X  navigation behaviors.
Consider for example the case where a Web developer wants to arrange the structure of a site such as to inter-link associated pages. This can be achieved by the proposed method which finds such associations.
At this point we have to emphasize that the validation and the interpretation procedures do not concern only a specific clustering result, i.e. the one obtained from the determination of the optimal number of clusters according to the BIC criterion and the subsequent application of the EM algorithm. If we determine another ing groups will be probably quite different. However, the suggested procedure should be applied to any group-ing so as to examine whether the groups are separable and interpretable. 6. Experimentation-results 6.1. The data sets
The methods described can be applied on usage data of any Web site. In this paper, they have been applied on two real data sets: the first data set (called msnbc data set) comes from an active popular commercial Web server (msn.com 5 ) which consists of a daily record of approximately 6000 users X  sessions, with an average of 5.7 page views per session. This data set includes visits which are recorded at the level of URL category and are recorded in time order and no pre-processing was required since data set was given in sessions. The second data set (called csd data set) comes from an educational Web server (the Department of Computer Science in
Aristotle University of Thessaloniki), which consists of approximately 3437 users X  sessions, with an average of the categories assigned to the total of 11,342 Web pages. Table 4 summarizes the details of these data sets.
Each event in the sequence-session corresponds to a user X  X  request for a page, which is recorded at the level of page category and not at the level of URL. In order to apply the methods discussed in the previous sections we have to use transition matrices to represent the navigation steps of the users from category to category.
Since it is important for the interpretation of the clustering to know the first and the last page categories, struction of the transition matrices to define only one auxiliary category (for example the  X  X  X uter-state X  X ) we choosed to work with two, such that in the interpretation phase we can investigate which page categories are associated with  X  X  X ntry X  X  and  X  X  X xit X  X  by plotting them separately with distinct points.

The categories of each data set are described in Tables 5 and 6 . Then, for each data set, we select the first determine the number of clusters. 6.2. Clustering and validating of users X  sessions
After preprocessing and setup of the datasets, we determine the number of clusters by finding the value that minimizes the out-of-sample predictive score, given in Eq. (1) . Figs. 3 and 4 show several out-of-sam-ple log-likelihoods for varying number of clusters. The x-axis represents the number of clusters, while the y-axis represents the out-of-sample log-likelihood. From these figures, it is evident that the out-of-sample log-likelihood is minimized when the number of clusters is 5 and 4 for the msnbc and the csd data set, respectively.
 by a probabilistic distribution (first-order Markov model). Using the EM algorithm we learn the parameters of each Markov model as well as the proportion of users X  sessions assigned to each cluster. Then, we assign each validate them by forming the corresponding contingency table and using the v tribution. mfloat Table 7Tables 8 and 9 present the contingency tables derived after the clustering of the two data sets. Since the frequencies in the cells are computed by Eq. (3) we give the tables with rounded entries.
As depicted in this table, for both data sets, the value of the v guishable clusters.
 6.3. Cluster analysis interpretation
After the validation procedure, the next step is to apply the CO-AN method to the contingency tables in order to visualize the clusters and the page categories.
To visualize the quality the of clustering algorithm, we depict the associations among the clusters for both data sets. As can be seen in Figs. 5 and 6 , each cluster is represented by a point. According to these plots, a general observation that can be taken for both data sets is that the resulted clusters are separable since there are no coincident points. It is worth mentioning that this observation is in accordance with the results of the v test that we have been obtained previously. An inside view of each cluster will be presented in Section 6.3.2 . 6.3.1. Visualizing the associations of web pages
The proposed clustering analysis can also be used to graphically display the usage relevance among Web page categories, since Web requests are recorded at the level of page category (in practice, categories are typ-ically determined by the Web site administrator). Figs. 7 and 8 illustrate the usage associations between Web page categories as resulted from the employed correspondence analysis for the msnbc and csd data sets, respec-tively. Each category is represented by a point, i.e. if some points are close to each other, this means that the
Web page categories (corresponding to these points), are associated with each other. Thus, observing these figures, we can extract useful information and understand Web users X  navigational behavior and trends. The following observations in Figs. 7 and 8 results will help in understanding the web usage trends:
Msnbc data set : From Fig. 7 , it is evident that the Web users who visit pages about  X  X  X ews X  X , most probably will visit, in the same navigation session, pages about  X  X  X n air X  X  (since categories 3 and 7 are closely asso-ciated). Similarly, pages about  X  X  X ulletin board service (bbs) X  X  are closely associated with pages about  X  X  X ravel X  X  (since categories 17 and 18 are closely associated). Furthermore, the users tend to exit from a Web navigation path, when they have previously visited Web pages about  X  X  X ech X  X ,  X  X  X ocal X  X  or  X  X  X ealth X  X , i.e. there is a trend to follow a particular navigation pathway prior exiting. This fact is probably an indication that these pages are not quite attractive and the users abandon the Web site. Another remark is that when users visit pages either about  X  X  X rontpage X  X  or about  X  X  X ummary X  X , they do not visit pages about  X  X  X ealth X  X  (since categories 2 and 16 are quite loosely associated). Moreover, it should be noted that the  X  X  X tart-state X  X  (category 1) is too far from the  X  X  X nd-state X  X  (category 19), which means that these states are not associated with each other. This result justifies are initial choice to consider a different state for the beginning and the ending of each session.

Csd data set : From Fig. 8 , it is evident that the  X  X  X tart state X  X  and  X  X  X ome X  X  are closely associated with each
Also it seems that users tend to visit in the same sessions categories in couples such as categories  X  X  X onfer-ences X  X  and  X  X  X inks X  X  and categories  X  X  X abs X  X  and  X  X  X isc X  X . On the other hand, it is evident that the category  X  X  X ersonnel X  X  is visited solely and separately than other categories. This is due to the potential tend to search for particular people individually, since it is quite often to navigate on the Web when looking for particular academics or faculty (e.g. in an effort to look for a collaboration or establishing a communication contact with a professor). 6.3.2. An inside view of the clusters
Except of analyzing the association among Web page categories it is also very useful to have a view about the contents of each cluster, since a deeper knowledge for the inside of each cluster can draw useful and mean-ingful inferences for the users X  navigation behavior. More specifically, Figs. 9 and 10 depict the percentage frequency of requested Web page categories observed in each cluster to help in understanding users X  naviga-tion behavior for both msnbc and csd data sets. The following comments aim at giving an inside view of the resulted clusters per data set:
Msnbc data set :From Fig. 9 , it is evident that the users X  sessions that belong to cluster 1 refer to of a wide range of pages, showing more preference to  X  X  X ports X  X ,  X  X  X isc X  X ,  X  X  X ocal X  X  and  X  X  X ews X  X  categories. This may be an indication that the users who navigated as described in these sessions, had no particular interest at a specific category but they have rather showed browsing behavior within the Web site, navigating over var-ious page categories. On the other hand, the users X  sessions in cluster 2 show a special interest to  X  X  X usi-ness X  X , and  X  X  X n-air X  X , i.e. these users are probably business-oriented (e.g. they are interested in stock market which involved both business and it might be shown on communications media). In cluster 3, 30% of the total requested Web page categories belong to  X  X  X rontpage X  X , i.e. we might have users interested in
Web page authoring. Users X  sessions on cluster 4 show high interest for the  X  X  X rontpage X  X ,  X  X  X ews X  X  and  X  X  X ech X  X  categories (and low interest for all the other categories), i.e. it might declare focused navigation on using technology for Web news site authoring. On the other hand, users X  sessions in cluster 5 present high interest only for the categories which refer about  X  X  X eather X  X ,  X  X  X ocal X  X  and  X  X  X sn-sports X  X  so they might refer to users interested in a game and they want to get information about local weather predictions.
Csd data set: The users X  sessions in cluster 1 show a special interest to  X  X  X ome X  X , and  X  X  X abs X  X , i.e. users who followed such sessions might probably be (under-) graduate students who check the Home page and the
Lab schedule to check whether there are any announcements about their lab courses. In clusters 2 and 4, the most popular page category is also the  X  X  X ome X  X , i.e. we might conclude that we have users who are interested in the csd department establishment. Finally, in cluster 3, the users X  sessions show high inter-mostly (under-) graduate students who have focused interests on their Lab assignments, with no further interest for any other information about the department. Based on these observations an overall conclusion for the particular dataset is that users focus on navigating on few categories, namely the  X  X  X ome X  X  and  X  X  X ab X  X  categories. 6.3.3. Exploiting cluster validation and interpretation in practice
Visualizing the associations and then interpreting clusters of Web user sessions under the proposed proce-dures offers important information as discussed in the earlier subsections. Evaluating both the proposed val-idation and interpretation approaches on our considered real data datasets originating from two Web servers, we noticed that there are plenty of inferences that may be drawn in terms of users X  preferences, interests and origin. In this context, the adoption of the proposed validation and interpretation procedures in current Web-related applications might offer important benefits. Some indicative such applications are the following:
E-commerce applications : the proposed procedures in conjunction with a corresponding e-commerce data analysis ( Kohavi, Mason, Parekh, &amp; Zheng, 2004 ), may offer important knowledge about customers origin, needs and preferences. For example, the use of the interpretation procedure can maximize the sales by min-imizing the route of the potential customers X  page visits from homepage to the requested (for purchase) product. Moreover, validation of clusters of users X  sessions may indicate the separation in customer habits or product (dis)likes so that the underlying commercial company might guide certain advertising tasks towards a particular cluster, i.e. a group of customers with common navigational behavior.

Web site administration : the proposed approaches are also beneficial in terms of realizing how and with which patterns the Web site page categories are visited, so to take certain actions for revising Web site X  X  structure and presentation, in relation to Web site evaluation or reorganization ( Chakrabarti, 2003 ). There-fore, based on the results of visualizing certain associations among page categories, a Web site administra-tor might decide to take certain site structure rearrangements so that the accessing speed and the user inter-action with the site will be improved.

Caching and prefetching : having the proposed validated clusters of sessions which have been proven to show clearly separated groups, actions of caching and/or prefetching clusters may be beneficial in terms of the users X  perceived latency. The proposed validation and interpretation procedures are in accordance with the need to deliver the appropriate content to the interested users in a timely, scalable, and cost-effective manner ( Pallis &amp; Vakali, 2006 ).
 Certainly, there are more applications may benefited from the proposed work, such as searching on the
Web, as well as personalization and recommendation engines, which are also demanding in terms of Web usage interpretation and understanding. 7. Conclusions
This paper presents a complete framework for model-based cluster analysis for Web users X  sessions. Taking into consideration that the Markov models may provide valuable information for users X  navigation behavior which is often hidden, it is crucial to discover the hidden meaningful relationships among users X  sessions as well as between users X  sessions and Web objects. Towards this direction, the proposed validation and interpre-tation methods have been proved efficient and very robust for validating Web users X  sessions clusters as well as inferring meaningful results from these clusters. Specifically, the validation procedure is a newly presented approach in the literature for validating model-based clusters and the interpretation procedure is a novel visu-alization method for interpreting the clustering results by revealing interesting features for Web users X  navi-gation behavior and their interaction with the content/structure of Web sites.

Evaluating both the proposed validation and interpretation approaches on real data originating from inten-sive Web servers, we noticed that the proposed approach is a valuable tool for various Web-based applica-tions. Such indicative applications are benefited since Web usage clusters validation and interpretation is: facing some of the Web administrators problems, who need to validate and interpret the resulted clusters in order to improve site X  X  structure and organization; dealing with customers characterization in e-commerce applications, so that a company might increase their promotion or marketing actions at specified customer groups; identifying appropriate clusters which may then be cached or prefetched at particular locations. Moreover these clusters might guide certain searching and recommendation tasks.

It is interesting to investigate in a future work the impact of the proposed validation and interpretation on rent application testbeds in order to assess which of the two procedures (validation or interpretation) is most effective and beneficial.
 Acknowledgements
The authors appreciate and thank the anonymous reviewers for their valuable comments and suggestions, which have considerably contributed in improving the paper X  X  content, organization and readability. References
