 The running key cipher is an encoding scheme that uses a secret key R that is typically a string of words, usually taken from a book or other text that is agreed upon by the sender and receiver. When sending a plaintext message P , the sender truncates R to the length of the plaintext. The scheme also relies on a substitution function f , which is usually publicly known, that maps a plaintext letter p and key letter r to a unique ciphertext letter c . The most common choice for f is the tabula recta , where c = ( p + r ) mod 26 for letters in the English alphabet, with A = 0 , B = 1 , and so on.

To encode a plaintext with a running key, the spaces in the plaintext and the key are removed, and for every 0  X  i &lt; | P | , the ciphertext letter at posi-tion i is computed to be C i  X  f ( P i ,R i ) . Figure 1 shows an example encoding using the tabula recta .
For a given ciphertext and known f , the plaintext uniquely determines the running key and vice versa. Since we know that the plaintext and running key are both drawn from natural language, our objective function for the solution plaintext under some lan-guage model is: where the running key R P,C is the key that corre-sponds to plaintext P and ciphertext C .

Note that if R P,C is a perfectly random sequence of letters, this scheme is effectively a  X  X ne-time pad X , which is provably unbreakable (Shannon, 1949). The knowledge that both the plaintext and the key are natural language strings is important in breaking a running key cipher.

The letter-frequency distribution of running key ciphertexts is notably flatter than than the plaintext distribution, unlike substitution ciphers where the frequency profile remains unchanged, modulo letter substitutions. However, the ciphertext letter distri-bution is not uniform; there are peaks corresponding to letters (like I) that are formed by high-frequency plaintext/key pairs (like E and E). 2.1 Running Key Ciphers Bauer and Tate (2002) use letter n-grams (without smoothing) up to order 6 to find the most probable plaintext/key character pair at each position in the ci-phertext. They test their method on 1000-character ciphertexts produced from plaintexts and keys ex-tracted from Project Gutenberg. Their accuracies range from 28.9% to 33.5%, where accuracy is mea-sured as the percentage of correctly decoded char-acters. Such figures are too low to produce read-able plaintexts, especially if the decoded regions are not contiguous. Griffing (2006) uses Viterbi decod-ing and letter 6-grams to improve on the above re-sult, achieving a median 87% accuracy over several 1000-character ciphertexts. A key shortcoming of this work is that it requires searching through about 26 5 states at each position in the ciphertext. 2.2 Letter Substitution Ciphers Previous work in decipherment of classical ciphers has mainly focused on letter substitution. These ci-phers use a substitution table as the secret key. The ciphertext is generated by substituting each letter of the plaintext according to the substitution table. The table may be homophonic; that is, a single plaintext letter could map to more than one possible cipher-text letter. Just as in running key ciphers, spaces in the plaintext are usually removed before encoding.
Proposed decipherment solutions for letter substi-tution ciphers include techniques that use expecta-tion maximization (Ravi and Knight, 2008), genetic algorithms (Oranchak, 2008), integer programming (Ravi and Knight, 2009), A* decoding (Corlett and Penn, 2010), and Bayesian learning with Dirichlet processes (Ravi and Knight, 2011). 2.3 Vigen ` ere Ciphers A scheme similar to the running key cipher is the Vi-gen ` ere cipher, also known as the periodic key cipher. Instead of a single long string spanning the length of the plaintext, the key is a short string  X  usually but not always a single word or phrase  X  repeated to the length of the plaintext. Figure 2 shows an example Vigen ` ere cipher encoding. This cipher is less secure than the running key, since the short length of the key vastly reduces the size of the search space, and the periodic repetition of the key leaks information.
Recent work on decoding periodic key ciphers perform Viterbi search on the key using letter n-gram models (Olsen et al., 2011), with the assump-tion that the length of the key is known. If unknown, the key length can be inferred using the Kasiski Test (Kasiski, 1863) which takes advantage of repeated plaintext/key character pairs. In this paper, we describe a search algorithm that uses Gibbs Sampling to break a running key cipher. 3.1 Choice of Language Model The main advantage of a sampling-based approach over Viterbi decoding is that it allows us to seam-lessly use word-based language models. Lower or-der letter n-grams may fail to decipher most cipher-texts even with perfect search, since an incorrect plaintext and key could have higher likelihood un-der a weak language model than the actual message. 3.2 Blocked Sampling One possible approach is to sample a plaintext letter at each position in the ciphertext. The limitation of such a sampler for the running key problem is that is extremely slow to mix, especially for longer ci-phertexts: we found that in practice, it does not usu-ally converge to the optimal solution in a reasonable number of iterations even with simulated annealing. We therefore propose a blocked sampling algorithm that samples words rather than letters in the plain-text, as follows: 1. Initialize randomly P := p 1 p 2 ...p | C | , fix R as 2. Repeat for some number of iterations 3. Remove spaces and return P,R
Note that every time a word in P is sampled, it induces a change in R that may not be a word or a sequence of words, and vice versa. Sampling word boundaries will also produce hypotheses contain-ing non-words. For this reason, we use a word tri-gram model linearly interpolated with letter trigrams (including the space character). 1 The interpolation mainly serves to smooth the search space, with the added benefit of accounting for out-of-vocabulary, misspelled, or truncated words in the actual plaintext or key. Table 1 shows an example of one sampling iteration on the ciphertext shown in Figure 1. 4.1 Data We randomly select passages from the Project Gutenberg and Wall Street Journal Corpus extracts that are included in the NLTK toolkit (Bird et al., 2009). The passages are used as plaintext and key pairs, and combined to generate synthetic ciphertext data. Unlike previous works which used constant-length ciphertexts, we study the effect of message length on decipherment by varying the ciphertext length (10, 100, and 1000 characters).

Our language model is an interpolation of word trigrams and letter trigrams trained on the Brown Corpus (Nelson and Kucera, 1979), with Kneser-Ney smoothing. We fixed the word language model interpolation weight to  X  = 0 . 7 . 4.2 Baseline and Evaluation For comparison with the previous work, we re-implement Viterbi decoding over letter 6-grams (Griffing, 2006) trained on the Brown Corpus. In addition to decipherment accuracy, we compare the running time in seconds of the two algorithms. Both decipherment programs were implemented in Python and run on the same machines. The Gibbs Sampler was run for 10000 iterations.

As in the Griffing (2006) paper, since the plaintext and running key are interchangeable, we measure the accuracy of a hypothesized solution against the reference as the max of the accuracy between the hy-pothesized plaintext and the reference plaintext, and the hypothesized plaintext and the reference key. 4.3 Results Table 2 shows the average decipherment accuracy of our algorithm and the baseline on each dataset. Also shown is the number of times that the Gibbs Sam-pling search failed  X  that is, when the algorithm did not hypothesize a solution that had a probability at least as high as the reference within 10000 iterations.
It is clear that the Gibbs Sampler is orders of mag-nitude faster than Viterbi decoding. Performance on the short (length 10 ) ciphertexts is poor under both algorithms. This is expected, since the degree of message uncertainty, or message equivocation as defined by Shannon, is high for short ciphertexts: there are several possible plaintexts and keys be-sides the original that are likely under an English language model. Consider the ciphertext WAEEXF-PROV which was generated by the plaintext seg-ment ON A REFEREN and key INENTAL AKI. The algorithm hypothesizes that the plaintext is THE STRAND S and key DTAME OPELD, which both receive high language model probability.
However, on the long ciphertexts, our algorithm gets close to perfect decipherment, surpassing the Viterbi algorithm by a large margin. 2 Accuracies on the Wall Street Journal ciphertexts are higher than on the Gutenberg ciphertexts for our algorithm, which may be because the latter is more divergent from the Brown Corpus language model. 5.1 Unknown substitution functions Some running key ciphers also use a secret substi-tution function f rather than the tabula recta or an-other known function. In typical cases, these func-tions are not arbitrary, but are parameterized by a se-cret keyword that mutates the tabula recta table. For example, the function with the keyword CIPHER would be the substitution table shown in Table 3. Decoding a running key ciphertext under a latent substitution function is an open line of research. One possibility is to extend our approach by sampling the keyword or function in addition to the plaintext. 5.2 Exact search Since some the errors in Gibbs Sampling decipher-ment are due to search failures, a natural exten-sion of this work would be to adapt Viterbi search or other exact decoding algorithms like A* to use word-level language models. A naive implementa-tion of Viterbi word-based decoding results in com-putationally inefficient search spaces for large vo-cabularies, so more sophisticated methods or heuris-tics will be required. 5.3 Analysis of Running Key Decipherment While there has been theoretical and empirical anal-ysis of the security of letter substitution ciphers of various lengths under different language models (Shannon, 1949; Ravi and Knight, 2008), there has been no similar exposition of running key ciphers, which we reserve for future work. We propose a decipherment algorithm for running key ciphers that uses Blocked Gibbs Sampling and word-based language models, which shows signifi-cant speed and accuracy improvements over previ-ous research into this problem.
 We would like to thank Sujith Ravi for initial exper-iments using Gibbs sampling, and the anonymous reviewers. This research was supported in part by NSF grant 0904684.
