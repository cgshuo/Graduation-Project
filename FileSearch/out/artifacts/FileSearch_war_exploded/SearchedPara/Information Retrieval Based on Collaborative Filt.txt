 In this paper, we propose an information retrieval model called Latent Interest Semantic Map (LISM), which features retrieval composed of both Collaborative Filtering(CF) and Probabilistic Latent Semantic Analysis (PLSA). The motivation behind this study is that the relation between users and documents can be explained by the two different latent classes, where users belong probabilistically in one or more classes with the same interest groups, while documents also belong probabilistically in one or more class with the same topic groups. The novel aspect of LISM is that it simultaneously provides a user model and latent semantic analysis in one map. This benefit of LISM is to enable collaborative filtering in terms of user interest and document topic and thus solve the cold start problem. H.3.1 [ Analysis and Indexing ]: Clustering, Information filtering, MAP, PLSA, Retrieval models Collaborative Filtering, User behavior, Query suggestion, Document categorization, Relationship analysis, Search results, Latent semantic indexing, Bayesian statistics This paper considers an information retrieval model in which a user seeks information by using search engines. The goal of the information retrieval model is to assist users in their search for information. Search engines such as Clusty, Google, Theoma and Wisenut help users to retrieve information. These engines are seen to provide maps from queries to documents, and user information retrieval behavior could be projected onto these maps. The cause of inefficiency in user retrieval based on search engines is the independence of the relation among users from that among documents. The independence among users means that even though many users may use the same search system to find the same information, their efforts and strategies are not efficiently shared and utilized. The independence among documents means that even though many documents contain the same information, most of them are not linked to each other or categorized. Collaborative Filtering (CF) [1] and PLSA [12, 13] are promising methods for solving these weaknesses. Unfortunately these methods are applied independently and so can X  X  solve these problems simultaneously. 
We focus on these independence problems and propose the latent interest semantic map (LISM), which is a novel information retrieval model using both CF and PLSA. We assume that the observed user behavior can be modeled as a mixture of user groups, where the users belong probabilistically to one or more groups sharing the s ame interest gr oups, and documents can be modeled as a mixture of document groups, where the documents belong probabilistically to one or more groups sharing the same topic. Each probabilistic distribution over groups can be estimated. The novelty of LISM is to provide, simultaneously, a user model and latent semantic analysis in one map. While LISM requires two different kinds of variables for user interest and document topic class to be estimated, we extend Gaussian pLSA to estimate these two different kinds of latent variables. The impact of LISM in the information retrieval model is like the impact of PLSA in document analysis. LISM can decompose the relation between user and document into the relation between the user interest class and the document topic class. As part of LISM, CF allows us to define the relation between users by the relation between user interests and the relation between documents by the relation topic. Collaborative filtering is a technology that is complementary to content-based filtering and aims at learning predictive models of user preference, interest, or behavior for making predictions about what other items or articles an active user might be interested in from data such as user preference or behavior. Breese identified two methods of collaborative filtering algorithm: model-based and memory-based[1]. The model-based algorithm seeks to fit a probabilistic model to data through unsupervised learning techniques. The memory-based algorithm computes the similarity measure between the active user and each of the other users in data. The vote for an item that the active user has not yet rated is calculated as the similarity measure weighted over the other users X  votes for the item. A famous example of a memory-based algorithm was developed for the Group Lens project[19], Ringo[21]. 
PLSA is based on introducing a hidden variable, so that users and items are rendered conditionally independent [9, 10]. In contrast to standard latent semantic indexing (LSI) using singular value decomposition [7], PLSA has a solid statistical foundation, since it is based on the likelihood principle and defines a proper generative model for data. Brown et al. took a model mixed distribution as their starting point [13], yet did not introduce latent aspect variables, nor did they derive the corresponding EM algorithm [10]. Other work [15] was based on an aggregate Markov model with a back-off technique [11]. In this model, the hidden variable is assumed to be a third variable with a spurious correlation. The novelty of PLSA is that the introduction of the latent variable solves the problems targeted. However, PLSA, like other conventional probabilistic models, cannot fails to resolve the cold start problem. We introduce CF into the information retrieval to solve the problem of independence among users. This, of course, is neither a novel idea nor sufficient to solve this problem. The success of CF depends on what information can be shared and the similarity between users. Therefore, we can improve user information retrieval by using CF with LISM based on the model that is a mixture of user groups sharing the same interest groups and document groups sharing the same topic. The principle of LISM is based on the assumption that user information retrieval is the observed behavior of a user X  X  interests seeking information on a topic according to individual interests and the variable corresponding to these topics and individual interests. Here we show two examples of information retrieval based on CF with LISM. First, a search engine equipped with CF and LISM can customize query suggestions and categorize search results. For improving user support, for example, such a search system could suggest highly customized user queries with words that the system expects to be useful in the next query. In the case of query suggestions, a search engine based on CF can define the similarity and perform CF using these two different classes. First, the similarity can be defined using the probabilistic distribution over these latent classes. Because LISM has two different classes, we can define the two different classes. We assume that the interest class is the group sharing the same interest groups and that each user's probabilistic distribution over these groups is the affiliated probabilistic distribution over these groups. Thus the similarity between users or documents can be defined over the interest class in terms of the interest similarity. Similarly, we assume the topic class is the group sharing the same topic groups and that each document's probabilistic distribution over these groups is the affiliated probabilistic distribution over these groups. Thus the similarity between users or documents can be defined over the topic class in terms of the topic similarity. Second, collaborative filtering can be performed on these similarities. The performance of CF depends on the similarity. Because LISM has the above two different similarities, we can suggest words from the user X  X  history and documents identified by using these two different similarities. Therefore, LISM enables CF to define the similarity based on the similarity given in terms of interest class and topic class, even though only observed data such as each user X  X  click data or log history are available. In this subsection, we detail a novel approach to simultaneously extract two different kinds of latent classes underlying the observed data: the user interest class and topic class. We assume that the relation between an interest class and the document included in the user data can be explained in terms of the relation between the interest class to which the user belongs and the interest classes to which the document belong. Given this assumption, we can define the conditional probability distribution P(d,v|u) that user u will select document d and rate it v as follows: Here parameter  X  summarizes P(c|u) which denotes the conditional distribution that user u belongs interest class c , P(t|c) which denotes the conditional distribution that interest class c selects topic class t , P(d,v|t) which denotes the conditional P(d|t) which denotes the conditional distribution that topic class t selects document d , P(v|t,d) which denotes the conditional products of these probabilities, summed over c and t , run over all possible states of user interest class and document topic class. If rating data is given as a kind of user data, we normalize this data for each user and treat this normalized data the same as the probability distribution of rating data. While LISM needs two different variables as shown in Eq(1), the user interest class and topic class, behind users and documents, PLSA estimates only one kind of variable. To solve this problem, we propose an extension of the aspect model of PLSA. While the aspect model introduces only one kind of latent variable, Z, with state z for P(d,v|u) , our model introduces two different kinds of hidden variables, the user interest class C and the document topic rendered conditionally independent by these variables. To estimate the probability distribution, we introduce the document data as document-term frequency data, which is included in user history data. Here we introduce an algorithm that can estimate two different kinds of variables. We assume that the interest class C corresponds to hidden variables Z estimated by Gaussian pLSA and the topic class can also be estimated by Gaussian pLSA with the decomposition of document  X  word pairs. Therefore, our algorithm for LISM starts after calculating P(z|u) and P(d,v|z) , by Gaussian pLSA. First, once these probabilities are calculated, our algorithm identifies P(z|u) with P(c|u) and P(v|d,z) with P(v|d,c) . Second, our algorithm calculates P(t|d) ; i.e. which document d these calculated probabilities and P(v|c,d) and P(t|d) . The existence of P(t|d) in the formula enables us to deal with new documents that are not included in user history, for collaborative filtering. To calculate P(t|d) , we assume that the relation between a document and the words in it can be explained in terms of the relation between the topic class to which the document belongs and the topic classes to which the words belong, the same as PLSA. Given this assumption, we can define the joint probability of document d and word w as follows: where P(w|t) denotes the probability of topic class t generating word w , and P(d|t) denotes the probability of topic class t selecting document d . We use maximum a posteriori (MAP) instead of maximum likelihood (ML) used by PLSA to estimate these latent variables. MAP is a point estimate of the posterior probability under the defined probability densities taken from the adaptation data with some prior knowledge about the model parameters described by a prior distribution. As for the relation defined in LISM, we assume that users can be indexed by their interest classes, and similarly, that documents can be indexed by their topic classes. Given these assumptions, we can estimate topic class from documents and interest classes from user history data, through the following series of equations for LISM. 
Following the likelihood principle, we define the likelihood function L of the co-occurrence of document d selecting word w as where N(w, d) denotes the number of times that word w occurs in document d . In PLSA, the variational probability distribution Q is introduced and written by the given parameter as follows: Using Q, a family of risk functions can be defined as follows: This function is optimized by the Expectation Maximization (EM) algorithm [7], which is a standard statistical inference method that can be used to maximize the likelihood function. Here, we use a maximum a posteriori (MAP) parameter estimate to derive these parameters. This parameter is estimated from the maximum a posteriori estimate using a penalized EM as follows: E-step M-step 
Note that the main difference between MAP and PLSA is the existence of a priori distribution P(  X  ) . 
To calculate P(t|c) and P(v|d,t) , we assume that the relation between an interest class, a document, and its rating can be explained in terms of the relation between the topic class to which the interest class belongs and the topic classes to which the document belongs, as before, and its rating is the conditional probability density. Given this assumption, we can define the conditional probability distribution P(v|c,d) that interest class c will select document d and rate it v as follows: As discussed before, we calculate P(z|u) and P(d,v|z) , by Gaussian pLSA. Next we identify P(z|u) with P(c|u) and P(d,v|z) with P(d,v|c) , replaced by P(v|c,d)P(d|c) . The resulting conditional probability can be rewritten as follows: 
The EM algorithm proceeds by alternating the E-step in Eq(10) with the M-step in Eqs(11-13). Similarly, we can calculate P(t|c) and P(v|d,t) using P(d|t) and P(v|c,d) as follows: 
Notice that Eqs(14-17) are formed by replacing u by c and c by t in Eqs(10-13). In this process, we use P(d|t) calculated in advance. an initial value in the EM algorithm. As for P(v|d,t) , we also use a Gaussian mixture model with user-interest class mixing weights and include it in these formulas as follows. 
Notice that rating v c  X  in Eqs.(19,20) are normalized rating  X  a interest class-specific mean rating and a interest class-specific variation  X  c . As discussed in [12], there are a number of ways to extend the dependency structure of the co-occurrence model to include an additional response variable. This extension, which has proven most useful in empirical evaluations, introduces direct dependencies of the response variable on the document in question, but mediates the dependency on the user through a latent variable. The latter is assumed to capture user interest groups and document topic groups. Therefore, this resulting rating function can be defined by following the analogy of Gaussian pLSA[14]; we can define the expected response value as follows: The feature of LISM is the ability to calculate the probabilistic distribution over topic class as P(w|t) by including documents as well as their words. This allows the value of unobserved or new documents in user history data to be predicted by calculating their probabilities and substituting the probabilities for this equation. This is the reason why LISM can solve the cold start problem. The other feature of LISM is its ability to calculate different kinds probabilistic distribution of P(d|t) , P(t|c) and P(w|t) .This enables us to define the similarity between users, documents, user interest. and document topic class. Being considering the feature of membership as a probabilistic distribution, this similarity between documents with the topic class can be defined by Kullback-Leibler distance follows. We can define the other similarities in the same way. By using these similarities, we can classify users or documents in terms of user interest or document topic. This allows LISM to not only predict the value of each document but also recommend documents by these similarities as shown in Figure 1. Therefore, we can say that LISM improves user information retrieval by providing user the same information access as offered by prediction and classification. The data sets we used in the experiments were the Each Movie data set (for estimating interest class) and the Web Site Document, an Internet Movie Database (IMDb)[22] (for estimating topic class for LISM). The Each Movie data set was created by Digital Equipment Corporation (now HP) from a CF site for movies that was run by the same company. This data set consists of the ratings made by 72916 users for 1628 movies. The ratings are on a scale of 0 X 1 with the interval being 0.2. We multiplied the ratings by 5 through these experiments. Because this data is the largest publicly available data set and has the advantage of including explicit user ratings, it is commonly used in the evaluation of CF methods. The Web Site Document is an Internet Movie Database (IMDb)[18]. We collected data consisting of movie title, genre, cast, and summary from 1628 movies. There were 21 movie genres. Some movies had multiple genres. The average number of genres per movie was 2.3. The data also contained 8625 unique words and 623 unique cast members. The aim of these experiments is to show the LISM generated from both user history data and document data, and to verify that the proposed method can improve user information retrieval (by collaborative filtering). We used the protocol AllBut1 [1] to evaluate the prediction accuracies. The protocol is often used for evaluating collaborative filtering algorithms that include a given-k protocol where the algorithm is trained on k observations for each user and leaves out exactly one rating for every user with at least two observed ratings. The protocol is introduced by Breese[1] and has been adopted by almost all previous papers on collaborative filtering. Our concern is to solve the cold start problem, which is the biggest problem of CF, by LISM. For this experiment, we used modified AllBut1 that leaves out some common observations from the training data, then each probabilities are calculated without these removed observations. Finally we insert these documents into LISM and perform the evaluation to compare the rating of these observations with the rating predicted by LISM. Table 1 shows an example of recommendation results using two different similarities. These recommendations were given by LISM with topic class t = 35 and  X  =0.1, interest class c = 10 and  X  =0.1 to a user selecting  X  X oy Story X . In each row, the movies are sorted according to the similarity measures  X  X nterest class X  and  X  X opic class X  calculated from Eq(22) and its modified variant, respectively, for a single user. One can observe that the movies provided by each class are different, although they are recommended to the same user selecting the same movie. We can infer that the movies recommended using the interest class represent a preference for family and the movies predicted using the topic class represent the genre of action , as labeled by IMDb. From these results, we may say that CF with LISM can use the two different similarities to predict documents or words of different semantics. It is worth to mention that the precision of the interest class is statistically higher than that of the topic class. 
Table 1. Recommendation for  X  X oy Story X  based on the two While You Were Sleeping Table 2 shows a prediction accuracy comparison against Gaussian pLSA using user interest class c = 35 and document topic class t = 10. The LISM prediction is calculated by using Eq(21) to derive interest class-specific mean rating and variation. In this table, MAE denotes the Mean Absolute error and RMS denotes the rooted mean square. This table says that the relative performance gain of LISM against Gaussian pLSA is not so high by MAE, but is slightly higher by RMS. The difference between these methods is statistically significant at the 99% level, using a one-tailed F-test. 
Method Gaussian Table 3 shows a comparison of the prediction based on each user interest with the prediction based on topic class. In this experiment, we selected 20 movies rated by many users by high order of standard deviation. This process left only 8% of the original learning data. We evaluated the prediction rate of each movie left only in the test data. We used the user specific mean rating as baseline. The prediction is calculated following the methods in 4.3 after estimating P(w|t) and substituting it into the equation. These results show that LISM allows CF to recommend unobserved or new documents with better accuracy. The assumption behind LISM is that the relation between users and documents can be explained by the two different latent classes, where users belong probabilistically in one or more class with the same interest groups, while documents belong probabilistically in one or more class with the same topic groups. Therefore, LISM enables CF to define the similarity based on the terms of interest class and topic class, even though only observed data such as each user X  X  click data or log history are available. Furthermore LISM can provide two semantically different recommendations on documents or words based on the two different similarities as shown in Table 1. LISM is a natural model of user information retrieval and leads to the improvement in CF shown in Table 2 and 3. The effectiveness of prediction and recommendation based on LISM depends on the words or meta data of documents. Additionally, the most suitable number of user interest class and topic class remains an unresolved issue, which is also true for PLSA or Gaussian pLSA. In fact, the results of prediction shown in Table 2 are very sensitive to the numbers of both classes. It seems to be affected also by the quality or kinds of data used to calculate P(w|t) . As for the data used in these experiments, there were fewer topics than interest classes. This means that if the relations between user interest and movie topic are not so many, we have to consider also the difference of topic class (?). This paper proposed LISM featuring retrieval method composed of both Collaborative Filtering(CF) and Probabilistic Latent Semantic Analysis (PLSA). The contribution of LISM to information retrieval is that it can estimate two different kinds of hidden variables as user interest class and document topic class underlying the observed data. This enables CF to make prediction according to different semantics and hence improve the prediction by these estimated relations. LISM is also effective to avoid the cold star problem. One goal of information retrieval is to enable users to efficiently find topics based on their interests that go beyond simple queries. These two different latent classes may play a role in LISM to achieve this goal. Experiments confirmed that CF with LISM can solve the problem of the independence of users and documents and thus improve user information retrieval. [1]J. S. Breese, D. Heckerman and C. M. Kadie: Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the 14th Annual Conference on Uncertainty in Artificial Intelligence, pp. 43-52, July 1998. [2]A. A. Broder: A Taxonomy of Web Search. SIGIR Forum, Fall 2002, Vol. 36, No. 2, Finland, August 11-15, 2002. [3]D. Beeferman and A. Berger: Agglomerative clustering of a search system query log. In Proceedings of the 6th ACM SIGKDD, pp. 407-415, 2000. [4]J. S. Breese, D. Heckerman and C. M. Kadie: Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the 14th Annual Conference on Uncertainty in Artificial Intelligence, pp. 43-52, July 1998 [5]A. A. Broder  X  A Taxonomy of Web Search. SIGIR Forum, Fall 2002, Vol. 36, No. 2, Finland, August 11-15, 2002. [6]J. Canny: Collaborative Filtering with Privacy via Factor Analysis, ACM SIGIR, Tampere, Finland, August 2002. [7]B. D. Davison, D. G. Deschenes and D. B. Lewanda  X  Finding Relevant Website Queries, In Proceedings of the 12th World Wide Web Conference (WWW12), pp. 162-168, Budapest, May 2003. [8]S. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnas and R. A. Harshman  X  Indexing by Latent Semantic Analysis. JASIS, 41(6), pp. 391-407, 1990. [9]A. P. Dempster, N. M. Laird and D. B. Rubin  X  Maximum Likelihood from Incomplete Data via the EM Algorithm, Journal of the Royal Statistical Society, Series B, 39(1): 1-38, 1977. [10]L. Fitzpatrick and M. Dent  X  Automatic feedback using past queries: Social searching? In Proceedings of the 20th International ACM SIGIR, Philadelphia, PA, July 1997. [11]N. S. Glance  X  Community search assistant. In Artificial Intelligence for Web Search, pp. 29?34. AAAI Press, July 2000. [12]T. Hofmann  X  Unsupervised learning by probabilistic latent semantic analysis. Machine Learning Journal, 42(1): 177-196, 2001. [13]T. Hofmann  X  Collaborative filtering via Gaussian probabilistic latent semantic analysis, In Proceedings of the 26th ACM SIGIR, 2003. [14]G. Jeh and J. Widom. SimRank: A measure of structural-context similarity. In Proceedings of the 8th ACM SIGKDD, Edmonton, Alberta, Canada, July 2002. [15]A. Maedche, V. Pekar and S. Staab  X  Ontology Learning Part One -On Discovering Taxonomic Relations from the Web, Web Intelligence, Springer Verlag, 2002. [16]C. Manning and H. Shuetze  X  Foundations of Statistical Language Processing, MIT Press, 1999. [17]B. Marlin: Modeling User Rating Profiles For Collaborative Filtering. NIPS, 2003 [18]V. V. Raghavan and H. Sever  X  On the Reuse of Past Optimal Queries. In Proceedings of the 18th ACM SIGIR'95, Seattle, WA, USA, July 1995. [19]L. Saul and F. Pereira  X  Aggregate and mixed-order Markov models for statistical language processing. In Claire Cardie and Ralph Weischedel, editors, Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, pp. 81-89. Association for Computational Linguistics, Somerset, NJ. Distributed by Morgan Kaufmann, San Francisco, CA, 1997. [20]U. Shardanand and P. Maes  X  Social information ltering: algorithms for automating word of mouth. In Proc. on Human Factors in Computing Systems, pages 210-217, 1995. [21]P. Resnik, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl  X  Grouplens: An Open Architecture for Collaborative Filtering of NetNews, ACM Conf. Computer Supported Cooperative Work, Chapel Hill, NC, October 1994. [22]http://www.imdb.com
