 Frequent pattern mining is an important problem in data mining research. Ini-tially focused on the discovery of frequent itemsets [1], studies were extended to mine structural forms like sequences [2], trees [7] or graphs [22]. While itemset mining seeks frequent combinations of items in a set of transactions, structural mining seeks frequent substructures. Most existing studies focus only on one kind of problem (itemset mining or structural mining). However, in order to represent richer information, it seems natural to consider itemsets that are organized in complex structures. In this paper, we introduce the problem of mining attributed trees that are tree structures in which ea ch vertex is associated with an itemset.
In web log analysis, for example, it is common to represent user browsing in tree-like data where each page is identified with an unique id. However, one can more pertinently characterize browsed pages with lists of keywords associated with their content. This approach allows to capture the browsing habits of users even when the web site is reshuffled. Other applications can be imagined in vari-ous area such as retweet trees mining, spatio-temporal data mining, phylogenetic tree mining and XML document mining.

The key contributions of our work are the following: 1) We present the problem of mining ordered and unordered substructures in a collection of attributed trees. 2) We define canonical forms for attributed trees. 3) We propose a method for attributed trees enum eration that is based on two operations: itemset extension and tree extension. 4) We present an effi cient algorithm IMIT for extracting frequent substructures in a set of attr ibuted trees. 5) We perform extensive experiments on several synthetic datasets and a real weblogs dataset.
The rest of this paper is organised as fo llows. Section 2 presents basic concepts and defines the problem. Section 3 propos es a brief overview of related works, particularly few studies that mix itemset mining and structure mining. Section 4 describes the method including the search space exploration, the frequency com-putation and the candidates pruning method. Section 5 reports several applica-tions of the algorithms to mine both synthetic and real datasets. Finally, section 6 concludes the paper and presents possible extensions of the current work. In this section, we give basic definitions and concepts and then introduce the problem of attributed tree mining. 2.1 Preliminaries Let I = { i 1 ,i 2 ,..,i n } be a set of items. An itemset is a set P X  X  . The size of an itemset is the number of items. The set D of itemsets presents in a database is denoted by {P 1 , P 2 ,..., P m } where  X P  X  D , P X  X  . D is a transaction database.
A tree S =( V,E ) is a directed, acyclic an d connected graph where V is a set of vertices (nodes) and E = { ( u,v ) | u,v  X  V } is a set of edges. A distinguished node r  X  V is considered as the root, and for any other node x  X  V , there is a unique path from r to x . If there is a path from a vertex u to v in S =( V,E ), then u is an ancestor of v ( v is a descendant of u ). If ( u,v )  X  E (i.e. u is an immediate ancestor of v ), then u is the parent of v ( v is a child of u ). An ordered tree has a left-to-right ordering among the siblings. In this paper, unless otherwise specified, all trees we consider are unordered.

An attributed tree ,or( atree ) is a triple T =( V,E, X  )where( V,E )is the underlying tree and  X  : V  X  X  is a function which associates an itemset  X  ( u )  X  X  to each vertex u  X  V . The size of an attributed tree is the number of items associated with its vertices.

In this paper, we use a string representation for an atree based on that defined for labeled trees by Zaki [24]. This representation is only intended to provide a readable form for atrees. The string representation for an atree T is generated by adding a representation of the nodes found in T in a depth-first preorder traversal of T and adding a special symbol $ when a backtracking from a child to its direct parent occurs. In the paper, for simplicity, we omit the trailing $s. A string representation of a node is generated by listing all the items present in the associated itemset in a lexicographical order. For example, the string representation of atree T 2 from Fig. 1 is  X  ac $ cde ab $ a  X .
 Attributed trees can be understood as itemsets organized in a tree structure. As such, attributed tree inclusion can be defined with respect to itemsets inclusion or structural inclusion. For itemset inclusion, we say that atree T 1 is contained in another atree T 2 if both atrees have the same structure and for each vertex of T 1 , the associated itemset is contained in the itemset of the coresponding vertex in T 2 . More formally, T 1 =( V 1 ,E 1 , X  1 )is contained in T 2 =( V 2 ,E 2 , X  2 ), and is denoted by T 1 I T 2 , if V 1 = V 2 and E 1 = E 2 concept of subtree [5,7,12,17,19,23,24].

From the previous definition, we generalize the notion of asubtree in the fol-lowing way. T 1 =( V 1 ,E 1 , X  1 )isa asubtree of a atree T 2 =( V 2 ,E 2 , X  2 )and is denoted T 1 T 2 if T 1 is an isomorphic asubtree of T 2 , i.e. there exists a mapping  X  : V 1  X  V 2 such that T 1 = T 2 and ( u,v )  X  E 1 if (  X  ( u ) , X  ( v ))  X  E 2 asupertree of T 1 . T 1 is called an induced asubtree of T 2 iff T 1 is an isomorphic asubtree of T 2 and  X  preserves the parent-child relationships. T 1 is called an em-bedded asubtree of T 2 iff T 1 is an isomorphic asubtree of T 2 and  X  preserves the ancestor-descendant relationships. T 1 =( V 1 ,E 1 , X  1 ) is called a gap-i asub-tree of T 2 =( V 2 ,E 2 , X  2 ) iff T 1 is an isomorphic asubtree of T 2 and  X  preserves the ancestor-descendant relationships with the following constraint:  X  u  X  v  X  E 1 represents the number of edges between x and y in the atree.

Fig. 1 shows an example of an atree da tabase composed of three different atrees with two (incomplete) sets o f common asubtrees using a maximum gap of 0 and 1.

All tree mining algorithms dealing with unordered trees have to face the iso-morphism problem. To avoid the redundant generation of equivalent solutions, one tree is chosen as the canonical form and other alternative forms are discarded [3,8,17,23,25]. In previous works, canonical forms are based on a lexicographical ordering on node X  X  labels. In our work, we define an ordering based on node X  X  associated itemsets. Given two itemsets P and Q ( P = Q ), we say that P &lt; Q then |P| &gt; |Q| . From the definition above, an ordering,  X  , among atrees can be defined. From this, a canonical form of isomorphic atrees is easily deter-mined using the method presented by Chi et al. [7].

The problem with frequent atrees mining is that the number of frequent pat-terns is often large. In real applications, generating all solutions can be very expensive or even impossible. Moreover , lots of these frequent atrees contain redundant information. In Fig. 1, for example, atree  X  ae  X  is present in all trans-actions but the pattern is already encoded in atree  X  acde  X  because  X  ae  X  X s contained in atree  X  acde  X . This is the same for atree  X  aa  X  which is an asubtree of  X  aab $ c  X .

Since the proposal of Manilla et al. [13] huge efforts have been made to design condensed representations that are able to summarize solutions in smaller sets. Set of closed patterns is an example of such a condensed representation [18]. We say that an atree T is a closed atree if none of its proper asupertrees has the same support as T . In this paper, we introduce another condensed representation which is defined with respect to the contained in relationship only. We say that an atree T is a c-closed atree (content closed) if it is not contained (as defined above) in another atree with the same support as T . 2.2 Problem Statement Given a database B of atrees and an atree T ,the per-tree frequency of T is defined as the number of atrees in B for which T is an asubtree. An atree is frequent if its per-tree support is greater than or equal to a minimum threshold value. The problem consists in enumeratin g all frequent patterns in a given forest of atrees. Most of the earlier frequent tree mining algorithms are derived from the well-known Apriori strategy [1]: a succession of candidates generation phase followed by a support counting phase in which infrequent candidates are filtered out. Two strategies are possible for candidate generation: extension and join. With extension, a new candidate tree is generated by adding a node to a frequent tree [3,17]. With join, a new candidate is created by combining two frequent trees [12,25]. Combination of the two principles has also been studied [8].
Extension principle is a simple method suitable to mine implied trees because the number of nodes that can be used to extend a given subtree is often lower than the number of frequent subtrees.
 Other tree mining algorithms are derived from FP-growth approach [11]. These algorithms, which adopt the divide-and-conquer pattern-growth princi-ple avoid the costly process of candidate generation. However, pattern-growth approach cannot be extended simply to tackle the frequent tree pattern mining problem. Existing implementations are limited in the type of trees they can han-dle: induced unordered trees with no duplicate labels in each node X  X  childs [23], ordered trees [21] or embedded ordered trees [26] are some kind of trees that were successfully mined with pattern-growth approach.

Finding condensed representations of frequent patterns is a natural extension of pattern mining. For itemset mining, the notion of closure is formally defined [18]. Several works explored this topic in the context of tree mining and proposed mining methods as well as various implementations [9,19,20]. To the best of our knowledge, no method has been proposed for the general case of attributed trees. Recently we saw growing interest in minin g itemsets organized in structures. Miyoshi et al. [14] consider labeled graphs with quantitative attributes associated with vertices. This kind of structure allows to solve the problem by combining a  X  X lassical X  subgraph mining algorithm for the labeled graph, and an existing itemset mining algorithm for quantitative itemsets in each vertex. Mining at-tributed subgraphs independently of labels of vertices is impossible with this approach. Several studies [10,15,16] deal with attributed graphs but are looking for frequent subgraphs sharing common sets of attributes. Our work differs from these studies in the sense that itemsets associated with the vertices of a given frequent substructures are not necessarily identical. We are mainly interested in identifying induced ordered and unordered asub-trees. Depending on applications, some patterns including gaps in the ancestor-descendant relationship can also be considered. However, in order to collect only interesting patterns, the gap used should remain small. Otherwise, the relation-ship between a node and its descendants is not really tangible. Although we focus on induced asubtrees, we designed a general method that is able to mine asubtrees with any gap value, including embedded asubtrees. However, because of the primary objective, our method works better for induced asubtree mining and performances decrease as gap parameter increases. 4.1 Atrees Enumeration Using the operator  X  , it is possible to construct a candidate tree Q representing the complete search space [4] in the following way. The root node of the tree is at the top level and labeled with  X  . Recursively, for each leaf node n  X  Q , children n are added such that n  X  n . Children of a node n  X  Q , are generated either by tree extension or b y itemset extension.
 Tree Extension. For tree extension, we use a variation of the well-known rightmost path extension method [3,17]. Let T be an atree of size k. T can be extended to generate new atrees in two different ways. In the first way, a new child N is added to the rightmost node of T (right node extension). In the second way, a new sibling N is added to a node in the rightmost path of T (right path extension) [6].

In the classical approach, N represents every valid node from the input database. In our approach, new nodes N are created from every valid node Q from the input database. In fact, each node Q , associated with an itemset of size k , generates a set of k nodes N = { N 1 ,..,N k } used for tree extension. Each N i is associated with an itemset of size 1; the only item being the i th item of  X  ( Q ).
For example, in Fig. 1, the nodes that can be used for right node extension of pattern  X  acde  X  X re X  ab  X ,  X  a  X  (from atree T 2),  X  abc  X  X nd X  c  X  (from atree T 3). From node  X  abc  X , three extensions are generated ( X  a  X ,  X  b  X  X nd X  c  X ) while node  X  ab  X  generates  X  a  X  X nd X  b  X . Nodes  X  a  X  X nd X  c  X  generate extensions  X  a  X  X nd  X  c  X  respectively. Three different candida tes are then obtained by adding each of these extension to the candidate pattern:  X  acdea  X ,  X  acdeb  X  X nd X  acdec  X 
For ordered trees, this method of candidate generation has been shown to be complete as well as non-redundant [3]. However, for unordered trees, it might generate redundant patterns in the form of isomorphic trees. Duplicate can-didates are detected and discarded befo re the candidate extension process by performing a canonical check.
 Itemset Extension. For itemset extension, we use a variation of the method presented by Ayres et al. [4]. W ith this variation, a new item I is added to the itemset associated with the rightmost node of the candidate atree T .Itemsused for itemset extension are derived from the itemset associated with this node in the input database. The constraint is that the new item must be greater than any item associated with the rightmost node of T . 4.2 Frequency Computation We organize our data in a structure storing all information needed for the mining process. Our structure is an extension of the vertical representation of trees introduced by Zaki [24,25]. Briefly, each candidate asubtree is associated with its pattern and several data allowing to pinpoint all its occurrences in the database. The first candidates, composed of a unique node associated with one item, are generated by scanning the input database. Using only this unique structure, it is easy to compute the number of occu rrences of each pattern. In addition, this same structure is sufficient to gener ate all possible extensions of a given pattern. When a pattern of size k is processed, all occurrences are extended with tree extension and itemset extensi on methods described before to generate new ( k + 1)-candidates that are themselves stored in the structure. 4.3 Search Space Exploration Several techniques can be use d to prune the search tree.
 Candidate Pruning. The same rules specified by Agrawal and Srikant twenty years ago [1], can be applied to the case of atrees: i) any sub-pattern of a frequent pattern is frequent, and ii) any super-pattern of a non frequent pattern is non frequent. As the frequency count is an an ti-monotonic function (extending a pattern cannot lead to a new pattern with a greater frequency), is it possible to stop the exploration of a branch when the frequency of a candidate is less than the minimum support. For example, in Fig. 1, during the mining of atrees, when we examine pattern  X  aca  X  and found that its frequency is lower than the minimum support, we do not generate candidates obtained by extending  X  aca  X  (e.g .  X  acab  X ,  X  aca $ b  X ,  X  aca $$ c  X ).
In addition, in the case of unordered tree mining, extension of a candidate is stopped if it is not in canonical form.
 C-closed Atrees Enumeration. By enumerating only atrees that are not contained in another atree with the same support, the search space can be considerably reduced. Enumerating c-clos ed atrees involves the storage of every frequent pattern found with their associated per-tree frequency and their total number of occurrences in the database (the occurrence-match frequency ).
Let T be a candidate atree currently processed, T be the set of all previously identified frequent atrees and X be the set of candidates g enerated by extension of T . We distinguish two subsets of X . X I is the set of atrees generated by itemset extension of T and X T is composed of tree extensions of T . We define two functions: f t which gives the per-tree f requency of an atree and f o which returns its occurence-match frequency.

We say that T is a c-closed atree if  X  T  X  X  U X I such that T I T and f ( T )= f t ( T ). However, finding an itemset extension of T with the same per-tree frequency as T does not allows to stop the exploration of other candidates in X . The following additional conditions must also be satisfied:  X  T  X  X  U X T I T and f o ( T )= f o ( T ).

In Fig. 1, for example, the first candidate to be examined is  X  a  X  X ithaper-tree frequency of 3. By itemset extension, we build X I = {  X  ab  X  ,  X  ac  X  } . Candidate  X  ab  X  has a per-tree frequency of 3, therefore, candidate  X  a  X  is not c-closed as  X  a  X  I  X  ab  X . However, pattern  X  a  X  appears 7 times in the database while the total occurrence of candidate  X  ab  X  is 3. The 4 times where  X  a  X  occurs in an itemset which does not contain  X  b  X  may lead to the generat ion of other patterns that are c-closed. This is the case in Fig. 1 where a right node extension of pattern  X  a  X  generates candidate  X  ae  X  with a per-tree frequency of 3. Closed Atrees Enumeration. We say that T is a a closed atree if  X  T  X  X  U X such that T T and f t ( T )= f t ( T ). The extension of T can be stopped if  X 
T  X  X  U X : T T and f o ( T )= f o ( T ). In addition, one has also to remove non closed trees from T , i.e. all atrees that are asubtrees of T with a same per-tree frequency. The check for closu re requires to perform several subtree isomorphism checks that are costly operations. 4.4 Mining Algorithms Fig. 2 shows the high level structure of the IMIT algorithm. First, a set with all asubtree of size 1 is built by scanning the input database. Then, a loop allows to process every candidate in the set. The function GetFirst return the smallest candidate in the set according to the  X  operator. The processing involves a canonical test and a frequency test. A fr equent candidate which is in canonical form is added to the list of solutions and all of its extensions are added to the list of candidates. The processing of a candidate finishes by removing it from the candidates X  list.

This algorithm is sufficient to enumerate all solutions but it has a huge search space. To limit the redundancies in the set of solutions, we developed IMIT CLOSED, an algorithm extracting closed asubtrees (Fig. 3). As illus-trated in section 5, the algorithm is costly and is not usable to mine large input databases.

We designed IMIT CONTENT CLOSED, a third algorithm extracting c-closed asubtrees. This new algorithm (not shown in this paper) can be easily deduced from the IMIT CLOSED algorithm (Fig. 3) by replacing by I ,re-placing X by X I in line 5 and removing line 11 to 13. The use of I instead of allows to only perform itemsets inclusion tests that are less costly than subtree isomorphism checks. Lines 11 to 13 remove from the set of solutions those that are asubtree of the current candidate. This test is not needed for the extraction of c-closed patterns. Experiments show that this third algorithm is the best compromise between non redundancy of solutions and execution time. All algorithms are implemented in C++ using STL. Experiments were performed on a computer running Ubuntu 12.04 LTS and based on a Intel c Core TM i5-2400 @ 3.10GHz with 8 Gb main memory. All timings are based on total execution time, including all preprocessing and results output. 5.1 Synthetic Datasets We modified the synthetic data generation program proposed by Zaki [24] in order to be able to generate atrees with different size of itemsets. We added two new parameters controlling the minimum and maximum itemset X  X  size. This allows to generate atree with fixed itemset X  X  size or with a size randomly chosen in a range.
 We used the default parameters as in [24] except for the number of subtrees T that is set to 10,000. We build five datasets by varying the size of itemsets. In T10K, all vertices are associated with itemsets of size 1. This allows us to com-pare our implementation with SLEUTH [25]. In T10K-3 and T10K-5, vertices are associated with itemsets of size 3 and 5 respectively. In T10K-1/10, vertices are associated with itemsets of size randomly selected between 1 and 10, while in T10K-1/20, itemsets X  size vary from 1 to 20. 5.2 Web Logs Datasets We built a dataset on logs given by our university following the method described by Zaki [24]. However, instead of labeling nodes with URLs of the browsed pages, we associated them with itemsets re presenting keywords of their content. The dataset is composed of 126,396 attributed trees with itemsets of size 10 (10 keywords by page). 5.3 Performance Evaluation Fig. 4 shows the execution time for mining c-closed sets of induced unordered patterns using IMIT CONTENT CLOSED on our five synthetic datasets. For comparison, we added in the figure the execution time of SLEUTH, a refer-ence implementation of equivalence class extension paradigm [25], on the T10K dataset. IMIT CONTENT CLOSED is about two times slower than SLEUTH for all support values except the sma llest ones where SLEUTH is penalized by the cost of joining millions of frequent patterns.

Although IMIT CONTENT CLOSED is slower than SLEUTH, these results are satisfactory because our algorithm is designed to mine attributed trees. Assuch,itisnormaltoperformworstonm ining labeled trees than dedicated im-plementations. The memory footprint of our algorithm is twice as SLEUTH X  X  one.
The figure also shows that mining attri buted trees is extremely more comput-ing intensive than mining labeled trees; and the difference is largely underesti-mated because only c-closed patterns wer e mined. Mining all patterns generates a huge number of solutions and takes a long time. To give an idea, mining the T10K-3 dataset with a minimum support of 1% outputs 12 millions patterns in 15 hours (Fig. 5). Mining c-closed atrees allows to reduce both the number of patterns and the execution time. Thus, at 1% minimum support, 200 c-closed patterns are found in 4 seconds.

As shown in the same figure, the search for closed patterns allows to reduce further the number of patterns. At 1% minimum support, for example, the num-ber of patterns drops to 103. However, because of the costly subtree isomorphism checks, in return, performances collapse when patterns become numerous. The result is that the difference in computation time increases as the minimum sup-port decreases.

Fig. 6 show the execution time and number of c-closed patterns in the weblogs dataset. This dataset is much larger than synthetic datasets used before and its mining cannot be performed with a minimum support of less than 10% in a reasonable amount of time. Mining the weblog dataset with a minimum support of 6% lasts 6 hours and returns 360 patterns. In this paper, we introduce the problem of mining attributed trees. We investi-gate methods enumerating all frequent patterns or only closed ones, but these methods proved inefficient because of, in the first case, the huge number of pat-terns returned, and in the second case, the cost of subtree isomorphism checks. Finally, we propose a condensed representation of frequent atrees that is de-fined with respect to itemset inclusion. This representation allows to drastically reduce both the number of patterns and the execution time. We evaluate the ef-ficiency of the proposed algorithm, IMIT CONTENT CLOSED, and show that it successfully extract frequent patterns in large datasets. One future work is to extend the proposed algorithm to effect ively mine frequent closed patterns. Another future work consists in developing similar methods for mining more complex structures such as attributed graphs.
 Acknowledgments. This work was funded by French contract ANR-2010-COSI-012 FOSTER.

