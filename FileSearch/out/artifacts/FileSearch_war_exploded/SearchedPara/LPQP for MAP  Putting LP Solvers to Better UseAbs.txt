 Patrick Pletscher pletscher@inf.ethz.ch Sharon Wulff sharon.wulff@inf.ethz.ch Department of Computer Science, ETH Zurich, Switzerland We study the problem of maximum a posteriori (MAP) inference in graphical models. The MAP task is to compute a minimal energy assignment of a set of de-pendent variables. This is a crucial problem in many applications such as computational biology, natural language processing and computer vision. In the gen-eral case, MAP inference is intractable, and therefore most of the current research efforts are concentrated on finding efficient and accurate approximation algo-rithms. In recent years, linear programming (LP) re-laxations gained popularity due to their proven suc-cess in relevant applications. Several efficient algo-rithms have been developed to solve the linear program emerging from the relaxation. Despite their success, in many practical problems the solution attained by the LP relaxations is still far from the global minima. Our work improves over the LP relaxation by lever-aging on a second class of relaxations, namely the quadratic programming (QP) relaxation. The QP for-mulation offers a concise and compact description of the MAP problem. We formulate a joint LP and QP MAP objective, that encourages auxiliary vari-ables present in the LP relaxation, to agree with their counterpart in the QP relaxation, through a penalty function. Despite of the non-convexity of this objec-tive, we show that by slowly increasing the weight of the penalty, the solutions found are either competitive with, or in most cases better than the LP relaxation solutions. This is in general not the case for the few existing QP relaxation solvers.
 We propose two variants of the penalty function, each leading to a different LPQP objective. We show that the resulting non-convex objectives can be de-composed into a difference of convex functions, which we solve using the convex-concave procedure (CCCP). Having tackled the non-convexity with the CCCP, we solve one of the remaining convex problems with the dual decomposition method, and show that the other can be addressed with the norm-product belief propa-gation. Interestingly, the main computational task of both of the resulting LPQP algorithms, turns out to be solving known entropy-augmented LPs.
 Our contributions are as follows: First we introduce a combined LPQP objective, incorporating the QP constraints through a soft penalty function in the ob-jective. We propose two alternatives for the penalty function, which differ in the way the edges in the graph are weighted. Secondly, we derive CCCP based algo-rithms for the LPQP objectives, and show that their core computational effort reduces to current entropy-augmented LP solvers. This demonstrates that these modern LP solvers can in some cases be utilized in a better way, leading to possibly faster convergence, as well as lower energy MAP solutions. Through exper-iments on various datasets, we demonstrate the per-formance of the suggested LPQP MAP inference in comparison to other commonly used solvers.
 For an undirected graph G = ( V , E ), the MAP prob-lem is to assign each node in the graph to a class or category, such that the overall assignment minimizes an associated energy. Let x i denote a discrete variable with a finite domain X i 1 , representing the assignment of the i -th node. The MAP problem is defined as potential functions associated with the node and edge assignments. Problem (1) can be expressed as an in-teger quadratic program using a K -ary coding: min s.t.  X  i ; k  X  X  0 , 1 }  X  i,k and X The pairwise and unary potentials in (2), are repre-sented as a matrix  X  ij and a vector  X  i , respectively. Variational approaches to MAP inference reformulate the combinatorial optimization problem in (1) as a continuous optimization problem. The next sections formally define two such approaches, namely the LP and QP relaxations. In general, the LP minimization results in a lower bound on the energy of the global minimizer, while the QP results in an upper bound. 2.1. Linear Programming Relaxation The LP approach (Schlesinger, 1976; Wainwright &amp; Jordan, 2008) is based on a convex relaxation of (2), where an additional variable  X  ij is included for each edge. Proper local marginalization is enforced through summation constraints. The LP reads as with L G , the local marginal polytope: In the general case, L G is an inexact description of the so called marginal polytope M G , which requires an exponentially large number of constraints (Wainwright &amp; Jordan, 2008). If L G in (3) is replaced by M then the solution recovers the true MAP assignment. A solution to an LP-based approach, admits an easy to verify certificate of optimality. If the solution is integer, it is the global optimum.
 The work in (Sontag et al., 2008) proposes to tighten the polytope by including summation constraints over larger subsets of variables. This approach has been successful in identifying the global minima for some problems. However, it suffers from an increased com-plexity as ultimately an exponentially large set of pos-sible constraints might need to be searched over. 2.2. Quadratic Programming Relaxation An alternative relaxation of the integer quadratic pro-gram in (2) is obtained by simply dropping the integer constraints. The resulting QP is given by: min s.t. 0  X   X  i ; k  X  1  X  i,k and X A major advantage of the QP relaxation, is the fact that it is tight. In this context the tightness means that the minimizer of (4) is also the minimizer of (1), as was shown in (Ravikumar &amp; Lafferty, 2006). The QP also benefits from a more compact description compared to the LP relaxation, as it requires fewer constraints and variables to formulate the exact MAP problem. The variable vector  X  , is of size K  X |V| + K 2  X |E| in the LP (3) and only K  X |V| in the QP. The biggest drawback of the QP relaxation, is that in the general case the optimization problem is non-convex due to the edges product term. This fact renders an exact minimization difficult.
 In terms of motivation, our work is similar to the QP relaxation approach. The QP formulation of the MAP problem (4) was introduced in (Ravikumar &amp; Lafferty, 2006), but stems from classical mean-field approaches. Ravikumar &amp; Lafferty (2006) solved the non-convex problem using a convex relaxation. The solution was later improved in (Kappes &amp; Schnoerr, 2008) through a difference of convex functions formulation. Both solvers are generic in the sense that they do not ex-ploit the graph structure. Recently Kumar &amp; Zilber-stein (2011) introduced a message-passing algorithm for solving the QP relaxation. While improving the run time over the other two algorithms, it still gen-erally suffers from poor solutions due to local min-ima. The QP solvers often deal with this drawback by restarting with different initializations. We observed that our LPQP algorithms, are much more resilient with respect to the initialization. In all of the experi-ments we conducted, a restart was never required. We attribute this behavior to the gradual progression be-tween the LP and QP. Finally, in concurrent work Ku-mar et al. (2012) propose a hybrid LP and QP ap-proach to MAP, similar to our formulation discussed in the next section. The resulting optimization prob-lem is solved by a custom message-passing scheme. Our work on the other hand, in its essence reduces to well-known entropy-augmented LP objectives, for which efficient message-passing algorithms exist. We propose to optimize an objective which is a com-bination of the LP and QP relaxations. We retain the auxiliary variables  X  ij of the pairwise terms, but force these variables to agree with the product of the unary marginals  X  i and  X  j . The constraints, given by vec(  X  i  X  T j ) =  X  ij  X  ( i,j )  X  E 2 , are enforced through a penalty function g (  X  ) incorporated in the objective. The extent to which the constraint is enforced, is reg-ulated by the parameter  X  .
 We focus on the Kullback-Leibler (KL) divergence as the penalty function, due to the probabilistic nature of the compared marginal terms. For probability dis-tributions p and q of a discrete random variable, their KL divergence is defined to be The general form of the combined objective reads as The first term is simply the LP objective (3), written as a scalar product between the potential function, and the concatenated unary and pairwise variables. We investigate two constructions of the penalty term. The constructions differ in the weighting of the edges. Uniform Weighting The KL divergence is penal-ized in the same way for all the edges in the graph: Tree-based Weighting The KL divergence is pe-nalized uniformly within a forest-shaped sub-graph: g We assume that a decomposition of the original graph into acyclic subgraphs exists, and is given by The positive weights  X  a are tree specific, and assumed to sum to one. In this work we simply used  X  a = 1 / |A| . For  X  = 0, (5) amounts to the standard LP relaxation. On the other extreme when  X   X   X  , the constraints vec(  X  i  X  T j ) =  X  ij  X  ( i,j )  X  E are fulfilled and the QP relaxation is recovered. By successively increasing  X  during the run of our algorithms, we achieve a gradual enforcement of the constraints. In this section we derive two algorithms for the non-convex LPQP objective in (5), with the different penalty terms in (6) and (7). 4.1. Difference of Convex Functions (DC) The convex-concave procedure (CCCP) (Yuille &amp; Ran-garajan, 2003), can be applied to a constrained opti-mization problem, where the objective is non-convex, provided that the objective has a decomposition into a convex and a concave part. In our setting, we wish to find a decomposition of the form where both, u  X  (  X  ) and v  X  (  X  ) are convex. The CCCP algorithm proceeds by iteratively solving a convexified objective, obtained by a linearization of v  X  (  X  ): The decompositions of the two objectives, as well as the gradients of the concave part, are shown in Fig-ure 1. In the derivations we used the following identity
D KL (  X  ij , vec(  X  i  X  T j )) = H (  X  i ) + H (  X  j )  X  H (  X  which holds due to the marginalization constraints of the pairwise marginals (Wainwright &amp; Jordan, 2008). For both objectives, the convex part u  X  (  X  ) consists of the original LP formulation, with an additional term that encourages configurations with a large entropy. This term in the uniform weights penalty, is the en-tropy of the pairwise marginals, whereas in the tree-based penalty, it is the sum of tree entropies. The concave part of the decompositions, v  X  , corre-sponds to an entropy of the unary marginals. In the  X   X   X  X
X
X CCCP step (8), log(  X  i ) is replaced by log(  X  t i marginal from the previous iteration, resulting in an entropy approximation. 4.2. Algorithm Overview The general scheme of the suggested LPQP algorithms is shown in Algorithm 1. The algorithm consists of two loops. The inner loop solves the DC problem for a fixed penalty parameter  X  , whereas the outer loop gradually increases the value of  X  .
 Algorithm 1 LPQP algorithm scheme for MAP.
 Require: G = ( V , E ) ,  X  . 1: initialize  X   X  X  G uniform,  X  =  X  0 . 2: repeat 3: t = 0 ,  X  0 =  X  . 4: repeat 6: t = t + 1. 8:  X  =  X  t . 9: increase  X  . 10: until k  X   X   X  0 k 2  X   X  . 11: return  X  .
 The main computational task is in line 5, where a par-ticular instance of a convex optimization problem is solved. Warm-starting the problem in line 5 with the previous solution between successive calls, leads to a substantial speed-up. We choose the initial  X  =  X  0 depending on the scaling of the energies, and use a multiplicative increase with a fixed value. In the ex-periments we use a multiplicative factor of 1 . 5, but the results were not very sensitive to this choice. Solution Rounding Similarly to the LP and QP relaxations, the solutions returned by the LPQP al-gorithms can be fractional. Since the LPQP scheme ultimately solves a variant of the QP relaxation, to at-tain the final integer solutions, we use the QP solution rounding scheme suggested in (Ravikumar &amp; Lafferty, 2006). Given a unary marginals vector  X   X  , we assign the i -th node the label x  X  i given by Here N ( i ) denotes the neighbors of node i . After de-termining the label of the i -th variable, we set  X   X  i ; x and  X   X  i ; k = 0  X  k 6 = x  X  i , and continue until labels are assigned to all nodes. It can be verified that the rounded solution has an energy that is smaller or equal to the energy of the initial solution  X   X  . 4.3. Uniform Weighting The convex sub-problem we get in the CCCP step with the uniform weighting penalty function (6), is given by min where  X   X  i , is a modification of the unary potentials by an additional gradient term, originating in the lin-earized part of the DC decomposition (8) 3 . As a result of this unary potentials modification, con-figurations with small probability in the previous iter-ation t , are vigorously dis-encouraged.
 Belief Propagation The convex problem in (9) is solved by the norm-product belief-propagation (BP) algorithm (Hazan &amp; Shashua, 2010). It is a primal-dual ascent algorithm and is guaranteed to converge to the global optimum for any choice of  X  &gt; 0. The norm-product algorithm applied to (9) computes messages passed from node j to node i as follows  X   X 
X here we define  X  ij ( x i ,x j ) = exp(  X   X  ij ( x i ,x  X  ( x i ) = exp(  X   X   X  i ( x i )). Upon convergence the marginals  X  i are obtained by multiplying the incoming messages at variable i : Due to warm starting with the previous DC iteration solution, typically only few passes through the graph are needed for the messages to converge in the later stages of the run. 4.4. Tree-based Weighting The convex sub-problem corresponding to the CCCP step with the tree-based weighting penalty (7) is, min Where we define the entropy of a tree by
H As before, the linearization of the concave part in the CCCP step, results in a modification of the unaries Dual Decomposition The dual decomposition framework (Bertsekas, 1999; Komodakis et al., 2007), can be applied to an optimization problem provided that the objective can be decomposed into several sub-problems, also known in the literature as the slave problems. The global variables,  X  in our case, are replaced with local copies in each slave problem, de-noted here by  X  a , such that the minimization of the slave problems can be carried out independently. To enforce the local variables corresponding to the same original variables to assume the same value, a desig-nated constraint is introduced. The optimization of the sum of slave problems, subject to these constraints, is called the master problem. A dual decomposition of problem (11), was carried out in (Domke, 2011). We use the same decomposition, but take a different route optimizing the resulting master problem. Where the slave problems are defined as Note that since the summation over the trees now ex-tends to include the unary and pairwise terms, the cor-responding potentials should be adjusted accordingly Each slave problem is defined over a tree structured graph and can therefore be solved exactly using the sum-product algorithm, in two passes over the tree. The temperature in this case is  X  X  a . We solve the dual of the master problem using the FISTA (Beck &amp; Teboulle, 2009) algorithm. A similar solution was demonstrated in (Savchynskyy et al., 2011), on a more restricted decomposition. We refer to the appendix for more technical details. 4.5. Entropy-augmented LP Solvers Recently, several works (Jojic et al., 2010; Savchyn-skyy et al., 2011) proposed to smooth the LP objective by adding a term that favors entropic marginals. The merit of this additional term is in overcoming the non-smoothness of the objective. In order to ultimately solve the original LP, these entropy-augmented solvers progressively lower the entropy term. Naturally, the convergence of these algorithms is fairly fast in the be-ginning. This line of research originates in Nesterov X  X  work on fast gradient methods (Nesterov, 1983). The proposed LPQP solvers have the opposite behav-ior with respect to the smoothness of the objective. The influence of the entropy term is rather increased through the progression of the algorithm, leading to favorable convergence properties. We use LPQP-U to refer to the implementation of the uniform weighting penalty, and LPQP-T for the tree-based weighting. In the experiments where the graph did not have a natural decomposition, we used a depth-first search algorithm to construct a tree decomposi-tion in a greedy fashion for LPQP-T.
 Benchmarked Methods We compare the perfor-mance of LPQP-U and LPQP-T with the widely used MAP algorithms, tree-reweighted belief propagation (TRWS) (Kolmogorov, 2006) and max-product LP (MPLP) (Sontag et al., 2008), both of which are LP relaxations. For both algorithms we used the imple-mentation made available by the authors. These al-gorithms represent different trade-offs in performance. TRWS is a highly efficient message-passing algorithm for the standard LP relaxation. It is much faster than the MPLP, especially on large instances where the MPLP convergence is pretty slow. MPLP on the other hand, initially solves the LP relaxation over the local polytope, and in later iterations includes additional summation constraints over sets of three or four vari-ables. This strategy naturally leads to lower (better) energy solutions, on instances where the LP relaxation is not tight. The MPLP was shown to identify the global optimum for some problems.
 Performance Measures In this work we mainly compared the quality of the solutions, which in the MAP setting is most naturally measured by the en-ergy associated with an assignment (1). Strictly com-paring energy values is problematic for two reasons. The values lack proper scaling required for quantita-tive comparison of different results on the same prob-lem instance, and are not comparable across instances. We therefore exercise the following scoring procedure. Let e 1 ,...,e J denote the energies of the compared so-lutions, we set as the score of the i -th method. This scheme assigns the worst and the best methods, scores of zero and one respectively. The remaining methods get a fraction relative to their value between the best and the worst result. This procedure is not flawless since the scores are still computed relative to the worst energies. It was most often the case though, that TRWS was the lowest scoring method. Being an often used algorithm with provable merits, using it as a normalizing measure is in our opinion a sensible choice. In experiments where the optimal value is known, we use this value instead of min 1  X  j  X  J e j . In addition to comparing the quality of the solution, we comment about the trends in the efficiency (run-time) of the various methods. 5.1. Synthetic Potts Model Data We follow a similar experimental setup as in (Raviku-mar et al., 2010). The graph is a 4-nearest neigh-bor grid of varying size. We used M = 60 , 90 , 120 where M is the grid side-length, and M 2 is the over-all number of variables. We used K = 2 and K = 5 for the number of states. The unary potentials were randomly set to  X  i ; k ( x i )  X  Uniform (  X   X , X  ), and for  X  we used values in [0 . 05 , 0 . 5]. Note that the prob-lem instance gets harder for small values of  X  , this pa-rameter can be understood as the signal-to-noise ratio. The pairwise potentials  X  ij ( x i ,x j ), were set to penal-ize agreements or disagreements of the labels, by an amount  X  ij  X  Uniform (  X  1 , 1), chosen at random. We experiment we choose the graph decomposition for the LPQP-T solution as the vertical and horizontal split of the grid edges. The two trees have all the original nodes in common, but no overlapping edges.
 The results of the comparison using the performance measure given in (14), are presented in Table 1. For each choice of parameters, we averaged the scores of 5 runs. Furthermore, Figure 2 shows the progress of the objective during a run of the LPQP-U algorithm. In terms of running time, TRWS was always first to output a solution, followed by the LPQP algorithms. MPLP was always slower and on the larger instances did not converge within a predefined maximal time. We therefore restricted the number of tightening iter-ations of MPLP to a maximum of 1000. A tightening iteration includes additional constraints into the lo-cal marginal polytope. Even after this change, MPLP was still considerably slower than the other algorithms. Between the LPQP algorithms, the LPQP-U was most often faster than LPQP-T.
 As we expect, TRWS returned the worst assignment on almost all configurations. The energies obtained by LPQP-U, LPQP-T and MPLP were in general very close. We observe that both of the LPQP algorithms, returned slightly better solutions in comparison to the MPLP, when the potentials were sampled with lower signal-to-noise ratio  X  .
 The run time of LPQP-T seems to be mostly influ-enced by the structure of the decomposition. In later experiments where the decomposition consisted of a larger number of trees with more variables in com-mon, the LPQP-T was significantly slower compared to the LPQP-U. In terms of the energy of the solu-tions, the two algorithms were very similar. For this reason we report from now on the LPQP-U only. The LPQP-T can still be beneficial in settings where the computations are done on a distributed system. 5.2. Protein Design &amp; Prediction The protein inference problem discussed in (Yanover et al., 2006), consists of two tasks: protein side-chain prediction and protein design. For the protein predic-tion task, it was shown in (Yanover et al., 2006) that only for 30 out of the 370 protein prediction instances, the LP relaxation is not tight. For 28 of them, the true MAP was computed using general integer pro-gramming techniques, Figure 3 visualizes the results on these instances. The LPQP found the global min-imum of roughly 2 / 3 of these more difficult instances. On the remaining 340 instances, the LP is tight. The LPQP found the global optimum in all but three cases (results are not shown). MPLP was applied to this task in (Sontag et al., 2008), and achieved the global optimum on all instances.
 The protein design task consists of 97 instances. We used MPLP to compute the global optimum, but for one of the instances, MPLP did not finish within a time-budget of 7 days. The average scores for the re-maining 96 instances are as follows. LPQP-U: 0 . 93, MPLP: 1 and TRWS: 0 . 03. The average energies are: LPQP-U:  X  184 . 06, MPLP:  X  184 . 60, TRWS:  X  173 . 55. The QP message-passing algorithm in (Kumar &amp; Zil-berstein, 2011), was tested on this task as well. The evaluation criteria used in this work was the average (across the 97 instances) percentage of the optimal value. While the reported average value in (Kumar &amp; Zilberstein, 2011) is 97 . 7%, our solution achieves 99 . 7% percentage of the optimal value on average. 5.3. Decision Tree Fields As a last experiment we apply our LPQP algorithm to the recently published  X  X ard discrete energy min-imization instances X  dataset (Nowozin et al., 2011), available on the authors webpage. The task is to fill in, or inpaint, a blanked out area in a binary image of Chinese handwritten characters, see Figure 4. The dataset consists of 100 energy minimization instances, and comes with approximate MAP solutions obtained using simulated annealing (SA) inference, which was found to work better than TRWS. For 43 instances the LPQP algorithm obtained better solutions than the previously best known solutions. Figure 4 visual-izes some of the instances where the LPQP algorithm leads to a better solution. We observed that the SA so-lutions seem to hallucinate too much regularity which is not supported by the underlying energy. The scoring of the three algorithms is as follows. LPQP-U: 0 . 84, SA: 0 . 74 and TRWS: 0 . 21. We failed to apply MPLP as the tightening operation did not succeed. We introduce a novel formulation for MAP inference in graphical models, combining the LP and QP relax-ation terms through a KL divergence measure. The resulting problem, albeit being non-convex, gives rise to efficient algorithms built upon known LP solvers. We would like to thank Joachim Buhmann, Andreas Krause, Cheng Soon Ong and Christian Sigg for in-sightful discussions. The work was partially supported by the NCCR-MICS, a the Swiss National Science Foundation center, under grant #51NF40-111400. Beck, A and Teboulle, M. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences , 2(1), 2009. Bertsekas, D P. Nonlinear Programming . Athena Sci-entific, Belmont, MA, 1999.
 Domke, J. Dual decomposition for marginal inference. In AAAI , 2011.
 Hazan, T and Shashua, A. Norm-product belief prop-agation: Primal-dual message-passing for approxi-mate inference. IEEE TIT , 56(12):6294 X 6316, 2010. Jojic, V, Gould, S, and Koller, D. Accelerated dual decomposition for MAP inference. In ICML , 2010. Kappes, J and Schnoerr, C. MAP-Inference for Highly-Connected Graphs with DC-Programming. In DAGM , 2008.
 Kolmogorov, V. Convergent tree-reweighted message passing for energy minimization. PAMI , 2006.
 Komodakis, N, Paragios, N, and Tziritas, G. MRF op-timization via dual decomposition: Message-passing revisited. In In ICCV , 2007.
 Kumar, A and Zilberstein, S. Message-Passing Algo-rithms for Quadratic Programming Formulations of MAP Estimation. In UAI , 2011.
 Kumar, A, Zilberstein, S, and Toussaint, M. Message-Passing Algorithms for MAP Estimation Using DC Programming. In AISTATS , 2012.
 Nesterov, Y. A method of solving a convex program-ming problem with convergence rate o (1 /k 2 ). Soviet. Math. Dokl. , 27:372 X 376, 1983.
 Nowozin, S, Rother, C, Bagon, S, Sharp, T, Yao, B, and Kohli, P. Decision tree fields. In ICCV , pp. 1668 X 1675, 2011.
 Ravikumar, P and Lafferty, J. Quadratic Program-ming Relaxations for Metric Labeling and Markov Random Field MAP Estimation. In ICML , 2006.
 Ravikumar, P, Agarwal, A, and Wainwright, M J.
Message-passing for graph-structured linear pro-grams: Proximal methods and rounding schemes. J. Mach. Learn. Res. , 11:1043 X 1080, 2010.
 Savchynskyy, B, Kappes, J H, Schmidt, S, and Schn  X orr, C. A study of Nesterov X  X  scheme for Lagrangian decomposition and MAP labeling. In CVPR , pp. 1817 X 1823, 2011.
 Schlesinger, M I. Syntactic analysis of two-dimensional visual signals in noisy conditions. Kibernetika , 4: 113 X 130, 1976.
 Sontag, D, Meltzer, T, Globerson, A, Weiss, Y, and
Jaakkola, T. Tightening LP relaxations for MAP using message-passing. In UAI , pp. 503 X 510, 2008. Wainwright, M J and Jordan, M I. Graphical Mod-els, Exponential Families, and Variational Infer-ence . 2008.
 Yanover, C, Meltzer, T, and Weiss, Y. Linear pro-gramming relaxations and belief propagation  X  an empirical study. JMLR , 2006.
 Yuille, A L and Rangarajan, A. The concave-convex
