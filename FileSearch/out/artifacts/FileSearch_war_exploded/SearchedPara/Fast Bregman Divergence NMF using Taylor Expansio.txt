 Non-negative matrix factorization (NMF) provides a lower rank approximation of a matrix. Due to nonnegativity im-posed on the factors, it gives a latent structure that is often more physically meaningful than other lower rank approxi-mations such as singular value decomposition (SVD). Most of the algorithms proposed in literature for NMF have been based on minimizing the Frobenius norm. This is partly due to the fact that the minimization problem based on the Frobenius norm provides much more flexibility in alge-braic manipulation than other divergences. In this paper we propose a fast NMF algorithm that is applicable to general Bregman divergences. Through Taylor series expansion of the Bregman divergences, we reveal a relationship between Bregman divergences and Euclidean distance. This key rela-tionship provides a new direction for NMF algorithms with general Bregman divergences when combined with the scalar block coordinate descent method. The proposed algorithm generalizes several recently proposed methods for computa-tion of NMF with Bregman divergences and is computation-ally faster than existing alternatives. We demonstrate the effectiveness of our approach with experiments conducted on artificial as well as real world data.
 I.2.6 [ Artificial Intelligence ]: Learning; G.1.6 [ Numerical Analysis ]: Optimization Algorithms, Experimentation, Performance Non-negative Matrix Factorization, Bregman Divergences, Euclidean distance, Taylor Series Expansion
Non-negative matrix factorization (NMF) is a dimension-ality reduction method that has attracted great attention over a decade. It approximates a matrix A by a product of two lower rank matrices W and H with non-negative entries minimizing the divergence between A and WH T . Using Bregman divergences, our problem is to find where D  X  ( A k WH T ) denotes a Bregman divergence between A and WH T . The decomposition discovers a latent struc-ture in the data and is useful in signal processing, collabora-tive filtering, clustering, and other data-mining tasks. Due to the non-negativity constraint on W and H , NMF discov-ers a latent structure that is often more interpretable than SVD based factorizations.

Various Bregman divergences, such as Frobenius norm and KL divergence, have been used in a wide range of appli-cations, including text clustering, signal processing, image processing, and music analysis. A general NMF algorithm for various Bregman divergences not only offers a general so-lution for different applications, but also enables the knowl-edge share across different domains. Recent years have seen a surge of interest in NMF [25, 7, 22, 20]. The earliest NMF algorithms aimed at directly optimizing the divergence, re-sulting in higher scale computational costs. Moreover, most algorithms have been developed for Frobenius norm(which becomes the Euclidean distance for scalars) minimization, a popular special case of the Bregman divergence.

Lee and Seung X  X  simple multiplicative update rule [25] has been one of the most utilized method for NMF over a decade, for both Frobenius norm and KL(Kullback-Leibler) diver-gence. Dhillon et al. [8] extended it to solve NMF with general Bregman divergences. By using an auxiliary func-tion, Fevotte et al. [11] discussed the updating rule under the IS divergence, and applied it to music analysis. An alter-native updating rule is also provided based on the statistical interpretation of the properties of the IS divergence. Nev-ertheless, the above algorithms generally suffer from high computational cost and slow convergence [23].

Cichocki et al. [5] introduced an alternative algorithm with improved local updating rules, achieving high efficiency in solving NMF problems. The resulting algorithm applies to the Frobenius norm. Similar algorithms have been pro-posed for a few other divergences, but these algorithms show a relatively slow convergence.

Other NMF algorithms are proposed by Lin et al. [27] us-ing projected gradient with Armijo rule to build the updat-ing rule. Kim and Park [19, 20] proposed an NMF algorithm based on alternating non-negative least squares (ANLS) and an active set based algorithm. This algorithm was further improved by block principal pivoting in ANLS. An exten-s ive comparison of these algorithms appears in [22, 23]. For a survey of NMF algorithms, see [21].

In this paper, we propose a fast NMF algorithm for a gen-eral class of Bregman divergences. Using Taylor series we relate Bregman divergences to the Euclidean distance and show that the Bregman divergence optimization problem can be expressed in terms of the Euclidean distance. The discov-ered relationship between Bregman divergence and the Eu-clidean distance leads to local updating rules, and provides one efficient algorithmic framework which is applicable to NMF formulated in Bregman divergences, and solutions for a wide range of applications.

We investigate the performance of the new algorithm on both artificial and real world data sets, including Xspectra [6], AT&amp;T Laboratory Face Image data set [1], Movielens, and Netflix. We conduct a series of experiments comparing our proposed methods to previously proposed algorithms. Our experiments show that for a wide range of Bregman divergences our new algorithm is substantially faster.
Our main contributions in this paper include 1. a new relationship connecting Bregman divergences 2. an NMF algorithm applicable for all Bregman diver-
Note that by relating all Bregman divergences to the Eu-clidean distance, we propose one united highly efficient al-gorithm applicable for all NMF formulated in any Bregman divergences. In contrast, most other existing algorithms are designed for one or only a subset of Bregman divergences.
Table 1 summarizes the notations used in this paper.
In NMF, given a matrix A = [ a ij ]  X  R M  X  N + , and an inte-ger K  X  min( M, N ), we are to find W = [ w 1 , w 2 , . . . , w R + whose columns represent basis vectors in a K -dimensional space, and H = [ h 1 , h 2 , . . . , h K ]  X  R N  X  K + whose columns represent mixing proportions, such that The quality of this approximation can be measured using Bregman divergences, where  X  is a univariate convex smooth function.

Bregman divergences are not symmetric in general, and the solution for min D  X  ( WH T k A ) will be different from that of min D  X  ( A k WH T ). In this paper, we focus on D  X  ( A k WH T ) which is more widely used in applications. For instance, Probabilistic Latent Semantic Analysis (PLSI) [16], a statis-tical technique for data analysis, optimizes the same objec-tive function as NMF with Kullback-Leibler divergence [9]. Other examples are signal analysis using D KL ( A || WH T ) and music analysis using Itakura-Saito divergence D IS ( A || WH T ) . From a theoretical perspective, maximum likelihood estima-tion and information theory indicate that D KL ( A || WH T is better motivated than D KL ( WH T || A ), at least when the two arguments are probability vectors.
 The choice of  X  ( x ) = x 2 / 2 reduces D  X  to the squared Frobenius norm of E = A  X  WH T , which is the sum of squared entries of the residual matrix E (Notice that the Frobenius norm of a matrix can be viewed as the Euclidean distance of the corresponding vectorized matrix). Other choices for  X  result in the non-negative Kullback-Leibler (KL) divergence or Itakura-Saito (IS) divergence. The spe-cific choice of  X  depends on the application. For example, the Frobenius norm has been used successfully in text clus-tering [3]. KL divergence is well suited for many problems in signal processing [5] while IS divergence has been shown to perform well in music recommendation [11]. For other choices of  X  and areas where these divergences are ultilized, see [7].

In [2], Bregman divergences have been used to derive an exact characterization of the difference between the two sides of Jensen X  X  inequality. Banerjee et al. [3] discussed a cluster-ing algorithm for general Bregman divergences. They also showed that there exists a bijection between regular expo-nential families and large classes of Bregman divergences. Singh and Gordon [31] showed that methods such as NMF, Weighted SVD, pLSI can be viewed in a general framework of matrix factorization with Bregman divergences. Pietra et al. [30] derived and proved convergence of iterative al-gorithms to minimize Bregman divergence subject to linear constraints based on auxiliary functions. Wang and Schu-urmans [32] proposed a novel algorithm that extracts hid-den latent structure by minimizing Bregman divergences. Lebanon [24] used Taylor series approximation to show a re-lationship between KL divergences and the Fisher geometry which enjoys certain axiomatic properties.

Some examples of Bregman divergences and the corre-sponding  X  functions are listed in Table 2.
Many existing NMF algorithms can be explained using the block coordinate descent framework [21]. Different par-titions of variables W and H lead to different NMF algo-rithms. One natural way of partition [8, 19, 22] is the two blocks representing W and H , with which the subproblems result in a nonnegativity constrained least square (NLS) problem. Another way of partition [5, 14] is K ( M + N ) blocks where each represents a single element in W or H .
Coordinate descent is also employed to solve many other problems. Wu et al. [33] came up with coordinate descent algorithm for l 1 regularized regression, Lasso. A greedy co-ordinate descent method was proposed in [26] to solve the Basis Pursuit problem, and can be applied to tasks such as compressed sensing and image denoising. Yun and Toh [34] proposed a block coordinate gradient descent method for general l 1 -regularized convex minimization problems. Re-cently, a fast coordinate descent algorithm was developed in [13] to estimate generalized linear models with convex penalties. Coordinate descent was also used for solving non-convex penalty functions, such as smoothly clipped absolute deviation (SCAD) penalty and the minimax concave penalty (MCP) in [4].

We denote the residual term in the NMF approximation (1) as A  X  WH T = A ( k )  X  w k h T k , where the k -residual A is define as for k = 1 , . . . , K . In the case of  X  ( x ) = 1 2 x 2 , D squared Frobenius norm Let us define which is the t -th power of t-norm distance between vector-ized matrices A and A 0 . Then we have
Cichocki et al. [5] proposed an algorithm called Hier-archical Alternating Least Squares ( HALS ) for NMF with Frobenius norm. They designed local updating rules based on the relationship in Eqn (2), leading to a fast algorithm. Each updating step solves a sub-optimization problem with a closed form solution, and the algorithm converges much faster than the multiplicative updating rule in [25, 8]. Al-though similar algorithms for Alpha divergence and Beta divergence have been proposed, they aimed at minimizing D  X  ( A ( k ) k w k h T k ) instead of D  X  ( A k WH T ), which are two different functions for most Bregman divergences other than the Frobenius norm.

In this paper, using the relationship in Eqn (3), the opti-mization goal changes from the approximation between the given matrix and the multiplication of two low-rank matri-ces to the approximation between the k -residual matrix and the multiplication of two vectors. Since elements in w k (or h ) can be computed independently, we actually focus on the approximation between a ( k ) ij (single element in k -residual matrix) and the multiplication of w ik and h jk . Based on this observation, a novel scalar coordinate descent algorithm with k ( m + n ) scalar blocks can be designed. In the rest of this section, we will
The following proposition shows a new relationship be-tween Bregman divergences and the Euclidean distance, which plays a key role in our fast algorithm development. Proposition 3.1.
 Proof. The Taylor expansion of D  X  ( a ij k a 0 ij ) leads to D  X  ( a ij k a 0 ij ) =  X  ( a ij )  X   X  ( a 0 ij )  X  X  X   X  ( a 0 where  X  t  X  ( a 0 ij ) is the t -order derivative of  X  at a
The above relationship is then employed to replace our ob jective function D  X  ( A k WH T ) with an expression that show how this relationship allows us to recast the problem in a form that is easier to solve and leads to a novel and efficient algorithm. Notice that this relationship is an equality rather than an approximation.

Taylor expansion has been utilized in numerical prob-lems including a quadratic approximation of the objective or loss function. For instance, to solve a regularized log-determinant program, Hsieh et al. [18] proposed a novel al-gorithm which is based on Newton X  X  method and employs a quadratic approximation. For the l 1 -regularized linear least squares problem, a gradient projection method was proposed in [12] to solve the bound constrained quadratic program-ming reformulation. Yun. et al [34] went a step further by using quadratic approximation to solve the general l 1 regularized convex minimization problem. In each iteration, the objective is replaced by a strictly convex quadratic ap-proximation, then block coordinate descent is used to obtain a feasible descent direction. Taylor explansion was also em-ployed to approximate non-convex penalties, such as SCAD [10] and MCP [29]. Based on Eqns (3) and (4) , the Bregman divergences D  X  ( A k WH T ) can be expressed in terms E t ( a ( k ) ij as Instead of calculating the partial derivatives of D  X  ( A k WH with respect to W and H , we turn to the partial derivative of E ( a ( k ) ij k w ik h jk ) with respect to smaller blocks, w Using this and the scalar block coordinate descent frame-work in constrained optimization where each block consists of a single unknown element in W or H ( assuming other elements are fixed), a novel fast algorithm can be derived.
From and Eqn (4), we obtain Summing over the matrix rows and columns, we have 1
The solution for the scalar block h jk can be obtained by solving: which leads to the element-wise updating rule: Similarly, we can derive an updating rule for w ik .
The summary of the algorithm, which we refer to as sBCD (Scalar Block Coordinate Descent) is shown in Algorithm 1 Note that the algorithm follows the block coordinate descent framework where each element in W and H is considered as a scalar block that we update in each step.
 The algorithm above is expressed in a general form for all Bregman divergences. Replacing  X  ( x ) with the correspond-ing expression provides the specific algorithm for each spe-cific Bregman divergence. Interestingly, for squared Frobe-nius norm, the updating rule is precisely the same as HALS algorithm proposed in [5]. Some specific updating rules are listed in Table 2.

The following rearrangements of expressions show an in-teresting relationship between sBCD and two other NMF al-gorithms, Multiplcative Updating and Gradient Descent methods. According to Eqns (5) and (6), we have d efinition of can be found in Table 1. [ x ] + = max { x, 0 } .
 Algorithm 1 sBCD A lgorithm 1: Given A  X  R M  X  N , a reduced dimension K , and function 2: A 0 = WH T 3: E = A  X  A 0 4: repeat 5: B =  X  2  X  ( A 0 ) 6: for k = 1 , 2 , . . . , K do 8: for j = 1 , 2 , . . . , N do 10: end for 11: for i = 1 , 2 , . . . , M do 13: end for 15: end for 16: A 0 = WH T 17: until stopping criterion is reached constraint is enforced to ensure h jk to be nonnegative.
On the other hand, multiplicative updating rule proposed in [25] can be written as:
A gradient descent algorithm for NMF is also proposed in [25], which uses a fixed step size. With the above rearrange-ments of expressions, we can see that the difference between sBCD , Multiplicative Updating and Gradient Descent is the step sizes only. The advantage of sBCD and Multiplica-tive Updating over Gradient Descent is that they choose step sizes according to the result of previous iteration. Fur-ther comparsion of step sizes of sBCD and Multiplicative Updating shows that
The above equation illustrates that Multiplicative Up-dating uses a conservative step size in order to keep the update result nonnegative, while a longer step is used by sBCD to make each updating more efficient.
An important variation of NMF is the NMF subject to sparsity constraints [19] on one or both factors. For imposing sparsity on H , the objective function is replaced with the following penalized version: 3
N otice in implementation, regularization term k W k F is added to prevent it from growing too large. where  X  i s regularization paramter. Although k X k 1 is not differentiable in general, in NMF it is differentiable in the specific domain due to the condition that H is non-negative.
The corresponding sBCD updating rule is
Sparsity on W can be imposed in an analogous way.
The experiments are conducted on artificial and real world data sets. The randomly generated data sets have prob-lem sizes ( M, N, K ) = (2000 , 1000 , 30), (2000 , 1000 , 60), and (3000 , 2000 , 30). The initial matrices for W and H were gen-erated with uniform random values in [0.5, 1.5]. To remove sampling noise we average results using 5 different initial values. Our first real world data set follows the Xspectra setup in [6]. A matrix of size 1000  X  10 is formed by using ten noisy mixtures of five smooth sources. Mixed signals are corrupted by additive Guassian noise. For this data set, the ground-truth factors are provided, enabling the testing of al-gorithms X  accuracy in recovering factors. A larger real world data set is the AT&amp;T face image data set [1]. This data set contains 400 facial images (10 images of each of 40 different people) with a single facial image containing 92  X  112 pix-els in 8-bit grey level. The resulting data matrix is of size 10304  X  400. Movielens data set with rating matrix of size 71567  X  65133 is also used, The largest data set is Netflix with a sparse rating matrix of size 480189  X  17770. We employ two types of metrics, Bregman divergences D  X  ( A k WH T ) and Signal to Interference Ratio( SIR ) [5].
SIR is a commonly used metric in signal processing. We employ it here to judge how well the computed factors W and H match the ground-truth. Denoting the ground-truth as  X  W and  X  H , the values of SIR for W is calculated as: w here w k and  X  w k are normalized to have unit L 2 norm. SIR for H is computed analogously.
In our experiments we use four Bregman divergences: Frobe-nius, KL, IS and Beta (  X  = 2) divergences. Our algorithm is compared to the following three methods for NMF using specific subset of Bregman divergences: Conjugate gradient(CG) : This approach is based on the BlockPivot : This algorithm [22] is also based on the alter-GCD/CCD : A coordinate descent algorithm called Greedy Co-and the following methods which are designed for NMF for-mulating using general Bregman divergences: Multiplicative updating : This approach uses the multi-Gradient descent : This algorithm [25] calculates the first sBCD : Our proposed approach. The code is available at
Table 3 shows above approaches X  applicability to differ-ent divergences. For each specific divergence, not all listed approaches are compared since some of them may be not applicable. Therefore, for each case we conduct a separate series of experiments.

Figure 1 and 3 compare the performance of our approach with others measured by D  X  ( A k WH T ). In general, Mul-tiplicative updating converges relatively slow compared to others, but often find a good solution. For real world data, Gradient descent performs poorly. Multiplicative updating performs better than Gradient descent . F igure 2: Performance of NMF with various Breg-man Divergences
This experiment is conducted on 5 smooth data set where the problem size is ( M, N, K ) = (1000 , 10 , 5). In the figures of the first row, the y axis measures SIR( W ,  X  W ); in the figures of the second row, the y axis measures SIR( H ,  X 
For Frobenius norm, CG can reach better solutions than the above two, but requires huge computational cost. Block-Pivot performs better than CG , significantly reducing the computational cost by using block pvioting scheme to speed up the process of finding optimal solution. Our approach performs better than all others expect GCD . For KL diver-gence, CCD is only slightly better than sBCD . The difference is much smaller than the difference between GCD and sBCD under Frobenius norm. Although our approach does not outperform GCD and CCD , we must notice that GCD targets at solving NMF with Frobenius norm only, while CCD targets at KL divergence only. On the other hand, our approach pro-vides a general solution to NMF with Bregman divergences.
For IS and Beta divergences, our approach performs better than all other compared approaches, in both artificial and real world data. Its convergence behavior and the solution to the factorization is the best among all the approaches.
When handling large real world data sets, we notice that the performance curve of the above algorithms was not nec-essarily so smooth. However, the advantage of sBCD and CCD over Multiplicative updating and Gradient descent is still very significant, especially at the first several itera-tions. The more sparse A is, the greater improvement sBCD can obtain over the others.
 Table 4: Performance for various reduced ranks The table shows the time and iteration numbers needed for convergences under both IS and Beta divergence. The input matrix is of size 2000  X  1500 and the convergence relative decrease in residual values, where  X  D  X  ( A k WH is the absolute difference of D  X  ( A k WH T ) between two
Figure 2 compares the performance of our approach with t he other algorithms and the performance is measured by SIR . It illustrates that sBCD and CCD can recover the ground-truth factors  X  W and  X  H much better than Multiplicative updating and Gradient descent . The results from Figure 2  X 
H can be recovered much better than  X  W . This may due to the fact that  X  H is given signal matrix while  X  W is generated randomly.
 The following experiments evaluate how the variation of K influences the performance. From Table 4 we can see that our algorithm has a significant advantage in conver-gence behavior over the other two approaches. The advan-tage becomes greater with the increase of K . For sBCD , the number of iterations needed for convergence increases very slowly, while there is a sharp increase in the case of Multi-plicative updating and Gradient descent .
In sBCD , the computation of the term  X  2  X  ( a 0 ij ) may be costly, since a 0 ij varies in each iteration. To address this is-sue, we also consider the following two alternative updating rules which can, in some cases, provide additional computa-tional savings. Performance comparison of sBCD and those two variations is shown in Figure 4.
As shown in Figure 4, in most cases, sBCD-AL-A gi ves the slowest convergence and the worst solution. sBCD converges faster and obtains a better solution than sBCD-AL-B . sBCD also performs better consistently. The nature of A and the  X  may decide how well the alternative updating rules approx-imate sBCD . For example, in IS divergence, sBCD gains an impressive advantage over the other two algorithms. How-ever, in a few cases(especially the signal data), the difference among the three algorithms is not significant. This indicates that the two alternative algorithms may be more suitable for certain real world applications due to their simplicity in im-plementation and relatively lower storage cost. F igure 3: Performance of NMF with various Breg-man Divergences on Large Scale Data
The y axis measures the logarithm of the relative residual value. ( M, N, K ) values are Face Image: (10304 , 400 , 20), Movielens: (71567 , 65133 , 20), Netflix: (480189 , 17770 , 20).
For NMF with additional constraints, due to lack of space we only report here the result for the KL-divergence case when imposing sparsity constraint on H only. Figure 5 shows that with even with constraints added, the relative trends of our three proposed algorithms remain the same.
Here we choose text summarization as the application task, and conduct experiments to explore how different di-vergences can affect the topic generation. In this applica-tion, a document-text matrix is first built to describe the corpus. The matrix is then factorized by our proposed NMF algorithms to analyze the topic distribution over the corpus. Finally, the obtained document-topic matrix is used as fea-tures in model training for text summarization. We expect stronger features obtained from this NMF process.
The DUC2001 data set is used for evaluation in this series of experiments. It contains around 147 summary-document pairs. The respective ground-truth summaries are generated by manually extracting a certain number of sentences from each single document. A 10-fold cross validation process is employed in the experiments. Structural SVM algorithm is used for model training and prediction. For evaluation, we employ the ROUGE metric 4 [28].
F or details, see http://berouge.com/default.aspx. (a) KL, 1500*1000, K = 30 F igure 4: Comparison of Our Three Proposed Algo-rithms (a) KL, 1500*1000, K = 30
Table 5 shows that when divergence is KL, a best summa-rization model can be trained. Using Frobenius norm also leads to a comparable result. When divergence is IS or Beta, the summary prediction is relatively inaccurate. Thus, we can conclude that, in text topic analysis, using the NMF with Frobenius norm and KL divergence is more suitable than IS divergence and Beta divergence. The above results also illustrate that stronger features extracted from NMF contribute to a better summarization model.
In this paper, a novel fast algorithm named sBCD is pro-posed to solve the NMF with Bregman divergences. The algorithm is designed by deriving an equivalent optimiza-tion problem involving the Euclidean distance. A local up-dating rule is obtained by setting the gradient of the new objective function to zero with respect to each element of the two matrix factors. Experimental results demonstrate the effectiveness of our approach.

The relationship that we derive between Bregman diver-gences and the Euclidean distance is new. In addition to leading to our updating rule, this connection may be used in other data mining algorithms based on Bregman diver-gences, such as K-means, SVM. Table 5: Performance of Text Summarization Using N MF with Different Divergences
W e are very grateful to the editor and anonymous review-ers for valuable comments and suggestions based on which we were able to improve the manuscript substantially. The work of the first and third authors were supported in part by the National Science Foundation grants CCF-0732318 and CCF-0808863.
