 H.3.3 [ Information Systems ]: Information Search and Retrieval. Algorithms, Experimentation. Mining, Named Entities, Named Entity Translation Equivalents, Cross-Language Information Retrieval, Comparable Corpora. Named Entities (NEs) form a significant fraction of query terms in Information Retrieval (IR) systems and have a substantial impact on their retrieval performance. NEs are even more important in Cross Language Information Retrieval (CLIR), as in addition to being a significant component of query terms, any errors in their translations act as noise affecting adversely the retrieval performance (Mandl and Womser-Hacker, 2005, Xu and Weischedel, 2005). From the resource side for CLIR, bilingual dictionaries typically offer only limited support as they do not have sufficient coverage of NEs, as new NEs are introduced to the vocabulary of a language every day. On the other hand, machine transliteration systems often produce misspelled or incorrect transliterations affecting the CLIR retrieval performance. In recent times, the large quantity and the perpetual availability of news corpora in many of the world X  X  languages simultaneously, have spurred interest in a promising alternative to NE translation or transliteration, namely, the mining of Named Entity Transliteration Equivalents (NETEs) from such news corpora (Klementiev and Roth, 2006; Tao et al., 2006). Formally, comparable news corpora are time-aligned news stories in a pair of languages from a reasonably long period in time. NETEs mined from comparable news corpora could be valuable in many tasks such as CLIR and MT, to effectively complement the bilingual dictionaries and the machine transliteration systems. This opportunity is precisely what we address in our work. We introduce a novel method, called MINT ( MI ning N amed-entity T ransliteration equivalents), with the following innovations for effective mining of NETEs from comparable corpora: In the first stage of the MINT method, documents fr om the comparable corpora ( C S , C T ) in languages S and T are compared for content similarity to produce a collection A S,T of article pairs, namely ( D S , D T ), that have similar content. The cross-language document similarity model uses negative KL-divergen ce between the source and target document probability distribu tions, and measures the similarity between a given pair of doc uments. Given two documents D S , D T in source and target languages respectively, the cross-language document similarity between the two documents is given by The second stage of the MINT method works on each p air of consisting of (  X  S ,  X  T ) that are transliteration equivalents. The transliteration similarity between  X  S and  X  T , is measured by the transliteration similarity model employing a logist ic function, that captures cross-language associations for the p air (  X  S ,  X  T ) (such as, the character sequences, couplings of substring s, monotonicity of alignment, lengths, etc.) and w is the weights vector, which is learnt discriminatively over a corpus of known tran sliterations. Our empirical investigation consists of experiments in three data environments, each with a different focus: 1. IDEAL: An environment to measure the effectiveness of 2. NEAR-IDEAL: An environment in which articles are al igned 3. REAL: An environment in which NETEs are mined from The test bed for evaluating the IDEAL data environm ent consisted of 200 articles from a corpus consisting of ~2500 p airs of aligned articles. In NEAR-IDEAL, the same corpus without t he pairing information was used. Finally, in REAL data enviro nment, a test bed of 100 articles from a corpus of ~200K publishe d articles in a pair of languages was used. Table 1 provides the M ean Reciprocal Rank (MRR) of the mined NETE in each of the three environments. We implemented a baseline system, Co Ranking, along the lines of (Klementiev and Roth, 2006). We extracted NEs from the English articles using Stanford named entity recognizer (Finkel et al., 2005). 
