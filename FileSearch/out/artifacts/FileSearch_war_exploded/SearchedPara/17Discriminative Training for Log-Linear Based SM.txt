 Statistical methods have been the dominant methods for machine translation, espe-cially since [Och and Ney 2002] introduced the log-linear model for statistical machine translation (SMT), in which a weight has to be specified to measure the contributions from each feature function. The aim of discriminative training or tuning weight on a given development set, such that its testing performance is optimal with respect to the desired evaluation criteria. Discriminative training is one of the most important components in SMT, and various training methods have been proposed. Ac-cording to their optimization objectives, these methods are based on likelihood [Och and Ney 2002; Blunsom et al. 2008], error rate [Och 2003; Zhao and Chen 2009; Pauls et al. 2009; Galley and Quirk 2011], hinge loss [Watanabe et al. 2007; Chiang et al. 2008] and ranking [Hopkins and May 2011], and among which minimum error rate training (MERT) [Och 2003] is the most popular one.

All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call these global training methods. One of their advantages is that they allow us to train a single weight offline, making them efficient. However, due to the diversity and uneven distribution of source sentences [Li et al. 2010], they suffer from some shortcomings within this pipeline.

First, on the document level, the performance of these methods is dependent on the choice of a development set. As referred in our experiment, the BLEU points [Papineni et al. 2002] for NIST08 are 19.04 when the Moses system is tuned on NIST02 by MERT. However, its performance improves to 21.28 when tuned on NIST06. This shows that global methods may potentially lead to an unstable testing performance, if a develop-ment set employed for tuning is different from the test data with regards to its domain. The automatic selection of a development set [Tamchyna et al. 2012; Zheng et al. 2010] may partially address the problem, but it also suffers from some limitations to some extention. On the one hand, automatic selection requires a large set of candidate de-velopment sets, which should guarantee the quality as high as possible and be close to the testing conditions. However, such development sets are scarce and may be limited to particular language directions in practice. On the other hand, even if a large set of these data is available, it may be inefficient in some situations, such as, an online service or instant translation service, due to its high cost for training which demands several hours or even days for iteratively decoding an entire development data. Second, translations become inconsistent on the sentence level [Ma et al. 2011]. Global training methods try to optimize the weight towards the best performance for the whole set, and they do not take the sentence-wise performance into consideration. Therefore, it is not always possible to achieve good translation for every sentence even on the close testing on the development data. The main reason is that different sen-tences may need different optimal weights, and global methods can not obtain a single weight which is optimum to satisfy all the sentences. Figure 1(a) shows an example of this, in which a development set contains two sentences f and feature vectors h . As suggested by Hopkins and May [2011], tuning on Figure 1(a) can be transformed into a PRO style two-class classification problem in Figure 1(b), which consists of two positive examples  X  2, 0 and 1, 0 , and two negative examples  X  1, 0 and 2, 0 . Since the problem in Figure 1(b) is not linearly separable, there exists no hypersurface to discriminate positive examples and negative examples. In other words, there exists no single weight W which simultaneously obtains e e 21 as translation for f 1 and f 2 via the max-posterior decoding strategy (to be shown in Equation (2) later). However, we can achieve this with two sentence-wise local weights: 1, 1 for f 1 and  X  1, 1 for f 2 .

In this article, inspired by KNN-SVM [Zhang et al. 2006], we propose a local train-ing method, which trains sentence-wise local weights instead of a single global weight, to address the two problems above. Compared with global training methods, in which training and testing are separated, our method works in an online fashion, in which training is performed during testing. This online fashion has an advantage in that it can use the information from test sentences, and thus adapt the weights for them, by dynamically tuning the weights on translation examples which are similar to these test sentences. Similar to the method of development set automatic selection, the local training method may also suffer from the problem of efficiency. To put it into prac-tice, we propose a novel two-phase training method based on ultraconservative up-date which avoids retraining and iterative decoding on a development set. Our local training method has two advantages: first, it significantly outperforms global meth-ods MERT and MIRA [Watanabe et al. 2007; Chiang et al. 2008], especially when the test set is different from the development set; second, it improves the translation consistency. In addition, since testing with a local method corresponds to a nonlinear translation model, or a local linear model (see Section 6), our local method potentially leads to more powerful description ability than that of a log-linear model. Experiments on NIST Chinese-to-English translation tasks with both medium and large scales of training data show that our local training method significantly gains over MERT, with maximum improvements up to 2.0 BLEU points, and its efficiency is comparable to that of the global training method.

The rest of this article is organized as follows. Section 2 reviews the log-linear model and its global training methods; Section 3 introduces the main idea of local methods and their algorithms; Section 4 and Section 5 present two practices for the imple-mentation of local methods: retrieval of translation examples and ultraconservative update; Section 6 explains the relationship of local methods with linear and nonlin-ear models when testing; Section 7 shows the advantages of local methods over global methods with experiments, followed by related works and conclusion in Section 8 and Section 9, respectively. Suppose f is a source sentence, and e is one of its translation candidates. The log-linear translation model is defined as the following conditional probability: where the following hold.  X  c is the translation space consisting of all possible translation candidates e for f .
Since the exact size of c is exponential with regard to the number of words in f ,a well-known practice is to approximate c with a k-best list translation of f instead.  X  h is a feature vector defined over a bilingual sentence be an arbitrary feature, such as language model or word penalty.  X  W is a weight with respect to the feature vector h , and it is required to be specified by discriminative training.
 With the translation model in Equation (1), translation (or decoding) is considered as an optimization problem: Equation (2) is called the max-posterior decoding strategy. Given a development set Dev ={ f j , r j } with r j as a reference translation set of f , there are various methods to tune W in Equation (1). Intuitively, the main idea of these methods is to derive a globally optimum single weight W such that P ( e | f j ; W )&gt; P ( e | f j ; W ) if the BLEU points of the translation pair e and e of f tion Loss ( Dev ; W ) defined over Dev . In particular, the loss function can be employed as follows:  X  error rate for MERT [Och 2003], that is, where Error is a translation evaluation metric for a document, for example, minus
BLEU;  X  generalized hinge loss for MIRA [Chiang et al. 2008; Watanabe et al. 2007], that is, where h ( f j , e j  X  , e jn ) = h ( f j , e j  X  )  X  h ( f one; jn is the number of errors between e j  X  and e jn , that is, the errors measured by the BLEU difference;  X  ranking loss for PRO [Hopkins and May 2011], that is, where e jn and e jk are a pair of translations for f j such that the error number of e greater than that of e jk .

These tuning methods fall into the same pipeline when testing: first, they optimize a single global weight W with regard to an objective function defined over Dev ;then the optimized W is used to decode all sentences for testing. A biggest characteristic of the global methods is that all test sentences globally share the same weight W . Figure 2(a) shows a diagram of global methods for tuning and testing. As shown in the figure, tuning does not take test sentence information into consideration, and can be performed offline before testing; thus global methods for tuning and testing are very efficient, even if tuning can consume several hours or even days.

Generally, if the development set and test set share the same distribution, the global methods will achieve the best performance. However, such ideal conditions do not hold in practice due to the linguistic diversity around the world and uneven distribution of languages both geographically and demographically [Clemens et al. 2011]. What usually happens is that the testing performance is highly dependent on the choice of development set. Furthermore, the translation results of test sentences are inconsis-tent on the sentence level since tuning is performed on the document level, especially when test sentences are diverse. The local training method [Bottou and Vapnik 1992] is widely employed in computer vi-sion [Cheng et al. 2010; Zhang et al. 2006]. Compared with the global training method, which tries to fit a single weight onto the training data, the local one learns weights for each test example based on the local neighborhood information. It is superior to the global one when the data sets are not evenly distributed [Bottou and Vapnik 1992].
One successful instance of local training methods is the KNN-SVM [Zhang et al. 2006]. A multiclass KNN-SVM simply works as follows: for each query, (1) retrieves the top-K neighbors from all training examples; (2) if the K neighbors have the same label, the query is labeled as same and it exits; otherwise, it computes the pairwise distances between the K neighbors as a distance matrix; (3) transforms the distance matrix into a kernel matrix and trains multiclass SVM; (4) uses the resulting classifier to label the query.

Motivated by KNN-SVM, we will extend the idea of local training to statistical ma-chine translation in the rest of this section. Figure 2(b) shows a diagram of local meth-ods for tuning and testing. Unlike the global methods in Figure 2(a), local methods employ a retrieval set, a set of bilingual sentences, in the tuning module, and take the information from test sentences into consideration during tuning.

Suppose T be a test set, Dev a development set, and D retrieval data. The local train-ing in SMT is described in Algorithm 1. For each sentence t examples D i is retrieved from D using a similarity metric (line 2), a weight W timized on Dev and D i (line 3), 2 and, finally, t i is decoded with W At the end of this algorithm, it returns the translation results for T . Please note that line 3 utilizes similar translation examples to adapt weights for test sentences, thus our local training method can be considered as an adaptation of translation weights.
Algorithm 1 suffers from a problem with training efficiency in line 3. It is impractical to train a weight W i on Dev and D i from scratch for every sentence, since iteratively decoding Dev and D i is time consuming when we apply a tuner such as MERT. To address this problem, we propose a novel training approach based on a two-phase training method.

In the first phase, we use a global training method, such as MERT, to tune a baseline weight on the development set Dev in an offline manner. In the second phase, we utilize the retrieved examples to tune sentence-wise local weights by slightly updating the baseline weight via ultraconservative update, as will be shown later. Since this two-phase method learns W i only on  X  D i instead of the much larger data, that is, union of Dev and  X  D i , it is more efficient than Algorithm 1. In this manner, this two-phase method can consider not only the common characteristics learnt from Dev , but also the knowledge for each individual sentence learnt from similar examples during testing. In the second phase, we perform decoding only once for retrieved examples D several rounds of decoding are possible and potentially better if one does not care about training speed. Furthermore, instead of on-the-fly decoding, we decode the retrieval data D offline using the parameter from our baseline weight and its nbest translation candidates are saved with training examples to increase the training efficiency.
The two-phase local training algorithm is described in Algorithm 2, where c r s denote the translation candidate set and reference set for each sentence f retrieval data, respectively, and K is the retrieval size. It globally trains a baseline weight W b (line 1), and decodes each sentence in retrieval data D with the weight W to obtain k-best translation candidates (line 2). For each sentence t a local weight W i (line 5) and performs testing with W i the two-phase training involves global training in line 1 and local training in line 5.
From Algorithm 2, one can see that our method is effective even if the test set is un-known, such as in the scenario of online translation services, since the global training on development set and decoding on retrieval data can be performed offline.
In the next two sections, we will discuss the details about the similarity metric in line 4 and the ultraconservative update in line 5 of Algorithm 2. In line 4 of Algorithm 2, to retrieve training examples for the sentence t a metric to retrieve similar translation examples. We assume that the metric satisfies this property as: the more similar the test sentence and translation examples are, the better translation result one obtains when decoding the test sentence with the weight trained on the translation examples.
 The metric we consider here is derived from an example-based machine translation. To retrieve translation examples for a test sentence, [Watanabe and Sumita 2003] defined a metric based on a combination of edit distance and TF-IDF [Manning and Sch  X  utze 1999]: where  X ( 0  X   X   X  1 ) is an interpolation weight, f i ( i = can also be considered as a document, | f i | denotes the length of f denote edit distance and TF-IDF over a pair of sequences, respectively. In this article, we call it a combined metric. Please note that the combined metric depends only on the source side of bilingual sentences. Under the combined metric, we assume that the optimal translation weights of the similar source sentences are closer, such as in example-based translation, where similar source sentences have similar translations.
Since the computational complexity of the edit distance is O sentences f 1 and f 2 , the complexity of the combined similarity metric involved in line 4is O ( S  X  maxLen 2 ) , where maxLen is the maximal length of all sentences t Therefore, if S is large enough, then an exact retrieval in Algorithm 2 is inefficient. Instead, we employ an approximate retrieval for the combined metric as follows: for each t i , we firstly retrieve the top S ( S S ) examples with regard to TF-IDF metric, and then rerank these top S examples with regard to the combined metric. Given that the complexity of O ( S  X  maxLen ) for TF-IDF is O ( S  X  maxLen method requires O ( S  X  maxLen + S  X  maxLen 2 ) , which is more efficient if S S .In our experiments, we set S = 50, 000.

As an alternative, Li et al. [2010] proposed a bilingual measure, in which each bilin-gual sentence ( f i , e i ) is represented as a real valued vector h are translation features. The metric of two sentences is defined as cosine between their corresponding real-valued vectors: where V ( f ) denotes a vector derived from the translation space of f . Given a trans-lation weight W , V ( f ) can be specified as a feature vector of article, we use the k-best list to approximate c ,set W = tained in line 1 of Algorithm 2, and adopt the average feature vector method for V This metric is defined upon feature vectors of bilingual sentences siders the information both from the source side and the target side. However, it may also induce the risk of an approximation of translation space with k-best list and noise in the feature estimation of phrase table. In order to accelerate the retrieval speed so that Algorithm 2 is more efficient for larger retrieval sets, the retrieval process is parallelized as follows: the retrieval data D is split into several parts, each of which is assigned to one CPU for independent retrieval. Each CPUs accepts a query and returns its top-K results, and then all these top-K results from individual CPU are merged into the final top-K retrieved examples. Following the notations in Algorithm 2, W b is the baseline weight, and { j , c weight, denoted by W i , which is a local weight used for decoding the sentence t Algorithm 1 which performs tuning on the whole development set Dev learned by ultraconservative update which slightly adjusts W
Ultraconservative update [Crammer and Singer 2003; Crammer et al. 2006] is an efficient way to consider the trade-off between the progress made on development set Dev and the progress made on  X  D i . It desires that the optimal weight W only be close to the baseline weight W b , but also achieve low loss over the retrieved examples  X  D i .

Formally, the objective of ultraconservative update can be defined as follows: where d ( W , W b ) is a distance metric over the pair of weights W and W we employ L 2 norm of the difference of W and W b . Loss ( defined on  X  D i and it evaluates the performance of W over rameter. If  X  D i is more similar to the test sentence t achieved for the larger  X  . In particular, if  X  D i consists of only a single sentence t best performance will be obtained when  X  goes to infinity. MIRA [Watanabe et al. 2007; Chiang et al. 2008] is a form of ultraconservative update in Equation (7) where Loss is defined as the hinge loss in Equation (4). In detail, it tries to minimize the following quadratic programming: where jn is the sentence-wise BLEU error as referred to in [Chiang et al. 2008], denotes the number of k-best translation candidates in c j in Equation (4).

Typically, there are two methods to address this quadratic programming. The first one is the subgradient descent method [Shalev-Shwartz et al. 2007]. Since the objective in Equation (8) is convex, it can be guaranteed that the subgradient descent converges to the unique optimal solution. The second method is derived from SMO (Sequen-tial Minimal Optimization) [Platt 1999] which is employed in [Chiang et al. 2008; Watanabe et al. 2007]. After the introduction of K slack variables for Equation (8), one can obtain a constraint quadratic programming (primal) problem. If one applies the SMO method to its dual problem and recasts some of the variables in the dual prob-lem into their corresponding variables in the primal problem, then the optimization algorithm can be derived. We do not present the derivation for this online algorithm, but refer to [Chiang et al. 2008; Platt 1999; Shimizu and Haas 2006; Watanabe et al. 2007] for more details. In our later experiments, we apply the second one as the im-plementation, although both of these two methods perform similarly in our internal studies.

Unlike [Chiang et al. 2008; Watanabe et al. 2007], which employ the MIRA to glob-ally train SMT, we apply MIRA as one of local training method for SMT and we call this a hinge loss based ultraconservative update (or HLBUU for short) to highlight its advantage of ultraconservative update in line 5 of Algorithm 2.

Further, there is another difference between HLBUU and MIRA in [Chiang et al. 2008; Watanabe et al. 2007]. The former is a batch version of MIRA [Cherry and Foster 2012] which updates the weight with all the training examples, but the latter is an online one which updates with each example [Watanabe et al. 2007] or part of examples [Chiang et al. 2008]. Therefore, HLBUU is more ultraconservative. Instead of taking into account the margin-based hinge loss between a pair of transla-tionsasthe L oss in (7), we consider the error rate of translation candidates with re-ultraconservative update is as follows: where  X  e ( f j ; W ) is defined in Equation (2), and Error (minus BLEU [Papineni et al. 2002]) of a candidate e with respect to r
Due to the existence of an L 2 norm in objective function (9), the optimization algorithm MERT can not be applied for this question since the exact line search routine does not hold here. Motivated by Och [2003] and Smith and Eisner [2006], we approximate the Error in (9) by the expected loss, and then derive the following function: with where  X &gt; 0 is a real number valued smoother. One can see that, in the extreme case, for  X   X  X  X  , the objective in Equation (10) converges to Equation (9). We call Equation (10) the expected error rate based ultraconservative update, or EEBUU for short.
We apply the gradient decent method to minimize the Equation (10), as it is smooth with respect to W . By taking the derivation of P  X  ( e | to W , the following equation holds: with where E P  X  (  X | f ; W ) can be interpreted as the expectation of feature function h Equation (10) is as follows:
Since Equation (10) is nonconvex, the solution obtained by gradient method may depend on the initial point. In this article, we set the initial point as W a reasonable choice in our ultraconservative principle. We apply the conjugate gra-dient method to minimize Equation (10) and Algorithm 3 presents this pseudocode. Algorithm 3 inputs an initial weight W b , an iteration number MaxIter , an interation with W b and cur with 0 in line 1. Then, it optimizes W cur calculates the objective of Equation (10) in line 3 and subgradient in Equation (13) in line 4, based on the k -best -list ; in line 5 it optimizes W ations within CG, in other words, CG returns W cur + 1 2 after CGIter iterations instead of when it achieves its default stop condition; it normalizes W updates cur in line 7. Last, it returns W = W MaxIter after the loop. In particular, the normalization in line 6 is helpful to its performance, similar to the same operator in the implementation of MERT. Theoretically, there is an exceptional condition when W cur + 1 equal to 0, which did not occur in our experiments. In our implementation of Algorithm 3, we call the CG toolkit, cg descent [Hager and Zhang 2006], which re-quires overloading objective and sub-gradient functions. For the ease of description, we transform the values of these functions in this pseudo-code, instead of overloading functions. In global methods the optimal weight W obtained after tuning remains fixed for each sentence t in the test set. Therefore, if t is considered as a variable and W used during decoding, then W t is a constant, that is, W t strategy is described as argmax e W t  X  h ( t , e ) (See Equation (2)), the decision function for global methods is W  X  h ( t , e ) , which is linear with respect to h function 3 for global methods is shown in Figure 3(a), where dots denote the feature vectors of translation candidates for source sentences, and the line denotes a decision function specified by a weight W .

In local methods, the decoding weight W t is a variable depending on t . First, let us investigate the relationship between W t and t , and define some notations for the ease of description: D ( t ) 4 denotes a set of examples extracted from the retrieval data for t ; N ( t ) , a neighborhood 5 of t , denotes a set of test sentences whose member t suffices to D ( t ) = D ( t ) ,thatis, N ( t ) ={ t | D ( t ) = D ( since t  X  N ( t ) . According to Algorithm 2, W t is dependent both on W the solution of nonlinear programming in Equation (8) or Equation (10). Generally, the relationship between t and N ( t ) is complex, and is nonlinear. Therefore, the decision function W t  X  h ( t , e ) is nonlinear with regard to h (
If we consider the relationship between t and W t in a neighborhood N following assertion holds: for each t  X  N ( t ) , W t is not dependent on t but on t ,since the objective of t in Equation (8) or Equation (10) is independent on t according to the definition of N ( t ) . It follows that, for t  X  N ( t ) , W each t in N ( t ) , its decision function is W t  X  h ( t , e
In summary, local methods generally lead to a nonlinear decision function; however this is a linear function in a neighborhood locally, and thus it is a local linear func-tion. In this way, local methods perform as local linear models during testing, that is, nonlinear models which potentially have more powerful description ability than linear models. A decision function for local methods is shown in Figure 3(b), in which the dots in a circle denote the fecture vectors of translation candidates for all t t , and a segment denotes a decision function specified by W We conduct our experiments on several NIST Chinese-to-English In our experiments, the translation performances are measured by BLEU4 metric [Papineni et al. 2002] and we use mteval-v13a.pl for the evaluation tool. The signif-icance testing is performed by paired bootstrap resampling [Koehn 2004]. The training data is FBIS corpus; the development set is NIST02 evaluation data; the development test 7 set is NIST05; the test datasets are NIST06,and NIST08, re-spectively; and the monolingual data for language model is the Xinhua portion of the English Gigaword corpus. The details of these datasets used in our experiments are shown in Table I.

We run GIZA++ [Och and Ney 2000] on the training corpus to obtain the word alignment for each sentence pair, and employ the  X  X row-diag-final-and X  heuristic to obtain the symmetric word alignments [Koehn et al. 2003]. We train a 4-gram lan-guage model by using the SRILM Toolkits [Stolcke 2002] with modified Kneser-Ney smoothing [Chen and Goodman 1998]. We use an in-house developed hierarchical phrase-based translation system[Chiang 2005] as our baseline decoder, and we denote it as In-Hiero . In-Hiero consists of eight default features:  X  two translation probabilities,  X  two lexical translation probabilities,  X  one word penalty,  X  one glue rule penalty,  X  one synchronous rule penalty,  X  one language model.
 In-Hiero is with the default setting: for example, the beam size is set to 100 and the k-best decoding size k-best-size is set to 100 for tuning. As Table II indicates, our baseline In-Hiero 8 is comparable to the phrase-based MT (Moses) and the hierarchical phrase-based MT (Moses hier) implemented in Moses, an open source MT toolkit et al. 2007].

We adopt two global training methods, MERT and MIRA, as our baseline train-ing methods, which are the most popular global training methods for SMT. MERT is derived from the Moses toolkit; and a batch-style MIRA is implemented similar to [Cherry and Foster 2012]. Please note that there are two differences between MIRA and HLBUU: MIRA is employed as a global method but HLBUU is done as a local method; the loss of MIRA is defined on the dev set, but that of HLBUU is done on the retrieval set. For MIRA, we tune its hyperparameter on the development set in advance.

Since Algorithm 1 needs to perform retraining for each sentence and each retrain-ing may take several hours or even days, it is impractical to run Algorithm 1 for the whole test set. Therefore, we use Algorithm 2 as our local method to compare with our baseline methods.

To run Algorithm 2, the training data, FBIS corpus(catalog number: LDC2003E14), is used as our retrieval data and the retrieval size is set to 100. We use the baseline weight, W b , tuned on NIST02 by MERT. To accelerate the retrieval process, we use 10 CPUs for parallelization. We translate retrieval data D with W 100 best translation candidates. We set  X  = 0.1 for the interpolated TF-IDF metric in Section 4 as a retrieval metric. In our experiments, we implement two methods of ultraconservative update, that is, HLBUU and EEBUU. Both of their hyperparameters  X  are tuned on NIST05 and set as 0.018 and 0.06 for HLBUU and EEBUU, respectively. In the ultraconservative update step, only one CPU is employed. For EEBUU based local training method, we set MaxIter = 200, CGIter = 5 in Algorithm 3. Since both tuning on the dev set and decoding on the retrieval set can be performed offline in Algorithm 2, we exclude both of their runtimes and consider the actual run-times consumed only for testing to evaluate the efficiency of local methods. Thanks to the parallelization of retrieval and ultraconservative update methods, our local method presented in Algorithm 2 is very efficient. Table III shows that testing each sentence with local training method takes 2.9 seconds, which is comparable to the testing time 2.0 seconds for the global training method. In addition, we can see that the local train-ing is not the bottleneck, compared to the retrieval. Therefore, if we use LSH technique [Andoni and Indyk 2008] in retrieval process, the efficiency of local methods can be fur-ther improved.
 7.4.1. Main Results. Table IV shows the main results of our local training methods. The EEBUU training method significantly outperforms the MERT baseline, and the improvement achieves at least 0.68 BLEU points on NIST05 and even up to 2.0 BLEU points on NIST08. Compared with the global training method of MIRA, our local method HLBUU achieves similar improvements on these three test datasets. Fur-ther, we can also see that EEBUU and HLBUU are comparable on these three test sets. Both of these two local training methods achieve significant improvements over the baseline global methods of MERT and MIRA, which proves the effectiveness of our local training methods over global training methods. As discussed in the previous section, local methods can take the advantage of the sentence-wise weight by adap-tively optimizing toward the retrieved data, and thus outperform the global methods. Please note that we employed training data as our retrieval data, since the retrieval data should belong to the same domain as test sets, and should be large enough such that similar sentences can be retrieved. Of course, this retrieval data setting may de-crese our performance due to the potential overfitting. However, the results indicate that our simple setting can improve the performance.

As also mentioned in Section 1, the global methods tune parameters towards the document-level translation quality and do not care about the sentence-level quality. Thus the improved document-wise translation quality does not consistently imply sentence-wise improvement. We calculate sentence-wise BLEU on the test data and count the number of sentences with zero sentence BLEU as shown in Table V. In all the three test datasets, there are 1735 sentences with zero BLEU points for MERT, which account for 42.3% of all sentences. At the same time, the number of those sen-tences obtained by local methods are reduced to 1606. Therefore, the local training methods can also achieve consistent improvements on the sentence level and thus can improve the users X  experiences, along side obtaining improvements on the document level as referred to in Table IV. 7.4.2. Analysis for Test Set Similarities. Although both local methods HLBUU and EE-BUU achieved improvements on all translation test sets, their gains on the NIST06 set and the NIST08 set are significantly higher than those achieved on the NIST05 set. We hypothesize that the more different a test set and a development set are, the more potential improvements local training has for the sentences in this test set.
To test our hypothesis, we define a similarity metric between a test set and the development set as follows. First, for each sentence in a test set, we calculate TF-IDF scores between itself and the development set, then we accumulate these scores for all the sentences in a test set and average the accumulated score over the number of sentences in the test set. Finally, we define the final similarity as the average score instead of the accumulated score, since it reduces the dependency on the number of sentences in a test set, which may cause bias, that is, the larger the number of a test set is, the higher its similarity is.

We measure this similarity between the development dataset (NIST02) and the test datasets. Table VI shows that the similarities of NIST06 and NIST08 are much lower than that of NIST05. Therefore, this is potentially the reason why local training is more effective on NIST06 and NIST08. 7.4.3. The dependency of Hyperparameter on Local Training methods. The hyperparameter in both HLBUU (Equation 8) and EEBUU (Equation 10) has an important influence on translation performance. Figure 4 shows the influence on EEBUU on the test datasets. We can see that the performances for all these datasets improve as to 0.06 from 0, and the performance continues improving when NIST08 test set, on which the performance constantly improves up to 2.6 BLEU points over the baseline. As mentioned in Section 5, if the retrieved examples are very similar to the test sentence, a better performance will be achieved with the larger fore, it is reasonable that the performance improves when Further, the turning point appearing at 0.06 proves that on ultraconservative update is necessary. We can also see that the performance on NIST08 consistently improves and achieves a maximum gain when  X  is 0.1, but those on both NIST05 and NIST06 achieve the best when  X  is 0.06. This phenomenon can also be interpreted in Table VI as the lowest similarity between the development and NIST08 datasets. 7.4.4. Experiments on Domain Mismatch. As mentioned in Section 1, global training methods such as MERT are highly dependent on development sets. To investigate this situation, we consider the testing on NIST08, and use the global training method MERT to tune In-Hiero on NIST02, NIST05, and NIST06. We find that MERT is very sensitive to the development selection. As shown in Table VII, tuning on NIST06 achieves 21.28 BLEU points on NIST08 for testing, but tuning on NIST02 only achieves 19.03 BLEU points. To investigate this phenomenon, we calculate the simi-larities defined in subsection 7.4.2 between the test set (NIST08) and the development sets (NIST02, NIST05, NIST06). We find that NIST06 is most similar to NIST08, and NIST05 is more similar to NIST08 than to NIST02. This shows that global methods can achieve good testing performance if a suitable development set is employed. On the other hand, the translation performance of global methods will be degraded if one chooses poor development data that is not close to the test data.

Fortunately, local training methods can still achieve good performance even if we selected unsatisfactory development data. As also shown in Table VII, even if employ-ing NIST02, the worst set among those three sets, as the development set, the local training method based on EEBUU still obtains 21.08 BLEU points on NIST08 which is comparable to that of the global method tuning on NIST06. In practice, it is unusual that a close development set is available when testing and it is not a simple task to manually create such a development set, which limits global methods. However, we can efficiently avoid those errors incurred by incorrect development set selection with the help of local training. In addition, we use both NIST05 and NIST06 as dev sets and rerun the local method, we find that its testing BLEU points on NIST08 are 21.49 and 21.74, respectively. This result shows that even if we have selected a good dev set for testing, our local method can still obtain improvements. Furthermore, we can see that our local method is more stable than global methods when running on the different development sets. 7.4.5. The dependency on Retrieval for Local Training methods. We measure the various re-trieval settings which may affect the quality of local training. First, we consider the effect of  X  parameterizing the combined metric on testing performance. We set differ-ent values for  X  based on their performance on the test sets summarized in Table VIII. From Table VIII, we can see that the testing performance is not sensitive to  X  = 0.1 achieves the best performance.

Second, we also implement cosine similarity in Section 4 as an alternative retrieval metric, and compare it with the combined metric of tfidf-edit. As shown in Table IX, the combined metric achieves about 0.3 BLEU points over cosine . As discussed in Section 4, one possible reason why a cosine metric is worse is that it induces the risk of the approximation of translation space with k-best list and noise in the feature esti-mation of phrase table.

Finally, we consider the effect of retrieval size on local training methods. Gener-ally, better performance may be achieved when more examples are retrieved. In fact, in Table X there seems to be little dependency between the numbers of examples re-trieved and the translation quality, although they are positively related approximately. This fact shows another advantage of our local methods, that is, they are insensitive to this easily-tuned parameter. 7.4.6. The Quantity Estimation of the Potential for Local Methods. Although we have shown that the local methods implemented in algorithm 2 can achieve better translation re-sults than global methods, we were also curious about their potential. Therefore, we designed additional experiments to compute the upper bounds of local methods. We calculate the BLEU of the oracle translation in their 100-best translation list. Table XI shows that there are improvements of 9.0 BLEU points for local methods. Further, the oracle result of our local methods is better than that of global methods, which demon-strates advantages of local methods over global methods.

The above upper bound is too loose, and we present a tighter bound as follows. First, we construct a 2-best translation list which consists of the 1-best result of global meth-ods and the 1-best of local methods. Then, we calculate the oracle result of this 2-best list. As shown in Table XII, the oracle result gains at least 1.0 BLEU point over that of local methods, although the list contains only 2 translation candidates. Therefore, there is a potential for more improvements in the local training method. Actually, if we design a binary classifier to predict whether we should adopt the translations from local methods or not, we may further improve the translation results. Ideally, these improvements are achievable if such a classifier can make exact predictions. 7.4.7. Approximate Implementation of Algorithm 1. As mentioned before, running Algorithm 1 with the retraining method on the entire test set is impracticable. In-stead, we run it on part of the sentences from a test set: we select 12 sentences from a document in the NIST05 test set which share the same topic. Even if there are only 12 weights to be retrained on the merged data of the dev set and the retrieved examples, it still takes lots of time. Observing that these 12 sentences are on the same topic, we hope that their retrieved examples will be similar to each other. Therefore, we re-train only a single weight for these test sentences instead of the exact implementation of Algorithm 1. Specifically, we retrieve 40 examples for each test sentence, and thus these retrieved examples amount to 480 in total. We use MERT for retraining on the merged data consisting of the dev set and the retrieved examples, and this method is listed as Retraining in Table XIII. As an alternative, we also the ultraconservative update (EEBUU) to train a single weight on the retrieved examples with multi-pass decoding rather than 1-pass decoding as Algorithm 2, and we list it as Ultraconserva-tive Update in Table XIII. The regularizer  X  in this method is set as 0.02.
From Table XIII, we can see that Retraining is better than the  X  X aseline X  global training with MERT on the dev set, which indirectly shows that the naive implemen-tation of local method (Algorithm 1) achieves gains over global methods. However, the retraining method is still worse than our local training method of Algorihtm 2. This implicitly indicates that Algorithm 2 is better than Algorithm 1 in terms of both of the translation accuracies and efficiencies. In addition, ultraconservative update per-forms best among all the methods. It scores 2.4 BLEU points higher than our local method, which shows that multi-pass decoding is helpful for local training. To our sur-prise, it gains up to 3.8 BLEU points more than the retraining method. We conjecture that reweighting the distribution of the dev and retrieval sets can improve the testing performance [Jiang and Zhai 2007; Foster et al. 2010]. Fortunately, with the help of regularizer  X  , ultraconservative update can balance the contributions from the dev set and the retrieval set, and thus can achieve the effect of reweighting.

Given that the ultraconservative update method is better than the local method on the small test set as shown in Table XIII, we run it for the entire NIST05 test set. We set the retrieval size as 70 for NIST05 and thus obtain a very large retrieved set (with 75,740 = 1, 082  X  70 sentences) as the dev set. After slight adjustment of the hyperparameter, it achieves 24.47 BLEU points on NIST05. However, the number is still about 0.4 BLEU points lower than our local method, even if our local training performed decoding on the retrieved examples only once. 7.4.8. Analysis on the Retrieved Examples. We measure the impact of the retrieved ex-amples to our local training. First, we select the subset of sentences from NIST05, the top-k longest sentences and the top-k shortest sentences for different k. Then, trans-lation qualities are measured on the subsets. The evaluation criterion the document BLEU gains of EEBUU over MERT on these k sentences are greater than 0.78 points, which is what the gains are for EEBUU on the entire NIST05 test set. As clearly shown in Table XIV, local methods can achieve much better transla-tions for long sentences than global methods: for all k, the gains are more than 0.78 BLEU points; particularly for k  X  60, the gains are over 1.0 BLEU points. But for short sentences, local methods seem to be comparable to global methods, although the gains are about 1.0 BLEU points when k=60. Therefore, these results show that local methods are preferable for translating long sentences as opposed to translating short sentences. One of the possible reasons is that for short sentences, translation members in their decoding space are relatively fewer, and thus it is easier to distinguish good translations from bad ones with a single weight by global methods. In other words, the potential of local methods for short sentences is more limited.
 Second, we choose subsets according to the top-k and low-k similarity scores from NIST05, and compare the gains of local methods over global methods. Since several sentences are retrieved for each test sentence, we take the average of the similarity scores of those retrieved examples. As shown in Table XV, for both top-k and low-k sentences, while the gains for local methods over global methods are almost positive, most gains are less than 0.78 BLEU points. This shows that it is unclear whether local methods are suitable to for high similarity sentences or low similarity sentences. We conjecture that, for those sentences with high similarity, the global methods already achieve good translations, and thus the improvements by local methods are limited; for those sentences with low similarity, the retrieval data is less helpful for adapting weights for local methods. In addition, we select the sentences with mid-k similarity scores, and their gains are shown in Table XV. Local methods seem to favor for these sentences, but evidence for this on similarity is not clearer than that for the sentence length. To test the scalability of our local methods, we conduct experiments on larger training data. Our experiments select some portion of the bilingual training data available for the NIST MT 2008 as the training data, 11 and its statistics are shown in Table XVI. The development set, development test set and test sets are the same as those in previous experiments. Further, we employ the same language model trained for the In-Hiero system. Since the previous experiments shows that Algorithm 2 is insensitive for most parameters except  X  , we set these parameters as before and only tune the development test set.

Table XVII compares global and local methods, and + denotes a local method is sig-nificantly better than both global methods MERT and MIRA with p Table XVII, we can see that local methods outperform global methods with gains up to 1.6 BLEU points on test sets. This experiment proves that local methods can improve the performance over global methods on large training data, and thus local methods are scalable to large scale of data. Several works have proposed discriminative techniques to train log-linear models for SMT. Och and Ney [2002] employed a method based on maximum likelihood estima-tion (MLE), and its objective is defined on surrogate reference sentences which have high sentence BLEU among the k-best translations. Similarly, Blunsom et al. [2008] proposed another training method within the MLE framework. Unlike Och and Ney [2002], they considered the derivation as a latent variable instead of an observable variable. Further, they defined the objective on the references instead of on surrogate references and on the derivation forest rather than on an approximate alternative, that is, a k-best list.

The above works do not completely relate to translation evaluation metrics, and thus Och [2003] designed an nonsmooth objective which is directly defined with translation evaluation metrics. To optimize the nonsmooth function, they pro-posed the MERT algorithm, which employs an efficient exact line search. Similarly, Zhao and Chen [2009] proposed a simplex method which employs an inexact line search to minimize the same objective as MERT. Due to the nonconvex and nonsmooth objective of MERT which can easily fall into local minima, Moore and Quirk [2008] pro-posed a discrete regularized method, and [Smith and Eisner 2006] proposed a smooth objective based on expected error rate and used a simulated annealing method for op-timization to avoid poor local minima. Galley and Quirk [2011] casted the objective of MERT into a combinatorial optimization and proposed an optimal method for its minimization with an exponential complexity.

Due to the nonconvex error rate based loss functions in the above works, their ob-jective functions are not simple to optimize. Instead, other works used indirect loss functions which are convex. Watanabe et al. [2007] and Chiang et al. [2008] presented a generalized hinge loss based objective. Further, unlike MERT taking all translations in k-best list into consideration, they only sample a part of translations consisting of oracle ones and nonoracle ones. They applied an algorithm derived from SMO to min-imize their loss function. The optimized weight satisfies that the margins between a pair of translations be greater than the difference in their evaluation metric scores. Similarly, Hopkins and May [2011] presented a ranking-based loss function from the view of classification, and employed the off-the-shelf MaxEnt toolkit to optimize the loss. But their optimized weight demand that the margins be greater than a fixed bias which need not be the difference in their metric scores.

Although our objective is indirectly or directly related to those of all the methods mentioned above, there are also large differences between them. These methods train a single weight for the entire test set, whereas our local training method learns a weight for each test sentence. Further, our translation framework integrates training and testing into one unit, instead of treating them separately. One of its advantages is that it can take into account the information from test sentences to be translated.
Our method resorts to utilizing translation examples, similar to some works on example-based translation [Watanabe and Sumita 2003] or the translation memory method [He et al. 2010; Ma et al. 2011]. For example, [Watanabe and Sumita 2003] proposed an example-based decoding algorithm for SMT. For each input sentence, they firstly initialized their decoding search from a similar translation extracted from a bilingual corpus, and then employed a greedy algorithm to search translations. Simi-larly, [Ma et al. 2011] used the source side of fuzzy matches from translation memory to constrain the translation of an input sentence. But they employed a discriminative learning method rather than a heuristic similarity metric, to determine whether the target side of the fuzzy matches should be used as a constraint when translating an in-put sentence. Unlike these methods using translation examples to implicitly construct translation rules for enlarging the decoding space, we employ them to discriminatively learn local weights instead.

Our method also employs IR methods to retrieve examples for a given test set, which retrieved top k similar sentences for each test sentence in terms of TFIDF from avail-able in-domain and out-of-domain training data, and then put all the retrieved sen-tences together to train an adapted translation model. Similarly, L  X  u et al. [2007] used a small adapted data set to optimize the distribution of the whole training data, and then trained an adapted translation model on the optimized training data. Both of their methods utilize the retrieved examples to train an adapted translation model and can be seen as an adaptation of the translation model. However, ours uses the retrieved examples to tune weights and thus can be considered as an adaptation of tuning. In addition, since ours does not change the translation model which needs to run GIZA++ and it can efficiently trains local weights, our method can be applied to online translation service.
 Our method can be considered as weight adaptation, and thus is closely related to Zhao et al. [2011] and Liu et al. [2012]. Zhao et al. [2011] propose a transductive learn-ing method which iteratively reestimates the weight using both development and test data, to overcome the weight bias-estimation problem suffered by MERT. Similarly, Liu et al. [2012] employ a cotraining framework to handle domain adaptation for transla-tion weight. They use translation results of a test set from heterogeneous decoder as a part of development data, in order to bias the weight towards the domain of a test set. Our method is different from these two methods mainly in two ways: first, its core tuning algorithm is not directly based upon MERT; second, it employs translation ex-amples similar to a test set instead of the test set itself, and thus does not need to (iteratively) decode on the test set during tuning.

At last, our local method discriminatively adapts weight and performs testing with the learned weight at the sentence level, which is close to online adaptation in computer-assisted translation [W  X  aschle et al. 2013]. Nevertheless, there are large differences between them. W  X  aschle et al. [2013] consider not only weight adaptaion, but also adaptaion of translation model and language model. Futhermore, during the weight discriminatively adapting procedure, it introduces additional features derived from user translation results which my contribute to adaptation, but ours only employs default features as standard MT setting. Global training methods such as MERT and MIRA suffer from the problems of devel-opment data selection and sentence-wise worse translation results. In this article, we propose a novel local training framework for SMT to alleviate these limitations. It has two characteristics, which are different from global training methods. First, instead of training a single global weight on the document level, it trains local weights on the sentence level. Second, instead of considering tuning and testing as two separate units, it unifies tuning and testing into one unit, which can employ the information from test sentences and adapt the weights for testing. Experimental results show that it achieves gains up to 2.0 BLEU points compared with global training. With the help of ultraconservative update, the time incurred by local training was negligible and the local training and testing in total took 2.9 seconds for each sentence.

In future work, we will further improve the local training method, since we observed many improvements that could be made during our experiments. For example, we will combine the 1-best results of global and local methods, and design a binary classifier to predict whether to adopt the results of the local method or not. Feature designing for this classifier is crucial for desirable prediction, and we will investigate helpful features such as sentence length.

