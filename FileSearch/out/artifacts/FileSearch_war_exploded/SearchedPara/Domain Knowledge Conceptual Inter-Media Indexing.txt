 Conceptual Indexing is a way to produce only one index for many multilingual documents. Inter-Media conceptual indexing promotes the use of common concepts between two media in order to use a single index for several media. In this paper we explore such an advance indexing point of view. We show the benefit of an automatic conceptual indexing for texts and its extension for text and image documents. Tests are conducted on the multilingual image and text medical document corpus of the CLEF initiative, where we obtain best results on text in 2005 and 2006, and show promising results on images, and best results for the combination of image and text.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Indexing methods, Linguistic pro-cessing Algorithms, Experimentation, Measurement, Theory. Conceptual Indexing, Inter-Media Indexing, Image Index-ing, Multilingual Text Indexing.
In an Information Retrieval (IR) system, automatic index-ing consists on describing documents in a way they can be easily retrieved. As recalls E. Voorhees in [34],  X  X ext retrieval is natural language processing X , but the purpose is not to un-derstand document content, rather to produce a description that enables the computation of a Relevance Status Value (RSV) as close as possible to human relevance judgment. Document understanding belongs to end user, but we could guess that if an Information Retrieval System (IRS) could in-corporate some of user knowledge and reasoning capabilities, it would help to produce more meaningful answers. This old paradigm [28], has nevertheless driven research on systems using domain knowledge (thesaurus, knowledge base, on-tology, etc), complex Natural Language Processing (NLP) or systems that describe document content (indexes) in a complex way (ex: Conceptual Graphs [14], Terminological Logics [24]), with a matching related to an uncertain logi-cal deduction [33]. This paradigm is very different from the most in use that considers an IRS as a function basedona word sequence or set, that approximates a stochastic asso-ciation between a query and a document also known as the  X  X ag of words X  paradigm.

We cannot claim we know which paradigm is best for IR, but we believe that the more explicit knowledge is taken into account, the better the IRS should be. We know how difficult it is to incorporate in an effective and efficient way knowledge and Natural Language Processing into an IRS. But we want to study the impact on IRS performance, of the use a large knowledge set in a narrow domain.
In this paper we promote the use of conceptual index pro-duced automatically from text, and images. This common unique index can be seen as Inter-Media because it stores in a common representation, both index for text and images. We prove the effectiveness of our approach using experi-ments done on a medical text and image collection. Knowl-edge and concept description will come from a very large meta-thesaurus (UMLS [22]). On the text side, NLP tools are used to identify concepts related to noun phrases. On the image side, a learning process is engaged to automat-ically associate a set of relevant concepts to images. Our ultimate goal is to show that it is possible to build a better IR system by using concepts instead of words or low level image features.

We briefly present some milestones in the domain of con-ceptual indexing in the next part. Then we present a general conceptual indexing framework (section 3). We instantiate this framework for text conceptual indexing (section 4) and image conceptual indexing (section 5). Finally we present our last results on a medical test collection (section 7), that outperform classical word base indexing.
One direction going toward more precision for indexing document in an identified domain, is to use terms instead of words. This has been studied and experimented for example in [16, 32]. An indexing using multi terms (e.g.  X  X kin can-cer X ) should improve precision as multi terms have precise meaning. But this can lead to a recall problem due to term variation and synonymy (e.g.  X  X elanoma X ). Indexing at the conceptual level should solve this problem because concepts are abstraction of terms. Moreover, at this conceptual level, we are no more language-dependent and such an IR system becomes multilingual as only one unique set of concepts is used to index a document in any language.
 Conceptual indexing comes from the early days of manual Library Document Indexing. After a long research period and a lot of progress, it is surprising that a lot of text IR systems are still based on the  X  X ord intersection X  paradigm. There are some works that claim doing automatic concept-base indexing and retrieval but in fact they do not really make a difference between words and concepts [25]. Con-cepts are abstraction of words, and any system claiming do-ing conceptual indexing should include the use of at least domain knowledge. Some works seem closer to conceptual indexing [7], but do not show significant improvement. One may think it is a disambiguation problem: when moving from word or terms to concepts, a disambiguation step is mandatory. Unfortunately, works like Sanderson X  X  [27] show IRS is more sensitive to erroneous disambiguation that am-biguity. However, reducing erroneous disambiguation seems possible with a positive impact on IR performance like in [31], even at a lower disambiguation rate than Sanderson X  X  claim.

Is a real and effective automatic conceptual indexing still an inaccessible dream? The answer may be  X  X es X  for an unrestricted domain.

Conceptual image indexing is much more challenging than text indexing. It is obvious that most of the time, users looking for an image, are more interested on what the image means that on the image itself. An image is supposed to be a snapshot of real objects. So indexing only image visual features like the color or shape, is most of the time useless. For example, in medical domain, physicians are looking for medical report or cases from a given pathology on a precise anatomy. Using an indexing vocabulary that is meaning-ful to user (ex: a thesaurus) is the minimum an image IRS should provide. Much image indexing proposals claim using concepts for image representation like in [11, 12]. Unfortu-nately, authors do not make a strong difference between a keyword and a concept.

In this proposal, we go further and use a common set of abstract identifiers to describe both text and images of multimedia documents. That X  X  what we call  X  X nter-Media X  indexing. These identifiers are concepts that enable access to either textual or visual content from a single index.
When talking about conceptual indexing, one have to clar-ify the notion of concept which is a difficult task. In [13], a concept is close to the notion of category, with some math-ematical constraints. We have to be pragmatic and sketch  X  X oncepts X  close to our actual needs and uses. Concepts can be defined as human understandable unique abstract notions independent from any direct material support, inde-pendent from any language or information representation, and used to organize perception and knowledge. So con-cepts are abstraction units, built by human and generalized from common properties of object, facts, event, etc. From this definition, no machines can extract concepts from any digital source, but rather, it can try to map concepts to parts of digitalized data (image, text, etc). In practice concepts are identifiers with associate information to describe them, usually texts and terms, but also image patches, logical def-initions or constrains. For example, CYC [18] is a large set of concepts (ontology) in a machine readable format where concepts are described by a logical expression and a set of related terms. ConceptNet [23] is more informal, without logical language, and it captures common sense knowledge with an emphasis on rich semantic relations. We bet in the near future new IRS will use combinations of massive knowl-edge sources including common sense.

Conceptual indexing can be simply defined as: using con-cept identifiers in index instead of words or terms, or image features. The characteristic of such an index is first to be me-dia independent, and for text, to be language independent. However there are challenges in setting up a conceptual in-dexing. The first challenge we foresee is the correct use of massive knowledge sets. We agree with Lin [21] about the importance of knowledge for conceptual indexing. He de-fines tree types of knowledge:
Knowledge built by specialists is mandatory for concep-tual indexing, but we think that domain knowledge is manda-tory to index document, as problem knowledge is useful to structure the query and solve it properly.

Domain Knowledge resources can be briefly classified rela-tively to their usage: a Terminology describes all possible or acceptable terms from a domain. They are used for language normalization, official translation, etc. Then by definition, a term is a noun phrase that belongs to a terminology. For example the role of  X  X rand Dictionnaire Terminologique X  1 to help bilingual Canadian people to use the correct term in each official language. A Thesaurus in IR is used for docu-ment indexing, often for manual indexing. Hence thesaurus may include word entries that are not really terms because they are not used in actual text. For example, the entry Technology and Food and Beverages in MESH thesaurus is not a term in medicine, but is used to support the the-saurus hierarchy. Thesaurus and Terminology are practical structure, oriented toward word usage. Ontology is more oriented toward abstract description and it is usually built from formal description of concepts. Of course all these do-main knowledge examples are still incomplete compared to the effective content of an encyclopaedia, but before being able to use complex and complete knowledge bases, our hy-pothesis is that even a simple domain knowledge model can help the indexing process of the IRS.

In this paper we use domain knowledge and emphasis on the importance of using problem knowledge in conjunction with domain knowledge: our experience shows that a real difference is obtained when using problem knowledge even in a rather simple way. Let X  X  first examine the case of textual indexing. Later we will describe conceptual image indexing.
Domain knowledge is the key for associating concepts to text and then to use them as index. Because we are dealing with text, this resource should incorporate all useful terms and term variations of a domain, eventually in different lan-guages, and each term should be properly associated to con-cepts. It is costly to manually build such a resource. Sec-ond, we need an automated tool to identify concepts from raw text. Concepts identification is difficult because of the inherent ambiguity and flexibility of the natural language. There are also lots of language phenomena such as elision that complicates the task of detecting concepts. Moreover, by definition, concepts have unique meaning. Selecting con-cept from text means disambiguating the text, which is al-ways a very difficult task [15]. Finally, a flat set of concepts can lead to a sharp decline of recall if the system is not able to establish a link from general concepts in a query (e.g.  X  X one fracture X ), and perhaps more precise concepts present in documents (e.g.  X  X racture of the femur X ). Relation in the knowledge resource is hence mandatory. To sum up, for a conceptual text indexing we need: http://www.gra nddictionnaire.com
Conceptual text indexing is then the operation of trans-forming natural language document into an indexing struc-ture of concepts (sets, vectors, graphs, etc) by the way of the conceptual mapping algorithm using the domain knowledge resource.
One may think that dealing with a precise domain may re-duce some of the concepts extraction problems, like ambigu-ity. This is partially true. Term ambiguity arises when dif-ferent concepts may be mapped to a single term. In practice, ambiguity depends on the precision of the domain knowledge resource. If we reduce the domain, then we also reduce pos-sible term acceptions, hence also ambiguity. For example,  X  X -ray X  may refer to a wave in physics, but could only refer to an image modality in radiology. Unfortunately, when we have more precise concepts (and terms), we are confronted with another form of ambiguity: a structural ambiguity .At syntactic level, structural ambiguity occurs when a phrase has more than one underlying structure, such as  X  X he girl hit the boy with a book X . At a concept level, it corresponds to several ways of concept extraction, where some are composi-tion of others. For example the term  X  X ight lobe pneumonia X  can be associated to a single concept, but can be split into two terms associated with other concepts:  X  X ight lobe X  and  X  X neumonia X .
 A solution is to model  X  X oncepts structure equivalence X . This consists on setting up a model that expresses concept composition and relations. Some of these relations can be equivalence or subsumption. A Terminological Logic can be used, see for example [30] but it is often neither simple nor possible to set up such process for indexing purpose using a real large set of concepts, because concepts have to be expressed in the chosen formalism. A large ontology on medicine with concepts expressed in a logical format does not yet exit.

Another common difficulty for concept extraction is term variation. Despite the fact terms should be stable noun phrases [10], there are still in practice a lot of variations in technical terms. It is the role of the terminology to list all term variations, but in practice some variations have to be processed by the conceptual mapping algorithm.
In spite of these difficulties, conceptual indexing can pro-duce a high precision multilingual index, and can solve very precise queries. This solution is adapted for the medical domain. In the following we detail the steps that lead to concept identification.
For IR purpose, we concentrate on noun phrases only, be-cause they are supporting most part of document theme. Globally the following steps are needed to identify concepts from texts:
The identification step is critical because it relies on the quality of the terminological resource. A too small resource will produce silence in concept detection, a larger will pro-duce ambiguity. The deepness of a resource is also impor-tant. It refers to the size of the conceptual hierarchy and the focus of the concepts. For example concepts in deep resources are associated to very long noun phrases, like the concept 2 C0161118 associated to the phrase  X  X listers with epidermal loss due to second degree burn of chest wall, ex-cluding breast and nipple X . Deep resources will produce much more detailed and precise concepts and can lead to structural ambiguity. In the following we show how these steps are instantiated in practice. As we focus on the medical domain, we have selected UMLS for our Domain Knowledge resource simply because no other resources of its size exists currently. In fact, UMLS is a meta-thesaurus, it means a merge of existing thesaurus and terminology. Merging different thesaurus does not lead to an ideal conceptual structure: not all entries are terms,
Example from UMLS so not all entries can be found in actual text, like C0029537  X  X ther chest pain X . Moreover, different thesaurus structures (ex: hierarchy) have to be merged in one structure. This is a difficult problem. The merge has been done by exhibit-ing concepts linking multiple terms from multiple sources. UMLS is a still good candidate to approximate a domain knowledge resource for medical image and text indexing. At first because of its size: the base includes more than 5.5 millions of terms in 17 languages and 1.1 million of unique concepts. It is maintained by specialists with two updates a year. Unfortunately, UMLS is neither complete, nor consis-tent. In particular, the links among concepts are not equally distributed. The inter-concept relationship (like hierarchies) is those from the source original thesaurus. Hence there is a sort of redundancy as multiple similar path can be found between two concepts using different sources. In order to have a common categorization of this concept set, UMLS has a global high level semantic category called semantic types and semantic groups [8] assigned manually and inde-pendently of all thesaurus hierarchies by the meta-thesaurus editors. These structures are the only one that are consistent for the whole data set.
Based on UMLS, we use two different tools for concept identification: MetaMap and XIotaMap. MetaMap [4, 6] is provided by NLM and can only treat English texts. Concept identification follows the general steps defined previously. For other language (French and German), we have used XIotaMap 3 tool. The steps are:
We thank Loic Maisonnasse for the development of this tool.
XIotaMap does not solve the structural ambiguity: it in-cludes in the index all concepts potentially extracted from texts. We have to note, as verbs are not treated in both of these tools, so some part of the original information is lost. For example,  X  X he chest is infected X  cannot trigger the concept of  X  X hest infection X  4
We propose in the following, a simplified output example of MetaMap from the sentence  X  X how me a chest x-ray with tuberculosis X . At first the parser produces the POS ( tag ) and a simplified dependency tree with identification of the head and mod ifiers of the noun phrase. phrase( X  X how X ,[verb([lexmatch([show]), phrase(me,[pron([lexmatch([me]),inputmatch([me]) phrase( X  X  chest x-ray X ,
Only noun phrases are then mapped to concepts with an evaluation (negative number) of each possible concept proposition. For each concept proposition, each word of the associated term is mapped to the list of source term. For example [2,2],[1,1] for the third candidate means that the second term "x" of "chest x-ray" matches with "X" of the candidate term "X-ray" associated with the concept C0034571 . The number that follows is the distance of this matching: 0 is an exact spelling matching, 1 is a inflectional variant (ex: plural form, see [5] for more information). candidates([ ev(-923, X  X 0202783 X , X  X hest x-ray X , ev(-895, X  X 0856599 X , X  X reast X-ray X ,[breast,x,ray] ev(-861, X  X 0034571 X , X  X -ray X , X  X oentgenographic X  ev(-861, X  X 0043299 X , X  X -ray X  ev(-861, X  X 0043309 X , X  X -ray X , X  X oentgen Rays X  ev(-861, X  X 1306645 X , X  X -ray X  ...

In this example, 17 possible concepts have been identi-fied as possible association to the text  X  X  chest x-ray X . The ordering is only based on syntactic variations and it is not supposed to be a semantic distance. Hence this ordering cannot be considered as a disambiguation. In our work, we are interested in precision oriented indexing, so we have de-cided to retain for indexing the best MetaMap proposition, plus all sub partial matching with no variation (i.e. a 0 dis-tance value in the matching ev list). This is a way to take into account structural ambiguity, even if it is probably not the best representation.
Unfortunately we do not known for the moment the real proportion of situation where verbs are interesting to be treated in the CLEF collection.
In an ideal situation, the conceptual model should be com-posed of a logical structure to represent index, and a fuzzy subsumption for the matching process. Unfortunately, as we are not able to automatically build such a structure, we pro-pose to use a simple set structure with some weighting. The matching is then a weighted intersection set. There is a pro-fusion of weighting schemes for text indexing at world level, based on term distribution assumption. Most are based on probability theory [2] and are quite effective on textual in-dexing. Concept identification step associates a word se-quence to a set of possible concepts. It seems reasonable to first make the hypothesis that the concept distribution of such a conceptual indexing approach will be similar to word distribution. In reality i t is incorrect: first because concepts may be associated with large terms, hence concept statistical distribution may be different from single word dis-tribution. Second, because of structural ambiguities: we put in the index several possible concepts associated to different coverage of a noun phrase. In this way we violate the usual independence assumption between items in the index that is behind all weighing scheme. We guess there are some more researches to be done in this area to come out with a weight-ing scheme adapted to conceptual indexing. In this paper, we will experiment only few classical weighting schemes.
We have previously shown the usage of Domain Knowl-edge at indexing time. We propose to use Problem Knowl-edge (PK) at querying time. Our assumption is that queries are structured at a high conceptual level. It means that we consider the semantic groups of UMLS as a simple descrip-tion of problem knowledge. At least, this choice is almost true for quite all CLEF queries. We have found out that most of the queries explicitly refer to two or three semantic groups. For example  X  X how me x-ray images of vertebral osteophytes X  refers to a modality image, an anatomy and a pathology. We model the influence of PK by a function PK multiplied to the normal RSV (see equation 1).
 We have tested two PK functions: Both techniques have brought great improvement to the re-sults, as shown in the experiments (see section 7 table 3). So Problem Knowledge seems to be the key knowledge to use in Conceptual Text Indexing, in order to have a noticable quantum leap in the results.
We perform our experiments on the Medical CLEF collec-tion (see details in section 7). Each medical report is associ-ated with at least one image. A document in each different language follows a parallel treatment path. The indexing of these different sources in the case of documents written in different languages can produce different indexes or can be merged. In that case, we come out with a unique multilin-gual conceptual vector. We have made the assumption that conceptual indexing do behave like word indexing. So we propose to experiment usual IR weighting and matching: This DFR weighting scheme has been proposed by Gianni Amati in [1]. Theoretical discussions about this approach can be found in [3].This model is based on the computation of the divergence distribution from a random distribution. The formula for the weighting is given by: With the following variables: Frequency f  X  t,d is normalized by the length W d of document d related to average documents length awr W d .Aconstant c influences this average: With the following variables:
For all our experiences, we have taken c =1. Wehaveno-ticed small improvement for other value (ex: 0 . 7), but this change is difficult to optimize in a real situation, i.e. with-out having the query relevance. For conceptual indexing, language model seems inappropriate: the basic assumption in all language models is that the matching is related to the probability of generating the query considering a language model derived from the document (and also the corpus). As a language model is just a probability distribution of terms, it may be interesting to extend it to concepts. Hence we are about to experiment this model too.
On the visual side, the four elements described in section 4 have equivalence in the image side. We have set up a list of visual terms associated to UMLS concepts. They are typ-ical patches characterized by a visual appearance in medical image regions and having an unambiguous meaning. Visual terms are associated to a set of concepts, for example the modality of the image and anatomy of what is shown on this patch. The set of concept and conceptual structure is simi-lar to text. Of course we have developed a dedicated image to concept mapping algorithm. We have experimented two complementary indexing approaches:
This global indexing is based on a two level hierarchi-cal classifier according to mainly modality concepts. This modality classifier is learned from about 4000 images split in 32 classes: 22 grey level modalities, and 10 color modal-ities. Each indexing term is characterized by a modality, anatomy (e.g. chest X-ray, gross photography of an organ) and sometimes, a spatial concept (e.g. axial, frontal), or a color percept (color, grey).

Training images come from CLEF database (about 2500 samples), from the IRMA database (about 300 samples), and from the web (about 1200 samples). Images from CLEF were selected after modality text concept extraction, fol-lowed by a manual filtering. The first level of the classifier corresponds to a classification for grey level versus color im-ages using the first three color moments in the HSV on the entire image. The second level corresponds to the classifi-cation of modality knowing the image is in the grey or the color cluster. For the grey level cluster, we use grey level histogram (32 bins), texture features (mean and variance of Gabor coefficients for 5 scales and 6 orientations), and thumbnails (grey values of 16x16 resized image). For the color cluster, we have adopted HSV histogram (125 bins), Gabor texture features, and thumbnails with zero-mean nor-malization. For each SVM classifier, we adopted a RBF kernel exp(  X  X  x  X  y | 2 ) with a modified city-block distance: tors; x f ,y f are feature vectors of type f; N f is the feature vector dimension, and F is the number of feature types 5 . This just-in-time feature fusion within the kernel combines the contribution of color, texture, and spatial features equally [19]. Probability of a modality MOD i for an image z is given by:
P ( MOD i | z )= P ( MOD i where C and G denote the color and the grey level clusters respectively, and the conditional probability P ( MOD i |
F = 1 for the grey versus color classifier, F =3forthe conditional modality classifiers: color, texture, thumbnails. is given by: where D c is the signed distance to the SVM hyperplane that separate class c from the other classes of the cluster V .
After learning using SVM-Light [17], each image z is in-dexed according to modality given its low-level features z Indexes weight are probability values given by Equation (5).
Local indexing uses Local Visual Patches (LVP). LVP are grouped in Local Visual Concepts (LVC) linked with con-cepts from UMLS. In these experiments, we have adopted color and texture features, SVM classifier with same param-eters as global indexing. Color features are the three first color moments of Hue, Saturation, and Value. Texture is mean and variance of Gabor coefficients using 5 scales and 6 orientations. Zero-mean normalization is applied. The training dataset is composed of 3631 LVP extracted from 1033 images mostly coming from the web (921 images com-ing from the web and 112 images from the CLEF collection  X  0 . 2%).

After learning, LVC are identified during image indexing using image patches without region segmentation to form a LVC histogram. See [20] for more details about this index-ing technique. Each patch is then classified into one of the LVC using the Semantic Patch Classifier. Histogram aggre-gation per block gives the final image index. Each bin of the LVC histogram of a given block B corresponds to the prob-ability of a LVC i presence in this block. This probability is computed as follows: where B is an image block, z an image patch, | z  X  B | the intersection area between z and B ,and P ( LVC i | z )isgiven by Equation (6).
Fusion between text and image can be done at query-ing time or at indexing time. Both are possible because we have a real inter-media index in a common conceptual space. The querying time fusion combines visual and tex-tual similarity measures: the Relevance Status Value (RSV) between a mixed 6 query Q =( Q I ,Q T ) and mixed document D =( D I ,D T ) is then computed by an normalized weighted linear combination of RSV: RSV ( Q, D )=  X RSV I ( Q I ,D I ) where RSV V is the maximum of visual similarity between all images of Q I and all images of D I , RSV T is the textual Rel-evance Status Value. D I denotes the image database, and D
T denotes the text database. The factor  X  allows control of the weight between textual image similarity. Indexing time fusion can be done by the merge of index.
The test-bed we used for experiments, the ImageCLEFmed benchmark, includes 50026 medical images with associated medical reports in English, French and German. The 30 top-ics for 2006 also include images and associated text. Word-based text indexing results are in table 1. In DRF* and BM25*, query weight are normalized with log, idf and vector size. We have used the X-Iota system [9] for indexing and retrieval. The result tables show Mean Average Precision (MAP) across all queries. As expected, probabilistic mod-els have good results, but the difference with the classical Vector Space Model (VSM) is not noticeable, in some case even this VSM model is better which is quite unusual. Con-ceptual text indexing results are in table 2. It is interesting to note that differences between weighting schemes are not significant. The improvement using concepts is noticeable for every weighting but also not very high. The decisive im-provement comes with the use of Problem Knowledge. This result in table 3 shows clearly that the use of this knowledge always improve the results. This improvement is compared to the conceptual indexing with all languages of table 2. Re-sults are also in favour of intersection of the semantic groups. It means that the matching at this semantic level is very im-portant. We think it is easy to understand: these semantic groups produce an implicit structuring of the query. Docu-ments that include most of these semantic groups are better than the one that partially answer them. In other words, a document that does not include every sub domain of a query is less relevant.

On the image side, we have experimented the three re-trieval methods: local; global and the mean of both (see last column  X  = 1 of table 4). In the global method, an image is represented by a concept histogram, each bin corresponding to a modality probability. We use Manhattan distance to compute the RSV. For the local UMLS visual indexing, the RSV is the mean of block by block Manhattan distances on
I for image and T for text all the possible matches. We have then combined these two methods (All) with the mean fusion of the global and local retrieval. Results are quite low but near the top compared to other CLEF results: this visual task is very difficult.
Finally, table 4 shows the mutual influence between con-ceptual text and image indexing. Results show enhance-ments for all  X  in the range from 0 . 1to0 . 9. This clearly shows the interest of an inter-media conceptual indexing. We also have to mention that these results outperform those obtained in 2006 by CLEF participants in text and text plus image. This clearly shows the potential of knowledge-based and conceptual indexing.
Our work shows that using concepts instead of words is a good solution for specialized domain, but not enough to make a breakthrough. Problem Knowledge (PK) on query side is a very effective technique, and conceptual indexing is mandatory for using PK. We can conclude that inter-media conceptual indexing outperforms all other techniques, forexamplethoseusedinofficialresults 7 of CLEF 2006, in particular those word-based. We can claim that this is one of the first use of concept that has a very obvious benefice to IR. We strongly believe that the future of IR lays on the use of large knowledge sets, especially Domain, Problem and Common Sense Knowledge.

This work is the result of a French-Singaporean collabora-tion. This work also partially belongs to the ISERE project, sponsored by the French Ministry of Foreign Affairs. We thank Loic Maisonnasse for the development of XIotaMap. [1] G. Amati, C. Carpineto, and G. Romano. Comparing [2] G. Amati and C. J. Van Rijsbergen. Probabilistic
We ran best in CLEF 2005 and 2006 official results using a similar approach. [3] G. Amati and C. J. van Rijsbergen. Probabilistic [4] A. Aronson. Effective mapping of biomedical text to [5] A. R. Aronson. Metamap: Mapping text to the umls [6] A. R. Aronson, T. C. Rindflesch, and A. C. Browne. [7] M. Baziz, M. Boughanem, and N. Aussenac-Gilles. [8] O. Bodenreider and A. T. Mccray. Exploring semantic [9] J.-P. Chevallet. X-iota: An open xml framework for ir [10] B. Daille, B. Habert, C. Jacquemin, and J. Royaut  X  e. [11] M. Ferecatu, N. Boujemaa, and M. Crucianu. Hybrid [12] Y. Gao and J. Fan. Incorporating concept ontology to [13] J. Goguen. What is a concept ? Lecture Notes in [14] T. Huibers, I. Ounis, and J.-P. Chevallet. Conceptual [15] N. Ide and J. Veronis. Introduction to the special issue [16] C. Jacquemin, J. L. Klavans, and E. Tzoukermann. [17] T. Joachims. Learning to Classify Text using Support [18] D. B. Lenat. Cyc: a large-scale investment in [19] J. Lim and J. Jin. Discovering recurrent image [20] J.-H. Lim and J.-P. Chevallet. Vismed: A visual [21] J. Lin and D. Demner-Fushman. The role of knowledge [22] D. Lindberg, B. Humphreys, and A. Mccray. The [23] H. Liu and P. Singh. Conceptnet a practical [24] C. Meghini, F. Sebastiani, U. Straccia, and C. Thanos. [25] Y. Qiu and H.-P. Frei. Concept based query expansion. [26] S. E. Robertson and S. Walker. Some simple effective [27] M. Sanderson. Word sense disambiguation and [28] R. C. Schank, J. L. Kolodner, and G. DeJong. [29] H. Schmid. Probabilistic part-of-speech tagging using [30] F. Sebastiani. A probabilistic terminological logic for [31] C. Stokoe, M. P. Oakes, and J. Tait. Word sense [32] E. Tzoukermann, J. L. Klavans, and C. Jacquemin. [33] C. J. van Rijsbergen. A non-classical logic for [34] E. M. Voorhees. Natural language processing and
