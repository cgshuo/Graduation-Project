 In this pap er, we consider the problem of adapting statistical classi ers trained from some source domains where lab eled examples are available to a target domain where no lab eled example is available. One characteristic of suc h a domain adaptation problem is that the examples in the source do-mains and the target domain are kno wn to follo w di eren t distributions. Thus a regular classi cation metho d would tend to over t the source domains. We presen t a two-stage approac h to domain adaptation, where at the rst gener-alization stage, we look for a set of features generalizable across domains, and at the second adaptation stage, we pick up useful features speci c to the target domain. Observing that the exact objectiv e function is hard to optimize, we then prop ose a num ber of heuristics to appro ximately achiev e the goal of generalization and adaptation. Our exp erimen ts on gene name recognition using a real data set sho w the e ec-tiveness of our general framew ork and the heuristics. I.2.7 [ Arti cial Intelligence ]: Natural Language Pro cess-ing| text analysis ; I.5.1 [ Pattern Recognition ]: Mo dels| statistic al algorithms, exp erimen tation classi cation, domain adaptation, feature selection, semi-sup ervised learning, logistic regression
Classi cation is a commonly used technique for kno wledge managemen t, and in particular, for managing textual infor-mation. Besides text categorization, man y other text analy-sis tasks also rely on accurate classi cation algorithms. For example, information extraction problems suc h as named entity recognition and relation extraction from textual data are often cast into classi cation problems. Spam ltering is usually carried out with classi ers trained from kno wn spam emails. Sen timen t analysis suc h as classifying sub jectiv e vs. objectiv e or positiv e vs. negativ e statemen ts is also a typical classi cation problem.

In standard classi cation, the lab eled data on whic h we train our classi er and the data on whic h we want to mak e predictions come from the same domain, and thus share the same distribution. However, in realit y, we often face situ-ations where we want to mak e predictions on a target do-main, but the lab eled examples we have are all from some di eren t sour ce domains, and the data in the target and the source domains are kno wn to follo w di eren t distribu-tions. For example, when training spam lters, we only have example spam and ham emails from some public re-sources, but ideally we would like to customize the spam lter for a particular user, esp ecially if we have some (un-lab eled) emails from the user's mailb ox. When classifying positiv e and negativ e pro duct reviews, we may have lab eled reviews of some pro ducts, but would like to classify unla-beled reviews of some other pro duct. Another example is gene name recognition in biomedical text mining. We may want to recognize gene names in literature about a \new organism" (e.g., honey bee), but we only have lab eled train-ing data for some well-studied \old organisms" (e.g., y and yeast). In these situations, a regular classi er trained from the lab eled examples in the source domains may not perform well on the unlab eled examples in the target domain because it may over t the source domains. We thus face a domain adaptation problem|w e need to adapt classi ers trained from one or sev eral source domains to a target domain that is di eren t from but related to the source domains.
Note that although in standard classi cation we also face the problem of over tting, the problem would be alleviated if we have a lot of training data. In domain adaptation, however, the problem of over tting is inher ent because our training data is alw ays a biased sample w.r.t. the target domain; the risk of over tting would not disapp ear no mat-ter how much training data we have in the source domains. Thus the problem of domain adaptation is fundamen tally di eren t from standard classi cation.

Formally , we de ne the general domain adaptation prob-lem in the follo wing way. First of all, we have a classi cation task that involves an input variable X , represen ted by a p -dimensional feature vector, and a discrete output variable Y . Let X and Y denote the set of values X and Y may S tak e, resp ectiv ely. The classi cation task is to predict the correct value of Y given any value of X . Mo deling the con-ditional probabilit y distribution p ( y j X ) appropriately is the key problem in order to achiev e high classi cation accuracy; once p ( Y j X ) is estimated, we can mak e predictions based on this distribution.
 We further assume that there are K source domains fD s k g and a target domain D t , eac h having its only join t distri-bution p ( x ; y ). Although p ( X ), the marginal probabilit y distribution of X , may be very di eren t in these di eren t domains, we in general assume that the conditional proba-bilit y distribution p ( Y j X ) is prett y stable across domains. In fact, without this basic assumption, it is hard to learn from the source domains and transfer the kno wledge to the target domain. However, assuming that di eren t domains share the same p ( Y j X ) does not mean that a mo del learned in a source domain to appro ximate p ( Y j X ) can still mak e good predictions on a target domain, because the mo del learned from the source domain only pro vides good appro x-imations to p ( Y j X = x ) for an example x in the source domain training set or near some source domain example, but in general we can exp ect the target domain to con tain examples that do not occur in the source domain or are not close to any source domain example.

We assume that we have a set of lab eled examples for eac h source domain, and a set of unlab eled examples for the D , and f x t i g N t i =1 the examples for D t . The goal of domain adaptation is then to estimate a good mo del for p ( Y j X ) from the lab eled examples suc h that this estimated mo del can mak e good predictions on the unlab eled examples in the target domain.

To solv e the domain adaptation problem, intuitiv ely, we want to mak e the most use of the lab eled examples without over tting the source domains. We also want to exploit the unlab eled examples in the target domain to possibly pick up patterns that do not exist in the source domains. Follo wing this intuition, we prop ose to address the domain adaptation problem in two steps: (1) We rst nd the common fea-tures that are imp ortan t for both the source and the target domains. (2) We then iden tify useful features that are spe-ci c to the target domain but cannot be learned from the source domains, possibly through semi-sup ervised learning. We thus prop ose a two-stage approac h to domain adapta-tion, where at the rst stage we iden tify a set of generalizable features for the classi cation task and learn the appropriate weigh ts for these generalizable features, and at the second stage, we pick up useful features speci c for the target do-main by using some examples from the target domain with pseudo lab els. The two-stage idea can be illustrated in an abstract way by Figure 1. For clarit y, we assume that there is only one source domain. Here, the two ovals represen t the source and the target domains, resp ectiv ely. The shaded area represen ts the instances well-explained by the classi -cation mo del. At the rst stage, we want to shift the mo del towards the common part shared by the source and the tar-get domains, and at the second stage, we want to expand the mo del with characteristics speci c to the target domain.
We sho w that the two-stage approac h can be formally de-ned as an optimization problem. However, since it is di-cult to optimize the objectiv e function directly , we prop ose two heuristics to appro ximately solv e the problem. Our ex-perimen ts on gene name recognition using a real data set sho w that this two-stage approac h coupled with the heuris-tics performs better than standard sup ervised learning and a standard semi-sup ervised learning metho d, whic h we regard as baselines.

The rest of the pap er is organized as follo ws. In Section 2, we introduce the two-stage approac h to domain adaptation, form ulate the problem as an optimization problem, and sho w two heuristics to appro ximately optimize the objectiv e func-tion. We then explain some implemen tation details of the two-stage approac h in Section 3. We sho w our exp erimen t results in Section 4. Finally we discuss related work in Sec-tion 5 and conclude in Section 6.
We will use the logistic regression classi er as a basis to presen t the prop osed two-stage approac h to domain adap-tation [10]. Our approac h to domain adaptation, however, is general to all linear classi ers, and therefore should also be applicable to other classi ers suc h as supp ort vector ma-chines and perceptrons.

We rst brie y review the logistic regression mo del and discuss why it would over t the source domains if we do not regularize the mo del appropriately .
In logistic regression mo dels (a.k.a. maxim um entrop y mo dels) as well as other linear classi cation mo dels, we assume that the input variable X is represen ted by a p -dimensional feature vector, and the classi er is a weigh t vec-tor (in the case of binary classi cation) or a set of weigh t vectors (in the case of multi-class classi cation) that rep-resen t separating hyperplanes in the p -dimensional vector space. Without loss of generalit y, in the rest of this pap er, we consider only multi-class classi cation problems.
For logistic regression mo dels, we assume that the condi-tional probabilit y of a class lab el y given an example x is given by where Here w is a p jY j weigh t matrix. w y denotes the column vector of w corresp onding to the class lab el y , and w T note the transp ose of w y . w T y x is therefore the inner pro duct of w y and x .

In the standard form ulation of sup ervised learning, we have a set of training examples together with their lab els, ing regularized empirical risk minimization [14]. Speci cally , if we use log likeliho od as our loss function, we optimize the follo wing objectiv e function: where k w k 2 = y 2Y k w y k 2 , and is a regularization pa-rameter that is man ually set based on prior kno wledge or empirically set by cross validation. The regularization term k w k 2 is used to avoid over tting the training data.
To see why we may over t a domain with this kind of mo dels, let us consider the simple case where all features are binary . Intuitiv ely, the weigh t for a given feature f and a given class lab el y would be high if man y examples in the training set with lab el y con tain the feature f while man y examples with lab els di eren t from y do not con tain the feature f , i.e., feature f is highly correlated with y in the training domain. When we move to a target domain that is di eren t from the training domain, if the weigh ts learned from the training domain no longer give good pre-dictions, a reasonable explanation is that some features that have high correlations with certain class lab els in the train-ing domain do not have as high correlations with the same class lab els any more in the new domain, and vise versa. However, the training domain is still useful to us if there ex-ist some features that have high correlations with the same class lab els in both the training and the target domains. We call these features gener alizable features. If in the training domain, these generalizable features are weak er than those useful domain-sp eci c features, then the generalizable fea-tures may not get high weigh ts because of the regulariza-tion term k w k 2 , whic h penalizes high weigh ts. In another word, because of this regularization term, generalizable fea-tures are comp eting with domain-sp eci c features for the weigh t mass. Ideally , if we want to learn a mo del from the training domain that is also useful in the target domain, we want the weigh t mass to be assigned to those generalizable features rather than those domain-sp eci c features. This kind of skewe d regularization can be achiev ed by imp osing a larger to the weigh ts of those domain-sp eci c features. In Section 2.2, we will sho w how this skewed regularization is imp osed in the objectiv e function.
The rst stage of our two-stage approac h to domain adap-tation is therefore a domain generalization stage. We have sho wn that in order to mak e the mo del learned from the source domains useful in the target domain, we need to reg-ularize the learning pro cess suc h that the weigh t mass is mostly kept on the generalizable features. There are two problems that need to be solv ed here: (1) To iden tify the generalizable features; (2) To learn appropriate weigh ts for these generalizable features. We rst sho w how the sec-ond problem can be solv ed given a xed set of generalizable features. We then sho w how to iden tify the generalizable features.

We rst explain some notation. To easily represen t the separation of the generalizable features from other features in our mathematical form ulation, we introduce a matrix A to represen t the set of generalizable features. Formally , A is an h p matrix ( h &lt; p ) that transforms an instance x represen ted as a p -dimensional vector in the original feature space into an h -dimensional vector z = A x in the reduced generalizable feature space. In another word, A is a matrix in whic h eac h entry is either 0 or 1, and AA T = I h h . For example, the follo wing 2 6 matrix A chooses the second and the fth rows in a 6-dimensional feature vector to form a new 2-dimensional feature vector.
 In the rest of this pap er, the constrain ts that eac h entry of A is 0 or 1 and AA T = I h h are implied whenev er we refer to A . Suc h a matrix A essen tially de nes a set of h generalizable features. Here we assume that the num ber of generalizable features h is xed.

We now sho w how to learn a set of appropriate weigh ts for the generalizable features selected by A given a xed A . In standard sup ervised learning, we learn a single weigh t matrix w for all features using all the training examples. When the training data falls into sev eral domains, however, we cannot exp ect the optimal weigh ts to be the same for all domains. We thus introduce K di eren t weigh t matrices, f w k g K k =1 , for the K training domains. However, since the generalizable features beha ve similarly in di eren t domains, we exp ect the weigh ts for them to be similar across domains. To capture this, we decomp ose eac h w k as follo ws: where v is an h jY j matrix shared by all domains, and u k is domain-sp eci c. We can think of v as essen tially the weigh t matrix for the generalizable features.

Giv en the training examples from the source domains, and given a xed A , we can learn weigh t matrices v and f u k by optimizing the follo wing objectiv e function: The rst term in the objectiv e function is the regularization term, where di eren t regularization parameters are put on v and f u k g . The second term is the empirical risk (log likeliho od of the training data). Note that the learned ^ v and f ^ u k g are dep enden t on A , and therefore, we represen t them as functions of A .

Now recall that we want to put more weigh t mass on the generalizable features. To achiev e this goal, we simply set to be much larger than 1. With s 1, we penalize large values of f u k g more than large values of v , and therefore, we naturally give the most weigh t mass to v unless the training examples strongly favor some large values of f u k g .
Note that in (5) we have made two mo di cations to the standard learning of logistic regression mo dels: (a) We have separated a subset of generalizable features (de ned by A ) so that we now have two sets of weigh ts (i.e., v and u k for eac h domain. (b) We tie the weigh t matrix v for the generalizable features across all the domains, while allo wing some sligh t domain variation captured by f u k g .
Next, we sho w how ideally generalizable features should be de ned based on the exp ected performance on the target domain. For any A , let ^ v ( A ) be the weigh t matrix learned from the training domains, as de ned in (5). Supp ose we only use these generalizable features to mak e predictions on the target domain. Recall that our ultimate goal is to mak e good predictions on the target domain. One way to quan tify this goal is to minimize the exp ected loss over all possible examples in the target domain, whic h can be captured by the follo wing objectiv e function: where p t ( x ; y ) denote the true join t probabilit y of x and y in the target domain, and z = A x .
 Equation (6) is the ideal criterion for choosing the optimal A . However, (6) is in practice infeasible to compute because (1) we do not kno w p t ( x ; y ), and (2) a brute force enumer-ation of possible values of A is too exp ensiv e. To mak e the objectiv e function feasible to compute, our general idea is to obtain an appro ximation of A . Here we discuss two strate-gies of appro ximating A .
In (6), instead of using p t ( x ; y ), whic h is unkno wn, we can use the empirical join t probabilit y of x and y from the source domains to appro ximate p t ( x ; y ). If we mak e sev eral further appro ximations, we obtain the follo wing objectiv e function: The ^ A and ^ v chosen in this way form the nal generaliz-able mo del we use for predictions on the target domain. Note that (7) is the same as (5) except that A is now free to change inside the objectiv e function. In Section 3.1, we will explain how we can solv e this optimization problem ef-cien tly without enumerating all the possible values of A .
Note that in this appro ximation, we use the empirical risk on the training data to assess the qualit y of A , that is, we train and validate on the same data. However, to avoid over-tting, in general we want to use di eren t data for training and validation. In the next section, we sho w suc h a metho d that uses cross validation. The exp erimen t results in Sec-tion 4 also sho w that the cross validation metho d is better than the join t optimization metho d.
A better way to appro ximate A is a domain cross vali-dation metho d. Here we borro w the idea of leave-one-out cross validation from regular sup ervised learning. However, we treat eac h domain as if it were a single training example. Thus, given a xed A , we rst learn the weigh t matrix ^ v ( A ) using all but one training domains, and then test the per-formance on the held-out training domain. We rep eat this pro cedure for eac h held-out training domain, and tak e the average performance as an indicator of how good A is.
Formally , we want to nd ^ A that optimizes the follo wing objectiv e function: ^ A = arg min where z k i = A x k i , and ^ v ( k; A ) is the optimal weigh t ma-trix for the features selected by A , learned from all source domains except D s k . In another word, ^ v ( k; A ) is obtained by
However, even with this appro ximation, in practice it is still infeasible to enumerate all possible A when optimizing (8). In Sect. 3.2, we will prop ose a heuristic way to appro x-imate the optimization problem in (8).
After the rst stage of domain generalization, we will ob-tain an A , whic h represen ts the set of generalizable features learned from the source domains, as well as a set of weigh ts for these generalizable features. In the second stage of do-main adaptation, our goal is to pick up those features that are speci cally useful for the target domain, but cannot be learned from the source domains. A sensible way to achiev e this goal is to include some lab eled instances from the target domain in the learning pro cess. Since we only consider the situation where we do not have any lab eled examples in the target domain, here we adopt bootstrapping, a commonly used semi-sup ervised learning metho d, to mak e use of the target domain examples [15]. More speci cally , with the best generalizable mo del that we have learned from the source domains, we mak e predictions on the unlab eled examples in the target domain, choose the most con den t m examples together with the pseudo lab els, and include these lab eled examples in our objectiv e function to learn the weigh ts.
Formally , let ^ A be the optimal feature selection matrix that we have obtained in the rst domain generalization domain that have been predicted with the highest probabil-ities p (^ y t i j x t i ), where ^ y t i is the predicted lab el of x learn weigh t matrices ^ v and ^ u t by optimizing the follo wing objectiv e function:
Equation (10) is very similar to (5). The target domain is treated in the same way as all source domains in the ob-jectiv e function, except for the regularization parameter In general, we want to set t s because our goal is ex-actly to learn the weigh ts for the domain-sp eci c features in the target domain. After we have learned ^ v and ^ u t , we set mak e predictions on the target domain.
In this section, we discuss some implemen tation details that have been left out in Section 2.
We rst discuss how to solv e the optimization problem in (7). The problem form ulation is very similar to the optimiza-tion problem in [1], whic h can be solv ed by an alternating optimization pro cedure [3]. We thus also use alternating op-timization to solv e our problem. We give the outline of the pro cedure below.

Recall that w k = A T v + u k for eac h k . Equation (7) can then be rewritten as follo ws: ^ A; ^ v ; f ^ w k g = arg min
When f w k g K k =1 are xed, the second term in (11) is also xed, while we can vary A and v to minimize the rst term. When A is xed, we can vary v and f u k g K k =1 to minimize (7), whic h is equiv alen t to varying v and f w k g K k =1 to minimize (11). Thus, we alternate between xing f w k g K k =1 and x-function: 1. Initialize f w k g K k =1 : for eac h k , set w k to the weigh t 2. Fix f w k g , solv e for ^ A and ^ v : 3. Fix A , solv e for ^ v and f ^ u k g : 4. For all k , set w k = A T v + u k . 5. Rep eat 2, 3 and 4 until A does not change any more.
In the algorithm outlined above, the optimization problem de ned in step 3 is similar to the standard training of logis-tic regression mo dels. The optimization problem de ned in step 2 in general can be reduced to an SVD (singular value decomp osition) problem if A is an arbitrary matrix satisfy-ing AA T = I . See [1] for the deriv ation of the solution for a similar problem. In our case, since we restrict the entries of A to be either 1 or 0, the problem is further simpli ed, and the solution can be easily obtained by ranking the features with a scoring function and selecting the best h features. We leave out the technical details here.

Since in both step 2 and step 3, the value of the objectiv e function decreases, the alternating optimization pro cedure con verges to a local minim um.
We now discuss how to appro ximate the optimization prob-lem de ned in (8). First, let us consider a single comp onen t of (8):
Recall that ^ v ( k; A ) is the weigh t matrix learned from all training examples except those from D s k , with a xed A . Consider another weigh t matrix ^ ( k; A ) de ned as follo ws: In order to minimize (12), we want ^ v ( k; A ) to be as close to ^ ( k; A ) as possible because ^ ( k; A ) almost directly mini-mizes (12). To measure the similarit y between ^ ( k; A ) and ^ v ( k; A ), we can use the sum of the inner pro ducts between eac h pair of the corresp onding column vectors of ^ ( k; A ) and ^ v ( k; A ). Formally , we introduce a scoring function S ( ; v ) as follo ws: The choice of this similarit y measure can be justi ed as fol-lows. The weigh t matrices and v eac h represen t a linear classi er in an h -dimensional feature space. We can roughly think of the column vector y (or v y ) as what classi er (or v ) regards as a canonical example that belongs to class y . To measure how close these two classi ers are to eac h other, we can measure the pairwise similarit y between the canonical examples of the two classi ers, where similarit y is de ned as the inner pro duct between two vectors. It is im-portan t to note that we want to use inner pro duct instead of cosine similarit y because the larger the norm of a canonical example is, the more con den t the classi er is about that canonical example. In another word, the length of the vec-tor y roughly corresp onds to our con dence that examples belonging to class y are along the direction of this vector.
Having understo od the meaning of S ( ; v ), we can now use the follo wing optimization problem to appro ximate (8): where ^ ( k; A ) and ^ v ( k; A ) are de ned in (13) and (9), re-spectiv ely.

We still have not addressed the problem that it is not feasible to enumerate all possible A . We now mak e a -nal appro ximation, whic h allo ws us to incremen tally select h features rather than enumerating all possible subsets of features of size h . First, let ^ k be the optimal weigh t ma-trix learned from the training examples in D s k without any feature selection. Formally , Similarly , de ne ^ k as We now appro ximate ^ ( k; A ) and ^ v ( k; A ) as follo ws: What (18) and (19) mean is that we can roughly use the weigh ts learned from the training data without feature se-lection to appro ximate the weigh ts learned with feature se-lection.

Let f 1 ; : : : ; f h be the set of features selected by A . Let y;f denote the weigh t for class y and feature f in weigh t matrix . We then have Now it is clear that we can maximize (20) by selecting h features that have the highest scores
To summarize the techniques we have discussed, we have sho wn that at the domain generalization stage, we have two heuristics for nding a good set of generalizable features, represen ted by the matrix A , together with a weigh t ma-trix v . The rst heuristic is a join t optimization metho d, whic h can be carried out using an alternating optimization pro cedure. The second heuristic is a domain cross validation metho d, whic h can be appro ximated by ranking the features based on (21) and selecting the top h features. Once the top h features are selected, we still optimize (5) to nd the op-timal ^ v .

It is worth pointing out that although the rst heuristic metho d may largely increase the computational complexit y because of the num ber of iterations, the second heuristic metho d is not very exp ensiv e. For K source domains, the second heuristic metho d requires training 2 K classi ers at the domain cross validation step and training a nal clas-si er after the optimal A is found. Furthermore, although our domain adaptation metho d increases the computational complexit y at the training stage, the computational com-plexit y at the testing stage is not a ected because the out-put of our classi cation metho d is simply a weigh t matrix, whic h is the same as in regular classi cation metho d.
In this section, we sho w our empirical evaluation of the two-stage domain adaptation approac h with the prop osed heuristics.
We tested our metho d on the problem of recognizing gene and protein names from biomedical literature. The data set we used is from the BioCreA tIvE I challenge, Task 1B, and was pro cessed as describ ed in [11]. 1 In particular, the data set con tains three subsets, corresp onding to three organisms, y, mouse, and yeast. Thus we can naturally treat eac h 1 http://bio creativ e.sourceforge.net/bio creativ e 1 task1b.h tml organism as an individual domain. Note that since the lab els in this data set were not man ually assigned, the data set is noisy and the absolute performance on this data set is lower than the state-of-the-art for gene recognition. The task is cast into a classi cation problem to predict the boundaries of gene men tions, where eac h word in the text is classi ed as either part of a gene name or outside of any gene name. We follo w a commonly used Mark ov mo del based sequen tial tagging metho d to recognition gene names in this way [8]. We use F1 as the primary performance measure, where F1 is de ned as
We ran three parallel sets of exp erimen ts. In eac h set of exp erimen ts, we use two organisms as the source domains, and the third organism as the target domain. We refer to the three sets of exp erimen ts as F+M ) Y, M+Y ) F and Y+F ) M, where F, M and Y denote y, mouse and yeast, resp ectiv ely.
 Our domain adaptation metho d consists of two stages. For eac h stage, we compare our metho d with a corresp ond-ing baseline metho d. For the generalization stage, we con-sider a baseline metho d whic h com bines the two training do-mains without considering the domain di erence. We also consider feature selection in the baseline metho d, that is, we rst rank the features based on some commonly used feature selection criterion, and then select the top h features. In our exp erimen ts, we used the 2 statistic measure to rank the features. We call this baseline metho d BL . We implemen ted the rst stage of our metho d using both the join t optimiza-tion heuristic and the domain cross validation heuristic. We call the rst DA-1 and the second DA-2 . When comparing DA-1 and DA-2 with BL, we vary the value of h for all three metho ds.

For the adaptation stage of our domain adaptation metho d, we consider a baseline metho d that uses regular bootstrap-ping. In particular, at the i 'th round of bootstrapping, we use the curren t mo del to lab el the sen tences in the target domain, and choose m = 200 i sen tences that are lab eled with gene men tions and are predicted with the highest prob-abilities. We add these m sen tences with the predicted lab els to the training set, and retrain the mo del. We call this base-line semi-sup ervised learning metho d BL-SSL . In compari-son, our domain adaptiv e metho d also chooses m sen tences in eac h round of bootstrapping in the same way, but uses (10) to learn a new mo del. Since our results sho wed that DA-2 is better than DA-1, in the adaptation stage, we only com bined DA-2 with bootstrapping. We call this metho d DA-2-SSL .

In all exp erimen ts, we set to 10 6 . This value was cho-sen based on cross validation on the training data. In DA-1, DA-2 and DA-2-SSL, we set s to 10 6 . This value was ar-bitrarily chosen to be sucien tly large. In DA-2-SSL, we set t to 1. This value was also arbitrarily chosen to be sucien tly smaller than s . In Table 1, we compare the performance of BL, DA-1 and DA-2 when h is set to the total num ber of features (desig-nated as Max in the table) and the optimal value (designated as Opt in the table). First, we can see that when h is set to the total num ber of features, DA-1 and DA-2 either per-form similarly to BL, or perform sligh tly better than BL. This comparison sho ws that even if we include all features in the generalizable set, considering the domain di erence in the training data and optimizing (5) to learn the com-mon weigh ts shared by all training domains is still better than ignoring the domain di erence. Second, the optimal performance achiev ed by DA-2 is better than that of DA-1, whic h, in two out of the three cases, is better than that of BL. This comparison sho ws the adv antage of the domain adaptiv e metho d if we can appropriately set h . It also sho ws that in general the domain cross validation heuristic is better than the join t optimization heuristic.

In Figure 2, we sho w the performance of the three meth-ods when the value of h varies from 1 to the total num ber of features. As we can see, for F+M ) Y and Y+F ) M, BL achiev es better performance when a small num ber of features (100 features) are used, but the performance drops when more features are included. For M+Y ) F, BL achiev es the best performance when 10000 features are used. In all three settings, however, the performance of BL at h = 100000 (roughly one ten th of the total num ber of features) is much lower than the performance when all features are used. This uctuation of BL suggests that the 2 statistic measure com-puted from the source domain examples is not reliable any more on the target domain. Since in practice, it is hard to predict the optimal value of h , DA-1 and DA-2 are more robust than BL for domain adaptation because their perfor-mance is more stable when h is relativ ely large.
For the metho ds BL-SSL and DA-2-SSL, we choose the best mo dels learned by BL and DA-2 as the starting mo d-els, resp ectiv ely. In another word, we assume that the op-timal value of h is used. We also consider another baseline, BL-SSL-2 , where we use all features instead of the top h fea-tures. The reason we include BL-SSL-2 is that we found that in the case with F+M ) Y, BL-SSL-2 performed reasonably but BL-SSL performed poorly .

In Table 2, we sho w the performance of the three metho ds when m = 1000 and when m is set optimally (designated as Opt in the table), i.e., when we stop bootstrapping at the iteration righ t before the performance decreases. We can see that when m = 1000, DA-2-SSL alw ays performs better than BL and BL-2, although in Y+F ) M, the impro vemen t is minor. When m is set optimally , DA-2-SSL performs sig-ni can tly better than the two baseline metho ds.
 In Figure 3, we sho w the comparison between BL-SSL, BL-SSL-2 and DA-2-SSL when m varies from 0 to 1000. We can mak e a num ber of observ ations from Figure 3. First, the performance of these semi-sup ervised learning metho ds does not alw ays increase as m increases. Indeed, in semi-sup ervised learning, since the target examples added to the training set may not be lab eled correctly , when more target examples are added, we may introduce noise and therefore decrease the performance. Second, except for BL-SSL with F+M ) Y, the performance of the two baseline bootstrap-ping metho ds monotonically increases as m increases, but the performance of DA-2-SSL decreases as m increases when m is above a certain num ber. This comparison suggests that DA-2-SSL may be a ected by the noise in the training data more than the baseline metho ds. Indeed, there is a tradeo between adaptation and robustness. Because of the noise in the target examples with pseudo lab els, when we adapt to the target domain using these target examples, we can pick up either correct or incorrect classi cation patterns. Since DA-2-SSL is a more aggressiv e adaptiv e metho d than BL-SSL and BL-SSL-2, it will both gain more from the correct information and su er more from the noise con tained in the target examples with pseudo lab els. Nev ertheless, DA-2-SSL outp erforms both baselines in the whole spectrum of values of m . Also, in the cases of F+M ) Y and M+Y ) F, we can see that the performance of DA-2-SSL is still stable when m increases. In the case of Y+F ) M, 600 is the threshold for m under whic h the performance is also stable. An imp ortan t future researc h question is to automatically set m inside a safe range.

The di erence between BL-SSL and DA-2-SSL is attributed to two factors: the di erence between the pseudo lab eled sen tences added to the training set, and the di erence be-tween the learning algorithms. In order to separate the two factors, we designed another diagnostic metho d, DA-2-BL-SSL , where we choose the best 200 sen tences predicted by DA-2 to add to the training set at the rst round of boot-strapping, but we use the regular bootstrapping metho d as in BL as the learning algorithm. In other words, DA-2-BL-SSL uses the same pseudo lab eled sen tences in the rst round as DA-2-SSL, but uses the same learning algorithm as BL-SSL. We sho w the performance of DA-2-BL-SSL also in Fig-ure 3. As we can see, compared with BL-SSL, DA-2-BL-SSL performed better, whic h suggests that the di erence between BL-SSL and DA-2-SSL is indeed caused to some degree by the di erence between the pseudo lab eled sen tences added to the training set. In other words, DA-2-SSL performed better than BL-SSL partly because DA-2 gave more accu-rate pseudo lab els than BL to start with. Next, let us com-pare DA-2-BL-SSL with DA-2-SSL. For F+M ) Y, DA-2-SSL performed consisten tly better than DA-2-BL-SSL for all values of m . For M+Y ) F, when m = 400 ; 600, DA-2-BL-SSL performed similarly to DA-2-SSL, but when m 800, DA-2-BL-SSL performed sligh tly better than DA-2-SSL. For Y+F ) M, DA-2-SSL again performed better than DA-2-BL-SSL except when m = 1000. This comparison between the two metho ds suggests that on the one hand, besides better pseudo lab els, our domain adaptiv e learning algorithm in DA-2-SSL also con tributed to the impro vemen t over BL in man y cases. On the other hand, when a relativ ely large num-ber of pseudo lab eled examples are used, the more aggressiv e metho d DA-2-SSL may introduce more noise, and hence not perform as well as the less aggressiv e, regular bootstrapping metho d. This again suggests that it is imp ortan t to nd a good value of m .
The problem of domain adaptation has dra wn a lot of at-ten tion recen tly. For text analysis and textual information managemen t, people have prop osed di eren t metho ds to ad-dress the domain adaptation problem in the speci c learning tasks they study [13, 6, 9, 5].

Recen tly there have also been a few studies that prop osed principled metho ds to address the general domain adapta-tion problem. In most studies, it is assumed that there is a single source domain and a target domain. Daum e and Marcu prop osed a mo del in whic h they assume that the data in eac h domain is generated from a mixture of a general distribution and a domain-sp eci c distribution, and these distributions share a common prior [7]. With lab eled exam-ples from both the source domain and the target domain, they can join tly learn the three distributions as well as the classi cation mo dels for eac h distribution. Li and Bilmes prop osed a metho d for domain adaptation by imp osing a Bayesian div ergence prior learned from the source domain when training on the target domain [12].

Ando and Zhang [1] prop osed a multi-task learning metho d for semi-sup ervised learning. Although their metho d was not designed for domain adaptation, later in [4, 2], the au-thors borro wed Ando and Zhang's metho d, and studied the domain adaptation problem from a feature represen tation persp ectiv e. They iden tify a generalizable feature repre-sen tation across domains by creating man y auxiliary prob-lems and performing multi-task learning on these problems. Their assumption is that a good common represen tation for these auxiliary problems is also a good represen tation for the learning problem of interest. Our mo del looks very sim-Figure 2: Comparison between BL, DA-1 and DA-2 as h Varies Figure 3: Comparison between BL-SSL, BL-SSL-2, DA-2-SSL and DA-2-BL-SSL as m Varies ilar to the mo del in the aforemen tioned work. However, in con trast, our mo del is a special case of multi-task learn-ing where both the lower-dimensional feature represen tation and the weigh ts for these features are shared by the di eren t tasks, because we are essen tially learning the same task.
Classi cation is an imp ortan t technique for man y kno wl-edge managemen t applications, but we often lack training data in the domain in whic h we want to mak e predictions. If we have training data from some related domains, we can adapt the classi er learned from these related source do-mains to our target domain. In this work, we prop osed a two-stage approac h to domain adaptation for statistical classi ers where at the rst stage we try to nd a gener-alizable feature represen tation across di eren t domains as well as appropriate weigh ts for these features, and at the second stage we try to pick up features speci cally useful for the target domain by emplo ying semi-sup ervised learn-ing. Our exp erimen t results from the gene name recognition task using a real data set sho w that our prop osed two-stage approac h coupled with the heuristics we have prop osed is e ectiv e for domain adaptation. Our two-stage approac h is a general metho d so it should be applicable to other tasks that involve domain adaptation for classi ers.

In our metho d, there are sev eral parameters that need to be set. The regularization parameter is similar to what is used in regular sup ervised learning, and therefore can be tuned by regular cross validation. For s , we set it to 10 6 , but we have found it not very sensitiv e as long as s 1. For t , curren tly we set it to 1. Since this parameter con-trols how much we want to rely on the pseudo-lab eled target domain examples, in our future work, we will vary the value and study its impact to the performance. The parameter h de nes the num ber of generalizable features to use. In our exp erimen ts, setting h to a relativ ely large value is safe. However, we need exp erimen ts on more data sets in order to dra w any conclusion. On the other hand, presumably we can use domain cross validation to select a good h . We also leave this study to our future work. The parameter m de-nes the num ber of pseudo lab eled target examples to use. As in regular bootstrapping metho d, setting this num ber can be tric ky. In the future, we will also study automatic ways of choosing a safe range for m .

Our curren t framew ork also has the limitation that in or-der to iden tify the generalizable features, we need to have at least two domains in the training data. In the future, we plan to remo ve this constrain t, and study whether target examples with pseudo lab els can also help us iden tify the generalizable features.
This researc h is supp orted in part by MIAS, a DHS Insti-tute of Discrete Science Cen ter for Multimo dal Information Access and Syn thesis, and by National Science Foundation under award num ber 0425852. We thank the anon ymous review ers for their invaluable commen ts. [1] R. K. Ando and T. Zhang. A framew ork for learning [2] S. Ben-Da vid, J. Blitzer, K. Crammer, and F. Pereira. [3] J. C. Bezdek and R. J. Hatha way. Some notes on [4] J. Blitzer, R. McDonald, and F. Pereira. Domain [5] Y. S. Chan and H. T. Ng. Estimating class priors in [6] C. Chelba and A. Acero. Adaptation of maxim um [7] H. Daum e III and D. Marcu. Domain adaptation for [8] J. Fink el, S. Dingare, C. D. Manning, M. Nissim, [9] R. Florian, H. Hassan, A. Ittycheriah, H. Jing, [10] D. W. Hosmer and S. Lemesho w. Applie d Logistic [11] J. Jiang and C. Zhai. Exploiting domain structure for [12] X. Li and J. Bilmes. A Bayesian div ergence prior for [13] B. Roark and M. Bacc hiani. Sup ervised and [14] V. N. Vapnik. The Natur e of Statistic al Learning [15] X. Zhu. Semi-sup ervised learning literature surv ey.
